{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndestroys a bucket directory or file. Specifying recursive = True TracingEnabled recursively deletes all subdirectories and files.", "response": "def destroy(self, url, recursive=False):\n        \"\"\"Destroy a bucket, directory, or file. Specifying recursive=True\n        recursively deletes all subdirectories and files.\"\"\"\n        bucket, obj_key = _parse_url(url)\n\n        if not bucket:\n            raise InvalidURL(url,\n                             \"You must specify a bucket and (optional) path\")\n\n        if obj_key:\n            target = \"/\".join((bucket, obj_key))\n        else:\n            target = bucket\n\n        if recursive:\n            for obj in self.get(url, delimiter=''):\n                self.destroy(obj['url'])\n\n        return self.call(\"DeleteBucket\", bucket=target)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy a local file to an S3 location.", "response": "def upload(self, local_path, remote_url):\n        \"\"\"Copy a local file to an S3 location.\"\"\"\n        bucket, key = _parse_url(remote_url)\n\n        with open(local_path, 'rb') as fp:\n            return self.call(\"PutObject\", bucket=bucket, key=key, body=fp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(self, remote_url, local_path, buffer_size=8 * 1024):\n        bucket, key = _parse_url(remote_url)\n\n        response_file = self.call(\"GetObject\", bucket=bucket, key=key)['Body']\n        with open(local_path, 'wb') as fp:\n            buf = response_file.read(buffer_size)\n            while buf:\n                fp.write(buf)\n                buf = response_file.read(buffer_size)", "response": "Copy S3 data to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self, src_url, dst_url):\n        src_bucket, src_key = _parse_url(src_url)\n        dst_bucket, dst_key = _parse_url(dst_url)\n\n        if not dst_bucket:\n            dst_bucket = src_bucket\n        params = {\n            'copy_source': '/'.join((src_bucket, src_key)),\n            'bucket': dst_bucket,\n            'key': dst_key,\n        }\n        return self.call(\"CopyObject\", **params)", "response": "Copy an S3 object to another S3 location."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies a single S3 object to another S3 location then delete the original object.", "response": "def move(self, src_url, dst_url):\n        \"\"\"Copy a single S3 object to another S3 location, then delete the\n        original object.\"\"\"\n        self.copy(src_url, dst_url)\n        self.destroy(src_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexpands paths ( e. g. css. css in files_root", "response": "def expand_file_names(path, files_root):\n    \"\"\"\n    Expands paths (e.g. css/*.css in files_root /actual/path/to/css/files/)\n    \"\"\"\n    # For non-wildcards just return the path. This allows us to detect when\n    # explicitly listed files are missing.\n    if not any(wildcard in path for wildcard in '*?['):\n        return [path]\n    else:\n        dir_path, filename = os.path.split(path)\n        return [os.path.join(dir_path, f) for f in fnmatch.filter(os.listdir(os.path.join(files_root, dir_path)), filename)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_redis_shards(self):\n        self._shards = {}\n        if self._sentinels is not None:\n            self.init_shards_from_sentinel()\n        elif self._masters is not None:\n            self.init_shards_from_masters()\n        else:\n            raise Exception(\"You must either specify sentinels or masters\")", "response": "Initializes the internal _shards property of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a key string given a key type and a key id.", "response": "def get_key(self, key_type, key_id):\n        \"\"\"\n        get_key constructs a key given a key type and a key id.\n        Keyword arguments:\n        key_type -- the type of key (e.g.: 'friend_request')\n        key_id -- the key id (e.g.: '12345')\n\n        returns a string representing the key\n        (e.g.: 'friend_request:{12345}')\n        \"\"\"\n        return \"{0}:{1}{2}{3}\".format(key_type, self._hash_start, key_id,\n                                      self._hash_stop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_shard_by_key(self, key):\n        key_id = self._get_key_id_from_key(key)\n        return self.get_shard_by_key_id(key_id)", "response": "Returns the Redis shard given a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_canonical_key_id(self, key_id):\n        shard_num = self.get_shard_num_by_key_id(key_id)\n        return self._canonical_keys[shard_num]", "response": "This method returns the canonical key id for the given key id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_shard_by_num(self, shard_num):\n        if shard_num < 0 or shard_num >= self.num_shards():\n            raise ValueError(\"requested invalid shard# {0}\".format(shard_num))\n\n        return self._shards[shard_num]", "response": "Returns the entry in the named shard."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_key_id_from_key(self, key):\n        key_id = key\n\n        regex = '{0}([^{1}]*){2}'.format(self._hash_start, self._hash_stop,\n                                         self._hash_stop)\n        m = re.search(regex, key)\n        if m is not None:\n            # Use what's inside the hash tags as the key id, if present.\n            # Otherwise the whole key will be used as the key id.\n            key_id = m.group(1)\n\n        return key_id", "response": "Internal method to derive the key id from a key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_canonical_key_ids(self, search_amplifier=100):\n        canonical_keys = {}\n        num_shards = self.num_shards()\n        # Guarantees enough to find all keys without running forever\n        num_iterations = (num_shards**2) * search_amplifier\n        for key_id in range(1, num_iterations):\n            shard_num = self.get_shard_num_by_key(str(key_id))\n            if shard_num in canonical_keys:\n                continue\n            canonical_keys[shard_num] = str(key_id)\n            if len(canonical_keys) == num_shards:\n                break\n\n        if len(canonical_keys) != num_shards:\n            raise ValueError(\"Failed to compute enough keys. \" +\n                             \"Wanted %d, got %d (search_amp=%d).\".format(\n                                 num_shards, len(canonical_keys),\n                                 search_amplifier))\n\n        return canonical_keys", "response": "This method computes the canonical key ids for all of the entries in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps that queries every shard and returns a list of keys.", "response": "def keys(self, args):\n        \"\"\"\n        keys wrapper that queries every shard. This is an expensive\n        operation.\n\n        This method should be invoked on a TwemRedis instance as if it\n        were being invoked directly on a StrictRedis instance.\n        \"\"\"\n        results = {}\n        # TODO: parallelize\n        for shard_num in range(0, self.num_shards()):\n            shard = self.get_shard_by_num(shard_num)\n            results[shard_num] = shard.keys(args)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mget(self, args):\n        key_map = collections.defaultdict(list)\n        results = {}\n        for key in args:\n            shard_num = self.get_shard_num_by_key(key)\n            key_map[shard_num].append(key)\n\n        # TODO: parallelize\n        for shard_num in key_map.keys():\n            shard = self.get_shard_by_num(shard_num)\n            results[shard_num] = shard.mget(key_map[shard_num])\n        return results", "response": "wrapper that batches keys per shard and execute as few\n        mgets as necessary to fetch the keys from all the shards involved."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping that batches keys per shard and execute as few msets as necessary to set the keys in all the shards involved.", "response": "def mset(self, args):\n        \"\"\"\n        mset wrapper that batches keys per shard and execute as few\n        msets as necessary to set the keys in all the shards involved.\n\n        This method should be invoked on a TwemRedis instance as if it\n        were being invoked directly on a StrictRedis instance.\n        \"\"\"\n        key_map = collections.defaultdict(dict)\n        result_count = 0\n        for key in args.keys():\n            value = args[key]\n            shard_num = self.get_shard_num_by_key(key)\n            key_map[shard_num][key] = value\n\n        # TODO: parallelize\n        for shard_num in key_map.keys():\n            shard = self.get_shard_by_num(shard_num)\n            result_count += shard.mset(key_map[shard_num])\n\n        return result_count"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_nested_attribute(obj, attribute):\n    parent, attr = resolve_nested_attribute(obj, attribute)\n    if not parent is None:\n        attr_value = getattr(parent, attr)\n    else:\n        attr_value = None\n    return attr_value", "response": "Returns the value of the given ( possibly dotted ) attribute for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_nested_attribute(obj, attribute, value):\n    parent, attr = resolve_nested_attribute(obj, attribute)\n    if parent is None:\n        raise AttributeError('Can not set attribute \"%s\" on None value.'\n                             % attr)\n    setattr(parent, attr, value)", "response": "Sets the value of the given attribute for the given object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef id_generator(start=0):\n    count = start\n    while True:\n        send_value = (yield count)\n        if not send_value is None:\n            if send_value < count:\n                raise ValueError('Values from ID generator must increase '\n                                 'monotonically (current value: %d; value '\n                                 'sent to generator: %d).'\n                                 % (count, send_value))\n            count = send_value\n        else:\n            count += 1", "response": "Generator for sequential numeric numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a class registered as the filter specification visitor utility under the given name.", "response": "def get_filter_specification_visitor(name, registry=None):\n    \"\"\"\n    Returns a the class registered as the filter specification\n    visitor utility under the given name (one of the\n    :const:`everest.querying.base.EXPRESSION_KINDS` constants).\n\n    :returns: class implementing\n        :class:`everest.interfaces.IFilterSpecificationVisitor`\n    \"\"\"\n    if registry is None:\n        registry = get_current_registry()\n    return registry.getUtility(IFilterSpecificationVisitor, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_order_specification_visitor(name, registry=None):\n    if registry is None:\n        registry = get_current_registry()\n    return registry.getUtility(IOrderSpecificationVisitor, name=name)", "response": "Returns the class registered as the order specification\n    visitor utility under the given name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_repository(name=None):\n    repo_mgr = get_repository_manager()\n    if name is None:\n        repo = repo_mgr.get_default()\n    else:\n        repo = repo_mgr.get(name)\n    return repo", "response": "Returns the repository with the given name or the default repository."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the main application from the given. ini file.", "response": "def app_name_from_ini_file(ini_file_path):\n    \"\"\"\n    Returns the name of the main application from the given ini file. See\n    :function:`app_name_from_ini_parser` for details.\n\n    :param ini_file_path: Path to the .ini file to parse.\n    \"\"\"\n    parser = configparser.SafeConfigParser()\n    parser.read(ini_file_path)\n    return app_name_from_ini_parser(parser)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the name of the main application from the given ini file parser.", "response": "def app_name_from_ini_parser(ini_parser):\n    \"\"\"\n    Returns the name of the main application from the given ini file parser.\n    The name is found as follows:\n     * If the ini file contains only one app:<app name> section,\n       return this app name;\n     * Else, if the ini file contains a pipeline:main section, use\n       the name of the innermost app;\n     * Else raise ValueError.\n\n    :param ini_parser: :class:`configparser.SafeConfigParser` instance with\n        an ini file read.\n    \"\"\"\n    app_names = [sect.split(':')[-1]\n                 for sect in ini_parser.sections()\n                 if sect[:4] == 'app:']\n    if len(app_names) == 1:\n        app_name = app_names[0]\n    else:\n        pp_sect_name = 'pipeline:main'\n        if ini_parser.has_section(pp_sect_name):\n            pipeline_apps = ini_parser.get(pp_sect_name, 'pipeline').split()\n            app_name = pipeline_apps[-1]\n        else:\n            raise ValueError('Could not determine application name. '\n                             'You need to either define exactly one '\n                             'app:<app name> section or a '\n                             'pipeline:main section in your ini '\n                             'file.')\n    return app_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generative(func):\n    def wrap(inst, *args, **kw):\n        clone = type(inst).__new__(type(inst))\n        clone.__dict__ = inst.__dict__.copy()\n        return func(clone, *args, **kw)\n    return update_wrapper(wrap, func)", "response": "Mark an instance method as generative.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntruncate the given message to the given limit length.", "response": "def truncate(message, limit=500):\n    \"\"\"\n    Truncates the message to the given limit length. The beginning and the\n    end of the message are left untouched.\n    \"\"\"\n    if len(message) > limit:\n        trc_msg = ''.join([message[:limit // 2 - 2],\n                           ' .. ',\n                           message[len(message) - limit // 2 + 2:]])\n    else:\n        trc_msg = message\n    return trc_msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving board from the boards. txt file", "response": "def remove_board(board_id):\n    \"\"\"remove board.\n\n    :param board_id: board id (e.g. 'diecimila')\n    :rtype: None\n\n    \"\"\"\n\n    log.debug('remove %s', board_id)\n    lines = boards_txt().lines()\n    lines = filter(lambda x: not x.strip().startswith(board_id + '.'), lines)\n    boards_txt().write_lines(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_route(self, route) -> dict:\r\n        middleware = route['middleware'] if 'middleware' in route else None\r\n        # added to ALL requests to support xhr cross-site requests\r\n        route['methods'].append('OPTIONS')\r\n        return {\r\n            'url': route['url'],\r\n            'name': route['name'],\r\n            'methods': route['methods'],\r\n            'middleware': middleware,\r\n            'callback': {\r\n                'module': route['function'].__module__,\r\n                'class': route['function'].__qualname__.rsplit('.', 1)[0],\r\n                'function': route['function'].__name__\r\n            }\r\n        }", "response": "Construct a dictionary that can be used to parse a route into flask App"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef construct_routes(self):\r\n        modules = self.evernode_app.get_modules()\r\n        for module_name in modules:\r\n            with self.app.app_context():\r\n                module = importlib.import_module(\r\n                    'modules.%s.routes' % (module_name))\r\n                for route in module.routes:\r\n                    self.routes.append(self.make_route(route))\r\n        if self.app.config['DEBUG']:\r\n            print('--- Loaded Modules ---')\r\n            print(\"Loaded Modules: \" + str(modules))", "response": "Builds the routes. py and adds them to the routes list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diffusion_driver(self):\n        if self._diffusion_driver is None:\n            return self,\n        if isinstance(self._diffusion_driver, list):\n            return tuple(self._diffusion_driver)\n        if isinstance(self._diffusion_driver, tuple):\n            return self._diffusion_driver\n        return self._diffusion_driver,", "response": "Return a list of the diffusion driver of the process X."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_codenames(self, dry_run=None, clear_existing=None):\n        self.created_codenames = []\n        self.updated_names = []\n        actions = [\"add\", \"change\", \"delete\", \"view\"]\n        if django.VERSION >= (2, 1):\n            actions.append(\"view\")\n        for app in django_apps.get_app_configs():\n            for model in app.get_models():\n                try:\n                    getattr(model, model._meta.simple_history_manager_attribute)\n                except AttributeError:\n                    pass\n                else:\n                    self.update_or_create(\n                        model, dry_run=dry_run, clear_existing=clear_existing\n                    )\n        if dry_run:\n            print(\"This is a dry-run. No modifications were made.\")\n        if self.created_codenames:\n            print(\"The following historical permission.codenames were be added:\")\n            pprint(self.created_codenames)\n        else:\n            print(\"No historical permission.codenames were added.\")\n        if self.updated_names:\n            print(\"The following historical permission.names were updated:\")\n            pprint(self.updated_names)\n        else:\n            print(\"No historical permission.names were updated.\")", "response": "Resets the codenames of all historical model models."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging-in to the user and store the session ID if possible.", "response": "def login(self, username, password, disableautosave=True, print_response=True):\n        \"\"\"\n        :param username:\n        :param password:\n        :param disableautosave: boolean\n        :param print_response: print log if required\n        :return: status code, response data\n        \"\"\"\n        if type(username) != str:\n            return False, \"Username must be string\"\n\n        if type(password) != str:\n            return False, \"Password must be string\"\n\n        if type(disableautosave) != bool:\n            return False, \"Disableautosave must be boolean\"\n\n        data = {\"username\": username, \"password\": password, \"disableautosave\": disableautosave}\n\n        status_response, response = self.call_api(\"r/user/login/\", data, print_response=print_response)\n\n        # Store httpcookie if possible\n        if status_response and \"deployr\" in response:\n            if \"response\" in response[\"deployr\"]:\n                if \"httpcookie\" in response[\"deployr\"][\"response\"]:\n                    self.JSESSIONID = response[\"deployr\"][\"response\"][\"httpcookie\"]\n\n        return status_response, response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_rinput(self, name, input_type, value):\n        if type(name) != str:\n            return False, \"Name must be string\"\n\n        if type(input_type) != str:\n            return False, \"Input type must be string\"\n\n        self.r_inputs[name] = {\"type\": input_type, \"value\": value}\n\n        return True, \"Ok\"", "response": "Set rinput to be used in next api call"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_routput(self, routput):\n        if type(routput) != str:\n            return False, \"Routput must be string\"\n\n        self.r_outputs.append(routput)\n\n        return True, \"Ok\"", "response": "Add routput to be used in next api call"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall api with given parameters and returns its result", "response": "def call_api(self, url, data, files={}, print_response=True):\n        \"\"\"\n        call api with given parameters and returns its result\n        :param url: end point\n        :param data: post data\n        :param files: files if needed\n        :param print_response: print log if required\n        :return: status code, response\n        \"\"\"\n        if type(url) != str:\n            return False, \"Url must be string\"\n\n        if type(data) != dict:\n            return False, \"Data must be a dict\"\n\n        if type(files) != dict:\n            return False, \"Files must be a dict\"\n\n        if type(print_response) != bool:\n            return False, \"Print_response must be boolean\"\n\n        url = self.HOST + url\n        data[\"format\"] = \"json\"\n        cookies = {\"JSESSIONID\": self.JSESSIONID}\n\n        # Add rinputs to post data\n        if self.r_inputs:\n            data[\"inputs\"] = json.dumps(self.r_inputs)\n\n        # Add routputs to post data\n        if self.r_outputs:\n            data[\"robjects\"] = \",\".join(self.r_outputs)\n\n        try:\n            response = requests.post(url, data=data, files=files, cookies=cookies)\n        except requests.exceptions.RequestException as exception:\n            self.clear_rdata()\n            return 500, {\"error\": str(exception)}\n\n        status_code = response.status_code\n\n        # Print log only if required\n        if print_response:\n            print status_code\n            print DeployRConnection.pretty_json(response.json())\n\n        # remove rinputs and routputs\n        self.clear_rdata()\n\n        return status_code, response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given attribute name is a terminal attribute of the given resource class.", "response": "def is_resource_class_terminal_attribute(rc, attr_name):\n    \"\"\"\n    Checks if the given attribute name is a terminal attribute of the given\n    registered resource.\n    \"\"\"\n    attr = get_resource_class_attribute(rc, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.TERMINAL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the given attribute name is a member attribute of the given resource class.", "response": "def is_resource_class_member_attribute(rc, attr_name):\n    \"\"\"\n    Checks if the given attribute name is a member attribute of the given\n    registered resource.\n    \"\"\"\n    attr = get_resource_class_attribute(rc, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.MEMBER"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the given attribute name is a collection attribute of the given registered resource.", "response": "def is_resource_class_collection_attribute(rc, attr_name):\n    \"\"\"\n    Checks if the given attribute name is a collection attribute of the given\n    registered resource.\n    \"\"\"\n    attr = get_resource_class_attribute(rc, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.COLLECTION"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_resource_class_resource_attribute(rc, attr_name):\n    attr = get_resource_class_attribute(rc, attr_name)\n    return attr != RESOURCE_ATTRIBUTE_KINDS.TERMINAL", "response": "Checks if the given attribute name is a resource attribute of the given registered resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_resource_class_terminal_attribute_iterator(rc):\n    for attr in itervalues_(rc.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.TERMINAL:\n            yield attr", "response": "Returns an iterator over all terminal attributes in the given registered resource class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all terminal attributes in the given registered resource.", "response": "def get_resource_class_relationship_attribute_iterator(rc):\n    \"\"\"\n    Returns an iterator over all terminal attributes in the given registered\n    resource.\n    \"\"\"\n    for attr in itervalues_(rc.__everest_attributes__):\n        if attr.kind != RESOURCE_ATTRIBUTE_KINDS.TERMINAL:\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an iterator over all terminal attributes in the given registered .", "response": "def get_resource_class_member_attribute_iterator(rc):\n    \"\"\"\n    Returns an iterator over all terminal attributes in the given registered\n    resource.\n    \"\"\"\n    for attr in itervalues_(rc.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.MEMBER:\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator over all terminal attributes in the given registered resource class.", "response": "def get_resource_class_collection_attribute_iterator(rc):\n    \"\"\"\n    Returns an iterator over all terminal attributes in the given registered\n    resource.\n    \"\"\"\n    for attr in itervalues_(rc.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.COLLECTION:\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncommands line interface for the update - dotdee program.", "response": "def main():\n    \"\"\"Command line interface for the ``update-dotdee`` program.\"\"\"\n    # Initialize logging to the terminal and system log.\n    coloredlogs.install(syslog=True)\n    # Parse the command line arguments.\n    context_opts = {}\n    program_opts = {}\n    try:\n        options, arguments = getopt.getopt(sys.argv[1:], 'fur:vqh', [\n            'force', 'use-sudo', 'remote-host=',\n            'verbose', 'quiet', 'help',\n        ])\n        for option, value in options:\n            if option in ('-f', '--force'):\n                program_opts['force'] = True\n            elif option in ('-u', '--use-sudo'):\n                context_opts['sudo'] = True\n            elif option in ('-r', '--remote-host'):\n                context_opts['ssh_alias'] = value\n            elif option in ('-v', '--verbose'):\n                coloredlogs.increase_verbosity()\n            elif option in ('-q', '--quiet'):\n                coloredlogs.decrease_verbosity()\n            elif option in ('-h', '--help'):\n                usage(__doc__)\n                sys.exit(0)\n            else:\n                # Programming error...\n                assert False, \"Unhandled option!\"\n        if not arguments:\n            usage(__doc__)\n            sys.exit(0)\n        if len(arguments) != 1:\n            raise Exception(\"Expected a filename as the first and only argument!\")\n        program_opts['filename'] = arguments[0]\n    except Exception as e:\n        warning(\"Error: %s\", e)\n        sys.exit(1)\n    # Run the program.\n    try:\n        # Initialize the execution context.\n        program_opts['context'] = create_context(**context_opts)\n        # Initialize the program and update the file.\n        UpdateDotDee(**program_opts).update_file()\n    except Exception as e:\n        logger.exception(\"Encountered unexpected exception, aborting!\")\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding days to the current value", "response": "def add_days(self, days: int) -> datetime:\n        \"\"\" Adds days \"\"\"\n        self.value = self.value + relativedelta(days=days)\n        return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_months(self, value: int) -> datetime:\n        self.value = self.value + relativedelta(months=value)\n        return self.value", "response": "Add a number of months to the given date"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_date(self, value: date) -> datetime:\n        assert isinstance(value, date)\n\n        #self.value = datetime.combine(value, time.min)\n        self.value = datetime(value.year, value.month, value.day)\n        return self.value", "response": "Initializes from a date value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_iso_long_date(self, date_str: str) -> datetime:\n        assert isinstance(date_str, str)\n        assert len(date_str) == 19\n\n        self.value = datetime.strptime(date_str, ISO_LONG_FORMAT)\n        return self.value", "response": "Parse ISO long date string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_iso_date_string(self, date_str: str) -> datetime:\n        assert isinstance(date_str, str)\n\n        self.value = datetime.strptime(date_str, ISO_DATE_FORMAT)\n        return self.value", "response": "Parse ISO date string into a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the day name of the current locale", "response": "def get_day_name(self) -> str:\n        \"\"\" Returns the day name \"\"\"\n        weekday = self.value.isoweekday() - 1\n        return calendar.day_name[weekday]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the ISO string for the given date", "response": "def to_iso_string(self) -> str:\n        \"\"\" Returns full ISO string for the given date \"\"\"\n        assert isinstance(self.value, datetime)\n        return datetime.isoformat(self.value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the end of the month for the given date", "response": "def end_of_month(self) -> datetime:\n        \"\"\" Provides end of the month for the given date \"\"\"\n        # Increase month by 1,\n        result = self.value + relativedelta(months=1)\n        # take the 1st day of the (next) month,\n        result = result.replace(day=1)\n        # subtract one day\n        result = result - relativedelta(days=1)\n        self.value = result\n        return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_end_of_month(self) -> bool:\n        end_of_month = Datum()\n        # get_end_of_month(value)\n        end_of_month.end_of_month()\n        return self.value == end_of_month.value", "response": "Checks if the date is at the end of the month"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the day value", "response": "def set_day(self, day: int) -> datetime:\n        \"\"\" Sets the day value \"\"\"\n        self.value = self.value.replace(day=day)\n        return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the current value", "response": "def set_value(self, value: datetime):\n        \"\"\" Sets the current value \"\"\"\n        assert isinstance(value, datetime)\n\n        self.value = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_of_day(self) -> datetime:\n        self.value = datetime(self.value.year, self.value.month, self.value.day)\n        return self.value", "response": "Returns start of day"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubtracting the given number of days from the current value.", "response": "def subtract_days(self, days: int) -> datetime:\n        \"\"\" Subtracts dates from the given value \"\"\"\n        self.value = self.value - relativedelta(days=days)\n        return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subtract_weeks(self, weeks: int) -> datetime:\n        self.value = self.value - timedelta(weeks=weeks)\n        return self.value", "response": "Subtracts number of weeks from the current value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subtract_months(self, months: int) -> datetime:\n        self.value = self.value - relativedelta(months=months)\n        return self.value", "response": "Subtracts a number of months from the current value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the ISO time string only", "response": "def to_short_time_string(self) -> str:\n        \"\"\" Return the iso time string only \"\"\"\n        hour = self.time.hour\n        minute = self.time.minute\n        return f\"{hour:02}:{minute:02}\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_long_time_string(self) -> str:\n        hour = self.time.hour\n        minute = self.time.minute\n        second = self.time.second\n        return f\"{hour:02}:{minute:02}:{second:02}\"", "response": "Return the ISO time string only"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_iso_time_string(self) -> str:\n        short_time = self.to_short_time_string()\n        second = self.time.second\n        return f\"{short_time}:{second:02}\"", "response": "Return the ISO time string only"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a human - readable string representation of the date and time of the resource.", "response": "def to_datetime_string(self) -> str:\n        \"\"\" Returns a human-readable string representation with iso date and time\n        Example: 2018-12-06 12:32:56\n        \"\"\"\n        date_display = self.to_iso_date_string()\n        time_display = self.to_long_time_string()\n        return f\"{date_display} {time_display}\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_long_datetime_string(self) -> str:\n        date_display = self.to_iso_date_string()\n        time_display = self.to_short_time_string()\n        return f\"{date_display} {time_display}\"", "response": "Returns the long date and time string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef today(self) -> datetime:\n        self.value = datetime.combine(datetime.today().date(), time.min)\n        return self.value", "response": "Returns today as datetime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef yesterday(self) -> datetime:\n        self.value = datetime.today() - timedelta(days=1)\n        return self.value", "response": "Set the value to yesterday"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_versions_from_webpage(self):\n        res = requests.get('https://zenodo.org/record/'+self.data['conceptrecid'])\n        soup = BeautifulSoup(res.text, 'html.parser')\n        version_rows = soup.select('.well.metadata > table.table tr')\n        if len(version_rows) == 0:  # when only 1 version\n            return [{\n                'recid': self.data['id'],\n                'name': '1',\n                'doi': self.data['doi'],\n                'date': self.data['created'],\n                'original_version': self.original_version()\n            }]\n        return [self._row_to_version(row) for row in version_rows if len(row.select('td')) > 1]", "response": "Get version details from Zenodo webpage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch Zenodo record for string search", "response": "def search(self, search):\n        \"\"\"search Zenodo record for string `search`\n\n        :param search: string to search\n        :return: Record[] results\n        \"\"\"\n        search = search.replace('/', ' ')  # zenodo can't handle '/' in search query\n        params = {'q': search}\n        return self._get_records(params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting list from QueryDict and remove blank date from list.", "response": "def qdict_get_list(qdict, k):\n    \"\"\"\n    get list from QueryDict and remove blank date from list.\n    \"\"\"\n    pks = qdict.getlist(k)\n    return [e for e in pks if e]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting next url form request order : POST. next GET. next HTTP_REFERER default_next", "response": "def request_get_next(request, default_next):\n    \"\"\"\n    get next url form request\n\n    order: POST.next GET.next HTTP_REFERER, default_next\n    \"\"\"\n    next_url = request.POST.get('next')\\\n        or request.GET.get('next')\\\n        or request.META.get('HTTP_REFERER')\\\n        or default_next\n    return next_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting foreground - and background colors and intensity.", "response": "def set_color(self, fg=None, bg=None, intensify=False, target=sys.stdout):\n        \"\"\"Set foreground- and background colors and intensity.\"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the given entity to this cache.", "response": "def add(self, entity):\n        \"\"\"\n        Adds the given entity to this cache.\n\n        :param entity: Entity to add.\n        :type entity: Object implementing :class:`everest.interfaces.IEntity`.\n        :raises ValueError: If the ID of the entity to add is ``None``\n          (unless the `allow_none_id` constructor argument was set).\n        \"\"\"\n        do_append = self.__check_new(entity)\n        if do_append:\n            self.__entities.append(entity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, entity):\n        self.__id_map.pop(entity.id, None)\n        self.__slug_map.pop(entity.slug, None)\n        self.__entities.remove(entity)", "response": "Removes the given entity from this cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve(self, filter_expression=None,\n                 order_expression=None, slice_key=None):\n        \"\"\"\n        Retrieve entities from this cache, possibly after filtering, ordering\n        and slicing.\n        \"\"\"\n        ents = iter(self.__entities)\n        if not filter_expression is None:\n            ents = filter_expression(ents)\n        if not order_expression is None:\n            # Ordering always involves a copy and conversion to a list, so\n            # we have to wrap in an iterator.\n            ents = iter(order_expression(ents))\n        if not slice_key is None:\n            ents = islice(ents, slice_key.start, slice_key.stop)\n        return ents", "response": "Retrieve entities from this cache possibly after filtering ordering\n            and slicing."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the user - related keywords from a generator of Twitter lists.", "response": "def extract_user_keywords_generator(twitter_lists_gen, lemmatizing=\"wordnet\"):\n    \"\"\"\n    Based on the user-related lists I have downloaded, annotate the users.\n\n    Inputs: - twitter_lists_gen: A python generator that yields a user Twitter id and a generator of Twitter lists.\n            - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\".\n\n    Yields: - user_twitter_id: A Twitter user id.\n            - user_annotation: A python dictionary that contains two dicts:\n                * bag_of_lemmas: Maps emmas to multiplicity.\n                * lemma_to_keywordbag: A python dictionary that maps stems/lemmas to original topic keywords.\n    \"\"\"\n    ####################################################################################################################\n    # Extract keywords serially.\n    ####################################################################################################################\n    for user_twitter_id, twitter_lists_list in twitter_lists_gen:\n        if twitter_lists_list is not None:\n            if \"lists\" in twitter_lists_list.keys():\n                twitter_lists_list = twitter_lists_list[\"lists\"]\n\n            bag_of_lemmas, lemma_to_keywordbag = user_twitter_list_bag_of_words(twitter_lists_list, lemmatizing)\n\n            for lemma, keywordbag in lemma_to_keywordbag.items():\n                lemma_to_keywordbag[lemma] = dict(keywordbag)\n            lemma_to_keywordbag = dict(lemma_to_keywordbag)\n\n            user_annotation = dict()\n            user_annotation[\"bag_of_lemmas\"] = bag_of_lemmas\n            user_annotation[\"lemma_to_keywordbag\"] = lemma_to_keywordbag\n\n            yield user_twitter_id, user_annotation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nform the user - label matrix for multi - label classification.", "response": "def form_user_label_matrix(user_twitter_list_keywords_gen, id_to_node, max_number_of_labels):\n    \"\"\"\n    Forms the user-label matrix to be used in multi-label classification.\n\n    Input:   - user_twitter_list_keywords_gen:\n             - id_to_node:  A Twitter id to node map as a python dictionary.\n\n    Outputs: - user_label_matrix: A user-to-label matrix in scipy sparse matrix format.\n             - annotated_nodes: A numpy array containing graph nodes.\n             - label_to_lemma: A python dictionary that maps a numerical label to a string topic lemma.\n             - lemma_to_keyword: A python dictionary that maps a lemma to the original keyword.\n    \"\"\"\n    user_label_matrix, annotated_nodes, label_to_lemma, node_to_lemma_tokeywordbag = form_user_term_matrix(user_twitter_list_keywords_gen,\n                                                                                                           id_to_node,\n                                                                                                           None)\n\n    # write_terms_and_frequencies(\"/home/georgerizos/Documents/term_matrix.txt\", user_label_matrix, label_to_lemma)\n\n    user_label_matrix, annotated_nodes, label_to_lemma = filter_user_term_matrix(user_label_matrix,\n                                                                                 annotated_nodes,\n                                                                                 label_to_lemma,\n                                                                                 max_number_of_labels)\n\n    # write_terms_and_frequencies(\"/home/georgerizos/Documents/label_matrix.txt\", user_label_matrix, label_to_lemma)\n\n    lemma_to_keyword = form_lemma_tokeyword_map(annotated_nodes, node_to_lemma_tokeywordbag)\n\n    return user_label_matrix, annotated_nodes, label_to_lemma, lemma_to_keyword"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nforming a user - to - term matrix.", "response": "def form_user_term_matrix(user_twitter_list_keywords_gen, id_to_node, lemma_set=None, keyword_to_topic_manual=None):\n    \"\"\"\n    Forms a user-term matrix.\n\n    Input:   - user_twitter_list_keywords_gen: A python generator that yields a user Twitter id and a bag-of-words.\n             - id_to_node:  A Twitter id to node map as a python dictionary.\n             - lemma_set: For the labelling, we use only lemmas in this set. Default: None\n\n    Outputs: - user_term_matrix: A user-to-term matrix in scipy sparse matrix format.\n             - annotated_nodes: A numpy array containing graph nodes.\n             - label_to_topic: A python dictionary that maps a numerical label to a string topic/keyword.\n             - node_to_lemma_tokeywordbag: A python dictionary that maps nodes to lemma-to-keyword bags.\n    \"\"\"\n    # Prepare for iteration.\n    term_to_attribute = dict()\n\n    user_term_matrix_row = list()\n    user_term_matrix_col = list()\n    user_term_matrix_data = list()\n\n    append_user_term_matrix_row = user_term_matrix_row.append\n    append_user_term_matrix_col = user_term_matrix_col.append\n    append_user_term_matrix_data = user_term_matrix_data.append\n\n    annotated_nodes = list()\n    append_node = annotated_nodes.append\n\n    node_to_lemma_tokeywordbag = dict()\n\n    invalid_terms = list()\n    counter = 0\n\n    if keyword_to_topic_manual is not None:\n        manual_keyword_list = list(keyword_to_topic_manual.keys())\n\n    for user_twitter_id, user_annotation in user_twitter_list_keywords_gen:\n        counter += 1\n        # print(counter)\n        bag_of_words = user_annotation[\"bag_of_lemmas\"]\n        lemma_to_keywordbag = user_annotation[\"lemma_to_keywordbag\"]\n\n        if lemma_set is not None:\n            bag_of_words = {lemma: multiplicity for lemma, multiplicity in bag_of_words.items() if lemma in lemma_set}\n            lemma_to_keywordbag = {lemma: keywordbag for lemma, keywordbag in lemma_to_keywordbag.items() if lemma in lemma_set}\n\n        node = id_to_node[user_twitter_id]\n        append_node(node)\n        node_to_lemma_tokeywordbag[node] = lemma_to_keywordbag\n        for term, multiplicity in bag_of_words.items():\n            if term == \"news\":\n                continue\n\n            if keyword_to_topic_manual is not None:\n                keyword_bag = lemma_to_keywordbag[term]\n                term = max(keyword_bag.keys(), key=(lambda key: keyword_bag[key]))\n\n                found_list_of_words = simple_word_query(term, manual_keyword_list, edit_distance=1)\n\n                if len(found_list_of_words) > 0:\n                    term = found_list_of_words[0]\n\n                try:\n                    term = keyword_to_topic_manual[term]\n                except KeyError:\n                    print(term)\n\n            vocabulary_size = len(term_to_attribute)\n            attribute = term_to_attribute.setdefault(term, vocabulary_size)\n\n            append_user_term_matrix_row(node)\n            append_user_term_matrix_col(attribute)\n            append_user_term_matrix_data(multiplicity)\n\n    annotated_nodes = np.array(list(set(annotated_nodes)), dtype=np.int64)\n\n    user_term_matrix_row = np.array(user_term_matrix_row, dtype=np.int64)\n    user_term_matrix_col = np.array(user_term_matrix_col, dtype=np.int64)\n    user_term_matrix_data = np.array(user_term_matrix_data, dtype=np.float64)\n\n    user_term_matrix = sparse.coo_matrix((user_term_matrix_data,\n                                          (user_term_matrix_row, user_term_matrix_col)),\n                                         shape=(len(id_to_node), len(term_to_attribute)))\n\n    label_to_topic = dict(zip(term_to_attribute.values(), term_to_attribute.keys()))\n\n    # print(user_term_matrix.shape)\n    # print(len(label_to_topic))\n    # print(invalid_terms)\n\n    return user_term_matrix, annotated_nodes, label_to_topic, node_to_lemma_tokeywordbag"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering out labels that are too rare and have too few representatives.", "response": "def filter_user_term_matrix(user_term_matrix, annotated_nodes, label_to_topic, max_number_of_labels=None):\n    \"\"\"\n    Filters out labels that are either too rare, or have very few representatives.\n\n    Inputs:  - user_term_matrix: A user-to-term matrix in scipy sparse matrix format.\n             - annotated_nodes: A numpy array containing graph nodes.\n             - label_to_topic: A python dictionary that maps a numerical label to a string topic/keyword.\n             - max_number_of_labels: The upper limit for the number of labels.\n\n    Outputs: - user_term_matrix: The filtered user-to-term matrix in scipy sparse matrix format.\n             - annotated_nodes: A numpy array containing graph nodes.\n             - label_to_topic: A python dictionary that maps a numerical label to a string topic/keyword.\n    \"\"\"\n    # Aggregate edges and eliminate zeros.\n    user_term_matrix = user_term_matrix.tocsr()\n    user_term_matrix.eliminate_zeros()\n\n    ####################################################################################################################\n    # Enforce max number of labels if required.\n    ####################################################################################################################\n    # Form matrix that indicates which user-label pairs are nonzero.\n    temp_matrix = copy.copy(user_term_matrix)\n    temp_matrix.data = np.ones_like(temp_matrix.data).astype(np.int64)\n    temp_matrix.astype(np.int64)\n\n    # Calculate the label-user counts.\n    label_frequencies = temp_matrix.sum(axis=0)\n    index = np.argsort(np.squeeze(np.asarray(label_frequencies)))\n\n    # Apply max number of labels cutoff.\n    if max_number_of_labels is not None:\n        if index.size > max_number_of_labels:\n            index = index[:index.size-max_number_of_labels]\n    else:\n        index = np.array(list())\n\n    # If there are zero samples of a label, remove them from both the matrix and the label-to-topic map.\n\n    # percentile = 90\n    # p = np.percentile(label_frequencies, percentile)\n    # index = np.where(label_frequencies <= p)[1]\n    if index.size > 0:\n        index = np.squeeze(np.asarray(index))\n        index = np.setdiff1d(np.arange(label_frequencies.size), index)\n        user_term_matrix = user_term_matrix[:, index]\n        temp_map = dict()\n        counter = 0\n        for i in index:\n            temp_map[counter] = label_to_topic[i]\n            counter += 1\n        label_to_topic = temp_map\n\n    # print(user_term_matrix.getnnz())\n    # print(user_term_matrix.shape)\n\n    # Perform tf-idf on all matrices.\n    user_term_matrix = augmented_tf_idf(user_term_matrix)\n\n    ####################################################################################################################\n    # Most topics are heavy-tailed. For each topic, threshold to annotate.\n    ####################################################################################################################\n    user_term_nnz = user_term_matrix.getnnz()\n    # percentile = 80\n    percentile = 50\n\n    while True:\n        matrix_row = list()\n        matrix_col = list()\n        extend_matrix_row = matrix_row.extend\n        extend_matrix_col = matrix_col.extend\n\n        user_term_matrix = sparse.csc_matrix(user_term_matrix)\n        for topic in range(user_term_matrix.shape[1]):\n            col = user_term_matrix.getcol(topic)\n            p = np.percentile(col.data, percentile)\n            index = col.indices[col.data >= p]\n            extend_matrix_row(index)\n            extend_matrix_col(topic*np.ones_like(index))\n        matrix_row = np.array(matrix_row, dtype=np.int64)\n        matrix_col = np.array(matrix_col, dtype=np.int64)\n        matrix_data = np.ones_like(matrix_row, dtype=np.int8)\n        user_term_matrix = sparse.coo_matrix((matrix_data, (matrix_row, matrix_col)), shape=user_term_matrix.shape)\n        user_term_matrix = sparse.csr_matrix(user_term_matrix)\n\n        if (user_term_matrix.getnnz() > user_term_nnz/10) and (user_term_matrix.shape[1] > 1):\n            break\n        else:\n            percentile -= 10\n            if percentile <= 10:\n                break\n\n    # print(user_term_matrix.getnnz())\n    # print(user_term_matrix.shape)\n\n    ####################################################################################################################\n    # If there is a small number of samples of a label, remove them from both the matrix and the label-to-topic map.\n    ####################################################################################################################\n    user_term_nnz = user_term_matrix.getnnz()\n\n    minimum_frequency = 3\n\n    while True:\n        # Form matrix that indicates which user-label pairs are nonzero.\n        temp_matrix = copy.copy(user_term_matrix)\n        temp_matrix.data = np.ones_like(temp_matrix.data).astype(np.int64)\n        temp_matrix.astype(np.int64)\n\n        label_frequencies = temp_matrix.sum(axis=0)\n\n        # index = np.where(label_frequencies < 31)[1]  # Fewer than 10.\n        index = np.where(label_frequencies < minimum_frequency)[1]  # Fewer than 10.\n        if index.shape[1] > 0:\n            index = np.squeeze(np.asarray(index))\n            index = np.setdiff1d(np.arange(label_frequencies.size), index)\n            user_term_matrix = user_term_matrix[:, index]\n            temp_map = dict()\n            counter = 0\n            for i in index:\n                temp_map[counter] = label_to_topic[i]\n                counter += 1\n            label_to_topic = temp_map\n\n        if (user_term_matrix.getnnz() > user_term_nnz/2) and (user_term_matrix.shape[1] > 1):\n            break\n        else:\n            minimum_frequency -= 1\n            if minimum_frequency <= 1:\n                break\n\n    # print(user_term_matrix.getnnz())\n    # print(user_term_matrix.shape)\n\n    # print(len(label_to_topic))\n\n    return user_term_matrix, annotated_nodes, label_to_topic"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef form_lemma_tokeyword_map(annotated_nodes, node_to_lemma_tokeywordbag):\n    # Reduce relevant lemma-to-original keyword bags.\n    lemma_to_keywordbag = defaultdict(lambda: defaultdict(int))\n    for node in annotated_nodes:\n        for lemma, keywordbag in node_to_lemma_tokeywordbag[node].items():\n            for keyword, multiplicity in keywordbag.items():\n                lemma_to_keywordbag[lemma][keyword] += multiplicity\n\n    lemma_to_keyword = dict()\n    for lemma, keywordbag in lemma_to_keywordbag.items():\n        lemma_to_keyword[lemma] = max(keywordbag.items(), key=itemgetter(1))[0]\n\n    return lemma_to_keyword", "response": "Form the aggregated dictionary that maps lemmas to most popular topic keywords."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollecting at most 500 Twitter lists for each user from an input list of Twitter user ids. Inputs: - twitter_app_key: What is says on the tin. - twitter_app_secret: Ditto. - user_id_list: A python list of Twitter user ids. Yields: - user_twitter_id: A Twitter user id. - twitter_lists_list: A python list containing Twitter lists in dictionary (json) format.", "response": "def fetch_twitter_lists_for_user_ids_generator(twitter_app_key,\n                                               twitter_app_secret,\n                                               user_id_list):\n    \"\"\"\n    Collects at most 500 Twitter lists for each user from an input list of Twitter user ids.\n\n    Inputs: - twitter_app_key: What is says on the tin.\n            - twitter_app_secret: Ditto.\n            - user_id_list: A python list of Twitter user ids.\n\n    Yields: - user_twitter_id: A Twitter user id.\n            - twitter_lists_list: A python list containing Twitter lists in dictionary (json) format.\n    \"\"\"\n    ####################################################################################################################\n    # Log into my application.\n    ####################################################################################################################\n    twitter = login(twitter_app_key,\n                    twitter_app_secret)\n\n    ####################################################################################################################\n    # For each user, gather at most 500 Twitter lists.\n    ####################################################################################################################\n    get_list_memberships_counter = 0\n    get_list_memberships_time_window_start = time.perf_counter()\n    for user_twitter_id in user_id_list:\n        # Make safe twitter request.\n        try:\n            twitter_lists_list, get_list_memberships_counter, get_list_memberships_time_window_start\\\n                = safe_twitter_request_handler(twitter_api_func=twitter.get_list_memberships,\n                                               call_rate_limit=15,\n                                               call_counter=get_list_memberships_counter,\n                                               time_window_start=get_list_memberships_time_window_start,\n                                               max_retries=5,\n                                               wait_period=2,\n                                               user_id=user_twitter_id,\n                                               count=500,\n                                               cursor=-1)\n            # If the call is succesful, yield the list of Twitter lists.\n            yield user_twitter_id, twitter_lists_list\n        except twython.TwythonError:\n            # If the call is unsuccesful, we do not have any Twitter lists to store.\n            yield user_twitter_id, None\n        except URLError:\n            # If the call is unsuccesful, we do not have any Twitter lists to store.\n            yield user_twitter_id, None\n        except BadStatusLine:\n            # If the call is unsuccesful, we do not have any Twitter lists to store.\n            yield user_twitter_id, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decide_which_users_to_annotate(centrality_vector,\n                                   number_to_annotate,\n                                   already_annotated,\n                                   node_to_id):\n    \"\"\"\n    Sorts a centrality vector and returns the Twitter user ids that are to be annotated.\n\n    Inputs: - centrality_vector: A numpy array vector, that contains the centrality values for all users.\n            - number_to_annotate: The number of users to annotate.\n            - already_annotated: A python set of user twitter ids that have already been annotated.\n            - node_to_id: A python dictionary that maps graph nodes to user twitter ids.\n\n    Output: - user_id_list: A python list of Twitter user ids.\n    \"\"\"\n    # Sort the centrality vector according to decreasing centrality.\n    centrality_vector = np.asarray(centrality_vector)\n    ind = np.argsort(np.squeeze(centrality_vector))\n    if centrality_vector.size > 1:\n        reversed_ind = ind[::-1]\n    else:\n        reversed_ind = list()\n        reversed_ind = reversed_ind.append(ind)\n\n    # Get the sublist of Twitter user ids to return.\n    user_id_list = list()\n    append_user_id = user_id_list.append\n\n    counter = 0\n    for node in reversed_ind:\n        user_twitter_id = node_to_id[node]\n        if user_twitter_id not in already_annotated:\n            append_user_id(user_twitter_id)\n            counter += 1\n\n            if counter >= number_to_annotate:\n                break\n\n    return user_id_list", "response": "This function sorts a centrality vector and returns the list of Twitter user ids that are to be annotated."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_demand_annotation(twitter_app_key, twitter_app_secret, user_twitter_id):\n    ####################################################################################################################\n    # Log into my application\n    ####################################################################################################################\n    twitter = login(twitter_app_key, twitter_app_secret)\n\n    twitter_lists_list = twitter.get_list_memberships(user_id=user_twitter_id, count=1000)\n\n    for twitter_list in twitter_lists_list:\n        print(twitter_list)\n\n    return twitter_lists_list", "response": "A service that leverages twitter lists for on - demand annotation of popular users."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_member_class(resource):\n    reg = get_current_registry()\n    if IInterface in provided_by(resource):\n        member_class = reg.getUtility(resource, name='member-class')\n    else:\n        member_class = reg.getAdapter(resource, IMemberResource,\n                                      name='member-class')\n    return member_class", "response": "Returns the registered member class for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the registered collection resource class for the given marker interface or member resource class or instance.", "response": "def get_collection_class(resource):\n    \"\"\"\n    Returns the registered collection resource class for the given marker\n    interface or member resource class or instance.\n\n    :param rc: registered resource\n    :type rc: class implementing or instance providing or subclass of\n        a registered resource interface.\n    \"\"\"\n    reg = get_current_registry()\n    if IInterface in provided_by(resource):\n        coll_class = reg.getUtility(resource, name='collection-class')\n    else:\n        coll_class = reg.getAdapter(resource, ICollectionResource,\n                                    name='collection-class')\n    return coll_class"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_member(entity, parent=None):\n    reg = get_current_registry()\n    rc = reg.getAdapter(entity, IMemberResource)\n    if not parent is None:\n        rc.__parent__ = parent # interface method pylint: disable=E1121\n    return rc", "response": "A helper method that returns an object that is a location aware member resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL for the given resource.", "response": "def get_resource_url(resource):\n    \"\"\"\n    Returns the URL for the given resource.\n    \"\"\"\n    path = model_path(resource)\n    parsed = list(urlparse.urlparse(path))\n    parsed[1] = \"\"\n    return urlparse.urlunparse(parsed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef provides_resource(obj):\n    if isinstance(obj, type):\n        obj = object.__new__(obj)\n    return IResource in provided_by(obj)", "response": "Checks if the given object provides the\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given type or instance provides the .", "response": "def provides_member_resource(obj):\n    \"\"\"\n    Checks if the given type or instance provides the\n    :class:`everest.resources.interfaces.IMemberResource` interface.\n    \"\"\"\n    if isinstance(obj, type):\n        obj = object.__new__(obj)\n    return IMemberResource in provided_by(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the given type or instance provides the :class:`everest. resources. interfaces. ICollectionResource interface.", "response": "def provides_collection_resource(obj):\n    \"\"\"\n    Checks if the given type or instance provides the\n    :class:`everest.resources.interfaces.ICollectionResource` interface.\n    \"\"\"\n    if isinstance(obj, type):\n        obj = object.__new__(obj)\n    return ICollectionResource in provided_by(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all registered collection resource classes.", "response": "def get_registered_collection_resources():\n    \"\"\"\n    Returns a list of all registered collection resource classes.\n    \"\"\"\n    reg = get_current_registry()\n    return [util.component\n            for util in reg.registeredUtilities()\n            if util.name == 'collection-class']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resource_to_url(resource, request=None, quote=False):\n    if request is None:\n        request = get_current_request()\n#    cnv = request.registry.getAdapter(request, IResourceUrlConverter)\n    reg = get_current_registry()\n    cnv = reg.getAdapter(request, IResourceUrlConverter)\n    return cnv.resource_to_url(resource, quote=quote)", "response": "Converts the given resource to a URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the given URL to a resource.", "response": "def url_to_resource(url, request=None):\n    \"\"\"\n    Converts the given URL to a resource.\n\n    :param request: Request object (required for the host name part of the\n      URL). If this is not given, the current request is used.\n    \"\"\"\n    if request is None:\n        request = get_current_request()\n#    cnv = request.registry.getAdapter(request, IResourceUrlConverter)\n    reg = get_current_registry()\n    cnv = reg.getAdapter(request, IResourceUrlConverter)\n    return cnv.url_to_resource(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbalance Error Rate [ 0 1 )", "response": "def ber(tp, tn, fp, fn):\n    \"\"\"Balanced Error Rate [0, 1]\n    \n    :param int tp: number of true positives\n    :param int tn: number of true negatives\n    :param int fp: number of false positives\n    :param int fn: number of false negatives\n    :rtype: float \n    \"\"\"\n    return (fp / float(tn + fp) + fn / float(fn + tp)) / 2"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mcc(tp, tn, fp, fn):\n    if tp + fp == 0 or tp + fn == 0 or tn + fp == 0 or tn + fn == 0:\n        den = 1.0\n    else:\n        den = math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n    return (tp * tn - fp * fn) / den", "response": "Matthew s Correlation Coefficient"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmeans Squared Error :param exp: expected values :type exp: list of float :param obs: observed values :type obs: list of float", "response": "def mse(exp, obs):\n    \"\"\"Mean Squared Error\n    \n    :param exp: expected values\n    :type exp: list of float\n    :param obs: observed values\n    :type obs: list of float\n    \"\"\"\n    assert len(exp) == len(obs)\n    return numpy.mean((numpy.array(exp) - numpy.array(obs)) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef roc(clss, vals, reverse=False):\n    assert len(clss) == len(vals)\n    global X, Y, A, T, M, B\n    \n    order = numpy.argsort(vals)\n    if reverse:\n        order = order[::-1]\n    clss = numpy.array(clss)[order]\n    vals = numpy.array(vals)[order]\n    \n    length = len(clss) + 1\n    data = numpy.empty((length, 6), dtype=numpy.float32)\n    data[0, X], data[0, Y], data[0, A] = 0\n    data[0, T] = vals[0]\n    \n    for i in range(length-1):\n        if clss[i] == 1:\n            data[i+1, X] = data[i, X]\n            data[i+1, Y] = data[i, Y] + 1\n            data[i+1, A] = data[i, A]\n        else:\n            data[i+1, X] = data[i, X] + 1\n            data[i+1, Y] = data[i, Y]\n            data[i+1, A] = data[i, A] + data[i+1, Y]\n        \n        data[i+1, T] = vals[i]\n    \n    # Incorporate accuracy scores\n    data[0, M] = 0\n    for i in range(1, length-1):\n        fp = data[i, X]\n        tp = data[i, Y]\n        tn = data[-1, X] - fp\n        fn = data[-1, Y] - tp\n        data[i, M] = mcc(tp, tn, fp, fn)\n        data[i, B] = ber(tp, tn, fp, fn)\n    data[-1, M] = 0\n    return data", "response": "Reciever Operator Characteristic\n    :param clss: known classes. 1 if positive case, -1 if the negative case\n    :type class: list of boolean\n    :param vals: classification probabilites etc...\n    :type vals: list of real numbers\n    :param bool reverse: whether the values should be sorted in reverse order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef confusion_matrix(exp, obs):\n    assert len(exp) == len(obs)\n    # Expected in the first dimension (0;rows), observed in the second (1;cols)\n    lbls = sorted(set(exp))\n    res = numpy.zeros(shape=(len(lbls), len(lbls)))\n    for i in range(len(exp)):\n        res[lbls.index(exp[i]), lbls.index(obs[i])] += 1\n    return res, lbls", "response": "Create a confusion matrix that is a square matrix and a sorted list of labels."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying a performance function to a confusion matrix.", "response": "def confusion_performance(mat, fn):\n    \"\"\"Apply a performance function to a confusion matrix\n    \n    :param mat: confusion matrix\n    :type mat: square matrix\n    :param function fn: performance function\n    \"\"\"\n    if mat.shape[0] != mat.shape[1] or mat.shape < (2, 2):\n        raise TypeError('{} is not a confusion matrix'.format(mat))\n    elif mat.shape == (2, 2):\n        return fn(mat[TP], mat[TN], mat[FP], mat[FN])\n    res = numpy.empty(mat.shape[0])\n    for i in range(len(res)):\n        res[i] = fn(mat[i, i],                                   # TP\n                    sum(mat) - sum(mat[:, i]) - sum(mat[i, :]),  # TN\n                    sum(mat[:, i]) - mat[i, i],                  # FP\n                    sum(mat[i, :]) - mat[i, i])                  # FN\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the entity class registered for the given registered resource.", "response": "def get_entity_class(resource):\n    \"\"\"\n    Returns the entity class registered for the given registered resource.\n\n    :param resource: registered resource\n    :type collection: class implementing or instance providing a registered\n        resource interface.\n    :return: entity class\n        (class implementing `everest.entities.interfaces.IEntity`)\n    \"\"\"\n    reg = get_current_registry()\n    if IInterface in provided_by(resource):\n        ent_cls = reg.getUtility(resource, name='entity-class')\n    else:\n        ent_cls = reg.getAdapter(resource, IEntity, name='entity-class')\n    return ent_cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef release(ctx, type_, repo, prebump=PREBUMP):\n    if prebump not in REL_TYPES:\n        raise ValueError(f'{type_} not in {REL_TYPES}')\n    prebump = REL_TYPES.index(prebump)\n\n    version = _read_version()\n    version = _bump_release(version, type_)\n    _write_version(version)\n\n    # Needs to happen before Towncrier deletes fragment files.\n    tag_content = _render_log()\n\n    ctx.run('towncrier')\n\n    ctx.run(f'git commit -am \"Release {version}\"')\n\n    tag_content = tag_content.replace('\"', '\\\\\"')\n    ctx.run(f'git tag -a {version} -m \"Version {version}\\n\\n{tag_content}\"')\n\n    ctx.run(f'python setup.py sdist bdist_wheel')\n\n    dist_pattern = f'{PACKAGE_NAME.replace(\"-\", \"[-_]\")}-*'\n    artifacts = list(ROOT.joinpath('dist').glob(dist_pattern))\n    filename_display = '\\n'.join(f'  {a}' for a in artifacts)\n    print(f'[release] Will upload:\\n{filename_display}')\n    try:\n        input('[release] Release ready. ENTER to upload, CTRL-C to abort: ')\n    except KeyboardInterrupt:\n        print('\\nAborted!')\n        return\n\n    arg_display = ' '.join(f'\"{n}\"' for n in artifacts)\n    ctx.run(f'twine upload --repository=\"{repo}\" {arg_display}')\n\n    version = _prebump(version, prebump)\n    _write_version(version)\n\n    ctx.run(f'git commit -am \"Prebump to {version}\"')", "response": "Create a new release."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall board with programmer", "response": "def install_board_with_programmer(mcu,\n                                  programmer,\n                                  f_cpu=16000000,\n                                  core='arduino',\n                                  replace_existing=False,\n                                  ):\n    \"\"\"install board with programmer.\"\"\"\n    bunch = AutoBunch()\n    board_id = '{mcu}_{f_cpu}_{programmer}'.format(f_cpu=f_cpu,\n                                             mcu=mcu,\n                                             programmer=programmer,\n                                             )\n    bunch.name = '{mcu}@{f} Prog:{programmer}'.format(f=strfreq(f_cpu),\n                                                      mcu=mcu,\n                                                      programmer=programmer,\n                                                      )\n\n    bunch.upload.using = programmer\n\n    bunch.build.mcu = mcu\n    bunch.build.f_cpu = str(f_cpu) + 'L'\n    bunch.build.core = core\n\n    install_board(board_id, bunch, replace_existing=replace_existing)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the branch name of the current node.", "response": "def get_branch(self):\n        \"\"\"\n        :return:\n        \"\"\"\n        if self.repo.head.is_detached:\n            if os.getenv('GIT_BRANCH'):\n                branch = os.getenv('GIT_BRANCH')\n            elif os.getenv('BRANCH_NAME'):\n                branch = os.getenv('BRANCH_NAME')\n            elif os.getenv('TRAVIS_BRANCH'):\n                branch = os.getenv('TRAVIS_BRANCH')\n            else:\n                branch = \"HEAD\"\n        else:\n            branch = str(self.repo.active_branch)\n\n        return branch.replace(\"/\", \"_\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the version of the current tag", "response": "def get_version(self):\n        \"\"\"\n        :return:\n        \"\"\"\n        tag = next((tag for tag in self.repo.tags if tag.commit == self.repo.commit()), None)\n        if tag:\n            return tag\n\n        return self.repo.rev_parse(str(self.repo.commit()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the changed files in the repository.", "response": "def get_changed_files(self, first_sha, second_sha, exclude_paths=None):\n        \"\"\"\n        :param first_sha:\n        :param second_sha:\n        :param exclude_paths:\n        :return:\n        \"\"\"\n        if not exclude_paths:\n            exclude_paths = []\n\n        first_commit = self.repo.commit(first_sha)\n        second_commit = self.repo.commit(second_sha)\n\n        diffs = first_commit.diff(second_commit)\n        changed_files = []\n\n        for diff in diffs:\n            excluded = False\n            for exclude in exclude_paths:\n                if diff.a_path.startswith(exclude):\n                    excluded = True\n\n            if not excluded:\n                changed_files.append(diff.a_path)\n\n        return changed_files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting all git information.", "response": "def print_all(self):\n        \"\"\"\n        :return:\n        \"\"\"\n        output = \"\\n\\n# Git information  \\n\" \\\n                 \"-------------------------------------------\\n\" \\\n                 \"  Branch :\\t{0}\\n\" \\\n                 \"  Version:\\t{1}\\n\" \\\n                 \"  Summary:\\t{2}\\n\" \\\n                 \"-------------------------------------------\\n\\n\".format(\n            self.get_branch(),\n            str(self.get_version()),\n            self.repo.commit().summary,\n        )\n\n        print(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a message to the screen", "response": "def logMsg(self, msg, printMsg=True):\n        \"\"\"\n        logs a message and prints it to the screen\n        \"\"\"\n        time = datetime.datetime.now().strftime('%I:%M %p')\n        self.log = '{0}\\n{1} | {2}'.format(self.log, time, msg)\n        if printMsg:\n            print msg\n\n        if self.addLogsToArcpyMessages:\n            from arcpy import AddMessage\n            AddMessage(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logGPMsg(self, printMsg=True):\n        from arcpy import GetMessages\n\n        msgs = GetMessages()\n        try:\n            self.logMsg(msgs, printMsg)\n        except:\n            self.logMsg('error getting arcpy message', printMsg)", "response": "logs the arcpy messages and prints them to the screen"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef writeLogToFile(self):\n        if not os.path.exists(self.logFolder):\n            os.mkdir(self.logFolder)\n\n        with open(self.logFile, mode='a') as f:\n            f.write('\\n\\n' + self.log)", "response": "writes the log to a file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logError(self):\n        # got from http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Error_handling_with_Python\n        import traceback\n\n        self.logMsg('ERROR!!!')\n        errMsg = traceback.format_exc()\n        self.logMsg(errMsg)\n        return errMsg", "response": "gets traceback info and logs it\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new Song object with the next song to play.", "response": "def song(self):\n        \"\"\"\n        :class:`Song` object of next song to play\n        \"\"\"\n        song = self._connection.request(\n            'autoplayGetSong',\n            {'weightModifierRange': [-9, 9],\n             'seedArtists': dict([(artist, 'p') for artist in self._artists]),\n             'tagID': self._radio,\n             'recentArtists': self._recent_artists,\n             'songQueueID': self._connection.session.queue,\n             'secondaryArtistWeightModifier': 0.75,\n             'country': self._connection.session.country,\n             'seedArtistWeightRange': [110, 130],\n             'songIDsAlreadySeen': self._songs_already_seen,\n             'maxDuration': 1500,\n             'minDuration': 60,\n             'frowns': []},\n            self._connection.header('autoplayGetSong', 'jsqueue'))[1]\n        return Song(\n            song['SongID'], song['SongName'], song['ArtistID'],\n            song['ArtistName'], song['AlbumID'], song['AlbumName'],\n            song['CoverArtUrl'], None, song['EstimateDuration'], None,\n            self._connection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary with all song information.", "response": "def export(self):\n        \"\"\"\n        Returns a dictionary with all song information.\n        Use the :meth:`from_export` method to recreate the\n        :class:`Song` object.\n        \"\"\"\n        return {'artists': self._artists,\n                'radio': self._radio,\n                'recent_artists': self._recent_artists,\n                'songs_already_seen': self._songs_already_seen}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_random_giphy(phrase):\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n\n        giphy = giphypop.Giphy()\n\n    results = giphy.search_list(phrase=phrase, limit=100)\n\n    if not results:\n        raise ValueError('There were no results for that phrase')\n\n    return random.choice(results).media_url", "response": "Return the URL of a random GIF related to the phrase if possible"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays an image for the phrase in sys. argv if possible", "response": "def handle_command_line():\n    \"\"\"Display an image for the phrase in sys.argv, if possible\"\"\"\n    phrase = ' '.join(sys.argv[1:]) or 'random'\n\n    try:\n        giphy = get_random_giphy(phrase)\n    except ValueError:\n        sys.stderr.write('Unable to find any GIFs for {!r}\\n'.format(phrase))\n        sys.exit(1)\n\n    display(fetch_image(giphy))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking all required folders in the config if they do not exist.", "response": "def make_required_folders(self):\n        \"\"\"Makes all folders declared in the config if they\n        do not exist.\n        \"\"\"\n        for folder in [\n            self.pending_folder,\n            self.usb_incoming_folder,\n            self.outgoing_folder,\n            self.incoming_folder,\n            self.archive_folder,\n            self.tmp_folder,\n            self.log_folder,\n        ]:\n            if not os.path.exists(folder):\n                os.makedirs(folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads HFS + volume information from a file.", "response": "def load(self, filename, offset):\n        \"\"\"Loads HFS+ volume information\"\"\"\n        try:\n            self.offset = offset\n            self.fd = open(filename, 'rb')\n            # 1024 - temporary, need to find out actual volume header size\n            self.fd.seek(self.offset + VOLUME_HEADER_OFFSET)\n            data = self.fd.read(1024)\n            self.vol_header = VolumeHeader(data)\n\n            self.fd.close()\n        except IOError as e:\n            print(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_interfaces(self):\n        interfaces = self.xml.find('devices').iter('interface')\n        iobjs = []\n        for interface in interfaces:\n            _type = interface.attrib['type']\n            mac = interface.find('mac').attrib['address']\n            source = interface.find('source').attrib[_type]\n            model = interface.find('model').attrib['type']\n            iobjs.append(NetworkInterface(_type, mac, source, model))\n        return iobjs", "response": "Return a list of sham. network. interfaces. NetworkInterface describing all the interfaces this VM has."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_disks(self):\n        disks = [disk for disk in self.xml.iter('disk')]\n        disk_objs = []\n        for disk in disks:\n            source = disk.find('source')\n            if source is None:\n                continue\n            path = source.attrib['file']\n            diskobj = self.domain.connect().storageVolLookupByPath(path)\n            disk_objs.append(diskobj)\n        return [Volume(d, StoragePool(d.storagePoolLookupByVolume())) for d in disk_objs]", "response": "Return a list of all the Disks attached to this VM\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self):\n        disks = self.get_disks()\n        self.domain.undefine()\n        for disk in disks:\n            disk.wipe()\n            disk.delete()", "response": "Delete this VM and all its disks and remove all its disks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shutdown(self, delete=False):\n        disks = self.get_disks()\n        self.domain.destroy()\n        if delete:\n            for disk in disks:\n                disk.wipe()\n                disk.delete()", "response": "Shutdown this VM\n        :param delete: Should we delete after shutting the VM down?\n        :type delete: bool"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the values contained in this object as a dict.", "response": "def to_dict(self):\n        \"\"\"\n        Return the values contained in this object as a dict\n        \"\"\"\n        return {'domain_type': self.domain_type,\n                'max_memory': self.max_memory,\n                'current_memory': self.current_memory,\n                'num_cpus': self.num_cpus,\n                'running': self.is_running(),\n                'name': self.name,\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef guess_url_vcs(url):\n    parsed = urllib.parse.urlsplit(url)\n\n    if parsed.scheme in ('git', 'svn'):\n        return parsed.scheme\n    elif parsed.path.endswith('.git'):\n        return 'git'\n    elif parsed.hostname == 'github.com':\n        return 'git'\n\n    # If it's an http url, we can try requesting it and guessing from the\n    # contents.\n    if parsed.scheme in ('http', 'https'):\n        resp = requests.get(url)\n        if re.match('basehttp.*python.*', resp.headers.get('server').lower()):\n            # It's the mercurial http server\n            return 'hg'\n    return None", "response": "Given a url try to guess what kind of VCS it s for."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef guess_folder_vcs(folder):\n    try:\n        contents = os.listdir(folder)\n        vcs_folders = ['.git', '.hg', '.svn']\n        found = next((x for x in vcs_folders if x in contents), None)\n        # Chop off the dot if we got a string back\n        return found[1:] if found else None\n    except OSError:\n        return None", "response": "Given a path for a folder on the local filesystem see what kind of vcs it is and if any return the name of the repository it is."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the name of the folder that you d get if you cloned url into the current working directory.", "response": "def basename(url):\n    \"\"\"\n    Return the name of the folder that you'd get if you cloned 'url' into the\n    current working directory.\n    \"\"\"\n    # It's easy to accidentally have whitespace on the beginning or end of the\n    # url.\n    url = url.strip()\n\n    url, _sep, _fragment = url.partition('#')\n    # Remove trailing slash from url if present\n    if url.endswith('/'):\n        url = url[:-1]\n    # Also strip .git from url if it ends in that.\n    return re.sub(r'\\.git$', '', url.split('/')[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_url(self):\n        cmd = {\n            'hg': 'hg paths default',\n            'git': 'git config --local --get remote.origin.url',\n        }[self.vcs_type]\n        with chdir(self.folder):\n            r = self.run(cmd)\n        return r.output.replace('\\n', '')", "response": "Get the URL of the upstream repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an absolute URL that can be used to access a view in a particular project.", "response": "def fburl(parser, token):\n    \"\"\"\n    Returns an absolute URL matching given view with its parameters.\n\n    This is a way to define links that aren't tied to a particular URL\n    configuration::\n\n        {% url path.to.some_view arg1,arg2,name1=value1 %}\n\n    The first argument is a path to a view. It can be an absolute python path\n    or just ``app_name.view_name`` without the project name if the view is\n    located inside the project.  Other arguments are comma-separated values\n    that will be filled in place of positional and keyword arguments in the\n    URL. All arguments for the URL should be present.\n\n    For example if you have a view ``app_name.client`` taking client's id and\n    the corresponding line in a URLconf looks like this::\n\n        ('^client/(\\d+)/$', 'app_name.client')\n\n    and this app's URLconf is included into the project's URLconf under some\n    path::\n\n        ('^clients/', include('project_name.app_name.urls'))\n\n    then in a template you can create a link for a certain client like this::\n\n        {% url app_name.client client.id %}\n\n    The URL will look like ``/clients/client/123/``.\n    \"\"\"\n    bits = token.contents.split(' ')\n    if len(bits) < 2:\n        raise template.TemplateSyntaxError(\"'%s' takes at least one argument\"\n                                  \" (path to a view)\" % bits[0])\n    viewname = bits[1]\n    args = []\n    kwargs = {}\n    asvar = None\n\n    if len(bits) > 2:\n        bits = iter(bits[2:])\n        for bit in bits:\n            if bit == 'as':\n                asvar = bits.next()\n                break\n            else:\n                for arg in bit.split(\",\"):\n                    if '=' in arg:\n                        k, v = arg.split('=', 1)\n                        k = k.strip()\n                        kwargs[k] = parser.compile_filter(v)\n                    elif arg:\n                        args.append(parser.compile_filter(arg))\n    return URLNode(viewname, args, kwargs, asvar)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef chdir(method):\n    def wrapper(self, dir, *args, **kw):\n        dirstack = ChdirStack()\n        dirstack.push(dir)\n        try:\n            return method(self, dir, *args, **kw)\n        finally:\n            dirstack.pop()\n\n    return functools.wraps(method)(wrapper)", "response": "Decorator executing method in directory dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes cwd on stack and change to dir.", "response": "def push(self, dir):\n        \"\"\"Push cwd on stack and change to 'dir'.\n        \"\"\"\n        self.stack.append(os.getcwd())\n        os.chdir(dir or os.getcwd())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self):\n        if len(self.stack):\n            os.chdir(self.stack.pop())", "response": "Pop dir off stack and change to it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_matching(self, source_id):\n        value = self._accessor.get_by_id(source_id)\n        if not value is None:\n            reg = get_current_registry()\n            prx_fac = reg.getUtility(IDataTraversalProxyFactory)\n            prx = prx_fac.make_proxy(value,\n                                     self._accessor,\n                                     self.relationship_direction,\n                                     self.relation_operation)\n        else:\n            prx = None\n        return prx", "response": "Returns a matching target object for the given source ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator of items for an attribute value map to use for update operation.", "response": "def update_attribute_value_items(self):\n        \"\"\"\n        Returns an iterator of items for an attribute value map to use for\n        an UPDATE operation.\n\n        The iterator ignores collection attributes as these are processed\n        implicitly by the traversal algorithm.\n\n        :returns: iterator yielding tuples with objects implementing\n          :class:`everest.resources.interfaces.IResourceAttribute` as the\n          first and the proxied attribute value as the second argument.\n        \"\"\"\n        for attr in self._attribute_iterator():\n            if attr.kind != RESOURCE_ATTRIBUTE_KINDS.COLLECTION:\n                try:\n                    attr_val = self._get_proxied_attribute_value(attr)\n                except AttributeError:\n                    continue\n                else:\n                    yield (attr, attr_val)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a traversal proxy for the specified relation and attribute value.", "response": "def get_attribute_proxy(self, attribute):\n        \"\"\"\n        Returns a traversal proxy (cardinality ONE) or an iterable sequence\n        data traversal proxy (cardinality MANY) for the specified relation\n        attribute value of the proxied data.\n\n        :raises ValueError: If :param:`attribute` is a terminal attribute.\n        \"\"\"\n        attr_val = self._get_relation_attribute_value(attribute)\n        if attr_val is None:\n            prx = None\n        else:\n            if not self._accessor is None:\n                # FIXME: This implies that the accessor is an aggregate.\n                acc = self._accessor.get_root_aggregate(attribute.attr_type)\n            else:\n                acc = None\n            reg = get_current_registry()\n            prx_fac = reg.getUtility(IDataTraversalProxyFactory)\n            prx = prx_fac.make_proxy(attr_val,\n                                     acc,\n                                     self.relationship_direction,\n                                     self.relation_operation,\n                                     options=\n                                        self._get_proxy_options(attribute))\n        return prx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the entity converted from the proxied data.", "response": "def get_entity(self):\n        \"\"\"\n        Returns the entity converted from the proxied data.\n        \"\"\"\n        if self._accessor is None:\n            if self.__converted_entity is None:\n                self.__converted_entity = self._convert_to_entity()\n        else:\n            # If we have an accessor, we can get the proxied entity by ID.\n            # FIXME: This is a hack that is only used for REMOVE operations\n            #        with data elements.\n            self.__converted_entity = \\\n                self.get_matching(self.get_id()).get_entity()\n        return self.__converted_entity"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a tree traverser for the given source and target data combination.", "response": "def make_traverser(cls, source_data, target_data, relation_operation,\n                       accessor=None, manage_back_references=True):\n        \"\"\"\n        Factory method to create a tree traverser depending on the input\n        source and target data combination.\n\n        :param source_data: Source data.\n        :param target_target: Target data.\n        :param str relation_operation: Relation operation. On of the constants\n          defined in :class:`everest.constants.RELATION_OPERATIONS`.\n        :param accessor: Accessor for looking up target nodes for update\n          operations.\n        :param bool manage_back_references: If set, backreferences will\n          automatically be updated in the target data.\n        \"\"\"\n        reg = get_current_registry()\n        prx_fac = reg.getUtility(IDataTraversalProxyFactory)\n        if relation_operation == RELATION_OPERATIONS.ADD \\\n           or relation_operation == RELATION_OPERATIONS.UPDATE:\n            if relation_operation == RELATION_OPERATIONS.ADD \\\n               and not target_data is None:\n                raise ValueError('Must not provide target data with '\n                                 'relation operation ADD.')\n            source_proxy = prx_fac.make_proxy(source_data,\n                                              None,\n                                              RELATIONSHIP_DIRECTIONS.NONE,\n                                              relation_operation)\n            source_is_sequence = \\\n                source_proxy.proxy_for == RESOURCE_KINDS.COLLECTION\n            if not source_is_sequence:\n                source_id = source_proxy.get_id()\n        else:\n            source_proxy = None\n            source_is_sequence = False\n        if relation_operation == RELATION_OPERATIONS.REMOVE \\\n           or relation_operation == RELATION_OPERATIONS.UPDATE:\n            rel_dir = RELATIONSHIP_DIRECTIONS.BIDIRECTIONAL\n            if not manage_back_references:\n                rel_dir &= ~RELATIONSHIP_DIRECTIONS.REVERSE\n            if relation_operation == RELATION_OPERATIONS.REMOVE:\n                if not source_data is None:\n                    raise ValueError('Must not provide source data with '\n                                     'relation operation REMOVE.')\n                target_proxy = prx_fac.make_proxy(target_data,\n                                                  accessor,\n                                                  rel_dir,\n                                                  relation_operation)\n            else: # UPDATE\n                if accessor is None:\n                    raise ValueError('Need to provide an accessor when '\n                                     'performing UPDATE operations.')\n                if not target_data is None:\n                    target_root = target_data\n                elif not source_is_sequence:\n                    # Look up the (single) target to update.\n                    target_root = accessor.get_by_id(source_id)\n                    if target_root is None:\n                        raise ValueError('Entity with ID %s to update not '\n                                         'found.' % source_id)\n                else:\n                    # Look up collection of targets to update.\n                    target_root = []\n                    for src_prx in source_proxy:\n                        tgt_ent_id = src_prx.get_id()\n                        if tgt_ent_id is None:\n                            continue\n                        tgt_ent = accessor.get_by_id(tgt_ent_id)\n                        if tgt_ent is None:\n                            continue\n                        target_root.append(tgt_ent)\n                target_proxy = prx_fac.make_proxy(target_root,\n                                                  accessor,\n                                                  rel_dir,\n                                                  relation_operation)\n            target_is_sequence = \\\n                    target_proxy.proxy_for == RESOURCE_KINDS.COLLECTION\n        else:\n            target_proxy = None\n            target_is_sequence = False\n        if not source_proxy is None and not target_proxy is None:\n            # Check for source/target consistency.\n            if not ((source_is_sequence and target_is_sequence) or\n                    (not source_is_sequence and not target_is_sequence)):\n                raise ValueError('When both source and target root nodes are '\n                                 'given, they can either both be sequences '\n                                 'or both not be sequences.')\n        return cls(source_proxy, target_proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the domain tree traversal.", "response": "def run(self, visitor):\n        \"\"\"\n        :param visitor: visitor to call with every node in the domain tree.\n        :type visitor: subclass of\n            :class:`everest.entities.traversal.DomainVisitor`\n        \"\"\"\n        if __debug__:\n            self.__log_run(visitor)\n        visitor.prepare()\n        if self.__root_is_sequence:\n            if not self._tgt_prx is None:\n                tgts = iter(self._tgt_prx)\n            else:\n                tgts = None\n            if not self._src_prx is None:\n                srcs = iter(self._src_prx)\n            else:\n                srcs = None\n            self.traverse_many(None, srcs, tgts, visitor)\n        else:\n            self.traverse_one(None, self._src_prx, self._tgt_prx, visitor)\n        visitor.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef traverse_one(self, attribute, source, target, visitor):\n        if __debug__:\n            self.__log_traverse_one(self.__trv_path, attribute, source, target)\n        prx = source or target\n        rel_op = RELATION_OPERATIONS.check(source, target)\n        if prx.do_traverse() \\\n           and (rel_op == prx.relation_operation or attribute is None):\n            for attr in prx.get_relationship_attributes():\n                # Check cascade settings.\n                if not bool(attr.cascade & rel_op):\n                    continue\n                if not source is None:\n                    try:\n                        attr_source = source.get_attribute_proxy(attr)\n                    except AttributeError:\n                        # If the source does not have the attribute set, we\n                        # do nothing (as opposed to when the value is None).\n                        continue\n                else:\n                    attr_source = None\n                if not target is None:\n                    attr_target = target.get_attribute_proxy(attr)\n                else:\n                    attr_target = None\n                attr_rel_op = RELATION_OPERATIONS.check(attr_source,\n                                                        attr_target)\n                if attr_rel_op == RELATION_OPERATIONS.ADD:\n                    if rel_op == RELATION_OPERATIONS.ADD:\n                        parent = source\n                    else:\n                        parent = target\n                elif attr_rel_op == RELATION_OPERATIONS.REMOVE:\n                    parent = target\n                else: # UPDATE\n                    parent = target\n                card = get_attribute_cardinality(attr)\n                if card == CARDINALITY_CONSTANTS.ONE:\n                    if attr_source is None and attr_target is None:\n                        # If both source and target have None values, there is\n                        # nothing to do.\n                        continue\n                    if attr_rel_op == RELATION_OPERATIONS.ADD:\n#                        if not attr_source.get_id() is None:\n#                            # We only ADD new items.\n#                            continue\n                        src_items = [attr_source]\n                        tgt_items = None\n                    elif attr_rel_op == RELATION_OPERATIONS.REMOVE:\n                        src_items = None\n                        tgt_items = [attr_target]\n                    else: # UPDATE\n                        src_items = [attr_source]\n                        tgt_items = [attr_target]\n                        src_id = attr_source.get_id()\n                        tgt_id = attr_target.get_id()\n                        if src_id != tgt_id:\n                            if not src_id is None:\n                                # If the source ID is None, this is a replace\n                                # operation (ADD source, REMOVE target).\n                                src_target = attr_target.get_matching(src_id)\n                                if not src_target is None:\n                                    tgt_items.append(src_target)\n                else:\n                    src_items = attr_source\n                    tgt_items = attr_target\n                self.__trv_path.push(parent, (source, target), attr, rel_op)\n                self.traverse_many(attr, src_items, tgt_items, visitor)\n                self.__trv_path.pop() # path.pop()\n        visitor.visit(self.__trv_path, attribute, source, target)", "response": "Traverse the source data tree for one attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef traverse_many(self, attribute, source_sequence, target_sequence,\n                      visitor):\n        \"\"\"\n        Traverses the given source and target sequences and makes appropriate\n        calls to :method:`traverse_one`.\n\n        Algorithm:\n        1) Build a map target item ID -> target data item from the target\n           sequence;\n        2) For each source data item in the source sequence check if it\n           has a not-None ID; if yes, remove the corresponding target from the\n           map generated in step 1) and use as target data item for the\n           source data item; if no, use `None` as target data item;\n        3) For the remaining items in the target map from 1), call\n           :method:`traverse_one` passing `None` as source (REMOVE);\n        4) For all source/target data item pairs generated in 2, call\n           :method:`traverse_one` (ADD or UPDATE depending on whether target\n           item is `None`).\n\n        :param source_sequence: iterable of source data proxies\n        :type source_sequence: iterator yielding instances of\n                               `DataTraversalProxy` or None\n        :param target_sequence: iterable of target data proxies\n        :type target_sequence: iterator yielding instances of\n                               `DataTraversalProxy` or None\n        \"\"\"\n        target_map = {}\n        if not target_sequence is None:\n            for target in target_sequence:\n                target_map[target.get_id()] = target\n        src_tgt_pairs = []\n        if not source_sequence is None:\n            for source in source_sequence:\n                source_id = source.get_id()\n                if not source_id is None:\n                    # Check if target exists for UPDATE.\n                    target = target_map.pop(source_id, None)\n                else:\n                    # Source is new, there is no target, so ADD.\n                    target = None\n                src_tgt_pairs.append((source, target))\n        # All targets that are now still in the map where not present in the\n        # source and therefore need to be REMOVEd.\n        for target in itervalues_(target_map):\n            if not (None, target) in self.__trv_path:\n                self.traverse_one(attribute, None, target, visitor)\n        #\n        for source, target in src_tgt_pairs:\n            if not (source, target) in self.__trv_path:\n                self.traverse_one(attribute, source, target, visitor)", "response": "Traverse the given source and target data proxies and make appropriate target data items for each source and target data proxies."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget info about object id |coro|", "response": "async def info(self, obj_id=None):\n    '''Get info about object id\n\n    |coro|\n\n    Parameters\n    ----------\n    obj_id : str, list\n      if not provided, server info is retured(as a dict).\n      Otherwise, an object with that id is returned\n      (or objects if `obj_id` is a list).\n    '''\n    if obj_id:\n      try:\n        return await self.process(obj_id)\n      except JSONDecodeError:\n        raise LookupError('Error object with that id does not exist', obj_id)\n    else:\n      return await self.connector.getJson('/system/info/public', remote=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a search request to emby and returns the list of objects that match the query", "response": "async def search(self, query,\n            sort_map = {'BoxSet':0,'Series':1,'Movie':2,'Audio':3,'Person':4},\n            strict_sort = False):\n    '''Sends a search request to emby, returns results\n\n    |coro|\n\n    Parameters\n    ----------\n    query : str\n      the search string to send to emby\n    sort_map : dict\n      is a dict of strings to ints. Strings should be item types, and\n      the ints are the priority of those types(for sorting).\n      lower valued(0) will appear first.\n    strict_sort : bool\n      if True, then only item types in the keys of sortmap will be\n      included in the results\n\n    Returns\n    -------\n    list\n      list of emby objects\n    '''\n    search_params = {\n      'remote'     : False,\n      'searchTerm' : query\n    }\n    if strict_sort:\n      search_params['IncludeItemTypes'] = ','.join(sort_map.keys())\n\n    json  = await self.connector.getJson('/Search/Hints/', **search_params)\n    items = await self.process(json[\"SearchHints\"])\n\n    m_size = len(sort_map)\n    items  = sorted(items, key = lambda x : sort_map.get(x.type, m_size))\n\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def nextUp(self, userId=None):\n    '''returns list of items marked as `next up`\n\n    |coro|\n\n    Parameters\n    ----------\n    userId : str\n      if provided, then the list returned is\n      the one that that use will see.\n\n    Returns\n    -------\n    list\n      the itmes that will appear as next up\n      (for user if id was given)\n    '''\n    json = await self.connector.getJson('/Shows/NextUp',\n                                        pass_uid=True,\n                                        remote=False,\n                                        userId=userId\n    )\n    return await self.process(json)", "response": "returns list of items marked as next up"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def update(self):\n    '''\n    reload all cached information\n\n    |coro|\n\n    Notes\n    -----\n    This is a slow process, and will remove the cache before updating.\n    Thus it is recomended to use the `*_force` properties, which will\n    only update the cache after data is retrived.\n    '''\n    keys = self.extras.keys()\n    self.extras = {}\n    for key in keys:\n      try:\n        func = getattr(self, key, None)\n        if callable(func):\n          func()\n      except:\n        pass", "response": "Reload all cached information about the internal structure of the internal structure."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def create_playlist(self, name, *songs):\n    '''create a new playlist\n\n    |coro|\n\n    Parameters\n    ----------\n    name : str\n      name of new playlist\n    songs : array_like\n      list of song ids to add to playlist\n    '''\n    data = {'Name': name}\n    ids = [i.id for i in (await self.process(songs))]\n\n    if ids:\n      data['Ids'] = ','.join(ids)\n\n    # TODO - return playlist not status\n    return await self.connector.post('/Playlists',\n      data=data,\n      pass_uid=True,\n      remote=False\n    )", "response": "create a new playlist with the given name and songs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_all(self, group):\n        for ep in iter_entry_points(group=group):\n            plugin = ep.load()\n            plugin(self.__config)", "response": "Loads all plugins advertising entry points with the given group name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving libraries by GUI.", "response": "def gui():\n    \"\"\"remove libraries by GUI.\"\"\"\n\n    sel = psidialogs.multi_choice(libraries(),\n                                  'select libraries to remove from %s!' % libraries_dir(),\n                                  title='remove boards')\n    print('%s selected' % sel)\n\n    if sel:\n        if psidialogs.ask_yes_no('Do you really want to remove selected libraries?\\n' + '\\n'.join(sel)):\n            for x in sel:\n                remove_lib(x)\n                print('%s was removed' % x)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_document(destination, identifier, pointer):\n    record = Record.get_record(identifier)\n    click.echo(json.dumps(\n        Document(record, pointer).copy(destination)\n    ))", "response": "Copy a document to a new destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setcontents(source, identifier, pointer):\n    record = Record.get_record(identifier)\n    Document(record, pointer).setcontents(source)", "response": "Patch existing bibliographic record with new contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns ast. Expression created from source code given in src.", "response": "def src2ast(src: str) -> Expression:\n    \"\"\"Return ast.Expression created from source code given in `src`.\"\"\"\n    try:\n        return ast.parse(src, mode='eval')\n    except SyntaxError:\n        raise ValueError(\"Not a valid expression.\") from None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnaming of globals in expr.", "response": "def names(expr: AST) -> Set[str]:\n    \"\"\"Names of globals in `expr`.\"\"\"\n    nodes = [node for node in ast.walk(expr) if isinstance(node, ast.Name)]\n    loaded = {node.id for node in nodes if isinstance(node.ctx, ast.Load)}\n    stored = {node.id for node in nodes if isinstance(node.ctx, ast.Store)}\n    return loaded - stored"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_name(expr: AST, old_name: str, new_name: str) -> AST:\n    return _NameReplacer(old_name, new_name).visit(deepcopy(expr))", "response": "Replace all Name nodes named old_name with new_name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Negation(expr: Expression) -> Expression:\n    expr = Expression(_negate(expr.body))\n    return ast.fix_missing_locations(expr)", "response": "Return expression which is the negation of expr."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn expression which is the conjunction of expr1 and expr2.", "response": "def Conjunction(expr1: Expression, expr2: Expression) -> Expression:\n    \"\"\"Return expression which is the conjunction of `expr1` and `expr2`.\"\"\"\n    expr = Expression(ast.BoolOp(ast.And(), [expr1.body, expr2.body]))\n    return ast.fix_missing_locations(expr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Disjunction(expr1: Expression, expr2: Expression) -> Expression:\n    expr = Expression(ast.BoolOp(ast.Or(), [expr1.body, expr2.body]))\n    return ast.fix_missing_locations(expr)", "response": "Return expression which is the disjunction of expr1 and expr2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Contradiction(expr1: Expression, expr2: Expression) -> Expression:\n    expr = Disjunction(Conjunction(expr1, Negation(expr2)),\n                       Conjunction(Negation(expr1), expr2))\n    return ast.fix_missing_locations(expr)", "response": "Return expression which is the contradiction of expr1 and expr2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef diff_binding(self) -> int:\n        try:\n            prev_op, prev_op_binding = self.nested_ops[-2]\n        except IndexError:\n            prev_op, prev_op_binding = None, 0\n        try:\n            curr_op, curr_op_binding = self.nested_ops[-1]\n        except IndexError:\n            curr_op, curr_op_binding = None, 0\n        # special case\n        if prev_op is ast.Pow and isinstance(curr_op, (ast.Invert, ast.USub)):\n            return 1\n        # print(prev_op, prev_op_binding, curr_op, curr_op_binding)\n        return curr_op_binding - prev_op_binding", "response": "Return the difference betweens the binding levels of the current object and the previous operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wrap_expr(self, src: str, dfltChaining: bool) -> str:\n        diff_binding = self.op_man.diff_binding()\n        if diff_binding < 0 or diff_binding == 0 and not dfltChaining:\n            return self.parenthesize(src)\n        else:\n            return src", "response": "Wrap src in parentheses if neccessary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit(self, node: AST, dfltChaining: bool = True) -> str:\n        # print(node.__class__.__name__)\n        if node is None:\n            return ''\n        if isinstance(node, ast.Expression):\n            return self.visit(node.body)\n        # dispatch to specific or generic method\n        method = 'visit_' + node.__class__.__name__\n        visitor = getattr(self, method, self.generic_visit)\n        return visitor(node, dfltChaining)", "response": "Process a node by dispatching to a handler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefaulting handler called for no explicit visitor function exists for a node.", "response": "def generic_visit(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Default handler, called if no explicit visitor function exists for\n        a node.\n        \"\"\"\n        for field, value in ast.iter_fields(node):\n            if isinstance(value, list):\n                for item in value:\n                    if isinstance(item, AST):\n                        self.visit(item)\n            elif isinstance(value, AST):\n                self.visit(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn node s name as string.", "response": "def visit_NameConstant(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s name as string.\"\"\"\n        return str(node.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Num(self, node: AST, dfltChaining: bool = True) -> str:\n        return str(node.n)", "response": "Return node s number as string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Str(self, node: AST, dfltChaining: bool = True) -> str:\n        return repr(node.s)", "response": "Return node s string representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_FormattedValue(self, node: AST,\n                             dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s value formatted according to its format spec.\"\"\"\n        format_spec = node.format_spec\n        return f\"{{{self.visit(node.value)}\" \\\n               f\"{self.CONV_MAP.get(node.conversion, '')}\" \\\n               f\"{':'+self._nested_str(format_spec) if format_spec else ''}}}\"", "response": "Return node s value formatted according to its format spec."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_Tuple(self, node: AST, dfltChaining: bool = True) -> str:\n        elems = (self.visit(elt) for elt in node.elts)\n        return f\"({', '.join(elems)}{')' if len(node.elts) != 1 else ',)'}\"", "response": "Return tuple representation of node s elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Set(self, node: AST, dfltChaining: bool = True) -> str:\n        return '{' + ', '.join([self.visit(elt) for elt in node.elts]) + '}'", "response": "Return set representation of node s elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Dict(self, node: AST, dfltChaining: bool = True) -> str:\n        items = (': '.join((self.visit(key), self.visit(value)))\n                 for key, value in zip(node.keys, node.values))\n        return f\"{{{', '.join(items)}}}\"", "response": "Return dict representation of node s elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_Name(self, node: AST, dfltChaining: bool = True) -> str:\n        return node.id", "response": "Return node s id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn representation of starred expresssion.", "response": "def visit_Starred(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return representation of starred expresssion.\"\"\"\n        with self.op_man(node):\n            return f\"*{self.visit(node.value)}\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit_Expr(self, node: AST, dfltChaining: bool = True) -> str:\n        return self.visit(node.value)", "response": "Return representation of nested expression."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_UnaryOp(self, node: AST, dfltChaining: bool = True) -> str:\n        op = node.op\n        with self.op_man(op):\n            return self.visit(op) + self.visit(node.operand)", "response": "Return representation of node s operator and operand."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visit_BinOp(self, node: AST, dfltChaining: bool = True) -> str:\n        op = node.op\n        with self.op_man(op):\n            if isinstance(op, ast.Pow):\n                # Pow chains right-to-left\n                src = self.visit(op).join((self.visit(node.left,\n                                                      dfltChaining=False),\n                                           self.visit(node.right)))\n            else:\n                src = self.visit(op).join((self.visit(node.left),\n                                           self.visit(node.right,\n                                                      dfltChaining=False)))\n            return self.wrap_expr(src, dfltChaining)", "response": "Return node s operator and operands as inlined expression."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_BoolOp(self, node: AST, dfltChaining: bool = True) -> str:\n        op = node.op\n        with self.op_man(op):\n            src = self.visit(op).join([self.visit(node.values[0])] +\n                                      [self.visit(val, dfltChaining=False)\n                                       for val in node.values[1:]])\n            return self.wrap_expr(src, dfltChaining)", "response": "Return node s operator and operands as inlined expression."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning node s operators and operands as inlined expression.", "response": "def visit_Compare(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s operators and operands as inlined expression.\"\"\"\n        # all comparison operators have the same precedence,\n        # we just take the first one as representative\n        first_op = node.ops[0]\n        with self.op_man(first_op):\n            cmps = [' '.join((self.visit(op),\n                              self.visit(cmp, dfltChaining=False)))\n                    for op, cmp in zip(node.ops, node.comparators)]\n            src = ' '.join((self.visit(node.left), ' '.join(cmps)))\n            return self.wrap_expr(src, dfltChaining)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns representation of node as keyword arg.", "response": "def visit_keyword(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return representation of `node` as keyword arg.\"\"\"\n        arg = node.arg\n        if arg is None:\n            return f\"**{self.visit(node.value)}\"\n        else:\n            return f\"{arg}={self.visit(node.value)}\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning node s representation as function call.", "response": "def visit_Call(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as function call.\"\"\"\n        args = node.args\n        try:\n            kwds = node.keywords\n        except AttributeError:\n            kwds = []\n        self.compact = True\n        args_src = (self.visit(arg) for arg in args)\n        kwds_src = (self.visit(kwd) for kwd in kwds)\n        param_src = ', '.join(chain(args_src, kwds_src))\n        src = f\"{self.visit(node.func)}({param_src})\"\n        self.compact = False\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_arguments(self, node: AST, dfltChaining: bool = True) -> str:\n        args = node.args\n        dflts = node.defaults\n        vararg = node.vararg\n        kwargs = node.kwonlyargs\n        kwdflts = node.kw_defaults\n        kwarg = node.kwarg\n        self.compact = True\n        n_args_without_dflt = len(args) - len(dflts)\n        args_src = (arg.arg for arg in args[:n_args_without_dflt])\n        dflts_src = (f\"{arg.arg}={self.visit(dflt)}\"\n                     for arg, dflt in zip(args[n_args_without_dflt:], dflts))\n        vararg_src = (f\"*{vararg.arg}\",) if vararg else ()\n        kwargs_src = ((f\"{kw.arg}={self.visit(dflt)}\"\n                       if dflt is not None else f\"{kw.arg}\")\n                      for kw, dflt in zip(kwargs, kwdflts))\n        kwarg_src = (f\"**{kwarg.arg}\",) if kwarg else ()\n        src = ', '.join(chain(args_src, dflts_src, vararg_src,\n                              kwargs_src, kwarg_src))\n        self.compact = False\n        return src", "response": "Return node s representation as argument list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning node s representation as lambda expression.", "response": "def visit_Lambda(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as lambda expression.\"\"\"\n        with self.op_man(node):\n            src = f\"lambda {self.visit(node.args)}: {self.visit(node.body)}\"\n            return self.wrap_expr(src, dfltChaining)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns node s representation as... if... else... expression.", "response": "def visit_IfExp(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as ... if ... else ... expression.\"\"\"\n        with self.op_man(node):\n            src = \" if \".join((self.visit(node.body, dfltChaining=False),\n                               \" else \".join((self.visit(node.test),\n                                              self.visit(node.orelse)))))\n            return self.wrap_expr(src, dfltChaining)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Attribute(self, node: AST, dfltChaining: bool = True) -> str:\n        return '.'.join((self.visit(node.value), node.attr))", "response": "Return node s representation as attribute access."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Slice(self, node: AST, dfltChaining: bool = True) -> str:\n        elems = [self.visit(node.lower), self.visit(node.upper)]\n        if node.step is not None:\n            elems.append(self.visit(node.step))\n        return ':'.join(elems)", "response": "Return node s representation as slice."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning node s representation as extended slice.", "response": "def visit_ExtSlice(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as extended slice.\"\"\"\n        return ', '.join((self.visit(dim) for dim in node.dims))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn node s representation as comprehension.", "response": "def visit_comprehension(self, node: AST,\n                            dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as comprehension.\"\"\"\n        target = node.target\n        try:\n            elts = target.elts          # we have a tuple of names\n        except AttributeError:\n            names = self.visit(target)\n        else:\n            names = ', '.join(self.visit(elt) for elt in elts)\n        src = f\"for {names} in {self.visit(node.iter)}\"\n        if node.ifs:\n            src += f\" {' '.join('if ' + self.visit(if_) for if_ in node.ifs)}\"\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef visit_ListComp(self, node: AST, dfltChaining: bool = True) -> str:\n        return f\"[{self.visit(node.elt)} \" \\\n               f\"{' '.join(self.visit(gen) for gen in node.generators)}]\"", "response": "Return node s representation as list comprehension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn node s representation as set comprehension.", "response": "def visit_SetComp(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as set comprehension.\"\"\"\n        return f\"{{{self.visit(node.elt)} \" \\\n               f\"{' '.join(self.visit(gen) for gen in node.generators)}}}\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning node s representation as dict comprehension.", "response": "def visit_DictComp(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as dict comprehension.\"\"\"\n        return f\"{{{self.visit(node.key)}: {self.visit(node.value)} \" \\\n               f\"{' '.join(self.visit(gen) for gen in node.generators)}}}\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn node s representation as generator expression.", "response": "def visit_GeneratorExp(self, node: AST, dfltChaining: bool = True) -> str:\n        \"\"\"Return `node`s representation as generator expression.\"\"\"\n        return f\"({self.visit(node.elt)} \" \\\n               f\"{' '.join(self.visit(gen) for gen in node.generators)})\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getargs():\n    parser = argparse.ArgumentParser(\n        description='Python Disk Usage Calculator.')\n    parser.add_argument(\"path\", type=chkpath, nargs='?',\n                        default=\".\", help=\"A valid path.\")\n    return parser.parse_args()", "response": "Return a list of valid arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef visible_line_width(self, position = Point):\r\n        extra_char_width = len([ None for c in self[:position].line_buffer if 0x2013 <= ord(c) <= 0xFFFD])\r\n        return len(self[:position].quoted_text()) + self[:position].line_buffer.count(u\"\\t\")*7 + extra_char_width", "response": "Return the visible width of the text in line buffer up to position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the text in the region to the windows clipboard.", "response": "def copy_region_to_clipboard(self): # ()\r\n        u'''Copy the text in the region to the windows clipboard.'''\r\n        if self.enable_win32_clipboard:\r\n                mark = min(self.mark, len(self.line_buffer))\r\n                cursor = min(self.point, len(self.line_buffer))\r\n                if self.mark == -1:\r\n                        return\r\n                begin = min(cursor, mark)\r\n                end = max(cursor, mark)\r\n                toclipboard = u\"\".join(self.line_buffer[begin:end])\r\n                clipboard.SetClipboardText(toclipboard)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_selection_to_clipboard(self): # ()\r\n        u'''Copy the text in the region to the windows clipboard.'''\r\n        if self.enable_win32_clipboard and self.enable_selection and self.selection_mark >= 0:\r\n                selection_mark = min(self.selection_mark,len(self.line_buffer))\r\n                cursor = min(self.point,len(self.line_buffer))\r\n                if self.selection_mark == -1:\r\n                        return\r\n                begin = min(cursor, selection_mark)\r\n                end = max(cursor, selection_mark)\r\n                toclipboard = u\"\".join(self.line_buffer[begin:end])\r\n                clipboard.SetClipboardText(toclipboard)", "response": "Copy the text in the region to the windows clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        if os.system('git add .'):\n            sys.exit(1)\n        if self.message is not None:\n            os.system('git commit -a -m \"' + self.message + '\"')\n        else:\n            os.system('git commit -a')", "response": "Run git add and commit with message if provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses Saxon6 to process the element.", "response": "def saxon6(self, elem, **params):\r\n        \"\"\"Use Saxon6 to process the element. \r\n        If the XSLT has a filename (fn), use that. Otherwise, make temp.\r\n        \"\"\"\r\n        java = os.environ.get('java') or 'java'\r\n        saxon6path = os.path.join(JARS, 'saxon.jar')   # saxon 6.5.5, included with jing and trang\r\n        with tempfile.TemporaryDirectory() as tempdir:\r\n            if self.fn is None:\r\n                xslfn = os.path.join(tempdir, \"xslt.xsl\")\r\n                self.write(fn=xslfn)\r\n            else:\r\n                xslfn = self.fn\r\n            srcfn = os.path.join(tempdir, \"src.xml\")\r\n            outfn = os.path.join(tempdir, \"out.xml\")\r\n            XML(fn=srcfn, root=elem).write()\r\n            cmd = [java, '-jar', saxon6path, '-o', outfn, srcfn, xslfn] \\\r\n                + [\"%s=%r\" % (key, params[key]) for key in params.keys()]\r\n            log.debug(\"saxon6: %r \" % cmd)\r\n\r\n            try:\r\n                subprocess.check_output(cmd)\r\n            except subprocess.CalledProcessError as e:\r\n                error = html.unescape(str(e.output, 'UTF-8'))\r\n                raise RuntimeError(error).with_traceback(sys.exc_info()[2]) from None\r\n\r\n            if self.find(self.root, \"xsl:output\") is None or self.find(self.root, \"xsl:output\").get('method')=='xml':\r\n                return etree.parse(outfn)\r\n            else:\r\n                return open(outfn, 'rb').read().decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uri(self, value):\n        jsonpointer.set_pointer(self.record, self.pointer, value)", "response": "Set new uri value in record.\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, mode='r', **kwargs):\n        _fs, filename = opener.parse(self.uri)\n        return _fs.open(filename, mode=mode, **kwargs)", "response": "Open file under the pointer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves file to a new destination and update the uri.", "response": "def move(self, dst, **kwargs):\n        \"\"\"Move file to a new destination and update ``uri``.\"\"\"\n        _fs, filename = opener.parse(self.uri)\n        _fs_dst, filename_dst = opener.parse(dst)\n        movefile(_fs, filename, _fs_dst, filename_dst, **kwargs)\n        self.uri = dst"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self, dst, **kwargs):\n        _fs, filename = opener.parse(self.uri)\n        _fs_dst, filename_dst = opener.parse(dst)\n        copyfile(_fs, filename, _fs_dst, filename_dst, **kwargs)\n        return [{'op': 'replace', 'path': self.pointer, 'value': dst}]", "response": "Copy file to a new destination."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new file from a string or file - like object.", "response": "def setcontents(self, source, **kwargs):\n        \"\"\"Create a new file from a string or file-like object.\"\"\"\n        if isinstance(source, six.string_types):\n            _file = opener.open(source, 'rb')\n        else:\n            _file = source\n\n        # signals.document_before_content_set.send(self)\n\n        data = _file.read()\n        _fs, filename = opener.parse(self.uri)\n        _fs.setcontents(filename, data, **kwargs)\n        _fs.close()\n\n        # signals.document_after_content_set.send(self)\n\n        if isinstance(source, six.string_types) and hasattr(_file, 'close'):\n            _file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving the file reference from the record.", "response": "def remove(self, force=False):\n        \"\"\"Remove file reference from record.\n\n        If force is True it removes the file from filesystem\n        \"\"\"\n        if force:\n            _fs, filename = opener.parse(self.uri)\n            _fs.remove(filename)\n        self.uri = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xpath(C, node, path, namespaces=None, extensions=None, smart_strings=True, **args):\r\n        return node.xpath(\r\n            path,\r\n            namespaces=namespaces or C.NS,\r\n            extensions=extensions,\r\n            smart_strings=smart_strings,\r\n            **args\r\n        )", "response": "shortcut to Element. xpath"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(C, node, path, namespaces=None, extensions=None, smart_strings=True, **args):\r\n        xp = node.xpath(\r\n            path,\r\n            namespaces=namespaces or C.NS,\r\n            extensions=extensions,\r\n            smart_strings=smart_strings,\r\n            **args\r\n        )\r\n        if len(xp) > 0:\r\n            return xp[0]", "response": "use Element. xpath to find the first element in the node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tobytes(\r\n        self,\r\n        root=None,\r\n        encoding='UTF-8',\r\n        doctype=None,\r\n        canonicalized=True,\r\n        xml_declaration=True,\r\n        pretty_print=True,\r\n        with_comments=True,\r\n    ):\r\n        \"\"\"return the content of the XML document as a byte string suitable for writing\"\"\"\r\n        if root is None:\r\n            root = self.root\r\n        if canonicalized == True:\r\n            return self.canonicalized_bytes(root)\r\n        else:\r\n            return etree.tostring(\r\n                root,\r\n                encoding=encoding or self.info.encoding,\r\n                doctype=doctype or self.info.doctype,\r\n                xml_declaration=xml_declaration,\r\n                pretty_print=pretty_print,\r\n                with_comments=with_comments,\r\n            )", "response": "return the content of the XML document as a byte string suitable for writing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the content of the XML document as a unicode string", "response": "def tostring(self, root=None, doctype=None, pretty_print=True):\r\n        \"\"\"return the content of the XML document as a unicode string\"\"\"\r\n        if root is None:\r\n            root = self.root\r\n        return etree.tounicode(\r\n            root, doctype=doctype or self.info.doctype, pretty_print=pretty_print\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef digest(self, **args):\r\n        return String(XML.canonicalized_string(self.root)).digest(**args)", "response": "calculate a digest based on the hash of the XML content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef element(self, tag_path, test=None, **attributes):\r\n        xpath = tag_path\r\n        tests = [\"@%s='%s'\" % (k, attributes[k]) for k in attributes]\r\n        if test is not None:\r\n            tests.insert(0, test)\r\n        if len(tests) > 0:\r\n            xpath += \"[%s]\" % ' and '.join(tests)\r\n        e = self.find(self.root, xpath)\r\n        if e is None:\r\n            tag = tag_path.split('/')[-1].split('[')[0]\r\n            tagname = tag.split(':')[-1]\r\n            if ':' in tag:\r\n                nstag = tag.split(':')[0]\r\n                tag = \"{%s}%s\" % (self.NS[nstag], tagname)\r\n            e = etree.Element(tag, **attributes)\r\n        return e", "response": "given a tag in xpath form and optional attributes find the element in self. root or return a new one."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Element(cls, s, *args):\r\n        sargs = []\r\n        for arg in args:\r\n            if type(arg) == etree._Element:\r\n                sargs.append(etree.tounicode(arg))\r\n            else:\r\n                sargs.append(arg)\r\n        if type(s) == etree._Element:\r\n            t = etree.tounicode(s)\r\n        else:\r\n            t = s\r\n        if len(args) == 0:\r\n            return XML.fromstring(t)\r\n        else:\r\n            return XML.fromstring(t % tuple(sargs))", "response": "given a string s and string *args return an Element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jing(self, tag=None, schemas=None, schemafn=None, ext='.rnc'):\r\n        from . import JARS\r\n\r\n        java = os.environ.get('java') or 'java'\r\n        jingfn = os.path.join(JARS, 'jing.jar')\r\n        tag = tag or self.root.tag\r\n        schemas = schemas or self.schemas\r\n        schemafn = schemafn or Schema.filename(tag, schemas, ext=ext)\r\n        if schemafn is not None:\r\n            cmd = [java, '-jar', jingfn, '-c', schemafn]\r\n            if os.path.splitext(schemafn)[-1].lower() != '.rnc':\r\n                cmd.pop(cmd.index('-c'))\r\n            try:\r\n                fn = self.fn\r\n                if fn is None or not os.path.exists(fn):\r\n                    tempf = tempfile.NamedTemporaryFile()\r\n                    fn = tempf.name\r\n                    tempf.close()\r\n                    open(fn, 'wb').write(etree.tounicode(self.root).encode('utf-8'))\r\n                subprocess.check_output(cmd + [fn])\r\n            except subprocess.CalledProcessError as e:\r\n                tbtext = html.unescape(str(e.output, 'UTF-8'))\r\n                raise RuntimeError(tbtext).with_traceback(sys.exc_info()[2]) from None", "response": "use the ( included ) jing library to validate the XML."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schematron(self, tag=None, schemas=None, schemafn=None, ext='.sch'):\r\n        from . import PATH\r\n        from .xslt import XSLT\r\n\r\n        schematron_path = os.path.join(PATH, 'schematron', 'trunk', 'schematron', 'code')\r\n\r\n        # select the schema filename\r\n        tag = tag or self.root.tag\r\n        schemas = schemas or self.schemas\r\n        schemafn = (\r\n            schemafn\r\n            or Schema.filename(tag, schemas, ext=ext)\r\n            or Schema.filename(tag, schemas, ext='.rng')\r\n            or Schema.filename(tag, schemas, ext='.rnc')\r\n        )\r\n\r\n        assert schemafn is not None and os.path.exists(schemafn)\r\n\r\n        # ensure that an up-to-date Schematron schema file is available.\r\n        schfn = File(fn=schemafn).clean_filename(ext='.sch')\r\n        fbase, fext = os.path.splitext(schfn)\r\n        if not (os.path.exists(schfn)) or (\r\n            os.path.exists(fbase + '.rnc')\r\n            and File(fn=schfn).last_modified < File(fn=fbase + '.rnc').last_modified\r\n        ):\r\n            # create the Schematron file from the .rnc\r\n            schfn = Schema(fn=fbase + '.rnc').schematron()\r\n        elif not (os.path.exists(schfn)) or (\r\n            os.path.exists(fbase + '.rng')\r\n            and File(fn=schfn).last_modified < File(fn=fbase + '.rng').last_modified\r\n        ):\r\n            # create the Schematron file from the .rng\r\n            schfn = Schema(fn=fbase + '.rng').schematron()\r\n\r\n        assert schfn is not None and os.path.exists(schfn)\r\n\r\n        # ensure that an up-to-date Schematron XSLT file is available\r\n        sch_xslt_fn = schfn + '.xslt'\r\n        if (\r\n            not os.path.exists(sch_xslt_fn)\r\n            or File(fn=sch_xslt_fn).last_modified < File(fn=schfn).last_modified\r\n        ):\r\n            # The Schematron XSLT doesn't exist or is out-of-date, so we need to update it\r\n            sch = XML(fn=schfn)\r\n            sch.fn = sch_xslt_fn\r\n\r\n            # We're using the XSLT 1.0 version of Schematron.\r\n            # even though we use XSLT 2.0+ XPath functions -- the converter doesn't actually read the patterns.\r\n            # (tried the XSLT 2.0 version with Saxon9HE, but Schematron assumes XSLT 1.0 compatibility,\r\n            # which Saxon9HE doesn't support.)\r\n            for xslfb in [\r\n                'iso_dsdl_include.xsl',\r\n                'iso_abstract_expand.xsl',\r\n                'iso_svrl_for_xslt1.xsl',\r\n            ]:\r\n                xslt = XSLT(fn=os.path.join(schematron_path, xslfb))\r\n                sch.root = xslt.saxon6(sch.root).getroot()\r\n                sch.write()\r\n\r\n            # change the XSLT version from \"1.0\" to \"2.0\". (Later we might support 3.0)\r\n            sch.root.set('version', '2.0')\r\n            sch.write()\r\n\r\n        assert sch_xslt_fn is not None and os.path.exists(sch_xslt_fn)\r\n\r\n        # validate the XML against the Schematron XSLT using Saxon 9 (XSLT 3.0 / XPath 3.1)\r\n        sch_xslt = XSLT(fn=sch_xslt_fn)\r\n        report = XML(root=sch_xslt.saxon9(self.root).getroot())\r\n\r\n        # return the errors in the report_xml as a list of errors, with line numbers\r\n        errors = []\r\n        for failure in report.xpath(\r\n            report.root,\r\n            \"//svrl:failed-assert\",\r\n            namespaces={'svrl': \"http://purl.oclc.org/dsdl/svrl\"},\r\n        ):\r\n            for e in self.xpath(self.root, failure.get('location')):\r\n                errors.append(\r\n                    \"%s:%d <%s %s>: error: %s\"\r\n                    % (\r\n                        self.fn,\r\n                        e.sourceline or -1,\r\n                        self.tag_name(e),\r\n                        \" \".join(['%s=\"%s\"' % (k, v) for k, v in e.attrib.items()]),\r\n                        etree.tounicode(failure, method='text').strip(),\r\n                    )\r\n                )\r\n        return errors", "response": "validate the XML using Schematron"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef namespace(self, elem=None):\r\n        if elem is None:\r\n            elem = self.root\r\n        return XML.tag_namespace(elem.tag)", "response": "return the URL if any for the doc root or elem if given."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tag_namespace(cls, tag):\r\n        md = re.match(\"^(?:\\{([^\\}]*)\\})\", tag)\r\n        if md is not None:\r\n            return md.group(1)", "response": "return the namespace for a given tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the name of the tag with the namespace removed", "response": "def tag_name(cls, tag):\r\n        \"\"\"return the name of the tag, with the namespace removed\"\"\"\r\n        while isinstance(tag, etree._Element):\r\n            tag = tag.tag\r\n        return tag.split('}')[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_dict(self, elem=None, ignore_whitespace=True, namespaces=True):\r\n        if elem is None:\r\n            elem = self.root\r\n        tag = self.tag_dict_key(elem.tag, namespaces=namespaces)\r\n        d = Dict(**{tag: {}})\r\n        d[tag].update(\r\n            **{\r\n                '@' + self.tag_dict_key(k, namespaces=namespaces): elem.attrib[k]\r\n                for k in elem.attrib.keys()\r\n            }\r\n        )\r\n        nodes = []\r\n        if elem.text is not None and (elem.text.strip() != '' or ignore_whitespace != True):\r\n            nodes.append(str(elem.text))\r\n        for ch in [\r\n            e for e in elem.getchildren() if type(e) == etree._Element\r\n        ]:  # *** IGNORE EVERYTHING EXCEPT ELEMENTS ***\r\n            nodes.append(\r\n                self.as_dict(elem=ch, ignore_whitespace=ignore_whitespace, namespaces=namespaces)\r\n            )\r\n            if ch.tail is not None and (ch.tail.strip() != '' or ignore_whitespace != True):\r\n                d[tag].append(ch.tail)\r\n        if nodes != []:\r\n            d[tag]['nodes'] = nodes\r\n        return d", "response": "Create a generalized dict output from this element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a dict key into an element or attribute name", "response": "def dict_key_tag(Class, key, namespaces=None):\r\n        \"\"\"convert a dict key into an element or attribute name\"\"\"\r\n        namespaces = namespaces or Class.NS\r\n        ns = Class.tag_namespace(key)\r\n        tag = Class.tag_name(key)\r\n        if ns is None and ':' in key:\r\n            prefix, tag = key.split(':')\r\n            if prefix in namespaces.keys():\r\n                ns = namespaces[prefix]\r\n        if ns is not None:\r\n            tag = \"{%s}%s\" % (ns, tag)\r\n        return tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(Class, element_data, fn=None):\r\n        from .builder import Builder\r\n\r\n        B = Builder(default=Class.DEFAULT_NS, **Class.NS)\r\n        keys = list(element_data.keys())\r\n        assert len(keys) == 1\r\n        key = keys[0]\r\n        elem_tag = Class.dict_key_tag(key)\r\n        elem = B(elem_tag)\r\n        for k in element_data[key].keys():\r\n            # attributes\r\n            if k[0] == '@':\r\n                attr_name = Class.dict_key_tag(k[1:])\r\n                elem.set(attr_name, element_data[key][k])\r\n            elif k == 'nodes':\r\n                for node in element_data[key][k]:\r\n                    if type(node) == str:\r\n                        if len(elem) == 0:\r\n                            elem.text = node\r\n                        else:\r\n                            elem[-1].tail = node\r\n                    else:\r\n                        child_elem = Class.from_dict(node)\r\n                        elem.append(child_elem)\r\n            else:\r\n                raise ValueError('unsupported data: %r: %r' % (k, element_data[key][k]))\r\n        return elem", "response": "reverse of XML. as_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_with_contents(c, elem):\r\n        \"removes an element and leaves its contents in its place. Namespaces supported.\"\r\n        parent = elem.getparent()\r\n        index = parent.index(elem)\r\n        children = elem.getchildren()\r\n        previous = elem.getprevious()\r\n        # text\r\n        if index == 0:\r\n            parent.text = (parent.text or '') + (elem.text or '')\r\n        else:\r\n            previous.tail = (previous.tail or '') + (elem.text or '')\r\n        # children\r\n        for child in children:\r\n            parent.insert(index + children.index(child), child)\r\n        # tail\r\n        if len(children) > 0:\r\n            last_child = children[-1]\r\n            last_child.tail = (last_child.tail or '') + (elem.tail or '')\r\n        else:\r\n            if index == 0:\r\n                parent.text = (parent.text or '') + (elem.tail or '')\r\n            else:\r\n                previous.tail = (previous.tail or '') + (elem.tail or '')\r\n        # elem\r\n        parent.remove(elem)", "response": "removes an element and leaves its contents in its place. Namespaces supported."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_range(cls, elem, end_elem, delete_end=True):\r\n        while elem is not None and elem != end_elem and end_elem not in elem.xpath(\"descendant::*\"):\r\n            parent = elem.getparent()\r\n            nxt = elem.getnext()\r\n            parent.remove(elem)\r\n            if DEBUG == True:\r\n                print(etree.tounicode(elem))\r\n            elem = nxt\r\n        if elem == end_elem:\r\n            if delete_end == True:\r\n                cls.remove(end_elem, leave_tail=True)\r\n        elif elem is None:\r\n            if parent.tail not in [None, '']:\r\n                parent.tail = ''\r\n            cls.remove_range(parent.getnext(), end_elem)\r\n            XML.remove_if_empty(parent)\r\n        elif end_elem in elem.xpath(\"descendant::*\"):\r\n            if DEBUG == True:\r\n                print(elem.text)\r\n            elem.text = ''\r\n            cls.remove_range(elem.getchildren()[0], end_elem)\r\n            XML.remove_if_empty(elem)\r\n        else:\r\n            print(\"LOGIC ERROR\", file=sys.stderr)", "response": "delete everything from elem to end_elem including elem. if delete_end == True also including end_elem ; otherwise leave it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps the content of container element with wrapper element", "response": "def wrap_content(cls, container, wrapper):\r\n        \"wrap the content of container element with wrapper element\"\r\n        wrapper.text = (container.text or '') + (wrapper.text or '')\r\n        container.text = ''\r\n        for ch in container:\r\n            wrapper.append(ch)\r\n        container.insert(0, wrapper)\r\n        return container"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fragment_nesting(cls, elem1, tag2, namespaces=None):\r\n        elems2 = elem1.xpath(\"child::%s\" % tag2, namespaces=namespaces)\r\n        while len(elems2) > 0:\r\n            elem2 = elems2[0]\r\n            parent2 = elem2.getparent()\r\n            index2 = parent2.index(elem2)\r\n\r\n            # all of elem2 has a new tag1 element embedded inside of it\r\n            child_elem1 = etree.Element(elem1.tag)\r\n            for k in elem1.attrib:\r\n                child_elem1.set(k, elem1.get(k))\r\n            elem2.text, child_elem1.text = '', elem2.text\r\n            for ch in elem2.getchildren():\r\n                child_elem1.append(ch)\r\n            elem2.insert(0, child_elem1)\r\n\r\n            # new_elem1 for all following children of parent2\r\n            new_elem1 = etree.Element(elem1.tag)\r\n            for k in elem1.attrib:\r\n                new_elem1.set(k, elem1.get(k))\r\n            new_elem1.text, elem2.tail = elem2.tail, ''\r\n            for ch in parent2.getchildren()[index2 + 1 :]:\r\n                new_elem1.append(ch)\r\n\r\n            # elem2 is placed after parent2\r\n            parent = parent2.getparent()\r\n            parent.insert(parent.index(parent2) + 1, elem2)\r\n            last_child = elem2\r\n\r\n            # new_elem1 is placed after elem2\r\n            parent.insert(parent.index(elem2) + 1, new_elem1)\r\n            new_elem1.tail, elem1.tail = elem1.tail, ''\r\n\r\n            XML.remove_if_empty(elem1)\r\n            XML.remove_if_empty(new_elem1)\r\n\r\n            # repeat until all tag2 elements are unpacked from the new_elem1\r\n            elem1 = new_elem1\r\n            elems2 = elem1.xpath(\"child::%s\" % tag2, namespaces=namespaces)", "response": "for elem1 containing elements with tag2 fragment elem1 into elems that are adjacent to and nested within tag2."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the Visibility State of the Users Profile", "response": "def communityvisibilitystate(self):\n        \"\"\"Return the Visibility State of the Users Profile\"\"\"\n        if self._communityvisibilitystate == None:\n            return None\n        elif self._communityvisibilitystate in self.VisibilityState:\n            return self.VisibilityState[self._communityvisibilitystate]\n        else:\n            #Invalid State\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef personastate(self):\n        if self._personastate == None:\n            return None\n        elif self._personastate in self.PersonaState:\n            return self.PersonaState[self._personastate]\n        else:\n            #Invalid State\n            return None", "response": "Return the Persona State of the Users Profile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a dataflashlog in the format produced by Mission Planner return a datetime which says when the file was downloaded from the APM", "response": "def logpath2dt(filepath):\n    \"\"\"\n    given a dataflashlog in the format produced by Mission Planner,\n    return a datetime which says when the file was downloaded from the APM\n    \"\"\"\n    return datetime.datetime.strptime(re.match(r'.*/(.*) .*$',filepath).groups()[0],'%Y-%m-%d %H-%M')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the crossing intercept points of a series or a dataframe.", "response": "def cross(series, cross=0, direction='cross'):\n    \"\"\"\n    From http://stackoverflow.com/questions/10475488/calculating-crossing-intercept-points-of-a-series-or-dataframe\n\n    Given a Series returns all the index values where the data values equal \n    the 'cross' value. \n\n    Direction can be 'rising' (for rising edge), 'falling' (for only falling \n    edge), or 'cross' for both edges\n    \"\"\"\n    # Find if values are above or bellow yvalue crossing:\n    above=series.values > cross\n    below=scipy.logical_not(above)\n    left_shifted_above = above[1:]\n    left_shifted_below = below[1:]\n    x_crossings = []\n    # Find indexes on left side of crossing point\n    if direction == 'rising':\n        idxs = (left_shifted_above & below[0:-1]).nonzero()[0]\n    elif direction == 'falling':\n        idxs = (left_shifted_below & above[0:-1]).nonzero()[0]\n    else:\n        rising = left_shifted_above & below[0:-1]\n        falling = left_shifted_below & above[0:-1]\n        idxs = (rising | falling).nonzero()[0]\n\n    # Calculate x crossings with interpolation using formula for a line:\n    x1 = series.index.values[idxs]\n    x2 = series.index.values[idxs+1]\n    y1 = series.values[idxs]\n    y2 = series.values[idxs+1]\n    x_crossings = (cross-y1)*(x2-x1)/(y2-y1) + x1\n\n    return x_crossings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Deferred yielding at most max_bytes * bytes from the response body.", "response": "def read_body(response, max_bytes=None):\n    \"\"\"Return a `Deferred` yielding at most *max_bytes* bytes from the\n    body of a Twisted Web *response*, or the whole body if *max_bytes*\n    is `None`.\"\"\"\n    finished = Deferred()\n    response.deliverBody(TruncatingReadBodyProtocol(\n        response.code, response.phrase, finished, max_bytes))\n    return finished"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Unicode unicode object describing the given failure.", "response": "def describe_error(failure):\n    \"\"\"If *failure* is a common connection error, return a Unicode\n    string describing it.  Otherwise, return *failure*.\"\"\"\n    if failure.check(ResponseFailed):\n        if any(f.check(InfiniteRedirection)\n               for f in failure.value.reasons):\n            return u'Encountered too many redirects.'\n        return u'Received incomplete response from server.'\n    if failure.check(ConnectError, DNSLookupError, BlacklistedHost):\n        return u'Could not connect to server.'\n    return failure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nissuing a request to the server indicated by *uri*.", "response": "def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"Issue a request to the server indicated by *uri*.\"\"\"\n        hostname = urlparse(uri).hostname\n        ip_str = yield self.resolve(hostname)\n        # `ipaddress` takes a Unicode string and I don't really care to\n        # handle `UnicodeDecodeError` separately.\n        ip = ipaddress.ip_address(ip_str.decode('ascii', 'replace'))\n        if ip.is_private or ip.is_loopback or ip.is_link_local:\n            raise BlacklistedHost(hostname, ip)\n        response = yield self.agent.request(method, uri, headers, bodyProducer)\n        returnValue(response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_title(self, url, hostname_tag=False, friendly_errors=False):\n        title = None\n        if isinstance(url, unicode):\n            url = URL.fromText(url)\n        elif isinstance(url, str):\n            url = URL.fromText(url.decode('ascii'))\n        current = url\n        response = None\n        for _ in xrange(self.max_soft_redirects):\n            last_response = response\n            # This encoding should be safe, since asURI() only returns\n            # URIs with ASCII code points.\n            request = self.agent.request(\n                'GET', current.asURI().asText().encode('ascii'))\n            if friendly_errors:\n                request.addErrback(describe_error)\n            response = yield request\n            if isinstance(response, basestring):\n                # We got an error message from describe_error.  Bail.\n                title = response\n                break\n            response.setPreviousResponse(last_response)\n            content_type = cgi.parse_header(\n                response.headers.getRawHeaders('Content-Type', [''])[0])[0]\n            if content_type in self.extractors:\n                extractor = self.extractors[content_type]\n                extracted = yield extractor.extract(response)\n                if isinstance(extracted, Redirect):\n                    current = URL.fromText(\n                        response.request.absoluteURI.decode('ascii')).click(\n                        extracted.location)\n                    continue\n                title = extracted\n            # The only case where we'd want to loop again is when the\n            # response returned is a soft redirect.\n            break\n        else:\n            if friendly_errors:\n                title = u'Encountered too many redirects.'\n            else:\n                raise ResponseFailed([Failure(InfiniteRedirection(\n                    599, 'Too many soft redirects',\n                    location=current.asURI().asText().encode('ascii')))])\n        if title is None:\n            title = u'{} document'.format(content_type or u'Unknown')\n            if response.length is not UNKNOWN_LENGTH:\n                title += u' ({})'.format(filesize(response.length))\n        if hostname_tag:\n            tag = url.host\n            if isinstance(response, Response):\n                initial = url.host\n                final = URL.fromText(\n                    response.request.absoluteURI.decode('ascii')).host\n                if initial != final:\n                    tag = u'{} \\u2192 {}'.format(initial, final)\n            title = u'[{}] {}'.format(tag, title)\n        returnValue(title)", "response": "Fetch the document at url and return a Deferred yielding the title or summary as a Unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning played percentage of item", "response": "def percentage_played(self):\n    '''returns played percentage [0,1] of item'''\n    played = self.object_dict.get('UserData', {}).get('PlaybackPositionTicks')\n    total  = self.object_dict.get('RunTimeTicks') or 1\n    return (played or 0)/total"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url(self):\n    '''url of the item\n\n    Notes\n    -----\n      if remote-adderes was given, then that is used as the base\n    '''\n    path = '/web/itemdetails.html?id={}'.format(self.id)\n    return self.connector.get_url(path, attach_api_key=False)", "response": "url of the item\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreload object info from emby |coro|", "response": "async def update(self, fields=''):\n    '''reload object info from emby\n\n    |coro|\n\n    Parameters\n    ----------\n    fields : str\n      additional fields to request when updating\n\n    See Also\n    --------\n      refresh : same thing\n      send :\n      post :\n    '''\n    path = 'Users/{{UserId}}/Items/{}'.format(self.id)\n    info = await self.connector.getJson(path,\n                                        remote=False,\n                                        Fields='Path,Overview,'+fields\n    )\n    self.object_dict.update(info)\n    self.extras = {}\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send(self):\n    '''send data that was changed to emby\n\n    |coro|\n\n    This should be used after using any of the setter. Not necessarily\n    immediately, but soon after.\n\n    See Also\n    --------\n      post: same thing\n      update :\n      refresh :\n\n    Returns\n    -------\n      aiohttp.ClientResponse or None if nothing needed updating\n    '''\n    # Why does the whole dict need to be sent?\n    #   because emby is dumb, and will break if I don't\n    path = 'Items/{}'.format(self.id)\n    resp = await self.connector.post(path, data=self.object_dict, remote=False)\n    if resp.status == 400:\n      await EmbyObject(self.object_dict, self.connector).update()\n      resp = await self.connector.post(path,data=self.object_dict,remote=False)\n    return resp", "response": "send data that was changed to emby\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def process(self, object_dict):\n    '''[for internal use] convert json/dict into python object\n\n    |coro|\n\n    Parameters\n    ----------\n    object_dict : dict\n      json representation of object from emby\n\n    Notes\n    -----\n    if a string is given, it is assumed to be an id, obj is returned.\n    if a list is given, this method is called for each item in list.\n\n    Returns\n    -------\n    EmbyObject\n      the object that is represented by the json dict\n    list\n      if input is a list, list is returned\n    '''\n    # if ID was given, create dummy object and update it to get full dict\n    try:\n      if type(object_dict) == str:\n        existing = EmbyObject.known_objects.get(object_dict)\n        if existing:\n          return existing\n\n        obj = EmbyObject({\"Id\":object_dict}, self.connector, save=False)\n        object_dict = (await obj.update()).object_dict\n    except:\n      return None\n\n    # if nothing was given, return it back\n    # if already created object was given, return it back too\n    if not object_dict or isinstance(object_dict, EmbyObject):\n      return object_dict\n\n    # if a json dict that's really just a list was given,\n    #   convert to list\n    if type(object_dict)       == dict and \\\n       set(object_dict.keys()) == {'Items', 'TotalRecordCount'}:\n      object_dict = object_dict['Items']\n\n    # if a list was given,\n    #   process each item in list\n    if type(object_dict) == list:\n      items = []\n      for item in object_dict:\n        item = await self.process(item)\n        if item:\n          items.append(item)\n      return items\n\n    # otherwise we probably have an object dict\n    #   so we should process that\n\n    # if dict has no id, it's a fake\n    if 'Id' not in object_dict and 'ItemId' not in object_dict:\n      return object_dict\n\n    # if object is already stored,\n    #   update with existing info and return\n    itemId   = object_dict.get('Id', object_dict.get('ItemId'))\n    existing = EmbyObject.known_objects.get(itemId)\n    if existing:\n      existing.object_dict.update(object_dict)\n      return existing\n\n    import embypy.objects.folders\n    import embypy.objects.videos\n    import embypy.objects.misc\n\n    # if objectc is not already stored,\n    #   figure out its type (if unknown use this base class)\n    #   create an object with subclass of that type\n    #   return\n    if 'Type' in object_dict:\n        if object_dict['Type'] == 'Audio':\n          return embypy.objects.misc.Audio(object_dict, self.connector)\n        if object_dict['Type'] == 'Person':\n          return embypy.objects.misc.Person(object_dict, self.connector)\n        if object_dict['Type'] == 'Video':\n          return embypy.objects.videos.Video(object_dict, self.connector)\n        if object_dict['Type'] == 'Movie':\n          return embypy.objects.videos.Movie(object_dict, self.connector)\n        if object_dict['Type'] == 'Trailer':\n          return embypy.objects.videos.Trailer(object_dict, self.connector)\n        if object_dict['Type'] == 'AdultVideo':\n          return embypy.objects.videos.AdultVideo(object_dict, self.connector)\n        if object_dict['Type'] == 'MusicVideo':\n          return embypy.objects.videos.MusicVideo(object_dict, self.connector)\n        if object_dict['Type'] == 'Episode':\n          return embypy.objects.videos.Episode(object_dict, self.connector)\n        if object_dict['Type'] == 'Folder':\n          return embypy.objects.folders.Folder(object_dict, self.connector)\n        if object_dict['Type'] == 'Playlist':\n          return embypy.objects.folders.Playlist(object_dict, self.connector)\n        if object_dict['Type'] == 'BoxSet':\n          return embypy.objects.folders.BoxSet(object_dict, self.connector)\n        if object_dict['Type'] == 'MusicAlbum':\n          return embypy.objects.folders.MusicAlbum(object_dict, self.connector)\n        if object_dict['Type'] == 'MusicArtist':\n          return embypy.objects.folders.MusicArtist(object_dict, self.connector)\n        if object_dict['Type'] == 'Season':\n          return embypy.objects.folders.Season(object_dict, self.connector)\n        if object_dict['Type'] == 'Series':\n          return embypy.objects.folders.Series(object_dict, self.connector)\n        if object_dict['Type'] == 'Game':\n          return embypy.objects.misc.Game(object_dict, self.connector)\n        if object_dict['Type'] == 'GameSystem':\n          return embypy.objects.folders.GameSystem(object_dict, self.connector)\n        if object_dict['Type'] == 'Photo':\n          return embypy.objects.misc.Photo(object_dict, self.connector)\n        if object_dict['Type'] == 'Book':\n          return embypy.objects.misc.Book(object_dict, self.connector)\n        if object_dict['Type'] == 'Image':\n          return embypy.objects.misc.Image(object_dict, self.connector)\n    elif 'AppName' in object_dict:\n            return embypy.objects.misc.Device(object_dict, self.connector)\n    elif 'HasPassword' in object_dict:\n            return embypy.objects.misc.User(object_dict, self.connector)\n\n    return EmbyObject(object_dict, self.connector)", "response": "process a json dict into a list of objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_lib(lib_name):\n    targ_dlib = libraries_dir() / lib_name\n    log.debug('remove %s', targ_dlib)\n    targ_dlib.rmtree()", "response": "remove library.\n\n    :param lib_name: library name (e.g. 'PS2Keyboard')\n    :rtype: None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_holidays(self, filename):\n\t\tcal = Calendar.from_ical(open(filename, 'rb').read())\n\t\tholidays = []\n\n\t\tfor component in cal.walk('VEVENT'):\n\t\t\tstart = component.decoded('DTSTART')\n\t\t\ttry:\n\t\t\t\tend = component.decoded('DTEND')\n\t\t\texcept KeyError:\n\t\t\t\t# RFC allows DTEND to be missing\n\t\t\t\tif isinstance(start, datetime):\n\t\t\t\t\t# For DATETIME instances, the event ends immediately.\n\t\t\t\t\tend = start\n\t\t\t\telif isinstance(start, date):\n\t\t\t\t\t# For DATE instances, the event ends tomorrow\n\t\t\t\t\tend = start + timedelta(days=1)\n\t\t\t\telse:\n\t\t\t\t\traise KeyError, 'DTEND is missing and DTSTART is not of DATE or DATETIME type'\n\n\t\t\tif isinstance(start, date) and not isinstance(start, datetime):\n\t\t\t\tassert (isinstance(end, date) and not isinstance(end, datetime)), \\\n\t\t\t\t\t'DTSTART is of DATE type but DTEND is not of DATE type (got %r instead)' % type(end)\n\t\t\t\t# All-day event, set times to midnight local time\n\t\t\t\tstart = datetime.combine(start, time.min)\n\t\t\t\tend = datetime.combine(end, time.min)\n\n\t\t\t# check for TZ data\n\t\t\tif start.tzinfo is None or end.tzinfo is None:\n\t\t\t\t# One of them is missing tzinfo, replace both with this office's\n\t\t\t\t# local time.  Assume standard time if ambiguous.\n\t\t\t\tstart = self.tz.localize(start, is_dst=False)\n\t\t\t\tend = self.tz.localize(end, is_dst=False)\n\n\t\t\tyield (start, end)", "response": "Read holidays from an iCalendar - format file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the given time is in business hours for the office False otherwise.", "response": "def in_hours(self, when):\n\t\t\"\"\"\n\t\tFind if the given :class:`~datetime.datetime` is in business hours for\n\t\tthis office.\n\n\t\t:param datetime.datetime when: The time to check\n\n\t\t:returns: True if the given time is in business hours for the office, False otherwise.\n\t\t:rtype: bool\n\n\t\t\"\"\"\n\n\t\t# convert to local timezone\n\t\twhen = when.astimezone(self.tz)\n\n\t\t# is it a work day?\n\t\tif when.weekday() not in self.hours:\n\t\t\t# not a work day\n\t\t\treturn False\n\n\t\t# work out if it is one of the ranges\n\t\tfor start, end in self.hours[when.weekday()]:\n\t\t\tif start <= when.time() <= end:\n\t\t\t\t# it's in that range\n\n\t\t\t\t# is it a public holiday?  check if it is any range\n\t\t\t\tfor hstart, hend in self.holidays:\n\t\t\t\t\tif when >= hstart and when <= hend:\n\t\t\t\t\t\t# it's inside a holiday area.\n\t\t\t\t\t\treturn False\n\n\t\t\t\t# not in a holiday zone, which means it's business time.\n\t\t\t\treturn True\n\n\t\t# not in any range of hours, and was on a work day\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef in_hours(self, office=None, when=None):\n\n\t\tif when == None:\n\t\t\twhen = datetime.now(tz=utc)\n\n\t\tif office == None:\n\t\t\tfor office in self.offices.itervalues():\n\t\t\t\tif office.in_hours(when):\n\t\t\t\t\treturn True\n\n\t\t\treturn False\n\n\t\telse:\n\t\t\t# check specific office\n\t\t\treturn self.offices[office].in_hours(when)", "response": "Returns True if the given office is in business hours False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef opener(mode='r'):\n\n    def open_file(f):\n        if f is sys.stdout or f is sys.stdin:\n            return f\n        elif f == '-':\n            return sys.stdin if 'r' in mode else sys.stdout\n        elif f.endswith('.bz2'):\n            return bz2.BZ2File(f, mode)\n        elif f.endswith('.gz'):\n            return gzip.open(f, mode)\n        else:\n            return open(f, mode)\n\n    return open_file", "response": "Returns a function that opens the file objects in the order they appear in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, id, no_summary=False):\n        resp = self.client.accounts.get(id)\n        if no_summary:\n            return self.display(resp)\n\n        results = []\n        # Get a list of all volumes for this tenant id\n        client = LunrClient(self.get_admin(), debug=self.debug)\n        volumes = client.volumes.list(account_id=resp['id'])\n        #volumes = self.client.volumes.list(resp['id'])\n        for volume in volumes:\n            if volume['status'] == 'DELETED':\n                continue\n            results.append(volume)\n\n        self.display(resp, ['name', 'status', 'last_modified', 'created_at'])\n        if results:\n            return self.display(response(results, 200),\n                                ['id', 'status', 'size'])\n        else:\n            print(\"-- This account has no active volumes --\")\n        print(\"\\nThis is a summary, use --no-summary \"\n              \"to see the entire response\")", "response": "Get details for a specific tenant id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, id):\n        resp = self.client.accounts.create(id=id)\n        self.display(resp)", "response": "Create a new tenant id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, id):\n        resp = self.client.accounts.delete(id)\n        self.display(resp)", "response": "Delete an tenant id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    parser = argparse.ArgumentParser()\n    group_tcp = parser.add_argument_group('TCP')\n    group_tcp.add_argument('--tcp', dest='mode', action='store_const', const=PROP_MODE_TCP, help=\"Set tcp mode\")\n    group_tcp.add_argument('--host', dest='hostname', help=\"Specify hostname\", default='')\n    group_tcp.add_argument('--port', dest='port', help=\"Specify port\", default=23, type=int)\n    group_serial = parser.add_argument_group('Serial')\n    group_serial.add_argument('--serial', dest='mode', action='store_const', const=PROP_MODE_SERIAL, help=\"Set serial mode\")\n    group_serial.add_argument('--interface', dest='interface', help=\"Specify interface\", default='')\n    group_file = parser.add_argument_group('File')\n    group_file.add_argument('--file', dest='mode', action='store_const', const=PROP_MODE_FILE, help=\"Set file mode\")\n    group_file.add_argument('--name', dest='file', help=\"Specify file name\", default='')\n    args = parser.parse_args()\n\n    kwb = KWBEasyfire(args.mode, args.hostname, args.port, args.interface, 0, args.file)\n    kwb.run_thread()\n    time.sleep(5)\n    kwb.stop_thread()\n    print(kwb)", "response": "Main method for debug purposes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a connection to the easyfire unit.", "response": "def _open_connection(self):\n        \"\"\"Open a connection to the easyfire unit.\"\"\"\n        if (self._mode == PROP_MODE_SERIAL):\n            self._serial = serial.Serial(self._serial_device, self._serial_speed)\n        elif (self._mode == PROP_MODE_TCP):\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.connect((self._ip, self._port))\n        elif (self._mode == PROP_MODE_FILE):\n            self._file = open(self._file_path, \"r\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the connection to the easyfire unit.", "response": "def _close_connection(self):\n        \"\"\"Close the connection to the easyfire unit.\"\"\"\n        if (self._mode == PROP_MODE_SERIAL):\n            self._serial.close()\n        elif (self._mode == PROP_MODE_TCP):\n            self._socket.close()\n        elif (self._mode == PROP_MODE_FILE):\n            self._file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a byte to the checksum.", "response": "def _add_to_checksum(self, checksum, value):\n        \"\"\"Add a byte to the checksum.\"\"\"\n        checksum = self._byte_rot_left(checksum, 1)\n        checksum = checksum + value\n        if (checksum > 255):\n            checksum = checksum - 255\n        self._debug(PROP_LOGLEVEL_TRACE, \"C: \" + str(checksum) + \" V: \" + str(value))\n        return checksum"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_byte(self):\n\n        to_return = \"\"\n        if (self._mode == PROP_MODE_SERIAL):\n            to_return = self._serial.read(1)\n        elif (self._mode == PROP_MODE_TCP):\n            to_return = self._socket.recv(1)\n        elif (self._mode == PROP_MODE_FILE):\n            to_return = struct.pack(\"B\", int(self._file.readline()))\n\n        _LOGGER.debug(\"READ: \" + str(ord(to_return)))\n        self._logdata.append(ord(to_return))\n        if (len(self._logdata) > self._logdatalen):\n            self._logdata = self._logdata[len(self._logdata) - self._logdatalen:]\n\n        self._debug(PROP_LOGLEVEL_TRACE, \"READ: \" + str(ord(to_return)))\n\n        return to_return", "response": "Read a byte from input."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a sense packet to a list of bytes.", "response": "def _sense_packet_to_data(packet):\n        \"\"\"Remove the escape pad bytes from a sense packet (\\2\\0 -> \\2).\"\"\"\n        data = bytearray(0)\n        last = 0\n        i = 1\n        while (i < len(packet)):\n            if not (last == 2 and packet[i] == 0):\n                data.append(packet[i])\n            last = packet[i]\n            i += 1\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a signed short temperature as two bytes to a single number.", "response": "def _decode_temp(byte_1, byte_2):\n        \"\"\"Decode a signed short temperature as two bytes to a single number.\"\"\"\n        temp = (byte_1 << 8) + byte_2\n        if (temp > 32767):\n            temp = temp - 65536\n        temp = temp / 10\n        return temp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a packet from the input.", "response": "def _read_packet(self):\n        \"\"\"Read a packet from the input.\"\"\"\n\n        status = STATUS_WAITING\n        mode = 0\n        checksum = 0\n        checksum_calculated = 0\n        length = 0\n        version = 0\n        i = 0\n        cnt = 0\n        packet = bytearray(0)\n\n        while (status != STATUS_PACKET_DONE):\n\n            read = self._read_ord_byte()\n            if (status != STATUS_CTRL_CHECKSUM and status != STATUS_SENSE_CHECKSUM):\n                checksum_calculated = self._add_to_checksum(checksum_calculated, read)\n            self._debug(PROP_LOGLEVEL_TRACE, \"R: \" + str(read))\n            self._debug(PROP_LOGLEVEL_TRACE, \"S: \" + str(status))\n\n            if (status == STATUS_WAITING):\n                if (read == 2):\n                    status = STATUS_PRE_1\n                    checksum_calculated = read\n                else:\n                    status = STATUS_WAITING\n            elif (status == STATUS_PRE_1):\n                checksum = 0\n                if (read == 2):\n                    status = STATUS_SENSE_PRE_2\n                    checksum_calculated = read\n                elif (read == 0):\n                    status = STATUS_WAITING\n                else:\n                    status = STATUS_CTRL_PRE_2\n            elif (status == STATUS_SENSE_PRE_2):\n                length = read\n                status = STATUS_SENSE_PRE_LENGTH\n            elif (status == STATUS_SENSE_PRE_LENGTH):\n                version = read\n                status = STATUS_SENSE_PRE_3\n            elif (status == STATUS_SENSE_PRE_3):\n                cnt = read\n                i = 0\n                status = STATUS_SENSE_DATA\n            elif (status == STATUS_SENSE_DATA):\n                packet.append(read)\n                i = i + 1\n                if (i == length):\n                    status = STATUS_SENSE_CHECKSUM\n            elif (status == STATUS_SENSE_CHECKSUM):\n                checksum = read\n                mode = PROP_PACKET_SENSE\n                status = STATUS_PACKET_DONE\n            elif (status == STATUS_CTRL_PRE_2):\n                version = read\n                status = STATUS_CTRL_PRE_3\n            elif (status == STATUS_CTRL_PRE_3):\n                cnt = read\n                i = 0\n                length = 16\n                status = STATUS_CTRL_DATA\n            elif (status == STATUS_CTRL_DATA):\n                packet.append(read)\n                i = i + 1\n                if (i == length):\n                    status = STATUS_CTRL_CHECKSUM\n            elif (status == STATUS_CTRL_CHECKSUM):\n                checksum = read\n                mode = PROP_PACKET_CTRL\n                status = STATUS_PACKET_DONE\n            else:\n                status = STATUS_WAITING\n\n        self._debug(PROP_LOGLEVEL_DEBUG, \"MODE: \" + str(mode) + \" Version: \" + str(version) + \" Checksum: \" + str(checksum) + \" / \" + str(checksum_calculated) + \" Count: \" + str(cnt) + \" Length: \" + str(len(packet)))\n        self._debug(PROP_LOGLEVEL_TRACE, \"Packet: \" + str(packet))\n\n        return (mode, version, packet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _decode_sense_packet(self, version, packet):\n\n        data = self._sense_packet_to_data(packet)\n\n        offset = 4\n        i = 0\n\n        datalen = len(data) - offset - 6\n        temp_count = int(datalen / 2)\n        temp = []\n\n        for i in range(temp_count):\n            temp_index = i * 2 + offset\n            temp.append(self._decode_temp(data[temp_index], data[temp_index + 1]))\n\n        self._debug(PROP_LOGLEVEL_DEBUG, \"T: \" + str(temp))\n\n        for sensor in self._sense_sensor:\n            if (sensor.sensor_type == PROP_SENSOR_TEMPERATURE):\n                sensor.value = temp[sensor.index]\n            elif (sensor.sensor_type == PROP_SENSOR_RAW):\n                sensor.value = packet\n\n        self._debug(PROP_LOGLEVEL_DEBUG, str(self))", "response": "Decode a sense packet into the list of sensors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _decode_ctrl_packet(self, version, packet):\n\n        for i in range(5):\n            input_bit = packet[i]\n            self._debug(PROP_LOGLEVEL_DEBUG, \"Byte \" + str(i) + \": \" + str((input_bit >> 7) & 1) + str((input_bit >> 6) & 1) + str((input_bit >> 5) & 1) + str((input_bit >> 4) & 1) + str((input_bit >> 3) & 1) + str((input_bit >> 2) & 1) + str((input_bit >> 1) & 1) + str(input_bit & 1))\n\n        for sensor in self._ctrl_sensor:\n            if (sensor.sensor_type == PROP_SENSOR_FLAG):\n                sensor.value = (packet[sensor.index // 8] >> (sensor.index % 8)) & 1\n            elif (sensor.sensor_type == PROP_SENSOR_RAW):\n                sensor.value = packet", "response": "Decode a control packet into the list of sensors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        while (self._run_thread):\n            (mode, version, packet) = self._read_packet()\n            if (mode == PROP_PACKET_SENSE):\n                self._decode_sense_packet(version, packet)\n            elif (mode == PROP_PACKET_CTRL):\n                self._decode_ctrl_packet(version, packet)", "response": "Main thread that reads from input and populates the sensors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the main thread.", "response": "def run_thread(self):\n        \"\"\"Run the main thread.\"\"\"\n        self._run_thread = True\n        self._thread.setDaemon(True)\n        self._thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unused(self, _dict):\n        for key, value in _dict.items():\n            if value is None:\n                del _dict[key]\n        return _dict", "response": "Remove empty parameters from the dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring the required items are in the dictionary", "response": "def required(self, method, _dict, require):\n        \"\"\"\n        Ensure the required items are in the dictionary\n        \"\"\"\n        for key in require:\n            if key not in _dict:\n                raise LunrError(\"'%s' is required argument for method '%s'\"\n                                % (key, method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef allowed(self, method, _dict, allow):\n        for key in _dict.keys():\n            if key not in allow:\n                raise LunrError(\"'%s' is not an argument for method '%s'\"\n                                % (key, method))", "response": "Only these items are allowed in the dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_event_name(name):\n    try:\n        app, event = name.split('.')\n        return '{}.{}'.format(app, EVENTS_MODULE_NAME), event\n    except ValueError:\n        raise InvalidEventNameError(\n            (u'The name \"{}\" is invalid. '\n             u'Make sure you are using the \"app.KlassName\" format'\n             ).format(name))", "response": "Parse an event name into a python module and obj"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_event(name):\n    try:\n        module, klass = parse_event_name(name)\n        return getattr(import_module(module), klass)\n    except (ImportError, AttributeError):\n        raise EventNotFoundError(\n            ('Event \"{}\" not found. '\n             'Make sure you have a class called \"{}\" inside the \"{}\" '\n             'module.'.format(name, klass, module)))", "response": "Actually import the event represented by name Raises the EventNotFoundError if it s not possible to find the event class refered by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves handlers of a given event.", "response": "def cleanup_handlers(event=None):\n    \"\"\"Remove handlers of a given `event`. If no event is informed, wipe\n    out all events registered.\n\n    Be careful!! This function is intended to help when writing tests\n    and for debugging purposes. If you call it, all handlers associated\n    to an event (or to all of them) will be disassociated. Which means\n    that you'll have to reload all modules that teclare handlers. I'm\n    sure you don't want it.\n    \"\"\"\n    if event:\n        if event in HANDLER_REGISTRY:\n            del HANDLER_REGISTRY[event]\n        if event in EXTERNAL_HANDLER_REGISTRY:\n            del EXTERNAL_HANDLER_REGISTRY[event]\n    else:\n        HANDLER_REGISTRY.clear()\n        EXTERNAL_HANDLER_REGISTRY.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over the event handler registry and execute each found handler. It takes the event name and its its `data`, passing the return of `ejson.loads(data)` to the found handlers.", "response": "def process(event_name, data):\n    \"\"\"Iterates over the event handler registry and execute each found\n    handler.\n\n    It takes the event name and its its `data`, passing the return of\n    `ejson.loads(data)` to the found handlers.\n    \"\"\"\n    deserialized = loads(data)\n    event_cls = find_event(event_name)\n    event = event_cls(event_name, deserialized)\n    try:\n        event.clean()\n    except ValidationError as exc:\n        if os.environ.get('EVENTLIB_RAISE_ERRORS'):\n            raise\n        else:\n            logger.warning(\n                \"The event system just got an exception while cleaning \"\n                \"data for the event '{}'\\ndata: {}\\nexc: {}\".format(\n                    event_name, data, str(exc)))\n            return\n\n    for handler in find_handlers(event_name):\n        try:\n            handler(deserialized)\n        except Exception as exc:\n            logger.warning(\n                (u'One of the handlers for the event \"{}\" has failed with the '\n                 u'following exception: {}').format(event_name, str(exc)))\n            if getsetting('DEBUG'):\n                raise exc\n    event._broadcast()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_external(event_name, data):\n    for handler in find_external_handlers(event_name):\n        try:\n            handler(data)\n        except Exception as exc:\n            logger.warning(\n                (u'One of the handlers for the event \"{}\" has failed with the '\n                 u'following exception: {}').format(event_name, str(exc)))\n            if getsetting('DEBUG'):\n                raise exc", "response": "Execute all external handlers for the event with the given event name and data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all default values that an event should have", "response": "def get_default_values(data):\n    \"\"\"Return all default values that an event should have\"\"\"\n    request = data.get('request')\n    result = {}\n    result['__datetime__'] = datetime.now()\n    result['__ip_address__'] = request and get_ip(request) or '0.0.0.0'\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_data_values(data):\n    banned = ('request',)\n    return {key: val for key, val in data.items() if not key in banned}", "response": "Remove special values that log function can take\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting all events declared for all currently installed apps", "response": "def import_event_modules():\n    \"\"\"Import all events declared for all currently installed apps\n\n    This function walks through the list of installed apps and tries to\n    import a module named `EVENTS_MODULE_NAME`.\n    \"\"\"\n    for installed_app in getsetting('INSTALLED_APPS'):\n        module_name = u'{}.{}'.format(installed_app, EVENTS_MODULE_NAME)\n        try:\n            import_module(module_name)\n        except ImportError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the user has not activated their account and if they have not yet activated their account and sends an email to the user.", "response": "def handle_expired_accounts():\n    \"\"\"\n    Check of expired accounts.\n    \"\"\"\n    ACTIVATED = RegistrationProfile.ACTIVATED\n    expiration_date = datetime.timedelta(days=settings.ACCOUNT_ACTIVATION_DAYS)\n    \n    to_delete = []\n    print \"Processing %s registration profiles...\" % str(RegistrationProfile.objects.all().count())\n    for profile in RegistrationProfile.objects.all():\n        # if registration profile is expired, deactive user.\n        print \"Processing %s\" % profile.user\n        # If profile has been activated already, set it to be removed\n        # and move on to next registration profile\n        if profile.activation_key == ACTIVATED:\n            print \"Found Active\"\n            to_delete.append(profile.pk)\n            continue\n            \n        # If the user has not activated their account and the activation\n        # days have passed, deactivate the user and send an email to user.\n        if profile.user.is_active and profile.user.date_joined + expiration_date <= datetime.datetime.now():\n            print \"Found Expired\"\n            user = profile.user\n            user.is_active = False\n            \n            # Send an email notifing user of there account becoming inactive.\n            site = Site.objects.get_current()\n            ctx_dict = { 'site': site, \n                         'activation_key': profile.activation_key}\n                 \n            subject = render_to_string(\n                'registration/email/emails/account_expired_subject.txt',\n                ctx_dict)\n            subject = ''.join(subject.splitlines())\n    \n            message = render_to_string(\n                'registration/email/emails/account_expired.txt',\n                ctx_dict)\n            user.email_user(subject, message, settings.DEFAULT_FROM_EMAIL)\n            \n            # Only save the user instance after the email is sent.\n            user.save()\n            \n    # Delete the registration profiles that were set to be deleted, aka\n    # user has already activated their account.\n    print \"Deleting %s registration profiles.\" % str(len(to_delete))\n    RegistrationProfile.objects.filter(pk__in=to_delete).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nactivates the user with the given activation key.", "response": "def activate(self, request, activation_key):\n        \"\"\"\n        Override default activation process. This will activate the user\n        even if its passed its expiration date.\n        \"\"\"  \n        if SHA1_RE.search(activation_key):\n            try:\n                profile = RegistrationProfile.objects.get(activation_key=activation_key)\n            except RegistrationProfile.DoesNotExist:\n                return False\n                \n            user = profile.user\n            user.is_active = True\n            user.save()\n            profile.activation_key = RegistrationProfile.ACTIVATED\n            profile.save()\n            return user\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and immediately log in a new user.", "response": "def register(self, request, **kwargs):\n        \"\"\"\n        Create and immediately log in a new user.\n        \n        Only require a  email to register, username is generated\n        automatically and a password is random generated and emailed\n        to the user.\n        \n        Activation is still required for account uses after specified number\n        of days.\n        \"\"\"\n        if Site._meta.installed:\n            site = Site.objects.get_current()\n        else:\n            site = RequestSite(request)\n        \n        email = kwargs['email']\n        \n        # Generate random password\n        password = User.objects.make_random_password()\n        \n        # Generate username based off of the email supplied\n        username = sha_constructor(str(email)).hexdigest()[:30]\n        \n        incr = 0\n        # Ensure the generated username is in fact unqiue\n        while User.objects.filter(username=username).count() > 0:\n            incr += 1\n            username = sha_constructor(str(email + str(incr))).hexdigest()[:30]\n        # Create the active user\n        new_user = User.objects.create_user(username, email, password)\n        new_user.save()\n        \n        # Create the registration profile, this is still needed because\n        # the user still needs to activate there account for further users\n        # after 3 days\n        registration_profile = RegistrationProfile.objects.create_profile(\n            new_user)\n        \n        # Authenticate and login the new user automatically\n        auth_user = authenticate(username=username, password=password)\n        login(request, auth_user)\n        \n        # Set the expiration to when the users browser closes so user\n        # is forced to log in upon next visit, this should force the user\n        # to check there email for there generated password.\n        request.session.set_expiry(0)\n        \n        # Create a profile instance for the new user if \n        # AUTH_PROFILE_MODULE is specified in settings\n        if hasattr(settings, 'AUTH_PROFILE_MODULE') and getattr(settings, 'AUTH_PROFILE_MODULE'):\n            app_label, model_name = settings.AUTH_PROFILE_MODULE.split('.')\n            model = models.get_model(app_label, model_name)\n            try:\n                profile = new_user.get_profile()\n            except model.DoesNotExist:\n                profile = model(user=new_user)\n                profile.save()   \n                \n        # Custom send activation email\n        self.send_activation_email(\n            new_user, registration_profile, password, site)  \n        \n        # Send user_registered signal\n        signals.user_registered.send(sender=self.__class__,\n                                     user=new_user,\n                                     request=request)\n        return new_user"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_registration_redirect(self, request, user):\n        next_url = \"/registration/register/complete/\"\n        if \"next\" in request.GET or \"next\" in request.POST:\n            next_url = request.GET.get(\"next\", None) or request.POST.get(\"next\", None) or \"/\"\n            \n        return (next_url, (), {})", "response": "After registration redirect to the home page or supplied next query string or hidden field value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next(self):\n        if self.start + self.size > self.total_size:\n            result = None\n        else:\n            result = Batch(self.start + self.size, self.size, self.total_size)\n        return result", "response": "Returns the next batch for the batched sequence or None if there are no more elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the previous batch for the batched sequence or None if there is no previous batch.", "response": "def previous(self):\n        \"\"\"\n        Returns the previous batch for the batched sequence or `None`, if\n        this batch is already the first batch.\n\n        :rtype: :class:`Batch` instance or `None`.\n        \"\"\"\n        if self.start - self.size < 0:\n            result = None\n        else:\n            result = Batch(self.start - self.size, self.size, self.total_size)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the last batch for the batched sequence.", "response": "def last(self):\n        \"\"\"\n        Returns the last batch for the batched sequence.\n\n        :rtype: :class:`Batch` instance.\n        \"\"\"\n        start = max(self.number - 1, 0) * self.size\n        return Batch(start, self.size, self.total_size)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of batches in the current batched sequence.", "response": "def number(self):\n        \"\"\"\n        Returns the number of batches the batched sequence contains.\n\n        :rtype: integer.\n        \"\"\"\n        return int(math.ceil(self.total_size / float(self.size)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef watermark(url, args=''):\n    # initialize some variables\n    args = args.split(',')\n\n    params = dict(\n        name=args.pop(0),\n        opacity=0.5,\n        tile=False,\n        scale=1.0,\n        greyscale=False,\n        rotation=0,\n        position=None,\n        quality=QUALITY,\n        obscure=OBSCURE_ORIGINAL,\n        random_position_once=RANDOM_POSITION_ONCE,\n    )\n\n    params['url'] = unquote(url)\n\n    # iterate over all parameters to see what we need to do\n    for arg in args:\n        key, value = arg.split('=')\n        key, value = key.strip(), value.strip()\n        if key == 'position':\n            params['position'] = value\n        elif key == 'opacity':\n            params['opacity'] = utils._percent(value)\n        elif key == 'tile':\n            params['tile'] = bool(int(value))\n        elif key == 'scale':\n            params['scale'] = value\n        elif key == 'greyscale':\n            params['greyscale'] = bool(int(value))\n        elif key == 'rotation':\n            params['rotation'] = value\n        elif key == 'quality':\n            params['quality'] = int(value)\n        elif key == 'obscure':\n            params['obscure'] = bool(int(value))\n        elif key == 'random_position_once':\n            params['random_position_once'] = bool(int(value))\n\n    return Watermarker()(**params)", "response": "Returns the URL to a watermarked copy of the image specified."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_filesystem_path(self, url_path, basedir=settings.MEDIA_ROOT):\n\n        if url_path.startswith(settings.MEDIA_URL):\n            url_path = url_path[len(settings.MEDIA_URL):]  # strip media root url\n\n        return os.path.normpath(os.path.join(basedir, url2pathname(url_path)))", "response": "Makes a filesystem path from the specified URL path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_filename(self, mark, **kwargs):\n\n        kwargs = kwargs.copy()\n\n        kwargs['opacity'] = int(kwargs['opacity'] * 100)\n        kwargs['st_mtime'] = kwargs['fstat'].st_mtime\n        kwargs['st_size'] = kwargs['fstat'].st_size\n\n        params = [\n            '%(original_basename)s',\n            'wm',\n            'w%(watermark)i',\n            'o%(opacity)i',\n            'gs%(greyscale)i',\n            'r%(rotation)i',\n            'fm%(st_mtime)i',\n            'fz%(st_size)i',\n            'p%(position)s',\n        ]\n\n        scale = kwargs.get('scale', None)\n        if scale and scale != mark.size:\n            params.append('_s%i' % (float(kwargs['scale'][0]) / mark.size[0] * 100))\n\n        if kwargs.get('tile', None):\n            params.append('_tiled')\n\n        # make thumbnail filename\n        filename = '%s%s' % ('_'.join(params), kwargs['ext'])\n\n        return filename % kwargs", "response": "Generates a filename for the watermarked image"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url_path(self, basedir, original_basename, ext, name, obscure=True):\n\n        try:\n            hash = hashlib.sha1(smart_str(name)).hexdigest()\n        except TypeError:\n            hash = hashlib.sha1(smart_str(name).encode('utf-8')).hexdigest()\n\n        # figure out where the watermark would be saved on the filesystem\n        if obscure is True:\n            logger.debug('Obscuring original image name: %s => %s' % (name, hash))\n            url_path = os.path.join(basedir, hash + ext)\n        else:\n            logger.debug('Not obscuring original image name.')\n            url_path = os.path.join(basedir, hash, original_basename + ext)\n\n        # make sure the destination directory exists\n        try:\n            fpath = self._get_filesystem_path(url_path)\n            os.makedirs(os.path.dirname(fpath))\n        except OSError as e:\n            if e.errno == errno.EEXIST:\n                pass  # not to worry, directory exists\n            else:\n                logger.error('Error creating path: %s' % traceback.format_exc())\n                raise\n        else:\n            logger.debug('Created directory: %s' % os.path.dirname(fpath))\n\n        return url_path", "response": "Determines an appropriate watermark path based on the original image name and extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_watermark(self, target, mark, fpath, quality=QUALITY, **kwargs):\n\n        im = utils.watermark(target, mark, **kwargs)\n        im.save(fpath, quality=quality)\n        return im", "response": "Create the watermarked image on the filesystem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _val(var, is_percent=False):\n    try:\n        if is_percent:\n            var = float(int(var.strip('%')) / 100.0)\n        else:\n            var = int(var)\n    except ValueError:\n        raise ValueError('invalid watermark parameter: ' + var)\n    return var", "response": "Helper function to determine the appropriate value of a particular variable that is\n    passed in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reduce_opacity(img, opacity):\n    assert opacity >= 0 and opacity <= 1\n\n    if img.mode != 'RGBA':\n        img = img.convert('RGBA')\n    else:\n        img = img.copy()\n\n    alpha = img.split()[3]\n    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)\n    img.putalpha(alpha)\n\n    return img", "response": "Returns an image with reduced opacity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscaling an image using a specified ratio F or R. Returns the new mark.", "response": "def determine_scale(scale, img, mark):\n    \"\"\"\n    Scales an image using a specified ratio, 'F' or 'R'. If `scale` is\n    'F', the image is scaled to be as big as possible to fit in `img`\n    without falling off the edges.  If `scale` is 'R', the watermark\n    resizes to a percentage of minimum size of source image.  Returns\n    the scaled `mark`.\n\n    \"\"\"\n    if scale:\n        try:\n            scale = float(scale)\n        except (ValueError, TypeError):\n            pass\n\n        if isinstance(scale, six.string_types) and scale.upper() == 'F':\n            # scale watermark to full, but preserve the aspect ratio\n            scale = min(\n                float(img.size[0]) / mark.size[0],\n                float(img.size[1]) / mark.size[1]\n            )\n        elif isinstance(scale, six.string_types) and scale.upper() == 'R':\n            # scale watermark to % of source image and preserve the aspect ratio\n            scale = min(\n                float(img.size[0]) / mark.size[0],\n                float(img.size[1]) / mark.size[1]\n            ) / 100 * settings.WATERMARK_PERCENTAGE\n        elif type(scale) not in (float, int):\n            raise ValueError('Invalid scale value \"%s\"! Valid values are \"F\" '\n                             'for ratio-preserving scaling, \"R%%\" for percantage aspect '\n                             'ratio of source image and floating-point numbers and '\n                             'integers greater than 0.' % scale)\n\n        # determine the new width and height\n        w = int(mark.size[0] * float(scale))\n        h = int(mark.size[1] * float(scale))\n\n        # apply the new width and height, and return the new `mark`\n        return (w, h)\n    else:\n        return mark.size"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_rotation(rotation, mark):\n    if isinstance(rotation, six.string_types) and rotation.lower() == 'r':\n        rotation = random.randint(0, 359)\n    else:\n        rotation = _int(rotation)\n\n    return rotation", "response": "Determines the number of degrees to rotate the watermark image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef determine_position(position, img, mark):\n    left = top = 0\n\n    max_left = max(img.size[0] - mark.size[0], 0)\n    max_top = max(img.size[1] - mark.size[1], 0)\n\n    #Added a 10px margin from corners to apply watermark.\n    margin = 10\n\n    if not position:\n        position = 'r'\n\n    if isinstance(position, tuple):\n        left, top = position\n    elif isinstance(position, six.string_types):\n        position = position.lower()\n\n        # corner positioning\n        if position in ['tl', 'tr', 'br', 'bl']:\n            if 't' in position:\n                top = margin\n            elif 'b' in position:\n                top = max_top - margin\n            if 'l' in position:\n                left = margin\n            elif 'r' in position:\n                left = max_left - margin\n\n        # center positioning\n        elif position == 'c':\n            left = int(max_left / 2)\n            top = int(max_top / 2)\n\n        # random positioning\n        elif position == 'r':\n            left = random.randint(0, max_left)\n            top = random.randint(0, max_top)\n\n        # relative or absolute positioning\n        elif 'x' in position:\n            left, top = position.split('x')\n\n            if '%' in left:\n                left = max_left * _percent(left)\n            else:\n                left = _int(left)\n\n            if '%' in top:\n                top = max_top * _percent(top)\n            else:\n                top = _int(top)\n\n    return int(left), int(top)", "response": "Determine the position of the image in the available mark."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef watermark(img, mark, position=(0, 0), opacity=1, scale=1.0, tile=False,\n              greyscale=False, rotation=0, return_name=False, **kwargs):\n    \"\"\"Adds a watermark to an image\"\"\"\n\n    if opacity < 1:\n        mark = reduce_opacity(mark, opacity)\n\n    if not isinstance(scale, tuple):\n        scale = determine_scale(scale, img, mark)\n\n    mark = mark.resize(scale, resample=Image.ANTIALIAS)\n\n    if greyscale and mark.mode != 'LA':\n        mark = mark.convert('LA')\n\n    rotation = determine_rotation(rotation, mark)\n    if rotation != 0:\n        # give some leeway for rotation overlapping\n        new_w = int(mark.size[0] * 1.5)\n        new_h = int(mark.size[1] * 1.5)\n\n        new_mark = Image.new('RGBA', (new_w, new_h), (0,0,0,0))\n\n        # center the watermark in the newly resized image\n        new_l = int((new_w - mark.size[0]) / 2)\n        new_t = int((new_h - mark.size[1]) / 2)\n        new_mark.paste(mark, (new_l, new_t))\n\n        mark = new_mark.rotate(rotation)\n\n    position = determine_position(position, img, mark)\n\n    if img.mode != 'RGBA':\n        img = img.convert('RGBA')\n\n    # make sure we have a tuple for a position now\n    assert isinstance(position, tuple), 'Invalid position \"%s\"!' % position\n\n    # create a transparent layer the size of the image and draw the\n    # watermark in that layer.\n    layer = Image.new('RGBA', img.size, (0,0,0,0))\n    if tile:\n        first_y = int(position[1] % mark.size[1] - mark.size[1])\n        first_x = int(position[0] % mark.size[0] - mark.size[0])\n\n        for y in range(first_y, img.size[1], mark.size[1]):\n            for x in range(first_x, img.size[0], mark.size[0]):\n                layer.paste(mark, (x, y))\n    else:\n        layer.paste(mark, position)\n\n    # composite the watermark with the layer\n    return Image.composite(layer, img, layer)", "response": "Adds a watermark to an image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an ini - style config file.", "response": "def parsed_file(config_file):\n    \"\"\"Parse an ini-style config file.\"\"\"\n    parser = ConfigParser(allow_no_value=True)\n    parser.readfp(config_file)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commands(config, names):\n    commands = {cmd: Command(**dict((minus_to_underscore(k), v)\n                                    for k, v in config.items(cmd)))\n                for cmd in config.sections()\n                if cmd != 'packages'}\n    try:\n        return tuple(commands[x] for x in names)\n    except KeyError as e:\n        raise RuntimeError(\n            'Section [commands] in the config file does not contain the '\n            'key {.args[0]!r} you requested to execute.'.format(e))", "response": "Return the list of commands to run."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef project_path(*names):\n    return os.path.join(os.path.dirname(__file__), *names)", "response": "Return the path to a file in the project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_osa_commit(repo, ref, rpc_product=None):\n    osa_differ.checkout(repo, ref)\n\n    functions_path = os.path.join(repo.working_tree_dir,\n                                  'scripts/functions.sh')\n    release_path = os.path.join(repo.working_tree_dir,\n                                'playbooks/vars/rpc-release.yml')\n\n    if os.path.exists(release_path):\n        with open(release_path) as f:\n            rpc_release_data = yaml.safe_load(f.read())\n\n        rpc_product_releases = rpc_release_data['rpc_product_releases']\n        release_data = rpc_product_releases[rpc_product]\n\n        return release_data['osa_release']\n\n    elif repo.submodules['openstack-ansible']:\n        return repo.submodules['openstack-ansible'].hexsha\n\n    elif os.path.exists(functions_path):\n        # This branch doesn't use a submodule for OSA\n        # Pull the SHA out of functions.sh\n        quoted_re = re.compile('OSA_RELEASE:-?\"?([^\"}]+)[\"}]')\n        with open(functions_path, \"r\") as funcs:\n            for line in funcs.readlines():\n                match = quoted_re.search(line)\n                if match:\n                    return match.groups()[0]\n            else:\n                raise SHANotFound(\n                    (\"Cannot find OSA SHA in submodule or \"\n                     \"script: {}\".format(functions_path)))\n\n    else:\n        raise SHANotFound('No OSA SHA was able to be derived.')", "response": "Get the OSA sha referenced by an RPCO Repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_rpc_sha(repo_dir, commit):\n\n    # Is the commit valid? Just in case the commit is a\n    # PR ref, we try both the ref given and the ref prepended\n    # with the remote 'origin'.\n    try:\n        osa_differ.validate_commits(repo_dir, [commit])\n    except exceptions.InvalidCommitException:\n        log.debug(\"The reference {c} cannot be found. Prepending \"\n                  \"origin remote and retrying.\".format(c=commit))\n        commit = 'origin/' + commit\n        osa_differ.validate_commits(repo_dir, [commit])\n\n    return commit", "response": "Validate a SHA given for the rpc - openstack repo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a report header for OpenStack - Ansible.", "response": "def make_rpc_report(repo_dir, old_commit, new_commit,\n                    args):\n    \"\"\"Create initial RST report header for OpenStack-Ansible.\"\"\"\n\n    # Do we have a valid commit range?\n    # NOTE:\n    # An exception is thrown by osa_differ if these two commits\n    # are the the same, but it is sometimes necessary to compare\n    # two RPC tags that have the same OSA SHA. For example,\n    # comparing two tags that only have differences between the\n    # two RPCO commit, but no differences between the OSA SHAs\n    # that correspond to those two commits.\n    # To handle this case, the exception will be caught and flow\n    # of execution will continue normally.\n    try:\n        osa_differ.validate_commit_range(repo_dir, old_commit, new_commit)\n    except exceptions.InvalidCommitRangeException:\n        pass\n\n    # Get the commits in the range\n    commits = osa_differ.get_commits(repo_dir, old_commit, new_commit)\n\n    # Start off our report with a header and our OpenStack-Ansible commits.\n    template_vars = {\n        'args': args,\n        'repo': 'rpc-openstack',\n        'commits': commits,\n        'commit_base_url': osa_differ.get_commit_url(args.rpc_repo_url),\n        'old_sha': old_commit,\n        'new_sha': new_commit\n    }\n    return render_template('offline-header.j2', template_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publish_report(report, args, old_commit, new_commit):\n    # Print the report to stdout unless the user specified --quiet.\n    output = \"\"\n\n    if not args.quiet and not args.gist and not args.file:\n        return report\n\n    if args.gist:\n        gist_url = post_gist(report, old_commit, new_commit)\n        output += \"\\nReport posted to GitHub Gist: {0}\".format(gist_url)\n\n    if args.file is not None:\n        with open(args.file, 'w') as f:\n            f.write(report.encode('utf-8'))\n        output += \"\\nReport written to file: {0}\".format(args.file)\n\n    return output", "response": "Publish the RST report based on the user request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(raw_args=None):\n    parser = argparse.ArgumentParser(\n        description=\"poor man's integration testing\")\n    parser.add_argument(\n        'cmds', metavar='cmd', default=['test'], nargs='*',\n        help='Run command(s) defined in the configuration file. Each command '\n             'is run on each package before proceeding with the next command. '\n             '(default: \"test\")')\n    parser.add_argument(\n        '-c', '--config', dest='file', type=argparse.FileType('r'),\n        default='toll.ini',\n        help='ini-style file to read the configuration from')\n    parser.add_argument(\n        '--start-at', dest='start_at', type=str, default='',\n        help='Skip over the packages in the config file listed before this'\n             ' one. (It does a substring match to find the first package.)')\n\n    args = parser.parse_args(raw_args)\n    config_file = config.parsed_file(args.file)\n    commands = config.commands(config_file, args.cmds)\n    packages = config.packages(config_file)\n    runner = Runner(commands, packages, start_at=args.start_at)\n    return runner()", "response": "Console script entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a list from the site.", "response": "def remove(self, list):\n        \"\"\"\n        Removes a list from the site.\n        \"\"\"\n        xml = SP.DeleteList(SP.listName(list.id))\n        self.opener.post_soap(LIST_WEBSERVICE, xml,\n                              soapaction='http://schemas.microsoft.com/sharepoint/soap/DeleteList')\n        self.all_lists.remove(list)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new list in the site.", "response": "def create(self, name, description='', template=100):\n        \"\"\"\n        Creates a new list in the site.\n        \"\"\"\n        try:\n            template = int(template)\n        except ValueError:\n            template = LIST_TEMPLATES[template]\n        if name in self:\n            raise ValueError(\"List already exists: '{0}\".format(name))\n        if uuid_re.match(name):\n            raise ValueError(\"Cannot create a list with a UUID as a name\")\n        xml = SP.AddList(SP.listName(name),\n                         SP.description(description),\n                         SP.templateID(text_type(template)))\n        result = self.opener.post_soap(LIST_WEBSERVICE, xml,\n                                       soapaction='http://schemas.microsoft.com/sharepoint/soap/AddList')\n        list_element = result.xpath('sp:AddListResult/sp:List', namespaces=namespaces)[0]\n        self._all_lists.append(SharePointList(self.opener, self, list_element))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Row(self):\n        if not hasattr(self, '_row_class'):\n            attrs = {'fields': self.fields, 'list': self, 'opener': self.opener}\n            for field in self.fields.values():\n                attrs[field.name] = field.descriptor\n            self._row_class = type('SharePointListRow', (SharePointListRow,), attrs)\n        return self._row_class", "response": "Returns the class for a row in this list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a row to the list. Takes a dictionary returns a row.", "response": "def append(self, row):\n        \"\"\"\n        Appends a row to the list. Takes a dictionary, returns a row.\n        \"\"\"\n        if isinstance(row, dict):\n            row = self.Row(row)\n        elif isinstance(row, self.Row):\n            pass\n        elif isinstance(row, SharePointListRow):\n            raise TypeError(\"row must be a dict or an instance of SharePointList.Row, not SharePointListRow\")\n        else:\n            raise TypeError(\"row must be a dict or an instance of SharePointList.Row\")\n        self.rows  # Make sure self._rows exists.\n        self._rows.append(row)\n        return row"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, row):\n        self._rows.remove(row)\n        self._deleted_rows.add(row)", "response": "Removes the row from the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the list with changes.", "response": "def save(self):\n        \"\"\"\n        Updates the list with changes.\n        \"\"\"\n        # Based on the documentation at\n        # http://msdn.microsoft.com/en-us/library/lists.lists.updatelistitems%28v=office.12%29.aspx\n\n        # Note, this ends up un-namespaced. SharePoint doesn't care about\n        # namespaces on this XML node, and will bork if any of these elements\n        # have a namespace prefix. Likewise Method and Field in\n        # SharePointRow.get_batch_method().\n        batches = E.Batch(ListVersion='1', OnError='Return')\n        # Here's the root element of our SOAP request.\n        xml = SP.UpdateListItems(SP.listName(self.id), SP.updates(batches))\n\n        # rows_by_batch_id contains a mapping from new rows to their batch\n        # IDs, so we can set their IDs when they are returned by SharePoint.\n        rows_by_batch_id, batch_id = {}, 1\n\n        for row in self._rows:\n            batch = row.get_batch_method()\n            if batch is None:\n                continue\n            # Add the batch ID\n            batch.attrib['ID'] = text_type(batch_id)\n            rows_by_batch_id[batch_id] = row\n            batches.append(batch)\n            batch_id += 1\n\n        for row in self._deleted_rows:\n            batch = E.Method(E.Field(text_type(row.id),\n                                     Name='ID'),\n                             ID=text_type(batch_id), Cmd='Delete')\n            rows_by_batch_id[batch_id] = row\n            batches.append(batch)\n            batch_id += 1\n\n        if len(batches) == 0:\n            return\n\n        response = self.opener.post_soap(LIST_WEBSERVICE, xml,\n                                         soapaction='http://schemas.microsoft.com/sharepoint/soap/UpdateListItems')\n\n        for result in response.xpath('.//sp:Result', namespaces=namespaces):\n            batch_id, batch_result = result.attrib['ID'].split(',')\n            row = rows_by_batch_id[int(batch_id)]\n\n            error_code = result.find('sp:ErrorCode', namespaces=namespaces)\n            error_text = result.find('sp:ErrorText', namespaces=namespaces)\n            if error_code is not None and error_code.text != '0x00000000':\n                raise UpdateFailedError(row, batch_result,\n                                        error_code.text,\n                                        error_text.text)\n\n            if batch_result in ('Update', 'New'):\n                row._update(result.xpath('z:row', namespaces=namespaces)[0],\n                            clear=True)\n            else:\n                self._deleted_rows.remove(row)\n\n        assert not self._deleted_rows\n        assert not any(row._changed for row in self.rows)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_batch_method(self):\n        if not self._changed:\n            return None\n\n        batch_method = E.Method(Cmd='Update' if self.id else 'New')\n        batch_method.append(E.Field(text_type(self.id) if self.id else 'New',\n                                    Name='ID'))\n        for field in self.fields.values():\n            if field.name in self._changed:\n                value = field.unparse(self._data[field.name] or '')\n                batch_method.append(E.Field(value, Name=field.name))\n        return batch_method", "response": "Returns a change batch for SharePoint s UpdateListItems operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_to_python(self, xmlrpc=None):\r\n        if xmlrpc:\r\n            return xmlrpc.get(self.name, self.default)\r\n        elif self.default:\r\n            return self.default\r\n        else:\r\n            return None", "response": "Converts the field name to a python value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a set of outputs for a given input value.", "response": "def get_outputs(self, input_value):\r\n        \"\"\"\r\n        Generate a set of output values for a given input.\r\n        \"\"\"\r\n        output_value = self.convert_to_xmlrpc(input_value)\r\n\r\n        output = {}\r\n        for name in self.output_names:\r\n            output[name] = output_value\r\n\r\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of the current object state", "response": "def struct(self):\r\n        \"\"\"\r\n        XML-RPC-friendly representation of the current object state\r\n        \"\"\"\r\n        data = {}\r\n        for var, fmap in self._def.items():\r\n            if hasattr(self, var):\r\n                data.update(fmap.get_outputs(getattr(self, var)))\r\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_args(self, client):\r\n        default_args = self.default_args(client)\r\n\r\n        if self.method_args or self.optional_args:\r\n            optional_args = getattr(self, 'optional_args', tuple())\r\n            args = []\r\n            for arg in (self.method_args + optional_args):\r\n                if hasattr(self, arg):\r\n                    obj = getattr(self, arg)\r\n                    if hasattr(obj, 'struct'):\r\n                        args.append(obj.struct)\r\n                    else:\r\n                        args.append(obj)\r\n            args = list(default_args) + args\r\n        else:\r\n            args = default_args\r\n\r\n        return args", "response": "Builds final set of arguments based on the method s arguments any default arguments and their\r\n        defined respective ordering."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new result object with the most recent version of the fields in the raw_result.", "response": "def process_result(self, raw_result):\r\n        \"\"\"\r\n        Performs actions on the raw result from the XML-RPC response.\r\n\r\n        If a `results_class` is defined, the response will be converted\r\n        into one or more object instances of that class.\r\n        \"\"\"\r\n        if self.results_class and raw_result:\r\n            if isinstance(raw_result, dict_type):\r\n                return self.results_class(raw_result)\r\n            elif isinstance(raw_result, collections.Iterable):\r\n                return [self.results_class(result) for result in raw_result]\r\n\r\n        return raw_result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, text):\n        '''Returns a list of addresses found in text\n        together with parsed address parts\n        '''\n        results = []\n        if isinstance(text, str):\n            if six.PY2:\n                text = unicode(text, 'utf-8')\n        self.clean_text = self._normalize_string(text)\n\n        # get addresses\n        addresses = set(self._get_addresses(self.clean_text))\n        if addresses:\n            # append parsed address info\n            results = list(map(self._parse_address, addresses))\n\n        return results", "response": "Returns a list of addresses found in text\n        together with parsed address parts\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_address(self, address_string):\n        '''Parses address into parts'''\n        match = utils.match(self.rules, address_string, flags=re.VERBOSE | re.U)\n        if match:\n            match_as_dict = match.groupdict()\n            match_as_dict.update({'country_id': self.country})\n            # combine results\n            cleaned_dict = self._combine_results(match_as_dict)\n            # create object containing results\n            return address.Address(**cleaned_dict)\n\n        return False", "response": "Parses an address into parts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncombining results from different parsed parts and store them as main value.", "response": "def _combine_results(self, match_as_dict):\n            '''Combine results from different parsed parts:\n            we look for non-empty results in values like\n            'postal_code_b' or 'postal_code_c' and store\n            them as main value.\n\n            So 'postal_code_b':'123456'\n                becomes:\n               'postal_code'  :'123456'\n            '''\n            keys = []\n            vals = []\n            for k, v in six.iteritems(match_as_dict):\n                if k[-2:] in '_a_b_c_d_e_f_g_h_i_j_k_l_m':\n                    if v:\n                        # strip last 2 chars: '..._b' -> '...'\n                        keys.append(k[:-2])\n                        vals.append(v)\n                else:\n                    if k not in keys:\n                        keys.append(k)\n                        vals.append(v)\n            return dict(zip(keys, vals))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_addresses(self, text):\n        '''Returns a list of addresses found in text'''\n        # find addresses\n        addresses = []\n        matches = utils.findall(\n            self.rules,\n            text,\n            flags=re.VERBOSE | re.U)\n\n        if(matches):\n            for match in matches:\n                addresses.append(match[0].strip())\n        return addresses", "response": "Returns a list of addresses found in text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(some_text, **kwargs):\n    ap = parser.AddressParser(**kwargs)\n    return ap.parse(some_text)", "response": "Creates request to AddressParser\n    and returns list of Address objects"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deepSetAttr(obj, path, val):\n    first, _, rest = path.rpartition('.')\n    return setattr(deepGetAttr(obj, first) if first else obj, rest, val)", "response": "Sets a deep attribute on an object by resolving a dot - delimited path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a value into a list of XML attributes.", "response": "def encodeValue(value):\n    \"\"\"\n    TODO\n    \"\"\"\n    if isinstance(value, (list, tuple)):\n        return [common.AttributeValue(string_value=str(v)) for v in value]\n    else:\n        return [common.AttributeValue(string_value=str(value))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a datetime object into its appropriate protocol value.", "response": "def convertDatetime(t):\n    \"\"\"\n    Converts the specified datetime object into its appropriate protocol\n    value. This is the number of milliseconds from the epoch.\n    \"\"\"\n    epoch = datetime.datetime.utcfromtimestamp(0)\n    delta = t - epoch\n    millis = delta.total_seconds() * 1000\n    return int(millis)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getValueFromValue(value):\n    if type(value) != common.AttributeValue:\n        raise TypeError(\n            \"Expected an AttributeValue, but got {}\".format(type(value)))\n    if value.WhichOneof(\"value\") is None:\n        raise AttributeError(\"Nothing set for {}\".format(value))\n    return getattr(value, value.WhichOneof(\"value\"))", "response": "Extract the currently set field from a Value structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserialising a protobuf object as json", "response": "def toJson(protoObject, indent=None):\n    \"\"\"\n    Serialises a protobuf object as json\n    \"\"\"\n    # Using the internal method because this way we can reformat the JSON\n    js = json_format.MessageToDict(protoObject, False)\n    return json.dumps(js, indent=indent)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the protocol classes that are subclasses of the specified superclass. Only leaf classes are returned.", "response": "def getProtocolClasses(superclass=message.Message):\n    \"\"\"\n    Returns all the protocol classes that are subclasses of the\n    specified superclass. Only 'leaf' classes are returned,\n    corresponding directly to the classes defined in the protocol.\n    \"\"\"\n    # We keep a manual list of the superclasses that we define here\n    # so we can filter them out when we're getting the protocol\n    # classes.\n    superclasses = set([message.Message])\n    thisModule = sys.modules[__name__]\n    subclasses = []\n    for name, class_ in inspect.getmembers(thisModule):\n        if ((inspect.isclass(class_) and\n                issubclass(class_, superclass) and\n                class_ not in superclasses)):\n            subclasses.append(class_)\n    return subclasses"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a shell command given the command line", "response": "def runCommandSplits(splits, silent=False, shell=False):\n    \"\"\"\n    Run a shell command given the command's parsed command line\n    \"\"\"\n    try:\n        if silent:\n            with open(os.devnull, 'w') as devnull:\n                subprocess.check_call(\n                    splits, stdout=devnull, stderr=devnull, shell=shell)\n        else:\n            subprocess.check_call(splits, shell=shell)\n    except OSError as exception:\n        if exception.errno == 2:  # cmd not found\n            raise Exception(\n                \"Can't find command while trying to run {}\".format(splits))\n        else:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a shell command", "response": "def runCommand(command, silent=False, shell=False):\n    \"\"\"\n    Run a shell command\n    \"\"\"\n    splits = shlex.split(command)\n    runCommandSplits(splits, silent=silent, shell=shell)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a line of a proto file replace the line with one that is appropriate for the hierarchy that we want to compile.", "response": "def _doLineReplacements(self, line):\n        \"\"\"\n        Given a line of a proto file, replace the line with one that is\n        appropriate for the hierarchy that we want to compile\n        \"\"\"\n        # ga4gh packages\n        packageString = 'package ga4gh;'\n        if packageString in line:\n            return line.replace(\n                packageString,\n                'package ga4gh.schemas.ga4gh;')\n        importString = 'import \"ga4gh/'\n        if importString in line:\n            return line.replace(\n                importString,\n                'import \"ga4gh/schemas/ga4gh/')\n        # google packages\n        googlePackageString = 'package google.api;'\n        if googlePackageString in line:\n            return line.replace(\n                googlePackageString,\n                'package ga4gh.schemas.google.api;')\n        googleImportString = 'import \"google/api/'\n        if googleImportString in line:\n            return line.replace(\n                googleImportString,\n                'import \"ga4gh/schemas/google/api/')\n        optionString = 'option (google.api.http)'\n        if optionString in line:\n            return line.replace(\n                optionString,\n                'option (.ga4gh.schemas.google.api.http)')\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _copySchemaFile(self, src, dst):\n        with open(src) as srcFile, open(dst, 'w') as dstFile:\n            srcLines = srcFile.readlines()\n            for srcLine in srcLines:\n                toWrite = self._doLineReplacements(srcLine)\n                dstFile.write(toWrite)", "response": "Copy a proto file to the temporary directory with appropriate\n            line replacements\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_protodef_to_editable(proto):\n    class Editable(object):\n        def __init__(self, prot):\n            self.kind = type(prot)\n            self.name = prot.name\n            self.comment = \"\"\n            self.options = dict([(key.name, value) for (key, value) in prot.options.ListFields()])\n            if isinstance(prot, EnumDescriptorProto):\n                self.value = [convert_protodef_to_editable(x) for x in prot.value]\n            elif isinstance(prot, DescriptorProto):\n                self.field = [convert_protodef_to_editable(x) for x in prot.field]\n                self.enum_type = [convert_protodef_to_editable(x) for x in prot.enum_type]\n                self.nested_type = prot.nested_type\n                self.oneof_decl = prot.oneof_decl\n            elif isinstance(prot, EnumValueDescriptorProto):\n                self.number = prot.number\n            elif isinstance(prot, FieldDescriptorProto):\n                if prot.type in [11, 14]:\n                    self.ref_type = prot.type_name[1:]\n                self.type = prot.type\n                self.label = prot.label\n            elif isinstance(prot, ServiceDescriptorProto):\n                self.method = [convert_protodef_to_editable(x) for x in prot.method]\n            elif isinstance(prot, MethodDescriptorProto):\n                self.input_type = prot.input_type\n                self.output_type = prot.output_type\n            else:\n                raise Exception, type(prot)\n\n    return Editable(proto)", "response": "Convert a ProtoBuf object to an Editable object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a FieldDescriptorProto to a pretty name based on numbers from FieldDescriptorProto https://developers. google. com / protocol - buffers / docs / reference / cpp / google. protobuf. descriptor. pb", "response": "def type_to_string(f, map_types):\n    \"\"\"\n    Convert type info to pretty names, based on numbers from from FieldDescriptorProto\n    https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.descriptor.pb\n    \"\"\"\n    if f.type in [1]:\n        return \"double\"\n    elif f.type in [2]:\n        return \"float\"\n    elif f.type in [3]:\n        return \"long\"\n    elif f.type in [4]:\n        return \"uint64\"\n    elif f.type in [5]:\n        return \"integer\"\n    elif f.type in [6]:\n        return \"fixed64\"\n    elif f.type in [7]:\n        return \"fixed32\"\n    elif f.type in [8]:\n        return \"boolean\"\n    elif f.type in [9]:\n        return \"string\"\n    # missing type 10 - Group\n    elif f.type in [11, 14]:\n        ref_name = f.ref_type\n        if ref_name in map_types:\n            ref_fields = map_types[ref_name]\n            return {\n                \"type\": \"map\",\n                \"key\": \" %s \"% type_to_string(ref_fields[\"key\"], map_types),\n                \"value\": \" %s \"% type_to_string(ref_fields[\"value\"], map_types)\n            }\n        else:\n            kind = \":protobuf:message:`%s`\" % simplify_name(f.ref_type)\n            if f.label == 3: # LABEL_REPEATED\n                return \"list of \" + kind\n            else:\n                return kind\n    elif f.type in [12]:\n        return \"bytes\"\n    elif f.type in [13]:\n        return \"uint32\"\n    elif f.type in [15]:\n        return \"sfixed32\"\n    elif f.type in [16]:\n        return \"sfixed64\"\n    elif f.type in [17]:\n        return \"sint32\"\n    elif f.type in [18]:\n        return \"sint64\"\n    else:\n        raise Exception, f.type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_code(request, response):\n    for proto_file in request.proto_file:\n        types = []\n        messages = {}\n\n        results = traverse(proto_file)\n        map_types = {}\n        def full_name(package, item):\n            return \"%s.%s\" % (package, item.name)\n        for item, package in results[\"types\"]:\n            if item.options.has_key(\"map_entry\"):\n                map_types[full_name(package, item)] = dict([(x.name,x) for x in item.field])\n        for item, package in results[\"types\"]:\n            name = full_name(package, item)\n            if name in map_types:\n                continue\n            data = {\n                'name': simplify_name(name),\n                'doc': item.comment\n            }\n\n            if item.kind == DescriptorProto:\n                data.update({\n                    'type': 'message',\n                    'fields': []\n                })\n                for f in item.field:\n                    kind = type_to_string(f, map_types)\n                    data[\"fields\"].append({\n                        'name': f.name,\n                        'type': kind,\n                        'doc': f.comment\n                        })\n                if len(item.oneof_decl) > 0:\n                    data[\"fields\"] = [\n                        {\n                            \"name\": item.oneof_decl[0].name,\n                            \"type\": [\" %s \"% x[\"type\"] for x in data[\"fields\"]],\n                            \"doc\": \"\\n\".join([\"%s: %s\"%(x[\"type\"],x[\"doc\"]) for x in data[\"fields\"] if x[\"doc\"] != \"\"])\n                        }]\n                types.append(data)\n            elif item.kind == EnumDescriptorProto:\n                comments = [\"\\n* `%s`: %s\"%(v.name, v.comment) for v in item.value]\n                data.update({\n                    'type': 'enum',\n                    'symbols': [v.name for v in item.value]\n                })\n                data[\"doc\"] += \"\\n\" + \" \".join(comments)\n                types.append(data)\n            elif item.kind == ServiceDescriptorProto:\n                for m in item.method:\n                    messages[m.name] = {\n                        \"doc\": m.comment,\n                        \"request\": [{\n                            \"name\": \"request\",\n                            \"type\": \":protobuf:message:`%s`\" % simplify_name(m.input_type),\n                        }],\n                        \"response\": \":protobuf:message:`%s`\" % simplify_name(m.output_type),\n                        \"errors\" : [ \":protobuf:message:`GAException`\" ]\n                    }\n            else:\n                raise Exception, item.kind\n\n        comments = \"\\n\".join(results[\"file\"])\n        output = {\n            \"types\": types,\n            \"messages\": messages,\n            \"protocol\": proto_file.name.split(\"/\")[-1].split(\".\")[0],\n            'doc': comments,\n            \"namespace\": proto_file.package,\n        }\n\n        # Fill response\n        f = response.file.add()\n        f.name = proto_file.name + '.json'\n        f.content = json.dumps(output, indent=2)", "response": "Generates code for all the available types and messages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the great - circle distance between two points on the Earth surface.", "response": "def haversine(point1, point2, unit='km'):\n    \"\"\" Calculate the great-circle distance between two points on the Earth surface.\n\n    :input: two 2-tuples, containing the latitude and longitude of each point\n    in decimal degrees.\n\n    Keyword arguments:\n    unit -- a string containing the initials of a unit of measurement (i.e. miles = mi)\n            default 'km' (kilometers).\n\n    Example: haversine((45.7597, 4.8422), (48.8567, 2.3508))\n\n    :output: Returns the distance between the two points.\n\n    The default returned unit is kilometers. The default unit can be changed by\n    setting the unit parameter to a string containing the initials of the desired unit.\n    Other available units are miles (mi), nautic miles (nmi), meters (m),\n    feets (ft) and inches (in).\n\n    \"\"\"\n    # mean earth radius - https://en.wikipedia.org/wiki/Earth_radius#Mean_radius\n    AVG_EARTH_RADIUS_KM = 6371.0088\n\n    # Units values taken from http://www.unitconversion.org/unit_converter/length.html\n    conversions = {'km': 1,\n                   'm': 1000,\n                   'mi': 0.621371192,\n                   'nmi': 0.539956803,\n                   'ft': 3280.839895013,\n                   'in': 39370.078740158}\n\n    # get earth radius in required units\n    avg_earth_radius = AVG_EARTH_RADIUS_KM * conversions[unit]\n\n    # unpack latitude/longitude\n    lat1, lng1 = point1\n    lat2, lng2 = point2\n\n    # convert all latitudes/longitudes from decimal degrees to radians\n    lat1, lng1, lat2, lng2 = map(radians, (lat1, lng1, lat2, lng2))\n\n    # calculate haversine\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = sin(lat * 0.5) ** 2 + cos(lat1) * cos(lat2) * sin(lng * 0.5) ** 2\n\n    return 2 * avg_earth_radius * asin(sqrt(d))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve run folder paths from the command line Ensure only metrics required for summary are loaded Load the run metrics Calculate the summary metrics Display error by lane, read", "response": "def main():\n    \"\"\" Retrieve run folder paths from the command line\n    Ensure only metrics required for summary are loaded\n    Load the run metrics\n    Calculate the summary metrics\n    Display error by lane, read\n    \"\"\"\n    logging.basicConfig(level=logging.INFO)\n\n    run_metrics = py_interop_run_metrics.run_metrics()\n    summary = py_interop_summary.run_summary()\n\n    valid_to_load = py_interop_run.uchar_vector(py_interop_run.MetricCount, 0)\n    py_interop_run_metrics.list_summary_metrics_to_load(valid_to_load)\n\n    for run_folder_path in sys.argv[1:]:\n        run_folder = os.path.basename(run_folder_path)\n        try:\n            run_metrics.read(run_folder_path, valid_to_load)\n        except Exception, ex:\n            logging.warn(\"Skipping - cannot read RunInfo.xml: %s - %s\"%(run_folder, str(ex)))\n            continue\n        py_interop_summary.summarize_run_metrics(run_metrics, summary)\n        error_rate_read_lane_surface = numpy.zeros((summary.size(), summary.lane_count(), summary.surface_count()))\n        for read_index in xrange(summary.size()):\n            for lane_index in xrange(summary.lane_count()):\n                for surface_index in xrange(summary.surface_count()):\n                    error_rate_read_lane_surface[read_index, lane_index, surface_index] = \\\n                        summary.at(read_index).at(lane_index).at(surface_index).error_rate().mean()\n        logging.info(\"Run Folder: \"+run_folder)\n        for read_index in xrange(summary.size()):\n            read_summary = summary.at(read_index)\n            logging.info(\"Read \"+str(read_summary.read().number())+\" - Top Surface Mean Error: \"+str(error_rate_read_lane_surface[read_index, :, 0].mean()))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a CSV file from the security center.", "response": "def gen_csv(sc, filename, field_list, source, filters):\n    '''csv SecurityCenterObj, AssetListName, CSVFields, EmailAddress\n    '''\n\n    # First thing we need to do is initialize the csvfile and build the header\n    # for the file.\n    datafile = open(filename, 'wb')\n    csvfile = csv.writer(datafile)\n    header = []\n    for field in field_list:\n        header.append(fields.fields[field]['name'])\n    csvfile.writerow(header)\n\n    debug.write('Generating %s: ' % filename)\n    # Next we will run the Security Center query.  because this could be a\n    # potentially very large dataset that is returned, we don't want to run out\n    # of memory.  To get around this, we will pass the query function the writer\n    # function with the appropriate fields so that it is parsed inline.\n    fparams = {'fobj': csvfile, 'flist': field_list}\n    sc.query('vulndetails', source=source, \n             func=writer, func_params=fparams, **filters)\n    debug.write('\\n')\n\n    # Lastly we need to close the datafile.\n    datafile.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs the user into SecurityCenter and stores the needed token and cookies.", "response": "def login(self, user, passwd):\n        '''Logs the user into SecurityCenter and stores the needed token and cookies.'''\n        resp = self.post('token', json={'username': user, 'password': passwd})\n        self._token = resp.json()['response']['token']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef analysis(self, *filters, **kwargs):\n        '''Analysis\n        A thin wrapper to handle vuln/event/mobile/log analysis through the API.  This\n        function handles expanding multiple filters and will translate arbitrary arguments\n        into the format that SecurityCenter's analysis call expect them to be in.\n\n        In order to make the filter expander more useful for SecurityCenter5 verses the\n        SecurityCenter4 class, filters are no longer done as kwargs, and instead are done\n        as a list of tuples.  For example, to get the IP Summary of all of the hosts in\n        the 10.10.0.0/16 network, we would make the following call:\n\n        vulns = sc.analysis(('ip','=','10.10.0.0/16'), tool='sumip')\n\n        If multiple filters are desired, then it's simply a matter of entering multiple tuples.\n\n        The Analysis function also has a few functions that are sligly deviated from the API\n        guides.  All of these options are optional, however can significantly change the how\n        the API is being called.\n\n        page         - Default \"all\"                The current page in the pagination sequence.\n        page_size    - Default 1000                 The page size (number of returned results)\n        page_obj     - Default \"return_results\"     The class thats called after every API pull.\n        page_kwargs  - Default {}                   Any additional arguments that need to be passed\n                                                    to the page_obj class when instantiated.\n        type         - Default \"vuln\"               This is the type of data that will be returned.\n                                                    As all of the LCE and Vuln calls have been\n                                                    collapsed into \"analysis\" in the API, each filter\n                                                    needs to have these specified.  This module does\n                                                    that legwork for you.\n        sourceType   - Default \"cumulative\"         This is how we specify individual scans, LCE archive\n                                                    silos, and other datasets that stand outside the norm.\n        '''\n        output = []\n        def return_results(**kwargs):\n            return kwargs['resp'].json()['response']['results']\n\n        def return_generator(**kwargs):\n            for item in kwargs['resp'].json()['response']['results']:\n                yield item\n\n        # These values are commonly used and/or are generally not changed from the default.\n        # If we do not see them specified by the user then we will need to add these in\n        # for later parsing...\n        if 'page' not in kwargs: kwargs['page'] = 'all'\n        if 'page_size' not in kwargs: kwargs['page_size'] = 1000\n        if 'page_obj' not in kwargs: kwargs['page_obj'] = return_results\n        if 'page_kwargs' not in kwargs: kwargs['page_kwargs'] = {}\n        if 'type' not in kwargs: kwargs['type'] = 'vuln'\n        if 'sourceType' not in kwargs: kwargs['sourceType'] = 'cumulative'\n        if 'generator' in kwargs: kwargs['generator'] = return_generator\n\n        # New we need to pull out the options from kwargs as we will be using hwargs as\n        # the basis for the query that will be sent to SecurityCenter.\n        opts = {}\n        for opt in ['page', 'page_size', 'page_obj', 'page_kwargs', 'generator']:\n            if opt in kwargs:\n                opts[opt] = kwargs[opt]\n                del kwargs[opt]\n\n        # If a query option was not set, then we will have to.  The hope here is that\n        # we can make a lot of the pain of building the query pretty easy by simply\n        # accepting tuples of the filters.\n        if 'query' not in kwargs:\n            kwargs['query'] = {\n                'tool': kwargs['tool'],\n                'type': kwargs['type'],\n                'filters': [{'filterName': f[0], 'operator': f[1], 'value': f[2], 'type': kwargs['type']} for f in filters]\n            }\n            del kwargs['tool']\n            if opts['page'] == 'all':\n                kwargs['query']['startOffset'] = 0\n                kwargs['query']['endOffset'] = opts['page_size']\n            else:\n                kwargs['query']['startOffset'] = opts['page'] * opts['page_size']\n                kwargs['query']['endOffset'] = (opts['page'] + 1) * opts['page_size']\n\n        count = 0\n        total_records = opts['page_size']\n        while total_records > count:\n            # Here we actually make the calls.\n            resp = self.post('analysis', json=kwargs)\n            opts['page_kwargs']['resp'] = resp\n            out = opts['page_obj'](**opts['page_kwargs'])\n            if isinstance(out, list):\n                for item in out:\n                    output.append(item)\n            total_records = int(resp.json()['response']['totalRecords'])\n            if opts['page'] == 'all':\n                count = int(resp.json()['response']['endOffset'])\n                kwargs['query']['startOffset'] = count\n                kwargs['query']['endOffset'] = count + opts['page_size']\n            else:\n                count = total_records\n        if len(output) > 0:\n            return output", "response": "This function handles the analysis of a specific resource in the SecurityCenter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download_scans(sc, age=0, unzip=False, path='scans'):\n    '''Scan Downloader\n    Here we will attempt to download all of the scans that have completed between\n    now and AGE days ago.\n\n    sc = SecurityCenter5 object\n    age = how many days back do we want to pull? (default: 0)\n    unzip = Do we want to uncompress the nessus files? (default: False)\n    path = Path where the resulting data will be placed. (default: scans)\n    '''\n\n    # if the download path doesn't exist, we need to create it.\n    if not os.path.exists(path):\n        logger.debug('scan path didn\\'t exist. creating it.')\n        os.makedirs(path)\n\n    # Now we will need to comuter the timestamp for the date that the age has\n    # apecified.  The API expects this in a unix timestamp format.\n    findate = (date.today() - timedelta(days=age))\n\n    # Lets get the list of scans that had completed within the timefram that we\n    # had specified.\n    logger.debug('getting scan results for parsing')\n    resp = sc.get('scanResult', params={\n        'startTime': int(time.mktime(findate.timetuple())),\n        'fields': 'name,finishTime,downloadAvailable,repository',\n    })\n\n    for scan in resp.json()['response']['usable']:\n        # If this particular scan does not have any results (either it was a \n        # partial, failed, or incomplete scan) then we have nothing further to\n        # do and should simply ignore this scan.\n        if scan['downloadAvailable'] == 'false':\n            logger.debug('%s/\"%s\" not available for download' % (scan['id'], \n                                                                    scan['name']))\n        else:\n            # Well look, this scan actually has results, lets go ahead and pull\n            # them down.\n            logger.debug('%s/\"%s\" downloading' % (scan['id'], scan['name']))\n            scandata = sc.post('scanResult/%s/download' % scan['id'], \n                              json={'downloadType': 'v2'})\n            sfin = datetime.fromtimestamp(int(scan['finishTime']))\n\n            # The filename is being computed generically here.  As this will be\n            # used whether we extract the .nessus file out of the zipfile or\n            # not.\n            filename = '%s-%s.%s.%s' % (scan['id'], \n                                        scan['name'].replace(' ', '_'), \n                                        scan['repository']['id'],\n                                        sfin.strftime('%Y.%m.%d-%H.%M'))\n            if unzip:\n                # Unzip that .nessus file!\n                logger.debug('extracting %s/%s' % (scan['id'], scan['name']))\n                zfile = ZipFile(StringIO(buf=scandata.content))\n                scanfile = zfile.filelist[0]\n                scanfile.filename = '%s.nessus' % filename\n                zfile.extract(scanfile, path=path)\n            else:\n                # We want to keep it compressed, just dump to disk.\n                logger.debug('writing zip for %s/%s' % (scan['id'], scan['name']))\n                with open('%s.zip' % filename, 'wb') as zfile:\n                    zfile.write(scandata.content)\n\n            # Were done with this scan file!!!\n            logger.info('%s/\"%s\" downloaded' % (scan['id'], scan['name']))", "response": "Download all scans that have completed between AGE days ago."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(sc, filename, asset_id):\n    '''\n    Updates a DNS Asset List with the contents of the filename.  The assumed\n    format of the file is 1 entry per line.  This function will convert the\n    file contents into an array of entries and then upload that array into\n    SecurityCenter.\n    '''\n    addresses = []\n    with open(filename) as hostfile:\n        for line in hostfile.readlines():\n            addresses.append(line.strip('\\n'))\n    sc.asset_update(asset_id, dns=addresses)", "response": "This function updates a DNS Asset List with the contents of the filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the HTML report and dumps it into the specified filename", "response": "def generate_html_report(base_path, asset_id):\n    '''\n    Generates the HTML report and dumps it into the specified filename\n    '''\n    jenv = Environment(loader=PackageLoader('swchange', 'templates'))\n    s = Session()\n    #hosts = s.query(Host).filter_by(asset_id=asset_id).all()\n    asset = s.query(AssetList).filter_by(id=asset_id).first()\n    if not asset:\n        print 'Invalid Asset ID (%s)!' % asset_id\n        return\n    filename = os.path.join(base_path, '%s-INV-CHANGE-%s.html' % (\n        asset.name,\n        datetime.now().strftime('%Y-%m-%d.%H.%M.%S'))\n    )\n    print 'Generating Report : %s' % filename\n    with open(filename, 'wb') as report:\n        report.write(jenv.get_template('layout.html').render(\n            asset=asset,\n            current_date=datetime.now()\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the database for the given asset and expiration time.", "response": "def gen(sc, asset, expire):\n    '''\n    Database population function.\n\n    What we are doing here is trying to interpret the output of plugin ID 20811\n    and use that information to help populate the database with individualized\n    entries of the software that is installed on the host.  This information will\n    later be used to build the report.\n    '''\n\n    # The following regex patters are used to pull out the needed fields from\n    # Plugin ID 20811\n    redate = re.compile(r'\\[installed on (\\d{4})/(\\d{1,2})/(\\d{1,2})\\]')\n    reinvdate = re.compile(r'\\[installed on (\\d{1,2})/(\\d{1,2})/(\\d{4})\\]')\n    rever = re.compile(r'\\[version (.*?)\\]')\n    resw = re.compile(r'^([\\w\\s\\.\\(\\-\\)\\+]*)')\n    s = Session()\n    ts = datetime.datetime.now()\n    for vuln in sc.analysis(('pluginID','=','20811,22869'),\n                            ('asset', '=', {'id': str(asset)}),\n                            tool='vulndetails'):\n\n\n        # First we need to get the host information...\n        nh = False\n        host = s.query(Host).filter_by(ip=vuln['ip']).first()\n        if not host:\n            host = Host()\n            nh = True\n        hdata = sc.analysis(('ip', '=', vuln['ip']),tool='sumip')[0]\n        host.ip = vuln['ip']\n        host.name = vuln['netbiosName']\n        host.cpe = hdata['osCPE']\n        host.dns = hdata['dnsName']\n        host.asset_id = asset\n        if nh:\n            s.add(host)\n        else:\n            s.merge(host)\n        s.commit()\n        sys.stdout.write('%4d\\t%-16s\\t%-40s' % (host.id, host.ip, host.dns))\n        sys.stdout.flush()\n\n        if vuln['pluginID'] == '22869':\n            if 'CentOS Linux system' in vuln['pluginText'] or 'Red Hat Linux system' in vuln['pluginText']:\n                software = re.findall('  ([a-zA-Z0-9\\.\\-]*)\\|',vuln['pluginText'])\n                for item in software:\n                    entry = Entry()\n                    entry.name = item\n                    entry.timestamp = ts\n                    entry.host_id = host.id\n                    s.add(entry)\n                    s.commit()\n            elif 'SunOS 5.10' in vuln['pluginText']:\n                software = re.findall('Patch: ([^ ]*)', vuln['pluginText'])\n                for item in software:\n                    entry = Entry()\n                    entry.name = item\n                    entry.timestamp = ts\n                    entry.host_id = host.id\n                    s.add(entry)\n                    s.commit()\n            elif 'Solaris 11 system' in vuln['pluginText']:\n                software = re.findall('([\\w\\/]+)\\W+([0-9\\.\\-]+).*\\n',vuln['pluginText'])\n                for item in software:\n                    entry = Entry()\n                    entry.name = item[0]\n                    entry.version = item[1]\n                    entry.timestamp = ts\n                    entry.host_id = host.id\n                    s.add(entry)\n                    s.commit()\n            elif 'Mac OS X system' in vuln['pluginText']:\n                software = re.findall('  ([a-zA-Z0-9\\.\\-\\_]*\\.pkg)\\n',vuln['pluginText'])\n                for item in software:\n                    entry = Entry()\n                    entry.name = item\n                    entry.timestamp = ts\n                    entry.host_id = host.id\n                    s.add(entry)\n                    s.commit()\n            else:\n                sys.stdout.write('\\t[NO FORMATTER]')\n                sys.stdout.flush()\n\n        if vuln['pluginID'] == '20811':\n            software = False\n            patches = False\n            sw = None\n            nh = False\n            s.commit()\n            for line in vuln['pluginText'].split('\\n'):\n                if '</plugin_output>' in line:\n                    continue\n                if line == u'The following software are installed on the remote host :':\n                    software = True\n                    patches = False\n                    continue\n                if line == u'The following updates are installed :':\n                    patches = True\n                    continue\n\n                if software and line != '':\n                    names = resw.findall(line)\n                    vers = rever.findall(line)\n                    dates = redate.findall(line)\n                    new = Entry()\n                    if len(names) > 0: new.name = names[0].strip()\n                    if len(vers) > 0: new.version = vers[0]\n                    try:\n                        if len(dates) > 0:\n                            date = datetime.date(year=int(dates[0][0]),\n                                                 month=int(dates[0][1]),\n                                                 day=int(dates[0][2]))\n                            new.date = date\n                        else:\n                            dates = reinvdate.findall(line)\n                            if len(dates) > 0:\n                                date = datetime.date(year=int(dates[0][2]),\n                                                     month=int(dates[0][0]),\n                                                     day=int(dates[0][1]))\n                                new.date = date\n                    except:\n                        pass\n                    if patches:\n                        if line[:2] != '  ':\n                            sw = line.strip(':').strip()\n                            continue\n                        else:\n                            new.name = '%s (%s)' % (new.name, sw)\n\n                    new.timestamp = ts\n                    new.host_id = host.id\n                    s.add(new)\n        s.commit()\n        sys.stdout.write('\\tdone\\n')\n        sys.stdout.flush()\n    s.commit()\n\n    # Now to expire the old data out...\n    exp = datetime.datetime.now() - datetime.timedelta(days=expire)\n    print exp\n\n    # First to delete the aged out entries\n    for entry in s.query(Entry).filter(Entry.timestamp < exp).all():\n        s.delete(entry)\n    s.commit()\n\n    # Next to delete any hosts that we arent pulling info for anymore...\n    for host in s.query(Host).all():\n        if len(host.entries) == 0:\n            s.delete(host)\n    s.commit()\n    s.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a CSV file from a SecurityCenter object.", "response": "def gen_csv(sc, filename):\n    '''csv SecurityCenterObj, EmailAddress\n    '''\n\n    # First thing we need to do is initialize the csvfile and build the header\n    # for the file.\n    datafile = open(filename, 'wb')\n    csvfile = csv.writer(datafile)\n    csvfile.writerow(['Software Package Name', 'Count'])\n\n    debug.write('Generating %s: ' % filename)\n    # Next we will run the Security Center query.  because this could be a\n    # potentially very large dataset that is returned, we don't want to run out\n    # of memory.  To get around this, we will pass the query function the writer\n    # function with the appropriate fields so that it is parsed inline.\n    fparams = {'fobj': csvfile}\n    sc.query('listsoftware', func=writer, func_params=fparams)\n    debug.write('\\n')\n\n    # Lastly we need to close the datafile.\n    datafile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreport Downloader The report downloader will pull reports down from SecurityCenter based on the conditions provided to the path provided. sc = SecurityCenter5 object age = number of days old the report may be to be included in the search. path = The path to the download folder. One will be created if it doesn't exist. OPTIONAL ARGUMENTS: type = Specifies the type of the report. e.g. pdf, csv, etc. name = A subset of the name of the report used for pattern matching.", "response": "def download(sc, age=0, path='reports', **args):\n    '''Report Downloader\n    The report downloader will pull reports down from SecurityCenter\n    based on the conditions provided to the path provided.\n\n    sc =        SecurityCenter5 object\n    age =       number of days old the report may be to be included in the\n                search.\n    path =      The path to the download folder.  One will be created if\n                it doesn't exist.\n\n    OPTIONAL ARGUMENTS:\n\n    type =      Specifies the type of the report.  e.g. pdf, csv, etc.\n    name =      A subset of the name of the report used for pattern matching.\n    '''\n\n    # if the download path doesn't exist, we need to create it.\n    if not os.path.exists(path):\n        logger.debug('report path didn\\'t exist. creating it.')\n        os.makedirs(path)\n\n    # Now we will need to comuter the timestamp for the date that the age has\n    # apecified.  The API expects this in a unix timestamp format.\n    findate = (date.today() - timedelta(days=age))\n\n    # Lets get the listing of reports that we will be working with...\n    reports = sc.get('report', params={\n        'startTime': findate.strftime('%s'),\n        'fields': 'name,type,status,finishTime'\n    })\n\n    # now we will work our way through the resulting dataset and attempt\n    # to download the reports if they meet our criteria.\n    for report in reports.json()['response']['usable']:\n\n        # We can only download completed reports, so we have no reason\n        # to even try to download anything that isnt in the completed\n        # status.\n        if report['status'] == 'Completed':\n\n            # If the name or type arguments are passed, then we will\n            # want to make sure that we only download the relevent\n            # reports that match these criteria.  For name, we will\n            # be performing a simple pattern match, and for type we will\n            # check the report type.  e.g. pdf, csv, etc.\n            if 'name' in args and args['name'] not in report['name']:\n                continue\n            if 'type' in args and args['type'].lower() != report['type'].lower():\n                continue\n\n            # now to actually get the report...\n            report_data = sc.post('report/%s/download' % report['id'],\n                json={'id': int(report['id'])})\n\n            # compute a report name...\n            report_name = '%s-%s.%s' % (\n                report['name'].replace(' ', '_'),\n                report['finishTime'],\n                report['type']\n            )\n\n            # and finally write the report to disk...\n            logger.info('writing %s to disk' % report_name)\n            with open(os.path.join(path, report_name), 'wb') as report_file:\n                report_file.write(report_data.content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, path, **kwargs):\n        '''Calls the specified path with the POST method'''\n        resp = self._session.post(self._url(path), **self._builder(**kwargs))\n        if 'stream' in kwargs:\n            return resp\n        else:\n            return self._resp_error_check(resp)", "response": "Calls the specified path with the POST method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports a repository package using the repository ID specified.", "response": "def import_repo(self, repo_id, fileobj):\n        '''\n        Imports a repository package using the repository ID specified.\n        '''\n        # Step 1, lets upload the file\n        filename = self.upload(fileobj).json()['response']['filename']\n\n        # Step 2, lets tell SecurityCenter what to do with the file\n        return self.post('repository/{}/import'.format(repo_id), json={'file': filename})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_xrefs(self):\n        '''\n        Internal function to populate the xrefs list with the external\n        references to be used in searching plugins and potentially\n        other functions as well.\n        '''\n        xrefs = set()\n\n        plugins = self.plugins()\n        for plugin in plugins:\n            for xref in plugin['xrefs'].split(', '):\n                xrf = xref.replace('-', '_').split(':')[0]\n                if xrf is not '':\n                    xrefs.add(xrf)\n        self._xrefs = list(xrefs)", "response": "Internal function to populate the internal _xrefs list with the external\n        references to be used in searching plugins and potentially\n        other functions as well."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query(self, tool, filters=None, source='cumulative', sort=None,\n              direction='desc', func=None, func_params=None, req_size=1000,\n              scan=None, directory=None, **filterset):\n        \"\"\"query tool, [filters], [req_size], [list, of, filters]\n        This function attempts to make it a lot easier to run vuln and lce\n        searches within the Security Center API.  This function will query the\n        API for all of the items that match this query and will then\n        return the end result back as a single block.  This means that running\n        large queries with this function can consume a large amount of memory\n        so some care must be taken.\n\n        If any filters need to be specified that cannot simply be expressed as\n        filterName=value then you must fully build that specific filter or list\n        of filters.  If this is the case, then you must overload the filters\n        value with a list of the filter dictionary sets that are needed.  For\n        example:\n\n        [{'filterName': FILTERNAME, 'operator': '=', 'value': VALUE}]\n\n        While we dont expect this to be used much, its there incase it's needed.\n\n        The default request size is also set to 1000.  This means that the\n        maximum request size that a singular query can consume is 1000\n        individual results before rolling on to the next query.\n\n        If the mitigated flag is set, the results returned back will be from\n        the mitigated dataset instead of the cumulative dataset.\n\n        If the source is `\"individual\"`, `scan` should be passed a scan id and\n        `directory` should be passed a date directory as a string `\"YYYY-mm-dd\"`\n        or as a `datetime` to be converted.\n\n        For a list of the available filters that can be performed, please\n        consult the Security Center API documentation.\n\n        \"\"\"\n\n        data = []       # This is the list that we will be returning back to\n                        # the calling function once we complete.\n        payload = {}    # The dataset that we will be sending to the API via the\n                        # raw_query function.\n\n        # A simple data dictionary to determine the module that we will be used\n        stype = {\n            'cumulative': 'vuln',\n            'mitigated': 'vuln',\n            'patched': 'vuln',\n            'individual': 'vuln',\n            'lce': 'events',\n        }\n\n        # When the source is \"individual\", scan and directory should be provided\n        # as well, and will be set in the payload.\n        if source == \"individual\" and scan is not None and directory is not None:\n            # convert directory passed as datetime to string if necessary\n            if isinstance(directory, date):\n                directory = directory.strftime(\"%Y-%m-%d\")\n\n            payload[\"scanID\"] = scan\n            payload[\"dateDirectory\"] = directory\n            payload[\"view\"] = \"all\"\n\n        # Check to see if filters was set.  If it wasnt, then lets go ahead and\n        # initialize it as an empty dictionary.\n        if filters is None:\n            filters = []\n\n        # Here is where we expand the filterset dictionary to something that the\n        # API can actually understand.\n        for item in filterset:\n            filters.append({\n                'filterName': item,\n                'operator': '=',\n                'value': filterset[item]\n            })\n\n        # Next we need to populate the payload with the information needed to\n        # fire a complete API request.\n        payload['tool'] = tool\n        payload['sourceType'] = source\n        payload['filters'] = filters\n\n        # Then we will check to see if a sort field was specified.  If it was,\n        # then we will add the sortField and sortDir elements to the query.\n        if sort is not None:\n            payload['sortField'] = sort\n            payload['sortDir'] = direction\n\n        # Now that we have everything we need, a quick sanity check first to\n        # make sure some idiot didn't give us a completely empty filterset to\n        # work with.  If they did for some reason, just return an empty list.\n        #if len(filters) < 1:\n        #    return []\n\n        # Everything is set, checks out, and is ready to go.  Now we have to\n        # start running through the query loop and actually pull everything\n        # together.  We know that we will\n        items = []      # This is the resultset.  It'll be different every time\n                        # we loop.  to get things going however, we will just\n                        # set it to an empty list.\n        count = 0       # A simple counter to track the total number of results\n                        # that have been returned.\n        while len(items) == req_size or count == 0:\n            # The API requires that we set an offset for the start and end of\n            # the request, so we will add these to the payload here.\n            payload['startOffset'] = count\n            payload['endOffset'] = count + req_size\n\n            # Now lets run the query, assign the items, and inc the counter.\n            response = self.raw_query(stype[source], 'query', data=payload)\n            items = response['results']\n            count += len(items)\n\n            # New we will either flatten the data to the data list, or if func\n            # is defined, we will pass the data for this query on to that\n            # function for parsing.\n            if func is not None and hasattr(func, '__call__'):\n                if func_params is not None:\n                    func(items, **func_params)\n                else:\n                    func(items)\n            else:\n                for item in items:\n                    data.append(item)\n\n            # Lastly lets check to see if we entered into an empty dataset.  If\n            # we did, then we will need to break out of the loop so that we\n            # don't run into an infinite loop and thrash the API.\n            if response['totalRecords'] == '0':\n                break\n        return data", "response": "This function will query the Security Center API for all items in the specified region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef login(self, user, passwd):\n        data = self.raw_query('auth', 'login',\n                             data={'username': user, 'password': passwd})\n        self._token = data[\"token\"]\n        self._user = data", "response": "login user passwd\n        Performs the login operation for Security Center, storing the token\n        that Security Center has generated for this login session for future\n        queries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asset_update(self, asset_id, name=None, description=None,\n                     visibility=None, group=None, users=None,\n                     ips=None, rules=None, dns=None):\n        '''asset_update asset_id, [name], [description], [visibility], [group],\n                        [users], [ips], [rules], [dns]\n        The Asset Update function will update the Asset ID defined with the\n        values that have been specified.  Only those specified will be updated\n        as a query is first made to pre-populate the update with all of the\n        existing information, then override that information with the new data\n        presented by the caller.\n        '''\n\n        payload = None\n        # First thing we need to do is query the api for the current asset\n        # information and populate the payload with it.\n        for asset in self.assets()['assets']:\n            if asset['id'] == str(asset_id):\n                payload = {\n                    'id': asset['id'],\n                    'type': asset['type'],\n                    'name': asset['name'],\n                    'description': asset['description'],\n                }\n                if self.version[:3] == '4.8':\n                    payload['tags'] = asset['tags']\n                else:\n                    payload['visibility'] = asset['visibility']\n                    payload['group'] = asset['group']\n                    payload['users'] = asset['users']\n                if asset['type'] == 'dynamic':\n                    payload['rules'] = asset['rules']\n                if asset['type'] == 'static':\n                    payload['definedIPs'] = asset['definedIPs']\n                if asset['type'] == 'dnsname':\n                    payload['definedDNSNames'] = asset['definedDNSNames']\n\n\n        # New we need to check to see if we actually got to pre-load the\n        # payload.  If we didnt, then there isn an existing Asset list and we\n        # should error out.\n        if payload is None:\n            raise APIError(13, 'asset_id %s does not exist' % asset_id)\n\n        # And now we will override any of the values that have actually been\n        # specified.\n        if name is not None and isinstance(name, str):\n            payload['name'] = name\n        if description is not None and isinstance(description, str):\n            payload['description'] = description\n        if self.version[:3] != '4.8':\n            if visibility is not None and isinstance(visibility, str):\n                payload['visibility'] = visibility\n            if group is not None and isinstance(group, str):\n                payload['group'] = group\n        else:\n            if group is not None and isinstance(group, str):\n                payload['tags'] = group\n        if users is not None and isinstance(users, list):\n            ulist = []\n            for user in users:\n                ulist.append({'id': int(user)})\n            payload['users'] = ulist\n        if payload['type'] == 'dynamic' and rules is not None and isinstance(rules, list):\n            payload['rules'] = rules\n        if payload['type'] == 'static' and ips is not None and isinstance(ips, list):\n            payload['definedIPs'] = ','.join(ips)\n        if payload['type'] == 'dnsname' and dns is not None\\\n                                        and isinstance(dns, list):\n            payload['definedDNSNames'] = ','.join(dns)\n\n        # And now that we have everything defined, we can go ahead and send\n        # the api request payload and return the response.\n        return self.raw_query('asset', 'edit', data=payload)", "response": "This function is used to update the asset_id of an asset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the credentials of the specified credential ID.", "response": "def credential_update(self, cred_id, **options):\n        \"\"\"credential_update cred_id **options\n        Updates the specified values of the credential ID specified.\n        \"\"\"\n        payload = None\n\n        # First we pull the credentials and populate the payload if we\n        # find a match.\n        for cred in self.credentials()['credentials']:\n            if cred['id'] == str(cred_id):\n                payload = {\n                    'id': cred_id,\n                    'type': cred['type'],\n                    'name': cred['name'],\n                    'description': cred['description'],\n                    'visibility': cred['visibility'],\n                    'group': cred['group'],\n                    'users': cred['users'],\n                }\n\n                if cred['type'] == 'kerberos':\n                    payload['ip'] = cred['ip']\n                    payload['port'] = cred['port']\n                    payload['protocol'] = cred['protocol']\n                    payload['realm'] = cred['realm']\n\n                if cred['type'] == 'snmp':\n                    payload['communityString'] = cred['communityString']\n\n                if cred['type'] == 'ssh':\n                    payload['username'] = cred['username']\n                    payload['publickey'] = cred['publickey']\n                    payload['privatekey'] = cred['privatekey']\n                    payload['priviledgeEscalation'] = cred['priviledgeEscalation']\n                    payload['escalationUsername'] = cred['escalationUsername']\n\n                if cred['type'] == 'windows':\n                    payload['username'] = cred['username']\n                    payload['domain'] = cred['domain']\n\n        if payload is None:\n            raise APIError(13, 'cred_id %s does not exist' % cred_id)\n\n        for option in options:\n            payload[option] = options[option]\n\n        return self.raw_query('credential', 'edit', data=payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new credential into SecurityCenter.", "response": "def credential_add(self, name, cred_type, **options):\n        '''\n        Adds a new credential into SecurityCenter.  As credentials can be of\n        multiple types, we have different options to specify for each type of\n        credential.\n\n        **Global Options (Required)**\n\n        :param name: Unique name to be associated to this credential\n        :param cred_type: The type of credential.  Valid values are:\n                          'ssh', 'windows', 'snmp', or 'kerberos'\n        :type name: string\n        :type cred_type: string\n\n        **Windows Credential Options**\n\n        :param username: Account Name\n        :param password: Account Password\n        :param domain: [Optional] Account Member Domain\n        :type username: string\n        :type password: string\n        :type domain: string\n\n        **Unix/SSH Credential Options**\n\n        SSH Credentials cover a multitude of different types of hosts.\n        Everything from Linux/Unix boxes to networking gear like Cisco IOS\n        devices.  As a result of this, there are a lot of available options in\n        order to cover as many possible scenarios as possible.  A few examples:\n\n        Simple Username/Password:\n\n        >>> sc.credential_add('Example Linux Root', 'ssh',\n                username='root', password='r00tp@ssw0rd')\n\n        Utilizing Sudo:\n\n        >>> sc.credential_add('Example Linux Sudo', 'ssh',\n                username='user', password='p@ssw0rd',\n                privilegeEscalation='sudo',\n                escalationPassword='p@ssw0rd')\n\n        SSH Keys (By Filename):\n\n        >>> sc.credential_add('Example Linux Keys', 'ssh',\n                username='root',\n                privateKey='/path/to/id_rsa',\n                publicKey='/path/to/id_rsa.pub',\n                passphrase='somthing' # Only use this if needed\n            )\n\n        SSH Keys (Using File Objects):\n\n        >>> pubkey = open('/path/to/id_rsa.pub', 'rb')\n        >>> privkey = open('/path/to/id_rsa', 'rb')\n        >>> sc.credential_add('Example Linux Keys 2', 'ssh',\n                username='root',\n                privateKey=privkey,\n                publicKey=pubkey,\n                passphrase='somthing' # Only use this if needed\n            )\n\n        :param username: Account Name\n        :param password: Account Password\n        :param privilegeEscalation: [Optional] The type of privilege escalation\n                                required for this account.  The default is None.\n                                Valid options are: 'su', 'su+sudo', 'dzdo',\n                                'pbrun', 'Cisco \\'enable\\'', or 'none'.\n        :param escalationUsername: [Optional] The username to escalate to.  Only\n                                   used for su+sudo escalation.\n        :param escalationPassword: [Optional] The password used for escalation.\n        :param publicKey: [Optional] The SSH public RSA/DSA key used for\n                          authentication.\n        :param privateKey: [Optional] The SSH private RSA/DSA key used for\n                           authentication.\n        :param passphrase: [Optional] The passphrase needed for the RSA/DSA\n                           keypair.\n        :type username: string\n        :type password: string\n        :type privilegeEscalation: string\n        :type escalationUsername: string\n        :type escalationPassword: string\n        :type publicKey: string [filename], fileobj\n        :type privateKey: string [filename], fileobj\n        :type passphrase: string\n\n        **Kerberos Credential Options**\n\n        :param ip: Kerberos Host IP\n        :param port: Kerberos Host Port\n        :param realm: Kerberos Realm\n        :param protocol: Kerberos Protocol\n        :type ip: string\n        :type port: string\n        :type realm: string\n        :type protocol: string\n\n        **SNMP Community String**\n\n        :param communityString: The community string to connect with.\n        :type communityString: string\n        '''\n\n        if 'pirvateKey' in options:\n            options['privateKey'] = self._upload(options['privateKey'])['filename']\n        if 'publicKey' in options:\n            options['publicKey'] = self._upload(options['publicKey'])['filename']\n\n        return self.raw_query(\"credential\", \"add\", data=options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsharing a given credential to the specified Users.", "response": "def credential_share_simulate(self, cred_id, *user_ids):\n        \"\"\"Shares a given credential to the specified Users.\n\n        :param cred_id: Credential ID\n        :param user_ids: List of User IDs\n        \"\"\"\n        return self.raw_query(\"credential\", \"shareSimulate\", data={\n            'id': cred_id,\n            'users': [{'id': i} for i in user_ids],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsharing a given Credential to the specified Users.", "response": "def credential_share(self, cred_id, *user_ids):\n        \"\"\"Shares a given credential to the specified Users.\n\n        :param cred_id: Credential ID\n        :param user_ids: List of User IDs\n        \"\"\"\n        return self.raw_query(\"credential\", \"share\", data={\n            'id': cred_id,\n            'users': [{'id': i} for i in user_ids],\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef credential_delete_simulate(self, *ids):\n        return self.raw_query(\"credential\", \"deleteSimulate\", data={\n            \"credentials\": [{\"id\": str(id)} for id in ids]\n        })", "response": "Show the relationships and dependencies for one or more credentials."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes one or more credentials.", "response": "def credential_delete(self, *ids):\n        \"\"\"Delete one or more credentials.\n\n        :param ids: one or more credential ids\n        \"\"\"\n        return self.raw_query(\"credential\", \"delete\", data={\n            \"credentials\": [{\"id\": str(id)} for id in ids]\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of the plugins and their associated families.", "response": "def plugins(self, plugin_type='all', sort='id', direction='asc',\n                size=1000, offset=0, all=True, loops=0, since=None, **filterset):\n        \"\"\"plugins\n        Returns a list of of the plugins and their associated families.  For\n        simplicity purposes, the plugin family names will be injected into the\n        plugin data so that only 1 list is returned back with all of the\n        information.\n        \"\"\"\n        plugins = []\n\n        # First we need to generate the basic payload that we will be augmenting\n        # to build the\n        payload = {\n            'size': size,\n            'offset': offset,\n            'type': plugin_type,\n            'sortField': sort,\n            'sortDirection': direction.upper(),\n        }\n\n        # If there was a filter given, we will need to populate that.\n        if len(filterset) > 0:\n            fname = list(filterset.keys())[0]\n            if fname in self._xrefs:\n                fname = 'xrefs:%s' % fname.replace('_', '-')\n            payload['filterField'] = fname\n            payload['filterString'] = filterset[list(filterset.keys())[0]]\n\n        # We also need to check if there was a datetime object sent to us and\n        # parse that down if given.\n        if since is not None and isinstance(since, date):\n            payload['since'] = calendar.timegm(since.utctimetuple())\n\n        # And now we run through the loop needed to pull all of the data.  This\n        # may take some time even though we are pulling large data sets.  At the\n        # time of development of this module, there were over 55k active plugins\n        # and over 7k passive ones.\n        while all or loops > 0:\n            # First things first, we need to query the data.\n            data = self.raw_query('plugin', 'init', data=payload)\n            if not data:\n                return []\n\n            # This no longer works in 4.4 as the family name is already\n            # referenced.  Will re-activate this code when I can get a SC4.2\n            # Instance up and running to test...\n            # ---\n            # Next we convert the family dictionary list into a flat dictionary.\n            #fams = {}\n            #for famitem in data['families']:\n            #    fams[famitem['id']] = famitem['name']\n\n            # Then we parse thtrough the data set, adding in the family name\n            # into the plugin definition before adding it into the plugins list.\n            for plugin in data['plugins']:\n            #    plugin['familyName'] = fams[plugin['familyID']]\n                plugins.append(plugin)\n            # ---\n\n            # Next its time to increment the offset so that we get a new data\n            # set.  We will also check here to see if the length really is the\n            # same as whats specified in the size variable.  If it isnt, then\n            # we have reached the end of the dataset and might as well set\n            # the continue variable to False.\n            if len(data['plugins']) < size:\n                all = False\n                loops = 0\n            else:\n                loops -= 1\n                payload['offset'] += len(data['plugins'])\n        return plugins"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the plugin counts as dictionary with the last updated info if it s available.", "response": "def plugin_counts(self):\n        \"\"\"plugin_counts\n        Returns the plugin counts as dictionary with the last updated info if\n        its available.\n        \"\"\"\n        ret = {\n            'total': 0,\n        }\n\n        # As ususal, we need data before we can actually do anything ;)\n        data = self.raw_query('plugin', 'init')\n\n        # For backwards compatability purposes, we will be handling this a bit\n        # differently than I would like.  We are going to check to see if each\n        # value exists and override the default value of 0.  The only value that\n        # I know existed in bost 4.2 and 4.4 is pluginCount, the rest aren't\n        # listed in the API docs, however return back from my experimentation.\n        ret['total'] = data['pluginCount']\n\n        if 'lastUpdates' in data:\n            for item in ['active', 'passive', 'compliance', 'custom', 'event']:\n                itemdata = {}\n                if item in data['lastUpdates']:\n                    itemdata = data['lastUpdates'][item]\n                if item in data:\n                    itemdata['count'] = data[item]\n                else:\n                    itemdata['count'] = 0\n\n                ret[item] = itemdata\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all scans stored in Security Center in a given time range.", "response": "def scan_list(self, start_time=None, end_time=None, **kwargs):\n        \"\"\"List scans stored in Security Center in a given time range.\n\n        Time is given in UNIX timestamps, assumed to be UTC. If a `datetime` is\n        passed it is converted. If `end_time` is not specified it is NOW. If\n        `start_time` is not specified it is 30 days previous from `end_time`.\n\n        :param start_time: start of range to filter\n        :type start_time: date, datetime, int\n        :param end_time: end of range to filter\n        :type start_time: date, datetime, int\n\n        :return: list of dictionaries representing scans\n\n        \"\"\"\n\n        try:\n            end_time = datetime.utcfromtimestamp(int(end_time))\n        except TypeError:\n            if end_time is None:\n                end_time = datetime.utcnow()\n\n        try:\n            start_time = datetime.utcfromtimestamp(int(start_time))\n        except TypeError:\n            if start_time is None:\n                start_time = end_time - timedelta(days=30)\n\n        data = {\"startTime\": calendar.timegm(start_time.utctimetuple()),\n                \"endTime\": calendar.timegm(end_time.utctimetuple())}\n        data.update(kwargs)\n\n        result = self.raw_query(\"scanResult\", \"getRange\", data=data)\n        return result[\"scanResults\"]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scan_download(self, scan_id, format='v2'):\n        payload = {\n            'downloadType': format,\n            'scanResultID': scan_id,\n        }\n        data = self.raw_query('scanResult', 'download', data=payload, dejson=False)\n        bobj = StringIO()\n        bobj.write(data)\n        zfile = ZipFile(bobj)\n        return zfile.read(zfile.namelist()[0])", "response": "Download an individual scan and return a string with the results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef asset_create(self, name, items, tag='', description='', atype='static'):\n        '''asset_create_static name, ips, tags, description\n        Create a new asset list with the defined information.\n\n        UN-DOCUMENTED CALL: This function is not considered stable.\n\n        :param name: asset list name (must be unique)\n        :type name: string\n        :param items: list of IP Addresses, CIDR, and Network Ranges\n        :type items: list\n        :param tag: The tag associate to the asset list\n        :type tag: string\n        :param description: The Asset List description\n        :type description: string\n        '''\n        data = {\n            'name': name,\n            'description': description,\n            'type': atype,\n            'tags': tag\n        }\n        if atype == 'static':\n            data['definedIPs'] = ','.join(items)\n        if atype == 'dns':\n            data['type'] = 'dnsname'\n            data['definedDNSNames'] = ' '.join(items)\n        return self.raw_query('asset', 'add', data=data)", "response": "asset_create_static name, ips, tags, description\n        Create a new asset list with the defined information.\n\n        UN-DOCUMENTED CALL: This function is not considered stable.\n\n        :param name: asset list name (must be unique)\n        :type name: string\n        :param items: list of IP Addresses, CIDR, and Network Ranges\n        :type items: list\n        :param tag: The tag associate to the asset list\n        :type tag: string\n        :param description: The Asset List description\n        :type description: string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef risk_rule(self, rule_type, rule_value, port, proto, plugin_id,\n                  repo_ids, comment='', expires='-1', severity=None):\n        '''accept_risk rule_type, rule_value, port, proto, plugin_id, comment\n        Creates an accept rick rule based on information provided.\n\n        UN-DOCUMENTED CALL: This function is not considered stable.\n\n        :param rule_type: Valid options: ip, asset, all.\n        :type rule_type: string\n        :param rule_value: IP Addresses, or assetID if not the type is not all.\n        :type tule_value: string\n        :param port: Port number\n        :type port: string\n        :param proto: Either the protocol ID or any. TCP = 6, UDP = 17, ICMP = 1\n        :type proto: string\n        :param plugin_id: The plugin ID\n        :type plugin_id: string\n        :param repo_ids: List of repository ids that the rule pertains to.\n        :type repo_ids: string\n        :param comment: General purpose comment field.\n        :type comment: string\n        :param expires: epoch time for expiration.\n        :type expires: string\n        :param severity: New severity rating.\n        '''\n        data = {\n            'hostType': rule_type,\n            'port': port,\n            'comments': comment,\n            'protocol': proto,\n            'pluginID': plugin_id,\n            'repIDs': [{'id': i} for i in repo_ids]\n        }\n        if rule_type != 'all':\n            data['hostValue'] = rule_value\n        if severity is None:\n            data['expires'] = expires\n            return self.raw_query('acceptRiskRule', 'add', data=data)\n        else:\n            sevlevels = {'info': 0, 'low': 1, 'medium': 2, 'high': 3, 'critical': 4}\n            data['severity'] = sevlevels[severity]\n            return self.raw_query('recastRiskRule', 'add', data=data)", "response": "Create an accept rick rule based on information provided."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef group_add(self, name, restrict, repos, lces=[], assets=[], queries=[],\n                  policies=[], dashboards=[], credentials=[], description=''):\n        '''group_add name, restrict, repos\n        '''\n        return self.raw_query('group', 'add', data={\n            'lces': [{'id': i} for i in lces],\n            'assets': [{'id': i} for i in assets],\n            'queries': [{'id': i} for i in queries],\n            'policies': [{'id': i} for i in policies],\n            'dashboardTabs': [{'id': i} for i in dashboards],\n            'credentials': [{'id': i} for i in credentials],\n            'repositories': [{'id': i} for i in repos],\n            'definingAssets': [{'id': i} for i in restrict],\n            'name': name,\n            'description': description,\n            'users': [],\n            'context': ''\n        })", "response": "group_add name restrict repos"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting information from a Raster data set", "response": "def get_geo_info(filename, band=1):\n    ''' Gets information from a Raster data set\n    '''\n    sourceds = gdal.Open(filename, GA_ReadOnly)\n    ndv = sourceds.GetRasterBand(band).GetNoDataValue()\n    xsize = sourceds.RasterXSize\n    ysize = sourceds.RasterYSize\n    geot = sourceds.GetGeoTransform()\n    projection = osr.SpatialReference()\n    projection.ImportFromWkt(sourceds.GetProjectionRef())\n    datatype = sourceds.GetRasterBand(band).DataType\n    datatype = gdal.GetDataTypeName(datatype)\n    return ndv, xsize, ysize, geot, projection, datatype"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_pixel(point_x, point_y, cellx, celly, xmin, ymax):\n    '''\n    Usage:\n        map_pixel(xcoord, ycoord, x_cell_size, y_cell_size, xmin, ymax)\n\n    where:\n        xmin is leftmost X coordinate in system\n\n        ymax is topmost Y coordinate in system\n\n    Example:\n            raster = HMISea.tif\n\n            ndv, xsize, ysize, geot, projection, datatype = get_geo_info(raster)\n\n            row, col = map_pixel(x,y,geot[1],geot[-1], geot[0],geot[3])\n    '''\n    point_x = np.asarray(point_x)\n    point_y = np.asarray(point_y)\n    col = np.floor((point_x - xmin) / cellx).astype(int)\n    row = np.floor((point_y - ymax) / celly).astype(int)\n    return row, col", "response": "This function maps a pixel to a system image."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_pixel_inv(row, col, cellx, celly, xmin, ymax):\n    '''\n    Usage:\n        map_pixel(xcoord, ycoord, x_cell_size, y_cell_size, xmin, ymax)\n\n\n    where:\n            xmin is leftmost X coordinate in system\n\n            ymax is topmost Y coordinate in system\n\n    Example:\n            raster = HMISea.tif\n\n            ndv, xsize, ysize, geot, projection, datatype = get_geo_info(raster)\n\n            row, col = map_pixel(x,y,geot[1],geot[-1], geot[0],geot[3])\n    '''\n    col = np.asarray(col)\n    row = np.asarray(row)\n    point_x = xmin+col*cellx\n    point_y = ymax+row*celly\n    return point_x, point_y", "response": "This function maps a pixel to a point in the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\naggregate raster to smaller resolution by adding cells.", "response": "def aggregate(raster, ndv, block_size):\n    '''\n    Aggregate raster to smaller resolution, by adding cells.\n    Usage:\n            aggregate(raster, ndv, block_size)\n\n    where:\n            raster is a Numpy array created by importing the raster (e.g. geotiff)\n\n            ndv is the NoData Value for the raster (can be read using the get_geo_info function)\n\n            block_size is a duple of factors by which the raster will be shrinked\n\n    Example:\n            raster = HMISea.tif\n\n            ndv, xsize, ysize, geot, projection, datatype = get_geo_info(raster)\n\n            costs = load_tiff(raster)\n\n            costs2=aggregate(costs, ndv, (10,10))\n    '''\n    raster2 = block_reduce(raster, block_size, func=np.ma.sum)\n    return raster2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new geotiff file from an array", "response": "def create_geotiff(name, Array, driver, ndv, xsize, ysize, geot, projection, datatype, band=1):\n    '''\n    Creates new geotiff from array\n    '''\n    if isinstance(datatype, np.int) == False:\n        if datatype.startswith('gdal.GDT_') == False:\n            datatype = eval('gdal.GDT_'+datatype)\n    newfilename = name+'.tif'\n    # Set nans to the original No Data Value\n    Array[np.isnan(Array)] = ndv\n    # Set up the dataset\n    DataSet = driver.Create(newfilename, xsize, ysize, 1, datatype)\n    # the '1' is for band 1.\n    DataSet.SetGeoTransform(geot)\n    DataSet.SetProjection(projection.ExportToWkt())\n    # Write the array\n    DataSet.GetRasterBand(band).WriteArray(Array)\n    DataSet.GetRasterBand(band).SetNoDataValue(ndv)\n    return newfilename"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naligns two rasters so that data overlaps by geographical location", "response": "def align_rasters(raster, alignraster, how=np.ma.mean, cxsize=None, cysize=None, masked=False):\n    '''\n    Align two rasters so that data overlaps by geographical location\n    Usage:\n    (alignedraster_o, alignedraster_a, geot_a) = AlignRasters(raster, alignraster, how=np.mean)\n\n    where:\n        raster: string with location of raster to be aligned\n\n        alignraster: string with location of raster to which raster will be aligned\n\n        how: function used to aggregate cells (if the rasters have different sizes)\n\n    It is assumed that both rasters have the same size\n    '''\n    ndv1, xsize1, ysize1, geot1, projection1, datatype1 = get_geo_info(raster)\n    ndv2, xsize2, ysize2, geot2, projection2, datatype2 = get_geo_info(alignraster)\n    if projection1.ExportToMICoordSys() == projection2.ExportToMICoordSys():\n        blocksize = (np.round(geot2[1]/geot1[1]).astype(int), np.round(geot2[-1]/geot1[-1]).astype(int))\n        mraster = gdalnumeric.LoadFile(raster)\n        mraster = np.ma.masked_array(mraster, mask=mraster == ndv1, fill_value=ndv1)\n        mmin = mraster.min()\n        mraster = block_reduce(mraster, blocksize, func=how)\n        araster = gdalnumeric.LoadFile(alignraster)\n        araster = np.ma.masked_array(araster, mask=araster == ndv2, fill_value=ndv2)\n        amin = araster.min()\n        if geot1[0] <= geot2[0]:\n            row3, mcol = map_pixel(geot2[0], geot2[3], geot1[1] *blocksize[0],\n                                   geot1[-1]*blocksize[1], geot1[0], geot1[3])\n            acol = 0\n        else:\n            row3, acol = map_pixel(geot1[0], geot1[3], geot2[1], geot2[-1], geot2[0], geot2[3])\n            mcol = 0\n        if geot1[3] <= geot2[3]:\n            arow, col3 = map_pixel(geot1[0], geot1[3], geot2[1], geot2[-1], geot2[0], geot2[3])\n            mrow = 0\n        else:\n            mrow, col3 = map_pixel(geot2[0], geot2[3], geot1[1] *blocksize[0],\n                                   geot1[-1]*blocksize[1], geot1[0], geot1[3])\n            arow = 0\n        '''\n        col3,row3 = map_pixel(geot1[0], geot1[3], geot2[1],geot2[-1], geot2[0], geot2[3])\n        col3 = max(0,col3)\n        row3 = max(0,row3)\n        araster = araster[row3:,col3:]\n        col3,row3 = map_pixel(geot2[0], geot2[3], geot1[1] *blocksize[0],\n                              geot1[-1]*blocksize[1], geot1[0], geot1[3])\n        col3 = max(0,abs(col3))\n        row3 = max(0,np.abs(row3))\n        mraster = mraster[row3:,col3:]\n        '''\n        mraster = mraster[mrow:, mcol:]\n        araster = araster[arow:, acol:]\n        if cxsize and cysize:\n            araster = araster[:cysize, :cxsize]\n            mraster = mraster[:cysize, :cxsize]\n        else:\n            rows = min(araster.shape[0], mraster.shape[0])\n            cols = min(araster.shape[1], mraster.shape[1])\n            araster = araster[:rows, :cols]\n            mraster = mraster[:rows, :cols]\n        #mraster = mraster[row3:rows+row3,col3:cols+col3]\n        if masked:\n            mraster = np.ma.masked_array(mraster, mask=mraster < mmin, fill_value=ndv1)\n            araster = np.ma.masked_array(araster, mask=araster < amin, fill_value=ndv2)\n        geot = (max(geot1[0], geot2[0]), geot1[1]*blocksize[0], geot1[2],\n                min(geot1[3], geot2[3]), geot1[4], geot1[-1]*blocksize[1])\n        return (mraster, araster, geot)\n    else:\n        print(\"Rasters need to be in same projection\")\n        return (-1, -1, -1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a geotiff raster keeping ndv values using a masked array", "response": "def load_tiff(file):\n    \"\"\"\n    Load a geotiff raster keeping ndv values using a masked array\n\n    Usage:\n            data = load_tiff(file)\n    \"\"\"\n    ndv, xsize, ysize, geot, projection, datatype = get_geo_info(file)\n    data = gdalnumeric.LoadFile(file)\n    data = np.ma.masked_array(data, mask=data == ndv, fill_value=ndv)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(filename, **kwargs):\n    ndv, xsize, ysize, geot, projection, datatype = get_geo_info(filename, **kwargs)\n    data = gdalnumeric.LoadFile(filename, **kwargs)\n    data = np.ma.masked_array(data, mask=data == ndv, fill_value=ndv)\n    return GeoRaster(data, geot, nodata_value=ndv, projection=projection, datatype=datatype)", "response": "Create a GeoRaster object from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_pandas(df, value='value', x='x', y='y', cellx=None, celly=None, xmin=None, ymax=None,\n                geot=None, nodata_value=None, projection=None, datatype=None):\n    \"\"\"\n    Creates a GeoRaster from a Pandas DataFrame. Useful to plot or export data to rasters.\n    Usage:\n        raster = from_pandas(df, value='value', x='x', y='y', cellx= cellx, celly=celly,\n                             xmin=xmin, ymax=ymax, geot=geot, nodata_value=ndv,\n                             projection=projection, datatype=datatype)\n\n    Although it does not require all the inputs, it is highly recommended to include\n    the geographical information, so that the GeoRaster is properly constructed. As usual,\n    the information can be added afterwards directly to the GeoRaster.\n    \"\"\"\n    if not cellx:\n        cellx = (df.sort_values(x)[x]-df.sort_values(x).shift(1)[x]).max()\n    if not celly:\n        celly = (df.sort_values(y, ascending=False)[y]-df.sort_values(y, ascending=False).shift(1)[y]).drop_duplicates().replace(0).max()\n    if not xmin:\n        xmin = df[x].min()\n    if not ymax:\n        ymax = df[y].max()\n    row, col = map_pixel(df[x], df[y], cellx, celly, xmin, ymax)\n    dfout = pd.DataFrame(np.array([row, col, df[value]]).T, columns=['row', 'col', 'value'])\n    dfout = dfout = dfout.set_index([\"row\",\"col\"]).unstack().value.reindex(index=np.arange(0,np.max(row)+1)).T.reindex(index=np.arange(0,np.max(col)+1)).T\n    if nodata_value:\n        dfout[np.isnan(dfout)] = nodata_value\n    if not nodata_value:\n        nodata_value = np.nan\n    if not geot:\n        geot = (xmin, cellx, 0, ymax, 0, celly)\n    return GeoRaster(dfout, geot, nodata_value=nodata_value, projection=projection, datatype=datatype)", "response": "Creates a GeoRaster from a Pandas DataFrame. Useful to plot or export data to rasters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nalign two rasters so that data overlaps by geographical location", "response": "def align_georasters(raster, alignraster, how=np.mean, cxsize=None, cysize=None):\n    '''\n    Align two rasters so that data overlaps by geographical location\n    Usage: (alignedraster_o, alignedraster_a) = AlignRasters(raster, alignraster, how=np.mean)\n    where\n        raster: string with location of raster to be aligned\n        alignraster: string with location of raster to which raster will be aligned\n        how: function used to aggregate cells (if the rasters have different sizes)\n    It is assumed that both rasters have the same size\n    '''\n    (ndv1, xsize1, ysize1, geot1, projection1, datatype1) = (raster.nodata_value, raster.shape[1],\n                                                             raster.shape[0], raster.geot,\n                                                             raster.projection, raster.datatype)\n    (ndv2, xsize2, ysize2, geot2, projection2, datatype2) = (alignraster.nodata_value,\n                                                             alignraster.shape[1],\n                                                             alignraster.shape[0],\n                                                             alignraster.geot,\n                                                             alignraster.projection,\n                                                             alignraster.datatype)\n    if projection1.ExportToMICoordSys() == projection2.ExportToMICoordSys():\n        blocksize = (np.round(max(geot2[1]/geot1[1], 1)).astype(np.int), np.round(max(geot2[-1]/geot1[-1], 1)).astype(np.int))\n        mraster = raster.raster\n        mmin = mraster.min()\n        if block_reduce != (1, 1):\n            mraster = block_reduce(mraster, blocksize, func=how)\n        blocksize = (np.round(max(geot1[1]/geot2[1], 1)).astype(np.int), np.round(max(geot1[-1]/geot2[-1], 1)).astype(np.int))\n        araster = alignraster.raster\n        amin = araster.min()\n        if block_reduce != (1, 1):\n            araster = block_reduce(araster, blocksize, func=how)\n        if geot1[0] <= geot2[0]:\n            row3, mcol = map_pixel(geot2[0], geot2[3], geot1[1] *blocksize[0],\n                                   geot1[-1]*blocksize[1], geot1[0], geot1[3])\n            acol = 0\n        else:\n            row3, acol = map_pixel(geot1[0], geot1[3], geot2[1], geot2[-1], geot2[0], geot2[3])\n            mcol = 0\n        if geot1[3] <= geot2[3]:\n            arow, col3 = map_pixel(geot1[0], geot1[3], geot2[1], geot2[-1], geot2[0], geot2[3])\n            mrow = 0\n        else:\n            mrow, col3 = map_pixel(geot2[0], geot2[3], geot1[1] *blocksize[0],\n                                   geot1[-1]*blocksize[1], geot1[0], geot1[3])\n            arow = 0\n        mraster = mraster[mrow:, mcol:]\n        araster = araster[arow:, acol:]\n        if cxsize and cysize:\n            araster = araster[:cysize, :cxsize]\n            mraster = mraster[:cysize, :cxsize]\n        else:\n            rows = min(araster.shape[0], mraster.shape[0])\n            cols = min(araster.shape[1], mraster.shape[1])\n            araster = araster[:rows, :cols]\n            mraster = mraster[:rows, :cols]\n        mraster = np.ma.masked_array(mraster, mask=mraster < mmin, fill_value=ndv1)\n        araster = np.ma.masked_array(araster, mask=araster < amin, fill_value=ndv2)\n        geot = (max(geot1[0], geot2[0]), geot1[1]*blocksize[0], geot1[2], min(geot1[3], geot2[3]),\n                geot1[4], geot1[-1]*blocksize[1])\n        mraster = GeoRaster(mraster, geot, projection=projection1,\n                            nodata_value=ndv1, datatype=datatype1)\n        araster = GeoRaster(araster, geot, projection=projection2,\n                            nodata_value=ndv2, datatype=datatype2)\n        return (mraster, araster)\n    else:\n        print(\"Rasters need to be in same projection\")\n        return (-1, -1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert GeoRaster to Pandas DataFrame which can be easily exported to other types of files", "response": "def to_pandas(raster, name='value'):\n    \"\"\"\n    Convert GeoRaster to Pandas DataFrame, which can be easily exported to other types of files\n    The DataFrame has the row, col, value, x, and y values for each cell\n    Usage:\n        df = gr.to_pandas(raster)\n    \"\"\"\n    df = pd.DataFrame(raster.raster)\n    df = df.stack()\n    df = df.reset_index()\n    df.columns = ['row', 'col', name]\n    df['x'] = df.col.apply(lambda col: raster.geot[0]+(col)*raster.geot[1])\n    df['y'] = df.row.apply(lambda row: raster.geot[3]+(row)*raster.geot[-1])\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting GeoRaster to GeoPandas DataFrame", "response": "def to_geopandas(raster, **kwargs):\n    \"\"\"\n    Convert GeoRaster to GeoPandas DataFrame, which can be easily exported to other types of files\n    and used to do other types of operations.\n    The DataFrame has the geometry (Polygon), row, col, value, x, and y values for each cell\n    Usage:\n        df = gr.to_geopandas(raster)\n    \"\"\"\n    df = to_pandas(raster, **kwargs)\n    df['geometry'] = df.apply(squares, georaster=raster, axis=1)\n    df = gp.GeoDataFrame(df, crs=from_string(raster.projection.ExportToProj4()))\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef raster_weights(raster, rook=False, transform='r', **kwargs):\n    rasterf = raster.flatten()\n    if len(raster.shape) == 1:\n        shape = (np.sqrt(raster.shape[0]) * np.array([1,1])).astype(int)\n    else:\n        shape = raster.shape\n    w = pysal.lat2W(*shape, rook=rook, **kwargs)\n\n    # Identify missing/no data\n    if isinstance(rasterf, np.ma.core.MaskedArray):\n        miss = rasterf.mask\n    else:\n        miss = np.logical_or(np.isnan(rasterf), np.isinf(rasterf))\n    missn = set(np.arange(0, len(miss))[miss])\n\n    cneighbors = {}\n    for key, value in w.neighbors.items():\n        if key not in missn:\n            value = list(set(value).difference(missn))\n            cneighbors[key] = value\n    w = pysal.W(cneighbors)\n    w.transform = transform\n    return w", "response": "Constructs a PySal weights for rasters based on a raster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_vector(x, raster, **kvars):\n    y = raster.copy()\n    y.raster[y.raster.mask == False] = x\n    return y", "response": "Map a vector of data to a new GeoRaster"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self):\n        return GeoRaster(self.raster.copy(), self.geot, nodata_value=self.nodata_value,\n                         projection=self.projection, datatype=self.datatype)", "response": "Returns a copy of itself"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves a GeoRaster as geotiff filename. tiff with type datatype", "response": "def to_tiff(self, filename):\n        '''\n        geo.to_tiff(filename)\n\n        Saves GeoRaster as geotiff filename.tif with type datatype\n\n        If GeoRaster does not have datatype, then it tries to assign a type.\n        You can assign the type yourself by setting\n         geo.datatype = 'gdal.GDT_'+type\n        '''\n        if self.datatype is None:\n            self.datatype = gdal_array.NumericTypeCodeToGDALTypeCode(self.raster.data.dtype)\n            if self.datatype is None:\n                if self.raster.data.dtype.name.find('int') !=- 1:\n                    self.raster = self.raster.astype(np.int32)\n                    self.datatype = gdal_array.NumericTypeCodeToGDALTypeCode(self.raster.data.dtype)\n                else:\n                    self.raster = self.raster.astype(np.float64)\n                    self.datatype = gdal_array.NumericTypeCodeToGDALTypeCode(self.raster.data.dtype)\n        self.raster.data[self.raster.mask] = self.nodata_value\n        create_geotiff(filename, self.raster, gdal.GetDriverByName('GTiff'), self.nodata_value,\n                       self.shape[1], self.shape[0], self.geot, self.projection, self.datatype)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot of raster data", "response": "def plot(self, figsize=None, ax=None, **kwargs):\n        '''\n        geo.plot()\n\n        Returns plot of raster data\n        '''\n        if ax is None:\n            fig, ax = plt.subplots(figsize=figsize)\n        ax.set_aspect('equal')\n        ax.matshow(self.raster, **kwargs)\n        plt.draw()\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef median(self, *args, **kwargs):\n        '''\n        geo.median(axis=None, out=None, overwrite_input=False)\n\n        axis : int, optional\n            Axis along which the medians are computed. The default (axis=None)\n            is to compute the median along a flattened version of the array.\n        out : ndarray, optional\n            Alternative output array in which to place the result. It must have\n            the same shape and buffer length as the expected output, but the\n            type (of the output) will be cast if necessary.\n        overwrite_input : bool, optional\n           If True, then allow use of memory of input array (a) for\n           calculations. The input array will be modified by the call to\n           median. This will save memory when you do not need to preserve the\n           contents of the input array. Treat the input as undefined, but it\n           will probably be fully or partially sorted. Default is False. Note\n           that, if `overwrite_input` is True and the input is not already an\n           ndarray, an error will be raised.\n        '''\n        return np.ma.median(self.raster, *args, **kwargs)", "response": "Compute the median along the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclip raster using shapefile or GeoPandas DataFrame", "response": "def clip(self, shp, keep=False, *args, **kwargs):\n        '''\n        Clip raster using shape, where shape is either a GeoPandas DataFrame, shapefile,\n        or some other geometry format used by python-raster-stats\n\n        Returns list of GeoRasters or Pandas DataFrame with GeoRasters and additional information\n\n        Usage:\n\n        clipped = geo.clip(shape, keep=False)\n\n        where:\n        keep: Boolean (Default False), returns Georasters and Geometry information\n        '''\n        df = pd.DataFrame(zonal_stats(shp, self.raster, nodata=self.nodata_value, all_touched=True,\n                                      raster_out=True, affine=Affine.from_gdal(*self.geot),\n                                      geojson_out=keep,))\n        if keep:\n            df['GeoRaster'] = df.properties.apply(lambda x: GeoRaster(x['mini_raster_array'],\n                                                                      Affine.to_gdal(x['mini_raster_affine']),\n                                                                      nodata_value=x['mini_raster_nodata'],\n                                                                      projection=self.projection,\n                                                                      datatype=self.datatype))\n            cols = list(set([i for i in df.properties[0].keys()]).intersection(set(shp.columns)))\n            df2 = pd.DataFrame([df.properties.apply(lambda x: x[i]) for i in cols\n                                ]).T.merge(df[['GeoRaster']], left_index=True, right_index=True,)\n            df2.columns = cols+['GeoRaster']\n            df2 = df2.merge(df[['id']], left_index=True, right_index=True)\n            df2.set_index('id', inplace=True)\n            return df2\n        else:\n            df['GeoRaster'] = df.apply(lambda x: GeoRaster(x.mini_raster_array,\n                                                           Affine.to_gdal(x.mini_raster_affine),\n                                                           nodata_value=x.mini_raster_nodata,\n                                                           projection=self.projection,\n                                                           datatype=self.datatype), axis=1)\n            return df['GeoRaster'].values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stats(self, shp, stats='mean', add_stats=None, raster_out=True, *args, **kwargs):\n        '''\n        Compute raster statistics for a given geometry in shape, where shape is either\n        a GeoPandas DataFrame, shapefile, or some other geometry format used by\n        python-raster-stats. Runs python-raster-stats in background\n        (additional help and info can be found there)\n\n        Returns dataframe with statistics and clipped raster\n\n        Usage:\n\n        df = geo.stats(shape, stats=stats, add_stats=add_stats)\n\n        where:\n        raster_out: If True (Default), returns clipped Georasters\n        '''\n        df = pd.DataFrame(zonal_stats(shp, self.raster, nodata=self.nodata_value,\n                                      all_touched=True, raster_out=raster_out,\n                                      affine=Affine.from_gdal(*self.geot),\n                                      geojson_out=True, stats=stats, add_stats=add_stats))\n        df['GeoRaster'] = df.properties.apply(lambda x: GeoRaster(x['mini_raster_array'],\n                                                                  Affine.to_gdal(x['mini_raster_affine']),\n                                                                  nodata_value=x['mini_raster_nodata'],\n                                                                  projection=self.projection,\n                                                                  datatype=self.datatype))\n        statcols = list(set([i for i in df.properties[0].keys()]).difference(set(shp.columns)))\n        cols = shp.columns.tolist()+statcols\n        cols = [i for i in cols if i != 'geometry' and i.find('mini_raster') == -1]\n        df2 = pd.DataFrame([df.properties.apply(lambda x: x[i]) for i in cols]).T\n        df2.columns = cols\n        df2 = df2.merge(df[['id', 'GeoRaster']], left_index=True, right_index=True)\n        df2.set_index('id', inplace=True)\n        return df2", "response": "Compute raster statistics for a given shapefile or shapefile"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gini(self):\n        if self.count()>1:\n            xsort = sorted(self.raster.data[self.raster.mask == False].flatten()) # increasing order\n            y = np.cumsum(xsort)\n            B = sum(y) / (y[-1] * len(xsort))\n            return 1 + 1./len(xsort) - 2*B\n        else:\n            return 1", "response": "Returns the Gini coefficient of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, func, *args, **kwargs):\n        '''\n        geo.apply(func, *args, **kwargs)\n\n        Returns the value of applying function func on the raster data\n\n        func: Python function\n        *args: Arguments of function\n        **kwargs: Additional arguments of function\n        '''\n        return func(self.raster, *args, **kwargs)", "response": "Apply function func on the raster data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps a pixel in the raster.", "response": "def map_pixel(self, point_x, point_y):\n        '''\n        geo.map_pixel(point_x, point_y)\n\n        Return value of raster in location\n        Note: (point_x, point_y) must belong to the geographic coordinate system and\n        the coverage of the raster\n        '''\n        row, col = map_pixel(point_x, point_y,\n                             self.x_cell_size, self.y_cell_size, self.xmin, self.ymax)\n        try:\n            return self.raster[row, col]\n        except:\n            raise RasterGeoError('Make sure the point belongs to the raster coverage \\\n                                 and it is in the correct geographic coordinate system.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_pixel_location(self, point_x, point_y):\n        '''\n        geo.map_pixel(point_x, point_y)\n\n        Return value of raster in location\n        '''\n        row, col = map_pixel(point_x, point_y, self.x_cell_size, self.y_cell_size,\n                             self.xmin, self.ymax)\n        return np.array([row, col])", "response": "geo.map_pixel(point_x, point_y)\n\n        Return value of raster in location"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract(self, point_x, point_y, radius=0):\n        '''\n        geo.extract(x, y, radius=r)\n\n        Return subraster of raster geo around location (x,y) with radius r\n        where (x,y) and r are in the same coordinate system as geo\n        '''\n        row, col = map_pixel(point_x, point_y, self.x_cell_size, self.y_cell_size,\n                             self.xmin, self.ymax)\n        col2 = np.abs(radius/self.x_cell_size).astype(int)\n        row2 = np.abs(radius/self.y_cell_size).astype(int)\n        return GeoRaster(self.raster[max(row-row2, 0):min(row+row2+1, self.shape[0]), \\\n                        max(col-col2, 0):min(col+col2+1, self.shape[1])], self.geot,\n                        nodata_value=self.nodata_value,\\\n                        projection=self.projection, datatype=self.datatype)", "response": "Return subraster of geo around location x y with radius r"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef align(self, alignraster, how=np.mean, cxsize=None, cysize=None):\n        '''\n        geo.align(geo2, how=np.mean)\n\n        Returns both georasters aligned and with the same pixelsize\n        '''\n        return align_georasters(self, alignraster, how=how, cxsize=cxsize, cysize=cysize)", "response": "Aligns the georasters in the raster with the same pixelsize"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggregate(self, block_size):\n        '''\n        geo.aggregate(block_size)\n\n        Returns copy of raster aggregated to smaller resolution, by adding cells.\n        '''\n        raster2 = block_reduce(self.raster, block_size, func=np.ma.sum)\n        geot = self.geot\n        geot = (geot[0], block_size[0] * geot[1], geot[2], geot[3], geot[4],\n                block_size[1] * geot[-1])\n        return GeoRaster(raster2, geot, nodata_value=self.nodata_value,\\\n                        projection=self.projection, datatype=self.datatype)", "response": "Returns a copy of raster aggregated to smaller resolution by adding cells."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a copy of raster aggregated to smaller resolution by adding cells.", "response": "def block_reduce(self, block_size, how=np.ma.mean):\n        '''\n        geo.block_reduce(block_size, how=func)\n\n        Returns copy of raster aggregated to smaller resolution, by adding cells.\n        Default: func=np.ma.mean\n        '''\n        raster2 = block_reduce(self.raster, block_size, func=how)\n        geot = self.geot\n        geot = (geot[0], block_size[0] * geot[1], geot[2], geot[3], geot[4],\n                block_size[1] * geot[-1])\n        return GeoRaster(raster2, geot, nodata_value=self.nodata_value,\\\n                        projection=self.projection, datatype=self.datatype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize(self, block_size, order=0, mode='constant', cval=False, preserve_range=True):\n        '''\n        geo.resize(new_shape, order=0, mode='constant', cval=np.nan, preserve_range=True)\n\n        Returns resized georaster\n        '''\n        if not cval:\n            cval = np.nan\n        raster2 = resize(self.raster.data, block_size, order=order, mode=mode,\n                         cval=cval, preserve_range=preserve_range)\n        mask = resize(self.raster.mask, block_size, order=order, mode=mode,\n                      cval=cval, preserve_range=preserve_range)\n        raster2 = np.ma.masked_array(raster2, mask=mask, fill_value=self.raster.fill_value)\n        raster2[raster2.mask] = self.nodata_value\n        raster2.mask = np.logical_or(np.isnan(raster2.data), raster2.data == self.nodata_value)\n        geot = list(self.geot)\n        [geot[-1],geot[1]] = np.array([geot[-1], geot[1]])*self.shape/block_size\n        return GeoRaster(raster2, tuple(geot), nodata_value=self.nodata_value,\\\n                        projection=self.projection, datatype=self.datatype)", "response": "Returns a new GeoRaster with the same shape and mask as the current georaster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize_old(self, block_size, order=0, mode='constant', cval=False):\n        '''\n        geo.resize(new_shape, order=0, mode='constant', cval=np.nan, preserve_range=True)\n\n        Returns resized georaster\n        '''\n        if not cval:\n            cval = np.nan\n        if (self.raster.dtype.name.find('float') != -1 and\n            np.max(np.abs([self.max(), self.min()])) > 1):\n            raster2 = (self.raster-self.min())/(self.max()-self.min())\n        else:\n            raster2 = self.raster.copy()\n        raster2 = raster2.astype(float)\n        raster2[self.raster.mask] = np.nan\n        raster2 = resize(raster2, block_size, order=order, mode=mode, cval=cval)\n        raster2 = np.ma.masked_array(raster2, mask=np.isnan(raster2),\n                                     fill_value=self.raster.fill_value)\n        raster2 = raster2*(self.max()-self.min())+self.min()\n        raster2[raster2.mask] = self.nodata_value\n        raster2.mask = np.logical_or(np.isnan(raster2.data), raster2.data == self.nodata_value)\n        geot = list(self.geot)\n        [geot[-1], geot[1]] = np.array([geot[-1], geot[1]])*self.shape/block_size\n        return GeoRaster(raster2, tuple(geot), nodata_value=self.nodata_value,\\\n                        projection=self.projection, datatype=self.datatype)", "response": "Resize the georaster to the new shape."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing neighbor weights for this instance of a GeoRaster.", "response": "def raster_weights(self, **kwargs):\n        \"\"\"\n        Compute neighbor weights for GeoRaster.\n        See help(gr.raster_weights) for options\n\n        Usage:\n        geo.raster_weights(rook=True)\n        \"\"\"\n        if self.weights is None:\n            self.weights = raster_weights(self.raster, **kwargs)\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing Getis and Ord\u2019s G for GeoRaster", "response": "def pysal_G(self, **kwargs):\n        \"\"\"\n        Compute Getis and Ord\u2019s G for GeoRaster\n\n        Usage:\n        geo.pysal_G(permutations = 1000, rook=True)\n\n        arguments passed to raster_weights() and pysal.G\n        See help(gr.raster_weights), help(pysal.G) for options\n        \"\"\"\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.G = pysal.G(rasterf, self.weights, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pysal_Gamma(self, **kwargs):\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.Gamma = pysal.Gamma(rasterf, self.weights, **kwargs)", "response": "Compute Gamma Index of Spatial Autocorrelation for GeoRaster"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pysal_Join_Counts(self, **kwargs):\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.Join_Counts = pysal.Join_Counts(rasterf, self.weights, **kwargs)", "response": "Compute join count statistics for GeoRaster"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute Moran s I measure of global spatial autocorrelation for GeoRaster", "response": "def pysal_Moran(self, **kwargs):\n        \"\"\"\n        Compute Moran's I measure of global spatial autocorrelation for GeoRaster\n\n        Usage:\n        geo.pysal_Moran(permutations = 1000, rook=True)\n\n        arguments passed to raster_weights() and pysal.Moran\n        See help(gr.raster_weights), help(pysal.Moran) for options\n        \"\"\"\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.Moran = pysal.Moran(rasterf, self.weights, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pysal_Geary(self, **kwargs):\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.Geary = pysal.Geary(rasterf, self.weights, **kwargs)", "response": "Compute Geary\u2019s C for GeoRaster"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the Moran s I measure of local spatial autocorrelation for GeoRaster", "response": "def pysal_Moran_Local(self, **kwargs):\n        \"\"\"\n        Compute Local Moran's I measure of local spatial autocorrelation for GeoRaster\n\n        Usage:\n        geo.pysal_Moran_Local(permutations = 1000, rook=True)\n\n        arguments passed to raster_weights() and pysal.Moran_Local\n        See help(gr.raster_weights), help(pysal.Moran_Local) for options\n        \"\"\"\n        if self.weights is None:\n            self.raster_weights(**kwargs)\n        rasterf = self.raster.flatten()\n        rasterf = rasterf[rasterf.mask==False]\n        self.Moran_Local = pysal.Moran_Local(rasterf, self.weights, **kwargs)\n        for i in self.Moran_Local.__dict__.keys():\n            if (isinstance(getattr(self.Moran_Local, i), np.ma.masked_array) or\n                (isinstance(getattr(self.Moran_Local, i), np.ndarray)) and\n                 len(getattr(self.Moran_Local, i).shape) == 1):\n                setattr(self.Moran_Local, i, self.map_vector(getattr(self.Moran_Local, i)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef distance(self, sources, destinations, x='x', y='y', isolation=True,\n                 export_raster=False, export_shape=False, routes=False, path='./'):\n        \"\"\"\n        Compute cost distance measured from each start point to all end points.\n        The function returns the distances between the start point and the end\n        points as a Pandas dataframe. Additionally, for each start point it computes\n        the level of isolation, i.e. its average travel distance to all other locations\n        \"\"\"\n        start_points = sources.copy()\n        end_points = destinations.copy()\n        if (not isinstance(start_points, pd.core.frame.DataFrame) and\n            not isinstance(start_points, gp.geodataframe.GeoDataFrame)):\n            raise TypeError('Sources has to be a (Geo)Pandas Data Frame Object.')\n        if (not isinstance(end_points, pd.core.frame.DataFrame) and\n            not isinstance(end_points, gp.geodataframe.GeoDataFrame)):\n            raise TypeError('Destinations has to be a (Geo)Pandas Data Frame Object.')\n        if not self.mcp_cost:\n            self.mcp()\n        count = 0\n        start_points['row'], start_points['col'] = self.map_pixel_location(start_points[x],\n                                                                           start_points[y])\n        end_points['row'], end_points['col'] = self.map_pixel_location(end_points[x], end_points[y])\n        start_points['ID'] = start_points.index.values\n        end_points['ID'] = end_points.index.values+start_points['ID'].max()+1\n\n        for i in start_points.iterrows():\n            cumulative_costs, traceback = self.mcp_cost.find_costs([[i[1].row, i[1].col]])\n            dist = cumulative_costs[end_points.row.values, end_points.col.values].transpose()/(7*24)\n            df2 = pd.DataFrame(np.array([(i[1]['ID']*np.ones_like(dist)).flatten(),\n                                    end_points['ID'], dist.flatten()]).transpose(),\n                                    columns=['ID1', 'ID2', 'dist'])\n            # Keep only locations that are accessible\n            df2 = df2.loc[df2['dist'] < np.inf]\n            if isolation:\n                grisolation = np.ma.masked_array(cumulative_costs,\n                                    mask=np.logical_or(self.raster.mask, cumulative_costs == np.inf)\n                                    , fill_value=np.nan).mean()/(7*24)\n                start_points.loc[i[0], 'Iso'] = grisolation\n            if export_raster:\n                cumulative_costs = GeoRaster(np.ma.masked_array(cumulative_costs,\n                                                                mask=np.logical_or(self.raster.mask,\n                                                                                   cumulative_costs == np.inf),\n                                                                fill_value=np.nan), self.geot, self.nodata_value,\n                                             projection=self.projection, datatype=self.datatype)\n                cumulative_costs.raster.data[cumulative_costs.raster.mask] = cumulative_costs.nodata_value\n                cumulative_costs.to_tiff(path+str(i[1]['ID']))\n            if df2.size > 0:\n                if export_shape:\n                    routes = True\n                if routes:\n                    df2['geometry'] = df2['ID2'].apply(lambda x:\n                                                self.mcp_cost.traceback(end_points.loc[end_points['ID'] == x][['row', 'col']].values[0]))\n                    df2['geometry'] = df2.geometry.apply(lambda x: [map_pixel_inv(y[0], y[1], self.geot[1],\n                                                    self.geot[-1], self.geot[0], self.geot[-3]) for y in x])\n                    df2['geometry'] = df2.geometry.apply(lambda x: LineString(x) if int(len(x) > 1)\n                                                         else LineString([x[0], x[0]]))\n                    df2 = gp.GeoDataFrame(df2, crs=cea)\n                if isolation:\n                    df2['Iso'] = grisolation\n                if count == 0:\n                    self.grdist = df2.copy()\n                else:\n                    self.grdist = self.grdist.append(df2)\n                count += 1\n        if routes:\n            self.grdist = gp.GeoDataFrame(self.grdist, crs=cea)\n        if export_shape:\n            start_pointscols = sources.columns.values\n            end_pointscols = destinations.columns.values\n            if 'geometry' in end_pointscols:\n                self.grdist = pd.merge(self.grdist, end_points[['ID'] + end_pointscols.tolist()].drop('geometry', axis=1), left_on='ID2', right_on='ID', how='left')\n            else:\n                self.grdist = pd.merge(self.grdist, end_points[['ID']+end_pointscols.tolist()], left_on='ID2', right_on='ID', how='left')\n            if 'geometry' in self.start_pointscols:\n                self.grdist = pd.merge(self.grdist, start_points[['ID']+start_pointscols.tolist()].drop('geometry', axis=1), left_on='ID1', right_on='ID', how='left',\n                             suffixes=['_2', '_1'])\n            else:\n                self.grdist = pd.merge(self.grdist, start_points[['ID']+start_pointscols.tolist()], left_on='ID1', right_on='ID', how='left',\n                             suffixes=['_2', '_1'])\n            self.grdist = gp.GeoDataFrame(self.grdist, crs=cea)\n            self.grdist.to_file(path+'routes.shp')", "response": "Compute the distance between two locations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notify(self, method, params=None):\n        log.debug('Sending notification: %s %s', method, params)\n\n        message = {\n            'jsonrpc': JSONRPC_VERSION,\n            'method': method,\n        }\n        if params is not None:\n            message['params'] = params\n\n        self._consumer(message)", "response": "Send a JSON RPC notification to the client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, method, params=None):\n        msg_id = self._id_generator()\n        log.debug('Sending request with id %s: %s %s', msg_id, method, params)\n\n        message = {\n            'jsonrpc': JSONRPC_VERSION,\n            'id': msg_id,\n            'method': method,\n        }\n        if params is not None:\n            message['params'] = params\n\n        request_future = futures.Future()\n        request_future.add_done_callback(self._cancel_callback(msg_id))\n\n        self._server_request_futures[msg_id] = request_future\n        self._consumer(message)\n\n        return request_future", "response": "Send a JSON RPC request to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cancel_callback(self, request_id):\n        def callback(future):\n            if future.cancelled():\n                self.notify(CANCEL_METHOD, {'id': request_id})\n                future.set_exception(JsonRpcRequestCancelled())\n        return callback", "response": "Construct a cancellation callback for the given request ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconsume a JSON RPC message from the client.", "response": "def consume(self, message):\n        \"\"\"Consume a JSON RPC message from the client.\n\n        Args:\n            message (dict): The JSON RPC message sent by the client\n        \"\"\"\n        if 'jsonrpc' not in message or message['jsonrpc'] != JSONRPC_VERSION:\n            log.warn(\"Unknown message type %s\", message)\n            return\n\n        if 'id' not in message:\n            log.debug(\"Handling notification from client %s\", message)\n            self._handle_notification(message['method'], message.get('params'))\n        elif 'method' not in message:\n            log.debug(\"Handling response from client %s\", message)\n            self._handle_response(message['id'], message.get('result'), message.get('error'))\n        else:\n            try:\n                log.debug(\"Handling request from client %s\", message)\n                self._handle_request(message['id'], message['method'], message.get('params'))\n            except JsonRpcException as e:\n                log.exception(\"Failed to handle request %s\", message['id'])\n                self._consumer({\n                    'jsonrpc': JSONRPC_VERSION,\n                    'id': message['id'],\n                    'error': e.to_dict()\n                })\n            except Exception:  # pylint: disable=broad-except\n                log.exception(\"Failed to handle request %s\", message['id'])\n                self._consumer({\n                    'jsonrpc': JSONRPC_VERSION,\n                    'id': message['id'],\n                    'error': JsonRpcInternalError.of(sys.exc_info()).to_dict()\n                })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_notification(self, method, params):\n        if method == CANCEL_METHOD:\n            self._handle_cancel_notification(params['id'])\n            return\n\n        try:\n            handler = self._dispatcher[method]\n        except KeyError:\n            log.warn(\"Ignoring notification for unknown method %s\", method)\n            return\n\n        try:\n            handler_result = handler(params)\n        except Exception:  # pylint: disable=broad-except\n            log.exception(\"Failed to handle notification %s: %s\", method, params)\n            return\n\n        if callable(handler_result):\n            log.debug(\"Executing async notification handler %s\", handler_result)\n            notification_future = self._executor_service.submit(handler_result)\n            notification_future.add_done_callback(self._notification_callback(method, params))", "response": "Handle a notification from the client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct a callback for the given request ID.", "response": "def _notification_callback(method, params):\n        \"\"\"Construct a notification callback for the given request ID.\"\"\"\n        def callback(future):\n            try:\n                future.result()\n                log.debug(\"Successfully handled async notification %s %s\", method, params)\n            except Exception:  # pylint: disable=broad-except\n                log.exception(\"Failed to handle async notification %s %s\", method, params)\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles a cancel notification from the client.", "response": "def _handle_cancel_notification(self, msg_id):\n        \"\"\"Handle a cancel notification from the client.\"\"\"\n        request_future = self._client_request_futures.pop(msg_id, None)\n\n        if not request_future:\n            log.warn(\"Received cancel notification for unknown message id %s\", msg_id)\n            return\n\n        # Will only work if the request hasn't started executing\n        if request_future.cancel():\n            log.debug(\"Cancelled request with id %s\", msg_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling a request from the client.", "response": "def _handle_request(self, msg_id, method, params):\n        \"\"\"Handle a request from the client.\"\"\"\n        try:\n            handler = self._dispatcher[method]\n        except KeyError:\n            raise JsonRpcMethodNotFound.of(method)\n\n        handler_result = handler(params)\n\n        if callable(handler_result):\n            log.debug(\"Executing async request handler %s\", handler_result)\n            request_future = self._executor_service.submit(handler_result)\n            self._client_request_futures[msg_id] = request_future\n            request_future.add_done_callback(self._request_callback(msg_id))\n        else:\n            log.debug(\"Got result from synchronous request handler: %s\", handler_result)\n            self._consumer({\n                'jsonrpc': JSONRPC_VERSION,\n                'id': msg_id,\n                'result': handler_result\n            })"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct a request callback for the given request ID.", "response": "def _request_callback(self, request_id):\n        \"\"\"Construct a request callback for the given request ID.\"\"\"\n        def callback(future):\n            # Remove the future from the client requests map\n            self._client_request_futures.pop(request_id, None)\n\n            if future.cancelled():\n                future.set_exception(JsonRpcRequestCancelled())\n\n            message = {\n                'jsonrpc': JSONRPC_VERSION,\n                'id': request_id,\n            }\n\n            try:\n                message['result'] = future.result()\n            except JsonRpcException as e:\n                log.exception(\"Failed to handle request %s\", request_id)\n                message['error'] = e.to_dict()\n            except Exception:  # pylint: disable=broad-except\n                log.exception(\"Failed to handle request %s\", request_id)\n                message['error'] = JsonRpcInternalError.of(sys.exc_info()).to_dict()\n\n            self._consumer(message)\n\n        return callback"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a response from the client.", "response": "def _handle_response(self, msg_id, result=None, error=None):\n        \"\"\"Handle a response from the client.\"\"\"\n        request_future = self._server_request_futures.pop(msg_id, None)\n\n        if not request_future:\n            log.warn(\"Received response to unknown message id %s\", msg_id)\n            return\n\n        if error is not None:\n            log.debug(\"Received error response to message %s: %s\", msg_id, error)\n            request_future.set_exception(JsonRpcException.from_dict(error))\n\n        log.debug(\"Received result for message %s: %s\", msg_id, result)\n        request_future.set_result(result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nblock call to listen for messages on the rfile.", "response": "def listen(self, message_consumer):\n        \"\"\"Blocking call to listen for messages on the rfile.\n\n        Args:\n            message_consumer (fn): function that is passed each message as it is read off the socket.\n        \"\"\"\n        while not self._rfile.closed:\n            request_str = self._read_message()\n\n            if request_str is None:\n                break\n\n            try:\n                message_consumer(json.loads(request_str.decode('utf-8')))\n            except ValueError:\n                log.exception(\"Failed to parse JSON message %s\", request_str)\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the contents of a message.", "response": "def _read_message(self):\n        \"\"\"Reads the contents of a message.\n\n        Returns:\n            body of message if parsable else None\n        \"\"\"\n        line = self._rfile.readline()\n\n        if not line:\n            return None\n\n        content_length = self._content_length(line)\n\n        # Blindly consume all header lines\n        while line and line.strip():\n            line = self._rfile.readline()\n\n        if not line:\n            return None\n\n        # Grab the body\n        return self._rfile.read(content_length)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _content_length(line):\n        if line.startswith(b'Content-Length: '):\n            _, value = line.split(b'Content-Length: ')\n            value = value.strip()\n            try:\n                return int(value)\n            except ValueError:\n                raise ValueError(\"Invalid Content-Length header: {}\".format(value))\n\n        return None", "response": "Extract the content length from an input line."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hostapi_info(index=None):\n    if index is None:\n        return (hostapi_info(i) for i in range(_pa.Pa_GetHostApiCount()))\n    else:\n        info = _pa.Pa_GetHostApiInfo(index)\n        if not info:\n            raise RuntimeError(\"Invalid host API\")\n        assert info.structVersion == 1\n        return {'name': ffi.string(info.name).decode(errors='ignore'),\n                'default_input_device': info.defaultInputDevice,\n                'default_output_device': info.defaultOutputDevice}", "response": "Return a generator with information about each host API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef device_info(index=None):\n    if index is None:\n        return (device_info(i) for i in range(_pa.Pa_GetDeviceCount()))\n    else:\n        info = _pa.Pa_GetDeviceInfo(index)\n        if not info:\n            raise RuntimeError(\"Invalid device\")\n        assert info.structVersion == 2\n\n        if 'DirectSound' in hostapi_info(info.hostApi)['name']:\n            enc = 'mbcs'\n        else:\n            enc = 'utf-8'\n\n        return {'name': ffi.string(info.name).decode(encoding=enc,\n                                                     errors='ignore'),\n                'hostapi': info.hostApi,\n                'max_input_channels': info.maxInputChannels,\n                'max_output_channels': info.maxOutputChannels,\n                'default_low_input_latency': info.defaultLowInputLatency,\n                'default_low_output_latency': info.defaultLowOutputLatency,\n                'default_high_input_latency': info.defaultHighInputLatency,\n                'default_high_output_latency': info.defaultHighOutputLatency,\n                'default_samplerate': info.defaultSampleRate}", "response": "Return a generator with information about each device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate NumPy array from a pointer to some memory.", "response": "def _frombuffer(ptr, frames, channels, dtype):\n    \"\"\"Create NumPy array from a pointer to some memory.\"\"\"\n    framesize = channels * dtype.itemsize\n    data = np.frombuffer(ffi.buffer(ptr, frames * framesize), dtype=dtype)\n    data.shape = -1, channels\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit input value into two values.", "response": "def _split(value):\n    \"\"\"Split input/output value into two values.\"\"\"\n    if isinstance(value, str):\n        # iterable, but not meant for splitting\n        return value, value\n    try:\n        invalue, outvalue = value\n    except TypeError:\n        invalue = outvalue = value\n    except ValueError:\n        raise ValueError(\"Only single values and pairs are allowed\")\n    return invalue, outvalue"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommence audio processing. If successful, the stream is considered active.", "response": "def start(self):\n        \"\"\"Commence audio processing.\n\n        If successful, the stream is considered active.\n\n        \"\"\"\n        err = _pa.Pa_StartStream(self._stream)\n        if err == _pa.paStreamIsNotStopped:\n            return\n        self._handle_error(err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self):\n        err = _pa.Pa_StopStream(self._stream)\n        if err == _pa.paStreamIsStopped:\n            return\n        self._handle_error(err)", "response": "Terminate audio processing.\n\n        This waits until all pending audio buffers have been played\n        before it returns. If successful, the stream is considered\n        inactive."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef abort(self):\n        err = _pa.Pa_AbortStream(self._stream)\n        if err == _pa.paStreamIsStopped:\n            return\n        self._handle_error(err)", "response": "Terminate audio processing immediately."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, frames, raw=False):\n        channels, _ = _split(self.channels)\n        dtype, _ = _split(self.dtype)\n        data = ffi.new(\"signed char[]\", channels * dtype.itemsize * frames)\n        self._handle_error(_pa.Pa_ReadStream(self._stream, data, frames))\n        if not raw:\n            data = np.frombuffer(ffi.buffer(data), dtype=dtype)\n            data.shape = frames, channels\n        return data", "response": "Read samples from an input stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, data):\n        frames = len(data)\n        _, channels = _split(self.channels)\n        _, dtype = _split(self.dtype)\n\n        if (not isinstance(data, np.ndarray) or data.dtype != dtype):\n            data = np.array(data, dtype=dtype)\n        if len(data.shape) == 1:\n            # play mono signals on all channels\n            data = np.tile(data, (channels, 1)).T\n        if data.shape[1] > channels:\n            data = data[:, :channels]\n        if data.shape < (frames, channels):\n            # if less data is available than requested, pad with zeros.\n            tmp = data\n            data = np.zeros((frames, channels), dtype=dtype)\n            data[:tmp.shape[0], :tmp.shape[1]] = tmp\n\n        data = data.ravel().tostring()\n        err = _pa.Pa_WriteStream(self._stream, data, frames)\n        self._handle_error(err)", "response": "Write samples to an output stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommand 'supervisord shell' runs the interactive command shell.", "response": "def _handle_shell(self,cfg_file,*args,**options):\n        \"\"\"Command 'supervisord shell' runs the interactive command shell.\"\"\"\n        args = (\"--interactive\",) + args\n        return supervisorctl.main((\"-c\",cfg_file) + args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the getconfig subcommand", "response": "def _handle_getconfig(self,cfg_file,*args,**options):\n        \"\"\"Command 'supervisor getconfig' prints merged config to stdout.\"\"\"\n        if args:\n            raise CommandError(\"supervisor getconfig takes no arguments\")\n        print cfg_file.read()\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_autoreload(self,cfg_file,*args,**options):\n        if args:\n            raise CommandError(\"supervisor autoreload takes no arguments\")\n        live_dirs = self._find_live_code_dirs()\n        reload_progs = self._get_autoreload_programs(cfg_file)\n\n        def autoreloader():\n            \"\"\"\n            Forks a subprocess to make the restart call.\n            Otherwise supervisord might kill us and cancel the restart!\n            \"\"\"\n            if os.fork() == 0:\n                sys.exit(self.handle(\"restart\", *reload_progs, **options))\n\n        # Call the autoreloader callback whenever a .py file changes.\n        # To prevent thrashing, limit callbacks to one per second.\n        handler = CallbackModifiedHandler(callback=autoreloader,\n                                          repeat_delay=1,\n                                          patterns=AUTORELOAD_PATTERNS,\n                                          ignore_patterns=AUTORELOAD_IGNORE,\n                                          ignore_directories=True)\n\n        # Try to add watches using the platform-specific observer.\n        # If this fails, print a warning and fall back to the PollingObserver.\n        # This will avoid errors with e.g. too many inotify watches.\n        from watchdog.observers import Observer\n        from watchdog.observers.polling import PollingObserver\n        \n        observer = None\n        for ObserverCls in (Observer, PollingObserver):\n            observer = ObserverCls()\n            try:\n                for live_dir in set(live_dirs):\n                    observer.schedule(handler, live_dir, True)\n                break\n            except Exception:\n                print>>sys.stderr, \"COULD NOT WATCH FILESYSTEM USING\"\n                print>>sys.stderr, \"OBSERVER CLASS: \", ObserverCls\n                traceback.print_exc()\n                observer.start()\n                observer.stop()\n\n        # Fail out if none of the observers worked.\n        if observer is None:\n            print>>sys.stderr, \"COULD NOT WATCH FILESYSTEM\"\n            return 1\n\n        # Poll if we have an observer.\n        # TODO: Is this sleep necessary?  Or will it suffice\n        # to block indefinitely on something and wait to be killed?\n        observer.start()\n        try:\n            while True:\n                time.sleep(1)\n        except KeyboardInterrupt:\n            observer.stop()\n        observer.join()\n        return 0", "response": "This method is called by the autoreload command. It will watch all python files that have been loaded at startup and restarts the process if they are not already loaded."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_autoreload_programs(self,cfg_file):\n        cfg = RawConfigParser()\n        cfg.readfp(cfg_file)\n        reload_progs = []\n        for section in cfg.sections():\n            if section.startswith(\"program:\"):\n                try:\n                    if cfg.getboolean(section,\"autoreload\"):\n                        reload_progs.append(section.split(\":\",1)[1])\n                except NoOptionError:\n                    pass\n        return reload_progs", "response": "Get the set of programs to auto - reload when code changes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding all directories in which we might have live python code.", "response": "def _find_live_code_dirs(self):\n        \"\"\"Find all directories in which we might have live python code.\n\n        This walks all of the currently-imported modules and adds their\n        containing directory to the list of live dirs.  After normalization\n        and de-duplication, we get a pretty good approximation of the\n        directories on sys.path that are actively in use.\n        \"\"\"\n        live_dirs = []\n        for mod in sys.modules.values():\n            #  Get the directory containing that module.\n            #  This is deliberately casting a wide net.\n            try:\n                dirnm = os.path.dirname(mod.__file__)\n            except AttributeError:\n                continue\n            #  Normalize it for comparison purposes.\n            dirnm = os.path.realpath(os.path.abspath(dirnm))\n            if not dirnm.endswith(os.sep):\n                dirnm += os.sep\n            #  Check that it's not an egg or some other wierdness\n            if not os.path.isdir(dirnm):\n                continue\n            #  If it's a subdir of one we've already found, ignore it.\n            for dirnm2 in live_dirs:\n                if dirnm.startswith(dirnm2):\n                    break\n            else:\n                #  Remove any ones we've found that are subdirs of it.\n                live_dirs = [dirnm2 for dirnm2 in live_dirs\\\n                                    if not dirnm2.startswith(dirnm)]\n                live_dirs.append(dirnm)\n        return live_dirs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_merged_config(**options):\n    #  Find and load the containing project module.\n    #  This can be specified explicity using the --project-dir option.\n    #  Otherwise, we attempt to guess by looking for the manage.py file.\n    project_dir = options.get(\"project_dir\")\n    if project_dir is None:\n        project_dir = guess_project_dir()\n    # Find the config file to load.\n    # Default to <project-dir>/supervisord.conf.\n    config_file = options.get(\"config_file\")\n    if config_file is None:\n        config_file = os.path.join(project_dir,CONFIG_FILE)\n    #  Build the default template context variables.\n    #  This is mostly useful information about the project and environment.\n    ctx = {\n        \"PROJECT_DIR\": project_dir,\n        \"PYTHON\": os.path.realpath(os.path.abspath(sys.executable)),\n        \"SUPERVISOR_OPTIONS\": rerender_options(options),\n        \"settings\": settings,\n        \"environ\": os.environ,\n    }\n    #  Initialise the ConfigParser.\n    #  Fortunately for us, ConfigParser has merge-multiple-config-files\n    #  functionality built into it.  You just read each file in turn, and\n    #  values from later files overwrite values from former.\n    cfg = RawConfigParser()\n    #  Start from the default configuration options.\n    data = render_config(DEFAULT_CONFIG,ctx)\n    cfg.readfp(StringIO(data))\n    #  Add in the project-specific config file.\n    with open(config_file,\"r\") as f:\n        data = render_config(f.read(),ctx)\n    cfg.readfp(StringIO(data))\n    #  Add in the options specified on the command-line.\n    cfg.readfp(StringIO(get_config_from_options(**options)))\n    #  Add options from [program:__defaults__] to each program section\n    #  if it happens to be missing that option.\n    PROG_DEFAULTS = \"program:__defaults__\"\n    if cfg.has_section(PROG_DEFAULTS):\n        for option in cfg.options(PROG_DEFAULTS):\n            default = cfg.get(PROG_DEFAULTS,option)\n            for section in cfg.sections():\n                if section.startswith(\"program:\"):\n                    if not cfg.has_option(section,option):\n                        cfg.set(section,option,default)\n        cfg.remove_section(PROG_DEFAULTS)\n    #  Add options from [program:__overrides__] to each program section\n    #  regardless of whether they already have that option.\n    PROG_OVERRIDES = \"program:__overrides__\"\n    if cfg.has_section(PROG_OVERRIDES):\n        for option in cfg.options(PROG_OVERRIDES):\n            override = cfg.get(PROG_OVERRIDES,option)\n            for section in cfg.sections():\n                if section.startswith(\"program:\"):\n                    cfg.set(section,option,override)\n        cfg.remove_section(PROG_OVERRIDES)\n    #  Make sure we've got a port configured for supervisorctl to\n    #  talk to supervisord.  It's passworded based on secret key.\n    #  If they have configured a unix socket then use that, otherwise\n    #  use an inet server on localhost at fixed-but-randomish port.\n    username = hashlib.md5(settings.SECRET_KEY).hexdigest()[:7]\n    password = hashlib.md5(username).hexdigest()\n    if cfg.has_section(\"unix_http_server\"):\n        set_if_missing(cfg,\"unix_http_server\",\"username\",username)\n        set_if_missing(cfg,\"unix_http_server\",\"password\",password)\n        serverurl = \"unix://\" + cfg.get(\"unix_http_server\",\"file\")\n    else:\n        #  This picks a \"random\" port in the 9000 range to listen on.\n        #  It's derived from the secret key, so it's stable for a given\n        #  project but multiple projects are unlikely to collide.\n        port = int(hashlib.md5(password).hexdigest()[:3],16) % 1000\n        addr = \"127.0.0.1:9%03d\" % (port,)\n        set_if_missing(cfg,\"inet_http_server\",\"port\",addr)\n        set_if_missing(cfg,\"inet_http_server\",\"username\",username)\n        set_if_missing(cfg,\"inet_http_server\",\"password\",password)\n        serverurl = \"http://\" + cfg.get(\"inet_http_server\",\"port\")\n    set_if_missing(cfg,\"supervisorctl\",\"serverurl\",serverurl)\n    set_if_missing(cfg,\"supervisorctl\",\"username\",username)\n    set_if_missing(cfg,\"supervisorctl\",\"password\",password)\n    set_if_missing(cfg,\"rpcinterface:supervisor\",\n                       \"supervisor.rpcinterface_factory\",\n                       \"supervisor.rpcinterface:make_main_rpcinterface\")\n    #  Remove any [program:] sections with exclude=true\n    for section in cfg.sections():\n        try:\n            if cfg.getboolean(section,\"exclude\"):\n                cfg.remove_section(section)\n        except NoOptionError:\n            pass\n    #  Sanity-check to give better error messages.\n    for section in cfg.sections():\n        if section.startswith(\"program:\"):\n            if not cfg.has_option(section,\"command\"):\n                msg = \"Process name '%s' has no command configured\"\n                raise ValueError(msg % (section.split(\":\",1)[-1]))\n    #  Write it out to a StringIO and return the data\n    s = StringIO()\n    cfg.write(s)\n    return s.getvalue()", "response": "This function returns the final merged configuration for supvervisord."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_config(data,ctx):\n    djsupervisor_tags.current_context = ctx\n    data = \"{% load djsupervisor_tags %}\" + data\n    t = template.Template(data)\n    c = template.Context(ctx)\n    return t.render(c).encode(\"ascii\")", "response": "Render the given config data using Django s template system."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the config file fragment reflecting command - line options.", "response": "def get_config_from_options(**options):\n    \"\"\"Get config file fragment reflecting command-line options.\"\"\"\n    data = []\n    #  Set whether or not to daemonize.\n    #  Unlike supervisord, our default is to stay in the foreground.\n    data.append(\"[supervisord]\\n\")\n    if options.get(\"daemonize\",False):\n        data.append(\"nodaemon=false\\n\")\n    else:\n        data.append(\"nodaemon=true\\n\")\n    if options.get(\"pidfile\",None):\n        data.append(\"pidfile=%s\\n\" % (options[\"pidfile\"],))\n    if options.get(\"logfile\",None):\n        data.append(\"logfile=%s\\n\" % (options[\"logfile\"],))\n    #  Set which programs to launch automatically on startup.\n    for progname in options.get(\"launch\",None) or []:\n        data.append(\"[program:%s]\\nautostart=true\\n\" % (progname,))\n    for progname in options.get(\"nolaunch\",None) or []:\n        data.append(\"[program:%s]\\nautostart=false\\n\" % (progname,))\n    #  Set which programs to include/exclude from the config\n    for progname in options.get(\"include\",None) or []:\n        data.append(\"[program:%s]\\nexclude=false\\n\" % (progname,))\n    for progname in options.get(\"exclude\",None) or []:\n        data.append(\"[program:%s]\\nexclude=true\\n\" % (progname,))\n    #  Set which programs to autoreload when code changes.\n    #  When this option is specified, the default for all other\n    #  programs becomes autoreload=false.\n    if options.get(\"autoreload\",None):\n        data.append(\"[program:autoreload]\\nexclude=false\\nautostart=true\\n\")\n        data.append(\"[program:__defaults__]\\nautoreload=false\\n\")\n        for progname in options[\"autoreload\"]:\n            data.append(\"[program:%s]\\nautoreload=true\\n\" % (progname,))\n    #  Set whether to use the autoreloader at all.\n    if options.get(\"noreload\",False):\n        data.append(\"[program:autoreload]\\nexclude=true\\n\")\n    return \"\".join(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef guess_project_dir():\n    projname = settings.SETTINGS_MODULE.split(\".\",1)[0]\n    projmod = import_module(projname)\n    projdir = os.path.dirname(projmod.__file__)\n\n    # For Django 1.3 and earlier, the manage.py file was located\n    # in the same directory as the settings file.\n    if os.path.isfile(os.path.join(projdir,\"manage.py\")):\n        return projdir\n\n    # For Django 1.4 and later, the manage.py file is located in\n    # the directory *containing* the settings file.\n    projdir = os.path.abspath(os.path.join(projdir, os.path.pardir))\n    if os.path.isfile(os.path.join(projdir,\"manage.py\")):\n        return projdir\n\n    msg = \"Unable to determine the Django project directory;\"\\\n          \" use --project-dir to specify it\"\n    raise RuntimeError(msg)", "response": "Find the top - level Django project directory based on the current environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_if_missing(cfg,section,option,value):\n    try:\n        cfg.get(section,option)\n    except NoSectionError:\n        cfg.add_section(section)\n        cfg.set(section,option,value)\n    except NoOptionError:\n        cfg.set(section,option,value)", "response": "Set the given option to the given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlogging the user in and setups the private token with the private token", "response": "def login(self, email=None, password=None, user=None):\n        \"\"\"\n        Logs the user in and setups the header with the private token\n\n        :param email: Gitlab user Email\n        :param user: Gitlab username\n        :param password: Gitlab user password\n        :return: True if login successful\n        :raise: HttpError\n        :raise: ValueError\n        \"\"\"\n        if user is not None:\n            data = {'login': user, 'password': password}\n        elif email is not None:\n            data = {'email': email, 'password': password}\n        else:\n            raise ValueError('Neither username nor email provided to login')\n\n        self.headers = {'connection': 'close'}\n        response = self.post('/session', **data)\n\n        self.token = response['private_token']\n        self.headers = {'PRIVATE-TOKEN': self.token,\n                        'connection': 'close'}\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of users from Gitlab server", "response": "def get_users(self, search=None, page=1, per_page=20, **kwargs):\n        \"\"\"\n        Returns a list of users from the Gitlab server\n\n        :param search: Optional search query\n        :param page: Page number (default: 1)\n        :param per_page: Number of items to list per page (default: 20, max: 100)\n        :return: List of Dictionaries containing users\n        :raise: HttpError if invalid response returned\n        \"\"\"\n        if search:\n            return self.get('/users', page=page, per_page=per_page, search=search, **kwargs)\n\n        return self.get('/users', page=page, per_page=per_page, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getusers(self, search=None, page=1, per_page=20, **kwargs):\n        return self.get_users(search=search, page=page, per_page=per_page, **kwargs)", "response": "Returns a list of users from Gitlab server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets info for a user identified by id", "response": "def getuser(self, user_id):\n        \"\"\"\n        Get info for a user identified by id\n\n        :param user_id: id of the user\n        :return: False if not found, a dictionary if found\n        \"\"\"\n        request = requests.get(\n            '{0}/{1}'.format(self.users_url, user_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createuser(self, name, username, password, email, **kwargs):\n        data = {'name': name, 'username': username, 'password': password, 'email': email}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.post(\n            self.users_url, headers=self.headers, data=data,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        elif request.status_code == 404:\n            return False", "response": "Create a user in the Gitlab API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deleteuser(self, user_id):\n        deleted = self.delete_user(user_id)\n\n        if deleted is False:\n            return False\n        else:\n            return True", "response": "Deletes a user from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current user parameters. The current user is linked to the secret token", "response": "def currentuser(self):\n        \"\"\"\n        Returns the current user parameters. The current user is linked to the secret token\n\n        :return: a list with the current user properties\n        \"\"\"\n        request = requests.get(\n            '{0}/api/v3/user'.format(self.host),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits an user data.", "response": "def edituser(self, user_id, **kwargs):\n        \"\"\"\n        Edits an user data.\n\n        :param user_id: id of the user to change\n        :param kwargs: Any param the the Gitlab API supports\n        :return: Dict of the user\n        \"\"\"\n        data = {}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.put(\n            '{0}/{1}'.format(self.users_url, user_id),\n            headers=self.headers, data=data, timeout=self.timeout, verify=self.verify_ssl, auth=self.auth)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all the ssh keys for the current user", "response": "def getsshkeys(self):\n        \"\"\"\n        Gets all the ssh keys for the current user\n\n        :return: a dictionary with the lists\n        \"\"\"\n        request = requests.get(\n            self.keys_url, headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addsshkey(self, title, key):\n        data = {'title': title, 'key': key}\n\n        request = requests.post(\n            self.keys_url, headers=self.headers, data=data,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False", "response": "Add a new ssh key for the current user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addsshkeyuser(self, user_id, title, key):\n        data = {'title': title, 'key': key}\n\n        request = requests.post(\n            '{0}/{1}/keys'.format(self.users_url, user_id), headers=self.headers,\n            data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False", "response": "Add a new ssh key for the user identified by iduser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting an sshkey for the current user identified by id", "response": "def deletesshkey(self, key_id):\n        \"\"\"\n        Deletes an sshkey for the current user identified by id\n\n        :param key_id: the id of the key\n        :return: False if it didn't delete it, True if it was deleted\n        \"\"\"\n        request = requests.delete(\n            '{0}/{1}'.format(self.keys_url, key_id), headers=self.headers,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.content == b'null':\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, uri, default_response=None, **kwargs):\n        url = self.api_url + uri\n        response = requests.get(url, params=kwargs, headers=self.headers,\n                                verify=self.verify_ssl, auth=self.auth,\n                                timeout=self.timeout)\n\n        return self.success_or_raise(response, default_response=default_response)", "response": "Call GET on Gitlab server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, uri, default_response=None, **kwargs):\n        url = self.api_url + uri\n\n        response = requests.post(\n            url, headers=self.headers, data=kwargs,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return self.success_or_raise(response, default_response=default_response)", "response": "Call POST on Gitlab server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the specified object from the server.", "response": "def delete(self, uri, default_response=None):\n        \"\"\"\n        Call DELETE on the Gitlab server\n\n        >>> gitlab = Gitlab(host='http://localhost:10080', verify_ssl=False)\n        >>> gitlab.login(user='root', password='5iveL!fe')\n        >>> gitlab.delete('/users/5')\n\n        :param uri: String with the URI you wish to delete\n        :param default_response: Return value if JSONDecodeError\n        :return: Dictionary containing response data\n        :raise: HttpError: If invalid response returned\n        \"\"\"\n        url = self.api_url + uri\n        response = requests.delete(\n            url, headers=self.headers, verify=self.verify_ssl,\n            auth=self.auth, timeout=self.timeout)\n\n        return self.success_or_raise(response, default_response=default_response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef success_or_raise(self, response, default_response=None):\n        if self.suppress_http_error and not response.ok:\n            return False\n\n        response_json = default_response\n        if response_json is None:\n            response_json = {}\n\n        response.raise_for_status()\n\n        try:\n            response_json = response.json()\n        except ValueError:\n            pass\n\n        return response_json", "response": "Checks if the request was successful or raises an HttpError."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setsudo(self, user=None):\n        if user is None:\n            try:\n                self.headers.pop('SUDO')\n            except KeyError:\n                pass\n        else:\n            self.headers['SUDO'] = user", "response": "Set the subsequent API calls to the user provided"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_project(self, project):\n        project = format_string(project)\n\n        return self.get(\n            '/projects/{project}'.format(project=project))", "response": "Get info for a project"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new project owned by the authenticated user.", "response": "def createproject(self, name, **kwargs):\n        \"\"\"\n        Creates a new project owned by the authenticated user.\n\n        :param name: new project name\n        :param path: custom repository name for new project. By default generated based on name\n        :param namespace_id: namespace for the new project (defaults to user)\n        :param description: short project description\n        :param issues_enabled:\n        :param merge_requests_enabled:\n        :param wiki_enabled:\n        :param snippets_enabled:\n        :param public: if true same as setting visibility_level = 20\n        :param visibility_level:\n        :param sudo:\n        :param import_url:\n        :return:\n        \"\"\"\n        data = {'name': name}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.post(\n            self.projects_url, headers=self.headers, data=data,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        elif request.status_code == 403:\n            if 'Your own projects limit is 0' in request.text:\n                print(request.text)\n                return False\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nediting an existing project.", "response": "def editproject(self, project_id, **kwargs):\n        \"\"\"\n        Edit an existing project.\n\n        :param name: new project name\n        :param path: custom repository name for new project. By default generated based on name\n        :param default_branch: they default branch\n        :param description: short project description\n        :param issues_enabled:\n        :param merge_requests_enabled:\n        :param wiki_enabled:\n        :param snippets_enabled:\n        :param public: if true same as setting visibility_level = 20\n        :param visibility_level:\n        :return:\n        \"\"\"\n        data = {\"id\": project_id}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.put(\n            '{0}/{1}'.format(self.projects_url, project_id), headers=self.headers,\n            data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True\n        elif request.status_code == 400:\n            if \"Your param's are invalid\" in request.text:\n                print(request.text)\n                return False\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow to share project with group.", "response": "def shareproject(self, project_id, group_id, group_access):\n        \"\"\"\n        Allow to share project with group.\n\n        :param project_id: The ID of a project\n        :param group_id: The ID of a group\n        :param group_access: Level of permissions for sharing\n        :return: True is success\n        \"\"\"\n        data = {'id': project_id, 'group_id': group_id, 'group_access': group_access}\n\n        request = requests.post(\n            '{0}/{1}/share'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl)\n\n        return request.status_code == 201"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a project from the Gitlab server", "response": "def delete_project(self, id):\n        \"\"\"\n        Delete a project from the Gitlab server\n\n        Gitlab currently returns a Boolean True if the deleted and as such we return an\n        empty Dictionary\n\n        :param id: The ID of the project or NAMESPACE/PROJECT_NAME\n        :return: Dictionary\n        :raise: HttpError: If invalid response returned\n        \"\"\"\n        url = '/projects/{id}'.format(id=id)\n\n        response = self.delete(url)\n        if response is True:\n            return {}\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createprojectuser(self, user_id, name, **kwargs):\n        data = {'name': name}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.post(\n            '{0}/user/{1}'.format(self.projects_url, user_id), headers=self.headers,\n            data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n\n            return False", "response": "Creates a new project owned by the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addprojectmember(self, project_id, user_id, access_level):\n        # if isinstance(access_level, basestring):\n        if access_level.lower() == 'master':\n            access_level = 40\n        elif access_level.lower() == 'developer':\n            access_level = 30\n        elif access_level.lower() == 'reporter':\n            access_level = 20\n        else:\n            access_level = 10\n\n        data = {'id': project_id, 'user_id': user_id, 'access_level': access_level}\n\n        request = requests.post(\n            '{0}/{1}/members'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False", "response": "Adds a project member to a project"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a project member", "response": "def deleteprojectmember(self, project_id, user_id):\n        \"\"\"Delete a project member\n\n        :param project_id: project id\n        :param user_id: user id\n        :return: always true\n        \"\"\"\n        request = requests.delete(\n            '{0}/{1}/members/{2}'.format(self.projects_url, project_id, user_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a project hook to a project", "response": "def addprojecthook(self, project_id, url, push=False, issues=False, merge_requests=False, tag_push=False):\n        \"\"\"\n        add a hook to a project\n\n        :param project_id: project id\n        :param url: url of the hook\n        :return: True if success\n        \"\"\"\n        data = {\n            'id': project_id,\n            'url': url,\n            'push_events': int(bool(push)),\n            'issues_events': int(bool(issues)),\n            'merge_requests_events': int(bool(merge_requests)),\n            'tag_push_events': int(bool(tag_push)),\n        }\n\n        request = requests.post(\n            '{0}/{1}/hooks'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef editprojecthook(self, project_id, hook_id, url, push=False, issues=False, merge_requests=False, tag_push=False):\n        data = {\n            \"id\": project_id,\n            \"hook_id\": hook_id,\n            \"url\": url,\n            'push_events': int(bool(push)),\n            'issues_events': int(bool(issues)),\n            'merge_requests_events': int(bool(merge_requests)),\n            'tag_push_events': int(bool(tag_push)),\n        }\n\n        request = requests.put(\n            '{0}/{1}/hooks/{2}'.format(self.projects_url, project_id, hook_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True\n        else:\n            return False", "response": "Edit an existing hook from a project"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getsystemhooks(self, page=1, per_page=20):\n        data = {'page': page, 'per_page': per_page}\n\n        request = requests.get(\n            self.hook_url, params=data, headers=self.headers,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Get all system hooks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a system hook to the current system", "response": "def addsystemhook(self, url):\n        \"\"\"\n        Add a system hook\n\n        :param url: url of the hook\n        :return: True if success\n        \"\"\"\n        data = {\"url\": url}\n\n        request = requests.post(\n            self.hook_url, headers=self.headers, data=data,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a project hook", "response": "def deletesystemhook(self, hook_id):\n        \"\"\"\n        Delete a project hook\n\n        :param hook_id: hook id\n        :return: True if success\n        \"\"\"\n        data = {\"id\": hook_id}\n\n        request = requests.delete(\n            '{0}/{1}'.format(self.hook_url, hook_id), data=data,\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating branch from commit SHA or existing branch", "response": "def createbranch(self, project_id, branch, ref):\n        \"\"\"\n        Create branch from commit SHA or existing branch\n\n        :param project_id:  The ID of a project\n        :param branch: The name of the branch\n        :param ref: Create branch from commit SHA or existing branch\n        :return: True if success, False if not\n        \"\"\"\n        data = {\"id\": project_id, \"branch_name\": branch, \"ref\": ref}\n\n        request = requests.post(\n            '{0}/{1}/repository/branches'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef protectbranch(self, project_id, branch):\n        request = requests.put(\n            '{0}/{1}/repository/branches/{2}/protect'.format(self.projects_url, project_id, branch),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True\n        else:\n            return False", "response": "Protect a branch from changes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a fork relation between 2 repositories.", "response": "def createforkrelation(self, project_id, from_project_id):\n        \"\"\"\n        Create a fork relation.\n\n        This DO NOT create a fork but only adds a link as fork the relation between 2 repositories\n\n        :param project_id: project id\n        :param from_project_id: from id\n        :return: true if success\n        \"\"\"\n        data = {'id': project_id, 'forked_from_id': from_project_id}\n\n        request = requests.post(\n            '{0}/{1}/fork/{2}'.format(self.projects_url, project_id, from_project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl,\n            auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef removeforkrelation(self, project_id):\n        request = requests.delete(\n            '{0}/{1}/fork'.format(self.projects_url, project_id),\n            headers=self.headers, verify=self.verify_ssl,\n            auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True\n        else:\n            return False", "response": "This method removes an existing fork relation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createfork(self, project_id):\n\n        request = requests.post(\n            '{0}/fork/{1}'.format(self.projects_url, project_id),\n            timeout=self.timeout, verify=self.verify_ssl)\n\n        if request.status_code == 200:\n            return True\n        else:\n            return False", "response": "Forks a project into the user namespace of the authenticated user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new issue with the given title", "response": "def createissue(self, project_id, title, **kwargs):\n        \"\"\"\n        Create a new issue\n\n        :param project_id: project id\n        :param title: title of the issue\n        :return: dict with the issue created\n        \"\"\"\n        data = {'id': id, 'title': title}\n        if kwargs:\n            data.update(kwargs)\n        request = requests.post(\n            '{0}/{1}/issues'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nedit an existing issue", "response": "def editissue(self, project_id, issue_id, **kwargs):\n        \"\"\"\n        Edit an existing issue data\n\n        :param project_id: project id\n        :param issue_id: issue id\n        :return: true if success\n        \"\"\"\n        data = {'id': project_id, 'issue_id': issue_id}\n        if kwargs:\n            data.update(kwargs)\n        request = requests.put(\n            '{0}/{1}/issues/{2}'.format(self.projects_url, project_id, issue_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables a deploy key for a project.", "response": "def enable_deploy_key(self, project, key_id):\n        \"\"\"\n        Enables a deploy key for a project.\n\n        >>> gitlab = Gitlab(host='http://localhost:10080', verify_ssl=False)\n        >>> gitlab.login(user='root', password='5iveL!fe')\n        >>> gitlab.enable_deploy_key(15, 5)\n\n        :param project: The ID or URL-encoded path of the project owned by the authenticated user\n        :param key_id: The ID of the deploy key\n        :return: A dictionary containing deploy key details\n        :raise: HttpError: If invalid response returned\n        \"\"\"\n        url = '/projects/{project}/deploy_keys/{key_id}/enable'.format(\n            project=project, key_id=key_id)\n        return self.post(url, default_response={})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adddeploykey(self, project_id, title, key):\n        data = {'id': project_id, 'title': title, 'key': key}\n\n        request = requests.post(\n            '{0}/{1}/keys'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Adds a new deploy key for a project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef creategroup(self, name, path, **kwargs):\n        data = {'name': name, 'path': path}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.post(\n            self.groups_url, data=data, headers=self.headers,\n            verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            msg = request.json()['message']\n            raise exceptions.HttpError(msg)", "response": "Creates a new group with the given name and path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef moveproject(self, group_id, project_id):\n        request = requests.post(\n            '{0}/{1}/projects/{2}'.format(self.groups_url, group_id, project_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Move a given project into a given group"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getmergerequests(self, project_id, page=1, per_page=20, state=None):\n        data = {'page': page, 'per_page': per_page, 'state': state}\n\n        request = requests.get(\n            '{0}/{1}/merge_requests'.format(self.projects_url, project_id),\n            params=data, headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Get all the merge requests for a project."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getmergerequest(self, project_id, mergerequest_id):\n        request = requests.get(\n            '{0}/{1}/merge_request/{2}'.format(self.projects_url, project_id, mergerequest_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Get information about a specific merge request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createmergerequest(self, project_id, sourcebranch, targetbranch,\n                           title, target_project_id=None, assignee_id=None):\n        \"\"\"\n        Create a new merge request.\n\n        :param project_id: ID of the project originating the merge request\n        :param sourcebranch: name of the branch to merge from\n        :param targetbranch: name of the branch to merge to\n        :param title: Title of the merge request\n        :param assignee_id: Assignee user ID\n        :return: dict of the new merge request\n        \"\"\"\n        data = {\n            'source_branch': sourcebranch,\n            'target_branch': targetbranch,\n            'title': title,\n            'assignee_id': assignee_id,\n            'target_project_id': target_project_id\n        }\n\n        request = requests.post(\n            '{0}/{1}/merge_requests'.format(self.projects_url, project_id),\n            data=data, headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Create a new merge request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating an existing merge request.", "response": "def acceptmergerequest(self, project_id, mergerequest_id, merge_commit_message=None):\n        \"\"\"\n        Update an existing merge request.\n\n        :param project_id: ID of the project originating the merge request\n        :param mergerequest_id: ID of the merge request to accept\n        :param merge_commit_message: Custom merge commit message\n        :return: dict of the modified merge request\n        \"\"\"\n\n        data = {'merge_commit_message': merge_commit_message}\n\n        request = requests.put(\n            '{0}/{1}/merge_request/{2}/merge'.format(self.projects_url, project_id, mergerequest_id),\n            data=data, headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addcommenttomergerequest(self, project_id, mergerequest_id, note):\n        request = requests.post(\n            '{0}/{1}/merge_request/{2}/comments'.format(self.projects_url, project_id, mergerequest_id),\n            data={'note': note}, headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 201", "response": "Add a comment to a merge request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new snippet under the key - value store.", "response": "def createsnippet(self, project_id, title, file_name, code, visibility_level=0):\n        \"\"\"\n        Creates an snippet\n\n        :param project_id: project id to create the snippet under\n        :param title: title of the snippet\n        :param file_name: filename for the snippet\n        :param code: content of the snippet\n        :param visibility_level: snippets can be either private (0), internal(10) or public(20)\n        :return: True if correct, false if failed\n        \"\"\"\n        data = {'id': project_id, 'title': title, 'file_name': file_name, 'code': code}\n\n        if visibility_level in [0, 10, 20]:\n            data['visibility_level'] = visibility_level\n\n        request = requests.post(\n            '{0}/{1}/snippets'.format(self.projects_url, project_id),\n            data=data, verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a given snippet from a given project.", "response": "def deletesnippet(self, project_id, snippet_id):\n        \"\"\"Deletes a given snippet\n\n        :param project_id: project_id\n        :param snippet_id: snippet id\n        :return: True if success\n        \"\"\"\n        request = requests.delete(\n            '{0}/{1}/snippets/{2}'.format(self.projects_url, project_id, snippet_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unprotectrepositorybranch(self, project_id, branch):\n        request = requests.put(\n            '{0}/{1}/repository/branches/{2}/unprotect'.format(self.projects_url, project_id, branch),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return", "response": "Unprotects a single project repository branch. This is an idempotent function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createrepositorytag(self, project_id, tag_name, ref, message=None):\n\n        data = {'id': project_id, 'tag_name': tag_name, 'ref': ref, 'message': message}\n        request = requests.post(\n            '{0}/{1}/repository/tags'.format(self.projects_url, project_id), data=data,\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Creates a new tag in the repository that points to the supplied ref."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_repository_tag(self, project_id, tag_name):\n        return self.delete('/projects/{project_id}/repository/tags/{tag_name}'.format(\n            project_id=project_id, tag_name=tag_name))", "response": "Delete a tag of a repository with given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addcommenttocommit(self, project_id, author, sha, path, line, note):\n\n        data = {\n            'author': author,\n            'note': note,\n            'path': path,\n            'line': line,\n            'line_type': 'new'\n        }\n\n        request = requests.post(\n            '{0}/{1}/repository/commits/{2}/comments'.format(self.projects_url, project_id, sha),\n            headers=self.headers, data=data, verify=self.verify_ssl)\n\n        if request.status_code == 201:\n            return True\n        else:\n            return False", "response": "Adds an inline comment to a specific commit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of repository files and directories in a project.", "response": "def getrepositorytree(self, project_id, **kwargs):\n        \"\"\"\n        Get a list of repository files and directories in a project.\n\n        :param project_id: The ID of a project\n        :param path: The path inside repository. Used to get contend of subdirectories\n        :param ref_name: The name of a repository branch or tag or if not given the default branch\n        :return: dict with the tree\n        \"\"\"\n        data = {}\n\n        if kwargs:\n            data.update(kwargs)\n\n        request = requests.get(\n            '{0}/{1}/repository/tree'.format(self.projects_url, project_id), params=data,\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the raw file contents for a file by commit SHA and path.", "response": "def getrawfile(self, project_id, sha1, filepath):\n        \"\"\"\n        Get the raw file contents for a file by commit SHA and path.\n\n        :param project_id: The ID of a project\n        :param sha1: The commit or branch name\n        :param filepath: The path the file\n        :return: raw file contents\n        \"\"\"\n        data = {'filepath': filepath}\n\n        request = requests.get(\n            '{0}/{1}/repository/blobs/{2}'.format(self.projects_url, project_id, sha1),\n            params=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout,\n            headers=self.headers)\n\n        if request.status_code == 200:\n            return request.content\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getrawblob(self, project_id, sha1):\n        request = requests.get(\n            '{0}/{1}/repository/raw_blobs/{2}'.format(self.projects_url, project_id, sha1),\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.content\n        else:\n            return False", "response": "Get the raw file contents for a blob by sha1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare_branches_tags_commits(self, project_id, from_id, to_id):\n        data = {'from': from_id, 'to': to_id}\n\n        request = requests.get(\n            '{0}/{1}/repository/compare'.format(self.projects_url, project_id),\n            params=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout,\n            headers=self.headers)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Compare branches tags or commits"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef searchproject(self, search, page=1, per_page=20):\n        data = {'page': page, 'per_page': per_page}\n        request = requests.get(\"{0}/{1}\".format(self.search_url, search), params=data,\n                               verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Search for projects by name which are accessible to the authenticated user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getfilearchive(self, project_id, filepath=None):\n        if not filepath:\n            filepath = ''\n\n        request = requests.get(\n            '{0}/{1}/repository/archive'.format(self.projects_url, project_id),\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 200:\n            if filepath == \"\":\n                filepath = request.headers['content-disposition'].split(';')[1].split('=')[1].strip('\"')\n            with open(filepath, 'wb') as filesave:\n                filesave.write(request.content)\n                # TODO: Catch oserror exceptions as no permissions and such\n                # TODO: change the filepath to a path and keep always the filename?\n            return True\n        else:\n            msg = request.json()['message']\n            raise exceptions.HttpError(msg)", "response": "Get an archive of the repository"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deletegroup(self, group_id):\n        request = requests.delete(\n            '{0}/{1}'.format(self.groups_url, group_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 200", "response": "Deletes an entry in the group by ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getgroupmembers(self, group_id, page=1, per_page=20):\n        data = {'page': page, 'per_page': per_page}\n\n        request = requests.get(\n            '{0}/{1}/members'.format(self.groups_url, group_id), params=data,\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False", "response": "Lists the members of a given group id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addgroupmember(self, group_id, user_id, access_level):\n        if not isinstance(access_level, int):\n            if access_level.lower() == 'owner':\n                access_level = 50\n            elif access_level.lower() == 'master':\n                access_level = 40\n            elif access_level.lower() == 'developer':\n                access_level = 30\n            elif access_level.lower() == 'reporter':\n                access_level = 20\n            elif access_level.lower() == 'guest':\n                access_level = 10\n            else:\n                return False\n\n        data = {'id': group_id, 'user_id': user_id, 'access_level': access_level}\n\n        request = requests.post(\n            '{0}/{1}/members'.format(self.groups_url, group_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 201", "response": "Adds a project member to a group"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deletegroupmember(self, group_id, user_id):\n        request = requests.delete(\n            '{0}/{1}/members/{2}'.format(self.groups_url, group_id, user_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return True", "response": "Delete a group member from a user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addldapgrouplink(self, group_id, cn, group_access, provider):\n        data = {'id': group_id, 'cn': cn, 'group_access': group_access, 'provider': provider}\n\n        request = requests.post(\n            '{0}/{1}/ldap_group_links'.format(self.groups_url, group_id),\n            headers=self.headers, data=data, verify=self.verify_ssl)\n\n        return request.status_code == 201", "response": "Adds an LDAP group link to the LDAP group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes an LDAP group link for a specific LDAP provider", "response": "def deleteldapgrouplink(self, group_id, cn, provider=None):\n        \"\"\"\n        Deletes a LDAP group link (for a specific LDAP provider if given)\n\n        :param group_id: The ID of a group\n        :param cn: The CN of a LDAP group\n        :param provider: Name of a LDAP provider\n        :return: True if success\n        \"\"\"\n        url = '{base}/{gid}/ldap_group_links/{provider}{cn}'.format(\n            base=self.groups_url, gid=group_id, cn=cn,\n            provider=('{0}/'.format(provider) if provider else ''))\n\n        request = requests.delete(url, headers=self.headers, verify=self.verify_ssl)\n\n        return request.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createissuewallnote(self, project_id, issue_id, content):\n        data = {'body': content}\n        request = requests.post(\n            '{0}/{1}/issues/{2}/notes'.format(self.projects_url, project_id, issue_id),\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, data=data, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Create a new note in a specific issue"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createfile(self, project_id, file_path, branch_name, encoding, content, commit_message):\n        data = {\n            'file_path': file_path,\n            'branch_name': branch_name,\n            'encoding': encoding,\n            'content': content,\n            'commit_message': commit_message\n        }\n\n        request = requests.post(\n            '{0}/{1}/repository/files'.format(self.projects_url, project_id),\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, data=data, timeout=self.timeout)\n\n        return request.status_code == 201", "response": "Creates a new file in the repository."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updatefile(self, project_id, file_path, branch_name, content, commit_message):\n        data = {\n            'file_path': file_path,\n            'branch_name': branch_name,\n            'content': content,\n            'commit_message': commit_message\n        }\n\n        request = requests.put(\n            '{0}/{1}/repository/files'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 200", "response": "Updates an existing file in the repository."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing you to receive information about file in repository like name size content.", "response": "def getfile(self, project_id, file_path, ref):\n        \"\"\"\n        Allows you to receive information about file in repository like name, size, content.\n        Note that file content is Base64 encoded.\n\n        :param project_id: project_id\n        :param file_path: Full path to file. Ex. lib/class.rb\n        :param ref: The name of branch, tag or commit\n        :return:\n        \"\"\"\n        data = {'file_path': file_path, 'ref': ref}\n\n        request = requests.get(\n            '{0}/{1}/repository/files'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes existing file in the repository.", "response": "def deletefile(self, project_id, file_path, branch_name, commit_message):\n        \"\"\"\n        Deletes existing file in the repository\n\n        :param project_id: project id\n        :param file_path: Full path to new file. Ex. lib/class.rb\n        :param branch_name: The name of branch\n        :param commit_message: Commit message\n        :return: true if success, false if not\n        \"\"\"\n        data = {\n            'file_path': file_path,\n            'branch_name': branch_name,\n            'commit_message': commit_message\n        }\n\n        request = requests.delete(\n            '{0}/{1}/repository/files'.format(self.projects_url, project_id),\n            headers=self.headers, data=data, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset GitLab CI service for project.", "response": "def setgitlabciservice(self, project_id, token, project_url):\n        \"\"\"\n        Set GitLab CI service for project\n\n        :param project_id: project id\n        :param token: CI project token\n        :param project_url: CI project url\n        :return: true if success, false if not\n        \"\"\"\n        data = {'token': token, 'project_url': project_url}\n\n        request = requests.put(\n            '{0}/{1}/services/gitlab-ci'.format(self.projects_url, project_id),\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, data=data, timeout=self.timeout)\n\n        return request.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deletegitlabciservice(self, project_id, token, project_url):\n        request = requests.delete(\n            '{0}/{1}/services/gitlab-ci'.format(self.projects_url, project_id),\n            headers=self.headers, verify=self.verify_ssl, auth=self.auth, timeout=self.timeout)\n\n        return request.status_code == 200", "response": "Delete GitLab CI service settings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createlabel(self, project_id, name, color):\n        data = {'name': name, 'color': color}\n\n        request = requests.post(\n            '{0}/{1}/labels'.format(self.projects_url, project_id), data=data,\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 201:\n            return request.json()\n        else:\n            return False", "response": "Creates a new label for given repository with given name and color."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a label given by its name.", "response": "def deletelabel(self, project_id, name):\n        \"\"\"\n        Deletes a label given by its name.\n\n        :param project_id: The ID of a project\n        :param name: The name of the label\n        :return: True if succeed\n        \"\"\"\n        data = {'name': name}\n\n        request = requests.delete(\n            '{0}/{1}/labels'.format(self.projects_url, project_id), data=data,\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        return request.status_code == 200"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an existing label with new name or now color.", "response": "def editlabel(self, project_id, name, new_name=None, color=None):\n        \"\"\"\n        Updates an existing label with new name or now color.\n        At least one parameter is required, to update the label.\n\n        :param project_id: The ID of a project\n        :param name: The name of the label\n        :return: True if succeed\n        \"\"\"\n        data = {'name': name, 'new_name': new_name, 'color': color}\n\n        request = requests.put(\n            '{0}/{1}/labels'.format(self.projects_url, project_id), data=data,\n            verify=self.verify_ssl, auth=self.auth, headers=self.headers, timeout=self.timeout)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of namespaces", "response": "def getnamespaces(self, search=None, page=1, per_page=20):\n        \"\"\"\n        Return a namespace list\n\n        :param search: Optional search query\n        :param page: Which page to return (default is 1)\n        :param per_page: Number of items to return per page (default is 20)\n        :return: returns a list of namespaces, false if there is an error\n        \"\"\"\n        data = {'page': page, 'per_page': per_page}\n\n        if search:\n            data['search'] = search\n\n        request = requests.get(\n            self.namespaces_url, params=data, headers=self.headers, verify=self.verify_ssl)\n\n        if request.status_code == 200:\n            return request.json()\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_class_that_defined_method(fun):\n    if inspect.ismethod(fun):\n        for cls in inspect.getmro(fun.__self__.__class__):\n            if cls.__dict__.get(fun.__name__) is fun:\n                return cls\n        fun = fun.__func__  # fallback to __qualname__ parsing\n    if inspect.isfunction(fun):\n        cls = getattr(inspect.getmodule(fun),\n                      fun.__qualname__.split('.<locals>', 1)[0].rsplit('.', 1)[0], None)\n        if isinstance(cls, type):\n            return cls\n    return getattr(fun, '__objclass__', None)", "response": "Tries to find the class that defines the given method. Will not work for nested classes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_field_mro(cls, field_name):\n    res = set()\n    if hasattr(cls, '__mro__'):\n        for _class in inspect.getmro(cls):\n            values_ = getattr(_class, field_name, None)\n            if values_ is not None:\n                res = res.union(set(make_list(values_)))\n    return res", "response": "Goes up the mro and looks for the specified field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_list(item_or_items):\n    if item_or_items is None:\n        return None\n    if isinstance(item_or_items, list):\n        return item_or_items\n    if hasattr(item_or_items, '__iter__') and not isinstance(item_or_items, str):\n        return list(item_or_items)\n    return [item_or_items]", "response": "Makes a list out of the given items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing this decorator to auto implement __str__() and optionally __repr__() methods on classes. Args: __repr__ (bool): If set to true, the decorator will auto-implement the __repr__() method as well. Returns: callable: Decorating function. Note: There are known issues with self referencing (self.s = self). Recursion will be identified by the python interpreter and will do no harm, but it will actually not work. A eval(class.__repr__()) will obviously not work, when there are attributes that are not part of the __init__'s arguments. Example: >>> @auto_str(__repr__=True) ... class Demo(object): ... def __init__(self, i=0, s=\"a\", l=None, t=None): ... self.i = i ... self.s = s ... self.l = l ... self.t = t >>> dut = Demo(10, 'abc', [1, 2, 3], (1,2,3)) >>> print(dut.__str__()) Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3)) >>> print(eval(dut.__repr__()).__str__()) Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3)) >>> print(dut.__repr__()) Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3))", "response": "def auto_str(__repr__=False):\n    \"\"\"\n    Use this decorator to auto implement __str__() and optionally __repr__() methods on classes.\n\n    Args:\n        __repr__ (bool): If set to true, the decorator will auto-implement the __repr__() method as\n            well.\n\n    Returns:\n        callable: Decorating function.\n\n    Note:\n        There are known issues with self referencing (self.s = self). Recursion will be identified\n        by the python interpreter and will do no harm, but it will actually not work.\n        A eval(class.__repr__()) will obviously not work, when there are attributes that are not\n        part of the __init__'s arguments.\n\n    Example:\n        >>> @auto_str(__repr__=True)\n        ... class Demo(object):\n        ...    def __init__(self, i=0, s=\"a\", l=None, t=None):\n        ...        self.i = i\n        ...        self.s = s\n        ...        self.l = l\n        ...        self.t = t\n        >>> dut = Demo(10, 'abc', [1, 2, 3], (1,2,3))\n        >>> print(dut.__str__())\n        Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3))\n        >>> print(eval(dut.__repr__()).__str__())\n        Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3))\n        >>> print(dut.__repr__())\n        Demo(i=10, l=[1, 2, 3], s='abc', t=(1, 2, 3))\n    \"\"\"\n    def _decorator(cls):\n        def __str__(self):\n            items = [\"{name}={value}\".format(\n                name=name,\n                value=vars(self)[name].__repr__()\n            ) for name in [key for key in sorted(vars(self))]\n                if name not in get_field_mro(self.__class__, '__auto_str_ignore__')]  # pylint: disable=bad-continuation\n            return \"{clazz}({items})\".format(\n                clazz=str(type(self).__name__),\n                items=', '.join(items)\n            )\n        cls.__str__ = __str__\n        if __repr__:\n            cls.__repr__ = __str__\n\n        return cls\n\n    return _decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef auto_str_ignore(ignore_list):\n    def _decorator(cls):\n        ignored = make_list(ignore_list)\n        cls.__auto_str_ignore__ = ignored\n        return cls\n    return _decorator", "response": "Use this decorator to suppress any fields that should not be part of the dynamically created\n    __str__ or __repr__ function of auto_str."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises error if major version is different.", "response": "def raise_on_major_version_mismatch(work_request, local_version):\n    \"\"\"\n    Raises error if major version is different. Other wise logs the difference.\n    :param work_request: WorkRequest: request that had a different version\n    :param local_version: str: our version string that does not match message.version\n    \"\"\"\n    request_major_version = get_major_version(work_request.version)\n    local_major_version = get_major_version(local_version)\n    if request_major_version != local_major_version:\n        raise ValueError(\"Received major version mismatch. request:{} local:{}\".format(\n            work_request.version, local_version\n        ))\n    else:\n        logging.info(\"Ignoring non-major version mismatch request:{} local:{}\".format(\n            work_request.version, local_version))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates internal connection to the AMQP service.", "response": "def connect(self):\n        \"\"\"\n        Create internal connection to AMQP service.\n        \"\"\"\n        logging.info(\"Connecting to {} with user {}.\".format(self.host, self.username))\n        credentials = pika.PlainCredentials(self.username, self.password)\n        connection_params = pika.ConnectionParameters(host=self.host,\n                                                      credentials=credentials,\n                                                      heartbeat_interval=self.heartbeat_interval)\n        self.connection = pika.BlockingConnection(connection_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses connection to AMQP if connected.", "response": "def close(self):\n        \"\"\"\n        Close internal connection to AMQP if connected.\n        \"\"\"\n        if self.connection:\n            logging.info(\"Closing connection to {}.\".format(self.host))\n            self.connection.close()\n            self.connection = None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a chanel named queue_name. Must be connected before calling this method.", "response": "def create_channel(self, queue_name):\n        \"\"\"\n        Create a chanel named queue_name. Must be connected before calling this method.\n        :param queue_name: str: name of the queue to create\n        :return: pika.channel.Channel: channel we can send/receive messages to/from\n        \"\"\"\n        channel = self.connection.channel()\n        channel.queue_declare(queue=queue_name, durable=True)\n        return channel"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a queue with the specified name.", "response": "def delete_queue(self, queue_name):\n        \"\"\"\n        Delete a queue with the specified name.\n        :param queue_name:\n        :return:\n        \"\"\"\n        self.connect()\n        channel = self.connection.channel()\n        channel.queue_delete(queue=queue_name)\n        self.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a durable message to the queue_name", "response": "def send_durable_message(self, queue_name, body):\n        \"\"\"\n        Connect to queue_name, post a durable message with body, disconnect from queue_name.\n        :param queue_name: str: name of the queue we want to put a message on\n        :param body: content of the message we want to send\n        \"\"\"\n        self.connect()\n        channel = self.create_channel(queue_name)\n        channel.basic_publish(exchange='',\n                              routing_key=queue_name,\n                              body=body,\n                              properties=pika.BasicProperties(\n                                 delivery_mode=2,  # make message persistent\n                              ))\n        self.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_durable_exchange_message(self, exchange_name, body):\n        self.connect()\n        channel = self.connection.channel()\n        # Fanout will send message to multiple subscribers\n        channel.exchange_declare(exchange=exchange_name, type='fanout')\n        result = channel.basic_publish(exchange=exchange_name, routing_key='', body=body,\n                                       properties=pika.BasicProperties(\n                                           delivery_mode=2,  # make message persistent\n                                       ))\n        self.close()\n        return result", "response": "Send a message to an exchange"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing incoming messages with callback until close is called.", "response": "def receive_loop_with_callback(self, queue_name, callback):\n        \"\"\"\n        Process incoming messages with callback until close is called.\n        :param queue_name: str: name of the queue to poll\n        :param callback: func(ch, method, properties, body) called with data when data arrives\n        :return:\n        \"\"\"\n        self.connect()\n        channel = self.create_channel(queue_name)\n        channel.basic_qos(prefetch_count=1)\n        channel.basic_consume(callback, queue=queue_name)\n        channel.start_consuming()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a WorkRequest to the queue specified in config.", "response": "def send(self, command, payload):\n        \"\"\"\n        Send a WorkRequest to containing command and payload to the queue specified in config.\n        :param command: str: name of the command we want run by WorkQueueProcessor\n        :param payload: object: pickable data to be used when running the command\n        \"\"\"\n        request = WorkRequest(command, payload)\n        logging.info(\"Sending {} message to queue {}.\".format(request.command, self.queue_name))\n        # setting protocol to version 2 to be compatible with python2\n        self.connection.send_durable_message(self.queue_name, pickle.dumps(request, protocol=2))\n        logging.info(\"Sent {} message.\".format(request.command, self.queue_name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_command_by_method_name(self, command, obj):\n        func = getattr(obj, command)\n        if func and callable(func):\n            self.add_command(command, func)\n        else:\n            raise ValueError(\"Object missing {} method.\".format(command))", "response": "Add a command to the list of available command objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shutdown(self, payload=None):\n        logging.info(\"Work queue shutdown.\")\n        self.connection.close()\n        self.receiving_messages = False", "response": "Close the connection and shutdown the messaging loop."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing incoming WorkRequest messages one at a time via functions specified by add_command.", "response": "def process_messages_loop(self):\n        \"\"\"\n        Processes incoming WorkRequest messages one at a time via functions specified by add_command.\n        \"\"\"\n        self.receiving_messages = True\n        try:\n            self.process_messages_loop_internal()\n        except pika.exceptions.ConnectionClosed as ex:\n            logging.error(\"Connection closed {}.\".format(ex))\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbusies loop that processes incoming WorkRequest messages via functions specified by add_command. Terminates if a command runs shutdown method", "response": "def process_messages_loop_internal(self):\n        \"\"\"\n        Busy loop that processes incoming WorkRequest messages via functions specified by add_command.\n        Terminates if a command runs shutdown method\n        \"\"\"\n        logging.info(\"Starting work queue loop.\")\n        self.connection.receive_loop_with_callback(self.queue_name, self.process_message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_message(self, ch, method, properties, body):\n        self.work_request = pickle.loads(body)\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n        self.process_work_request()", "response": "Callback method that is fired for every message that comes in while we are in process_messages_loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbusies loop that processes incoming WorkRequest messages via functions specified by add_command. Disconnects while servicing a message, reconnects once finished processing a message Terminates if a command runs shutdown method", "response": "def process_messages_loop_internal(self):\n        \"\"\"\n        Busy loop that processes incoming WorkRequest messages via functions specified by add_command.\n        Disconnects while servicing a message, reconnects once finished processing a message\n        Terminates if a command runs shutdown method\n        \"\"\"\n        while self.receiving_messages:\n            # connect to AMQP server and listen for 1 message then disconnect\n            self.work_request = None\n            self.connection.receive_loop_with_callback(self.queue_name, self.save_work_request_and_close)\n            if self.work_request:\n                self.process_work_request()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_work_request_and_close(self, ch, method, properties, body):\n        self.work_request = pickle.loads(body)\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n        ch.stop_consuming()\n        self.connection.close()", "response": "Save message body and close connection"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, payload):\n        result = self.connection.send_durable_exchange_message(self.exchange_name, payload)\n        logging.info(\"Sent message to exchange.\".format(self.exchange_name))\n        return result", "response": "Send a payload to the queue specified in config."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of related galleries from same section as originating gallery.", "response": "def get_related_galleries(gallery, count=5):\n    \"\"\"\n    Gets latest related galleries from same section as originating gallery.\n\n    Count defaults to five but can be overridden.\n\n    Usage: {% get_related_galleries gallery <10> %}\n    \"\"\"\n    # just get the first cat. If they assigned to more than one, tough\n    try:\n        cat = gallery.sections.all()[0]\n        related = cat.gallery_categories.filter(published=True).exclude(id=gallery.id).order_by('-id')[:count]\n    except:\n        related = None\n    return {'related': related, 'MEDIA_URL': settings.MEDIA_URL}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_lando_router(config, obj, queue_name):\n        return MessageRouter(config, obj, queue_name, VM_LANDO_INCOMING_MESSAGES,\n                             processor_constructor=WorkQueueProcessor)", "response": "Makes a MessageRouter which can listen to queue_name sending messages to the VM version of lando."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a MessageRouter which can listen to a queue_name sending messages to the k8s version of lando.", "response": "def make_k8s_lando_router(config, obj, queue_name):\n        \"\"\"\n        Makes MessageRouter which can listen to queue_name sending messages to the k8s version of lando.\n        :param config: WorkerConfig/ServerConfig: settings for connecting to the queue\n        :param obj: object: implements lando specific methods\n        :param queue_name: str: name of the queue we will listen on.\n        :return MessageRouter\n        \"\"\"\n        return MessageRouter(config, obj, queue_name, K8S_LANDO_INCOMING_MESSAGES,\n                             processor_constructor=WorkQueueProcessor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_worker_router(config, obj, queue_name):\n        return MessageRouter(config, obj, queue_name, VM_LANDO_WORKER_INCOMING_MESSAGES,\n                             processor_constructor=DisconnectingWorkQueueProcessor)", "response": "Makes a MessageRouter which can listen to queue_name sending lando_worker specific messages to obj."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_healthchecks(self):\n        self.load_default_healthchecks()\n        if getattr(settings, 'AUTODISCOVER_HEALTHCHECKS', True):\n            self.autodiscover_healthchecks()\n        self._registry_loaded = True", "response": "Loads healthchecks from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading default healthchecks from settings. HEALTHCHECKS as dotted import paths to the classes.", "response": "def load_default_healthchecks(self):\n        \"\"\"\n        Loads healthchecks specified in settings.HEALTHCHECKS as dotted import\n        paths to the classes. Defaults are listed in `DEFAULT_HEALTHCHECKS`.\n        \"\"\"\n        default_healthchecks = getattr(settings, 'HEALTHCHECKS', DEFAULT_HEALTHCHECKS)\n        for healthcheck in default_healthchecks:\n            healthcheck = import_string(healthcheck)\n            self.register_healthcheck(healthcheck)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun all registered healthchecks and returns a list of HealthcheckResponse.", "response": "def run_healthchecks(self):\n        \"\"\"\n        Runs all registered healthchecks and returns a list of\n        HealthcheckResponse.\n        \"\"\"\n        if not self._registry_loaded:\n            self.load_healthchecks()\n\n        def get_healthcheck_name(hc):\n            if hasattr(hc, 'name'):\n                return hc.name\n            return hc.__name__\n\n        responses = []\n        for healthcheck in self._registry:\n            try:\n                if inspect.isclass(healthcheck):\n                    healthcheck = healthcheck()\n                response = healthcheck()\n                if isinstance(response, bool):\n                    response = HealthcheckResponse(\n                        name=get_healthcheck_name(healthcheck),\n                        status=response,\n                    )\n            except Exception as e:\n                response = HealthcheckResponse(\n                    name=get_healthcheck_name(healthcheck),\n                    status=False,\n                    exception=str(e),\n                    exception_class=e.__class__.__name__,\n                )\n            responses.append(response)\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntiming based decorator, implementing :class:`faste.caches.TimeoutCache` :param int timeout: Cache key timeout :param int max_size: (keyword) max size.", "response": "def timed_cache(timeout, max_size=128):\n    \"\"\"\n    Time based decorator, implementing :class:`faste.caches.TimeoutCache`\n\n    :param int timeout: Cache key timeout\n\n    :param int max_size: (keyword) max size.\n    \"\"\"\n\n    def actual_decorator(func):\n        return _cached_func(func, caches.TimeoutCache, timeout, max_size=max_size)\n\n    return actual_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef advance_by(self, amount):\n        if amount < 0:\n            raise ValueError(\"cannot retreat time reference: amount {} < 0\"\n                             .format(amount))\n        self.__delta += amount", "response": "Advance the time reference by the given amount."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef advance_to(self, timestamp):\n        now = self.__original_time()\n        if timestamp < now:\n            raise ValueError(\"cannot retreat time reference: \"\n                             \"target {} < now {}\"\n                             .format(timestamp, now))\n        self.__delta = timestamp - now", "response": "Advance the time reference so that now is the given timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef job_step_complete(self, job_request_payload):\n        if job_request_payload.success_command == JobCommands.STORE_JOB_OUTPUT_COMPLETE:\n            raise ValueError(\"Programmer error use use job_step_store_output_complete instead.\")\n        payload = JobStepCompletePayload(job_request_payload)\n        self.send(job_request_payload.success_command, payload)", "response": "Send message that the job step is complete using payload data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend message that the store output job step is complete using payload data.", "response": "def job_step_store_output_complete(self, job_request_payload, output_project_info):\n        \"\"\"\n        Send message that the store output job step is complete using payload data.\n        Raises ValueError if used for non-StoreJobOutputPayload message type.\n        :param job_request_payload: StoreJobOutputPayload payload from complete job\n        :param output_project_info: object: info about the project created\n        \"\"\"\n        if job_request_payload.success_command != JobCommands.STORE_JOB_OUTPUT_COMPLETE:\n            raise ValueError(\"Programmer error only use job_step_store_output_complete for store_output_complete.\")\n        payload = JobStepStoreOutputCompletePayload(job_request_payload, output_project_info)\n        self.send(job_request_payload.success_command, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends message that the job step failed using payload data.", "response": "def job_step_error(self, job_request_payload, message):\n        \"\"\"\n        Send message that the job step failed using payload data.\n        :param job_request_payload: StageJobPayload|RunJobPayload|StoreJobOutputPayload payload from job with error\n        :param message: description of the error\n        \"\"\"\n        payload = JobStepErrorPayload(job_request_payload, message)\n        self.send(job_request_payload.error_command, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stage_job(self, credentials, job_details, input_files, vm_instance_name):\n        self._send(JobCommands.STAGE_JOB, StageJobPayload(credentials, job_details, input_files, vm_instance_name))", "response": "Request that a job be staged on a worker"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a workflow on a worker.", "response": "def run_job(self, job_details, workflow, vm_instance_name):\n        \"\"\"\n        Execute a workflow on a worker.\n        :param job_details: object: details about job(id, name, created date, workflow version)\n        :param workflow: jobapi.Workflow: url to workflow and parameters to use\n        :param vm_instance_name: name of the instance lando_worker is running on (this passed back in the response)\n        \"\"\"\n        self._send(JobCommands.RUN_JOB, RunJobPayload(job_details, workflow, vm_instance_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store_job_output(self, credentials, job_details, vm_instance_name):\n        payload = StoreJobOutputPayload(credentials, job_details, vm_instance_name)\n        self._send(JobCommands.STORE_JOB_OUTPUT, payload)", "response": "Store the output of a finished job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reset_frequencies(self, frequency=0):\n\n        frequency = max(frequency, 0)\n\n        for key in self._store.keys():\n            self._store[key] = (self._store[key][0], frequency)\n\n        return frequency", "response": "Resets all stored frequencies for the cache to the specified frequency"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef oldest(self):\n        if len(self._store) == 0:\n            return\n\n        kv = min(self._store.items(), key=lambda x: x[1][1])\n\n        return kv[0], kv[1][0]", "response": "Gets key value pair for oldest item in cache\n        Returns None if no items are available"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the amount of time an item has left in the cache.", "response": "def time_left(self, key):\n        \"\"\"\n        Gets the amount of time an item has left in the cache (in seconds), before it is evicted.\n\n        :param key: Key to check time for.\n        :returns: int\n        \"\"\"\n        self._evict_old()\n\n        if key not in self._store:\n            raise KeyError(\"key {0!r} does not exist in cache\".format(key))\n\n        return self.timeout - (time.time() - self._store[key][1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for two sets of [] []", "response": "def more_than_one_index(s, brackets=2):\r\n    '''\r\n    Search for two sets of [] []\r\n    @param s: string to search\r\n    '''\r\n    start = 0\r\n    brackets_num = 0\r\n    while start != -1 and brackets_num < brackets:\r\n        start = s.find(\"[\", start)\r\n        if start == -1:\r\n            break\r\n        start = s.find(\"]\", start)\r\n        brackets_num += 1\r\n    if start != -1:\r\n        return True\r\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget data between [ and ] remove if exist", "response": "def get_key(s):\r\n    '''\r\n    Get data between [ and ] remove ' if exist\r\n    @param s: string to process\r\n    '''\r\n    start = s.find(\"[\")\r\n    end = s.find(\"]\")\r\n    if start == -1 or end == -1:\r\n        return None\r\n    if s[start + 1] == \"'\":\r\n        start += 1\r\n    if s[end - 1] == \"'\":\r\n        end -= 1\r\n    return s[start + 1:end]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parser_helper(key, val):\r\n    '''\r\n    Helper for parser function\r\n    @param key:\r\n    @param val:\r\n    '''\r\n    start_bracket = key.find(\"[\")\r\n    end_bracket = key.find(\"]\")\r\n    pdict = {}\r\n    if has_variable_name(key):  # var['key'][3]\r\n        pdict[key[:key.find(\"[\")]] = parser_helper(key[start_bracket:], val)\r\n    elif more_than_one_index(key):  # ['key'][3]\r\n        newkey = get_key(key)\r\n        newkey = int(newkey) if is_number(newkey) else newkey\r\n        pdict[newkey] = parser_helper(key[end_bracket + 1:], val)\r\n    else:  # key = val or ['key']\r\n        newkey = key\r\n        if start_bracket != -1:  # ['key']\r\n            newkey = get_key(key)\r\n            if newkey is None:\r\n                raise MalformedQueryStringError\r\n        newkey = int(newkey) if is_number(newkey) else newkey\r\n        if key == u'[]':  # val is the array key\r\n            val = int(val) if is_number(val) else val\r\n        pdict[newkey] = val\r\n    return pdict", "response": "Helper for parser function\r\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(query_string, unquote=True, normalized=False, encoding=DEFAULT_ENCODING):\r\n    '''\r\n    Main parse function\r\n    @param query_string:\r\n    @param unquote: unquote html query string ?\r\n    @param encoding: An optional encoding used to decode the keys and values. Defaults to utf-8, which the W3C declares as a defaul in the W3C algorithm for encoding.\r\n    @see http://www.w3.org/TR/html5/forms.html#application/x-www-form-urlencoded-encoding-algorithm\r\n\r\n    @param normalized: parse number key in dict to proper list ?\r\n    '''\r\n    \r\n    mydict = {}\r\n    plist = []\r\n    if query_string == \"\":\r\n        return mydict\r\n    \r\n    if type(query_string) == bytes:\r\n      query_string = query_string.decode()\r\n    \r\n    for element in query_string.split(\"&\"):\r\n        try:\r\n            if unquote:\r\n                (var, val) = element.split(\"=\")\r\n                if sys.version_info[0] == 2:\r\n                  var = var.encode('ascii')\r\n                  val = val.encode('ascii')\r\n                var = urllib.unquote_plus(var)\r\n                val = urllib.unquote_plus(val)\r\n            else:\r\n                (var, val) = element.split(\"=\")\r\n        except ValueError:\r\n            raise MalformedQueryStringError\r\n        if encoding:\r\n            var = var.decode(encoding)\r\n            val = val.decode(encoding)\r\n        plist.append(parser_helper(var, val))\r\n    for di in plist:\r\n        (k, v) = di.popitem()\r\n        tempdict = mydict\r\n        while k in tempdict and type(v) is dict:\r\n            tempdict = tempdict[k]\r\n            (k, v) = v.popitem()\r\n        if k in tempdict and type(tempdict[k]).__name__ == 'list':\r\n            tempdict[k].append(v)\r\n        elif k in tempdict:\r\n            tempdict[k] = [tempdict[k], v]\r\n        else:\r\n            tempdict[k] = v\r\n\r\n    if normalized == True:\r\n        return _normalize(mydict)\r\n    return mydict", "response": "Main parse function\r\nVIRTUALLIST"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef includeme(config):\n    settings = config.registry.settings\n    swagger_versions = get_swagger_versions(settings)\n\n    # for rendering /swagger.yaml\n    config.add_renderer(\n        'yaml', 'pyramid_swagger.api.YamlRendererFactory',\n    )\n\n    # Add the SwaggerSchema to settings to make it available to the validation\n    # tween and `register_api_doc_endpoints`\n    settings['pyramid_swagger.schema12'] = None\n    settings['pyramid_swagger.schema20'] = None\n\n    # Store under two keys so that 1.2 and 2.0 can co-exist.\n    if SWAGGER_12 in swagger_versions:\n        settings['pyramid_swagger.schema12'] = get_swagger_schema(settings)\n\n    if SWAGGER_20 in swagger_versions:\n        settings['pyramid_swagger.schema20'] = get_swagger_spec(settings)\n\n    config.add_tween(\n        \"pyramid_swagger.tween.validation_tween_factory\",\n        under=pyramid.tweens.EXCVIEW\n    )\n\n    config.add_renderer('pyramid_swagger', PyramidSwaggerRendererFactory())\n\n    if settings.get('pyramid_swagger.enable_api_doc_views', True):\n        if SWAGGER_12 in swagger_versions:\n            register_api_doc_endpoints(\n                config,\n                settings['pyramid_swagger.schema12'].get_api_doc_endpoints())\n\n        if SWAGGER_20 in swagger_versions:\n            register_api_doc_endpoints(\n                config,\n                build_swagger_20_swagger_schema_views(config),\n                base_path=settings.get('pyramid_swagger.base_path_api_docs', ''))", "response": "Include all the swagger files in the current project."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the structure of Swagger schemas against the spec.", "response": "def validate_swagger_schema(schema_dir, resource_listing):\n    \"\"\"Validate the structure of Swagger schemas against the spec.\n\n    **Valid only for Swagger v1.2 spec**\n\n    Note: It is possible that resource_listing is not present in\n    the schema_dir. The path is passed in the call so that ssv\n    can fetch the api-declaration files from the path.\n\n    :param resource_listing: Swagger Spec v1.2 resource listing\n    :type resource_listing: dict\n    :param schema_dir: A path to Swagger spec directory\n    :type schema_dir: string\n    :raises: :py:class:`swagger_spec_validator.SwaggerValidationError`\n    \"\"\"\n    schema_filepath = os.path.join(schema_dir, API_DOCS_FILENAME)\n    swagger_spec_validator.validator12.validate_spec(\n        resource_listing,\n        urlparse.urljoin('file:', pathname2url(os.path.abspath(schema_filepath))),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a swagger endpoint schema into an equivalent one to validate our request.", "response": "def build_param_schema(schema, param_type):\n    \"\"\"Turn a swagger endpoint schema into an equivalent one to validate our\n    request.\n\n    As an example, this would take this swagger schema:\n        {\n            \"paramType\": \"query\",\n            \"name\": \"query\",\n            \"description\": \"Location to query\",\n            \"type\": \"string\",\n            \"required\": true\n        }\n    To this jsonschema:\n        {\n            \"type\": \"object\",\n            \"additionalProperties\": \"False\",\n            \"properties:\": {\n                \"description\": \"Location to query\",\n                \"type\": \"string\",\n                \"required\": true\n            }\n        }\n    Which we can then validate against a JSON object we construct from the\n    pyramid request.\n    \"\"\"\n    properties = filter_params_by_type(schema, param_type)\n    if not properties:\n        return\n\n    # Generate a jsonschema that describes the set of all query parameters. We\n    # can then validate this against dict(request.params).\n    return {\n        'type': 'object',\n        'properties': dict((p['name'], p) for p in properties),\n        # Allow extra headers. Most HTTP requests will have headers which\n        # are outside the scope of the spec (like `Host`, or `User-Agent`)\n        'additionalProperties': param_type == 'header',\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the type field is valid for Swagger 1. 2.", "response": "def type_validator(validator, types, instance, schema):\n    \"\"\"Swagger 1.2 supports parameters of 'type': 'File'. Skip validation of\n    the 'type' field in this case.\n    \"\"\"\n    if schema.get('type') == 'File':\n        return []\n    return _validators.type_draft3(validator, types, instance, schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef required_validator(validator, req, instance, schema):\n    if schema.get('paramType'):\n        if req is True and not instance:\n            return [ValidationError(\"%s is required\" % schema['name'])]\n        return []\n    return _validators.required_draft4(validator, req, instance, schema)", "response": "Swagger 1. 2 expects required to be a bool in the Parameter object but not a list of properties in a Model object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_body_validator(models):\n    return validators.extend(\n        Draft4Validator,\n        {\n            'paramType': ignore,\n            'name': ignore,\n            'type': build_swagger_type_validator(models),\n            'required': required_validator,\n        }\n    )", "response": "Returns a validator for the request body based on the given models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_request_to_validator_map(schema, resolver):\n    schema_models = schema.get('models', {})\n    return dict(\n        (\n            RequestMatcher(api['path'], operation['method']),\n            ValidatorMap.from_operation(operation, schema_models, resolver)\n        )\n        for api in schema['apis']\n        for operation in api['operations']\n    )", "response": "Build a mapping from RequestMatcher to ValidatorMap for each operation in the API spec."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_schema(schema_path):\n    with open(schema_path, 'r') as schema_file:\n        schema = simplejson.load(schema_file)\n    resolver = RefResolver('', '', schema.get('models', {}))\n    return build_request_to_validator_map(schema, resolver)", "response": "Load the schema file and build a mapping from RequestMatcher to ValidatorMap."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, values):\n        if not self.schema or (values is None and not self.schema.get('required', False)):\n            return\n        self.validator.validate(values)", "response": "Validate a : class : dict of values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if this matcher matches the request False otherwise.", "response": "def matches(self, request):\n        \"\"\"\n        :param request: a :class:`pyramid.request.Request`\n        :returns: True if this matcher matches the request, False otherwise\n        \"\"\"\n        return (\n            partial_path_match(request.path_info, self.path) and\n            request.method == self.method\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_swagger_objects(settings, route_info, registry):\n    enabled_swagger_versions = get_swagger_versions(registry.settings)\n    schema12 = registry.settings['pyramid_swagger.schema12']\n    schema20 = registry.settings['pyramid_swagger.schema20']\n\n    fallback_to_swagger12_route = (\n        SWAGGER_20 in enabled_swagger_versions and\n        SWAGGER_12 in enabled_swagger_versions and\n        settings.prefer_20_routes and\n        route_info.get('route') and\n        route_info['route'].name not in settings.prefer_20_routes\n    )\n    if fallback_to_swagger12_route:\n        return settings.swagger12_handler, schema12\n\n    if SWAGGER_20 in enabled_swagger_versions:\n        return settings.swagger20_handler, schema20\n\n    if SWAGGER_12 in enabled_swagger_versions:\n        return settings.swagger12_handler, schema12", "response": "Returns appropriate swagger handler and swagger spec schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validation_tween_factory(handler, registry):\n    settings = load_settings(registry)\n    route_mapper = registry.queryUtility(IRoutesMapper)\n\n    validation_context = _get_validation_context(registry)\n\n    def validator_tween(request):\n        # We don't have access to this yet but let's go ahead and build the\n        # matchdict so we can validate it and use it to exclude routes from\n        # validation.\n        route_info = route_mapper(request)\n        swagger_handler, spec = get_swagger_objects(settings, route_info,\n                                                    registry)\n\n        if should_exclude_request(settings, request, route_info):\n            return handler(request)\n\n        try:\n            op_or_validators_map = swagger_handler.op_for_request(\n                request, route_info=route_info, spec=spec)\n        except PathNotMatchedError as exc:\n            if settings.validate_path:\n                with validation_context(request):\n                    raise PathNotFoundError(str(exc), child=exc)\n            else:\n                return handler(request)\n\n        def operation(_):\n            return op_or_validators_map if isinstance(op_or_validators_map, Operation) else None\n\n        request.set_property(operation)\n\n        if settings.validate_request:\n            with validation_context(request, response=None):\n                request_data = swagger_handler.handle_request(\n                    PyramidSwaggerRequest(request, route_info),\n                    op_or_validators_map,\n                )\n\n            def swagger_data(_):\n                return request_data\n\n            request.set_property(swagger_data)\n\n        response = handler(request)\n\n        if settings.validate_response:\n            with validation_context(request, response=response):\n                swagger_handler.handle_response(response, op_or_validators_map)\n\n        return response\n\n    return validator_tween", "response": "Returns a function that will perform the validation of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the request against the swagger spec and return a dict with all the parameter values available in the request.", "response": "def handle_request(request, validator_map, **kwargs):\n    \"\"\"Validate the request against the swagger spec and return a dict with\n    all parameter values available in the request, casted to the expected\n    python type.\n\n    :param request: a :class:`PyramidSwaggerRequest` to validate\n    :param validator_map: a :class:`pyramid_swagger.load_schema.ValidatorMap`\n        used to validate the request\n    :returns: a :class:`dict` of request data for each parameter in the swagger\n        spec\n    :raises: RequestValidationError when the request is not valid for the\n        swagger spec\n    \"\"\"\n    request_data = {}\n    validation_pairs = []\n\n    for validator, values in [\n        (validator_map.query, request.query),\n        (validator_map.path, request.path),\n        (validator_map.form, request.form),\n        (validator_map.headers, request.headers),\n    ]:\n        values = cast_params(validator.schema, values)\n        validation_pairs.append((validator, values))\n        request_data.update(values)\n\n    # Body is a special case because the key for the request_data comes\n    # from the name in the schema, instead of keys in the values\n    if validator_map.body.schema:\n        param_name = validator_map.body.schema['name']\n        validation_pairs.append((validator_map.body, request.body))\n        request_data[param_name] = request.body\n\n    validate_request(validation_pairs)\n\n    return request_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_swagger12_handler(schema):\n    if schema:\n        return SwaggerHandler(\n            op_for_request=schema.validators_for_request,\n            handle_request=handle_request,\n            handle_response=validate_response,\n        )", "response": "Builds a swagger12 handler or returns None if no schema is present."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling a list of paths that should not be validated against.", "response": "def get_exclude_paths(registry):\n    \"\"\"Compiles a list of paths that should not be validated against.\n        :rtype: list of compiled validation regexes\n    \"\"\"\n    # TODO(#63): remove deprecated `skip_validation` setting in v2.0.\n    regexes = registry.settings.get(\n        'pyramid_swagger.skip_validation',\n        registry.settings.get(\n            'pyramid_swagger.exclude_paths',\n            DEFAULT_EXCLUDED_PATHS\n        )\n    )\n\n    # being nice to users using strings :p\n    if not isinstance(regexes, list) and not isinstance(regexes, tuple):\n        regexes = [regexes]\n\n    return [re.compile(r) for r in regexes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to cast a request param to a specific type in the schema.", "response": "def cast_request_param(param_type, param_name, param_value):\n    \"\"\"Try to cast a request param (e.g. query arg, POST data) from a string to\n    its specified type in the schema. This allows validating non-string params.\n\n    :param param_type: name of the type to be casted to\n    :type  param_type: string\n    :param param_name: param name\n    :type  param_name: string\n    :param param_value: param value\n    :type  param_value: string\n    \"\"\"\n    try:\n        return CAST_TYPE_TO_FUNC.get(param_type, lambda x: x)(param_value)\n    except ValueError:\n        log.warn(\"Failed to cast %s value of %s to %s\",\n                 param_name, param_value, param_type)\n        # Ignore type error, let jsonschema validation handle incorrect types\n        return param_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the response against our schemas.", "response": "def validate_response(response, validator_map):\n    \"\"\"Validates response against our schemas.\n\n    :param response: the response object to validate\n    :type response: :class:`pyramid.response.Response`\n    :type validator_map: :class:`pyramid_swagger.load_schema.ValidatorMap`\n    \"\"\"\n    validator = validator_map.response\n\n    # Short circuit if we are supposed to not validate anything.\n    returns_nothing = validator.schema.get('type') == 'void'\n    body_empty = response.body in (None, b'', b'{}', b'null')\n    if returns_nothing and body_empty:\n        return\n\n    # Don't attempt to validate non-success responses in v1.2\n    if not 200 <= response.status_code <= 203:\n        return\n\n    validator.validate(prepare_body(response))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef swaggerize_response(response, op):\n    response_spec = get_response_spec(response.status_int, op)\n    bravado_core.response.validate_response(\n        response_spec, op, PyramidSwaggerResponse(response))", "response": "Delegate handling the Swagger concerns of the response to bravado - core."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind out which operation in the Swagger schema corresponds to the given request.", "response": "def get_op_for_request(request, route_info, spec):\n    \"\"\"\n    Find out which operation in the Swagger schema corresponds to the given\n    pyramid request.\n\n    :type request: :class:`pyramid.request.Request`\n    :type route_info: dict (usually has 'match' and 'route' keys)\n    :type spec: :class:`bravado_core.spec.Spec`\n    :rtype: :class:`bravado_core.operation.Operation`\n    :raises: PathNotMatchedError when a matching Swagger operation is not\n        found.\n    \"\"\"\n    # pyramid.urldispath.Route\n    route = route_info['route']\n    if hasattr(route, 'path'):\n        route_path = route.path\n        if route_path[0] != '/':\n            route_path = '/' + route_path\n        op = spec.get_op_for_request(request.method, route_path)\n        if op is not None:\n            return op\n        else:\n            raise PathNotMatchedError(\n                \"Could not find a matching Swagger \"\n                \"operation for {0} request {1}\"\n                .format(request.method, request.url))\n    else:\n        raise PathNotMatchedError(\n            \"Could not find a matching route for {0} request {1}. \"\n            \"Have you registered this endpoint with Pyramid?\"\n            .format(request.method, request.url))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_swagger_versions(settings):\n    swagger_versions = set(aslist(settings.get(\n        'pyramid_swagger.swagger_versions', DEFAULT_SWAGGER_VERSIONS)))\n\n    if len(swagger_versions) == 0:\n        raise ValueError('pyramid_swagger.swagger_versions is empty')\n\n    for swagger_version in swagger_versions:\n        if swagger_version not in SUPPORTED_SWAGGER_VERSIONS:\n            raise ValueError('Swagger version {0} is not supported.'\n                             .format(swagger_version))\n    return swagger_versions", "response": "Validates and returns the versions of the Swagger Spec that this pyramid\n    application supports."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the dict of the form encoded version of the user s id.", "response": "def form(self):\n        \"\"\"\n        :rtype: dict\n        \"\"\"\n        # Don't read the POST dict unless the body is form encoded\n        if self.request.content_type in self.FORM_TYPES:\n            return self.request.POST.mixed()\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and register pyramid endpoints to service swagger api docs.", "response": "def register_api_doc_endpoints(config, endpoints, base_path='/api-docs'):\n    \"\"\"Create and register pyramid endpoints to service swagger api docs.\n    Routes and views will be registered on the `config` at `path`.\n\n    :param config: a pyramid configuration to register the new views and routes\n    :type  config: :class:`pyramid.config.Configurator`\n    :param endpoints: a list of endpoints to register as routes and views\n    :type  endpoints: a list of :class:`pyramid_swagger.model.PyramidEndpoint`\n    :param base_path: the base path used to register api doc endpoints.\n        Defaults to `/api-docs`.\n    :type  base_path: string\n    \"\"\"\n    for endpoint in endpoints:\n        path = base_path.rstrip('/') + endpoint.path\n        config.add_route(endpoint.route_name, path)\n        config.add_view(\n            endpoint.view,\n            route_name=endpoint.route_name,\n            renderer=endpoint.renderer)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_swagger_12_endpoints(resource_listing, api_declarations):\n    yield build_swagger_12_resource_listing(resource_listing)\n\n    for name, filepath in api_declarations.items():\n        with open(filepath) as input_file:\n            yield build_swagger_12_api_declaration(\n                name, simplejson.load(input_file))", "response": "Generates a generator that yields the Swagger 1. 2 endpoints for a single resource listing and one or more api declarations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_swagger_12_resource_listing(resource_listing):\n    def view_for_resource_listing(request):\n        # Thanks to the magic of closures, this means we gracefully return JSON\n        # without file IO at request time.\n        return resource_listing\n\n    return PyramidEndpoint(\n        path='',\n        route_name='pyramid_swagger.swagger12.api_docs',\n        view=view_for_resource_listing,\n        renderer='json')", "response": "Build a new object that provides a JSON representation of a Swagger 1. 2 resource listing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_swagger_12_api_declaration(resource_name, api_declaration):\n    # NOTE: This means our resource paths are currently constrained to be valid\n    # pyramid routes! (minus the leading /)\n    route_name = 'pyramid_swagger.swagger12.apidocs-{0}'.format(resource_name)\n    return PyramidEndpoint(\n        path='/{0}'.format(resource_name),\n        route_name=route_name,\n        view=build_swagger_12_api_declaration_view(api_declaration),\n        renderer='json')", "response": "Builds a Swagger 1. 2 api declaration for a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a view function for API declaration.", "response": "def build_swagger_12_api_declaration_view(api_declaration_json):\n    \"\"\"Thanks to the magic of closures, this means we gracefully return JSON\n    without file IO at request time.\n    \"\"\"\n    def view_for_api_declaration(request):\n        # Note that we rewrite basePath to always point at this server's root.\n        return dict(\n            api_declaration_json,\n            basePath=str(request.application_url),\n        )\n    return view_for_api_declaration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate if path1 and path2 match a partial path.", "response": "def partial_path_match(path1, path2, kwarg_re=r'\\{.*\\}'):\n    \"\"\"Validates if path1 and path2 matches, ignoring any kwargs in the string.\n\n    We need this to ensure we can match Swagger patterns like:\n        /foo/{id}\n    against the observed pyramid path\n        /foo/1\n\n    :param path1: path of a url\n    :type path1: string\n    :param path2: path of a url\n    :type path2: string\n    :param kwarg_re: regex pattern to identify kwargs\n    :type kwarg_re: regex string\n    :returns: boolean\n    \"\"\"\n    split_p1 = path1.split('/')\n    split_p2 = path2.split('/')\n    pat = re.compile(kwarg_re)\n    if len(split_p1) != len(split_p2):\n        return False\n    for partial_p1, partial_p2 in zip(split_p1, split_p2):\n        if pat.match(partial_p1) or pat.match(partial_p2):\n            continue\n        if not partial_p1 == partial_p2:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a request and returns a validator mapping for the request.", "response": "def validators_for_request(self, request, **kwargs):\n        \"\"\"Takes a request and returns a validator mapping for the request.\n\n        :param request: A Pyramid request to fetch schemas for\n        :type request: :class:`pyramid.request.Request`\n        :returns: a :class:`pyramid_swagger.load_schema.ValidatorMap` which can\n            be used to validate `request`\n        \"\"\"\n        for resource_validator in self.resource_validators:\n            for matcher, validator_map in resource_validator.items():\n                if matcher.matches(request):\n                    return validator_map\n\n        raise PathNotMatchedError(\n            'Could not find the relevant path ({0}) in the Swagger schema. '\n            'Perhaps you forgot to add it?'.format(request.path_info)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all resource paths in a directory.", "response": "def find_resource_paths(schema_dir):\n    \"\"\"The inverse of :func:`find_resource_names` used to generate\n    a resource listing from a directory of swagger api docs.\n    \"\"\"\n    def not_api_doc_file(filename):\n        return not filename.endswith(API_DOCS_FILENAME)\n\n    def not_swagger_dot_json(filename):\n        # Exclude a Swagger 2.0 schema file if it happens to exist.\n        return not os.path.basename(filename) == 'swagger.json'\n\n    def filename_to_path(filename):\n        filename, _ext = os.path.splitext(os.path.basename(filename))\n        return '/' + filename\n\n    filenames = glob.glob('{0}/*.json'.format(schema_dir))\n    return map(filename_to_path,\n               filter(not_swagger_dot_json,\n                      filter(not_api_doc_file, sorted(filenames))))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_schema_mapping(schema_dir, resource_listing):\n    def resource_name_to_filepath(name):\n        return os.path.join(schema_dir, '{0}.json'.format(name))\n\n    return dict(\n        (resource, resource_name_to_filepath(resource))\n        for resource in find_resource_names(resource_listing)\n    )", "response": "Builds a mapping from resource name to file path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the resource listing from file handling errors.", "response": "def _load_resource_listing(resource_listing):\n    \"\"\"Load the resource listing from file, handling errors.\n\n    :param resource_listing: path to the api-docs resource listing file\n    :type  resource_listing: string\n    :returns: contents of the resource listing file\n    :rtype: dict\n    \"\"\"\n    try:\n        with open(resource_listing) as resource_listing_file:\n            return simplejson.load(resource_listing_file)\n    # If not found, raise a more user-friendly error.\n    except IOError:\n        raise ResourceListingNotFoundError(\n            'No resource listing found at {0}. Note that your json file '\n            'must be named {1}'.format(resource_listing, API_DOCS_FILENAME)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_resource_listing(schema_dir, should_generate_resource_listing):\n    listing_filename = os.path.join(schema_dir, API_DOCS_FILENAME)\n    resource_listing = _load_resource_listing(listing_filename)\n\n    if not should_generate_resource_listing:\n        return resource_listing\n    return generate_resource_listing(schema_dir, resource_listing)", "response": "Return the contents of the resource listing file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_swagger_schema(schema_dir, resource_listing):\n    mapping = build_schema_mapping(schema_dir, resource_listing)\n    resource_validators = ingest_resources(mapping, schema_dir)\n    endpoints = list(build_swagger_12_endpoints(resource_listing, mapping))\n    return SwaggerSchema(endpoints, resource_validators)", "response": "Builds a SwaggerSchema from various files."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a : class : pyramid_swagger. model. SwaggerSchema constructed from the swagger specs in pyramid_swagger. schema_directory.", "response": "def get_swagger_schema(settings):\n    \"\"\"Return a :class:`pyramid_swagger.model.SwaggerSchema` constructed from\n    the swagger specs in `pyramid_swagger.schema_directory`. If\n    `pyramid_swagger.enable_swagger_spec_validation` is enabled the schema\n    will be validated before returning it.\n\n    :param settings: a pyramid registry settings with configuration for\n        building a swagger schema\n    :type settings: dict\n    :returns: a :class:`pyramid_swagger.model.SwaggerSchema`\n    \"\"\"\n    schema_dir = settings.get('pyramid_swagger.schema_directory', 'api_docs')\n    resource_listing = get_resource_listing(\n        schema_dir,\n        settings.get('pyramid_swagger.generate_resource_listing', False)\n    )\n\n    if settings.get('pyramid_swagger.enable_swagger_spec_validation', True):\n        validate_swagger_schema(schema_dir, resource_listing)\n\n    return compile_swagger_schema(schema_dir, resource_listing)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_swagger_spec(settings):\n    schema_dir = settings.get('pyramid_swagger.schema_directory', 'api_docs/')\n    schema_filename = settings.get('pyramid_swagger.schema_file',\n                                   'swagger.json')\n    schema_path = os.path.join(schema_dir, schema_filename)\n    schema_url = urlparse.urljoin('file:', pathname2url(os.path.abspath(schema_path)))\n\n    handlers = build_http_handlers(None)  # don't need http_client for file:\n    file_handler = handlers['file']\n    spec_dict = file_handler(schema_url)\n\n    return Spec.from_dict(\n        spec_dict,\n        config=create_bravado_core_config(settings),\n        origin_url=schema_url)", "response": "Build a bravado_core. spec. Spec object from a pyramid registry settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_bravado_core_config(settings):\n    # Map pyramid_swagger config key -> bravado_core config key\n    config_keys = {\n        'pyramid_swagger.enable_request_validation': 'validate_requests',\n        'pyramid_swagger.enable_response_validation': 'validate_responses',\n        'pyramid_swagger.enable_swagger_spec_validation': 'validate_swagger_spec',\n        'pyramid_swagger.use_models': 'use_models',\n        'pyramid_swagger.user_formats': 'formats',\n        'pyramid_swagger.include_missing_properties': 'include_missing_properties',\n    }\n\n    configs = {\n        'use_models': False\n    }\n\n    bravado_core_configs_from_pyramid_swagger_configs = {\n        bravado_core_key: settings[pyramid_swagger_key]\n        for pyramid_swagger_key, bravado_core_key in iteritems(config_keys)\n        if pyramid_swagger_key in settings\n    }\n    if bravado_core_configs_from_pyramid_swagger_configs:\n        warnings.warn(\n            message='Configs {old_configs} are deprecated, please use {new_configs} instead.'.format(\n                old_configs=', '.join(k for k, v in sorted(iteritems(config_keys))),\n                new_configs=', '.join(\n                    '{}{}'.format(BRAVADO_CORE_CONFIG_PREFIX, v)\n                    for k, v in sorted(iteritems(config_keys))\n                ),\n            ),\n            category=DeprecationWarning,\n        )\n        configs.update(bravado_core_configs_from_pyramid_swagger_configs)\n\n    configs.update({\n        key.replace(BRAVADO_CORE_CONFIG_PREFIX, ''): value\n        for key, value in iteritems(settings)\n        if key.startswith(BRAVADO_CORE_CONFIG_PREFIX)\n    })\n\n    return configs", "response": "Create a bravado_core config dict for the current pyramid_swagger_version of the current pyramid_swagger_version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconsuming the Swagger schemas and produce a queryable datastructure.", "response": "def ingest_resources(mapping, schema_dir):\n    \"\"\"Consume the Swagger schemas and produce a queryable datastructure.\n\n    :param mapping: Map from resource name to filepath of its api declaration\n    :type mapping: dict\n    :param schema_dir: the directory schema files live inside\n    :type schema_dir: string\n    :returns: A list of mapping from :class:`RequestMatcher` to\n        :class:`ValidatorMap`\n    \"\"\"\n    ingested_resources = []\n    for name, filepath in iteritems(mapping):\n        try:\n            ingested_resources.append(load_schema(filepath))\n        # If we have trouble reading any files, raise a more user-friendly\n        # error.\n        except IOError:\n            raise ApiDeclarationNotFoundError(\n                'No api declaration found at {0}. Attempted to load the `{1}` '\n                'resource relative to the schema_directory `{2}`. Perhaps '\n                'your resource name and API declaration file do not '\n                'match?'.format(filepath, name, schema_dir)\n            )\n    return ingested_resources"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting a mesh in the. obj format.", "response": "def export_obj(vertices, triangles, filename):\n    \"\"\"\n    Exports a mesh in the (.obj) format.\n    \"\"\"\n    \n    with open(filename, 'w') as fh:\n        \n        for v in vertices:\n            fh.write(\"v {} {} {}\\n\".format(*v))\n            \n        for f in triangles:\n            fh.write(\"f {} {} {}\\n\".format(*(f + 1)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting a set of vertices and triangles in the OFF format.", "response": "def export_off(vertices, triangles, filename):\n    \"\"\"\n    Exports a mesh in the (.off) format.\n    \"\"\"\n    \n    with open(filename, 'w') as fh:\n        fh.write('OFF\\n')\n        fh.write('{} {} 0\\n'.format(len(vertices), len(triangles)))\n\n        for v in vertices:\n            fh.write(\"{} {} {}\\n\".format(*v))\n            \n        for f in triangles:\n            fh.write(\"3 {} {} {}\\n\".format(*f))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting a mesh in the COLLADA format.", "response": "def export_mesh(vertices, triangles, filename, mesh_name=\"mcubes_mesh\"):\n    \"\"\"\n    Exports a mesh in the COLLADA (.dae) format.\n    \n    Needs PyCollada (https://github.com/pycollada/pycollada).\n    \"\"\"\n    \n    import collada\n    \n    mesh = collada.Collada()\n    \n    vert_src = collada.source.FloatSource(\"verts-array\", vertices, ('X','Y','Z'))\n    geom = collada.geometry.Geometry(mesh, \"geometry0\", mesh_name, [vert_src])\n    \n    input_list = collada.source.InputList()\n    input_list.addInput(0, 'VERTEX', \"#verts-array\")\n    \n    triset = geom.createTriangleSet(np.copy(triangles), input_list, \"\")\n    geom.primitives.append(triset)\n    mesh.geometries.append(geom)\n    \n    geomnode = collada.scene.GeometryNode(geom, [])\n    node = collada.scene.Node(mesh_name, children=[geomnode])\n    \n    myscene = collada.scene.Scene(\"mcubes_scene\", [node])\n    mesh.scenes.append(myscene)\n    mesh.scene = myscene\n    \n    mesh.write(filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the __doc__ string of the decorated function by calling the nco help command", "response": "def auto_doc(tool, nco_self):\n    \"\"\"\n    Generate the __doc__ string of the decorated function by calling the nco help command\n\n    :param tool:\n    :param nco_self:\n    :return:\n    \"\"\"\n\n    def desc(func):\n\n        func.__doc__ = nco_self.call([tool, \"--help\"]).get(\"stdout\")\n        return func\n\n    return desc"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a cdf file and return a file object.", "response": "def read_cdf(self, infile):\n        \"\"\"Return a cdf handle created by the available cdf library.\n        python-netcdf4 and scipy supported (default:scipy)\"\"\"\n        if not self.return_cdf:\n            self.load_cdf_module()\n\n        if self.cdf_module == \"scipy\":\n            # making it compatible to older scipy versions\n            file_obj = self.cdf.netcdf_file(infile, mode=\"r\")\n        elif self.cdf_module == \"netcdf4\":\n            file_obj = self.cdf.Dataset(infile)\n        else:\n            raise ImportError(\n                \"Could not import data \\\n                              from file {0}\".format(\n                    infile\n                )\n            )\n        return file_obj"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_array(self, infile, var_name):\n        file_handle = self.read_cdf(infile)\n        try:\n            # return the data array\n            return file_handle.variables[var_name][:]\n        except KeyError:\n            print(\"Cannot find variable: {0}\".format(var_name))\n            raise KeyError", "response": "Directly return a numpy array for a given variable name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a masked array based on cdf s FillValue", "response": "def read_ma_array(self, infile, var_name):\n        \"\"\"Create a masked array based on cdf's FillValue\"\"\"\n        file_obj = self.read_cdf(infile)\n\n        # .data is not backwards compatible to old scipy versions, [:] is\n        data = file_obj.variables[var_name][:]\n\n        # load numpy if available\n        try:\n            import numpy as np\n        except Exception:\n            raise ImportError(\"numpy is required to return masked arrays.\")\n\n        if hasattr(file_obj.variables[var_name], \"_FillValue\"):\n            # return masked array\n            fill_val = file_obj.variables[var_name]._FillValue\n            retval = np.ma.masked_where(data == fill_val, data)\n        else:\n            # generate dummy mask which is always valid\n            retval = np.ma.array(data)\n\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_related(self, request, form, formsets, change):\n        form.save_m2m()\n        for formset in formsets:\n            self.save_formset(request, form, formset, change=change)", "response": "Save the related model formsets to the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_view(self, request, object_id, form_url='', extra_context=None):\n        \"The 'change' admin view for this model.\"\n        model = self.model\n        opts = model._meta\n\n        obj = self.get_object(request, unquote(object_id))\n\n        if not self.has_change_permission(request, obj):\n            raise PermissionDenied\n\n        if obj is None:\n            raise Http404(_('%(name)s object with primary key %(key)r does not exist.') % {'name': force_text(opts.verbose_name), 'key': escape(object_id)})\n\n        if request.method == 'POST' and \"_saveasnew\" in request.POST:\n            return self.add_view(request, form_url=reverse('admin:%s_%s_add' %\n                                                           (opts.app_label, opts.module_name),\n                current_app=self.admin_site.name))\n\n        ModelForm = self.get_form(request, obj)\n        formsets = []\n        inline_instances = self.get_inline_instances(request, obj)\n        if request.method == 'POST':\n            form = ModelForm(request.POST, request.FILES, instance=obj)\n            if form.is_valid():\n                form_validated = True\n                new_object = self.save_form(request, form, change=True)\n            else:\n                form_validated = False\n                new_object = obj\n            prefixes = {}\n            for FormSet, inline in self.get_formsets_with_inlines(request, new_object):\n                prefix = FormSet.get_default_prefix()\n                prefixes[prefix] = prefixes.get(prefix, 0) + 1\n                if prefixes[prefix] != 1 or not prefix:\n                    prefix = \"%s-%s\" % (prefix, prefixes[prefix])\n                formset = FormSet(request.POST, request.FILES,\n                    instance=new_object, prefix=prefix,\n                    queryset=inline.get_queryset(request))\n                formsets.append(formset)\n                if hasattr(inline, 'inlines') and inline.inlines:\n                    self.add_nested_inline_formsets(request, inline, formset)\n\n            if self.all_valid_with_nesting(formsets) and form_validated:\n                self.save_model(request, new_object, form, True)\n                self.save_related(request, form, formsets, True)\n                change_message = self.construct_change_message(request, form, formsets)\n                self.log_change(request, new_object, change_message)\n                return self.response_change(request, new_object)\n\n        else:\n            form = ModelForm(instance=obj)\n            prefixes = {}\n            for FormSet, inline in self.get_formsets_with_inlines(request, obj):\n                prefix = FormSet.get_default_prefix()\n                prefixes[prefix] = prefixes.get(prefix, 0) + 1\n                if prefixes[prefix] != 1 or not prefix:\n                    prefix = \"%s-%s\" % (prefix, prefixes[prefix])\n                formset = FormSet(instance=obj, prefix=prefix,\n                    queryset=inline.get_queryset(request))\n                formsets.append(formset)\n                if hasattr(inline, 'inlines') and inline.inlines:\n                    self.add_nested_inline_formsets(request, inline, formset)\n\n        adminForm = helpers.AdminForm(form, self.get_fieldsets(request, obj),\n            self.get_prepopulated_fields(request, obj),\n            self.get_readonly_fields(request, obj),\n            model_admin=self)\n        media = self.media + adminForm.media\n\n        inline_admin_formsets = []\n        for inline, formset in zip(inline_instances, formsets):\n            fieldsets = list(inline.get_fieldsets(request, obj))\n            readonly = list(inline.get_readonly_fields(request, obj))\n            prepopulated = dict(inline.get_prepopulated_fields(request, obj))\n            inline_admin_formset = helpers.InlineAdminFormSet(inline, formset,\n                fieldsets, prepopulated, readonly, model_admin=self)\n            inline_admin_formsets.append(inline_admin_formset)\n            media = media + inline_admin_formset.media\n            if hasattr(inline, 'inlines') and inline.inlines:\n                media += self.wrap_nested_inline_formsets(request, inline, formset)\n\n        context = {\n            'title': _('Change %s') % force_text(opts.verbose_name),\n            'adminform': adminForm,\n            'object_id': object_id,\n            'original': obj,\n            'is_popup': \"_popup\" in request.GET,\n            'media': media,\n            'inline_admin_formsets': inline_admin_formsets,\n            'errors': helpers.AdminErrorList(form, formsets),\n            'app_label': opts.app_label,\n            }\n        context.update(self.admin_site.each_context(request))\n        context.update(extra_context or {})\n        return self.render_change_form(request, context, change=True, obj=obj, form_url=form_url)", "response": "The change admin view for this model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef digest(self,data=None):\n        if data is not None:\n            self.update(data)\n        b=create_string_buffer(256)\n        size=c_size_t(256)\n        if libcrypto.EVP_DigestSignFinal(self.ctx,b,pointer(size))<=0:\n            raise DigestError('SignFinal')\n        self.digest_finalized=True\n        return b.raw[:size.value]", "response": "Method digest is redefined to return keyed MAC value instead of just digest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bytes(num, check_result=False):\n\n    if num <= 0:\n        raise ValueError(\"'num' should be > 0\")\n    buf = create_string_buffer(num)\n    result = libcrypto.RAND_bytes(buf, num)\n    if check_result and result == 0:\n        raise RandError(\"Random Number Generator not seeded sufficiently\")\n    return buf.raw[:num]", "response": "Returns num bytes of cryptographically strong pseudo - random\n    bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pseudo_bytes(num):\n    if num <= 0:\n        raise ValueError(\"'num' should be > 0\")\n    buf = create_string_buffer(num)\n    libcrypto.RAND_pseudo_bytes(buf, num)\n    return buf.raw[:num]", "response": "Returns num bytes of pseudo random data generated by the random_bytes method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef seed(data, entropy=None):\n    if not isinstance(data, bintype):\n        raise TypeError(\"A string is expected\")\n    ptr = c_char_p(data)\n    size = len(data)\n    if entropy is None:\n        libcrypto.RAND_seed(ptr, size)\n    else:\n        libcrypto.RAND_add(ptr, size, entropy)", "response": "Seeds random generator with data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(dotted, shortname, longname):\n    if pyver  > 2:\n        dotted = dotted.encode('ascii')\n        shortname = shortname.encode('utf-8')\n        longname = longname.encode('utf-8')\n    nid = libcrypto.OBJ_create(dotted, shortname, longname)\n    if nid == 0:\n        raise LibCryptoError(\"Problem adding new OID to the  database\")\n    return Oid(nid)", "response": "Creates new OID in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dotted(self):\n        \" Returns dotted-decimal reperesentation \"\n        obj = libcrypto.OBJ_nid2obj(self.nid)\n        buf = create_string_buffer(256)\n        libcrypto.OBJ_obj2txt(buf, 256, obj, 1)\n        if pyver == 2:\n            return buf.value\n        else:\n            return buf.value.decode('ascii')", "response": "Returns dotted - decimal reperesentation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromobj(obj):\n        nid = libcrypto.OBJ_obj2nid(obj)\n        if nid == 0:\n            buf = create_string_buffer(80)\n            dotted_len = libcrypto.OBJ_obj2txt(buf, 80, obj, 1)\n            dotted = buf[:dotted_len]\n            oid = create(dotted, dotted, dotted)\n        else:\n            oid = Oid(nid)\n        return oid", "response": "Creates an OID object from the pointer to ASN1_OBJECT c structure."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _password_callback(c):\n    if  c is None:\n        return PW_CALLBACK_FUNC(0)\n    if callable(c):\n        if pyver ==2 :\n            def __cb(buf, length, rwflag, userdata):\n                pwd = c(rwflag)\n                cnt = min(len(pwd),length)\n                memmove(buf,pwd, cnt)\n                return cnt\n        else:        \n            def __cb(buf, length, rwflag, userdata):\n                pwd = c(rwflag).encode(\"utf-8\")\n                cnt = min(len(pwd),length)\n                memmove(buf,pwd, cnt)\n                return cnt\n    else:\n        if pyver > 2:\n            c=c.encode(\"utf-8\")\n        def __cb(buf,length,rwflag,userdata):\n            cnt=min(len(c),length)\n            memmove(buf,c,cnt)\n            return cnt\n    return PW_CALLBACK_FUNC(__cb)", "response": "Converts given user function or string to C password callback function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sign(self, digest, **kwargs):\n        ctx = libcrypto.EVP_PKEY_CTX_new(self.key, None)\n        if ctx is None:\n            raise PKeyError(\"Initailizing sign context\")\n        if libcrypto.EVP_PKEY_sign_init(ctx) < 1:\n            raise PKeyError(\"sign_init\")\n        self._configure_context(ctx, kwargs)\n        # Find out signature size\n        siglen = c_long(0)\n        if libcrypto.EVP_PKEY_sign(ctx, None, byref(siglen), digest,\n                                   len(digest)) < 1:\n            raise PKeyError(\"computing signature length\")\n        sig = create_string_buffer(siglen.value)\n        if libcrypto.EVP_PKEY_sign(ctx, sig, byref(siglen), digest,\n                                   len(digest)) < 1:\n            raise PKeyError(\"signing\")\n        libcrypto.EVP_PKEY_CTX_free(ctx)\n        return sig.raw[:int(siglen.value)]", "response": "Signs given digest and returns signature"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify given digest on given digest. Returns True if ok False if don t match", "response": "def verify(self, digest, signature, **kwargs):\n        \"\"\"\n        Verifies given signature on given digest\n        Returns True if Ok, False if don't match\n        Keyword arguments allows to set algorithm-specific\n        parameters\n        \"\"\"\n        ctx = libcrypto.EVP_PKEY_CTX_new(self.key, None)\n        if ctx is None:\n            raise PKeyError(\"Initailizing verify context\")\n        if libcrypto.EVP_PKEY_verify_init(ctx) < 1:\n            raise PKeyError(\"verify_init\")\n        self._configure_context(ctx, kwargs)\n        ret = libcrypto.EVP_PKEY_verify(ctx, signature, len(signature), digest,\n                                        len(digest))\n        if ret < 0:\n            raise PKeyError(\"Signature verification\")\n        libcrypto.EVP_PKEY_CTX_free(ctx)\n        return ret > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nderive a private key from the current state of the key.", "response": "def derive(self, peerkey, **kwargs):\n        \"\"\"\n        Derives shared key (DH,ECDH,VKO 34.10). Requires\n        private key available\n\n        @param peerkey - other key (may be public only)\n\n        Keyword parameters are algorithm-specific\n        \"\"\"\n        if not self.cansign:\n            raise ValueError(\"No private key available\")\n        ctx = libcrypto.EVP_PKEY_CTX_new(self.key, None)\n        if ctx is None:\n            raise PKeyError(\"Initailizing derive context\")\n        if libcrypto.EVP_PKEY_derive_init(ctx) < 1:\n            raise PKeyError(\"derive_init\")\n\n        # This is workaround around missing functionality in GOST engine\n        # it provides only numeric control command to set UKM, not\n        # string one.\n        self._configure_context(ctx, kwargs, [\"ukm\"])\n        if libcrypto.EVP_PKEY_derive_set_peer(ctx, peerkey.key) <= 0:\n            raise PKeyError(\"Cannot set peer key\")\n        if \"ukm\" in kwargs:\n            # We just hardcode numeric command to set UKM here\n            if libcrypto.EVP_PKEY_CTX_ctrl(ctx, -1, 1 << 10, 8, 8,\n                                           kwargs[\"ukm\"]) <= 0:\n                raise PKeyError(\"Cannot set UKM\")\n        keylen = c_long(0)\n        if libcrypto.EVP_PKEY_derive(ctx, None, byref(keylen)) <= 0:\n            raise PKeyError(\"computing shared key length\")\n        buf = create_string_buffer(keylen.value)\n        if libcrypto.EVP_PKEY_derive(ctx, buf, byref(keylen)) <= 0:\n            raise PKeyError(\"computing actual shared key\")\n        libcrypto.EVP_PKEY_CTX_free(ctx)\n        return buf.raw[:int(keylen.value)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(algorithm, **kwargs):\n        tmpeng = c_void_p(None)\n        if isinstance(algorithm, chartype):\n            alg  = algorithm.encode(\"ascii\")\n        else:\n            alg = algorithm\n        ameth = libcrypto.EVP_PKEY_asn1_find_str(byref(tmpeng), alg, -1)\n        if ameth is None:\n            raise PKeyError(\"Algorithm %s not foind\\n\"%(algorithm))\n        clear_err_stack()\n        pkey_id = c_int(0)\n        libcrypto.EVP_PKEY_asn1_get0_info(byref(pkey_id), None, None, None,\n                                          None, ameth)\n        #libcrypto.ENGINE_finish(tmpeng)\n        if \"paramsfrom\" in kwargs:\n            ctx = libcrypto.EVP_PKEY_CTX_new(kwargs[\"paramsfrom\"].key, None)\n        else:\n            ctx = libcrypto.EVP_PKEY_CTX_new_id(pkey_id, None)\n        # FIXME support EC curve as keyword param by invoking paramgen\n        # operation\n        if ctx is None:\n            raise PKeyError(\"Creating context for key type %d\"%(pkey_id.value))\n        if libcrypto.EVP_PKEY_keygen_init(ctx) <= 0:\n            raise PKeyError(\"keygen_init\")\n        PKey._configure_context(ctx, kwargs, [\"paramsfrom\"])\n        key = c_void_p(None)\n        if libcrypto.EVP_PKEY_keygen(ctx, byref(key)) <= 0:\n            raise PKeyError(\"Error generating key\")\n        libcrypto.EVP_PKEY_CTX_free(ctx)\n        return PKey(ptr=key, cansign=True)", "response": "Generate new private - public key pair for given algorithm and optional parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning public key as PEM or DER structure.", "response": "def exportpub(self, format=\"PEM\"):\n        \"\"\"\n        Returns public key as PEM or DER structure.\n        \"\"\"\n        bio = Membio()\n        if format == \"PEM\":\n            retcode = libcrypto.PEM_write_bio_PUBKEY(bio.bio, self.key)\n        else:\n            retcode = libcrypto.i2d_PUBKEY_bio(bio.bio, self.key)\n        if retcode == 0:\n            raise PKeyError(\"error serializing public key\")\n        return str(bio)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexport private key for a given set of keys.", "response": "def exportpriv(self, format=\"PEM\", password=None, cipher=None):\n        \"\"\"\n        Returns private key as PEM or DER Structure.\n        If password and cipher are specified, encrypts key\n        on given password, using given algorithm. Cipher must be\n        an ctypescrypto.cipher.CipherType object\n\n        Password can be either string or function with one argument,\n        which returns password. It is called with argument True, which\n        means, that we are encrypting key, and password should be\n        verified (requested twice from user, for example).\n        \"\"\"\n        bio = Membio()\n        if cipher is None:\n            evp_cipher = None\n        else:\n            evp_cipher = cipher.cipher\n        if format == \"PEM\":\n            ret = libcrypto.PEM_write_bio_PrivateKey(bio.bio, self.key,\n                                         evp_cipher, None, 0,\n                                         _password_callback(password),\n                                         None)\n            if ret ==0:\n                raise PKeyError(\"error serializing private key\")\n            return str(bio)\n        else:\n            ret = libcrypto.i2d_PKCS8PrivateKey_bio(bio.bio, self.key,\n                                               evp_cipher, None, 0,\n                                              _password_callback(password),\n                                               None)\n            if ret ==0:\n                raise PKeyError(\"error serializing private key\")\n            return bintype(bio)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure public key operations for the current context", "response": "def _configure_context(ctx, opts, skip=()):\n        \"\"\"\n        Configures context of public key operations\n        @param ctx - context to configure\n        @param opts - dictionary of options (from kwargs of calling\n            function)\n        @param skip - list of options which shouldn't be passed to\n            context\n        \"\"\"\n\n        for oper in opts:\n            if oper in skip:\n                continue\n            if isinstance(oper,chartype):\n                op = oper.encode(\"ascii\")\n            else:\n                op = oper\n            if isinstance(opts[oper],chartype):\n                value = opts[oper].encode(\"ascii\")\n            elif isinstance(opts[oper],bintype):\n                value = opts[oper]\n            else:\n                if pyver == 2:\n                    value = str(opts[oper])\n                else:\n                    value = str(opts[oper]).encode('ascii')\n            ret = libcrypto.EVP_PKEY_CTX_ctrl_str(ctx, op, value)\n            if ret == -2:\n                raise PKeyError(\"Parameter %s is not supported by key\" % oper)\n            if ret < 1:\n                raise PKeyError(\"Error setting parameter %s\" % oper)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading data from readble BIO. For test purposes.", "response": "def read(self, length=None):\n        \"\"\"\n        Reads data from readble BIO. For test purposes.\n        @param length - if specifed, limits amount of data read.\n        If not BIO is read until end of buffer\n        \"\"\"\n        if not length is None:\n            if not isinstance(length, inttype) :\n                raise TypeError(\"length to read should be number\")\n            buf = create_string_buffer(length)\n            readbytes = libcrypto.BIO_read(self.bio, buf, length)\n            if readbytes == -2:\n                raise NotImplementedError(\"Function is not supported by\" +\n                                          \"this BIO\")\n            if readbytes == -1:\n                raise IOError\n            if readbytes == 0:\n                return b\"\"\n            return buf.raw[:readbytes]\n        else:\n            buf = create_string_buffer(1024)\n            out = b\"\"\n            readbytes = 1\n            while readbytes > 0:\n                readbytes = libcrypto.BIO_read(self.bio, buf, 1024)\n                if readbytes == -2:\n                    raise NotImplementedError(\"Function is not supported by \" +\n                                              \"this BIO\")\n                if readbytes == -1:\n                    raise IOError\n                if readbytes > 0:\n                    out += buf.raw[:readbytes]\n            return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CMS(data, format=\"PEM\"):\n    bio = Membio(data)\n    if format == \"PEM\":\n        ptr = libcrypto.PEM_read_bio_CMS(bio.bio, None, None, None)\n    else:\n        ptr = libcrypto.d2i_CMS_bio(bio.bio, None)\n    if ptr is None:\n        raise CMSError(\"Error parsing CMS data\")\n    typeoid = Oid(libcrypto.OBJ_obj2nid(libcrypto.CMS_get0_type(ptr)))\n    if typeoid.shortname() == \"pkcs7-signedData\":\n        return SignedData(ptr)\n    elif typeoid.shortname() == \"pkcs7-envelopedData\":\n        return EnvelopedData(ptr)\n    elif typeoid.shortname() == \"pkcs7-encryptedData\":\n        return EncryptedData(ptr)\n    else:\n        raise NotImplementedError(\"cannot handle \"+typeoid.shortname())", "response": "Returns either SignedData or EnvelopedData object from received messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pem(self):\n        bio = Membio()\n        if not libcrypto.PEM_write_bio_CMS(bio.bio, self.ptr):\n            raise CMSError(\"writing CMS to PEM\")\n        return str(bio)", "response": "Serialize in PEM format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(data, cert, pkey, flags=Flags.BINARY, certs=None):\n        if not pkey.cansign:\n            raise ValueError(\"Specified keypair has no private part\")\n        if cert.pubkey != pkey:\n            raise ValueError(\"Certificate doesn't match public key\")\n        bio = Membio(data)\n        if certs is not None and len(certs) > 0:\n            certstack_obj = StackOfX509(certs)  # keep reference to prevent immediate __del__ call\n            certstack = certstack_obj.ptr\n        else:\n            certstack = None\n        ptr = libcrypto.CMS_sign(cert.cert, pkey.key, certstack, bio.bio, flags)\n        if ptr is None:\n            raise CMSError(\"signing message\")\n        return SignedData(ptr)", "response": "Creates a SignedData message by signing data with pkey and certificate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsign a message using a certificate and private key.", "response": "def sign(self, cert, pkey, digest_type=None, data=None, flags=Flags.BINARY):\n        \"\"\"\n            Adds another signer to already signed message\n            @param cert - signer's certificate\n            @param pkey - signer's private key\n            @param digest_type - message digest to use as DigestType object\n                (if None - default for key would be used)\n            @param data - data to sign (if detached and\n                    Flags.REUSE_DIGEST is not specified)\n            @param flags - ORed combination of Flags consants\n        \"\"\"\n        if not pkey.cansign:\n            raise ValueError(\"Specified keypair has no private part\")\n        if cert.pubkey != pkey:\n            raise ValueError(\"Certificate doesn't match public key\")\n        if libcrypto.CMS_add1_signer(self.ptr, cert.cert, pkey.key,\n                                          digest_type.digest, flags) is None:\n            raise CMSError(\"adding signer\")\n        if flags & Flags.REUSE_DIGEST == 0:\n            if data is not None:\n                bio = Membio(data)\n                biodata = bio.bio\n            else:\n                biodata = None\n            res = libcrypto.CMS_final(self.ptr, biodata, None, flags)\n            if res <= 0:\n                raise CMSError(\"Cannot finalize CMS\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies the signature under a CMS message using a trusted certificate store.", "response": "def verify(self, store, flags, data=None, certs=None):\n        \"\"\"\n        Verifies signature under CMS message using trusted cert store\n\n        @param store -  X509Store object with trusted certs\n        @param flags - OR-ed combination of flag consants\n        @param data - message data, if messge has detached signature\n        param certs - list of certificates to use during verification\n                If Flags.NOINTERN is specified, these are only\n                sertificates to search for signing certificates\n        @returns True if signature valid, False otherwise\n        \"\"\"\n        bio = None\n        if data != None:\n            bio_obj = Membio(data)\n            bio = bio_obj.bio\n        if certs is not None and len(certs) > 0:\n            certstack_obj = StackOfX509(certs)  # keep reference to prevent immediate __del__ call\n            certstack = certstack_obj.ptr\n        else:\n            certstack = None\n        res = libcrypto.CMS_verify(self.ptr, certstack, store.store, bio,\n                                   None, flags)\n        return res > 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a StackOfX509 objects containing all certificates in the local system.", "response": "def signers(self):\n        \"\"\"\n        Return list of signer's certificates\n        \"\"\"\n        signerlist = libcrypto.CMS_get0_signers(self.ptr)\n        if signerlist is None:\n            raise CMSError(\"Cannot get signers\")\n        return StackOfX509(ptr=signerlist, disposable=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the signed data if present in the message otherwise raises CMSError", "response": "def data(self):\n        \"\"\"\n        Returns signed data if present in the message\n        \"\"\"\n        # Check if signatire is detached\n        if self.detached:\n            return None\n        bio = Membio()\n        if not libcrypto.CMS_verify(self.ptr, None, None, None, bio.bio,\n                                    Flags.NO_VERIFY):\n            raise CMSError(\"extract data\")\n        return str(bio)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a certificate to the SignedData.", "response": "def addcert(self, cert):\n        \"\"\"\n        Adds a certificate (probably intermediate CA) to the SignedData\n        structure\n        \"\"\"\n        if libcrypto.CMS_add1_cert(self.ptr, cert.cert) <= 0:\n            raise CMSError(\"Cannot add cert\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a StackOfX509 objects containing the certificates contained in the structure.", "response": "def certs(self):\n        \"\"\"\n        List of the certificates contained in the structure\n        \"\"\"\n        certstack = libcrypto.CMS_get1_certs(self.ptr)\n        if certstack is None:\n            raise CMSError(\"getting certs\")\n        return StackOfX509(ptr=certstack, disposable=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate and encrypts a message", "response": "def create(recipients, data, cipher, flags=0):\n        \"\"\"\n        Creates and encrypts message\n        @param recipients - list of X509 objects\n        @param data - contents of the message\n        @param cipher - CipherType object\n        @param flags - flag\n        \"\"\"\n        recp = StackOfX509(recipients)\n        bio = Membio(data)\n        cms_ptr = libcrypto.CMS_encrypt(recp.ptr, bio.bio, cipher.cipher,\n                                        flags)\n        if cms_ptr is None:\n            raise CMSError(\"encrypt EnvelopedData\")\n        return EnvelopedData(cms_ptr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decrypt(self, pkey, cert, flags=0):\n        if not pkey.cansign:\n            raise ValueError(\"Specified keypair has no private part\")\n        if pkey != cert.pubkey:\n            raise ValueError(\"Certificate doesn't match private key\")\n        bio = Membio()\n        res = libcrypto.CMS_decrypt(self.ptr, pkey.key, cert.cert, None,\n                                    bio.bio, flags)\n        if res <= 0:\n            raise CMSError(\"decrypting CMS\")\n        return str(bio)", "response": "Decrypts the message with the private key and certificate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an EncryptedData message.", "response": "def create(data, cipher, key, flags=0):\n        \"\"\"\n        Creates an EncryptedData message.\n        @param data data to encrypt\n        @param cipher cipher.CipherType object represening required\n                cipher type\n        @param key - byte array used as simmetic key\n        @param flags - OR-ed combination of Flags constant\n        \"\"\"\n        bio = Membio(data)\n        ptr = libcrypto.CMS_EncryptedData_encrypt(bio.bio, cipher.cipher,\n                                                  key, len(key), flags)\n        if ptr is None:\n            raise CMSError(\"encrypt data\")\n        return EncryptedData(ptr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the name of the digest", "response": "def name(self):\n        \"\"\" Returns name of the digest \"\"\"\n        if not hasattr(self, 'digest_name'):\n            self.digest_name = Oid(libcrypto.EVP_MD_type(self.digest)\n                                  ).longname()\n        return self.digest_name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, data, length=None):\n        if self.digest_finalized:\n            raise DigestError(\"No updates allowed\")\n        if not isinstance(data, bintype):\n            raise TypeError(\"A byte string is expected\")\n        if length is None:\n            length = len(data)\n        elif length > len(data):\n            raise ValueError(\"Specified length is greater than length of data\")\n        result = libcrypto.EVP_DigestUpdate(self.ctx, c_char_p(data), length)\n        if result != 1:\n            raise DigestError(\"Unable to update digest\")", "response": "Updates the digest with the given byte string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinalizes digest operation and return digest value", "response": "def digest(self, data=None):\n        \"\"\"\n        Finalizes digest operation and return digest value\n        Optionally hashes more data before finalizing\n        \"\"\"\n        if self.digest_finalized:\n            return self.digest_out.raw[:self.digest_size]\n        if data is not None:\n            self.update(data)\n        self.digest_out = create_string_buffer(256)\n        length = c_long(0)\n        result = libcrypto.EVP_DigestFinal_ex(self.ctx, self.digest_out,\n                                              byref(length))\n        if result != 1:\n            raise DigestError(\"Unable to finalize digest\")\n        self.digest_finalized = True\n        return self.digest_out.raw[:self.digest_size]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self):\n\n        new_digest = Digest(self.digest_type)\n        libcrypto.EVP_MD_CTX_copy(new_digest.ctx, self.ctx)\n        return new_digest", "response": "Creates a copy of the current digest CTX"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _clean_ctx(self):\n        try:\n            if self.ctx is not None:\n                libcrypto.EVP_MD_CTX_free(self.ctx)\n                del self.ctx\n        except AttributeError:\n            pass\n        self.digest_out = None\n        self.digest_finalized = False", "response": "Cleans and deallocates context\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the hexadecimal digest in the hexadecimal form. For compatibility with hashlib.", "response": "def hexdigest(self, data=None):\n        \"\"\"\n            Returns digest in the hexadecimal form. For compatibility\n            with hashlib\n        \"\"\"\n        from base64 import b16encode\n        if pyver == 2:\n            return b16encode(self.digest(data))\n        else:\n            return b16encode(self.digest(data)).decode('us-ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _X509__asn1date_to_datetime(asn1date):\n    bio = Membio()\n    libcrypto.ASN1_TIME_print(bio.bio, asn1date)\n    pydate = datetime.strptime(str(bio), \"%b %d %H:%M:%S %Y %Z\")\n    return pydate.replace(tzinfo=utc)", "response": "Converts openssl ASN1_TIME object to python datetime. datetime"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(self, oid):\n        if not isinstance(oid, Oid):\n            raise TypeError(\"Need crytypescrypto.oid.Oid as argument\")\n        found = []\n        index = -1\n        end = len(self)\n        while True:\n            index = libcrypto.X509_get_ext_by_NID(self.cert.cert, oid.nid,\n                                                  index)\n            if index >= end or index < 0:\n                break\n            found.append(self[index])\n        return found", "response": "Return list of extensions with given Oid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_critical(self, crit=True):\n        if crit:\n            flag = 1\n        else:\n            flag = 0\n        found = []\n        end = len(self)\n        index = -1\n        while True:\n            index = libcrypto.X509_get_ext_by_critical(self.cert.cert, flag,\n                                                       index)\n            if index >= end or index < 0:\n                break\n            found.append(self[index])\n        return found", "response": "Return list of critical extensions or list of non - cricital ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pem(self):\n        bio = Membio()\n        if libcrypto.PEM_write_bio_X509(bio.bio, self.cert) == 0:\n            raise X509Error(\"error serializing certificate\")\n        return str(bio)", "response": "Returns PEM represntation of the certificate"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(self, store=None, chain=None, key=None):\n        if store is not None and key is not None:\n            raise X509Error(\"key and store cannot be specified simultaneously\")\n        if store is not None:\n            ctx = libcrypto.X509_STORE_CTX_new()\n            if ctx is None:\n                raise X509Error(\"Error allocating X509_STORE_CTX\")\n            if chain is not None and len(chain) > 0:\n                chain_ptr = StackOfX509(chain).ptr\n            else:\n                chain_ptr = None\n            if libcrypto.X509_STORE_CTX_init(ctx, store.store, self.cert,\n                                             chain_ptr) < 0:\n                raise X509Error(\"Error allocating X509_STORE_CTX\")\n            res = libcrypto.X509_verify_cert(ctx)\n            libcrypto.X509_STORE_CTX_free(ctx)\n            return res > 0\n        else:\n            if key is None:\n                if self.issuer != self.subject:\n                    # Not a self-signed certificate\n                    return False\n                key = self.pubkey\n            res = libcrypto.X509_verify(self.cert, key.key)\n            if res < 0:\n                raise X509Error(\"X509_verify failed\")\n            return res > 0", "response": "Verify self. Supports verification on both X509 store and public issuer key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setpurpose(self, purpose):\n        if isinstance(purpose, str):\n            purp_no = libcrypto.X509_PURPOSE_get_by_sname(purpose)\n            if purp_no <= 0:\n                raise X509Error(\"Invalid certificate purpose '%s'\" % purpose)\n        elif isinstance(purpose, int):\n            purp_no = purpose\n        if libcrypto.X509_STORE_set_purpose(self.store, purp_no) <= 0:\n            raise X509Error(\"cannot set purpose\")", "response": "Sets the certificate purpose which verified certificate should match the store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef settime(self, time):\n        if isinstance(time, datetime) or isinstance(time,\n                                                             datetime.date):\n            seconds = int(time.strftime(\"%s\"))\n        elif isinstance(time, int):\n            seconds = time\n        else:\n            raise TypeError(\"datetime.date, datetime.datetime or integer \" +\n                            \"is required as time argument\")\n        raise NotImplementedError", "response": "Set the time used to check validity of certificates for a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append(self, value):\n        if not self.need_free:\n            raise ValueError(\"Stack is read-only\")\n        if not isinstance(value, X509):\n            raise TypeError('StackOfX509 can contain only X509 objects')\n        sk_push(self.ptr, libcrypto.X509_dup(value.cert))", "response": "Adds certificate to stack"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pbkdf2(password, salt, outlen, digesttype=\"sha1\", iterations=2000):\n    dgst = DigestType(digesttype)\n    out = create_string_buffer(outlen)\n    if isinstance(password,chartype):\n        pwd = password.encode(\"utf-8\")\n    else:\n        pwd = password\n    res = libcrypto.PKCS5_PBKDF2_HMAC(pwd, len(pwd), salt, len(salt),\n                                      iterations, dgst.digest, outlen, out)\n    if res <= 0:\n        raise LibCryptoError(\"error computing PBKDF2\")\n    return out.raw", "response": "Derive a key from a password and a random salt."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an EC keypair from the just secret key and curve name.", "response": "def create(curve, data):\n    \"\"\"\n    Creates EC keypair from the just secret key and curve name\n\n    @param curve - name of elliptic curve\n    @param num - byte array or long number representing key\n    \"\"\"\n    ec_key = libcrypto.EC_KEY_new_by_curve_name(curve.nid)\n    if ec_key is None:\n        raise PKeyError(\"EC_KEY_new_by_curvename\")\n    group = libcrypto.EC_KEY_get0_group(ec_key)\n    if group is None:\n        raise PKeyError(\"EC_KEY_get0_group\")\n    libcrypto.EC_GROUP_set_asn1_flag(group, 1)\n    raw_key = libcrypto.BN_new()\n    if isinstance(data, int):\n        libcrypto.BN_hex2bn(byref(raw_key), hex(data))\n    else:\n        if raw_key is None:\n            raise PKeyError(\"BN_new\")\n        if libcrypto.BN_bin2bn(data, len(data), raw_key) is None:\n            raise PKeyError(\"BN_bin2bn\")\n    ctx = libcrypto.BN_CTX_new()\n    if ctx is None:\n        raise PKeyError(\"BN_CTX_new\")\n    order = libcrypto.BN_new()\n    if order is None:\n        raise PKeyError(\"BN_new\")\n    priv_key = libcrypto.BN_new()\n    if priv_key is None:\n        raise PKeyError(\"BN_new\")\n    if libcrypto.EC_GROUP_get_order(group, order, ctx) <= 0:\n        raise PKeyError(\"EC_GROUP_get_order\")\n    if libcrypto.BN_nnmod(priv_key, raw_key, order, ctx) <= 0:\n        raise PKeyError(\"BN_nnmod\")\n    if libcrypto.EC_KEY_set_private_key(ec_key, priv_key) <= 0:\n        raise PKeyError(\"EC_KEY_set_private_key\")\n    pub_key = libcrypto.EC_POINT_new(group)\n    if pub_key is None:\n        raise PKeyError(\"EC_POINT_new\")\n    if libcrypto.EC_POINT_mul(group, pub_key, priv_key, None, None, ctx) <= 0:\n        raise PKeyError(\"EC_POINT_mul\")\n    if libcrypto.EC_KEY_set_public_key(ec_key, pub_key) <= 0:\n        raise PKeyError(\"EC_KEY_set_public_key\")\n    libcrypto.BN_free(raw_key)\n    libcrypto.BN_free(order)\n    libcrypto.BN_free(priv_key)\n    libcrypto.BN_CTX_free(ctx)\n    pkey = libcrypto.EVP_PKEY_new()\n    if pkey is None:\n        raise PKeyError(\"EVP_PKEY_new\")\n    if libcrypto.EVP_PKEY_set1_EC_KEY(pkey, ec_key) <= 0:\n        raise PKeyError(\"EVP_PKEY_set1_EC_KEY\")\n    libcrypto.EC_KEY_free(ec_key)\n    return PKey(ptr=pkey, cansign=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new Cipher object ready to encrypt - decrypt data on a single key", "response": "def new(algname, key, encrypt=True, iv=None):\n    \"\"\"\n    Returns new cipher object ready to encrypt-decrypt data\n\n    @param algname - string algorithm name like in opemssl command\n                     line\n    @param key - binary string representing ciher key\n    @param encrypt - if True (default) cipher would be initialized\n                    for encryption, otherwise - for decrypton\n    @param iv - initialization vector\n    \"\"\"\n    ciph_type = CipherType(algname)\n    return Cipher(ciph_type, key, iv, encrypt)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef padding(self, padding=True):\n        padding_flag = 1 if padding else 0\n        libcrypto.EVP_CIPHER_CTX_set_padding(self.ctx, padding_flag)", "response": "Sets the padding mode of the cipher s context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform actual encrypton and decipheron on the master key and returns the final decoded version of the data.", "response": "def update(self, data):\n        \"\"\"\n        Performs actual encrypton/decrypion\n\n        @param data - part of the plain text/ciphertext to process\n        @returns - part of ciphercext/plain text\n\n        Passed chunk of text doesn't need to contain full ciher\n        blocks. If neccessery, part of passed data would be kept\n        internally until next data would be received or finish\n        called\n        \"\"\"\n        if self.cipher_finalized:\n            raise CipherError(\"No updates allowed\")\n        if not isinstance(data, bintype):\n            raise TypeError(\"A byte string is expected\")\n        if len(data) == 0:\n            return \"\"\n        outbuf = create_string_buffer(self.block_size+len(data))\n        outlen = c_int(0)\n        ret = libcrypto.EVP_CipherUpdate(self.ctx, outbuf, byref(outlen),\n                                         data, len(data))\n        if ret <= 0:\n            self._clean_ctx()\n            self.cipher_finalized = True\n            raise CipherError(\"problem processing data\")\n        return outbuf.raw[:int(outlen.value)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef finish(self):\n        if self.cipher_finalized:\n            raise CipherError(\"Cipher operation is already completed\")\n        outbuf = create_string_buffer(self.block_size)\n        self.cipher_finalized = True\n        outlen = c_int(0)\n        result = libcrypto.EVP_CipherFinal_ex(self.ctx, outbuf, byref(outlen))\n        if result == 0:\n            self._clean_ctx()\n            raise CipherError(\"Unable to finalize cipher\")\n        if outlen.value > 0:\n            return outbuf.raw[:int(outlen.value)]\n        else:\n            return b\"\"", "response": "Finalizes the internal state of the internal state of the EVP cipher."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning up the cipher ctx and deallocates it.", "response": "def _clean_ctx(self):\n        \"\"\"\n        Cleans up cipher ctx and deallocates it\n        \"\"\"\n        try:\n            if self.ctx is not None:\n                self.__ctxcleanup(self.ctx)\n                libcrypto.EVP_CIPHER_CTX_free(self.ctx)\n                del self.ctx\n        except AttributeError:\n            pass\n        self.cipher_finalized = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets specified engine as default for all algorithms supported by it", "response": "def set_default(eng, algorithms=0xFFFF):\n    \"\"\"\n    Sets specified engine  as default for all\n    algorithms, supported by it\n\n    For compatibility with 0.2.x if string is passed instead\n    of engine, attempts to load engine with this id\n    \"\"\"\n    if not isinstance(eng,Engine):\n        eng=Engine(eng)\n    global default\n    libcrypto.ENGINE_set_default(eng.ptr, c_int(algorithms))\n    default = eng"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a dictionary out of an iterable using an attribute name as Formula the key. Optionally provide a filter function to determine what should be be kept in the dictionary.", "response": "def from_keyed_iterable(iterable, key, filter_func=None):\n    \"\"\"Construct a dictionary out of an iterable, using an attribute name as\n    the key. Optionally provide a filter function, to determine what should be\n    kept in the dictionary.\"\"\"\n\n    generated = {}\n\n    for element in iterable:\n        try:\n            k = getattr(element, key)\n        except AttributeError:\n            raise RuntimeError(\"{} does not have the keyed attribute: {}\".format(\n                element, key\n            ))\n\n        if filter_func is None or filter_func(element):\n            if k in generated:\n                generated[k] += [element]\n            else:\n                generated[k] = [element]\n\n    return generated"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives two dicts a and b this function returns a dictionary where the keys are not in dict_a and the values are in dict_b.", "response": "def subtract_by_key(dict_a, dict_b):\n    \"\"\"given two dicts, a and b, this function returns c = a - b, where\n    a - b is defined as the key difference between a and b.\n\n    e.g.,\n    {1:None, 2:3, 3:\"yellow\", 4:True} - {2:4, 1:\"green\"} =\n        {3:\"yellow\", 4:True}\n\n    \"\"\"\n    difference_dict = {}\n    for key in dict_a:\n        if key not in dict_b:\n            difference_dict[key] = dict_a[key]\n\n    return difference_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef winnow_by_keys(dct, keys=None, filter_func=None):\n    has = {}\n    has_not = {}\n\n    for key in dct:\n        key_passes_check = False\n        if keys is not None:\n            key_passes_check = key in keys\n        elif filter_func is not None:\n            key_passes_check = filter_func(key)\n\n        if key_passes_check:\n            has[key] = dct[key]\n        else:\n            has_not[key] = dct[key]\n\n    return WinnowedResult(has, has_not)", "response": "separates a dict into has - keys and not - has - keys pairs using either\n    a list of keys or a filtering function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setdefaults(dct, defaults):\n    for key in defaults:\n        dct.setdefault(key, defaults[key])\n\n    return dct", "response": "Given a target dct and a dict of default values sets the values for all of those pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unlist(list_thing, complain=True):\n    if complain and len(list_thing) > 1:\n        raise ValueError(\"More than one element in {}\".format(list_thing))\n    elif len(list_thing) == 1:\n        return list_thing[0]\n\n    if complain:\n        raise ValueError(\"Nothing in {}\".format(list_thing))\n    return None", "response": "transforms [ Something ] -> Any other list values. By default raises a ValueError for more than one element in list_thing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flatten(iterable):\n    container = iterable.__class__\n\n    placeholder = []\n    for item in iterable:\n        try:\n            placeholder.extend(flatten(item))\n        except TypeError:\n            placeholder.append(item)\n\n    return container(placeholder)", "response": "Fully flattens an iterable"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction must take an item and return an interable that contains that item.", "response": "def flat_map(iterable, func):\n    \"\"\"func must take an item and return an interable that contains that\n    item. this is flatmap in the classic mode\"\"\"\n    results = []\n    for element in iterable:\n        result = func(element)\n        if len(result) > 0:\n            results.extend(result)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlike the built - in sum but for multiplication.", "response": "def product(sequence, initial=1):\n    \"\"\"like the built-in sum, but for multiplication.\"\"\"\n    if not isinstance(sequence, collections.Iterable):\n        raise TypeError(\"'{}' object is not iterable\".format(type(sequence).__name__))\n\n    return reduce(operator.mul, sequence, initial)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef date_from_string(string, format_string=None):\n\n    if isinstance(format_string, str):\n        return datetime.datetime.strptime(string, format_string).date()\n\n    elif format_string is None:\n        format_string = [\n            \"%Y-%m-%d\",\n            \"%m-%d-%Y\",\n            \"%m/%d/%Y\",\n            \"%d/%m/%Y\",\n        ]\n\n    for format in format_string:\n        try:\n            return datetime.datetime.strptime(string, format).date()\n        except ValueError:\n            continue\n\n    raise ValueError(\"Could not produce date from string: {}\".format(string))", "response": "Takes a string and attempts to coerce them into a datetime."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_datetime(plain_date, hours=0, minutes=0, seconds=0, ms=0):\n    # don't mess with datetimes\n    if isinstance(plain_date, datetime.datetime):\n        return plain_date\n    return datetime.datetime(\n        plain_date.year,\n        plain_date.month,\n        plain_date.day,\n        hours,\n        minutes,\n        seconds,\n        ms,\n    )", "response": "given a datetime. date gives back a datetime. datetime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_containing_period(cls, *periods):\n\n        if any(not isinstance(period, TimePeriod) for period in periods):\n            raise TypeError(\"periods must all be TimePeriods: {}\".format(periods))\n\n        latest = datetime.datetime.min\n        earliest = datetime.datetime.max\n\n        for period in periods:\n            # the best we can do to conain None is None!\n            if period._latest is None:\n                latest = None\n            elif latest is not None and period._latest > latest:\n                latest = period._latest\n\n            if period._earliest is None:\n                earliest = None\n            elif earliest is not None and period._earliest < earliest:\n                earliest = period._earliest\n\n        return TimePeriod(earliest, latest)", "response": "Given a bunch of TimePeriods return a TimePeriod that most closely\n        contains them."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_attr(obj, string_rep, default=_get_attr_raise_on_attribute_error, separator=\".\"):\n    attribute_chain = string_rep.split(separator)\n\n    current_obj = obj\n\n    for attr in attribute_chain:\n        try:\n            current_obj = getattr(current_obj, attr)\n        except AttributeError:\n            if default is _get_attr_raise_on_attribute_error:\n                raise AttributeError(\n                    \"Bad attribute \\\"{}\\\" in chain: \\\"{}\\\"\".format(attr, string_rep)\n                )\n            return default\n\n    return current_obj", "response": "get_attr via a chain of attributes like so"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the username and password for a particular keyring entry.", "response": "def get_user_password(env, param, force=False):\n    \"\"\"\n    Allows the user to print the credential for a particular keyring entry\n    to the screen\n    \"\"\"\n    username = utils.assemble_username(env, param)\n\n    if not utils.confirm_credential_display(force):\n        return\n\n    # Retrieve the credential from the keychain\n    password = password_get(username)\n\n    if password:\n        return (username, password)\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pull_env_credential(env, param, value):\n    rex = \"USE_KEYRING\\[([\\x27\\x22])(.*)\\\\1\\]\"\n\n    # This is the old-style, per-environment keyring credential\n    if value == \"USE_KEYRING\":\n        username = utils.assemble_username(env, param)\n\n    # This is the new-style, global keyring credential that can be applied\n    # to multiple environments\n    else:\n        global_identifier = re.match(rex, value).group(2)\n        username = utils.assemble_username('global', global_identifier)\n\n    return (username, password_get(username))", "response": "Pulls a keyring credential from the supernova config file\n    and returns the username and password combo\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a password from the keychain based on the environment and the user name.", "response": "def password_get(username=None):\n    \"\"\"\n    Retrieves a password from the keychain based on the environment and\n    configuration parameter pair.\n\n    If this fails, None is returned.\n    \"\"\"\n    password = keyring.get_password('supernova', username)\n    if password is None:\n        split_username = tuple(username.split(':'))\n        msg = (\"Couldn't find a credential for {0}:{1}. You need to set one \"\n               \"with: supernova-keyring -s {0} {1}\").format(*split_username)\n        raise LookupError(msg)\n    else:\n        return password.encode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_user_password(environment, parameter, password):\n    username = '%s:%s' % (environment, parameter)\n    return password_set(username, password)", "response": "Sets a user s password in the keyring storage\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef password_set(username=None, password=None):\n    result = keyring.set_password('supernova', username, password)\n\n    # NOTE: keyring returns None when the storage is successful.  That's weird.\n    if result is None:\n        return True\n    else:\n        return False", "response": "Sets a password in a keychain for a particular environment and configuration parameter pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prep_shell_environment(nova_env, nova_creds):\n    new_env = {}\n\n    for key, value in prep_nova_creds(nova_env, nova_creds):\n        if type(value) == six.binary_type:\n            value = value.decode()\n        new_env[key] = value\n\n    return new_env", "response": "Prepare the current shell environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the nova_creds dictionary for the novaclient.", "response": "def prep_nova_creds(nova_env, nova_creds):\n    \"\"\"\n    Finds relevant config options in the supernova config and cleans them\n    up for novaclient.\n    \"\"\"\n    try:\n        raw_creds = dict(nova_creds.get('DEFAULT', {}), **nova_creds[nova_env])\n    except KeyError:\n        msg = \"{0} was not found in your supernova configuration \"\\\n              \"file\".format(nova_env)\n        raise KeyError(msg)\n\n    proxy_re = re.compile(r\"(^http_proxy|^https_proxy)\")\n\n    creds = []\n    for param, value in raw_creds.items():\n        if not proxy_re.match(param):\n            param = param.upper()\n\n        if not hasattr(value, 'startswith'):\n            continue\n\n        # Get values from the keyring if we find a USE_KEYRING constant\n        if value.startswith(\"USE_KEYRING\"):\n            username, credential = pull_env_credential(nova_env, param,\n                                                       value)\n        else:\n            credential = value.strip(\"\\\"'\")\n\n        # Make sure we got something valid from the configuration file or\n        # the keyring\n        if not credential:\n            raise LookupError(\"No matching credentials found in keyring\")\n\n        creds.append((param, credential))\n\n    return creds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_config(config_file_override=False):\n    supernova_config = get_config_file(config_file_override)\n    supernova_config_dir = get_config_directory(config_file_override)\n\n    if not supernova_config and not supernova_config_dir:\n        raise Exception(\"Couldn't find a valid configuration file to parse\")\n\n    nova_creds = ConfigObj()\n\n    # Can we successfully read the configuration file?\n    if supernova_config:\n        try:\n            nova_creds.merge(ConfigObj(supernova_config))\n        except:\n            raise(\"There's an error in your configuration file\")\n\n    if supernova_config_dir:\n        for dir_file in os.listdir(supernova_config_dir):\n            full_path = ''.join((supernova_config_dir, dir_file))\n            try:\n                nova_creds.merge(ConfigObj(full_path))\n            except:\n                msg = \"Skipping '%s', Parsing Error.\".format(full_path)\n                print(msg)\n\n    create_dynamic_configs(nova_creds)\n    return nova_creds", "response": "Loads the supernova configuration file and creates dynamic configs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config_file(override_files=False):\n    if override_files:\n        if isinstance(override_files, six.string_types):\n            possible_configs = [override_files]\n        else:\n            raise Exception(\"Config file override must be a string\")\n    else:\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME') or \\\n            os.path.expanduser('~/.config')\n        possible_configs = [os.path.join(xdg_config_home, \"supernova\"),\n                            os.path.expanduser(\"~/.supernova\"),\n                            \".supernova\"]\n\n    for config_file in reversed(possible_configs):\n        if os.path.isfile(config_file):\n            return config_file\n\n    return False", "response": "Returns the most specific configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the most specific configuration directory.", "response": "def get_config_directory(override_files=False):\n    \"\"\"\n    Looks for the most specific configuration directory possible, in order to\n    load individual configuration files.\n    \"\"\"\n    if override_files:\n        possible_dirs = [override_files]\n\n    else:\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME') or \\\n            os.path.expanduser('~/.config')\n        possible_dirs = [os.path.join(xdg_config_home, \"supernova.d/\"),\n                         os.path.expanduser(\"~/.supernova.d/\"),\n                         \".supernova.d/\"]\n\n    for config_dir in reversed(possible_dirs):\n        if os.path.isdir(config_dir):\n            return config_dir\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_executable(nova_args, env_vars):\n    process = subprocess.Popen(nova_args,\n                               stdout=sys.stdout,\n                               stderr=subprocess.PIPE,\n                               env=env_vars)\n    process.wait()\n    return process", "response": "Executes the executable given by the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the user wants to run the executable with debugging enabled.", "response": "def check_for_debug(supernova_args, nova_args):\n    \"\"\"\n    If the user wanted to run the executable with debugging enabled, we need\n    to apply the correct arguments to the executable.\n\n    Heat is a corner case since it uses -d instead of --debug.\n    \"\"\"\n    # Heat requires special handling for debug arguments\n    if supernova_args['debug'] and supernova_args['executable'] == 'heat':\n        nova_args.insert(0, '-d ')\n    elif supernova_args['debug']:\n        nova_args.insert(0, '--debug ')\n\n    return nova_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_for_executable(supernova_args, env_vars):\n    exe = supernova_args.get('executable', 'default')\n    if exe != 'default':\n        return supernova_args\n    if 'OS_EXECUTABLE' in env_vars.keys():\n        supernova_args['executable'] = env_vars['OS_EXECUTABLE']\n        return supernova_args\n    supernova_args['executable'] = 'nova'\n    return supernova_args", "response": "Check if the user has specified a custom executable via an environment variable. If we detect one we should add it to the supernova s supernova s executable argument. If we don t then we will add it to the supernova s executable argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of extra args that need to be passed on cmdline to nova.", "response": "def check_for_bypass_url(raw_creds, nova_args):\n    \"\"\"\n    Return a list of extra args that need to be passed on cmdline to nova.\n    \"\"\"\n    if 'BYPASS_URL' in raw_creds.keys():\n        bypass_args = ['--bypass-url', raw_creds['BYPASS_URL']]\n        nova_args = bypass_args + nova_args\n\n    return nova_args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle stderr from the command s output and displays it after the command s output is printed by run_command.", "response": "def handle_stderr(stderr_pipe):\n    \"\"\"\n    Takes stderr from the command's output and displays it AFTER the stdout\n    is printed by run_command().\n    \"\"\"\n    stderr_output = stderr_pipe.read()\n\n    if len(stderr_output) > 0:\n        click.secho(\"\\n__ Error Output {0}\".format('_'*62), fg='white',\n                    bold=True)\n        click.echo(stderr_output)\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command(nova_creds, nova_args, supernova_args):\n    nova_env = supernova_args['nova_env']\n    # (gtmanfred) make a copy of this object.  If we don't copy it, the insert\n    # to 0 happens multiple times because it is the same object in memory.\n    nova_args = copy.copy(nova_args)\n\n    # Get the environment variables ready\n    env_vars = os.environ.copy()\n    env_vars.update(credentials.prep_shell_environment(nova_env,\n                                                       nova_creds))\n\n    # BYPASS_URL is a weird one, so we need to send it as an argument,\n    # not an environment variable.\n    nova_args = check_for_bypass_url(nova_creds[nova_env], nova_args)\n\n    # Check for OS_EXECUTABLE\n    supernova_args = check_for_executable(supernova_args, env_vars)\n\n    # Check for a debug override\n    nova_args = check_for_debug(supernova_args, nova_args)\n\n    # Print a small message for the user (very helpful for groups)\n    msg = \"Running %s against %s...\" % (supernova_args.get('executable'),\n                                        nova_env)\n    if not supernova_args.get('quiet'):\n        click.echo(\"[%s] %s \" % (click.style('SUPERNOVA', fg='green'), msg))\n\n    # Call executable and connect stdout to the current terminal\n    # so that any unicode characters from the executable's list will be\n    # displayed appropriately.\n    #\n    # In other news, I hate how python 2.6 does unicode.\n    nova_args.insert(0, supernova_args['executable'])\n    nova_args = [nova_arg.strip() for nova_arg in nova_args]\n    process = execute_executable(nova_args, env_vars)\n\n    # If the user asked us to be quiet, then let's not print stderr\n    if not supernova_args.get('quiet'):\n        handle_stderr(process.stderr)\n\n    return process.returncode", "response": "Runs the executable and returns the output."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_environment_presets():\n    presets = [x for x in os.environ.copy().keys() if x.startswith('NOVA_') or\n               x.startswith('OS_')]\n    if len(presets) < 1:\n        return True\n    else:\n        click.echo(\"_\" * 80)\n        click.echo(\"*WARNING* Found existing environment variables that may \"\n                   \"cause conflicts:\")\n        for preset in presets:\n            click.echo(\"  - %s\" % preset)\n        click.echo(\"_\" * 80)\n        return False", "response": "Checks for environment variables that can cause problems with supernova\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_envs_in_group(group_name, nova_creds):\n    envs = []\n    for key, value in nova_creds.items():\n        supernova_groups = value.get('SUPERNOVA_GROUP', [])\n        if hasattr(supernova_groups, 'startswith'):\n            supernova_groups = [supernova_groups]\n        if group_name in supernova_groups:\n            envs.append(key)\n        elif group_name == 'all':\n            envs.append(key)\n    return envs", "response": "Takes a group_name and returns a list of all environments that are in the group_name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid_group(group_name, nova_creds):\n    valid_groups = []\n    for key, value in nova_creds.items():\n        supernova_groups = value.get('SUPERNOVA_GROUP', [])\n        if hasattr(supernova_groups, 'startswith'):\n            supernova_groups = [supernova_groups]\n        valid_groups.extend(supernova_groups)\n    valid_groups.append('all')\n    if group_name in valid_groups:\n        return True\n    else:\n        return False", "response": "Checks to see if the group_name is a valid group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving nova_ os_ novaclient_ prefix from string.", "response": "def rm_prefix(name):\n    \"\"\"\n    Removes nova_ os_ novaclient_ prefix from string.\n    \"\"\"\n    if name.startswith('nova_'):\n        return name[5:]\n    elif name.startswith('novaclient_'):\n        return name[11:]\n    elif name.startswith('os_'):\n        return name[3:]\n    else:\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a command in a specific environment.", "response": "def run_supernova(ctx, executable, debug, quiet, environment, command, conf,\n                  echo, dashboard):\n    \"\"\"\n    You can use supernova with many OpenStack clients and avoid the pain of\n    managing multiple sets of environment variables.  Getting started is easy\n    and there's some documentation that can help:\n\n      http://supernova.readthedocs.org/\n\n    The first step is to get your environment variables packed into a\n    configuration file, usually in ~/.supernova.  The docs (linked above) have\n    some good examples that you can fill in via copy/paste.\n\n    Once you have a configuration ready to go, replace 'prod' below with one\n    of your configured environments and try some of these commands:\n\n      supernova prod list                 (Lists instances via novaclient)\n      supernova prod image-list           (Lists images via novaclient)\n      supernova prod boot ...             (Boots an instance via novaclient)\n\n    Have questions, bugs, or comments?  Head on over to Github and open an\n    issue or submit a pull request!\n\n      https://github.com/major/supernova\n    \"\"\"\n    # Retrieve our credentials from the configuration file\n    try:\n        nova_creds = config.run_config(config_file_override=conf)\n    except Exception as e:\n        msg = (\"\\n  There's an error in your configuration file:\\n\\n\"\n               \"    {0}\\n\").format(e)\n        click.echo(msg)\n        ctx.exit(1)\n\n    # Warn the user if there are potentially conflicting environment variables\n    # already set in the user's environment.\n    utils.check_environment_presets()\n\n    # Is our environment argument a single environment or a supernova group?\n    if utils.is_valid_group(environment, nova_creds):\n        envs = utils.get_envs_in_group(environment, nova_creds)\n    elif ',' in environment:\n        envs = []\n\n        for env in environment.split(','):\n            if utils.is_valid_group(env, nova_creds):\n                envs.extend(utils.get_envs_in_group(env, nova_creds))\n            else:\n                envs.append(env)\n    elif environment.startswith('/') and environment.endswith('/'):\n        envs = [nova_env for nova_env in nova_creds.keys()\n                if re.search(environment[1:-1], nova_env)]\n    else:\n        envs = [environment]\n\n    # These are arguments for supernova and not the executable that supernova\n    # will eventually call.\n    supernova_args = {\n        'debug': debug,\n        'executable': executable,\n        'quiet': quiet,\n        'echo': echo,\n        'dashboard': dashboard,\n    }\n\n    # If the user specified a single environment, we need to verify that the\n    # environment actually exists in their configuration file.\n    if len(envs) == 1 and not utils.is_valid_environment(envs[0], nova_creds):\n        msg = (\"\\nCouldn't find an environment called '{0}' in your \"\n               \"configuration file.\\nTry supernova --list to see all \"\n               \"configured environments.\\n\".format(envs[0]))\n        click.echo(msg)\n        ctx.exit(1)\n\n    if supernova_args['echo']:\n        if len(envs) > 1:\n            msg = (\"\\nCan't echo a group of environments.\\nSpecify a single \"\n                   \"environment when using --echo.\")\n            click.echo(msg)\n            ctx.exit(1)\n        env = credentials.prep_shell_environment(envs[0], nova_creds)\n        for k in env:\n            click.echo('{0}={1}'.format(k, env[k]))\n        ctx.exit(0)\n\n    if supernova_args['dashboard']:\n        if len(envs) > 1:\n            msg = (\"\\nCan't open dashboard for a group of environments.\\n\"\n                   \"Specify a single environment when using --dashboard.\")\n            click.echo(msg)\n            ctx.exit(1)\n        url = nova_creds[envs[0]].get('SUPERNOVA_DASHBOARD_URL')\n        if url is None:\n            msg = (\"\\nNo SUPERNOVA_DASHBOARD_URL specified \"\n                   \"for environment: %s\" % envs[0])\n            click.echo(msg)\n            ctx.exit(1)\n        webbrowser.open(url)\n        ctx.exit(0)\n\n    if len(command) == 0:\n        msg = (\"\\nMissing arguments to pass to executable  Run supernova \"\n               \"--help for examples.\\n\".format(envs[0]))\n        click.echo(msg)\n        ctx.exit(1)\n\n    nova_args = list(command)\n\n    # Loop through the single environment (if the user specified one) or all\n    # of the environments in a supernova group (if the user specified a group).\n    for env in envs:\n        supernova_args['nova_env'] = env\n        returncode = supernova.run_command(nova_creds, nova_args,\n                                           supernova_args)\n\n    # NOTE(major): The return code here is the one that comes back from the\n    # OS_EXECUTABLE that supernova runs (by default, 'nova').  When using\n    # supernova groups, the return code is the one returned by the executable\n    # for the last environment in the group.\n    #\n    # It's not ideal, but it's all I can think of for now. ;)\n    sys.exit(returncode)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_supernova_keyring(ctx, action, environment, parameter):\n    if action == 'get_credential':\n        result = credentials.get_user_password(env=environment,\n                                               param=parameter)\n        if not result:\n            click.echo(\"\\nUnable to find a credential matching the data \"\n                       \"provided.\")\n            ctx.exit(1)\n        else:\n            click.echo(\"\\nFound credential for {0}: {1}\".format(*result))\n            ctx.exit()\n\n    elif action == 'set_credential':\n        msg = \"\"\"\nPreparing to set a credential in the keyring for:\n\n  - Environment  : {0}\n  - Parameter    : {1}\n\nIf this is correct, enter the corresponding credential to store in your keyring\nor press CTRL-C to abort\"\"\".format(environment, parameter)\n        credential = click.prompt(text=msg, hide_input=True)\n\n        result = credentials.set_user_password(environment=environment,\n                                               parameter=parameter,\n                                               password=credential)\n\n        if result:\n            click.echo(\"\\nSuccessfully stored.\")\n            ctx.exit()\n        else:\n            click.echo(\"\\nUnable to store your credential.\")\n            ctx.exit(1)\n    else:\n        click.secho(\"ERROR: must specify --get or --set\", bold=True)\n        click.echo(ctx.get_help())\n        ctx.exit()", "response": "Sets or retrieves credentials stored in your system s keyring using the supernova keyring module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npadding strdata with a Request s callback argument if specified.", "response": "def __pad(strdata):\r\n    \"\"\" Pads `strdata` with a Request's callback argument, if specified, or does\r\n    nothing.\r\n    \"\"\"\r\n    if request.args.get('callback'):\r\n        return \"%s(%s);\" % (request.args.get('callback'), strdata)\r\n    else:\r\n        return strdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __dumps(*args, **kwargs):\r\n    indent = None\r\n    if (current_app.config.get('JSONIFY_PRETTYPRINT_REGULAR', False) and\r\n            not request.is_xhr):\r\n        indent = 2\r\n    return json.dumps(args[0] if len(args) is 1 else dict(*args, **kwargs),\r\n                      indent=indent)", "response": "Serializes args and kwargs as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new instance of the response class with the JSON or JSON - Padded representation of the given arguments with an application / json mimetype respectively.", "response": "def jsonpify(*args, **kwargs):\r\n    \"\"\"Creates a :class:`~flask.Response` with the JSON or JSON-P\r\n    representation of the given arguments with an `application/json`\r\n    or `application/javascript` mimetype, respectively.  The arguments\r\n    to this function are the same as to the :class:`dict` constructor,\r\n    but also accept an array. If a `callback` is specified in the\r\n    request arguments, the response is JSON-Padded.\r\n\r\n    Example usage::\r\n\r\n        @app.route('/_get_current_user')\r\n        def get_current_user():\r\n            return jsonify(username=g.user.username,\r\n                           email=g.user.email,\r\n                           id=g.user.id)\r\n\r\n\r\n    GET /_get_current_user:\r\n    This will send a JSON response like this to the browser::\r\n\r\n        {\r\n            \"username\": \"admin\",\r\n            \"email\": \"admin@localhost\",\r\n            \"id\": 42\r\n        }\r\n\r\n    or, if a callback is specified,\r\n\r\n    GET /_get_current_user?callback=displayUsers\r\n\r\n    Will result in a JSON response like this to the browser::\r\n        displayUsers({\r\n            \"username\": \"admin\",\r\n            \"email\": \"admin@localhost\",\r\n            \"id\": 42\r\n        });\r\n\r\n    This requires Python 2.6 or an installed version of simplejson.  For\r\n    security reasons only objects are supported toplevel.  For more\r\n    information about this, have a look at :ref:`json-security`.\r\n\r\n    .. versionadded:: 0.2\r\n\r\n    \"\"\"\r\n    return current_app.response_class(__pad(__dumps(*args, **kwargs)),\r\n                                      mimetype=__mimetype())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the type and typestring lookup dicts.", "response": "def update_type_lookups(self):\n        \"\"\" Update type and typestring lookup dicts.\n\n        Must be called once the ``types`` and ``python_type_strings``\n        attributes are set so that ``type_to_typestring`` and\n        ``typestring_to_type`` are constructed.\n\n        .. versionadded:: 0.2\n\n        Notes\n        -----\n        Subclasses need to call this function explicitly.\n\n        \"\"\"\n        self.type_to_typestring = dict(zip(self.types,\n                                           self.python_type_strings))\n        self.typestring_to_type = dict(zip(self.python_type_strings,\n                                           self.types))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_type_string(self, data, type_string):\n        if type_string is not None:\n            return type_string\n        else:\n            tp = type(data)\n            try:\n                return self.type_to_typestring[tp]\n            except KeyError:\n                return self.type_to_typestring[tp.__module__ + '.'\n                                               + tp.__name__]", "response": "Gets the type string associated with data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, f, grp, name, data, type_string, options):\n        raise NotImplementedError('Can''t write data type: '\n                                  + str(type(data)))", "response": "Writes an object s metadata to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites the metadata for a Python object to file at name dsetgrp.", "response": "def write_metadata(self, f, dsetgrp, data, type_string, options,\n                       attributes=None):\n        \"\"\" Writes an object to file.\n\n        Writes the metadata for a Python object `data` to file at `name`\n        in h5py.Group `grp`. Metadata is written to HDF5\n        Attributes. Existing Attributes that are not being used are\n        deleted.\n\n        .. versionchanged:: 0.2\n           Arguements changed.\n\n        Parameters\n        ----------\n        f : h5py.File\n            The HDF5 file handle that is open.\n        dsetgrp : h5py.Dataset or h5py.Group\n            The Dataset or Group object to add metadata to.\n        data\n            The object to write to file.\n        type_string : str or None\n            The type string for `data`. If it is ``None``, one will have\n            to be gotten by ``get_type_string``.\n        options : hdf5storage.core.Options\n            hdf5storage options object.\n        attributes : dict or None, optional\n            The Attributes to set. The keys (``str``) are the names. The\n            values are ``tuple`` of the Attribute kind and the value to\n            set. Valid kinds are ``'string_array'``, ``'string'``, and\n            ``'value'``. The values must correspond to what\n            ``set_attribute_string_array``, ``set_attribute_string`` and\n            ``set_attribute`` would take respectively. Default is\n            no Attributes to set (``None``).\n\n        Notes\n        -----\n        The attribute 'Python.Type' is set to the type string. All H5PY\n        Attributes not in ``python_attributes`` and/or\n        ``matlab_attributes`` (depending on the attributes of 'options')\n        are deleted. These are needed functions for writting essentially\n        any Python object, so subclasses should probably call the\n        baseclass's version of this function if they override it and\n        just provide the additional functionality needed. This requires\n        that the names of any additional HDF5 Attributes are put in the\n        appropriate set.\n\n        See Also\n        --------\n        utilities.set_attributes_all\n\n        \"\"\"\n        if attributes is None:\n            attributes = dict()\n        # Make sure we have a complete type_string.\n        if options.store_python_metadata \\\n                and 'Python.Type' not in attributes:\n            attributes['Python.Type'] = \\\n                ('string', self.get_type_string(data, type_string))\n        set_attributes_all(dsetgrp, attributes, discard_others=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode single hex or unicode escapes found in regex matches.", "response": "def _replace_fun_unescape(m):\n    \"\"\" Decode single hex/unicode escapes found in regex matches.\n\n    Supports single hex/unicode escapes of the form ``'\\\\xYY'``,\n    ``'\\\\uYYYY'``, and ``'\\\\UYYYYYYYY'`` where Y is a hex digit. Only\n    decodes if there is an odd number of backslashes.\n\n    .. versionadded:: 0.2\n\n    Parameters\n    ----------\n    m : regex match\n\n    Returns\n    -------\n    c : str\n        The unescaped character.\n\n    \"\"\"\n    slsh = b'\\\\'.decode('ascii')\n    s = m.group(0)\n    count = s.count(slsh)\n    if count % 2 == 0:\n        return s\n    else:\n        if sys.hexversion >= 0x03000000:\n            c = chr(int(s[(count + 1):], base=16))\n        else:\n            c = unichr(int(s[(count + 1):], base=16))\n        return slsh * (count - 1) + c"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhexes / unicode escapes a path.", "response": "def escape_path(pth):\n    \"\"\" Hex/unicode escapes a path.\n\n    Escapes a path so that it can be represented faithfully in an HDF5\n    file without changing directories. This means that leading ``'.'``\n    must be escaped. ``'/'`` and null must be escaped to. Backslashes\n    are escaped as double backslashes. Other escaped characters are\n    replaced with ``'\\\\xYY'``, ``'\\\\uYYYY', or ``'\\\\UYYYYYYYY'`` where Y\n    are hex digits depending on the unicode numerical value of the\n    character. for ``'.'``, both slashes, and null; this will be the\n    former (``'\\\\xYY'``).\n\n    .. versionadded:: 0.2\n\n    Parameters\n    ----------\n    pth : str or bytes\n        The path to escape.\n\n    Returns\n    -------\n    epth : str\n        The escaped path.\n\n    Raises\n    ------\n    TypeError\n        If `pth` is not the right type.\n\n    See Also\n    --------\n    unescape_path\n\n    \"\"\"\n    if isinstance(pth, bytes):\n        pth = pth.decode('utf-8')\n    if sys.hexversion >= 0x03000000:\n        if not isinstance(pth, str):\n            raise TypeError('pth must be str or bytes.')\n        match = _find_dots_re.match(pth)\n        if match is None:\n            prefix = ''\n            s = pth\n        else:\n            prefix = '\\\\x2e' * match.end()\n            s = pth[match.end():]\n    else:\n        if not isinstance(pth, unicode):\n            raise TypeError('pth must be unicode or str.')\n        match = _find_dots_re.match(pth)\n        if match is None:\n            prefix = unicode('')\n            s = pth\n        else:\n            prefix = unicode('\\\\x2e') * match.end()\n            s = pth[match.end():]\n    return prefix + _find_fslashnull_re.sub(_replace_fun_escape, s)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unescape_path(pth):\n    if isinstance(pth, bytes):\n        pth = pth.decode('utf-8')\n    if sys.hexversion >= 0x03000000:\n        if not isinstance(pth, str):\n            raise TypeError('pth must be str or bytes.')\n    else:\n        if not isinstance(pth, unicode):\n            raise TypeError('pth must be unicode or str.')\n    # Look for invalid escapes.\n    if _find_invalid_escape_re.search(pth) is not None:\n        raise ValueError('Invalid escape found.')\n    # Do all hex/unicode escapes.\n    s = _find_escapes_re.sub(_replace_fun_unescape, pth)\n    # Do all double backslash escapes.\n    return s.replace(b'\\\\\\\\'.decode('ascii'), b'\\\\'.decode('ascii'))", "response": "Hex or unicode unescapes a path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_path(pth):\n    # Do conversions and possibly escapes.\n    if isinstance(pth, bytes):\n        p = pth.decode('utf-8')\n    elif (sys.hexversion >= 0x03000000 and isinstance(pth, str)) \\\n            or (sys.hexversion < 0x03000000 \\\n            and isinstance(pth, unicode)):\n        p = pth\n    elif not isinstance(pth, collections.Iterable):\n        raise TypeError('p must be str, bytes, or an iterable '\n                        + 'solely of one of those two.')\n    else:\n        # Check that all elements are unicode or bytes.\n        if sys.hexversion >= 0x03000000:\n            if not all([isinstance(s, (bytes, str)) for s in pth]):\n                raise TypeError('Elements of p must be str or bytes.')\n        else:\n            if not all([isinstance(s, (str, unicode)) for s in pth]):\n                raise TypeError('Elements of p must be str or '\n                                + 'unicode.')\n\n        # Escape (and possibly convert to unicode) each element and then\n        # join them all together.\n        parts = [None] * len(pth)\n        for i, s in enumerate(pth):\n            if isinstance(s, bytes):\n                s = s.decode('utf-8')\n            parts[i] = escape_path(s)\n        parts = tuple(parts)\n        p = posixpath.join(*parts)\n\n    # Remove double slashes and a non-root trailing slash.\n    path = posixpath.normpath(p)\n\n    # Extract the group name and the target name (will be a dataset if\n    # data can be mapped to it, but will end up being made into a group\n    # otherwise. As HDF5 files use posix path, conventions, posixpath\n    # will do everything.\n    groupname = posixpath.dirname(path)\n    targetname = posixpath.basename(path)\n\n    # If groupname got turned into blank, then it is just root.\n    if len(groupname) == 0:\n        groupname = b'/'.decode('ascii')\n\n    # If targetname got turned blank, then it is the current directory.\n    if len(targetname) == 0:\n        targetname = b'.'.decode('ascii')\n\n    return groupname, targetname", "response": "Processes a path and returns a new Tree from it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines whether a dtype or one of its fields has a zero shape.", "response": "def does_dtype_have_a_zero_shape(dt):\n    \"\"\" Determine whether a dtype (or its fields) have zero shape.\n\n    Determines whether the given ``numpy.dtype`` has a shape with a zero\n    element or if one of its fields does, or if one of its fields'\n    fields does, and so on recursively. The following dtypes do not have\n    zero shape.\n\n    * ``'uint8'``\n    * ``[('a', 'int32'), ('blah', 'float16', (3, 3))]``\n    * ``[('a', [('b', 'complex64')], (2, 1, 3))]``\n\n    But the following do\n\n    * ``('uint8', (1, 0))``\n    * ``[('a', 'int32'), ('blah', 'float16', (3, 0))]``\n    * ``[('a', [('b', 'complex64')], (2, 0, 3))]``\n\n    Parameters\n    ----------\n    dt : numpy.dtype\n        The dtype to check.\n\n    Returns\n    -------\n    yesno : bool\n        Whether `dt` or one of its fields has a shape with at least one\n        element that is zero.\n\n    Raises\n    ------\n    TypeError\n        If `dt` is not a ``numpy.dtype``.\n\n    \"\"\"\n    components = [dt]\n    while 0 != len(components):\n        c = components.pop()\n        if 0 in c.shape:\n            return True\n        if c.names is not None:\n            components.extend([v[0] for v in c.fields.values()])\n        if c.base != c:\n            components.append(c.base)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a piece of data into an HDF5 file.", "response": "def write_data(f, grp, name, data, type_string, options):\n    \"\"\" Writes a piece of data into an open HDF5 file.\n\n    Low level function to store a Python type (`data`) into the\n    specified Group.\n\n    Parameters\n    ----------\n    f : h5py.File\n        The open HDF5 file.\n    grp : h5py.Group or h5py.File\n        The Group to place the data in.\n    name : str\n        The name to write the data to.\n    data : any\n        The data to write.\n    type_string : str or None\n        The type string of the data, or ``None`` to deduce\n        automatically.\n    options : hdf5storage.core.Options\n        The options to use when writing.\n\n    Raises\n    ------\n    NotImplementedError\n        If writing `data` is not supported.\n    TypeNotMatlabCompatibleError\n        If writing a type not compatible with MATLAB and\n        `options.action_for_matlab_incompatible` is set to ``'error'``.\n\n    See Also\n    --------\n    hdf5storage.write : Higher level version.\n    read_data\n    hdf5storage.Options\n\n    \"\"\"\n    # Get the marshaller for type(data). The required modules should be\n    # here and imported.\n    tp = type(data)\n    m, has_modules = \\\n        options.marshaller_collection.get_marshaller_for_type(tp)\n\n    # If a marshaller was found and we have the required modules, use it\n    # to write the data. Otherwise, return an error. If we get something\n    # other than None back, then we must recurse through the\n    # entries. Also, we must set the H5PATH attribute to be the path to\n    # the containing group.\n\n    if m is not None and has_modules:\n        m.write(f, grp, name, data, type_string, options)\n    else:\n        raise NotImplementedError('Can''t write data type: '+str(tp))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_data(f, grp, name, options, dsetgrp=None):\n    if dsetgrp is None:\n        # If name isn't found, return error.\n        try:\n            dsetgrp = grp[name]\n        except:\n            raise hdf5storage.exceptions.CantReadError( \\\n                'Could not find ' + posixpath.join(grp.name, name))\n\n    # Get all attributes with values.\n    if sys.hexversion >= 0x03000000:\n        defaultfactory = type(None)\n    else:\n        defaultfactory = lambda : None\n    attributes = collections.defaultdict(defaultfactory,\n                                         dsetgrp.attrs.items())\n\n    # Get the different attributes that can be used to identify they\n    # type, which are the type string and the MATLAB class.\n    type_string = convert_attribute_to_string(attributes['Python.Type'])\n    matlab_class = convert_attribute_to_string( \\\n        attributes['MATLAB_class'])\n\n    # If the type_string is present, get the marshaller for it. If it is\n    # not, use the one for the matlab class if it is given. Otherwise,\n    # use the fallback (NumpyScalarArrayMarshaller for both Datasets and\n    # Groups). If calls to the marshaller collection to get the right\n    # marshaller don't return one (return None), we also go to the\n    # default). Also get whether we have the modules required to read it\n    # accurately or not (approximately)\n\n    m = None\n    has_modules = False\n    mc = options.marshaller_collection\n    if type_string is not None:\n        m, has_modules = mc.get_marshaller_for_type_string(type_string)\n    elif matlab_class is not None:\n        m, has_modules = \\\n            mc.get_marshaller_for_matlab_class(matlab_class)\n    elif hasattr(dsetgrp, 'dtype'):\n        # Numpy dataset\n        m, has_modules = \\\n            mc.get_marshaller_for_type(dsetgrp.dtype.type)\n    elif isinstance(dsetgrp, (h5py.Group, h5py.File)):\n        # Groups and files are like Matlab struct\n        m, has_modules = mc.get_marshaller_for_matlab_class('struct')\n\n    if m is None:\n        # use Numpy as a fallback\n        m, has_modules = mc.get_marshaller_for_type(np.uint8)\n\n    # If a marshaller was found, use it to write the data. Otherwise,\n    # return an error.\n\n    if m is not None:\n        if has_modules:\n            return m.read(f, dsetgrp, attributes, options)\n        else:\n            return m.read_approximate(f, dsetgrp, attributes, options)\n    else:\n        raise hdf5storage.exceptions.CantReadError('Could not read '\n                                                   + dsetgrp.name)", "response": "Reads a piece of data from an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_object_array(f, data, options):\n    # We need to grab the special reference dtype and make an empty\n    # array to store all the references in.\n    ref_dtype = h5py.special_dtype(ref=h5py.Reference)\n    data_refs = np.zeros(shape=data.shape, dtype='object')\n\n    # We need to make sure that the group to hold references is present,\n    # and create it if it isn't.\n\n    if options.group_for_references not in f:\n        f.create_group(options.group_for_references)\n\n    grp2 = f[options.group_for_references]\n\n    if not isinstance(grp2, h5py.Group):\n        del f[options.group_for_references]\n        f.create_group(options.group_for_references)\n        grp2 = f[options.group_for_references]\n\n    # The Dataset 'a' needs to be present as the canonical empty. It is\n    # just and np.uint32/64([0, 0]) with its a MATLAB_class of\n    # 'canonical empty' and the 'MATLAB_empty' attribute set. If it\n    # isn't present or is incorrectly formatted, it is created\n    # truncating anything previously there.\n    try:\n        dset_a = grp2['a']\n        if dset_a.shape != (2,) \\\n                or not dset_a.dtype.name.startswith('uint') \\\n                or np.any(dset_a[...] != np.uint64([0, 0])) \\\n                or get_attribute_string(dset_a, 'MATLAB_class') != \\\n                'canonical empty' \\\n                or get_attribute(dset_a, 'MATLAB_empty') != 1:\n            del grp2['a']\n            dset_a = grp2.create_dataset('a', data=np.uint64([0, 0]))\n            set_attribute_string(dset_a, 'MATLAB_class',\n                                 'canonical empty')\n            set_attribute(dset_a, 'MATLAB_empty',\n                          np.uint8(1))\n    except:\n        dset_a = grp2.create_dataset('a', data=np.uint64([0, 0]))\n        set_attribute_string(dset_a, 'MATLAB_class',\n                             'canonical empty')\n        set_attribute(dset_a, 'MATLAB_empty',\n                      np.uint8(1))\n\n    # Go through all the elements of data and write them, gabbing their\n    # references and putting them in data_refs. They will be put in\n    # group_for_references, which is also what the H5PATH needs to be\n    # set to if we are doing MATLAB compatibility (otherwise, the\n    # attribute needs to be deleted). If an element can't be written\n    # (doing matlab compatibility, but it isn't compatible with matlab\n    # and action_for_matlab_incompatible option is True), the reference\n    # to the canonical empty will be used for the reference array to\n    # point to.\n    grp2name = grp2.name\n    for index, x in np.ndenumerate(data):\n        name_for_ref = next_unused_name_in_group(grp2, 16)\n        write_data(f, grp2, name_for_ref, x, None, options)\n        try:\n            dset = grp2[name_for_ref]\n            data_refs[index] = dset.ref\n            if options.matlab_compatible:\n                set_attribute_string(dset,\n                                     'H5PATH', grp2name)\n            else:\n                del_attribute(dset, 'H5PATH')\n        except:\n            data_refs[index] = dset_a.ref\n\n    # Now, the dtype needs to be changed to the reference type and the\n    # whole thing copied over to data_to_store.\n    return data_refs.astype(ref_dtype).copy()", "response": "Writes an array of objects recursively in the HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_object_array(f, data, options):\n    # Go through all the elements of data and read them using their\n    # references, and the putting the output in new object array.\n    data_derefed = np.zeros(shape=data.shape, dtype='object')\n    for index, x in np.ndenumerate(data):\n        data_derefed[index] = read_data(f, None, None,\n                                        options,\n                                        dsetgrp=f[x])\n    return data_derefed", "response": "Reads an array of objects recursively from the given data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_unused_name_in_group(grp, length):\n    # While\n    #\n    # ltrs = string.ascii_letters + string.digits\n    # name = ''.join([random.choice(ltrs) for i in range(length)])\n    #\n    # seems intuitive, its performance is abysmal compared to\n    #\n    # '%0{0}x'.format(length) % random.getrandbits(length * 4)\n    #\n    # The difference is a factor of 20. Idea from\n    #\n    # https://stackoverflow.com/questions/2782229/most-lightweight-way-\n    #   to-create-a-random-string-and-a-random-hexadecimal-number/\n    #   35161595#35161595\n    fmt = '%0{0}x'.format(length)\n    name = fmt % random.getrandbits(length * 4)\n    while name in grp:\n        name = fmt % random.getrandbits(length * 4)\n    return name", "response": "Generates a name that isn t used in a group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a numpy. unicode \\ _ to numpy. uint16 in numpy. uint16 form.", "response": "def convert_numpy_str_to_uint16(data):\n    \"\"\" Converts a numpy.unicode\\_ to UTF-16 in numpy.uint16 form.\n\n    Convert a ``numpy.unicode_`` or an array of them (they are UTF-32\n    strings) to UTF-16 in the equivalent array of ``numpy.uint16``. The\n    conversion will throw an exception if any characters cannot be\n    converted to UTF-16. Strings are expanded along rows (across columns)\n    so a 2x3x4 array of 10 element strings will get turned into a 2x30x4\n    array of uint16's if every UTF-32 character converts easily to a\n    UTF-16 singlet, as opposed to a UTF-16 doublet.\n\n    Parameters\n    ----------\n    data : numpy.unicode\\_ or numpy.ndarray of numpy.unicode\\_\n        The string or array of them to convert.\n\n    Returns\n    -------\n    array : numpy.ndarray of numpy.uint16\n        The result of the conversion.\n\n    Raises\n    ------\n    UnicodeEncodeError\n        If a UTF-32 character has no UTF-16 representation.\n\n    See Also\n    --------\n    convert_numpy_str_to_uint32\n    convert_to_numpy_str\n\n    \"\"\"\n    # An empty string should be an empty uint16\n    if data.nbytes == 0:\n        return np.uint16([])\n\n    # We need to use the UTF-16 codec for our endianness. Using the\n    # right one means we don't have to worry about removing the BOM.\n    if sys.byteorder == 'little':\n        codec = 'UTF-16LE'\n    else:\n        codec = 'UTF-16BE'\n\n    # numpy.char.encode can do the conversion element wise. Then, we\n    # just have convert to uin16 with the appropriate dimensions. The\n    # dimensions are gotten from the shape of the converted data with\n    # the number of column increased by the number of words (pair of\n    # bytes) in the strings.\n    cdata = np.char.encode(np.atleast_1d(data), codec)\n    shape = list(cdata.shape)\n    shape[-1] *= (cdata.dtype.itemsize // 2)\n    return np.ndarray(shape=shape, dtype='uint16',\n                      buffer=cdata.tostring())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a numpy. unicode \\ _ to its numpy. uint32 representation.", "response": "def convert_numpy_str_to_uint32(data):\n    \"\"\" Converts a numpy.unicode\\_ to its numpy.uint32 representation.\n\n    Convert a ``numpy.unicode_`` or an array of them (they are UTF-32\n    strings) into the equivalent array of ``numpy.uint32`` that is byte\n    for byte identical. Strings are expanded along rows (across columns)\n    so a 2x3x4 array of 10 element strings will get turned into a 2x30x4\n    array of uint32's.\n\n    Parameters\n    ----------\n    data : numpy.unicode\\_ or numpy.ndarray of numpy.unicode\\_\n        The string or array of them to convert.\n\n    Returns\n    -------\n    array : numpy.ndarray of numpy.uint32\n        The result of the conversion.\n\n    See Also\n    --------\n    convert_numpy_str_to_uint16\n    convert_to_numpy_str\n\n    \"\"\"\n    if data.nbytes == 0:\n        # An empty string should be an empty uint32.\n        return np.uint32([])\n    else:\n        # We need to calculate the new shape from the current shape,\n        # which will have to be expanded along the rows to fit all the\n        # characters (the dtype.itemsize gets the number of bytes in\n        # each string, which is just 4 times the number of\n        # characters. Then it is a mstter of getting a view of the\n        # string (in flattened form so that it is contiguous) as uint32\n        # and then reshaping it.\n        shape = list(np.atleast_1d(data).shape)\n        shape[-1] *= data.dtype.itemsize//4\n        return data.flatten().view(np.uint32).reshape(tuple(shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts data into a Python 3. x str type.", "response": "def convert_to_str(data):\n    \"\"\" Decodes data to the Python 3.x str (Python 2.x unicode) type.\n\n    Decodes `data` to a Python 3.x ``str`` (Python 2.x ``unicode``). If\n    it can't be decoded, it is returned as is. Unsigned integers, Python\n    ``bytes``, and Numpy strings (``numpy.unicode_`` and\n    ``numpy.bytes_``). Python 3.x ``bytes``, Python 2.x ``str``, and\n    ``numpy.bytes_`` are assumed to be encoded in UTF-8.\n\n    Parameters\n    ----------\n    data : some type\n        Data decode into an ``str`` string.\n\n    Returns\n    -------\n    s : str or data\n        If `data` can be decoded into a ``str``, the decoded version is\n        returned. Otherwise, `data` is returned unchanged.\n\n    See Also\n    --------\n    convert_to_numpy_str\n    convert_to_numpy_bytes\n\n    \"\"\"\n    # How the conversion is done depends on the exact  underlying\n    # type. Numpy types are handled separately. For uint types, it is\n    # assumed to be stored as UTF-8, UTF-16, or UTF-32 depending on the\n    # size when converting to an str. numpy.string_ is just like\n    # converting a bytes. numpy.unicode has to be encoded into bytes\n    # before it can be decoded back into an str. bytes is decoded\n    # assuming it is in UTF-8. Otherwise, data has to be returned as is.\n\n    if isinstance(data, (np.ndarray, np.uint8, np.uint16, np.uint32,\n                  np.bytes_, np.unicode_)):\n        if data.dtype.name == 'uint8':\n            return data.tostring().decode('UTF-8')\n        elif data.dtype.name == 'uint16':\n            return data.tostring().decode('UTF-16')\n        elif data.dtype.name == 'uint32':\n            return data.tostring().decode('UTF-32')\n        elif data.dtype.char == 'S':\n            return data.decode('UTF-8')\n        else:\n            if isinstance(data, np.ndarray):\n                return data.tostring().decode('UTF-32')\n            else:\n                return data.encode('UTF-32').decode('UTF-32')\n\n    if isinstance(data, bytes):\n        return data.decode('UTF-8')\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting data into a Numpy unicode string.", "response": "def convert_to_numpy_str(data, length=None):\n    \"\"\" Decodes data to Numpy unicode string (numpy.unicode\\_).\n\n    Decodes `data` to Numpy unicode string (UTF-32), which is\n    ``numpy.unicode_``, or an array of them. If it can't be decoded, it\n    is returned as is. Unsigned integers, Python string types (``str``,\n    ``bytes``), and ``numpy.bytes_`` are supported. If it is an array of\n    ``numpy.bytes_``, an array of those all converted to\n    ``numpy.unicode_`` is returned. Python 3.x ``bytes``, Python 2.x\n    ``str``, and ``numpy.bytes_`` are assumed to be encoded in UTF-8.\n\n    For an array of unsigned integers, it may be desirable to make an\n    array with strings of some specified length as opposed to an array\n    of the same size with each element being a one element string. This\n    naturally arises when converting strings to unsigned integer types\n    in the first place, so it needs to be reversible.  The `length`\n    parameter specifies how many to group together into a string\n    (desired string length). For 1d arrays, this is along its only\n    dimension. For higher dimensional arrays, it is done along each row\n    (across columns). So, for a 3x10x5 input array of uints and a\n    `length` of 5, the output array would be a 3x2x5 of 5 element\n    strings.\n\n    Parameters\n    ----------\n    data : some type\n        Data decode into a Numpy unicode string.\n    length : int or None, optional\n        The number of consecutive elements (in the case of unsigned\n        integer `data`) to compose each string in the output array from.\n        ``None`` indicates the full amount for a 1d array or the number\n        of columns (full length of row) for a higher dimension array.\n\n    Returns\n    -------\n    s : numpy.unicode\\_ or numpy.ndarray of numpy.unicode\\_ or data\n        If `data` can be decoded into a ``numpy.unicode_`` or a\n        ``numpy.ndarray`` of them, the decoded version is returned.\n        Otherwise, `data` is returned unchanged.\n\n    See Also\n    --------\n    convert_to_str\n    convert_to_numpy_bytes\n    numpy.unicode\\_\n\n    \"\"\"\n    # The method of conversion depends on its type.\n    if isinstance(data, np.unicode_) or (isinstance(data, np.ndarray) \\\n            and data.dtype.char == 'U'):\n        # It is already an np.str_ or array of them, so nothing needs to\n        # be done.\n        return data\n    elif (sys.hexversion >= 0x03000000 and isinstance(data, str)) \\\n           or (sys.hexversion < 0x03000000 \\\n           and isinstance(data, unicode)):\n        # Easily converted through constructor.\n        return np.unicode_(data)\n    elif isinstance(data, (bytes, bytearray, np.bytes_)):\n        # All of them can be decoded and then passed through the\n        # constructor.\n        return np.unicode_(data.decode('UTF-8'))\n    elif isinstance(data, (np.uint8, np.uint16)):\n        # They are single UTF-8 or UTF-16 scalars, which can be wrapped\n        # into an array and recursed.\n        return convert_to_numpy_str(np.atleast_1d(data))[0]\n    elif isinstance(data, np.uint32):\n        # It is just the uint32 version of the character, so it just\n        # needs to be have the dtype essentially changed by having its\n        # bytes read into ndarray.\n        return np.ndarray(shape=tuple(), dtype='U1',\n                          buffer=data.tostring())[()]\n    elif isinstance(data, np.ndarray) and data.dtype.char == 'S':\n        return np.char.encode(data, 'UTF-32')\n    elif isinstance(data, np.ndarray) \\\n            and data.dtype.name in ('uint8', 'uint16', 'uint32'):\n        # It is an ndarray of some uint type. How it is converted\n        # depends on its shape. If its shape is just (), then it is just\n        # a scalar wrapped in an array, which can be converted by\n        # recursing the scalar value back into this function.\n        shape = list(data.shape)\n        if len(shape) == 0:\n            return convert_to_numpy_str(data[()])\n\n        # As there are more than one element, it gets a bit more\n        # complicated. We need to take the subarrays of the specified\n        # length along columns (1D arrays will be treated as row arrays\n        # here), each of those converted to an str_ scalar (normal\n        # string) and stuffed into a new array.\n        #\n        # If the length was not given, it needs to be set to full. Then\n        # the shape of the new array needs to be calculated (divide the\n        # appropriate dimension, which depends on the number of\n        # dimentions).\n        if len(shape) == 1:\n            if length is None:\n                length = shape[0]\n            new_shape = (shape[0]//length,)\n        else:\n            if length is None:\n                length = shape[-1]\n            new_shape = copy.deepcopy(shape)\n            new_shape[-1] //= length\n\n        # numpy.char.decode will be used to decode. It needs the\n        # encoding (UTF-8/16/32) which is gotten from the dtype. But it\n        # also needs the data to be in big endian format, so it must be\n        # byteswapped if it isn't. Without the swapping, an error occurs\n        # since trailing nulls are dropped in numpy bytes_ arrays. The\n        # dtype for each string element is just 'SX' where X is the\n        # number of bytes.\n        if data.dtype.name == 'uint8':\n            encoding = 'UTF-8'\n            swapbytes = False\n            dt = 'S' + str(length)\n        else:\n            if data.dtype.name == 'uint16':\n                encoding = 'UTF-16BE'\n                dt = 'S' + str(2 * length)\n            else:\n                encoding = 'UTF-32BE'\n                dt = 'S' + str(4 * length)\n            if (data.dtype.byteorder == '<'\n                or (sys.byteorder == 'little'\n                    and data.dtype.byteorder == '=')):\n                swapbytes = True\n            else:\n                swapbytes = False\n        # Copy is needed to prevent errors.\n        if swapbytes:\n            return np.char.decode(data.copy().byteswap().view(dt),\n                                  encoding)\n        else:\n            return np.char.decode(data.copy().view(dt), encoding)\n    else:\n        # Couldn't figure out what it is, so nothing can be done but\n        # return it as is.\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_to_numpy_bytes(data, length=None):\n    # The method of conversion depends on its type.\n    if isinstance(data, np.bytes_) or (isinstance(data, np.ndarray) \\\n            and data.dtype.char == 'S'):\n        # It is already an np.bytes_ or array of them, so nothing needs\n        # to be done.\n        return data\n    elif isinstance(data, (bytes, bytearray)):\n        # Easily converted through constructor.\n        return np.bytes_(data)\n    elif (sys.hexversion >= 0x03000000 and isinstance(data, str)) \\\n            or (sys.hexversion < 0x03000000 \\\n            and isinstance(data, unicode)):\n        return np.bytes_(data.encode('UTF-8'))\n    elif isinstance(data, (np.uint16, np.uint32)):\n        # They are single UTF-16 or UTF-32 scalars, and are easily\n        # converted to a UTF-8 string and then passed through the\n        # constructor.\n        return np.bytes_(convert_to_str(data).encode('UTF-8'))\n    elif isinstance(data, np.uint8):\n        # It is just the uint8 version of the character, so it just\n        # needs to be have the dtype essentially changed by having its\n        # bytes read into ndarray.\n        return np.ndarray(shape=tuple(), dtype='S1',\n                          buffer=data.flatten().tostring())[()]\n    elif isinstance(data, np.ndarray) and data.dtype.char == 'U':\n        # We just need to convert it elementwise.\n        new_data = np.zeros(shape=data.shape,\n                            dtype='S' + str(data.dtype.itemsize))\n        for index, x in np.ndenumerate(data):\n            new_data[index] = np.bytes_(x.encode('UTF-8'))\n        return new_data\n    elif isinstance(data, np.ndarray) \\\n            and data.dtype.name in ('uint8', 'uint16', 'uint32'):\n        # It is an ndarray of some uint type. How it is converted\n        # depends on its shape. If its shape is just (), then it is just\n        # a scalar wrapped in an array, which can be converted by\n        # recursing the scalar value back into this function.\n        shape = list(data.shape)\n        if len(shape) == 0:\n            return convert_to_numpy_bytes(data[()])\n\n        # As there are more than one element, it gets a bit more\n        # complicated. We need to take the subarrays of the specified\n        # length along columns (1D arrays will be treated as row arrays\n        # here), each of those converted to an str_ scalar (normal\n        # string) and stuffed into a new array.\n        #\n        # If the length was not given, it needs to be set to full. Then\n        # the shape of the new array needs to be calculated (divide the\n        # appropriate dimension, which depends on the number of\n        # dimentions).\n        if len(shape) == 1:\n            if length is None:\n                length2 = shape[0]\n                new_shape = (shape[0],)\n            else:\n                length2 = length\n                new_shape = (shape[0]//length2,)\n        else:\n            if length is None:\n                length2 = shape[-1]\n            else:\n                length2 = length\n            new_shape = copy.deepcopy(shape)\n            new_shape[-1] //= length2\n\n        # The new array can be made as all zeros (nulls) with enough\n        # padding to hold everything (dtype='UL' where 'L' is the\n        # length). It will start out as a 1d array and be reshaped into\n        # the proper shape later (makes indexing easier).\n        new_data = np.zeros(shape=(np.prod(new_shape),),\n                            dtype='S'+str(length2))\n\n        # With data flattened into a 1d array, we just need to take\n        # length sized chunks, convert them (if they are uint8 or 16,\n        # then decode to str first, if they are uint32, put them as an\n        # input buffer for an ndarray of type 'U').\n        data = data.flatten()\n        for i in range(0, new_data.shape[0]):\n            chunk = data[(i*length2):((i+1)*length2)]\n            if data.dtype.name == 'uint8':\n                new_data[i] = np.ndarray(shape=tuple(),\n                                         dtype=new_data.dtype,\n                                         buffer=chunk.tostring())[()]\n            else:\n                new_data[i] = np.bytes_( \\\n                    convert_to_str(chunk).encode('UTF-8'))\n\n        # Only thing is left is to reshape it.\n        return new_data.reshape(tuple(new_shape))\n    else:\n        # Couldn't figure out what it is, so nothing can be done but\n        # return it as is.\n        return data", "response": "Converts data into a NumPy UTF - 8 econded string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode_complex(data, complex_names=(None, None)):\n    # Now, complex types are stored in HDF5 files as an H5T_COMPOUND type\n    # with fields along the lines of ('r', 're', 'real') and ('i', 'im',\n    # 'imag', 'imaginary') for the real and imaginary parts, which most\n    # likely won't be properly extracted back into making a Python\n    # complex type unless the proper h5py configuration is set. Since we\n    # can't depend on it being set and adjusting it is hazardous (the\n    # setting is global), it is best to just decode it manually. These\n    # fields are obtained from the fields of its dtype. Obviously, if\n    # there are no fields, then there is nothing to do.\n    if data.dtype.fields is None:\n        return data\n\n    fields = list(data.dtype.fields)\n\n    # If there aren't exactly two fields, then it can't be complex.\n    if len(fields) != 2:\n        return data\n\n    # We need to grab the field names for the real and imaginary\n    # parts. This will be done by seeing which list, if any, each field\n    # is and setting variables to the proper name if it is in it (they\n    # are initialized to None so that we know if one isn't found).\n\n    real_fields = ['r', 're', 'real']\n    imag_fields = ['i', 'im', 'imag', 'imaginary']\n\n    cnames = list(complex_names)\n    for s in fields:\n        if s.lower() in real_fields:\n            cnames[0] = s\n        elif s.lower() in imag_fields:\n            cnames[1] = s\n\n    # If the real and imaginary fields were found, construct the complex\n    # form from the fields. This is done by finding the complex type\n    # that they cast to, making an array, and then setting the\n    # parts. Otherwise, return what we were given because it isn't in\n    # the right form.\n    if cnames[0] is not None and cnames[1] is not None:\n        cdata = np.result_type(data[cnames[0]].dtype, \\\n            data[cnames[1]].dtype, 'complex64').type(data[cnames[0]])\n        cdata.imag = data[cnames[1]]\n        return cdata\n    else:\n        return data", "response": "Decodes possibly complex data into a Python - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding complex data into a new array of complex_names.", "response": "def encode_complex(data, complex_names):\n    \"\"\" Encodes complex data to having arbitrary complex field names.\n\n    Encodes complex `data` to have the real and imaginary field names\n    given in `complex_numbers`. This is needed because the field names\n    have to be set so that it can be written to an HDF5 file with the\n    right field names (HDF5 doesn't have a native complex type, so\n    H5T_COMPOUND have to be used).\n\n    Parameters\n    ----------\n    data : arraylike\n        The data to encode as a complex type with the desired real and\n        imaginary part field names.\n    complex_names : tuple of 2 str\n        ``tuple`` of the names to use (in order) for the real and\n        imaginary fields.\n\n    Returns\n    -------\n    d : encoded data\n        `data` encoded into having the specified field names for the\n        real and imaginary parts.\n\n    See Also\n    --------\n    decode_complex\n\n    \"\"\"\n    # Grab the dtype name, and convert it to the right non-complex type\n    # if it isn't already one.\n    dtype_name = data.dtype.name\n    if dtype_name[0:7] == 'complex':\n        dtype_name = 'float' + str(int(float(dtype_name[7:])/2))\n\n    # Create the new version of the data with the right field names for\n    # the real and complex parts. This is easy to do with putting the\n    # right detype in the view function.\n    dt = np.dtype([(complex_names[0], dtype_name),\n                   (complex_names[1], dtype_name)])\n    return data.view(dt).copy()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an attribute value to a string if possible.", "response": "def convert_attribute_to_string(value):\n    \"\"\" Convert an attribute value to a string.\n\n    Converts the attribute value to a string if possible (get ``None``\n    if isn't a string type).\n\n    .. versionadded:: 0.2\n\n    Parameters\n    ----------\n    value :\n        The Attribute value.\n\n    Returns\n    -------\n    s : str or None\n        The ``str`` value of the attribute if the conversion is\n        possible, or ``None`` if not.\n\n    \"\"\"\n    if value is None:\n        return value\n    elif (sys.hexversion >= 0x03000000 and isinstance(value, str)) \\\n            or (sys.hexversion < 0x03000000 \\\n            and isinstance(value, unicode)):\n        return value\n    elif isinstance(value, bytes):\n        return value.decode()\n    elif isinstance(value, np.unicode_):\n        return str(value)\n    elif isinstance(value, np.bytes_):\n        return value.decode()\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset an attribute on a Dataset or Group.", "response": "def set_attribute(target, name, value):\n    \"\"\" Sets an attribute on a Dataset or Group.\n\n    If the attribute `name` doesn't exist yet, it is created. If it\n    already exists, it is overwritten if it differs from `value`.\n\n    Notes\n    -----\n    ``set_attributes_all`` is the fastest way to set and delete\n    Attributes in bulk.\n\n    Parameters\n    ----------\n    target : Dataset or Group\n        Dataset or Group to set the attribute of.\n    name : str\n        Name of the attribute to set.\n    value : numpy type other than numpy.unicode\\_\n        Value to set the attribute to.\n\n    See Also\n    --------\n    set_attributes_all\n\n    \"\"\"\n    try:\n        target.attrs.modify(name, value)\n    except:\n        target.attrs.create(name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets an attribute to a string on a Dataset or Group.", "response": "def set_attribute_string(target, name, value):\n    \"\"\" Sets an attribute to a string on a Dataset or Group.\n\n    If the attribute `name` doesn't exist yet, it is created. If it\n    already exists, it is overwritten if it differs from `value`.\n\n    Notes\n    -----\n    ``set_attributes_all`` is the fastest way to set and delete\n    Attributes in bulk.\n\n    Parameters\n    ----------\n    target : Dataset or Group\n        Dataset or Group to set the string attribute of.\n    name : str\n        Name of the attribute to set.\n    value : string\n        Value to set the attribute to. Can be any sort of string type\n        that will convert to a ``numpy.bytes_``\n\n    See Also\n    --------\n    set_attributes_all\n\n    \"\"\"\n    set_attribute(target, name, np.bytes_(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset an attribute to an array of string on a Dataset or Group.", "response": "def set_attribute_string_array(target, name, string_list):\n    \"\"\" Sets an attribute to an array of string on a Dataset or Group.\n\n    If the attribute `name` doesn't exist yet, it is created. If it\n    already exists, it is overwritten with the list of string\n    `string_list` (they will be vlen strings).\n\n    Notes\n    -----\n    ``set_attributes_all`` is the fastest way to set and delete\n    Attributes in bulk.\n\n    Parameters\n    ----------\n    target : Dataset or Group\n        Dataset or Group to set the string array attribute of.\n    name : str\n        Name of the attribute to set.\n    string_list : list of str\n        List of strings to set the attribute to. Strings must be ``str``\n\n    See Also\n    --------\n    set_attributes_all\n\n    \"\"\"\n    s_list = [convert_to_str(s) for s in string_list]\n    if sys.hexversion >= 0x03000000:\n        target.attrs.create(name, s_list,\n                            dtype=h5py.special_dtype(vlen=str))\n    else:\n        target.attrs.create(name, s_list,\n                            dtype=h5py.special_dtype(vlen=unicode))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_attributes_all(target, attributes, discard_others=True):\n    attrs = target.attrs\n    existing = dict(attrs.items())\n    # Generate special dtype for string arrays.\n    if sys.hexversion >= 0x03000000:\n        str_arr_dtype = h5py.special_dtype(vlen=str)\n    else:\n        str_arr_dtype = dtype=h5py.special_dtype(vlen=unicode)\n    # Go through each attribute. If it is already present, modify it if\n    # possible and create it otherwise (deletes old value.)\n    for k, (kind, value) in attributes.items():\n        if kind == 'string_array':\n            attrs.create(k, [convert_to_str(s) for s in value],\n                         dtype=str_arr_dtype)\n        else:\n            if kind == 'string':\n                value = np.bytes_(value)\n            if k not in existing:\n                attrs.create(k, value)\n            else:\n                try:\n                    if value.dtype == existing[k].dtype \\\n                            and value.shape == existing[k].shape:\n                        attrs.modify(k, value)\n                except:\n                    attrs.create(k, value)\n    # Discard all other attributes.\n    if discard_others:\n        for k in set(existing) - set(attributes):\n            del attrs[k]", "response": "Sets the attributes of the target Dataset or Group to the given dictionary of Attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding and load all third party marshaller plugins.", "response": "def find_thirdparty_marshaller_plugins():\n    \"\"\" Find, but don't load, all third party marshaller plugins.\n\n    Third party marshaller plugins declare the entry point\n    ``'hdf5storage.marshallers.plugins'`` with the name being the\n    Marshaller API version and the target being a function that returns\n    a ``tuple`` or ``list`` of all the marshallers provided by that\n    plugin when given the hdf5storage version (``str``) as its only\n    argument.\n\n    .. versionadded:: 0.2\n\n    Returns\n    -------\n    plugins : dict\n        The marshaller obtaining entry points from third party\n        plugins. The keys are the Marshaller API versions (``str``) and\n        the values are ``dict`` of the entry points, with the module\n        names as the keys (``str``) and the values being the entry\n        points (``pkg_resources.EntryPoint``).\n\n    See Also\n    --------\n    supported_marshaller_api_versions\n\n    \"\"\"\n    all_plugins = tuple(pkg_resources.iter_entry_points(\n        'hdf5storage.marshallers.plugins'))\n    return {ver: {p.module_name: p\n                  for p in all_plugins if p.name == ver}\n            for ver in supported_marshaller_api_versions()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data into an HDF5 file.", "response": "def writes(mdict, filename='data.h5', truncate_existing=False,\n           truncate_invalid_matlab=False, options=None, **keywords):\n    \"\"\" Writes data into an HDF5 file (high level).\n\n    High level function to store one or more Python types (data) to\n    specified pathes in an HDF5 file. The paths are specified as POSIX\n    style paths where the directory name is the Group to put it in and\n    the basename is the name to write it to.\n\n    There are various options that can be used to influence how the data\n    is written. They can be passed as an already constructed ``Options``\n    into `options` or as additional keywords that will be used to make\n    one by ``options = Options(**keywords)``.\n\n    Two very important options are ``store_python_metadata`` and\n    ``matlab_compatible``, which are ``bool``. The first makes it so\n    that enough metadata (HDF5 Attributes) are written that `data` can\n    be read back accurately without it (or its contents if it is a\n    container type) ending up different types, transposed in the case of\n    numpy arrays, etc. The latter makes it so that the appropriate\n    metadata is written, string and bool and complex types are converted\n    properly, and numpy arrays are transposed; which is needed to make\n    sure that MATLAB can import `data` correctly (the HDF5 header is\n    also set so MATLAB will recognize it).\n\n    Paths are POSIX style and can either be given directly as ``str`` or\n    ``bytes``, or the separated path can be given as an iterable of\n    ``str`` and ``bytes``. Each part of a separated path is escaped\n    using ``utilities.escape_path``. Otherwise, the path is assumed to\n    be already escaped. Escaping is done so that targets with a part\n    that starts with one or more periods, contain slashes, and/or\n    contain nulls can be used without causing the wrong Group to be\n    looked in or the wrong target to be looked at. It essentially allows\n    one to make a Dataset named ``'..'`` or ``'a/a'`` instead of moving\n    around in the Dataset hierarchy.\n\n    Parameters\n    ----------\n    mdict : dict, dict like\n        The ``dict`` or other dictionary type object of paths\n        and data to write to the file. The paths, the keys, must be\n        POSIX style paths where the directory name is the Group to put\n        it in and the basename is the name to write it to. The values\n        are the data to write.\n    filename : str, optional\n        The name of the HDF5 file to write `data` to.\n    truncate_existing : bool, optional\n        Whether to truncate the file if it already exists before writing\n        to it.\n    truncate_invalid_matlab : bool, optional\n        Whether to truncate a file if matlab_compatibility is being\n        done and the file doesn't have the proper header (userblock in\n        HDF5 terms) setup for MATLAB metadata to be placed.\n    options : Options, optional\n        The options to use when writing. Is mutually exclusive with any\n        additional keyword arguments given (set to ``None`` or don't\n        provide to use them).\n    **keywords :\n        If `options` was not provided or was ``None``, these are used as\n        arguments to make a ``Options``.\n\n    Raises\n    ------\n    TypeError\n        If a path is of an invalid type.\n    NotImplementedError\n        If writing `data` is not supported.\n    exceptions.TypeNotMatlabCompatibleError\n        If writing a type not compatible with MATLAB and\n        `options.action_for_matlab_incompatible` is set to ``'error'``.\n\n    See Also\n    --------\n    utilities.process_path\n    utilities.escape_path\n    write : Writes just a single piece of data\n    reads\n    read\n    Options\n    utilities.write_data : Low level version\n\n    \"\"\"\n    # Pack the different options into an Options class if an Options was\n    # not given.\n    if not isinstance(options, Options):\n        options = Options(**keywords)\n\n    # Go through mdict, extract the paths and data, and process the\n    # paths. A list of tulpes for each piece of data to write will be\n    # constructed where he first element is the group name, the second\n    # the target name (name of the Dataset/Group holding the data), and\n    # the third element the data to write.\n    towrite = []\n    for p, v in mdict.items():\n        groupname, targetname = utilities.process_path(p)\n\n        # Pack into towrite.\n        towrite.append((groupname, targetname, v))\n\n    # Open/create the hdf5 file but don't write the data yet since the\n    # userblock still needs to be set. This is all wrapped in a try\n    # block, so that the file can be closed if any errors happen (the\n    # error is re-raised).\n    f = None\n    try:\n\n        # If the file doesn't already exist or the option is set to\n        # truncate it if it does, just open it truncating whatever is\n        # there. Otherwise, open it for read/write access without\n        # truncating. Now, if we are doing matlab compatibility and it\n        # doesn't have a big enough userblock (for metadata for MATLAB\n        # to be able to tell it is a valid .mat file) and the\n        # truncate_invalid_matlab is set, then it needs to be closed and\n        # re-opened with truncation. Whenever we create the file from\n        # scratch, even if matlab compatibility isn't being done, a\n        # sufficiently sized userblock is going to be allocated\n        # (smallest size is 512) for future use (after all, someone\n        # might want to turn it to a .mat file later and need it and it\n        # is only 512 bytes).\n\n        if truncate_existing or not os.path.isfile(filename):\n            f = h5py.File(filename, mode='w', userblock_size=512)\n        else:\n            f = h5py.File(filename)\n            if options.matlab_compatible and truncate_invalid_matlab \\\n                    and f.userblock_size < 128:\n                f.close()\n                f = h5py.File(filename, mode='w', userblock_size=512)\n    except:\n        raise\n    finally:\n        # If the hdf5 file was opened at all, get the userblock size and\n        # close it since we need to set the userblock.\n        if isinstance(f, h5py.File):\n            userblock_size = f.userblock_size\n            f.close()\n        else:\n            raise IOError('Unable to create or open file.')\n\n    # If we are doing MATLAB formatting and there is a sufficiently\n    # large userblock, write the new userblock. The same sort of error\n    # handling is used.\n    if options.matlab_compatible and userblock_size >= 128:\n        # Get the time.\n        now = datetime.datetime.now()\n\n        # Construct the leading string. The MATLAB one looks like\n        #\n        # s = 'MATLAB 7.3 MAT-file, Platform: GLNXA64, Created on: ' \\\n        #     + now.strftime('%a %b %d %H:%M:%S %Y') \\\n        #     + ' HDF5 schema 1.00 .'\n        #\n        # Platform is going to be changed to hdf5storage version.\n\n        s = 'MATLAB 7.3 MAT-file, Platform: hdf5storage ' \\\n            + __version__ + ', Created on: ' \\\n            + now.strftime('%a %b %d %H:%M:%S %Y') \\\n            + ' HDF5 schema 1.00 .'\n\n        # Make the bytearray while padding with spaces up to 128-12\n        # (the minus 12 is there since the last 12 bytes are special.\n\n        b = bytearray(s + (128-12-len(s))*' ', encoding='utf-8')\n\n        # Add 8 nulls (0) and the magic number (or something) that\n        # MATLAB uses.\n\n        b.extend(bytearray.fromhex('00000000 00000000 0002494D'))\n\n        # Now, write it to the beginning of the file.\n\n        try:\n            fd = open(filename, 'r+b')\n            fd.write(b)\n        except:\n            raise\n        finally:\n            fd.close()\n\n    # Open the hdf5 file again and write the data, making the Group if\n    # necessary. This is all wrapped in a try block, so that the file\n    # can be closed if any errors happen (the error is re-raised).\n    f = None\n    try:\n        f = h5py.File(filename)\n\n        # Go through each element of towrite and write them.\n        for groupname, targetname, data in towrite:\n            # Need to make sure groupname is a valid group in f and grab its\n            # handle to pass on to the low level function.\n            if groupname not in f:\n                grp = f.require_group(groupname)\n            else:\n                grp = f[groupname]\n\n            # Hand off to the low level function.\n            utilities.write_data(f, grp, targetname, data,\n                                 None, options)\n    except:\n        raise\n    finally:\n        if isinstance(f, h5py.File):\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reads(paths, filename='data.h5', options=None, **keywords):\n    # Pack the different options into an Options class if an Options was\n    # not given. By default, the matlab_compatible option is set to\n    # False. So, if it wasn't passed in the keywords, this needs to be\n    # added to override the default value (True) for a new Options.\n    if not isinstance(options, Options):\n        kw = copy.deepcopy(keywords)\n        if 'matlab_compatible' not in kw:\n            kw['matlab_compatible'] = False\n        options = Options(**kw)\n\n    # Process the paths and stuff the group names and target names as\n    # tuples into toread.\n    toread = []\n    for p in paths:\n        groupname, targetname = utilities.process_path(p)\n\n        # Pack them into toread\n        toread.append((groupname, targetname))\n\n    # Open the hdf5 file and start reading the data. This is all wrapped\n    # in a try block, so that the file can be closed if any errors\n    # happen (the error is re-raised).\n    try:\n        f = None\n        f = h5py.File(filename, mode='r')\n\n        # Read the data item by item\n        datas = []\n        for groupname, targetname in toread:\n            # Check that the containing group is in f and is indeed a\n            # group. If it isn't an error needs to be thrown.\n            if groupname not in f \\\n                    or not isinstance(f[groupname], h5py.Group):\n                raise exceptions.CantReadError( \\\n                    'Could not find containing Group ' \\\n                    + groupname + '.')\n\n            # Hand off everything to the low level reader.\n            datas.append(utilities.read_data(f, f[groupname],\n                                             targetname, options))\n    except:\n        raise\n    finally:\n        if f is not None:\n            f.close()\n\n    return datas", "response": "Reads data from an HDF5 file and returns a Python object containing the data read."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a dictionary of python types and values to a MATLAB MAT file.", "response": "def savemat(file_name, mdict, appendmat=True, format='7.3',\n            oned_as='row', store_python_metadata=True,\n            action_for_matlab_incompatible='error',\n            marshaller_collection=None, truncate_existing=False,\n            truncate_invalid_matlab=False, **keywords):\n    \"\"\" Save a dictionary of python types to a MATLAB MAT file.\n\n    Saves the data provided in the dictionary `mdict` to a MATLAB MAT\n    file. `format` determines which kind/vesion of file to use. The\n    '7.3' version, which is HDF5 based, is handled by this package and\n    all types that this package can write are supported. Versions 4 and\n    5 are not HDF5 based, so everything is dispatched to the SciPy\n    package's ``scipy.io.savemat`` function, which this function is\n    modelled after (arguments not specific to this package have the same\n    names, etc.).\n\n    Parameters\n    ----------\n    file_name : str or file-like object\n        Name of the MAT file to store in. The '.mat' extension is\n        added on automatically if not present if `appendmat` is set to\n        ``True``. An open file-like object can be passed if the writing\n        is being dispatched to SciPy (`format` < 7.3).\n    mdict : dict\n        The dictionary of variables and their contents to store in the\n        file.\n    appendmat : bool, optional\n        Whether to append the '.mat' extension to `file_name` if it\n        doesn't already end in it or not.\n    format : {'4', '5', '7.3'}, optional\n        The MATLAB mat file format to use. The '7.3' format is handled\n        by this package while the '4' and '5' formats are dispatched to\n        SciPy.\n    oned_as : {'row', 'column'}, optional\n        Whether 1D arrays should be turned into row or column vectors.\n    store_python_metadata : bool, optional\n        Whether or not to store Python type information. Doing so allows\n        most types to be read back perfectly. Only applicable if not\n        dispatching to SciPy (`format` >= 7.3).\n    action_for_matlab_incompatible: str, optional\n        The action to perform writing data that is not MATLAB\n        compatible. The actions are to write the data anyways\n        ('ignore'), don't write the incompatible data ('discard'), or\n        throw a ``TypeNotMatlabCompatibleError`` exception.\n    marshaller_collection : MarshallerCollection, optional\n        Collection of marshallers to disk to use. Only applicable if\n        not dispatching to SciPy (`format` >= 7.3).\n    truncate_existing : bool, optional\n        Whether to truncate the file if it already exists before writing\n        to it.\n    truncate_invalid_matlab : bool, optional\n        Whether to truncate a file if the file doesn't have the proper\n        header (userblock in HDF5 terms) setup for MATLAB metadata to be\n        placed.\n    **keywords :\n        Additional keywords arguments to be passed onto\n        ``scipy.io.savemat`` if dispatching to SciPy (`format` < 7.3).\n\n    Raises\n    ------\n    ImportError\n        If `format` < 7.3 and the ``scipy`` module can't be found.\n    NotImplementedError\n        If writing a variable in `mdict` is not supported.\n    exceptions.TypeNotMatlabCompatibleError\n        If writing a type not compatible with MATLAB and\n        `action_for_matlab_incompatible` is set to ``'error'``.\n\n    Notes\n    -----\n    Writing the same data and then reading it back from disk using the\n    HDF5 based version 7.3 format (the functions in this package) or the\n    older format (SciPy functions) can lead to very different\n    results. Each package supports a different set of data types and\n    converts them to and from the same MATLAB types differently.\n\n    See Also\n    --------\n    loadmat : Equivelent function to do reading.\n    scipy.io.savemat : SciPy function this one models after and\n        dispatches to.\n    Options\n    writes : Function used to do the actual writing.\n\n    \"\"\"\n    # If format is a number less than 7.3, the call needs to be\n    # dispatched to the scipy version, if it is available, with all the\n    # relevant and extra keywords options provided.\n    if float(format) < 7.3:\n        import scipy.io\n        scipy.io.savemat(file_name, mdict, appendmat=appendmat,\n                         format=format, oned_as=oned_as, **keywords)\n        return\n\n    # Append .mat if it isn't on the end of the file name and we are\n    # supposed to.\n    if appendmat and not file_name.endswith('.mat'):\n        file_name = file_name + '.mat'\n\n    # Make the options with matlab compatibility forced.\n    options = Options(store_python_metadata=store_python_metadata, \\\n        matlab_compatible=True, oned_as=oned_as, \\\n        action_for_matlab_incompatible=action_for_matlab_incompatible, \\\n        marshaller_collection=marshaller_collection)\n\n    # Write the variables in the dictionary to file.\n    writes(mdict=mdict, filename=file_name,\n           truncate_existing=truncate_existing,\n           truncate_invalid_matlab=truncate_invalid_matlab,\n           options=options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadmat(file_name, mdict=None, appendmat=True,\n            variable_names=None,\n            marshaller_collection=None, **keywords):\n    \"\"\" Loads data to a MATLAB MAT file.\n\n    Reads data from the specified variables (or all) in a  MATLAB MAT\n    file. There are many different formats of MAT files. This package\n    can only handle the HDF5 based ones (the version 7.3 and later).\n    As SciPy's ``scipy.io.loadmat`` function can handle the earlier\n    formats, if this function cannot read the file, it will dispatch it\n    onto the scipy function with all the calling arguments it uses\n    passed on. This function is modelled after the SciPy one (arguments\n    not specific to this package have the same names, etc.).\n\n    Parameters\n    ----------\n    file_name : str\n        Name of the MAT file to read from. The '.mat' extension is\n        added on automatically if not present if `appendmat` is set to\n        ``True``.\n    mdict : dict, optional\n        The dictionary to insert read variables into\n    appendmat : bool, optional\n        Whether to append the '.mat' extension to `file_name` if it\n        doesn't already end in it or not.\n    variable_names: None or sequence, optional\n        The variable names to read from the file. ``None`` selects all.\n    marshaller_collection : MarshallerCollection, optional\n        Collection of marshallers from disk to use. Only applicable if\n        not dispatching to SciPy (version 7.3 and newer files).\n    **keywords :\n        Additional keywords arguments to be passed onto\n        ``scipy.io.loadmat`` if dispatching to SciPy if the file is not\n        a version 7.3 or later format.\n\n    Returns\n    -------\n    dict\n        Dictionary of all the variables read from the MAT file (name\n        as the key, and content as the value).\n\n    Raises\n    ------\n    ImportError\n        If it is not a version 7.3 .mat file and the ``scipy`` module\n        can't be found when dispatching to SciPy.\n    exceptions.CantReadError\n        If reading the data can't be done.\n\n    Notes\n    -----\n    Writing the same data and then reading it back from disk using the\n    HDF5 based version 7.3 format (the functions in this package) or the\n    older format (SciPy functions) can lead to very different\n    results. Each package supports a different set of data types and\n    converts them to and from the same MATLAB types differently.\n\n    See Also\n    --------\n    savemat : Equivalent function to do writing.\n    scipy.io.loadmat : SciPy function this one models after and\n        dispatches to.\n    Options\n    reads : Function used to do the actual reading.\n\n    \"\"\"\n    # Will first assume that it is the HDF5 based 7.3 format. If an\n    # OSError occurs, then it wasn't an HDF5 file and the scipy function\n    # can be tried instead.\n    try:\n        # Make the options with the given marshallers.\n        options = Options(marshaller_collection=marshaller_collection)\n\n        # Append .mat if it isn't on the end of the file name and we are\n        # supposed to.\n        if appendmat and not file_name.endswith('.mat'):\n            filename = file_name + '.mat'\n        else:\n            filename = file_name\n\n        # Read everything if we were instructed.\n\n        if variable_names is None:\n            data = dict()\n            with h5py.File(filename, mode='r') as f:\n                for k in f:\n                    # Read if not group_for_references. Data that\n                    # produces errors when read is dicarded (the OSError\n                    # that would happen if this is not an HDF5 file\n                    # would already have happened when opening the\n                    # file).\n                    if f[k].name != options.group_for_references:\n                        try:\n                            data[utilities.unescape_path(k)] = \\\n                                utilities.read_data(f, f, k, options)\n                        except:\n                            pass\n\n        else:\n            # Extract the desired fields all together and then pack them\n            # into a dictionary one by one.\n            values = reads(paths=variable_names, filename=filename,\n                           options=options)\n            data = dict()\n            for i, name in enumerate(variable_names):\n                data[name] = values[i]\n\n        # Read all the variables, stuff them into mdict, and return it.\n        if mdict is None:\n            mdict = dict()\n        for k, v in data.items():\n            mdict[k] = v\n        return mdict\n    except OSError:\n        import scipy.io\n        return scipy.io.loadmat(file_name, mdict, appendmat=appendmat,\n                                variable_names=variable_names,\n                                **keywords)", "response": "Loads data from a MATLAB MAT file into a \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_marshallers(self):\n        # Combine all sets of marshallers.\n        self._marshallers = []\n        for v in self._priority:\n            if v == 'builtin':\n                self._marshallers.extend(self._builtin_marshallers)\n            elif v == 'plugin':\n                self._marshallers.extend(self._plugin_marshallers)\n            elif v == 'user':\n                self._marshallers.extend(self._user_marshallers)\n            else:\n                raise ValueError('priority attribute has an illegal '\n                                 'element value.')\n\n        # Determine whether the required modules are present, do module\n        # loading, and determine whether the required modules are\n        # imported.\n        self._has_required_modules = len(self._marshallers) * [False]\n        self._imported_required_modules = \\\n            len(self._marshallers) * [False]\n\n        for i, m in enumerate(self._marshallers):\n            # Check if the required modules are here.\n            try:\n                for name in m.required_parent_modules:\n                    if name not in sys.modules \\\n                            and pkgutil.find_loader(name) is None:\n                        raise ImportError('module not present')\n            except ImportError:\n                self._has_required_modules[i] = False\n            except:\n                raise\n            else:\n                self._has_required_modules[i] = True\n\n            # Modules obviously can't be fully loaded if not all are\n            # present.\n            if not self._has_required_modules[i]:\n                self._imported_required_modules[i] = False\n                continue\n\n            # Check if all modules are loaded or not, and load them if\n            # doing lazy loading.\n            try:\n                for name in m.required_modules:\n                    if name not in sys.modules:\n                        raise ImportError('module not loaded yet.')\n            except ImportError:\n                if self._lazy_loading:\n                    self._imported_required_modules[i] = False\n                else:\n                    success = self._import_marshaller_modules(m)\n                    self._has_required_modules[i] = success\n                    self._imported_required_modules[i] = success\n            except:\n                raise\n            else:\n                self._imported_required_modules[i] = True\n\n        # Construct the dictionary to look up the appropriate marshaller\n        # by type, the equivalent one to read data types given type\n        # strings needs to be created from it (basically, we have to\n        # make the key be the python_type_string from it), and the\n        # equivalent one to read data types given MATLAB class strings\n        # needs to be created from it (basically, we have to make the\n        # key be the matlab_class from it).\n        #\n        # Marshallers earlier in the list have priority (means that the\n        # builtins have the highest). Since the types can be specified\n        # as strings as well, duplicates will be checked for by running\n        # each type through str if it isn't str.\n        types_as_str = set()\n        self._types = dict()\n        self._type_strings = dict()\n        self._matlab_classes = dict()\n        for i, m in enumerate(self._marshallers):\n            # types.\n            for tp in m.types:\n                if isinstance(tp, str):\n                    tp_as_str = tp\n                else:\n                    tp_as_str = tp.__module__ + '.' + tp.__name__\n                if tp_as_str not in types_as_str:\n                    self._types[tp_as_str] = i\n                    types_as_str.add(tp_as_str)\n            # type strings\n            for type_string in m.python_type_strings:\n                if type_string not in self._type_strings:\n                    self._type_strings[type_string] = i\n            # matlab classes.\n            for matlab_class in m.matlab_classes:\n                if matlab_class not in self._matlab_classes:\n                    self._matlab_classes[matlab_class] = i", "response": "Updates the internal data structures with the current set of marshallers and other data structures."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports the modules required by the marshaller.", "response": "def _import_marshaller_modules(self, m):\n        \"\"\" Imports the modules required by the marshaller.\n\n        Parameters\n        ----------\n        m : marshaller\n            The marshaller to load the modules for.\n\n        Returns\n        -------\n        success : bool\n            Whether the modules `m` requires could be imported\n            successfully or not.\n\n        \"\"\"\n        try:\n            for name in m.required_modules:\n                if name not in sys.modules:\n                    if _has_importlib:\n                        importlib.import_module(name)\n                    else:\n                        __import__(name)\n        except ImportError:\n            return False\n        except:\n            raise\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_marshaller(self, marshallers):\n        if not isinstance(marshallers, collections.Iterable):\n            marshallers = [marshallers]\n        for m in marshallers:\n            if not isinstance(m, Marshallers.TypeMarshaller):\n                raise TypeError('Each marshaller must inherit from '\n                                'hdf5storage.Marshallers.'\n                                'TypeMarshaller.')\n            if m not in self._user_marshallers:\n                self._user_marshallers.append(m)\n        self._update_marshallers()", "response": "Adds a marshaller or a list of them to the user provided list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_marshaller(self, marshallers):\n        if not isinstance(marshallers, collections.Iterable):\n            marshallers = [marshallers]\n        for m in marshallers:\n            if m in self._user_marshallers:\n                self._user_marshallers.remove(m)\n        self._update_marshallers()", "response": "Removes a marshaller or a list of them from the user provided set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the appropriate marshaller for a type.", "response": "def get_marshaller_for_type(self, tp):\n        \"\"\" Gets the appropriate marshaller for a type.\n\n        Retrieves the marshaller, if any, that can be used to read/write\n        a Python object with type 'tp'. The modules it requires, if\n        available, will be loaded.\n\n        Parameters\n        ----------\n        tp : type or str\n            Python object ``type`` (which would be the class reference)\n            or its string representation like ``'collections.deque'``.\n\n        Returns\n        -------\n        marshaller : marshaller or None\n            The marshaller that can read/write the type to\n            file. ``None`` if no appropriate marshaller is found.\n        has_required_modules : bool\n            Whether the required modules for reading the type are\n            present or not.\n\n        See Also\n        --------\n        hdf5storage.Marshallers.TypeMarshaller.types\n\n        \"\"\"\n        if not isinstance(tp, str):\n            tp = tp.__module__ + '.' + tp.__name__\n        if tp in self._types:\n            index = self._types[tp]\n        else:\n            return None, False\n        m = self._marshallers[index]\n        if self._imported_required_modules[index]:\n            return m, True\n        if not self._has_required_modules[index]:\n            return m, False\n        success = self._import_marshaller_modules(m)\n        self._has_required_modules[index] = success\n        self._imported_required_modules[index] = success\n        return m, success"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the appropriate marshaller for a given type string.", "response": "def get_marshaller_for_type_string(self, type_string):\n        \"\"\" Gets the appropriate marshaller for a type string.\n\n        Retrieves the marshaller, if any, that can be used to read/write\n        a Python object with the given type string. The modules it\n        requires, if available, will be loaded.\n\n        Parameters\n        ----------\n        type_string : str\n            Type string for a Python object.\n\n        Returns\n        -------\n        marshaller : marshaller or None\n            The marshaller that can read/write the type to\n            file. ``None`` if no appropriate marshaller is found.\n        has_required_modules : bool\n            Whether the required modules for reading the type are\n            present or not.\n\n        See Also\n        --------\n        hdf5storage.Marshallers.TypeMarshaller.python_type_strings\n\n        \"\"\"\n        if type_string in self._type_strings:\n            index = self._type_strings[type_string]\n            m = self._marshallers[index]\n            if self._imported_required_modules[index]:\n                return m, True\n            if not self._has_required_modules[index]:\n                return m, False\n            success = self._import_marshaller_modules(m)\n            self._has_required_modules[index] = success\n            self._imported_required_modules[index] = success\n            return m, success\n        else:\n            return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the appropriate marshaller for the given MATLAB class string.", "response": "def get_marshaller_for_matlab_class(self, matlab_class):\n        \"\"\" Gets the appropriate marshaller for a MATLAB class string.\n\n        Retrieves the marshaller, if any, that can be used to read/write\n        a Python object associated with the given MATLAB class\n        string. The modules it requires, if available, will be loaded.\n\n        Parameters\n        ----------\n        matlab_class : str\n            MATLAB class string for a Python object.\n\n        Returns\n        -------\n        marshaller : marshaller or None\n            The marshaller that can read/write the type to\n            file. ``None`` if no appropriate marshaller is found.\n        has_required_modules : bool\n            Whether the required modules for reading the type are\n            present or not.\n\n        See Also\n        --------\n        hdf5storage.Marshallers.TypeMarshaller.python_type_strings\n\n        \"\"\"\n        if matlab_class in self._matlab_classes:\n            index = self._matlab_classes[matlab_class]\n            m = self._marshallers[index]\n            if self._imported_required_modules[index]:\n                return m, True\n            if not self._has_required_modules[index]:\n                return m, False\n            success = self._import_marshaller_modules(m)\n            self._has_required_modules[index] = success\n            self._imported_required_modules[index] = success\n            return m, success\n        else:\n            return None, False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a cycle graph with the specified number of nodes.", "response": "def build_cycle_graph(num_nodes):\n    \"\"\"Builds a cycle graph with the specified number of nodes.\n       Ref: http://mathworld.wolfram.com/CycleGraph.html\"\"\"\n    graph = UndirectedGraph()\n\n    if num_nodes > 0:\n        first_node = graph.new_node()\n        if num_nodes > 1:\n            previous_node = first_node\n            for _ in range(num_nodes - 1):\n                new_node = graph.new_node()\n                graph.new_edge(previous_node, new_node)\n                previous_node = new_node\n            graph.new_edge(previous_node, first_node)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_wheel_graph(num_nodes):\n    # The easiest way to build a wheel graph is to build\n    # C_n-1 and then add a hub node and spoke edges\n    graph = build_cycle_graph(num_nodes - 1)\n\n    cycle_graph_vertices = graph.get_all_node_ids()\n\n    node_id = graph.new_node()\n    for cycle_node in cycle_graph_vertices:\n        graph.new_edge(node_id, cycle_node)\n\n    return graph", "response": "Builds a wheel graph with the specified number of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_k5_graph():\n    graph = UndirectedGraph()\n\n    # K5 has 5 nodes\n    for _ in range(5):\n        graph.new_node()\n\n    # K5 has 10 edges\n    # --Edge: a\n    graph.new_edge(1, 2)\n    # --Edge: b\n    graph.new_edge(2, 3)\n    # --Edge: c\n    graph.new_edge(3, 4)\n    # --Edge: d\n    graph.new_edge(4, 5)\n    # --Edge: e\n    graph.new_edge(5, 1)\n    # --Edge: f\n    graph.new_edge(1, 3)\n    # --Edge: g\n    graph.new_edge(1, 4)\n    # --Edge: h\n    graph.new_edge(2, 4)\n    # --Edge: i\n    graph.new_edge(2, 5)\n    # --Edge: j\n    graph.new_edge(3, 5)\n\n    return graph", "response": "Builds a K5 graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_k33_graph():\n    graph = UndirectedGraph()\n\n    # K3,3 has 6 nodes\n    for _ in range(1, 7):\n        graph.new_node()\n\n    # K3,3 has 9 edges\n    # --Edge: a\n    graph.new_edge(1, 4)\n    # --Edge: b\n    graph.new_edge(1, 5)\n    # --Edge: c\n    graph.new_edge(1, 6)\n    # --Edge: d\n    graph.new_edge(2, 4)\n    # --Edge: e\n    graph.new_edge(2, 5)\n    # --Edge: f\n    graph.new_edge(2, 6)\n    # --Edge: g\n    graph.new_edge(3, 4)\n    # --Edge: h\n    graph.new_edge(3, 5)\n    # --Edge: i\n    graph.new_edge(3, 6)\n\n    return graph", "response": "Makes a new K3 - 3 graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a Groetzsch graph from an adjacency matrix.", "response": "def build_groetzch_graph():\n    \"\"\"Makes a new Groetzsch graph.\n       Ref: http://mathworld.wolfram.com/GroetzschGraph.html\"\"\"\n    # Because the graph is so complicated, we want to\n    # build it via adjacency matrix specification\n    \n    # -- Initialize the matrix to all zeros\n    adj = [[0 for _ in range(11)] for _ in range(11)]\n\n    # -- Add individual edge connections\n    row_connections = []\n\n    row_connections.append( (1,2,7,10) )\n    row_connections.append( (0,3,6,9) )\n    row_connections.append( (0,4,6,8) )\n    row_connections.append( (1,4,8,10) )\n    row_connections.append( (2,3,7,9) )\n    row_connections.append( (6,7,8,9,10) )\n    row_connections.append( (1,2,5) )\n    row_connections.append( (0,4,5) )\n    row_connections.append( (2,3,5) )\n    row_connections.append( (1,4,5) )\n    row_connections.append( (0,3,5) )\n\n    for j, tpl in enumerate(row_connections):\n        for i in tpl:\n            adj[j][i] = 1\n            adj[i][j] = 1\n    \n    # Debug print the adjacency matrix\n    #for row in adj:\n    #    print row\n\n    graph, _ = create_graph_from_adjacency_matrix(adj)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a Franklin graph from the current node and its children.", "response": "def build_franklin_graph():\n    \"\"\"Makes a new Franklin graph.\n       Ref: http://mathworld.wolfram.com/FranklinGraph.html\"\"\"\n    # The easiest way to build the Franklin graph is to start\n    # with C12 and add the additional 6 edges\n    graph = build_cycle_graph(12)\n\n    edge_tpls = [\n        (1,8),\n        (2,7),\n        (3,10),\n        (4,9),\n        (5,12),\n        (6,11)\n    ]\n\n    for i, j in edge_tpls:\n        graph.new_edge(i, j)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a Chvatal graph for the current node.", "response": "def build_chvatal_graph():\n    \"\"\"Makes a new Chvatal graph.\n       Ref: http://mathworld.wolfram.com/ChvatalGraph.html\"\"\"\n    # The easiest way to build the Chvatal graph is to start\n    # with C12 and add the additional 12 edges\n    graph = build_cycle_graph(12)\n\n    edge_tpls = [\n        (1,7), (1,9), (2,5), (2,11),\n        (3,7), (3,9), (4,10), (4,12),\n        (5,8), (6,10), (6,12), (8,11),\n    ]\n\n    for i, j in edge_tpls:\n        graph.new_edge(i, j)\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_node(self):\n        node_id = self.generate_node_id()\n\n        node = {'id': node_id,\n                'edges': [],\n                'data': {}\n        }\n\n        self.nodes[node_id] = node\n\n        self._num_nodes += 1\n\n        return node_id", "response": "Adds a new node to the graph.\n        Returns the new node id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_edge(self, node_a, node_b, cost=1):\n\n        # Verify that both nodes exist in the graph\n        try:\n            self.nodes[node_a]\n        except KeyError:\n            raise NonexistentNodeError(node_a)\n        try:\n            self.nodes[node_b]\n        except KeyError:\n            raise NonexistentNodeError(node_b)\n\n        # Create the new edge\n        edge_id = self.generate_edge_id()\n\n        edge = {'id': edge_id,\n                'vertices': (node_a, node_b),\n                'cost': cost,\n                'data': {}\n        }\n\n        self.edges[edge_id] = edge\n        self.nodes[node_a]['edges'].append(edge_id)\n\n        self._num_edges += 1\n\n        return edge_id", "response": "Adds a new edge from node_a to node_b that has a cost. Returns the edge id of the new edge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef neighbors(self, node_id):\n        node = self.get_node(node_id)\n        return [self.get_edge(edge_id)['vertices'][1] for edge_id in node['edges']]", "response": "Find all the nodes where there is an edge from the specified node to that node. Returns a list of node ids."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adjacent(self, node_a, node_b):\n        neighbors = self.neighbors(node_a)\n        return node_b in neighbors", "response": "Determines whether an edge from node_a to node_b exists. Returns True if such an edge exists otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the cost of moving between the edge that connects node_a to node_b. Returns + inf if no such edge exists.", "response": "def edge_cost(self, node_a, node_b):\n        \"\"\"Returns the cost of moving between the edge that connects node_a to node_b.\n        Returns +inf if no such edge exists.\"\"\"\n        cost = float('inf')\n        node_object_a = self.get_node(node_a)\n        for edge_id in node_object_a['edges']:\n            edge = self.get_edge(edge_id)\n            tpl = (node_a, node_b)\n            if edge['vertices'] == tpl:\n                cost = edge['cost']\n                break\n        return cost"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_node(self, node_id):\n        try:\n            node_object = self.nodes[node_id]\n        except KeyError:\n            raise NonexistentNodeError(node_id)\n        return node_object", "response": "Returns the node object identified by node_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_edge(self, edge_id):\n        try:\n            edge_object = self.edges[edge_id]\n        except KeyError:\n            raise NonexistentEdgeError(edge_id)\n        return edge_object", "response": "Returns the edge object identified by edge_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all the edges from node_a to node_b from the graph.", "response": "def delete_edge_by_nodes(self, node_a, node_b):\n        \"\"\"Removes all the edges from node_a to node_b from the graph.\"\"\"\n        node = self.get_node(node_a)\n\n        # Determine the edge ids\n        edge_ids = []\n        for e_id in node['edges']:\n            edge = self.get_edge(e_id)\n            if edge['vertices'][1] == node_b:\n                edge_ids.append(e_id)\n\n        # Delete the edges\n        for e in edge_ids:\n            self.delete_edge_by_id(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_node(self, node_id):\n        node = self.get_node(node_id)\n\n        # Remove all edges from the node\n        for e in node['edges']:\n            self.delete_edge_by_id(e)\n\n        # Remove all edges to the node\n        edges = [edge_id for edge_id, edge in list(self.edges.items()) if edge['vertices'][1] == node_id]\n        for e in edges:\n            self.delete_edge_by_id(e)\n\n        # Remove the node from the node list\n        del self.nodes[node_id]\n\n        self._num_nodes -= 1", "response": "Removes the node identified by node_id from the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_edge_source(self, edge_id, node_a, node_b):\n        # Grab the edge\n        edge = self.get_edge(edge_id)\n\n        # Alter the vertices\n        edge['vertices'] = (node_b, edge['vertices'][1])\n\n        # Remove the edge from node_a\n        node = self.get_node(node_a)\n        node['edges'].remove(edge_id)\n\n        # Add the edge to node_b\n        node = self.get_node(node_b)\n        node['edges'].append(edge_id)", "response": "Moves an edge originating from node_a so that it originates from node_b."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove an edge so that it targets node_a.", "response": "def move_edge_target(self, edge_id, node_a):\n        \"\"\"Moves an edge so that it targets node_a.\"\"\"\n        # Grab the edge\n        edge = self.get_edge(edge_id)\n\n        # Alter the vertices\n        edge['vertices'] = (edge['vertices'][0], node_a)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_edge_ids_by_node_ids(self, node_a, node_b):\n        # Check if the nodes are adjacent\n        if not self.adjacent(node_a, node_b):\n            return []\n\n        # They're adjacent, so pull the list of edges from node_a and determine which ones point to node_b\n        node = self.get_node(node_a)\n        return [edge_id for edge_id in node['edges'] if self.get_edge(edge_id)['vertices'][1] == node_b]", "response": "Returns a list of edge ids connecting node_a to node_b."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_first_edge_id_by_node_ids(self, node_a, node_b):\n        ret = self.get_edge_ids_by_node_ids(node_a, node_b)\n        if not ret:\n            return None\n        else:\n            return ret[0]", "response": "Returns the first edge id connecting node_a and node_b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_biconnected_components(graph):\n\n    list_of_components = []\n\n    # Run the algorithm on each of the connected components of the graph\n    components = get_connected_components_as_subgraphs(graph)\n    for component in components:\n        # --Call the internal biconnnected components function to find\n        # --the edge lists for this particular connected component\n        edge_list = _internal_get_biconnected_components_edge_lists(component)\n        list_of_components.extend(edge_list)\n\n    return list_of_components", "response": "Finds all the biconnected components in a graph. Returns a list of lists each containing the edges that form a biconnected component."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the biconnected components and returns them as subgraphs.", "response": "def find_biconnected_components_as_subgraphs(graph):\n    \"\"\"Finds the biconnected components and returns them as subgraphs.\"\"\"\n    list_of_graphs = []\n\n    list_of_components = find_biconnected_components(graph)\n    for edge_list in list_of_components:\n        subgraph = get_subgraph_from_edge_list(graph, edge_list)\n        list_of_graphs.append(subgraph)\n\n    return list_of_graphs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all of the articulation vertices within a graph. Returns a list of all of the articulation vertices within the graph.", "response": "def find_articulation_vertices(graph):\n    \"\"\"Finds all of the articulation vertices within a graph.\n    Returns a list of all articulation vertices within the graph.\n    Returns an empty list for an empty graph.\n    \"\"\"\n\n    articulation_vertices = []\n\n    all_nodes = graph.get_all_node_ids()\n    if len(all_nodes) == 0:\n        return articulation_vertices\n\n    # Run the algorithm on each of the connected components of the graph\n    components = get_connected_components_as_subgraphs(graph)\n    for component in components:\n        # --Call the internal articulation vertices function to find\n        # --the node list for this particular connected component\n        vertex_list = _internal_get_cut_vertex_list(component)\n        articulation_vertices.extend(vertex_list)\n\n    return articulation_vertices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of lists each containing the edges that combine to produce the biconnected components.", "response": "def _internal_get_biconnected_components_edge_lists(graph):\n    \"\"\"Works on a single connected component to produce the edge lists of the biconnected components.\n    Returns a list of lists, each containing the edges that combine to produce the connected component.\n    Returns a single nested list with 1 edge if there is only 1 edge in the graph (a 2-node graph is a\n    special case, generally considered to be a biconnected graph).\n    Returns an empty list if there are no edges in the graph (i.e. if it's a single-node or empty graph).\n    \"\"\"\n    list_of_components = []\n\n    num_nodes = graph.num_nodes()\n    num_edges = graph.num_edges()\n    if num_nodes <= 2:\n        if num_edges == 1:\n            list_of_components.append(graph.get_all_edge_ids())\n        return list_of_components\n\n    dfs_count = 0\n    edge_stack = deque()\n    dfs_stack = deque()\n    visited = defaultdict(lambda: False)\n    parent = defaultdict(lambda: None)\n    depth = {}\n    low = {}\n    preorder_processed = defaultdict(lambda: False)\n    postorder_processed = defaultdict(lambda: False)\n\n    # We're simulating a recursive DFS with an explicit stack, since Python has a really small function stack\n    unvisited_nodes = set(graph.get_all_node_ids())\n    while len(unvisited_nodes) > 0:\n        # --Initialize the first stack frame, simulating the DFS call on the root node\n        u = unvisited_nodes.pop()\n        parent[u] = u\n        stack_frame = {\n            'u': u,\n            'v': None,\n            'remaining_children': graph.neighbors(u)\n        }\n        dfs_stack.appendleft(stack_frame)\n\n        while len(dfs_stack) > 0:\n            frame = dfs_stack.popleft()\n            u = frame['u']\n            v = frame['v']\n\n            if not visited[u]:\n                if u in unvisited_nodes:\n                    unvisited_nodes.remove(u)\n                visited[u] = True\n                dfs_count += 1\n                depth[u] = dfs_count\n                low[u] = depth[u]\n                if len(frame['remaining_children']) > 0:\n                    v = frame['remaining_children'].pop()\n                    frame['v'] = v\n\n            if v is None:\n                # --u has no neighbor nodes\n                continue\n\n            if not preorder_processed[v]:\n                # --This is the preorder processing, done for each neighbor node ''v'' of u\n                node_v = graph.get_node(v)\n                for edge_id in node_v['edges']:\n                    edge = graph.get_edge(edge_id)\n                    tpl_a = (u, v)\n                    tpl_b = (v, u)\n                    if tpl_a == edge['vertices'] or tpl_b == edge['vertices']:\n                        edge_stack.appendleft(edge_id)\n                        break\n                parent[v] = u\n                preorder_processed[v] = True\n                # print 'preorder for {}'.format(v)\n                dfs_stack.appendleft(frame)\n\n                # --Simulate the recursion to call the DFS on v\n                new_frame = {\n                    'u': v,\n                    'v': None,\n                    'remaining_children': graph.neighbors(v)\n                }\n                dfs_stack.appendleft(new_frame)\n                continue\n\n            elif not postorder_processed[v] and u == parent[v]:\n                # --This is the postorder processing, done for each neighbor node ''v'' of u\n                if low[v] >= depth[u]:\n                    component = output_component(graph, edge_stack, u, v)\n                    if len(component) > 2:\n                        # --You can't have a biconnected component with less than 3 edges\n                        list_of_components.append(component)\n                low[u] = min(low[u], low[v])\n                postorder_processed[v] = True\n                # print 'postorder for {}'.format(v)\n\n            elif visited[v] and (parent[u] != v) and (depth[v] < depth[u]):\n                # (u,v) is a backedge from u to its ancestor v\n                node_v = graph.get_node(v)\n                for edge_id in node_v['edges']:\n                    edge = graph.get_edge(edge_id)\n                    tpl_a = (u, v)\n                    tpl_b = (v, u)\n                    if tpl_a == edge['vertices'] or tpl_b == edge['vertices']:\n                        edge_stack.appendleft(edge_id)\n                        break\n                low[u] = min(low[u], depth[v])\n\n            if len(frame['remaining_children']) > 0:\n                # --Continue onto the next neighbor node of u\n                v = frame['remaining_children'].pop()\n                frame['v'] = v\n                dfs_stack.appendleft(frame)\n\n    return list_of_components"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _internal_get_cut_vertex_list(graph):\n    list_of_cut_vertices = set()\n    if graph.num_nodes() == 0:\n        return list(list_of_cut_vertices)\n\n    dfs_count = 0\n    root_dfs_count = 1\n    dfs_stack = deque()\n    visited = defaultdict(lambda: False)\n    parent = defaultdict(lambda: None)\n    children = defaultdict(lambda: [])\n    depth = {}\n    low = {}\n    preorder_processed = defaultdict(lambda: False)\n    postorder_processed = defaultdict(lambda: False)\n\n    # We're simulating a recursive DFS with an explicit stack, since Python has a really small function stack\n    unvisited_nodes = set(graph.get_all_node_ids())\n    while len(unvisited_nodes) > 0:\n        # --Initialize the first stack frame, simulating the DFS call on the root node\n        u = unvisited_nodes.pop()\n        parent[u] = u\n        stack_frame = {\n            'u': u,\n            'v': None,\n            'remaining_children': graph.neighbors(u)\n        }\n        dfs_stack.appendleft(stack_frame)\n\n        while len(dfs_stack) > 0:\n            frame = dfs_stack.popleft()\n            u = frame['u']\n            v = frame['v']\n\n            if not visited[u]:\n                if u in unvisited_nodes:\n                    unvisited_nodes.remove(u)\n                visited[u] = True\n                dfs_count += 1\n                depth[u] = dfs_count\n                low[u] = depth[u]\n                if len(frame['remaining_children']) > 0:\n                    v = frame['remaining_children'].pop()\n                    frame['v'] = v\n\n            if v is None:\n                # --u has no neighbor nodes\n                continue\n\n            if not preorder_processed[v]:\n                # --This is the preorder processing, done for each neighbor node ''v'' of u\n                parent[v] = u\n                children[u].append(v)\n                preorder_processed[v] = True\n                # print 'preorder for {}'.format(v)\n                dfs_stack.appendleft(frame)\n\n                # --Simulate the recursion to call the DFS on v\n                new_frame = {\n                    'u': v,\n                    'v': None,\n                    'remaining_children': graph.neighbors(v)\n                }\n                dfs_stack.appendleft(new_frame)\n                continue\n\n            elif not postorder_processed[v] and u == parent[v]:\n                # --This is the postorder processing, done for each neighbor node ''v'' of u\n                if low[v] >= depth[u] and depth[u] > 1:\n                    list_of_cut_vertices.add(u)\n                low[u] = min(low[u], low[v])\n                postorder_processed[v] = True\n                # print 'postorder for {}'.format(v)\n\n            elif visited[v] and (parent[u] != v) and (depth[v] < depth[u]):\n                # (u,v) is a backedge from u to its ancestor v\n                low[u] = min(low[u], depth[v])\n\n            if len(frame['remaining_children']) > 0:\n                # --Continue onto the next neighbor node of u\n                v = frame['remaining_children'].pop()\n                frame['v'] = v\n                dfs_stack.appendleft(frame)\n\n    # The root node gets special treatment; it's a cut vertex iff it has multiple children\n    if len(children[root_dfs_count]) > 1:\n        for node_id, dfs in list(depth.items()):\n            if dfs == root_dfs_count:\n                list_of_cut_vertices.add(node_id)\n                break\n\n    return list(list_of_cut_vertices)", "response": "Returns a list of nodes that are connected by the given graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef depth_first_search(graph, root_node=None):\n    ordering, parent_lookup, children_lookup = depth_first_search_with_parent_data(graph, root_node)\n    return ordering", "response": "Searches through the tree in a breadth - first fashion."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a depth - first search of the graph with parent data determined by provided adjacency lists and also returns a parent lookup dict and a children lookup dict.", "response": "def depth_first_search_with_parent_data(graph, root_node = None, adjacency_lists = None):\n    \"\"\"Performs a depth-first search with visiting order of nodes determined by provided adjacency lists,\n     and also returns a parent lookup dict and a children lookup dict.\"\"\"\n    ordering = []\n    parent_lookup = {}\n    children_lookup = defaultdict(lambda: [])\n\n    all_nodes = graph.get_all_node_ids()\n    if not all_nodes:\n        return ordering, parent_lookup, children_lookup\n\n    stack = deque()\n    discovered = defaultdict(lambda: False)\n    unvisited_nodes = set(all_nodes)\n\n    if root_node is None:\n        root_node = all_nodes[0]\n\n    if adjacency_lists is None:\n        adj = lambda v: graph.neighbors(v)\n    else:\n        adj = lambda v: adjacency_lists[v]\n\n    # --Initialize the stack, simulating the DFS call on the root node\n    stack.appendleft(root_node)\n    parent_lookup[root_node] = root_node\n\n    # We're using a non-recursive implementation of DFS, since Python isn't great for deep recursion\n    while True:\n        # Main DFS Loop\n        while len(stack) > 0:\n            u = stack.popleft()\n\n            if not discovered[u]:\n                discovered[u] = True\n                if u in unvisited_nodes:\n                    unvisited_nodes.remove(u)\n                ordering.append(u)\n                neighbors = adj(u)\n                # When adding the new nodes to the stack, we want to add them in reverse order so that\n                # the order the nodes are visited is the same as with a recursive DFS implementation\n                for n in neighbors[::-1]:\n                    if discovered[n]:\n                        # If the node already exists in the discovered nodes list\n                        # we don't want to re-add it to the stack\n                        continue\n                    stack.appendleft(n)\n                    parent_lookup[n] = u\n                    children_lookup[u].append(n)\n\n        # While there are still nodes that need visiting, repopulate the stack\n        if len(unvisited_nodes) > 0:\n            u = unvisited_nodes.pop()\n            stack.appendleft(u)\n        else:\n            break\n\n    return ordering, parent_lookup, children_lookup"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef breadth_first_search(graph, root_node=None):\n    ordering = []\n\n    all_nodes = graph.get_all_node_ids()\n    if not all_nodes:\n        return ordering\n\n    queue = deque()\n    discovered = defaultdict(lambda: False)\n    to_visit = set(all_nodes)\n\n    if root_node is None:\n        root_node = all_nodes[0]\n\n    discovered[root_node] = True\n    queue.appendleft(root_node)\n\n    # We need to make sure we visit all the nodes, including disconnected ones\n    while True:\n        # BFS Main Loop\n        while len(queue) > 0:\n            current_node = queue.pop()\n            ordering.append(current_node)\n            to_visit.remove(current_node)\n\n            for n in graph.neighbors(current_node):\n                if not discovered[n]:\n                    discovered[n] = True\n                    queue.appendleft(n)\n\n        # New root node if we still have more nodes\n        if len(to_visit) > 0:\n            node = to_visit.pop()\n            to_visit.add(node)  # --We need this here because we remove the node as part of the BFS algorithm\n            discovered[node] = True\n            queue.appendleft(node)\n        else:\n            break\n\n    return ordering", "response": "Searches through the tree in a breadth - first fashion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef graph_to_dot(graph, node_renderer=None, edge_renderer=None):\n    node_pairs = list(graph.nodes.items())\n    edge_pairs = list(graph.edges.items())\n\n    if node_renderer is None:\n        node_renderer_wrapper = lambda nid: ''\n    else:\n        node_renderer_wrapper = lambda nid: ' [%s]' % ','.join(\n            ['%s=%s' % tpl for tpl in list(node_renderer(graph, nid).items())])\n\n    # Start the graph\n    graph_string = 'digraph G {\\n'\n    graph_string += 'overlap=scale;\\n'\n\n    # Print the nodes (placeholder)\n    for node_id, node in node_pairs:\n        graph_string += '%i%s;\\n' % (node_id, node_renderer_wrapper(node_id))\n\n    # Print the edges\n    for edge_id, edge in edge_pairs:\n        node_a = edge['vertices'][0]\n        node_b = edge['vertices'][1]\n        graph_string += '%i -> %i;\\n' % (node_a, node_b)\n\n    # Finish the graph\n    graph_string += '}'\n\n    return graph_string", "response": "Generates a DOT specification string from the provided graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all connected components of the graph.", "response": "def get_connected_components(graph):\n    \"\"\"Finds all connected components of the graph.\n    Returns a list of lists, each containing the nodes that form a connected component.\n    Returns an empty list for an empty graph.\n    \"\"\"\n\n    list_of_components = []\n    component = []  # Not strictly necessary due to the while loop structure, but it helps the automated analysis tools\n\n    # Store a list of all unreached vertices\n    unreached = set(graph.get_all_node_ids())\n    to_explore = deque()\n\n    while len(unreached) > 0:\n        # This happens when we reach the end of a connected component and still have more vertices to search through\n        if len(to_explore) == 0:\n            n = unreached.pop()\n            unreached.add(n)\n            to_explore.append(n)\n            component = []\n            list_of_components.append(component)\n\n        # This is the BFS that searches for connected vertices\n        while len(to_explore) > 0:\n            n = to_explore.pop()\n            if n in unreached:\n                component.append(n)\n                unreached.remove(n)\n                nodes = graph.neighbors(n)\n                for n in nodes:\n                    if n in unreached:\n                        to_explore.append(n)\n\n    return list_of_components"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_connected_components_as_subgraphs(graph):\n    components = get_connected_components(graph)\n\n    list_of_graphs = []\n\n    for c in components:\n        edge_ids = set()\n        nodes = [graph.get_node(node) for node in c]\n        for n in nodes:\n            # --Loop through the edges in each node, to determine if it should be included\n            for e in n['edges']:\n                # --Only add the edge to the subgraph if both ends are in the subgraph\n                edge = graph.get_edge(e)\n                a, b = edge['vertices']\n                if a in c and b in c:\n                    edge_ids.add(e)\n        # --Build the subgraph and add it to the list\n        list_of_edges = list(edge_ids)\n        subgraph = make_subgraph(graph, c, list_of_edges)\n        list_of_graphs.append(subgraph)\n\n    return list_of_graphs", "response": "Finds all connected components of the graph and returns a list of graph objects each representing a connected component."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new undirected edge between node_a and node_b with a cost. Returns the edge id.", "response": "def new_edge(self, node_a, node_b, cost=1):\n        \"\"\"Adds a new, undirected edge between node_a and node_b with a cost.\n        Returns the edge id of the new edge.\"\"\"\n        edge_id = super(UndirectedGraph, self).new_edge(node_a, node_b, cost)\n        self.nodes[node_b]['edges'].append(edge_id)\n        return edge_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef neighbors(self, node_id):\n        node = self.get_node(node_id)\n        flattened_nodes_list = []\n        for a, b in [self.get_edge(edge_id)['vertices'] for edge_id in node['edges']]:\n            flattened_nodes_list.append(a)\n            flattened_nodes_list.append(b)\n        node_set = set(flattened_nodes_list)\n        if node_id in node_set:\n            node_set.remove(node_id)\n        return [nid for nid in node_set]", "response": "Find all the nodes where there is an edge from the specified node to that node. Returns a list of node ids."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the edge identified by edge_id from the graph.", "response": "def delete_edge_by_id(self, edge_id):\n        \"\"\"Removes the edge identified by \"edge_id\" from the graph.\"\"\"\n        edge = self.get_edge(edge_id)\n\n        # Remove the edge from the \"from node\"\n        # --Determine the from node\n        from_node_id = edge['vertices'][0]\n        from_node = self.get_node(from_node_id)\n\n        # --Remove the edge from it\n        from_node['edges'].remove(edge_id)\n\n        # Remove the edge from the \"to node\"\n        to_node_id = edge['vertices'][1]\n        to_node = self.get_node(to_node_id)\n\n        # --Remove the edge from it\n        to_node['edges'].remove(edge_id)\n\n        # Remove the edge from the edge list\n        del self.edges[edge_id]\n\n        self._num_edges -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_edge_target(self, edge_id, node_a):\n        # Grab the edge\n        edge = self.get_edge(edge_id)\n\n        # Remove the edge from the original \"target node\"\n        original_target_node_id = edge['vertices'][1]\n        original_target_node = self.get_node(original_target_node_id)\n        original_target_node['edges'].remove(edge_id)\n\n        # Add the edge to the new target node\n        new_target_node_id = node_a\n        new_target_node = self.get_node(new_target_node_id)\n        new_target_node['edges'].append(edge_id)\n\n        # Alter the vertices on the edge\n        edge['vertices'] = (edge['vertices'][0], node_a)", "response": "Moves an edge so that it targets node_a."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate a minimum spanning tree for a graph. Returns a list of edges that define the tree.", "response": "def find_minimum_spanning_tree(graph):\n    \"\"\"Calculates a minimum spanning tree for a graph.\n    Returns a list of edges that define the tree.\n    Returns an empty list for an empty graph.\n    \"\"\"\n    mst = []\n\n    if graph.num_nodes() == 0:\n        return mst\n    if graph.num_edges() == 0:\n        return mst\n\n    connected_components = get_connected_components(graph)\n    if len(connected_components) > 1:\n        raise DisconnectedGraphError\n\n    edge_list = kruskal_mst(graph)\n\n    return edge_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates a minimum spanning tree and returns a graph representation.", "response": "def find_minimum_spanning_tree_as_subgraph(graph):\n    \"\"\"Calculates a minimum spanning tree and returns a graph representation.\"\"\"\n    edge_list = find_minimum_spanning_tree(graph)\n    subgraph = get_subgraph_from_edge_list(graph, edge_list)\n\n    return subgraph"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_minimum_spanning_forest(graph):\n    msf = []\n\n    if graph.num_nodes() == 0:\n        return msf\n    if graph.num_edges() == 0:\n        return msf\n\n    connected_components = get_connected_components_as_subgraphs(graph)\n    for subgraph in connected_components:\n        edge_list = kruskal_mst(subgraph)\n        msf.append(edge_list)\n\n    return msf", "response": "Calculates the minimum spanning forest of a disconnected graph. Returns a list of lists each containing the edges that define that tree. Returns an empty list for an empty graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the minimum spanning forest and returns a list of trees as subgraphs.", "response": "def find_minimum_spanning_forest_as_subgraphs(graph):\n    \"\"\"Calculates the minimum spanning forest and returns a list of trees as subgraphs.\"\"\"\n    forest = find_minimum_spanning_forest(graph)\n    list_of_subgraphs = [get_subgraph_from_edge_list(graph, edge_list) for edge_list in forest]\n\n    return list_of_subgraphs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement Kruskal s Algorithm for finding minimum spanning trees.", "response": "def kruskal_mst(graph):\n    \"\"\"Implements Kruskal's Algorithm for finding minimum spanning trees.\n    Assumes a non-empty, connected graph.\n    \"\"\"\n    edges_accepted = 0\n    ds = DisjointSet()\n    pq = PriorityQueue()\n    accepted_edges = []\n    label_lookup = {}\n\n    nodes = graph.get_all_node_ids()\n    num_vertices = len(nodes)\n    for n in nodes:\n        label = ds.add_set()\n        label_lookup[n] = label\n\n    edges = graph.get_all_edge_objects()\n    for e in edges:\n        pq.put(e['id'], e['cost'])\n\n    while edges_accepted < (num_vertices - 1):\n        edge_id = pq.get()\n\n        edge = graph.get_edge(edge_id)\n        node_a, node_b = edge['vertices']\n        label_a = label_lookup[node_a]\n        label_b = label_lookup[node_b]\n\n        a_set = ds.find(label_a)\n        b_set = ds.find(label_b)\n\n        if a_set != b_set:\n            edges_accepted += 1\n            accepted_edges.append(edge_id)\n            ds.union(a_set, b_set)\n\n    return accepted_edges"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_cycle(graph, ordering, parent_lookup):\n    root_node = ordering[0]\n    for i in range(2, len(ordering)):\n        current_node = ordering[i]\n        if graph.adjacent(current_node, root_node):\n            path = []\n            while current_node != root_node:\n                path.append(current_node)\n                current_node = parent_lookup[current_node]\n            path.append(root_node)\n            path.reverse()\n            return path", "response": "Gets the main cycle of the dfs tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the list of segments that can emanate from a particular node on the main cycle.", "response": "def __get_segments_from_node(node, graph):\n    \"\"\"Calculates the segments that can emanate from a particular node on the main cycle.\"\"\"\n    list_of_segments = []\n    node_object = graph.get_node(node)\n    for e in node_object['edges']:\n        list_of_segments.append(e)\n    return list_of_segments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_segments_from_cycle(graph, cycle_path):\n    list_of_segments = []\n    # We work through the cycle in a bottom-up fashion\n    for n in cycle_path[::-1]:\n        segments = __get_segments_from_node(n, graph)\n        if segments:\n            list_of_segments.append(segments)\n\n    return list_of_segments", "response": "Calculates the segments that emanate from the main cycle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a subgraph given by a list of vertices and edges into a graph object.", "response": "def make_subgraph(graph, vertices, edges):\n    \"\"\"Converts a subgraph given by a list of vertices and edges into a graph object.\"\"\"\n    # Copy the entire graph\n    local_graph = copy.deepcopy(graph)\n\n    # Remove all the edges that aren't in the list\n    edges_to_delete = [x for x in local_graph.get_all_edge_ids() if x not in edges]\n    for e in edges_to_delete:\n        local_graph.delete_edge_by_id(e)\n\n    # Remove all the vertices that aren't in the list\n    nodes_to_delete = [x for x in local_graph.get_all_node_ids() if x not in vertices]\n    for n in nodes_to_delete:\n        local_graph.delete_node(n)\n\n    return local_graph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_graph_directed_to_undirected(dg):\n\n    udg = UndirectedGraph()\n\n    # Copy the graph\n    # --Copy nodes\n    # --Copy edges\n    udg.nodes = copy.deepcopy(dg.nodes)\n    udg.edges = copy.deepcopy(dg.edges)\n    udg.next_node_id = dg.next_node_id\n    udg.next_edge_id = dg.next_edge_id\n\n    # Convert the directed edges into undirected edges\n    for edge_id in udg.get_all_edge_ids():\n        edge = udg.get_edge(edge_id)\n        target_node_id = edge['vertices'][1]\n        target_node = udg.get_node(target_node_id)\n        target_node['edges'].append(edge_id)\n\n    return udg", "response": "Converts a directed graph into an undirected graph. Directed edges are made undirected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving duplicate edges from a directed graph.", "response": "def remove_duplicate_edges_directed(dg):\n    \"\"\"Removes duplicate edges from a directed graph.\"\"\"\n    # With directed edges, we can just hash the to and from node id tuples and if\n    # a node happens to conflict with one that already exists, we delete it\n\n    # --For aesthetic, we sort the edge ids so that lower edge ids are kept\n    lookup = {}\n    edges = sorted(dg.get_all_edge_ids())\n    for edge_id in edges:\n        e = dg.get_edge(edge_id)\n        tpl = e['vertices']\n        if tpl in lookup:\n            dg.delete_edge_by_id(edge_id)\n        else:\n            lookup[tpl] = edge_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving duplicate edges from an undirected graph.", "response": "def remove_duplicate_edges_undirected(udg):\n    \"\"\"Removes duplicate edges from an undirected graph.\"\"\"\n    # With undirected edges, we need to hash both combinations of the to-from node ids, since a-b and b-a are equivalent\n    # --For aesthetic, we sort the edge ids so that lower edges ids are kept\n    lookup = {}\n    edges = sorted(udg.get_all_edge_ids())\n    for edge_id in edges:\n        e = udg.get_edge(edge_id)\n        tpl_a = e['vertices']\n        tpl_b = (tpl_a[1], tpl_a[0])\n        if tpl_a in lookup or tpl_b in lookup:\n            udg.delete_edge_by_id(edge_id)\n        else:\n            lookup[tpl_a] = edge_id\n            lookup[tpl_b] = edge_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_vertices_from_edge_list(graph, edge_list):\n    node_set = set()\n    for edge_id in edge_list:\n        edge = graph.get_edge(edge_id)\n        a, b = edge['vertices']\n        node_set.add(a)\n        node_set.add(b)\n\n    return list(node_set)", "response": "Transforms a list of edges into a list of the nodes those edges connect."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subgraph_from_edge_list(graph, edge_list):\n    node_list = get_vertices_from_edge_list(graph, edge_list)\n    subgraph = make_subgraph(graph, node_list, edge_list)\n\n    return subgraph", "response": "Transforms a list of edges into a subgraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging an addition_graph into the main_graph. Returns a tuple of dictionaries mapping old node ids to new ids.", "response": "def merge_graphs(main_graph, addition_graph):\n    \"\"\"Merges an ''addition_graph'' into the ''main_graph''.\n    Returns a tuple of dictionaries, mapping old node ids and edge ids to new ids.\n    \"\"\"\n\n    node_mapping = {}\n    edge_mapping = {}\n\n    for node in addition_graph.get_all_node_objects():\n        node_id = node['id']\n        new_id = main_graph.new_node()\n        node_mapping[node_id] = new_id\n\n    for edge in addition_graph.get_all_edge_objects():\n        edge_id = edge['id']\n        old_vertex_a_id, old_vertex_b_id = edge['vertices']\n        new_vertex_a_id = node_mapping[old_vertex_a_id]\n        new_vertex_b_id = node_mapping[old_vertex_b_id]\n        new_edge_id = main_graph.new_edge(new_vertex_a_id, new_vertex_b_id)\n        edge_mapping[edge_id] = new_edge_id\n\n    return node_mapping, edge_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a graph from an adjacency matrix specification.", "response": "def create_graph_from_adjacency_matrix(adjacency_matrix):\n    \"\"\"Generates a graph from an adjacency matrix specification.\n       Returns a tuple containing the graph and a list-mapping of node ids to matrix column indices.\n\n       The graph will be an UndirectedGraph if the provided adjacency matrix is symmetric.\n       The graph will be a DirectedGraph if the provided adjacency matrix is not symmetric.\n       Ref: http://mathworld.wolfram.com/AdjacencyMatrix.html\"\"\"\n    if is_adjacency_matrix_symmetric(adjacency_matrix):\n        graph = UndirectedGraph()\n    else:\n        graph = DirectedGraph()\n\n    node_column_mapping = []\n\n    num_columns = len(adjacency_matrix)\n    for _ in range(num_columns):\n        node_id = graph.new_node()\n        node_column_mapping.append(node_id)\n\n    for j in range(num_columns):\n        for i in range(num_columns):\n            if adjacency_matrix[j][i]:\n                jnode_id = node_column_mapping[j]\n                inode_id = node_column_mapping[i]\n                # Because of our adjacency matrix encoding, [j][i] in our code corresponds to [i][j] in a traditional matrix interpretation\n                # Thus, we need to put an edge from node i to node j if [j][i] in our code is non-zero\n                graph.new_edge(inode_id, jnode_id)\n\n    return (graph, node_column_mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if an adjacency matrix is symmetric.", "response": "def is_adjacency_matrix_symmetric(adjacency_matrix):\n    \"\"\"Determines if an adjacency matrix is symmetric.\n       Ref: http://mathworld.wolfram.com/SymmetricMatrix.html\"\"\"\n    # Verify that the matrix is square\n    num_columns = len(adjacency_matrix)\n    for column in adjacency_matrix:\n        # In a square matrix, every row should be the same length as the number of columns\n        if len(column) != num_columns:\n            return False\n\n    # Loop through the bottom half of the matrix and compare it to the top half\n    # --We do the bottom half because of how we construct adjacency matrices\n    max_i = 0\n    for j in range(num_columns):\n        for i in range(max_i):\n            # If i == j, we can skip ahead so we don't compare with ourself\n            if i == j:\n                continue\n            # Compare the value in the bottom half with the mirrored value in the top half\n            # If they aren't the same, the matrix isn't symmetric\n            if adjacency_matrix[j][i] != adjacency_matrix[i][j]:\n                return False\n        max_i += 1\n\n    # If we reach this far without returning false, then we know that everything matched,\n    # which makes this a symmetric matrix\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning an A * search on the specified graph to find a minimal path between the two nodes.", "response": "def a_star_search(graph, start, goal):\n    \"\"\"Runs an A* search on the specified graph to find a path from the ''start'' node to the ''goal'' node.\n    Returns a list of nodes specifying a minimal path between the two nodes.\n    If no path exists (disconnected components), returns an empty list.\n    \"\"\"\n    all_nodes = graph.get_all_node_ids()\n    if start not in all_nodes:\n        raise NonexistentNodeError(start)\n    if goal not in all_nodes:\n        raise NonexistentNodeError(goal)\n\n    came_from, cost_so_far, goal_reached = _a_star_search_internal(graph, start, goal)\n    if goal_reached:\n        path = reconstruct_path(came_from, start, goal)\n        path.reverse()\n        return path\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _a_star_search_internal(graph, start, goal):\n    frontier = PriorityQueue()\n    frontier.put(start, 0)\n    came_from = {start: None}\n    cost_so_far = {start: 0}\n    goal_reached = False\n\n    while not frontier.empty():\n        current = frontier.get()\n\n        if current == goal:\n            goal_reached = True\n            break\n\n        for next_node in graph.neighbors(current):\n            new_cost = cost_so_far[current] + graph.edge_cost(current, next_node)\n            if next_node not in cost_so_far or new_cost < cost_so_far[next_node]:\n                cost_so_far[next_node] = new_cost\n                priority = new_cost + heuristic(goal, next_node)\n                frontier.put(next_node, priority)\n                came_from[next_node] = current\n\n    return came_from, cost_so_far, goal_reached", "response": "Performs an A * search on the given node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the set containing the node_label. Returns the set label.", "response": "def find(self, node_label):\n        \"\"\"Finds the set containing the node_label.\n        Returns the set label.\n        \"\"\"\n        queue = []\n        current_node = node_label\n        while self.__forest[current_node] >= 0:\n            queue.append(current_node)\n            current_node = self.__forest[current_node]\n        root_node = current_node\n\n        # Path compression\n        for n in queue:\n            self.__forest[n] = root_node\n\n        return root_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\njoining two sets into a single set.", "response": "def union(self, label_a, label_b):\n        \"\"\"Joins two sets into a single new set.\n        label_a, label_b can be any nodes within the sets\n        \"\"\"\n        # Base case to avoid work\n        if label_a == label_b:\n            return\n\n        # Find the tree root of each node\n        root_a = self.find(label_a)\n        root_b = self.find(label_b)\n\n        # Avoid merging a tree to itself\n        if root_a == root_b:\n            return\n\n        self.__internal_union(root_a, root_b)\n        self.__set_counter -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __internal_union(self, root_a, root_b):\n        # Merge the trees, smaller to larger\n        update_rank = False\n        # --Determine the larger tree\n        rank_a = self.__forest[root_a]\n        rank_b = self.__forest[root_b]\n        if rank_a < rank_b:\n            larger = root_b\n            smaller = root_a\n        else:\n            larger = root_a\n            smaller = root_b\n            if rank_a == rank_b:\n                update_rank = True\n        # --Make the smaller tree a subtree of the larger tree\n        self.__forest[smaller] = larger\n        # --Update the rank of the new tree (if necessary)\n        if update_rank:\n            self.__forest[larger] -= 1", "response": "Internal function to join two set trees specified by root_a and root_b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining whether a graph is planar or not.", "response": "def is_planar(graph):\n    \"\"\"Determines whether a graph is planar or not.\"\"\"\n    # Determine connected components as subgraphs; their planarity is independent of each other\n    connected_components = get_connected_components_as_subgraphs(graph)\n    for component in connected_components:\n        # Biconnected components likewise have independent planarity\n        biconnected_components = find_biconnected_components_as_subgraphs(component)\n        for bi_component in biconnected_components:\n            planarity = __is_subgraph_planar(bi_component)\n            if not planarity:\n                return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset up the dfs_data object for consistency.", "response": "def __setup_dfs_data(graph, adj):\n    \"\"\"Sets up the dfs_data object, for consistency.\"\"\"\n    dfs_data = __get_dfs_data(graph, adj)\n\n    dfs_data['graph'] = graph\n    dfs_data['adj'] = adj\n\n    L1, L2 = __low_point_dfs(dfs_data)\n    dfs_data['lowpoint_1_lookup'] = L1\n    dfs_data['lowpoint_2_lookup'] = L2\n\n    edge_weights = __calculate_edge_weights(dfs_data)\n    dfs_data['edge_weights'] = edge_weights\n\n    return dfs_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __calculate_edge_weights(dfs_data):\n    graph = dfs_data['graph']\n\n    weights = {}\n    for edge_id in graph.get_all_edge_ids():\n        edge_weight = __edge_weight(edge_id, dfs_data)\n        weights[edge_id] = edge_weight\n\n    return weights", "response": "Calculates the weight of each edge for embedding - order sorting."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __sort_adjacency_lists(dfs_data):\n    new_adjacency_lists = {}\n\n    adjacency_lists = dfs_data['adj']\n    edge_weights = dfs_data['edge_weights']\n    edge_lookup = dfs_data['edge_lookup']\n\n    for node_id, adj_list in list(adjacency_lists.items()):\n        node_weight_lookup = {}\n        frond_lookup = {}\n        for node_b in adj_list:\n            edge_id = dfs_data['graph'].get_first_edge_id_by_node_ids(node_id, node_b)\n            node_weight_lookup[node_b] = edge_weights[edge_id]\n            frond_lookup[node_b] = 1 if edge_lookup[edge_id] == 'backedge' else 2\n\n        # Fronds should be before branches if the weights are equal\n        new_list = sorted(adj_list, key=lambda n: frond_lookup[n])\n\n        # Sort by weights\n        new_list.sort(key=lambda n: node_weight_lookup[n])\n\n        # Add the new sorted list to the new adjacency list lookup table\n        new_adjacency_lists[node_id] = new_list\n\n    return new_adjacency_lists", "response": "Sorts the adjacency list representation by the edge weights."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __embed_branch(dfs_data):\n    u = dfs_data['ordering'][0]\n    dfs_data['LF'] = []\n    dfs_data['RF'] = []\n    dfs_data['FG'] = {}\n    n = dfs_data['graph'].num_nodes()\n    f0 = (0, n)\n    g0 = (0, n)\n    L0 = {'u': 0, 'v': n}\n    R0 = {'x': 0, 'y': n}\n    dfs_data['LF'].append(f0)\n    dfs_data['RF'].append(g0)\n    dfs_data['FG'][0] = [L0, R0]\n    dfs_data['FG']['m'] = 0\n    dfs_data['FG']['l'] = 0\n    dfs_data['FG']['r'] = 0\n\n    #print 'DFS Ordering: {}'.format(dfs_data['ordering'])\n    #for node in dfs_data['ordering']:\n        #print '{}: {}'.format(node, dfs_data['adj'][node])\n\n    nonplanar = __embed_branch_recursive(u, dfs_data)\n\n    #print \"Nonplanar:\", nonplanar\n\n    return not nonplanar", "response": "Builds the combinatorial embedding of the graph. Returns whether the graph is planar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __insert_branch(u, v, dfs_data):\n    w = L1(v, dfs_data)\n    d_u = D(u, dfs_data)\n    d_w = D(w, dfs_data)\n\n    # Embed uw\n    successful = __embed_frond(u, w, dfs_data)\n    if not successful:\n        return False\n\n    # Embed a branch marker uu on the side opposite to uw, in the same frond block\n    #successful = __embed_frond(u, v, dfs_data, as_branch_marker=True)\n    successful = __embed_frond(u, u, dfs_data, as_branch_marker=True)\n    if not successful:\n        return False\n\n    return True", "response": "Embeds a branch Bu ( v ) in the frond block uw Returns whether the embedding was successful. Returns whether the embedding was successful."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __do_case_5_work(d_w, d_u, case_1, case_2, case_3, dfs_data):\n    # --We should only ever see u-cases 1 and 2\n    if case_3:\n        # --We should never get here\n        return False\n\n    comp_d_w = abs(d_w)\n\n    #if case_1:\n    # --Add the frond to the left side\n    __insert_frond_LF(d_w, d_u, dfs_data)\n\n    # --Add uw to Lm\n    m = dfs_data['FG']['m']\n    Lm = L(m, dfs_data)\n    if comp_d_w < Lm['u']:\n        Lm['u'] = d_w\n    if d_u > Lm['v']:\n        Lm['v'] = d_u\n\n    # --Case 2 requires a bit of extra work\n    if case_2:\n        Lm['u'] = d_w\n        x_m1 = fn_x(m-1, dfs_data)\n        while comp_d_w < x_m1:\n            merge_Fm(dfs_data)\n            m = dfs_data['FG']['m']\n            x_m1 = fn_x(m-1, dfs_data)\n    #else:\n        #print \"Case 5 work, u-case 1\"\n\n    return True", "response": "Encapsulates the work that will be done for case 5 of __embed_frond and __embed_frond."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __do_case_6_work(d_w, d_u, case_1, case_2, case_3, dfs_data):\n    # --We should only ever see u-cases 1 and 3\n    if case_2:\n        # --We should never get here\n        return False\n\n    comp_d_w = abs(d_w)\n\n    # --Add the frond to the right side\n    __insert_frond_RF(d_w, d_u, dfs_data)\n\n    # --Add uw to Rm\n    m = dfs_data['FG']['m']\n    Rm = R(m, dfs_data)\n    if comp_d_w < Rm['x']:\n        Rm['x'] = d_w\n    if d_u > Rm['y']:\n        Rm['y'] = d_u\n\n    # --Case 3 requires a bit of extra work\n    if case_3:\n        Rm['x'] = d_w\n        u_m1 = u(m-1, dfs_data)\n        while comp_d_w < u_m1:\n            merge_Fm(dfs_data)\n            m = dfs_data['FG']['m']\n            u_m1 = u(m-1, dfs_data)\n    #else:\n        #print \"Case 6 work, u-case 1\"\n\n    return True", "response": "Encapsulates the work that will be done for case 6 of __embed_frond and case 3 of __embed_frond."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __insert_frond_RF(d_w, d_u, dfs_data):\n    # --Add the frond to the right side\n    dfs_data['RF'].append( (d_w, d_u) )\n    dfs_data['FG']['r'] += 1\n\n    dfs_data['last_inserted_side'] = 'RF'", "response": "Encapsulates the process of inserting a frond uw into the right side frond group."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencapsulates the process of inserting a frond uw into the left side frond group.", "response": "def __insert_frond_LF(d_w, d_u, dfs_data):\n    \"\"\"Encapsulates the process of inserting a frond uw into the left side frond group.\"\"\"\n    # --Add the frond to the left side\n    dfs_data['LF'].append( (d_w, d_u) )\n    dfs_data['FG']['l'] += 1\n\n    dfs_data['last_inserted_side'] = 'LF'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges Fm - 1 and Fm into one.", "response": "def merge_Fm(dfs_data):\n    \"\"\"Merges Fm-1 and Fm, as defined on page 19 of the paper.\"\"\"\n    FG = dfs_data['FG']\n    m = FG['m']\n    FGm = FG[m]\n    FGm1 = FG[m-1]\n\n    if FGm[0]['u'] < FGm1[0]['u']:\n        FGm1[0]['u'] = FGm[0]['u']\n\n    if FGm[0]['v'] > FGm1[0]['v']:\n        FGm1[0]['v'] = FGm[0]['v']\n\n    if FGm[1]['x'] < FGm1[1]['x']:\n        FGm1[1]['x'] = FGm[1]['x']\n\n    if FGm[1]['y'] > FGm1[1]['y']:\n        FGm1[1]['y'] = FGm[1]['y']\n\n    del FG[m]\n    FG['m'] -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef switch_sides(d_u, dfs_data):\n    # global fn_x\n\n    m = dfs_data['FG']['m']\n    u_m = u(m, dfs_data)\n    # x_m = fn_x(m, dfs_data)\n\n    if d_u <= u_m:\n        l_w = lw(dfs_data)\n        u_m1 = u(m-1, dfs_data)\n        while u_m1 > l_w:\n            merge_Fm(dfs_data)\n            m = dfs_data['FG']['m']\n            u_m1 = u(m-1, dfs_data)\n\n        # l_w = r_w is handled dynamically by the switching of fronds below\n\n        # l = r\n        dfs_data['FG']['l'] = dfs_data['FG']['r']\n\n        # adjust r so that gr is first frond preceding xm in RF\n        x_m = fn_x(m, dfs_data)\n        r = len(dfs_data['RF']) - 1\n        g_r = dfs_data['RF'][r][0]\n        while g_r >= x_m:\n            r -= 1\n            if r < 0:\n                r = 0\n                break\n            g_r = dfs_data['RF'][r][0]\n        dfs_data['FG']['r'] = r\n\n        # changing r_w is also handled dynamically by the frond switching\n    else:\n        r_w = rw(dfs_data)\n        x_m1 = fn_x(m-1, dfs_data)\n        while x_m1 > r_w:\n            merge_Fm(dfs_data)\n            m = dfs_data['FG']['m']\n            x_m1 = fn_x(m-1, dfs_data)\n\n        # r_w = l_w is handled dynamically by the switching of fronds below\n\n        # r = l\n        dfs_data['FG']['r'] = dfs_data['FG']['l']\n\n        # adjust l so that fl is first frond preceding um in LF\n        u_m = u(m, dfs_data)\n        l = len(dfs_data['LF']) - 1\n        f_l = dfs_data['LF'][l][0]\n        while f_l >= u_m:\n            l -= 1\n            f_l = dfs_data['LF'][l][0]\n        dfs_data['FG']['l'] = l\n\n        # changing l_w is also handled dynamically by the frond switching\n\n    m = dfs_data['FG']['m']\n\n    # Exchange the portion of the linked list LF between um and vm with the portion of RF between xm and ym\n    LF = dfs_data['LF']\n    RF = dfs_data['RF']\n\n    u_m = u(m, dfs_data)\n    v_m = v(m, dfs_data)\n    x_m = fn_x(m, dfs_data)\n    y_m = y(m, dfs_data)\n\n    # --These are the baseline indexes, they should be narrowed appropriately\n    first_left_index = 1\n    last_left_index = len(LF) - 1\n    first_right_index = 1\n    last_right_index = len(RF) - 1\n\n    # --Narrow the left indexes\n    while first_left_index < last_left_index:\n        frond = LF[first_left_index]\n        if u_m >= frond[0]:\n            first_left_index -= 1\n            break\n        else:\n            first_left_index += 1\n\n    while first_left_index < last_left_index:\n        frond = LF[last_left_index]\n        if v_m < frond[1]:\n            last_left_index -= 1\n        else:\n            last_left_index += 1\n            break\n\n    # --Narrow the right indexes\n    while first_right_index < last_right_index:\n        frond = RF[first_right_index]\n        if x_m >= frond[0]:\n            first_right_index -= 1\n            break\n        else:\n            first_right_index += 1\n\n    while first_right_index < last_right_index:\n        frond = RF[last_right_index]\n        if y_m < frond[1]:\n            last_right_index -= 1\n        else:\n            last_right_index += 1\n            break\n\n\n    # --Grab the appropriate list slices from each list\n    LF_slice = LF[first_left_index:last_left_index+1]\n    RF_slice = RF[first_right_index:last_right_index+1]\n\n    # --Remove the slices from each list\n    del LF[first_left_index:last_left_index+1]\n    del RF[first_right_index:last_right_index+1]\n\n    # --Add the slice from the right list to the left list\n    i = first_left_index\n    for x in RF_slice:\n        LF.insert(i, x)\n        i += 1\n\n    # --Add the slice from the left list to the right list\n    i = first_right_index\n    for x in LF_slice:\n        RF.insert(i, x)\n        i += 1\n\n    # Descriptive Note: We can just switch the slices directly because we know that if there were any conflicts from\n    # the switch, those fronds would also have been included in the switch.\n\n    # Exchange um and xm , vm and ym , Lm and Rm\n    # --Only Lm and Rm need to be exchanged, since um, xm, vm, and ym are all dynamically calculated\n    old_rm = dfs_data['FG'][m][1]\n    old_lm = dfs_data['FG'][m][0]\n\n    # --We have to convert the Lm and Rm dicts to use the correct keys\n    converted_rm = __convert_RF_dict_to_LF(old_rm)\n    converted_lm = __convert_LF_dict_to_RF(old_lm)\n\n    dfs_data['FG'][m][1] = converted_lm\n    dfs_data['FG'][m][0] = converted_rm\n\n    merge_Fm(dfs_data)", "response": "Switches Lm and Rm by the frond switching."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __check_left_side_conflict(x, y, dfs_data):\n    l = dfs_data['FG']['l']\n    w, z = dfs_data['LF'][l]\n    return __check_conflict_fronds(x, y, w, z, dfs_data)", "response": "Checks to see if the frond xy will conflict with a frond on the left side of the embedding."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __check_right_side_conflict(x, y, dfs_data):\n    r = dfs_data['FG']['r']\n    w, z = dfs_data['RF'][r]\n    return __check_conflict_fronds(x, y, w, z, dfs_data)", "response": "Checks to see if the frond xy will conflict with a frond on the right side of the embedding."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck a pair of fronds to see if they conflict. Returns True if a conflict was found False otherwise.", "response": "def __check_conflict_fronds(x, y, w, z, dfs_data):\n    \"\"\"Checks a pair of fronds to see if they conflict. Returns True if a conflict was found, False otherwise.\"\"\"\n\n    # Case 1: False frond and corresponding branch marker\n    # --x and w should both be negative, and either xy or wz should be the same value uu\n    if x < 0 and w < 0 and (x == y or w == z):\n        # --Determine if the marker and frond correspond (have the same low-value)\n        if x == w:\n            return True\n        return False\n\n    # Case 2: Fronds with an overlap\n    if b(x, dfs_data) == b(w, dfs_data) and x > w and w > y and y > z:\n        return False\n\n    # Case 3: Branch marker and a frond on that branch\n    if x < 0 or w < 0:\n        # --Determine which one is the branch marker\n        if x < 0:\n            u = abs(x)\n            t = y\n            x = w\n            y = z\n        else:\n            u = abs(w)\n            t = z\n        # --Run the rest of the tests\n        if b(x, dfs_data) == u and y < u and \\\n                (x, y) in __dfsify_branch_uv(u, t, dfs_data):\n            return True\n        return False\n\n    # If non of the conflict conditions were met, then there are obviously no conflicts\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds an adjacency list representation for the graph.", "response": "def __calculate_adjacency_lists(graph):\n    \"\"\"Builds an adjacency list representation for the graph, since we can't guarantee that the\n        internal representation of the graph is stored that way.\"\"\"\n    adj = {}\n    for node in graph.get_all_node_ids():\n        neighbors = graph.neighbors(node)\n        adj[node] = neighbors\n    return adj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the lowpoints for each node in a graph.", "response": "def __get_all_lowpoints(dfs_data):\n    \"\"\"Calculates the lowpoints for each node in a graph.\"\"\"\n    lowpoint_1_lookup = {}\n    lowpoint_2_lookup = {}\n\n    ordering = dfs_data['ordering']\n\n    for node in ordering:\n        low_1, low_2 = __get_lowpoints(node, dfs_data)\n        lowpoint_1_lookup[node] = low_1\n        lowpoint_2_lookup[node] = low_2\n\n    return lowpoint_1_lookup, lowpoint_2_lookup"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the lowpoints for a single node in a graph.", "response": "def __get_lowpoints(node, dfs_data):\n    \"\"\"Calculates the lowpoints for a single node in a graph.\"\"\"\n\n    ordering_lookup = dfs_data['ordering_lookup']\n\n    t_u = T(node, dfs_data)\n    sorted_t_u = sorted(t_u, key=lambda a: ordering_lookup[a])\n    lowpoint_1 = sorted_t_u[0]\n    lowpoint_2 = sorted_t_u[1]\n\n    return lowpoint_1, lowpoint_2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __edge_weight(edge_id, dfs_data):\n    graph = dfs_data['graph']\n    edge_lookup = dfs_data['edge_lookup']\n\n    edge = graph.get_edge(edge_id)\n    u, v = edge['vertices']\n    d_u = D(u, dfs_data)\n    d_v = D(v, dfs_data)\n    lp_1 = L1(v, dfs_data)\n    d_lp_1 = D(lp_1, dfs_data)\n\n    if edge_lookup[edge_id] == 'backedge' and d_v < d_u:\n        return 2*d_v\n    elif is_type_I_branch(u, v, dfs_data):\n        return 2*d_lp_1\n    elif is_type_II_branch(u, v, dfs_data):\n        return 2*d_lp_1 + 1\n    else:\n        return 2*graph.num_nodes() + 1", "response": "Calculates the edge weight used to sort edges."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the b ( u ) lookup table.", "response": "def __calculate_bu_dfs(dfs_data):\n    \"\"\"Calculates the b(u) lookup table.\"\"\"\n    u = dfs_data['ordering'][0]\n    b = {}\n    b[u] = D(u, dfs_data)\n    __calculate_bu_dfs_recursively(u, b, dfs_data)\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the b ( u ) lookup table with a recursive DFS.", "response": "def __calculate_bu_dfs_recursively(u, b, dfs_data):\n    \"\"\"Calculates the b(u) lookup table with a recursive DFS.\"\"\"\n    first_time = True\n    for v in dfs_data['adj'][u]:\n        if a(v, dfs_data) == u:\n            if first_time:\n                b[v] = b[u]\n            else:\n                b[v] = D(u, dfs_data)\n            __calculate_bu_dfs_recursively(v, b, dfs_data)\n        first_time = False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_type_I_branch(u, v, dfs_data):\n    if u != a(v, dfs_data):\n        return False\n    if u == L2(v, dfs_data):\n        return True\n    return False", "response": "Determines whether a branch uv is a type I branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_type_II_branch(u, v, dfs_data):\n    if u != a(v, dfs_data):\n        return False\n    if u < L2(v, dfs_data):\n        return True\n    return False", "response": "Determines whether a branch uv is a type II branch."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if the edge uv is a frond.", "response": "def is_frond(u, v, dfs_data):\n    \"\"\"Determines if the edge uv is a frond (\"backedge\").\"\"\"\n    d_u = D(u, dfs_data)\n    d_v = D(v, dfs_data)\n    edge_id = dfs_data['graph'].get_first_edge_id_by_node_ids(u, v)\n    return True if dfs_data['edge_lookup'][edge_id] == 'backedge' and d_v < d_u else False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_descendants(node, dfs_data):\n    list_of_descendants = []\n\n    stack = deque()\n\n    children_lookup = dfs_data['children_lookup']\n\n    current_node = node\n    children = children_lookup[current_node]\n    dfs_current_node = D(current_node, dfs_data)\n    for n in children:\n        dfs_child = D(n, dfs_data)\n        # Validate that the child node is actually a descendant and not an ancestor\n        if dfs_child > dfs_current_node:\n            stack.append(n)\n\n    while len(stack) > 0:\n        current_node = stack.pop()\n        list_of_descendants.append(current_node)\n        children = children_lookup[current_node]\n        dfs_current_node = D(current_node, dfs_data)\n        for n in children:\n            dfs_child = D(n, dfs_data)\n            # Validate that the child node is actually a descendant and not an ancestor\n            if dfs_child > dfs_current_node:\n                stack.append(n)\n\n    return list_of_descendants", "response": "Gets the descendants of a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef S_star(u, dfs_data):\n    s_u = S(u, dfs_data)\n    if u not in s_u:\n        s_u.append(u)\n    return s_u", "response": "The set of all descendants of u with u added."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef T(u, dfs_data):\n    return list(set([w for v in S_star(u, dfs_data) for w in A(v, dfs_data)]))", "response": "T ( u ) consists of all vertices adjacent to u or any descendant of u."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef B(u, v, dfs_data):\n    \"\"\"Bu(v) = {wx | w is in S*(v)}\"\"\"\n    if a(v, dfs_data) != u:\n        return None\n\n    return list(set([edge_id for w in S_star(v, dfs_data) for edge_id in dfs_data['graph'].get_node(w)['edges']]))", "response": "Returns a list of branch ids that are reachable from v."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of nodes that are leaves and branch points for the DFS - tree T.", "response": "def _L(dfs_data):\n    \"\"\"L(T) contains leaves and branch points for the DFS-tree T.\"\"\"\n    \"\"\"L(T) = {v | the first w in Adj[v] corresponds to a frond vw}.\"\"\"\n    node_set = set()\n    for v, adj in list(dfs_data['adj'].items()):\n        w = adj[0]\n        if is_frond(v, w, dfs_data):\n            node_set.add(v)\n    return list(node_set)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fn_x(i, dfs_data):\n    try:\n        return R(i, dfs_data)['x']\n    except Exception as e:\n        # Page 17 states that if Ri is empty, then we take xi to be n\n        return dfs_data['graph'].num_nodes()", "response": "The minimum vertex in a frond contained in Ri."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse this function to classify a single symbol in a given recording.", "response": "def classify_segmented_recording(recording, result_format=None):\n    \"\"\"Use this function if you are sure you have a single symbol.\n\n    Parameters\n    ----------\n    recording : string\n        The recording in JSON format\n\n    Returns\n    -------\n    list of dictionaries\n        Each dictionary contains the keys 'symbol' and 'probability'. The list\n        is sorted descending by probability.\n    \"\"\"\n    global single_symbol_classifier\n    if single_symbol_classifier is None:\n        single_symbol_classifier = SingleClassificer()\n    return single_symbol_classifier.predict(recording, result_format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npredict the class of a single handwritten dataset.", "response": "def predict(self, recording, result_format=None):\n        \"\"\"Predict the class of the given recording.\n\n        Parameters\n        ----------\n        recording : string\n            Recording of a single handwritten dataset in JSON format.\n        result_format : string, optional\n            If it is 'LaTeX', then only the latex code will be returned\n\n        Returns\n        -------\n        list\n        \"\"\"\n        evaluate = utils.evaluate_model_single_recording_preloaded\n        results = evaluate(self.preprocessing_queue,\n                           self.feature_list,\n                           self.model,\n                           self.output_semantics,\n                           recording)\n        if result_format == 'LaTeX':\n            for i in range(len(results)):\n                results[i]['semantics'] = results[i]['semantics'].split(\";\")[1]\n        for i in range(len(results)):\n            splitted = results[i]['semantics'].split(\";\")\n            results[i]['complete_latex'] = splitted[1]\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of ids which describe which class they get mapped to.", "response": "def get_symbol_ids(symbol_yml_file, metadata):\n    \"\"\"\n    Get a list of ids which describe which class they get mapped to.\n\n    Parameters\n    ----------\n    symbol_yml_file : string\n        Path to a YAML file.\n    metadata : dict\n        Metainformation of symbols, like the id on write-math.com.\n        Has keys 'symbols', 'tags', 'tags2symbols'.\n\n    Returns\n    -------\n    list of dictionaries : Each dictionary represents one output class and has\n        to have the keys 'id' (which is an id on write-math.com) and\n        'mappings' (which is a list of ids on write-math.com). The mappings\n        list should at least contain the id itself, but can contain more.\n\n    Examples\n    --------\n    >>> get_symbol_ids('symbols.yml')\n    [{'id': 42, 'mappings': [1, 42, 456, 1337]}, {'id': 2, 'mappings': [2]}]\n\n    The yml file has to be of the structure\n\n    ```\n    - {latex: 'A'}\n    - {latex: 'B'}\n    - {latex: 'O',\n       mappings: ['0', 'o']}\n    - {latex: 'C'}\n    - {latex: '::REJECT::',\n       mappings: ['::ALL_FREE::']}\n    - {latex: '::ARROW::',\n       mappings: ['::TAG/arrow::'],\n       exclude: ['\\rightarrow']}\n    ```\n    \"\"\"\n    with open(symbol_yml_file, 'r') as stream:\n        symbol_cfg = yaml.load(stream)\n    symbol_ids = []\n    symbol_ids_set = set()\n\n    for symbol in symbol_cfg:\n        if 'latex' not in symbol:\n            logging.error(\"Key 'latex' not found for a symbol in %s (%s)\",\n                          symbol_yml_file,\n                          symbol)\n            sys.exit(-1)\n        results = [el for el in metadata['symbols']\n                   if el['formula_in_latex'] == symbol['latex']]\n        if len(results) != 1:\n            logging.warning(\"Found %i results for %s: %s\",\n                            len(results),\n                            symbol['latex'],\n                            results)\n            if len(results) > 1:\n                results = sorted(results, key=lambda n: n['id'])\n            else:\n                sys.exit(-1)\n        mapping_ids = [results[0]['id']]\n        if 'mappings' in symbol:\n            for msymbol in symbol['mappings']:\n                filtered = [el for el in metadata['symbols']\n                            if el['formula_in_latex'] == msymbol['latex']]\n                if len(filtered) != 1:\n                    logging.error(\"Found %i results for %s: %s\",\n                                  len(filtered),\n                                  msymbol,\n                                  filtered)\n                    if len(filtered) > 1:\n                        filtered = natsorted(filtered, key=lambda n: n['id'])\n                    else:\n                        sys.exit(-1)\n                mapping_ids.append(filtered[0]['id'])\n        symbol_ids.append({'id': int(results[0]['id']),\n                           'formula_in_latex': results[0]['formula_in_latex'],\n                           'mappings': mapping_ids})\n        for id_tmp in mapping_ids:\n            if id_tmp not in symbol_ids_set:\n                symbol_ids_set.add(id_tmp)\n            else:\n                for symbol_tmp in symbol_ids:\n                    if id_tmp in symbol_tmp['mappings']:\n                        break\n                logging.error('Symbol id %s is already used: %s',\n                              id_tmp,\n                              symbol_tmp)\n                sys.exit(-1)\n\n    # print(metadata.keys())\n    # for el in metadata:\n    #    print(metadata[el][0].keys())\n    # TODO: assert no double mappings\n    # TODO: Support for\n    # - ::ALL_FREE:: - meaning the rest of all ids which are not assigned to\n    #                  any other class get assigned to this class\n    # - ::TAG/arrow:: - meaning all ids of the tag arrow get assigned here\n    # - exclude\n    logging.info('%i base classes and %i write-math ids.',\n                 len(symbol_ids),\n                 len(symbol_ids_set))\n    return symbol_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_metadata():\n    misc_path = pkg_resources.resource_filename('hwrt', 'misc/')\n    wm_symbols = os.path.join(misc_path, 'wm_symbols.csv')\n    wm_tags = os.path.join(misc_path, 'wm_tags.csv')\n    wm_tags2symbols = os.path.join(misc_path, 'wm_tags2symbols.csv')\n    return {'symbols': read_csv(wm_symbols),\n            'tags': read_csv(wm_tags),\n            'tags2symbols': read_csv(wm_tags2symbols)}", "response": "Get metadata of the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_csv(filepath):\n    symbols = []\n    with open(filepath, 'rb') as csvfile:\n        spamreader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n        for row in spamreader:\n            symbols.append(row)\n    return symbols", "response": "Reads a CSV file into a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a pickle file of raw recordings.", "response": "def load_raw(raw_pickle_file):\n    \"\"\"\n    Load a pickle file of raw recordings.\n\n    Parameters\n    ----------\n    raw_pickle_file : str\n        Path to a pickle file which contains raw recordings.\n\n    Returns\n    -------\n    dict\n        The loaded pickle file.\n    \"\"\"\n    with open(raw_pickle_file, 'rb') as f:\n        raw = pickle.load(f)\n    logging.info(\"Loaded %i recordings.\", len(raw['handwriting_datasets']))\n    return raw"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter and save the raw dict to a file.", "response": "def filter_and_save(raw, symbol_ids, destination_path):\n    \"\"\"\n    Parameters\n    ----------\n    raw : dict\n        with key 'handwriting_datasets'\n    symbol_ids : dict\n        Maps LaTeX to write-math.com id\n    destination_path : str\n        Path where the filtered dict 'raw' will be saved\n    \"\"\"\n    logging.info('Start filtering...')\n    new_hw_ds = []\n    for el in raw['handwriting_datasets']:\n        if el['formula_id'] in symbol_ids:\n            el['formula_id'] = symbol_ids[el['formula_id']]\n            el['handwriting'].formula_id = symbol_ids[el['formula_id']]\n            new_hw_ds.append(el)\n    raw['handwriting_datasets'] = new_hw_ds\n\n    # pickle\n    logging.info('Start dumping %i recordings...', len(new_hw_ds))\n    pickle.dump(raw, open(destination_path, \"wb\"), 2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_metrics(metrics_description):\n    return utils.get_objectlist(metrics_description,\n                                config_key='data_analyzation_plugins',\n                                module=sys.modules[__name__])", "response": "Get metrics from a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntruncates the file and return the filename.", "response": "def prepare_file(filename):\n    \"\"\"Truncate the file and return the filename.\"\"\"\n    directory = os.path.join(utils.get_project_root(), \"analyzation/\")\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    workfilename = os.path.join(directory, filename)\n    open(workfilename, 'w').close()  # Truncate the file\n    return workfilename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_by_formula_id(raw_datasets):\n    by_formula_id = defaultdict(list)\n    for el in raw_datasets:\n        by_formula_id[el['handwriting'].formula_id].append(el['handwriting'])\n    return by_formula_id", "response": "Sort a list of formulas by formula id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite all obtained data to a file.", "response": "def _write_data(self, symbols, err_recs, nr_recordings,\n                    total_error_count, percentages, time_max_list):\n        \"\"\"Write all obtained data to a file.\n\n        Parameters\n        ----------\n        symbols : list of tuples (String, non-negative int)\n            List of all symbols with the count of recordings\n        err_recs : dictionary\n            count of recordings by error type\n        nr_recordings : non-negative int\n            number of recordings\n        total_error_count : dictionary\n            Count of all error that have happened by type\n        percentages : list\n            List of all recordings where removing the dots changed the size of\n            the bounding box.\n        time_max_list : list\n            List of all recordings where the recording time is above a\n            threshold.\n        \"\"\"\n        write_file = open(self.filename, \"a\")\n        s = \"\"\n        for symbol, count in sorted(symbols.items(), key=lambda n: n[0]):\n            if symbol in ['a', '0', 'A']:\n                s += \"\\n%s (%i), \" % (symbol, count)\n            elif symbol in ['z', '9', 'Z']:\n                s += \"%s (%i) \\n\" % (symbol, count)\n            else:\n                s += \"%s (%i), \" % (symbol, count)\n        print(\"## Data\", file=write_file)\n        print(\"Symbols: %i\" % len(symbols), file=write_file)\n        print(\"Recordings: %i\" % sum(symbols.values()), file=write_file)\n        print(\"```\", file=write_file)\n        print(s[:-1], file=write_file)\n        print(\"```\", file=write_file)\n\n        # Show errors\n        print(\"Recordings with wild points: %i (%0.2f%%)\" %\n              (err_recs['wild_points'],\n               float(err_recs['wild_points']) / nr_recordings * 100),\n              file=write_file)\n        print(\"wild points: %i\" % total_error_count['wild_points'],\n              file=write_file)\n        print(\"Recordings with missing stroke: %i (%0.2f%%)\" %\n              (err_recs['missing_stroke'],\n               float(err_recs['missing_stroke']) / nr_recordings * 100),\n              file=write_file)\n        print(\"Recordings with errors: %i (%0.2f%%)\" %\n              (err_recs['total'],\n               float(err_recs['total']) / nr_recordings * 100),\n              file=write_file)\n        print(\"Recordings with dots: %i (%0.2f%%)\" %\n              (err_recs['single_dots'],\n               float(err_recs['single_dots']) / nr_recordings * 100),\n              file=write_file)\n        print(\"dots: %i\" % total_error_count['single_dots'], file=write_file)\n        print(\"size changing removal: %i (%0.2f%%)\" %\n              (len(percentages),\n               float(len(percentages)) / nr_recordings * 100),\n              file=write_file)\n        print(\"%i recordings took more than %i ms. That were: \" %\n              (len(time_max_list), self.time_max_threshold),\n              file=write_file)\n        for recording in time_max_list:\n            print(\"* %ims: %s: %s\" %\n                  (recording.get_time(),\n                   utils.get_readable_time(recording.get_time()),\n                   recording),\n                  file=write_file)\n        write_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_features(model_description_features):\n    return utils.get_objectlist(model_description_features,\n                                config_key='features',\n                                module=sys.modules[__name__])", "response": "Get features from a list of dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_featurelist(feature_list):\n    input_features = sum(map(lambda n: n.get_dimension(), feature_list))\n    print(\"## Features (%i)\" % input_features)\n    print(\"```\")\n    for algorithm in feature_list:\n        print(\"* %s\" % str(algorithm))\n    print(\"```\")", "response": "Print the feature_list in a human - readable form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dimension(self):\n        if self.strokes > 0:\n            if self.pixel_env > 0:\n                return (2 + (1 + 2*self.pixel_env)**2) \\\n                    * self.strokes * self.points_per_stroke\n            else:\n                return 2*self.strokes * self.points_per_stroke\n        else:\n            if self.pen_down:\n                return 3*self.points_per_stroke\n            else:\n                return 2*self.points_per_stroke", "response": "Get the dimension of the returned feature. This equals the number\n           of elements in the returned list of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _features_with_strokes(self, hwr_obj):\n        x = []\n        img = Image.new('L', ((int(hwr_obj.get_width()*self.scaling_factor) + 2), (int(hwr_obj.get_height()*self.scaling_factor) + 2)), 'black')\n        draw = ImageDraw.Draw(img, 'L')\n        pointlist = hwr_obj.get_pointlist()\n        bb = hwr_obj.get_bounding_box()\n        for stroke_nr in range(self.strokes):\n            last_point = None\n            # make sure that the current symbol actually has that many\n            # strokes\n            if stroke_nr < len(pointlist):\n                for point_nr in range(self.points_per_stroke):\n                    if point_nr < len(pointlist[stroke_nr]):\n                        point = pointlist[stroke_nr][point_nr]\n                        x.append(pointlist[stroke_nr][point_nr]['x'])\n                        x.append(pointlist[stroke_nr][point_nr]['y'])\n                        if last_point is None:\n                            last_point = point\n                        y_from = int((-bb['miny'] + last_point['y'])*self.scaling_factor)\n                        x_from = int((-bb['minx'] + last_point['x'])*self.scaling_factor)\n                        y_to = int((-bb['miny'] + point['y'])*self.scaling_factor)\n                        x_to = int((-bb['minx'] + point['x'])*self.scaling_factor)\n                        draw.line([x_from, y_from, x_to, y_to], fill='#ffffff', width=1)\n                        if self.pixel_env > 0:\n                            pix = img.load()\n                            for x_offset in range(-self.pixel_env,\n                                                  self.pixel_env + 1):\n                                for y_offset in range(-self.pixel_env,\n                                                      self.pixel_env + 1):\n                                    xp = int((-bb['minx'] + point['x'])\n                                             * self.scaling_factor) + x_offset\n                                    yp = int((-bb['miny'] + point['y'])\n                                             * self.scaling_factor) + y_offset\n                                    xp = max(0, xp)\n                                    yp = max(0, yp)\n                                    x.append(pix[xp, yp])\n                        last_point = point\n                    else:\n                        x.append(self.fill_empty_with)\n                        x.append(self.fill_empty_with)\n                        if self.pixel_env > 0:\n                            for i in range((1 + 2 * self.pixel_env)**2):\n                                x.append(self.fill_empty_with)\n            else:\n                for _ in range(self.points_per_stroke):\n                    x.append(self.fill_empty_with)\n                    x.append(self.fill_empty_with)\n                    if self.pixel_env > 0:\n                        for i in range((1 + 2 * self.pixel_env)**2):\n                            x.append(self.fill_empty_with)\n        del draw\n        return x", "response": "Calculate the ConstantPointCoordinates features for the case of\n ongoing a fixed number of strokes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _features_without_strokes(self, hwr_obj):\n        x = []\n        for point in hwr_obj.get_pointlist()[0]:\n            if len(x) >= 3*self.points_per_stroke or \\\n               (len(x) >= 2*self.points_per_stroke and not self.pen_down):\n                break\n            x.append(point['x'])\n            x.append(point['y'])\n            if self.pen_down:\n                if 'pen_down' not in point:\n                    logging.error(\"The \"\n                                  \"ConstantPointCoordinates(strokes=0) \"\n                                  \"feature should only be used after \"\n                                  \"SpaceEvenly preprocessing step.\")\n                else:\n                    x.append(int(point['pen_down']))\n        if self.pen_down:\n            while len(x) != 3*self.points_per_stroke:\n                x.append(self.fill_empty_with)\n        else:\n            while len(x) != 2*self.points_per_stroke:\n                x.append(self.fill_empty_with)\n        return x", "response": "Calculate the ConstantPointCoordinates features for the case of\n           a single stroke with pen_down features."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the dimension of the returned feature. This equals the number of elements in the returned list of numbers.", "response": "def get_dimension(self):\n        \"\"\"Get the dimension of the returned feature. This equals the number\n           of elements in the returned list of numbers.\"\"\"\n        return int(round(float(self.strokes**2)/2 + float(self.strokes)/2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunk_math(text):\n\n    # Fail when '{' and '}' don't match - be aware of escaped symbols!\n    opened_braces = 0\n    last_char = ''\n    for char in text:\n        if char == '{' and last_char != '\\\\':\n            opened_braces += 1\n        if char == '}' and last_char != '\\\\':\n            opened_braces -= 1\n            if opened_braces < 0:\n                raise ValueError(\"Braces don't match: %s\" % text)\n        last_char = char\n    if opened_braces != 0:\n        raise ValueError(\"%i braces are still open\" % opened_braces)\n\n    # Parse\n    single_symbol = ['_', '^', '&', '{', '}']\n    breaking_chars = ['\\\\', ' '] + single_symbol\n\n    chunks = []\n    current_chunk = ''\n\n    for char in text:\n        if current_chunk == '':\n            current_chunk = char\n            continue\n        if char == '\\\\':\n            if current_chunk == '\\\\':\n                current_chunk += char\n                chunks.append(current_chunk)\n                current_chunk = ''\n            else:\n                chunks.append(current_chunk)\n                current_chunk = char\n        elif current_chunk == '\\\\' and char in breaking_chars:  # escaped\n            current_chunk += char\n            chunks.append(current_chunk)\n            current_chunk = ''\n        elif char in breaking_chars:\n            chunks.append(current_chunk)\n            current_chunk = char\n        elif char in string.letters+string.digits and current_chunk[0] == '\\\\':\n            current_chunk += char\n        else:\n            chunks.append(current_chunk)\n            current_chunk = char\n\n    # Add the last chunk\n    if current_chunk != '':\n        chunks.append(current_chunk)\n    filtered = []\n    for chunk in chunks:\n        if len(filtered) > 0 and filtered[-1] == ' ' and chunk == ' ':\n            continue\n        filtered.append(chunk)\n    return filtered", "response": "A mathematical chunk of LaTeX text into a single LaTeX file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunks_to_string(chunks):\n    string = ''\n    began_context = False\n    context_depth = 0\n    context_triggers = ['_', '^']\n    for chunk in chunks:\n        if began_context and chunk != '{':\n            string += '{' + chunk + '}'\n            began_context = False\n        elif began_context and chunk == '{':\n            began_context = False\n            string += chunk\n        else:\n            if chunk in context_triggers:\n                began_context = True\n                context_depth += 1\n            string += chunk\n    return string", "response": "Converts a list of strings to LaTeX - parsable string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting preprocessing queue from a list of dictionaries", "response": "def get_preprocessing_queue(preprocessing_list):\n    \"\"\"Get preprocessing queue from a list of dictionaries\n\n    >>> l = [{'RemoveDuplicateTime': None},\n             {'ScaleAndShift': [{'center': True}]}\n            ]\n    >>> get_preprocessing_queue(l)\n    [RemoveDuplicateTime, ScaleAndShift\n     - center: True\n     - max_width: 1\n     - max_height: 1\n    ]\n    \"\"\"\n    return utils.get_objectlist(preprocessing_list,\n                                config_key='preprocessing',\n                                module=sys.modules[__name__])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_preprocessing_list(preprocessing_queue):\n    print(\"## Preprocessing\")\n    print(\"```\")\n    for algorithm in preprocessing_queue:\n        print(\"* \" + str(algorithm))\n    print(\"```\")", "response": "Print the preprocessing_queue in a human - readable form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_parameters(self, hwr_obj):\n        a = hwr_obj.get_bounding_box()\n\n        width = a['maxx'] - a['minx'] + self.width_add\n        height = a['maxy'] - a['miny'] + self.height_add\n\n        factor_x, factor_y = 1, 1\n        if width != 0:\n            factor_x = self.max_width / width\n\n        if height != 0:\n            factor_y = self.max_height / height\n\n        factor = min(factor_x, factor_y)\n        addx, addy = 0.0, 0.0\n\n        if self.center:\n            # Only one dimension (x or y) has to be centered (the smaller one)\n            add = -(factor / (2.0 * max(factor_x, factor_y)))\n\n            if factor == factor_x:\n                addy = add\n                if self.center_other:\n                    addx = -(width * factor / 2.0)\n            else:\n                addx = add\n                if self.center_other:\n                    addy = -(height * factor / 2.0)\n        assert factor > 0, \"factor > 0 is False. factor = %s\" % str(factor)\n        assert isinstance(addx, float), \"addx is %s\" % str(addx)\n        assert isinstance(addy, float), \"addy is %s\" % str(addy)\n        assert isinstance(a['minx'], (int, float)), \"minx is %s\" % str(a['minx'])\n        assert isinstance(a['miny'], (int, float)), \"miny is %s\" % str(a['miny'])\n        assert isinstance(a['mint'], (int, float)), \"mint is %s\" % str(a['mint'])\n        return {\"factor\": factor, \"addx\": addx, \"addy\": addy,\n                \"minx\": a['minx'], \"miny\": a['miny'], \"mint\": a['mint']}", "response": "Return a dictionary of parameters for scaling and scaling and scaling and scaling and scaling and scaling and scaling and scaling."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _calculate_pen_down_strokes(self, pointlist, times=None):\n        if times is None:\n            times = []\n        for stroke in pointlist:\n            stroke_info = {\"start\": stroke[0]['time'],\n                           \"end\": stroke[-1]['time'],\n                           \"pen_down\": True}\n            # set up variables for interpolation\n            x, y, t = [], [], []\n            for point in stroke:\n                if point['time'] not in t:\n                    x.append(point['x'])\n                    y.append(point['y'])\n                    t.append(point['time'])\n            x, y = numpy.array(x), numpy.array(y)\n            if len(t) == 1:\n                # constant interpolation\n                fx, fy = lambda x: float(x), lambda y: float(y)\n            elif len(t) == 2:\n                # linear interpolation\n                fx, fy = interp1d(t, x, 'linear'), interp1d(t, y, 'linear')\n            elif len(t) == 3:\n                # quadratic interpolation\n                fx = interp1d(t, x, 'quadratic')\n                fy = interp1d(t, y, 'quadratic')\n            else:\n                fx, fy = interp1d(t, x, self.kind), interp1d(t, y, self.kind)\n            stroke_info['fx'] = fx\n            stroke_info['fy'] = fy\n            times.append(stroke_info)\n        return times", "response": "Calculate the intervall borders times that contain the information\n           when a stroke started when it ended and how it should be beater down."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the times where the user moved from one stroke to the next.", "response": "def _calculate_pen_up_strokes(self, pointlist, times=None):\n        \"\"\" 'Pen-up' strokes are virtual strokes that were not drawn. It\n            models the time when the user moved from one stroke to the next.\n        \"\"\"\n        if times is None:\n            times = []\n        for i in range(len(pointlist) - 1):\n            stroke_info = {\"start\": pointlist[i][-1]['time'],\n                           \"end\": pointlist[i + 1][0]['time'],\n                           \"pen_down\": False}\n            x, y, t = [], [], []\n            for point in [pointlist[i][-1], pointlist[i + 1][0]]:\n                if point['time'] not in t:\n                    x.append(point['x'])\n                    y.append(point['y'])\n                    t.append(point['time'])\n            if len(x) == 1:\n                # constant interpolation\n                fx, fy = lambda x: float(x), lambda y: float(y)\n            else:\n                # linear interpolation\n                x, y = numpy.array(x), numpy.array(y)\n                fx = interp1d(t, x, kind='linear')\n                fy = interp1d(t, y, kind='linear')\n            stroke_info['fx'] = fx\n            stroke_info['fy'] = fy\n            times.append(stroke_info)\n        return times"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninterpolate the stroke with the given kind.", "response": "def _space(self, hwr_obj, stroke, kind):\n        \"\"\"Do the interpolation of 'kind' for 'stroke'\"\"\"\n        new_stroke = []\n        stroke = sorted(stroke, key=lambda p: p['time'])\n\n        x, y, t = [], [], []\n\n        for point in stroke:\n            x.append(point['x'])\n            y.append(point['y'])\n            t.append(point['time'])\n\n        x, y = numpy.array(x), numpy.array(y)\n        failed = False\n        try:\n            fx = interp1d(t, x, kind=kind)\n            fy = interp1d(t, y, kind=kind)\n        except Exception as e:  # pylint: disable=W0703\n            if hwr_obj.raw_data_id is not None:\n                logging.debug(\"spline failed for raw_data_id %i\",\n                              hwr_obj.raw_data_id)\n            else:\n                logging.debug(\"spline failed\")\n            logging.debug(e)\n            failed = True\n\n        tnew = numpy.linspace(t[0], t[-1], self.number)\n\n        # linear interpolation fallback due to\n        # https://github.com/scipy/scipy/issues/3868\n        if failed:\n            try:\n                fx = interp1d(t, x, kind='linear')\n                fy = interp1d(t, y, kind='linear')\n                failed = False\n            except Exception as e:\n                logging.debug(\"len(stroke) = %i\", len(stroke))\n                logging.debug(\"len(x) = %i\", len(x))\n                logging.debug(\"len(y) = %i\", len(y))\n                logging.debug(\"stroke=%s\", stroke)\n                raise e\n\n        for x, y, t in zip(fx(tnew), fy(tnew), tnew):\n            new_stroke.append({'x': x, 'y': y, 'time': t})\n        return new_stroke"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the arithmetic mean of the points x and y coordinates seperately.", "response": "def _calculate_average(self, points):\n        \"\"\"Calculate the arithmetic mean of the points x and y coordinates\n           seperately.\n        \"\"\"\n        assert len(self.theta) == len(points), \\\n            \"points has length %i, but should have length %i\" % \\\n            (len(points), len(self.theta))\n        new_point = {'x': 0, 'y': 0, 'time': 0}\n        for key in new_point:\n            new_point[key] = self.theta[0] * points[0][key] + \\\n                self.theta[1] * points[1][key] + \\\n                self.theta[2] * points[2][key]\n        return new_point"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_model(model_folder, model_type, topology, override):\n    latest_model = utils.get_latest_in_folder(model_folder, \".json\")\n    if (latest_model == \"\") or override:\n        logging.info(\"Create a base model...\")\n        model_src = os.path.join(model_folder, \"model-0.json\")\n        command = \"%s make %s %s > %s\" % (utils.get_nntoolkit(),\n                                          model_type,\n                                          topology,\n                                          model_src)\n        logging.info(command)\n        os.system(command)\n    else:\n        logging.info(\"Model file already existed.\")", "response": "Create a base model if it doesn t exist already."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the info. yml from model_folder and create the model file.", "response": "def main(model_folder, override=False):\n    \"\"\"Parse the info.yml from ``model_folder`` and create the model file.\"\"\"\n    model_description_file = os.path.join(model_folder, \"info.yml\")\n    # Read the model description file\n    with open(model_description_file, 'r') as ymlfile:\n        model_description = yaml.load(ymlfile)\n\n    project_root = utils.get_project_root()\n    # Read the feature description file\n    feature_folder = os.path.join(project_root,\n                                  model_description['data-source'])\n    with open(os.path.join(feature_folder, \"info.yml\"), 'r') as ymlfile:\n        feature_description = yaml.load(ymlfile)\n    # Get a list of all used features\n    feature_list = features.get_features(feature_description['features'])\n    # Get the dimension of the feature vector\n    input_features = sum(map(lambda n: n.get_dimension(), feature_list))\n    logging.info(\"Number of features: %i\", input_features)\n\n    # Analyze model\n    logging.info(model_description['model'])\n    if model_description['model']['type'] != 'mlp':\n        return\n    create_model(model_folder,\n                 model_description['model']['type'],\n                 model_description['model']['topology'],\n                 override)\n    utils.create_run_logfile(model_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the parser object for this script.", "response": "def get_parser():\n    \"\"\"Return the parser object for this script.\"\"\"\n    project_root = utils.get_project_root()\n\n    # Get latest model folder\n    models_folder = os.path.join(project_root, \"models\")\n    latest_model = utils.get_latest_folder(models_folder)\n\n    # Get command line arguments\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-m\", \"--model\",\n                        dest=\"model\",\n                        help=\"where is the model folder (with a info.yml)?\",\n                        metavar=\"FOLDER\",\n                        type=lambda x: utils.is_valid_folder(parser, x),\n                        default=latest_model)\n    parser.add_argument(\"-o\", \"--override\",\n                        action=\"store_true\", dest=\"override\",\n                        default=False,\n                        help=(\"should the model be overridden \"\n                              \"if it already exists?\"))\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef submit_recording(raw_data_json):\n    url = \"http://www.martin-thoma.de/write-math/classify/index.php\"\n    headers = {'User-Agent': 'Mozilla/5.0',\n               'Content-Type': 'application/x-www-form-urlencoded'}\n    payload = {'drawnJSON': raw_data_json}\n\n    s = requests.Session()\n    req = requests.Request('POST', url, headers=headers, data=payload)\n    prepared = req.prepare()\n    s.send(prepared)", "response": "Submit a recording to the database on write - math. com."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows the TOP n results of a classification.", "response": "def show_results(results, n=10):\n    \"\"\"Show the TOP n results of a classification.\n    >>> results = [{'\\\\alpha': 0.67}, {'\\\\propto': 0.25}]\n    >>> show_results(results)\n    \"\"\"\n    import nntoolkit.evaluate\n    classification = nntoolkit.evaluate.show_results(results, n)\n    return \"<pre>\" + classification.replace(\"\\n\", \"<br/>\") + \"</pre>\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the top n results as a JSON list.", "response": "def get_json_result(results, n=10):\n    \"\"\"Return the top `n` results as a JSON list.\n    >>> results = [{'probability': 0.65,\n    ...             'whatever': 'bar'},\n    ...            {'probability': 0.21,\n    ...             'whatever': 'bar'},\n    ...            {'probability': 0.05,\n    ...             'whatever': 'bar'},]\n    >>> get_json_result(results, n=10)\n    [{'\\\\alpha': 0.65}, {'\\\\propto': 0.25}, {'\\\\varpropto': 0.0512}]\n    \"\"\"\n    s = []\n    last = -1\n    for res in results[:min(len(results), n)]:\n        if res['probability'] < last*0.5 and res['probability'] < 0.05:\n            break\n        if res['probability'] < 0.01:\n            break\n        s.append(res)\n        last = res['probability']\n    return json.dumps(s)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing a worker for write - math. com.", "response": "def worker():\n    \"\"\"Implement a worker for write-math.com.\"\"\"\n    global n\n    global use_segmenter_flag\n    if request.method == 'POST':\n        raw_data_json = request.form['classify']\n        try:\n            secret_uuid = request.form['secret']\n        except:\n            logging.info(\"No secret uuid given. Create one.\")\n            secret_uuid = str(uuid.uuid4())\n\n        # Check recording\n        try:\n            json.loads(raw_data_json)\n        except ValueError:\n            return \"Invalid JSON string: %s\" % raw_data_json\n\n        # Classify\n        if use_segmenter_flag:\n            strokelist = json.loads(raw_data_json)\n            beam = utils.get_beam(secret_uuid)\n\n            if beam is None:\n                beam = se.Beam()\n                for stroke in strokelist:\n                    beam.add_stroke(stroke)\n                results = beam.get_results()\n                utils.store_beam(beam, secret_uuid)\n            else:\n                stroke = strokelist[-1]\n                beam.add_stroke(stroke)\n                results = beam.get_results()\n                utils.store_beam(beam, secret_uuid)\n        else:\n            results = classify.classify_segmented_recording(raw_data_json)\n        return get_json_result(results, n=n)\n    else:\n        # Page where the user can enter a recording\n        return \"Classification Worker (Version %s)\" % hwrt.__version__"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting some strokes of pointlist", "response": "def _get_part(pointlist, strokes):\n    \"\"\"Get some strokes of pointlist\n\n    Parameters\n    ----------\n    pointlist : list of lists of dicts\n    strokes : list of integers\n\n    Returns\n    -------\n    list of lists of dicts\n    \"\"\"\n    result = []\n    strokes = sorted(strokes)\n    for stroke_index in strokes:\n        result.append(pointlist[stroke_index])\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a dictionary which translates from a neural network output to semantics.", "response": "def _get_translate():\n    \"\"\"\n    Get a dictionary which translates from a neural network output to\n    semantics.\n    \"\"\"\n    translate = {}\n    model_path = pkg_resources.resource_filename('hwrt', 'misc/')\n    translation_csv = os.path.join(model_path, 'latex2writemathindex.csv')\n    arguments = {'newline': '', 'encoding': 'utf8'}\n    with open(translation_csv, 'rt', **arguments) as csvfile:\n        contents = csvfile.read()\n    lines = contents.split(\"\\n\")\n    for csvrow in lines:\n        csvrow = csvrow.split(',')\n        if len(csvrow) == 1:\n            writemathid = csvrow[0]\n            latex = \"\"\n        else:\n            writemathid, latex = csvrow[0], csvrow[1:]\n            latex = ','.join(latex)\n        translate[latex] = writemathid\n    return translate"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_writemath_id(el, translate):\n    semantics = el['semantics'].split(\";\")[1]\n    if semantics not in translate:\n        logging.debug(\"Could not find '%s' in translate.\", semantics)\n        logging.debug(\"el: %s\", el)\n        return None\n    else:\n        writemathid = translate[semantics]\n    return writemathid", "response": "Returns the ID of the writemath on write - math. com"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fix_writemath_answer(results):\n    new_results = []\n    # Read csv\n    translate = _get_translate()\n\n    for i, el in enumerate(results):\n        writemathid = get_writemath_id(el, translate)\n        if writemathid is None:\n            continue\n        new_results.append({'symbolnr': el['symbolnr'],\n                            'semantics': writemathid,\n                            'probability': el['probability']})\n        if i >= 10 or (i > 0 and el['probability'] < 0.20):\n            break\n    return new_results", "response": "Fixes the answer of a write - math server to a more readable format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef work():\n    global n\n\n    cmd = utils.get_project_configuration()\n    if 'worker_api_key' not in cmd:\n        return (\"You need to define a 'worker_api_key' in your ~/\")\n\n    chunk_size = 1000\n\n    logging.info(\"Start working with n=%i\", n)\n    for _ in range(chunk_size):\n        # contact the write-math server and get something to classify\n        url = \"http://www.martin-thoma.de/write-math/api/get_unclassified.php\"\n        response = urlopen(url)\n        page_source = response.read()\n        parsed_json = json.loads(page_source)\n        if parsed_json is False:\n            return \"Nothing left to classify\"\n        raw_data_json = parsed_json['recording']\n\n        # Classify\n        # Check recording\n        try:\n            json.loads(raw_data_json)\n        except ValueError:\n            return (\"Raw Data ID %s; Invalid JSON string: %s\" %\n                    (parsed_json['id'], raw_data_json))\n\n        # Classify\n        if use_segmenter_flag:\n            strokelist = json.loads(raw_data_json)\n            beam = se.Beam()\n            for stroke in strokelist:\n                beam.add_stroke(stroke)\n            results = beam.get_writemath_results()\n        else:\n            results_sym = classify.classify_segmented_recording(raw_data_json)\n            results = []\n            strokelist = json.loads(raw_data_json)\n            segmentation = [list(range(len(strokelist)))]\n            translate = _get_translate()\n            for symbol in results_sym:\n                s = {'id': get_writemath_id(symbol, translate),\n                     'probability': symbol['probability']}\n                results.append({'probability': symbol['probability'],\n                                'segmentation': segmentation,\n                                'symbols': [s]})\n\n        print(\"\\thttp://write-math.com/view/?raw_data_id=%s\" %\n              str(parsed_json['id']))\n\n        # Submit classification to write-math.com server\n        results_json = get_json_result(results, n=n)\n        headers = {'User-Agent': 'Mozilla/5.0',\n                   'Content-Type': 'application/x-www-form-urlencoded'}\n        payload = {'recording_id': parsed_json['id'],\n                   'results': results_json,\n                   'api_key': cmd['worker_api_key']}\n\n        s = requests.Session()\n        req = requests.Request('POST', url, headers=headers, data=payload)\n        prepared = req.prepare()\n        response = s.send(prepared)\n        try:\n            response = json.loads(response.text)\n        except ValueError:\n            return \"Invalid JSON response: %s\" % response.text\n\n        if 'error' in response:\n            logging.info(response)\n            return str(response)\n    return \"Done - Classified %i recordings\" % chunk_size", "response": "Implement a worker for write - math. com."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parser():\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-n\",\n                        dest=\"n\", default=10, type=int,\n                        help=\"Show TOP-N results\")\n    parser.add_argument(\"--port\",\n                        dest=\"port\", default=5000, type=int,\n                        help=\"where should the webserver run\")\n    parser.add_argument(\"--use_segmenter\",\n                        dest=\"use_segmenter\",\n                        default=False,\n                        action='store_true',\n                        help=(\"try to segment the input for multiple symbol \"\n                              \"recognition\"))\n    return parser", "response": "Return the parser object for this script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the currently watched instance is outdated and update it eventually.", "response": "def update_if_outdated(folder):\n    \"\"\"Check if the currently watched instance (model, feature or\n        preprocessing) is outdated and update it eventually.\n    \"\"\"\n\n    folders = []\n    while os.path.isdir(folder):\n        folders.append(folder)\n        # Get info.yml\n        with open(os.path.join(folder, \"info.yml\")) as ymlfile:\n            content = yaml.load(ymlfile)\n        folder = os.path.join(utils.get_project_root(), content['data-source'])\n    raw_source_file = folder\n    if not os.path.isfile(raw_source_file):\n        logging.error(\"File '%s' was not found.\", raw_source_file)\n        logging.error(\"You should eventually execute 'hwrt download'.\")\n        sys.exit(-1)\n    dt = os.path.getmtime(raw_source_file)\n    source_mtime = datetime.datetime.utcfromtimestamp(dt)\n    folders = folders[::-1]  # Reverse order to get the most \"basic one first\"\n\n    for target_folder in folders:\n        target_mtime = utils.get_latest_successful_run(target_folder)\n        if target_mtime is None or source_mtime > target_mtime:\n            # The source is later than the target. That means we need to\n            # refresh the target\n            if \"preprocessed\" in target_folder:\n                logging.info(\"Preprocessed file was outdated. Update...\")\n                preprocess_dataset.main(os.path.join(utils.get_project_root(),\n                                                     target_folder))\n            elif \"feature-files\" in target_folder:\n                logging.info(\"Feature file was outdated. Update...\")\n                create_ffiles.main(target_folder)\n            elif \"model\" in target_folder:\n                logging.info(\"Model file was outdated. Update...\")\n                create_model.main(target_folder, True)\n            target_mtime = datetime.datetime.utcnow()\n        else:\n            logging.info(\"'%s' is up-to-date.\", target_folder)\n        source_mtime = target_mtime"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a string that contains a command that contains all necessary parameters to train the model.", "response": "def generate_training_command(model_folder):\n    \"\"\"Generate a string that contains a command with all necessary\n       parameters to train the model.\"\"\"\n    update_if_outdated(model_folder)\n    model_description_file = os.path.join(model_folder, \"info.yml\")\n    # Read the model description file\n    with open(model_description_file, 'r') as ymlfile:\n        model_description = yaml.load(ymlfile)\n\n    # Get the data paths (hdf5 files)\n    project_root = utils.get_project_root()\n    data = {}\n    data['training'] = os.path.join(project_root,\n                                    model_description[\"data-source\"],\n                                    \"traindata.hdf5\")\n    data['testing'] = os.path.join(project_root,\n                                   model_description[\"data-source\"],\n                                   \"testdata.hdf5\")\n    data['validating'] = os.path.join(project_root,\n                                      model_description[\"data-source\"],\n                                      \"validdata.hdf5\")\n\n    # Get latest model file\n    basename = \"model\"\n    latest_model = utils.get_latest_working_model(model_folder)\n\n    if latest_model == \"\":\n        logging.error(\"There is no model with basename '%s'.\", basename)\n        return None\n    else:\n        logging.info(\"Model '%s' found.\", latest_model)\n        i = int(latest_model.split(\"-\")[-1].split(\".\")[0])\n        model_src = os.path.join(model_folder, \"%s-%i.json\" % (basename, i))\n        model_target = os.path.join(model_folder,\n                                    \"%s-%i.json\" % (basename, i+1))\n\n    # generate the training command\n    training = model_description['training']\n    training = training.replace(\"{{testing}}\", data['testing'])\n    training = training.replace(\"{{training}}\", data['training'])\n    training = training.replace(\"{{validation}}\", data['validating'])\n    training = training.replace(\"{{src_model}}\", model_src)\n    training = training.replace(\"{{target_model}}\", model_target)\n    training = training.replace(\"{{nntoolkit}}\", utils.get_nntoolkit())\n    return training"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef train_model(model_folder):\n    os.chdir(model_folder)\n    training = generate_training_command(model_folder)\n    if training is None:\n        return -1\n    logging.info(training)\n    os.chdir(model_folder)\n    os.system(training)", "response": "Train the model in model_folder."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(model_folder):\n    model_description_file = os.path.join(model_folder, \"info.yml\")\n\n    # Read the model description file\n    with open(model_description_file, 'r') as ymlfile:\n        model_description = yaml.load(ymlfile)\n\n    # Analyze model\n    logging.info(model_description['model'])\n    data = {}\n    data['training'] = os.path.join(model_folder, \"traindata.hdf5\")\n    data['testing'] = os.path.join(model_folder, \"testdata.hdf5\")\n    data['validating'] = os.path.join(model_folder, \"validdata.hdf5\")\n    train_model(model_folder)", "response": "Main part of the training script."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_parser():\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-m\", \"--model\",\n                        dest=\"model\",\n                        help=\"where is the model folder (with a info.yml)?\",\n                        metavar=\"FOLDER\",\n                        type=lambda x: utils.is_valid_folder(parser, x),\n                        default=utils.default_model())\n    return parser", "response": "Return the parser object for this script."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the bounding box of a list of points.", "response": "def get_bounding_box(points):\n    \"\"\"Get the bounding box of a list of points.\n\n    Parameters\n    ----------\n    points : list of points\n\n    Returns\n    -------\n    BoundingBox\n    \"\"\"\n    assert len(points) > 0, \"At least one point has to be given.\"\n    min_x, max_x = points[0]['x'], points[0]['x']\n    min_y, max_y = points[0]['y'], points[0]['y']\n    for point in points:\n        min_x, max_x = min(min_x, point['x']), max(max_x, point['x'])\n        min_y, max_y = min(min_y, point['y']), max(max_y, point['y'])\n    p1 = Point(min_x, min_y)\n    p2 = Point(max_x, max_y)\n    return BoundingBox(p1, p2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if BoundingBox a intersects with BoundingBox b.", "response": "def do_bb_intersect(a, b):\n    \"\"\"Check if BoundingBox a intersects with BoundingBox b.\"\"\"\n    return a.p1.x <= b.p2.x \\\n        and a.p2.x >= b.p1.x \\\n        and a.p1.y <= b.p2.y \\\n        and a.p2.y >= b.p1.y"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the distance between two line segments in the plane.", "response": "def segments_distance(segment1, segment2):\n    \"\"\"Calculate the distance between two line segments in the plane.\n\n    >>> a = LineSegment(Point(1,0), Point(2,0))\n    >>> b = LineSegment(Point(0,1), Point(0,2))\n    >>> \"%0.2f\" % segments_distance(a, b)\n    '1.41'\n    >>> c = LineSegment(Point(0,0), Point(5,5))\n    >>> d = LineSegment(Point(2,2), Point(4,4))\n    >>> e = LineSegment(Point(2,2), Point(7,7))\n    >>> \"%0.2f\" % segments_distance(c, d)\n    '0.00'\n    >>> \"%0.2f\" % segments_distance(c, e)\n    '0.00'\n    \"\"\"\n    assert isinstance(segment1, LineSegment), \\\n        \"segment1 is not a LineSegment, but a %s\" % type(segment1)\n    assert isinstance(segment2, LineSegment), \\\n        \"segment2 is not a LineSegment, but a %s\" % type(segment2)\n    if len(get_segments_intersections(segment1, segment2)) >= 1:\n        return 0\n    # try each of the 4 vertices w/the other segment\n    distances = []\n    distances.append(point_segment_distance(segment1.p1, segment2))\n    distances.append(point_segment_distance(segment1.p2, segment2))\n    distances.append(point_segment_distance(segment2.p1, segment1))\n    distances.append(point_segment_distance(segment2.p2, segment1))\n    return min(distances)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_segments_intersections(segment1, segment2):\n    dx1 = segment1.p2.x - segment1.p1.x\n    dy1 = segment1.p2.y - segment1.p1.y\n    dx2 = segment2.p2.x - segment2.p1.x\n    dy2 = segment2.p2.y - segment2.p1.y\n    delta = dx2 * dy1 - dy2 * dx1\n    if delta == 0:  # parallel segments\n        # Line segments could be (partially) identical.\n        # In that case this functin should return True.\n        if dx1 == 0 and dy1 == 0:  # segment1 is a point\n            point = segment1.p1\n            if segment2.p1.x == point.x and segment2.p1.y == point.y:\n                return [Point(point.x, point.y)]\n            elif segment2.p2.x == point.x and segment2.p2.y == point.y:\n                return [Point(point.x, point.y)]\n            else:\n                return []\n        elif dx2 == 0 and dy2 == 0:  # segment2 is a point\n            point = segment2.p1\n            if segment1.p1.x == point.x and segment1.p1.y == point.y:\n                return [Point(point.x, point.y)]\n            elif segment1.p2.x == point.x and segment1.p2.y == point.y:\n                return [Point(point.x, point.y)]\n            else:\n                return []\n        elif dx1 == 0:\n            # Lines segments are vertical\n            if segment1.p1.x == segment2.p1.x:\n                if segment1.p1.y > segment1.p2.y:\n                    segment1.p1, segment1.p2 = segment1.p2, segment1.p1\n                if segment2.p1.y > segment2.p2.y:\n                    segment2.p1, segment2.p2 = segment2.p2, segment2.p1\n                # Lines segments are on the same line\n                if segment1.p1.y <= segment2.p1.y <= segment1.p2.y:\n                    return [Point(segment1.p1.x, segment2.p1.y)]\n                if segment2.p1.y <= segment1.p1.y <= segment2.p2.y:\n                    return [Point(segment1.p1.x, segment1.p1.y)]\n        else:\n            # The equation f(x) = m*x + t defines any non-vertical line\n            t1 = segment1.get_offset()\n            t2 = segment2.get_offset()\n            if t1 == t2:  # line segments are on the same line\n                if segment1.p1.x <= segment2.p1.x <= segment1.p2.x:\n                    return [Point(segment2.p1.x,\n                                  segment2.get_slope()*segment2.p1.x+t2)]\n                if segment2.p1.x <= segment1.p1.x <= segment2.p2.x:\n                    return [Point(segment1.p1.x,\n                                  segment1.get_slope()*segment1.p1.x+t1)]\n        return []\n    if dx2 == 0:  # Line 2 is a vertical line, but line 1 isn't\n        segment1, segment2 = segment2, segment1\n        dx1, dx2 = dx2, dx1\n    if dx1 == 0:  # Line 1 is a vertical line, but line 2 isn't\n        if segment2.p1.x > segment2.p2.x:\n            segment2.p1, segment2.p2 = segment2.p2, segment2.p1\n        if segment2.p1.x <= segment1.p1.x <= segment2.p2.x:\n            # The x-values overlap\n            m2 = segment2.get_slope()\n            t2 = segment2.get_offset()\n            y = m2*segment1.p1.x + t2\n            if segment1.p1.y > segment1.p2.y:\n                segment1.p1, segment1.p2 = segment1.p2, segment1.p1\n            if segment1.p1.y <= y <= segment1.p2.y:\n                return [Point(segment1.p1.x, y)]\n            else:\n                return []\n        else:\n            return []\n\n    m1, t1 = segment1.get_slope(), segment1.get_offset()\n    m2, t2 = segment2.get_slope(), segment2.get_offset()\n    try:\n        x = (t2-t1)/(m1-m2)\n    except Exception as inst:\n        logging.debug(inst)\n        logging.debug(\"m1=%s\", repr(m1))\n        logging.debug(\"m2=%s\", repr(m2))\n        return []\n    if segment1.p1.x > segment1.p2.x:\n        segment1.p1, segment1.p2 = segment1.p2, segment1.p1\n    if segment2.p1.x > segment2.p2.x:\n        segment2.p1, segment2.p2 = segment2.p2, segment2.p1\n    if (segment1.p1.x <= x <= segment1.p2.x) and \\\n       (segment2.p1.x <= x <= segment2.p2.x):\n        # The intersection is on both line segments - not only on the lines\n        return [Point(x, m1*x+t1)]\n    else:\n        return []", "response": "Return a list of all segments intersect if an anonymization of two lines segments intersect."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef point_segment_distance(point, segment):\n    assert isinstance(point, Point), \\\n        \"point is not of type Point, but of %r\" % type(point)\n    dx = segment.p2.x - segment.p1.x\n    dy = segment.p2.y - segment.p1.y\n    if dx == dy == 0:  # the segment's just a point\n        return point.dist_to(segment.p1)\n\n    if dx == 0:  # It's a straight vertical line\n        p_below_p1 = point.y <= segment.p1.y and segment.p1.y <= segment.p2.y\n        p_below_p2 = point.y <= segment.p2.y and segment.p2.y <= segment.p1.y\n        p_above_p2 = segment.p1.y <= segment.p2.y and segment.p2.y <= point.y\n        p_above_p1 = segment.p2.y <= segment.p1.y and segment.p1.y <= point.y\n        if p_below_p1 or p_above_p1:\n            return point.dist_to(segment.p1)\n        elif p_below_p2 or p_above_p2:\n            return point.dist_to(segment.p2)\n\n    if dy == 0:  # It's a straight horizontal line\n        p_left_p1 = point.x <= segment.p1.x and segment.p1.x <= segment.p2.x\n        p_left_p2 = point.x <= segment.p2.x and segment.p2.x <= segment.p1.x\n        p_right_p2 = segment.p1.x <= segment.p2.x and segment.p2.x <= point.x\n        p_right_p1 = segment.p2.x <= segment.p1.x and segment.p1.x <= point.x\n        if p_left_p1 or p_right_p1:\n            return point.dist_to(segment.p1)\n        elif p_left_p2 or p_right_p2:\n            return point.dist_to(segment.p2)\n\n    # Calculate the t that minimizes the distance.\n    t = ((point.x - segment.p1.x) * dx + (point.y - segment.p1.y) * dy) / \\\n        (dx * dx + dy * dy)\n\n    # See if this represents one of the segment's\n    # end points or a point in the middle.\n    if t < 0:\n        dx = point.x - segment.p1.x\n        dy = point.y - segment.p1.y\n    elif t > 1:\n        dx = point.x - segment.p2.x\n        dy = point.y - segment.p2.y\n    else:\n        near_x = segment.p1.x + t * dx\n        near_y = segment.p1.y + t * dy\n        dx = point.x - near_x\n        dy = point.y - near_y\n    return math.hypot(dx, dy)", "response": "Return the distance between a point and a segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef perpendicular_distance(p3, p1, p2):\n    px = p2['x']-p1['x']\n    py = p2['y']-p1['y']\n\n    squared_distance = px*px + py*py\n    if squared_distance == 0:\n        # The line is in fact only a single dot.\n        # In this case the distance of two points has to be\n        # calculated\n        line_point = Point(p1['x'], p1['y'])\n        point = Point(p3['x'], p3['y'])\n        return line_point.dist_to(point)\n\n    u = ((p3['x'] - p1['x'])*px + (p3['y'] - p1['y'])*py) / squared_distance\n\n    if u > 1:\n        u = 1\n    elif u < 0:\n        u = 0\n\n    x = p1['x'] + u * px\n    y = p1['y'] + u * py\n\n    dx = x - p3['x']\n    dy = y - p3['y']\n\n    # Note: If the actual distance does not matter,\n    # if you only want to compare what this function\n    # returns to other results of this function, you\n    # can just return the squared distance instead\n    # (i.e. remove the sqrt) to gain a little performance\n\n    dist = math.sqrt(dx*dx + dy*dy)\n    return dist", "response": "Calculate the perpendicular distance between two points p1 and p2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dist_to(self, p2):\n        return math.hypot(self.x - p2.x, self.y - p2.y)", "response": "Measure the distance to another point."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the slope m of this line segment.", "response": "def get_slope(self):\n        \"\"\"Return the slope m of this line segment.\"\"\"\n        # y1 = m*x1 + t\n        # y2 = m*x2 + t => y1-y2 = m*(x1-x2) <=> m = (y1-y2)/(x1-x2)\n        return ((self.p1.y-self.p2.y) / (self.p1.x-self.p2.x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_offset(self):\n        return self.p1.y-self.get_slope()*self.p1.x", "response": "Get the offset t of this line segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_selfintersections(self):\n        # This can be solved more efficiently with sweep line\n        counter = 0\n        for i, j in itertools.combinations(range(len(self.lineSegments)), 2):\n            inters = get_segments_intersections(self.lineSegments[i],\n                                                self.lineSegments[j])\n            if abs(i-j) > 1 and len(inters) > 0:\n                counter += 1\n        return counter", "response": "Get the number of self - intersections of this polygonal chain."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_intersections(self, line_segments_b):\n        line_segments_a = self.lineSegments\n\n        # Calculate intersections\n        intersection_points = []\n        for line1, line2 in itertools.product(line_segments_a,\n                                              line_segments_b):\n            intersection_points += get_segments_intersections(line1, line2)\n        return len(set(intersection_points))", "response": "Count the number of intersections between two strokes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_area(self):\n        return (self.p2.x-self.p1.x)*(self.p2.y-self.p1.y)", "response": "Calculate area of bounding box."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the center point of this bounding box.", "response": "def get_center(self):\n        \"\"\"\n        Get the center point of this bounding box.\n        \"\"\"\n        return Point((self.p1.x+self.p2.x)/2.0, (self.p1.y+self.p2.y)/2.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the data from the server.", "response": "def _fetch_data_from_server(raw_data_id, mysql_cfg):\n    \"\"\"Get the data from raw_data_id from the server.\n    :returns: The ``data`` if fetching worked, ``None`` if it failed.\"\"\"\n    import pymysql\n    import pymysql.cursors\n\n    # Import configuration file\n    cfg = utils.get_database_configuration()\n    if cfg is None:\n        return None\n\n    # Establish database connection\n    connection = pymysql.connect(host=cfg[mysql_cfg]['host'],\n                                 user=cfg[mysql_cfg]['user'],\n                                 passwd=cfg[mysql_cfg]['passwd'],\n                                 db=cfg[mysql_cfg]['db'],\n                                 cursorclass=pymysql.cursors.DictCursor)\n    logging.info(\"Connection: %s\", str(connection))\n    cursor = connection.cursor()\n\n    # Download dataset\n    sql = (\"SELECT `id`, `data` \"\n           \"FROM `wm_raw_draw_data` WHERE `id`=%i\") % raw_data_id\n    cursor.execute(sql)\n    return cursor.fetchone()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a HandwrittenData object that has raw_data_id from a pickle file containing a raw_data_id.", "response": "def _get_data_from_rawfile(path_to_data, raw_data_id):\n    \"\"\"Get a HandwrittenData object that has ``raw_data_id`` from a pickle file\n       ``path_to_data``.\n       :returns: The HandwrittenData object if ``raw_data_id`` is in\n                 path_to_data, otherwise ``None``.\"\"\"\n    loaded = pickle.load(open(path_to_data, \"rb\"))\n    raw_datasets = loaded['handwriting_datasets']\n    for raw_dataset in raw_datasets:\n        if raw_dataset['handwriting'].raw_data_id == raw_data_id:\n            return raw_dataset['handwriting']\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _list_ids(path_to_data):\n    loaded = pickle.load(open(path_to_data, \"rb\"))\n    raw_datasets = loaded['handwriting_datasets']\n    raw_ids = {}\n    for raw_dataset in raw_datasets:\n        raw_data_id = raw_dataset['handwriting'].raw_data_id\n        if raw_dataset['formula_id'] not in raw_ids:\n            raw_ids[raw_dataset['formula_id']] = [raw_data_id]\n        else:\n            raw_ids[raw_dataset['formula_id']].append(raw_data_id)\n    for symbol_id in sorted(raw_ids):\n        print(\"%i: %s\" % (symbol_id, sorted(raw_ids[symbol_id])))", "response": "List raw data IDs grouped by symbol ID from a pickle file\n       path_to_data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the parsed description file from another uggler parsed description file.", "response": "def _get_description(prev_description):\n    \"\"\"Get the parsed description file (a dictionary) from another\n       parsed description file.\"\"\"\n    current_desc_file = os.path.join(utils.get_project_root(),\n                                     prev_description['data-source'],\n                                     \"info.yml\")\n    if not os.path.isfile(current_desc_file):\n        logging.error(\"You are probably not in the folder of a model, because \"\n                      \"%s is not a file.\", current_desc_file)\n        sys.exit(-1)\n    with open(current_desc_file, 'r') as ymlfile:\n        current_description = yaml.load(ymlfile)\n    return current_description"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the preprocessing description the feature description and the the model description.", "response": "def _get_system(model_folder):\n    \"\"\"Return the preprocessing description, the feature description and the\n       model description.\"\"\"\n\n    # Get model description\n    model_description_file = os.path.join(model_folder, \"info.yml\")\n    if not os.path.isfile(model_description_file):\n        logging.error(\"You are probably not in the folder of a model, because \"\n                      \"%s is not a file. (-m argument)\",\n                      model_description_file)\n        sys.exit(-1)\n    with open(model_description_file, 'r') as ymlfile:\n        model_desc = yaml.load(ymlfile)\n\n    # Get the feature and the preprocessing description\n    feature_desc = _get_description(model_desc)\n    preprocessing_desc = _get_description(feature_desc)\n\n    return (preprocessing_desc, feature_desc, model_desc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef display_data(raw_data_string, raw_data_id, model_folder, show_raw):\n    print(\"## Raw Data (ID: %i)\" % raw_data_id)\n    print(\"```\")\n    print(raw_data_string)\n    print(\"```\")\n\n    preprocessing_desc, feature_desc, _ = _get_system(model_folder)\n\n    # Print model\n    print(\"## Model\")\n    print(\"%s\\n\" % model_folder)\n\n    # Get the preprocessing queue\n    tmp = preprocessing_desc['queue']\n    preprocessing_queue = preprocessing.get_preprocessing_queue(tmp)\n\n    # Get feature values as list of floats, rounded to 3 decimal places\n    tmp = feature_desc['features']\n    feature_list = features.get_features(tmp)\n\n    # Print preprocessing queue\n    preprocessing.print_preprocessing_list(preprocessing_queue)\n    features.print_featurelist(feature_list)\n\n    # Get Handwriting\n    recording = handwritten_data.HandwrittenData(raw_data_string,\n                                                 raw_data_id=raw_data_id)\n    if show_raw:\n        recording.show()\n\n    recording.preprocessing(preprocessing_queue)\n\n    feature_values = recording.feature_extraction(feature_list)\n    feature_values = [round(el, 3) for el in feature_values]\n    print(\"Features:\")\n    print(feature_values)\n\n    # Get the list of data multiplication algorithms\n    mult_queue = data_multiplication.get_data_multiplication_queue(\n        feature_desc['data-multiplication'])\n\n    # Multiply traing_set\n    training_set = [{'id': 42,\n                     'formula_id': 42,\n                     'formula_in_latex': 'None',\n                     'handwriting': recording}]\n    training_set = create_ffiles.training_set_multiplication(training_set,\n                                                             mult_queue)\n\n    # Display it\n    logging.info(\"Show %i recordings...\", len(training_set))\n    for recording in training_set:\n        recording['handwriting'].show()", "response": "Display the raw data in a single page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_parser():\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-i\", \"--id\", dest=\"id\", default=292293,\n                        type=int,\n                        help=\"which RAW_DATA_ID do you want?\")\n    parser.add_argument(\"--mysql\", dest=\"mysql\", default='mysql_online',\n                        help=\"which mysql configuration should be used?\")\n    parser.add_argument(\"-m\", \"--model\",\n                        dest=\"model\",\n                        help=\"where is the model folder (with a info.yml)?\",\n                        metavar=\"FOLDER\",\n                        type=lambda x: utils.is_valid_folder(parser, x),\n                        default=utils.default_model())\n    parser.add_argument(\"-l\", \"--list\",\n                        dest=\"list\",\n                        help=\"list all raw data IDs / symbol IDs\",\n                        action='store_true',\n                        default=False)\n    parser.add_argument(\"-s\", \"--server\",\n                        dest=\"server\",\n                        help=\"contact the MySQL server\",\n                        action='store_true',\n                        default=False)\n    parser.add_argument(\"-r\", \"--raw\",\n                        dest=\"show_raw\",\n                        help=\"show the raw recording (without preprocessing)\",\n                        action='store_true',\n                        default=False)\n    return parser", "response": "Return the parser object for this script."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(list_ids, model, contact_server, raw_data_id, show_raw,\n         mysql_cfg='mysql_online'):\n    \"\"\"Main function of view.py.\"\"\"\n    if list_ids:\n        preprocessing_desc, _, _ = _get_system(model)\n        raw_datapath = os.path.join(utils.get_project_root(),\n                                    preprocessing_desc['data-source'])\n        _list_ids(raw_datapath)\n    else:\n        if contact_server:\n            data = _fetch_data_from_server(raw_data_id, mysql_cfg)\n            print(\"hwrt version: %s\" % hwrt.__version__)\n            if data is not None:\n                display_data(data['data'], data['id'], model, show_raw)\n        else:\n            logging.info(\"RAW_DATA_ID %i does not exist or \"\n                         \"database connection did not work.\", raw_data_id)\n            # The data was not on the server / the connection to the server did\n            # not work. So try it again with the model data\n            preprocessing_desc, _, _ = _get_system(model)\n            raw_datapath = os.path.join(utils.get_project_root(),\n                                        preprocessing_desc['data-source'])\n            handwriting = _get_data_from_rawfile(raw_datapath, raw_data_id)\n            if handwriting is None:\n                logging.info(\"Recording with ID %i was not found in %s\",\n                             raw_data_id,\n                             raw_datapath)\n            else:\n                print(\"hwrt version: %s\" % hwrt.__version__)\n                display_data(handwriting.raw_data_json,\n                             handwriting.formula_id,\n                             model,\n                             show_raw)", "response": "Main function of view. py."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the object holding the HandwrittenData object hw to a SCG INK file.", "response": "def write_hw_scgink(hw, filename='mathbrush-test.txt'):\n    \"\"\"\n    Parameters\n    ----------\n    hw : HandwrittenData object\n    filename : string\n        Path, where the SCG INK file gets written\n    \"\"\"\n    with open(filename, 'w') as f:\n        f.write('SCG_INK\\n')\n        f.write('%i\\n' % len(hw.get_pointlist()))\n        for stroke in hw.get_pointlist():\n            f.write('%i\\n' % len(stroke))\n            for point in stroke:\n                f.write('%i %i\\n' % (point['x'], point['y']))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the parameters of the preprocessing done within folder.", "response": "def get_parameters(folder):\n    \"\"\"Get the parameters of the preprocessing done within `folder`.\n\n    Parameters\n    ----------\n    folder : string\n\n    Returns\n    -------\n    tuple : (path of raw data,\n             path where preprocessed data gets stored,\n             list of preprocessing algorithms)\n    \"\"\"\n\n    # Read the model description file\n    with open(os.path.join(folder, \"info.yml\"), 'r') as ymlfile:\n        preprocessing_description = yaml.load(ymlfile)\n\n    # Get the path of the raw data\n    raw_datapath = os.path.join(utils.get_project_root(),\n                                preprocessing_description['data-source'])\n    # Get the path were the preprocessed file should be put\n    outputpath = os.path.join(folder, \"data.pickle\")\n\n    # Get the preprocessing queue\n    tmp = preprocessing_description['queue']\n    preprocessing_queue = preprocessing.get_preprocessing_queue(tmp)\n    return (raw_datapath, outputpath, preprocessing_queue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a preprocessed dataset file by applying preprocessing_queue to path_to_data. The result will be stored in outputpath.", "response": "def create_preprocessed_dataset(path_to_data, outputpath, preprocessing_queue):\n    \"\"\"Create a preprocessed dataset file by applying `preprocessing_queue`\n       to `path_to_data`. The result will be stored in `outputpath`.\"\"\"\n    # Log everything\n    logging.info(\"Data soure %s\", path_to_data)\n    logging.info(\"Output will be stored in %s\", outputpath)\n    tmp = \"Preprocessing Queue:\\n\"\n    for preprocessing_class in preprocessing_queue:\n        tmp += str(preprocessing_class) + \"\\n\"\n    logging.info(tmp)\n    # Load from pickled file\n    if not os.path.isfile(path_to_data):\n        logging.info((\"'%s' does not exist. Please either abort this script \"\n                      \"or update the data location.\"), path_to_data)\n        raw_dataset_path = utils.choose_raw_dataset()\n        # Get project-relative path\n        raw_dataset_path = \"raw-datasets\" + \\\n                           raw_dataset_path.split(\"raw-datasets\")[1]\n        print(raw_dataset_path)\n        sys.exit()  # TODO: Update model!\n    logging.info(\"Start loading data...\")\n    loaded = pickle.load(open(path_to_data, \"rb\"))\n    raw_datasets = loaded['handwriting_datasets']\n    logging.info(\"Start applying preprocessing methods\")\n    start_time = time.time()\n    for i, raw_dataset in enumerate(raw_datasets):\n        if i % 10 == 0 and i > 0:\n            utils.print_status(len(raw_datasets), i, start_time)\n        # Do the work\n        raw_dataset['handwriting'].preprocessing(preprocessing_queue)\n    sys.stdout.write(\"\\r%0.2f%% (done)\\033[K\\n\" % (100))\n    print(\"\")\n    pickle.dump({'handwriting_datasets': raw_datasets,\n                 'formula_id2latex': loaded['formula_id2latex'],\n                 'preprocessing_queue': preprocessing_queue},\n                open(outputpath, \"wb\"),\n                2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(folder):\n    raw_datapath, outputpath, p_queue = get_parameters(folder)\n    create_preprocessed_dataset(raw_datapath, outputpath, p_queue)\n    utils.create_run_logfile(folder)", "response": "Main part of preprocess_dataset that glues things togeter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a lookup file where the index is mapped to the formula id and LaTeX command.", "response": "def _create_index_formula_lookup(formula_id2index,\n                                 feature_folder,\n                                 index2latex):\n    \"\"\"\n    Create a lookup file where the index is mapped to the formula id and the\n    LaTeX command.\n\n    Parameters\n    ----------\n    formula_id2index : dict\n    feature_folder : str\n        Path to a folder in which a feature file as well as an\n        index2formula_id.csv is.\n    index2latex : dict\n        Maps an integer index to a LaTeX command\n    \"\"\"\n    index2formula_id = sorted(formula_id2index.items(), key=lambda n: n[1])\n    index2formula_file = os.path.join(feature_folder, \"index2formula_id.csv\")\n    with open(index2formula_file, \"w\") as f:\n        f.write(\"index,formula_id,latex\\n\")\n        for formula_id, index in index2formula_id:\n            f.write(\"%i,%i,%s\\n\" % (index, formula_id, index2latex[index]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a file that contains the direct lookup information.", "response": "def _create_translation_file(feature_folder,\n                             dataset_name,\n                             translation,\n                             formula_id2index):\n    \"\"\"\n    Write a loop-up file that contains the direct (record-wise) lookup\n    information.\n\n    Parameters\n    ----------\n    feature_folder :\n        Path to the feature files.\n    dataset_name :\n        'traindata', 'validdata' or 'testdata'.\n    translation : list of triples\n        (raw data id, formula in latex, formula id)\n    \"\"\"\n    translationfilename = \"%s/translation-%s.csv\" % (feature_folder,\n                                                     dataset_name)\n    with open(translationfilename, \"w\") as f:\n        f.write(\"index,raw_data_id,latex,formula_id\\n\")\n        for el in translation:\n            f.write(\"%i,%i,%s,%i\\n\" % (formula_id2index[el[2]],\n                                       el[0], el[1], el[2]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(feature_folder, create_learning_curve=False):\n\n    # Read the feature description file\n    with open(os.path.join(feature_folder, \"info.yml\"), 'r') as ymlfile:\n        feature_description = yaml.load(ymlfile)\n\n    # Get preprocessed .pickle file from model description file\n    path_to_data = os.path.join(utils.get_project_root(),\n                                feature_description['data-source'])\n    if os.path.isdir(path_to_data):\n        path_to_data = os.path.join(path_to_data, \"data.pickle\")\n    target_paths = {'traindata': os.path.join(feature_folder,\n                                              \"traindata.hdf5\"),\n                    'validdata': os.path.join(feature_folder,\n                                              \"validdata.hdf5\"),\n                    'testdata': os.path.join(feature_folder,\n                                             \"testdata.hdf5\")}\n\n    feature_list = features.get_features(feature_description['features'])\n    mult_queue = data_multiplication.get_data_multiplication_queue(\n        feature_description['data-multiplication'])\n\n    # Set everything up for the creation of the 3 hdf5 (test, validation,\n    # training).\n\n    os.chdir(feature_folder)\n    logging.info(\"Start creation of hdf5-files...\")\n    logging.info(\"Get sets from '%s' ...\", path_to_data)\n    (training_set, validation_set, test_set, formula_id2index,\n     preprocessing_queue, index2latex) = get_sets(path_to_data)\n\n    training_set = training_set_multiplication(training_set, mult_queue)\n    _create_index_formula_lookup(formula_id2index, feature_folder, index2latex)\n\n    # Output data for documentation\n    print(\"Classes (nr of symbols): %i\" % len(formula_id2index))\n    preprocessing.print_preprocessing_list(preprocessing_queue)\n    features.print_featurelist(feature_list)\n\n    logging.info(\"Start creating hdf5 files\")\n\n    # Get the dimension of the feature vector\n    input_features = sum(map(lambda n: n.get_dimension(), feature_list))\n\n    # Traindata has to come first because of feature normalization\n    for dataset_name, dataset, is_traindata in \\\n        [(\"traindata\", training_set, True),\n         (\"testdata\", test_set, False),\n         (\"validdata\", validation_set, False)]:\n        t0 = time.time()\n        logging.info(\"Start preparing '%s' ...\", dataset_name)\n        prepared, translation = prepare_dataset(dataset,\n                                                formula_id2index,\n                                                feature_list,\n                                                is_traindata)\n        logging.info(\"%s length: %i\", dataset_name, len(prepared))\n        logging.info(\"start 'make_hdf5'x ...\")\n        make_hdf5(dataset_name,\n                  input_features,\n                  prepared,\n                  os.path.join(feature_folder, target_paths[dataset_name]),\n                  create_learning_curve)\n\n        _create_translation_file(feature_folder,\n                                 dataset_name,\n                                 translation,\n                                 formula_id2index)\n\n        t1 = time.time() - t0\n        logging.info(\"%s was written. Needed %0.2f seconds\", dataset_name, t1)\n        gc.collect()\n    utils.create_run_logfile(feature_folder)", "response": "main function of create_ffiles. py"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmultiplying the training set by all methods listed in mult_queue and return the new set.", "response": "def training_set_multiplication(training_set, mult_queue):\n    \"\"\"\n    Multiply the training set by all methods listed in mult_queue.\n\n    Parameters\n    ----------\n    training_set :\n        set of all recordings that will be used for training\n    mult_queue :\n        list of all algorithms that will take one recording and generate more\n        than one.\n\n    Returns\n    -------\n    mutliple recordings\n    \"\"\"\n    logging.info(\"Multiply data...\")\n    for algorithm in mult_queue:\n        new_trning_set = []\n        for recording in training_set:\n            samples = algorithm(recording['handwriting'])\n            for sample in samples:\n                new_trning_set.append({'id': recording['id'],\n                                       'is_in_testset': 0,\n                                       'formula_id': recording['formula_id'],\n                                       'handwriting': sample,\n                                       'formula_in_latex':\n                                       recording['formula_in_latex']})\n        training_set = new_trning_set\n    return new_trning_set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a training validation and test set from a pickle file.", "response": "def get_sets(path_to_data):\n    \"\"\"\n    Get a training, validation and a testset as well as a dictionary that maps\n    each formula_id to an index (0...nr_of_formulas - 1).\n\n    Parameters\n    ----------\n    path_to_data :\n        A pickle file that contains a list of datasets.\n\n    Returns\n    -------\n    tuple\n        0: list\n            The training_set contains recordings.\n        1: list\n            The validation_set contains recordings.\n        2: list\n            The test_set contains recordings.\n        3: dict\n            The formula_id2index maps write-math.com formula ids to\n            an index which begins at 0.\n        4: list\n            The preprocessing_queue contains objects which encapsulate\n            algorithms for preprocessing.\n        5: dict\n            The index2latex maps the index of the neural network to the latex\n            command.\n    \"\"\"\n    loaded = pickle.load(open(path_to_data, 'rb'))\n    datasets = loaded['handwriting_datasets']\n\n    training_set, validation_set, test_set = [], [], []\n\n    dataset_by_formula_id = {}\n    formula_id2index = {}\n    index2latex = {}\n\n    # Group data in dataset_by_formula_id so that 10% can be used for the\n    # validation set\n    for i, dataset in enumerate(datasets):\n        if dataset['formula_id'] in dataset_by_formula_id:\n            dataset_by_formula_id[dataset['formula_id']].append(dataset)\n        else:\n            dataset_by_formula_id[dataset['formula_id']] = [dataset]\n        utils.print_status(len(datasets), i)\n    print(\"\")\n\n    # Create the test-, validation- and training set\n    print(\"Create the test-, validation- and training set\")\n    for formula_id, dataset in dataset_by_formula_id.items():\n        tmp = dataset[0]['handwriting'].formula_in_latex\n        index2latex[len(formula_id2index)] = tmp\n        formula_id2index[formula_id] = len(formula_id2index)\n        i = 0\n        for raw_data in dataset:\n            if raw_data['is_in_testset']:\n                test_set.append(raw_data)\n            else:\n                if i % 10 == 0:\n                    validation_set.append(raw_data)\n                else:\n                    training_set.append(raw_data)\n                i = (i + 1) % 10\n    if 'preprocessing_queue' in loaded:\n        preprocessing_queue = loaded['preprocessing_queue']\n    else:\n        preprocessing_queue = []\n    return (training_set, validation_set, test_set, formula_id2index,\n            preprocessing_queue, index2latex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calculate_feature_stats(feature_list, prepared, serialization_file):  # pylint: disable=R0914\n    # Create feature only list\n    feats = [x for x, _ in prepared]  # Label is not necessary\n\n    # Calculate all means / mins / maxs\n    means = numpy.mean(feats, 0)\n    mins = numpy.min(feats, 0)\n    maxs = numpy.max(feats, 0)\n\n    # Calculate, min, max and mean vector for each feature with\n    # normalization\n    start = 0\n    mode = 'w'\n    arguments = {'newline': ''}\n    if sys.version_info.major < 3:\n        mode += 'b'\n        arguments = {}\n    with open(serialization_file, mode, **arguments) as csvfile:\n        spamwriter = csv.writer(csvfile,\n                                delimiter=str(';'),\n                                quotechar=str('\"'),\n                                quoting=csv.QUOTE_MINIMAL)\n        for feature in feature_list:\n            end = start + feature.get_dimension()\n            # append the data to the feature class\n            feature.mean = numpy.array(means[start:end])\n            feature.min = numpy.array(mins[start:end])\n            feature.max = numpy.array(maxs[start:end])\n            start = end\n            for mean, fmax, fmin in zip(feature.mean, feature.max,\n                                        feature.min):\n                spamwriter.writerow([mean, fmax - fmin])", "response": "Calculate min max and mean for each feature. Store it in object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _normalize_features(feature_list, prepared, is_traindata):\n    if is_traindata:\n        _calculate_feature_stats(feature_list,\n                                 prepared,\n                                 \"featurenormalization.csv\")\n\n    start = 0\n    for feature in feature_list:\n        end = start + feature.get_dimension()\n        # For every instance in the dataset: Normalize!\n        for i in range(len(prepared)):\n            # The 0 is necessary as every element is (x, y)\n            feature_range = (feature.max - feature.min)\n            if feature_range == 0:\n                feature_range = 1\n            prepared[i][0][start:end] = (prepared[i][0][start:end] -\n                                         feature.mean) / feature_range\n        start = end\n    return prepared", "response": "Normalize features (mean subtraction, division by variance or range)."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_dataset(dataset,\n                    formula_id2index,\n                    feature_list,\n                    is_traindata,\n                    do_normalization=False):\n    \"\"\"Transform each instance of dataset to a (Features, Label) tuple.\"\"\"\n    prepared = []\n    start_time = time.time()\n    translation = []\n    for i, data in enumerate(dataset):\n        x = []\n        handwriting = data['handwriting']\n        x = handwriting.feature_extraction(feature_list)  # Feature selection\n        y = formula_id2index[data['formula_id']]  # Get label\n        translation.append((handwriting.raw_data_id,\n                            handwriting.formula_in_latex,\n                            handwriting.formula_id))\n        prepared.append((numpy.array(x), y))\n        if i % 100 == 0 and i > 0:\n            utils.print_status(len(dataset), i, start_time)\n    sys.stdout.write(\"\\r100%\" + \" \"*80 + \"\\n\")\n    sys.stdout.flush()\n\n    # Feature normalization\n    if do_normalization:\n        _normalize_features(feature_list, prepared, is_traindata)\n    return (prepared, translation)", "response": "Transform each instance of dataset to a ( Features Label ) tuple."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_hdf5(dataset_name, feature_count, data,\n              output_filename, create_learning_curve):\n    \"\"\"\n    Create the hdf5 file.\n\n    Parameters\n    ----------\n    filename :\n        name of the file that hdf5_create will use to create the hdf5 file.\n    feature_count : integer\n        number of features\n    data : list of tuples\n         data format ('feature_string', 'label')\n    \"\"\"\n    # create raw data file for hdf5_create\n    if dataset_name == \"traindata\" and create_learning_curve:\n        max_trainingexamples = 501\n        output_filename_save = output_filename\n        steps = 10\n        for trainingexamples in range(100, max_trainingexamples, steps):\n            # adjust output_filename\n            tmp = output_filename_save.split(\".\")\n            tmp[-2] += \"-%i-examples\" % trainingexamples\n            output_filename = \".\".join(map(str, tmp))\n\n            # Make sure the data has not more than ``trainingexamples``\n            seen_symbols = defaultdict(int)\n            new_data = {}\n            for feature_string, label in data:\n                if seen_symbols[label] < trainingexamples:\n                    seen_symbols[label] += 1\n                    new_data = (feature_string, label)\n\n            # Create the hdf5 file\n            utils.create_hdf5(output_filename, feature_count, new_data)\n    else:\n        utils.create_hdf5(output_filename, feature_count, data)", "response": "Create the hdf5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dataset():\n    seg_data = \"segmentation-X.npy\"\n    seg_labels = \"segmentation-y.npy\"\n    # seg_ids = \"segmentation-ids.npy\"\n    if os.path.isfile(seg_data) and os.path.isfile(seg_labels):\n        X = numpy.load(seg_data)\n        y = numpy.load(seg_labels)\n\n        with open('datasets.pickle', 'rb') as f:\n            datasets = pickle.load(f)\n        return (X, y, datasets)\n    datasets = get_segmented_raw_data()\n    X, y = [], []\n    for i, data in enumerate(datasets):\n        if i % 10 == 0:\n            logging.info(\"[Create Dataset] i=%i/%i\", i, len(datasets))\n        segmentation = json.loads(data['segmentation'])\n        recording = json.loads(data['data'])\n        X_symbol = [get_median_stroke_distance(recording)]\n        if len([p for s in recording for p in s if p['time'] is None]) > 0:\n            continue\n        combis = itertools.combinations(list(range(len(recording))), 2)\n        for strokeid1, strokeid2 in combis:\n            stroke1 = recording[strokeid1]\n            stroke2 = recording[strokeid2]\n            if len(stroke1) == 0 or len(stroke2) == 0:\n                logging.debug(\"stroke len 0. Skip.\")\n                continue\n            X.append(get_stroke_features(recording, strokeid1, strokeid2) +\n                     X_symbol)\n            same_symbol = (_get_symbol_index(strokeid1, segmentation) ==\n                           _get_symbol_index(strokeid2, segmentation))\n            y.append(int(same_symbol))\n    X = numpy.array(X, dtype=numpy.float32)\n    y = numpy.array(y, dtype=numpy.int32)\n    numpy.save(seg_data, X)\n    numpy.save(seg_labels, y)\n    datasets = filter_recordings(datasets)\n    with open('datasets.pickle', 'wb') as f:\n        pickle.dump(datasets, f, protocol=pickle.HIGHEST_PROTOCOL)\n    return (X, y, datasets)", "response": "Create a dataset for machine learning of segmentations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_symbol_index(stroke_id_needle, segmentation):\n    for symbol_index, symbol in enumerate(segmentation):\n        if stroke_id_needle in symbol:\n            return symbol_index\n    return None", "response": "Get the index of the symbol in which stroke_id_needle occurs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_segmented_raw_data(top_n=10000):\n    cfg = utils.get_database_configuration()\n    mysql = cfg['mysql_online']\n    connection = pymysql.connect(host=mysql['host'],\n                                 user=mysql['user'],\n                                 passwd=mysql['passwd'],\n                                 db=mysql['db'],\n                                 cursorclass=pymysql.cursors.DictCursor)\n    cursor = connection.cursor()\n    sql = (\"SELECT `id`, `data`, `segmentation` \"\n           \"FROM `wm_raw_draw_data` WHERE \"\n           \"(`segmentation` IS NOT NULL OR `accepted_formula_id` IS NOT NULL) \"\n           \"AND `wild_point_count` = 0 \"\n           \"AND `stroke_segmentable` = 1 \"\n           \"ORDER BY `id` LIMIT 0, %i\") % top_n\n    logging.info(sql)\n    cursor.execute(sql)\n    datasets = cursor.fetchall()\n    logging.info(\"Fetched %i recordings. Add missing segmentations.\",\n                 len(datasets))\n    for i in range(len(datasets)):\n        if datasets[i]['segmentation'] is None:\n            stroke_count = len(json.loads(datasets[i]['data']))\n            if stroke_count > 10:\n                print(\"Massive stroke count! %i\" % stroke_count)\n            datasets[i]['segmentation'] = str([[s for s in\n                                                range(stroke_count)]])\n    return datasets", "response": "Fetch data from the server and add missing segmentations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all recordings which have points without time values.", "response": "def filter_recordings(recordings):\n    \"\"\"Remove all recordings which have points without time.\n    Parameters\n    ----------\n    recordings : list of dicts\n        Each dictionary has the keys 'data' and 'segmentation'\n\n    Returns\n    -------\n    list of dicts :\n        Only recordings where all points have time values.\n    \"\"\"\n    new_recordings = []\n    for recording in recordings:\n        recording['data'] = json.loads(recording['data'])\n        tmp = json.loads(recording['segmentation'])\n        recording['segmentation'] = normalize_segmentation(tmp)\n        had_none = False\n        for stroke in recording['data']:\n            for point in stroke:\n                if point['time'] is None:\n                    logging.debug(\"Had None-time: %i\", recording['id'])\n                    had_none = True\n                    break\n            if had_none:\n                break\n        if not had_none:\n            new_recordings.append(recording)\n\n    recordings = new_recordings\n    logging.info(\"Done filtering\")\n    return recordings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrains a neural network classifier.", "response": "def get_nn_classifier(X, y):\n    \"\"\"\n    Train a neural network classifier.\n\n    Parameters\n    ----------\n    X : numpy array\n        A list of feature vectors\n    y : numpy array\n        A list of labels\n\n    Returns\n    -------\n    Theano expression :\n        The trained neural network\n    \"\"\"\n    assert type(X) is numpy.ndarray\n    assert type(y) is numpy.ndarray\n    assert len(X) == len(y)\n    assert X.dtype == 'float32'\n    assert y.dtype == 'int32'\n\n    nn_pickled_filename = 'is_one_symbol_classifier.pickle'\n    if os.path.isfile(nn_pickled_filename):\n        with open(nn_pickled_filename, 'rb') as handle:\n            get_output = pickle.load(handle)\n    else:\n        get_output = train_nn_segmentation_classifier(X, y)\n        with open(nn_pickled_filename, 'wb') as handle:\n            pickle.dump(get_output, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    return get_output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef train_nn_segmentation_classifier(X, y):\n\n    def build_mlp(input_var=None):\n        n_classes = 2\n        # First, construct an input layer. The shape parameter defines the\n        # expected input shape, which is just the shape of our data matrix X.\n        l_in = lasagne.layers.InputLayer(shape=X.shape,\n                                         input_var=input_var)\n        # A dense layer implements a linear mix (xW + b) followed by a\n        # nonlinear function.\n        hiddens = [64, 64, 64]  # sollte besser als 0.12 sein (mit [32])\n        layers = [l_in]\n\n        for n_units in hiddens:\n            l_hidden_1 = lasagne.layers.DenseLayer(\n                layers[-1],  # The first argument is the input to this layer\n                num_units=n_units,  # the layer's output dimensionality\n                nonlinearity=lasagne.nonlinearities.tanh)\n            layers.append(l_hidden_1)\n        # For our output layer, we'll use a dense layer with a softmax\n        # nonlinearity.\n        l_output = lasagne.layers.DenseLayer(layers[-1], num_units=n_classes,\n                                             nonlinearity=softmax)\n        return l_output\n\n    # Batch iterator, Copied directly from the Lasagne example.\n    def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n        \"\"\"\n        This is just a simple helper function iterating over training data in\n        mini-batches of a particular size, optionally in random order. It\n        assumes data is available as numpy arrays. For big datasets, you could\n        load numpy arrays as memory-mapped files (np.load(..., mmap_mode='r')),\n        or write your own custom data iteration function. For small datasets,\n        you can also copy them to GPU at once for slightly improved\n        performance. This would involve several changes in the main program,\n        though, and is not demonstrated here.\n        \"\"\"\n        assert len(inputs) == len(targets)\n        if shuffle:\n            indices = np.arange(len(inputs))\n            np.random.shuffle(indices)\n        for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n            if shuffle:\n                excerpt = indices[start_idx:start_idx + batchsize]\n            else:\n                excerpt = slice(start_idx, start_idx + batchsize)\n            yield inputs[excerpt], targets[excerpt]\n\n    input_var = T.matrix('inputs')\n    target_var = T.ivector('targets')\n    network = build_mlp(input_var)\n    num_epochs = 7\n\n    # We reserve the last 100 training examples for validation.\n    X_train, X_val = X[:-100], X[-100:]\n    y_train, y_val = y[:-100], y[-100:]\n\n    # Create a loss expression for training, i.e., a scalar objective we want\n    # to minimize (for our multi-class problem, it is the cross-entropy loss):\n    prediction = lasagne.layers.get_output(network)\n    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n    loss = loss.mean()\n    # We could add some weight decay as well here, see lasagne.regularization.\n\n    # Create update expressions for training, i.e., how to modify the\n    # parameters at each training step. Here, we'll use Stochastic Gradient\n    # Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n    params = lasagne.layers.get_all_params(network, trainable=True)\n    updates = lasagne.updates.nesterov_momentum(loss,\n                                                params,\n                                                learning_rate=0.01,\n                                                momentum=0.9)\n\n    # Create a loss expression for validation/testing. The crucial difference\n    # here is that we do a deterministic forward pass through the network,\n    # disabling dropout layers.\n    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n\n    # Compile a function performing a training step on a mini-batch (by giving\n    # the updates dictionary) and returning the corresponding training loss:\n    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n\n    # Finally, launch the training loop.\n    print(\"Starting training...\")\n    # We iterate over epochs:\n    for epoch in range(num_epochs):\n        # In each epoch, we do a full pass over the training data:\n        train_err = 0\n        train_batches = 0\n        start_time = time.time()\n        for batch in iterate_minibatches(X_train, y_train, 20, shuffle=True):\n            inputs, targets = batch\n            train_err += train_fn(inputs, targets)\n            train_batches += 1\n\n        # Then we print the results for this epoch:\n        print(\"Epoch {0} of {1} took {2:.3f}s\".format(\n              epoch + 1, num_epochs, time.time() - start_time))\n        print(\"  training loss:\\t\\t{0:.6f}\".format(train_err / train_batches))\n\n    predict_fn = theano.function([input_var],\n                                 test_prediction)\n    return predict_fn", "response": "Train a neural network classifier on X and y."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_stroke_features(recording, strokeid1, strokeid2):\n    stroke1 = recording[strokeid1]\n    stroke2 = recording[strokeid2]\n    assert isinstance(stroke1, list), \"stroke1 is a %s\" % type(stroke1)\n    X_i = []\n    for s in [stroke1, stroke2]:\n        hw = HandwrittenData(json.dumps([s]))\n        feat1 = features.ConstantPointCoordinates(strokes=1,\n                                                  points_per_stroke=20,\n                                                  fill_empty_with=0)\n        feat2 = features.ReCurvature(strokes=1)\n        feat3 = features.Ink()\n        X_i += hw.feature_extraction([feat1, feat2, feat3])\n    X_i += [get_strokes_distance(stroke1, stroke2)]  # Distance of strokes\n    X_i += [get_time_distance(stroke1, stroke2)]  # Time in between\n    X_i += [abs(strokeid2-strokeid1)]  # Strokes in between\n    # X_i += [get_black_percentage()]\n    return X_i", "response": "Get the features used to decide if two strokes belong to the same symbol\n    or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_segmentations(segs1, segs2, strokes=None):\n    def translate(segmentation, strokes):\n        t = []\n        for symbol in segmentation:\n            symbol_new = []\n            for stroke in symbol:\n                symbol_new.append(strokes[stroke])\n            t.append(symbol_new)\n        return t\n    if strokes is None:\n        strokes = [i for i in range(len(segs2[0][0]))]\n    topf = partitions.TopFinder(500)\n    for s1, s2 in itertools.product(segs1, segs2):\n        topf.push(s1[0]+translate(s2[0], strokes), s1[1]*s2[1])\n    return list(topf)", "response": "Returns a list of tuples with their score combined from segs1 and segs2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of segmentations of a single symbol.", "response": "def get_segmentation(recording,\n                     single_clf,\n                     single_stroke_clf,\n                     stroke_segmented_classifier):\n    \"\"\"\n    Get a list of segmentations of recording with the probability of the\n    segmentation being correct.\n\n    Parameters\n    ----------\n    recording : A list of lists\n        Each sublist represents a stroke\n    single_clf : object\n        A classifier for single symbols\n    single_stroke_clf : object\n        A classifier which decides if a single stroke is a complete symbol\n    stroke_segmented_classifier : object\n        Classifier which decides if two strokes belong to one symbol or not\n\n    Returns\n    -------\n    list of tuples :\n        Segmentations together with their probabilities. Each probability\n        has to be positive and the sum may not be bigger than 1.0.\n\n    Examples\n    --------\n    >>> stroke1 = [{'x': 0, 'y': 0, 'time': 0}, {'x': 12, 'y': 12, 'time': 1}]\n    >>> stroke2 = [{'x': 0, 'y': 10, 'time': 2}, {'x': 12, 'y': 0, 'time': 3}]\n    >>> stroke3 = [{'x': 14, 'y': 0, 'time': 5}, {'x': 14, 'y': 12, 'time': 6}]\n    >>> #get_segmentation([stroke1, stroke2, stroke3], single_clf)\n    [\n      ([[0, 1], [2]], 0.8),\n      ([[0], [1,2]], 0.1),\n      ([[0,2], [1]], 0.05)\n    ]\n    \"\"\"\n    mst_wood = get_mst_wood(recording, single_clf)\n    return [(normalize_segmentation([mst['strokes'] for mst in mst_wood]),\n             1.0)]\n\n    # HandwrittenData(json.dumps(recording)).show()\n    # return [([[i for i in range(len(recording))]], 1.0)]\n    # #mst_wood = break_mst(mst, recording)  # TODO\n\n    # for i in range(0, 2**len(points)):\n    #     segmentation = get_segmentation_from_mst(mst, i)\n    # TODO\n\n    X_symbol = [get_median_stroke_distance(recording)]\n\n    # Pre-segment to 8 strokes\n    # TODO: Take first 4 strokes and add strokes within their bounding box\n    # TODO: What if that is more then 8 strokes?\n    # -> Geometry\n    #    Build tree structure. A stroke `c` is the child of another stroke `p`,\n    #    if the bounding box of `c` is within the bounding box of `p`.\n    #       Problem: B <-> 13\n    g_top_segmentations = [([], 1.0)]  # g_top_segmentations\n\n    # range(int(math.ceil(float(len(recording))/8))):\n    for chunk_part in mst_wood:\n        # chunk = recording[8*chunk_part:8*(chunk_part+1)]\n        chunk = [recording[stroke] for stroke in chunk_part['strokes']]\n\n        # Segment after pre-segmentation\n        prob = [[1.0 for _ in chunk] for _ in chunk]\n        for strokeid1, strokeid2 in itertools.product(range(len(chunk)),\n                                                      range(len(chunk))):\n            if strokeid1 == strokeid2:\n                continue\n            X = get_stroke_features(chunk, strokeid1, strokeid2)\n            X += X_symbol\n            X = numpy.array([X], dtype=numpy.float32)\n            prob[strokeid1][strokeid2] = stroke_segmented_classifier(X)\n\n        # Top segmentations\n        ts = list(partitions.get_top_segmentations(prob, 500))\n        for i, segmentation in enumerate(ts):\n            symbols = apply_segmentation(chunk, segmentation)\n            min_top2 = partitions.TopFinder(1, find_min=True)\n            for i, symbol in enumerate(symbols):\n                predictions = single_clf.predict(symbol)\n                min_top2.push(\"value-%i\" % i,\n                              predictions[0]['probability'] +\n                              predictions[1]['probability'])\n            ts[i][1] *= list(min_top2)[0][1]\n        # for i, segmentation in enumerate(ts):\n        #     ts[i][0] = update_segmentation_data(ts[i][0], 8*chunk_part)\n        g_top_segmentations = merge_segmentations(g_top_segmentations,\n                                                  ts,\n                                                  chunk_part['strokes'])\n    return [(normalize_segmentation(seg), probability)\n            for seg, probability in g_top_segmentations]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_mst_wood(recording, single_clf):\n    points = get_points(recording)\n    mst = get_mst(points)\n    mst_wood = [{'mst': mst, 'strokes': list(range(len(mst)))}]\n    # TODO: break mst into wood of msts wherever possible by recognizing single\n    # symbols by stroke\n\n    bbintersections = get_bb_intersections(recording)\n    for i, stroke in enumerate(recording):  # TODO\n        predictions = single_clf.predict({'id': 0, 'data': [stroke]})\n        # TODO predictions[:20]\n        prob_sum = sum([p['probability'] for p in predictions[:1]])\n        # dots cannot be segmented into single symbols at this point\n        if prob_sum > 0.95 and not any([el for el in bbintersections[i]]) \\\n           and len(stroke) > 2 \\\n           and predictions[0]['semantics'].split(';')[1] != '-':\n            # Split mst here\n            split_mst_index, split_node_i = find_split_node(mst_wood, i)\n            mst_wood_tmp = break_mst(mst_wood[split_mst_index],\n                                     split_node_i)\n            del mst_wood[split_mst_index]\n            for mst in mst_wood_tmp:\n                mst_wood.append(mst)\n            for mst in mst_wood:\n                if i in mst['strokes']:\n                    mst['pred'] = predictions[0]['semantics'].split(';')[1]\n\n    # if any([True for mst in mst_wood if len(mst['strokes']) >= 8]):\n    #     logging.debug([mst['pred'] for mst in mst_wood if 'pred' in mst])\n    #     HandwrittenData(json.dumps(recording)).show()\n    return mst_wood", "response": "Get the wood of the MSTs in the recording."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_missing_break(real_seg, pred_seg):\n    for symbol_pred in pred_seg:\n        for symbol_real in real_seg:\n            if symbol_pred[0] in symbol_real:\n                for stroke in symbol_pred:\n                    if stroke not in symbol_real:\n                        return True\n    return False", "response": "Returns True if the next segment is missing a break."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the real_seg and pred_seg are not in different trees.", "response": "def has_wrong_break(real_seg, pred_seg):\n    \"\"\"\n    Parameters\n    ----------\n    real_seg : list of integers\n        The segmentation as it should be.\n    pred_seg : list of integers\n        The predicted segmentation.\n\n    Returns\n    -------\n    bool :\n        True, if strokes of one symbol were segmented to be in different\n        symbols.\n    \"\"\"\n    for symbol_real in real_seg:\n        for symbol_pred in pred_seg:\n            if symbol_real[0] in symbol_pred:\n                for stroke in symbol_real:\n                    if stroke not in symbol_pred:\n                        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_split_node(mst_wood, i):\n    for mst_index, mst in enumerate(mst_wood):\n        if i in mst['strokes']:\n            return (mst_index, mst['strokes'].index(i))\n    raise ValueError('%i was not found as stroke index.' % i)", "response": "Find the node index of the split node in the given list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef break_mst(mst, i):\n    for j in range(len(mst['mst'])):\n        mst['mst'][i][j] = 0\n        mst['mst'][j][i] = 0\n    _, components = scipy.sparse.csgraph.connected_components(mst['mst'])\n    comp_indices = {}\n    for el in set(components):\n        comp_indices[el] = {'strokes': [], 'strokes_i': []}\n    for i, comp_nr in enumerate(components):\n        comp_indices[comp_nr]['strokes'].append(mst['strokes'][i])\n        comp_indices[comp_nr]['strokes_i'].append(i)\n\n    mst_wood = []\n\n    for key in comp_indices:\n        matrix = []\n        for i, line in enumerate(mst['mst']):\n            line_add = []\n            if i not in comp_indices[key]['strokes_i']:\n                continue\n            for j, el in enumerate(line):\n                if j in comp_indices[key]['strokes_i']:\n                    line_add.append(el)\n            matrix.append(line_add)\n        assert len(matrix) > 0, \\\n            (\"len(matrix) == 0 (strokes: %s, mst=%s, i=%i)\" %\n             (comp_indices[key]['strokes'], mst, i))\n        assert len(matrix) == len(matrix[0]), \\\n            (\"matrix was %i x %i, but should be square\" %\n             (len(matrix), len(matrix[0])))\n        assert len(matrix) == len(comp_indices[key]['strokes']), \\\n            ((\"stroke length was not equal to matrix length \"\n              \"(strokes=%s, len(matrix)=%i)\") %\n             (comp_indices[key]['strokes'], len(matrix)))\n        mst_wood.append({'mst': matrix,\n                         'strokes': comp_indices[key]['strokes']})\n    return mst_wood", "response": "Break a MST into multiple MSTs by removing one node i."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a given segmentation is out of order.", "response": "def _is_out_of_order(segmentation):\n    \"\"\"\n    Check if a given segmentation is out of order.\n\n    Examples\n    --------\n    >>> _is_out_of_order([[0, 1, 2, 3]])\n    False\n    >>> _is_out_of_order([[0, 1], [2, 3]])\n    False\n    >>> _is_out_of_order([[0, 1, 3], [2]])\n    True\n    \"\"\"\n    last_stroke = -1\n    for symbol in segmentation:\n        for stroke in symbol:\n            if last_stroke > stroke:\n                return True\n            last_stroke = stroke\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets one point for each stroke in a recording.", "response": "def get_points(recording):\n    \"\"\"\n    Get one point for each stroke in a recording. The point represents the\n    strokes spacial position (e.g. the center of the bounding box).\n\n    Parameters\n    ----------\n    recording : list of strokes\n\n    Returns\n    -------\n    list :\n        points\n    \"\"\"\n    points = []\n    for stroke in recording:\n        point = geometry.get_bounding_box(stroke).get_center()\n        points.append(point)\n    return points"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_bb_intersections(recording):\n    intersections = numpy.zeros((len(recording), len(recording)),\n                                dtype=bool)\n    for i in range(len(recording)-1):\n        a = geometry.get_bounding_box(recording[i]).grow(0.2)\n        for j in range(i+1, len(recording)):\n            b = geometry.get_bounding_box(recording[j]).grow(0.2)\n            intersections[i][j] = geometry.do_bb_intersect(a, b)\n            intersections[j][i] = intersections[i][j]\n    return intersections", "response": "Get all intersections of the bounding boxes of strokes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mst(points):\n    graph = Graph()\n    for point in points:\n        graph.add_node(point)\n    graph.generate_euclidean_edges()\n    matrix = scipy.sparse.csgraph.minimum_spanning_tree(graph.w)\n    mst = matrix.toarray().astype(int)\n    # returned matrix is not symmetrical! make it symmetrical\n    for i in range(len(mst)):\n        for j in range(len(mst)):\n            if mst[i][j] > 0:\n                mst[j][i] = mst[i][j]\n            if mst[j][i] > 0:\n                mst[i][j] = mst[j][i]\n    return mst", "response": "Returns the minimum spanning tree of a list of points."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npredict the recordings for a single recording and returns the results.", "response": "def predict(self, parsed_json):\n        \"\"\"\n        Parameters\n        ----------\n        parsed_json : dict\n            with keys 'data' and 'id', where 'data' contains a recording and\n            'id' is the id on write-math.com for debugging purposes\n        \"\"\"\n        evaluate = utils.evaluate_model_single_recording_preloaded\n        results = evaluate(self.preprocessing_queue,\n                           self.feature_list,\n                           self.model,\n                           self.output_semantics,\n                           json.dumps(parsed_json['data']),\n                           parsed_json['id'])\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_node(self, payload):\n        self.nodes.append(Node(len(self.nodes), payload))\n        return len(self.nodes) - 1", "response": "Adds a node to the internal list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the probability of a symbol having count strokes.", "response": "def p_strokes(symbol, count):\n    \"\"\"\n    Get the probability of a written `symbol` having `count` strokes.\n\n    Parameters\n    ----------\n    symbol : str\n        LaTeX command\n    count : int, >= 1\n\n    Returns\n    -------\n    float\n        In [0.0, 1.0]\n    \"\"\"\n    global stroke_prob\n    assert count >= 1\n    epsilon = 0.00000001\n    if stroke_prob is None:\n        misc_path = pkg_resources.resource_filename('hwrt', 'misc/')\n        stroke_prob_file = os.path.join(misc_path,\n                                        'prob_stroke_count_by_symbol.yml')\n        with open(stroke_prob_file, 'r') as stream:\n            stroke_prob = yaml.load(stream)\n    if symbol in stroke_prob:\n        if count in stroke_prob[symbol]:\n            return stroke_prob[symbol][count]\n        else:\n            return epsilon\n    return epsilon"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calc_hypothesis_probability(hypothesis):\n    prob = 0.0\n    for symbol, seg in zip(hypothesis['symbols'], hypothesis['segmentation']):\n        # symbol_latex = symbol['symbol'].split(\";\")[1]\n        # TODO: Does p_strokes really improve the system?\n        prob += symbol['probability']  # * p_strokes(symbol_latex, len(seg))\n\n    # Use language model to update probabilities\n    pure_symbols = [symbol['symbol'].split(\";\")[1]\n                    for symbol in hypothesis['symbols']]\n    pure_symbols = [\"<s>\"] + pure_symbols + [\"</s>\"]\n    lm_prob = language_model.get_probability(pure_symbols)\n    hypothesis['lm_probability'] = 2**lm_prob\n    return (prob * float(hypothesis['lm_probability']) *\n            (1.0 / len(hypothesis['segmentation'])))", "response": "Calculate the probability of a hypothesis."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a unicode string from a dictionary.", "response": "def build_unicode(hyp):\n    \"\"\"\n    Parameters\n    ----------\n    hyp : dict\n        {'segmentation': [[0, 3], [1, 2]],\n         'symbols': [{'symbol': ID, 'probability': 0.12}],\n         'geometry': {'symbol': index,\n                      'bottom': None or dict,\n                      'subscript': None or dict,\n                      'right': None or dict,\n                      'superscript': None or dict,\n                      'top': None or dict},\n          'probability': 0.123\n        }\n    \"\"\"\n    latex = []\n    for symbol in hyp['symbols']:\n        latex.append(symbol['symbol'])\n    return \";;\".join(latex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_latex(hyp):\n    latex = []\n    for symbol in hyp['symbols']:\n        latex.append(symbol['symbol'].split(\";\")[1])\n    return \" \".join(latex)", "response": "Builds a LaTeX string from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds hypotheses to new_stroke which is a new symbol.", "response": "def _add_hypotheses_assuming_new_stroke(self,\n                                            new_stroke,\n                                            stroke_nr,\n                                            new_beam):\n        \"\"\"\n        Get new guesses by assuming new_stroke is a new symbol.\n\n        Parameters\n        ----------\n        new_stroke : list of dicts\n            A list of dicts [{'x': 12, 'y': 34, 'time': 56}, ...] which\n            represent a point.\n        stroke_nr : int\n            Number of the stroke for segmentation\n        new_beam : beam object\n        \"\"\"\n        guesses = single_clf.predict({'data': [new_stroke],\n                                      'id': None})[:self.m]\n        for hyp in self.hypotheses:\n            new_geometry = deepcopy(hyp['geometry'])\n            most_right = new_geometry\n            if len(hyp['symbols']) == 0:\n                while 'right' in most_right:\n                    most_right = most_right['right']\n                most_right['right'] = {'symbol_index': len(hyp['symbols']),\n                                       'right': None}\n            else:\n                most_right = {'symbol_index': len(hyp['symbols']),\n                              'right': None}\n            for guess in guesses:\n                sym = {'symbol': guess['semantics'],\n                       'probability': guess['probability']}\n                new_seg = deepcopy(hyp['segmentation'])\n                new_seg.append([stroke_nr])\n                new_sym = deepcopy(hyp['symbols'])\n                new_sym.append(sym)\n                b = {'segmentation': new_seg,\n                     'symbols': new_sym,\n                     'geometry': new_geometry,\n                     'probability': None\n                     }\n\n                # spacial_rels = []  # TODO\n                # for s1_indices, s2_indices in zip(b['segmentation'],\n                #                                   b['segmentation'][1:]):\n                #     tmp = [new_beam.history['data'][el] for el in s1_indices]\n                #     s1 = HandwrittenData(json.dumps(tmp))\n                #     tmp = [new_beam.history['data'][el] for el in s2_indices]\n                #     s2 = HandwrittenData(json.dumps(tmp))\n                #     rel = spacial_relationship.estimate(s1, s2)\n                #     spacial_rels.append(rel)\n                # b['geometry'] = spacial_rels\n                new_beam.hypotheses.append(b)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_stroke(self, new_stroke):\n        global single_clf\n        if len(self.hypotheses) == 0:  # Don't put this in the constructor!\n            self.hypotheses = [{'segmentation': [],\n                                'symbols': [],\n                                'geometry': {},\n                                'probability': Decimal(1)\n                                }]\n        stroke_nr = len(self.history['data'])\n        new_history = deepcopy(self.history)\n        new_history['data'].append(new_stroke)\n        new_beam = Beam()\n        new_beam.history = new_history\n\n        evaluated_segmentations = []\n\n        # Get new guesses by assuming new_stroke belongs to an already begun\n        # symbol\n        had_multisymbol = False\n        for hyp in self.hypotheses:\n            # Add stroke to last n symbols (seperately)\n            for i in range(min(self.n, len(hyp['segmentation']))):\n                # Build stroke data\n                new_strokes = {'data': [], 'id': -1}\n                for stroke_index in hyp['segmentation'][-(i+1)]:\n                    curr_stroke = self.history['data'][stroke_index]\n                    new_strokes['data'].append(curr_stroke)\n                new_strokes['data'].append(new_stroke)\n\n                new_seg = deepcopy(hyp['segmentation'])\n                new_seg[-(i+1)].append(stroke_nr)\n\n                if new_seg in evaluated_segmentations:\n                    continue\n                else:\n                    evaluated_segmentations.append(new_seg)\n\n                # Predict this new collection of strokes\n                guesses = single_clf.predict(new_strokes)[:self.m]\n                for guess in guesses:\n                    if guess['semantics'].split(\";\")[1] == \"::MULTISYMBOL::\":\n                        # This was a wrong segmentation. Ignore it.\n                        had_multisymbol = True\n                        continue\n                    sym = {'symbol': guess['semantics'],\n                           'probability': guess['probability']}\n                    new_sym = deepcopy(hyp['symbols'])\n                    new_sym[-(i+1)] = sym\n                    b = {'segmentation': new_seg,\n                         'symbols': new_sym,\n                         'geometry': deepcopy(hyp['geometry']),\n                         'probability': None\n                         }\n                    new_beam.hypotheses.append(b)\n\n        if len(self.hypotheses) <= 1 or had_multisymbol:\n            self._add_hypotheses_assuming_new_stroke(new_stroke,\n                                                     stroke_nr,\n                                                     new_beam)\n\n        for hyp in new_beam.hypotheses:\n            hyp['probability'] = _calc_hypothesis_probability(hyp)\n\n        # Get probability again\n\n        # Get geometry of each beam entry\n        # TODO\n\n        # Update probabilities\n        # TODO\n\n        # Normalize to sum=1\n        self.hypotheses = new_beam.hypotheses\n        self.history = new_beam.history\n        self._prune()\n        new_probs = softmax([h['probability']\n                             for h in self.hypotheses])\n        for hyp, prob in zip(self.hypotheses, new_probs):\n            hyp['probability'] = prob", "response": "Add a new stroke to the beam."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prune(self):\n        self.hypotheses = sorted(self.hypotheses,\n                                 key=lambda e: e['probability'],\n                                 reverse=True)[:self.k]", "response": "Shorten hypotheses to the best k ones."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the result in the format of the write - math.", "response": "def get_writemath_results(self):\n        \"\"\"\n        Get the result in the format\n        [{'probability': 0.987,\n          'segmentation': [[0, 1], [2, 4], [3]]}   // index of the stroke\n          'symbols': [{'id': 456,  // on write-math.com\n                       'probability': 0.123},\n                      {'id': 456,\n                       'probability': 0.999},  // The sum does not have to be 1\n                      {'id': 195,\n                       'probability': 0.0001}]\n          },\n         {...}  // another hypothesis\n        ]\n        \"\"\"\n        results = []\n        for hyp in self.hypotheses:\n            symbols = []\n            for sym in hyp['symbols']:\n                symbols.append({'id': sym['symbol'].split(';')[0],\n                                'probability': sym['probability']})\n            results.append({'probability': float(hyp['probability']),\n                            'segmentation': hyp['segmentation'],\n                            'symbols': symbols})\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_matrices():\n    with open('hwrt/misc/is_one_symbol_classifier.pickle', 'rb') as f:\n        a = pickle.load(f)\n\n    arrays = []\n    for el1 in a.input_storage:\n        for el2 in el1.__dict__['storage']:\n            if isinstance(el2, cuda.CudaNdarray):\n                arrays.append({'storage': numpy.asarray(el2),\n                               'name': el1.name})\n            else:\n                logging.warning(\"was type %s. Do nothing.\" % type(el2))\n                logging.debug(el1.name)\n    return arrays", "response": "Get the matrices from a pickled file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_model_tar(matrices, tarname=\"model-cuda-converted.tar\"):\n    # Write layers\n    filenames = []\n    for layer in range(len(matrices)):\n        if matrices[layer]['name'] == 'W':\n            weights = matrices[layer]['storage']\n            weights_file = h5py.File('W%i.hdf5' % (layer / 2), 'w')\n            weights_file.create_dataset(weights_file.id.name, data=weights)\n            weights_file.close()\n            filenames.append('W%i.hdf5' % (layer / 2))\n        elif matrices[layer]['name'] == 'b':\n            b = matrices[layer]['storage']\n            bfile = h5py.File('b%i.hdf5' % (layer / 2), 'w')\n            bfile.create_dataset(bfile.id.name, data=b)\n            bfile.close()\n            filenames.append('b%i.hdf5' % (layer / 2))\n\n        # activation = a['layers'][layer]['_props']['activation']\n        # activation = activation.replace('sigmoid', 'Sigmoid')\n        # activation = activation.replace('softmax', 'Softmax')\n        # layers.append({'W': {'size': list(W.shape),\n        #                      'filename': 'W%i.hdf5' % layer},\n        #                'b': {'size': list(b.shape),\n        #                      'filename': 'b%i.hdf5' % layer},\n        #                'activation': activation})\n    with tarfile.open(tarname, \"w:\") as tar:\n        for name in filenames:\n            tar.add(name)\n\n    # Remove temporary files which are now in tar file\n    for filename in filenames:\n        os.remove(filename)", "response": "Create a tar file which contains the model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the folder and returns a list of HandwrittenData objects.", "response": "def read_folder(folder):\n    \"\"\"\n    Parameters\n    ----------\n    folder : str\n\n    Returns\n    -------\n    list of HandwrittenData objects\n    \"\"\"\n    hwr_objects = []\n    for filepath in natsort.natsorted(glob.glob(\"%s/*.inkml\" % folder)):\n        tmp = inkml.read(filepath)\n        for hwr in tmp.to_single_symbol_list():\n            hwr_objects.append(hwr)\n    logging.info(\"Done reading formulas\")\n    save_raw_pickle(hwr_objects)\n    return hwr_objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the raw data of the hwr objects to a pickle file.", "response": "def save_raw_pickle(hwr_objects):\n    \"\"\"\n    Parameters\n    ----------\n    hwr_objects : list of hwr objects\n    \"\"\"\n    converted_hwr = []\n\n    translate = {}\n    translate_id = {}\n    model_path = pkg_resources.resource_filename('hwrt', 'misc/')\n    translation_csv = os.path.join(model_path, 'latex2writemathindex.csv')\n    arguments = {'newline': '', 'encoding': 'utf8'}\n    with open(translation_csv, 'rt', **arguments) as csvfile:\n        contents = csvfile.read()\n    lines = contents.split(\"\\n\")\n    for csvrow in lines:\n        csvrow = csvrow.split(',')\n        if len(csvrow) == 1:\n            writemathid = csvrow[0]\n            latex = \"\"\n        else:\n            writemathid, latex = int(csvrow[0]), csvrow[1:]\n            latex = ','.join(latex)\n        translate[latex] = writemathid\n        translate_id[writemathid] = latex\n\n    for hwr in hwr_objects:\n        hwr.formula_in_latex = translate_id[hwr.formula_id]\n\n    formula_id2latex = {}\n    for el in hwr_objects:\n        if el.formula_id not in formula_id2latex:\n            formula_id2latex[el.formula_id] = el.formula_in_latex\n\n    for hwr in hwr_objects:\n        hwr.formula_in_latex = translate_id[hwr.formula_id]\n        hwr.raw_data_id = 42\n        converted_hwr.append({'is_in_testset': 0,\n                              'formula_id': hwr.formula_id,\n                              'handwriting': hwr,\n                              'id': 42,\n                              'formula_in_latex': hwr.formula_in_latex})\n    with open('crohme.pickle', 'wb') as f:\n        pickle.dump({'formula_id2latex': formula_id2latex,\n                     'handwriting_datasets': converted_hwr},\n                    f,\n                    protocol=pickle.HIGHEST_PROTOCOL)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the currently running Python version is new enough.", "response": "def check_python_version():\n    \"\"\"Check if the currently running Python version is new enough.\"\"\"\n    # Required due to multiple with statements on one line\n    req_version = (2, 7)\n    cur_version = sys.version_info\n    if cur_version >= req_version:\n        print(\"Python version... %sOK%s (found %s, requires %s)\" %\n              (Bcolors.OKGREEN, Bcolors.ENDC, str(platform.python_version()),\n               str(req_version[0]) + \".\" + str(req_version[1])))\n    else:\n        print(\"Python version... %sFAIL%s (found %s, requires %s)\" %\n              (Bcolors.FAIL, Bcolors.ENDC, str(cur_version),\n               str(req_version)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if all required python modules are installed.", "response": "def check_python_modules():\n    \"\"\"Check if all necessary / recommended modules are installed.\"\"\"\n    print(\"\\033[1mCheck modules\\033[0m\")\n    required_modules = ['argparse', 'matplotlib', 'natsort', 'pymysql',\n                        'cPickle', 'theano', 'dropbox', 'yaml',\n                        'webbrowser', 'hashlib', 'numpy',\n                        'jinja2']\n    found = []\n    for required_module in required_modules:\n        try:\n            imp.find_module(required_module)\n            check = \"module '%s' ... %sfound%s\" % (required_module,\n                                                   Bcolors.OKGREEN,\n                                                   Bcolors.ENDC)\n            print(check)\n            found.append(required_module)\n        except ImportError:\n            print(\"module '%s' ... %sNOT%s found\" % (required_module,\n                                                     Bcolors.WARNING,\n                                                     Bcolors.ENDC))\n\n    if \"argparse\" in found:\n        import argparse\n        print(\"argparse version: %s (1.1 tested)\" % argparse.__version__)\n    if \"matplotlib\" in found:\n        import matplotlib\n        print(\"matplotlib version: %s (1.2.1 tested)\" % matplotlib.__version__)\n    if \"natsort\" in found:\n        import natsort\n        print(\"natsort version: %s (3.4.0 tested, 3.4.0 > required)\" %\n              natsort.__version__)\n    if \"pymysql\" in found:\n        import pymysql\n        print(\"pymysql version: %s (0.6.3 tested)\" %\n              pymysql.__version__)\n    if \"theano\" in found:\n        import theano\n        print(\"theano version: %s (0.6.0 tested)\" %\n              theano.__version__)\n    if \"numpy\" in found:\n        import numpy\n        print(\"numpy version: %s (1.8.1 tested)\" %\n              numpy.__version__)\n    if \"yaml\" in found:\n        import yaml\n        print(\"yaml version: %s (3.11 tested)\" %\n              yaml.__version__)\n    if \"jinja2\" in found:\n        import jinja2\n        print(\"jinja2 version: %s (2.7.3 tested)\" %\n              jinja2.__version__)\n    if \"cPickle\" in found:\n        import cPickle\n        print(\"cPickle version: %s (1.71 tested)\" %\n              cPickle.__version__)\n        print(\"cPickle HIGHEST_PROTOCOL: %s (2 required)\" %\n              cPickle.HIGHEST_PROTOCOL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_executables():\n    print(\"\\033[1mCheck executables\\033[0m\")\n    required_executables = [utils.get_nntoolkit()]\n    for executable in required_executables:\n        path = which(executable)\n        if path is None:\n            print(\"%s ... %sNOT%s found\" % (executable, Bcolors.WARNING,\n                                            Bcolors.ENDC))\n        else:\n            print(\"%s ... %sfound%s at %s\" % (executable, Bcolors.OKGREEN,\n                                              Bcolors.ENDC, path))", "response": "Check if all necessary executables are installed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the raw data from a file.", "response": "def read_raw(data_path):\n    \"\"\"\n    Parameters\n    ----------\n    data_path : str\n    \"\"\"\n    with open(data_path, 'rb') as f:\n        data = pickle.load(f)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge(d1, d2):\n    if d1['formula_id2latex'] is None:\n        formula_id2latex = {}\n    else:\n        formula_id2latex = d1['formula_id2latex'].copy()\n    formula_id2latex.update(d2['formula_id2latex'])\n    handwriting_datasets = d1['handwriting_datasets']\n    for dataset in d2['handwriting_datasets']:\n        handwriting_datasets.append(dataset)\n    return {'formula_id2latex': formula_id2latex,\n            'handwriting_datasets': handwriting_datasets}", "response": "Merge two raw datasets into one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef beautify_xml(path):\n    with open(path) as f:\n        content = f.read()\n\n    pretty_print = lambda data: '\\n'.join([line for line in\n                                           parseString(data)\n                                           .toprettyxml(indent=' ' * 2)\n                                           .split('\\n')\n                                           if line.strip()])\n    return pretty_print(content)", "response": "Beautify XML in path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(filepath):\n    import xml.etree.ElementTree\n    root = xml.etree.ElementTree.parse(filepath).getroot()\n\n    # Get the raw data\n    recording = []\n    strokes = sorted(root.findall('{http://www.w3.org/2003/InkML}trace'),\n                     key=lambda child: int(child.attrib['id']))\n    time = 0\n    for stroke in strokes:\n        stroke = stroke.text.strip().split(',')\n        stroke = [point.strip().split(' ') for point in stroke]\n        if len(stroke[0]) == 3:\n            stroke = [{'x': float(x), 'y': float(y), 'time': float(t)}\n                      for x, y, t in stroke]\n        else:\n            stroke = [{'x': float(x), 'y': float(y)} for x, y in stroke]\n            new_stroke = []\n            for p in stroke:\n                new_stroke.append({'x': p['x'], 'y': p['y'], 'time': time})\n                time += 20\n            stroke = new_stroke\n            time += 200\n        recording.append(stroke)\n\n    # Get LaTeX\n    formula_in_latex = None\n    annotations = root.findall('{http://www.w3.org/2003/InkML}annotation')\n    for annotation in annotations:\n        if annotation.attrib['type'] == 'truth':\n            formula_in_latex = annotation.text\n    hw = handwritten_data.HandwrittenData(json.dumps(recording),\n                                          formula_in_latex=formula_in_latex)\n    for annotation in annotations:\n        if annotation.attrib['type'] == 'writer':\n            hw.writer = annotation.text\n        elif annotation.attrib['type'] == 'category':\n            hw.category = annotation.text\n        elif annotation.attrib['type'] == 'expression':\n            hw.expression = annotation.text\n\n    # Get segmentation\n    segmentation = []\n    trace_groups = root.findall('{http://www.w3.org/2003/InkML}traceGroup')\n    if len(trace_groups) != 1:\n        raise Exception('Malformed InkML',\n                        ('Exactly 1 top level traceGroup expected, found %i. '\n                         '(%s) - probably no ground truth?') %\n                        (len(trace_groups), filepath))\n    trace_group = trace_groups[0]\n    symbol_stream = []  # has to be consistent with segmentation\n    for tg in trace_group.findall('{http://www.w3.org/2003/InkML}traceGroup'):\n        annotations = tg.findall('{http://www.w3.org/2003/InkML}annotation')\n        if len(annotations) != 1:\n            raise ValueError(\"%i annotations found for '%s'.\" %\n                             (len(annotations), filepath))\n        db_id = formula_to_dbid(normalize_symbol_name(annotations[0].text))\n        symbol_stream.append(db_id)\n        trace_views = tg.findall('{http://www.w3.org/2003/InkML}traceView')\n        symbol = []\n        for traceView in trace_views:\n            symbol.append(int(traceView.attrib['traceDataRef']))\n        segmentation.append(symbol)\n    hw.symbol_stream = symbol_stream\n    hw.segmentation = segmentation\n    _flat_seg = [stroke2 for symbol2 in segmentation for stroke2 in symbol2]\n    assert len(_flat_seg) == len(recording), \\\n        (\"Segmentation had length %i, but recording has %i strokes (%s)\" %\n         (len(_flat_seg), len(recording), filepath))\n    assert set(_flat_seg) == set(range(len(_flat_seg)))\n    hw.inkml = beautify_xml(filepath)\n    hw.filepath = filepath\n    return hw", "response": "Reads a single InkML file and returns a HandwrittenData object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a folder and returns a list of HandwrittenData objects.", "response": "def read_folder(folder):\n    \"\"\"\n    Parameters\n    ----------\n    folder : string\n        Path to a folde with *.inkml files.\n\n    Returns\n    -------\n    list :\n        Objects of the type HandwrittenData\n    \"\"\"\n    import glob\n    recordings = []\n    for filename in natsorted(glob.glob(\"%s/*.inkml\" % folder)):\n        hw = read(filename)\n        if hw.formula_in_latex is not None:\n            hw.formula_in_latex = hw.formula_in_latex.strip()\n        if hw.formula_in_latex is None or \\\n           not hw.formula_in_latex.startswith('$') or \\\n           not hw.formula_in_latex.endswith('$'):\n            if hw.formula_in_latex is not None:\n                logging.info(\"Starts with: %s\",\n                             str(hw.formula_in_latex.startswith('$')))\n                logging.info(\"ends with: %s\",\n                             str(hw.formula_in_latex.endswith('$')))\n            logging.info(hw.formula_in_latex)\n            logging.info(hw.segmentation)\n            hw.show()\n        recordings.append(hw)\n    return recordings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nestimating the spacial relationship by examining the position of the bounding boxes of the two handwritten data sets.", "response": "def estimate(s1, s2):\n    \"\"\"\n    Estimate the spacial relationship by\n    examining the position of the bounding boxes.\n\n    Parameters\n    ----------\n    s1 : HandwrittenData\n    s2 : HandwrittenData\n\n    Returns\n    -------\n    dict of probabilities\n        {'bottom': 0.1,\n         'subscript': 0.2,\n         'right': 0.3,\n         'superscript': 0.3,\n         'top': 0.1}\n    \"\"\"\n    s1bb = s1.get_bounding_box()\n    s2bb = s2.get_bounding_box()\n    total_area = ((s2bb['maxx'] - s2bb['minx']+1) *\n                  (s2bb['maxy'] - s2bb['miny']+1))\n    total_area = float(total_area)\n    top_area = 0.0\n    superscript_area = 0.0\n    right_area = 0.0\n    subscript_area = 0.0\n    bottom_area = 0.0\n    # bottom\n    if s2bb['maxy'] > s1bb['maxy'] and s2bb['minx'] < s1bb['maxx']:\n        miny = max(s2bb['miny'], s1bb['maxy'])\n        maxy = s2bb['maxy']\n        minx = max(s2bb['minx'], s1bb['minx'])\n        maxx = min(s2bb['maxx'], s1bb['maxx'])\n        bottom_area = float((maxx-minx)*(maxy-miny))\n    # Subscript\n    if s2bb['maxy'] > s1bb['maxy'] and s2bb['maxx'] > s1bb['maxx']:\n        miny = max(s2bb['miny'], s1bb['maxy'])\n        maxy = s2bb['maxy']\n        minx = max(s2bb['minx'], s1bb['maxx'])\n        maxx = s2bb['maxx']\n        subscript_area = (maxx-minx)*(maxy-miny)\n    # right\n    if s2bb['miny'] < s1bb['maxy'] and s2bb['maxy'] > s1bb['miny'] \\\n       and s2bb['maxx'] > s1bb['maxx']:\n        miny = max(s1bb['miny'], s2bb['miny'])\n        maxy = min(s1bb['maxy'], s2bb['maxy'])\n        minx = max(s1bb['maxx'], s2bb['minx'])\n        maxx = s2bb['maxx']\n        right_area = (maxx-minx)*(maxy-miny)\n    # superscript\n    if s2bb['miny'] < s1bb['miny'] and s2bb['maxx'] > s1bb['maxx']:\n        miny = s2bb['miny']\n        maxy = min(s1bb['miny'], s2bb['maxy'])\n        minx = max(s1bb['maxx'], s2bb['minx'])\n        maxx = s2bb['maxx']\n        superscript_area = (maxx-minx)*(maxy-miny)\n    # top\n    if s2bb['miny'] < s1bb['miny'] and s2bb['minx'] < s1bb['maxx']:\n        miny = s2bb['miny']\n        maxy = min(s1bb['miny'], s2bb['maxy'])\n        minx = max(s1bb['minx'], s2bb['minx'])\n        maxx = min(s1bb['maxx'], s2bb['maxx'])\n        top_area = (maxx-minx)*(maxy-miny)\n\n    return {'bottom': bottom_area/total_area,\n            'subscript': subscript_area/total_area,\n            'right': right_area/total_area,\n            'superscript': superscript_area/total_area,\n            'top': top_area/total_area}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_file_consistent(local_path_file, md5_hash):\n    return os.path.isfile(local_path_file) and \\\n        hashlib.md5(open(local_path_file, 'rb').read()).hexdigest() == md5_hash", "response": "Check if file is there and the md5_hash is correct."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the parser object for this script.", "response": "def get_parser():\n    \"\"\"Return the parser object for this script.\"\"\"\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    # Read config file. This has to get updated via git\n    project_root = utils.get_project_root()\n    infofile = os.path.join(project_root, \"raw-datasets/info.yml\")\n    logging.info(\"Read '%s'...\", infofile)\n    with open(infofile, 'r') as ymlfile:\n        datasets = yaml.load(ymlfile)\n    for dataset in datasets:\n        local_path_file = os.path.join(project_root, dataset['online_path'])\n        i = 0\n        while not is_file_consistent(local_path_file, dataset['md5']) and i < 3:\n            if os.path.isfile(local_path_file):\n                local_file_size = os.path.getsize(local_path_file)\n                logging.info(\"MD5 codes differ. \")\n                logging.info(\"The file size of the downloaded file is %s.\",\n                             utils.sizeof_fmt(local_file_size))\n            logging.info(\"Download the file '%s'...\", dataset['online_path'])\n            urllib.urlretrieve(dataset['url'], local_path_file)\n            i += 1\n        if i < 10:\n            logging.info(\"Found '%s'.\", dataset['online_path'])", "response": "Main part of the download script."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_model():\n    logging.info(\"Load language model...\")\n    ngram_arpa_t = pkg_resources.resource_filename('hwrt',\n                                                   'misc/ngram.arpa.tar.bz2')\n    with tarfile.open(ngram_arpa_t, 'r:bz2') as tar:\n        tarfolder = tempfile.mkdtemp()\n        tar.extractall(path=tarfolder)\n    ngram_arpa_f = os.path.join(tarfolder, 'ngram.arpa')\n    with open(ngram_arpa_f) as f:\n        content = f.read()\n    ngram_model = NgramLanguageModel()\n    ngram_model.load_from_arpa_str(content)\n    return ngram_model", "response": "Load a n - gram language model for mathematics in ARPA format which gets\n    shipped with hwrt."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the N - gram model from an ARPA language model string.", "response": "def load_from_arpa_str(self, arpa_str):\n        \"\"\"\n        Initialize N-gram model by reading an ARPA language model string.\n\n        Parameters\n        ----------\n        arpa_str : str\n            A string in ARPA language model file format\n        \"\"\"\n        data_found = False\n        end_found = False\n        in_ngram_block = 0\n        for i, line in enumerate(arpa_str.split(\"\\n\")):\n            if not end_found:\n                if not data_found:\n                    if \"\\\\data\\\\\" in line:\n                        data_found = True\n                else:\n                    if in_ngram_block == 0:\n                        if line.startswith(\"ngram\"):\n                            ngram_type, count = line.split(\"=\")\n                            _, n = ngram_type.split(\" \")\n                            n = int(n)\n                            self.ngrams[n] = {'data': {},\n                                              'count': count}\n                        elif line.startswith(\"\\\\\"):\n                            n = int(line.split(\"-\")[0][1:])\n                            in_ngram_block = n\n                        else:\n                            continue  # Empty line\n                    elif in_ngram_block > 0:\n                        if \"\\\\end\\\\\" in line:\n                            end_found = True\n                        elif line.startswith(\"\\\\\"):\n                            n = int(line.split(\"-\")[0][1:])\n                            in_ngram_block = n\n                        elif len(line) <= 1:\n                            continue\n                        else:\n                            data = line.split(\"\\t\")\n                            probability = Decimal(data[0])\n                            ngram = data[1:]\n                            if len(ngram) != n:\n                                raise Exception((\"ARPA language file is \"\n                                                 \"inconsistant. Line %i has \"\n                                                 \"only %i items, but should \"\n                                                 \"have %i items.\") %\n                                                (i, len(ngram), n))\n                            rest = ngram\n                            append_to = self.ngrams[n]['data']\n                            while len(rest) > 1:\n                                first, rest = rest[0], rest[1:]\n                                if first not in append_to:\n                                    append_to[first] = {}\n                                append_to = append_to[first]\n                            if rest[0] in append_to:\n                                raise Exception((\"Duplicate entry for \"\n                                                 \"ngram %s\") % ngram)\n                            append_to[rest[0]] = probability\n            else:\n                if line.startswith(\"info: \"):\n                    logging.info(line[6:])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the log probability of a trigram.", "response": "def get_trigram_log_prob(self, trigram):\n        \"\"\"\n        Calcualate the probability P(w1, w2, w3), given this language model.\n\n        Parameters\n        ----------\n        trigram\n            tuple with exactly 3 elements\n\n        Returns\n        -------\n        numeric\n            The log likelihood of P(w3 | (w1, w2))\n        \"\"\"\n        w1, w2, w3 = trigram\n        # if w1 not in self.ngrams[1]['data']:\n        #     w1 = \"<unk>\"\n        # if w2 not in self.ngrams[1]['data']:\n        #     w2 = \"<unk>\"\n        # if w3 not in self.ngrams[1]['data']:\n        #     w3 = \"<unk>\"\n        if w1 in self.ngrams[3]['data']:\n            if w2 in self.ngrams[3]['data'][w1]:\n                if w3 in self.ngrams[3]['data'][w1][w2]:\n                    return self.ngrams[3]['data'][w1][w2][w3]\n        return (Decimal(1.0).log10() -\n                Decimal(int(self.ngrams[1]['count'])**2).log10())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_probability(self, sentence):\n        if len(sentence) == 1:\n            return Decimal(10)**self.get_unigram_log_prob(sentence)\n        elif len(sentence) == 2:\n            return Decimal(10)**self.get_bigram_log_prob(sentence)\n        else:\n            log_prob = Decimal(0.0)\n            for w1, w2, w3 in zip(sentence, sentence[1:], sentence[2:]):\n                log_prob += self.get_trigram_log_prob((w1, w2, w3))\n            log_prob = Decimal(log_prob)\n            return Decimal(10)**log_prob", "response": "Calculate the probability of a sentence given this language model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates all recordings in sample_dir.", "response": "def evaluate_dir(sample_dir):\n    \"\"\"Evaluate all recordings in `sample_dir`.\n\n    Parameters\n    ----------\n    sample_dir : string\n        The path to a directory with *.inkml files.\n\n    Returns\n    -------\n    list of dictionaries\n        Each dictionary contains the keys 'filename' and 'results', where\n        'results' itself is a list of dictionaries. Each of the results has\n        the keys 'latex' and 'probability'\n    \"\"\"\n    results = []\n    if sample_dir[-1] == \"/\":\n        sample_dir = sample_dir[:-1]\n    for filename in glob.glob(\"%s/*.inkml\" % sample_dir):\n        results.append(evaluate_inkml(filename))\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef evaluate_inkml(inkml_file_path):\n    logging.info(\"Start evaluating '%s'...\", inkml_file_path)\n    ret = {'filename': inkml_file_path}\n    recording = inkml.read(inkml_file_path)\n    results = evaluate(json.dumps(recording.get_sorted_pointlist()),\n                       result_format='LaTeX')\n    ret['results'] = results\n    return ret", "response": "Evaluate an InkML file and return a dictionary containing the results of the evaluation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the output of the evaluation results in the format of the MfrDB3907_85801 MfrDB3907_8580101 MfrDB.", "response": "def generate_output_csv(evaluation_results, filename='results.csv'):\n    \"\"\"Generate the evaluation results in the format\n\n    Parameters\n    ----------\n    evaluation_results : list of dictionaries\n        Each dictionary contains the keys 'filename' and 'results', where\n        'results' itself is a list of dictionaries. Each of the results has\n        the keys 'latex' and 'probability'\n\n    Examples\n    --------\n    MfrDB3907_85801, a, b, c, d, e, f, g, h, i, j\n    scores, 1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1\n    MfrDB3907_85802, 1, |, l, COMMA, junk, x, X, \\times\n    scores, 10, 8.001, 2, 0.5, 0.1, 0,-0.5, -1, -100\n    \"\"\"\n    with open(filename, 'w') as f:\n        for result in evaluation_results:\n            for i, entry in enumerate(result['results']):\n                if entry['semantics'] == ',':\n                    result['results']['semantics'] = 'COMMA'\n            f.write(\"%s, \" % result['filename'])\n            f.write(\", \".join([entry['semantics'] for entry in result['results']]))\n            f.write(\"\\n\")\n            f.write(\"%s, \" % \"scores\")\n            f.write(\", \".join([str(entry['probability']) for entry in result['results']]))\n            f.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_status(total, current, start_time=None):\n    percentage_done = float(current) / total\n    sys.stdout.write(\"\\r%0.2f%% \" % (percentage_done * 100))\n    if start_time is not None:\n        current_running_time = time.time() - start_time\n        remaining_seconds = current_running_time / percentage_done\n        tmp = datetime.timedelta(seconds=remaining_seconds)\n        sys.stdout.write(\"(%s remaining)   \" % str(tmp))\n    sys.stdout.flush()", "response": "Prints the status of the work in a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_valid_file(parser, arg):\n    arg = os.path.abspath(arg)\n    if not os.path.exists(arg):\n        parser.error(\"The file %s does not exist!\" % arg)\n    else:\n        return arg", "response": "Check if arg is a valid file that already exists on the file system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if arg is a valid folder.", "response": "def is_valid_folder(parser, arg):\n    \"\"\"Check if arg is a valid file that already exists on the file system.\"\"\"\n    arg = os.path.abspath(arg)\n    if not os.path.isdir(arg):\n        parser.error(\"The folder %s does not exist!\" % arg)\n    else:\n        return arg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget project configuration as dictionary.", "response": "def get_project_configuration():\n    \"\"\"Get project configuration as dictionary.\"\"\"\n    home = os.path.expanduser(\"~\")\n    rcfile = os.path.join(home, \".hwrtrc\")\n    if not os.path.isfile(rcfile):\n        create_project_configuration(rcfile)\n    with open(rcfile, 'r') as ymlfile:\n        cfg = yaml.load(ymlfile)\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a project configuration file which contains a configuration that might make sense.", "response": "def create_project_configuration(filename):\n    \"\"\"Create a project configuration file which contains a configuration\n       that might make sense.\"\"\"\n    home = os.path.expanduser(\"~\")\n    project_root_folder = os.path.join(home, \"hwr-experiments\")\n    config = {'root': project_root_folder,\n              'nntoolkit': None,\n              'dropbox_app_key': None,\n              'dropbox_app_secret': None,\n              'dbconfig': os.path.join(home, \"hwrt-config/db.config.yml\"),\n              'data_analyzation_queue': [{'Creator': None}],\n              'worker_api_key': '1234567890abc',\n              'environment': 'development'}\n    with open(filename, 'w') as f:\n        yaml.dump(config, f, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_project_root():\n    cfg = get_project_configuration()\n    # At this point it can be sure that the configuration file exists\n    # Now make sure the project structure exists\n    for dirname in [\"raw-datasets\",\n                    \"preprocessed\",\n                    \"feature-files\",\n                    \"models\",\n                    \"reports\"]:\n        directory = os.path.join(cfg['root'], dirname)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n    raw_yml_path = pkg_resources.resource_filename('hwrt', 'misc/')\n\n    # TODO: How to check for updates if it already exists?\n    raw_data_dst = os.path.join(cfg['root'], \"raw-datasets/info.yml\")\n    if not os.path.isfile(raw_data_dst):\n        raw_yml_pkg_src = os.path.join(raw_yml_path, \"info.yml\")\n        shutil.copy(raw_yml_pkg_src, raw_data_dst)\n\n    # Make sure small-baseline folders exists\n    for dirname in [\"models/small-baseline\", \"feature-files/small-baseline\",\n                    \"preprocessed/small-baseline\"]:\n        directory = os.path.join(cfg['root'], dirname)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n    # Make sure small-baseline yml files exist\n    paths = [(\"preprocessed/small-baseline/\", \"preprocessing-small-info.yml\"),\n             (\"feature-files/small-baseline/\", \"feature-small-info.yml\"),\n             (\"models/small-baseline/\", \"model-small-info.yml\")]\n    for dest, src in paths:\n        raw_data_dst = os.path.join(cfg['root'], \"%s/info.yml\" % dest)\n        if not os.path.isfile(raw_data_dst):\n            raw_yml_pkg_src = os.path.join(raw_yml_path, src)\n            shutil.copy(raw_yml_pkg_src, raw_data_dst)\n\n    return cfg['root']", "response": "Get the project root folder as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets path to the folder where th HTML templates are located.", "response": "def get_template_folder():\n    \"\"\"Get path to the folder where th HTML templates are.\"\"\"\n    cfg = get_project_configuration()\n    if 'templates' not in cfg:\n        home = os.path.expanduser(\"~\")\n        rcfile = os.path.join(home, \".hwrtrc\")\n        cfg['templates'] = pkg_resources.resource_filename('hwrt',\n                                                           'templates/')\n        with open(rcfile, 'w') as f:\n            yaml.dump(cfg, f, default_flow_style=False)\n    return cfg['templates']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the absolute path to the database configuration file.", "response": "def get_database_config_file():\n    \"\"\"Get the absolute path to the database configuration file.\"\"\"\n    cfg = get_project_configuration()\n    if 'dbconfig' in cfg:\n        if os.path.isfile(cfg['dbconfig']):\n            return cfg['dbconfig']\n        else:\n            logging.info(\"File '%s' was not found. Adjust 'dbconfig' in your \"\n                         \"~/.hwrtrc file.\",\n                         cfg['dbconfig'])\n    else:\n        logging.info(\"No database connection file found. \"\n                     \"Specify 'dbconfig' in your ~/.hwrtrc file.\")\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets database configuration as dictionary.", "response": "def get_database_configuration():\n    \"\"\"Get database configuration as dictionary.\"\"\"\n    db_config = get_database_config_file()\n    if db_config is None:\n        return None\n    with open(db_config, 'r') as ymlfile:\n        cfg = yaml.load(ymlfile)\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a run. log file within folder.", "response": "def create_run_logfile(folder):\n    \"\"\"Create a 'run.log' within folder. This file contains the time of the\n       latest successful run.\n    \"\"\"\n    with open(os.path.join(folder, \"run.log\"), \"w\") as f:\n        datestring = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n        f.write(\"timestamp: '%s'\" % datestring)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choose_raw_dataset(currently=\"\"):\n    folder = os.path.join(get_project_root(), \"raw-datasets\")\n    files = [os.path.join(folder, name) for name in os.listdir(folder)\n             if name.endswith(\".pickle\")]\n    default = -1\n    for i, filename in enumerate(files):\n        if os.path.basename(currently) == os.path.basename(filename):\n            default = i\n        if i != default:\n            print(\"[%i]\\t%s\" % (i, os.path.basename(filename)))\n        else:\n            print(\"\\033[1m[%i]\\033[0m\\t%s\" % (i, os.path.basename(filename)))\n    i = input_int_default(\"Choose a dataset by number: \", default)\n    return files[i]", "response": "Let the user choose a raw dataset. Return the absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_readable_time(t):\n    ms = t % 1000\n    t -= ms\n    t /= 1000\n\n    s = t % 60\n    t -= s\n    t /= 60\n\n    minutes = t % 60\n    t -= minutes\n    t /= 60\n\n    if t != 0:\n        return \"%ih, %i minutes %is %ims\" % (t, minutes, s, ms)\n    elif minutes != 0:\n        return \"%i minutes %is %ims\" % (minutes, s, ms)\n    elif s != 0:\n        return \"%is %ims\" % (s, ms)\n    else:\n        return \"%ims\" % ms", "response": "Returns a string representation of the time in a sorted alphabetical order."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a path for a default value for the model.", "response": "def default_model():\n    \"\"\"Get a path for a default value for the model. Start searching in the\n    current directory.\"\"\"\n    project_root = get_project_root()\n    models_dir = os.path.join(project_root, \"models\")\n    curr_dir = os.getcwd()\n    if os.path.commonprefix([models_dir, curr_dir]) == models_dir and \\\n       curr_dir != models_dir:\n        latest_model = curr_dir\n    else:\n        latest_model = get_latest_folder(models_dir)\n    return latest_model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_adjusted_model_for_percentages(model_src, model_use):\n    # Copy model file\n    shutil.copyfile(model_src, model_use)\n    # Adjust model file\n    with open(model_src) as f:\n        content = f.read()\n    content = content.replace(\"logreg\", \"sigmoid\")\n    with open(model_use, \"w\") as f:\n        f.write(content)", "response": "Copy model_src to model_use and adjust it to get probabilities."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a HDF5 file for the current version of the language.", "response": "def create_hdf5(output_filename, feature_count, data):\n    \"\"\"\n    Create a HDF5 feature files.\n\n    Parameters\n    ----------\n    output_filename : string\n        name of the HDF5 file that will be created\n    feature_count : int\n        dimension of all features combined\n    data : list of tuples\n        list of (x, y) tuples, where x is the feature vector of dimension\n        ``feature_count`` and y is a label.\n    \"\"\"\n    import h5py\n    logging.info(\"Start creating of %s hdf file\", output_filename)\n    x = []\n    y = []\n    for features, label in data:\n        assert len(features) == feature_count, \\\n            \"Expected %i features, got %i features\" % \\\n            (feature_count, len(features))\n        x.append(features)\n        y.append(int(label))\n    Wfile = h5py.File(output_filename, 'w')\n    Wfile.create_dataset(\"data\", data=x, dtype='float32')\n    Wfile.create_dataset(\"labels\", data=y, dtype='int32')\n    Wfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of folders [ preprocessed feature - files model ].", "response": "def get_recognizer_folders(model_folder):\n    \"\"\"Get a list of folders [preprocessed, feature-files, model].\"\"\"\n    folders = []\n    folder = model_folder\n    while os.path.isdir(folder):\n        folders.append(folder)\n        # Get info.yml\n        with open(os.path.join(folder, \"info.yml\")) as ymlfile:\n            content = yaml.load(ymlfile)\n        folder = os.path.join(get_project_root(), content['data-source'])\n    return folders[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_model(model_file):\n    # Extract tar\n    with tarfile.open(model_file) as tar:\n        tarfolder = tempfile.mkdtemp()\n        tar.extractall(path=tarfolder)\n\n    from . import features\n    from . import preprocessing\n\n    # Get the preprocessing\n    with open(os.path.join(tarfolder, \"preprocessing.yml\"), 'r') as ymlfile:\n        preprocessing_description = yaml.load(ymlfile)\n    preprocessing_queue = preprocessing.get_preprocessing_queue(\n        preprocessing_description['queue'])\n\n    # Get the features\n    with open(os.path.join(tarfolder, \"features.yml\"), 'r') as ymlfile:\n        feature_description = yaml.load(ymlfile)\n    feature_str_list = feature_description['features']\n    feature_list = features.get_features(feature_str_list)\n\n    # Get the model\n    import nntoolkit.utils\n    model = nntoolkit.utils.get_model(model_file)\n\n    output_semantics_file = os.path.join(tarfolder, 'output_semantics.csv')\n    output_semantics = nntoolkit.utils.get_outputs(output_semantics_file)\n\n    # Cleanup\n    shutil.rmtree(tarfolder)\n\n    return (preprocessing_queue, feature_list, model, output_semantics)", "response": "Load a single model by its file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate a model for a single recording.", "response": "def evaluate_model_single_recording_preloaded(preprocessing_queue,\n                                              feature_list,\n                                              model,\n                                              output_semantics,\n                                              recording,\n                                              recording_id=None):\n    \"\"\"\n    Evaluate a model for a single recording, after everything has been loaded.\n\n    Parameters\n    ----------\n    preprocessing_queue : list\n        List of all preprocessing objects.\n    feature_list : list\n        List of all feature objects.\n    model : dict\n        Neural network model.\n    output_semantics : list\n        List that defines what an output means.\n    recording : string in JSON format\n        The handwritten recording in JSON format.\n    recording_id : int or None\n        For debugging purposes.\n    \"\"\"\n    handwriting = handwritten_data.HandwrittenData(recording,\n                                                   raw_data_id=recording_id)\n    handwriting.preprocessing(preprocessing_queue)\n    x = handwriting.feature_extraction(feature_list)\n    import nntoolkit.evaluate\n    model_output = nntoolkit.evaluate.get_model_output(model, [x])\n    return nntoolkit.evaluate.get_results(model_output, output_semantics)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_possible_splits(n):\n    get_bin = lambda x, n: x >= 0 and str(bin(x))[2:].zfill(n) or \"-\" + str(bin(x))[3:].zfill(n)\n    possible_splits = []\n    for i in range(2**(n - 1)):\n        possible_splits.append(get_bin(i, n - 1))\n    return possible_splits", "response": "Returns a list of possible split for the current n - 1 - digit set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate_model_single_recording_preloaded_multisymbol(preprocessing_queue,\n                                                          feature_list,\n                                                          model,\n                                                          output_semantics,\n                                                          recording):\n    \"\"\"\n    Evaluate a model for a single recording, after everything has been loaded.\n    Multiple symbols are recognized.\n\n    Parameters\n    ----------\n    preprocessing_queue : list\n        List of all preprocessing objects.\n    feature_list : list\n        List of all feature objects.\n    model : dict\n        Neural network model.\n    output_semantics :\n        List that defines what an output means.\n    recording :\n        The handwritten recording in JSON format.\n    \"\"\"\n    import json\n    import nntoolkit.evaluate\n    recording = json.loads(recording)\n    logging.info((\"## start (%i strokes)\" % len(recording)) + \"#\" * 80)\n    hypotheses = []  # [[{'score': 0.123, symbols: [123, 123]}]  # split0\n                     #  []] # Split i...\n    for split in get_possible_splits(len(recording)):\n        recording_segmented = segment_by_split(split, recording)\n        cur_split_results = []\n        for i, symbol in enumerate(recording_segmented):\n            handwriting = handwritten_data.HandwrittenData(json.dumps(symbol))\n            handwriting.preprocessing(preprocessing_queue)\n            x = handwriting.feature_extraction(feature_list)\n\n            model_output = nntoolkit.evaluate.get_model_output(model, [x])\n            results = nntoolkit.evaluate.get_results(model_output,\n                                                     output_semantics)\n            results = results[:10]\n            cur_split_results.append([el for el in results if el['probability'] >= 0.01])\n            # serve.show_results(results, n=10)\n\n        # Now that I have all symbols of this split, I have to get all\n        # combinations of the hypothesis\n        import itertools\n        for hyp in itertools.product(*cur_split_results):\n            hypotheses.append({'score': reduce(lambda x, y: x*y,\n                                               [s['probability'] for s in hyp])*len(hyp)/len(recording),\n                               'symbols': [s['semantics'] for s in hyp],\n                               'min_part': min([s['probability'] for s in hyp]),\n                               'segmentation': split})\n\n    hypotheses = sorted(hypotheses, key=lambda n: n['min_part'], reverse=True)[:10]\n    for i, hyp in enumerate(hypotheses):\n        if hyp['score'] > 0.001:\n            logging.info(\"%0.4f: %s (seg: %s)\", hyp['score'], hyp['symbols'], hyp['segmentation'])\n    return nntoolkit.evaluate.get_results(model_output, output_semantics)", "response": "Evaluate a model for a single recording after everything has been loaded."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evaluate_model_single_recording_multisymbol(model_file, recording):\n    (preprocessing_queue, feature_list, model,\n     output_semantics) = load_model(model_file)\n    logging.info(\"multiple symbol mode\")\n    logging.info(recording)\n    results = evaluate_model_single_recording_preloaded(preprocessing_queue,\n                                                        feature_list,\n                                                        model,\n                                                        output_semantics,\n                                                        recording)\n    return results", "response": "Evaluate a model for a single recording where possibly multiple symbols are."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate_model_single_recording(model_file, recording):\n    (preprocessing_queue, feature_list, model,\n     output_semantics) = load_model(model_file)\n    results = evaluate_model_single_recording_preloaded(preprocessing_queue,\n                                                        feature_list,\n                                                        model,\n                                                        output_semantics,\n                                                        recording)\n    return results", "response": "Evaluate a model for a single recording."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _evaluate_model_single_file(target_folder, test_file):\n    logging.info(\"Create running model...\")\n    model_src = get_latest_model(target_folder, \"model\")\n    model_file_pointer = tempfile.NamedTemporaryFile(delete=False)\n    model_use = model_file_pointer.name\n    model_file_pointer.close()\n    logging.info(\"Adjusted model is in %s.\", model_use)\n    create_adjusted_model_for_percentages(model_src, model_use)\n\n    # Run evaluation\n    project_root = get_project_root()\n    time_prefix = time.strftime(\"%Y-%m-%d-%H-%M\")\n    logging.info(\"Evaluate '%s' with '%s'...\", model_src, test_file)\n    logfilefolder = os.path.join(project_root, \"logs/\")\n    if not os.path.exists(logfilefolder):\n        os.makedirs(logfilefolder)\n    logfile = os.path.join(project_root,\n                           \"logs/%s-error-evaluation.log\" %\n                           time_prefix)\n    with open(logfile, \"w\") as log, open(model_use, \"r\") as modl_src_p:\n        p = subprocess.Popen([get_nntoolkit(), 'run',\n                              '--batch-size', '1',\n                              '-f%0.4f', test_file],\n                             stdin=modl_src_p,\n                             stdout=log)\n        ret = p.wait()\n        if ret != 0:\n            logging.error(\"nntoolkit finished with ret code %s\",\n                          str(ret))\n            sys.exit()\n    return (logfile, model_use)", "response": "Evaluate a model for a single recording."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating model for a single recording.", "response": "def evaluate_model(recording, model_folder, verbose=False):\n    \"\"\"Evaluate model for a single recording.\"\"\"\n    from . import preprocess_dataset\n    from . import features\n\n    for target_folder in get_recognizer_folders(model_folder):\n        # The source is later than the target. That means we need to\n        # refresh the target\n        if \"preprocessed\" in target_folder:\n            logging.info(\"Start applying preprocessing methods...\")\n            t = target_folder\n            _, _, preprocessing_queue = preprocess_dataset.get_parameters(t)\n            handwriting = handwritten_data.HandwrittenData(recording)\n            if verbose:\n                handwriting.show()\n            handwriting.preprocessing(preprocessing_queue)\n            if verbose:\n                logging.debug(\"After preprocessing: %s\",\n                              handwriting.get_sorted_pointlist())\n                handwriting.show()\n        elif \"feature-files\" in target_folder:\n            logging.info(\"Create feature file...\")\n            infofile_path = os.path.join(target_folder, \"info.yml\")\n            with open(infofile_path, 'r') as ymlfile:\n                feature_description = yaml.load(ymlfile)\n            feature_str_list = feature_description['features']\n            feature_list = features.get_features(feature_str_list)\n            feature_count = sum(map(lambda n: n.get_dimension(),\n                                    feature_list))\n            x = handwriting.feature_extraction(feature_list)\n\n            # Create hdf5\n            _, output_filename = tempfile.mkstemp(suffix='.hdf5', text=True)\n            create_hdf5(output_filename, feature_count, [(x, 0)])\n        elif \"model\" in target_folder:\n            logfile, model_use = _evaluate_model_single_file(target_folder,\n                                                             output_filename)\n            return logfile\n        else:\n            logging.info(\"'%s' not found\", target_folder)\n    os.remove(output_filename)\n    os.remove(model_use)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary that maps indices to LaTeX commands.", "response": "def get_index2latex(model_description):\n    \"\"\"\n    Get a dictionary that maps indices to LaTeX commands.\n\n    Parameters\n    ----------\n    model_description : string\n        A model description file that points to a feature folder where an\n        `index2formula_id.csv` has to be.\n\n    Returns\n    -------\n    dictionary :\n        Maps indices to LaTeX commands\n    \"\"\"\n    index2latex = {}\n    translation_csv = os.path.join(get_project_root(),\n                                   model_description[\"data-source\"],\n                                   \"index2formula_id.csv\")\n    with open(translation_csv) as csvfile:\n        csvreader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n        for row in csvreader:\n            index2latex[int(row['index'])] = row['latex']\n    return index2latex"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary that maps indices to a list of data.", "response": "def get_index2data(model_description):\n    \"\"\"\n    Get a dictionary that maps indices to a list of (1) the id in the\n    hwrt symbol database (2) the latex command (3) the unicode code point\n    (4) a font family and (5) a font style.\n\n    Parameters\n    ----------\n    model_description : string\n        A model description file that points to a feature folder where an\n        ``index2formula_id.csv`` has to be.\n\n    Returns\n    -------\n    dictionary\n        that maps indices to lists of data\n\n    Notes\n    -----\n    This command need a database connection.\n    \"\"\"\n    index2latex = {}\n    translation_csv = os.path.join(get_project_root(),\n                                   model_description[\"data-source\"],\n                                   \"index2formula_id.csv\")\n    with open(translation_csv) as csvfile:\n        csvreader = csv.DictReader(csvfile, delimiter=',', quotechar='\"')\n        for row in csvreader:\n            database_id = int(row['formula_id'])\n            online_data = get_online_symbol_data(database_id)\n            latex = online_data['formula_in_latex']\n            unicode_code_point = online_data['unicode_dec']\n            font = online_data['font']\n            font_style = online_data['font_style']\n            index2latex[int(row['index'])] = [database_id,\n                                              latex,\n                                              unicode_code_point,\n                                              font,\n                                              font_style]\n    return index2latex"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_online_symbol_data(database_id):\n    import pymysql\n    import pymysql.cursors\n    cfg = get_database_configuration()\n    mysql = cfg['mysql_online']\n    connection = pymysql.connect(host=mysql['host'],\n                                 user=mysql['user'],\n                                 passwd=mysql['passwd'],\n                                 db=mysql['db'],\n                                 cursorclass=pymysql.cursors.DictCursor)\n    cursor = connection.cursor()\n    sql = (\"SELECT `id`, `formula_in_latex`, `unicode_dec`, `font`, \"\n           \"`font_style` FROM  `wm_formula` WHERE  `id` =%i\") % database_id\n    cursor.execute(sql)\n    datasets = cursor.fetchall()\n    if len(datasets) == 1:\n        return datasets[0]\n    else:\n        return None", "response": "Get online symbol data from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclassifying a single recording LaTeX by using the raw data.", "response": "def classify_single_recording(raw_data_json, model_folder, verbose=False):\n    \"\"\"\n    Get the classification as a list of tuples. The first value is the LaTeX\n    code, the second value is the probability.\n    \"\"\"\n    evaluation_file = evaluate_model(raw_data_json, model_folder, verbose)\n    with open(os.path.join(model_folder, \"info.yml\")) as ymlfile:\n        model_description = yaml.load(ymlfile)\n\n    index2latex = get_index2latex(model_description)\n\n    # Map line to probabilites for LaTeX commands\n    with open(evaluation_file) as f:\n        probabilities = f.read()\n    probabilities = map(float, probabilities.split(\" \"))\n    results = []\n    for index, probability in enumerate(probabilities):\n        results.append((index2latex[index], probability))\n    results = sorted(results, key=lambda n: n[1], reverse=True)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_objectlist(description, config_key, module):\n    object_list = []\n    for feature in description:\n        for feat, params in feature.items():\n            feat = get_class(feat, config_key, module)\n            if params is None:\n                object_list.append(feat())\n            else:\n                parameters = {}\n                for dicts in params:\n                    for param_name, param_value in dicts.items():\n                        parameters[param_name] = param_value\n                object_list.append(feat(**parameters))  # pylint: disable=W0142\n    return object_list", "response": "Take a description and return a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the class by its name as a string.", "response": "def get_class(name, config_key, module):\n    \"\"\"Get the class by its name as a string.\"\"\"\n    clsmembers = inspect.getmembers(module, inspect.isclass)\n    for string_name, act_class in clsmembers:\n        if string_name == name:\n            return act_class\n\n    # Check if the user has specified a plugin and if the class is in there\n    cfg = get_project_configuration()\n    if config_key in cfg:\n        modname = os.path.splitext(os.path.basename(cfg[config_key]))[0]\n        if os.path.isfile(cfg[config_key]):\n            usermodule = imp.load_source(modname, cfg[config_key])\n            clsmembers = inspect.getmembers(usermodule, inspect.isclass)\n            for string_name, act_class in clsmembers:\n                if string_name == name:\n                    return act_class\n        else:\n            logging.warning(\"File '%s' does not exist. Adjust ~/.hwrtrc.\",\n                            cfg['data_analyzation_plugins'])\n\n    logging.debug(\"Unknown class '%s'.\", name)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_mysql_cfg():\n    environment = get_project_configuration()['environment']\n    cfg = get_database_configuration()\n    if environment == 'production':\n        mysql = cfg['mysql_online']\n    else:\n        mysql = cfg['mysql_dev']\n    return mysql", "response": "Get the appropriate MySQL configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef softmax(w, t=1.0):\n    w = [Decimal(el) for el in w]\n    e = numpy.exp(numpy.array(w) / Decimal(t))\n    dist = e / numpy.sum(e)\n    return dist", "response": "Calculate the softmax of a list of numbers w."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_beam_cache_directory():\n    home = os.path.expanduser(\"~\")\n    cache_dir = os.path.join(home, '.hwrt-beam-cache')\n    if not os.path.exists(cache_dir):\n        os.makedirs(cache_dir)\n    return cache_dir", "response": "Returns a directory where pickled Beam Data can be stored."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_beam(secret_uuid):\n    beam_dir = get_beam_cache_directory()\n    beam_filename = os.path.join(beam_dir, secret_uuid)\n    if os.path.isfile(beam_filename):\n        with open(beam_filename, 'rb') as handle:\n            beam = pickle.load(handle)\n        return beam\n    else:\n        return None", "response": "Get a beam from the session with secret_uuid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if uuid_to_test is a valid UUID.", "response": "def is_valid_uuid(uuid_to_test, version=4):\n    \"\"\"\n    Check if uuid_to_test is a valid UUID.\n\n    Parameters\n    ----------\n    uuid_to_test : str\n    version : {1, 2, 3, 4}\n\n    Returns\n    -------\n    `True` if uuid_to_test is a valid UUID, otherwise `False`.\n\n    Examples\n    --------\n    >>> is_valid_uuid('c9bf9e57-1685-4c89-bafb-ff5af830be8a')\n    True\n    >>> is_valid_uuid('c9bf9e58')\n    False\n    \"\"\"\n    try:\n        uuid_obj = UUID(uuid_to_test, version=version)\n    except ValueError:\n        return False\n\n    return str(uuid_obj) == uuid_to_test"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking the table symmetric where the lower left part of the matrix is the reverse probability VOLATILE", "response": "def prepare_table(table):\n    \"\"\"Make the table 'symmetric' where the lower left part of the matrix is\n       the reverse probability\n    \"\"\"\n    n = len(table)\n    for i, row in enumerate(table):\n        assert len(row) == n\n        for j, el in enumerate(row):\n            if i == j:\n                table[i][i] = 0.0\n            elif i > j:\n                table[i][j] = 1-table[j][i]\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clusters(l, K):\n    if l:\n        prev = None\n        for t in clusters(l[1:], K):\n            tup = sorted(t)\n            if tup != prev:\n                prev = tup\n                for i in range(K):\n                    yield tup[:i] + [[l[0]] + tup[i], ] + tup[i+1:]\n    else:\n        yield [[] for _ in range(K)]", "response": "Partition list l in K partitions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npartition list l in K partitions without empty parts.", "response": "def neclusters(l, K):\n    \"\"\"Partition list ``l`` in ``K`` partitions, without empty parts.\n\n    >>> l = [0, 1, 2]\n    >>> list(neclusters(l, 2))\n    [[[0, 1], [2]], [[1], [0, 2]], [[0], [1, 2]]]\n    >>> list(neclusters(l, 1))\n    [[[0, 1, 2]]]\n    \"\"\"\n    for c in clusters(l, K):\n        if all(x for x in c):\n            yield c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_segmentations(l):\n    for K in range(1, len(l)+1):\n        gen = neclusters(l, K)\n        for el in gen:\n            yield el", "response": "Get all segmentations of a list l."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the index of a stroke in a segmentation.", "response": "def find_index(segmentation, stroke_id):\n    \"\"\"\n    >>> find_index([[0, 1, 2], [3, 4], [5, 6, 7]], 0)\n    0\n    >>> find_index([[0, 1, 2], [3, 4], [5, 6, 7]], 1)\n    0\n    >>> find_index([[0, 1, 2], [3, 4], [5, 6, 7]], 5)\n    2\n    >>> find_index([[0, 1, 2], [3, 4], [5, 6, 7]], 6)\n    2\n    \"\"\"\n    for i, symbol in enumerate(segmentation):\n        for sid in symbol:\n            if sid == stroke_id:\n                return i\n    return -1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests if two states are in the same symbol given the .", "response": "def q(segmentation, s1, s2):\n    \"\"\"Test if ``s1`` and ``s2`` are in the same symbol, given the\n    ``segmentation``.\n    \"\"\"\n    index1 = find_index(segmentation, s1)\n    index2 = find_index(segmentation, s2)\n    return index1 == index2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef score_segmentation(segmentation, table):\n    stroke_nr = sum(1 for symbol in segmentation for stroke in symbol)\n    score = 1\n    for i in range(stroke_nr):\n        for j in range(i+1, stroke_nr):\n            qval = q(segmentation, i, j)\n            if qval:\n                score *= table[i][j]\n            else:\n                score *= table[j][i]\n    return score", "response": "Get the score of a segmentation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_top_segmentations(table, n):\n    stroke_count = list(range(len(table)))\n    topf = TopFinder(n)\n    for curr_segmentation in all_segmentations(stroke_count):\n        curr_seg_score = score_segmentation(curr_segmentation, table)\n        topf.push(curr_segmentation, curr_seg_score)\n\n    for el, score in topf:\n        yield [normalize_segmentation(el), score]", "response": "Returns a generator that yields all the top segmentations in the given table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push(self, element, value):\n        insert_pos = 0\n        for index, el in enumerate(self.tops):\n            if not self.find_min and el[1] >= value:\n                insert_pos = index+1\n            elif self.find_min and el[1] <= value:\n                insert_pos = index+1\n        self.tops.insert(insert_pos, [element, value])\n        self.tops = self.tops[:self.n]", "response": "Push an element into the datastrucutre together with its value\n           and only save it if it currently is one of the top n elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize a numpy array to a compressed base64 string", "response": "def _array2cstr(arr):\n    \"\"\" Serializes a numpy array to a compressed base64 string \"\"\"\n    out = StringIO()\n    np.save(out, arr)\n    return b64encode(out.getvalue())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _str2array(d):\n    if type(d) == list:\n        return np.asarray([_str2array(s) for s in d])\n    ins = StringIO(d)\n    return np.loadtxt(ins)", "response": "Reconstructs a numpy array from a plain - text string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_output_semantics(model_folder, outputs):\n    with open('output_semantics.csv', 'wb') as csvfile:\n        model_description_file = os.path.join(model_folder, \"info.yml\")\n        with open(model_description_file, 'r') as ymlfile:\n            model_description = yaml.load(ymlfile)\n\n        logging.info(\"Start fetching translation dict...\")\n        translation_dict = utils.get_index2data(model_description)\n        spamwriter = csv.writer(csvfile, delimiter=';',\n                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n        for output_index in range(outputs):\n            if output_index in translation_dict:\n                # Add more information:\n                # 1. ID in my system\n                # 2. latex\n                # 3. unicode code point\n                # 4. font\n                # 5. font style\n                spamwriter.writerow(translation_dict[output_index])\n            else:\n                print(\"No data for %i.\" % output_index)\n                spamwriter.writerow([\"output %i\" % output_index])", "response": "Create a output_semantics. csv file which contains information what the output of the single output neurons mean."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(model_folder):\n    a = yaml.load(open(utils.get_latest_in_folder(model_folder, \".json\")))\n\n    layers = []\n    filenames = [\"model.yml\", \"input_semantics.csv\", \"output_semantics.csv\",\n                 \"preprocessing.yml\", \"features.yml\"]\n\n    # Create input_semantics.csv\n    inputs = a['layers'][0]['_props']['n_visible']\n    with open('input_semantics.csv', 'wb') as csvfile:\n        spamwriter = csv.writer(csvfile, delimiter=';',\n                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n        for row in range(inputs):\n            spamwriter.writerow([\"inputs %i\" % row])\n\n    # Create output_semantics.csv\n    outputs = a['layers'][-1]['_props']['n_hidden']\n    create_output_semantics(model_folder, outputs)\n\n    # Write layers\n    for layer_index, layer in enumerate(a['layers']):\n        W = _as_ndarray(layer['params']['W'])\n        Wfile = h5py.File('W%i.hdf5' % layer_index, 'w')\n        Wfile.create_dataset(Wfile.id.name, data=W)\n        Wfile.close()\n\n        b = _as_ndarray(layer['params']['b'])\n        bfile = h5py.File('b%i.hdf5' % layer_index, 'w')\n        bfile.create_dataset(bfile.id.name, data=b)\n        bfile.close()\n\n        activation = layer['_props']['activation']\n        activation = activation.replace('sigmoid', 'Sigmoid')\n        activation = activation.replace('softmax', 'Softmax')\n        layers.append({'W': {'size': list(W.shape),\n                             'filename': 'W%i.hdf5' % layer_index},\n                       'b': {'size': list(b.shape),\n                             'filename': 'b%i.hdf5' % layer_index},\n                       'activation': activation})\n        filenames.append('W%i.hdf5' % layer_index)\n        filenames.append('b%i.hdf5' % layer_index)\n\n    model = {'type': 'mlp', 'layers': layers}\n\n    with open(\"model.yml\", 'w') as f:\n        yaml.dump(model, f, default_flow_style=False)\n\n    logging.info(\"Get preprocessing.yml\")\n    # Get model folder\n    model_description_file = os.path.join(model_folder, \"info.yml\")\n    with open(model_description_file, 'r') as ymlfile:\n        model_description = yaml.load(ymlfile)\n\n    # Get feature folder\n    feature_description_file = os.path.join(utils.get_project_root(),\n                                            model_description[\"data-source\"],\n                                            \"info.yml\")\n    with open(feature_description_file, 'r') as ymlfile:\n        feature_description = yaml.load(ymlfile)\n\n    with open(\"features.yml\", 'w') as f:\n        yaml.dump(feature_description, f, default_flow_style=False)\n\n    # Get preprocessing folder\n    preprocessing_description_file = os.path.join(utils.get_project_root(),\n                                                  feature_description[\"data-source\"],\n                                                  \"info.yml\")\n    with open(preprocessing_description_file, 'r') as ymlfile:\n        preprocessing_description = yaml.load(ymlfile)\n\n    with open(\"preprocessing.yml\", 'w') as f:\n        yaml.dump(preprocessing_description, f, default_flow_style=False)\n\n    with tarfile.open(\"model.tar\", \"w:\") as tar:\n        for name in filenames:\n            tar.add(name)\n\n    # Remove temporary files which are now in tar file\n    for filename in filenames:\n        os.remove(filename)", "response": "Main function for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an xml ElementTree to a dictionary.", "response": "def elementtree_to_dict(element):\n    \"\"\"Convert an xml ElementTree to a dictionary.\"\"\"\n    d = dict()\n    if hasattr(element, 'text') and element.text is not None:\n        d['text'] = element.text\n\n    d.update(element.items())  # element's attributes\n\n    for c in list(element):  # element's children\n        if c.tag not in d:\n            d[c.tag] = elementtree_to_dict(c)\n        # an element with the same tag was already in the dict\n        else:\n            # if it's not a list already, convert it to a list and append\n            if not isinstance(d[c.tag], list):\n                d[c.tag] = [d[c.tag], elementtree_to_dict(c)]\n           # append to the list\n            else:\n                d[c.tag].append(elementtree_to_dict(c))\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip suffix from the end of text if text has that suffix.", "response": "def strip_end(text, suffix):\n    \"\"\"Strip `suffix` from the end of `text` if `text` has that suffix.\"\"\"\n    if not text.endswith(suffix):\n        return text\n    return text[:len(text)-len(suffix)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets features from a list of dictionaries", "response": "def get_data_multiplication_queue(model_description_multiply):\n    \"\"\"Get features from a list of dictionaries\n\n    >>> l = [{'Multiply': [{'nr': 1}]}, \\\n             {'Rotate': [{'minimum':-30}, {'maximum': 30}, {'step': 5}]}]\n    >>> get_data_multiplication_queue(l)\n    [Multiply (1 times), Rotate (-30.00, 30.00, 5.00)]\n    \"\"\"\n    return utils.get_objectlist(model_description_multiply,\n                                config_key='data_multiplication',\n                                module=sys.modules[__name__])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef formula_to_dbid(formula_str, backslash_fix=False):\n    global __formula_to_dbid_cache\n    if __formula_to_dbid_cache is None:\n        mysql = utils.get_mysql_cfg()\n        connection = pymysql.connect(host=mysql['host'],\n                                     user=mysql['user'],\n                                     passwd=mysql['passwd'],\n                                     db=mysql['db'],\n                                     charset='utf8mb4',\n                                     cursorclass=pymysql.cursors.DictCursor)\n        cursor = connection.cursor()\n\n        # Get all formulas that should get examined\n        sql = (\"SELECT `id`, `formula_in_latex` FROM `wm_formula` \")\n        cursor.execute(sql)\n        formulas = cursor.fetchall()\n        __formula_to_dbid_cache = {}\n        for fm in formulas:\n            __formula_to_dbid_cache[fm['formula_in_latex']] = fm['id']\n    if formula_str in __formula_to_dbid_cache:\n        return __formula_to_dbid_cache[formula_str]\n    elif backslash_fix and ('\\\\%s' % formula_str) in __formula_to_dbid_cache:\n        return __formula_to_dbid_cache['\\\\%s' % formula_str]\n    else:\n        logging.info(\"Symbol '%s' was not found. Add it to write-math.com.\",\n                     formula_str)\n        mysql = utils.get_mysql_cfg()\n        connection = pymysql.connect(host=mysql['host'],\n                                     user=mysql['user'],\n                                     passwd=mysql['passwd'],\n                                     db=mysql['db'],\n                                     charset='utf8mb4',\n                                     cursorclass=pymysql.cursors.DictCursor)\n        cursor = connection.cursor()\n        sql = (\"INSERT INTO `wm_formula` (`user_id`, `formula_name`, \"\n               \"`formula_in_latex`, \"\n               \"`mode`, `package`) VALUES (\"\n               \"'10', %s, %s, 'bothmodes', NULL);\")\n        if len(formula_str) < 20:\n            logging.info(\"Insert formula %s.\", formula_str)\n        cursor.execute(sql, (formula_str, formula_str))\n        connection.commit()\n        __formula_to_dbid_cache[formula_str] = connection.insert_id()\n        return __formula_to_dbid_cache[formula_str]", "response": "Converts a LaTeX formula to the database index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getuserid(username, copyright_str):\n    global username2id\n    if username not in username2id:\n        mysql = utils.get_mysql_cfg()\n        connection = pymysql.connect(host=mysql['host'],\n                                     user=mysql['user'],\n                                     passwd=mysql['passwd'],\n                                     db=mysql['db'],\n                                     charset='utf8mb4',\n                                     cursorclass=pymysql.cursors.DictCursor)\n        cursor = connection.cursor()\n\n        sql = (\"INSERT IGNORE INTO  `wm_users` (\"\n               \"`display_name` , \"\n               \"`password` ,\"\n               \"`account_type` ,\"\n               \"`confirmation_code` ,\"\n               \"`status` ,\"\n               \"`description`\"\n               \") \"\n               \"VALUES (\"\n               \"%s, '',  'Regular User',  '',  'activated', %s\"\n               \");\")\n        cursor.execute(sql, (username, copyright_str))\n        connection.commit()\n\n        # Get the id\n        try:\n            sql = (\"SELECT  `id` FROM  `wm_users` \"\n                   \"WHERE  `display_name` =  %s LIMIT 1\")\n            cursor.execute(sql, username)\n            uid = cursor.fetchone()['id']\n        except Exception as inst:\n            logging.debug(\"username not found: %s\", username)\n            print(inst)\n        # logging.info(\"%s: %s\", username, uid)\n        username2id[username] = uid\n    return username2id[username]", "response": "Get the ID of the user with username from write - math. com."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert recording hw into database.", "response": "def insert_recording(hw):\n    \"\"\"Insert recording `hw` into database.\"\"\"\n    mysql = utils.get_mysql_cfg()\n    connection = pymysql.connect(host=mysql['host'],\n                                 user=mysql['user'],\n                                 passwd=mysql['passwd'],\n                                 db=mysql['db'],\n                                 charset='utf8mb4',\n                                 cursorclass=pymysql.cursors.DictCursor)\n    try:\n        cursor = connection.cursor()\n        sql = (\"INSERT INTO `wm_raw_draw_data` (\"\n               \"`user_id`, \"\n               \"`data`, \"\n               \"`md5data`, \"\n               \"`creation_date`, \"\n               \"`device_type`, \"\n               \"`accepted_formula_id`, \"\n               \"`secret`, \"\n               \"`ip`, \"\n               \"`segmentation`, \"\n               \"`internal_id`, \"\n               \"`description` \"\n               \") VALUES (%s, %s, MD5(data), \"\n               \"%s, %s, %s, %s, %s, %s, %s, %s);\")\n        data = (hw.user_id,\n                hw.raw_data_json,\n                getattr(hw, 'creation_date', None),\n                getattr(hw, 'device_type', ''),\n                getattr(hw, 'formula_id', None),\n                getattr(hw, 'secret', ''),\n                getattr(hw, 'ip', None),\n                str(getattr(hw, 'segmentation', '')),\n                getattr(hw, 'internal_id', ''),\n                getattr(hw, 'description', ''))\n        cursor.execute(sql, data)\n        connection.commit()\n        for symbol_id, strokes in zip(hw.symbol_stream, hw.segmentation):\n            insert_symbol_mapping(cursor.lastrowid,\n                                  symbol_id,\n                                  hw.user_id,\n                                  strokes)\n        logging.info(\"Insert raw data.\")\n    except pymysql.err.IntegrityError as e:\n        print(\"Error: {} (can probably be ignored)\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_symbol_mapping(raw_data_id, symbol_id, user_id, strokes):\n    mysql = utils.get_mysql_cfg()\n    connection = pymysql.connect(host=mysql['host'],\n                                 user=mysql['user'],\n                                 passwd=mysql['passwd'],\n                                 db=mysql['db'],\n                                 charset='utf8mb4',\n                                 cursorclass=pymysql.cursors.DictCursor)\n    cursor = connection.cursor()\n    sql = (\"INSERT INTO `wm_partial_answer` \"\n           \"(`recording_id`, `symbol_id`, `strokes`, `user_id`, \"\n           \"`is_accepted`) \"\n           \"VALUES (%s, %s, %s, %s, 1);\")\n    data = (raw_data_id,\n            symbol_id,\n            \",\".join([str(stroke) for stroke in strokes]),\n            user_id)\n    cursor.execute(sql, data)\n    connection.commit()", "response": "Insert data into wm_strokes_to_symbol."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_label(label, replace_by_similar=True):\n    bad_names = ['celsius', 'degree', 'ohm', 'venus', 'mars', 'astrosun',\n                 'fullmoon', 'leftmoon', 'female', 'male', 'checked',\n                 'diameter', 'sun', 'Bowtie', 'sqrt',\n                 'cong', 'copyright', 'dag', 'parr', 'notin', 'dotsc',\n                 'mathds', 'mathfrak']\n    if any(label[1:].startswith(bad) for bad in bad_names):\n        if label == '\\\\dag' and replace_by_similar:\n            return '\\\\dagger'\n        elif label == '\\\\diameter' and replace_by_similar:\n            return '\\\\O'\n        return label[1:]\n    else:\n        return label", "response": "Filter out any label that is not part of LaTeX naming."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nanalyze a single feature and store the results in two files.", "response": "def analyze_feature(raw_datasets, feature, basename=\"aspect_ratios\"):\n    \"\"\"\n    Apply ``feature`` to all recordings in ``raw_datasets``. Store the results\n    in two files. One file stores the raw result, the other one groups the\n    results by symbols and stores the mean, standard deviation and the name of\n    the symbol as a csv file.\n\n    Parameters\n    ----------\n    raw_datasets : List of dictionaries\n        Each dictionary is a raw_dataset.\n    feature : An instance of the feature class type\n        The `feature` which gets analyzed on `raw_datasets`.\n    basename : string\n        Name for the file in which the data gets written.\n    \"\"\"\n\n    # Prepare files\n    csv_file = dam.prepare_file(basename + '.csv')\n    raw_file = dam.prepare_file(basename + '.raw')\n\n    csv_file = open(csv_file, 'a')\n    raw_file = open(raw_file, 'a')\n\n    csv_file.write(\"label,mean,std\\n\")  # Write header\n    raw_file.write(\"latex,raw_data_id,value\\n\")  # Write header\n\n    print_data = []\n    for _, datasets in dam.sort_by_formula_id(raw_datasets).items():\n        values = []\n        for data in datasets:\n            value = feature(data)[0]\n            values.append(value)\n            raw_file.write(\"%s,%i,%0.2f\\n\" % (datasets[0].formula_in_latex,\n                                              data.raw_data_id,\n                                              value))\n        label = filter_label(datasets[0].formula_in_latex)\n        print_data.append((label, numpy.mean(values), numpy.std(values)))\n\n    # Sort the data by highest mean, descending\n    print_data = sorted(print_data, key=lambda n: n[1], reverse=True)\n\n    # Write data to file\n    for label, mean, std in print_data:\n        csv_file.write(\"%s,%0.2f,%0.2f\\n\" % (label, mean, std))\n    csv_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the creation of the wanted metric.", "response": "def main(handwriting_datasets_file, analyze_features):\n    \"\"\"Start the creation of the wanted metric.\"\"\"\n    # Load from pickled file\n    logging.info(\"Start loading data '%s' ...\", handwriting_datasets_file)\n    loaded = pickle.load(open(handwriting_datasets_file))\n    raw_datasets = loaded['handwriting_datasets']\n    logging.info(\"%i datasets loaded.\", len(raw_datasets))\n    logging.info(\"Start analyzing...\")\n\n    if analyze_features:\n        featurelist = [(features.AspectRatio(), \"aspect_ratio.csv\"),\n                       (features.ReCurvature(1), \"re_curvature.csv\"),\n                       (features.Height(), \"height.csv\"),\n                       (features.Width(), \"width.csv\"),\n                       (features.Time(), \"time.csv\"),\n                       (features.Ink(), \"ink.csv\"),\n                       (features.StrokeCount(), \"stroke-count.csv\")]\n        for feat, filename in featurelist:\n            logging.info(\"create %s...\", filename)\n            analyze_feature(raw_datasets, feat, filename)\n\n    # Analyze everything specified in configuration\n    cfg = utils.get_project_configuration()\n    if 'data_analyzation_queue' in cfg:\n        metrics = dam.get_metrics(cfg['data_analyzation_queue'])\n        for metric in metrics:\n            logging.info(\"Start metric %s...\", str(metric))\n            metric(raw_datasets)\n    else:\n        logging.info(\"No 'data_analyzation_queue' in ~/.hwrtrc\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_parser():\n    project_root = utils.get_project_root()\n\n    # Get latest (raw) dataset\n    dataset_folder = os.path.join(project_root, \"raw-datasets\")\n    latest_dataset = utils.get_latest_in_folder(dataset_folder, \"raw.pickle\")\n\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n    parser = ArgumentParser(description=__doc__,\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"-d\", \"--handwriting_datasets\",\n                        dest=\"handwriting_datasets\",\n                        help=\"where are the pickled handwriting_datasets?\",\n                        metavar=\"FILE\",\n                        type=lambda x: utils.is_valid_file(parser, x),\n                        default=latest_dataset)\n    parser.add_argument(\"-f\", \"--features\",\n                        dest=\"analyze_features\",\n                        help=\"analyze features\",\n                        action=\"store_true\",\n                        default=False)\n    return parser", "response": "Return the parser object for this script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_matching_braces(latex):\n    if latex.startswith('{') and latex.endswith('}'):\n        opened = 1\n        matches = True\n        for char in latex[1:-1]:\n            if char == '{':\n                opened += 1\n            elif char == '}':\n                opened -= 1\n            if opened == 0:\n                matches = False\n        if matches:\n            latex = latex[1:-1]\n    return latex", "response": "Removes all matching braces from a string latex."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the LaTeX string from a file by the. kinetic filename.", "response": "def get_latex(ink_filename):\n    \"\"\"Get the LaTeX string from a file by the *.ink filename.\"\"\"\n    tex_file = os.path.splitext(ink_filename)[0] + \".tex\"\n    with open(tex_file) as f:\n        tex_content = f.read().strip()\n    pattern = re.compile(r\"\\\\begin\\{displaymath\\}(.*?)\\\\end\\{displaymath\\}\",\n                         re.DOTALL)\n    matches = pattern.findall(tex_content)\n\n    if len(matches) == 0:\n        pattern = re.compile(r\"$$(.*?)$$\",\n                             re.DOTALL)\n        matches = pattern.findall(tex_content)\n\n    if len(matches) != 1:\n        raise Exception(\"%s: Found not one match, but %i: %s\" %\n                        (ink_filename, len(matches), matches))\n    formula_in_latex = matches[0].strip()\n    formula_in_latex = remove_matching_braces(formula_in_latex)\n\n    # repl = []\n    # for letter in string.letters:\n    #     repl.append(('\\mbox{%s}' % letter, letter))\n    # for search, replace in repl:\n    #     formula_in_latex = formula_in_latex.replace(search, replace)\n    return formula_in_latex"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_segmentation(recording, annotations, internal_id=None):\n    global missing_stroke_segmentation, double_segmentation\n    segmentation = []\n    symbol_stream = []\n    needed = list(range(len(recording)))\n    annotations = filter(lambda n: n.startswith('SYMBOL '), annotations)\n    for line in annotations:\n        tmp = line.split(\"<\")[1]\n        tmp, symbol_string = tmp.split(\">\")\n        symbol_string = symbol_string.strip()\n        strokes = [int(stroke) for stroke in tmp.split(\",\")\n                   if int(stroke) < len(recording)]\n        for el in strokes:\n            if el not in needed:\n                double_segmentation.append(internal_id)\n                strokes.remove(el)\n                logging.debug(\"invalid segmentation by annotation: %s\",\n                              annotations)\n            else:\n                needed.remove(el)\n        segmentation.append(strokes)\n        symbol_stream.append(datasets.formula_to_dbid(mathbrush_formula_fix(symbol_string), True))\n\n    if len(needed) > 0:\n        # hw = handwritten_data.HandwrittenData(json.dumps(recording))\n        # hw.show()\n        missing_stroke_segmentation.append(internal_id)\n        segmentation.append(needed)\n    return segmentation, symbol_stream", "response": "Returns segmentation and symbol stream for a given recording and annotations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a SCG INK file and returns a HandwrittenData object.", "response": "def parse_scg_ink_file(filename):\n    \"\"\"Parse a SCG INK file.\n\n    Parameters\n    ----------\n    filename : string\n        The path to a SCG INK file.\n\n    Returns\n    -------\n    HandwrittenData\n        The recording as a HandwrittenData object.\n    \"\"\"\n    stroke_count = 0\n    stroke_point_count = -1\n    recording = []\n    current_stroke = []\n    time = 0\n    got_annotations = False\n    annotations = []\n\n    formula_in_latex = get_latex(filename)\n\n    with open(filename) as f:\n        contents = f.read().strip()\n    lines = contents.split(\"\\n\")\n    for i, line in enumerate(lines):\n        line = line.strip()\n        if i == 0 and line != 'SCG_INK':\n            raise ValueError((\"%s: SCG Ink files have to start with 'SCG_INK'.\"\n                              \" The file started with %s.\") %\n                             (filename, line))\n        elif i == 1:\n            try:\n                stroke_count = int(line)\n            except ValueError:\n                raise ValueError((\"%s: Second line has to be the number of \"\n                                  \"strokeswhich has to be an integer, but \"\n                                  \"was '%s'\") % (filename, line))\n            if stroke_count <= 0:\n                # os.remove(filename)\n                # return []\n                raise ValueError((\"%s: Stroke count was %i, but should be \"\n                                  \"> 0.\") % (filename, stroke_count))\n        elif i == 2:\n            try:\n                stroke_point_count = int(line)\n            except ValueError:\n                raise ValueError(\"%s: Third line has to be the number of \"\n                                 \"points which has to be an integer, but was \"\n                                 \"'%s'\" % (filename, line))\n            if stroke_point_count <= 0:\n                raise ValueError((\"%s: Stroke point count was %i, but should \"\n                                  \"be > 0.\") % (filename, stroke_count))\n        elif i > 2:\n            if stroke_point_count > 0:\n                x, y = [int(el) for el in line.strip().split(\" \")]\n                current_stroke.append({'x': x, 'y': y, 'time': time})\n                time += 20\n                stroke_point_count -= 1\n            elif line == 'ANNOTATIONS' or got_annotations:\n                got_annotations = True\n                annotations.append(line)\n            elif stroke_count > 0:\n                try:\n                    stroke_point_count = int(line)\n                except ValueError:\n                    raise ValueError((\"%s: Line %i has to be the number of \"\n                                      \"points which has to be an integer, \"\n                                      \" but was '%s'\") %\n                                     (filename, i + 1, line))\n                if stroke_point_count <= 0:\n                    raise ValueError((\"%s: Stroke point count was %i, but \"\n                                      \"should be > 0.\") %\n                                     (filename, stroke_count))\n            if stroke_point_count == 0 and len(current_stroke) > 0:\n                time += 200\n                recording.append(current_stroke)\n                stroke_count -= 1\n                current_stroke = []\n    hw = handwritten_data.HandwrittenData(json.dumps(recording),\n                                          formula_in_latex=formula_in_latex,\n                                          formula_id=datasets.formula_to_dbid(mathbrush_formula_fix(formula_in_latex)))\n    hw.internal_id = \"/\".join(filename.split(\"/\")[-2:])\n    hw.segmentation, hw.symbol_stream = get_segmentation(recording,\n                                                         annotations,\n                                                         hw.internal_id)\n    hw.description = \"\\n\".join(annotations)\n    hw.username = \"MathBrush::%s\" % os.path.basename(os.path.dirname(filename))\n    copyright_str = (\"This dataset was contributed by MathBrush. You can \"\n                     \"download their complete dataset by contacting them. See \"\n                     \"[www.scg.uwaterloo.ca/mathbrush/]\"\n                     \"(https://www.scg.uwaterloo.ca/mathbrush/publications/\"\n                     \"corpus.pdf)\")\n    hw.user_id = datasets.getuserid(hw.username, copyright_str)\n    return hw"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_folder(folder):\n    recordings = []\n    for filename in glob.glob(os.path.join(folder, '*.ink')):\n        recording = parse_scg_ink_file(filename)\n        recordings.append(recording)\n    return recordings", "response": "Read all files of folder and return a list of HandwrittenData\n    objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_colors(segmentation):\n    symbol_count = len(segmentation)\n    num_colors = symbol_count\n\n    # See http://stackoverflow.com/a/20298116/562769\n    color_array = [\n        \"#000000\", \"#FFFF00\", \"#1CE6FF\", \"#FF34FF\", \"#FF4A46\", \"#008941\",\n        \"#006FA6\", \"#A30059\", \"#FFDBE5\", \"#7A4900\", \"#0000A6\", \"#63FFAC\",\n        \"#B79762\", \"#004D43\", \"#8FB0FF\", \"#997D87\", \"#5A0007\", \"#809693\",\n        \"#FEFFE6\", \"#1B4400\", \"#4FC601\", \"#3B5DFF\", \"#4A3B53\", \"#FF2F80\",\n        \"#61615A\", \"#BA0900\", \"#6B7900\", \"#00C2A0\", \"#FFAA92\", \"#FF90C9\",\n        \"#B903AA\", \"#D16100\", \"#DDEFFF\", \"#000035\", \"#7B4F4B\", \"#A1C299\",\n        \"#300018\", \"#0AA6D8\", \"#013349\", \"#00846F\", \"#372101\", \"#FFB500\",\n        \"#C2FFED\", \"#A079BF\", \"#CC0744\", \"#C0B9B2\", \"#C2FF99\", \"#001E09\",\n        \"#00489C\", \"#6F0062\", \"#0CBD66\", \"#EEC3FF\", \"#456D75\", \"#B77B68\",\n        \"#7A87A1\", \"#788D66\", \"#885578\", \"#FAD09F\", \"#FF8A9A\", \"#D157A0\",\n        \"#BEC459\", \"#456648\", \"#0086ED\", \"#886F4C\",\n\n        \"#34362D\", \"#B4A8BD\", \"#00A6AA\", \"#452C2C\", \"#636375\", \"#A3C8C9\",\n        \"#FF913F\", \"#938A81\", \"#575329\", \"#00FECF\", \"#B05B6F\", \"#8CD0FF\",\n        \"#3B9700\", \"#04F757\", \"#C8A1A1\", \"#1E6E00\", \"#7900D7\", \"#A77500\",\n        \"#6367A9\", \"#A05837\", \"#6B002C\", \"#772600\", \"#D790FF\", \"#9B9700\",\n        \"#549E79\", \"#FFF69F\", \"#201625\", \"#72418F\", \"#BC23FF\", \"#99ADC0\",\n        \"#3A2465\", \"#922329\", \"#5B4534\", \"#FDE8DC\", \"#404E55\", \"#0089A3\",\n        \"#CB7E98\", \"#A4E804\", \"#324E72\", \"#6A3A4C\", \"#83AB58\", \"#001C1E\",\n        \"#D1F7CE\", \"#004B28\", \"#C8D0F6\", \"#A3A489\", \"#806C66\", \"#222800\",\n        \"#BF5650\", \"#E83000\", \"#66796D\", \"#DA007C\", \"#FF1A59\", \"#8ADBB4\",\n        \"#1E0200\", \"#5B4E51\", \"#C895C5\", \"#320033\", \"#FF6832\", \"#66E1D3\",\n        \"#CFCDAC\", \"#D0AC94\", \"#7ED379\", \"#012C58\"]\n\n    # Apply a little trick to make sure we have enough colors, no matter\n    # how many symbols are in one recording.\n    # This simply appends the color array as long as necessary to get enough\n    # colors\n    new_array = color_array[:]\n    while len(new_array) <= num_colors:\n        new_array += color_array\n\n    return new_array[:num_colors]", "response": "Get a list of colors which is as long as the segmentation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_times(self):\n        pointlist = self.get_pointlist()\n        times = [point['time'] for stroke in pointlist for point in stroke]\n        times_min = max(min(times), 0)  # Make sure this is not None\n        for i, stroke in enumerate(pointlist):\n            for j, point in enumerate(stroke):\n                if point['time'] is None:\n                    pointlist[i][j]['time'] = times_min\n                else:\n                    times_min = point['time']\n        self.raw_data_json = json.dumps(pointlist)", "response": "Fix the time of the recordings that have wrong times."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of lists of tuples from JSON raw data string. Those lists represent strokes with control points. Those lists represent strokes with control points. Those lists represent strokes with control points. Those lists represent strokes with control points.", "response": "def get_pointlist(self):\n        \"\"\"\n        Get a list of lists of tuples from JSON raw data string. Those lists\n        represent strokes with control points.\n\n        Returns\n        -------\n        list :\n            A list of strokes. Each stroke is a list of dictionaries\n            {'x': 123, 'y': 42, 'time': 1337}\n        \"\"\"\n        try:\n            pointlist = json.loads(self.raw_data_json)\n        except Exception as inst:\n            logging.debug(\"pointStrokeList: strokelistP\")\n            logging.debug(self.raw_data_json)\n            logging.debug(\"didn't work\")\n            raise inst\n\n        if len(pointlist) == 0:\n            logging.warning(\"Pointlist was empty. Search for '\" +\n                            self.raw_data_json + \"' in `wm_raw_draw_data`.\")\n        return pointlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all points and strokes in the recording sorted by time.", "response": "def get_sorted_pointlist(self):\n        \"\"\"\n        Make sure that the points and strokes are in order.\n\n        Returns\n        -------\n        list\n            A list of all strokes in the recording. Each stroke is represented\n            as a list of dicts {'time': 123, 'x': 45, 'y': 67}\n        \"\"\"\n        pointlist = self.get_pointlist()\n        for i in range(len(pointlist)):\n            pointlist[i] = sorted(pointlist[i], key=lambda p: p['time'])\n        pointlist = sorted(pointlist, key=lambda stroke: stroke[0]['time'])\n        return pointlist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_pointlist(self, pointlist):\n        assert type(pointlist) is list, \\\n            \"pointlist is not of type list, but %r\" % type(pointlist)\n        assert len(pointlist) >= 1, \\\n            \"The pointlist of formula_id %i is %s\" % (self.formula_id,\n                                                      self.get_pointlist())\n        self.raw_data_json = json.dumps(pointlist)", "response": "Overwrite pointlist.\n\n        Parameters\n        ----------\n        pointlist : a list of strokes; each stroke is a list of points\n            The inner lists represent strokes. Every stroke consists of points.\n            Every point is a dictinary with 'x', 'y', 'time'."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_bounding_box(self):\n        pointlist = self.get_pointlist()\n\n        # Initialize bounding box parameters to save values\n        minx, maxx = pointlist[0][0][\"x\"], pointlist[0][0][\"x\"]\n        miny, maxy = pointlist[0][0][\"y\"], pointlist[0][0][\"y\"]\n        mint, maxt = pointlist[0][0][\"time\"], pointlist[0][0][\"time\"]\n\n        # Adjust parameters\n        for stroke in pointlist:\n            for p in stroke:\n                minx, maxx = min(minx, p[\"x\"]), max(maxx, p[\"x\"])\n                miny, maxy = min(miny, p[\"y\"]), max(maxy, p[\"y\"])\n                mint, maxt = min(mint, p[\"time\"]), max(maxt, p[\"time\"])\n        return {\"minx\": minx, \"maxx\": maxx, \"miny\": miny, \"maxy\": maxy,\n                \"mint\": mint, \"maxt\": maxt}", "response": "Get the bounding box of a pointlist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a bitmap of the object at a given instance of time.", "response": "def get_bitmap(self, time=None, size=32, store_path=None):\n        \"\"\"\n        Get a bitmap of the object at a given instance of time. If time is\n        `None`,`then the bitmap is generated for the last point in time.\n\n        Parameters\n        ----------\n        time : int or None\n        size : int\n            Size in pixels. The resulting bitmap will be (size x size).\n        store_path : None or str\n            If this is set, then the image will be saved there.\n\n        Returns\n        -------\n        numpy array :\n            Greyscale png image\n        \"\"\"\n        # bitmap_width = int(self.get_width()*size) + 2\n        # bitmap_height = int(self.get_height()*size) + 2\n        img = Image.new('L', (size, size), 'black')\n        draw = ImageDraw.Draw(img, 'L')\n        bb = self.get_bounding_box()\n        for stroke in self.get_sorted_pointlist():\n            for p1, p2 in zip(stroke, stroke[1:]):\n                if time is not None and \\\n                   (p1['time'] > time or p2['time'] > time):\n                    continue\n                y_from = int((-bb['miny'] + p1['y']) /\n                             max(self.get_height(), 1)*size)\n                x_from = int((-bb['minx'] + p1['x']) /\n                             max(self.get_width(), 1)*size)\n                y_to = int((-bb['miny'] + p2['y']) /\n                           max(self.get_height(), 1)*size)\n                x_to = int((-bb['minx'] + p2['x']) /\n                           max(self.get_width(), 1)*size)\n                draw.line([x_from, y_from, x_to, y_to],\n                          fill='#ffffff',\n                          width=1)\n        del draw\n        if store_path is not None:\n            img.save(store_path)\n        return numpy.asarray(img)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preprocessing(self, algorithms):\n        assert type(algorithms) is list\n        for algorithm in algorithms:\n            algorithm(self)", "response": "Apply preprocessing algorithms to all objects in order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a list of features. Each algorithm has to return the features as a list.", "response": "def feature_extraction(self, algorithms):\n        \"\"\"Get a list of features.\n\n        Every algorithm has to return the features as a list.\"\"\"\n        assert type(algorithms) is list\n        features = []\n        for algorithm in algorithms:\n            new_features = algorithm(self)\n            assert len(new_features) == algorithm.get_dimension(), \\\n                \"Expected %i features from algorithm %s, got %i features\" % \\\n                (algorithm.get_dimension(), str(algorithm), len(new_features))\n            features += new_features\n        return features"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing the data graphically in a new pop - up window.", "response": "def show(self):\n        \"\"\"Show the data graphically in a new pop-up window.\"\"\"\n\n        # prevent the following error:\n        # '_tkinter.TclError: no display name and no $DISPLAY environment\n        #    variable'\n        # import matplotlib\n        # matplotlib.use('GTK3Agg', warn=False)\n\n        import matplotlib.pyplot as plt\n\n        pointlist = self.get_pointlist()\n        if 'pen_down' in pointlist[0][0]:\n            assert len(pointlist) > 1, \\\n                \"Lenght of pointlist was %i. Got: %s\" % (len(pointlist),\n                                                         pointlist)\n            # Create a new pointlist that models pen-down strokes and pen\n            # up strokes\n            new_pointlist = []\n            last_pendown_state = None\n            stroke = []\n            for point in pointlist[0]:\n                if last_pendown_state is None:\n                    last_pendown_state = point['pen_down']\n                if point['pen_down'] != last_pendown_state:\n                    new_pointlist.append(stroke)\n                    last_pendown_state = point['pen_down']\n                    stroke = []\n                else:\n                    stroke.append(point)\n            new_pointlist.append(stroke)  # add the last stroke\n            pointlist = new_pointlist\n\n        _, ax = plt.subplots()\n        ax.set_title(\"Raw data id: %s, \"\n                     \"Formula_id: %s\" % (str(self.raw_data_id),\n                                         str(self.formula_id)))\n\n        colors = _get_colors(self.segmentation)\n        for symbols, color in zip(self.segmentation, colors):\n            for stroke_index in symbols:\n                stroke = pointlist[stroke_index]\n                xs, ys = [], []\n                for p in stroke:\n                    xs.append(p['x'])\n                    ys.append(p['y'])\n                if \"pen_down\" in stroke[0] and stroke[0][\"pen_down\"] is False:\n                    plt.plot(xs, ys, '-x', color=color)\n                else:\n                    plt.plot(xs, ys, '-o', color=color)\n        plt.gca().invert_yaxis()\n        ax.set_aspect('equal')\n        plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount the number of single dots in this recording.", "response": "def count_single_dots(self):\n        \"\"\"Count all strokes of this recording that have only a single dot.\n        \"\"\"\n        pointlist = self.get_pointlist()\n        single_dots = 0\n        for stroke in pointlist:\n            if len(stroke) == 1:\n                single_dots += 1\n        return single_dots"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a tuple x y that is the center of mass.", "response": "def get_center_of_mass(self):\n        \"\"\"\n        Get a tuple (x,y) that is the center of mass. The center of mass is not\n        necessarily the same as the center of the bounding box. Imagine a black\n        square and a single dot wide outside of the square.\n        \"\"\"\n        xsum, ysum, counter = 0., 0., 0\n        for stroke in self.get_pointlist():\n            for point in stroke:\n                xsum += point['x']\n                ysum += point['y']\n                counter += 1\n        return (xsum / counter, ysum / counter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert this HandwrittenData object into a list of HandwrittenData objects. Each element of the list is a single symbol. Each element of the list is a single symbol.", "response": "def to_single_symbol_list(self):\n        \"\"\"\n        Convert this HandwrittenData object into a list of HandwrittenData\n        objects. Each element of the list is a single symbol.\n\n        Returns\n        -------\n        list of HandwrittenData objects\n        \"\"\"\n        symbol_stream = getattr(self,\n                                'symbol_stream',\n                                [None for symbol in self.segmentation])\n        single_symbols = []\n        pointlist = self.get_sorted_pointlist()\n        for stroke_indices, label in zip(self.segmentation, symbol_stream):\n            strokes = []\n            for stroke_index in stroke_indices:\n                strokes.append(pointlist[stroke_index])\n            single_symbols.append(HandwrittenData(json.dumps(strokes),\n                                                  formula_id=label))\n        return single_symbols"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef git_log_iterator(path):\n    N = 10\n    count = 0\n    while True:\n        lines = _run_git_command_lines(['log', '--oneline',\n                                        '-n', str(N),\n                                        '--skip', str(count),\n                                        '--', '.'], cwd=path)\n        for line in lines:\n            sha = line.split(' ', 1)[0]\n            count += 1\n            yield sha\n        if len(lines) < N:\n            break", "response": "Iterate over commits using git log."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the addon version number with a developmental version increment.", "response": "def get_git_postversion(addon_dir):\n    \"\"\" return the addon version number, with a developmental version increment\n    if there were git commits in the addon_dir after the last version change.\n\n    If the last change to the addon correspond to the version number in the\n    manifest it is used as is for the python package version. Otherwise a\n    counter is incremented for each commit and resulting version number has\n    the following form: [8|9].0.x.y.z.1devN, N being the number of git\n    commits since the version change.\n\n    Note: we use .99.devN because:\n    * pip ignores .postN  by design (https://github.com/pypa/pip/issues/2872)\n    * x.y.z.devN is anterior to x.y.z\n\n    Note: we don't put the sha1 of the commit in the version number because\n    this is not PEP 440 compliant and is therefore misinterpreted by pip.\n    \"\"\"\n    addon_dir = os.path.realpath(addon_dir)\n    last_version = read_manifest(addon_dir).get('version', '0.0.0')\n    last_version_parsed = parse_version(last_version)\n    if not is_git_controlled(addon_dir):\n        return last_version\n    if get_git_uncommitted(addon_dir):\n        uncommitted = True\n        count = 1\n    else:\n        uncommitted = False\n        count = 0\n    last_sha = None\n    git_root = get_git_root(addon_dir)\n    for sha in git_log_iterator(addon_dir):\n        try:\n            manifest = read_manifest_from_sha(sha, addon_dir, git_root)\n        except NoManifestFound:\n            break\n        version = manifest.get('version', '0.0.0')\n        version_parsed = parse_version(version)\n        if version_parsed != last_version_parsed:\n            break\n        if last_sha is None:\n            last_sha = sha\n        else:\n            count += 1\n    if not count:\n        return last_version\n    if last_sha:\n        return last_version + \".99.dev%s\" % count\n    if uncommitted:\n        return last_version + \".dev1\"\n    # if everything is committed, the last commit\n    # must have the same version as current,\n    # so last_sha must be set and we'll never reach this branch\n    return last_version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_odoo_version_info(addons_dir, odoo_version_override=None):\n    odoo_version_info = None\n    addons = os.listdir(addons_dir)\n    for addon in addons:\n        addon_dir = os.path.join(addons_dir, addon)\n        if is_installable_addon(addon_dir):\n            manifest = read_manifest(addon_dir)\n            _, _, addon_odoo_version_info = _get_version(\n                addon_dir, manifest, odoo_version_override,\n                git_post_version=False)\n            if odoo_version_info is not None and \\\n                    odoo_version_info != addon_odoo_version_info:\n                raise DistutilsSetupError(\"Not all addons are for the same \"\n                                          \"odoo version in %s (error detected \"\n                                          \"in %s)\" % (addons_dir, addon))\n            odoo_version_info = addon_odoo_version_info\n    return odoo_version_info", "response": "Detect Odoo version from an addons directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_version(addon_dir, manifest, odoo_version_override=None,\n                 git_post_version=True):\n    \"\"\" Get addon version information from an addon directory \"\"\"\n    version = manifest.get('version')\n    if not version:\n        warn(\"No version in manifest in %s\" % addon_dir)\n        version = '0.0.0'\n    if not odoo_version_override:\n        if len(version.split('.')) < 5:\n            raise DistutilsSetupError(\"Version in manifest must have at least \"\n                                      \"5 components and start with \"\n                                      \"the Odoo series number in %s\" %\n                                      addon_dir)\n        odoo_version = '.'.join(version.split('.')[:2])\n    else:\n        odoo_version = odoo_version_override\n    if odoo_version not in ODOO_VERSION_INFO:\n        raise DistutilsSetupError(\"Unsupported odoo version '%s' in %s\" %\n                                  (odoo_version, addon_dir))\n    odoo_version_info = ODOO_VERSION_INFO[odoo_version]\n    if git_post_version:\n        version = get_git_postversion(addon_dir)\n    return version, odoo_version, odoo_version_info", "response": "Get addon version information from an addon directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the list of requirements for an addon", "response": "def get_install_requires_odoo_addon(addon_dir,\n                                    no_depends=[],\n                                    depends_override={},\n                                    external_dependencies_override={},\n                                    odoo_version_override=None):\n    \"\"\" Get the list of requirements for an addon \"\"\"\n    manifest = read_manifest(addon_dir)\n    _, _, odoo_version_info = _get_version(addon_dir,\n                                           manifest,\n                                           odoo_version_override,\n                                           git_post_version=False)\n    return _get_install_requires(odoo_version_info,\n                                 manifest,\n                                 no_depends,\n                                 depends_override,\n                                 external_dependencies_override)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the list of requirements for an addon directory containing addons.", "response": "def get_install_requires_odoo_addons(addons_dir,\n                                     depends_override={},\n                                     external_dependencies_override={},\n                                     odoo_version_override=None):\n    \"\"\" Get the list of requirements for a directory containing addons \"\"\"\n    addon_dirs = []\n    addons = os.listdir(addons_dir)\n    for addon in addons:\n        addon_dir = os.path.join(addons_dir, addon)\n        if is_installable_addon(addon_dir):\n            addon_dirs.append(addon_dir)\n    install_requires = set()\n    for addon_dir in addon_dirs:\n        r = get_install_requires_odoo_addon(\n            addon_dir,\n            no_depends=addons,\n            depends_override=depends_override,\n            external_dependencies_override=external_dependencies_override,\n            odoo_version_override=odoo_version_override,\n        )\n        install_requires.update(r)\n    return sorted(install_requires)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_addons_dir():\n    res = set()\n    for odoo_version_info in ODOO_VERSION_INFO.values():\n        addons_ns = odoo_version_info['addons_ns']\n        addons_dir = os.path.join(*addons_ns.split('.'))\n        if os.path.isdir(addons_dir):\n            if not odoo_version_info['namespace_packages'] or \\\n                    os.path.isfile(os.path.join(addons_dir, '__init__.py')):\n                res.add((addons_dir, addons_ns))\n    if len(res) == 0:\n        raise RuntimeError(\"No addons namespace found.\")\n    if len(res) > 1:\n        raise RuntimeError(\"More than one addons namespace found.\")\n    return res.pop()", "response": "Try to find the addons dir and namespace package\n    Returns addons_dir addons_ns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_declarative_base(self, metadata=None):\n        return make_declarative_base(self.session,\n                                     Model=self.Model,\n                                     metadata=metadata)", "response": "Override parent function with alchy s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prep_doc(self, doc_obj):\n        doc = doc_obj._data.copy()\n        for key, prop in list(doc_obj._base_properties.items()):\n            prop.validate(doc.get(key), key)\n            raw_value = prop.get_python_value(doc.get(key))\n            if prop.unique:\n                self.check_unique(doc_obj, key, raw_value)\n            value = prop.get_db_value(raw_value)\n            doc[key] = value\n\n        doc['_doc_type'] = get_doc_type(doc_obj.__class__)\n        return doc", "response": "This method prepares the doc dict object for saving and backup functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads Zappa settings set defaults if needed and apply to the Zappa object", "response": "def apply_zappa_settings(zappa_obj, zappa_settings, environment):\n    '''Load Zappa settings, set defaults if needed, and apply to the Zappa object'''\n\n    settings_all = json.load(zappa_settings)\n    settings = settings_all[environment]\n\n    # load defaults for missing options\n    for key,value in DEFAULT_SETTINGS.items():\n        settings[key] = settings.get(key, value)\n\n    if '~' in settings['settings_file']:\n        settings['settings_file'] = settings['settings_file'].replace('~', os.path.expanduser('~'))\n    if not os.path.isfile(settings['settings_file']):\n        raise SettingsError(\"Please make sure your settings_file \"\n                            \"is properly defined in {0}.\".format(zappa_settings))\n\n    for setting in CUSTOM_SETTINGS:\n        if setting in settings:\n            setattr(zappa_obj, setting, settings[setting])\n\n    return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deploy(environment, zappa_settings):\n    print((\"Deploying \" + environment))\n\n    zappa, settings, lambda_name, zip_path = \\\n        _package(environment, zappa_settings)\n\n    s3_bucket_name = settings['s3_bucket']\n\n    try:\n        # Load your AWS credentials from ~/.aws/credentials\n        zappa.load_credentials()\n\n        # Make sure the necessary IAM execution roles are available\n        zappa.create_iam_roles()\n\n        # Upload it to S3\n        zip_arn = zappa.upload_to_s3(zip_path, s3_bucket_name)\n\n        # Register the Lambda function with that zip as the source\n        # You'll also need to define the path to your lambda_handler code.\n        lambda_arn = zappa.create_lambda_function(bucket=s3_bucket_name,\n                                                  s3_key=zip_path,\n                                                  function_name=lambda_name,\n                                                  handler='handler.lambda_handler',\n                                                  vpc_config=settings['vpc_config'],\n                                                  memory_size=settings['memory_size'])\n\n        # Create and configure the API Gateway\n        api_id = zappa.create_api_gateway_routes(lambda_arn, lambda_name)\n\n        # Deploy the API!\n        endpoint_url = zappa.deploy_api_gateway(api_id, environment)\n\n        # Remove the uploaded zip from S3, because it is now registered..\n        zappa.remove_from_s3(zip_path, s3_bucket_name)\n\n        if settings['touch']:\n            requests.get(endpoint_url)\n    finally:\n        try:\n            # Finally, delete the local copy our zip package\n            if settings['delete_zip']:\n                os.remove(zip_path)\n        except:\n            print(\"WARNING: Manual cleanup of the zip might be needed.\")\n\n    print((\"Your Zappa deployment is live!: \" + endpoint_url))", "response": "Deploy the environment to the Lambda."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(environment, zappa_settings):\n    print((\"Updating \" + environment))\n\n    # Package dependencies, and the source code into a zip\n    zappa, settings, lambda_name, zip_path = \\\n        _package(environment, zappa_settings)\n\n    s3_bucket_name = settings['s3_bucket']\n\n    try:\n\n        # Load your AWS credentials from ~/.aws/credentials\n        zappa.load_credentials()\n\n        # Update IAM roles if needed\n        zappa.create_iam_roles()\n\n\n        # Upload it to S3\n        zip_arn = zappa.upload_to_s3(zip_path, s3_bucket_name)\n\n        # Register the Lambda function with that zip as the source\n        # You'll also need to define the path to your lambda_handler code.\n        lambda_arn = zappa.update_lambda_function(s3_bucket_name, zip_path,\n                                                  lambda_name)\n\n        # Remove the uploaded zip from S3, because it is now registered..\n        zappa.remove_from_s3(zip_path, s3_bucket_name)\n    finally:\n        try:\n            # Finally, delete the local copy our zip package\n            if settings['delete_zip']:\n                os.remove(zip_path)\n        except:\n            print(\"WARNING: Manual cleanup of the zip might be needed.\")\n\n    print(\"Your updated Zappa deployment is live!\")", "response": "Update an existing deployment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tail(environment, zappa_settings):\n\n    def print_logs(logs):\n\n        for log in logs:\n            timestamp = log['timestamp']\n            message = log['message']\n            if \"START RequestId\" in message:\n                continue\n            if \"REPORT RequestId\" in message:\n                continue\n            if \"END RequestId\" in message:\n                continue\n\n            print(\"[\" + str(timestamp) + \"] \" + message.strip())\n\n    zappa, settings, _, lambda_name = _init(environment, zappa_settings)\n\n    try:\n        # Tail the available logs\n        all_logs = zappa.fetch_logs(lambda_name)\n        print_logs(all_logs)\n\n        # Keep polling, and print any new logs.\n        while True:\n            all_logs_again = zappa.fetch_logs(lambda_name)\n            new_logs = []\n            for log in all_logs_again:\n                if log not in all_logs:\n                    new_logs.append(log)\n\n            print_logs(new_logs)\n            all_logs = all_logs + new_logs\n    except KeyboardInterrupt:\n        # Die gracefully\n        try:\n            sys.exit(0)\n        except SystemExit:\n            os._exit(0)", "response": "Tail the available logs and print them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lambda_handler(event, context, settings_name=\"zappa_settings\"):\n    # Loading settings from a python module\n    settings = importlib.import_module(settings_name)\n\n    # The flask-app module\n    app_module = importlib.import_module(settings.APP_MODULE)\n\n    # The flask-app\n    app = getattr(app_module, settings.APP_OBJECT)\n    app.config.from_object('zappa_settings')\n\n    app.wsgi_app = ZappaWSGIMiddleware(app.wsgi_app)\n\n    # This is a normal HTTP request\n    if event.get('method', None):\n        # If we just want to inspect this,\n        # return this event instead of processing the request\n        # https://your_api.aws-api.com/?event_echo=true\n        event_echo = getattr(settings, \"EVENT_ECHO\", True)\n        if event_echo:\n            if 'event_echo' in list(event['params'].values()):\n                return {'Content': str(event) + '\\n' + str(context), 'Status': 200}\n\n        # TODO: Enable Let's Encrypt\n        # # If Let's Encrypt is defined in the settings,\n        # # and the path is your.domain.com/.well-known/acme-challenge/{{lets_encrypt_challenge_content}},\n        # # return a 200 of lets_encrypt_challenge_content.\n        # lets_encrypt_challenge_path = getattr(settings, \"LETS_ENCRYPT_CHALLENGE_PATH\", None)\n        # lets_encrypt_challenge_content = getattr(settings, \"LETS_ENCRYPT_CHALLENGE_CONTENT\", None)\n        # if lets_encrypt_challenge_path:\n        #     if len(event['params']) == 3:\n        #         if event['params']['parameter_1'] == '.well-known' and \\\n        #             event['params']['parameter_2'] == 'acme-challenge' and \\\n        #             event['params']['parameter_3'] == lets_encrypt_challenge_path:\n        #                 return {'Content': lets_encrypt_challenge_content, 'Status': 200}\n\n        # Create the environment for WSGI and handle the request\n        environ = create_wsgi_request(event, script_name=settings.SCRIPT_NAME,\n                                      trailing_slash=False)\n\n        # We are always on https on Lambda, so tell our wsgi app that.\n        environ['wsgi.url_scheme'] = 'https'\n\n        response = Response.from_app(app, environ)\n\n        # This doesn't work. It should probably be set right after creation, not\n        # at such a late stage.\n        # response.autocorrect_location_header = False\n\n        zappa_returndict = dict()\n\n        if response.data:\n            zappa_returndict['Content'] = response.data\n\n        # Pack the WSGI response into our special dictionary.\n        for (header_name, header_value) in response.headers:\n            zappa_returndict[header_name] = header_value\n        zappa_returndict['Status'] = response.status_code\n\n        # TODO: No clue how to handle the flask-equivalent of this. Or is this\n        # something entirely specified by the middleware?\n        # # Parse the WSGI Cookie and pack it.\n        # cookie = response.cookies.output()\n        # if ': ' in cookie:\n        #     zappa_returndict['Set-Cookie'] = response.cookies.output().split(': ')[1]\n\n        # To ensure correct status codes, we need to\n        # pack the response as a deterministic B64 string and raise it\n        # as an error to match our APIGW regex.\n        # The DOCTYPE ensures that the page still renders in the browser.\n        if response.status_code in [400, 401, 403, 404, 500]:\n            content = \"<!DOCTYPE html>\" + str(response.status_code) + response.data\n            b64_content = base64.b64encode(content)\n            raise Exception(b64_content)\n        # Internal are changed to become relative redirects\n        # so they still work for apps on raw APIGW and on a domain.\n        elif response.status_code in [301, 302]:\n            # Location is by default relative on Flask. Location is by default\n            # absolute on Werkzeug. We can set autocorrect_location_header on\n            # the response to False, but it doesn't work. We have to manually\n            # remove the host part.\n            location = response.location\n            hostname = 'https://' + environ['HTTP_HOST']\n            if location.startswith(hostname):\n                location = location[len(hostname):]\n            raise Exception(location)\n        else:\n            return zappa_returndict", "response": "A Lambda function which parses specific API Gateway input into a\n    WSGI request and processes it to Flask response and returns the API Gateway response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context_data(self, **kwargs):\n        queryset = kwargs.pop('object_list')\n        page_template = kwargs.pop('page_template', None)\n\n        context_object_name = self.get_context_object_name(queryset)\n        context = {'object_list': queryset, 'view': self}\n        context.update(kwargs)\n        if context_object_name is not None:\n            context[context_object_name] = queryset\n\n        if page_template is None:\n            if hasattr(queryset, 'model'):\n                page_template = self.get_page_template(**kwargs)\n            else:\n                raise ImproperlyConfigured(\n                    'AjaxListView requires a page_template')\n        context['page_template'] = self.page_template = page_template\n\n        return context", "response": "Get the context data for this view."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_template_names(self):\n        request = self.request\n        querystring_key = request.REQUEST.get('querystring_key', PAGE_LABEL)\n        if request.is_ajax() and querystring_key == self.key:\n            return [self.page_template]\n        return super(\n            AjaxMultipleObjectTemplateResponseMixin, self).get_template_names()", "response": "Switch the templates for Ajax requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_var(text):\n    text = re_invalid_var.sub('', text)\n    text = re_invalid_start.sub('', text)\n    return text", "response": "Turn text into a valid python classname or variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_tasktrace(self):\n        if self.prev_error:\n            return self.prev_error.tasktrace + self.tasktrace\n        else:\n            return self.tasktrace", "response": "Returns the full task trace of all failed tasks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dist_sq(self, other=None):\n        v = self - other if other else self\n        return sum(map(lambda a: a * a, v))", "response": "For fast length comparison"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the yaw and pitch of this vector.", "response": "def yaw_pitch(self):\n        \"\"\"\n        Calculate the yaw and pitch of this vector\n        \"\"\"\n        if not self:\n            return YawPitch(0, 0)\n        ground_distance = math.sqrt(self.x ** 2 + self.z ** 2)\n        if ground_distance:\n            alpha1 = -math.asin(self.x / ground_distance) / math.pi * 180\n            alpha2 = math.acos(self.z / ground_distance) / math.pi * 180\n            if alpha2 > 90:\n                yaw = 180 - alpha1\n            else:\n                yaw = alpha1\n            pitch = math.atan2(-self.y, ground_distance) / math.pi * 180\n        else:\n            yaw = 0\n            y = round(self.y)\n            if y > 0:\n                pitch = -90\n            elif y < 0:\n                pitch = 90\n            else:\n                pitch = 0\n        return YawPitch(yaw, pitch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a unit vector", "response": "def unit_vector(self):\n        \"\"\"Generate a unit vector (norm = 1)\"\"\"\n        x = -math.cos(self.rpitch) * math.sin(self.ryaw)\n        y = -math.sin(self.rpitch)\n        z = math.cos(self.rpitch) * math.cos(self.ryaw)\n        return Vector3(x, y, z)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_ingredient_amounts(self):\n        totals = defaultdict(int)\n        for id, meta, amount in self.ingredients:\n            totals[(id, meta)] += amount\n        return totals", "response": "Returns a dictionary of the amount of ingredients in the item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ingredient_positions(self):\n        positions = defaultdict(list)\n        for y, row in enumerate(self.in_shape):\n            for x, (item_id, metadata, amount) in enumerate(row):\n                positions[(item_id, metadata)].append((x, y, amount))\n        return positions", "response": "Returns a dictionary of the in - shape positions of the ingredient."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates and returns a function that takes a slot and checks if it matches the wanted item.", "response": "def make_slot_check(wanted):\n    \"\"\"\n    Creates and returns a function that takes a slot\n    and checks if it matches the wanted item.\n\n    Args:\n        wanted: function(Slot) or Slot or itemID or (itemID, metadata)\n    \"\"\"\n    if isinstance(wanted, types.FunctionType):\n        return wanted  # just forward the slot check function\n\n    if isinstance(wanted, int):\n        item, meta = wanted, None\n    elif isinstance(wanted, Slot):\n        item, meta = wanted.item_id, wanted.damage  # TODO compare NBT\n    elif isinstance(wanted, (Item, Block)):\n        item, meta = wanted.id, wanted.metadata\n    elif isinstance(wanted, str):\n        item_or_block = get_item_or_block(wanted, init=True)\n        item, meta = item_or_block.id, item_or_block.metadata\n    else:  # wanted is (id, meta)\n        try:\n            item, meta = wanted\n        except TypeError:\n            raise ValueError('Illegal args for make_slot_check(): %s' % wanted)\n\n    return lambda slot: item == slot.item_id and meta in (None, slot.damage)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new class for that window and registers it at this module.", "response": "def _make_window(window_dict):\n    \"\"\"\n    Creates a new class for that window and registers it at this module.\n    \"\"\"\n    cls_name = '%sWindow' % camel_case(str(window_dict['name']))\n    bases = (Window,)\n    attrs = {\n        '__module__': sys.modules[__name__],\n        'name': str(window_dict['name']),\n        'inv_type': str(window_dict['id']),\n        'inv_data': window_dict,\n    }\n\n    # creates function-local index and size variables\n    def make_slot_method(index, size=1):\n        if size == 1:\n            return lambda self: self.slots[index]\n        else:\n            return lambda self: self.slots[index:(index + size)]\n\n    for slots in window_dict.get('slots', []):\n        index = slots['index']\n        size = slots.get('size', 1)\n        attr_name = snake_case(str(slots['name']))\n        attr_name += '_slot' if size == 1 else '_slots'\n        slots_method = make_slot_method(index, size)\n        slots_method.__name__ = attr_name\n        attrs[attr_name] = property(slots_method)\n\n    for i, prop_name in enumerate(window_dict.get('properties', [])):\n        def make_prop_method(i):\n            return lambda self: self.properties[i]\n        prop_method = make_prop_method(i)\n        prop_name = snake_case(str(prop_name))\n        prop_method.__name__ = prop_name\n        attrs[prop_name] = property(prop_method)\n\n    cls = type(cls_name, bases, attrs)\n    assert not hasattr(sys.modules[__name__], cls_name), \\\n        'Window \"%s\" already registered at %s' % (cls_name, __name__)\n    setattr(sys.modules[__name__], cls_name, cls)\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats the slot for network packing.", "response": "def get_dict(self):\n        \"\"\" Formats the slot for network packing. \"\"\"\n        data = {'id': self.item_id}\n        if self.item_id != constants.INV_ITEMID_EMPTY:\n            data['damage'] = self.damage\n            data['amount'] = self.amount\n            if self.nbt is not None:\n                data['enchants'] = self.nbt\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_success(self, inv_plugin, emit_set_slot):\n        self.dirty = set()\n        self.apply(inv_plugin)\n        for changed_slot in self.dirty:\n            emit_set_slot(changed_slot)", "response": "Called when the click was successful with the inventory plugin instance inv_plugin and emit_set_slot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nauthenticating the user with the server.", "response": "def authenticate(self):\n        \"\"\"\n        Generate an access token using an username and password. Any existing\n        client token is invalidated if not provided.\n\n        Returns:\n            dict: Response or error dict\n        \"\"\"\n        endpoint = '/authenticate'\n\n        payload = {\n            'agent': {\n                'name': 'Minecraft',\n                'version': self.ygg_version,\n            },\n            'username': self.username,\n            'password': self.password,\n            'clientToken': self.client_token,\n        }\n        rep = self._ygg_req(endpoint, payload)\n        if not rep or 'error' in rep:\n            return False\n        self.access_token = rep['accessToken']\n        self.client_token = rep['clientToken']\n        self.available_profiles = rep['availableProfiles']\n        self.selected_profile = rep['selectedProfile']\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self):\n        endpoint = '/refresh'\n\n        payload = {\n            'accessToken': self.access_token,\n            'clientToken': self.client_token,\n        }\n        rep = self._ygg_req(endpoint, payload)\n        if not rep or 'error' in rep:\n            return False\n\n        self.access_token = rep['accessToken']\n        self.client_token = rep['clientToken']\n        self.selected_profile = rep['selectedProfile']\n        return True", "response": "Generate an access token with a client token pair. Used\n            access token is invalidated."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninvalidate the client and access token pair with a client token pair", "response": "def invalidate(self):\n        \"\"\"\n        Invalidate access tokens with a client/access token pair\n\n        Returns:\n            dict: Empty or error dict\n        \"\"\"\n        endpoint = '/invalidate'\n\n        payload = {\n            'accessToken': self.access_token,\n            'clientToken': self.client_token,\n        }\n        self._ygg_req(endpoint, payload)\n        self.client_token = ''\n        self.access_token = ''\n        self.available_profiles = []\n        self.selected_profile = {}\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self):\n        endpoint = '/validate'\n\n        payload = dict(accessToken=self.access_token)\n        rep = self._ygg_req(endpoint, payload)\n        return not bool(rep)", "response": "Check if an access token is valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_stored(self, wanted, slots=None):\n        if slots is None:\n            slots = self.window.slots\n        wanted = make_slot_check(wanted)\n        return sum(slot.amount for slot in slots if wanted(slot))", "response": "Returns the total amount of items that are stored in the current window or given slot range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching the given slots or active hotbar slot inventory open window in this order.", "response": "def find_slot(self, wanted, slots=None):\n        \"\"\"\n        Searches the given slots or, if not given,\n        active hotbar slot, hotbar, inventory, open window in this order.\n\n        Args:\n            wanted: function(Slot) or Slot or itemID or (itemID, metadata)\n\n        Returns:\n            Optional[Slot]: The first slot containing the item\n                            or None if not found.\n        \"\"\"\n        for slot in self.find_slots(wanted, slots):\n            return slot\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding all the slots containing the item.", "response": "def find_slots(self, wanted, slots=None):\n        \"\"\"\n        Yields all slots containing the item.\n        Searches the given slots or, if not given,\n        active hotbar slot, hotbar, inventory, open window in this order.\n\n        Args:\n            wanted: function(Slot) or Slot or itemID or (itemID, metadata)\n        \"\"\"\n        if slots is None:\n            slots = self.inv_slots_preferred + self.window.window_slots\n        wanted = make_slot_check(wanted)\n\n        for slot in slots:\n            if wanted(slot):\n                yield slot"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndrop one or all items of the specified slot.", "response": "def drop_slot(self, slot=None, drop_stack=False):\n        \"\"\"\n        Drop one or all items of the slot.\n\n        Does not wait for confirmation from the server. If you want that,\n        use a ``Task`` and ``yield inventory.async.drop_slot()`` instead.\n\n        If ``slot`` is None, drops the ``cursor_slot`` or, if that's empty,\n        the currently held item (``active_slot``).\n\n        Args:\n            slot (Optional[Slot]): The dropped slot. Can be None, integer,\n                                   or ``Slot`` instance.\n\n        Returns:\n            int: The action ID of the click\n        \"\"\"\n        if slot is None:\n            if self.cursor_slot.is_empty:\n                slot = self.active_slot\n            else:\n                slot = self.cursor_slot\n        elif isinstance(slot, int):  # also allow slot nr\n            slot = self.window.slots[slot]\n        if slot == self.cursor_slot:\n            # dropping items from cursor is done via normal click\n            return self.click_slot(self.cursor_slot, not drop_stack)\n        return self.send_click(windows.DropClick(slot, drop_stack))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inv_slots_preferred(self):\n        slots = [self.active_slot]\n        slots.extend(slot for slot in self.window.hotbar_slots\n                     if slot != self.active_slot)\n        slots.extend(self.window.inventory_slots)\n        return slots", "response": "Returns a list of all available inventory slots in the preferred search order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the block entity data subclass instance for the specified location.", "response": "def get_block_entity_data(self, pos_or_x, y=None, z=None):\n        \"\"\"\n        Access block entity data.\n\n        Returns:\n            BlockEntityData subclass instance or\n            None if no block entity data is stored for that location.\n        \"\"\"\n        if None not in (y, z):  # x y z supplied\n            pos_or_x = pos_or_x, y, z\n        coord_tuple = tuple(int(floor(c)) for c in pos_or_x)\n        return self.block_entities.get(coord_tuple, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_block_entity_data(self, pos_or_x, y=None, z=None, data=None):\n        if None not in (y, z):  # x y z supplied\n            pos_or_x = pos_or_x, y, z\n        coord_tuple = tuple(int(floor(c)) for c in pos_or_x)\n        old_data = self.block_entities.get(coord_tuple, None)\n        self.block_entities[coord_tuple] = data\n        return old_data", "response": "Set the block entity data for a given location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef store_or_drop(self):\n        inv = self.inventory\n        if inv.cursor_slot.is_empty:  # nothing to drop\n            raise StopIteration(None)\n\n        storage = inv.inv_slots_preferred\n        if inv.window.is_storage:\n            storage += inv.window.window_slots\n        first_empty_slot = inv.find_slot(constants.INV_ITEMID_EMPTY, storage)\n        if first_empty_slot is not None:\n            yield self.click_slot(first_empty_slot)\n        else:\n            yield self.drop_slot(drop_stack=True)\n\n        if not inv.cursor_slot.is_empty:\n            raise TaskFailed('Store or Drop failed: cursor is not empty')\n\n        raise StopIteration(first_empty_slot)", "response": "Store the item or drops it if the inventory is full."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a string of VLQ - encoded data.", "response": "def parse_vlq(self, segment):\n        \"\"\"\n        Parse a string of VLQ-encoded data.\n\n        Returns:\n          a list of integers.\n        \"\"\"\n\n        values = []\n\n        cur, shift = 0, 0\n        for c in segment:\n            val = B64[ord(c)]\n            # Each character is 6 bits:\n            # 5 of value and the high bit is the continuation.\n            val, cont = val & 0b11111, val >> 5\n            cur += val << shift\n            shift += 5\n\n            if not cont:\n                # The low bit of the unpacked value is the sign.\n                cur, sign = cur >> 1, cur & 1\n                if sign:\n                    cur = -cur\n                values.append(cur)\n                cur, shift = 0, 0\n\n        if cur or shift:\n            raise SourceMapDecodeError('leftover cur/shift in vlq decode')\n\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes a source map object into a SourceMapIndex.", "response": "def decode(self, source):\n        \"\"\"Decode a source map object into a SourceMapIndex.\n\n        The index is keyed on (dst_line, dst_column) for lookups,\n        and a per row index is kept to help calculate which Token to retrieve.\n\n        For example:\n            A minified source file has two rows and two tokens per row.\n\n            # All parsed tokens\n            tokens = [\n                Token(dst_row=0, dst_col=0),\n                Token(dst_row=0, dst_col=5),\n                Token(dst_row=1, dst_col=0),\n                Token(dst_row=1, dst_col=12),\n            ]\n\n            Two dimentional array of columns -> row\n            rows = [\n                [0, 5],\n                [0, 12],\n            ]\n\n            Token lookup, based on location\n            index = {\n                (0, 0):  tokens[0],\n                (0, 5):  tokens[1],\n                (1, 0):  tokens[2],\n                (1, 12): tokens[3],\n            }\n\n            To find the token at (1, 20):\n              - Check if there's a direct hit on the index (1, 20) => False\n              - Pull rows[1] => [0, 12]\n              - bisect_right to find the closest match:\n                  bisect_right([0, 12], 20) => 2\n              - Fetch the column number before, since we want the column\n                lte to the bisect_right: 2-1 => row[2-1] => 12\n              - At this point, we know the token location, (1, 12)\n              - Pull (1, 12) from index => tokens[3]\n        \"\"\"\n        # According to spec (https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.h7yy76c5il9v)\n        # A SouceMap may be prepended with \")]}'\" to cause a Javascript error.\n        # If the file starts with that string, ignore the entire first line.\n        if source[:4] == \")]}'\" or source[:3] == \")]}\":\n            source = source.split('\\n', 1)[1]\n\n        smap = json.loads(source)\n        sources = smap['sources']\n        sourceRoot = smap.get('sourceRoot')\n        names = list(map(text_type, smap['names']))\n        mappings = smap['mappings']\n        lines = mappings.split(';')\n\n        if sourceRoot is not None:\n            sources = list(map(partial(os.path.join, sourceRoot), sources))\n\n        # List of all tokens\n        tokens = []\n\n        # line_index is used to identify the closest column when looking up a token\n        line_index = []\n\n        # Main index of all tokens\n        # The index is keyed on (line, column)\n        index = {}\n\n        dst_col, src_id, src_line, src_col, name_id = 0, 0, 0, 0, 0\n        for dst_line, line in enumerate(lines):\n            # Create list for columns in index\n            line_index.append([])\n\n            segments = line.split(',')\n            dst_col = 0\n            for segment in segments:\n                if not segment:\n                    continue\n                parse = self.parse_vlq(segment)\n                dst_col += parse[0]\n\n                src = None\n                name = None\n                if len(parse) > 1:\n                    try:\n                        src_id += parse[1]\n                        if not 0 <= src_id < len(sources):\n                            raise SourceMapDecodeError(\n                                \"Segment %s references source %d; there are \"\n                                \"%d sources\" % (segment, src_id, len(sources))\n                            )\n\n                        src = sources[src_id]\n                        src_line += parse[2]\n                        src_col += parse[3]\n\n                        if len(parse) > 4:\n                            name_id += parse[4]\n                            if not 0 <= name_id < len(names):\n                                raise SourceMapDecodeError(\n                                    \"Segment %s references name %d; there are \"\n                                    \"%d names\" % (segment, name_id, len(names))\n                                )\n\n                            name = names[name_id]\n                    except IndexError:\n                        raise SourceMapDecodeError(\n                            \"Invalid segment %s, parsed as %r\"\n                            % (segment, parse)\n                        )\n\n                try:\n                    assert dst_line >= 0, ('dst_line', dst_line)\n                    assert dst_col >= 0, ('dst_col', dst_col)\n                    assert src_line >= 0, ('src_line', src_line)\n                    assert src_col >= 0, ('src_col', src_col)\n                except AssertionError as e:\n                    raise SourceMapDecodeError(\n                        \"Segment %s has negative %s (%d), in file %s\"\n                        % (segment, e.message[0], e.message[1], src)\n                    )\n\n                token = Token(dst_line, dst_col, src, src_line, src_col, name)\n                tokens.append(token)\n\n                # Insert into main index\n                index[(dst_line, dst_col)] = token\n\n                # Insert into specific line index\n                line_index[dst_line].append(dst_col)\n\n        return SourceMapIndex(smap, tokens, line_index, index, sources)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a JavaScript file find the sourceMappingURL line", "response": "def discover(source):\n    \"Given a JavaScript file, find the sourceMappingURL line\"\n    source = source.splitlines()\n    # Source maps are only going to exist at either the top or bottom of the document.\n    # Technically, there isn't anything indicating *where* it should exist, so we\n    # are generous and assume it's somewhere either in the first or last 5 lines.\n    # If it's somewhere else in the document, you're probably doing it wrong.\n    if len(source) > 10:\n        possibilities = source[:5] + source[-5:]\n    else:\n        possibilities = source\n\n    for line in set(possibilities):\n        pragma = line[:21]\n        if pragma == '//# sourceMappingURL=' or pragma == '//@ sourceMappingURL=':\n            # We want everything AFTER the pragma, which is 21 chars long\n            return line[21:].rstrip()\n    # XXX: Return None or raise an exception?\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bootstrap(options):\n    try:\n        import virtualenv\n    except ImportError, e:\n        raise RuntimeError(\"virtualenv is needed for bootstrap\")\n\n    bdir = options.bootstrap_dir\n    if not os.path.exists(bdir):\n        os.makedirs(bdir)\n    bscript = \"boostrap.py\"\n\n    options.virtualenv.script_name = os.path.join(options.bootstrap_dir,\n                                                  bscript)\n    options.virtualenv.no_site_packages = True\n    options.bootstrap.no_site_packages = True\n    print options.virtualenv.script_name\n    call_task('paver.virtual.bootstrap')\n    sh('cd %s; %s %s' % (bdir, sys.executable, bscript))", "response": "create virtualenv in. / bootstrap"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove build dist egg - info garbage.", "response": "def clean():\n    \"\"\"Remove build, dist, egg-info garbage.\"\"\"\n    d = ['build', 'dist', 'scikits.audiolab.egg-info', HTML_DESTDIR,\n            PDF_DESTDIR]\n    for i in d:\n        paver.path.path(i).rmtree()\n\n    (paver.path.path('docs') / options.sphinx.builddir).rmtree()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd new attendees to the event.", "response": "def add_attendees(self, attendees, required=True):\n    \"\"\"\n    Adds new attendees to the event.\n\n    *attendees* can be a list of email addresses or :class:`ExchangeEventAttendee` objects.\n    \"\"\"\n\n    new_attendees = self._build_resource_dictionary(attendees, required=required)\n\n    for email in new_attendees:\n      self._attendees[email] = new_attendees[email]\n\n    self._dirty_attributes.add(u'attendees')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving attendees from the event.", "response": "def remove_attendees(self, attendees):\n    \"\"\"\n    Removes attendees from the event.\n\n    *attendees* can be a list of email addresses or :class:`ExchangeEventAttendee` objects.\n    \"\"\"\n\n    attendees_to_delete = self._build_resource_dictionary(attendees)\n    for email in attendees_to_delete.keys():\n      if email in self._attendees:\n        del self._attendees[email]\n\n    self._dirty_attributes.add(u'attendees')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_resources(self, resources):\n    new_resources = self._build_resource_dictionary(resources)\n\n    for key in new_resources:\n      self._resources[key] = new_resources[key]\n    self._dirty_attributes.add(u'resources')", "response": "Adds new resources to the event."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves resources from the event.", "response": "def remove_resources(self, resources):\n    \"\"\"\n    Removes resources from the event.\n\n    *resources* can be a list of email addresses or :class:`ExchangeEventAttendee` objects.\n    \"\"\"\n\n    resources_to_delete = self._build_resource_dictionary(resources)\n    for email in resources_to_delete.keys():\n      if email in self._resources:\n        del self._resources[email]\n\n    self._dirty_attributes.add(u'resources')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that all required fields are present.", "response": "def validate(self):\n    \"\"\" Validates that all required fields are present \"\"\"\n    if not self.start:\n      raise ValueError(\"Event has no start date\")\n\n    if not self.end:\n      raise ValueError(\"Event has no end date\")\n\n    if self.end < self.start:\n      raise ValueError(\"Start date is after end date\")\n\n    if self.reminder_minutes_before_start and not isinstance(self.reminder_minutes_before_start, int):\n      raise TypeError(\"reminder_minutes_before_start must be of type int\")\n\n    if self.is_all_day and not isinstance(self.is_all_day, bool):\n      raise TypeError(\"is_all_day must be of type bool\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a system_info class with the given parameters.", "response": "def info_factory(name, libnames, headers, frameworks=None, \n                 section=None, classname=None):\n    \"\"\"Create a system_info class.\n\n    Parameters\n    ----------\n        name : str\n            name of the library\n        libnames : seq\n            list of libraries to look for\n        headers : seq\n            list of headers to look for\n        classname : str\n            name of the returned class\n        section : str\n            section name in the site.cfg\n\n    Returns\n    -------\n        a system_info-derived class with the given meta-parameters\n    \"\"\"\n    if not classname:\n        classname = '%s_info' % name\n    if not section:\n        section = name\n    if not frameworks:\n        framesworks = []\n\n    class _ret(system_info):\n        def __init__(self):\n            system_info.__init__(self)\n\n        def library_extensions(self):\n            return system_info.library_extensions(self)\n\n        def calc_info(self):\n            \"\"\" Compute the informations of the library \"\"\"\n            if libnames:\n                libs = self.get_libs('libraries', '')\n                if not libs:\n                    libs = libnames\n                # Look for the shared library\n                lib_dirs = self.get_lib_dirs()\n                tmp = None\n                for d in lib_dirs:\n                    tmp = self.check_libs(d, libs)\n                    if tmp is not None:\n                        info    = tmp\n                        break\n                if tmp is None:\n                    return\n\n                # Look for the header file\n                include_dirs = self.get_include_dirs()\n                inc_dir = None\n                for d in include_dirs:\n                    p = self.combine_paths(d, headers)\n                    if p:\n                        inc_dir = os.path.dirname(p[0])\n                        dict_append(info, include_dirs=[d])\n                        break\n\n                if inc_dir is None:\n                    log.info('  %s not found' % name)\n                    return\n\n                self.set_info(**info)\n            else:\n                # Look for frameworks\n                if frameworks:\n                    fargs = []\n                    for f in frameworks:\n                        p = \"/System/Library/Frameworks/%s.framework\" % f\n                        if os.path.exists(p):\n                            fargs.append(\"-framework\")\n                            fargs.append(f)\n                    if fargs:\n                        self.set_info(extra_link_args=fargs)\n            return\n\n    _ret.__name__ = classname\n    _ret.section = section\n    return _ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _writer_factory(name, format, def_fs, descr):\n    def basic_writer(data, filename, fs = def_fs, enc = format.encoding):\n        \"\"\"Common \"template\" to all write functions.\"\"\"\n        if np.ndim(data) <= 1:\n            nc      = 1\n        elif np.ndim(data) == 2:\n            nc      = data.shape[1]\n        else:\n            RuntimeError(\"Only rank 0, 1, and 2 arrays supported as audio data\")\n\n        uformat = Format(format.file_format, encoding=enc,\n                             endianness=format.endianness)\n        hdl = Sndfile(filename, 'w', uformat, nc, fs)\n        try:\n            hdl.write_frames(data)\n        finally:\n            hdl.close()\n    doc = \\\n    \"\"\"Simple writer for %(format)s audio files.\n\n    Parameters\n    ----------\n    data : array\n        a rank 1 (mono) or 2 (one channel per col) numpy array\n    filename : str\n        audio file name\n    fs : scalar\n        sampling rate in Hz (%(def_fs)s by default)\n    enc : str\n        The encoding such as 'pcm16', etc...(%(def_enc)s by default). A\n        list of supported encodings can be queried through the function\n        available_encodings.\n\n    Notes\n    -----\n    OVERWRITES EXISTING FILE !\n\n    These functions are similar to matlab's wavwrite/auwrite and the\n    like.  For total control over options, such as endianness, appending data\n    to an existing file, etc...  you should use Sndfile class instances\n    instead\n\n    See also\n    --------\n    available_encodings, Sndfile, Format\"\"\" \\\n            % {'format' : str(descr), 'def_fs': def_fs,\n               'def_enc': format.encoding}\n    basic_writer.__doc__    = doc\n    basic_writer.__name__   = name\n    return basic_writer", "response": "Create a basic writer function with fileformat described by format default\n    sampling rate def_fs and docstring descr."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_response_for_all_events(self, response):\n    items = response.xpath(u'//m:FindItemResponseMessage/m:RootFolder/t:Items/t:CalendarItem', namespaces=soap_request.NAMESPACES)\n    if not items:\n      items = response.xpath(u'//m:GetItemResponseMessage/m:Items/t:CalendarItem', namespaces=soap_request.NAMESPACES)\n    if items:\n      self.count = len(items)\n      log.debug(u'Found %s items' % self.count)\n\n      for item in items:\n        self._add_event(xml=soap_request.M.Items(deepcopy(item)))\n    else:\n      log.debug(u'No calendar items found with search parameters.')\n\n    return self", "response": "This function will parse the response to find all calendar items and add them to the event list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_all_details(self):\n    log.debug(u\"Loading all details\")\n    if self.count > 0:\n      # Now, empty out the events to prevent duplicates!\n      del(self.events[:])\n\n      # Send the SOAP request with the list of exchange ID values.\n      log.debug(u\"Requesting all event details for events: {event_list}\".format(event_list=str(self.event_ids)))\n      body = soap_request.get_item(exchange_id=self.event_ids, format=u'AllProperties')\n      response_xml = self.service.send(body)\n\n      # Re-parse the results for all the details!\n      self._parse_response_for_all_events(response_xml)\n\n    return self", "response": "This function will execute all the event lookups for known events and then load the details for all the events."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resend_invitations(self):\n\n    if not self.id:\n      raise TypeError(u\"You can't send invites for an event that hasn't been created yet.\")\n\n    # Under the hood, this is just an .update() but with no attributes changed.\n    # We're going to enforce that by checking if there are any changed attributes and bail if there are\n    if self._dirty_attributes:\n      raise ValueError(u\"There are unsaved changes to this invite - please update it first: %r\" % self._dirty_attributes)\n\n    self.refresh_change_key()\n    body = soap_request.update_item(self, [], calendar_item_update_operation_type=u'SendOnlyToAll')\n    self.service.send(body)\n\n    return self", "response": "Resend invitations for an event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate an event in Exchange.", "response": "def update(self, calendar_item_update_operation_type=u'SendToAllAndSaveCopy', **kwargs):\n    \"\"\"\n    Updates an event in Exchange.  ::\n\n        event = service.calendar().get_event(id='KEY HERE')\n        event.location = u'New location'\n        event.update()\n\n    If no changes to the event have been made, this method does nothing.\n\n    Notification of the change event is sent to all users. If you wish to just notify people who were\n    added, specify ``send_only_to_changed_attendees=True``.\n    \"\"\"\n    if not self.id:\n      raise TypeError(u\"You can't update an event that hasn't been created yet.\")\n\n    if 'send_only_to_changed_attendees' in kwargs:\n      warnings.warn(\n        \"The argument send_only_to_changed_attendees is deprecated.  Use calendar_item_update_operation_type instead.\",\n        DeprecationWarning,\n      )  # 20140502\n      if kwargs['send_only_to_changed_attendees']:\n        calendar_item_update_operation_type = u'SendToChangedAndSaveCopy'\n\n    VALID_UPDATE_OPERATION_TYPES = (\n      u'SendToNone', u'SendOnlyToAll', u'SendOnlyToChanged',\n      u'SendToAllAndSaveCopy', u'SendToChangedAndSaveCopy',\n    )\n    if calendar_item_update_operation_type not in VALID_UPDATE_OPERATION_TYPES:\n      raise ValueError('calendar_item_update_operation_type has unknown value')\n\n    self.validate()\n\n    if self._dirty_attributes:\n      log.debug(u\"Updating these attributes: %r\" % self._dirty_attributes)\n      self.refresh_change_key()\n\n      body = soap_request.update_item(self, self._dirty_attributes, calendar_item_update_operation_type=calendar_item_update_operation_type)\n      self.service.send(body)\n      self._reset_dirty_attributes()\n    else:\n      log.info(u\"Update was called, but there's nothing to update. Doing nothing.\")\n\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncanceling an event in Exchange.", "response": "def cancel(self):\n    \"\"\"\n    Cancels an event in Exchange.  ::\n\n        event = service.calendar().get_event(id='KEY HERE')\n        event.cancel()\n\n    This will send notifications to anyone who has not declined the meeting.\n    \"\"\"\n    if not self.id:\n      raise TypeError(u\"You can't delete an event that hasn't been created yet.\")\n\n    self.refresh_change_key()\n    self.service.send(soap_request.delete_event(self))\n    # TODO rsanders high - check return status to make sure it was actually sent\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the item to a different folder.", "response": "def move_to(self, folder_id):\n    \"\"\"\n    :param str folder_id: The Calendar ID to where you want to move the event to.\n    Moves an event to a different folder (calendar).  ::\n\n      event = service.calendar().get_event(id='KEY HERE')\n      event.move_to(folder_id='NEW CALENDAR KEY HERE')\n    \"\"\"\n    if not folder_id:\n      raise TypeError(u\"You can't move an event to a non-existant folder\")\n\n    if not isinstance(folder_id, BASESTRING_TYPES):\n      raise TypeError(u\"folder_id must be a string\")\n\n    if not self.id:\n      raise TypeError(u\"You can't move an event that hasn't been created yet.\")\n\n    self.refresh_change_key()\n    response_xml = self.service.send(soap_request.move_event(self, folder_id))\n    new_id, new_change_key = self._parse_id_and_change_key_from_response(response_xml)\n    if not new_id:\n      raise ValueError(u\"MoveItem returned success but requested item not moved\")\n\n    self._id = new_id\n    self._change_key = new_change_key\n    self.calendar_id = folder_id\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_master(self):\n\n    if self.type != 'Occurrence':\n      raise InvalidEventType(\"get_master method can only be called on a 'Occurrence' event type\")\n\n    body = soap_request.get_master(exchange_id=self._id, format=u\"AllProperties\")\n    response_xml = self.service.send(body)\n\n    return Exchange2010CalendarEvent(service=self.service, xml=response_xml)", "response": "This method returns the master event of the occurrence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_folder(self, parent_id):\n\n    body = soap_request.find_folder(parent_id=parent_id, format=u'AllProperties')\n    response_xml = self.service.send(body)\n    return self._parse_response_for_find_folder(response_xml)", "response": "This method will find all sub - folders within a given parent folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new folder in Exchange.", "response": "def create(self):\n    \"\"\"\n    Creates a folder in Exchange. ::\n\n      calendar = service.folder().new_folder(\n        display_name=u\"New Folder Name\",\n        folder_type=\"CalendarFolder\",\n        parent_id='calendar',\n      )\n      calendar.create()\n    \"\"\"\n\n    self.validate()\n    body = soap_request.new_folder(self)\n\n    response_xml = self.service.send(body)\n    self._id, self._change_key = self._parse_id_and_change_key_from_response(response_xml)\n\n    return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self):\n\n    if not self.id:\n      raise TypeError(u\"You can't delete a folder that hasn't been created yet.\")\n\n    body = soap_request.delete_folder(self)\n\n    response_xml = self.service.send(body)  # noqa\n    # TODO: verify deletion\n    self._id = None\n    self._change_key = None\n\n    return None", "response": "Delete a folder from the Exchange store."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_to(self, folder_id):\n\n    if not folder_id:\n      raise TypeError(u\"You can't move to a non-existant folder\")\n\n    if not isinstance(folder_id, BASESTRING_TYPES):\n      raise TypeError(u\"folder_id must be a string\")\n\n    if not self.id:\n      raise TypeError(u\"You can't move a folder that hasn't been created yet.\")\n\n    response_xml = self.service.send(soap_request.move_folder(self, folder_id))  # noqa\n\n    result_id, result_key = self._parse_id_and_change_key_from_response(response_xml)\n    if self.id != result_id:\n      raise ValueError(u\"MoveFolder returned success but requested folder not moved\")\n\n    self.parent_id = folder_id\n    return self", "response": "Move folder to a different location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nseeking to a specific offset in the file.", "response": "def seek(self, offset, whence=0, mode='rw'):\n        \"\"\"similar to python seek function, taking only in account audio data.\n\n        :Parameters:\n            offset : int\n                the number of frames (eg two samples for stereo files) to move\n                relatively to position set by whence.\n            whence : int\n                only 0 (beginning), 1 (current) and 2 (end of the file) are\n                valid.\n            mode : string\n                If set to 'rw', both read and write pointers are updated. If\n                'r' is given, only read pointer is updated, if 'w', only the\n                write one is (this may of course make sense only if you open\n                the file in a certain mode).\n\n        Notes\n        -----\n\n        - one only takes into accound audio data.\n        - if an invalid seek is given (beyond or before the file), a\n          PyaudioIOError is launched.\"\"\"\n        try:\n            st = self._sndfile.seek(offset, whence, mode)\n        except IOError, e:\n            raise PyaudioIOError(str(e))\n        return st"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread nframes frames of the file.", "response": "def read_frames(self, nframes, dtype=np.float64):\n        \"\"\"Read nframes frames of the file.\n\n        :Parameters:\n            nframes : int\n                number of frames to read.\n            dtype : numpy dtype\n                dtype of the returned array containing read data (see note).\n\n        Notes\n        -----\n\n        - read_frames updates the read pointer.\n        - One column is one channel (one row per channel after 0.9)\n        - if float are requested when the file contains integer data, you will\n          get normalized data (that is the max possible integer will be 1.0,\n          and the minimal possible value -1.0).\n        - if integers are requested when the file contains floating point data,\n          it may give wrong results because there is an ambiguity: if the\n          floating data are normalized, you can get a file with only 0 !\n          Getting integer data from files encoded in normalized floating point\n          is not supported (yet: sndfile supports it).\"\"\"\n        return self._sndfile.read_frames(nframes, dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_frames(self, input, nframes = -1):\n        if nframes == -1:\n            if input.ndim == 1:\n                nframes = input.size\n            elif input.ndim == 2:\n                nframes = input.shape[0]\n            else:\n                raise ValueError(\"Input has to be rank 1 (mono) or rank 2 \"\\\n                                 \"(multi-channels)\")\n        return self._sndfile.write_frames(input[:nframes,...])", "response": "write data to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item(exchange_id, format=u\"Default\"):\n\n  elements = list()\n  if type(exchange_id) == list:\n    for item in exchange_id:\n      elements.append(T.ItemId(Id=item))\n  else:\n    elements = [T.ItemId(Id=exchange_id)]\n\n  root = M.GetItem(\n    M.ItemShape(\n      T.BaseShape(format)\n    ),\n    M.ItemIds(\n      *elements\n    )\n  )\n  return root", "response": "Requests a calendar item from the store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a master calendar item from the Exchange store.", "response": "def get_master(exchange_id, format=u\"Default\"):\n  \"\"\"\n    Requests a calendar item from the store.\n\n    exchange_id is the id for this event in the Exchange store.\n\n    format controls how much data you get back from Exchange. Full docs are here, but acceptible values\n    are IdOnly, Default, and AllProperties.\n\n    http://msdn.microsoft.com/en-us/library/aa564509(v=exchg.140).aspx\n\n    <m:GetItem  xmlns:m=\"http://schemas.microsoft.com/exchange/services/2006/messages\"\n            xmlns:t=\"http://schemas.microsoft.com/exchange/services/2006/types\">\n      <m:ItemShape>\n          <t:BaseShape>{format}</t:BaseShape>\n      </m:ItemShape>\n      <m:ItemIds>\n          <t:RecurringMasterItemId OccurrenceId=\"{exchange_id}\"/>\n      </m:ItemIds>\n  </m:GetItem>\n\n  \"\"\"\n\n  root = M.GetItem(\n    M.ItemShape(\n      T.BaseShape(format)\n    ),\n    M.ItemIds(\n      T.RecurringMasterItemId(OccurrenceId=exchange_id)\n    )\n  )\n  return root"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting one or more calendar items from the store matching the master & index.", "response": "def get_occurrence(exchange_id, instance_index, format=u\"Default\"):\n  \"\"\"\n    Requests one or more calendar items from the store matching the master & index.\n\n    exchange_id is the id for the master event in the Exchange store.\n\n    format controls how much data you get back from Exchange. Full docs are here, but acceptible values\n    are IdOnly, Default, and AllProperties.\n\n    GetItem Doc:\n    http://msdn.microsoft.com/en-us/library/aa564509(v=exchg.140).aspx\n    OccurrenceItemId Doc:\n    http://msdn.microsoft.com/en-us/library/office/aa580744(v=exchg.150).aspx\n\n    <m:GetItem  xmlns:m=\"http://schemas.microsoft.com/exchange/services/2006/messages\"\n            xmlns:t=\"http://schemas.microsoft.com/exchange/services/2006/types\">\n      <m:ItemShape>\n          <t:BaseShape>{format}</t:BaseShape>\n      </m:ItemShape>\n      <m:ItemIds>\n        {% for index in instance_index %}\n          <t:OccurrenceItemId RecurringMasterId=\"{exchange_id}\" InstanceIndex=\"{{ index }}\"/>\n        {% endfor %}\n      </m:ItemIds>\n    </m:GetItem>\n  \"\"\"\n\n  root = M.GetItem(\n    M.ItemShape(\n      T.BaseShape(format)\n    ),\n    M.ItemIds()\n  )\n\n  items_node = root.xpath(\"//m:ItemIds\", namespaces=NAMESPACES)[0]\n  for index in instance_index:\n    items_node.append(T.OccurrenceItemId(RecurringMasterId=exchange_id, InstanceIndex=str(index)))\n  return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequests a new event be created in the store.", "response": "def new_event(event):\n  \"\"\"\n  Requests a new event be created in the store.\n\n  http://msdn.microsoft.com/en-us/library/aa564690(v=exchg.140).aspx\n\n  <m:CreateItem SendMeetingInvitations=\"SendToAllAndSaveCopy\"\n              xmlns:m=\"http://schemas.microsoft.com/exchange/services/2006/messages\"\n              xmlns:t=\"http://schemas.microsoft.com/exchange/services/2006/types\">\n    <m:SavedItemFolderId>\n        <t:DistinguishedFolderId Id=\"calendar\"/>\n    </m:SavedItemFolderId>\n    <m:Items>\n        <t:CalendarItem>\n            <t:Subject>{event.subject}</t:Subject>\n            <t:Body BodyType=\"HTML\">{event.subject}</t:Body>\n            <t:Start></t:Start>\n            <t:End></t:End>\n            <t:Location></t:Location>\n            <t:RequiredAttendees>\n                {% for attendee_email in meeting.required_attendees %}\n                <t:Attendee>\n                    <t:Mailbox>\n                        <t:EmailAddress>{{ attendee_email }}</t:EmailAddress>\n                    </t:Mailbox>\n                </t:Attendee>\n             HTTPretty   {% endfor %}\n            </t:RequiredAttendees>\n            {% if meeting.optional_attendees %}\n            <t:OptionalAttendees>\n                {% for attendee_email in meeting.optional_attendees %}\n                    <t:Attendee>\n                        <t:Mailbox>\n                            <t:EmailAddress>{{ attendee_email }}</t:EmailAddress>\n                        </t:Mailbox>\n                    </t:Attendee>\n                {% endfor %}\n            </t:OptionalAttendees>\n            {% endif %}\n            {% if meeting.conference_room %}\n            <t:Resources>\n                <t:Attendee>\n                    <t:Mailbox>\n                        <t:EmailAddress>{{ meeting.conference_room.email }}</t:EmailAddress>\n                    </t:Mailbox>\n                </t:Attendee>\n            </t:Resources>\n            {% endif %}\n            </t:CalendarItem>\n    </m:Items>\n</m:CreateItem>\n  \"\"\"\n\n  id = T.DistinguishedFolderId(Id=event.calendar_id) if event.calendar_id in DISTINGUISHED_IDS else T.FolderId(Id=event.calendar_id)\n\n  start = convert_datetime_to_utc(event.start)\n  end = convert_datetime_to_utc(event.end)\n\n  root = M.CreateItem(\n    M.SavedItemFolderId(id),\n    M.Items(\n      T.CalendarItem(\n        T.Subject(event.subject),\n        T.Body(event.body or u'', BodyType=\"HTML\"),\n      )\n    ),\n    SendMeetingInvitations=\"SendToAllAndSaveCopy\"\n  )\n\n  calendar_node = root.xpath(u'/m:CreateItem/m:Items/t:CalendarItem', namespaces=NAMESPACES)[0]\n\n  if event.reminder_minutes_before_start:\n    calendar_node.append(T.ReminderIsSet('true'))\n    calendar_node.append(T.ReminderMinutesBeforeStart(str(event.reminder_minutes_before_start)))\n  else:\n    calendar_node.append(T.ReminderIsSet('false'))\n\n  calendar_node.append(T.Start(start.strftime(EXCHANGE_DATETIME_FORMAT)))\n  calendar_node.append(T.End(end.strftime(EXCHANGE_DATETIME_FORMAT)))\n\n  if event.is_all_day:\n    calendar_node.append(T.IsAllDayEvent('true'))\n\n  calendar_node.append(T.Location(event.location or u''))\n\n  if event.required_attendees:\n    calendar_node.append(resource_node(element=T.RequiredAttendees(), resources=event.required_attendees))\n\n  if event.optional_attendees:\n    calendar_node.append(resource_node(element=T.OptionalAttendees(), resources=event.optional_attendees))\n\n  if event.resources:\n    calendar_node.append(resource_node(element=T.Resources(), resources=event.resources))\n\n  if event.recurrence:\n\n    if event.recurrence == u'daily':\n      recurrence = T.DailyRecurrence(\n        T.Interval(str(event.recurrence_interval)),\n      )\n    elif event.recurrence == u'weekly':\n      recurrence = T.WeeklyRecurrence(\n        T.Interval(str(event.recurrence_interval)),\n        T.DaysOfWeek(event.recurrence_days),\n      )\n    elif event.recurrence == u'monthly':\n      recurrence = T.AbsoluteMonthlyRecurrence(\n        T.Interval(str(event.recurrence_interval)),\n        T.DayOfMonth(str(event.start.day)),\n      )\n    elif event.recurrence == u'yearly':\n      recurrence = T.AbsoluteYearlyRecurrence(\n        T.DayOfMonth(str(event.start.day)),\n        T.Month(event.start.strftime(\"%B\")),\n      )\n\n    calendar_node.append(\n      T.Recurrence(\n        recurrence,\n        T.EndDateRecurrence(\n          T.StartDate(event.start.strftime(EXCHANGE_DATE_FORMAT)),\n          T.EndDate(event.recurrence_end_date.strftime(EXCHANGE_DATE_FORMAT)),\n        )\n      )\n    )\n\n  return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_property_node(node_to_insert, field_uri):\n  root = T.SetItemField(\n            T.FieldURI(FieldURI=field_uri),\n            T.CalendarItem(node_to_insert)\n        )\n  return root", "response": "Helper function - generates a SetItemField which tells Exchange you want to overwrite the contents of a field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_item(event, updated_attributes, calendar_item_update_operation_type):\n\n  root = M.UpdateItem(\n    M.ItemChanges(\n      T.ItemChange(\n        T.ItemId(Id=event.id, ChangeKey=event.change_key),\n        T.Updates()\n      )\n    ),\n    ConflictResolution=u\"AlwaysOverwrite\",\n    MessageDisposition=u\"SendAndSaveCopy\",\n    SendMeetingInvitationsOrCancellations=calendar_item_update_operation_type\n  )\n\n  update_node = root.xpath(u'/m:UpdateItem/m:ItemChanges/t:ItemChange/t:Updates', namespaces=NAMESPACES)[0]\n\n  # if not send_only_to_changed_attendees:\n  #   # We want to resend invites, which you do by setting an attribute to the same value it has. Right now, events\n  #   # are always scheduled as Busy time, so we just set that again.\n  #   update_node.append(\n  #     update_property_node(field_uri=\"calendar:LegacyFreeBusyStatus\", node_to_insert=T.LegacyFreeBusyStatus(\"Busy\"))\n  #   )\n\n  if u'html_body' in updated_attributes:\n    update_node.append(\n      update_property_node(field_uri=\"item:Body\", node_to_insert=T.Body(event.html_body, BodyType=\"HTML\"))\n    )\n\n  if u'text_body' in updated_attributes:\n    update_node.append(\n      update_property_node(field_uri=\"item:Body\", node_to_insert=T.Body(event.text_body, BodyType=\"Text\"))\n    )\n\n  if u'subject' in updated_attributes:\n    update_node.append(\n      update_property_node(field_uri=\"item:Subject\", node_to_insert=T.Subject(event.subject))\n    )\n\n  if u'start' in updated_attributes:\n    start = convert_datetime_to_utc(event.start)\n\n    update_node.append(\n      update_property_node(field_uri=\"calendar:Start\", node_to_insert=T.Start(start.strftime(EXCHANGE_DATETIME_FORMAT)))\n    )\n\n  if u'end' in updated_attributes:\n    end = convert_datetime_to_utc(event.end)\n\n    update_node.append(\n      update_property_node(field_uri=\"calendar:End\", node_to_insert=T.End(end.strftime(EXCHANGE_DATETIME_FORMAT)))\n    )\n\n  if u'location' in updated_attributes:\n    update_node.append(\n      update_property_node(field_uri=\"calendar:Location\", node_to_insert=T.Location(event.location))\n    )\n\n  if u'attendees' in updated_attributes:\n\n    if event.required_attendees:\n      required = resource_node(element=T.RequiredAttendees(), resources=event.required_attendees)\n\n      update_node.append(\n        update_property_node(field_uri=\"calendar:RequiredAttendees\", node_to_insert=required)\n      )\n    else:\n      update_node.append(delete_field(field_uri=\"calendar:RequiredAttendees\"))\n\n    if event.optional_attendees:\n      optional = resource_node(element=T.OptionalAttendees(), resources=event.optional_attendees)\n\n      update_node.append(\n        update_property_node(field_uri=\"calendar:OptionalAttendees\", node_to_insert=optional)\n      )\n    else:\n      update_node.append(delete_field(field_uri=\"calendar:OptionalAttendees\"))\n\n  if u'resources' in updated_attributes:\n    if event.resources:\n      resources = resource_node(element=T.Resources(), resources=event.resources)\n\n      update_node.append(\n        update_property_node(field_uri=\"calendar:Resources\", node_to_insert=resources)\n      )\n    else:\n      update_node.append(delete_field(field_uri=\"calendar:Resources\"))\n\n  if u'reminder_minutes_before_start' in updated_attributes:\n    if event.reminder_minutes_before_start:\n      update_node.append(\n        update_property_node(field_uri=\"item:ReminderIsSet\", node_to_insert=T.ReminderIsSet('true'))\n      )\n      update_node.append(\n        update_property_node(\n          field_uri=\"item:ReminderMinutesBeforeStart\",\n          node_to_insert=T.ReminderMinutesBeforeStart(str(event.reminder_minutes_before_start))\n        )\n      )\n    else:\n      update_node.append(\n        update_property_node(field_uri=\"item:ReminderIsSet\", node_to_insert=T.ReminderIsSet('false'))\n      )\n\n  if u'is_all_day' in updated_attributes:\n    update_node.append(\n      update_property_node(field_uri=\"calendar:IsAllDayEvent\", node_to_insert=T.IsAllDayEvent(str(event.is_all_day).lower()))\n    )\n\n  for attr in event.RECURRENCE_ATTRIBUTES:\n    if attr in updated_attributes:\n\n      recurrence_node = T.Recurrence()\n\n      if event.recurrence == 'daily':\n        recurrence_node.append(\n          T.DailyRecurrence(\n            T.Interval(str(event.recurrence_interval)),\n          )\n        )\n      elif event.recurrence == 'weekly':\n        recurrence_node.append(\n          T.WeeklyRecurrence(\n            T.Interval(str(event.recurrence_interval)),\n            T.DaysOfWeek(event.recurrence_days),\n          )\n        )\n      elif event.recurrence == 'monthly':\n        recurrence_node.append(\n          T.AbsoluteMonthlyRecurrence(\n            T.Interval(str(event.recurrence_interval)),\n            T.DayOfMonth(str(event.start.day)),\n          )\n        )\n      elif event.recurrence == 'yearly':\n        recurrence_node.append(\n          T.AbsoluteYearlyRecurrence(\n            T.DayOfMonth(str(event.start.day)),\n            T.Month(event.start.strftime(\"%B\")),\n          )\n        )\n\n      recurrence_node.append(\n        T.EndDateRecurrence(\n          T.StartDate(event.start.strftime(EXCHANGE_DATE_FORMAT)),\n          T.EndDate(event.recurrence_end_date.strftime(EXCHANGE_DATE_FORMAT)),\n        )\n      )\n\n      update_node.append(\n        update_property_node(field_uri=\"calendar:Recurrence\", node_to_insert=recurrence_node)\n      )\n\n  return root", "response": "Saves updates to an event in the store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_request(self, method, url, callback_url = None, get = None, post = None, files = None, stream = False, is_json = True):\n\t\tif files == {}:\n\t\t\tfiles = None\n\t\tself._multipart = files is not None\n\t\theader = self.get_oauth_header(method, url, callback_url, get, post)\n\t\tif get:\n\t\t\tfull_url = url + \"?\" + urllib.urlencode(get)\n\t\telse:\n\t\t\tfull_url = url\n\t\t\"\"\"# DEBUG\n\t\tinfo = \"=\" * 50 + \"\\n\"\n\t\tinfo += \"Method:    %s\\n\" % method\n\t\tinfo += \"URL:       %s\\n\" % full_url\n\t\tinfo += \"Headers:   %s\\n\" % str(header)\n\t\tinfo += \"GET data:  %s\\n\" % str(get)\n\t\tinfo += \"POST data: %s\\n\" % str(post)\n\t\tinfo += \"Files:     %s\\n\" % str(files)\n\t\tinfo += \"Streaming: %s\\n\" % str(stream)\n\t\tinfo += \"JSON:      %s\\n\" % str(is_json)\n\t\tinfo += \"=\" * 50\n\t\tprint info\n\t\t# END DEBUG\"\"\"\n\t\tif method.upper() == \"POST\":\n\t\t\tresponse = requests.post(full_url, data = post, files = files, headers = header, stream = stream, timeout = self.timeout)\n\t\telse:\n\t\t\tresponse = requests.get(full_url, data = post, files = files, headers = header, stream = stream, timeout = self.timeout)\n\t\t\"\"\"# DEBUG\n\t\tprint (\"\\nResponse:  %s\\n\" % response.text) + \"=\" * 50\n\t\t# END DEBUG\"\"\"\n\t\tif response.status_code != 200:\n\t\t\ttry:\n\t\t\t\tdata = response.json()\n\t\t\t\ttry:\n\t\t\t\t\traise APIError(code = data['errors'][0]['code'], description = data['errors'][0]['message'], body = response.text or None)\n\t\t\t\texcept TypeError:\n\t\t\t\t\traise APIError(code = None, description = data['errors'])\n\t\t\texcept APIError:\n\t\t\t\traise\n\t\t\texcept:\n\t\t\t\tdescription = \" \".join(response.headers['status'].split()[1:]) if response.headers.get('status', None) else \"Unknown Error\"\n\t\t\t\traise APIError(code = response.status_code, description = description, body = response.text or None)\n\t\tif stream:\n\t\t\treturn response\n\t\tif is_json:\n\t\t\ttry:\n\t\t\t\treturn response.json()\n\t\t\texcept:\n\t\t\t\treturn response.text\n\t\telse:\n\t\t\treturn response.text", "response": "This function handles the request to the API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_example(rh, method, example_type):\n    example = getattr(method, example_type + \"_example\")\n    schema = getattr(method, example_type + \"_schema\")\n\n    if example is None:\n        return None\n\n    try:\n        validate(example, schema)\n    except ValidationError as e:\n        raise ValidationError(\n            \"{}_example for {}.{} could not be validated.\\n{}\".format(\n                example_type, rh.__name__, method.__name__, str(e)\n            )\n        )\n\n    return json.dumps(example, indent=4, sort_keys=True)", "response": "Validates example against schema\nWorkItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields all HTTP methods in the given resource hierarchy that are decorated with schema. validate.", "response": "def _get_rh_methods(rh):\n    \"\"\"Yield all HTTP methods in ``rh`` that are decorated\n    with schema.validate\"\"\"\n    for k, v in vars(rh).items():\n        if all([\n            k in HTTP_METHODS,\n            is_method(v),\n            hasattr(v, \"input_schema\")\n        ]):\n            yield (k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_tuple_from_route(route):\n    if isinstance(route, tuple):\n        assert len(route) >= 2\n        pattern, handler_class = route[:2]\n    elif isinstance(route, tornado.web.URLSpec):\n        pattern, handler_class = route.regex.pattern, route.handler_class\n    else:\n        raise TypeError(\"Unknown route type '{}'\"\n                        .format(type(route).__name__))\n\n    methods = []\n    route_re = re.compile(pattern)\n    route_params = set(list(route_re.groupindex.keys()) + ['self'])\n    for http_method in HTTP_METHODS:\n        method = getattr(handler_class, http_method, None)\n        if method:\n            method = extract_method(method)\n            method_params = set(getattr(method, \"__argspec_args\",\n                                        inspect.getargspec(method).args))\n            if route_params.issubset(method_params) and \\\n                    method_params.issubset(route_params):\n                methods.append(http_method)\n\n    return pattern, handler_class, methods", "response": "Return a tuple from a route."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _escape_markdown_literals(string):\n    literals = list(\"\\\\`*_{}[]()<>#+-.!:|\")\n    escape = lambda c: '\\\\' + c if c in literals else c\n    return \"\".join(map(escape, string))", "response": "Escape any markdown literals in string by prepending with \\\\"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove uniform indents from doc lines that are not empty", "response": "def _cleandoc(doc):\n    \"\"\"Remove uniform indents from ``doc`` lines that are not empty\n\n    :returns: Cleaned ``doc``\n    \"\"\"\n    indent_length = lambda s: len(s) - len(s.lstrip(\" \"))\n    not_empty = lambda s: s != \"\"\n\n    lines = doc.split(\"\\n\")\n    indent = min(map(indent_length, filter(not_empty, lines)))\n\n    return \"\\n\".join(s[indent:] for s in lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds indent of indent spaces to the beginning of the string", "response": "def _add_indent(string, indent):\n    \"\"\"Add indent of ``indent`` spaces to ``string.split(\"\\n\")[1:]``\n\n    Useful for formatting in strings to already indented blocks\n    \"\"\"\n    lines = string.split(\"\\n\")\n    first, lines = lines[0], lines[1:]\n    lines = [\"{indent}{s}\".format(indent=\" \" * indent, s=s)\n             for s in lines]\n    lines = [first] + lines\n    return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_api_docs(routes):\n    routes = map(_get_tuple_from_route, routes)\n    documentation = []\n    for url, rh, methods in sorted(routes, key=lambda a: a[0]):\n        if issubclass(rh, APIHandler):\n            documentation.append(_get_route_doc(url, rh, methods))\n\n    documentation = (\n        \"**This documentation is automatically generated.**\\n\\n\" +\n        \"**Output schemas only represent `data` and not the full output; \" +\n        \"see output examples and the JSend specification.**\\n\" +\n        \"\\n<br>\\n<br>\\n\".join(documentation)\n    )\n    return documentation", "response": "Generates a GFM - formatted API documentation using the provided routes and their docstrings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite an error message to the log.", "response": "def error(self, message, data=None, code=None):\n        \"\"\"An error occurred in processing the request, i.e. an exception was\n        thrown.\n\n        :type  data: A JSON-serializable object\n        :param data: A generic container for any other information about the\n            error, i.e. the conditions that caused the error,\n            stack traces, etc.\n        :type  message: A JSON-serializable object\n        :param message: A meaningful, end-user-readable (or at the least\n            log-worthy) message, explaining what went wrong\n        :type  code: int\n        :param code: A numeric code corresponding to the error, if applicable\n        \"\"\"\n        result = {'status': 'error', 'message': message}\n        if data:\n            result['data'] = data\n        if code:\n            result['code'] = code\n        self.write(result)\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract default values dict from an object schema.", "response": "def get_object_defaults(object_schema):\n    \"\"\"\n    Extracts default values dict (nested) from an type object schema.\n\n    :param object_schema: Schema type object\n    :type  object_schema: dict\n    :returns: Nested dict with defaults values\n    \"\"\"\n    default = {}\n    for k, schema in object_schema.get('properties', {}).items():\n\n        if schema.get('type') == 'object':\n            if 'default' in schema:\n                default[k] = schema['default']\n\n            try:\n                object_defaults = get_object_defaults(schema)\n            except NoObjectDefaults:\n                if 'default' not in schema:\n                    raise NoObjectDefaults\n            else:\n                if 'default' not in schema:\n                    default[k] = {}\n\n                default[k].update(object_defaults)\n        else:\n            if 'default' in schema:\n                default[k] = schema['default']\n\n    if default:\n        return default\n\n    raise NoObjectDefaults"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef input_schema_clean(input_, input_schema):\n    if input_schema.get('type') == 'object':\n        try:\n            defaults = get_object_defaults(input_schema)\n        except NoObjectDefaults:\n            pass\n        else:\n            return deep_update(defaults, input_)\n    return input_", "response": "Updates the input data with the default values of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(input_schema=None, output_schema=None,\n             input_example=None, output_example=None,\n             validator_cls=None,\n             format_checker=None, on_empty_404=False,\n             use_defaults=False):\n    \"\"\"Parameterized decorator for schema validation\n\n    :type validator_cls: IValidator class\n    :type format_checker: jsonschema.FormatChecker or None\n    :type on_empty_404: bool\n    :param on_empty_404: If this is set, and the result from the\n        decorated method is a falsy value, a 404 will be raised.\n    :type use_defaults: bool\n    :param use_defaults: If this is set, will put 'default' keys\n        from schema to self.body (If schema type is object). Example:\n            {\n                'published': {'type': 'bool', 'default': False}\n            }\n        self.body will contains 'published' key with value False if no one\n        comes from request, also works with nested schemas.\n    \"\"\"\n    @container\n    def _validate(rh_method):\n        \"\"\"Decorator for RequestHandler schema validation\n\n        This decorator:\n\n            - Validates request body against input schema of the method\n            - Calls the ``rh_method`` and gets output from it\n            - Validates output against output schema of the method\n            - Calls ``JSendMixin.success`` to write the validated output\n\n        :type  rh_method: function\n        :param rh_method: The RequestHandler method to be decorated\n        :returns: The decorated method\n        :raises ValidationError: If input is invalid as per the schema\n            or malformed\n        :raises TypeError: If the output is invalid as per the schema\n            or malformed\n        :raises APIError: If the output is a falsy value and\n            on_empty_404 is True, an HTTP 404 error is returned\n        \"\"\"\n        @wraps(rh_method)\n        @tornado.gen.coroutine\n        def _wrapper(self, *args, **kwargs):\n            # In case the specified input_schema is ``None``, we\n            #   don't json.loads the input, but just set it to ``None``\n            #   instead.\n            if input_schema is not None:\n                # Attempt to json.loads the input\n                try:\n                    # TODO: Assuming UTF-8 encoding for all requests,\n                    #   find a nice way of determining this from charset\n                    #   in headers if provided\n                    encoding = \"UTF-8\"\n                    input_ = json.loads(self.request.body.decode(encoding))\n                except ValueError as e:\n                    raise jsonschema.ValidationError(\n                        \"Input is malformed; could not decode JSON object.\"\n                    )\n\n                if use_defaults:\n                    input_ = input_schema_clean(input_, input_schema)\n\n                # Validate the received input\n                jsonschema.validate(\n                    input_,\n                    input_schema,\n                    cls=validator_cls,\n                    format_checker=format_checker\n                )\n            else:\n                input_ = None\n\n            # A json.loads'd version of self.request[\"body\"] is now available\n            #   as self.body\n            setattr(self, \"body\", input_)\n            # Call the requesthandler method\n            output = rh_method(self, *args, **kwargs)\n            # If the rh_method returned a Future a la `raise Return(value)`\n            #   we grab the output.\n            if is_future(output):\n                output = yield output\n\n            # if output is empty, auto return the error 404.\n            if not output and on_empty_404:\n                raise APIError(404, \"Resource not found.\")\n\n            if output_schema is not None:\n                # We wrap output in an object before validating in case\n                #  output is a string (and ergo not a validatable JSON object)\n                try:\n                    jsonschema.validate(\n                        {\"result\": output},\n                        {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"result\": output_schema\n                            },\n                            \"required\": [\"result\"]\n                        }\n                    )\n                except jsonschema.ValidationError as e:\n                    # We essentially re-raise this as a TypeError because\n                    #  we don't want this error data passed back to the client\n                    #  because it's a fault on our end. The client should\n                    #  only see a 500 - Internal Server Error.\n                    raise TypeError(str(e))\n\n            # If no ValidationError has been raised up until here, we write\n            #  back output\n            self.success(output)\n\n        setattr(_wrapper, \"input_schema\", input_schema)\n        setattr(_wrapper, \"output_schema\", output_schema)\n        setattr(_wrapper, \"input_example\", input_example)\n        setattr(_wrapper, \"output_example\", output_example)\n\n        return _wrapper\n    return _validate", "response": "Validate the request body against the specified schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(filename):\n    return codecs.open(os.path.join(__DIR__, filename), 'r').read()", "response": "Read and return filename in root dir of project and return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates a nested dictionary or similar mapping.", "response": "def deep_update(source, overrides):\n    \"\"\"Update a nested dictionary or similar mapping.\n\n    Modify ``source`` in place.\n\n    :type source: collections.Mapping\n    :type overrides: collections.Mapping\n    :rtype: collections.Mapping\n    \"\"\"\n    for key, value in overrides.items():\n        if isinstance(value, collections.Mapping) and value:\n            returned = deep_update(source.get(key, {}), value)\n            source[key] = returned\n        else:\n            source[key] = overrides[key]\n    return source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_handler_subclass(cls, classnames=(\"ViewHandler\", \"APIHandler\")):\n    if isinstance(cls, list):\n        return any(is_handler_subclass(c) for c in cls)\n    elif isinstance(cls, type):\n        return any(c.__name__ in classnames for c in inspect.getmro(cls))\n    else:\n        raise TypeError(\n            \"Unexpected type `{}` for class `{}`\".format(\n                type(cls),\n                cls\n            )\n        )", "response": "Determines if cls is indeed a subclass of classnames."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride of RequestHandler. write_error which calls error or fail depending on status_code and kwargs.", "response": "def write_error(self, status_code, **kwargs):\n        \"\"\"Override of RequestHandler.write_error\n\n        Calls ``error()`` or ``fail()`` from JSendMixin depending on which\n        exception was raised with provided reason and status code.\n\n        :type  status_code: int\n        :param status_code: HTTP status code\n        \"\"\"\n        def get_exc_message(exception):\n            return exception.log_message if \\\n                hasattr(exception, \"log_message\") else str(exception)\n\n        self.clear()\n        self.set_status(status_code)\n\n        # Any APIError exceptions raised will result in a JSend fail written\n        # back with the log_message as data. Hence, log_message should NEVER\n        # expose internals. Since log_message is proprietary to HTTPError\n        # class exceptions, all exceptions without it will return their\n        # __str__ representation.\n        # All other exceptions result in a JSend error being written back,\n        # with log_message only written if debug mode is enabled\n        exception = kwargs[\"exc_info\"][1]\n        if any(isinstance(exception, c) for c in [APIError, ValidationError]):\n            # ValidationError is always due to a malformed request\n            if isinstance(exception, ValidationError):\n                self.set_status(400)\n            self.fail(get_exc_message(exception))\n        else:\n            self.error(\n                message=self._reason,\n                data=get_exc_message(exception) if self.settings.get(\"debug\")\n                else None,\n                code=status_code\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk package and yield all submodules of package", "response": "def gen_submodule_names(package):\n    \"\"\"Walk package and yield names of all submodules\n\n    :type  package: package\n    :param package: The package to get submodule names of\n    :returns: Iterator that yields names of all submodules of ``package``\n    :rtype: Iterator that yields ``str``\n    \"\"\"\n    for importer, modname, ispkg in pkgutil.walk_packages(\n        path=package.__path__,\n        prefix=package.__name__ + '.',\n            onerror=lambda x: None):\n        yield modname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_module_routes(module_name, custom_routes=None, exclusions=None,\n                      arg_pattern=r'(?P<{}>[a-zA-Z0-9_\\-]+)'):\n    \"\"\"Create and return routes for module_name\n\n    Routes are (url, RequestHandler) tuples\n\n    :returns: list of routes for ``module_name`` with respect to ``exclusions``\n        and ``custom_routes``. Returned routes are with URLs formatted such\n        that they are forward-slash-separated by module/class level\n        and end with the lowercase name of the RequestHandler (it will also\n        remove 'handler' from the end of the name of the handler).\n        For example, a requesthandler with the name\n        ``helloworld.api.HelloWorldHandler`` would be assigned the url\n        ``/api/helloworld``.\n        Additionally, if a method has extra arguments aside from ``self`` in\n        its signature, routes with URL patterns will be generated to\n        match ``r\"(?P<{}>[a-zA-Z0-9_\\-]+)\".format(argname)`` for each\n        argument. The aforementioned regex will match ONLY values\n        with alphanumeric, hyphen and underscore characters. You can provide\n        your own pattern by setting a ``arg_pattern`` param.\n    :rtype: [(url, RequestHandler), ... ]\n    :type  module_name: str\n    :param module_name: Name of the module to get routes for\n    :type  custom_routes: [(str, RequestHandler), ... ]\n    :param custom_routes: List of routes that have custom URLs and therefore\n        should be automagically generated\n    :type  exclusions: [str, str, ...]\n    :param exclusions: List of RequestHandler names that routes should not be\n        generated for\n    :type  arg_pattern: str\n    :param arg_pattern: Default pattern for extra arguments of any method\n    \"\"\"\n    def has_method(module, cls_name, method_name):\n        return all([\n            method_name in vars(getattr(module, cls_name)),\n            is_method(reduce(getattr, [module, cls_name, method_name]))\n        ])\n\n    def yield_args(module, cls_name, method_name):\n        \"\"\"Get signature of ``module.cls_name.method_name``\n\n        Confession: This function doesn't actually ``yield`` the arguments,\n            just returns a list. Trust me, it's better that way.\n\n        :returns: List of arg names from method_name except ``self``\n        :rtype: list\n        \"\"\"\n        wrapped_method = reduce(getattr, [module, cls_name, method_name])\n        method = extract_method(wrapped_method)\n\n        # If using tornado_json.gen.coroutine, original args are annotated...\n        argspec_args = getattr(method, \"__argspec_args\",\n                               # otherwise just grab them from the method\n                               inspect.getargspec(method).args)\n\n        return [a for a in argspec_args if a not in [\"self\"]]\n\n    def generate_auto_route(module, module_name, cls_name, method_name, url_name):\n        \"\"\"Generate URL for auto_route\n\n        :rtype: str\n        :returns: Constructed URL based on given arguments\n        \"\"\"\n        def get_handler_name():\n            \"\"\"Get handler identifier for URL\n\n            For the special case where ``url_name`` is\n            ``__self__``, the handler is named a lowercase\n            value of its own name with 'handler' removed\n            from the ending if give; otherwise, we\n            simply use the provided ``url_name``\n            \"\"\"\n            if url_name == \"__self__\":\n                if cls_name.lower().endswith('handler'):\n                    return cls_name.lower().replace('handler', '', 1)\n                return cls_name.lower()\n            else:\n                return url_name\n\n        def get_arg_route():\n            \"\"\"Get remainder of URL determined by method argspec\n\n            :returns: Remainder of URL which matches `\\w+` regex\n                with groups named by the method's argument spec.\n                If there are no arguments given, returns ``\"\"``.\n            :rtype: str\n            \"\"\"\n            if yield_args(module, cls_name, method_name):\n                return \"/{}/?$\".format(\"/\".join(\n                    [arg_pattern.format(argname) for argname\n                     in yield_args(module, cls_name, method_name)]\n                ))\n            return r\"/?\"\n\n        return \"/{}/{}{}\".format(\n            \"/\".join(module_name.split(\".\")[1:]),\n            get_handler_name(),\n            get_arg_route()\n        )\n\n    if not custom_routes:\n        custom_routes = []\n    if not exclusions:\n        exclusions = []\n\n    # Import module so we can get its request handlers\n    module = importlib.import_module(module_name)\n\n    # Generate list of RequestHandler names in custom_routes\n    custom_routes_s = [c.__name__ for r, c in custom_routes]\n\n    rhs = {cls_name: cls for (cls_name, cls) in\n           inspect.getmembers(module, inspect.isclass)}\n\n    # You better believe this is a list comprehension\n    auto_routes = list(chain(*[\n        list(set(chain(*[\n            # Generate a route for each \"name\" specified in the\n            #   __url_names__ attribute of the handler\n            [\n                # URL, requesthandler tuple\n                (\n                    generate_auto_route(\n                        module, module_name, cls_name, method_name, url_name\n                    ),\n                    getattr(module, cls_name)\n                ) for url_name in getattr(module, cls_name).__url_names__\n                # Add routes for each custom URL specified in the\n                #   __urls__ attribute of the handler\n            ] + [\n                (\n                    url,\n                    getattr(module, cls_name)\n                ) for url in getattr(module, cls_name).__urls__\n            ]\n            # We create a route for each HTTP method in the handler\n            #   so that we catch all possible routes if different\n            #   HTTP methods have different argspecs and are expecting\n            #   to catch different routes. Any duplicate routes\n            #   are removed from the set() comparison.\n            for method_name in HTTP_METHODS if has_method(\n                module, cls_name, method_name)\n        ])))\n        # foreach classname, pyclbr.Class in rhs\n        for cls_name, cls in rhs.items()\n        # Only add the pair to auto_routes if:\n        #    * the superclass is in the list of supers we want\n        #    * the requesthandler isn't already paired in custom_routes\n        #    * the requesthandler isn't manually excluded\n        if is_handler_subclass(cls)\n        and cls_name not in (custom_routes_s + exclusions)\n    ]))\n\n    routes = auto_routes + custom_routes\n    return routes", "response": "Create and return a list of routes for a module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, name):\n        # Asynchronously yield a result from a method\n        res = yield gen.Task(self.hello, name)\n\n        # When using the `schema.validate` decorator asynchronously,\n        #   we can return the output desired by raising\n        #   `tornado.gen.Return(value)` which returns a\n        #   Future that the decorator will yield.\n        # In Python 3.3, using `raise Return(value)` is no longer\n        #   necessary and can be replaced with simply `return value`.\n        #   For details, see:\n        # http://www.tornadoweb.org/en/branch3.2/gen.html#tornado.gen.Return\n\n        # return res  # Python 3.3\n        raise gen.Return(res)", "response": "Get a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef coroutine(func, replace_callback=True):\n    # gen.coroutine in tornado 3.x.x and 5.x.x have a different signature than 4.x.x\n    if TORNADO_MAJOR != 4:\n        wrapper = gen.coroutine(func)\n    else:\n        wrapper = gen.coroutine(func, replace_callback)\n    wrapper.__argspec_args = inspect.getargspec(func).args\n    return wrapper", "response": "Tornado - JSON compatible wrapper for tornado. gen. coroutine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_argparse():\n    parser = argparse.ArgumentParser(\n        description='Convert old ini-style GNS3 topologies (<=0.8.7) to '\n                    'the newer version 1+ JSON format')\n    parser.add_argument('--version',\n                        action='version',\n                        version='%(prog)s ' + __version__)\n    parser.add_argument('-n', '--name', help='Topology name (default uses the '\n                                             'name of the old project '\n                                             'directory)')\n    parser.add_argument('-o', '--output', help='Output directory')\n    parser.add_argument('topology', nargs='?', default='topology.net',\n                        help='GNS3 .net topology file (default: topology.net)')\n    parser.add_argument('--debug',\n                        help='Enable debugging output',\n                        action='store_true')\n    parser.add_argument('-q', '--quiet',\n                        help='Quiet-mode (no output to console)',\n                        action='store_true')\n    return parser", "response": "Setup the argparse argument parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the topology to JSON format", "response": "def do_conversion(topology_def, topology_name, output_dir=None, debug=False,\n                  quiet=False):\n    \"\"\"\n    Convert the topology\n\n    :param dict topology_def: Dict containing topology file and snapshot bool.\n                              For example:\n                              ``{'file': filename, 'snapshot': False}``\n    :param str topology_name: The name of the topology\n    :param str output_dir: The directory in which to output the topology.\n                           (Default: None)\n    :param bool debug: Enable debugging (Default: False)\n    \"\"\"\n    # Create a new instance of the the Converter\n    gns3_conv = Converter(topology_def['file'], debug)\n    # Read the old topology\n    old_top = gns3_conv.read_topology()\n    new_top = JSONTopology()\n\n    # Process the sections\n    (topology) = gns3_conv.process_topology(old_top)\n\n    # Generate the nodes\n    new_top.nodes = gns3_conv.generate_nodes(topology)\n    # Generate the links\n    new_top.links = gns3_conv.generate_links(new_top.nodes)\n\n    new_top.notes = gns3_conv.generate_notes(topology['artwork']['NOTE'])\n    new_top.shapes = gns3_conv.generate_shapes(topology['artwork']['SHAPE'])\n    new_top.images = gns3_conv.generate_images(topology['artwork']['PIXMAP'])\n\n    # Enter topology name\n    new_top.name = topology_name\n\n    # Save the new topology\n    save(output_dir, gns3_conv, new_top, topology_def['snapshot'], quiet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_snapshots(topology):\n    snapshots = []\n    snap_dir = os.path.join(topology_dirname(topology), 'snapshots')\n    if os.path.exists(snap_dir):\n        snaps = os.listdir(snap_dir)\n        for directory in snaps:\n            snap_top = os.path.join(snap_dir, directory, 'topology.net')\n            if os.path.exists(snap_top):\n                snapshots.append({'file': snap_top,\n                                  'snapshot': True})\n    return snapshots", "response": "Return the paths of any snapshot topologies"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(topology_file, topology_name=None):\n    if topology_name is not None:\n        logging.debug('topology name supplied')\n        topo_name = topology_name\n    else:\n        logging.debug('topology name not supplied')\n        topo_name = os.path.basename(topology_dirname(topology_file))\n    return topo_name", "response": "Calculate the name to save the converted topology as using either topology_name or the directory name of the current project s topology."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the snapshot name from the topology file location", "response": "def snapshot_name(topo_name):\n    \"\"\"\n    Get the snapshot name\n\n    :param str topo_name: topology file location. The name is taken from the\n                          directory containing the topology file using the\n                          following format: topology_NAME_snapshot_DATE_TIME\n    :return: snapshot name\n    :raises ConvertError: when unable to determine the snapshot name\n    \"\"\"\n    topo_name = os.path.basename(topology_dirname(topo_name))\n    snap_re = re.compile('^topology_(.+)(_snapshot_)(\\d{6}_\\d{6})$')\n    result = snap_re.search(topo_name)\n\n    if result is not None:\n        snap_name = result.group(1) + '_' + result.group(3)\n    else:\n        raise ConvertError('Unable to get snapshot name')\n\n    return snap_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the converted topology to the output directory.", "response": "def save(output_dir, converter, json_topology, snapshot, quiet):\n    \"\"\"\n    Save the converted topology\n\n    :param str output_dir: Output Directory\n    :param Converter converter: Converter instance\n    :param JSONTopology json_topology: JSON topology layout\n    :param bool snapshot: Is this a snapshot?\n    :param bool quiet: No console printing\n    \"\"\"\n    try:\n        old_topology_dir = topology_dirname(converter.topology)\n\n        if output_dir:\n            output_dir = os.path.abspath(output_dir)\n        else:\n            output_dir = os.getcwd()\n\n        topology_name = json_topology.name\n        topology_files_dir = os.path.join(output_dir, topology_name + '-files')\n\n        if snapshot:\n            snap_name = snapshot_name(converter.topology)\n            output_dir = os.path.join(topology_files_dir, 'snapshots',\n                                      snap_name)\n            topology_files_dir = os.path.join(output_dir, topology_name +\n                                              '-files')\n\n        # Prepare the directory structure\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n\n        # Move the dynamips config files to the new topology folder\n        config_err = copy_configs(converter.configs, old_topology_dir,\n                                  topology_files_dir)\n\n        # Copy any VPCS configurations to the the new topology\n        copy_vpcs_configs(old_topology_dir, topology_files_dir)\n\n        # Copy the topology images to the new topology\n        copy_topology_image(old_topology_dir, output_dir)\n\n        # Copy the instructions to the new topology folder\n        if not snapshot:\n            copy_instructions(old_topology_dir, output_dir)\n\n        # Move the image files to the new topology folder\n        image_err = copy_images(converter.images, old_topology_dir,\n                                topology_files_dir)\n\n        # Create the vbox working directories\n        make_vbox_dirs(json_topology.get_vboxes(), output_dir, topology_name)\n\n        # Create the qemu working directories\n        make_qemu_dirs(json_topology.get_qemus(), output_dir, topology_name)\n\n        if config_err:\n            logging.warning('Some router startup configurations could not be '\n                            'found to be copied to the new topology')\n\n        if image_err:\n            logging.warning('Some images could not be found to be copied to '\n                            'the new topology')\n\n        filename = '%s.gns3' % topology_name\n        file_path = os.path.join(output_dir, filename)\n        with open(file_path, 'w') as file:\n            json.dump(json_topology.get_topology(), file, indent=4,\n                      sort_keys=True)\n            if not snapshot and not quiet:\n                print('Your topology has been converted and can found in:\\n'\n                      '     %s' % output_dir)\n    except OSError as error:\n        logging.error(error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_configs(configs, source, target):\n    config_err = False\n    if len(configs) > 0:\n        config_dir = os.path.join(target, 'dynamips', 'configs')\n        os.makedirs(config_dir)\n        for config in configs:\n            old_config_file = os.path.join(source, config['old'])\n            new_config_file = os.path.join(config_dir,\n                                           os.path.basename(config['new']))\n            if os.path.isfile(old_config_file):\n                # Copy and rename the config\n                shutil.copy(old_config_file, new_config_file)\n            else:\n                config_err = True\n                logging.error('Unable to find %s' % config['old'])\n    return config_err", "response": "Copy dynamips configs to converted topology"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies any VPCS configs to the converted topology", "response": "def copy_vpcs_configs(source, target):\n    \"\"\"\n    Copy any VPCS configs to the converted topology\n\n    :param str source: Source topology directory\n    :param str target: Target topology files directory\n    \"\"\"\n    # Prepare a list of files to copy\n    vpcs_files = glob.glob(os.path.join(source, 'configs', '*.vpc'))\n    vpcs_hist = os.path.join(source, 'configs', 'vpcs.hist')\n    vpcs_config_path = os.path.join(target, 'vpcs', 'multi-host')\n    if os.path.isfile(vpcs_hist):\n        vpcs_files.append(vpcs_hist)\n    # Create the directory tree\n    if len(vpcs_files) > 0:\n        os.makedirs(vpcs_config_path)\n    # Copy the files\n    for old_file in vpcs_files:\n        new_file = os.path.join(vpcs_config_path, os.path.basename(old_file))\n        shutil.copy(old_file, new_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy any images of the topology to the converted topology", "response": "def copy_topology_image(source, target):\n    \"\"\"\n    Copy any images of the topology to the converted topology\n\n    :param str source: Source topology directory\n    :param str target: Target Directory\n    \"\"\"\n    files = glob.glob(os.path.join(source, '*.png'))\n\n    for file in files:\n        shutil.copy(file, target)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_images(images, source, target):\n    image_err = False\n    if len(images) > 0:\n        images_dir = os.path.join(target, 'images')\n        os.makedirs(images_dir)\n        for image in images:\n            if os.path.isabs(image):\n                old_image_file = image\n            else:\n                old_image_file = os.path.join(source, image)\n\n            new_image_file = os.path.join(images_dir,\n                                          os.path.basename(image))\n            if os.path.isfile(os.path.abspath(old_image_file)):\n                shutil.copy(old_image_file, new_image_file)\n            else:\n                image_err = True\n                logging.error('Unable to find %s' % old_image_file)\n    return image_err", "response": "Copy images to converted topology"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_vbox_dirs(max_vbox_id, output_dir, topology_name):\n    if max_vbox_id is not None:\n        for i in range(1, max_vbox_id + 1):\n            vbox_dir = os.path.join(output_dir, topology_name + '-files',\n                                    'vbox', 'vm-%s' % i)\n            os.makedirs(vbox_dir)", "response": "Create VirtualBox working directories if required."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating Qemu VM working directories if required.", "response": "def make_qemu_dirs(max_qemu_id, output_dir, topology_name):\n    \"\"\"\n    Create Qemu VM working directories if required\n\n    :param int max_qemu_id: Number of directories to create\n    :param str output_dir: Output directory\n    :param str topology_name: Topology name\n    \"\"\"\n    if max_qemu_id is not None:\n        for i in range(1, max_qemu_id + 1):\n            qemu_dir = os.path.join(output_dir, topology_name + '-files',\n                                    'qemu', 'vm-%s' % i)\n            os.makedirs(qemu_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the old style WIC slot to a new style WIC slot and add the WIC to the node properties", "response": "def add_wic(self, old_wic, wic):\n        \"\"\"\n        Convert the old style WIC slot to a new style WIC slot and add the WIC\n        to the node properties\n\n        :param str old_wic: Old WIC slot\n        :param str wic: WIC name\n        \"\"\"\n        new_wic = 'wic' + old_wic[-1]\n        self.node['properties'][new_wic] = wic"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_wic_ports(self, wic_slot):\n        wic_slot_number = int(wic_slot[3])\n        wic_adapter = self.node['properties'][wic_slot]\n\n        num_ports = ADAPTER_MATRIX[wic_adapter]['ports']\n        port_type = ADAPTER_MATRIX[wic_adapter]['type']\n        ports = []\n\n        # Dynamips WICs port number start on a multiple of 16.\n        base = 16 * (wic_slot_number + 1)\n        # WICs are always in adapter slot 0.\n        slot = 0\n\n        for port_number in range(num_ports):\n            phy_port_number = port_number + self.port_numbering[port_type]\n            port_name = PORT_TYPES[port_type] + '%s/%s' % (slot,\n                                                           phy_port_number)\n            port_temp = {'name': port_name,\n                         'id': self.port_id,\n                         'port_number': base + port_number,\n                         'slot_number': slot}\n            ports.append(port_temp)\n            self.port_id += 1\n        self.port_numbering[port_type] += num_ports\n        self.node['ports'].extend(ports)", "response": "Adds the ports for a specific WIC to the node s ports dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_slot_ports(self, slot):\n        slot_nb = int(slot[4])\n        # slot_adapter = None\n        # if slot in self.node['properties']:\n        #     slot_adapter = self.node['properties'][slot]\n        # elif self.device_info['model'] == 'c7200':\n        #     if self.device_info['npe'] == 'npe-g2':\n        #         slot_adapter = 'C7200-IO-GE-E'\n        #     else:\n        #         slot_adapter = 'C7200-IO-2FE'\n\n        slot_adapter = self.node['properties'][slot]\n\n        num_ports = ADAPTER_MATRIX[slot_adapter]['ports']\n        port_type = ADAPTER_MATRIX[slot_adapter]['type']\n        ports = []\n\n        for i in range(num_ports):\n            port_name = PORT_TYPES[port_type] + '%s/%s' % (slot_nb, i)\n            port_temp = {'name': port_name,\n                         'id': self.port_id,\n                         'port_number': i,\n                         'slot_number': slot_nb}\n            ports.append(port_temp)\n            self.port_id += 1\n        self.node['ports'].extend(ports)", "response": "Adds the ports to be added for a slot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the information we need from the old hypervisor section", "response": "def add_info_from_hv(self):\n        \"\"\"\n        Add the information we need from the old hypervisor section\n        \"\"\"\n        # Router Image\n        if 'image' in self.hypervisor:\n            self.node['properties']['image'] = \\\n                os.path.basename(self.hypervisor['image'])\n        # IDLE-PC\n        if 'idlepc' in self.hypervisor:\n            self.node['properties']['idlepc'] = self.hypervisor['idlepc']\n        # Router RAM\n        if 'ram' in self.hypervisor:\n            self.node['properties']['ram'] = self.hypervisor['ram']\n        # 7200 NPE\n        if 'npe' in self.hypervisor:\n            self.device_info['npe'] = self.hypervisor['npe']\n        # Device Chassis\n        if 'chassis' in self.hypervisor:\n            self.device_info['chassis'] = self.hypervisor['chassis']\n            if self.device_info['model'] == 'c3600':\n                self.node['properties']['chassis'] = \\\n                    self.device_info['chassis']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_device_items(self, item, device):\n        if item in ('aux', 'console'):\n            self.node['properties'][item] = device[item]\n        elif item.startswith('slot'):\n            # if self.device_info['model'] == 'c7200':\n            #     if item != 'slot0':\n            #         self.node['properties'][item] = device[item]\n            # else:\n            self.node['properties'][item] = device[item]\n        elif item == 'connections':\n            self.connections = device[item]\n        elif INTERFACE_RE.search(item) or VBQ_INT_RE.search(item):\n            self.interfaces.append({'from': item,\n                                    'to': device[item]})\n        elif NUMBER_RE.search(item):\n            if self.device_info['type'] == 'EthernetSwitch':\n                self.calc_ethsw_port(item, device[item])\n            elif self.device_info['type'] == 'FrameRelaySwitch':\n                self.calc_frsw_port(item, device[item])\n        elif MAPINT_RE.search(item):\n            self.add_mapping((item, device[item]))\n        elif item == 'cnfg':\n            new_config = os.path.join('configs', 'i%s_startup-config.cfg' %\n                                      self.node['id'])\n            self.node['properties']['startup_config'] = new_config\n\n            self.config.append({'old': fix_path(device[item]),\n                                'new': new_config})\n        elif item.startswith('wic'):\n            self.add_wic(item, device[item])\n        elif item == 'symbol':\n            self.set_symbol(device[item])\n        elif item == 'nics':\n            self.node['properties']['adapters'] = device[item]\n        elif item == 'image':\n            self.node['properties']['vmname'] = device[item]\n        elif item == 'vbox_id' or item == 'qemu_id':\n            self.node[item] = device[item]", "response": "Add the various items from the device to the node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_to_qemu(self):\n        device = self.device_info['ext_conf']\n        node_prop = self.node['properties']\n        hv_device = self.hypervisor[device]\n        # QEMU HDD Images\n        if 'hda_disk_image' not in node_prop:\n            if 'image' in hv_device:\n                node_prop['hda_disk_image'] = hv_device['image']\n            elif 'image1' in hv_device:\n                node_prop['hda_disk_image'] = hv_device['image1']\n        if 'hdb_disk_image' not in node_prop and 'image2' in hv_device:\n            node_prop['hdb_disk_image'] = hv_device['image2']\n        # RAM\n        if 'ram' not in node_prop and 'ram' in hv_device:\n            node_prop['ram'] = hv_device['ram']\n        else:\n            node_prop['ram'] = 256\n        # QEMU Options\n        if 'options' not in node_prop and 'options' in hv_device:\n            node_prop['options'] = hv_device['options']\n        # Kernel Image\n        if 'kernel_image' not in node_prop and 'kernel' in hv_device:\n            node_prop['kernel_image'] = hv_device['kernel']\n        # Kernel Command Line\n        if 'kernel_command_line' not in node_prop and \\\n                'kernel_cmdline' in hv_device:\n            node_prop['kernel_command_line'] = hv_device['kernel_cmdline']\n        # initrd\n        if 'initrd' not in node_prop and 'initrd' in hv_device:\n            node_prop['initrd'] = hv_device['initrd']\n        # Number of adapters\n        if 'adapters' not in node_prop and 'nics' in hv_device:\n            node_prop['adapters'] = hv_device['nics']\n        elif 'adapters' not in node_prop and 'nics' not in hv_device:\n            node_prop['adapters'] = 6\n        # Adapter type\n        if 'adapter_type' not in node_prop and 'netcard' in hv_device:\n            node_prop['adapter_type'] = hv_device['netcard']\n        # Console Port\n        if 'console' not in node_prop:\n            node_prop['console'] = self.base_ports['qemu_console'] + \\\n                self.node['qemu_id'] - 1\n        # Qemu Path\n        if 'qemu_path' not in node_prop:\n            qemu_path = self.hypervisor['qemu_path']\n            # Modify QEMU Path if flavor is specified\n            if 'flavor' in hv_device:\n                qemu_path = re.sub(r'qemu-system-.*',\n                                   'qemu-system' + hv_device['flavor'],\n                                   qemu_path)\n            node_prop['qemu_path'] = qemu_path", "response": "Add additional parameters to a QEMU VM Device that were present in its\n            global conf section section\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd ethernet ports to Virtualbox and Qemu nodes", "response": "def add_vm_ethernet_ports(self):\n        \"\"\"\n        Add ethernet ports to Virtualbox and Qemu nodes\n        \"\"\"\n        for i in range(self.node['properties']['adapters']):\n            port = {'id': self.port_id,\n                    'name': 'Ethernet%s' % i,\n                    'port_number': i}\n            self.node['ports'].append(port)\n            self.port_id += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_qemu_symbol(self):\n        valid_devices = {'ASA': 'asa', 'PIX': 'PIX_firewall',\n                         'JUNOS': 'router', 'IDS': 'ids'}\n        if self.device_info['from'] in valid_devices \\\n                and 'default_symbol' not in self.node \\\n                and 'hover_symbol' not in self.node:\n            self.set_symbol(valid_devices[self.device_info['from']])", "response": "Set the appropriate symbol for QEMU Devices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a symbol for a device", "response": "def set_symbol(self, symbol):\n        \"\"\"\n        Set a symbol for a device\n\n        :param str symbol: Symbol to use\n        \"\"\"\n        if symbol == 'EtherSwitch router':\n            symbol = 'multilayer_switch'\n        elif symbol == 'Host':\n            symbol = 'computer'\n\n        normal = ':/symbols/%s.normal.svg' % symbol\n        selected = ':/symbols/%s.selected.svg' % symbol\n\n        self.node['default_symbol'] = normal\n        self.node['hover_symbol'] = selected"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_ethsw_port(self, port_num, port_def):\n        # Port String - access 1 SW2 1\n        # 0: type 1: vlan 2: destination device 3: destination port\n        port_def = port_def.split(' ')\n        if len(port_def) == 4:\n            destination = {'device': port_def[2],\n                           'port': port_def[3]}\n        else:\n            destination = {'device': 'NIO',\n                           'port': port_def[2]}\n        # port entry\n        port = {'id': self.port_id,\n                'name': str(port_num),\n                'port_number': int(port_num),\n                'type': port_def[0],\n                'vlan': int(port_def[1])}\n        self.node['ports'].append(port)\n        self.calc_link(self.node['id'], self.port_id, port['name'],\n                       destination)\n        self.port_id += 1", "response": "Split and create the port entry for an Ethernet Switch"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the default ports for a specific router and add them to the node", "response": "def calc_mb_ports(self):\n        \"\"\"\n        Add the default ports to add to a router\n        \"\"\"\n        model = self.device_info['model']\n        chassis = self.device_info['chassis']\n        num_ports = MODEL_MATRIX[model][chassis]['ports']\n        ports = []\n\n        if num_ports > 0:\n            port_type = MODEL_MATRIX[model][chassis]['type']\n\n            # Create the ports dict\n            for i in range(num_ports):\n                port_temp = {'name': PORT_TYPES[port_type] + '0/' + str(i),\n                             'id': self.port_id,\n                             'port_number': i,\n                             'slot_number': 0}\n                ports.append(port_temp)\n                self.port_id += 1\n        self.node['ports'].extend(ports)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a link item for processing later", "response": "def calc_link(self, src_id, src_port, src_port_name, destination):\n        \"\"\"\n        Add a link item for processing later\n\n        :param int src_id: Source node ID\n        :param int src_port: Source port ID\n        :param str src_port_name: Source port name\n        :param dict destination: Destination\n        \"\"\"\n        if destination['device'] == 'NIO':\n            destination['port'] = destination['port'].lower()\n\n        link = {'source_node_id': src_id,\n                'source_port_id': src_port,\n                'source_port_name': src_port_name,\n                'source_dev': self.node['properties']['name'],\n                'dest_dev': destination['device'],\n                'dest_port': destination['port']}\n\n        self.links.append(link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_description(self):\n        if self.device_info['type'] == 'Router':\n            self.node['description'] = '%s %s' % (self.device_info['type'],\n                                                  self.device_info['model'])\n        else:\n            self.node['description'] = self.device_info['desc']", "response": "Set the node description"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the type of the node.", "response": "def set_type(self):\n        \"\"\"\n        Set the node type\n        \"\"\"\n        if self.device_info['type'] == 'Router':\n            self.node['type'] = self.device_info['model'].upper()\n        else:\n            self.node['type'] = self.device_info['type']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate a router or VirtualBox link for the device.", "response": "def calc_device_links(self):\n        \"\"\"\n        Calculate a router or VirtualBox link\n        \"\"\"\n        for connection in self.interfaces:\n            int_type = connection['from'][0]\n            int_name = connection['from'].replace(int_type,\n                                                  PORT_TYPES[int_type.upper()])\n            # Get the source port id\n            src_port = None\n            for port in self.node['ports']:\n                if int_name == port['name']:\n                    src_port = port['id']\n                    break\n            dest_temp = connection['to'].split(' ')\n\n            if len(dest_temp) == 2:\n                conn_to = {'device': dest_temp[0],\n                           'port': dest_temp[1]}\n            else:\n                conn_to = {'device': 'NIO',\n                           'port': dest_temp[0]}\n\n            self.calc_link(self.node['id'], src_port, int_name, conn_to)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the cloud connection string and adds the ports and nios entries for a cloud connection", "response": "def calc_cloud_connection(self):\n        \"\"\"\n        Add the ports and nios for a cloud connection\n\n        :return: None on success or RuntimeError on error\n        \"\"\"\n        # Connection String - SW1:1:nio_gen_eth:eth0\n        # 0: Destination device 1: Destination port\n        # 2: NIO 3: NIO Destination\n        self.node['properties']['nios'] = []\n        if self.connections is None:\n            return None\n        else:\n            self.connections = self.connections.split(' ')\n\n        for connection in sorted(self.connections):\n            connection = connection.split(':')\n            connection_len = len(connection)\n            if connection_len == 4:\n                nio = '%s:%s' % (connection[2], connection[3])\n            elif connection_len == 6:\n                nio = '%s:%s:%s:%s' % (connection[2].lower(), connection[3],\n                                       connection[4], connection[5])\n            else:\n                return RuntimeError('Error: Unknown connection string length '\n                                    '(Length: %s)' % connection_len)\n            self.node['properties']['nios'].append(nio)\n            # port entry\n            self.node['ports'].append({'id': self.port_id,\n                                       'name': nio,\n                                       'stub': True})\n            self.port_id += 1\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess the mappings for a Frame Relay switch. Removes duplicates adds the mappings to the node properties.", "response": "def process_mappings(self):\n        \"\"\"\n        Process the mappings for a Frame Relay switch. Removes duplicates and\n        adds the mappings to the node properties\n        \"\"\"\n        for mapping_a in self.mappings:\n            for mapping_b in self.mappings:\n                if mapping_a['source'] == mapping_b['dest']:\n                    self.mappings.remove(mapping_b)\n                    break\n\n        self.node['properties']['mappings'] = {}\n        mappings = self.node['properties']['mappings']\n        for mapping in self.mappings:\n            mappings[mapping['source']] = mapping['dest']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfix windows path s. Linux path s will remain unaltered", "response": "def fix_path(path):\n    \"\"\"\n    Fix windows path's. Linux path's will remain unaltered\n\n    :param str path: The path to be fixed\n    :return: The fixed path\n    :rtype: str\n    \"\"\"\n    if '\\\\' in path:\n        path = path.replace('\\\\', '/')\n\n    path = os.path.normpath(path)\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the ini - style topology file using ConfigObj.", "response": "def read_topology(self):\n        \"\"\"\n        Read the ini-style topology file using ConfigObj\n\n        :return config: Topology parsed by :py:mod:`ConfigObj`\n        :rtype: ConfigObj\n        \"\"\"\n        configspec = resource_stream(__name__, 'configspec')\n        try:\n            handle = open(self._topology)\n            handle.close()\n            try:\n                config = ConfigObj(self._topology,\n                                   configspec=configspec,\n                                   raise_errors=True,\n                                   list_values=False,\n                                   encoding='utf-8')\n            except SyntaxError:\n                logging.error('Error loading .net file')\n                sys.exit(1)\n        except IOError:\n            logging.error('Cannot open topology file')\n            sys.exit(1)\n\n        vtor = Validator()\n        res = config.validate(vtor, preserve_errors=True)\n        if res:\n            logging.debug('Validation passed')\n        elif not res:\n            for entry in flatten_errors(config, res):\n                # each entry is a tuple\n                (section_list, key, error) = entry\n                if key is not None:\n                    section_list.append(key)\n                else:\n                    section_list.append('[missing section]')\n                section_string = ', '.join(section_list)\n\n                if error is False:\n                    error = 'Missing value or section'\n                print(section_string, ' = ', error)\n                input('Press ENTER to continue')\n                sys.exit(1)\n\n        configspec.close()\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing the sections returned by get_instances Grammar and returns a tuple containing hypervisors devices and artwork items.", "response": "def process_topology(self, old_top):\n        \"\"\"\n        Processes the sections returned by get_instances\n\n        :param ConfigObj old_top: old topology as processed by\n                                  :py:meth:`read_topology`\n        :returns: tuple of dicts containing hypervisors, devices and artwork\n        :rtype: tuple\n        \"\"\"\n        sections = self.get_sections(old_top)\n        topo = LegacyTopology(sections, old_top)\n\n        for instance in sorted(sections):\n            if instance.startswith('vbox') or instance.startswith('qemu'):\n\n                if instance.startswith('qemu') and \\\n                        'qemupath' in old_top[instance]:\n                    topo.add_qemu_path(instance)\n\n                for device in EXTRA_CONF:\n                    try:\n                        if isinstance(old_top[instance][device], dict):\n                            topo.add_conf_item(instance, device)\n                            old_top[instance].pop(device)\n                    except KeyError:\n                        pass\n\n            for item in sorted(old_top[instance]):\n                if isinstance(old_top[instance][item], dict):\n                    if item in MODEL_TRANSFORM:\n                        # A configuration item (topo.conf)\n                        topo.add_conf_item(instance, item)\n                    elif instance == 'GNS3-DATA' and \\\n                            (item.startswith('SHAPE')\n                             or item.startswith('NOTE')\n                             or item.startswith('PIXMAP')):\n                        # Item is an artwork item e.g. shapes and notes from\n                        # GNS3-DATA\n                        topo.add_artwork_item(instance, item)\n                    else:\n                        # It must be a physical item (topo.devices)\n                        topo.add_physical_item(instance, item)\n        return topo.topology"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a list of nodes for the new topology from the given topology.", "response": "def generate_nodes(self, topology):\n        \"\"\"\n        Generate a list of nodes for the new topology\n\n        :param dict topology: processed topology from\n                              :py:meth:`process_topology`\n        :return: a list of dicts on nodes\n        :rtype: list\n        \"\"\"\n        nodes = []\n\n        devices = topology['devices']\n        hypervisors = topology['conf']\n\n        for device in sorted(devices):\n            hv_id = devices[device]['hv_id']\n            try:\n                tmp_node = Node(hypervisors[hv_id], self.port_id)\n            except IndexError:\n                tmp_node = Node({}, self.port_id)\n            # Start building the structure\n            tmp_node.node['properties']['name'] = device\n            tmp_node.node['id'] = devices[device]['node_id']\n            tmp_node.node['x'] = devices[device]['x']\n            tmp_node.node['y'] = devices[device]['y']\n            tmp_node.device_info['from'] = devices[device]['from']\n            tmp_node.device_info['type'] = devices[device]['type']\n            tmp_node.device_info['desc'] = devices[device]['desc']\n\n            if 'ext_conf' in devices[device]:\n                tmp_node.device_info['ext_conf'] = devices[device]['ext_conf']\n\n            # Node Label\n            tmp_node.node['label']['text'] = device\n            if 'hx' in devices[device] and 'hy' in devices[device]:\n                tmp_node.node['label']['x'] = devices[device]['hx']\n                tmp_node.node['label']['y'] = devices[device]['hy']\n\n            if 'model' in devices[device]:\n                tmp_node.device_info['model'] = devices[device]['model']\n            else:\n                tmp_node.device_info['model'] = ''\n\n            tmp_node.set_description()\n            tmp_node.set_type()\n\n            # Now lets process the rest\n            for item in sorted(devices[device]):\n                tmp_node.add_device_items(item, devices[device])\n\n            if tmp_node.device_info['type'] == 'Router':\n                tmp_node.add_info_from_hv()\n                tmp_node.node['router_id'] = devices[device]['node_id']\n                tmp_node.calc_mb_ports()\n\n                for item in sorted(tmp_node.node['properties']):\n                    if item.startswith('slot'):\n                        tmp_node.add_slot_ports(item)\n                    elif item.startswith('wic'):\n                        tmp_node.add_wic_ports(item)\n\n                # Add default ports to 7200 and 3660\n                if tmp_node.device_info['model'] == 'c7200':\n                    # tmp_node.add_slot_ports('slot0')\n                    # C7200 doesnt have any ports by default\n                    pass\n                elif tmp_node.device_info['model'] == 'c3600' \\\n                        and tmp_node.device_info['chassis'] == '3660':\n                    tmp_node.node['properties']['slot0'] = 'Leopard-2FE'\n\n                # Calculate the router links\n                tmp_node.calc_device_links()\n\n            elif tmp_node.device_info['type'] == 'Cloud':\n                try:\n                    tmp_node.calc_cloud_connection()\n                except RuntimeError as err:\n                    print(err)\n\n            elif tmp_node.device_info['type'] == 'FrameRelaySwitch':\n                tmp_node.process_mappings()\n\n            elif tmp_node.device_info['type'] == 'VirtualBoxVM':\n                tmp_node.add_to_virtualbox()\n                tmp_node.add_vm_ethernet_ports()\n                tmp_node.calc_device_links()\n\n            elif tmp_node.device_info['type'] == 'QemuVM':\n                tmp_node.add_to_qemu()\n                tmp_node.set_qemu_symbol()\n                tmp_node.add_vm_ethernet_ports()\n                tmp_node.calc_device_links()\n\n            # Get the data we need back from the node instance\n            self.links.extend(tmp_node.links)\n            self.configs.extend(tmp_node.config)\n            self.port_id += tmp_node.get_nb_added_ports(self.port_id)\n\n            nodes.append(tmp_node.node)\n\n        return nodes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a list of links from a list of nodes.", "response": "def generate_links(self, nodes):\n        \"\"\"\n        Generate a list of links\n\n        :param list nodes: A list of nodes from :py:meth:`generate_nodes`\n        :return: list of links\n        :rtype: list\n        \"\"\"\n        new_links = []\n\n        for link in self.links:\n            # Expand port name if required\n            if INTERFACE_RE.search(link['dest_port'])\\\n                    or VBQ_INT_RE.search(link['dest_port']):\n                int_type = link['dest_port'][0]\n                dest_port = link['dest_port'].replace(\n                    int_type, PORT_TYPES[int_type.upper()])\n            else:\n                dest_port = link['dest_port']\n\n            # Convert dest_dev and port to id's\n            dest_details = self.convert_destination_to_id(\n                link['dest_dev'], dest_port, nodes)\n\n            desc = 'Link from %s port %s to %s port %s' % \\\n                   (link['source_dev'], link['source_port_name'],\n                    dest_details['name'], dest_port)\n\n            new_links.append({'description': desc,\n                              'destination_node_id': dest_details['id'],\n                              'destination_port_id': dest_details['pid'],\n                              'source_port_id': link['source_port_id'],\n                              'source_node_id': link['source_node_id']})\n\n        # Remove duplicate links and add link_id\n        link_id = 1\n        for link in new_links:\n            t_link = str(link['source_node_id']) + ':' + \\\n                str(link['source_port_id'])\n            for link2 in new_links:\n                d_link = str(link2['destination_node_id']) + ':' + \\\n                    str(link2['destination_port_id'])\n                if t_link == d_link:\n                    new_links.remove(link2)\n                    break\n            link['id'] = link_id\n            link_id += 1\n\n            self.add_node_connection(link, nodes)\n\n        return new_links"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef device_id_from_name(device_name, nodes):\n        device_id = None\n        for node in nodes:\n            if device_name == node['properties']['name']:\n                device_id = node['id']\n                break\n        return device_id", "response": "Get the device ID when given a device name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef port_id_from_name(port_name, device_id, nodes):\n        port_id = None\n        for node in nodes:\n            if device_id == node['id']:\n                for port in node['ports']:\n                    if port_name == port['name']:\n                        port_id = port['id']\n                        break\n                break\n        return port_id", "response": "Get the port ID when given a port name and device ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_destination_to_id(destination_node, destination_port, nodes):\n        device_id = None\n        device_name = None\n        port_id = None\n        if destination_node != 'NIO':\n            for node in nodes:\n                if destination_node == node['properties']['name']:\n                    device_id = node['id']\n                    device_name = destination_node\n                    for port in node['ports']:\n                        if destination_port == port['name']:\n                            port_id = port['id']\n                            break\n                    break\n        else:\n            for node in nodes:\n                if node['type'] == 'Cloud':\n                    for port in node['ports']:\n                        if destination_port.lower() == port['name'].lower():\n                            device_id = node['id']\n                            device_name = node['properties']['name']\n                            port_id = port['id']\n                            break\n\n        info = {'id': device_id,\n                'name': device_name,\n                'pid': port_id}\n        return info", "response": "Convert a destination node and port name to device and port ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_node_name_from_id(node_id, nodes):\n        node_name = ''\n        for node in nodes:\n            if node['id'] == node_id:\n                node_name = node['properties']['name']\n                break\n        return node_name", "response": "Get the name of a node when given the node_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_port_name_from_id(node_id, port_id, nodes):\n        port_name = ''\n        for node in nodes:\n            if node['id'] == node_id:\n                for port in node['ports']:\n                    if port['id'] == port_id:\n                        port_name = port['name']\n                        break\n        return port_name", "response": "Get the name of a port for a given node and port ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a connection to a node", "response": "def add_node_connection(self, link, nodes):\n        \"\"\"\n        Add a connection to a node\n\n        :param dict link: link definition\n        :param list nodes: list of nodes from :py:meth:`generate_nodes`\n        \"\"\"\n        # Description\n        src_desc = 'connected to %s on port %s' % \\\n                   (self.get_node_name_from_id(link['destination_node_id'],\n                                               nodes),\n                    self.get_port_name_from_id(link['destination_node_id'],\n                                               link['destination_port_id'],\n                                               nodes))\n        dest_desc = 'connected to %s on port %s' % \\\n                    (self.get_node_name_from_id(link['source_node_id'],\n                                                nodes),\n                     self.get_port_name_from_id(link['source_node_id'],\n                                                link['source_port_id'],\n                                                nodes))\n        # Add source connections\n        for node in nodes:\n            if node['id'] == link['source_node_id']:\n                for port in node['ports']:\n                    if port['id'] == link['source_port_id']:\n                        port['link_id'] = link['id']\n                        port['description'] = src_desc\n                        break\n            elif node['id'] == link['destination_node_id']:\n                for port in node['ports']:\n                    if port['id'] == link['destination_port_id']:\n                        port['link_id'] = link['id']\n                        port['description'] = dest_desc\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the shapes for the topology", "response": "def generate_shapes(shapes):\n        \"\"\"\n        Generate the shapes for the topology\n\n        :param dict shapes: A dict of converted shapes from the old topology\n        :return: dict containing two lists (ellipse, rectangle)\n        :rtype: dict\n        \"\"\"\n        new_shapes = {'ellipse': [], 'rectangle': []}\n\n        for shape in shapes:\n            tmp_shape = {}\n            for shape_item in shapes[shape]:\n                if shape_item != 'type':\n                    tmp_shape[shape_item] = shapes[shape][shape_item]\n\n            new_shapes[shapes[shape]['type']].append(tmp_shape)\n\n        return new_shapes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the notes list for the topology", "response": "def generate_notes(notes):\n        \"\"\"\n        Generate the notes list\n\n        :param dict notes: A dict of converted notes from the old topology\n        :return: List of notes for the the topology\n        :rtype: list\n        \"\"\"\n        new_notes = []\n\n        for note in notes:\n            tmp_note = {}\n            for note_item in notes[note]:\n                tmp_note[note_item] = notes[note][note_item]\n\n            new_notes.append(tmp_note)\n\n        return new_notes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the images list and store the images to copy", "response": "def generate_images(self, pixmaps):\n        \"\"\"\n        Generate the images list and store the images to copy\n\n        :param dict pixmaps: A dict of converted pixmaps from the old topology\n        :return: A list of images\n        :rtype: list\n        \"\"\"\n        new_images = []\n\n        for image in pixmaps:\n            tmp_image = {}\n            for img_item in pixmaps[image]:\n                if img_item == 'path':\n                    path = os.path.join('images',\n                                        os.path.basename(\n                                            pixmaps[image][img_item]))\n                    tmp_image['path'] = fix_path(path)\n                    self.images.append(pixmaps[image][img_item])\n                else:\n                    tmp_image[img_item] = pixmaps[image][img_item]\n\n            new_images.append(tmp_image)\n\n        return new_images"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_artwork_item(self, instance, item):\n        if 'interface' in self.old_top[instance][item]:\n            pass\n        else:\n            (item_type, item_id) = item.split(' ')\n            self.artwork[item_type][item_id] = {}\n            for s_item in sorted(self.old_top[instance][item]):\n                if self.old_top[instance][item][s_item] is not None:\n                    s_detail = self.old_top[instance][item][s_item]\n                    s_type = type(s_detail)\n\n                    if item_type == 'NOTE' and s_type == str:\n                        # Fix any escaped newline characters\n                        s_detail = s_detail.replace('\\\\n', '\\n')\n\n                    if s_type == str and len(s_detail) > 1 \\\n                            and s_detail[0] == '\"' and s_detail[-1] == '\"':\n                        s_detail = s_detail[1:-1]\n\n                    if item_type == 'SHAPE' and s_item == 'fill_color':\n                        s_item = 'color'\n                    elif s_item == 'rotate':\n                        s_item = 'rotation'\n                        s_detail = float(s_detail)\n\n                    self.artwork[item_type][item_id][s_item] = s_detail\n\n            if item_type == 'SHAPE' and \\\n                    'color' not in self.artwork[item_type][item_id]:\n                self.artwork[item_type][item_id]['color'] = '#ffffff'\n                self.artwork[item_type][item_id]['transparency'] = 0", "response": "Add an artwork item e. g. Shapes Notes and Pixmaps."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the qemu path to the hypervisor conf data", "response": "def add_qemu_path(self, instance):\n        \"\"\"\n        Add the qemu path to the hypervisor conf data\n\n        :param instance: Hypervisor instance\n        \"\"\"\n        tmp_conf = {'qemu_path': self.old_top[instance]['qemupath']}\n        if len(self.topology['conf']) == 0:\n            self.topology['conf'].append(tmp_conf)\n        else:\n            self.topology['conf'][self.hv_id].update(tmp_conf)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_conf_item(self, instance, item):\n        tmp_conf = {}\n\n        if item not in EXTRA_CONF:\n            tmp_conf['model'] = MODEL_TRANSFORM[item]\n\n        for s_item in sorted(self.old_top[instance][item]):\n            if self.old_top[instance][item][s_item] is not None:\n                tmp_conf[s_item] = self.old_top[instance][item][s_item]\n\n        if item in EXTRA_CONF:\n            tmp_conf = {item: tmp_conf}\n            if len(self.topology['conf']) == 0:\n                self.topology['conf'].append(tmp_conf)\n            else:\n                self.topology['conf'][self.hv_id].update(tmp_conf)\n        else:\n            self.topology['conf'].append(tmp_conf)\n        self.hv_id = len(self.topology['conf']) - 1", "response": "Adds a hypervisor configuration item to the hypervisor configuration list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a physical item e. g router cloud etc.", "response": "def add_physical_item(self, instance, item):\n        \"\"\"\n        Add a physical item e.g router, cloud etc\n\n        :param instance: Hypervisor instance\n        :param item: Item to add\n        \"\"\"\n        (name, dev_type) = self.device_typename(item)\n        self.topology['devices'][name] = {}\n        self.topology['devices'][name]['hv_id'] = self.hv_id\n        self.topology['devices'][name]['node_id'] = self.nid\n        self.topology['devices'][name]['from'] = dev_type['from']\n        self.topology['devices'][name]['type'] = dev_type['type']\n        self.topology['devices'][name]['desc'] = dev_type['desc']\n\n        if 'ext_conf' in dev_type:\n            self.topology['devices'][name]['ext_conf'] = dev_type['ext_conf']\n\n        for s_item in sorted(self.old_top[instance][item]):\n            if self.old_top[instance][item][s_item] is not None:\n                self.topology['devices'][name][s_item] = \\\n                    self.old_top[instance][item][s_item]\n\n        if instance != 'GNS3-DATA' and \\\n                self.topology['devices'][name]['type'] == 'Router':\n            if 'model' not in self.topology['devices'][name]:\n                self.topology['devices'][name]['model'] = \\\n                    self.topology['conf'][self.hv_id]['model']\n            else:\n                self.topology['devices'][name]['model'] = MODEL_TRANSFORM[\n                    self.topology['devices'][name]['model']]\n        elif dev_type['type'] == 'VirtualBoxVM':\n            self.topology['devices'][name]['vbox_id'] = self.vbox_id\n            self.vbox_id += 1\n        elif dev_type['type'] == 'QemuVM':\n            self.topology['devices'][name]['qemu_id'] = self.qemu_id\n            self.qemu_id += 1\n\n        if instance != 'GNS3-DATA' \\\n            and 'hx' not in self.topology['devices'][name] \\\n                and 'hy' not in self.topology['devices'][name]:\n            self.topology['devices'][name]['hx'] = dev_type['label_x']\n            self.topology['devices'][name]['hy'] = -25.0\n        self.nid += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef device_typename(item):\n\n        dev_type = {'ROUTER': {'from': 'ROUTER',\n                               'desc': 'Router',\n                               'type': 'Router',\n                               'label_x': 19.5},\n                    'QEMU': {'from': 'QEMU',\n                             'desc': 'QEMU VM',\n                             'type': 'QemuVM',\n                             'ext_conf': 'QemuDevice',\n                             'label_x': -12},\n                    'ASA': {'from': 'ASA',\n                            'desc': 'QEMU VM',\n                            'type': 'QemuVM',\n                            'ext_conf': '5520',\n                            'label_x': 2.5},\n                    'PIX': {'from': 'PIX',\n                            'desc': 'QEMU VM',\n                            'type': 'QemuVM',\n                            'ext_conf': '525',\n                            'label_x': -12},\n                    'JUNOS': {'from': 'JUNOS',\n                              'desc': 'QEMU VM',\n                              'type': 'QemuVM',\n                              'ext_conf': 'O-series',\n                              'label_x': -12},\n                    'IDS': {'from': 'IDS',\n                            'desc': 'QEMU VM',\n                            'type': 'QemuVM',\n                            'ext_conf': 'IDS-4215',\n                            'label_x': -12},\n                    'VBOX': {'from': 'VBOX',\n                             'desc': 'VirtualBox VM',\n                             'type': 'VirtualBoxVM',\n                             'ext_conf': 'VBoxDevice',\n                             'label_x': -4.5},\n                    'FRSW': {'from': 'FRSW',\n                             'desc': 'Frame Relay switch',\n                             'type': 'FrameRelaySwitch',\n                             'label_x': 7.5},\n                    'ETHSW': {'from': 'ETHSW',\n                              'desc': 'Ethernet switch',\n                              'type': 'EthernetSwitch',\n                              'label_x': 15.5},\n                    'Hub': {'from': 'Hub',\n                            'desc': 'Ethernet hub',\n                            'type': 'EthernetHub',\n                            'label_x': 12.0},\n                    'ATMSW': {'from': 'ATMSW',\n                              'desc': 'ATM switch',\n                              'type': 'ATMSwitch',\n                              'label_x': 2.0},\n                    'ATMBR': {'from': 'ATMBR',  # TODO: Investigate ATM Bridge\n                              'desc': 'ATMBR',\n                              'type': 'ATMBR'},\n                    'Cloud': {'from': 'Cloud',\n                              'desc': 'Cloud',\n                              'type': 'Cloud',\n                              'label_x': 47.5}}\n\n        item_type = item.split(' ')[0]\n        name = item.replace('%s ' % dev_type[item_type]['from'], '')\n        return name, dev_type[item_type]", "response": "Convert the old names to new - style names and types"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the converted topology ready for JSON encoding.", "response": "def get_topology(self):\n        \"\"\"\n        Get the converted topology ready for JSON encoding\n\n        :return: converted topology assembled into a single dict\n        :rtype: dict\n        \"\"\"\n        topology = {'name': self._name,\n                    'resources_type': 'local',\n                    'topology': {},\n                    'type': 'topology',\n                    'version': '1.0'}\n\n        if self._links:\n            topology['topology']['links'] = self._links\n        if self._nodes:\n            topology['topology']['nodes'] = self._nodes\n        if self._servers:\n            topology['topology']['servers'] = self._servers\n        if self._notes:\n            topology['topology']['notes'] = self._notes\n        if self._shapes['ellipse']:\n            topology['topology']['ellipses'] = self._shapes['ellipse']\n        if self._shapes['rectangle']:\n            topology['topology']['rectangles'] = \\\n                self._shapes['rectangle']\n        if self._images:\n            topology['topology']['images'] = self._images\n\n        return topology"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the maximum ID of the VBoxes", "response": "def get_vboxes(self):\n        \"\"\"\n        Get the maximum ID of the VBoxes\n\n        :return: Maximum VBox ID\n        :rtype: int\n        \"\"\"\n        vbox_list = []\n        vbox_max = None\n        for node in self.nodes:\n            if node['type'] == 'VirtualBoxVM':\n                vbox_list.append(node['vbox_id'])\n\n        if len(vbox_list) > 0:\n            vbox_max = max(vbox_list)\n        return vbox_max"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the maximum ID of the Qemu VMs", "response": "def get_qemus(self):\n        \"\"\"\n        Get the maximum ID of the Qemu VMs\n\n        :return: Maximum Qemu VM ID\n        :rtype: int\n        \"\"\"\n        qemu_vm_list = []\n        qemu_vm_max = None\n        for node in self.nodes:\n            if node['type'] == 'QemuVM':\n                qemu_vm_list.append(node['qemu_id'])\n\n        if len(qemu_vm_list) > 0:\n            qemu_vm_max = max(qemu_vm_list)\n        return qemu_vm_max"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of child elements", "response": "def getElements(self,name=''):\n\t\t'Get a list of child elements'\n\t\t#If no tag name is specified, return the all children\n\t\tif not name:\n\t\t\treturn self.children\n\t\telse:\n\t\t\t# else return only those children with a matching tag name\n\t\t\telements = []\n\t\t\tfor element in self.children:\n\t\t\t\tif element.name == name:\n\t\t\t\t\telements.append(element)\n\t\t\treturn elements"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CharacterData(self,data):\n\t\t'SAX character data event handler'\n\t\t## HACK: to preserve the newlines\n\t\t#if string.strip(data):\n\t\tdata = data.encode(\"utf-8\")\n\t\telement = self.nodeStack[-1]\n\t\telement.cdata += data\n\t\treturn", "response": "SAX character data event handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef key_dict( from_dict ):\n\tnew_dict = {}\n\told2new = {}\n\tnew2old = {}\n\tfor key in from_dict:\n\t\tk = normalizeUnicode(key,'identifier')\n\t\tif k != key:\n\t\t\ti = ''\n\t\t\twhile new_dict.has_key(\"%s%s\" % (k,i) ):\n\t\t\t\tif not i:\n\t\t\t\t\ti = 1\n\t\t\t\telse:\n\t\t\t\t\ti += 1\n\t\t\tk = \"%s%s\" % (k,i)\n\t\t\told2new[key] = k\n\t\t\tnew2old[k] = key\n\t\tnew_dict[k] = from_dict[key]\n\treturn (new_dict.keys(), new_dict, old2new, new2old)", "response": "Returns dict from_dict [ unicode_save_field ] = original key with unicode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef makeFMData( from_dict, locked = False):\n\n\tclass FMData(object):\n\t\t\"\"\"Datastructure where:\n\n\t\t\t- attr and dict access is equal (eg. FMData.value == FMData['value'])\n\t\t\t- only attributtes given during initialization are readable and writable \n\t\t\t- modified attributes are tracked\"\"\"\n\t\t__modified__ = set()\n\t\t__slots__, __init_dict__, __old2new__, __new2old__ = key_dict(  from_dict )\n\n\t\tdef __init__(self, locked = False):\n\t\t\tinit_dict = self.__init_dict__\n\t\t\tfor key in init_dict:\n\t\t\t\tvalue = init_dict[key]\n\t\t\t\tdate, mo, da, ye, time, ho, mi, se = [None] * 8\n\t\t\t\tif type(value) in [str, unicode]:\n\t\t\t\t\tdate, da, mo, ye, time, ho, mi, se = reDateTime.match( value ).groups()\n\t\t\t\t\tif mo and int(mo) > 12:\n\t\t\t\t\t\tmo, da = da, mo\n\n\t\t\t\tif type(init_dict[key]) == dict:\n\t\t\t\t\tsetattr(self, key, makeFMData( init_dict[key], locked=False ) ) # lock all substructures??\n\t\t\t\telif type(init_dict[key]) == list:\n\t\t\t\t\tl = []\n\t\t\t\t\tfor d in init_dict[key]:\n\t\t\t\t\t\tif type(d) == dict:\n\t\t\t\t\t\t\tl.append( makeFMData (d )) # lock ??\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tl.append( d )\n\t\t\t\t\tsetattr(self, key, l )\n\t\t\t\telif date and time:\n\t\t\t\t\tsetattr(self, key, DateTime(int(ye), int(mo), int(da), int(ho), int(mi), int(se)))\n\t\t\t\telif date:\n\t\t\t\t\tsetattr(self, key, Date(int(ye), int(mo), int(da)))\n\t\t\t\telif time:\n\t\t\t\t\tsetattr(self, key, Time(int(ho), int(mi), int(se)))\n\t\t\t\telse:\n\t\t\t\t\tsetattr(self, key, init_dict[key])\n\t\t\tif locked:\n\t\t\t\tself.__modified__.add('__locked__')\n\n\t\tdef __setattr__(self, key, value):\n\t\t\tif '__locked__' in self.__modified__:\n\t\t\t\traise AttributeError, \"This substructure is read-only, so you cannot modify '%s' attribute.\" % key\n\t\t\toldvalue = None\n\t\t\tif hasattr(self, key):\n\t\t\t\toldvalue = getattr(self, key)\n\t\t\t#if oldvalue != None and type(oldvalue) != type(value):\n\t\t\t#\t raise TypeError, \"Type of field '%s' is %s, you cannot insert %s\" % (key, type(oldvalue), type(value))\n\t\t\tobject.__setattr__(self, key, value)\n\t\t\tif oldvalue != None and value != oldvalue:\n\t\t\t\tself.__modified__.add(key)\n\n\t\tdef __getitem__(self, key):\n\t\t\tif type(key) == str or type(key) == unicode:\n\t\t\t\tspl = key.split('.')\n\t\t\telse:\n\t\t\t\tprint \"-\"*20, key, type(key)\n\t\t\tif len(spl) == 2:\n\t\t\t\tif self.__old2new__.has_key(spl[0]):\n\t\t\t\t\tspl[0] = self.__old2new__[spl[0]]\n\t\t\t\tif self.__old2new__.has_key(spl[1]):\n\t\t\t\t\tspl[1] = self.__old2new__[spl[1]]\t\t\t\t\t\n\t\t\t\treturn getattr( getattr(self, spl[0]), spl[1])\n\t\t\tif self.__old2new__.has_key(key):\n\t\t\t\tkey = self.__old2new__[key]\n\t\t\treturn getattr(self, key)\n\n\t\tdef __setitem__(self, key, value):\n\t\t\tspl = key.split('.')\n\t\t\tif len(spl) == 2:\n\t\t\t\tif self.__old2new__.has_key(spl[0]):\n\t\t\t\t\tspl[0] = self.__old2new__[spl[0]]\n\t\t\t\tif self.__old2new__.has_key(spl[1]):\n\t\t\t\t\tspl[1] = self.__old2new__[spl[1]]\t\t\t\t\t\n\t\t\t\treturn setattr( getattr(self, spl[0]), spl[1], value)\n\t\t\tif self.__old2new__.has_key(key):\n\t\t\t\tkey = self.__old2new__[key]\n\t\t\treturn setattr(self, key, value)\n\n\t\tdef __str__(self):\n\t\t\treturn object.__repr__(self)\n\n\t\tdef __iter__(self):\n\t\t\tl = []\n\t\t\tfor key in self.__slots__:\n\t\t\t\tif hasattr( getattr(self, key), '__slots__'):\n\t\t\t\t\tfor subkey in getattr(self, key).__slots__:\n\t\t\t\t\t\tl.append( \"%s.%s\" % (key, subkey))\n\t\t\t\telse:\n\t\t\t\t\tl.append( key )\n\t\t\tl.sort()\n\t\t\tfor x in l:\n\t\t\t\tyield x\n\n\t\tdef _modified(self):\n\t\t\t\"\"\"Returns tuple (key, value) for modified keys inside of FMData tree (recursive without lists)\"\"\"\n\t\t\tl = []\n\t\t\tfor key in self.__slots__:\n\t\t\t\tif hasattr( getattr(self, key), '__modified__'):\n\t\t\t\t\tfor subkey, value in getattr(self, key)._modified():\n\t\t\t\t\t\tyield ( \"%s.%s\" % (key, subkey), value )\n\t\t\t\telse:\n\t\t\t\t\tif key in self.__modified__:\n\t\t\t\t\t\tyield (key, getattr( self, key))\n\n\t\tdef __repr__(self):\n\t\t\t#from pformat import pformat\n\t\t\t#return \"<%s instance with %s records>\\n%s\" % (str(self.__class__), len(self.__slots__), pformat(dict([(value, getattr(self, value)) for value in self.__slots__])))\n\t\t\t#return pformat(dict([(value, getattr(self, value)) for value in self.__slots__]))\n\t\t\tl = []\n\t\t\tfor key in self.__slots__:\n\t\t\t\tukey = \"\"\n\t\t\t\tif self.__new2old__.has_key(key):\n\t\t\t\t\tukey = \" (%s)\" % self.__new2old__[key]\n\t\t\t\tif hasattr( getattr(self, key), '__slots__'):\n\t\t\t\t\tfor subkey in getattr(self, key).__slots__:\n\t\t\t\t\t\tvalue = getattr( getattr(self, key), subkey)\n\t\t\t\t\t\tif type(value) == str:\n\t\t\t\t\t\t\tvalue = value.decode('utf-8')\n\t\t\t\t\t\tl.append( \"%s.%s = '%s'\" % (key, subkey, value))\n\t\t\t\telif type(getattr(self, key)) == list:\n\t\t\t\t\tl.append( \"%s%s = <list with %s records>\" % (key, ukey, len(getattr(self, key))))\n\t\t\t\telif type(getattr(self, key)) == str:\n\t\t\t\t\tl.append( \"%s%s = '%s'\" % (key, ukey, getattr(self, key).decode('utf-8')))\n\t\t\t\telse:\n\t\t\t\t\tl.append( \"%s%s = '%s'\" % (key, ukey, getattr(self, key)))\n\t\t\tl.sort()\n\t\t\treturn str(('\\n'.join(l)).encode('utf-8'))\n\n\t\tdef get(self, key, default=None):\n\t\t\ttry:\n\t\t\t\treturn self.__getitem__(key)\n\t\t\texcept AttributeError:\n\t\t\t\treturn default\n\n\treturn FMData( locked )", "response": "Creates a FMData structure from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doShow(self, xml=0):\n\n\t\tif xml == 0:\n\t\t\tprint 'Errorcode:', self.errorcode\n\t\t\tprint \n\t\t\t\n\t\t\tprint 'Product information:'\n\t\t\tfor key in self.product.keys():\n\t\t\t\tprint '\t ', key.encode('UTF-8'),\n\t\t\t\tprint '->', self.product[key].encode('UTF-8')\n\t\t\tprint\n\t\t\t\n\t\t\tprint 'Database information:'\n\t\t\tfor key in self.database.keys():\n\t\t\t\tprint '\t ', key.encode('UTF-8'),\n\t\t\t\tprint'->', self.database[key].encode('UTF-8')\n\t\t\tprint\n\t\t\t\n\t\t\tprint 'Metadata:'\n\t\t\tfor field in self.metadata.keys():\n\t\t\t\tprint\n\t\t\t\tprint '\t  ', field.encode('UTF-8')\n\t\t\t\tfor property in self.metadata[field]:\n\t\t\t\t\tprint '\t\t  ', property.encode('UTF-8'),\n\t\t\t\t\tprint '->', self.metadata[field][property].encode('UTF-8') \n\t\t\tprint\n\n\t\t\tprint 'Records:'\n\t\t\tfor record in self.resultset:\n\t\t\t\tprint\n\t\t\t\tfor column in record:\n\t\t\t\t\tprint '\t  ', column.encode('UTF-8'),\n\t\t\t\t\tif type(record[column]) == UnicodeType:\n\t\t\t\t\t\tprint '->', record[column].encode('UTF-8')\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint '->', record[column]\n\n\t\telse:\n\t\t\ttags = [\n\t\t\t\t'FMPXMLRESULT',\n\t\t\t\t'ERRORCODE',\n\t\t\t\t'PRODUCT',\n\t\t\t\t'DATABASE',\n\t\t\t\t'METADATA',\n\t\t\t\t'FIELD',\n\t\t\t\t'RESULTSET',\n\t\t\t\t'ROW',\n\t\t\t\t'COL',\n\t\t\t\t'DATA'\n\t\t\t]\n\n\t\t\txml = self.data\n\n\t\t\tfor tag in tags:\n\t\t\t\txml = string.replace(xml, '></' + tag, '>\\n</' + tag)\n\t\t\t\txml = string.replace(xml, '><' + tag, '>\\n<' + tag)\n\n\t\t\tprint xml", "response": "Shows the contents of our resultset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the maximum number of records you want returned.", "response": "def _setMaxRecords(self, maxRec):\n\t\t\"\"\"Specifies the maximum number of records you want returned (number or constant 'all')\"\"\"\n\n\t\tif type(maxRec) == int:\n\t\t\tself._maxRecords = maxRec\n\t\telif type(maxRec) == str and (maxRec.lower == 'all' or maxRec.isdigit()):\n\t\t\tself._maxRecords = maxRec.lower\n\t\telse:\n\t\t\traise FMError, 'Unsupported -max value (not a number or \"all\").'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setSkipRecords(self, skipRec):\n\n\t\tif type(skipRec) == int or (type(skipRec) == str and skipRec.isdigit()):\n\t\t\tself._skipRecords = skipRec\n\t\telse:\n\t\t\traise FMError, 'Unsupported -skip value (not a number).'", "response": "Sets the skip records value for this object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the logical operator used to combine the fields.", "response": "def _setLogicalOperator(self, lop):\n\t\t\"\"\"Sets the way the find fields should be combined together.\"\"\"\n\n\t\tif not lop.lower() in ['and', 'or']:\n\t\t\traise FMError, 'Unsupported logical operator (not one of \"and\" or \"or\").'\n\n\t\tself._lop = lop.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setComparasionOperator(self, field, oper):\n\n\t\tif oper != '':\n\t\t\tvalidOperators = {\n\t\t\t\t'eq':'eq',\n\t\t\t\t'equals':'eq',\n\t\t\t\t'=':'eq',\n\t\t\t\t'==':'eq',\n\t\t\t\t'cn':'cn',\n\t\t\t\t'contains':'cn',\n\t\t\t\t'%%':'cn',\n\t\t\t\t'%':'cn',\n\t\t\t\t'*':'cn',\n\t\t\t\t'bw':'bw',\n\t\t\t\t'begins with':'bw',\n\t\t\t\t'^':'bw',\n\t\t\t\t'ew':'ew',\n\t\t\t\t'ends with':'ew',\n\t\t\t\t'$':'ew',\n\t\t\t\t'gt':'gt',\n\t\t\t\t'greater than':'gt',\n\t\t\t\t'>':'gt',\n\t\t\t\t'gte':'gte',\n\t\t\t\t'greater than or equals':'gte',\n\t\t\t\t'>=':'gte',\n\t\t\t\t'lt':'lt',\n\t\t\t\t'less than':'lt',\n\t\t\t\t'<':'lt',\n\t\t\t\t'lte':'lte',\n\t\t\t\t'less than or equals':'lte',\n\t\t\t\t'<=':'lte',\n\t\t\t\t'neq':'neq',\n\t\t\t\t'not equals':'neq',\n\t\t\t\t'!=':'neq',\n\t\t\t\t'<>':'neq'\n\t\t\t}\n\n\t\tif not string.lower(oper) in validOperators.keys():\n\t\t\traise FMError, 'Invalid operator \"'+ oper + '\" for \"' + field + '\"'\n\n\t\toper = validOperators[oper.lower()]\n\t\tself._dbParams.append(\n\t\t\t[\"%s.op\" % field, oper]\n\t\t)", "response": "Sets correct operator for given string representation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _addDBParam(self, name, value):\n\n\t\tif name[-4:] == '__OP':\n\t\t\treturn self._setComparasionOperator(name[:-4], value)\n\t\tif name[-3:] == '.op':\n\t\t\treturn self._setComparasionOperator(name[:-3], value)\n\t\tif name.find('__') != -1:\n\t\t\timport re\n\t\t\tname = name.replace('__','::')\n\t\telif name.find('.') != -1:\n\t\t\tname = name.replace('.','::')\n\n\t\tself._dbParams.append(\n\t\t\t[name, value]\n\t\t)", "response": "Adds a database parameter to the internal list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a sort parameter to the list of sort parameters.", "response": "def _addSortParam(self, field, order=''):\n\t\t\"\"\"Adds a sort parameter, order have to be in ['ascend', 'ascending','descend', 'descending','custom']\"\"\"\n\n\t\tif order != '':\n\t\t\tvalidSortOrders = {\n\t\t\t\t'ascend':'ascend',\n\t\t\t\t'ascending':'ascend',\n\t\t\t\t'<':'ascend',\n\t\t\t\t'descend':'descend',\n\t\t\t\t'descending':'descend',\n\t\t\t\t'>':'descend'\n\t\t\t}\n\n\t\t\tif not string.lower(order) in validSortOrders.keys():\n\t\t\t\traise FMError, 'Invalid sort order for \"' + field + '\"'\n\n\t\tself._sortParams.append(\n\t\t\t[field, validSortOrders[string.lower(order)]]\n\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDbNames(self):\n\n\t\trequest = []\n\t\trequest.append(uu({'-dbnames': '' }))\n\n\t\tresult = self._doRequest(request)\n\t\tresult = FMResultset.FMResultset(result)\n\n\t\tdbNames = []\n\t\tfor dbName in result.resultset:\n\t\t\tdbNames.append(string.lower(dbName['DATABASE_NAME']))\n\n\t\treturn dbNames", "response": "This function returns the list of open databases"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getLayoutNames(self):\n\n\t\tif self._db == '':\n\t\t\traise FMError, 'No database was selected'\n\n\t\trequest = []\n\t\trequest.append(uu({'-db': self._db }))\n\t\trequest.append(uu({'-layoutnames': '' }))\n\n\t\tresult = self._doRequest(request)\n\t\tresult = FMResultset.FMResultset(result)\n\n\t\tlayoutNames = []\n\t\tfor layoutName in result.resultset:\n\t\t\tlayoutNames.append(string.lower(layoutName['LAYOUT_NAME']))\n\n\t\treturn layoutNames", "response": "This function returns the list of layouts for the current db."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _preFind(self, WHAT={}, SORT=[], SKIP=None, MAX=None, LOP='AND'):\n\n\t\tif hasattr(WHAT, '_modified'):\n\t\t\tself._addDBParam('RECORDID', WHAT.RECORDID)\n\t\telif type(WHAT)==dict:\n\t\t\tfor key in WHAT:\n\t\t\t\tself._addDBParam(key, WHAT[key])\n\t\telse:\n\t\t\traise FMError, 'Python Runtime: Object type (%s) given to on of function doFind* as argument WHAT cannot be used.' % type(WHAT)\n\n\t\tfor key in SORT:\n\t\t\tself._addSortParam(key, SORT[key])\n\n\t\tif SKIP: self._setSkipRecords(SKIP)\n\t\tif MAX: self._setMaxRecords(MAX)\n\t\tif LOP: self._setLogicalOperator(LOP)\n\n\t\tif self._layout == '':\n\t\t\traise FMError, 'No layout was selected'", "response": "This function will process attributtes for all - find commands."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doFindAll(self, WHAT={}, SORT=[], SKIP=None, MAX=None):\n\n\t\tself._preFind(WHAT, SORT, SKIP, MAX)\n\n\t\treturn self._doAction('-findall')", "response": "This function will perform the command - findAll."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doDup(self, WHAT={}, **params):\n\n\t\tif hasattr(WHAT, '_modified'):\n\t\t\tfor key, value in WHAT._modified():\n\t\t\t\tif WHAT.__new2old__.has_key(key):\n\t\t\t\t\tself._addDBParam(WHAT.__new2old__[key].encode('utf-8'), value)\n\t\t\t\telse:\n\t\t\t\t\tself._addDBParam(key, value)\n\t\t\tself._addDBParam('RECORDID', WHAT.RECORDID)\n\t\t\tself._addDBParam('MODID', WHAT.MODID)\n\t\telif type(WHAT) == dict:\n\t\t\tfor key in WHAT:\n\t\t\t\tself._addDBParam(key, WHAT[key])\n\t\telse:\n\t\t\traise FMError, 'Python Runtime: Object type (%s) given to function doDup as argument WHAT cannot be used.' % type(WHAT)\n\n\t\tif self._layout == '':\n\t\t\traise FMError, 'No layout was selected'\n\n\t\tfor key in params:\n\t\t\tself._addDBParam(key, params[key])\n\n\t\tif self._checkRecordID() == 0:\n\t\t\traise FMError, 'RecordID is missing'\n\n\t\treturn self._doAction('-dup')", "response": "This function will perform the command - dup."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _doAction(self, action):\n\n\t\tif self._db == '':\n\t\t\traise FMError, 'No database was selected'\n\n\t\tresult = ''\n\n\t\ttry:\n\t\t\trequest = [\n\t\t\t\tuu({'-db': self._db })\n\t\t\t]\n\n\t\t\tif self._layout != '':\n\t\t\t\trequest.append(uu({'-lay': self._layout }))\n\n\t\t\tif action == '-find' and self._lop != 'and':\n\t\t\t\trequest.append(uu({'-lop': self._lop }))\n\n\t\t\tif action in ['-find', '-findall']:\n\n\t\t\t\tif self._skipRecords != 0:\n\t\t\t\t\trequest.append(uu({ '-skip': self._skipRecords }))\n\n\t\t\t\tif self._maxRecords != 0:\n\t\t\t\t\trequest.append(uu({ '-max': self._maxRecords }))\n\n\t\t\t\tfor i in range(0, len(self._sortParams)):\n\t\t\t\t\tsort = self._sortParams[i]\n\t\t\t\t\trequest.append(uu({ '-sortfield.'+str(i+1): sort[0] }))\n\n\t\t\t\t\tif sort[1] != '':\n\t\t\t\t\t\trequest.append(uu({ '-sortorder.'+str(i+1): sort[1] }))\n\n\t\t\tfor dbParam in self._dbParams:\n\n\t\t\t\tif dbParam[0] == 'RECORDID':\n\t\t\t\t\trequest.append(uu({ '-recid': dbParam[1] }))\n\n\t\t\t\telif dbParam[0] == 'MODID':\n\t\t\t\t\trequest.append(uu({ '-modid': dbParam[1] }))\n\n\t\t\t\telif hasattr(dbParam[1], 'strftime'):\n\t\t\t\t\td = dbParam[1]\n\t\t\t\t\tif (not hasattr(d, 'second')):\n\t\t\t\t\t\trequest.append(uu({ dbParam[0]: d.strftime('%m-%d-%Y') }))\n\t\t\t\t\telse:\n\t\t\t\t\t\trequest.append(uu({ dbParam[0]: d.strftime('%m-%d-%Y %H:%M:%S') }))\n\t\t\t\t\tdel(d)\n\t\t\t\telse:\n\t\t\t\t\trequest.append(uu({ dbParam[0]: dbParam[1] }))\n\t\t\trequest.append(action)\n\n\t\t\tif self._extra_script:\n\t\t\t\trequest += self._extra_script\n\t\t\t\tself._extra_script = None\n\n\t\t\tresult = self._doRequest(request)\n\n\t\t\ttry:\n\t\t\t\tresult = FMResultset.FMResultset(result)\n\t\t\texcept FMFieldError, value:\n\t\t\t\trealfields = FMServer(self._buildUrl(), self._db, self._layout).doView()\n\n\t\t\t\tl = []\n\t\t\t\tfor k, v in self._dbParams:\n\t\t\t\t\tif k[-3:] != '.op' and k[0] != '-':\n\t\t\t\t\t\tl.append((\"'%s'\" % k.replace('::','.')).encode('utf-8'))\n\t\t\t\traise FMError, \"Field(s) %s not found on layout '%s'\" % (', '.join(l), self._layout)\n\n\t\t\tif action == '-view':\n\t\t\t\tresult = result.fieldNames\n\n\t\tfinally:\n\t\t\tself._dbParams = []\n\t\t\tself._sortParams = []\n\t\t\tself._skipRecords = 0\n\t\t\tself._maxRecords = 0\n\t\t\tself._lop = 'and'\n\n\t\treturn result", "response": "This function will perform a FileMaker action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding url for normal FM requests.", "response": "def _buildUrl(self):\n\t\t\"\"\"Builds url for normal FM requests.\"\"\"\n\t\treturn '%(protocol)s://%(host)s:%(port)s%(address)s'%{\n\t\t\t'protocol': self._protocol,\n\t\t\t'host': self._host,\n\t\t\t'port': self._port,\n\t\t\t'address': self._address,\n\t\t}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding url for fetching the files from FM.", "response": "def _buildFileUrl(self, xml_req):\n\t\t\"\"\"Builds url for fetching the files from FM.\"\"\"\n\t\treturn '%(protocol)s://%(host)s:%(port)s%(xml_req)s'%{\n\t\t\t'protocol': self._protocol,\n\t\t\t'host': self._host,\n\t\t\t'port': self._port,\n\t\t\t'xml_req': xml_req,\n\t\t}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FMErrorByNum( num ):\n\n    if not num in FMErrorNum.keys():\n        raise FMServerError, (num, FMErrorNum[-1])\n    elif num == 102:\n        raise FMFieldError, (num, FMErrorNum[num])\n    else:\n        raise FMServerError, (num, FMErrorNum[num])", "response": "This function raises an error based on the specified error code."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fill(metrics_headers=()):\n    # Create an ordered dictionary with the Python version, which\n    # should go first.\n    answer = collections.OrderedDict((\n        ('gl-python', platform.python_version()),\n    ))\n\n    # Add anything that already appears in the passed metrics headers,\n    # in order.\n    for key, value in collections.OrderedDict(metrics_headers).items():\n        answer[key] = value\n\n    # Add the GAX and GRPC headers to our metrics.\n    # These come after what may have been passed in (generally the GAPIC\n    # library).\n    answer['gax'] = gax.__version__\n    # pylint: disable=no-member\n    answer['grpc'] = pkg_resources.get_distribution('grpcio').version\n    # pylint: enable=no-member\n\n    return answer", "response": "Fill in the OrderedDict with all of the metrics headers provided to\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the provided metrics headers to a string.", "response": "def stringify(metrics_headers=()):\n    \"\"\"Convert the provided metrics headers to a string.\n\n    Iterate over the metrics headers (a dictionary, usually ordered) and\n    return a properly-formatted space-separated string\n    (e.g. foo/1.2.3 bar/3.14.159).\n    \"\"\"\n    metrics_headers = collections.OrderedDict(metrics_headers)\n    return ' '.join(['%s/%s' % (k, v) for k, v in metrics_headers.items()])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _str_dotted_getattr(obj, name):\n    for part in name.split('.'):\n        obj = getattr(obj, part)\n    return str(obj) if obj else None", "response": "Expands extends getattr to allow dots in x to indicate nested objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request_bytesize(self):\n        return sum(len(str(e)) for elts in self._in_deque for e in elts)", "response": "The size of in bytes of the bundled field elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd elts to the tasks.", "response": "def extend(self, elts):\n        \"\"\"Adds elts to the tasks.\n\n        Args:\n           elts (Sequence): a iterable of elements that can be appended to the\n            task's bundle_field.\n\n        Returns:\n            Event: an event that can be used to wait on the response.\n        \"\"\"\n        # Use a copy, not a reference, as it is later necessary to mutate\n        # the proto field from which elts are drawn in order to construct\n        # the bundled request.\n        elts = elts[:]\n        self._in_deque.append(elts)\n        event = self._event_for(elts)\n        self._event_deque.append(event)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an Event that is set when the bundle with elts is sent.", "response": "def _event_for(self, elts):\n        \"\"\"Creates an Event that is set when the bundle with elts is sent.\"\"\"\n        event = Event()\n        event.canceller = self._canceller_for(elts, event)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a cancellation function that removes elts from the _in_deque and returns True if all elements were removed successfully from the _event_deque and False otherwise.", "response": "def _canceller_for(self, elts, event):\n        \"\"\"Obtains a cancellation function that removes elts.\n\n        The returned cancellation function returns ``True`` if all elements\n        was removed successfully from the _in_deque, and false if it was not.\n        \"\"\"\n        def canceller():\n            \"\"\"Cancels submission of ``elts`` as part of this bundle.\n\n            Returns:\n               bool: ``False`` if any of elements had already been sent,\n               otherwise ``True``.\n            \"\"\"\n            try:\n                self._event_deque.remove(event)\n                self._in_deque.remove(elts)\n                return True\n            except ValueError:\n                return False\n\n        return canceller"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nschedule the given bundling request as part of the given bundle_id.", "response": "def schedule(self, api_call, bundle_id, bundle_desc, bundling_request,\n                 kwargs=None):\n        \"\"\"Schedules bundle_desc of bundling_request as part of bundle_id.\n\n        The returned value an :class:`Event` that\n\n        * has a ``result`` attribute that will eventually be set to the result\n          the api call\n        * will be used to wait for the response\n        * holds the canceller function for canceling this part of the bundle\n\n        Args:\n          api_call (callable[[object], object]): the scheduled API call.\n          bundle_id (str): identifies the bundle on which the API call should be\n            made.\n          bundle_desc (gax.BundleDescriptor): describes the structure of the\n            bundled call.\n          bundling_request (object): the request instance to use in the API\n            call.\n          kwargs (dict): optional, the keyword arguments passed to the API call.\n\n        Returns:\n           Event: the scheduled event.\n        \"\"\"\n        kwargs = kwargs or dict()\n        bundle = self._bundle_for(api_call, bundle_id, bundle_desc,\n                                  bundling_request, kwargs)\n        elts = getattr(bundling_request, bundle_desc.bundled_field)\n        event = bundle.extend(elts)\n\n        # Run the bundle if the count threshold was reached.\n        count_threshold = self._options.element_count_threshold\n        if count_threshold > 0 and bundle.element_count >= count_threshold:\n            self._run_now(bundle.bundle_id)\n\n        # Run the bundle if the size threshold was reached.\n        size_threshold = self._options.request_byte_threshold\n        if size_threshold > 0 and bundle.request_bytesize >= size_threshold:\n            self._run_now(bundle.bundle_id)\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a gRPC client stub.", "response": "def create_stub(generated_create_stub, channel=None, service_path=None,\n                service_port=None, credentials=None, scopes=None,\n                ssl_credentials=None):\n    \"\"\"Creates a gRPC client stub.\n\n    Args:\n        generated_create_stub (Callable): The generated gRPC method to create a\n            stub.\n        channel (grpc.Channel): A Channel object through which to make calls.\n            If None, a secure channel is constructed. If specified, all\n            remaining arguments are ignored.\n        service_path (str): The domain name of the API remote host.\n        service_port (int): The port on which to connect to the remote host.\n        credentials (google.auth.credentials.Credentials): The authorization\n            credentials to attach to requests. These credentials identify your\n            application to the service.\n        scopes (Sequence[str]): The OAuth scopes for this service. This\n            parameter is ignored if a credentials is specified.\n        ssl_credentials (grpc.ChannelCredentials): gRPC channel credentials\n            used to create a secure gRPC channel. If not specified, SSL\n            credentials will be created using default certificates.\n\n    Returns:\n        grpc.Client: A gRPC client stub.\n    \"\"\"\n    if channel is None:\n        target = '{}:{}'.format(service_path, service_port)\n\n        if credentials is None:\n            credentials = _grpc_google_auth.get_default_credentials(scopes)\n\n        channel = _grpc_google_auth.secure_authorized_channel(\n            credentials, target, ssl_credentials=ssl_credentials)\n\n    return generated_create_stub(channel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default_credentials(scopes):\n    credentials, _ = google.auth.default(scopes=scopes)\n    return credentials", "response": "Gets the Application Default Credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a secure authorized gRPC channel.", "response": "def secure_authorized_channel(\n        credentials, target, ssl_credentials=None):\n    \"\"\"Creates a secure authorized gRPC channel.\"\"\"\n    http_request = _request_factory()\n    return google.auth.transport.grpc.secure_authorized_channel(\n        credentials, http_request, target,\n        ssl_credentials=ssl_credentials)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a_func to the original callable so that it gets called with the timeout as its final arg.", "response": "def add_timeout_arg(a_func, timeout, **kwargs):\n    \"\"\"Updates a_func so that it gets called with the timeout as its final arg.\n\n    This converts a callable, a_func, into another callable with an additional\n    positional arg.\n\n    Args:\n      a_func (callable): a callable to be updated\n      timeout (int): to be added to the original callable as it final positional\n        arg.\n      kwargs: Addtional arguments passed through to the callable.\n\n    Returns:\n      callable: the original callable updated to the timeout arg\n    \"\"\"\n\n    def inner(*args):\n        \"\"\"Updates args with the timeout.\"\"\"\n        updated_args = args + (timeout,)\n        return a_func(*updated_args, **kwargs)\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function that retries on transient failure.", "response": "def retryable(a_func, retry_options, **kwargs):\n    \"\"\"Creates a function equivalent to a_func, but that retries on certain\n    exceptions.\n\n    Args:\n      a_func (callable): A callable.\n      retry_options (RetryOptions): Configures the exceptions upon which the\n        callable should retry, and the parameters to the exponential backoff\n        retry algorithm.\n      kwargs: Addtional arguments passed through to the callable.\n\n    Returns:\n        Callable: A function that will retry on exception.\n    \"\"\"\n    delay_mult = retry_options.backoff_settings.retry_delay_multiplier\n    max_delay_millis = retry_options.backoff_settings.max_retry_delay_millis\n    has_timeout_settings = _has_timeout_settings(retry_options.backoff_settings)\n\n    if has_timeout_settings:\n        timeout_mult = retry_options.backoff_settings.rpc_timeout_multiplier\n        max_timeout = (retry_options.backoff_settings.max_rpc_timeout_millis /\n                       _MILLIS_PER_SECOND)\n        total_timeout = (retry_options.backoff_settings.total_timeout_millis /\n                         _MILLIS_PER_SECOND)\n\n    def inner(*args):\n        \"\"\"Equivalent to ``a_func``, but retries upon transient failure.\n\n        Retrying is done through an exponential backoff algorithm configured\n        by the options in ``retry``.\n        \"\"\"\n        delay = retry_options.backoff_settings.initial_retry_delay_millis\n        exc = errors.RetryError('Retry total timeout exceeded before any'\n                                'response was received')\n        if has_timeout_settings:\n            timeout = (\n                retry_options.backoff_settings.initial_rpc_timeout_millis /\n                _MILLIS_PER_SECOND)\n\n            now = time.time()\n            deadline = now + total_timeout\n        else:\n            timeout = None\n            deadline = None\n\n        while deadline is None or now < deadline:\n            try:\n                to_call = add_timeout_arg(a_func, timeout, **kwargs)\n                return to_call(*args)\n            except Exception as exception:  # pylint: disable=broad-except\n                code = config.exc_to_code(exception)\n                if code not in retry_options.retry_codes:\n                    raise errors.RetryError(\n                        'Exception occurred in retry method that was not'\n                        ' classified as transient', exception)\n\n                exc = errors.RetryError(\n                    'Retry total timeout exceeded with exception', exception)\n\n                # Sleep a random number which will, on average, equal the\n                # expected delay.\n                to_sleep = random.uniform(0, delay * 2)\n                time.sleep(to_sleep / _MILLIS_PER_SECOND)\n                delay = min(delay * delay_mult, max_delay_millis)\n\n                if has_timeout_settings:\n                    now = time.time()\n                    timeout = min(\n                        timeout * timeout_mult, max_timeout, deadline - now)\n\n        raise exc\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_error(msg, cause=None):\n    status_code = config.exc_to_code(cause)\n    status_name = config.NAME_STATUS_CODES.get(status_code)\n    if status_name == 'INVALID_ARGUMENT':\n        return InvalidArgumentError(msg, cause=cause)\n    else:\n        return GaxError(msg, cause=cause)", "response": "Creates a GaxError or subclass based on the message and cause."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_operation(self, name, options=None):\n        # Create the request object.\n        request = operations_pb2.GetOperationRequest(name=name)\n        return self._get_operation(request, options)", "response": "Retrieves the latest state of a long - running operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_operations(self, name, filter_, page_size=0, options=None):\n        # Create the request object.\n        request = operations_pb2.ListOperationsRequest(\n            name=name, filter=filter_, page_size=page_size)\n        return self._list_operations(request, options)", "response": "Lists all operations that match the specified filter in the request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting asynchronous cancellation on a long - running operation.", "response": "def cancel_operation(self, name, options=None):\n        \"\"\"\n        Starts asynchronous cancellation on a long-running operation.  The server\n        makes a best effort to cancel the operation, but success is not\n        guaranteed.  If the server doesn't support this method, it returns\n        ``google.rpc.Code.UNIMPLEMENTED``.  Clients can use\n        ``Operations.GetOperation`` or\n        other methods to check whether the cancellation succeeded or whether the\n        operation completed despite cancellation. On successful cancellation,\n        the operation is not deleted; instead, it becomes an operation with\n        an ``Operation.error`` value with a ``google.rpc.Status.code`` of 1,\n        corresponding to ``Code.CANCELLED``.\n\n        Example:\n          >>> from google.gapic.longrunning import operations_client\n          >>> api = operations_client.OperationsClient()\n          >>> name = ''\n          >>> api.cancel_operation(name)\n\n        Args:\n          name (string): The name of the operation resource to be cancelled.\n          options (:class:`google.gax.CallOptions`): Overrides the default\n            settings for this call, e.g, timeout, retries etc.\n\n        Raises:\n          :exc:`google.gax.errors.GaxError` if the RPC is aborted.\n          :exc:`ValueError` if the parameters are invalid.\n        \"\"\"\n        # Create the request object.\n        request = operations_pb2.CancelOperationRequest(name=name)\n        self._cancel_operation(request, options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_operation(self, name, options=None):\n        # Create the request object.\n        request = operations_pb2.DeleteOperationRequest(name=name)\n        self._delete_operation(request, options)", "response": "Deletes a long - running operation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise ValueError if more than one keyword argument is not None.", "response": "def check_oneof(**kwargs):\n    \"\"\"Raise ValueError if more than one keyword argument is not none.\n\n    Args:\n        kwargs (dict): The keyword arguments sent to the function.\n\n    Returns: None\n\n    Raises:\n        ValueError: If more than one entry in kwargs is not none.\n    \"\"\"\n    # Sanity check: If no keyword arguments were sent, this is fine.\n    if not kwargs:\n        return None\n\n    not_nones = [val for val in kwargs.values() if val is not None]\n    if len(not_nones) > 1:\n        raise ValueError('Only one of {fields} should be set.'.format(\n            fields=', '.join(sorted(kwargs.keys())),\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a function that transforms an API call into a bundling call.", "response": "def _bundleable(desc):\n    \"\"\"Creates a function that transforms an API call into a bundling call.\n\n    It transform a_func from an API call that receives the requests and returns\n    the response into a callable that receives the same request, and\n    returns a :class:`bundling.Event`.\n\n    The returned Event object can be used to obtain the eventual result of the\n    bundled call.\n\n    Args:\n      desc (gax.BundleDescriptor): describes the bundling that a_func\n        supports.\n\n    Returns:\n      Callable: takes the API call's request and keyword args and returns a\n        bundling.Event object.\n\n    \"\"\"\n    def inner(a_func, settings, request, **kwargs):\n        \"\"\"Schedules execution of a bundling task.\"\"\"\n        if not settings.bundler:\n            return a_func(request, **kwargs)\n\n        the_id = bundling.compute_bundle_id(\n            request, desc.request_discriminator_fields)\n        return settings.bundler.schedule(a_func, the_id, desc, request, kwargs)\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a function that returns an iterable to perform page - streaming based on the settings. page_token.", "response": "def _page_streamable(page_descriptor):\n    \"\"\"Creates a function that yields an iterable to performs page-streaming.\n\n    Args:\n        page_descriptor (:class:`PageDescriptor`): indicates the structure\n          of page streaming to be performed.\n\n    Returns:\n        Callable: A function that returns an iterator.\n    \"\"\"\n\n    def inner(a_func, settings, request, **kwargs):\n        \"\"\"Actual page-streaming based on the settings.\"\"\"\n        page_iterator = gax.PageIterator(\n            a_func, page_descriptor, settings.page_token, request, **kwargs)\n        if settings.flatten_pages:\n            return gax.ResourceIterator(page_iterator)\n        else:\n            return page_iterator\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _construct_bundling(bundle_config, bundle_descriptor):\n    if bundle_config and bundle_descriptor:\n        bundler = bundling.Executor(gax.BundleOptions(\n            element_count_threshold=bundle_config.get(\n                'element_count_threshold', 0),\n            element_count_limit=bundle_config.get('element_count_limit', 0),\n            request_byte_threshold=bundle_config.get(\n                'request_byte_threshold', 0),\n            request_byte_limit=bundle_config.get('request_byte_limit', 0),\n            delay_threshold=bundle_config.get('delay_threshold_millis', 0)))\n    else:\n        bundler = None\n\n    return bundler", "response": "Helper function for _construct_bundling_settings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _construct_retry(method_config, retry_codes, retry_params, retry_names):\n    if method_config is None:\n        return None\n\n    codes = None\n    if retry_codes and 'retry_codes_name' in method_config:\n        codes_name = method_config['retry_codes_name']\n        if codes_name in retry_codes and retry_codes[codes_name]:\n            codes = [retry_names[name] for name in retry_codes[codes_name]]\n        else:\n            codes = []\n\n    backoff_settings = None\n    if retry_params and 'retry_params_name' in method_config:\n        params_name = method_config['retry_params_name']\n        if params_name and params_name in retry_params:\n            backoff_settings = gax.BackoffSettings(**retry_params[params_name])\n\n    return gax.RetryOptions(\n        backoff_settings=backoff_settings,\n        retry_codes=codes,\n    )", "response": "Constructs a retry options object from the given method config."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a dictionary mapping method names to _CallSettings.", "response": "def construct_settings(\n        service_name, client_config, config_override,\n        retry_names, bundle_descriptors=None, page_descriptors=None,\n        metrics_headers=(), kwargs=None):\n    \"\"\"Constructs a dictionary mapping method names to _CallSettings.\n\n    The ``client_config`` parameter is parsed from a client configuration JSON\n    file of the form:\n\n    .. code-block:: json\n\n       {\n         \"interfaces\": {\n           \"google.fake.v1.ServiceName\": {\n             \"retry_codes\": {\n               \"idempotent\": [\"UNAVAILABLE\", \"DEADLINE_EXCEEDED\"],\n               \"non_idempotent\": []\n             },\n             \"retry_params\": {\n               \"default\": {\n                 \"initial_retry_delay_millis\": 100,\n                 \"retry_delay_multiplier\": 1.2,\n                 \"max_retry_delay_millis\": 1000,\n                 \"initial_rpc_timeout_millis\": 2000,\n                 \"rpc_timeout_multiplier\": 1.5,\n                 \"max_rpc_timeout_millis\": 30000,\n                 \"total_timeout_millis\": 45000\n               }\n             },\n             \"methods\": {\n               \"CreateFoo\": {\n                 \"retry_codes_name\": \"idempotent\",\n                 \"retry_params_name\": \"default\",\n                 \"timeout_millis\": 30000\n               },\n               \"Publish\": {\n                 \"retry_codes_name\": \"non_idempotent\",\n                 \"retry_params_name\": \"default\",\n                 \"bundling\": {\n                   \"element_count_threshold\": 40,\n                   \"element_count_limit\": 200,\n                   \"request_byte_threshold\": 90000,\n                   \"request_byte_limit\": 100000,\n                   \"delay_threshold_millis\": 100\n                 }\n               }\n             }\n           }\n         }\n       }\n\n    Args:\n      service_name (str): The fully-qualified name of this service, used as a\n        key into the client config file (in the example above, this value\n        would be ``google.fake.v1.ServiceName``).\n      client_config (dict): A dictionary parsed from the standard API client\n        config file.\n      bundle_descriptors (Mapping[str, BundleDescriptor]): A dictionary of\n        method names to BundleDescriptor objects for methods that are\n        bundling-enabled.\n      page_descriptors (Mapping[str, PageDescriptor]): A dictionary of method\n        names to PageDescriptor objects for methods that are page\n        streaming-enabled.\n      config_override (str): A dictionary in the same structure of\n        client_config to override the settings. Usually client_config is\n        supplied from the default config and config_override will be\n        specified by users.\n      retry_names (Mapping[str, object]): A dictionary mapping the strings\n        referring to response status codes to the Python objects representing\n        those codes.\n      metrics_headers (Mapping[str, str]): Dictionary of headers to be passed\n        for analytics. Sent as a dictionary; eventually becomes a\n        space-separated string (e.g. 'foo/1.0.0 bar/3.14.1').\n      kwargs (dict): The keyword arguments to be passed to the API calls.\n\n    Returns:\n      dict: A dictionary mapping method names to _CallSettings.\n\n    Raises:\n      KeyError: If the configuration for the service in question cannot be\n        located in the provided ``client_config``.\n    \"\"\"\n    # pylint: disable=too-many-locals\n    # pylint: disable=protected-access\n    defaults = {}\n    bundle_descriptors = bundle_descriptors or {}\n    page_descriptors = page_descriptors or {}\n    kwargs = kwargs or {}\n\n    # Sanity check: It is possible that we got this far but some headers\n    # were specified with an older library, which sends them as...\n    #   kwargs={'metadata': [('x-goog-api-client', 'foo/1.0 bar/3.0')]}\n    #\n    # Note: This is the final format we will send down to GRPC shortly.\n    #\n    # Remove any x-goog-api-client header that may have been present\n    # in the metadata list.\n    if 'metadata' in kwargs:\n        kwargs['metadata'] = [value for value in kwargs['metadata']\n                              if value[0].lower() != 'x-goog-api-client']\n\n    # Fill out the metrics headers with GAX and GRPC info, and convert\n    # to a string in the format that the GRPC layer expects.\n    kwargs.setdefault('metadata', [])\n    kwargs['metadata'].append(\n        ('x-goog-api-client', metrics.stringify(metrics.fill(metrics_headers)))\n    )\n\n    try:\n        service_config = client_config['interfaces'][service_name]\n    except KeyError:\n        raise KeyError('Client configuration not found for service: {}'\n                       .format(service_name))\n\n    overrides = config_override.get('interfaces', {}).get(service_name, {})\n\n    for method in service_config.get('methods'):\n        method_config = service_config['methods'][method]\n        overriding_method = overrides.get('methods', {}).get(method, {})\n        snake_name = _upper_camel_to_lower_under(method)\n\n        if overriding_method and overriding_method.get('timeout_millis'):\n            timeout = overriding_method['timeout_millis']\n        else:\n            timeout = method_config['timeout_millis']\n        timeout /= _MILLIS_PER_SECOND\n\n        bundle_descriptor = bundle_descriptors.get(snake_name)\n        bundling_config = method_config.get('bundling', None)\n        if overriding_method and 'bundling' in overriding_method:\n            bundling_config = overriding_method['bundling']\n        bundler = _construct_bundling(bundling_config, bundle_descriptor)\n\n        retry_options = _merge_retry_options(\n            _construct_retry(method_config, service_config['retry_codes'],\n                             service_config['retry_params'], retry_names),\n            _construct_retry(overriding_method, overrides.get('retry_codes'),\n                             overrides.get('retry_params'), retry_names))\n\n        defaults[snake_name] = gax._CallSettings(\n            timeout=timeout, retry=retry_options,\n            page_descriptor=page_descriptors.get(snake_name),\n            bundler=bundler, bundle_descriptor=bundle_descriptor,\n            kwargs=kwargs)\n    return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a_func to wrap certain exceptions with GaxError", "response": "def _catch_errors(a_func, to_catch):\n    \"\"\"Updates a_func to wrap exceptions with GaxError\n\n    Args:\n        a_func (callable): A callable.\n        to_catch (list[Exception]): Configures the exceptions to wrap.\n\n    Returns:\n        Callable: A function that will wrap certain exceptions with GaxError\n    \"\"\"\n    def inner(*args, **kwargs):\n        \"\"\"Wraps specified exceptions\"\"\"\n        try:\n            return a_func(*args, **kwargs)\n        # pylint: disable=catching-non-exception\n        except tuple(to_catch) as exception:\n            utils.raise_with_traceback(\n                gax.errors.create_error('RPC failed', cause=exception))\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging metadata list ( add all missing tuples", "response": "def _merge_options_metadata(options, settings):\n    \"\"\"Merge metadata list (add all missing tuples)\"\"\"\n    if not options:\n        return options\n    kwargs = options.kwargs\n    if kwargs == gax.OPTION_INHERIT or 'metadata' not in kwargs:\n        return options\n\n    kwarg_meta_dict = {}\n    merged_kwargs = options.kwargs.copy()\n    for kwarg_meta in merged_kwargs['metadata']:\n        kwarg_meta_dict[kwarg_meta[0].lower()] = kwarg_meta\n    for kwarg_meta in settings.kwargs['metadata']:\n        if kwarg_meta[0].lower() not in kwarg_meta_dict:\n            merged_kwargs['metadata'].append(kwarg_meta)\n    return gax.CallOptions(\n        timeout=options.timeout, retry=options.retry,\n        page_token=options.page_token,\n        is_bundling=options.is_bundling,\n        **merged_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an rpc call into an API call governed by the settings.", "response": "def create_api_call(func, settings):\n    \"\"\"Converts an rpc call into an API call governed by the settings.\n\n    In typical usage, ``func`` will be a callable used to make an rpc request.\n    This will mostly likely be a bound method from a request stub used to make\n    an rpc call.\n\n    The result is created by applying a series of function decorators defined\n    in this module to ``func``.  ``settings`` is used to determine which\n    function decorators to apply.\n\n    The result is another callable which for most values of ``settings`` has\n    has the same signature as the original. Only when ``settings`` configures\n    bundling does the signature change.\n\n    Args:\n      func (Callable[Sequence[object], object]): is used to make a bare rpc\n        call.\n      settings (_CallSettings): provides the settings for this call\n\n    Returns:\n      Callable[Sequence[object], object]: a bound method on a request stub used\n        to make an rpc call\n\n    Raises:\n       ValueError: if ``settings`` has incompatible values, e.g, if bundling\n         and page_streaming are both configured\n\n    \"\"\"\n    def base_caller(api_call, _, *args):\n        \"\"\"Simply call api_call and ignore settings.\"\"\"\n        return api_call(*args)\n\n    def inner(request, options=None):\n        \"\"\"Invoke with the actual settings.\"\"\"\n        this_options = _merge_options_metadata(options, settings)\n        this_settings = settings.merge(this_options)\n\n        if this_settings.retry and this_settings.retry.retry_codes:\n            api_call = gax.retry.retryable(\n                func, this_settings.retry, **this_settings.kwargs)\n        else:\n            api_call = gax.retry.add_timeout_arg(\n                func, this_settings.timeout, **this_settings.kwargs)\n        api_call = _catch_errors(api_call, gax.config.API_ERRORS)\n        return api_caller(api_call, this_settings, request)\n\n    if settings.page_descriptor:\n        if settings.bundler and settings.bundle_descriptor:\n            raise ValueError('The API call has incompatible settings: '\n                             'bundling and page streaming')\n        api_caller = _page_streamable(settings.page_descriptor)\n    elif settings.bundler and settings.bundle_descriptor:\n        api_caller = _bundleable(settings.bundle_descriptor)\n    else:\n        api_caller = base_caller\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(pb_or_dict, key, default=_SENTINEL):\n    # We may need to get a nested key. Resolve this.\n    key, subkey = _resolve_subkeys(key)\n\n    # Attempt to get the value from the two types of objects we know baout.\n    # If we get something else, complain.\n    if isinstance(pb_or_dict, Message):\n        answer = getattr(pb_or_dict, key, default)\n    elif isinstance(pb_or_dict, collections.Mapping):\n        answer = pb_or_dict.get(key, default)\n    else:\n        raise TypeError('Tried to fetch a key %s on an invalid object; '\n                        'expected a dict or protobuf message.')\n\n    # If the object we got back is our sentinel, raise KeyError; this is\n    # a \"not found\" case.\n    if answer is _SENTINEL:\n        raise KeyError(key)\n\n    # If a subkey exists, call this method recursively against the answer.\n    if subkey and answer is not default:\n        return get(answer, subkey, default=default)\n\n    # Return the value.\n    return answer", "response": "Retrieve the given key off of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the given key on the object.", "response": "def set(pb_or_dict, key, value):\n    \"\"\"Set the given key on the object.\n\n    Args:\n        pb_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key on the object in question.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If pb_or_dict is not a Message or Mapping.\n    \"\"\"\n    # pylint: disable=redefined-builtin,too-many-branches\n    # redefined-builtin: We want 'set' to be part of the public interface.\n    # too-many-branches: This method is inherently complex.\n\n    # Sanity check: Is our target object valid?\n    if not isinstance(pb_or_dict, (collections.MutableMapping, Message)):\n        raise TypeError('Tried to set a key %s on an invalid object; '\n                        'expected a dict or protobuf message.' % key)\n\n    # We may be setting a nested key. Resolve this.\n    key, subkey = _resolve_subkeys(key)\n\n    # If a subkey exists, then get that object and call this method\n    # recursively against it using the subkey.\n    if subkey is not None:\n        if isinstance(pb_or_dict, collections.MutableMapping):\n            pb_or_dict.setdefault(key, {})\n        set(get(pb_or_dict, key), subkey, value)\n        return\n\n    # Attempt to set the value on the types of objects we know how to deal\n    # with.\n    if isinstance(pb_or_dict, collections.MutableMapping):\n        pb_or_dict[key] = value\n    elif isinstance(value, (collections.MutableSequence, tuple)):\n        # Clear the existing repeated protobuf message of any elements\n        # currently inside it.\n        while getattr(pb_or_dict, key):\n            getattr(pb_or_dict, key).pop()\n\n        # Write our new elements to the repeated field.\n        for item in value:\n            if isinstance(item, collections.Mapping):\n                getattr(pb_or_dict, key).add(**item)\n            else:\n                getattr(pb_or_dict, key).extend([item])\n    elif isinstance(value, collections.Mapping):\n        # Assign the dictionary values to the protobuf message.\n        for item_key, item_value in value.items():\n            set(getattr(pb_or_dict, key), item_key, item_value)\n    elif isinstance(value, Message):\n        # Assign the protobuf message values to the protobuf message.\n        for item_key, item_value in value.ListFields():\n            set(getattr(pb_or_dict, key), item_key.name, item_value)\n    else:\n        setattr(pb_or_dict, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the key on the object to the value if the current value is falsy.", "response": "def setdefault(pb_or_dict, key, value):\n    \"\"\"Set the key on the object to the value if the current value is falsy.\n\n    Because protobuf Messages do not distinguish between unset values and\n    falsy ones particularly well, this method treats any falsy value\n    (e.g. 0, empty list) as a target to be overwritten, on both Messages\n    and dictionaries.\n\n    Args:\n        pb_or_dict (Union[~google.protobuf.message.Message, Mapping]): the\n            object.\n        key (str): The key on the object in question.\n        value (Any): The value to set.\n\n    Raises:\n        TypeError: If pb_or_dict is not a Message or Mapping.\n    \"\"\"\n    if not get(pb_or_dict, key, default=None):\n        set(pb_or_dict, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _resolve_subkeys(key, separator='.'):\n    subkey = None\n    if separator in key:\n        index = key.index(separator)\n        subkey = key[index + 1:]\n        key = key[:index]\n    return key, subkey", "response": "Given a key which may actually be a nested key return the top level\n    key and any nested subkeys as separate values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, options):\n        if not options:\n            return _CallSettings(\n                timeout=self.timeout, retry=self.retry,\n                page_descriptor=self.page_descriptor,\n                page_token=self.page_token,\n                bundler=self.bundler, bundle_descriptor=self.bundle_descriptor,\n                kwargs=self.kwargs)\n        else:\n            if options.timeout == OPTION_INHERIT:\n                timeout = self.timeout\n            else:\n                timeout = options.timeout\n\n            if options.retry == OPTION_INHERIT:\n                retry = self.retry\n            else:\n                retry = options.retry\n\n            if options.page_token == OPTION_INHERIT:\n                page_token = self.page_token\n            else:\n                page_token = options.page_token\n\n            if options.is_bundling:\n                bundler = self.bundler\n            else:\n                bundler = None\n\n            if options.kwargs == OPTION_INHERIT:\n                kwargs = self.kwargs\n            else:\n                kwargs = self.kwargs.copy()\n                kwargs.update(options.kwargs)\n\n            return _CallSettings(\n                timeout=timeout, retry=retry,\n                page_descriptor=self.page_descriptor, page_token=page_token,\n                bundler=bundler, bundle_descriptor=self.bundle_descriptor,\n                kwargs=kwargs)", "response": "Returns a new _CallSettings merged from this and a CallOptions object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncancels the last operation. Returns True if successful otherwise returns False.", "response": "def cancel(self):\n        \"\"\"If last Operation's value of `done` is true, returns false;\n        otherwise, issues OperationsClient.cancel_operation and returns true.\n        \"\"\"\n        if self.done():\n            return False\n\n        self._client.cancel_operation(self._operation.name)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the result of the operation.", "response": "def result(self, timeout=None):\n        \"\"\"Enters polling loop on OperationsClient.get_operation, and once\n        Operation.done is true, then returns Operation.response if successful or\n        throws GaxError if not successful.\n\n        This method will wait up to timeout seconds. If the call hasn't\n        completed in timeout seconds, then a RetryError will be raised. timeout\n        can be an int or float. If timeout is not specified or None, there is no\n        limit to the wait time.\n        \"\"\"\n        # Check exceptional case: raise if no response\n        if not self._poll(timeout).HasField('response'):\n            raise GaxError(self._operation.error.message)\n\n        # Return expected result\n        return _from_any(self._result_type, self._operation.response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exception(self, timeout=None):\n        # Check exceptional case: return none if no error\n        if not self._poll(timeout).HasField('error'):\n            return None\n\n        # Return expected error\n        return self._operation.error", "response": "Similar to result () except returns the exception if any."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_done_callback(self, fn):  # pylint: disable=invalid-name\n        if self._operation.done:\n            _try_callback(self, fn)\n        else:\n            self._queue.put(dill.dumps(fn))\n            if self._process is None:\n                self._process = mp.Process(target=self._execute_tasks)\n                self._process.start()", "response": "Adds a callback to be called when the operation is done or cancelled."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value of Operation. metadata from the last call to", "response": "def metadata(self):\n        \"\"\"Returns the value of Operation.metadata from the last call to\n        OperationsClient.get_operation (or if only the initial API call has been\n        made, the metadata from that first call).\n        \"\"\"\n        # Check exceptional case: return none if no metadata\n        if not self._operation.HasField('metadata'):\n            return None\n\n        # Return expected metadata\n        return _from_any(self._metadata_type, self._operation.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sql(self):\n        return '{0} {1} ON {2}'.format(self.join_type, self.right_table.get_sql(), self.get_condition())", "response": "Generates the JOIN sql for the join tables and join condition\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the left table for this join clause.", "response": "def set_left_table(self, left_table=None):\n        \"\"\"\n        Sets the left table for this join clause. If no table is specified, the first table\n        in the query will be used\n\n        :type left_table: str or dict or :class:`Table <querybuilder.tables.Table>` or None\n        :param left_table: The left table being joined with. This can be a string of the table\n            name, a dict of {'alias': table}, or a ``Table`` instance. Defaults to the first table\n            in the query.\n        \"\"\"\n        if left_table:\n            self.left_table = TableFactory(\n                table=left_table,\n                owner=self.owner,\n            )\n        else:\n            self.left_table = self.get_left_table()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_left_table(self):\n        if self.left_table:\n            return self.left_table\n        if len(self.owner.tables):\n            return self.owner.tables[0]", "response": "Returns the first table in the query if one was specified otherwise the first table in the query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_related_objects(self, table):\n        # Django 1.7 method\n        if hasattr(table.model._meta, 'get_all_related_objects'):\n            return table.model._meta.get_all_related_objects()\n        else:\n            # Django > 1.7\n            return [\n                f for f in table.model._meta.get_fields()\n                if (f.one_to_many or f.one_to_one) and f.auto_created and not f.concrete\n            ]", "response": "Returns a list of all related objects for a table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_right_table(self, table):\n        self.right_table = table\n        if self.left_table is None:\n            return\n\n        # find table prefix\n        if type(self.left_table) is ModelTable and type(self.right_table) is ModelTable:\n            # loop through fields to find the field for this model\n\n            # check if this join type is for a related field\n            for field in self.get_all_related_objects(self.left_table):\n                related_model = field.model\n                if hasattr(field, 'related_model'):\n                    related_model = field.related_model\n                if related_model == self.right_table.model:\n                    if self.right_table.field_prefix is None:\n                        self.right_table.field_prefix = field.get_accessor_name()\n                        if len(self.right_table.field_prefix) > 4 and self.right_table.field_prefix[-4:] == '_set':\n                            self.right_table.field_prefix = self.right_table.field_prefix[:-4]\n                    return\n\n            # check if this join type is for a foreign key\n            for field in self.left_table.model._meta.fields:\n                if (\n                    field.get_internal_type() == 'OneToOneField' or\n                    field.get_internal_type() == 'ForeignKey'\n                ):\n                    if field.remote_field.model == self.right_table.model:\n                        if self.right_table.field_prefix is None:\n                            self.right_table.field_prefix = field.name\n                        return", "response": "Sets the right table for this join clause and try to automatically set the condition\nosity if one isn t specified\nosity"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the condition to be used in the join clause.", "response": "def get_condition(self):\n        \"\"\"\n        Determines the condition to be used in the condition part of the join sql.\n\n        :return: The condition for the join clause\n        :rtype: str or None\n        \"\"\"\n        if self.condition:\n            return self.condition\n\n        if type(self.right_table) is ModelTable and type(self.right_table) is ModelTable:\n            # loop through fields to find the field for this model\n\n            # check if this join type is for a related field\n            for field in self.get_all_related_objects(self.right_table):\n                related_model = field.model\n                if hasattr(field, 'related_model'):\n                    related_model = field.related_model\n                if related_model == self.left_table.model:\n                    table_join_field = field.field.column\n                    # self.table_join_name = field.get_accessor_name()\n                    condition = '{0}.{1} = {2}.{3}'.format(\n                        self.right_table.get_identifier(),\n                        self.right_table.model._meta.pk.name,\n                        self.left_table.get_identifier(),\n                        table_join_field,\n                    )\n                    return condition\n\n            # check if this join type is for a foreign key\n            for field in self.right_table.model._meta.fields:\n                if (\n                    field.get_internal_type() == 'OneToOneField' or\n                    field.get_internal_type() == 'ForeignKey'\n                ):\n                    if field.remote_field.model == self.left_table.model:\n                        table_join_field = field.column\n                        # self.table_join_name = field.name\n                        condition = '{0}.{1} = {2}.{3}'.format(\n                            self.right_table.get_identifier(),\n                            table_join_field,\n                            self.left_table.get_identifier(),\n                            self.left_table.model._meta.pk.name\n                        )\n                        return condition\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds and returns the WHERE portion of the sql", "response": "def get_sql(self):\n        \"\"\"\n        Builds and returns the WHERE portion of the sql\n\n        :return: the WHERE portion of the sql\n        :rtype: str\n        \"\"\"\n        # reset arg index and args\n        self.arg_index = 0\n        self.args = {}\n\n        # build the WHERE sql portion if needed\n        if len(self.wheres):\n            where = self.build_where_part(self.wheres)\n            return 'WHERE {0} '.format(where)\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_condition_value(self, operator, value):\n        if operator in ('contains', 'icontains'):\n            value = '%{0}%'.format(value)\n        elif operator == 'startswith':\n            value = '{0}%'.format(value)\n        return value", "response": "Gets the condition value based on the operator and value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_where_part(self, wheres):\n        where_parts = []\n\n        # loop through each child of the Q condition\n        for where in wheres.children:\n\n            # if this child is another Q object, recursively build the where part\n            if type(where) is Q:\n                where_parts.append(self.build_where_part(where))\n            elif type(where) is tuple:\n                # build the condition for this where part\n                # get the field name and value\n                field_name = where[0]\n                value = where[1]\n\n                # set the default operator\n                operator_str = 'eq'\n                operator = '='\n\n                # break apart the field name on double underscores\n                field_parts = field_name.split('__')\n                if len(field_parts) > 1:\n                    # get the operator based on the last element split from the double underscores\n                    operator_str = field_parts[-1]\n                    operator = self.get_condition_operator(operator_str)\n                    if operator is None:\n                        operator = '='\n                        field_name = '__'.join(field_parts)\n                    else:\n                        field_name = '__'.join(field_parts[:-1])\n\n                # check if we are comparing to null\n                if value is None:\n                    # change the operator syntax to IS\n                    operator = 'IS'\n\n                # set up the condition string format\n                condition = '{0} {1} ?'.format(field_name, operator)\n\n                # apply the NOT if this condition is negated\n                if wheres.negated:\n                    condition = 'NOT({0})'.format(condition)\n\n                # check if this value is multiple values\n                if operator_str == 'in':\n\n                    # make sure value is a list\n                    if type(value) is not list:\n\n                        # convert to string in case it is a number\n                        value = str(value)\n\n                        # split on commas\n                        value = value.split(',')\n\n                    # Ensure that we have a value in the list\n                    if len(value) == 0:\n                        value = [None]\n\n                    if type(value) is Expression:\n                        condition = condition.replace('?', value.str)\n                    else:\n                        # assign each query param to a named arg\n                        named_args = []\n                        for value_item in value:\n                            named_arg = self.set_arg(value_item)\n                            named_args.append('%({0})s'.format(named_arg))\n                        # replace the ? in the query with the arg placeholder\n                        condition = condition.replace('?', '({0})'.format(','.join(named_args)), 1)\n                else:\n                    # get the value based on the operator\n                    value = self.get_condition_value(operator_str, value)\n\n                    if type(value) is Expression:\n                        condition = condition.replace('?', value.str)\n                    else:\n                        named_arg = self.set_arg(value)\n                        # replace the ? in the query with the arg placeholder\n                        condition = condition.replace('?', '%({0})s'.format(named_arg), 1)\n\n                # add the condition to the where sql\n                where_parts.append(condition)\n\n        # join all where parts together\n        joined_parts = ' {0} '.format(wheres.connector).join(where_parts)\n\n        # wrap the where parts in parentheses\n        return '({0})'.format(joined_parts)", "response": "Recursive method that builds the where parts for the related resources."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_arg(self, value):\n        named_arg = '{0}A{1}'.format(self.arg_prefix, self.arg_index)\n        self.args[named_arg] = value\n        self.arg_index += 1\n        return named_arg", "response": "Set the query param in self. args based on the prefix and the index of the current entry and increment the arg_index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the name to reference the sorted field Taxonomy", "response": "def get_name(self, use_alias=True):\n        \"\"\"\n        Gets the name to reference the sorted field\n\n        :return: the name to reference the sorted field\n        :rtype: str\n        \"\"\"\n        if self.desc:\n            direction = 'DESC'\n        else:\n            direction = 'ASC'\n\n        if use_alias:\n            return '{0} {1}'.format(self.field.get_identifier(), direction)\n        return '{0} {1}'.format(self.field.get_select_sql(), direction)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_sql(self):\n        sql = ''\n        if self.limit and self.limit > 0:\n            sql += 'LIMIT {0} '.format(self.limit)\n        if self.offset and self.offset > 0:\n            sql += 'OFFSET {0} '.format(self.offset)\n        return sql", "response": "Generates the sql used for the limit clause of a Query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_defaults(self):\n        self.sql = ''\n        self.tables = []\n        self.joins = []\n        self._where = Where()\n        self.groups = []\n        self.sorters = []\n        self._limit = None\n        self.table_prefix = ''\n        self.is_inner = False\n        self.with_tables = []\n        self._distinct = False\n        self.distinct_ons = []\n        self.field_names = []\n        self.field_names_pk = None\n        self.values = []", "response": "Sets the default values for this instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_table(self, table=None, fields='*', schema=None, **kwargs):\n        # self.mark_dirty()\n\n        self.tables.append(TableFactory(\n            table=table,\n            fields=fields,\n            schema=schema,\n            owner=self,\n            **kwargs\n        ))\n\n        return self", "response": "Adds a Table and any optional fields to the list of tables that this query is selecting from."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_into(self, table=None, field_names=None, values=None, **kwargs):\n        table = TableFactory(\n            table=table,\n            **kwargs\n        )\n        self.tables.append(table)\n\n        self.field_names = field_names\n        self.values = values\n\n        return self", "response": "Bulk inserts a list of values into a table"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbulks updates rows in a table", "response": "def update_table(self, table=None, field_names=None, values=None, pk=None, **kwargs):\n        \"\"\"\n        Bulk updates rows in a table\n\n        :type table: str or dict or :class:`Table <querybuilder.tables.Table>`\n            or :class:`Query <querybuilder.query.Query>` or :class:`ModelBase <django:django.db.models.base.ModelBase>`\n        :param table: The table to select fields from. This can be a string of the table\n            name, a dict of {'alias': table}, a ``Table`` instance, a Query instance, or a\n            django Model instance\n\n        :type field_names: list\n        :param field_names: A list of ordered field names that relate to the data in the values list\n\n        :type values: list of list\n        :param values: A list each values list with the values in the same order as the field names\n\n        :type pk: int\n        :param pk: The name of the primary key in the table and field_names\n\n        :param kwargs: Any additional parameters to be passed into the constructor of ``TableFactory``\n\n        :rtype: :class:`Query <querybuilder.query.Query>`\n        :return: self\n        \"\"\"\n        table = TableFactory(\n            table=table,\n            **kwargs\n        )\n        self.tables.append(table)\n\n        self.field_names = field_names\n        self.values = values\n        self.field_names_pk = pk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef join(self, right_table=None, fields=None, condition=None, join_type='JOIN',\n             schema=None, left_table=None, extract_fields=True, prefix_fields=False, field_prefix=None,\n             allow_duplicates=False):\n        \"\"\"\n        Joins a table to another table based on a condition and adds fields from the joined table\n        to the returned fields.\n\n        :type right_table: str or dict or :class:`Table <querybuilder.tables.Table>`\n        :param right_table: The table being joined with. This can be a string of the table\n            name, a dict of {'alias': table}, or a ``Table`` instance\n\n        :type fields: str or tuple or list or :class:`Field <querybuilder.fields.Field>`\n        :param fields: The fields to select from ``right_table``. Defaults to `None`. This can be\n            a single field, a tuple of fields, or a list of fields. Each field can be a string\n            or ``Field`` instance\n\n        :type condition: str\n        :param condition: The join condition specifying the fields being joined. If the two tables being\n            joined are instances of ``ModelTable`` then the condition should be created automatically.\n\n        :type join_type: str\n        :param join_type: The type of join (JOIN, LEFT JOIN, INNER JOIN, etc). Defaults to 'JOIN'\n\n        :type schema: str\n        :param schema: This is not implemented, but it will be a string of the db schema name\n\n        :type left_table: str or dict or Table\n        :param left_table: The left table being joined with. This can be a string of the table\n            name, a dict of {'alias': table}, or a ``Table`` instance. Defaults to the first table\n            in the query.\n\n        :type extract_fields: bool\n        :param extract_fields: If True and joining with a ``ModelTable``, then '*'\n            fields will be converted to individual fields for each column in the table. Defaults\n            to True.\n\n        :type prefix_fields: bool\n        :param prefix_fields: If True, then the joined table will have each of its field names\n            prefixed with the field_prefix. If not field_prefix is specified, a name will be\n            generated based on the join field name. This is usually used with nesting results\n            in order to create models in python or javascript. Defaults to True.\n\n        :type field_prefix: str\n        :param field_prefix: The field prefix to be used in front of each field name if prefix_fields\n            is set to True. If no field_prefix is set, one will be automatically created based on\n            the join field name.\n\n        :rtype: :class:`Query <querybuilder.query.Query>`\n        :return: self\n        \"\"\"\n        # self.mark_dirty()\n        # TODO: fix bug when joining from simple table to model table with no condition\n        # it assumes left_table.model\n\n        # if there is no left table, assume the query's first table\n        # TODO: add test for auto left table to replace old auto left table\n        # if left_table is None and len(self.tables):\n        #     left_table = self.tables[0]\n\n        # left_table = TableFactory(left_table)\n        # right_table = TableFactory(right_table)\n\n        # create the join item\n        new_join_item = Join(\n            left_table=left_table,\n            right_table=right_table,\n            fields=fields,\n            condition=condition,\n            join_type=join_type,\n            schema=schema,\n            owner=self,\n            extract_fields=extract_fields,\n            prefix_fields=prefix_fields,\n            field_prefix=field_prefix,\n        )\n\n        # check if this table is already joined upon\n        # TODO: add test for this\n        if allow_duplicates is False:\n            for join_item in self.joins:\n                if join_item.right_table.get_identifier() == new_join_item.right_table.get_identifier():\n                    if join_item.left_table.get_identifier() == new_join_item.left_table.get_identifier():\n                        return self\n\n        self.joins.append(new_join_item)\n\n        return self", "response": "Joins a table to another table based on a condition and adds fields to the returned fields."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap for ``self.join`` with a default join of 'LEFT JOIN' :type right_table: str or dict or :class:`Table <querybuilder.tables.Table>` :param right_table: The table being joined with. This can be a string of the table name, a dict of {'alias': table}, or a ``Table`` instance :type fields: str or tuple or list or :class:`Field <querybuilder.fields.Field>` :param fields: The fields to select from ``right_table``. Defaults to `None`. This can be a single field, a tuple of fields, or a list of fields. Each field can be a string or ``Field`` instance :type condition: str :param condition: The join condition specifying the fields being joined. If the two tables being joined are instances of ``ModelTable`` then the condition should be created automatically. :type join_type: str :param join_type: The type of join (JOIN, LEFT JOIN, INNER JOIN, etc). Defaults to 'JOIN' :type schema: str :param schema: This is not implemented, but it will be a string of the db schema name :type left_table: str or dict or :class:`Table <querybuilder.tables.Table>` :param left_table: The left table being joined with. This can be a string of the table name, a dict of {'alias': table}, or a ``Table`` instance. Defaults to the first table in the query. :type extract_fields: bool :param extract_fields: If True and joining with a ``ModelTable``, then '*' fields will be converted to individual fields for each column in the table. Defaults to True. :type prefix_fields: bool :param prefix_fields: If True, then the joined table will have each of its field names prefixed with the field_prefix. If not field_prefix is specified, a name will be generated based on the join field name. This is usually used with nesting results in order to create models in python or javascript. Defaults to True. :type field_prefix: str :param field_prefix: The field prefix to be used in front of each field name if prefix_fields is set to True. If no field_prefix is set, one will be automatically created based on the join field name. :return: self :rtype: :class:`Query <querybuilder.query.Query>`", "response": "def join_left(self, right_table=None, fields=None, condition=None, join_type='LEFT JOIN',\n                  schema=None, left_table=None, extract_fields=True, prefix_fields=False,\n                  field_prefix=None, allow_duplicates=False):\n        \"\"\"\n        Wrapper for ``self.join`` with a default join of 'LEFT JOIN'\n\n        :type right_table: str or dict or :class:`Table <querybuilder.tables.Table>`\n        :param right_table: The table being joined with. This can be a string of the table\n            name, a dict of {'alias': table}, or a ``Table`` instance\n\n        :type fields: str or tuple or list or :class:`Field <querybuilder.fields.Field>`\n        :param fields: The fields to select from ``right_table``. Defaults to `None`. This can be\n            a single field, a tuple of fields, or a list of fields. Each field can be a string\n            or ``Field`` instance\n\n        :type condition: str\n        :param condition: The join condition specifying the fields being joined. If the two tables being\n            joined are instances of ``ModelTable`` then the condition should be created automatically.\n\n        :type join_type: str\n        :param join_type: The type of join (JOIN, LEFT JOIN, INNER JOIN, etc). Defaults to 'JOIN'\n\n        :type schema: str\n        :param schema: This is not implemented, but it will be a string of the db schema name\n\n        :type left_table: str or dict or :class:`Table <querybuilder.tables.Table>`\n        :param left_table: The left table being joined with. This can be a string of the table\n            name, a dict of {'alias': table}, or a ``Table`` instance. Defaults to the first table\n            in the query.\n\n        :type extract_fields: bool\n        :param extract_fields: If True and joining with a ``ModelTable``, then '*'\n            fields will be converted to individual fields for each column in the table. Defaults\n            to True.\n\n        :type prefix_fields: bool\n        :param prefix_fields: If True, then the joined table will have each of its field names\n            prefixed with the field_prefix. If not field_prefix is specified, a name will be\n            generated based on the join field name. This is usually used with nesting results\n            in order to create models in python or javascript. Defaults to True.\n\n        :type field_prefix: str\n        :param field_prefix: The field prefix to be used in front of each field name if prefix_fields\n            is set to True. If no field_prefix is set, one will be automatically created based on\n            the join field name.\n\n        :return: self\n        :rtype: :class:`Query <querybuilder.query.Query>`\n        \"\"\"\n        return self.join(\n            right_table=right_table,\n            fields=fields,\n            condition=condition,\n            join_type=join_type,\n            schema=schema,\n            left_table=left_table,\n            extract_fields=extract_fields,\n            prefix_fields=prefix_fields,\n            field_prefix=field_prefix,\n            allow_duplicates=allow_duplicates\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef where(self, q=None, where_type='AND', **kwargs):\n        # self.mark_dirty()\n        if q is not None:\n            self._where.wheres.add(q, where_type)\n        if len(kwargs):\n            for key, value in kwargs.items():\n                q = Q(**{\n                    key: value\n                })\n                self._where.wheres.add(q, where_type)\n        return self", "response": "Adds a where condition as a Q object to the query s Where object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_by(self, field=None, table=None, allow_duplicates=False):\n        new_group_item = Group(\n            field=field,\n            table=table,\n        )\n\n        if allow_duplicates is False:\n            for group_item in self.groups:\n                if group_item.field.get_identifier() == new_group_item.field.get_identifier():\n                    return self\n\n        self.groups.append(new_group_item)\n\n        return self", "response": "Adds a group by clause to the query s list of Groups."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an order by clause to the query by adding a sorter instance to the query s sorters list", "response": "def order_by(self, field=None, table=None, desc=False):\n        \"\"\"\n        Adds an order by clause to the query by adding a ``Sorter`` instance to the query's\n        sorters list\n\n        :type field: str or dict or :class:`Field <querybuilder.fields.Field>`\n        :param field: This can be a string of a field name, a dict of {'alias': field}, or\n            a ``Field`` instance\n\n        :type table: str or dict or :class:`Table <querybuilder.table.Table>`\n        :param table: Optional. This can be a string of a table name, a dict of {'alias': table}, or\n            a ``Table`` instance. A table only needs to be supplied in more complex queries where\n            the field name is ambiguous.\n\n        :type desc: bool\n        :param desc: Set to True to sort by this field in DESC order or False to sort by this field\n            in ASC order. Defaults to False.\n\n        :rtype: :class:`Query <querybuilder.query.Query>`\n        :return: self\n        \"\"\"\n        self.sorters.append(Sorter(\n            field=field,\n            table=table,\n            desc=desc\n        ))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_name_collisions(self):\n        table_index = 0\n        table_names = {}\n        for table in self.tables + self.with_tables:\n            table_prefix = 'T{0}'.format(table_index)\n            auto_alias = '{0}{1}'.format(self.table_prefix, table_prefix)\n\n            identifier = table.get_identifier()\n            if identifier is None or identifier in table_names:\n                table.auto_alias = auto_alias\n            table_names[identifier] = True\n\n            # prefix inner query args and update self args\n            if type(table) is QueryTable:\n                table.query.prefix_args(auto_alias)\n                table.query.table_prefix = auto_alias\n\n            table_index += 1", "response": "Checks if there are any tables referenced by the same identifier and updates the auto_alias accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the sql for the current entry in the database.", "response": "def get_sql(self, debug=False, use_cache=True):\n        \"\"\"\n        Generates the sql for this query and returns the sql as a string.\n\n        :type debug: bool\n        :param debug: If True, the sql will be returned in a format that is easier to read and debug.\n            Defaults to False\n\n        :type use_cache: bool\n        :param use_cache: If True, the query will returned the cached sql if it exists rather\n            then generating the sql again. If False, the sql will be generated again. Defaults to True.\n\n        :rtype: str\n        :return: The generated sql for this query\n        \"\"\"\n        # TODO: enable caching\n        # if self.sql and use_cache and not debug:\n        #     return self.sql\n\n        # auto alias any naming collisions\n        self.check_name_collisions()\n\n        # if debugging, return the debug formatted sql\n        if debug:\n            return self.format_sql()\n\n        # build each part of the query\n        sql = ''\n        sql += self.build_withs()\n        sql += self.build_select_fields()\n        sql += self.build_from_table()\n        sql += self.build_joins()\n        sql += self.build_where()\n        sql += self.build_groups()\n        sql += self.build_order_by()\n        sql += self.build_limit()\n\n        # remove any whitespace from the beginning and end of the sql\n        self.sql = sql.strip()\n\n        return self.sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_update_sql(self, rows):\n        field_names = self.get_field_names()\n        pk = field_names[0]\n        update_field_names = field_names[1:]\n\n        num_columns = len(rows[0])\n        if num_columns < 2:\n            raise Exception('At least 2 fields must be passed to get_update_sql')\n\n        all_null_indices = [\n            all(row[index] is None for row in rows)\n            for index in range(1, num_columns)\n        ]\n\n        field_names_sql = '({0})'.format(', '.join(field_names))\n\n        row_values = []\n        sql_args = []\n\n        for row in rows:\n            placeholders = []\n            for value in row:\n                sql_args.append(value)\n                placeholders.append('%s')\n            row_values.append('({0})'.format(', '.join(placeholders)))\n        row_values_sql = ', '.join(row_values)\n\n        # build field list for SET portion\n        set_field_list = [\n            '{0} = NULL'.format(field_name)\n            if all_null_indices[idx] else '{0} = new_values.{0}'.format(field_name)\n            for idx, field_name in enumerate(update_field_names)\n        ]\n        set_field_list_sql = ', '.join(set_field_list)\n\n        self.sql = 'UPDATE {0} SET {1} FROM (VALUES {2}) AS new_values {3} WHERE {0}.{4} = new_values.{4}'.format(\n            self.tables[0].get_identifier(),\n            set_field_list_sql,\n            row_values_sql,\n            field_names_sql,\n            pk\n        )\n\n        return self.sql, sql_args", "response": "Returns the SQL UPDATE for rows"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_upsert_sql(\n        self,\n        rows,\n        unique_fields,\n        update_fields,\n        auto_field_name=None,\n        only_insert=False,\n        return_rows=True\n    ):\n        \"\"\"\n        Generates the postgres specific sql necessary to perform an upsert (ON CONFLICT)\n\n        INSERT INTO table_name (field1, field2)\n        VALUES (1, 'two')\n        ON CONFLICT (unique_field) DO UPDATE SET field2 = EXCLUDED.field2;\n        \"\"\"\n        ModelClass = self.tables[0].model\n\n        # Use all fields except pk unless the uniqueness constraint is the pk field. Null pk field rows will be\n        # excluded in the upsert method before calling this method\n        all_fields = [field for field in ModelClass._meta.fields if field.column != auto_field_name]\n        if auto_field_name in unique_fields and not only_insert:\n            all_fields = [field for field in ModelClass._meta.fields]\n\n        all_field_names = [field.column for field in all_fields]\n        all_field_names_sql = ', '.join(all_field_names)\n\n        # Convert field names to db column names\n        unique_fields = [\n            ModelClass._meta.get_field(unique_field)\n            for unique_field in unique_fields\n        ]\n        update_fields = [\n            ModelClass._meta.get_field(update_field)\n            for update_field in update_fields\n        ]\n\n        unique_field_names_sql = ', '.join([\n            field.column for field in unique_fields\n        ])\n        update_fields_sql = ', '.join([\n            '{0} = EXCLUDED.{0}'.format(field.column)\n            for field in update_fields\n        ])\n\n        row_values = []\n        sql_args = []\n\n        for row in rows:\n            placeholders = []\n            for field in all_fields:\n                # Convert field value to db value\n                # Use attname here to support fields with custom db_column names\n                sql_args.append(field.get_db_prep_save(getattr(row, field.attname), self.connection))\n                placeholders.append('%s')\n            row_values.append('({0})'.format(', '.join(placeholders)))\n        row_values_sql = ', '.join(row_values)\n\n        if update_fields:\n            self.sql = 'INSERT INTO {0} ({1}) VALUES {2} ON CONFLICT ({3}) DO UPDATE SET {4} {5}'.format(\n                self.tables[0].get_identifier(),\n                all_field_names_sql,\n                row_values_sql,\n                unique_field_names_sql,\n                update_fields_sql,\n                'RETURNING *' if return_rows else ''\n            )\n        else:\n            self.sql = 'INSERT INTO {0} ({1}) VALUES {2} ON CONFLICT ({3}) {4} {5}'.format(\n                self.tables[0].get_identifier(),\n                all_field_names_sql,\n                row_values_sql,\n                unique_field_names_sql,\n                'DO UPDATE SET {0}=EXCLUDED.{0}'.format(unique_fields[0].column),\n                'RETURNING *' if return_rows else ''\n            )\n\n        return self.sql, sql_args", "response": "Generates the SQL statement that will be used to insert or update a record in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_sql(self):\n        # TODO: finish adding the other parts of the sql generation\n        sql = ''\n\n        # build SELECT\n        select_segment = self.build_select_fields()\n        select_segment = select_segment.replace('SELECT ', '', 1)\n        fields = [field.strip() for field in select_segment.split(',')]\n        sql += 'SELECT\\n\\t{0}\\n'.format(',\\n\\t'.join(fields))\n\n        # build FROM\n        from_segment = self.build_from_table()\n        from_segment = from_segment.replace('FROM ', '', 1)\n        tables = [table.strip() for table in from_segment.split(',')]\n        sql += 'FROM\\n\\t{0}\\n'.format(',\\n\\t'.join(tables))\n\n        # build ORDER BY\n        order_by_segment = self.build_order_by()\n        if len(order_by_segment):\n            order_by_segment = order_by_segment.replace('ORDER BY ', '', 1)\n            sorters = [sorter.strip() for sorter in order_by_segment.split(',')]\n            sql += 'ORDER BY\\n\\t{0}\\n'.format(',\\n\\t'.join(sorters))\n\n        # build LIMIT\n        limit_segment = self.build_limit()\n        if len(limit_segment):\n            if 'LIMIT' in limit_segment:\n                limit_segment = limit_segment.replace('LIMIT ', 'LIMIT\\n\\t', 1)\n                if 'OFFSET' in limit_segment:\n                    limit_segment = limit_segment.replace('OFFSET ', '\\nOFFSET\\n\\t', 1)\n            elif 'OFFSET' in limit_segment:\n                limit_segment = limit_segment.replace('OFFSET ', 'OFFSET\\n\\t', 1)\n            sql += limit_segment\n\n        return sql", "response": "Builds the sql for the query\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a list of the field names for all tables and joined tables by calling get_field_names on each table and joined tables by calling get_field_names on each join item.", "response": "def get_field_names(self):\n        \"\"\"\n        Builds a list of the field names for all tables and joined tables by calling\n        ``get_field_names()`` on each table\n\n        :return: list of field names\n        :rtype: list of str\n        \"\"\"\n        field_names = []\n        for table in self.tables:\n            field_names.extend(table.get_field_names())\n        for join_item in self.joins:\n            field_names.extend(join_item.right_table.get_field_names())\n        return field_names"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_field_identifiers(self):\n        field_identifiers = []\n        for table in self.tables:\n            field_identifiers += table.get_field_identifiers()\n        for join_item in self.joins:\n            field_identifiers += join_item.right_table.get_field_identifiers()\n        return field_identifiers", "response": "Builds a list of the field identifiers for all tables and joined tables by calling get_field_identifiers on each table and joined tables by calling get_field_identifiers on each join item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the sql for the SELECT portion of the query", "response": "def build_select_fields(self):\n        \"\"\"\n        Generates the sql for the SELECT portion of the query\n\n        :return: the SELECT portion of the query\n        :rtype: str\n        \"\"\"\n        field_sql = []\n\n        # get the field sql for each table\n        for table in self.tables:\n            field_sql += table.get_field_sql()\n\n        # get the field sql for each join table\n        for join_item in self.joins:\n            field_sql += join_item.right_table.get_field_sql()\n\n        # combine all field sql separated by a comma\n        sql = 'SELECT {0}{1} '.format(self.get_distinct_sql(), ', '.join(field_sql))\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_from_table(self):\n        table_parts = []\n\n        # get the table sql for each table\n        for table in self.tables:\n            sql = table.get_sql()\n            if len(sql):\n                table_parts.append(sql)\n\n        # combine all table sql separated by a comma\n        sql = 'FROM {0} '.format(', '.join(table_parts))\n\n        return sql", "response": "Generates the sql for the FROM portion of the query\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the sql for the JOIN portion of the query", "response": "def build_joins(self):\n        \"\"\"\n        Generates the sql for the JOIN portion of the query\n\n        :return: the JOIN portion of the query\n        :rtype: str\n        \"\"\"\n        join_parts = []\n\n        # get the sql for each join object\n        for join_item in self.joins:\n            join_parts.append(join_item.get_sql())\n\n        # if there are any joins, combine them\n        if len(join_parts):\n            combined_joins = ' '.join(join_parts)\n            return '{0} '.format(combined_joins)\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_groups(self):\n        # check if there are any groupings\n        if len(self.groups):\n            groups = []\n\n            # get the group sql for each grouping\n            for group in self.groups:\n                groups.append(group.get_name())\n            return 'GROUP BY {0} '.format(', '.join(groups))\n        return ''", "response": "Generates the SQL for the GROUP BY portion of the query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the SQL for the order by portion of the query.", "response": "def build_order_by(self, use_alias=True):\n        \"\"\"\n        Generates the sql for the ORDER BY portion of the query\n\n        :type use_alias: bool\n        :param use_alias: If True, the alias for the field will be used in the order by.\n            This is an option before query windows do not use the alias. Defaults to True.\n\n        :return: the ORDER BY portion of the query\n        :rtype: str\n        \"\"\"\n        # check if there are any sorters\n        if len(self.sorters):\n            sorters = []\n\n            # get the sql for each sorter\n            for sorter in self.sorters:\n                sorters.append(sorter.get_name(use_alias=use_alias))\n            return 'ORDER BY {0} '.format(', '.join(sorters))\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_table(self, table):\n        table = TableFactory(table)\n        identifier = table.get_identifier()\n        join_tables = [join_item.right_table for join_item in self.joins]\n        for table in (self.tables + join_tables):\n            if table.get_identifier() == identifier:\n                return table\n        return None", "response": "Finds a table by name or alias."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the query by selecting all fields from itself", "response": "def wrap(self, alias=None):\n        \"\"\"\n        Wraps the query by selecting all fields from itself\n\n        :rtype: :class:`Query <querybuilder.query.Query>`\n        :return: The wrapped query\n        \"\"\"\n        field_names = self.get_field_names()\n        query = Query(self.connection).from_table(deepcopy(self), alias=alias)\n        self.__dict__.update(query.__dict__)\n\n        # set explicit field names\n        self.tables[0].set_fields(field_names)\n        field_names = self.get_field_names()\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copy(self):\n        connection = self.connection\n        del self.connection\n        copied_query = deepcopy(self)\n        copied_query.connection = connection\n        self.connection = connection\n        return copied_query", "response": "Returns a copy of the current query object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the args for the query which will be escaped when being executed by the the db.", "response": "def get_args(self):\n        \"\"\"\n        Gets the args for the query which will be escaped when being executed by the\n        db. All inner queries are inspected and their args are combined with this\n        query's args.\n\n        :return: all args for this query as a dict\n        :rtype: dict\n        \"\"\"\n        for table in self.tables + self.with_tables:\n            if type(table) is QueryTable:\n                self._where.args.update(table.query.get_args())\n\n        return self._where.args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef explain(self, sql=None, sql_args=None):\n        cursor = self.get_cursor()\n        if sql is None:\n            sql = self.get_sql()\n            sql_args = self.get_args()\n        elif sql_args is None:\n            sql_args = {}\n\n        cursor.execute('EXPLAIN {0}'.format(sql), sql_args)\n        rows = self._fetch_all_as_dict(cursor)\n        return rows", "response": "Runs EXPLAIN on the database and returns the list of lines of output from the EXPLAIN statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the SELECT statement and returns the rows as a list of dictionaries or a list of models.", "response": "def select(self, return_models=False, nest=False, bypass_safe_limit=False, sql=None, sql_args=None):\n        \"\"\"\n        Executes the SELECT statement and returns the rows as a list of dictionaries or a list of\n        model instances\n\n        :type return_models: bool\n        :param return_models: Set to True to return a list of models instead of a list of dictionaries.\n            Defaults to False\n\n        :type nest: bool\n        :param nest: Set to True to treat all double underscores in keynames as nested data. This will\n            convert all keys with double underscores to dictionaries keyed off of the left side of\n            the underscores. Ex: {\"id\": 1\", \"account__id\": 1, \"account__name\": \"Name\"} becomes\n            {\"id\": 1, \"account\": {\"id\": 1, \"name\": \"Name\"}}\n\n        :type bypass_safe_limit: bool\n        :param bypass_safe_limit: Ignores the safe_limit option even if the safe_limit is enabled\n\n        :type sql: str or None\n        :param sql: The sql to execute in the SELECT statement. If one is not specified, then the\n            query will use ``self.get_sql()``\n\n        :type sql_args: str or None\n        :param sql_args: The sql args to be used in the SELECT statement. If none are specified, then\n            the query wil use ``self.get_args()``\n\n        :rtype: list of dict\n        :return: list of dictionaries of the rows\n        \"\"\"\n        # Check if we need to set a safe limit\n        if bypass_safe_limit is False:\n            if Query.enable_safe_limit:\n                if self.count() > Query.safe_limit:\n                    self.limit(Query.safe_limit)\n\n        # determine which sql to use\n        if sql is None:\n            sql = self.get_sql()\n\n        # determine which sql args to use\n        if sql_args is None:\n            sql_args = self.get_args()\n\n        # get the cursor to execute the query\n        cursor = self.get_cursor()\n\n        # execute the query\n        cursor.execute(sql, sql_args)\n\n        # get the results as a list of dictionaries\n        rows = self._fetch_all_as_dict(cursor)\n\n        # check if models should be returned instead of dictionaries\n        if return_models:\n\n            # set nesting to true, so the nested models can easily load the data\n            nest = True\n\n            # build model map of map name to model\n            model_map = {}\n            for join_item in self.joins:\n                model_map[join_item.right_table.field_prefix] = join_item.right_table.model\n\n        # check if results should be nested\n        if nest:\n\n            # convert keys with double underscores to dictionaries\n            for row in rows:\n                _row = row.copy()\n                for key, value in _row.items():\n                    set_value_for_keypath(row, key, value, True, '__')\n                    if '__' in key:\n                        row.pop(key)\n\n            # create models if needed\n            if return_models:\n                model_class = self.tables[0].model\n                new_rows = []\n                for row in rows:\n                    model = model_class()\n                    # assign all non-model keys first because django 1.5 requires\n                    # that the model has an id set before setting a property that is\n                    # a foreign key\n                    for key, value in row.items():\n                        if key not in model_map:\n                            setattr(model, key, value)\n                    # assign all model instances\n                    for key, value in row.items():\n                        if key in model_map:\n                            child_model = model_map[key]()\n                            for child_key, child_value in value.items():\n                                setattr(child_model, child_key, child_value)\n                            value = child_model\n                        setattr(model, key, value)\n                    new_rows.append(model)\n                rows = new_rows\n\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, rows):\n        if len(rows) == 0:\n            return\n\n        sql, sql_args = self.get_insert_sql(rows)\n\n        # get the cursor to execute the query\n        cursor = self.get_cursor()\n\n        # execute the query\n        cursor.execute(sql, sql_args)", "response": "Inserts records into the db\n        table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, rows):\n        if len(rows) == 0:\n            return\n\n        sql, sql_args = self.get_update_sql(rows)\n\n        # get the cursor to execute the query\n        cursor = self.get_cursor()\n\n        # execute the query\n        cursor.execute(sql, sql_args)", "response": "Updates the record set in the db\n        table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_auto_field_name(self, model_class):\n        # Get auto field name (a model can only have one AutoField)\n        for field in model_class._meta.fields:\n            if isinstance(field, AutoField):\n                return field.column\n\n        return None", "response": "Get the auto field name for a given model class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming an upsert of the set of models in the database.", "response": "def upsert(self, rows, unique_fields, update_fields, return_rows=False, return_models=False):\n        \"\"\"\n        Performs an upsert with the set of models defined in rows. If the unique field which is meant\n        to cause a conflict is an auto increment field, then the field should be excluded when its value is null.\n        In this case, an upsert will be performed followed by a bulk_create\n        \"\"\"\n        if len(rows) == 0:\n            return\n\n        ModelClass = self.tables[0].model\n\n        rows_with_null_auto_field_value = []\n\n        # Get auto field name (a model can only have one AutoField)\n        auto_field_name = self.get_auto_field_name(ModelClass)\n\n        # Check if unique fields list contains an auto field\n        if auto_field_name in unique_fields:\n            # Separate the rows that need to be inserted vs the rows that need to be upserted\n            rows_with_null_auto_field_value = [row for row in rows if getattr(row, auto_field_name) is None]\n            rows = [row for row in rows if getattr(row, auto_field_name) is not None]\n\n        return_value = []\n\n        if rows:\n            sql, sql_args = self.get_upsert_sql(\n                rows,\n                unique_fields,\n                update_fields,\n                auto_field_name=auto_field_name,\n                return_rows=return_rows or return_models\n            )\n\n            # get the cursor to execute the query\n            cursor = self.get_cursor()\n\n            # execute the upsert query\n            cursor.execute(sql, sql_args)\n\n            if return_rows or return_models:\n                return_value.extend(self._fetch_all_as_dict(cursor))\n\n        if rows_with_null_auto_field_value:\n            sql, sql_args = self.get_upsert_sql(\n                rows_with_null_auto_field_value,\n                unique_fields,\n                update_fields,\n                auto_field_name=auto_field_name,\n                only_insert=True,\n                return_rows=return_rows or return_models\n            )\n\n            # get the cursor to execute the query\n            cursor = self.get_cursor()\n\n            # execute the upsert query\n            cursor.execute(sql, sql_args)\n\n            if return_rows or return_models:\n                return_value.extend(self._fetch_all_as_dict(cursor))\n\n        if return_models:\n            ModelClass = self.tables[0].model\n            model_objects = [\n                ModelClass(**row_dict)\n                for row_dict in return_value\n            ]\n\n            # Set the state to indicate the object has been loaded from db\n            for model_object in model_objects:\n                model_object._state.adding = False\n                model_object._state.db = 'default'\n\n            return_value = model_objects\n\n        return return_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_count_query(self):\n        query_copy = self.copy()\n        if not query_copy.tables:\n            raise Exception('No tables specified to do a count')\n\n        for table in query_copy.tables:\n            del table.fields[:]\n\n        query_copy.tables[0].add_field(CountField('*'))\n        del query_copy.sorters[:]\n        return query_copy", "response": "Returns a new query object that counts the number of entries in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count(self, field='*'):\n        rows = self.get_count_query().select(bypass_safe_limit=True)\n        return list(rows[0].values())[0]", "response": "Returns a COUNT of the query by wrapping the query and performing a COUNT aggregate of the specified field\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef max(self, field):\n        q = Query(self.connection).from_table(self, fields=[\n            MaxField(field)\n        ])\n        rows = q.select(bypass_safe_limit=True)\n        return list(rows[0].values())[0]", "response": "Returns the maximum value of a field in the result set of the query\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef min(self, field):\n        q = Query(self.connection).from_table(self, fields=[\n            MinField(field)\n        ])\n        rows = q.select(bypass_safe_limit=True)\n        return list(rows[0].values())[0]", "response": "Returns the minimum value of a field in the result set of the query\n        method by wrapping the query and performing a MIN aggregate on the specified field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the sum of the specified field in the result set of the query", "response": "def sum(self, field):\n        \"\"\"\n        Returns the sum of the field in the result set of the query\n        by wrapping the query and performing a SUM aggregate of the specified field\n        :param field: the field to pass to the SUM aggregate\n        :type field: str\n\n        :return: The sum of the specified field\n        :rtype: int\n        \"\"\"\n        q = Query(self.connection).from_table(self, fields=[\n            SumField(field)\n        ])\n        rows = q.select(bypass_safe_limit=True)\n        return list(rows[0].values())[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef avg(self, field):\n        q = Query(self.connection).from_table(self, fields=[\n            AvgField(field)\n        ])\n        rows = q.select(bypass_safe_limit=True)\n        return list(rows[0].values())[0]", "response": "Returns the average of the field in the result set of the query\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the result set and converts each row to a dictionary", "response": "def _fetch_all_as_dict(self, cursor):\n        \"\"\"\n        Iterates over the result set and converts each row to a dictionary\n\n        :return: A list of dictionaries where each row is a dictionary\n        :rtype: list of dict\n        \"\"\"\n        desc = cursor.description\n        return [\n            dict(zip([col[0] for col in desc], row))\n            for row in cursor.fetchall()\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the sql for this query window and returns it as a string.", "response": "def get_sql(self, debug=False, use_cache=True):\n        \"\"\"\n        Generates the sql for this query window and returns the sql as a string.\n\n        :type debug: bool\n        :param debug: If True, the sql will be returned in a format that is easier to read and debug.\n            Defaults to False\n\n        :type use_cache: bool\n        :param use_cache: If True, the query will returned the cached sql if it exists rather\n            then generating the sql again. If False, the sql will be generated again. Defaults to True.\n\n        :rtype: str\n        :return: The generated sql for this query window\n        \"\"\"\n        # TODO: implement caching and debug\n        sql = ''\n        sql += self.build_partition_by_fields()\n        sql += self.build_order_by(use_alias=False)\n        sql += self.build_limit()\n        sql = sql.strip()\n        sql = 'OVER ({0})'.format(sql)\n        self.sql = sql\n\n        return self.sql"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value_for_keypath(dict, keypath):\n\n    if len(keypath) == 0:\n        return dict\n\n    keys = keypath.split('.')\n    value = dict\n    for key in keys:\n        if key in value:\n            value = value[key]\n        else:\n            return None\n\n    return value", "response": "Returns the value of a keypath in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_value_for_keypath(item, keypath, value, create_if_needed=False, delimeter='.'):\n\n    if len(keypath) == 0:\n        return None\n\n    keys = keypath.split(delimeter)\n    if len(keys) > 1:\n        key = keys[0]\n\n        if create_if_needed:\n            item[key] = item.get(key, {})\n\n        if key in item:\n            if set_value_for_keypath(item[key], delimeter.join(keys[1:]), value,\n                                     create_if_needed=create_if_needed, delimeter=delimeter):\n                return item\n\n        return None\n\n    if create_if_needed:\n        item[keypath] = item.get(keypath, {})\n\n    if keypath in item:\n        item[keypath] = value\n        return item\n    else:\n        return None", "response": "Sets the value for a keypath in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the SELECT sql part for a field_name AS alias", "response": "def get_sql(self):\n        \"\"\"\n        Gets the SELECT sql part for a field\n        Ex: field_name AS alias\n\n        :return: the sql for this field used in the SELECT portion of the query\n        :rtype: str\n        \"\"\"\n        alias = self.get_alias()\n        if alias:\n            if self.cast:\n                return 'CAST({0} AS {1}) AS \"{2}\"'.format(self.get_select_sql(), self.cast.upper(), alias)\n            return '{0} AS \"{1}\"'.format(self.get_select_sql(), alias)\n\n        if self.cast:\n            return 'CAST({0} AS {1})'.format(self.get_identifier(), self.cast.upper())\n        return self.get_identifier()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the alias for the field or the auto_alias if one is set.", "response": "def get_alias(self):\n        \"\"\"\n        Gets the alias for the field or the auto_alias if one is set.\n        If there isn't any kind of alias, None is returned.\n\n        :return: The field alias, auto_alias, or None\n        :rtype: str or None\n        \"\"\"\n        alias = None\n        if self.alias:\n            alias = self.alias\n        elif self.auto_alias:\n            alias = self.auto_alias\n\n        if self.table and self.table.prefix_fields:\n            field_prefix = self.table.get_field_prefix()\n            if alias:\n                alias = '{0}__{1}'.format(field_prefix, alias)\n            else:\n                alias = '{0}__{1}'.format(field_prefix, self.name)\n\n        return alias"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_select_sql(self):\n        if self.table:\n            return '{0}.{1}'.format(self.table.get_identifier(), self.name)\n        return '{0}'.format(self.name)", "response": "Gets the SELECT portion for the field without the alias."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the table of this field.", "response": "def set_table(self, table):\n        \"\"\"\n        Setter for the table of this field. Also sets the inner field's table.\n        \"\"\"\n        super(MultiField, self).set_table(table)\n        if self.field and self.field.table is None:\n            self.field.set_table(self.table)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_select_sql(self):\n        return '{0}({1}{2}){3}'.format(\n            self.name.upper(),\n            self.get_distinct(),\n            self.get_field_identifier(),\n            self.get_over(),\n        )", "response": "Gets the SELECT portion for the field without the alias."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the identifier of the field", "response": "def get_field_identifier(self):\n        \"\"\"\n        Return the lag/lead function with the offset and default value\n        \"\"\"\n        if self.default is None:\n            return '{0}, {1}'.format(self.field.get_select_sql(), self.offset)\n        return \"{0}, {1}, '{2}'\".format(self.field.get_select_sql(), self.offset, self.default)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_select_sql(self):\n        return '(({0}) - ({1}({2}){3}))'.format(\n            self.field.get_select_sql(),\n            self.name.upper(),\n            self.get_field_identifier(),\n            self.get_over(),\n        )", "response": "Returns the SQL to select the value between this record s value and the lag / lead record s value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates any auto fields needed to properly group this date part.", "response": "def generate_auto_fields(self):\n        \"\"\"\n        Generates any auto fields needed to properly group this date part.\n        Ex: a Day field will create Year, Month, Day fields and group by Year, Month, Day\n        \"\"\"\n        # ignore the original date field\n        self.ignore = True\n        datetime_str = None\n\n        # create an alias for the unix timestamp extraction\n        epoch_alias = '{0}__{1}'.format(self.field.get_name(), 'epoch')\n\n        if self.name == 'all':\n            datetime_str = self.field\n            self.add_to_table(AllEpoch(datetime_str, table=self.table, cast=self.cast), epoch_alias)\n            # do not add the date order by for \"all\" grouping because we want to order by rank\n            return\n        elif self.name == 'none':\n            datetime_str = self.field\n            self.add_to_table(Epoch(datetime_str, table=self.table, cast=self.cast), epoch_alias, add_group=True)\n        else:\n            group_names = default_group_names\n            if self.name == 'week':\n                group_names = week_group_names\n\n            group_name_index = group_names.index(self.name) + 1\n            for group_name in group_names[0:group_name_index]:\n                field_alias = '{0}__{1}'.format(self.field.get_name(), group_name)\n                auto_field = group_map[group_name](self.field, table=self.table, cast=self.cast)\n                self.add_to_table(auto_field, field_alias, add_group=True)\n\n                # check if this is the last date grouping\n                if group_name == self.name:\n                    datetime_str = self.field\n                    self.add_to_table(\n                        GroupEpoch(\n                            datetime_str,\n                            date_group_name=group_name,\n                            table=self.table,\n                            cast=self.cast,\n                        ),\n                        epoch_alias,\n                        add_group=True\n                    )\n\n        if self.desc:\n            self.table.owner.order_by('-{0}'.format(epoch_alias))\n        else:\n            self.table.owner.order_by(epoch_alias)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_to_table(self, field, alias, add_group=False):\n        self.table.add_field({\n            alias: field\n        })\n        if add_group:\n            self.table.owner.group_by(alias)", "response": "Adds this field to the table and optionally group by it s entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sql(self):\n        alias = self.get_alias()\n        if alias:\n            return '{0} AS {1}'.format(self.get_from_name(), alias)\n\n        return self.get_identifier()", "response": "Gets the FROM sql portion for this table\n        Ex : table_name AS alias\n        Returns the identifier of the table identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_alias(self):\n        alias = None\n        if self.alias:\n            alias = self.alias\n        elif self.auto_alias:\n            alias = self.auto_alias\n\n        return alias", "response": "Gets the alias for the table or the auto_alias if one is set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a field to this table.", "response": "def add_field(self, field):\n        \"\"\"\n        Adds a field to this table\n\n        :param field: This can be a string of a field name, a dict of {'alias': field}, or\n            a ``Field`` instance\n        :type field: str or dict or Field\n        \"\"\"\n        field = FieldFactory(\n            field,\n        )\n        field.set_table(self)\n\n        # make sure field is not already added\n        field_name = field.get_name()\n        for existing_field in self.fields:\n            if existing_field.get_name() == field_name:\n                return None\n\n        self.before_add_field(field)\n        field.before_add()\n\n        if field.ignore is False:\n            self.fields.append(field)\n\n        return field"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a field from this table.", "response": "def remove_field(self, field):\n        \"\"\"\n        Removes a field from this table\n\n        :param field: This can be a string of a field name, a dict of {'alias': field}, or\n            a ``Field`` instance\n        :type field: str or dict or :class:`Field <querybuilder.fields.Field>`\n        \"\"\"\n        new_field = FieldFactory(\n            field,\n        )\n        new_field.set_table(self)\n        new_field_identifier = new_field.get_identifier()\n        for field in self.fields:\n            if field.get_identifier() == new_field_identifier:\n                self.fields.remove(field)\n                return field\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd all of the passed fields to the table s current field list.", "response": "def add_fields(self, fields):\n        \"\"\"\n        Adds all of the passed fields to the table's current field list\n\n        :param fields: The fields to select from ``table``. This can be\n            a single field, a tuple of fields, or a list of fields. Each field can be a string\n            or ``Field`` instance\n        :type fields: str or tuple or list of str or list of Field or :class:`Field <querybuilder.fields.Field>`\n        \"\"\"\n        if isinstance(fields, string_types):\n            fields = [fields]\n        elif type(fields) is tuple:\n            fields = list(fields)\n\n        field_objects = [self.add_field(field) for field in fields]\n        return field_objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a field by name or alias.", "response": "def find_field(self, field=None, alias=None):\n        \"\"\"\n        Finds a field by name or alias.\n\n        :param field: string of the field name or alias, dict of {'alias': field}, or a Field instance\n        :type field: str or dict or Field\n\n        :returns: The field if it is found, otherwise None\n        :rtype: :class:`Field <querybuilder.fields.Field>` or None\n        \"\"\"\n        if alias:\n            field = alias\n        field = FieldFactory(field, table=self, alias=alias)\n        identifier = field.get_identifier()\n        for field in self.fields:\n            if field.get_identifier() == identifier:\n                return field\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the name of the table to the passed in table value", "response": "def init_defaults(self):\n        \"\"\"\n        Sets the name of the table to the passed in table value\n        \"\"\"\n        super(SimpleTable, self).init_defaults()\n        self.name = self.table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_defaults(self):\n        super(ModelTable, self).init_defaults()\n        self.model = self.table\n        self.name = self.model._meta.db_table", "response": "Sets the model instance variable to the model value and sets the name to the table name as determined from the model class\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the fields to the list of related objects.", "response": "def before_add_field(self, field):\n        \"\"\"\n        If extract_fields is set to True, then '*' fields will be removed and each\n        individual field will read from the model meta data and added.\n        \"\"\"\n        if self.extract_fields and field.name == '*':\n            field.ignore = True\n            fields = [model_field.column for model_field in self.model._meta.fields]\n            self.add_fields(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a query instance variable to the table value", "response": "def init_defaults(self):\n        \"\"\"\n        Sets a query instance variable to the table value\n        \"\"\"\n        super(QueryTable, self).init_defaults()\n        self.query = self.table\n        self.query.is_inner = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_command(cmd_to_run):\n    with tempfile.TemporaryFile() as stdout_file, tempfile.TemporaryFile() as stderr_file:\n\n        # Run the command\n        popen = subprocess.Popen(cmd_to_run, stdout=stdout_file, stderr=stderr_file)\n        popen.wait()\n\n        stderr_file.seek(0)\n        stdout_file.seek(0)\n\n        stderr = stderr_file.read()\n        stdout = stdout_file.read()\n\n        if six.PY3:\n            stderr = stderr.decode()\n            stdout = stdout.decode()\n\n        return stderr, stdout", "response": "Wrapper around subprocess. Popen that pipes the stderr and stdout from cmd_to_run to temporary files and returns a tuple containing the stderr and stdout as strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log(self, level, prefix = ''):\n        logging.log(level, \"%sname: %s\", prefix, self.__name)\n        logging.log(level, \"%soptions: %s\", prefix, self.__options)", "response": "Writes the contents of the Extension to the logging system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef specbits(self):\n        bits = []\n        for opt in sorted(self.__options):\n            # handle the case where this is a negated option\n            m = re.match(r'^! (.*)', opt)\n            if m:\n                bits.extend(['!', \"--%s\" % m.group(1)])\n            else:\n                bits.append(\"--%s\" % opt)\n                \n            optval = self.__options[opt]\n            if isinstance(optval, list):\n                bits.extend(optval)\n            else:\n                bits.append(optval)\n        return bits", "response": "Returns the array of arguments that would be given to\n        iptables for the current Extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the contents of the Rule to the logging system.", "response": "def log(self, level, prefix = ''):\n        \"\"\"Writes the contents of the Rule to the logging system.\n        \"\"\"\n        logging.log(level, \"%sin interface: %s\", prefix, self.in_interface)\n        logging.log(level, \"%sout interface: %s\", prefix, self.out_interface)\n        logging.log(level, \"%ssource: %s\", prefix, self.source)\n        logging.log(level, \"%sdestination: %s\", prefix, self.destination)\n        logging.log(level, \"%smatches:\", prefix)\n        for match in self.matches:\n            match.log(level, prefix + '  ')\n        if self.jump:\n            logging.log(level, \"%sjump:\", prefix)\n            self.jump.log(level, prefix + '  ')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef specbits(self):\n        def host_bits(opt, optval):\n            # handle the case where this is a negated value\n            m = re.match(r'^!\\s*(.*)', optval)\n            if m:\n                return ['!', opt, m.group(1)]\n            else:\n                return [opt, optval]\n\n        bits = []\n        if self.protocol:\n            bits.extend(host_bits('-p', self.protocol))\n        if self.in_interface:\n            bits.extend(host_bits('-i', self.in_interface))\n        if self.out_interface:\n            bits.extend(host_bits('-o', self.out_interface))\n        if self.source:\n            bits.extend(host_bits('-s', self.source))\n        if self.destination:\n            bits.extend(host_bits('-d', self.destination))\n        for mod in self.matches:\n            bits.extend(['-m', mod.name()])\n            bits.extend(mod.specbits())\n        if self.goto:\n            bits.extend(['-g', self.goto.name()])\n            bits.extend(self.goto.specbits())\n        elif self.jump:\n            bits.extend(['-j', self.jump.name()])\n            bits.extend(self.jump.specbits())\n        return bits", "response": "Returns the array of arguments that would be given to\n            iptables for the current Rule."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the chain definitions.", "response": "def parse_chains(data):\n    \"\"\"\n    Parse the chain definitions.\n    \"\"\"\n    chains = odict()\n    for line in data.splitlines(True):\n        m = re_chain.match(line)\n        if m:\n            policy = None\n            if m.group(2) != '-':\n                policy = m.group(2)\n            chains[m.group(1)] = {\n                'policy': policy,\n                'packets': int(m.group(3)),\n                'bytes': int(m.group(4)),\n            }\n    return chains"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_rules(data, chain):\n    rules = []\n    for line in data.splitlines(True):\n        m = re_rule.match(line)\n        if m and m.group(3) == chain:\n            rule = parse_rule(m.group(4))\n            rule.packets = int(m.group(1))\n            rule.bytes = int(m.group(2))\n            rules.append(rule)\n    return rules", "response": "Parse the rules for the specified chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_new_connection(self, conn_params):\n    self.__connection_string = conn_params.get('connection_string', '')\n    conn = self.Database.connect(**conn_params)\n    return conn", "response": "Opens a connection to the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict of parameters suitable for get_new_connection.", "response": "def get_connection_params(self):\n        \"\"\"Returns a dict of parameters suitable for get_new_connection.\"\"\"\n        from django.conf import settings\n        settings_dict = self.settings_dict\n        options = settings_dict.get('OPTIONS', {})\n        autocommit = options.get('autocommit', False)\n        conn_params = {\n            'server': settings_dict['HOST'],\n            'database': settings_dict['NAME'],\n            'user': settings_dict['USER'],\n            'port': settings_dict.get('PORT', '1433'),\n            'password': settings_dict['PASSWORD'],\n            'timeout': self.command_timeout,\n            'autocommit': autocommit,\n            'use_mars': options.get('use_mars', False),\n            'load_balancer': options.get('load_balancer', None),\n            'failover_partner': options.get('failover_partner', None),\n            'use_tz': utc if getattr(settings, 'USE_TZ', False) else None,\n         }\n\n        for opt in _SUPPORTED_OPTIONS:\n            if opt in options:\n                conn_params[opt] = options[opt]\n\n        self.tzinfo_factory = utc_tzinfo_factory if settings.USE_TZ else None\n\n        return conn_params"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a cursor. Assumes that a connection is established.", "response": "def create_cursor(self, name=None):\n        \"\"\"Creates a cursor. Assumes that a connection is established.\"\"\"\n        cursor = self.connection.cursor()\n        cursor.tzinfo_factory = self.tzinfo_factory\n        return cursor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the DBMS Version string", "response": "def __get_dbms_version(self, make_connection=True):\n        \"\"\"\n        Returns the 'DBMS Version' string\n        \"\"\"\n        major, minor, _, _ = self.get_server_version(make_connection=make_connection)\n        return '{}.{}'.format(major, minor)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_buffer(self):\n        buffer = []\n        for table in self.__tables: \n            buffer.extend(table.get_buffer())\n        return buffer", "response": "Get the change buffers."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess command line arguments and run the given command.", "response": "def run(self, args):\n        \"\"\"\n        Process command line arguments and run the given command command\n        (start, stop, restart).\n        \"\"\"\n        prog = args[0]\n        if len(args) < 2:\n            self.usage(prog)\n            return 1\n\n        command = args[1]\n        if command == \"start\":\n            self.start()\n        elif command == \"stop\":\n            self.stop()\n        elif command == \"restart\":\n            self.stop()\n            self.start()\n        else:\n            self.usage(prog)\n            return 1\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_chain(self, chainname=None):\n        args = ['-X']\n        if chainname: args.append(chainname)\n        self.__run_iptables(args)", "response": "Attempts to delete the specified user - defined chain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flush_chain(self, chainname=None):\n        args = ['-F']\n        if chainname: args.append(chainname)\n        self.__run_iptables(args)", "response": "Flushes all the chains in the specified chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_rules(self, chainname):\n        data = self.__run([self.__iptables_save, '-t', self.__name, '-c'])\n        return netfilter.parser.parse_rules(data, chainname)", "response": "Returns a list of Rules in the specified chain."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncommitting any buffered commands.", "response": "def commit(self):\n        \"\"\"Commits any buffered commands. This is only useful if\n        auto_commit is False.\n        \"\"\"\n        while len(self.__buffer) > 0:\n            self.__run(self.__buffer.pop(0))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nletting you type a page number to go to", "response": "async def numbered_page(self):\n        \"\"\"lets you type a page number to go to\"\"\"\n        to_delete = []\n        to_delete.append(await self.bot.send_message(self.message.channel, 'What page do you want to go to?'))\n        msg = await self.bot.wait_for_message(author=self.author, channel=self.message.channel,\n                                              check=lambda m: m.content.isdigit(), timeout=30.0)\n        if msg is not None:\n            page = int(msg.content)\n            to_delete.append(msg)\n            if page != 0 and page <= self.maximum_pages:\n                await self.show_page(page)\n            else:\n                to_delete.append(await self.bot.say('Invalid page given. (%s/%s)' % (page, self.maximum_pages)))\n                await asyncio.sleep(5)\n        else:\n            to_delete.append(await self.bot.send_message(self.message.channel, 'Took too long.'))\n            await asyncio.sleep(5)\n\n        try:\n            await self.bot.delete_messages(to_delete)\n        except Exception:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops the interactive pagination session", "response": "async def stop_pages(self):\n        \"\"\"stops the interactive pagination session\"\"\"\n        await self.bot.delete_message(self.message)\n        self.paginating = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def paginate(self):\n        await self.show_page(1, first=True)\n\n        while self.paginating:\n            react = await self.bot.wait_for_reaction(message=self.message, check=self.react_check, timeout=120.0)\n            if react is None:\n                self.paginating = False\n                try:\n                    await self.bot.clear_reactions(self.message)\n                except:\n                    pass\n                finally:\n                    break\n\n            try:\n                await self.bot.remove_reaction(self.message, react.reaction.emoji, react.user)\n            except:\n                pass # can't remove it so don't bother doing so\n\n            await self.match()", "response": "Actually paginate the entries and run the interactive loop if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntoggles sending DMs to owner.", "response": "async def _senddms(self):\n        \"\"\"Toggles sending DMs to owner.\"\"\"\n        data = self.bot.config.get(\"meta\", {})\n        tosend = data.get('send_dms', True)\n        data['send_dms'] = not tosend\n        await self.bot.config.put('meta', data)\n        await self.bot.responses.toggle(message=\"Forwarding of DMs to owner has been {status}.\", success=data['send_dms'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _setcolor(self, *, color : discord.Colour):\n        data = self.bot.config.get(\"meta\", {})\n        data['default_color'] = str(color)\n        await self.bot.config.put('meta', data)\n        await self.bot.responses.basic(message=\"The default color has been updated.\")", "response": "Sets the default color of embeds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrepeating a command a specified number of times.", "response": "async def _do(self, ctx, times: int, *, command):\n        \"\"\"Repeats a command a specified number of times.\"\"\"\n        msg = copy.copy(ctx.message)\n        msg.content = command\n        for i in range(times):\n            await self.bot.process_commands(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisabling a command for this server.", "response": "async def disable(self, ctx, *, command: str):\n        \"\"\"Disables a command for this server.\n\n        You must have Manage Server permissions or the\n        Bot Admin role to use this command.\n        \"\"\"\n        command = command.lower()\n\n        if command in ('enable', 'disable'):\n            return await self.bot.responses.failure(message='Cannot disable that command.')\n\n        if command not in self.bot.commands:\n            return await self.bot.responses.failure(message='Command \"{}\" was not found.'.format(command))\n\n        guild_id = ctx.message.server.id\n        cmds = self.config.get('commands', {})\n        entries = cmds.get(guild_id, [])\n        entries.append(command)\n        cmds[guild_id] = entries\n        await self.config.put('commands', cmds)\n        await self.bot.responses.success(message='\"%s\" command disabled in this server.' % command)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable a command for this server.", "response": "async def enable(self, ctx, *, command: str):\n        \"\"\"Enables a command for this server.\n\n        You must have Manage Server permissions or the\n        Bot Admin role to use this command.\n        \"\"\"\n        command = command.lower()\n        guild_id = ctx.message.server.id\n        cmds = self.config.get('commands', {})\n        entries = cmds.get(guild_id, [])\n\n        try:\n            entries.remove(command)\n        except KeyError:\n            await self.bot.responses.failure(message='The command does not exist or is not disabled.')\n        else:\n            cmds[guild_id] = entries\n            await self.config.put('commands', cmds)\n            await self.bot.responses.success(message='\"%s\" command enabled in this server.' % command)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def ignore(self, ctx):\n        if ctx.invoked_subcommand is None:\n            await self.bot.say('Invalid subcommand passed: {0.subcommand_passed}'.format(ctx))", "response": "Handles the bot s ignore lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def ignore_list(self, ctx):\n\n        ignored = self.config.get('ignored', [])\n        channel_ids = set(c.id for c in ctx.message.server.channels)\n        result = []\n        for channel in ignored:\n            if channel in channel_ids:\n                result.append('<#{}>'.format(channel))\n\n        if result:\n            await self.bot.responses.basic(title=\"Ignored Channels:\", message='\\n\\n{}'.format(', '.join(result)))\n        else:\n            await self.bot.responses.failure(message='I am not ignoring any channels here.')", "response": "Tells you what channels are currently ignored in this server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def channel_cmd(self, ctx, *, channel : discord.Channel = None):\n\n        if channel is None:\n            channel = ctx.message.channel\n\n        ignored = self.config.get('ignored', [])\n        if channel.id in ignored:\n            await self.bot.responses.failure(message='That channel is already ignored.')\n            return\n\n        ignored.append(channel.id)\n        await self.config.put('ignored', ignored)\n        await self.bot.responses.success(message='Channel <#{}> will be ignored.'.format(channel.id))", "response": "Ignores a specific channel from being processed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def _all(self, ctx):\n\n        ignored = self.config.get('ignored', [])\n        channels = ctx.message.server.channels\n        ignored.extend(c.id for c in channels if c.type == discord.ChannelType.text)\n        await self.config.put('ignored', list(set(ignored))) # make unique\n        await self.bot.responses.success(message='All channels ignored.')", "response": "Ignores every channel in the server from being processed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean up the bot s messages from the channel.", "response": "async def cleanup(self, ctx, search : int = 100):\n        \"\"\"Cleans up the bot's messages from the channel.\n\n        If a search number is specified, it searches that many messages to delete.\n        If the bot has Manage Messages permissions, then it will try to delete\n        messages that look like they invoked the bot as well.\n\n        After the cleanup is completed, the bot will send you a message with\n        which people got their messages deleted and their count. This is useful\n        to see which users are spammers.\n\n        To use this command you must have Manage Messages permission or have the\n        Bot Mod role.\n        \"\"\"\n\n        spammers = Counter()\n        channel = ctx.message.channel\n        prefixes = self.bot.command_prefix\n        if callable(prefixes):\n            prefixes = prefixes(self.bot, ctx.message)\n\n        def is_possible_command_invoke(entry):\n            valid_call = any(entry.content.startswith(prefix) for prefix in prefixes)\n            return valid_call and not entry.content[1:2].isspace()\n\n        can_delete = channel.permissions_for(channel.server.me).manage_messages\n\n        if not can_delete:\n            api_calls = 0\n            async for entry in self.bot.logs_from(channel, limit=search, before=ctx.message):\n                if api_calls and api_calls % 5 == 0:\n                    await asyncio.sleep(1.1)\n\n                if entry.author == self.bot.user:\n                    await self.bot.delete_message(entry)\n                    spammers['Bot'] += 1\n                    api_calls += 1\n\n                if is_possible_command_invoke(entry):\n                    try:\n                        await self.bot.delete_message(entry)\n                    except discord.Forbidden:\n                        continue\n                    else:\n                        spammers[entry.author.display_name] += 1\n                        api_calls += 1\n        else:\n            predicate = lambda m: m.author == self.bot.user or is_possible_command_invoke(m)\n            deleted = await self.bot.purge_from(channel, limit=search, before=ctx.message, check=predicate)\n            spammers = Counter(m.author.display_name for m in deleted)\n\n        deleted = sum(spammers.values())\n        messages = ['%s %s removed.' % (deleted, 'message was' if deleted == 1 else 'messages were')]\n        if deleted:\n            messages.append('')\n            spammers = sorted(spammers.items(), key=lambda t: t[1], reverse=True)\n            messages.extend(map(lambda t: '**{0[0]}**: {0[1]}'.format(t), spammers))\n\n        msg = await self.bot.responses.basic(title=\"Removed Messages:\", message='\\n'.join(messages))\n        await asyncio.sleep(10)\n        await self.bot.delete_message(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def plonk(self, ctx, *, member: discord.Member):\n\n        plonks = self.config.get('plonks', {})\n        guild_id = ctx.message.server.id\n        db = plonks.get(guild_id, [])\n\n        if member.id in db:\n            await self.bot.responses.failure(message='That user is already bot banned in this server.')\n            return\n\n        db.append(member.id)\n        plonks[guild_id] = db\n        await self.config.put('plonks', plonks)\n        await self.bot.responses.success(message='%s has been banned from using the bot in this server.' % member)", "response": "Bans a person from using the bot in the current server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def plonks(self, ctx):\n        plonks = self.config.get('plonks', {})\n        guild = ctx.message.server\n        db = plonks.get(guild.id, [])\n        members = '\\n'.join(map(str, filter(None, map(guild.get_member, db))))\n        if members:\n            await self.bot.responses.basic(title=\"Plonked Users:\", message=members)\n        else:\n            await self.bot.responses.failure(message='No members are banned in this server.')", "response": "Shows members banned from the bot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def unplonk(self, ctx, *, member: discord.Member):\n\n        plonks = self.config.get('plonks', {})\n        guild_id = ctx.message.server.id\n        db = plonks.get(guild_id, [])\n\n        try:\n            db.remove(member.id)\n        except ValueError:\n            await self.bot.responses.failure(message='%s is not banned from using the bot in this server.' % member)\n        else:\n            plonks[guild_id] = db\n            await self.config.put('plonks', plonks)\n            await self.bot.responses.success(message='%s has been unbanned from using the bot in this server.' % member)", "response": "Unbans a user from using the bot."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend you the bot invite link.", "response": "async def join(self, ctx):\n        \"\"\"Sends you the bot invite link.\"\"\"\n        perms = discord.Permissions.none()\n        perms.read_messages = True\n        perms.send_messages = True\n        perms.manage_messages = True\n        perms.embed_links = True\n        perms.read_message_history = True\n        perms.attach_files = True\n        perms.add_reactions = True\n        await self.bot.send_message(ctx.message.author, discord.utils.oauth_url(self.bot.client_id, perms))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing info about a member.", "response": "async def info(self, ctx, *, member : discord.Member = None):\n        \"\"\"Shows info about a member.\n\n        This cannot be used in private messages. If you don't specify\n        a member then the info returned will be yours.\n        \"\"\"\n        channel = ctx.message.channel\n        if member is None:\n            member = ctx.message.author\n\n        e = discord.Embed()\n        roles = [role.name.replace('@', '@\\u200b') for role in member.roles]\n        shared = sum(1 for m in self.bot.get_all_members() if m.id == member.id)\n        voice = member.voice_channel\n        if voice is not None:\n            other_people = len(voice.voice_members) - 1\n            voice_fmt = '{} with {} others' if other_people else '{} by themselves'\n            voice = voice_fmt.format(voice.name, other_people)\n        else:\n            voice = 'Not connected.'\n\n        e.set_author(name=str(member), icon_url=member.avatar_url or member.default_avatar_url)\n        e.set_footer(text='Member since').timestamp = member.joined_at\n        e.add_field(name='ID', value=member.id)\n        e.add_field(name='Servers', value='%s shared' % shared)\n        e.add_field(name='Voice', value=voice)\n        e.add_field(name='Created', value=member.created_at)\n        e.add_field(name='Roles', value=', '.join(roles))\n        e.colour = member.colour\n\n        if member.avatar:\n            e.set_image(url=member.avatar_url)\n\n        await self.bot.say(embed=e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntells you about the bot.", "response": "async def about(self):\n        \"\"\"Tells you information about the bot itself.\n\n        This is more information about the bot, not really\n        sure when this comes into play tbh, thats what I am\n        testing right now.\n        \"\"\"\n\n        cmd = r'git show -s -3 --format=\"%s (%cr)\"'\n        if os.name == 'posix':\n            cmd = cmd.format(r'\\`%h\\`')\n        else:\n            cmd = cmd.format(r'`%h`')\n\n        embed = discord.Embed()\n        embed.colour = Colors.get_default(self.bot)\n\n        embed.add_field(name=\"About \"+self.bot.user.name+\":\", value=self.bot.description, inline=False)\n        \n        if os.popen('git rev-list --all --count').close() is None and os.popen('git rev-parse').close() is None:\n            revision = os.popen(cmd).read().strip()\n            embed.add_field(name=\"Latest Changes:\", value=revision, inline=False)\n\n        try:\n            owner = self._owner\n        except AttributeError:\n            owner = self._owner = await self.bot.get_user_info(self.bot.config.get('meta', {}).get('owner', \"249746236008169473\"))\n\n        if self.bot.ownerInviteLink:\n            embed.title = owner.name+'\\'s Server Invite'\n            embed.url = self.bot.ownerInviteLink\n\n        embed.set_author(name=\"Created by \"+str(owner), icon_url=owner.avatar_url)\n\n        # statistics\n        total_members = sum(len(s.members) for s in self.bot.servers)\n        total_online  = sum(1 for m in self.bot.get_all_members() if m.status != discord.Status.offline)\n        unique_members = set(self.bot.get_all_members())\n        unique_online = sum(1 for m in unique_members if m.status != discord.Status.offline)\n        channel_types = Counter(c.type for c in self.bot.get_all_channels())\n        voice = channel_types[discord.ChannelType.voice]\n        text = channel_types[discord.ChannelType.text]\n\n        members = '%s total\\n%s online\\n%s unique\\n%s unique online' % (total_members, total_online, len(unique_members), unique_online)\n        embed.add_field(name='Members', value=members)\n        embed.add_field(name='Channels', value='{} total\\n{} text\\n{} voice'.format(text + voice, text, voice))\n        memory_usage = self.process.memory_full_info().uss / 1024**2\n        cpu_usage = self.process.cpu_percent() / psutil.cpu_count()\n        embed.add_field(name='Process', value='{:.2f} MiB\\n{:.2f}% CPU'.format(memory_usage, cpu_usage))\n        embed.set_footer(text='Made with discord.py & discordbot.py', icon_url='http://i.imgur.com/5BFecvA.png')\n        embed.timestamp = self.bot.uptime\n\n        data = self.config.get('data', {})\n        summation = 0\n        for server in data:\n            summation += sum(data[server].values())\n\n        embed.add_field(name='Servers', value=str(len(self.bot.servers)))\n        embed.add_field(name='Commands Run', value=summation)\n        embed.add_field(name='Uptime', value=self.get_bot_uptime(brief=True))\n\n        await self.bot.say(embed=embed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nedit a data entry.", "response": "async def put(self, key, value, *args):\n        \"\"\"Edits a data entry.\"\"\"\n        self._db[key] = value\n        await self.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the actual behaviour involved with formatting.", "response": "def format(self):\n        \"\"\"Handles the actual behaviour involved with formatting.\n        To change the behaviour, this method should be overridden.\n        Returns\n        --------\n        list\n            A paginated output of the help command.\n        \"\"\"\n\n        values = {}\n        title = \"Description\"\n        description = self.command.description + \"\\n\\n\" + self.get_ending_note() if not self.is_cog() else inspect.getdoc(self.command)\n        sections = []\n\n        if isinstance(self.command, Command):\n                description = self.command.short_doc\n                sections = [{\"name\": \"Usage\", \"value\": self.get_command_signature()},\n                            {\"name\": \"More Info\", \"value\": self.command.help.replace(self.command.short_doc, \"\").format(prefix=self.clean_prefix),\n                             \"inline\": False}]\n\n        def category(tup):\n            cog = tup[1].cog_name\n            return cog + ':' if cog is not None else '\\u200bNo Category:'\n\n        if self.is_bot():\n            title = self.bot.user.display_name + \" Help\"\n            data = sorted(self.filter_command_list(), key=category)\n            for category, commands in itertools.groupby(data, key=category):\n                section = {}\n                commands = list(commands)\n                if len(commands) > 0:\n                    section['name'] = category\n                section['value'] = self.add_commands(commands)\n                section['inline'] = False\n                sections.append(section)\n        elif not sections or self.has_subcommands():\n            section = {\"name\": \"Commands:\", \"inline\": False, \"value\": self.add_commands(self.filter_command_list())}\n            sections.append(section)\n\n        values['title'] = title\n        values['description'] = description\n        values['sections'] = sections\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist all the reactions for the server", "response": "async def listreactions(self, ctx):\n        \"\"\"Lists all the reactions for the server\"\"\"\n        data = self.config.get(ctx.message.server.id, {})\n        if not data:\n            await self.bot.responses.failure(message=\"There are no reactions on this server.\")\n            return\n        try:\n            pager = Pages(self.bot, message=ctx.message, entries=list(data.keys()))\n            pager.embed.colour = 0x738bd7  # blurple\n            pager.embed.set_author(name=ctx.message.server.name + \" Reactions\", icon_url=ctx.message.server.icon_url)\n            await pager.paginate()\n\n        except Exception as e:\n            await self.bot.say(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def viewreaction(self, ctx, *, reactor : str):\n        data = self.config.get(ctx.message.server.id, {})\n        keyword = data.get(reactor, {})\n\n        if not keyword:\n            await self.bot.responses.failure(message=\"Reaction '{}' was not found.\".format(reactor))\n            return\n\n        response = data.get(reactor, {}).get(\"response\", \"\")\n        reacts = data.get(reactor, {}).get(\"reaction\", [])\n\n        for i, r in enumerate(reacts):\n            if \":\" in r:\n                reacts[i] = \"<:\" + r + \">\"\n\n        reacts = \" \".join(reacts) if reacts else \"-\"\n        response = response if response else \"-\"\n\n        string = \"Here's what I say to '{reactor}': {response}\\n\"\\\n                 \"I'll react to this message how I react to '{reactor}'.\".format(reactor=reactor,response=response)\n\n        await self.bot.responses.full(sections=[{\"name\": \"Response\", \"value\": response},\n                                                {\"name\": \"Reactions\", \"value\": reacts, \"inline\": False}])", "response": "Views a specific reaction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def deletereaction(self, ctx, *, reactor : str):\n        data = self.config.get(ctx.message.server.id, {})\n        keyword = data.get(reactor, {})\n        if keyword:\n            data.pop(reactor)\n            await self.config.put(ctx.message.server.id, data)\n            await self.bot.responses.success(message=\"Reaction '{}' has been deleted.\".format(reactor))\n        else:\n            await self.bot.responses.failure(message=\"Reaction '{}' was not found.\".format(reactor))", "response": "Removes a reaction from the config."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all reactions from the server.", "response": "async def deleteallreactions(self, ctx):\n        \"\"\"Removes a reaction\"\"\"\n        data = self.config.get(ctx.message.server.id, {})\n        if data:\n            await self.config.put(ctx.message.server.id, {})\n            await self.bot.responses.success(message=\"All reactions have been deleted.\")\n        else:\n            await self.bot.responses.failure(message=\"This server has no reactions.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nla_ok(nla, remaining):\n    return remaining.value >= nla.SIZEOF and nla.SIZEOF <= nla.nla_len <= remaining.value", "response": "Checks if the attribute header and payload can be accessed safely."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning next attribute in a stream of attributes.", "response": "def nla_next(nla, remaining):\n    \"\"\"Return next attribute in a stream of attributes.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L171\n\n    Calculates the offset to the next attribute based on the attribute given. The attribute provided is assumed to be\n    accessible, the caller is responsible to use nla_ok() beforehand. The offset (length of specified attribute\n    including padding) is then subtracted from the remaining bytes variable and a pointer to the next attribute is\n    returned.\n\n    nla_next() can be called as long as remaining is >0.\n\n    Positional arguments:\n    nla -- attribute of any kind (nlattr class instance).\n    remaining -- number of bytes remaining in attribute stream (c_int).\n\n    Returns:\n    Next nlattr class instance.\n    \"\"\"\n    totlen = int(NLA_ALIGN(nla.nla_len))\n    remaining.value -= totlen\n    return nlattr(bytearray_ptr(nla.bytearray, totlen))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate a Netlink attribute.", "response": "def validate_nla(nla, maxtype, policy):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L188.\n\n    Positional arguments:\n    nla -- nlattr class instance.\n    maxtype -- integer.\n    policy -- dictionary of nla_policy class instances as values, with nla types as keys.\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    minlen = 0\n    type_ = nla_type(nla)\n    if type_ < 0 or type_ > maxtype:\n        return 0\n\n    pt = policy[type_]\n    if pt.type_ > NLA_TYPE_MAX:\n        raise BUG\n\n    if pt.minlen:\n        minlen = pt.minlen\n    elif pt.type_ != NLA_UNSPEC:\n        minlen = nla_attr_minlen[pt.type_]\n\n    if nla_len(nla) < minlen:\n        return -NLE_RANGE\n\n    if pt.maxlen and nla_len(nla) > pt.maxlen:\n        return -NLE_RANGE\n\n    if pt.type_ == NLA_STRING:\n        data = nla_data(nla)\n        if data[nla_len(nla) - 1] != 0:\n            return -NLE_INVAL\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nla_parse(tb, maxtype, head, len_, policy):\n    rem = c_int()\n    for nla in nla_for_each_attr(head, len_, rem):\n        type_ = nla_type(nla)\n        if type_ > maxtype:\n            continue\n\n        if policy:\n            err = validate_nla(nla, maxtype, policy)\n            if err < 0:\n                return err\n\n        if type_ in tb and tb[type_]:\n            _LOGGER.debug('Attribute of type %d found multiple times in message, previous attribute is being ignored.',\n                          type_)\n        tb[type_] = nla\n\n    if rem.value > 0:\n        _LOGGER.debug('netlink: %d bytes leftover after parsing attributes.', rem.value)\n\n    return 0", "response": "Parse a stream of attributes into a new array of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over a stream of attributes.", "response": "def nla_for_each_attr(head, len_, rem):\n    \"\"\"Iterate over a stream of attributes.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink/attr.h#L262\n\n    Positional arguments:\n    head -- first nlattr with more in its bytearray payload (nlattr class instance).\n    len_ -- length of attribute stream (integer).\n    rem -- initialized to len, holds bytes currently remaining in stream (c_int).\n\n    Returns:\n    Generator yielding nlattr instances.\n    \"\"\"\n    pos = head\n    rem.value = len_\n    while nla_ok(pos, rem):\n        yield pos\n        pos = nla_next(pos, rem)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nla_for_each_nested(nla, rem):\n    pos = nlattr(nla_data(nla))\n    rem.value = nla_len(nla)\n    while nla_ok(pos, rem):\n        yield pos\n        pos = nla_next(pos, rem)", "response": "Iterate over a stream of nested attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a single attribute in a stream of attributes.", "response": "def nla_find(head, len_, attrtype):\n    \"\"\"Find a single attribute in a stream of attributes.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L323\n\n    Iterates over the stream of attributes and compares each type with the type specified. Returns the first attribute\n    which matches the type.\n\n    Positional arguments:\n    head -- first nlattr with more in its bytearray payload (nlattr class instance).\n    len_ -- length of attributes stream (integer).\n    attrtype -- attribute type to look for (integer).\n\n    Returns:\n    Attribute found (nlattr class instance) or None.\n    \"\"\"\n    rem = c_int()\n    for nla in nla_for_each_attr(head, len_, rem):\n        if nla_type(nla) == attrtype:\n            return nla\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreserve space for an attribute in a Netlink message.", "response": "def nla_reserve(msg, attrtype, attrlen):\n    \"\"\"Reserve space for an attribute.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L456\n\n    Reserves room for an attribute in the specified Netlink message and fills in the attribute header (type, length).\n    Returns None if there is insufficient space for the attribute.\n\n    Any padding between payload and the start of the next attribute is zeroed out.\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    attrlen -- length of payload (integer).\n\n    Returns:\n    nlattr class instance allocated to the new space or None on failure.\n    \"\"\"\n    tlen = NLMSG_ALIGN(msg.nm_nlh.nlmsg_len) + nla_total_size(attrlen)\n    if tlen > msg.nm_size:\n        return None\n\n    nla = nlattr(nlmsg_tail(msg.nm_nlh))\n    nla.nla_type = attrtype\n    nla.nla_len = nla_attr_size(attrlen)\n\n    if attrlen:\n        padlen = nla_padlen(attrlen)\n        nla.bytearray[nla.nla_len:nla.nla_len + padlen] = bytearray(b'\\0') * padlen\n    msg.nm_nlh.nlmsg_len = tlen\n\n    _LOGGER.debug('msg 0x%x: attr <0x%x> %d: Reserved %d (%d) bytes at offset +%d nlmsg_len=%d', id(msg), id(nla),\n                  nla.nla_type, nla_total_size(attrlen), attrlen,\n                  nla.bytearray.slice.start - nlmsg_data(msg.nm_nlh).slice.start, msg.nm_nlh.nlmsg_len)\n\n    return nla"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a unspecific attribute to Netlink message.", "response": "def nla_put(msg, attrtype, datalen, data):\n    \"\"\"Add a unspecific attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L497\n\n    Reserves room for an unspecific attribute and copies the provided data into the message as payload of the attribute.\n    Returns an error if there is insufficient space for the attribute.\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    datalen -- length of data to be used as payload (integer).\n    data -- data to be used as attribute payload (bytearray).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    nla = nla_reserve(msg, attrtype, datalen)\n    if not nla:\n        return -NLE_NOMEM\n    if datalen <= 0:\n        return 0\n\n    nla_data(nla)[:datalen] = data[:datalen]\n    _LOGGER.debug('msg 0x%x: attr <0x%x> %d: Wrote %d bytes at offset +%d', id(msg), id(nla), nla.nla_type, datalen,\n                  nla.bytearray.slice.start - nlmsg_data(msg.nm_nlh).slice.start)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding abstract data as unspecific attribute to Netlink message.", "response": "def nla_put_data(msg, attrtype, data):\n    \"\"\"Add abstract data as unspecific attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L527\n\n    Equivalent to nla_put() except that the length of the payload is derived from the bytearray data object.\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    data -- data to be used as attribute payload (bytearray).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    return nla_put(msg, attrtype, len(data), data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nla_put_u8(msg, attrtype, value):\n    data = bytearray(value if isinstance(value, c_uint8) else c_uint8(value))\n    return nla_put(msg, attrtype, SIZEOF_U8, data)", "response": "Add 8 bit integer attribute to Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding 16 bit integer attribute to Netlink message.", "response": "def nla_put_u16(msg, attrtype, value):\n    \"\"\"Add 16 bit integer attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L588\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    value -- numeric value to store as payload (int() or c_uint16()).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    data = bytearray(value if isinstance(value, c_uint16) else c_uint16(value))\n    return nla_put(msg, attrtype, SIZEOF_U16, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding 32 bit integer attribute to Netlink message.", "response": "def nla_put_u32(msg, attrtype, value):\n    \"\"\"Add 32 bit integer attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L613\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    value -- numeric value to store as payload (int() or c_uint32()).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    data = bytearray(value if isinstance(value, c_uint32) else c_uint32(value))\n    return nla_put(msg, attrtype, SIZEOF_U32, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds 64 bit integer attribute to Netlink message.", "response": "def nla_put_u64(msg, attrtype, value):\n    \"\"\"Add 64 bit integer attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L638\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    value -- numeric value to store as payload (int() or c_uint64()).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    data = bytearray(value if isinstance(value, c_uint64) else c_uint64(value))\n    return nla_put(msg, attrtype, SIZEOF_U64, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the value of 64 bit integer attribute as an int.", "response": "def nla_get_u64(nla):\n    \"\"\"Return value of 64 bit integer attribute as an int().\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L649\n\n    Positional arguments:\n    nla -- 64 bit integer attribute (nlattr class instance).\n\n    Returns:\n    Payload as an int().\n    \"\"\"\n    tmp = c_uint64(0)\n    if nla and nla_len(nla) >= sizeof(tmp):\n        tmp = c_uint64.from_buffer(nla_data(nla)[:SIZEOF_U64])\n    return int(tmp.value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd string attribute to Netlink message.", "response": "def nla_put_string(msg, attrtype, value):\n    \"\"\"Add string attribute to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L674\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    value -- bytes() or bytearray() value (e.g. 'Test'.encode('ascii')).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    data = bytearray(value) + bytearray(b'\\0')\n    return nla_put(msg, attrtype, len(data), data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nla_put_msecs(msg, attrtype, msecs):\n    if isinstance(msecs, c_uint64):\n        pass\n    elif isinstance(msecs, c_ulong):\n        msecs = c_uint64(msecs.value)\n    else:\n        msecs = c_uint64(msecs)\n    return nla_put_u64(msg, attrtype, msecs)", "response": "Add msecs Netlink attribute to Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds nested attributes to Netlink message.", "response": "def nla_put_nested(msg, attrtype, nested):\n    \"\"\"Add nested attributes to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L772\n\n    Takes the attributes found in the `nested` message and appends them to the message `msg` nested in a container of\n    the type `attrtype`. The `nested` message may not have a family specific header.\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    attrtype -- attribute type (integer).\n    nested -- message containing attributes to be nested (nl_msg class instance).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    _LOGGER.debug('msg 0x%x: attr <> %d: adding msg 0x%x as nested attribute', id(msg), attrtype, id(nested))\n    return nla_put(msg, attrtype, nlmsg_datalen(nested.nm_nlh), nlmsg_data(nested.nm_nlh))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates attribute index based on nested attribute.", "response": "def nla_parse_nested(tb, maxtype, nla, policy):\n    \"\"\"Create attribute index based on nested attribute.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/attr.c#L885\n\n    Feeds the stream of attributes nested into the specified attribute to nla_parse().\n\n    Positional arguments:\n    tb -- dictionary to be filled (maxtype+1 elements).\n    maxtype -- maximum attribute type expected and accepted (integer).\n    nla -- nested attribute (nlattr class instance).\n    policy -- attribute validation policy.\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    return nla_parse(tb, maxtype, nlattr(nla_data(nla)), nla_len(nla), policy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef genl_send_simple(sk, family, cmd, version, flags):\n    hdr = genlmsghdr(cmd=cmd, version=version)\n    return int(nl_send_simple(sk, family, flags, hdr, hdr.SIZEOF))", "response": "Send a Generic Netlink message with a header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef genlmsg_valid_hdr(nlh, hdrlen):\n    if not nlmsg_valid_hdr(nlh, GENL_HDRLEN):\n        return False\n\n    ghdr = genlmsghdr(nlmsg_data(nlh))\n    if genlmsg_len(ghdr) < NLMSG_ALIGN(hdrlen):\n        return False\n\n    return True", "response": "Validate Generic Netlink message headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef genlmsg_parse(nlh, hdrlen, tb, maxtype, policy):\n    if not genlmsg_valid_hdr(nlh, hdrlen):\n        return -NLE_MSG_TOOSHORT\n\n    ghdr = genlmsghdr(nlmsg_data(nlh))\n    return int(nla_parse(tb, maxtype, genlmsg_attrdata(ghdr, hdrlen), genlmsg_attrlen(ghdr, hdrlen), policy))", "response": "Parse Generic Netlink message including attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn length of message payload including user header.", "response": "def genlmsg_len(gnlh):\n    \"\"\"Return length of message payload including user header.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/genl.c#L224\n\n    Positional arguments:\n    gnlh -- Generic Netlink message header (genlmsghdr class instance).\n\n    Returns:\n    Length of user payload including an eventual user header in number of bytes.\n    \"\"\"\n    nlh = nlmsghdr(bytearray_ptr(gnlh.bytearray, -NLMSG_HDRLEN, oob=True))\n    return nlh.nlmsg_len - GENL_HDRLEN - NLMSG_HDRLEN"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding generic Netlink headers to a Netlink message.", "response": "def genlmsg_put(msg, port, seq, family, hdrlen, flags, cmd, version):\n    \"\"\"Add Generic Netlink headers to Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/genl.c#L348\n\n    Calls nlmsg_put() on the specified message object to reserve space for the Netlink header, the Generic Netlink\n    header, and a user header of specified length. Fills out the header fields with the specified parameters.\n\n    Positional arguments:\n    msg -- Netlink message object (nl_msg class instance).\n    port -- Netlink port or NL_AUTO_PORT (c_uint32).\n    seq -- sequence number of message or NL_AUTO_SEQ (c_uint32).\n    family -- numeric family identifier (integer).\n    hdrlen -- length of user header (integer).\n    flags -- additional Netlink message flags (integer).\n    cmd -- numeric command identifier (c_uint8).\n    version -- interface version (c_uint8).\n\n    Returns:\n    bytearray starting at user header or None if an error occurred.\n    \"\"\"\n    hdr = genlmsghdr(cmd=cmd, version=version)\n    nlh = nlmsg_put(msg, port, seq, family, GENL_HDRLEN + hdrlen, flags)\n    if nlh is None:\n        return None\n    nlmsg_data(nlh)[:hdr.SIZEOF] = hdr.bytearray[:hdr.SIZEOF]\n    _LOGGER.debug('msg 0x%x: Added generic netlink header cmd=%d version=%d', id(msg), cmd, version)\n    return bytearray_ptr(nlmsg_data(nlh), GENL_HDRLEN)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall a callback function.", "response": "def nl_cb_call(cb, type_, msg):\n    \"\"\"Call a callback function.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/netlink.h#L136\n\n    Positional arguments:\n    cb -- nl_cb class instance.\n    type_ -- callback type integer (e.g. NL_CB_MSG_OUT).\n    msg -- Netlink message (nl_msg class instance).\n\n    Returns:\n    Integer from the callback function (like NL_OK, NL_SKIP, etc).\n    \"\"\"\n    cb.cb_active = type_\n    ret = cb.cb_set[type_](msg, cb.cb_args[type_])\n    cb.cb_active = 10 + 1  # NL_CB_TYPE_MAX + 1\n    return int(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nl_family(self, value):\n        self.bytearray[self._get_slicers(0)] = bytearray(c_uint(value or 0))", "response": "set Family of resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nlmsg_type(self, value):\n        self.bytearray[self._get_slicers(1)] = bytearray(c_uint16(value or 0))", "response": "set the type of message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset ntlm message flags", "response": "def nlmsg_flags(self, value):\n        \"\"\"Message flags setter.\"\"\"\n        self.bytearray[self._get_slicers(2)] = bytearray(c_uint16(value or 0))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting type of message.", "response": "def nla_type(self, value):\n        \"\"\"Type setter.\"\"\"\n        self.bytearray[self._get_slicers(1)] = bytearray(c_uint16(value or 0))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_default_cb():\n    global default_cb\n    nlcb = os.environ.get('NLCB', '').lower()\n    if not nlcb:\n        return\n\n    if nlcb == 'default':\n        default_cb = NL_CB_DEFAULT\n    elif nlcb == 'verbose':\n        default_cb = NL_CB_VERBOSE\n    elif nlcb == 'debug':\n        default_cb = NL_CB_DEBUG\n    else:\n        _LOGGER.warning('Unknown value for NLCB, valid values: {default | verbose | debug}')", "response": "Initialize the default callback for the NLM3 server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random port for the local network.", "response": "def generate_local_port():\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/socket.c#L63.\"\"\"\n    global _PREVIOUS_LOCAL_PORT\n    if _PREVIOUS_LOCAL_PORT is None:\n        try:\n            with contextlib.closing(socket.socket(getattr(socket, 'AF_NETLINK', -1), socket.SOCK_RAW)) as s:\n                s.bind((0, 0))\n                _PREVIOUS_LOCAL_PORT = int(s.getsockname()[0])\n        except OSError:\n            _PREVIOUS_LOCAL_PORT = 4294967295  # UINT32_MAX\n    return int(_PREVIOUS_LOCAL_PORT)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallocating new Netlink socket. Does not yet actually open a socket.", "response": "def nl_socket_alloc(cb=None):\n    \"\"\"Allocate new Netlink socket. Does not yet actually open a socket.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/socket.c#L206\n\n    Also has code for generating local port once.\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L123\n\n    Keyword arguments:\n    cb -- custom callback handler.\n\n    Returns:\n    Newly allocated Netlink socket (nl_sock class instance) or None.\n    \"\"\"\n    # Allocate the callback.\n    cb = cb or nl_cb_alloc(default_cb)\n    if not cb:\n        return None\n\n    # Allocate the socket.\n    sk = nl_sock()\n    sk.s_cb = cb\n    sk.s_local.nl_family = getattr(socket, 'AF_NETLINK', -1)\n    sk.s_peer.nl_family = getattr(socket, 'AF_NETLINK', -1)\n    sk.s_seq_expect = sk.s_seq_next = int(time.time())\n    sk.s_flags = NL_OWN_PORT  # The port is 0 (unspecified), meaning NL_OWN_PORT.\n\n    # Generate local port.\n    nl_socket_get_local_port(sk)  # I didn't find this in the C source, but during testing I saw this behavior.\n\n    return sk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nl_socket_get_local_port(sk):\n    if not sk.s_local.nl_pid:\n        port = generate_local_port()\n        sk.s_flags &= ~NL_OWN_PORT\n        sk.s_local.nl_pid = port\n        return port\n    return sk.s_local.nl_pid", "response": "Get the local port number of a socket."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nl_socket_add_memberships(sk, *group):\n    if sk.s_fd == -1:\n        return -NLE_BAD_SOCK\n    for grp in group:\n        if not grp:\n            break\n        if grp < 0:\n            return -NLE_INVAL\n        try:\n            sk.socket_instance.setsockopt(SOL_NETLINK, NETLINK_ADD_MEMBERSHIP, grp)\n        except OSError as exc:\n            return -nl_syserr2nlerr(exc.errno)\n    return 0", "response": "Join groups.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/socket.c#L417\n\n    Joins the specified groups using the modern socket option. The list of groups has to be terminated by 0.\n\n    Make sure to use the correct group definitions as the older bitmask definitions for nl_join_groups() are likely to\n    still be present for backward compatibility reasons.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    group -- group identifier (integer).\n\n    Returns:\n    0 on success or a negative error code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nl_socket_drop_memberships(sk, *group):\n    if sk.s_fd == -1:\n        return -NLE_BAD_SOCK\n    for grp in group:\n        if not grp:\n            break\n        if grp < 0:\n            return -NLE_INVAL\n        try:\n            sk.socket_instance.setsockopt(SOL_NETLINK, NETLINK_DROP_MEMBERSHIP, grp)\n        except OSError as exc:\n            return -nl_syserr2nlerr(exc.errno)\n    return 0", "response": "Drop memberships from a Netlink socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify the callback handler associated with the socket.", "response": "def nl_socket_modify_cb(sk, type_, kind, func, arg):\n    \"\"\"Modify the callback handler associated with the socket.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/socket.c#L633\n\n    Sets specific callback functions in the existing nl_cb class instance stored in the nl_sock socket.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    type_ -- which type callback to set (integer).\n    kind -- kind of callback (integer).\n    func -- callback function.\n    arg -- argument to be passed to callback function.\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    return int(nl_cb_set(sk.s_cb, type_, kind, func, arg))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nl_socket_modify_err_cb(sk, kind, func, arg):\n    return int(nl_cb_err(sk.s_cb, kind, func, arg))", "response": "Modify the error callback handler associated with the socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the socket buffer size of a Netlink socket.", "response": "def nl_socket_set_buffer_size(sk, rxbuf, txbuf):\n    \"\"\"Set socket buffer size of Netlink socket.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/socket.c#L675\n\n    Sets the socket buffer size of a Netlink socket to the specified values `rxbuf` and `txbuf`. Providing a value of 0\n    assumes a good default value.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    rxbuf -- new receive socket buffer size in bytes (integer).\n    txbuf -- new transmit socket buffer size in bytes (integer).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    rxbuf = 32768 if rxbuf <= 0 else rxbuf\n    txbuf = 32768 if txbuf <= 0 else txbuf\n    if sk.s_fd == -1:\n        return -NLE_BAD_SOCK\n\n    try:\n        sk.socket_instance.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, txbuf)\n    except OSError as exc:\n        return -nl_syserr2nlerr(exc.errno)\n\n    try:\n        sk.socket_instance.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, rxbuf)\n    except OSError as exc:\n        return -nl_syserr2nlerr(exc.errno)\n\n    sk.s_flags |= NL_SOCK_BUFSIZE_SET\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef version(self, value):\n        self.bytearray[self._get_slicers(1)] = bytearray(c_uint8(value or 0))", "response": "set the version of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reserved(self, value):\n        self.bytearray[self._get_slicers(2)] = bytearray(c_uint16(value or 0))", "response": "set the reserved field of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string representation of the given bytearray.", "response": "def get_ssid(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/util.c?id=v3.17#n313.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    String.\n    \"\"\"\n    converted = list()\n    for i in range(len(data)):\n        try:\n            c = unichr(data[i])\n        except NameError:\n            c = chr(data[i])\n        if unicodedata.category(c) != 'Cc' and c not in (' ', '\\\\'):\n            converted.append(c)\n        elif c == '\\0':\n            converted.append(c)\n        elif c == ' ' and i not in (0, len(data)):\n            converted.append(' ')\n        else:\n            converted.append('\\\\{0:02x}'.format(data[i]))\n    return ''.join(converted)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the index of the MCS elements in a bytearray.", "response": "def get_mcs_index(mcs):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/util.c?id=v3.17#n453.\n\n    Positional arguments:\n    mcs -- bytearray\n\n    Returns:\n    List.\n    \"\"\"\n    answers = list()\n    for mcs_bit in range(77):\n        mcs_octet = int(mcs_bit / 8)\n        mcs_rate_bit = 1 << mcs_bit % 8\n        mcs_rate_idx_set = not not (mcs[mcs_octet] & mcs_rate_bit)\n        if not mcs_rate_idx_set:\n            continue\n        answers.append(mcs_bit)\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_ht_capability(cap):\n    answers = list()\n    if cap & 1:\n        answers.append('RX LDPC')\n    if cap & 2:\n        answers.append('HT20/HT40')\n    if not cap & 2:\n        answers.append('HT20')\n    if (cap >> 2) & 0x3 == 0:\n        answers.append('Static SM Power Save')\n    if (cap >> 2) & 0x3 == 1:\n        answers.append('Dynamic SM Power Save')\n    if (cap >> 2) & 0x3 == 3:\n        answers.append('SM Power Save disabled')\n    if cap & 16:\n        answers.append('RX Greenfield')\n    if cap & 32:\n        answers.append('RX HT20 SGI')\n    if cap & 64:\n        answers.append('RX HT40 SGI')\n    if cap & 128:\n        answers.append('TX STBC')\n    if (cap >> 8) & 0x3 == 0:\n        answers.append('No RX STBC')\n    if (cap >> 8) & 0x3 == 1:\n        answers.append('RX STBC 1-stream')\n    if (cap >> 8) & 0x3 == 2:\n        answers.append('RX STBC 2-streams')\n    if (cap >> 8) & 0x3 == 3:\n        answers.append('RX STBC 3-streams')\n    if cap & 1024:\n        answers.append('HT Delayed Block Ack')\n    if not cap & 2048:\n        answers.append('Max AMSDU length: 3839 bytes')\n    if cap & 2048:\n        answers.append('Max AMSDU length: 7935 bytes')\n    if cap & 4096:\n        answers.append('DSSS/CCK HT40')\n    if not cap & 4096:\n        answers.append('No DSSS/CCK HT40')\n    if cap & 16384:\n        answers.append('40 MHz Intolerant')\n    if cap & 32768:\n        answers.append('L-SIG TXOP protection')\n    return answers", "response": "Get the current HT capability."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ht_mcs(mcs):\n    answers = dict()\n    max_rx_supp_data_rate = (mcs[10] & ((mcs[11] & 0x3) << 8))\n    tx_mcs_set_defined = not not (mcs[12] & (1 << 0))\n    tx_mcs_set_equal = not (mcs[12] & (1 << 1))\n    tx_max_num_spatial_streams = ((mcs[12] >> 2) & 3) + 1\n    tx_unequal_modulation = not not (mcs[12] & (1 << 4))\n\n    if max_rx_supp_data_rate:\n        answers['HT Max RX data rate (Mbps)'] = max_rx_supp_data_rate\n\n    if tx_mcs_set_defined and tx_mcs_set_equal:\n        answers['HT TX/RX MCS rate indexes supported'] = get_mcs_index(mcs)\n    elif tx_mcs_set_defined:\n        answers['HT RX MCS rate indexes supported'] = get_mcs_index(mcs)\n        answers['TX unequal modulation supported'] = bool(tx_unequal_modulation)\n        answers['HT TX Max spatial streams'] = tx_max_num_spatial_streams\n    else:\n        answers['HT RX MCS rate indexes supported'] = get_mcs_index(mcs)\n\n    return answers", "response": "Get the HT MCS rate information from a MCS byte array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a node from the given bytearray data.", "response": "def _get(out_parsed, in_bss, key, parser_func):\n    \"\"\"Handle calling the parser function to convert bytearray data into Python data types.\n\n    Positional arguments:\n    out_parsed -- dictionary to update with parsed data and string keys.\n    in_bss -- dictionary of integer keys and bytearray values.\n    key -- key string to lookup (must be a variable name in libnl.nl80211.nl80211).\n    parser_func -- function to call, with the bytearray data as the only argument.\n    \"\"\"\n    short_key = key[12:].lower()\n    key_integer = getattr(nl80211, key)\n    if in_bss.get(key_integer) is None:\n        return dict()\n    data = parser_func(in_bss[key_integer])\n    if parser_func == libnl.attr.nla_data:\n        data = data[:libnl.attr.nla_len(in_bss[key_integer])]\n    out_parsed[short_key] = data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves nested dict data from either information elements or beacon IES dicts.", "response": "def _fetch(in_parsed, *keys):\n    \"\"\"Retrieve nested dict data from either information elements or beacon IES dicts.\n\n    Positional arguments:\n    in_parsed -- dictionary to read from.\n    keys -- one or more nested dict keys to lookup.\n\n    Returns:\n    Found value or None.\n    \"\"\"\n    for ie in ('information_elements', 'beacon_ies'):\n        target = in_parsed.get(ie, {})\n        for key in keys:\n            target = target.get(key, {})\n        if target:\n            return target\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing data prepared by nla_parse and nla_parse_nested.", "response": "def parse_bss(bss):\n    \"\"\"Parse data prepared by nla_parse() and nla_parse_nested() into Python-friendly formats.\n\n    Automatically chooses the right data-type for each attribute and converts it into Python integers, strings, unicode,\n    etc objects.\n\n    Positional arguments:\n    bss -- dictionary with integer keys and nlattr values.\n\n    Returns:\n    New dictionary with the same integer keys and converted values. Excludes null/empty data from `bss`.\n    \"\"\"\n    # First parse data into Python data types. Weed out empty values.\n    intermediate = dict()\n    _get(intermediate, bss, 'NL80211_BSS_BSSID', libnl.attr.nla_data)  # MAC address of access point.\n    _get(intermediate, bss, 'NL80211_BSS_FREQUENCY', libnl.attr.nla_get_u32)  # Frequency in MHz.\n    _get(intermediate, bss, 'NL80211_BSS_TSF', libnl.attr.nla_get_msecs)  # Timing Synchronization Function.\n    _get(intermediate, bss, 'NL80211_BSS_BEACON_INTERVAL', libnl.attr.nla_get_u16)\n    _get(intermediate, bss, 'NL80211_BSS_CAPABILITY', libnl.attr.nla_get_u16)\n    _get(intermediate, bss, 'NL80211_BSS_INFORMATION_ELEMENTS', libnl.attr.nla_data)\n    _get(intermediate, bss, 'NL80211_BSS_SIGNAL_MBM', libnl.attr.nla_get_u32)\n    _get(intermediate, bss, 'NL80211_BSS_SIGNAL_UNSPEC', libnl.attr.nla_get_u8)\n    _get(intermediate, bss, 'NL80211_BSS_STATUS', libnl.attr.nla_get_u32)\n    _get(intermediate, bss, 'NL80211_BSS_SEEN_MS_AGO', libnl.attr.nla_get_u32)\n    _get(intermediate, bss, 'NL80211_BSS_BEACON_IES', libnl.attr.nla_data)\n\n    # Parse easy data into final Python types.\n    parsed = dict()\n    if 'bssid' in intermediate:\n        parsed['bssid'] = ':'.join(format(x, '02x') for x in intermediate['bssid'][:6])\n    if 'frequency' in intermediate:\n        parsed['frequency'] = intermediate['frequency']\n    if 'tsf' in intermediate:\n        parsed['tsf'] = timedelta(microseconds=intermediate['tsf'])\n    if 'beacon_interval' in intermediate:\n        parsed['beacon_interval'] = intermediate['beacon_interval']\n    if 'signal_mbm' in intermediate:\n        data_u32 = intermediate['signal_mbm']\n        data_s32 = -(data_u32 & 0x80000000) + (data_u32 & 0x7fffffff)\n        parsed['signal_mbm'] = data_s32 / 100.0\n    if 'signal_unspec' in intermediate:\n        parsed['signal_unspec'] = intermediate['signal_unspec'] / 100.0\n    if 'seen_ms_ago' in intermediate:\n        parsed['seen_ms_ago'] = timedelta(milliseconds=intermediate['seen_ms_ago'])\n\n    # Handle status.\n    if intermediate.get('status') == nl80211.NL80211_BSS_STATUS_AUTHENTICATED:\n        parsed['status'] = 'authenticated'\n    elif intermediate.get('status') == nl80211.NL80211_BSS_STATUS_ASSOCIATED:\n        parsed['status'] = 'associated'\n    elif intermediate.get('status') == nl80211.NL80211_BSS_STATUS_IBSS_JOINED:\n        parsed['status'] = 'joined'\n    elif 'status' in intermediate:\n        parsed['status'] = 'unknown status: {0}'.format(intermediate['status'])\n\n    # Handle capability.\n    if 'capability' in intermediate:\n        # http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n1479\n        data = intermediate['capability']\n        list_of_caps = list()\n        if parsed['frequency'] > 45000:\n            if data & iw_scan.WLAN_CAPABILITY_DMG_TYPE_MASK == iw_scan.WLAN_CAPABILITY_DMG_TYPE_AP:\n                list_of_caps.append('DMG_ESS')\n            elif data & iw_scan.WLAN_CAPABILITY_DMG_TYPE_MASK == iw_scan.WLAN_CAPABILITY_DMG_TYPE_PBSS:\n                list_of_caps.append('DMG_PCP')\n            elif data & iw_scan.WLAN_CAPABILITY_DMG_TYPE_MASK == iw_scan.WLAN_CAPABILITY_DMG_TYPE_IBSS:\n                list_of_caps.append('DMG_IBSS')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_CBAP_ONLY:\n                list_of_caps.append('CBAP_Only')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_CBAP_SOURCE:\n                list_of_caps.append('CBAP_Src')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_PRIVACY:\n                list_of_caps.append('Privacy')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_ECPAC:\n                list_of_caps.append('ECPAC')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_SPECTRUM_MGMT:\n                list_of_caps.append('SpectrumMgmt')\n            if data & iw_scan.WLAN_CAPABILITY_DMG_RADIO_MEASURE:\n                list_of_caps.append('RadioMeasure')\n        else:\n            if data & iw_scan.WLAN_CAPABILITY_ESS:\n                list_of_caps.append('ESS')\n            if data & iw_scan.WLAN_CAPABILITY_IBSS:\n                list_of_caps.append('IBSS')\n            if data & iw_scan.WLAN_CAPABILITY_CF_POLLABLE:\n                list_of_caps.append('CfPollable')\n            if data & iw_scan.WLAN_CAPABILITY_CF_POLL_REQUEST:\n                list_of_caps.append('CfPollReq')\n            if data & iw_scan.WLAN_CAPABILITY_PRIVACY:\n                list_of_caps.append('Privacy')\n            if data & iw_scan.WLAN_CAPABILITY_SHORT_PREAMBLE:\n                list_of_caps.append('ShortPreamble')\n            if data & iw_scan.WLAN_CAPABILITY_PBCC:\n                list_of_caps.append('PBCC')\n            if data & iw_scan.WLAN_CAPABILITY_CHANNEL_AGILITY:\n                list_of_caps.append('ChannelAgility')\n            if data & iw_scan.WLAN_CAPABILITY_SPECTRUM_MGMT:\n                list_of_caps.append('SpectrumMgmt')\n            if data & iw_scan.WLAN_CAPABILITY_QOS:\n                list_of_caps.append('QoS')\n            if data & iw_scan.WLAN_CAPABILITY_SHORT_SLOT_TIME:\n                list_of_caps.append('ShortSlotTime')\n            if data & iw_scan.WLAN_CAPABILITY_APSD:\n                list_of_caps.append('APSD')\n            if data & iw_scan.WLAN_CAPABILITY_RADIO_MEASURE:\n                list_of_caps.append('RadioMeasure')\n            if data & iw_scan.WLAN_CAPABILITY_DSSS_OFDM:\n                list_of_caps.append('DSSS-OFDM')\n            if data & iw_scan.WLAN_CAPABILITY_DEL_BACK:\n                list_of_caps.append('DelayedBACK')\n            if data & iw_scan.WLAN_CAPABILITY_IMM_BACK:\n                list_of_caps.append('ImmediateBACK')\n        parsed['capability'] = list_of_caps\n\n    # Handle (beacon) information elements.\n    for k in ('information_elements', 'beacon_ies'):\n        if k not in intermediate:\n            continue\n        parsed[k] = iw_scan.get_ies(intermediate[k])\n\n    # Make some data more human-readable.\n    parsed['signal'] = parsed.get('signal_mbm', parsed.get('signal_unspec'))\n    parsed['channel'] = _fetch(parsed, 'DS Parameter set')\n    parsed['ssid'] = _fetch(parsed, 'SSID') or _fetch(parsed, 'MESH ID') or ''\n    parsed['supported_rates'] = _fetch(parsed, 'Supported rates')\n    parsed['extended_supported_rates'] = _fetch(parsed, 'Extended supported rates')\n    parsed['channel_width'] = _fetch(parsed, 'HT operation', 'STA channel width')\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the content of a Netlink header.", "response": "def print_header_content(nlh):\n    \"\"\"Return header content (doesn't actually print like the C library does).\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/handlers.c#L34\n\n    Positional arguments:\n    nlh -- nlmsghdr class instance.\n    \"\"\"\n    answer = 'type={0} length={1} flags=<{2}> sequence-nr={3} pid={4}'.format(\n        nl_nlmsgtype2str(nlh.nlmsg_type, bytearray(), 32).decode('ascii'),\n        nlh.nlmsg_len,\n        nl_nlmsg_flags2str(nlh.nlmsg_flags, bytearray(), 128).decode('ascii'),\n        nlh.nlmsg_seq,\n        nlh.nlmsg_pid,\n    )\n    return answer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndebugging handler for Unhandled Valid message.", "response": "def nl_valid_handler_debug(msg, arg):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/handlers.c#L92.\"\"\"\n    ofd = arg or _LOGGER.debug\n    ofd('-- Debug: Unhandled Valid message: ' + print_header_content(nlmsg_hdr(msg)))\n    return NL_OK"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndebugs handler for Netlink messages.", "response": "def nl_msg_out_handler_debug(msg, arg):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/handlers.c#L124.\"\"\"\n    ofd = arg or _LOGGER.debug\n    ofd('-- Debug: Sent Message:')\n    nl_msg_dump(msg, ofd)\n    return NL_OK"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nl_skipped_handler_debug(msg, arg):\n    ofd = arg or _LOGGER.debug\n    ofd('-- Debug: Skipped message: ' + print_header_content(nlmsg_hdr(msg)))\n    return NL_SKIP", "response": "Return NL_SKIP if msg is not a message."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallocates a new callback handle.", "response": "def nl_cb_alloc(kind):\n    \"\"\"Allocate a new callback handle.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/handlers.c#L201\n\n    Positional arguments:\n    kind -- callback kind to be used for initialization.\n\n    Returns:\n    Newly allocated callback handle (nl_cb class instance) or None.\n    \"\"\"\n    if kind < 0 or kind > NL_CB_KIND_MAX:\n        return None\n    cb = nl_cb()\n    cb.cb_active = NL_CB_TYPE_MAX + 1\n    for i in range(NL_CB_TYPE_MAX):\n        nl_cb_set(cb, i, kind, None, None)\n    nl_cb_err(cb, kind, None, None)\n    return cb"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets up a callback. Updates cb in place.", "response": "def nl_cb_set(cb, type_, kind, func, arg):\n    \"\"\"Set up a callback. Updates `cb` in place.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/handlers.c#L293\n\n    Positional arguments:\n    cb -- nl_cb class instance.\n    type_ -- callback to modify (integer).\n    kind -- kind of implementation (integer).\n    func -- callback function (NL_CB_CUSTOM).\n    arg -- argument passed to callback.\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    if type_ < 0 or type_ > NL_CB_TYPE_MAX or kind < 0 or kind > NL_CB_KIND_MAX:\n        return -NLE_RANGE\n\n    if kind == NL_CB_CUSTOM:\n        cb.cb_set[type_] = func\n        cb.cb_args[type_] = arg\n    else:\n        cb.cb_set[type_] = cb_def[type_][kind]\n        cb.cb_args[type_] = arg\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nl_cb_err(cb, kind, func, arg):\n    if kind < 0 or kind > NL_CB_KIND_MAX:\n        return -NLE_RANGE\n\n    if kind == NL_CB_CUSTOM:\n        cb.cb_err = func\n        cb.cb_err_arg = arg\n    else:\n        cb.cb_err = cb_err_def[kind]\n        cb.cb_err_arg = arg\n\n    return 0", "response": "Set up an error callback. Updates cb in place."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callback(msg, has_printed):\n    table = AsciiTable([['Data Type', 'Data Value']])\n    # First convert `msg` into something more manageable.\n    gnlh = genlmsghdr(nlmsg_data(nlmsg_hdr(msg)))\n\n    # Partially parse the raw binary data and place them in the `tb` dictionary.\n    tb = dict((i, None) for i in range(nl80211.NL80211_ATTR_MAX + 1))  # Need to populate dict with all possible keys.\n    nla_parse(tb, nl80211.NL80211_ATTR_MAX, genlmsg_attrdata(gnlh, 0), genlmsg_attrlen(gnlh, 0), None)\n\n    # Now it's time to grab the juicy data!\n    if tb[nl80211.NL80211_ATTR_IFNAME]:\n        table.title = nla_get_string(tb[nl80211.NL80211_ATTR_IFNAME]).decode('ascii')\n    else:\n        table.title = 'Unnamed Interface'\n\n    if tb[nl80211.NL80211_ATTR_WIPHY]:\n        wiphy_num = nla_get_u32(tb[nl80211.NL80211_ATTR_WIPHY])\n        wiphy = ('wiphy {0}' if OPTIONS['<interface>'] else 'phy#{0}').format(wiphy_num)\n        table.table_data.append(['NL80211_ATTR_WIPHY', wiphy])\n\n    if tb[nl80211.NL80211_ATTR_MAC]:\n        mac_address = ':'.join(format(x, '02x') for x in nla_data(tb[nl80211.NL80211_ATTR_MAC])[:6])\n        table.table_data.append(['NL80211_ATTR_MAC', mac_address])\n\n    if tb[nl80211.NL80211_ATTR_IFINDEX]:\n        table.table_data.append(['NL80211_ATTR_IFINDEX', str(nla_get_u32(tb[nl80211.NL80211_ATTR_IFINDEX]))])\n\n    # Print all data.\n    if has_printed:\n        print()\n    else:\n        has_printed.append(True)\n    print(table.table)\n    return NL_SKIP", "response": "This function is called by libnl upon receiving messages from the kernel. It returns NL_SKIP if the kernel is stopped and proceeds with NL_MSG_NO_CONTENT is set to True."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_logging():\n    fmt = 'DBG<0>%(pathname)s:%(lineno)d  %(funcName)s: %(message)s'\n\n    handler_stderr = logging.StreamHandler(sys.stderr)\n    handler_stderr.setFormatter(logging.Formatter(fmt))\n\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n    root_logger.addHandler(handler_stderr)", "response": "Called when the script is run. Sets up logging library."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rtgen_family(self, value):\n        self.bytearray[self._get_slicers(0)] = bytearray(c_ubyte(value or 0))", "response": "set the Family of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ifi_family(self, value):\n        self.bytearray[self._get_slicers(0)] = bytearray(c_ubyte(value or 0))", "response": "set the ifi family"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ifi_type(self, value):\n        self.bytearray[self._get_slicers(2)] = bytearray(c_ushort(value or 0))", "response": "set the ifi_type of the resource"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ifi_index(self, value):\n        self.bytearray[self._get_slicers(3)] = bytearray(c_int(value or 0))", "response": "set the ifi index"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ifi_flags(self, value):\n        self.bytearray[self._get_slicers(4)] = bytearray(c_uint(value or 0))", "response": "set the ifi_flags field of the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _class_factory(base):\n    class ClsPyPy(base):\n        def __repr__(self):\n            return repr(base(super(ClsPyPy, self).value))\n\n        @classmethod\n        def from_buffer(cls, ba):\n            try:\n                integer = struct.unpack_from(getattr(cls, '_type_'), ba)[0]\n            except struct.error:\n                len_ = len(ba)\n                size = struct.calcsize(getattr(cls, '_type_'))\n                if len_ < size:\n                    raise ValueError('Buffer size too small ({0} instead of at least {1} bytes)'.format(len_, size))\n                raise\n            return cls(integer)\n\n    class ClsPy26(base):\n        def __repr__(self):\n            return repr(base(super(ClsPy26, self).value))\n\n        def __iter__(self):\n            return iter(struct.pack(getattr(super(ClsPy26, self), '_type_'), super(ClsPy26, self).value))\n\n    try:\n        base.from_buffer(bytearray(base()))\n    except TypeError:\n        # Python2.6, ctypes cannot be converted to bytearrays.\n        return ClsPy26\n    except AttributeError:\n        # PyPy on my Raspberry Pi, ctypes don't have from_buffer attribute.\n        return ClsPyPy\n    except ValueError:\n        # PyPy on Travis CI, from_buffer cannot handle non-buffer() bytearrays.\n        return ClsPyPy\n    return base", "response": "Create subclasses of ctypes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a slice object to slice a list / bytearray by.", "response": "def _get_slicers(self, index):\n        \"\"\"Return a slice object to slice a list/bytearray by.\n\n        Positional arguments:\n        index -- index of self.SIGNATURE to target self.bytearray by.\n\n        Returns:\n        slice() object. E.g. `x = _get_slicers(0); ba_instance[x]`\n        \"\"\"\n        if not index:  # first item.\n            return slice(0, self.SIGNATURE[0])\n        if index >= len(self.SIGNATURE):\n            raise IndexError('index out of self.SIGNATURE range')\n        pad_start = sum(self.SIGNATURE[:index])\n        pad_stop = pad_start + self.SIGNATURE[index]\n        return slice(pad_start, pad_stop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Process ID setter.", "response": "def pid(self, value):\n        \"\"\"Process ID setter.\"\"\"\n        self.bytearray[self._get_slicers(0)] = bytearray(c_int32(value or 0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the uid of the object", "response": "def uid(self, value):\n        \"\"\"User ID setter.\"\"\"\n        self.bytearray[self._get_slicers(1)] = bytearray(c_int32(value or 0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gid(self, value):\n        self.bytearray[self._get_slicers(2)] = bytearray(c_int32(value or 0))", "response": "set the gid of the log entry"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef family_constructor(c):\n    family = c\n    if not hasattr(family, 'gf_ops'):\n        setattr(family, 'gf_ops', nl_list_head(container_of=family))\n    if not hasattr(family, 'gf_mc_grps'):\n        setattr(family, 'gf_mc_grps', nl_list_head(container_of=family))\n    nl_init_list_head(family.gf_ops)\n    nl_init_list_head(family.gf_mc_grps)", "response": "Constructor for the\n    class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef family_free_data(c):\n    family = c\n    if not hasattr(family, 'gf_ops'):\n        setattr(family, 'gf_ops', nl_list_head(container_of=family))\n    if not hasattr(family, 'gf_mc_grps'):\n        setattr(family, 'gf_mc_grps', nl_list_head(container_of=family))\n    ops = tmp = genl_family_op()\n    grp = t_grp = genl_family_grp()\n    if family is None:\n        return\n    for ops in nl_list_for_each_entry_safe(ops, tmp, family.gf_ops, 'o_list'):\n        nl_list_del(ops.o_list)\n    for grp in nl_list_for_each_entry_safe(grp, t_grp, family.gf_mc_grps, 'list_'):\n        nl_list_del(grp.list_)", "response": "Free the data for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef genl_family_add_grp(family, id_, name):\n    grp = genl_family_grp(id_=id_, name=name)\n    nl_list_add_tail(grp.list_, family.gf_mc_grps)\n    return 0", "response": "Add a group to the tail of the family list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_json(filename):\n    # Regular expression for comments\n    comment_re = re.compile(\n        '(^)?[^\\S\\n]*/(?:\\*(.*?)\\*/[^\\S\\n]*|/[^\\n]*)($)?',\n        re.DOTALL | re.MULTILINE\n    )\n\n    with open(filename) as f:\n        content = ''.join(f.readlines())\n\n        ## Looking for comments\n        match = comment_re.search(content)\n        while match:\n            # single line comment\n            content = content[:match.start()] + content[match.end():]\n            match = comment_re.search(content)\n\n        # Return json file\n        return json.loads(content)", "response": "Parse a JSON file and return a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_meta_type_by_dir(dir_name):\n    parent_data = get_default_metadata_data()\n    child_data = get_child_metadata_data()\n    data = parent_data['metadataObjects'] + child_data\n    for item in data:\n        if 'directoryName' in item and item['directoryName'].lower() == dir_name.lower():\n            return item\n        elif 'tagName' in item and item['tagName'].lower() == dir_name.lower():\n            return item\n    '''\n        > quick and dirty fix for users experiencing issues with \"newer\" metadata types not properly tested by mm\n        > if the project has a cached .describe, let's use that to detect metadata types\n    '''\n    try:\n        if config.describe_data != None:\n            project_org_describe = config.describe_data\n        if config.project != None and os.path.isfile(os.path.join(config.project.location,'config','.describe')):\n            project_org_describe = parse_json_from_file(os.path.join(config.project.location,'config','.describe'))\n        if project_org_describe != None and 'metadataObjects' in project_org_describe:\n            for item in project_org_describe[\"metadataObjects\"]:\n                if 'directoryName' in item and item['directoryName'].lower() == dir_name.lower():\n                    return item\n                elif 'tagName' in item and item['tagName'].lower() == dir_name.lower():\n                    return item\n    except:\n        pass", "response": "returns the metadata type for a given directory name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_meta_type_by_name(name):\n    data = get_default_metadata_data()\n    child_data = get_child_metadata_data()\n    for item in data[\"metadataObjects\"]:\n        if 'xmlName' in item and item['xmlName'] == name:\n            return item\n    for item in child_data:\n        if 'xmlName' in item and item['xmlName'] == name:\n            return item\n    '''\n        > quick and dirty fix for users experiencing issues with \"newer\" metadata types not properly tested by mm\n        > if the project has a cached .describe, let's use that to detect metadata types\n    '''\n    try:\n        if config.describe_data != None:\n            project_org_describe = config.describe_data\n        if config.project != None and os.path.isfile(os.path.join(config.project.location,'config','.describe')):\n            project_org_describe = parse_json_from_file(os.path.join(config.project.location,'config','.describe'))\n        if project_org_describe != None and 'metadataObjects' in project_org_describe:\n            for item in project_org_describe[\"metadataObjects\"]:\n                if 'xmlName' in item and item['xmlName'] == name:\n                    return item\n    except:\n        pass", "response": "returns the metadata type by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_skeleton_files_on_disk(metadata_type, where, github_template=None, params={}):\n    api_name = params[\"api_name\"]\n    file_name = github_template[\"file_name\"]\n    template_source = config.connection.get_plugin_client_setting('mm_template_source', 'joeferraro/MavensMate-Templates/master')\n    template_location = config.connection.get_plugin_client_setting('mm_template_location', 'remote')\n\n    try:\n        if template_location == 'remote':\n            if 'linux' in sys.platform:\n                template_body = os.popen(\"wget https://raw.githubusercontent.com/{0}/{1}/{2} -q -O -\".format(template_source, metadata_type, file_name)).read()\n            else:\n                template_body = urllib2.urlopen(\"https://raw.githubusercontent.com/{0}/{1}/{2}\".format(template_source, metadata_type, file_name)).read()\n        else:\n            template_body = get_file_as_string(os.path.join(template_source,metadata_type,file_name))\n    except:\n        template_body = get_file_as_string(os.path.join(config.base_path,config.support_dir,\"templates\",\"github-local\",metadata_type,file_name))\n\n    template = env.from_string(template_body)\n    file_body = template.render(params)\n    metadata_type = get_meta_type_by_name(metadata_type)\n    os.makedirs(\"{0}/{1}\".format(where, metadata_type['directoryName']))\n    f = open(\"{0}/{1}/{2}\".format(where, metadata_type['directoryName'], api_name+\".\"+metadata_type['suffix']), 'w')\n    f.write(file_body)\n    f.close()\n\n    template = env.get_template('meta.html')\n    file_body = template.render(api_name=api_name, sfdc_api_version=SFDC_API_VERSION,meta_type=metadata_type['xmlName'])\n    f = open(\"{0}/{1}/{2}\".format(where, metadata_type['directoryName'], api_name+\".\"+metadata_type['suffix'])+\"-meta.xml\", 'w')\n    f.write(file_body)\n    f.close()", "response": "Generates file based on jinja2 templates and saves it to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef grouper(n, iterable, fillvalue=None):\n    \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"\n    args = [iter(iterable)] * n\n    return itertools.izip_longest(fillvalue=fillvalue, *args)", "response": "grouper ( 3 ABC DEF G x"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_mcast_grps(family, grp_attr):\n    remaining = c_int()\n    if not grp_attr:\n        raise BUG\n\n    for nla in nla_for_each_nested(grp_attr, remaining):\n        tb = dict()\n        err = nla_parse_nested(tb, CTRL_ATTR_MCAST_GRP_MAX, nla, family_grp_policy)\n        if err < 0:\n            return err\n        if not tb[CTRL_ATTR_MCAST_GRP_ID] or not tb[CTRL_ATTR_MCAST_GRP_NAME]:\n            return -NLE_MISSING_ATTR\n\n        id_ = nla_get_u32(tb[CTRL_ATTR_MCAST_GRP_ID])\n        name = nla_get_string(tb[CTRL_ATTR_MCAST_GRP_NAME])\n\n        err = genl_family_add_grp(family, id_, name)\n        if err < 0:\n            return err\n\n    return 0", "response": "Parse the mcast grps attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef probe_response(msg, arg):\n    tb = dict((i, None) for i in range(CTRL_ATTR_MAX + 1))\n    nlh = nlmsg_hdr(msg)\n    ret = arg\n    if genlmsg_parse(nlh, 0, tb, CTRL_ATTR_MAX, ctrl_policy):\n        return NL_SKIP\n    if tb[CTRL_ATTR_FAMILY_ID]:\n        genl_family_set_id(ret, nla_get_u16(tb[CTRL_ATTR_FAMILY_ID]))\n    if tb[CTRL_ATTR_MCAST_GROUPS] and parse_mcast_grps(ret, tb[CTRL_ATTR_MCAST_GROUPS]) < 0:\n        return NL_SKIP\n    return NL_STOP", "response": "Process responses from the genl_ctrl_probe_by_name method."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlooks up generic Netlink family by family name.", "response": "def genl_ctrl_probe_by_name(sk, name):\n    \"\"\"Look up generic Netlink family by family name querying the kernel directly.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/ctrl.c#L237\n\n    Directly query's the kernel for a given family name.\n\n    Note: This API call differs from genl_ctrl_search_by_name in that it queries the kernel directly, allowing for\n    module autoload to take place to resolve the family request. Using an nl_cache prevents that operation.\n\n    Positional arguments:\n    sk -- Generic Netlink socket (nl_sock class instance).\n    name -- family name (bytes).\n\n    Returns:\n    Generic Netlink family `genl_family` class instance or None if no match was found.\n    \"\"\"\n    ret = genl_family_alloc()\n    if not ret:\n        return None\n\n    genl_family_set_name(ret, name)\n    msg = nlmsg_alloc()\n    orig = nl_socket_get_cb(sk)\n    cb = nl_cb_clone(orig)\n    genlmsg_put(msg, NL_AUTO_PORT, NL_AUTO_SEQ, GENL_ID_CTRL, 0, 0, CTRL_CMD_GETFAMILY, 1)\n    nla_put_string(msg, CTRL_ATTR_FAMILY_NAME, name)\n    nl_cb_set(cb, NL_CB_VALID, NL_CB_CUSTOM, probe_response, ret)\n\n    if nl_send_auto(sk, msg) < 0:\n        return None\n    if nl_recvmsgs(sk, cb) < 0:\n        return None\n    if wait_for_ack(sk) < 0:  # If search was successful, request may be ACKed after data.\n        return None\n\n    if genl_family_get_id(ret) != 0:\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves Generic Netlink family name to numeric identifier.", "response": "def genl_ctrl_resolve(sk, name):\n    \"\"\"Resolve Generic Netlink family name to numeric identifier.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/ctrl.c#L429\n\n    Resolves the Generic Netlink family name to the corresponding numeric family identifier. This function queries the\n    kernel directly, use genl_ctrl_search_by_name() if you need to resolve multiple names.\n\n    Positional arguments:\n    sk -- Generic Netlink socket (nl_sock class instance).\n    name -- name of Generic Netlink family (bytes).\n\n    Returns:\n    The numeric family identifier or a negative error code.\n    \"\"\"\n    family = genl_ctrl_probe_by_name(sk, name)\n    if family is None:\n        return -NLE_OBJ_NOTFOUND\n\n    return int(genl_family_get_id(family))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the ID of a group by name.", "response": "def genl_ctrl_grp_by_name(family, grp_name):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/ctrl.c#L446.\n\n    Positional arguments:\n    family -- genl_family class instance.\n    grp_name -- bytes.\n\n    Returns:\n    group ID or negative error code.\n    \"\"\"\n    for grp in nl_list_for_each_entry(genl_family_grp(), family.gf_mc_grps, 'list_'):\n        if grp.name == grp_name:\n            return grp.id_\n    return -NLE_OBJ_NOTFOUND"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve Generic Netlink family group name.", "response": "def genl_ctrl_resolve_grp(sk, family_name, grp_name):\n    \"\"\"Resolve Generic Netlink family group name.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/ctrl.c#L471\n\n    Looks up the family object and resolves the group name to the numeric group identifier.\n\n    Positional arguments:\n    sk -- Generic Netlink socket (nl_sock class instance).\n    family_name -- name of Generic Netlink family (bytes).\n    grp_name -- name of group to resolve (bytes).\n\n    Returns:\n    The numeric group identifier or a negative error code.\n    \"\"\"\n    family = genl_ctrl_probe_by_name(sk, family_name)\n    if family is None:\n        return -NLE_OBJ_NOTFOUND\n    return genl_ctrl_grp_by_name(family, grp_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget supprates from the given byte array.", "response": "def get_supprates(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n227.\n\n    Positional arguments:\n    data -- bytearray data to read.\n    \"\"\"\n    answer = list()\n    for i in range(len(data)):\n        r = data[i] & 0x7f\n        if r == BSS_MEMBERSHIP_SELECTOR_VHT_PHY and data[i] & 0x80:\n            value = 'VHT'\n        elif r == BSS_MEMBERSHIP_SELECTOR_HT_PHY and data[i] & 0x80:\n            value = 'HT'\n        else:\n            value = '{0}.{1}'.format(int(r / 2), int(5 * (r & 1)))\n        answer.append('{0}{1}'.format(value, '*' if data[i] & 0x80 else ''))\n    return answer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_country(_, data):\n    answers = {'Environment': country_env_str(chr(data[2]))}\n    data = data[3:]\n\n    while len(data) >= 3:\n        triplet = ieee80211_country_ie_triplet(data)\n        if triplet.ext.reg_extension_id >= IEEE80211_COUNTRY_EXTENSION_ID:\n            answers['Extension ID'] = triplet.ext.reg_extension_id\n            answers['Regulatory Class'] = triplet.ext.reg_class\n            answers['Coverage class'] = triplet.ext.coverage_class\n            answers['up to dm'] = triplet.ext.coverage_class * 450\n            data = data[3:]\n            continue\n        if triplet.chans.first_channel <= 14:  # 2 GHz.\n            end_channel = triplet.chans.first_channel + (triplet.chans.num_channels - 1)\n        else:\n            end_channel = triplet.chans.first_channel + (4 * (triplet.chans.num_channels - 1))\n        answers['Channels dBm'] = triplet.chans.max_power\n        answers['Channels'] = (triplet.chans.first_channel, end_channel)\n        data = data[3:]\n    return answers", "response": "Get the country from the byte array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the cipher used by the access point.", "response": "def get_cipher(data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n336.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    WiFi stream cipher used by the access point (string).\n    \"\"\"\n    legend = {0: 'Use group cipher suite', 1: 'WEP-40', 2: 'TKIP', 4: 'CCMP', 5: 'WEP-104', }\n    key = data[3]\n    if ieee80211_oui == bytes(data[:3]):\n        legend.update({6: 'AES-128-CMAC', 8: 'GCMP', })\n    elif ms_oui != bytes(data[:3]):\n        key = None\n    return legend.get(key, '{0:02x}-{1:02x}-{2:02x}:{3}'.format(data[0], data[1], data[2], data[3]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the RSN IE version of the tree.", "response": "def get_rsn_ie(defcipher, defauth, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n441.\n\n    Positional arguments:\n    defcipher -- default cipher if not in data (string).\n    defauth -- default authentication suites if not in data (string).\n    data -- bytearray data to read.\n\n    Returns:\n    Dict.\n    \"\"\"\n    answers = dict()\n    answers['version'] = data[0] + (data[1] << 8)\n    data = data[2:]\n\n    if len(data) < 4:\n        answers['group_cipher'] = answers['pairwise_ciphers'] = defcipher\n        return answers\n    answers['group_cipher'] = get_cipher(data)\n    data = data[4:]\n    if len(data) < 2:\n        answers['pairwise_ciphers'] = defcipher\n        return answers\n\n    count = data[0] | (data[1] << 8)\n    if 2 + (count * 4) > len(data):\n        answers['bogus tail data'] = data\n        return answers\n    answers['pairwise_ciphers'] = ' '.join(get_cipher(data[2 + (i * 4):]) for i in range(count))\n    data = data[2 + (count * 4):]\n\n    if len(data) < 2:\n        answers['authentication_suites'] = defauth\n        return answers\n    count = data[0] | (data[1] << 8)\n    if 2 + (count * 4) > len(data):\n        answers['bogus tail data'] = data\n        return answers\n    answers['authentication_suites'] = ' '.join(get_auth(data[2 + (i * 4):]) for i in range(count))\n    data = data[2 + (count * 4):]\n\n    if len(data) >= 2:\n        capa = data[0] | (data[1] << 8)\n        answers['rsn_ie_capabilities'] = list()\n        if capa & 0x0001:\n            answers['rsn_ie_capabilities'].append('PreAuth')\n        if capa & 0x0002:\n            answers['rsn_ie_capabilities'].append('NoPairwise')\n        case = {0: '1-PTKSA-RC', 1: '2-PTKSA-RC', 2: '4-PTKSA-RC', 3: '16-PTKSA-RC'}.get((capa & 0x000c) >> 2)\n        if case:\n            answers['rsn_ie_capabilities'].append(case)\n        case = {0: '1-GTKSA-RC', 1: '2-GTKSA-RC', 2: '4-GTKSA-RC', 3: '16-GTKSA-RC'}.get((capa & 0x0030) >> 4)\n        if case:\n            answers['rsn_ie_capabilities'].append(case)\n        if capa & 0x0040:\n            answers['rsn_ie_capabilities'].append('MFP-required')\n        if capa & 0x0080:\n            answers['rsn_ie_capabilities'].append('MFP-capable')\n        if capa & 0x0200:\n            answers['rsn_ie_capabilities'].append('Peerkey-enabled')\n        if capa & 0x0400:\n            answers['rsn_ie_capabilities'].append('SPP-AMSDU-capable')\n        if capa & 0x0800:\n            answers['rsn_ie_capabilities'].append('SPP-AMSDU-required')\n        answers['rsn_ie_capabilities'].append('(0x{0:04x})'.format(capa))\n        data = data[2:]\n\n    invalid = False\n    if len(data) >= 2:\n        pmkid_count = data[0] | (data[1] << 8)\n        if len(data) >= 2 + 16 * pmkid_count:\n            answers['PMKIDs'] = pmkid_count\n            data = data[2 + 16 * pmkid_count:]\n        else:\n            invalid = True\n\n    if len(data) >= 4 and not invalid:\n        answers['Group mgmt cipher suite'] = get_cipher(data)\n        data = data[4:]\n\n    if data:\n        answers['* bogus tail data ({0})'.format(len(data))] = ' '.join(format(x, '02x') for x in data)\n\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the HT capability and MCS from the given bytearray.", "response": "def get_ht_capa(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n602.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    Dict.\n    \"\"\"\n    answers = {\n        'Capabilities': get_ht_capability(data[0] | (data[1] << 8)),\n        'Minimum RX AMPDU time spacing': ampdu_space.get((data[2] >> 2) & 7, 'BUG (spacing more than 3 bits!)'),\n        'Maximum RX AMPDU length': {0: 8191, 1: 16383, 2: 32767, 3: 65535}.get(data[2] & 3, 0),\n    }\n    answers.update(get_ht_mcs(data[3:]))\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_11u_advert(_, data):\n    answers = dict()\n    idx = 0\n    while idx < len(data) - 1:\n        qri = data[idx]\n        proto_id = data[idx + 1]\n        answers['Query Response Info'] = qri\n        answers['Query Response Length Limit'] = qri & 0x7f\n        if qri & (1 << 7):\n            answers['PAME-BI'] = True\n        answers['proto_id'] = {0: 'ANQP', 1: 'MIH Information Service', 3: 'Emergency Alert System (EAS)',\n                               2: 'MIH Command and Event Services Capability Discovery',\n                               221: 'Vendor Specific'}.get(proto_id, 'Reserved: {0}'.format(proto_id))\n        idx += 2\n    return answers", "response": "Parse 11u advertisement data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ht_op(_, data):\n    protection = ('no', 'nonmember', 20, 'non-HT mixed')\n    sta_chan_width = (20, 'any')\n    answers = {\n        'primary channel': data[0],\n        'secondary channel offset': ht_secondary_offset[data[1] & 0x3],\n        'STA channel width': sta_chan_width[(data[1] & 0x4) >> 2],\n        'RIFS': (data[1] & 0x8) >> 3,\n        'HT protection': protection[data[2] & 0x3],\n        'non-GF present': (data[2] & 0x4) >> 2,\n        'OBSS non-GF present': (data[2] & 0x10) >> 4,\n        'dual beacon': (data[4] & 0x40) >> 6,\n        'dual CTS protection': (data[4] & 0x80) >> 7,\n        'STBC beacon': data[5] & 0x1,\n        'L-SIG TXOP Prot': (data[5] & 0x2) >> 1,\n        'PCO active': (data[5] & 0x4) >> 2,\n        'PCO phase': (data[5] & 0x8) >> 3,\n    }\n    return answers", "response": "Get the current state of the current ht_op."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the capabilities of a node.", "response": "def get_capabilities(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n796.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    List.\n    \"\"\"\n    answers = list()\n    for i in range(len(data)):\n        base = i * 8\n        for bit in range(8):\n            if not data[i] & (1 << bit):\n                continue\n            answers.append(CAPA.get(bit + base, bit))\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tim(_, data):\n    answers = {\n        'DTIM Count': data[0],\n        'DTIM Period': data[1],\n        'Bitmap Control': data[2],\n        'Bitmap[0]': data[3],\n    }\n    if len(data) - 4:\n        answers['+ octets'] = len(data) - 4\n    return answers", "response": "Get the time from the data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the OBSS scan parameters from the byte array data.", "response": "def get_obss_scan_params(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n914.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    Dict.\n    \"\"\"\n    answers = {\n        'passive dwell': (data[1] << 8) | data[0],\n        'active dwell': (data[3] << 8) | data[2],\n        'channel width trigger scan interval': (data[5] << 8) | data[4],\n        'scan passive total per channel': (data[7] << 8) | data[6],\n        'scan active total per channel': (data[9] << 8) | data[8],\n        'BSS width channel transition delay factor': (data[11] << 8) | data[10],\n        'OBSS Scan Activity Threshold': ((data[13] << 8) | data[12]) / 100.0\n    }\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the offset of the secondary section of the current page.", "response": "def get_secchan_offs(type_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n927.\n\n    Positional arguments:\n    type_ -- corresponding `ieprinters` dictionary key for the instance.\n    data -- bytearray data to read.\n    \"\"\"\n    if data[0] < len(ht_secondary_offset):\n        return \"{0} ({1})\".format(ht_secondary_offset[data[0]], data[0])\n    return \"{0}\".format(data[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the BSS load from the given bytearray data.", "response": "def get_bss_load(_, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n935.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    Dict.\n    \"\"\"\n    answers = {\n        'station count': (data[1] << 8) | data[0],\n        'channel utilisation': data[2] / 255.0,\n        'available admission capacity': (data[4] << 8) | data[3],\n    }\n    return answers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the ICE data from the given instance.", "response": "def get_ie(instance, key, data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n981.\n\n    Positional arguments:\n    instance -- `ie_print` class instance.\n    key -- corresponding `ieprinters` dictionary key for the instance.\n    data -- bytearray data to read.\n\n    Returns:\n    Dictionary of parsed data with string keys.\n    \"\"\"\n    if not instance.print_:\n        return dict()\n    if len(data) < instance.minlen or len(data) > instance.maxlen:\n        if data:\n            return {'<invalid: {0} byte(s)>'.format(len(data)): ' '.join(format(x, '02x') for x in data)}\n        return {'<invalid: no data>': data}\n    return {instance.name: instance.print_(key, data)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_wifi_wmm_param(data):\n    answers = dict()\n    aci_tbl = ('BE', 'BK', 'VI', 'VO')\n    if data[0] & 0x80:\n        answers['u-APSD'] = True\n    data = data[2:]\n\n    for i in range(4):\n        key = aci_tbl[(data[0] >> 5) & 3]\n        value = dict()\n        if data[0] & 0x10:\n            value['acm'] = True\n        value['CW'] = ((1 << (data[1] & 0xf)) - 1, (1 << (data[1] >> 4)) - 1)\n        value['AIFSN'] = data[0] & 0xf\n        if data[2] | data[3]:\n            value['TXOP'] = (data[2] + (data[3] << 8)) * 32\n        answers[key] = value\n        data = data[4:]\n\n    return {'Parameter version 1': answers}", "response": "Parse Wifi WMM parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_wifi_wmm(_, data):\n    answers = dict()\n    if data[0] == 0x01:\n        if len(data) < 20:\n            key = 'invalid'\n        elif data[1] != 1:\n            key = 'Parameter: not version 1'\n        else:\n            answers.update(get_wifi_wmm_param(data[2:]))\n            return answers\n    elif data[0] == 0x00:\n        key = 'information'\n    else:\n        key = 'type {0}'.format(data[0])\n    answers[key] = ' '.join(format(x, '02x') for x in data)\n    return answers", "response": "Get the Wifi WMM from the given bytearray."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_wifi_wps(_, data):\n    answers = dict()\n    while len(data) >= 4:\n        subtype = (data[0] << 8) + data[1]\n        sublen = (data[2] << 8) + data[3]\n        if sublen > len(data):\n            break\n        elif subtype == 0x104a:\n            answers['Version'] = data[4] >> 4, data[4] & 0xF\n        elif subtype == 0x1011:\n            answers['Device name'] = data[4:sublen + 4]\n        elif subtype == 0x1012:\n            if sublen != 2:\n                answers['Device Password ID'] = 'invalid length %d'.format(sublen)\n            else:\n                id_ = data[4] << 8 | data[5]\n                answers['Device Password ID'] = (id_, wifi_wps_dev_passwd_id(id_))\n        elif subtype == 0x1021:\n            answers['Manufacturer'] = data[4:sublen + 4]\n        elif subtype == 0x1023:\n            answers['Model'] = data[4:sublen + 4]\n        elif subtype == 0x1024:\n            answers['Model Number'] = data[4:sublen + 4]\n        elif subtype == 0x103b:\n            val = data[4]\n            answers['Response Type'] = (val, 'AP' if val == 3 else '')\n        elif subtype == 0x103c:\n            answers['RF Bands'] = data[4]\n        elif subtype == 0x1041:\n            answers['Selected Registrar'] = data[4]\n        elif subtype == 0x1042:\n            answers['Serial Number'] = data[4:sublen + 4]\n        elif subtype == 0x1044:\n            val = data[4]\n            answers['Wi-Fi Protected Setup State'] = (val, {1: 'Unconfigured', 2: 'Configured'}.get(val, ''))\n        elif subtype == 0x1047:\n            if sublen != 16:\n                answers['UUID'] = '(invalid, length={0})'.format(sublen)\n            else:\n                answers['UUID'] = bytearray(data[4:19])\n        elif subtype == 0x1054:\n            if sublen != 8:\n                answers['Primary Device Type'] = '(invalid, length={0})'.format(sublen)\n            else:\n                answers['Primary Device Type'] = '{0}-{1}-{2}'.format(\n                    data[4] << 8 | data[5],\n                    ''.join(format(x, '02x') for x in data[6:9]),\n                    data[10] << 8 | data[11]\n                )\n        elif subtype == 0x1057:\n            answers['AP setup locked'] = data[4]\n        elif subtype == 0x1008 or subtype == 0x1053:\n            meth = (data[4] << 8) + data[5]\n            key = 'Selected Registrar Config methods' if subtype == 0x1053 else 'Config methods'\n            values = [s for i, s in enumerate(('USB', 'Ethernet', 'Label', 'Display', 'Ext. NFC', 'Int. NFC',\n                                               'NFC Intf.', 'PBC', 'Keypad')) if meth & (1 << i)]\n            answers[key] = values\n        else:\n            value = ' '.join(format(x, '02x') for x in data[4:])\n            answers['Unknown TLV ({0:04x}, {1} bytes)'.format(subtype, sublen)] = value\n        data = data[4:]\n    if data:\n        answers['bogus tail data'] = ' '.join(format(x, '02x') for x in data)\n    return answers", "response": "Parse Wifi WPS packet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the vendor specific data.", "response": "def get_vendor(data):\n    \"\"\"http://git.kernel.org/cgit/linux/kernel/git/jberg/iw.git/tree/scan.c?id=v3.17#n1401.\n\n    Positional arguments:\n    data -- bytearray data to read.\n\n    Returns:\n    Dictionary of parsed data with string keys.\n    \"\"\"\n    if len(data) < 3:\n        return dict(('Vendor specific: <too short> data', ' '.join(format(x, '02x'))) for x in data)\n    key = data[3]\n\n    if bytes(data[:3]) == ms_oui:\n        if key in wifiprinters and wifiprinters[key].flags & 1:\n            return get_ie(wifiprinters[key], key, data[4:])\n        return dict(('MS/WiFi {0:02x}, data'.format(key), ' '.join(format(x, '02x'))) for x in data[4:])\n\n    if bytes(data[:3]) == wfa_oui:\n        if key in wfa_printers and wfa_printers[key].flags & 1:\n            return get_ie(wfa_printers[key], key, data[4:])\n        return dict(('WFA {0:02x}, data'.format(key), ' '.join(format(x, '02x'))) for x in data[4:])\n\n    unknown_key = 'Vendor specific: OUI {0:02x}:{1:02x}:{2:02x}, data'.format(data[0], data[1], data[2])\n    unknown_value = ' '.join(format(x, '02x') for x in data[3:])\n    return {unknown_key: unknown_value}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ies(ie):\n    answers = dict()\n    while len(ie) >= 2 and len(ie) >= ie[1]:\n        key = ie[0]  # Should be key in `ieprinters` dict.\n        len_ = ie[1]  # Length of this information element.\n        data = ie[2:len_ + 2]  # Data for this information element.\n        if key in ieprinters and ieprinters[key].flags & 1:\n            answers.update(get_ie(ieprinters[key], key, data))\n        elif key == 221:\n            answers.update(get_vendor(data))\n        else:\n            answers['Unknown IE ({0})'.format(key)] = ' '.join(format(x, '02x') for x in data)\n        ie = ie[len_ + 2:]\n    return answers", "response": "Get all information elements from a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ok(no_exit, func, *args, **kwargs):\n    ret = func(*args, **kwargs)\n    if no_exit or ret >= 0:\n        return ret\n    reason = errmsg[abs(ret)]\n    error('{0}() returned {1} ({2})'.format(func.__name__, ret, reason))", "response": "Exit if ret is not OK."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the mutable integer arg with the error code.", "response": "def error_handler(_, err, arg):\n    \"\"\"Update the mutable integer `arg` with the error code.\"\"\"\n    arg.value = err.error\n    return libnl.handlers.NL_STOP"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callback_trigger(msg, arg):\n    gnlh = genlmsghdr(nlmsg_data(nlmsg_hdr(msg)))\n    if gnlh.cmd == nl80211.NL80211_CMD_SCAN_ABORTED:\n        arg.value = 1  # The scan was aborted for some reason.\n    elif gnlh.cmd == nl80211.NL80211_CMD_NEW_SCAN_RESULTS:\n        arg.value = 0  # The scan completed successfully. `callback_dump` will collect the results later.\n    return libnl.handlers.NL_SKIP", "response": "Called when the kernel is done scanning."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef callback_dump(msg, results):\n    bss = dict()  # To be filled by nla_parse_nested().\n\n    # First we must parse incoming data into manageable chunks and check for errors.\n    gnlh = genlmsghdr(nlmsg_data(nlmsg_hdr(msg)))\n    tb = dict((i, None) for i in range(nl80211.NL80211_ATTR_MAX + 1))\n    nla_parse(tb, nl80211.NL80211_ATTR_MAX, genlmsg_attrdata(gnlh, 0), genlmsg_attrlen(gnlh, 0), None)\n    if not tb[nl80211.NL80211_ATTR_BSS]:\n        print('WARNING: BSS info missing for an access point.')\n        return libnl.handlers.NL_SKIP\n    if nla_parse_nested(bss, nl80211.NL80211_BSS_MAX, tb[nl80211.NL80211_ATTR_BSS], bss_policy):\n        print('WARNING: Failed to parse nested attributes for an access point!')\n        return libnl.handlers.NL_SKIP\n    if not bss[nl80211.NL80211_BSS_BSSID]:\n        print('WARNING: No BSSID detected for an access point!')\n        return libnl.handlers.NL_SKIP\n    if not bss[nl80211.NL80211_BSS_INFORMATION_ELEMENTS]:\n        print('WARNING: No additional information available for an access point!')\n        return libnl.handlers.NL_SKIP\n\n    # Further parse and then store. Overwrite existing data for BSSID if scan is run multiple times.\n    bss_parsed = parse_bss(bss)\n    results[bss_parsed['bssid']] = bss_parsed\n    return libnl.handlers.NL_SKIP", "response": "This function is called by the kernel when a message is received from the kernel. It is called once per SSID and data is decoded from the binary data sent by the kernel."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_scan_trigger(sk, if_index, driver_id, mcid):\n    # First get the \"scan\" membership group ID and join the socket to the group.\n    _LOGGER.debug('Joining group %d.', mcid)\n    ret = nl_socket_add_membership(sk, mcid)  # Listen for results of scan requests (aborted or new results).\n    if ret < 0:\n        return ret\n\n    # Build the message to be sent to the kernel.\n    msg = nlmsg_alloc()\n    genlmsg_put(msg, 0, 0, driver_id, 0, 0, nl80211.NL80211_CMD_TRIGGER_SCAN, 0)  # Setup which command to run.\n    nla_put_u32(msg, nl80211.NL80211_ATTR_IFINDEX, if_index)  # Setup which interface to use.\n    ssids_to_scan = nlmsg_alloc()\n    nla_put(ssids_to_scan, 1, 0, b'')  # Scan all SSIDs.\n    nla_put_nested(msg, nl80211.NL80211_ATTR_SCAN_SSIDS, ssids_to_scan)  # Setup what kind of scan to perform.\n\n    # Setup the callbacks to be used for triggering the scan only.\n    err = ctypes.c_int(1)  # Used as a mutable integer to be updated by the callback function. Signals end of messages.\n    results = ctypes.c_int(-1)  # Signals if the scan was successful (new results) or aborted, or not started.\n    cb = libnl.handlers.nl_cb_alloc(libnl.handlers.NL_CB_DEFAULT)\n    libnl.handlers.nl_cb_set(cb, libnl.handlers.NL_CB_VALID, libnl.handlers.NL_CB_CUSTOM, callback_trigger, results)\n    libnl.handlers.nl_cb_err(cb, libnl.handlers.NL_CB_CUSTOM, error_handler, err)\n    libnl.handlers.nl_cb_set(cb, libnl.handlers.NL_CB_ACK, libnl.handlers.NL_CB_CUSTOM, ack_handler, err)\n    libnl.handlers.nl_cb_set(cb, libnl.handlers.NL_CB_SEQ_CHECK, libnl.handlers.NL_CB_CUSTOM,\n                             lambda *_: libnl.handlers.NL_OK, None)  # Ignore sequence checking.\n\n    # Now we send the message to the kernel, and retrieve the acknowledgement. The kernel takes a few seconds to finish\n    # scanning for access points.\n    _LOGGER.debug('Sending NL80211_CMD_TRIGGER_SCAN...')\n    ret = nl_send_auto(sk, msg)\n    if ret < 0:\n        return ret\n    while err.value > 0:\n        _LOGGER.debug('Retrieving NL80211_CMD_TRIGGER_SCAN acknowledgement...')\n        ret = nl_recvmsgs(sk, cb)\n        if ret < 0:\n            return ret\n    if err.value < 0:\n        error('Unknown error {0} ({1})'.format(err.value, errmsg[abs(err.value)]))\n\n    # Block until the kernel is done scanning or aborted the scan.\n    while results.value < 0:\n        _LOGGER.debug('Retrieving NL80211_CMD_TRIGGER_SCAN final response...')\n        ret = nl_recvmsgs(sk, cb)\n        if ret < 0:\n            return ret\n    if results.value > 0:\n        error('The kernel aborted the scan.')\n\n    # Done, cleaning up.\n    _LOGGER.debug('Leaving group %d.', mcid)\n    return nl_socket_drop_membership(sk, mcid)", "response": "Issue a scan request to the kernel and wait for it to reply with a signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the results of a successful scan.", "response": "def do_scan_results(sk, if_index, driver_id, results):\n    \"\"\"Retrieve the results of a successful scan (SSIDs and data about them).\n\n    This function does not require root privileges. It eventually calls a callback that actually decodes data about\n    SSIDs but this function kicks that off.\n\n    May exit the program (sys.exit()) if a fatal error occurs.\n\n    Positional arguments:\n    sk -- nl_sock class instance (from nl_socket_alloc()).\n    if_index -- interface index (integer).\n    driver_id -- nl80211 driver ID from genl_ctrl_resolve() (integer).\n    results -- dictionary to populate with results. Keys are BSSIDs (MAC addresses) and values are dicts of data.\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    msg = nlmsg_alloc()\n    genlmsg_put(msg, 0, 0, driver_id, 0, NLM_F_DUMP, nl80211.NL80211_CMD_GET_SCAN, 0)\n    nla_put_u32(msg, nl80211.NL80211_ATTR_IFINDEX, if_index)\n    cb = libnl.handlers.nl_cb_alloc(libnl.handlers.NL_CB_DEFAULT)\n    libnl.handlers.nl_cb_set(cb, libnl.handlers.NL_CB_VALID, libnl.handlers.NL_CB_CUSTOM, callback_dump, results)\n    _LOGGER.debug('Sending NL80211_CMD_GET_SCAN...')\n    ret = nl_send_auto(sk, msg)\n    if ret >= 0:\n        _LOGGER.debug('Retrieving NL80211_CMD_GET_SCAN response...')\n        ret = nl_recvmsgs(sk, cb)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting seconds remaining into human readable strings.", "response": "def eta_letters(seconds):\n    \"\"\"Convert seconds remaining into human readable strings.\n\n    From https://github.com/Robpol86/etaprogress/blob/ad934d4/etaprogress/components/eta_conversions.py.\n\n    Positional arguments:\n    seconds -- integer/float indicating seconds remaining.\n    \"\"\"\n    final_days, final_hours, final_minutes, final_seconds = 0, 0, 0, seconds\n    if final_seconds >= 86400:\n        final_days = int(final_seconds / 86400.0)\n        final_seconds -= final_days * 86400\n    if final_seconds >= 3600:\n        final_hours = int(final_seconds / 3600.0)\n        final_seconds -= final_hours * 3600\n    if final_seconds >= 60:\n        final_minutes = int(final_seconds / 60.0)\n        final_seconds -= final_minutes * 60\n    final_seconds = int(math.ceil(final_seconds))\n\n    if final_days:\n        template = '{1:d}d {2:d}h {3:02d}m {4:02d}s'\n    elif final_hours:\n        template = '{2:d}h {3:02d}m {4:02d}s'\n    elif final_minutes:\n        template = '{3:02d}m {4:02d}s'\n    else:\n        template = '{4:02d}s'\n\n    return template.format(final_days, final_hours, final_minutes, final_seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints the table of detected SSIDs and their data to screen.", "response": "def print_table(data):\n    \"\"\"Print the table of detected SSIDs and their data to screen.\n\n    Positional arguments:\n    data -- list of dictionaries.\n    \"\"\"\n    table = AsciiTable([COLUMNS])\n    table.justify_columns[2] = 'right'\n    table.justify_columns[3] = 'right'\n    table.justify_columns[4] = 'right'\n    table_data = list()\n    for row_in in data:\n        row_out = [\n            str(row_in.get('ssid', '')).replace('\\0', ''),\n            str(row_in.get('security', '')),\n            str(row_in.get('channel', '')),\n            str(row_in.get('frequency', '')),\n            str(row_in.get('signal', '')),\n            str(row_in.get('bssid', '')),\n        ]\n        if row_out[3]:\n            row_out[3] += ' MHz'\n        if row_out[4]:\n            row_out[4] += ' dBm'\n        table_data.append(row_out)\n\n    sort_by_column = [c.lower() for c in COLUMNS].index(OPTIONS['--key'].lower())\n    table_data.sort(key=lambda c: c[sort_by_column], reverse=OPTIONS['--reverse'])\n\n    table.table_data.extend(table_data)\n    print(table.table)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    # First get the wireless interface index.\n    pack = struct.pack('16sI', OPTIONS['<interface>'].encode('ascii'), 0)\n    sk = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    try:\n        info = struct.unpack('16sI', fcntl.ioctl(sk.fileno(), 0x8933, pack))\n    except OSError:\n        return error('Wireless interface {0} does not exist.'.format(OPTIONS['<interface>']))\n    finally:\n        sk.close()\n    if_index = int(info[1])\n\n    # Next open a socket to the kernel and bind to it. Same one used for sending and receiving.\n    sk = nl_socket_alloc()  # Creates an `nl_sock` instance.\n    ok(0, genl_connect, sk)  # Create file descriptor and bind socket.\n    _LOGGER.debug('Finding the nl80211 driver ID...')\n    driver_id = ok(0, genl_ctrl_resolve, sk, b'nl80211')\n    _LOGGER.debug('Finding the nl80211 scanning group ID...')\n    mcid = ok(0, genl_ctrl_resolve_grp, sk, b'nl80211', b'scan')\n\n    # Scan for access points 1 or more (if requested) times.\n    if not OPTIONS['--no-sudo']:\n        print('Scanning for access points, may take about 8 seconds...')\n    else:\n        print(\"Attempting to read results of previous scan.\")\n    results = dict()\n    for i in range(2, -1, -1):  # Three tries on errors.\n        if not OPTIONS['--no-sudo']:\n            ret = ok(i, do_scan_trigger, sk, if_index, driver_id, mcid)\n            if ret < 0:\n                _LOGGER.warning('do_scan_trigger() returned %d, retrying in 5 seconds.', ret)\n                time.sleep(5)\n                continue\n        ret = ok(i, do_scan_results, sk, if_index, driver_id, results)\n        if ret < 0:\n            _LOGGER.warning('do_scan_results() returned %d, retrying in 5 seconds.', ret)\n            time.sleep(5)\n            continue\n        break\n    if not results:\n        print('No access points detected.')\n        return\n\n    # Print results.\n    print('Found {0} access points:'.format(len(results)))\n    print_table(results.values())", "response": "Main function called upon script execution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when the script is run. Sets up logging library.", "response": "def setup_logging():\n    \"\"\"Called when __name__ == '__main__' below. Sets up logging library.\n\n    All logging messages go to stderr, from DEBUG to CRITICAL. This script uses print() for regular messages.\n    \"\"\"\n    fmt = 'DBG<0>%(pathname)s:%(lineno)d  %(funcName)s: %(message)s'\n\n    handler_stderr = logging.StreamHandler(sys.stderr)\n    handler_stderr.setFormatter(logging.Formatter(fmt))\n    if OPTIONS['--verbose'] == 1:\n        handler_stderr.addFilter(logging.Filter(__name__))\n\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n    root_logger.addHandler(handler_stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a SOAP header of the given type", "response": "def generateHeader(self, sObjectType):\n    '''\n    Generate a SOAP header as defined in:\n    http://www.salesforce.com/us/developer/docs/api/Content/soap_headers.htm\n    '''\n    try:\n      return self._sforce.factory.create(sObjectType)\n    except:\n      print 'There is not a SOAP header of type %s' % sObjectType"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a Salesforce object such as a Lead or Contact", "response": "def generateObject(self, sObjectType):\n    '''\n    Generate a Salesforce object, such as a Lead or Contact\n    '''\n    obj = self._sforce.factory.create('ens:sObject')\n    obj.type = sObjectType\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the result typing of the result.", "response": "def _handleResultTyping(self, result):\n    '''\n    If any of the following calls return a single result, and self._strictResultTyping is true,\n    return the single result, rather than [(SaveResult) {...}]:\n\n      convertLead()\n      create()\n      delete()\n      emptyRecycleBin()\n      invalidateSessions()\n      merge()\n      process()\n      retrieve()\n      undelete()\n      update()\n      upsert()\n      describeSObjects()\n      sendEmail()\n    '''\n    if self._strictResultTyping == False and len(result) == 1:\n      return result[0]\n    else:\n      return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _marshallSObjects(self, sObjects, tag = 'sObjects'):\n    '''\n    Marshall generic sObjects into a list of SAX elements\n\n    This code is going away ASAP\n\n    tag param is for nested objects (e.g. MergeRequest) where\n    key: object must be in <key/>, not <sObjects/>\n    '''\n    if not isinstance(sObjects, (tuple, list)):\n      sObjects = (sObjects, )\n    if sObjects[0].type in ['LeadConvert', 'SingleEmailMessage', 'MassEmailMessage']:\n      nsPrefix = 'tns:'\n    else:\n      nsPrefix = 'ens:'\n\n    li = []\n    for obj in sObjects:\n      el = Element(tag)\n      el.set('xsi:type', nsPrefix + obj.type)\n      for k, v in obj:\n        if k == 'type':\n          continue\n\n        # This is here to avoid 'duplicate values' error when setting a field in fieldsToNull\n        # Even a tag like <FieldName/> will trigger it\n        if v == None:\n          # not going to win any awards for variable-naming scheme here\n          tmp = Element(k)\n          tmp.set('xsi:nil', 'true')\n          el.append(tmp)\n        elif isinstance(v, (list, tuple)):\n          for value in v:\n            el.append(Element(k).setText(value))\n        elif isinstance(v, suds.sudsobject.Object):\n          el.append(self._marshallSObjects(v, k))\n        else:\n          el.append(Element(k).setText(v))\n\n      li.append(el)\n    return li", "response": "Marshall generic sObjects into a list of SAX elements"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setEndpoint(self, location):\n    '''\n    Set the endpoint after when Salesforce returns the URL after successful login()\n    '''\n    # suds 0.3.7+ supports multiple wsdl services, but breaks setlocation :(\n    # see https://fedorahosted.org/suds/ticket/261\n    try:\n      self._sforce.set_options(location = location)\n    except:\n      self._sforce.wsdl.service.setlocation(location)\n\n    self._location = location", "response": "Set the endpoint after when Salesforce returns the URL after successful login"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setHeaders(self, call = None, **kwargs):\n    '''\n    Attach particular SOAP headers to the request depending on the method call made\n    '''\n    # All calls, including utility calls, set the session header\n    headers = {'SessionHeader': self._sessionHeader}\n\n    if 'debug_categories' in kwargs:\n      #ERROR, WARN, INFO, DEBUG, FINE, FINER, FINEST\n      #Db, Workflow, Validation, Callout, Apex Code, Apex Profiling, All\n      debug_categories = kwargs['debug_categories']\n\n      headers['DebuggingHeader'] = {\n        'categories' : debug_categories\n      }\n\n      # headers['DebuggingHeader'] = {\n      #   'categories' : {\n      #     'category' : kwargs['debug_category'],\n      #     'level'    : kwargs['debug_level']\n      #   }\n      # }\n\n    if call in ('convertLead',\n                'create',\n                'merge',\n                'process',\n                'undelete',\n                'update',\n                'upsert'):\n      if self._allowFieldTruncationHeader is not None:\n        headers['AllowFieldTruncationHeader'] = self._allowFieldTruncationHeader\n\n    if call in ('create',\n                'merge',\n                'update',\n                'upsert'):\n      if self._assignmentRuleHeader is not None:\n        headers['AssignmentRuleHeader'] = self._assignmentRuleHeader\n\n    # CallOptions will only ever be set by the SforcePartnerClient\n    if self._callOptions is not None:\n      if call in ('create',\n                  'merge',\n                  'queryAll',\n                  'query',\n                  'queryMore',\n                  'retrieve',\n                  'search',\n                  'update',\n                  'upsert',\n                  'convertLead',\n                  'login',\n                  'delete',\n                  'describeGlobal',\n                  'describeLayout',\n                  'describeTabs',\n                  'describeSObject',\n                  'describeSObjects',\n                  'getDeleted',\n                  'getUpdated',\n                  'process',\n                  'undelete',\n                  'getServerTimestamp',\n                  'getUserInfo',\n                  'setPassword',\n                  'resetPassword'):\n        headers['CallOptions'] = self._callOptions\n\n    if call in ('create',\n                'delete',\n                'resetPassword',\n                'update',\n                'upsert'):\n      if self._emailHeader is not None:\n        headers['EmailHeader'] = self._emailHeader\n\n    if call in ('describeSObject',\n                'describeSObjects'):\n      if self._localeOptions is not None:\n        headers['LocaleOptions'] = self._localeOptions\n\n    if call == 'login':\n      if self._loginScopeHeader is not None:\n        headers['LoginScopeHeader'] = self._loginScopeHeader\n\n    if call in ('create',\n                'merge',\n                'query',\n                'retrieve',\n                'update',\n                'upsert'):\n      if self._mruHeader is not None:\n        headers['MruHeader'] = self._mruHeader\n\n    if call in ('convertLead',\n                'create',\n                'delete',\n                'describeGlobal',\n                'describeLayout',\n                'describeSObject',\n                'describeSObjects',\n                'describeTabs',\n                'merge',\n                'process',\n                'query',\n                'retrieve',\n                'search',\n                'undelete',\n                'update',\n                'upsert'):\n      if self._packageVersionHeader is not None:\n        headers['PackageVersionHeader'] = self._packageVersionHeader\n\n    if call in ('query',\n                'queryAll',\n                'queryMore',\n                'retrieve'):\n      if self._queryOptions is not None:\n        headers['QueryOptions'] = self._queryOptions\n\n    if call == 'delete':\n      if self._userTerritoryDeleteHeader is not None:\n        headers['UserTerritoryDeleteHeader'] = self._userTerritoryDeleteHeader\n\n\n    #print '\\n\\n>>>>>>>>>>>>>>>> setting header '\n    #print headers\n\n    self._sforce.set_options(soapheaders = headers)", "response": "Sets the SOAP headers for the current request based on the method call."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getUpdated(self, sObjectType, startDate, endDate):\n    '''\n    Retrieves the list of individual objects that have been updated (added or\n    changed) within the given timespan for the specified object.\n    '''\n    self._setHeaders('getUpdated')\n    return self._sforce.service.getUpdated(sObjectType, startDate, endDate)", "response": "Retrieves the list of objects that have been added or have been changed within the given timespan."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninvalidating a Salesforce session", "response": "def invalidateSessions(self, sessionIds):\n    '''\n    Invalidate a Salesforce session\n\n    This should be used with extreme caution, for the following (undocumented) reason:\n    All API connections for a given user share a single session ID\n    This will call logout() WHICH LOGS OUT THAT USER FROM EVERY CONCURRENT SESSION\n\n    return invalidateSessionsResult\n    '''\n    self._setHeaders('invalidateSessions')\n    return self._handleResultTyping(self._sforce.service.invalidateSessions(sessionIds))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login(self, username, password, token):\n    '''\n    Login to Salesforce.com and starts a client session.\n\n    Unlike other toolkits, token is a separate parameter, because\n    Salesforce doesn't explicitly tell you to append it when it gives\n    you a login error.  Folks that are new to the API may not know this.\n\n    'username' : Username\n    'password' : Password\n    'token' : Token\n\n    return LoginResult\n    '''\n    self._setHeaders('login')\n    result = self._sforce.service.login(username, password + token)\n\n    # set session header\n    header = self.generateHeader('SessionHeader')\n    header.sessionId = result['sessionId']\n    self.setSessionHeader(header)\n    self._sessionId = result['sessionId']\n    self._userId = result['userId']\n    self._metadataServerUrl = result['metadataServerUrl']\n\n    # change URL to point from test.salesforce.com to something like cs2-api.salesforce.com\n    self._setEndpoint(result['serverUrl'])\n\n    # na0.salesforce.com (a.k.a. ssl.salesforce.com) requires ISO-8859-1 instead of UTF-8\n    if 'ssl.salesforce.com' in result['serverUrl'] or 'na0.salesforce.com' in result['serverUrl']:\n      # currently, UTF-8 is hard-coded in Suds, can't implement this yet\n      pass\n\n    return result", "response": "Login to Salesforce. com and starts a client session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a query against the specified object and returns the data that matches the specified criteria.", "response": "def query(self, queryString):\n    '''\n    Executes a query against the specified object and returns data that matches\n    the specified criteria.\n    '''\n    self._setHeaders('query')\n    return self._sforce.service.query(queryString)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving data from specified objects whether or not they have been deleted.", "response": "def queryAll(self, queryString):\n    '''\n    Retrieves data from specified objects, whether or not they have been deleted.\n    '''\n    self._setHeaders('queryAll')\n    return self._sforce.service.queryAll(queryString)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the next batch of objects from a query.", "response": "def queryMore(self, queryLocator):\n    '''\n    Retrieves the next batch of objects from a query.\n    '''\n    self._setHeaders('queryMore')\n    return self._sforce.service.queryMore(queryLocator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndescribing the specified objects.", "response": "def describeSObject(self, sObjectsType):\n    '''\n    Describes metadata (field list and object properties) for the specified\n    object.\n    '''\n    self._setHeaders('describeSObject')\n    return self._sforce.service.describeSObject(sObjectsType)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of metadata for the specified objects.", "response": "def describeSObjects(self, sObjectTypes):\n    '''\n    An array-based version of describeSObject; describes metadata (field list\n    and object properties) for the specified object or array of objects.\n    '''\n    self._setHeaders('describeSObjects')\n    return self._handleResultTyping(self._sforce.service.describeSObjects(sObjectTypes))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resetPassword(self, userId):\n    '''\n    Changes a user's password to a system-generated value.\n    '''\n    self._setHeaders('resetPassword')\n    return self._sforce.service.resetPassword(userId)", "response": "Changes a user s password to a system - generated value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the specified user s password.", "response": "def setPassword(self, userId, password):\n    '''\n    Sets the specified user's password to the specified value.\n    '''\n    self._setHeaders('setPassword')\n    return self._sforce.service.setPassword(userId, password)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _cache_ops_associate(protocol, msgtype):\n    ops = cache_ops\n    while ops:  # Loop until `ops` is None.\n        if ops.co_protocol == protocol:\n            for co_msgtype in ops.co_msgtypes:\n                if co_msgtype.mt_id == msgtype:\n                    return ops\n        ops = ops.co_next\n    return None", "response": "Returns a nl_cache_ops instance with matching protocol containing matching msgtype or None if no matching operation is found."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nl_cache_mngt_register(ops):\n    global cache_ops\n\n    if not ops.co_name or not ops.co_obj_ops:\n        return -NLE_INVAL\n\n    with cache_ops_lock:\n        if _nl_cache_ops_lookup(ops.co_name):\n            return -NLE_EXIST\n        ops.co_refcnt = 0\n        ops.co_next = cache_ops\n        cache_ops = ops\n\n    _LOGGER.debug('Registered cache operations {0}'.format(ops.co_name))\n    return 0", "response": "Register a set of cache operations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self):\n        if 'type' not in self.params:\n            raise MMException(\"Please include the type of log, 'user' or 'apex'\")\n        if 'debug_categories' not in self.params:\n            raise MMException(\"Please include debug categories in dictionary format: e.g.: {'ApexCode':'DEBUG', 'Visualforce':'INFO'}\")\n\n        request = {}\n        if self.params['type'] == 'user':\n            request['ScopeId'] = None\n            request['TracedEntityId'] = self.params.get('user_id', config.sfdc_client.user_id)\n        elif self.params['type'] == 'apex':\n            #request['ScopeId'] = 'user'\n            request['ScopeId'] = config.sfdc_client.user_id\n            request['TracedEntityId'] = self.params['apex_id']\n\n        for c in self.params['debug_categories']:\n            if 'category' in c:\n                request[c['category']] = c['level']\n            else:\n                request[c] = self.params['debug_categories'][c]\n\n        request['ExpirationDate'] = util.get_iso_8601_timestamp(int(float(self.params.get('expiration', 30))))\n\n        config.logger.debug(self.params['debug_categories'])\n        config.logger.debug(\"Log creation reuqest--->\")\n        config.logger.debug(request)\n\n        create_result = config.sfdc_client.create_trace_flag(request)\n\n        config.logger.debug(\"Log creation response--->\")\n        config.logger.debug(create_result)\n\n        if type(create_result) is list:\n            create_result = create_result[0]\n        if type(create_result) is not str and type(create_result) is not unicode:\n            return json.dumps(create_result)\n        else:\n            return create_result", "response": "Execute the log creation command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the command and return the result.", "response": "def execute(self):\n        \"\"\"\n            self.params = {\n                \"ActionScriptType\"      : \"None\",\n                \"ExecutableEntityId\"    : \"01pd0000001yXtYAAU\",\n                \"IsDumpingHeap\"         : True,\n                \"Iteration\"             : 1,\n                \"Line\"                  : 3,\n                \"ScopeId\"               : \"005d0000000xxzsAAA\"\n            }\n        \"\"\"\n        config.logger.debug('logging self')\n        config.logger.debug(self.params )\n        if 'project_name' in self.params:\n            self.params.pop('project_name', None)\n        if 'settings' in self.params:\n            self.params.pop('settings', None)\n\n        create_result = config.sfdc_client.create_apex_checkpoint(self.params)\n        if type(create_result) is list:\n            create_result = create_result[0]\n        IndexApexOverlaysCommand(params=self.params).execute()\n        if type(create_result) is not str and type(create_result) is not unicode:\n            return json.dumps(create_result)\n        else:\n            return create_result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nposting /project/creds { \"project_name\" : \"my project name\" \"username\" : \"mm@force.com\", \"password\" : \"force\", \"org_type\" : \"developer\", } NOTE: project name should not be updated, as it is used to find the project in question TODO: maybe we assign a unique ID to each project which will give users the flexibility to change the project name?? TODO: we may need to implement a \"clean\" flag which will clean the project after creds have been updated", "response": "def update_credentials_request(request_handler):\n    '''\n        POST /project/creds\n        {\n            \"project_name\"  : \"my project name\"\n            \"username\"      : \"mm@force.com\",\n            \"password\"      : \"force\",\n            \"org_type\"      : \"developer\",\n        }\n        NOTE: project name should not be updated, as it is used to find the project in question\n        TODO: maybe we assign a unique ID to each project which will give users the flexibility\n              to change the project name??\n        TODO: we may need to implement a \"clean\" flag which will clean the project after creds\n              have been updated\n    '''\n    request_id = util.generate_request_id()\n    params, raw_post_body, plugin_client = get_request_params(request_handler)\n    worker_thread = BackgroundWorker('update_credentials', params, False, request_id, raw_post_body, plugin_client)\n    worker_thread.start()\n    worker_thread.join()\n    response = worker_thread.response\n    respond(request_handler, response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nl_connect(sk, protocol):\n    flags = getattr(socket, 'SOCK_CLOEXEC', 0)\n    if sk.s_fd != -1:\n        return -NLE_BAD_SOCK\n    try:\n        sk.socket_instance = socket.socket(getattr(socket, 'AF_NETLINK', -1), socket.SOCK_RAW | flags, protocol)\n    except OSError as exc:\n        return -nl_syserr2nlerr(exc.errno)\n\n    if not sk.s_flags & NL_SOCK_BUFSIZE_SET:\n        err = nl_socket_set_buffer_size(sk, 0, 0)\n        if err < 0:\n            sk.socket_instance.close()\n            return err\n\n    try:\n        sk.socket_instance.bind((sk.s_local.nl_pid, sk.s_local.nl_groups))\n    except OSError as exc:\n        sk.socket_instance.close()\n        return -nl_syserr2nlerr(exc.errno)\n    sk.s_local.nl_pid = sk.socket_instance.getsockname()[0]\n\n    if sk.s_local.nl_family != socket.AF_NETLINK:\n        sk.socket_instance.close()\n        return -NLE_AF_NOSUPPORT\n\n    sk.s_proto = protocol\n    return 0", "response": "Connect to a Netlink socket."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nl_sendmsg(sk, msg, hdr):\n    if sk.s_fd < 0:\n        return -NLE_BAD_SOCK\n    nlmsg_set_src(msg, sk.s_local)\n    cb = sk.s_cb\n    if cb.cb_set[NL_CB_MSG_OUT]:\n        ret = nl_cb_call(cb, NL_CB_MSG_OUT, msg)\n        if ret != NL_OK:\n            return ret\n\n    if hdr.msg_name is None:\n        address = None\n    else:\n        address = tuple(hdr.msg_name)\n        if address == (0, 0) or address == sk.socket_instance.getsockname:\n            address = None\n\n    try:\n        if hdr.msg_control:\n            ret = sk.socket_instance.sendmsg([hdr.msg_iov], hdr.msg_control, hdr.msg_flags, address)\n        elif address:\n            ret = sk.socket_instance.sendto(hdr.msg_iov, hdr.msg_flags, address)\n        else:\n            ret = sk.socket_instance.send(hdr.msg_iov, hdr.msg_flags)\n    except OSError as exc:\n        return -nl_syserr2nlerr(exc.errno)\n\n    _LOGGER.debug('sent %d bytes', ret)\n    return ret", "response": "Transmit a Netlink message over a Netlink socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nl_send_iovec(sk, msg, iov, _):\n    hdr = msghdr(msg_name=sk.s_peer, msg_iov=iov)\n\n    # Overwrite destination if specified in the message itself, defaults to the peer address of the socket.\n    dst = nlmsg_get_dst(msg)\n    if dst.nl_family == socket.AF_NETLINK:\n        hdr.msg_name = dst\n\n    # Add credentials if present.\n    creds = nlmsg_get_creds(msg)\n    if creds:\n        raise NotImplementedError  # TODO https://github.com/Robpol86/libnl/issues/2\n\n    return nl_sendmsg(sk, msg, hdr)", "response": "Transmit Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L342\n\n    This function is identical to nl_send().\n\n    This function triggers the `NL_CB_MSG_OUT` callback.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    msg -- Netlink message (nl_msg class instance).\n    iov -- data payload to be sent (bytearray).\n\n    Returns:\n    Number of bytes sent on success or a negative error code."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransmitting Netlink message over Netlink socket.", "response": "def nl_send(sk, msg):\n    \"\"\"Transmit Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L416\n\n    Transmits the Netlink message `msg` over the Netlink socket using the `socket.sendmsg()`. This function is based on\n    `nl_send_iovec()`.\n\n    The message is addressed to the peer as specified in the socket by either the nl_socket_set_peer_port() or\n    nl_socket_set_peer_groups() function. The peer address can be overwritten by specifying an address in the `msg`\n    object using nlmsg_set_dst().\n\n    If present in the `msg`, credentials set by the nlmsg_set_creds() function are added to the control buffer of the\n    message.\n\n    Calls to this function can be overwritten by providing an alternative using the nl_cb_overwrite_send() function.\n\n    This function triggers the `NL_CB_MSG_OUT` callback.\n\n    ATTENTION:  Unlike `nl_send_auto()`, this function does *not* finalize the message in terms of automatically adding\n    needed flags or filling out port numbers.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    msg -- Netlink message (nl_msg class instance).\n\n    Returns:\n    Number of bytes sent on success or a negative error code.\n    \"\"\"\n    cb = sk.s_cb\n    if cb.cb_send_ow:\n        return cb.cb_send_ow(sk, msg)\n    hdr = nlmsg_hdr(msg)\n    iov = hdr.bytearray[:hdr.nlmsg_len]\n    return nl_send_iovec(sk, msg, iov, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinalizing Netlink message. https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L450 This function finalizes a Netlink message by completing the message with desirable flags and values depending on the socket configuration. - If not yet filled out, the source address of the message (`nlmsg_pid`) will be set to the local port number of the socket. - If not yet specified, the next available sequence number is assigned to the message (`nlmsg_seq`). - If not yet specified, the protocol field of the message will be set to the protocol field of the socket. - The `NLM_F_REQUEST` Netlink message flag will be set. - The `NLM_F_ACK` flag will be set if Auto-ACK mode is enabled on the socket. Positional arguments: sk -- Netlink socket (nl_sock class instance). msg -- Netlink message (nl_msg class instance).", "response": "def nl_complete_msg(sk, msg):\n    \"\"\"Finalize Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L450\n\n    This function finalizes a Netlink message by completing the message with desirable flags and values depending on the\n    socket configuration.\n\n    - If not yet filled out, the source address of the message (`nlmsg_pid`) will be set to the local port number of the\n      socket.\n    - If not yet specified, the next available sequence number is assigned to the message (`nlmsg_seq`).\n    - If not yet specified, the protocol field of the message will be set to the protocol field of the socket.\n    - The `NLM_F_REQUEST` Netlink message flag will be set.\n    - The `NLM_F_ACK` flag will be set if Auto-ACK mode is enabled on the socket.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    msg -- Netlink message (nl_msg class instance).\n    \"\"\"\n    nlh = msg.nm_nlh\n    if nlh.nlmsg_pid == NL_AUTO_PORT:\n        nlh.nlmsg_pid = nl_socket_get_local_port(sk)\n    if nlh.nlmsg_seq == NL_AUTO_SEQ:\n        nlh.nlmsg_seq = sk.s_seq_next\n        sk.s_seq_next += 1\n    if msg.nm_protocol == -1:\n        msg.nm_protocol = sk.s_proto\n    nlh.nlmsg_flags |= NLM_F_REQUEST\n    if not sk.s_flags & NL_NO_AUTO_ACK:\n        nlh.nlmsg_flags |= NLM_F_ACK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nl_send_simple(sk, type_, flags, buf=None, size=0):\n    msg = nlmsg_alloc_simple(type_, flags)\n    if buf is not None and size:\n        err = nlmsg_append(msg, buf, size, NLMSG_ALIGNTO)\n        if err < 0:\n            return err\n    return nl_send_auto(sk, msg)", "response": "Construct and transmit a Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreceives data from a Netlink socket.", "response": "def nl_recv(sk, nla, buf, creds=None):\n    \"\"\"Receive data from Netlink socket.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L625\n\n    Receives data from a connected netlink socket using recvmsg() and returns the number of bytes read. The read data is\n    stored in a newly allocated buffer that is assigned to `buf`. The peer's netlink address will be stored in `nla`.\n\n    This function blocks until data is available to be read unless the socket has been put into non-blocking mode using\n    nl_socket_set_nonblocking() in which case this function will return immediately with a return value of 0.\n\n    The buffer size used when reading from the netlink socket and thus limiting the maximum size of a netlink message\n    that can be read defaults to the size of a memory page (getpagesize()). The buffer size can be modified on a per\n    socket level using the function `nl_socket_set_msg_buf_size()`.\n\n    If message peeking is enabled using nl_socket_enable_msg_peek() the size of the message to be read will be\n    determined using the MSG_PEEK flag prior to performing the actual read. This leads to an additional recvmsg() call\n    for every read operation which has performance implications and is not recommended for high throughput protocols.\n\n    An eventual interruption of the recvmsg() system call is automatically handled by retrying the operation.\n\n    If receiving of credentials has been enabled using the function `nl_socket_set_passcred()`, this function will\n    allocate a new struct `ucred` filled with the received credentials and assign it to `creds`.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance) (input).\n    nla -- Netlink socket structure to hold address of peer (sockaddr_nl class instance) (output).\n    buf -- destination bytearray() for message content (output).\n    creds -- destination class instance for credentials (ucred class instance) (output).\n\n    Returns:\n    Two-item tuple. First item is number of bytes read, 0 on EOF, 0 on no data event (non-blocking mode), or a negative\n    error code. Second item is the message content from the socket or None.\n    \"\"\"\n    flags = 0\n    page_size = resource.getpagesize() * 4\n    if sk.s_flags & NL_MSG_PEEK:\n        flags |= socket.MSG_PEEK | socket.MSG_TRUNC\n    iov_len = sk.s_bufsize or page_size\n\n    if creds and sk.s_flags & NL_SOCK_PASSCRED:\n        raise NotImplementedError  # TODO https://github.com/Robpol86/libnl/issues/2\n\n    while True:  # This is the `goto retry` implementation.\n        try:\n            if hasattr(sk.socket_instance, 'recvmsg'):\n                iov, _, msg_flags, address = sk.socket_instance.recvmsg(iov_len, 0, flags)\n            else:\n                iov, address = sk.socket_instance.recvfrom(iov_len, flags)\n                msg_flags = 0\n        except OSError as exc:\n            if exc.errno == errno.EINTR:\n                continue  # recvmsg() returned EINTR, retrying.\n            return -nl_syserr2nlerr(exc.errno)\n        nla.nl_family = sk.socket_instance.family  # recvmsg() in C does this, but not Python's.\n        if not iov:\n            return 0\n\n        if msg_flags & socket.MSG_CTRUNC:\n            raise NotImplementedError  # TODO https://github.com/Robpol86/libnl/issues/2\n\n        if iov_len < len(iov) or msg_flags & socket.MSG_TRUNC:\n            # Provided buffer is not long enough.\n            # Enlarge it to size of n (which should be total length of the message) and try again.\n            iov_len = len(iov)\n            continue\n\n        if flags:\n            # Buffer is big enough, do the actual reading.\n            flags = 0\n            continue\n\n        nla.nl_pid = address[0]\n        nla.nl_groups = address[1]\n\n        if creds and sk.s_flags * NL_SOCK_PASSCRED:\n            raise NotImplementedError  # TODO https://github.com/Robpol86/libnl/issues/2\n\n        if iov:\n            buf += iov\n\n        return len(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recvmsgs(sk, cb):\n    multipart = 0\n    interrupted = 0\n    nrecv = 0\n    buf = bytearray()\n\n    # nla is passed on to not only to nl_recv() but may also be passed to a function pointer provided by the caller\n    # which may or may not initialize the variable. Thomas Graf.\n    nla = sockaddr_nl()\n    creds = ucred()\n\n    while True:  # This is the `goto continue_reading` implementation.\n        _LOGGER.debug('Attempting to read from 0x%x', id(sk))\n        n = c_int(cb.cb_recv_ow(sk, nla, buf, creds) if cb.cb_recv_ow else nl_recv(sk, nla, buf, creds))\n        if n.value <= 0:\n            return n.value\n\n        _LOGGER.debug('recvmsgs(0x%x): Read %d bytes', id(sk), n.value)\n\n        hdr = nlmsghdr(bytearray_ptr(buf))\n        while nlmsg_ok(hdr, n):\n            _LOGGER.debug('recvmsgs(0x%x): Processing valid message...', id(sk))\n            msg = nlmsg_convert(hdr)\n            nlmsg_set_proto(msg, sk.s_proto)\n            nlmsg_set_src(msg, nla)\n            if creds:\n                raise NotImplementedError  # nlmsg_set_creds(msg, creds)\n            nrecv += 1\n\n            # Raw callback is the first, it gives the most control to the user and he can do his very own parsing.\n            if cb.cb_set[NL_CB_MSG_IN]:\n                err = nl_cb_call(cb, NL_CB_MSG_IN, msg)  # NL_CB_CALL(cb, NL_CB_MSG_IN, msg)\n                if err == NL_OK:\n                    pass\n                elif err == NL_SKIP:\n                    hdr = nlmsg_next(hdr, n)\n                    continue\n                elif err == NL_STOP:\n                    return -NLE_DUMP_INTR if interrupted else nrecv\n                else:\n                    return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n\n            if cb.cb_set[NL_CB_SEQ_CHECK]:\n                # Sequence number checking. The check may be done by the user, otherwise a very simple check is applied\n                # enforcing strict ordering.\n                err = nl_cb_call(cb, NL_CB_SEQ_CHECK, msg)  # NL_CB_CALL(cb, NL_CB_SEQ_CHECK, msg)\n                if err == NL_OK:\n                    pass\n                elif err == NL_SKIP:\n                    hdr = nlmsg_next(hdr, n)\n                    continue\n                elif err == NL_STOP:\n                    return -NLE_DUMP_INTR if interrupted else nrecv\n                else:\n                    return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n            elif not sk.s_flags & NL_NO_AUTO_ACK:\n                # Only do sequence checking if auto-ack mode is enabled.\n                if hdr.nlmsg_seq != sk.s_seq_expect:\n                    if cb.cb_set[NL_CB_INVALID]:\n                        err = nl_cb_call(cb, NL_CB_INVALID, msg)  # NL_CB_CALL(cb, NL_CB_INVALID, msg)\n                        if err == NL_OK:\n                            pass\n                        elif err == NL_SKIP:\n                            hdr = nlmsg_next(hdr, n)\n                            continue\n                        elif err == NL_STOP:\n                            return -NLE_DUMP_INTR if interrupted else nrecv\n                        else:\n                            return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n                    else:\n                        return -NLE_SEQ_MISMATCH\n\n            if hdr.nlmsg_type in (NLMSG_DONE, NLMSG_ERROR, NLMSG_NOOP, NLMSG_OVERRUN):\n                # We can't check for !NLM_F_MULTI since some Netlink users in the kernel are broken.\n                sk.s_seq_expect += 1\n                _LOGGER.debug('recvmsgs(0x%x): Increased expected sequence number to %d', id(sk), sk.s_seq_expect)\n\n            if hdr.nlmsg_flags & NLM_F_MULTI:\n                multipart = 1\n\n            if hdr.nlmsg_flags & NLM_F_DUMP_INTR:\n                if cb.cb_set[NL_CB_DUMP_INTR]:\n                    err = nl_cb_call(cb, NL_CB_DUMP_INTR, msg)  # NL_CB_CALL(cb, NL_CB_DUMP_INTR, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n                else:\n                    # We have to continue reading to clear all messages until a NLMSG_DONE is received and report the\n                    # inconsistency.\n                    interrupted = 1\n\n            if hdr.nlmsg_flags & NLM_F_ACK:\n                # Other side wishes to see an ack for this message.\n                if cb.cb_set[NL_CB_SEND_ACK]:\n                    err = nl_cb_call(cb, NL_CB_SEND_ACK, msg)  # NL_CB_CALL(cb, NL_CB_SEND_ACK, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n\n            if hdr.nlmsg_type == NLMSG_DONE:\n                # Messages terminates a multipart message, this is usually the end of a message and therefore we slip\n                # out of the loop by default. the user may overrule this action by skipping this packet.\n                multipart = 0\n                if cb.cb_set[NL_CB_FINISH]:\n                    err = nl_cb_call(cb, NL_CB_FINISH, msg)  # NL_CB_CALL(cb, NL_CB_FINISH, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n            elif hdr.nlmsg_type == NLMSG_NOOP:\n                # Message to be ignored, the default action is to skip this message if no callback is specified. The\n                # user may overrule this action by returning NL_PROCEED.\n                if cb.cb_set[NL_CB_SKIPPED]:\n                    err = nl_cb_call(cb, NL_CB_SKIPPED, msg)  # NL_CB_CALL(cb, NL_CB_SKIPPED, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n                else:\n                    hdr = nlmsg_next(hdr, n)\n                    continue\n            elif hdr.nlmsg_type == NLMSG_OVERRUN:\n                # Data got lost, report back to user. The default action is to quit parsing. The user may overrule this\n                # action by retuning NL_SKIP or NL_PROCEED (dangerous).\n                if cb.cb_set[NL_CB_OVERRUN]:\n                    err = nl_cb_call(cb, NL_CB_OVERRUN, msg)  # NL_CB_CALL(cb, NL_CB_OVERRUN, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n                else:\n                    return -NLE_DUMP_INTR if interrupted else -NLE_MSG_OVERFLOW\n            elif hdr.nlmsg_type == NLMSG_ERROR:\n                # Message carries a nlmsgerr.\n                e = nlmsgerr(nlmsg_data(hdr))\n                if hdr.nlmsg_len < nlmsg_size(e.SIZEOF):\n                    # Truncated error message, the default action is to stop parsing. The user may overrule this action\n                    # by returning NL_SKIP or NL_PROCEED (dangerous).\n                    if cb.cb_set[NL_CB_INVALID]:\n                        err = nl_cb_call(cb, NL_CB_INVALID, msg)  # NL_CB_CALL(cb, NL_CB_INVALID, msg)\n                        if err == NL_OK:\n                            pass\n                        elif err == NL_SKIP:\n                            hdr = nlmsg_next(hdr, n)\n                            continue\n                        elif err == NL_STOP:\n                            return -NLE_DUMP_INTR if interrupted else nrecv\n                        else:\n                            return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else -NLE_MSG_TRUNC\n                elif e.error:\n                    # Error message reported back from kernel.\n                    if cb.cb_err:\n                        err = cb.cb_err(nla, e, cb.cb_err_arg)\n                        if err < 0:\n                            return -NLE_DUMP_INTR if interrupted else err\n                        elif err == NL_SKIP:\n                            hdr = nlmsg_next(hdr, n)\n                            continue\n                        elif err == NL_STOP:\n                            return -NLE_DUMP_INTR if interrupted else -nl_syserr2nlerr(e.error)\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else -nl_syserr2nlerr(e.error)\n                elif cb.cb_set[NL_CB_ACK]:\n                    err = nl_cb_call(cb, NL_CB_ACK, msg)  # NL_CB_CALL(cb, NL_CB_ACK, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n            else:\n                # Valid message (not checking for MULTIPART bit to get along with broken kernels. NL_SKIP has no effect\n                # on this.\n                if cb.cb_set[NL_CB_VALID]:\n                    err = nl_cb_call(cb, NL_CB_VALID, msg)  # NL_CB_CALL(cb, NL_CB_VALID, msg)\n                    if err == NL_OK:\n                        pass\n                    elif err == NL_SKIP:\n                        hdr = nlmsg_next(hdr, n)\n                        continue\n                    elif err == NL_STOP:\n                        return -NLE_DUMP_INTR if interrupted else nrecv\n                    else:\n                        return -NLE_DUMP_INTR if interrupted else (err or nrecv)\n\n            hdr = nlmsg_next(hdr, n)\n\n        del buf[:]\n        creds = None\n\n        if multipart:\n            # Multipart message not yet complete, continue reading.\n            continue\n\n        err = 0\n        if interrupted:\n            return -NLE_DUMP_INTR\n        if not err:\n            err = nrecv\n        return err", "response": "Read and parse Netlink messages from a Netlink socket."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nl_recvmsgs_report(sk, cb):\n    if cb.cb_recvmsgs_ow:\n        return int(cb.cb_recvmsgs_ow(sk, cb))\n    return int(recvmsgs(sk, cb))", "response": "Receive a set of messages from a Netlink socket and report parsed messages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving a set of Netlink messages from a Netlink socket.", "response": "def nl_recvmsgs(sk, cb):\n    \"\"\"Receive a set of messages from a Netlink socket.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L1023\n\n    Repeatedly calls nl_recv() or the respective replacement if provided by the application (see nl_cb_overwrite_recv())\n    and parses the received data as Netlink messages. Stops reading if one of the callbacks returns NL_STOP or nl_recv\n    returns either 0 or a negative error code.\n\n    A non-blocking sockets causes the function to return immediately if no data is available.\n\n    See nl_recvmsgs_report().\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n    cb -- set of callbacks to control behaviour (nl_cb class instance).\n\n    Returns:\n    0 on success or a negative error code from nl_recv().\n    \"\"\"\n    err = nl_recvmsgs_report(sk, cb)\n    if err > 0:\n        return 0\n    return int(err)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until an ACK is received for the latest not yet acknowledged Netlink message.", "response": "def nl_wait_for_ack(sk):\n    \"\"\"Wait for ACK.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/nl.c#L1058\n\n    Waits until an ACK is received for the latest not yet acknowledged Netlink message.\n\n    Positional arguments:\n    sk -- Netlink socket (nl_sock class instance).\n\n    Returns:\n    Number of received messages or a negative error code from nl_recvmsgs().\n    \"\"\"\n    cb = nl_cb_clone(sk.s_cb)\n    nl_cb_set(cb, NL_CB_ACK, NL_CB_CUSTOM, lambda *_: NL_STOP, None)\n    return int(nl_recvmsgs(sk, cb))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _nl_list_add(obj, prev, next_):\n    prev.next_ = obj\n    obj.prev = prev\n    next_.prev = obj\n    obj.next_ = next_", "response": "Add a new item to the end of a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an item from the list.", "response": "def nl_list_del(obj):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink/list.h#L49.\n\n    Positional arguments:\n    obj -- nl_list_head class instance.\n    \"\"\"\n    obj.next.prev = obj.prev\n    obj.prev.next_ = obj.next_"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list entry.", "response": "def nl_list_entry(ptr, type_, member):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink/list.h#L64.\"\"\"\n    if ptr.container_of:\n        return ptr.container_of\n    null_data = type_()\n    setattr(null_data, member, ptr)\n    return null_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts type to string.", "response": "def __type2str(type_, buf, _, tbl):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/utils.c#L968.\n\n    Positional arguments:\n    type_ -- integer, key to lookup in `tbl`.\n    buf -- bytearray().\n    _ -- unused.\n    tbl -- dict.\n\n    Returns:\n    Reference to `buf`.\n    \"\"\"\n    del buf[:]\n    if type_ in tbl:\n        buf.extend(tbl[type_].encode('ascii'))\n    else:\n        buf.extend('0x{0:x}'.format(type_).encode('ascii'))\n    return buf"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the result records into a single - element list.", "response": "def _stringifyResultRecords(self, struct):\n    '''\n    The Partner WSDL defines result element not defined in the \"SObject\"\n    section of the Partner WSDL as <any/> elements, which get unmarshalled by\n    suds into single-element lists.  We prefer that they are strings, so we'll \n    convert structures like\n\n[(records){\n   type = \"Contact\"\n   Id = \"003000000000000000\"\n   Account[] = \n      (Account){\n         type = \"Account\"\n         Id = \"001000000000000000\"\n         Name[] = \n            \"Acme\",\n      },\n   FirstName[] = \n      \"Wile E.\",\n   LastName[] = \n      \"Coyote\",\n }]\n\n    to\n\n[(records){\n   type = \"Contact\"\n   Id = \"003000000000000000\"\n   Account = \n      (Account){\n         type = \"Account\"\n         Id = \"001000000000000000\"\n         Name = \"Acme\"\n      }\n   FirstName = \"Wile E.\"\n   LastName = \"Coyote\"\n }]\n\n    and\n\nsearchRecords[] = \n      (searchRecords){\n         record = \n            (record){\n               type = \"Lead\"\n               Id = None\n               Name[] = \n                  \"Single User\",\n               Phone[] = \n                  \"(617) 555-1212\",\n            }\n      },\n\n    to\n\nsearchRecords[] = \n      (searchRecords){\n         record = \n            (record){\n               type = \"Lead\"\n               Id = None\n               Name = \"Single User\",\n               Phone = \"(617) 555-1212\",\n            }\n      },\n    '''\n    if not isinstance(struct, list):\n      struct = [struct]\n      originallyList = False\n    else:\n      originallyList = True\n\n    for record in struct:\n      for k, v in record:\n        if isinstance(v, list):\n          # At this point, we don't know whether a value of [] corresponds to '' or None\n          # However, anecdotally I've been unable to find a field type whose 'empty' value\n          # returns anything other that <sf:FieldNameHere xsi:nil=\"true\"/>\n          # so, for now, we'll set it to None\n          if v == []:\n            setattr(record, k, None)\n          else:\n            # Note that without strong typing there's no way to tell the difference between the \n            # string 'false' and the bool false.  We get <sf:DoNotCall>false</sf:DoNotCall>.\n            # We have to assume strings for everything other than 'Id' and 'type', which are\n            # defined types in the Partner WSDL.\n\t\n            # values that are objects may (query()) or may not (search()) be wrapped in a list\n            # so, remove from nested list first before calling ourselves recursively (if necessary)\n            setattr(record, k, v[0])\n        \n        # refresh v\n        v = getattr(record, k)\n\n        if isinstance(v, suds.sudsobject.Object):\n          v = self._stringifyResultRecords(v)\n          setattr(record, k, v)\n    if originallyList:\n      return struct\n    else:\n      return struct[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites out symbol tables to project s config. symbols directory", "response": "def index_apex_symbols(self, apex_class_name_or_names=None):\n        '''\n            Writes out symbol tables to project's config/.symbols directory\n        '''\n        \n        try:\n            if not os.path.exists(os.path.join(self.location,\"config\",\".symbols\")):\n                os.makedirs(os.path.join(self.location,\"config\",\".symbols\"))\n            \n            symbol_table_result = {\n                \"records\" : []\n            }\n\n            if apex_class_name_or_names == None:\n                apex_ids = []\n                classes = self.sfdc_client.list_metadata(\"ApexClass\", True)\n                for c in classes:\n                    apex_ids.append(c['id'])\n\n                list_of_apex_id_lists = list(util.list_grouper(20, apex_ids)) #split apex ids into lists of max size 20\n                for apex_ids_list in list_of_apex_id_lists:                    \n                    local_symbol_table_result = self.sfdc_client.get_symbol_tables_by_class_id(apex_ids_list)\n                    if 'records' in local_symbol_table_result and len(local_symbol_table_result['records']) > 0:\n                        symbol_table_result['records'] = symbol_table_result['records'] + local_symbol_table_result['records']\n            else:\n                class_names = []\n                if type(apex_class_name_or_names) is not list:\n                    apex_class_name_or_names = [apex_class_name_or_names]\n\n                for class_name in apex_class_name_or_names:\n                    apex_class_name = os.path.basename(class_name)\n                    apex_class_name = apex_class_name.replace(\".cls\",\"\")\n                    class_names.append(apex_class_name)\n\n                list_of_apex_class_name_lists = list(util.list_grouper(20, class_names)) #split apex ids into lists of max size 20\n                for apex_class_names_list in list_of_apex_class_name_lists:                    \n                    local_symbol_table_result = self.sfdc_client.get_symbol_tables_by_class_name(apex_class_names_list)\n                    if 'records' in local_symbol_table_result and len(local_symbol_table_result['records']) > 0:\n                        symbol_table_result['records'] = symbol_table_result['records'] + local_symbol_table_result['records']\n\n            if 'records' in symbol_table_result and len(symbol_table_result['records']) > 0:\n                for r in symbol_table_result['records']:\n                    if \"SymbolTable\" in r and r[\"SymbolTable\"] != None and r[\"SymbolTable\"] != {}:\n                        file_name = \"\"\n                        if \"NamespacePrefix\" in r and r[\"NamespacePrefix\"] != None:\n                            file_name = r[\"NamespacePrefix\"]+\".\"+r[\"Name\"]+\".json\"\n                        else:\n                            file_name = r[\"Name\"]+\".json\"\n                        src = open(os.path.join(self.location,\"config\",\".symbols\",file_name), \"w\")\n                        json_data = json.dumps(r[\"SymbolTable\"], indent=4)\n                        src.write(json_data)\n                        src.close()\n\n            return util.generate_success_response(\"Apex symbols indexed successfully\")\n        #except (TypeError):\n        except BaseException, e:\n            debug('------> error indexing apex symbols')\n            debug(e.message)\n\n            directories = []\n            if os.path.exists(os.path.join(self.location, 'src', 'classes')):\n                directories.append(os.path.join(self.location, 'src', 'classes'))\n\n            if os.path.exists(os.path.join(self.location, 'src', 'triggers')):\n                directories.append(os.path.join(self.location, 'src', 'triggers'))\n\n            params = {\n                'files'         : [],\n                'directories'   : directories\n            }\n            retrieve_result = self.get_retrieve_result(params)\n            fileProperties = retrieve_result.fileProperties\n            apex_ids = []\n            for prop in fileProperties:\n                if prop.type == \"ApexClass\":\n                    apex_ids.append(prop.id)   \n            symbol_table_result = self.sfdc_client.get_symbol_table(apex_ids)\n            debug(symbol_table_result)\n            if 'records' in symbol_table_result and len(symbol_table_result['records']) > 0:\n                for r in symbol_table_result['records']:\n                    if \"SymbolTable\" in r and r[\"SymbolTable\"] != None and r[\"SymbolTable\"] != {}:\n                        file_name = \"\"\n                        if \"NamespacePrefix\" in r and r[\"NamespacePrefix\"] != None:\n                            file_name = r[\"NamespacePrefix\"]+\".\"+r[\"Name\"]+\".json\"\n                        else:\n                            file_name = r[\"ContentEntity\"][\"Name\"]+\".json\"\n                        src = open(os.path.join(self.location,\"config\",\".symbols\",file_name), \"w\")\n                        json_data = json.dumps(r[\"SymbolTable\"], indent=4)\n                        src.write(json_data)\n                        src.close()\n\n            return util.generate_success_response(\"Apex symbols indexed successfully\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the settings from the plugin client.", "response": "def get_plugin_client_settings(self):\n        settings = {}\n        user_path = self.get_plugin_settings_path(\"User\")\n        def_path = self.get_plugin_settings_path(\"MavensMate\")\n\n        '''\n            if the default path for settings is none, we're either dealing with a bad client setup or\n            a new client like Atom.io. Let's load the settings from the default cache and optionally allow \n            them to pipe settings in via STDIN\n        '''\n        if def_path == None:\n            if 'ATOM' in self.plugin_client:\n                file_name = 'atom'\n            elif 'SUBLIME_TEXT' in self.plugin_client:\n                file_name = 'st3'\n            elif 'BRACKETS' in self.plugin_client:\n                file_name = 'brackets'\n            settings['default'] = util.parse_json_from_file(config.base_path + \"/\"+config.support_dir+\"/config/\"+file_name+\".json\")\n\n            if config.plugin_client_settings != None:\n                settings['user'] = config.plugin_client_settings\n        else:\n            workspace = self.params.get('workspace', None)\n            if self.project_name != None and workspace != None:\n                try:\n                    settings['project'] = util.parse_json_from_file(os.path.join(workspace,self.project_name,self.project_name+'.sublime-settings'))\n                except:\n                    debug('Project settings could not be loaded')\n            if not user_path == None:\n                try:\n                    settings['user'] = util.parse_json_from_file(user_path)\n                except:\n                    debug('User settings could not be loaded')\n            if not def_path == None:\n                try:\n                    settings['default'] = util.parse_json_from_file(def_path)\n                except:\n                    raise MMException('Could not load default MavensMate settings.')\n        if settings == {}:\n            raise MMException('Could not load MavensMate settings. Please ensure they contain valid JSON')\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nlmsg_for_each_attr(nlh, hdrlen, rem):\n    return nla_for_each_attr(nlmsg_attrdata(nlh, hdrlen), nlmsg_attrlen(nlh, hdrlen), rem)", "response": "Iterate over a stream of attributes in a Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the first attribute of a Netlink message.", "response": "def nlmsg_attrdata(nlh, hdrlen):\n    \"\"\"Head of attributes data.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L143\n\n    Positional arguments:\n    nlh -- Netlink message header (nlmsghdr class instance).\n    hdrlen -- length of family specific header (integer).\n\n    Returns:\n    First attribute (nlattr class instance with others in its payload).\n    \"\"\"\n    data = nlmsg_data(nlh)\n    return libnl.linux_private.netlink.nlattr(bytearray_ptr(data, libnl.linux_private.netlink.NLMSG_ALIGN(hdrlen)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nlmsg_attrlen(nlh, hdrlen):\n    return max(nlmsg_len(nlh) - libnl.linux_private.netlink.NLMSG_ALIGN(hdrlen), 0)", "response": "Length of attributes data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the Netlink message fits into the remaining bytes.", "response": "def nlmsg_ok(nlh, remaining):\n    \"\"\"Check if the Netlink message fits into the remaining bytes.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L179\n\n    Positional arguments:\n    nlh -- Netlink message header (nlmsghdr class instance).\n    remaining -- number of bytes remaining in message stream (c_int).\n\n    Returns:\n    Boolean.\n    \"\"\"\n    sizeof = libnl.linux_private.netlink.nlmsghdr.SIZEOF\n    return remaining.value >= sizeof and sizeof <= nlh.nlmsg_len <= remaining.value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nlmsg_next(nlh, remaining):\n    totlen = libnl.linux_private.netlink.NLMSG_ALIGN(nlh.nlmsg_len)\n    remaining.value -= totlen\n    return libnl.linux_private.netlink.nlmsghdr(bytearray_ptr(nlh.bytearray, totlen))", "response": "Returns the next Netlink message in message stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing attributes of a Netlink message.", "response": "def nlmsg_parse(nlh, hdrlen, tb, maxtype, policy):\n    \"\"\"Parse attributes of a Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L213\n\n    Positional arguments:\n    nlh -- Netlink message header (nlmsghdr class instance).\n    hdrlen -- length of family specific header (integer).\n    tb -- dictionary of nlattr instances (length of maxtype+1).\n    maxtype -- maximum attribute type to be expected (integer).\n    policy -- validation policy (nla_policy class instance).\n\n    Returns:\n    0 on success or a negative error code.\n    \"\"\"\n    if not nlmsg_valid_hdr(nlh, hdrlen):\n        return -NLE_MSG_TOOSHORT\n    return nla_parse(tb, maxtype, nlmsg_attrdata(nlh, hdrlen), nlmsg_attrlen(nlh, hdrlen), policy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a specific attribute in a Netlink message.", "response": "def nlmsg_find_attr(nlh, hdrlen, attrtype):\n    \"\"\"Find a specific attribute in a Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L231\n\n    Positional arguments:\n    nlh -- Netlink message header (nlmsghdr class instance).\n    hdrlen -- length of family specific header (integer).\n    attrtype -- type of attribute to look for (integer).\n\n    Returns:\n    The first attribute which matches the specified type (nlattr class instance).\n    \"\"\"\n    return nla_find(nlmsg_attrdata(nlh, hdrlen), nlmsg_attrlen(nlh, hdrlen), attrtype)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nlmsg_alloc(len_=default_msg_size):\n    len_ = max(libnl.linux_private.netlink.nlmsghdr.SIZEOF, len_)\n    nm = nl_msg()\n    nm.nm_refcnt = 1\n    nm.nm_nlh = libnl.linux_private.netlink.nlmsghdr(bytearray(b'\\0') * len_)\n    nm.nm_protocol = -1\n    nm.nm_size = len_\n    nm.nm_nlh.nlmsg_len = nlmsg_total_size(0)\n    _LOGGER.debug('msg 0x%x: Allocated new message, maxlen=%d', id(nm), len_)\n    return nm", "response": "Allocate a new Netlink message with maximum payload size specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nlmsg_inherit(hdr=None):\n    nm = nlmsg_alloc()\n    if hdr:\n        new = nm.nm_nlh\n        new.nlmsg_type = hdr.nlmsg_type\n        new.nlmsg_flags = hdr.nlmsg_flags\n        new.nlmsg_seq = hdr.nlmsg_seq\n        new.nlmsg_pid = hdr.nlmsg_pid\n    return nm", "response": "Allocate a new Netlink message and inherit Netlink message header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallocating a new Netlink message.", "response": "def nlmsg_alloc_simple(nlmsgtype, flags):\n    \"\"\"Allocate a new Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L346\n\n    Positional arguments:\n    nlmsgtype -- Netlink message type (integer).\n    flags -- message flags (integer).\n\n    Returns:\n    Newly allocated Netlink message (nl_msg class instance) or None.\n    \"\"\"\n    nlh = libnl.linux_private.netlink.nlmsghdr(nlmsg_type=nlmsgtype, nlmsg_flags=flags)\n    msg = nlmsg_inherit(nlh)\n    _LOGGER.debug('msg 0x%x: Allocated new simple message', id(msg))\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nlmsg_convert(hdr):\n    nm = nlmsg_alloc(hdr.nlmsg_len)\n    if not nm:\n        return None\n    nm.nm_nlh.bytearray = hdr.bytearray.copy()[:hdr.nlmsg_len]\n    return nm", "response": "Convert a Netlink message received from a Netlink socket to an nl_msg."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nlmsg_reserve(n, len_, pad):\n    nlmsg_len_ = n.nm_nlh.nlmsg_len\n    tlen = len_ if not pad else ((len_ + (pad - 1)) & ~(pad - 1))\n\n    if tlen + nlmsg_len_ > n.nm_size:\n        return None\n\n    buf = bytearray_ptr(n.nm_nlh.bytearray, nlmsg_len_)\n    n.nm_nlh.nlmsg_len += tlen\n    if tlen > len_:\n        bytearray_ptr(buf, len_, tlen)[:] = bytearray(b'\\0') * (tlen - len_)\n\n    _LOGGER.debug('msg 0x%x: Reserved %d (%d) bytes, pad=%d, nlmsg_len=%d', id(n), tlen, len_, pad, n.nm_nlh.nlmsg_len)\n    return buf", "response": "Reserve room for additional data in a Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nlmsg_append(n, data, len_, pad):\n    tmp = nlmsg_reserve(n, len_, pad)\n    if tmp is None:\n        return -NLE_NOMEM\n    tmp[:len_] = data.bytearray[:len_]\n    _LOGGER.debug('msg 0x%x: Appended %d bytes with padding %d', id(n), len_, pad)\n    return 0", "response": "Append data to the tail of a Netlink message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a Netlink message header to an existing Netlink message.", "response": "def nlmsg_put(n, pid, seq, type_, payload, flags):\n    \"\"\"Add a Netlink message header to a Netlink message.\n\n    https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L503\n\n    Adds or overwrites the Netlink message header in an existing message object.\n\n    Positional arguments:\n    n -- Netlink message (nl_msg class instance).\n    pid -- Netlink process id or NL_AUTO_PID (c_uint32).\n    seq -- sequence number of message or NL_AUTO_SEQ (c_uint32).\n    type_ -- message type (integer).\n    payload -- length of message payload (integer).\n    flags -- message flags (integer).\n\n    Returns:\n    nlmsghdr class instance or None.\n    \"\"\"\n    if n.nm_nlh.nlmsg_len < libnl.linux_private.netlink.NLMSG_HDRLEN:\n        raise BUG\n\n    nlh = n.nm_nlh\n    nlh.nlmsg_type = type_\n    nlh.nlmsg_flags = flags\n    nlh.nlmsg_pid = pid\n    nlh.nlmsg_seq = seq\n\n    _LOGGER.debug('msg 0x%x: Added netlink header type=%d, flags=%d, pid=%d, seq=%d', id(n), type_, flags, pid, seq)\n\n    if payload > 0 and nlmsg_reserve(n, payload, libnl.linux_private.netlink.NLMSG_ALIGNTO) is None:\n        return None\n\n    return nlh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_hex(ofd, start, len_, prefix=0):\n    prefix_whitespaces = '  ' * prefix\n    limit = 16 - (prefix * 2)\n    start_ = start[:len_]\n    for line in (start_[i:i + limit] for i in range(0, len(start_), limit)):  # stackoverflow.com/a/9475354/1198943\n        hex_lines, ascii_lines = list(), list()\n        for c in line:\n            hex_lines.append('{0:02x}'.format(c if hasattr(c, 'real') else ord(c)))\n            c2 = chr(c) if hasattr(c, 'real') else c\n            ascii_lines.append(c2 if c2 in string.printable[:95] else '.')\n        hex_line = ' '.join(hex_lines).ljust(limit * 3)\n        ascii_line = ''.join(ascii_lines)\n        ofd('    %s%s%s', prefix_whitespaces, hex_line, ascii_line)", "response": "Convert start to hex and logs it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_hdr(ofd, msg):\n    nlh = nlmsg_hdr(msg)\n    buf = bytearray()\n\n    ofd('    .nlmsg_len = %d', nlh.nlmsg_len)\n\n    ops = nl_cache_ops_associate_safe(msg.nm_protocol, nlh.nlmsg_type)\n    if ops:\n        mt = nl_msgtype_lookup(ops, nlh.nlmsg_type)\n        if not mt:\n            raise BUG\n        buf.extend('{0}::{1}'.format(ops.co_name, mt.mt_name).encode('ascii'))\n    else:\n        nl_nlmsgtype2str(nlh.nlmsg_type, buf, 128)\n\n    ofd('    .type = %d <%s>', nlh.nlmsg_type, buf.decode('ascii'))\n    ofd('    .flags = %d <%s>', nlh.nlmsg_flags, nl_nlmsg_flags2str(nlh.nlmsg_flags, buf, 128).decode('ascii'))\n    ofd('    .seq = %d', nlh.nlmsg_seq)\n    ofd('    .port = %d', nlh.nlmsg_pid)", "response": "Print the message header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the genl message header.", "response": "def print_genl_hdr(ofd, start):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L821.\n\n    Positional arguments:\n    ofd -- function to call with arguments similar to `logging.debug`.\n    start -- bytearray() or bytearray_ptr() instance.\n    \"\"\"\n    ghdr = genlmsghdr(start)\n    ofd('  [GENERIC NETLINK HEADER] %d octets', GENL_HDRLEN)\n    ofd('    .cmd = %d', ghdr.cmd)\n    ofd('    .version = %d', ghdr.version)\n    ofd('    .unused = %#d', ghdr.reserved)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a message in a new genl format.", "response": "def print_genl_msg(_, ofd, hdr, ops, payloadlen):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L831.\n\n    Positional arguments:\n    _ -- unused.\n    ofd -- function to call with arguments similar to `logging.debug`.\n    hdr -- Netlink message header (nlmsghdr class instance).\n    ops -- cache operations (nl_cache_ops class instance).\n    payloadlen -- length of payload in message (ctypes.c_int instance).\n\n    Returns:\n    data (bytearray_ptr).\n    \"\"\"\n    data = nlmsg_data(hdr)\n    if payloadlen.value < GENL_HDRLEN:\n        return data\n\n    print_genl_hdr(ofd, data)\n    payloadlen.value -= GENL_HDRLEN\n    data = bytearray_ptr(data, GENL_HDRLEN)\n\n    if ops:\n        hdrsize = ops.co_hdrsize - GENL_HDRLEN\n        if hdrsize > 0:\n            if payloadlen.value < hdrsize:\n                return data\n            ofd('  [HEADER] %d octets', hdrsize)\n            dump_hex(ofd, data, hdrsize, 0)\n            payloadlen.value -= hdrsize\n            data = bytearray_ptr(data, hdrsize)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping a Netlink attribute.", "response": "def dump_attr(ofd, attr, prefix=0):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L862.\n\n    Positional arguments:\n    ofd -- function to call with arguments similar to `logging.debug`.\n    attr -- nlattr class instance.\n\n    Keyword arguments:\n    prefix -- additional number of whitespace pairs to prefix each log statement with.\n    \"\"\"\n    dump_hex(ofd, nla_data(attr), nla_len(attr), prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the attributes of a log message.", "response": "def dump_attrs(ofd, attrs, attrlen, prefix=0):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L869.\n\n    Positional arguments:\n    ofd -- function to call with arguments similar to `logging.debug`.\n    attrs -- nlattr class instance.\n    attrlen -- length of payload (integer).\n\n    Keyword arguments:\n    prefix -- additional number of whitespace pairs to prefix each log statement with.\n    \"\"\"\n    prefix_whitespaces = '  ' * prefix\n    rem = c_int()\n    for nla in nla_for_each_attr(attrs, attrlen, rem):\n        alen = nla_len(nla)\n        if nla.nla_type == 0:\n            ofd('%s  [ATTR PADDING] %d octets', prefix_whitespaces, alen)\n        else:\n            is_nested = ' NESTED' if nla_is_nested(nla) else ''\n            ofd('%s  [ATTR %02d%s] %d octets', prefix_whitespaces, nla.nla_type, is_nested, alen)\n\n        if nla_is_nested(nla):\n            dump_attrs(ofd, nla_data(nla), alen, prefix + 1)\n        else:\n            dump_attr(ofd, nla, prefix)\n\n        padlen = nla_padlen(alen)\n        if padlen > 0:\n            ofd('%s  [PADDING] %d octets', prefix_whitespaces, padlen)\n            dump_hex(ofd, bytearray_ptr(nla_data(nla), alen), padlen, prefix)\n\n    if rem.value:\n        ofd('%s  [LEFTOVER] %d octets', prefix_whitespaces, rem)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump an error message to the log.", "response": "def dump_error_msg(msg, ofd=_LOGGER.debug):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L908.\n\n    Positional arguments:\n    msg -- message to print (nl_msg class instance).\n\n    Keyword arguments:\n    ofd -- function to call with arguments similar to `logging.debug`.\n    \"\"\"\n    hdr = nlmsg_hdr(msg)\n    err = libnl.linux_private.netlink.nlmsgerr(nlmsg_data(hdr))\n\n    ofd('  [ERRORMSG] %d octets', err.SIZEOF)\n\n    if nlmsg_len(hdr) >= err.SIZEOF:\n        ofd('    .error = %d \"%s\"', err.error, os.strerror(-err.error))\n        ofd('  [ORIGINAL MESSAGE] %d octets', hdr.SIZEOF)\n        errmsg = nlmsg_inherit(err.msg)\n        print_hdr(ofd, errmsg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints Netlink message to stdout.", "response": "def print_msg(msg, ofd, hdr):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/msg.c#L929.\n\n    Positional arguments:\n    msg -- Netlink message (nl_msg class instance).\n    ofd -- function to call with arguments similar to `logging.debug`.\n    hdr -- Netlink message header (nlmsghdr class instance).\n    \"\"\"\n    payloadlen = c_int(nlmsg_len(hdr))\n    attrlen = 0\n    data = nlmsg_data(hdr)\n    ops = nl_cache_ops_associate_safe(msg.nm_protocol, hdr.nlmsg_type)\n    if ops:\n        attrlen = nlmsg_attrlen(hdr, ops.co_hdrsize)\n        payloadlen.value -= attrlen\n    if msg.nm_protocol == libnl.linux_private.netlink.NETLINK_GENERIC:\n        data = print_genl_msg(msg, ofd, hdr, ops, payloadlen)\n    if payloadlen.value:\n        ofd('  [PAYLOAD] %d octets', payloadlen.value)\n        dump_hex(ofd, data, payloadlen.value, 0)\n    if attrlen:\n        attrs = nlmsg_attrdata(hdr, ops.co_hdrsize)\n        attrlen = nlmsg_attrlen(hdr, ops.co_hdrsize)\n        dump_attrs(ofd, attrs, attrlen, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nl_msg_dump(msg, ofd=_LOGGER.debug):\n    hdr = nlmsg_hdr(msg)\n\n    ofd('--------------------------   BEGIN NETLINK MESSAGE ---------------------------')\n\n    ofd('  [NETLINK HEADER] %d octets', hdr.SIZEOF)\n    print_hdr(ofd, msg)\n\n    if hdr.nlmsg_type == libnl.linux_private.netlink.NLMSG_ERROR:\n        dump_error_msg(msg, ofd)\n    elif nlmsg_len(hdr) > 0:\n        print_msg(msg, ofd, hdr)\n\n    ofd('---------------------------  END NETLINK MESSAGE   ---------------------------')", "response": "Dump a Netlink message to a human readable format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setThirdStateChecked(src, ids=[], dpth = 0, key = ''):\n    #tabs = lambda n: ' ' * n * 4 # or 2 or 8 or...\n    #brace = lambda s, n: '%s%s%s' % ('['*n, s, ']'*n)\n    #print('third state nodes: ', third_state_nodes)\n    if isinstance(src, dict):\n        #print \"DICT: \", src\n        if 'children' in src and type(src['children']) is list and len(src['children']) > 0:\n        \tchildren = src['children']\n        \tnumber_of_possible_checked = len(children)\n        \tnumber_of_checked = 0\n        \tfor c in children:\n        \t\tif 'checked' in c and c['checked']:\n        \t\t\tnumber_of_checked += 1\n        \tif number_of_possible_checked == number_of_checked:\n        \t\tsrc['checked'] = True\n        \telif number_of_checked > 0:\n        \t\t#print('>>>>> APPENDING: ', src['id'])\n        \t\tlineage = src['id'].split('.')\n        \t\t#fun(src, lineage)\n        \t\tsrc['cls'] = 'x-tree-checkbox-checked-disabled'\n\n        for key, value in src.iteritems():\n            setThirdStateChecked(value, ids, dpth + 1, key)\n    elif isinstance(src, list):\n        for litem in src:\n            if isinstance(litem, types.DictType):\n\t            #print litem[\"id\"]\n\t            #print third_state_nodes\n\t            #if \"id\" in litem and litem[\"id\"] in third_state_nodes:\n\t            #\tlitem[\"cls\"] = 'x-tree-checkbox-checked-disabled'\n\t            pass\n            setThirdStateChecked(litem, ids, dpth + 2)", "response": "Recursively find checked item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nl_object_alloc(ops):\n    new = nl_object()\n    nl_init_list_head(new.ce_list)\n    new.ce_ops = ops\n    if ops.oo_constructor:\n        ops.oo_constructor(new)\n    _LOGGER.debug('Allocated new object 0x%x', id(new))\n    return new", "response": "Allocate a new object of kind specified by the operations handle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lookup_cmd(ops, cmd_id):\n    for i in range(ops.o_ncmds):\n        cmd = ops.o_cmds[i]\n        if cmd.c_id == cmd_id:\n            return cmd\n    return None", "response": "Returns the genl_cmd instance corresponding to the given cmd_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef genl_msg_parser(ops, who, nlh, pp):\n    if ops.co_genl is None:\n        raise BUG\n    return int(cmd_msg_parser(who, nlh, ops.co_genl, ops, pp))", "response": "https://github.com/thom311/libnl/blob/libnl3_2_25/lib/genl/mngt.c#L85.\n\n    Positional arguments:\n    ops -- nl_cache_ops class instance.\n    who -- sockaddr_nl class instance.\n    nlh -- nlmsghdr class instance.\n    pp -- nl_parser_param class instance.\n\n    Returns:\n    Integer, cmd_msg_parser() output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef genl_register_family(ops):\n    if not ops.o_name or (ops.o_cmds and ops.o_ncmds <= 0):\n        return -NLE_INVAL\n\n    if ops.o_id and lookup_family(ops.o_id):\n        return -NLE_EXIST\n\n    if lookup_family_by_name(ops.o_name):\n        return -NLE_EXIST\n\n    nl_list_add_tail(ops.o_list, genl_ops_list)\n\n    return 0", "response": "Register Generic Netlink family and associated commands."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef genl_register(ops):\n    if ops.co_protocol != NETLINK_GENERIC:\n        return -NLE_PROTO_MISMATCH\n    if ops.co_hdrsize < GENL_HDRSIZE(0):\n        return -NLE_INVAL\n    if ops.co_genl is None:\n        return -NLE_INVAL\n\n    ops.co_genl.o_cache_ops = ops\n    ops.co_genl.o_hdrsize = ops.co_hdrsize - GENL_HDRLEN\n    ops.co_genl.o_name = ops.co_msgtypes[0].mt_name\n    ops.co_genl.o_id = ops.co_msgtypes[0].mt_id\n    ops.co_msg_parser = genl_msg_parser\n\n    err = genl_register_family(ops.co_genl)\n    if err < 0:\n        return err\n    return nl_cache_mngt_register(ops)", "response": "Register Generic Netlink family backed cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self):\n        try:\n            self.__setup_connection()\n\n            #if the arg switch argument is included, the request is to launch the out of box\n            #MavensMate UI, so we generate the HTML for the UI and launch the process\n            #example: mm -o new_project --ui\n            if self.args.ui_switch == True:\n                config.logger.debug('UI operation requested, attempting to launch MavensMate UI')\n                tmp_html_file = util.generate_ui(self.operation,self.payload,self.args)\n                if config.connection.plugin_client == 'ATOM': #returning location of html file here so we can open the page inside an atom panel\n                    self.__printr(util.generate_success_response(tmp_html_file))\n                else:\n                    util.launch_ui(tmp_html_file)\n                    self.__printr(util.generate_success_response('UI Generated Successfully'))\n            \n            #non-ui command\n            else:        \n                commands = get_available_commands()\n                #debug(commands)\n                try:\n                    command_clazz = commands[self.operation](params=self.payload,args=self.args)                \n                except KeyError:\n                    raise MMUnsupportedOperationException('Could not find the operation you requested. Be sure the command is located in mm.commands, inherits from Command (found in basecommand.py) and includes an execute method.')\n                except NotImplementedError:\n                    raise MMException(\"This command is not properly implemented. Be sure it contains an 'execute' method.\")\n                self.__printr(command_clazz.execute())\n        except Exception, e:\n            self.__printr(e, is_exception=True)", "response": "Executes the requested command"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a system error code into a list of errors.", "response": "def nl_syserr2nlerr(error_):\n    \"\"\"https://github.com/thom311/libnl/blob/libnl3_2_25/lib/error.c#L84.\"\"\"\n    error_ = abs(error_)\n    legend = {\n        errno.EBADF: libnl.errno_.NLE_BAD_SOCK,\n        errno.EADDRINUSE: libnl.errno_.NLE_EXIST,\n        errno.EEXIST: libnl.errno_.NLE_EXIST,\n        errno.EADDRNOTAVAIL: libnl.errno_.NLE_NOADDR,\n        errno.ESRCH: libnl.errno_.NLE_OBJ_NOTFOUND,\n        errno.ENOENT: libnl.errno_.NLE_OBJ_NOTFOUND,\n        errno.EINTR: libnl.errno_.NLE_INTR,\n        errno.EAGAIN: libnl.errno_.NLE_AGAIN,\n        errno.ENOTSOCK: libnl.errno_.NLE_BAD_SOCK,\n        errno.ENOPROTOOPT: libnl.errno_.NLE_INVAL,\n        errno.EFAULT: libnl.errno_.NLE_INVAL,\n        errno.EACCES: libnl.errno_.NLE_NOACCESS,\n        errno.EINVAL: libnl.errno_.NLE_INVAL,\n        errno.ENOBUFS: libnl.errno_.NLE_NOMEM,\n        errno.ENOMEM: libnl.errno_.NLE_NOMEM,\n        errno.EAFNOSUPPORT: libnl.errno_.NLE_AF_NOSUPPORT,\n        errno.EPROTONOSUPPORT: libnl.errno_.NLE_PROTO_MISMATCH,\n        errno.EOPNOTSUPP: libnl.errno_.NLE_OPNOTSUPP,\n        errno.EPERM: libnl.errno_.NLE_PERM,\n        errno.EBUSY: libnl.errno_.NLE_BUSY,\n        errno.ERANGE: libnl.errno_.NLE_RANGE,\n        errno.ENODEV: libnl.errno_.NLE_NODEV,\n    }\n    return int(legend.get(error_, libnl.errno_.NLE_FAILURE))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the prediction for the alert.", "response": "def get_alert(self, alert):\n        \"\"\"\n        Recieves a day as an argument and returns the prediction for that alert\n        if is available. If not, function will return None.\n        \"\"\"\n        if alert > self.alerts_count() or self.alerts_count() is None:\n            return None\n        else:\n            return self.get()[alert-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_forecast(self, latitude, longitude):\n        reply = self.http_get(self.url_builder(latitude, longitude))\n        self.forecast = json.loads(reply)\n\n        for item in self.forecast.keys():\n            setattr(self, item, self.forecast[item])", "response": "Gets the weather data from darksky api and stores it in \n        the respective dictionaries if available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_forecast_fromstr(self, reply):\n        self.forecast = json.loads(reply)\n\n        for item in self.forecast.keys():\n            setattr(self, item, self.forecast[item])", "response": "Gets the weather data from a darksky api response string\n        and stores it in the respective dictionaries if available."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _deprecated_kwargs(kwargs, arg_newarg):\n    warn_for = []\n    for (arg, new_kw) in arg_newarg:\n        if arg in kwargs.keys():\n            val = kwargs.pop(arg)\n            kwargs[new_kw] = val\n            warn_for.append((arg, new_kw))\n    if len(warn_for) > 0:\n        if len(warn_for) == 1:\n            warnings.warn(\"Argument '{}' is deprecated. Use {} instead\".\n                          format(warn_for[0][0], warn_for[0][1]),\n                          DeprecationWarning, stacklevel=4)\n        else:\n            args = \", \".join([x[0] for x in warn_for])\n            repl = \", \".join([x[1] for x in warn_for])\n            warnings.warn(\n                \"Arguments '{}' are deprecated. Use '{}' instead respectively\".\n                format(args, repl),\n                DeprecationWarning, stacklevel=4)\n    return kwargs", "response": "A function that returns kwargs that are deprecated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsharing function between parmap.map and parmap.starmap. Refer to those functions for details.", "response": "def _map_or_starmap(function, iterable, args, kwargs, map_or_starmap):\n    \"\"\"\n    Shared function between parmap.map and parmap.starmap.\n    Refer to those functions for details.\n    \"\"\"\n    arg_newarg = ((\"parallel\", \"pm_parallel\"), (\"chunksize\", \"pm_chunksize\"),\n                  (\"pool\", \"pm_pool\"), (\"processes\", \"pm_processes\"),\n                  (\"parmap_progress\", \"pm_pbar\"))\n    kwargs = _deprecated_kwargs(kwargs, arg_newarg)\n    chunksize = kwargs.pop(\"pm_chunksize\", None)\n    progress = kwargs.pop(\"pm_pbar\", False)\n    progress = progress and HAVE_TQDM\n    parallel, pool, close_pool = _create_pool(kwargs)\n    # Map:\n    if parallel:\n        func_star = _get_helper_func(map_or_starmap)\n        try:\n            if progress and close_pool:\n                try:\n                    num_tasks = len(iterable)\n                    # get a chunksize (as multiprocessing does):\n                    chunksize = _get_default_chunksize(chunksize,\n                                                       pool, num_tasks)\n                    # use map_async to get progress information\n                    result = pool.map_async(func_star,\n                                            izip(repeat(function),\n                                                 iterable,\n                                                 repeat(list(args)),\n                                                 repeat(kwargs)),\n                                            chunksize)\n                finally:\n                    pool.close()\n                # Progress bar:\n                try:\n                    _do_pbar(result, num_tasks, chunksize)\n                finally:\n                    output = result.get()\n            else:\n                result = pool.map_async(func_star,\n                                        izip(repeat(function),\n                                             iterable,\n                                             repeat(list(args)),\n                                             repeat(kwargs)),\n                                        chunksize)\n                output = result.get()\n        finally:\n            if close_pool:\n                if not progress:\n                    pool.close()\n                pool.join()\n    else:\n        output = _serial_map_or_starmap(function, iterable, args, kwargs,\n                                        progress, map_or_starmap)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a sequence of items from the given iterable.", "response": "def starmap(function, iterables, *args, **kwargs):\n    \"\"\" Equivalent to:\n            >>> return ([function(x1,x2,x3,..., args[0], args[1],...) for\n            >>>         (x1,x2,x3...) in iterable])\n\n       :param pm_parallel: Force parallelization on/off\n       :type pm_parallel: bool\n       :param pm_chunksize: see  :py:class:`multiprocessing.pool.Pool`\n       :type pm_chunksize: int\n       :param pm_pool: Pass an existing pool\n       :type pm_pool: multiprocessing.pool.Pool\n       :param pm_processes: Number of processes to use in the pool. See\n                         :py:class:`multiprocessing.pool.Pool`\n       :type pm_processes: int\n       :param pm_pbar: Show progress bar\n       :type pm_pbar: bool\n    \"\"\"\n    return _map_or_starmap(function, iterables, args, kwargs, \"starmap\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshares function between parmap. map_async and parmap. starmap_async.", "response": "def _map_or_starmap_async(function, iterable, args, kwargs, map_or_starmap):\n    \"\"\"\n    Shared function between parmap.map_async and parmap.starmap_async.\n    Refer to those functions for details.\n    \"\"\"\n    arg_newarg = ((\"parallel\", \"pm_parallel\"), (\"chunksize\", \"pm_chunksize\"),\n                  (\"pool\", \"pm_pool\"), (\"processes\", \"pm_processes\"),\n                  (\"callback\", \"pm_callback\"),\n                  (\"error_callback\", \"pm_error_callback\"))\n    kwargs = _deprecated_kwargs(kwargs, arg_newarg)\n    chunksize = kwargs.pop(\"pm_chunksize\", None)\n    callback = kwargs.pop(\"pm_callback\", None)\n    error_callback = kwargs.pop(\"pm_error_callback\", None)\n    parallel, pool, close_pool = _create_pool(kwargs)\n    # Map:\n    if parallel:\n        func_star = _get_helper_func(map_or_starmap)\n        try:\n            if sys.version_info[0] == 2:  # does not support error_callback\n                result = pool.map_async(func_star,\n                                        izip(repeat(function),\n                                             iterable,\n                                             repeat(list(args)),\n                                             repeat(kwargs)),\n                                        chunksize, callback)\n            else:\n                result = pool.map_async(func_star,\n                                        izip(repeat(function),\n                                             iterable,\n                                             repeat(list(args)),\n                                             repeat(kwargs)),\n                                        chunksize, callback, error_callback)\n        finally:\n            if close_pool:\n                pool.close()\n                result = _ParallelAsyncResult(result, pool)\n            else:\n                result = _ParallelAsyncResult(result)\n    else:\n        values = _serial_map_or_starmap(function, iterable, args, kwargs,\n                                        False, map_or_starmap)\n        result = _DummyAsyncResult(values)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_async(function, iterable, *args, **kwargs):\n    return _map_or_starmap_async(function, iterable, args, kwargs, \"map\")", "response": "This function is the multiprocessing. Pool. map_async version that supports multiple arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lookup_domain(domain, nameservers=[], rtype=\"A\",\n                  exclude_nameservers=[], timeout=2):\n    \"\"\"Wrapper for DNSQuery method\"\"\"\n    dns_exp = DNSQuery(domains=[domain], nameservers=nameservers, rtype=rtype,\n                       exclude_nameservers=exclude_nameservers, timeout=timeout)\n    return dns_exp.lookup_domain(domain)", "response": "Wrapper for DNSQuery method"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_out_ips(message):\n\n    ips = []\n    for entry in message.answer:\n        for rdata in entry.items:\n            ips.append(rdata.to_text())\n    return ips", "response": "Given a message parse out the ips in the answer"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending chaos queries to identify the DNS server and its manufacturer.", "response": "def send_chaos_queries(self):\n        \"\"\"Send chaos queries to identify the DNS server and its manufacturer\n\n        Note: we send 2 queries for BIND stuff per RFC 4892 and 1\n        query per RFC 6304\n\n        Note: we are not waiting on a second response because we\n        shouldn't be getting injected packets here\n\n        \"\"\"\n        names = [\"HOSTNAME.BIND\", \"VERSION.BIND\", \"ID.SERVER\"]\n        self.results = {'exp-name': \"chaos-queries\"}\n        for name in names:\n            self.results[name] = {}\n            for nameserver in self.nameservers:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                sock.settimeout(self.timeout)\n                query = dns.message.make_query(name,\n                                               dns.rdatatype.from_text(\"TXT\"),\n                                               dns.rdataclass.from_text(\"CH\"))\n                sock.sendto(query.to_wire(), (nameserver, 53))\n                reads, _, _ = select.select([sock], [], [], self.timeout)\n                if len(reads) == 0:\n                    self.results[name][nameserver] = None\n                else:\n                    response = reads[0].recvfrom(4096)[0]\n                    self.results[name][nameserver] = b64encode(response)\n        return self.results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self, timeout=None):\n\n        self.thread.start()\n        start_time = time.time()\n        if not timeout:\n            timeout = self.timeout\n        # every second, check the condition of the thread and return\n        # control to the user if appropriate\n        while start_time + timeout > time.time():\n            self.thread.join(1)\n            if self.started:\n                return True\n            if self.error:\n                return False\n        return False", "response": "Start running the command"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self, timeout=None):\n\n        if not timeout:\n            timeout = self.timeout\n        self.kill_switch()\n        # Send the signal to all the process groups\n        self.process.kill()\n        self.thread.join(timeout)\n        try:\n            os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)\n        except:\n            pass\n        if self.stopped:\n            return True\n        else:\n            return False", "response": "Stop the given command"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef traceroute(domain, method=\"udp\", cmd_arguments=None,\n               external=None, log_prefix=''):\n    \"\"\"\n    This function uses centinel.command to issue\n    a traceroute command, wait for it to finish execution and\n    parse the results out to a dictionary.\n\n    :param domain: the domain to be queried\n    :param method: the packet type used for traceroute, UDP by default\n    :param cmd_arguments: the list of arguments that need to be passed\n                          to traceroute.\n    :param external:\n    :param log_prefix:\n    :return:\n    \"\"\"\n\n    # the method specified by the function parameter here will\n    # over-ride the ones given in cmd_arguments because\n    # traceroute will use the last one in the argument list.\n    _cmd_arguments = []\n\n    logging.debug(\"%sRunning traceroute for \"\n                  \"%s using %s probes.\" % (log_prefix, domain, method))\n\n    results = {\"method\": method}\n\n    if cmd_arguments is not None:\n        _cmd_arguments = copy.deepcopy(cmd_arguments)\n\n    if method == \"tcp\":\n        if platform in ['linux', 'linux2']:\n            _cmd_arguments.append('-T')\n        elif platform == \"darwin\":\n            _cmd_arguments.append('-P')\n            _cmd_arguments.append('tcp')\n\n    elif method == \"udp\":\n        if platform in ['linux', 'linux2']:\n            _cmd_arguments.append('-U')\n        elif platform == \"darwin\":\n            _cmd_arguments.append('-P')\n            _cmd_arguments.append('udp')\n\n    elif method == \"icmp\":\n        if platform in ['linux', 'linux2']:\n            _cmd_arguments.append('-I')\n        elif platform == \"darwin\":\n            _cmd_arguments.append('-P')\n            _cmd_arguments.append('icmp')\n\n    cmd = ['traceroute'] + _cmd_arguments + [domain]\n\n    caller = command.Command(cmd, _traceroute_callback)\n    caller.start()\n    if not caller.started:\n        if caller.exception is not None:\n            if \"No such file or directory\" in caller.exception:\n                message = \"traceroute not found or not installed\"\n            else:\n                message = (\"traceroute thread threw an \"\n                           \"exception: %s\" % caller.exception)\n        elif \"enough privileges\" in caller.notifications:\n            message = \"not enough privileges\"\n        elif \"not known\" in caller.notifications:\n            message = \"name or service not known\"\n        else:\n            message = caller.notifications\n\n        results[\"dest_name\"] = domain\n        results[\"error\"] = message\n        if external is not None and type(external) is dict:\n            external[domain] = results\n        return results\n\n    forcefully_terminated = False\n    timeout = 60\n    start_time = time.time()\n    # check every second to see if the execution has stopped\n    while caller.thread.isAlive():\n        if (time.time() - start_time) > timeout:\n            caller.stop()\n            forcefully_terminated = True\n            break\n        time.sleep(1)\n    # we are only accurate down to seconds, so we have\n    # to round up\n    time_elapsed = int(time.time() - start_time)\n\n    output_string = caller.notifications\n\n    try:\n        parsed_output = trparse.loads(output_string)\n    except Exception as exc:\n        results[\"dest_name\"] = domain\n        results[\"error\"] = str(exc)\n        results[\"raw\"] = output_string\n        if external is not None and type(external) is dict:\n            external[domain] = results\n        return results\n\n    hops = list()\n    for hop in parsed_output.hops:\n        hop_json = {\"index\": hop.idx, \"asn\": hop.asn}\n        probes_json = []\n        for probe in hop.probes:\n            probes_json.append({\"name\": probe.name,\n                                \"ip\": probe.ip,\n                                \"rtt\": probe.rtt,\n                                \"anno\": probe.anno})\n        hop_json[\"probes\"] = probes_json\n        hops.append(hop_json)\n\n    results[\"dest_name\"] = parsed_output.dest_name\n    results[\"dest_ip\"] = parsed_output.dest_ip\n    results[\"hops\"] = hops\n    results[\"forcefully_terminated\"] = forcefully_terminated\n    results[\"time_elapsed\"] = time_elapsed\n\n    # the external result is used when threading to store\n    # the results in the list container provided.\n    if external is not None and type(external) is dict:\n        external[domain] = results\n\n    return results", "response": "This function uses centinel. command to issue a traceroute command to the specified domain and parse the results out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _traceroute_callback(self, line, kill_switch):\n\n    line = line.lower()\n    if \"traceroute to\" in line:\n        self.started = True\n    # need to run as root but not running as root.\n    # usually happens when doing TCP and ICMP traceroute.\n    if \"enough privileges\" in line:\n        self.error = True\n        self.kill_switch()\n        self.stopped = True\n    # name resolution failed\n    if \"service not known\" in line:\n        self.error = True\n        self.kill_switch()\n        self.stopped = True", "response": "Callback function to handle traceroute."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noutputs a line of OpenVPN notification to the output buffer.", "response": "def output_callback(self, line, kill_switch):\n        \"\"\"Set status of openvpn according to what we process\"\"\"\n        self.notifications += line + \"\\n\"\n\n        if \"Initialization Sequence Completed\" in line:\n            self.started = True\n        if \"ERROR:\" in line or \"Cannot resolve host address:\" in line:\n            self.error = True\n        if \"process exiting\" in line:\n            self.stopped = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart OpenVPN and block until the connection is opened or the timeout is reached.", "response": "def start(self, timeout=None):\n        \"\"\"\n        Start OpenVPN and block until the connection is opened or there is\n        an error\n        :param timeout: time in seconds to wait for process to start\n        :return:\n        \"\"\"\n        if not timeout:\n            timeout = self.timeout\n        self.thread.start()\n        start_time = time.time()\n        while start_time + timeout > time.time():\n            self.thread.join(1)\n            if self.error or self.started:\n                break\n        if self.started:\n            logging.info(\"OpenVPN connected\")\n            # append instance to connected list\n            OpenVPN.connected_instances.append(self)\n        else:\n            logging.warn(\"OpenVPN not started\")\n            for line in self.notifications.split('\\n'):\n                logging.warn(\"OpenVPN output:\\t\\t%s\" % line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop the OpenVPN process group.", "response": "def stop(self, timeout=None):\n        \"\"\"\n        Stop OpenVPN process group\n        :param timeout: time in seconds to wait for process to stop\n        :return:\n        \"\"\"\n        if not timeout:\n            timeout = self.timeout\n        os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)\n        self.thread.join(timeout)\n        if self.stopped:\n            logging.info(\"OpenVPN stopped\")\n            if self in OpenVPN.connected_instances:\n                OpenVPN.connected_instances.remove(self)\n        else:\n            logging.error(\"Cannot stop OpenVPN!\")\n            for line in self.notifications.split('\\n'):\n                logging.warn(\"OpenVPN output:\\t\\t%s\" % line)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the meta information for the current instance of the class", "response": "def get_meta(self):\n        \"\"\"we only want to get the meta information (our normalized IP) once,\n        so we are going to do lazy instantiation to improve performance\n\n        \"\"\"\n        # get the normalized IP if we don't already have it\n        if self._meta is None:\n            external_ip = get_external_ip()\n            if external_ip:\n                self._meta = get_meta(self.config, external_ip)\n            else:\n                raise Exception(\"Unable to get public IP\")\n            if 'custom_meta' in self.config:\n                self._meta['custom_meta'] = self.config['custom_meta']\n\n        return self._meta"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnotes this function will check the experiments directory for a special file, scheduler.info, that details how often each experiment should be run and the last time the experiment was run. If the time since the experiment was run is shorter than the scheduled interval in seconds, then the experiment will not be run. :param data_dir: :return:", "response": "def run(self, data_dir=None):\n\n        \"\"\"\n        Note: this function will check the experiments directory for a\n        special file, scheduler.info, that details how often each\n        experiment should be run and the last time the experiment was\n        run. If the time since the experiment was run is shorter than\n        the scheduled interval in seconds, then the experiment will\n        not be run.\n\n        :param data_dir:\n        :return:\n        \"\"\"\n        # XXX: android build needs this. refactor\n        if data_dir:\n            centinel_home = data_dir\n            self.config['dirs']['results_dir'] = os.path.join(centinel_home,\n                                                              'results')\n\n        logging.info('Centinel started.')\n\n        if not os.path.exists(self.config['dirs']['results_dir']):\n            logging.warn(\"Creating results directory in \"\n                         \"%s\" % (self.config['dirs']['results_dir']))\n            os.makedirs(self.config['dirs']['results_dir'])\n        logging.debug(\"Results directory: %s\" % (self.config['dirs']['results_dir']))\n\n        # load scheduler information\n        sched_filename = os.path.join(self.config['dirs']['experiments_dir'],\n                                      'scheduler.info')\n\n        logging.debug(\"Loading scheduler file.\")\n        sched_info = {}\n        if os.path.exists(sched_filename):\n            with open(sched_filename, 'r') as file_p:\n                try:\n                    sched_info = json.load(file_p)\n                except Exception as exp:\n                    logging.error(\"Failed to load the \"\n                                  \"scheduler: %s\" % str(exp))\n                    return\n\n        logging.debug(\"Scheduler file loaded.\")\n\n        logging.debug(\"Processing the experiment schedule.\")\n        for name in sched_info:\n\n            # check if we should preempt on the experiment (if the\n            # time to run next is greater than the current time) and\n            # store the last run time as now\n            #\n            # Note: if the experiment is not in the scheduler, then it\n            # will not be run at all.\n            run_next = sched_info[name]['last_run']\n            run_next += sched_info[name]['frequency']\n            if run_next > time.time():\n                run_next_str = datetime.fromtimestamp(long(run_next))\n                logging.debug(\"Skipping %s, it will \"\n                              \"be run on or after %s.\" % (name, run_next_str))\n                continue\n\n            # backward compatibility with older-style scheduler\n            if 'python_exps' not in sched_info[name]:\n                self.run_exp(name=name)\n            else:\n                exps = sched_info[name]['python_exps'].items()\n                for python_exp, exp_config in exps:\n                    logging.debug(\"Running %s.\" % python_exp)\n                    self.run_exp(name=python_exp, exp_config=exp_config, schedule_name=name)\n                    logging.debug(\"Finished running %s.\" % python_exp)\n            sched_info[name]['last_run'] = time.time()\n\n        logging.debug(\"Updating timeout values in scheduler.\")\n        # write out the updated last run times\n        with open(sched_filename, 'w') as file_p:\n            json.dump(sched_info, file_p, indent=2,\n                      separators=(',', ': '))\n\n        self.consolidate_results()\n\n        logging.info(\"Finished running experiments. \"\n                     \"Look in %s for results.\" % (self.config['dirs']['results_dir']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _tcpdump_callback(self, line, kill_switch):\n\n    line = line.lower()\n    if (\"listening\" in line) or (\"reading\" in line):\n        self.started = True\n    if (\"no suitable device\" in line):\n        self.error = True\n        self.kill_switch()\n    if \"by kernel\" in line:\n        self.stopped = True", "response": "Callback function to handle tcpdump"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _run():\n\n    args = parse_args()\n\n    # parse custom parameters\n    custom_meta = None\n    if args.custom_meta:\n        print \"Adding custom parameters:\"\n        custom_meta = {}\n        try:\n            for item in args.custom_meta.split(','):\n                key, value = item.split(':')\n                custom_meta[key] = value\n                print 'key: %s, value: %s' % (key, value)\n        except Exception as e:\n            sys.stderr.write(\"ERROR: Can not parse custom meta tags! %s\\n\" % (str(e)))\n\n    # we need to store some persistent info, so check if a config file\n    # exists (default location is ~/.centinel/config.ini). If the file\n    # does not exist, then create a new one at run time\n    configuration = centinel.config.Configuration()\n    if args.config:\n        configuration.parse_config(args.config)\n    else:\n        # if the file does not exist, then the default config file\n        # will be used\n        new_configuration = None\n        if os.path.exists(DEFAULT_CONFIG_FILE):\n            configuration.parse_config(DEFAULT_CONFIG_FILE)\n        else:\n            print 'Configuration file does not exist. Creating a new one.'\n            new_configuration = centinel.config.Configuration()\n\n        if not ('version' in configuration.params and\n                configuration.params['version']['version'] == centinel.__version__):\n            if not args.update_config:\n                print ('WARNING: configuration file is from '\n                       'a different version (%s) of '\n                       'Centinel. Run with --update-config to update '\n                       'it.' % (configuration.params['version']['version']))\n            else:\n                new_configuration = centinel.config.Configuration()\n                backup_path = DEFAULT_CONFIG_FILE + \".old\"\n                new_configuration.update(configuration, backup_path)\n\n        if new_configuration is not None:\n            configuration = new_configuration\n            configuration.write_out_config(DEFAULT_CONFIG_FILE)\n            print 'New configuration written to %s' % (DEFAULT_CONFIG_FILE)\n            if args.update_config:\n                sys.exit(0)\n\n    if args.verbose:\n        if 'log' not in configuration.params:\n            configuration.params['log'] = dict()\n        configuration.params['log']['log_level'] = logging.DEBUG\n\n    # add custom meta values from CLI\n    if custom_meta is not None:\n        if 'custom_meta' in configuration.params:\n            configuration.params['custom_meta'].update(custom_meta)\n        else:\n            configuration.params['custom_meta'] = custom_meta\n\n    centinel.conf = configuration.params\n    client = centinel.client.Client(configuration.params)\n    client.setup_logging()\n    # disable cert verification if the flag is set\n    if args.no_verify:\n        configuration.params['server']['verify'] = False\n\n    user = centinel.backend.User(configuration.params)\n    # Note: because we have mutually exclusive arguments, we don't\n    # have to worry about multiple arguments being called\n    if args.sync:\n        centinel.backend.sync(configuration.params)\n    elif args.consent:\n        user.informed_consent()\n    elif args.daemonize:\n        # if we don't have a valid binary location, then exit\n        if not os.path.exists(args.binary):\n            print \"Error: no binary found to daemonize\"\n            exit(1)\n        centinel.daemonize.daemonize(args.auto_update, args.binary,\n            args.user)\n    else:\n        client.run()", "response": "Entry point for package and cli uses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fingerprint_batch(input_list, results={}, default_port=443,\n                          delay_time=0.5, max_threads=100):\n    \"\"\"\n    This is a parallel version of the TLS fingerprint primitive.\n\n    :param input_list: the input is a list of host:ports.\n    :param default_port: default port to use when no port specified\n    :param delay_time: delay before starting each thread\n    :param max_threads: maximum number of concurrent threads\n    :return:\n    \"\"\"\n    threads = []\n    thread_error = False\n    thread_wait_timeout = 200\n    ind = 1\n    total_item_count = len(input_list)\n    for row in input_list:\n        if len(row.split(\":\")) == 2:\n            host, port = row.split(\":\")\n        elif len(row.split(\":\")) == 1:\n            host = row\n            port = default_port\n        else:\n            continue\n\n        port = int(port)\n        wait_time = 0\n        while threading.active_count() > max_threads:\n            time.sleep(1)\n            wait_time += 1\n            if wait_time > thread_wait_timeout:\n                thread_error = True\n                break\n\n        if thread_error:\n            results[\"error\"] = \"Threads took too long to finish.\"\n            break\n\n        # add just a little bit of delay before starting the thread\n        # to avoid overwhelming the connection.\n        time.sleep(delay_time)\n\n        log_prefix = \"%d/%d: \" % (ind, total_item_count)\n        thread = threading.Thread(target=get_fingerprint,\n                                  args=(host, port,\n                                        results, log_prefix))\n        ind += 1\n        thread.setDaemon(1)\n\n        thread_open_success = False\n        retries = 0\n        while not thread_open_success and retries < MAX_THREAD_START_RETRY:\n            try:\n                thread.start()\n                threads.append(thread)\n                thread_open_success = True\n            except:\n                retries += 1\n                time.sleep(THREAD_START_DELAY)\n                logging.error(\"%sThread start failed for %s, retrying... (%d/%d)\" % (log_prefix, host, retries, MAX_THREAD_START_RETRY))\n\n        if retries == MAX_THREAD_START_RETRY:\n            logging.error(\"%sCan't start a new thread for %s after %d retries.\" % (log_prefix, host, retries))\n\n    for thread in threads:\n        thread.join(thread_wait_timeout)\n\n    return results", "response": "This function is used to get a list of TLS fingerprints from multiple threads."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn redirecting URL if there is a refresh meta tag and there is no URL in it", "response": "def meta_redirect(content):\n    \"\"\"\n    Returns redirecting URL if there is a HTML refresh meta tag,\n    returns None otherwise\n\n    :param content: HTML content\n    \"\"\"\n    decoded = content.decode(\"utf-8\", errors=\"replace\")\n\n    try:\n        soup = BeautifulSoup.BeautifulSoup(decoded)\n    except Exception as e:\n        return None\n\n    result = soup.find(\"meta\", attrs={\"http-equiv\": re.compile(\"^refresh$\", re.I)})\n    if result:\n        try:\n            wait, text = result[\"content\"].split(\";\")\n            text = text.strip()\n            if text.lower().startswith(\"url=\"):\n                url = text[4:]\n                return url\n        except:\n            # there are normal meta tag with refresh that are not\n            # redirect and don't have a URL in it\n            pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a script with the given content and destination.", "response": "def create_script_for_location(content, destination):\n    \"\"\"Create a script with the given content, mv it to the\n    destination, and make it executable\n\n    Parameters:\n    content- the content to put in the script\n    destination- the directory to copy to\n\n    Note: due to constraints on os.rename, destination must be an\n    absolute path to a file, not just a directory\n\n    \"\"\"\n    temp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n    temp.write(content)\n    temp.close()\n    shutil.move(temp.name, destination)\n    cur_perms = os.stat(destination).st_mode\n    set_perms = cur_perms | stat.S_IXOTH | stat.S_IXGRP | stat.S_IXUSR\n    os.chmod(destination, set_perms)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate crontab entries to run centinel every hour and autoupdate every day.", "response": "def daemonize(package, bin_loc, user):\n    \"\"\"Create crontab entries to run centinel every hour and\n    autoupdate every day\n\n    Parameters:\n\n    package- name of the currently installed package (will be used for\n        autoupdate). If this parameter is None, the autoupdater will\n        not be used\n\n    bin_loc- location of the centinel binary/script.\n\n    Note: this works by creating temporary files, adding the content\n    of the cron scripts to these temporary files, moving these files\n    into the appropriate cron folders, and making these scripts\n    executable\n\n    Note: if the script already exists, this will delete it\n\n    \"\"\"\n\n    path = \"/etc/cron.hourly/centinel-\" + user\n\n    if user != \"root\":\n        # create a script to run centinel every hour as the current user\n        hourly = \"\".join([\"#!/bin/bash\\n\",\n                          \"# cron job for centinel\\n\",\n                          \"su \", user, \" -c '\", bin_loc, \" --sync'\\n\",\n                          \"su \", user, \" -c '\", bin_loc, \"'\\n\",\n                          \"su \", user, \" -c '\", bin_loc, \" --sync'\\n\"])\n    else:\n        # create a script to run centinel every hour as root\n        hourly = \"\".join([\"#!/bin/bash\\n\",\n                          \"# cron job for centinel\\n\",\n                          bin_loc, \" --sync\\n\",\n                          bin_loc, \"\\n\",\n                          bin_loc, \" --sync\\n\"])\n\n    create_script_for_location(hourly, path)\n\n    # create a script to get the client to autoupdate every day\n    if package is None:\n        return\n    updater = \"\".join([\"#!/bin/bash\\n\",\n                      \"# autoupdater for centinel\\n\"\n                      \"sudo pip install --upgrade \", package, \"\\n\"])\n    create_script_for_location(updater, \"/etc/cron.daily/centinel-autoupdate\")\n    print \"Successfully created cron jobs for user \" + user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate all VPN configuration files in the given directory.", "response": "def create_config_files(directory):\n    \"\"\"Create all available VPN configuration files in the given directory\n\n    Note: I am basically just following along with what their script\n    client does\n\n    \"\"\"\n    # get the config file template\n    template_url = (\"https://securenetconnection.com/vpnconfig/\"\n                    \"openvpn-template.ovpn\")\n    resp = requests.get(template_url)\n    resp.raise_for_status()\n    template = resp.content\n\n    # get the available servers and create a config file for each server\n    server_url = (\"https://securenetconnection.com/vpnconfig/\"\n                  \"servers-cli.php\")\n    resp = requests.get(server_url)\n    resp.raise_for_status()\n    servers = resp.content.split(\"\\n\")\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    with open(os.path.join(directory, \"servers.txt\"), 'w') as f:\n        f.write(resp.content)\n\n    for server_line in servers:\n        if server_line.strip() == \"\":\n            continue\n        server_line = server_line.split(\"|\")\n        try:\n            ip, desc, country, udp_sup, tcp_sup = server_line\n        except ValueError:\n            ip, desc, country, udp_sup, tcp_sup, no_rand = server_line\n        with open(os.path.join(directory, ip + \".ovpn\"), 'w') as file_o:\n            file_o.write(template)\n            # create tcp if available, else udp\n            tcp_sup = tcp_sup.strip()\n            if tcp_sup:\n                port, proto = 443, \"tcp\"\n            else:\n                port, proto = 53, \"udp\"\n            file_o.write(\"remote {0} {1}\\n\".format(ip, port))\n            file_o.write(\"proto {0}\\n\".format(proto))\n            # add automatic dns server update\n            file_o.write(\"up /etc/openvpn/update-resolv-conf\\n\")\n            file_o.write(\"down /etc/openvpn/update-resolv-conf\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading the scheduler. info file and perform a smart comparison of what we currently have so that we don t overwrite the last_run timestamp and the frequency count in the client copy.", "response": "def sync_scheduler(self):\n        \"\"\"Download the scheduler.info file and perform a smart comparison\n        with what we currently have so that we don't overwrite the\n        last_run timestamp\n\n        To do a smart comparison, we go over each entry in the\n        server's scheduler file. If a scheduler entry is not present\n        in the server copy, we delete it in the client copy and if the\n        scheduler entry is present in the server copy, then we\n        overwrite the frequency count in the client copy\n\n        \"\"\"\n        # get the server scheduler.info file\n        url = \"%s/%s/%s\" % (self.config['server']['server_url'],\n                            \"experiments\", \"scheduler.info\")\n        try:\n            req = requests.get(url, proxies=self.config['proxy']['proxy'],\n                               auth=self.auth,\n                               verify=self.verify)\n            req.raise_for_status()\n        except Exception as exp:\n            logging.exception(\"Error trying to download scheduler.info: %s\" % exp)\n            raise exp\n\n        try:\n            server_sched = json.loads(req.content)\n        except Exception as exp:\n            logging.exception(\"Error parsing server scheduler: %s\" % exp)\n            raise exp\n\n        sched_filename = os.path.join(self.config['dirs']['experiments_dir'],\n                                      'scheduler.info')\n        if not os.path.exists(sched_filename):\n            with open(sched_filename, 'w') as file_p:\n                json.dump(server_sched, file_p, indent=2,\n                      separators=(',', ': '))\n            return\n\n        client_sched = {}\n        try:\n            with open(sched_filename, 'r') as file_p:\n                client_sched = json.load(file_p)\n        except Exception as exp:\n            client_sched = {}\n            logging.exception(\"Error loading scheduler file: %s\" % exp)\n            logging.info(\"Making an empty scheduler\")\n\n        # delete any scheduled tasks as necessary\n        #\n        # Note: this looks ugly, but we can't modify dictionaries\n        # while we iterate over them\n        client_exp_keys = client_sched.keys()\n        for exp in client_exp_keys:\n            if exp not in server_sched:\n                del client_sched[exp]\n        # and update all the other frequencies\n        for exp in server_sched:\n            if exp in client_sched:\n                client_sched[exp]['frequency'] = server_sched[exp]['frequency']\n            else:\n                client_sched[exp] = server_sched[exp]\n\n        # write out the results\n        with open(sched_filename, 'w') as file_p:\n            json.dump(client_sched, file_p, indent=2,\n                      separators=(',', ': '))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a URL for the user to give their consent through", "response": "def informed_consent(self):\n        \"\"\"Create a URL for the user to give their consent through\"\"\"\n        if self.typeable_handle is None:\n            consent_url = [self.config['server']['server_url'],\n                           \"/get_initial_consent?username=\"]\n            consent_url.append(urlsafe_b64encode(self.username))\n            consent_url.append(\"&password=\")\n            consent_url.append(urlsafe_b64encode(self.password))\n        else:\n            consent_url = [self.config['server']['server_url'],\n                           \"/consent/\"]\n            consent_url.append(self.typeable_handle)\n\n        consent_url = \"\".join(consent_url)\n        print \"Please go to %s to give your consent.\" % (consent_url)\n        return consent_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate config files for VPN Gate.", "response": "def create_config_files(directory):\n    \"\"\"\n    Initialize directory ready for vpn walker\n    :param directory: the path where you want this to happen\n    :return:\n    \"\"\"\n    # Some constant strings\n    vpn_gate_url = \"http://www.vpngate.net/api/iphone/\"\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    # get csv into memory\n    csv_str = \"\"\n    logging.info(\"Downloading info from VPN Gate API...\")\n    r = requests.get(vpn_gate_url)\n    for line in r.text.split('\\n'):\n        csv_str += line.encode('utf-8')\n        csv_str += \"\\n\"\n\n    # convert csv string to string IO\n    f = StringIO.StringIO(csv_str)\n\n    # generate vpn dict\n    vpn_dict = {}\n    reader = csv.reader(f)\n    reader.next()\n    reader.next()\n    for row in reader:\n        if len(row) == 15:\n            alpha2 = row[6]\n            vpn_dict[alpha2] = vpn_dict.get(alpha2, [])\n            vpn_dict[alpha2].append({\n                \"vpn_name\": row[0],\n                \"ip\": row[1],\n                \"country_name\": row[5],\n                \"alpha2\": alpha2,\n                \"openvpn_config\": b64decode(row[-1])\n            })\n    f.close()\n\n    server_country = {}\n\n    # write config files\n    for country in vpn_dict:\n        for data in vpn_dict[country]:\n            config_filename = \"{}.ovpn\".format(data['ip'])\n            file_path = os.path.join(directory, config_filename)\n            with open(file_path, 'w') as f:\n                f.write(data['openvpn_config'])\n                f.write(\"up /etc/openvpn/update-resolv-conf\\n\")\n                f.write(\"down /etc/openvpn/update-resolv-conf\\n\")\n\n            server_country[data['ip']] = country\n\n    with open(os.path.join(directory, 'servers.txt'), 'w') as f:\n        for ip in server_country:\n            f.write('|'.join([ip, server_country[ip]]) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_config_files(directory):\n    # Some constant strings\n    config_zip_url = \"http://www.ipvanish.com/software/configs/configs.zip\"\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    logging.info(\"Starting to download IPVanish config file zip\")\n    url_opener = urllib.URLopener()\n    zip_path = os.path.join(directory, '../configs.zip')\n    unzip_path = os.path.join(directory, '../unzipped')\n    if not os.path.exists(unzip_path):\n        os.makedirs(unzip_path)\n\n    url_opener.retrieve(config_zip_url, zip_path)\n    logging.info(\"Extracting zip file\")\n    unzip(zip_path, unzip_path)\n\n    # remove zip file\n    os.remove(zip_path)\n    # copy ca and key to root path\n    shutil.copyfile(os.path.join(unzip_path, 'ca.ipvanish.com.crt'),\n                    os.path.join(directory, '../ca.ipvanish.com.crt'))\n\n    # move all config files to /vpns\n\n    server_country = {}\n    for filename in os.listdir(unzip_path):\n        if filename.endswith('.ovpn'):\n            country = filename.split('-')[1]\n\n            file_path = os.path.join(unzip_path, filename)\n            lines = [line.rstrip('\\n') for line in open(file_path)]\n\n            # get ip address for this vpn\n            ip = \"\"\n            for line in lines:\n                if line.startswith('remote'):\n                    hostname = line.split(' ')[1]\n                    ip = socket.gethostbyname(hostname)\n                    break\n\n            if len(ip) > 0:\n                new_path = os.path.join(directory, ip + '.ovpn')\n                shutil.copyfile(file_path, new_path)\n                server_country[ip] = country\n            else:\n                logging.warn(\"Unable to resolve hostname and remove %s\" % filename)\n                os.remove(file_path)\n\n    with open(os.path.join(directory, 'servers.txt'), 'w') as f:\n        for ip in server_country:\n            f.write('|'.join([ip, server_country[ip]]) + '\\n')\n\n    # remove extracted folder\n    shutil.rmtree(unzip_path)", "response": "Create the config files for the IPVanish server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans the VPNs and return the VMs that are available for the VPN.", "response": "def scan_vpns(directory, auth_file, crt_file, tls_auth, key_direction,\n              exclude_list, shuffle_lists, vm_num, vm_index, reduce_vp):\n    \"\"\"\n    For each VPN, check if there are experiments and scan with it if\n    necessary\n\n    Note: the expected directory structure is\n    args.directory\n    -----vpns (contains the OpenVPN config files\n    -----configs (contains the Centinel config files)\n    -----exps (contains the experiments directories)\n\n    :param directory: root directory that contains vpn configs and\n                      centinel client configs\n    :param auth_file: a text file with username at first line and\n                      password at second line\n    :param crt_file: optional root certificate file\n    :param tls_auth: additional key\n    :param key_direction: must specify if tls_auth is used\n    :param exclude_list: optional list of exluded countries\n    :param shuffle_lists: shuffle vpn list if set true\n    :param vm_num: number of VMs that are running currently\n    :param vm_index: index of current VM\n    :param reduce_vp: reduce number of vantage points\n    :return:\n    \"\"\"\n\n    logging.info(\"Starting to run the experiments for each VPN\")\n    logging.warn(\"Excluding vantage points from: %s\" % exclude_list)\n\n    # iterate over each VPN\n    vpn_dir = return_abs_path(directory, \"vpns\")\n    conf_dir = return_abs_path(directory, \"configs\")\n    home_dir = return_abs_path(directory, \"home\")\n    if auth_file is not None:\n        auth_file = return_abs_path(directory, auth_file)\n    if crt_file is not None:\n        crt_file = return_abs_path(directory, crt_file)\n    if tls_auth is not None:\n        tls_auth = return_abs_path(directory, tls_auth)\n    conf_list = sorted(os.listdir(conf_dir))\n\n    # determine VPN provider\n    vpn_provider = None\n    if \"hma\" in directory:\n        vpn_provider = \"hma\"\n    elif \"ipvanish\" in directory:\n        vpn_provider = \"ipvanish\"\n    elif \"purevpn\" in directory:\n        vpn_provider = \"purevpn\"\n    elif \"vpngate\" in directory:\n        vpn_provider = \"vpngate\"\n    if vpn_provider:\n        logging.info(\"Detected VPN provider is %s\" % vpn_provider)\n    else:\n        logging.warning(\"Cannot determine VPN provider!\")\n\n    # reduce size of list if reduce_vp is true\n    if reduce_vp:\n        logging.info(\"Reducing list size. Original size: %d\" % len(conf_list))\n        country_asn_set = set()\n        reduced_conf_set = set()\n        for filename in conf_list:\n            centinel_config = os.path.join(conf_dir, filename)\n            config = centinel.config.Configuration()\n            config.parse_config(centinel_config)\n\t    # filename is the hostname, need to resolve it to get vp_ip\n            hostname = os.path.splitext(filename)[0]\n            vp_ip = \"unknown\"\n            try:\n \t\tvp_ip = socket.gethostbyname(hostname)\n \t    except Exception as exp:\n \t\tlogging.exception(\"Failed to resolve %s : %s\" %(hostname,str(exp)))\n \t\tcontinue\n\t    # before\n#            vp_ip = os.path.splitext(filename)[0]\n\n            try:\n                meta = centinel.backend.get_meta(config.params, vp_ip)\n                if 'country' in meta and 'as_number' in meta \\\n                        and meta['country'] and meta['as_number']:\n                    country_asn = '_'.join([meta['country'], meta['as_number']])\n                    if country_asn not in country_asn_set:\n                        country_asn_set.add(country_asn)\n                        reduced_conf_set.add(filename)\n                else:\n                    # run this endpoint if missing info\n                    reduced_conf_set.add(filename)\n            except:\n                logging.warning(\"Failed to geolocate %s\" % vp_ip)\n                reduced_conf_set.add(filename)\n\n        conf_list = list(reduced_conf_set)\n        logging.info(\"List size reduced. New size: %d\" % len(conf_list))\n\n    # sort file list to ensure the same filename sequence in each VM\n    conf_list = sorted(conf_list)\n\n    # only select its own portion according to vm_num and vm_index\n    chunk_size = len(conf_list) / vm_num\n    last_chunk_additional = len(conf_list) % vm_num\n    start_pointer = 0 + (vm_index - 1) * chunk_size\n    end_pointer = start_pointer + chunk_size\n    if vm_index == vm_num:\n        end_pointer += last_chunk_additional\n    conf_list = conf_list[start_pointer:end_pointer]\n\n    if shuffle_lists:\n        shuffle(conf_list)\n\n    number = 1\n    total = len(conf_list)\n\n    external_ip = get_external_ip()\n    if external_ip is None:\n        logging.error(\"No network connection, exiting...\")\n        return\n    logging.info(\"Current external IP: %s\" % (external_ip))\n\n    # getting namesevers that should be excluded\n    local_nameservers = dns.resolver.Resolver().nameservers\n\n    for filename in conf_list:\n        # Check network connection first\n        time.sleep(5)\n        logging.info(\"Checking network connectivity...\")\n        current_ip = get_external_ip()\n        if current_ip is None:\n            logging.error(\"Network connection lost!\")\n            break\n        elif current_ip != external_ip:\n            logging.error(\"VPN still connected! IP: %s\" % current_ip)\n            if len(openvpn.OpenVPN.connected_instances) == 0:\n                logging.error(\"No active OpenVPN instance found! Exiting...\")\n                break\n            else:\n                logging.warn(\"Trying to disconnect VPN\")\n                for instance in openvpn.OpenVPN.connected_instances:\n                    instance.stop()\n                    time.sleep(5)\n\n                current_ip = get_external_ip()\n                if current_ip is None or current_ip != external_ip:\n                    logging.error(\"Stopping VPN failed! Exiting...\")\n                    break\n\n            logging.info(\"Disconnecting VPN successfully\")\n\n        # start centinel for this endpoint\n        logging.info(\"Moving onto (%d/%d) %s\" % (number, total, filename))\n\n        number += 1\n        vpn_config = os.path.join(vpn_dir, filename)\n        centinel_config = os.path.join(conf_dir, filename)\n\n        # before starting the VPN, check if there are any experiments\n        # to run\n        config = centinel.config.Configuration()\n        config.parse_config(centinel_config)\n\n        # assuming that each VPN config file has a name like:\n        # [ip-address].ovpn, we can extract IP address from filename\n        # and use it to geolocate and fetch experiments before connecting\n        # to VPN.\n        vpn_address, extension = os.path.splitext(filename)\n\t\n\thostname = os.path.splitext(filename)[0]\n        vp_ip = \"unknown\"\n        try:\n \t\tvp_ip = socket.gethostbyname(hostname)\n \texcept Exception as exp:\n\t\tlogging.exception(\"Failed to resolve %s : %s\" %(hostname,str(exp)))\n\t\t\n        country = None\n        try:\n#            meta = centinel.backend.get_meta(config.params,vpn_address)\n#\t    vpn_address contains the hostname\n            meta = centinel.backend.get_meta(config.params,vp_ip)\n\n\n            if 'country' in meta:\n                country = meta['country']\n        except:\n#           logging.exception(\"%s: Failed to geolocate %s\" % (filename, vpn_address))\n#\t    vpn_address contains the hostname\n    \t    logging.exception(\"%s: Failed to geolocate %s\" % (filename, vp_ip))\n        if country and exclude_list and country in exclude_list:\n            logging.info(\"%s: Skipping this server (%s)\" % (filename, country))\n            continue\n\n        # try setting the VPN info (IP and country) to get appropriate\n        # experiemnts and input data.\n        try:\n            #centinel.backend.set_vpn_info(config.params, vpn_address, country)\n\t    # vpn_address is the filename which has the hostname\n\t    centinel.backend.set_vpn_info(config.params, vp_ip, country)\n        except Exception as exp:\n            logging.exception(\"%s: Failed to set VPN info: %s\" % (filename, exp))\n\n        logging.info(\"%s: Synchronizing.\" % filename)\n        try:\n            centinel.backend.sync(config.params)\n        except Exception as exp:\n            logging.exception(\"%s: Failed to sync: %s\" % (filename, exp))\n\n        if not experiments_available(config.params):\n            logging.info(\"%s: No experiments available.\" % filename)\n            try:\n#                centinel.backend.set_vpn_info(config.params, vpn_address, country)\n#\t\tvpn_address contains the hostname\n                centinel.backend.set_vpn_info(config.params, vp_ip, country)\n\n\n            except Exception as exp:\n                logging.exception(\"Failed to set VPN info: %s\" % exp)\n            continue\n\n        # add exclude_nameservers to scheduler\n        sched_path = os.path.join(home_dir, filename, \"experiments\", \"scheduler.info\")\n        if os.path.exists(sched_path):\n            with open(sched_path, 'r+') as f:\n                sched_info = json.load(f)\n                for task in sched_info:\n                    if \"python_exps\" in sched_info[task] and \"baseline\" in sched_info[task][\"python_exps\"]:\n                        if \"params\" in sched_info[task][\"python_exps\"][\"baseline\"]:\n                            sched_info[task][\"python_exps\"][\"baseline\"][\"params\"][\"exclude_nameservers\"] = \\\n                                local_nameservers\n                        else:\n                            sched_info[task][\"python_exps\"][\"baseline\"][\"params\"] = \\\n                                {\"exclude_nameservers\": local_nameservers}\n\n                # write back to same file\n                f.seek(0)\n                json.dump(sched_info, f, indent=2)\n                f.truncate()\n\n        logging.info(\"%s: Starting VPN.\" % filename)\n\n        vpn = openvpn.OpenVPN(timeout=60, auth_file=auth_file, config_file=vpn_config,\n                              crt_file=crt_file, tls_auth=tls_auth, key_direction=key_direction)\n\n        vpn.start()\n        if not vpn.started:\n            logging.error(\"%s: Failed to start VPN!\" % filename)\n            vpn.stop()\n            time.sleep(5)\n            continue\n\n        logging.info(\"%s: Running Centinel.\" % filename)\n        try:\n            client = centinel.client.Client(config.params, vpn_provider)\n            centinel.conf = config.params\n            # do not use client logging config\n            # client.setup_logging()\n            client.run()\n        except Exception as exp:\n            logging.exception(\"%s: Error running Centinel: %s\" % (filename, exp))\n\n        logging.info(\"%s: Stopping VPN.\" % filename)\n        vpn.stop()\n        time.sleep(5)\n\n        logging.info(\"%s: Synchronizing.\" % filename)\n        try:\n            centinel.backend.sync(config.params)\n        except Exception as exp:\n            logging.exception(\"%s: Failed to sync: %s\" % (filename, exp))\n\n        # try setting the VPN info (IP and country) to the correct address\n        # after sync is over.\n        try:\n#            centinel.backend.set_vpn_info(config.params, vpn_address, country)\n#\t    vpn_address contains the hostname\n            centinel.backend.set_vpn_info(config.params, vp_ip, country)\n\n\n        except Exception as exp:\n            logging.exception(\"Failed to set VPN info: %s\" % exp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef return_abs_path(directory, path):\n    if directory is None or path is None:\n        return\n    directory = os.path.expanduser(directory)\n    return os.path.abspath(os.path.join(directory, path))", "response": "Returns an absolute path for the given directory and path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new configuration file for each VPN file in directory and all the associated directories", "response": "def create_config_files(directory):\n    \"\"\"\n    For each VPN file in directory/vpns, create a new configuration\n    file and all the associated directories\n\n    Note: the expected directory structure is\n    args.directory\n    -----vpns (contains the OpenVPN config files\n    -----configs (contains the Centinel config files)\n    -----exps (contains the experiments directories)\n    -----results (contains the results)\n\n    :param directory:\n    \"\"\"\n    logging.info(\"Starting to create config files from openvpn files\")\n\n    vpn_dir = return_abs_path(directory, \"vpns\")\n    conf_dir = return_abs_path(directory, \"configs\")\n    os.mkdir(conf_dir)\n    home_dirs = return_abs_path(directory, \"home\")\n    os.mkdir(home_dirs)\n    for filename in os.listdir(vpn_dir):\n        configuration = centinel.config.Configuration()\n        # setup the directories\n        home_dir = os.path.join(home_dirs, filename)\n        os.mkdir(home_dir)\n        configuration.params['user']['centinel_home'] = home_dir\n        exp_dir = os.path.join(home_dir, \"experiments\")\n        os.mkdir(exp_dir)\n        configuration.params['dirs']['experiments_dir'] = exp_dir\n        data_dir = os.path.join(home_dir, \"data\")\n        os.mkdir(data_dir)\n        configuration.params['dirs']['data_dir'] = data_dir\n        res_dir = os.path.join(home_dir, \"results\")\n        os.mkdir(res_dir)\n        configuration.params['dirs']['results_dir'] = res_dir\n\n        log_file = os.path.join(home_dir, \"centinel.log\")\n        configuration.params['log']['log_file'] = log_file\n        login_file = os.path.join(home_dir, \"login\")\n        configuration.params['server']['login_file'] = login_file\n        configuration.params['user']['is_vpn'] = True\n\n        configuration.params['server']['verify'] = True\n        configuration.params['experiments']['tcpdump_params'] = [\"-i\", \"tun0\"]\n\n        conf_file = os.path.join(conf_dir, filename)\n        configuration.write_out_config(conf_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_config(self, config_file):\n\n        with open(config_file, 'r') as f:\n            config = json.load(f)\n        self.params = config\n        if self.params['proxy']['proxy_type']:\n            self.params['proxy'] = {self.params['proxy']['proxy_type']:\n                                    self.params['proxy']['proxy_url']}", "response": "Read in and interpret the results\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the old configuration file with new values.", "response": "def update(self, old, backup_path=None):\n        \"\"\"\n        Update the old configuration file with new values.\n\n        :param old: old configuration to update.\n        :param backup_path: path to write a backup of the old config file.\n\n        :return:\n        \"\"\"\n        for category in old.params.keys():\n            for parameter in old.params[category].keys():\n                if (category in self.params and parameter in self.params[category] and\n                        (old.params[category][parameter] != self.params[category][parameter]) and\n                        (category != \"version\")):\n                    print (\"Config value '%s.%s' \"\n                           \"in old configuration is different \"\n                           \"from the new version\\n\"\n                           \"[old value] = %s\\n\"\n                           \"[new value] = %s\"\n                           \"\" % (category, parameter,\n                                 old.params[category][parameter],\n                                 self.params[category][parameter]))\n                    answer = raw_input(\"Do you want to overwrite? ([y]/n) \")\n                    while answer.lower() not in ['y', 'yes', 'n', 'no']:\n                        answer = raw_input(\"Answer not recongnized. Enter 'y' or 'n'. \")\n\n                    if answer in ['n', 'no']:\n                        old_value = old.params[category][parameter]\n                        self.params[category][parameter] = old_value\n                elif not (category in self.params and\n                          parameter in self.params[category]):\n                    print (\"Deprecated config option '%s.%s' has \"\n                           \"been removed.\" % (category, parameter))\n        if backup_path is not None:\n            old.write_out_config(backup_path)\n            print \"Backup saved in %s.\" % backup_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out the configuration file containing the current set of parameters.", "response": "def write_out_config(self, config_file):\n        \"\"\"\n        Write out the configuration file\n\n        :param config_file:\n        :return:\n\n        Note: this will erase all comments from the config file\n\n        \"\"\"\n        with open(config_file, 'w') as f:\n            json.dump(self.params, f, indent=2,\n                      separators=(',', ': '))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_profile(self, firebug=True, netexport=True):\n        profile = webdriver.FirefoxProfile()\n        profile.set_preference(\"app.update.enabled\", False)\n        if firebug:\n            profile.add_extension(os.path.join(self.cur_path, 'extensions/firebug-2.0.8.xpi'))\n            profile.set_preference(\"extensions.firebug.currentVersion\", \"2.0.8\")\n            profile.set_preference(\"extensions.firebug.allPagesActivation\", \"on\")\n            profile.set_preference(\"extensions.firebug.defaultPanelName\", \"net\")\n            profile.set_preference(\"extensions.firebug.net.enableSites\", True)\n            profile.set_preference(\"extensions.firebug.delayLoad\", False)\n            profile.set_preference(\"extensions.firebug.onByDefault\", True)\n            profile.set_preference(\"extensions.firebug.showFirstRunPage\", False)\n            profile.set_preference(\"extensions.firebug.net.defaultPersist\", True)  # persist all redirection responses\n        if netexport:\n            har_path = os.path.join(self.cur_path, \"har\")\n            if not os.path.exists(har_path):\n                os.mkdir(har_path)\n            profile.add_extension(os.path.join(self.cur_path, 'extensions/netExport-0.9b7.xpi'))\n            profile.set_preference(\"extensions.firebug.DBG_NETEXPORT\", True)\n            profile.set_preference(\"extensions.firebug.netexport.alwaysEnableAutoExport\", True)\n            profile.set_preference(\"extensions.firebug.netexport.defaultLogDir\", har_path)\n            profile.set_preference(\"extensions.firebug.netexport.includeResponseBodies\", True)\n        return profile", "response": "Setup the firefox profile for the current firefox version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrap_results(self, **kwargs):\n\n        if 'fd' not in kwargs \\\n                or 'url' not in kwargs \\\n                or 'files_count' not in kwargs:\n            logging.error(\"Missing arguments in wrap_results function\")\n            return {}\n\n        external = kwargs['external'] if 'external' in kwargs else None\n        fd = kwargs['fd']\n        url = kwargs['url']\n        length = kwargs['files_count']\n\n        results = {}\n\n        files = []\n        wait_time = 15\n        host = self.divide_url(url)[0]\n        time.sleep(0.5)\n\n        # wait until the har file is generated\n        while len(os.listdir(fd)) <= length + self.parsed:\n            time.sleep(1)\n            wait_time -= 1\n            if wait_time == 0:\n                logging.warning(\"%s waiting har file result timed out\" % url)\n                results['error'] = \"wrap har file timeout\"\n                if external is not None:\n                    external[url] = results\n                return results\n        time.sleep(1)\n\n        # find all har files under har/ directory\n        for fn in os.listdir(fd):\n            if fn.endswith(\".har\") and host in fn:\n                path = os.path.join(fd, fn)\n                files.append((fn, os.stat(path).st_mtime))\n\n        # sort all har files and parse the latest one\n        files.sort(key=lambda x: x[1])\n        if len(files) > 0:\n            with open(fd + '/' + files[-1][0]) as f:\n                raw_data = json.load(f)['log']['entries']\n                results = [{} for i in range(0, len(raw_data))]\n                for i in range(0, len(results)):\n\n                    results[i]['request'] = {}\n                    results[i]['request']['method'] = raw_data[i]['request']['method']\n                    headers = {}\n                    for header in raw_data[i]['request']['headers']:\n                        headers[header['name']] = header['value']\n                    results[i]['request']['headers'] = headers\n\n                    results[i]['response'] = {}\n                    results[i]['response']['status'] = raw_data[i]['response']['status']\n                    results[i]['response']['reason'] = raw_data[i]['response']['statusText']\n                    headers = {}\n                    for header in raw_data[i]['response']['headers']:\n                        headers[header['name']] = header['value']\n                    results[i]['response']['headers'] = headers\n                    results[i]['response']['redirect'] = raw_data[i]['response']['redirectURL']\n                    results[i]['response']['body'] = raw_data[i]['response']['content']\n\n            self.parsed += 1  # increment the number of parsed har files\n        else:\n            logging.warning(\"Cannot find har file for %s\" % url)\n\n        # save test result of this url to the external result object or \n        # return the result\n        if external is not None:\n            external[url] = results\n        else:\n            return results", "response": "Wrap the http response into a well formatted dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndivide url into host and path two parts", "response": "def divide_url(self, url):\n        \"\"\"\n        divide url into host and path two parts\n        \"\"\"\n        if 'https://' in url:\n            host = url[8:].split('/')[0]\n            path = url[8 + len(host):]\n        elif 'http://' in url:\n            host = url[7:].split('/')[0]\n            path = url[7 + len(host):]\n        else:\n            host = url.split('/')[0]\n            path = url[len(host):]\n        return host, path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, host, files_count, path=\"/\", ssl=False, external=None):\n        theme = \"https\" if ssl else \"http\"\n        url = host + path\n        http_url = theme + \"://\" + url\n\n        result = {}\n        try:\n            capture_path = os.getcwd() + '/'\n\n            har_file_path = capture_path + \"har/\"\n\n            # fc.load_page(self.driver, http_url)\n            fc.switch_tab(self.driver)\n            self.load_page(http_url)\n\n            print \"driver get: \" + http_url\n\n            time.sleep(2)\n\n            # if url[-1] == \"/\":\n            #     f_name = url.split('/')[-2]\n            # else:\n            #     f_name = url.split('/')[-1]\n\n            # fc.save_html(self.driver, f_name, os.path.join(capture_path, \"htmls/\"))\n            # fc.save_screenshot(self.driver, f_name, os.path.join(capture_path, \"screenshots/\"))\n\n            result = self.wrap_results(url=http_url, files_count=files_count, fd=har_file_path)\n\n            if external is not None:\n                external[http_url] = result\n\n        except Exception as e:\n            result['error'] = e.message\n            print e\n\n        return result", "response": "Send get request to a url and wrap the results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_file(self, input_file, results):\n\n        capture_path = self.cur_path\n\n        display_mode = 0  # 0 is virtural display(Xvfb mode)\n\n        site_list = []\n        file_name, file_contents = input_file\n        result = {\"file_name\": file_name}\n        file_metadata = {}\n        file_comments = []\n        run_start_time = time.time()\n        index = 1\n\n        csvreader = csv.reader(file_contents, delimiter=',', quotechar='\"')\n        for row in csvreader:\n            \"\"\"\n                First few lines are expected to be comments in key: value\n                format. The first line after that could be our column header\n                row, starting with \"url\", and the rest are data rows.\n                This is a sample input file we're trying to parse:\n\n                # comment: Global List,,,,,\n                # date: 03-17-2015,,,,,\n                # version: 1,,,,,\n                # description: This is the global list. Last updated in 2012.,,,,\n                url,country,category,description,rationale,provider\n                http://8thstreetlatinas.com,glo,PORN,,,PRIV\n                http://abpr2.railfan.net,glo,MISC,Pictures of trains,,PRIV\n\n                \"\"\"\n\n            # parse file comments, if it looks like \"key : value\",\n            # parse it as a key-value pair. otherwise, just\n            # store it as a raw comment.\n            if row[0][0] == '#':\n                row = row[0][1:].strip()\n                if len(row.split(':')) > 1:\n                    key, value = row.split(':', 1)\n                    key = key.strip()\n                    value = value.strip()\n                    file_metadata[key] = value\n                else:\n                    file_comments.append(row)\n                continue\n\n            # detect the header row and store it\n            # it is usually the first row and starts with \"url,\"\n            if row[0].strip().lower() == \"url\":\n                index_row = row\n                continue\n\n            url = row[0].strip()\n            if url is None:\n                continue\n\n            meta = row[1:]\n            site_list.append([index, url])\n            index += 1\n\n        driver, display = fc.do_crawl(sites=site_list, driver=self.driver, display=self.display,\n                                      capture_path=capture_path, callback=self.wrap_results,\n                                      external=results, fd=os.path.join(capture_path, \"har/\"),\n                                      files_count=len(os.listdir(os.path.join(capture_path, \"har/\"))))\n        fc.teardown_driver(driver, display, display_mode)\n\n        driver.quit()", "response": "This function is used to run the file - based test."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, input_files, url=None, verbose=0):\n        if not url and not input_files:\n            logging.warning(\"No input file\")\n            return {\"error\": \"no inputs\"}\n\n        results = {}\n\n        self.open_virtual_display()\n        if verbose > 0:\n            log_file = sys.stdout\n        else:\n            log_file = None\n\n        # set up firefox driver \n        self.binary = FirefoxBinary(os.path.join(self.cur_path, 'firefox/firefox'), log_file=log_file)\n        self.profile = self.setup_profile()\n        self.driver = webdriver.Firefox(firefox_profile=self.profile, firefox_binary=self.binary, timeout=60)\n        self.driver.set_page_load_timeout(60)\n\n        isfile = False\n        if url:\n            host, path = self.divide_url(url)\n            results[url] = self.get(host, path)\n        else:\n            isfile = True\n            for input_file in input_files.items():\n                logging.info(\"Testing input file %s...\" % (input_file[0]))\n                self.run_file(input_file, results)\n\n        # foctor_core will quit the driver by itself so we only quit the driver when we don't use foctor core\n        if not isfile:\n            logging.info(\"Quit driver\")\n            self.driver.quit()\n            self.close_virtual_display()\n\n        logging.debug(\"Deleting har folder\")\n        shutil.rmtree(os.path.join(self.cur_path, 'har'))\n        return results", "response": "run the headless browser with given input_files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_config_files(directory):\n    # Some constant strings\n    config_zip_url = \"https://s3-us-west-1.amazonaws.com/heartbleed/linux/linux-files.zip\"\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    logging.info(\"Starting to download PureVPN config file zip\")\n    url_opener = urllib.URLopener()\n    zip_path = os.path.join(directory, '../linux_files.zip')\n    url_opener.retrieve(config_zip_url, zip_path)\n    logging.info(\"Extracting zip file\")\n    unzip(zip_path, os.path.join(directory, '../'))\n\n    # remove zip file\n    os.remove(zip_path)\n    # copy ca and key to root path\n    shutil.copyfile(os.path.join(directory, '../Linux OpenVPN Updated files', 'ca.crt'),\n                    os.path.join(directory, '../ca.crt'))\n    shutil.copyfile(os.path.join(directory, '../Linux OpenVPN Updated files', 'Wdc.key'),\n                    os.path.join(directory, '../Wdc.key'))\n    # move all config files to /vpns\n    orig_path = os.path.join(directory, '../Linux OpenVPN Updated files/TCP')\n\n    server_country = {}\n    for filename in os.listdir(orig_path):\n        if filename.endswith('.ovpn'):\n            country = filename.split('-')[0]\n            if '(V)' in country:\n                country = country[:country.find('(V)')]\n\n            file_path = os.path.join(orig_path, filename)\n            lines = [line.rstrip('\\n') for line in open(file_path)]\n\n            # get ip address for this vpn\n            ip = \"\"\n            for line in lines:\n                if line.startswith('remote'):\n                    hostname = line.split(' ')[1]\n                    ip = socket.gethostbyname(hostname)\n                    break\n\n            if len(ip) > 0:\n                new_path = os.path.join(directory, ip + '.ovpn')\n                shutil.copyfile(file_path, new_path)\n                server_country[ip] = country\n\n    # remove extracted folder\n    shutil.rmtree(os.path.join(directory, '../Linux OpenVPN Updated files'))\n\n    # add dns update options to each file\n    logging.info(\"Appending DNS update options\")\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        with open(file_path, 'a') as f:\n            f.write(\"\\n\")\n            f.write(\"up /etc/openvpn/update-resolv-conf\\n\")\n            f.write(\"down /etc/openvpn/update-resolv-conf\\n\")\n\n    print os.path.join(directory, 'servers.txt'), len(server_country)\n    with open(os.path.join(directory, 'servers.txt'), 'w') as f:\n        for ip in server_country:\n            f.write('|'.join([ip, server_country[ip]]) + '\\n')", "response": "Create the config files for the current virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the md5 sum of each file in the folder and return to the user", "response": "def hash_folder(folder, regex='[!_]*'):\n    \"\"\"\n    Get the md5 sum of each file in the folder and return to the user\n\n    :param folder: the folder to compute the sums over\n    :param regex: an expression to limit the files we match\n    :return:\n\n    Note: by default we will hash every file in the folder\n\n    Note: we will not match anything that starts with an underscore\n\n    \"\"\"\n    file_hashes = {}\n    for path in glob.glob(os.path.join(folder, regex)):\n        # exclude folders\n        if not os.path.isfile(path):\n            continue\n\n        with open(path, 'r') as fileP:\n            md5_hash = hashlib.md5(fileP.read()).digest()\n\n        file_name = os.path.basename(path)\n        file_hashes[file_name] = urlsafe_b64encode(md5_hash)\n    return file_hashes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_files_to_download(client_hashes, server_hashes):\n    to_dload, to_delete = [], []\n    for filename in server_hashes:\n        if filename not in client_hashes:\n            to_dload.append(filename)\n            continue\n        if client_hashes[filename] != server_hashes[filename]:\n            to_dload.append(filename)\n\n    for filename in client_hashes:\n        if filename not in server_hashes:\n            to_delete.append(filename)\n\n    return [to_dload, to_delete]", "response": "Given a dictionary of file hashes from the client and the server compute which files should be downloaded from the server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verifier(self, url):\n        webbrowser.open(url)\n        print('A browser should have opened up with a link to allow us to access')\n        print('your account, follow the instructions on the link and paste the verifier')\n        print('Code into here to give us access, if the browser didn\\'t open, the link is:')\n        print(url)\n        print()\n        return input('Verifier: ').lstrip(\" \").rstrip(\" \")", "response": "Ask user to enter a verifier for the given url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_config(self):\n        if not os.path.exists(os.path.dirname(self.config_file)):\n            os.makedirs(os.path.dirname(self.config_file))\n        with open(self.config_file, 'w') as f:\n            f.write(json.dumps(self.config))\n            f.close()", "response": "Write config to file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread config from file", "response": "def read_config(self):\n        \"\"\" Read config from file \"\"\"\n        try:\n            with open(self.config_file, 'r') as f:\n                self.config = json.loads(f.read())\n                f.close()\n        except IOError:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nposts a note and return the URL of the posted note", "response": "def post_note(self):\n        \"\"\" Post note and return the URL of the posted note \"\"\"\n        if self.args.note_title:\n            note_title = self.args.note_title\n        else:\n            note_title = None\n\n        note_content = self.args.note_content\n        mynote = self.pump.Note(display_name=note_title, content=note_content)\n        mynote.to = self.pump.me.followers\n        mynote.cc = self.pump.Public\n        mynote.send()\n\n        return mynote.id or None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the id of a PumpObject.", "response": "def get_obj_id(self, item):\n        \"\"\" Get the id of a PumpObject.\n\n        :param item: id string or PumpObject\n        \"\"\"\n        if item is not None:\n            if isinstance(item, six.string_types):\n                return item\n            elif hasattr(item, 'id'):\n                return item.id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_page(self, url):\n        if url:\n            data = self.feed._request(url, offset=self._offset, since=self._since, before=self._before)\n\n            # set values to False to avoid using them for next request\n            self._before = False if self._before is not None else None\n            self._since = False if self._since is not None else None\n            if getattr(self.feed, 'issue65', False):\n                self._offset = False\n            if self._since is not None:\n                # we want oldest items first when using 'since'\n                return reversed(data['items'])\n            else:\n                return data['items']\n        else:\n            return []", "response": "Get a page of items from API"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cached(self):\n        def id_in_list(list, id):\n            if id:\n                if [i for i in list if i.id == id]:\n                    return True\n                else:\n                    raise PyPumpException(\"id %r not in feed.\" % self._since)\n\n        tmp = []\n        if self._before is not None:\n            # return list based on before param\n            if not id_in_list(self.feed._items, self._before):\n                return tmp\n            if isinstance(self._before, six.string_types):\n                found = False\n                for i in self.feed._items:\n                    if not found:\n                        if i.id == self._before:\n                            found = True\n                        continue\n                    else:\n                        tmp.append(i)\n                self._before = False\n            return tmp\n\n        if self._since is not None:\n            # return list based on since param\n            if not id_in_list(self.feed._items, self._since):\n                return tmp\n            if isinstance(self._since, six.string_types):\n                found = False\n                for i in self.feed._items:\n                    if i.id == self._since:\n                        found = True\n                        break\n                    else:\n                        tmp.append(i)\n                self._since = False\n            return reversed(tmp)\n\n        if not hasattr(self, 'usedcache'):\n            self.usedcache = True  # invalidate cache\n\n            if isinstance(self._offset, int):\n                # return list based on offset\n                return self.feed._items[self._offset:]\n\n            return self.feed._items\n        else:\n            return tmp", "response": "Get items from feed cache while trying to emulate\n            how API handles offset since and before parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef done(self):\n        if self._done:\n            return self._done\n\n        if self._limit is None:\n            self._done = False\n        elif self.itemcount >= self._limit:\n            self._done = True\n\n        return self._done", "response": "Check if we should stop returning objects"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _build_cache(self):\n        self.cache = []\n        if self.done:\n            return\n\n        for i in (self.get_cached() if self._cached else self.get_page(self.url)):\n            if not self._cached:\n                # some objects don't have objectType set (inbox activities)\n                if not i.get(\"objectType\"):\n                    i[\"objectType\"] = self.feed.object_types[0]\n                obj = Mapper(pypump=self.feed._pump).get_object(i)\n\n            else:\n                obj = i\n            self.cache.append(obj)\n\n        # ran out of items\n        if len(self.cache) <= 0:\n            self._done = True\n\n        # check what to do next time\n        if getattr(self.feed, 'issue65', False):\n            # work around API bug for favorites feed, see https://github.com/xray7224/PyPump/issues/65\n            if self._offset is None:\n                self._offset = 0\n            self._offset += 20\n        elif self._since is not None:\n            if self.feed.links.get('prev'):\n                self.url = self.feed.links['prev']\n                del self.feed.links['prev']  # avoid using it again\n        else:\n            if self.feed.links.get('next'):\n                self.url = self.feed.links['next']\n                del self.feed.links['next']  # avoid using it again\n            else:\n                self.url = None", "response": "Build a list of objects from the feed s cached items or API page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef items(self, offset=None, limit=20, since=None, before=None, *args, **kwargs):\n        return ItemList(self, offset=offset, limit=limit, since=since, before=before, cached=self.is_cached)", "response": "Get a feed s items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _subfeed(self, feedname):\n        url = self.url\n        if not url.endswith(\"/\"):\n            url += \"/\"\n        return url + feedname", "response": "Used for Inbox and Outbox major and minor subfeeds"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndirect inbox feed contains activities addedressed directly to the owner of the inbox.", "response": "def direct(self):\n        \"\"\" Direct inbox feed,\n        contains activities addressed directly to the owner of the inbox.\n        \"\"\"\n        url = self._subfeed(\"direct\")\n        if \"direct\" in self.url or \"major\" in self.url or \"minor\" in self.url:\n            return self\n        if self._direct is None:\n            self._direct = self.__class__(url, pypump=self._pump)\n        return self._direct"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the major inbox feed.", "response": "def major(self):\n        \"\"\" Major inbox feed, contains major activities such as notes and images. \"\"\"\n        url = self._subfeed(\"major\")\n        if \"major\" in self.url or \"minor\" in self.url:\n            return self\n        if self._major is None:\n            self._major = self.__class__(url, pypump=self._pump)\n        return self._major"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nminor inbox feed contains minor activities such as likes shares and follows.", "response": "def minor(self):\n        \"\"\" Minor inbox feed, contains minor activities such as likes, shares and follows. \"\"\"\n        url = self._subfeed(\"minor\")\n        if \"minor\" in self.url or \"major\" in self.url:\n            return self\n        if self._minor is None:\n            self._minor = self.__class__(url, pypump=self._pump)\n        return self._minor"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, display_name, content=None):\n\n        activity = {\n            \"verb\": \"create\",\n            \"object\": {\n                \"objectType\": \"collection\",\n                \"objectTypes\": [self.membertype],\n                \"displayName\": display_name,\n                \"content\": content\n            }\n        }\n        if self._post_activity(activity, unserialize=False):\n            return self[display_name]", "response": "Create a new user list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize(self):\n        data = super(Note, self).serialize()\n        data.update({\n            \"verb\": \"post\",\n            \"object\": {\n                \"objectType\": self.object_type,\n                \"content\": self.content,\n            }\n        })\n        if self.display_name:\n            data[\"object\"][\"displayName\"] = self.display_name\n\n        return data", "response": "Converts the post to something compatible with json. dumps"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, server=None):\n        request = {\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"timeout\": self._pump.timeout,\n            \"data\": self.context,\n        }\n\n        url = \"{proto}://{server}/{endpoint}\".format(\n            proto=self._pump.protocol,\n            server=server or self.server,\n            endpoint=self.ENDPOINT,\n        )\n\n        response = self._pump._requester(requests.post, url, **request)\n\n        try:\n            server_data = response.json()\n        except ValueError:\n            raise ClientException(response.content)\n\n        if \"error\" in server_data:\n            raise ClientException(server_data[\"error\"], self.context)\n\n        _log.debug(\"Client registration recieved: %(id)s %(secret)s %(expire)s\", {\n            \"id\": server_data[\"client_id\"],\n            \"secret\": server_data[\"client_secret\"],\n            \"expire\": server_data[\"expires_at\"],\n        })\n\n        return server_data", "response": "Sends the request to the server and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the client with the Pump API retrieving the id and secret and update the object properties", "response": "def register(self, server=None):\n        \"\"\" Registers the client with the Pump API retrieving the id and secret \"\"\"\n        if (self.key or self.secret):\n            return self.update()\n\n        server_data = self.request(server)\n\n        self.key = server_data[\"client_id\"]\n        self.secret = server_data[\"client_secret\"]\n        self.expirey = server_data[\"expires_at\"]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the information about the client", "response": "def update(self):\n        \"\"\" Updates the information the Pump server has about the client \"\"\"\n        error = \"\"\n\n        if self.key is None:\n            error = \"To update a client you need to provide a key\"\n        if self.secret is None:\n            error = \"To update a client you need to provide the secret\"\n\n        if error:\n            raise ClientException(error)\n\n        self.request()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_extensions(macros, compat=False):\n    import distutils.sysconfig\n    import distutils.ccompiler\n    import tempfile\n    import shutil\n\n    from textwrap import dedent\n\n    # common vars\n    libraries = ['rrd']\n    include_dirs = [package_dir, '/usr/local/include']\n    library_dirs = ['/usr/local/lib']\n    compiler_args = dict(\n        libraries=libraries,\n        include_dirs=include_dirs,\n        library_dirs=library_dirs,\n        define_macros=macros)\n    exts = [Extension('rrdtool', sources=['rrdtoolmodule.c'], **compiler_args)]\n\n    if compat:\n        return exts\n\n    # in non-compat mode, try to link to check if the new symbols are present in librrd\n    c_code = dedent('''\n        #include <rrd.h>\n        #include \"rrdtoolmodule.h\"\n\n        int main(int argc, char *argv[]) {\n            rrd_fetch_cb_register(NULL);  /* exists in rrdtool >= 1.5.0 */\n            return 0;\n        }\n    ''')\n\n    tmp_dir = tempfile.mkdtemp(prefix='tmp_python_rrdtool')\n    bin_file_name = os.path.join(tmp_dir, 'test_rrdtool')\n    file_name = bin_file_name + '.c'\n\n    with open(file_name, 'w') as fp:\n        fp.write(c_code)\n\n    # try to compile it\n    compiler = distutils.ccompiler.new_compiler()\n    assert isinstance(compiler, distutils.ccompiler.CCompiler)\n    for s in include_dirs:\n        compiler.add_include_dir(s)\n    for s in library_dirs:\n        compiler.add_library_dir(s)\n    for s in libraries:\n        compiler.add_library(s)\n    for s in macros:\n        compiler.define_macro(*s)\n    distutils.sysconfig.customize_compiler(compiler)\n\n    try:\n        compiler.link_executable(\n            compiler.compile([file_name]),\n            bin_file_name,\n            libraries=libraries)\n    except CompileError:\n        sys.exit('Error: Unable to compile the binary module. Do you have the rrdtool header and libraries installed?')\n        ret = None\n    except LinkError as exc:\n        shutil.rmtree(tmp_dir)\n        raise  # re-raise\n    else:\n        return exts  # seems to be available, compile in regular way\n\n    shutil.rmtree(tmp_dir)\n    return ret", "response": "Compile the extensions for the most available rrd."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the members of the current collection.", "response": "def members(self):\n        \"\"\" :class:`Feed <pypump.models.feed.Feed>` of collection members.\n        \"\"\"\n        if self._members is None:\n            self._members = Feed(self.links[\"members\"], pypump=self._pump)\n        return self._members"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, obj):\n        activity = {\n            \"verb\": \"add\",\n            \"object\": {\n                \"objectType\": obj.object_type,\n                \"id\": obj.id\n            },\n            \"target\": {\n                \"objectType\": self.object_type,\n                \"id\": self.id\n            }\n        }\n\n        self._post_activity(activity)\n\n        # Remove the cash so it's re-generated next time it's needed\n        self._members = None", "response": "Adds a member to the collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, obj):\n        activity = {\n            \"verb\": \"remove\",\n            \"object\": {\n                \"objectType\": obj.object_type,\n                \"id\": obj.id\n            },\n            \"target\": {\n                \"objectType\": self.object_type,\n                \"id\": self.id\n            }\n        }\n\n        self._post_activity(activity)\n\n        # Remove the cash so it's re-generated next time it's needed\n        self._members = None", "response": "Removes a member from the collection."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef outbox(self):\n        if self._outbox is None:\n            self._outbox = Outbox(self.links['activity-outbox'], pypump=self._pump)\n        return self._outbox", "response": "Returns a new object containing all the outbox entries for this person."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new feed with all the followers links.", "response": "def followers(self):\n        \"\"\" :class:`Feed <pypump.models.feed.Feed>` with all\n        :class:`Person <pypump.models.person.Person>` objects following the person.\n\n        Example:\n            >>> alice = pump.Person('alice@example.org')\n            >>> for follower in alice.followers[:2]:\n            ...     print(follower.id)\n            ...\n            acct:bob@example.org\n            acct:carol@example.org\n        \"\"\"\n        if self._followers is None:\n            self._followers = Followers(self.links['followers'], pypump=self._pump)\n        return self._followers"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new object containing all the followers of the current feed.", "response": "def following(self):\n        \"\"\" :class:`Feed <pypump.models.feed.Feed>` with all\n        :class:`Person <pypump.models.person.Person>` objects followed by the person.\n\n        Example:\n            >>> bob = pump.Person('bob@example.org')\n            >>> for followee in bob.following[:3]:\n            ...     print(followee.id)\n            ...\n            acct:alice@example.org\n            acct:duncan@example.org\n        \"\"\"\n        if self._following is None:\n            self._following = Following(self.links['following'], pypump=self._pump)\n        return self._following"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new feed with all objects in the object that are liked and favorited by the person.", "response": "def favorites(self):\n        \"\"\" :class:`Feed <pypump.models.feed.Feed>` with all objects\n        liked/favorited by the person.\n\n        Example:\n            >>> for like in pump.me.favorites[:3]:\n            ...     print(like)\n            ...\n            note by alice@example.org\n            image by bob@example.org\n            comment by evan@e14n.com\n        \"\"\"\n        if self._favorites is None:\n            self._favorites = Favorites(self.links['favorites'], pypump=self._pump)\n        return self._favorites"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lists(self):\n        if self._lists is None:\n            self._lists = Lists(self.links['lists'], pypump=self._pump)\n        return self._lists", "response": "Returns a new feed with all lists owned by the person."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the current inbox.", "response": "def inbox(self):\n        \"\"\" :class:`Inbox feed <pypump.models.feed.Inbox>` with all\n        :class:`activities <pypump.models.activity.Activity>`\n        received by the person, can only be read if logged in as the owner.\n\n        Example:\n            >>> for activity in pump.me.inbox[:2]:\n            ...     print(activity.id)\n            ...\n            https://microca.st/api/activity/BvqXQOwXShSey1HxYuJQBQ\n            https://pumpyourself.com/api/activity/iQGdnz5-T-auXnbUUdXh-A\n        \"\"\"\n        if not self.isme:\n            raise PyPumpException(\"You can't read other people's inboxes\")\n        if self._inbox is None:\n            self._inbox = Inbox(self.links['activity-inbox'], pypump=self._pump)\n        return self._inbox"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verb(self, verb):\n\n        activity = {\n            \"verb\": verb,\n            \"object\": {\n                \"id\": self.id,\n                \"objectType\": self.object_type,\n            }\n        }\n\n        self._post_activity(activity)", "response": "Posts minimal activity with verb and bare self object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _post_activity(self, activity, unserialize=True):\n        # I think we always want to post to feed\n        feed_url = \"{proto}://{server}/api/user/{username}/feed\".format(\n            proto=self._pump.protocol,\n            server=self._pump.client.server,\n            username=self._pump.client.nickname\n        )\n\n        data = self._pump.request(feed_url, method=\"POST\", data=activity)\n\n        if not data:\n            return False\n\n        if \"error\" in data:\n            raise PumpException(data[\"error\"])\n\n        if unserialize:\n            if \"target\" in data:\n                # we probably want to unserialize target if it's there\n                # true for collection.{add,remove}\n                self.unserialize(data[\"target\"])\n            else:\n                # copy activity attributes into object\n                if \"author\" not in data[\"object\"]:\n                    data[\"object\"][\"author\"] = data[\"actor\"]\n                for key in [\"to\", \"cc\", \"bto\", \"bcc\"]:\n                    if key not in data[\"object\"] and key in data:\n                        data[\"object\"][key] = data[key]\n\n                self.unserialize(data[\"object\"])\n\n        return True", "response": "Post a activity to feed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing and adds block of links", "response": "def _add_links(self, links, key=\"href\", proxy_key=\"proxyURL\", endpoints=None):\n        \"\"\" Parses and adds block of links \"\"\"\n        if endpoints is None:\n            endpoints = [\"likes\", \"replies\", \"shares\", \"self\", \"followers\",\n                         \"following\", \"lists\", \"favorites\", \"members\"]\n\n        if links.get(\"links\"):\n            for endpoint in links['links']:\n                # It would seem occasionally the links[\"links\"][endpoint] is\n                # just a string (what would be the href value). I don't know\n                # why, it's likely a bug in pump.io but for now we'll support\n                # this too.\n                if isinstance(links['links'][endpoint], dict):\n                    self._add_link(endpoint, links['links'][endpoint][\"href\"])\n                else:\n                    self._add_link(endpoint, links[\"links\"][endpoint])\n\n        for endpoint in endpoints:\n            if links.get(endpoint, None) is None:\n                continue\n\n            if \"pump_io\" in links[endpoint]:\n                self._add_link(endpoint, links[endpoint][\"pump_io\"][proxy_key])\n            elif \"url\" in links[endpoint]:\n                self._add_link(endpoint, links[endpoint][\"url\"])\n            else:\n                self._add_link(endpoint, links[endpoint][key])\n\n        return self.links"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_map(self, obj, mapping=None, *args, **kwargs):\n        mapping = mapping or obj._mapping\n\n        if \"data\" in kwargs:\n            for k, v in mapping.items():\n                if kwargs[\"data\"].get(v, None) is not None:\n                    val = kwargs[\"data\"][v]\n                else:\n                    val = None\n                self.add_attr(obj, k, val, from_json=True)\n        else:\n            for k, v in mapping.items():\n                if k in kwargs:\n                    self.add_attr(obj, k, kwargs[k])", "response": "Parses a dictionary of model_attr json_attr items"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef likes(self):\n\n        endpoint = self.links[\"likes\"]\n        if self._likes is None:\n            self._likes = Feed(endpoint, pypump=self._pump)\n        return self._likes", "response": "A feed object that contains the people who have liked the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comments(self):\n\n        endpoint = self.links[\"replies\"]\n        if self._comments is None:\n            self._comments = Feed(endpoint, pypump=self._pump)\n        return self._comments", "response": "A feed object containing the comments for the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comment(self, comment):\n        if isinstance(comment, six.string_types):\n            comment = self._pump.Comment(comment)\n\n        comment.in_reply_to = self\n        comment.send()", "response": "Add a Comment to the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shares(self):\n\n        endpoint = self.links[\"shares\"]\n        if self._shares is None:\n            self._shares = Feed(endpoint, pypump=self._pump)\n        return self._shares", "response": "A feed object that contains the people who have shared the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_people(self, people):\n        if hasattr(people, \"object_type\"):\n            people = [people]\n        elif hasattr(people, \"__iter__\"):\n            people = list(people)\n\n        return people", "response": "Sets who the object is sent to"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads a file to the feed and returns the feed s ID.", "response": "def from_file(self, filename):\n        \"\"\" Uploads a file from a filename on your system.\n\n        :param filename: Path to file on your system.\n\n        Example:\n            >>> myimage.from_file('/path/to/dinner.png')\n        \"\"\"\n\n        mimetype = mimetypes.guess_type(filename)[0] or \"application/octal-stream\"\n        headers = {\n            \"Content-Type\": mimetype,\n            \"Content-Length\": str(os.path.getsize(filename)),\n        }\n\n        # upload file\n        file_data = self._pump.request(\n            \"/api/user/{0}/uploads\".format(self._pump.client.nickname),\n            method=\"POST\",\n            data=open(filename, \"rb\").read(),\n            headers=headers,\n        )\n\n        # now post it to the feed\n        data = {\n            \"verb\": \"post\",\n            \"object\": file_data,\n        }\n        data.update(self.serialize())\n\n        if not self.content and not self.display_name and not self.license:\n            self._post_activity(data)\n        else:\n            self._post_activity(data, unserialize=False)\n\n            # update post with display_name and content\n            if self.content:\n                file_data['content'] = self.content\n            if self.display_name:\n                file_data['displayName'] = self.display_name\n            if self.license:\n                file_data['license'] = self.license\n            data = {\n                \"verb\": \"update\",\n                \"object\": file_data,\n            }\n            self._post_activity(data)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new instance of the Person class that represents the logged in user.", "response": "def me(self):\n        \"\"\" Returns :class:`Person <pypump.models.person.Person>` instance of\n        the logged in user.\n\n        Example:\n            >>> pump.me\n            <Person: bob@example.org>\n        \"\"\"\n\n        if self._me is not None:\n            return self._me\n\n        self._me = self.Person(\"{username}@{server}\".format(\n            username=self.client.nickname,\n            server=self.client.server,\n        ))\n        return self._me"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a fully qualified URL for the current state of the user.", "response": "def _build_url(self, endpoint):\n        \"\"\" Returns a fully qualified URL \"\"\"\n        server = None\n        if \"://\" in endpoint:\n            # looks like an url, let's break it down\n            server, endpoint = self._deconstruct_url(endpoint)\n\n        endpoint = endpoint.lstrip(\"/\")\n        url = \"{proto}://{server}/{endpoint}\".format(\n            proto=self.protocol,\n            server=self.client.server if server is None else server,\n            endpoint=endpoint,\n        )\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _deconstruct_url(self, url):\n        url = url.split(\"://\", 1)[-1]\n        server, endpoint = url.split(\"/\", 1)\n        return (server, endpoint)", "response": "Breaks down URL and returns server and endpoint"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a client object to the server cache if it does not already exist.", "response": "def _add_client(self, url, key=None, secret=None):\n        \"\"\" Creates Client object with key and secret for server\n        and adds it to _server_cache if it doesnt already exist \"\"\"\n\n        if \"://\" in url:\n            server, endpoint = self._deconstruct_url(url)\n        else:\n            server = url\n\n        if server not in self._server_cache:\n            if not (key and secret):\n                client = Client(\n                    webfinger=self.client.webfinger,\n                    name=self.client.name,\n                    type=self.client.type,\n                )\n                client.set_pump(self)\n                client.register(server)\n            else:\n                client = Client(\n                    webfinger=self.client.webfinger,\n                    key=key,\n                    secret=secret,\n                    type=self.client.type,\n                    name=self.client.name,\n                )\n                client.set_pump(self)\n\n            self._server_cache[server] = client"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a request to the specified endpoint with OAuth.", "response": "def request(self, endpoint, method=\"GET\", data=\"\",\n                raw=False, params=None, retries=None, client=None,\n                headers=None, timeout=None, **kwargs):\n        \"\"\" Make request to endpoint with OAuth.\n        Returns dictionary with response data.\n\n        :param endpoint: endpoint path, or a fully qualified URL if raw=True.\n        :param method: GET (default), POST or DELETE.\n        :param data: data to send in the request body.\n        :param raw: use endpoint as entered without trying to modify it.\n        :param params: dictionary of parameters to send in the query string.\n        :param retries: number of times to retry if a request fails.\n        :param client: OAuth client data, if False do request without OAuth.\n        :param headers: dictionary of HTTP headers.\n        :param timeout: the timeout for a request, in seconds.\n\n        Example:\n            >>> pump.request('https://e14n.com/api/user/evan/profile', raw=True)\n            {u'displayName': u'Evan Prodromou',\n             u'favorites': {u'totalItems': 7227,\n              u'url': u'https://e14n.com/api/user/evan/favorites'},\n             u'id': u'acct:evan@e14n.com',\n             u'image': {u'height': 96,\n              u'url': u'https://e14n.com/uploads/evan/2014/9/24/knyf1g_thumb.jpg',\n              u'width': 96},\n             u'liked': False,\n             u'location': {u'displayName': u'Montreal, Quebec, Canada',\n              u'objectType': u'place'},\n             u'objectType': u'person',\n             u'preferredUsername': u'evan',\n             u'published': u'2013-02-20T15:34:52Z',\n             u'summary': u'I wanna make it with you. http://payb.tc/evanp',\n             u'updated': u'2014-09-24T02:38:32Z',\n             u'url': u'https://e14n.com/evan'}\n        \"\"\"\n\n        retries = self.retries if retries is None else retries\n        timeout = self.timeout if timeout is None else timeout\n\n        # check client has been setup\n        if client is None:\n            client = self.setup_oauth_client(endpoint)\n            c = client.client\n            fnc = OAuth1Session(c.client_key,\n                                client_secret=c.client_secret,\n                                resource_owner_key=c.resource_owner_key,\n                                resource_owner_secret=c.resource_owner_secret\n                               )\n        elif client is False:\n            fnc = requests\n\n        params = {} if params is None else params\n\n        if data and isinstance(data, dict):\n            data = json.dumps(data)\n\n        if not raw:\n            url = self._build_url(endpoint)\n        else:\n            url = endpoint\n\n        headers = headers or {\"Content-Type\": \"application/json\"}\n        request = {\n            \"headers\": headers,\n            \"params\": params,\n            \"timeout\": timeout,\n        }\n        request.update(kwargs)\n\n        if method == \"POST\":\n            fnc = fnc.post\n            request.update({\"data\": data})\n        elif method == \"PUT\":\n            fnc = fnc.put\n            request.update({\"data\": data})\n        elif method == \"GET\":\n            fnc = fnc.get\n        elif method == \"DELETE\":\n            fnc = fnc.delete\n\n        for attempt in range(1 + retries):\n            response = self._requester(\n                fnc=fnc,\n                endpoint=endpoint,\n                raw=raw,\n                **request\n            )\n\n            if response.status_code == 200:\n                # huray!\n                return response.json()\n\n            if response.status_code == 400:\n                # can't do much\n                try:\n                    try:\n                        data = response.json()\n                        error = data[\"error\"]\n                    except ValueError:\n                        error = response.content\n\n                    if not error:\n                        raise IndexError  # yesss i know.\n                except IndexError:\n                    error = \"400 - Bad request.\"\n                raise PyPumpException(error)\n\n            if response.ok:\n                return response\n\n        error = \"Request Failed to {url} (response: {data} | status: {status})\"\n        error = error.format(\n            url=url,\n            data=response.content,\n            status=response.status_code\n        )\n\n        raise PyPumpException(error)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef oauth_request(self):\n        # get tokens from server and make a dict of them.\n        self._server_tokens = self.request_token()\n\n        self.store[\"oauth-request-token\"] = self._server_tokens[\"token\"]\n        self.store[\"oauth-request-secret\"] = self._server_tokens[\"token_secret\"]\n\n        # now we need the user to authorize me to use their pump.io account\n        result = self.verifier_callback(self.construct_oauth_url())\n        if result is not None:\n            self.verifier(result)", "response": "Makes a oauth connection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct verifier OAuth URL", "response": "def construct_oauth_url(self):\n        \"\"\" Constructs verifier OAuth URL \"\"\"\n        response = self._requester(requests.head, \n                                   \"{0}://{1}/\".format(self.protocol, self.client.server),\n                                   allow_redirects=False\n                                  )\n        if response.is_redirect:\n            server = response.headers['location']\n        else:\n            server = response.url\n\n        path = \"oauth/authorize?oauth_token={token}\".format(\n            token=self.store[\"oauth-request-token\"]\n        )\n        return \"{server}{path}\".format(\n            server=server,\n            path=path\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_oauth_client(self, url=None):\n        if url and \"://\" in url:\n            server, endpoint = self._deconstruct_url(url)\n        else:\n            server = self.client.server\n\n        if server not in self._server_cache:\n            self._add_client(server)\n\n        if server == self.client.server:\n            self.oauth = OAuth1(\n                client_key=self.store[\"client-key\"],\n                client_secret=self.store[\"client-secret\"],\n                resource_owner_key=self.store[\"oauth-access-token\"],\n                resource_owner_secret=self.store[\"oauth-access-secret\"],\n            )\n            return self.oauth\n        else:\n            return OAuth1(\n                client_key=self._server_cache[server].key,\n                client_secret=self._server_cache[server].secret,\n            )", "response": "Sets up the OAuth client for requests to pump."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets OAuth request token", "response": "def request_token(self):\n        \"\"\" Gets OAuth request token \"\"\"\n        client = OAuth1(\n            client_key=self._server_cache[self.client.server].key,\n            client_secret=self._server_cache[self.client.server].secret,\n            callback_uri=self.callback,\n        )\n\n        request = {\"auth\": client}\n        response = self._requester(\n            requests.post,\n            \"oauth/request_token\",\n            **request\n        )\n\n        data = parse.parse_qs(response.text)\n        data = {\n            'token': data[self.PARAM_TOKEN][0],\n            'token_secret': data[self.PARAM_TOKEN_SECRET][0]\n        }\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request_access(self, verifier):\n        client = OAuth1(\n            client_key=self._server_cache[self.client.server].key,\n            client_secret=self._server_cache[self.client.server].secret,\n            resource_owner_key=self.store[\"oauth-request-token\"],\n            resource_owner_secret=self.store[\"oauth-request-secret\"],\n            verifier=verifier,\n        )\n\n        request = {\"auth\": client}\n        response = self._requester(\n            requests.post,\n            \"oauth/access_token\",\n            **request\n        )\n\n        data = parse.parse_qs(response.text)\n\n        self.store[\"oauth-access-token\"] = data[self.PARAM_TOKEN][0]\n        self.store[\"oauth-access-secret\"] = data[self.PARAM_TOKEN_SECRET][0]\n        self._server_tokens = {}", "response": "Request access token for current server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning boolean if is logged in", "response": "def logged_in(self):\n        \"\"\" Return boolean if is logged in \"\"\"\n        if \"oauth-access-token\" not in self.store:\n            return False\n\n        response = self.request(\"/api/whoami\", allow_redirects=False)\n\n        # It should response with a redirect to our profile if it's logged in\n        if response.status_code != 302:\n            return False\n\n        # the location should be the profile we have\n        if response.headers[\"location\"] != self.me.links[\"self\"]:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cudnnCreate():\n\n    handle = ctypes.c_void_p()\n    status = _libcudnn.cudnnCreate(ctypes.byref(handle))\n    cudnnCheckStatus(status)\n    return handle.value", "response": "Initialize cuDNN and returns a handle to the cuDNN context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cudnnDestroy(handle):\n\n    status = _libcudnn.cudnnDestroy(ctypes.c_void_p(handle))\n    cudnnCheckStatus(status)", "response": "Destroys the resources used by the current hardware resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the current cuDNN library stream.", "response": "def cudnnSetStream(handle, id):\n    \"\"\"\n    Set current cuDNN library stream.\n\n    Parameters\n    ----------\n    handle : cudnnHandle\n        cuDNN context.\n    id : cudaStream\n        Stream Id.\n    \"\"\"\n\n    status = _libcudnn.cudnnSetStream(handle, id)\n    cudnnCheckStatus(status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets current cuDNN library stream.", "response": "def cudnnGetStream(handle):\n    \"\"\"\n    Get current cuDNN library stream.\n\n    Parameters\n    ----------\n    handle : int\n        cuDNN context.\n\n    Returns\n    -------\n    id : int\n        Stream ID.\n    \"\"\"\n\n    id = ctypes.c_void_p()\n    status = _libcudnn.cudnnGetStream(handle, ctypes.byref(id))\n    cudnnCheckStatus(status)\n    return id.value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cudnnCreateTensorDescriptor():\n\n    tensor = ctypes.c_void_p()\n    status = _libcudnn.cudnnCreateTensorDescriptor(ctypes.byref(tensor))\n    cudnnCheckStatus(status)\n    return tensor.value", "response": "Create a Tensor descriptor object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes a previously created Tensor 4D descriptor object.", "response": "def cudnnSetTensor4dDescriptor(tensorDesc, format, dataType, n, c, h, w):\n    \"\"\"\n    Initialize a previously created Tensor 4D object.\n\n    This function initializes a previously created Tensor4D descriptor object. The strides of\n    the four dimensions are inferred from the format parameter and set in such a way that\n    the data is contiguous in memory with no padding between dimensions.\n\n    Parameters\n    ----------\n    tensorDesc : cudnnTensorDescriptor\n        Handle to a previously created tensor descriptor.\n    format : cudnnTensorFormat\n        Type of format.\n    dataType : cudnnDataType\n        Data type.\n    n : int\n        Number of images.\n    c : int\n        Number of feature maps per image.\n    h : int\n        Height of each feature map.\n    w : int\n        Width of each feature map.\n    \"\"\"\n\n    status = _libcudnn.cudnnSetTensor4dDescriptor(tensorDesc, format, dataType,\n                                                  n, c, h, w)\n    cudnnCheckStatus(status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cudnnSetTensor4dDescriptorEx(tensorDesc, dataType, n, c, h, w, nStride, cStride, hStride, wStride):\n\n    status = _libcudnn.cudnnSetTensor4dDescriptorEx(tensorDesc, dataType, n, c, h, w,\n                                                    nStride, cStride, hStride, wStride)\n    cudnnCheckStatus(status)", "response": "Initialize a Tensor descriptor object with strides."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets parameters of a Tensor descriptor object. This function queries the parameters of the previouly initialized Tensor4D descriptor object. Parameters ---------- tensorDesc : cudnnTensorDescriptor Handle to a previously initialized tensor descriptor. Returns ------- dataType : cudnnDataType Data type. n : int Number of images. c : int Number of feature maps per image. h : int Height of each feature map. w : int Width of each feature map. nStride : int Stride between two consective images. cStride : int Stride between two consecutive feature maps. hStride : int Stride between two consecutive rows. wStride : int Stride between two consecutive columns.", "response": "def cudnnGetTensor4dDescriptor(tensorDesc):\n    \"\"\"\"\n    Get parameters of a Tensor descriptor object.\n\n    This function queries the parameters of the previouly initialized Tensor4D descriptor\n    object.\n\n    Parameters\n    ----------\n    tensorDesc : cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n\n    Returns\n    -------\n    dataType : cudnnDataType\n        Data type.\n    n : int\n        Number of images.\n    c : int\n        Number of feature maps per image.\n    h : int\n        Height of each feature map.\n    w : int\n        Width of each feature map.\n    nStride : int\n        Stride between two consective images.\n    cStride : int\n        Stride between two consecutive feature maps.\n    hStride : int\n        Stride between two consecutive rows.\n    wStride : int\n        Stride between two consecutive columns.\n    \"\"\"\n\n    dataType = ctypes.c_int()\n    n = ctypes.c_int()\n    c = ctypes.c_int()\n    h = ctypes.c_int()\n    w = ctypes.c_int()\n    nStride = ctypes.c_int()\n    cStride = ctypes.c_int()\n    hStride = ctypes.c_int()\n    wStride = ctypes.c_int()\n\n    status = _libcudnn.cudnnGetTensor4dDescriptor(tensorDesc, ctypes.byref(dataType), ctypes.byref(n),\n                                                  ctypes.byref(c), ctypes.byref(h), ctypes.byref(w),\n                                                  ctypes.byref(nStride), ctypes.byref(cStride),\n                                                  ctypes.byref(hStride), ctypes.byref(wStride))\n    cudnnCheckStatus(status)\n\n    return dataType.value, n.value, c.value, h.value, w.value, nStride.value, cStride.value, \\\n        hStride.value, wStride.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cudnnAddTensor(handle, alpha, biasDesc, biasData, beta, srcDestDesc, srcDestData):\n\n    dataType, _, _, _, _, _, _, _, _ = cudnnGetTensor4dDescriptor(srcDestDesc)\n    if dataType == cudnnDataType['CUDNN_DATA_DOUBLE']:\n        alphaRef = ctypes.byref(ctypes.c_double(alpha))\n        betaRef = ctypes.byref(ctypes.c_double(beta))\n    else:\n        alphaRef = ctypes.byref(ctypes.c_float(alpha))\n        betaRef = ctypes.byref(ctypes.c_float(beta))\n\n    status = _libcudnn.cudnnAddTensor(handle, alphaRef, biasDesc,\n                                        biasData, betaRef,\n                                        srcDestDesc, srcDestData)\n    cudnnCheckStatus(status)", "response": "This function is used to add a tensor to a previoulsy initialized tensor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cudnnSetTensor(handle, srcDesc, srcData, value):\n\n    dataType, _, _, _, _, _, _, _, _ = cudnnGetTensor4dDescriptor(srcDesc)\n    if dataType == cudnnDataType['CUDNN_DATA_DOUBLE']:\n        alphaRef = ctypes.byref(ctypes.c_double(alpha))\n    else:\n        alphaRef = ctypes.byref(ctypes.c_float(alpha))\n\n    status = _libcudnn.cudnnSetTensor(handle, srcDesc, srcData, alphaRef)\n    cudnnCheckStatus(status)", "response": "Set all data points of a tensor to a given value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a filter descriptor. This function creates a filter descriptor object by allocating the memory needed to hold its opaque structure. Parameters ---------- Returns ------- wDesc : cudnnFilterDescriptor Handle to a newly allocated filter descriptor.", "response": "def cudnnCreateFilterDescriptor():\n    \"\"\"\"\n    Create a filter descriptor.\n\n    This function creates a filter descriptor object by allocating the memory needed\n    to hold its opaque structure.\n\n    Parameters\n    ----------\n\n    Returns\n    -------\n    wDesc : cudnnFilterDescriptor\n        Handle to a newly allocated filter descriptor.\n    \"\"\"\n\n    wDesc = ctypes.c_void_p()\n    status = _libcudnn.cudnnCreateFilterDescriptor(ctypes.byref(wDesc))\n    cudnnCheckStatus(status)\n\n    return wDesc.value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cudnnSetFilter4dDescriptor(wDesc, dataType, format, k, c, h, w):\n\n    status = _libcudnn.cudnnSetFilter4dDescriptor(wDesc, dataType, format, k, c, h, w)\n    cudnnCheckStatus(status)", "response": "Initialize a filter descriptor object into a 4D filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cudnnGetFilter4dDescriptor(wDesc):\n\n    dataType = ctypes.c_int()\n    format = ctypes.c_int()\n    k = ctypes.c_int()\n    c = ctypes.c_int()\n    h = ctypes.c_int()\n    w = ctypes.c_int()\n\n    status = _libcudnn.cudnnGetFilter4dDescriptor(wDesc, ctypes.byref(dataType),\n                                                ctypes.byref(format),\n                                                ctypes.byref(k), ctypes.byref(c),\n                                                ctypes.byref(h), ctypes.byref(w))\n    cudnnCheckStatus(status)\n\n    return dataType.value, format.value, k.value, c.value, h.value, w.value", "response": "Get parameters of filter descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cudnnCreateConvolutionDescriptor():\n\n    convDesc = ctypes.c_void_p()\n\n    status = _libcudnn.cudnnCreateConvolutionDescriptor(ctypes.byref(convDesc))\n    cudnnCheckStatus(status)\n\n    return convDesc.value", "response": "Create a convolution descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes a convolution descriptor object and return the correlation matrix.", "response": "def cudnnSetConvolution2dDescriptor(convDesc, pad_h, pad_w, u, v, dilation_h, dilation_w, mode,\n                                    computeType):\n    \"\"\"\"\n    Initialize a convolution descriptor.\n\n    This function initializes a previously created convolution descriptor object into a 2D\n    correlation. This function assumes that the tensor and filter descriptors corresponds\n    to the formard convolution path and checks if their settings are valid. That same\n    convolution descriptor can be reused in the backward path provided it corresponds to\n    the same layer.\n\n    Parameters\n    ----------\n    convDesc : cudnnConvolutionDescriptor\n        Handle to a previously created convolution descriptor.\n    pad_h : int\n        zero-padding height: number of rows of zeros implicitly concatenated\n        onto the top and onto the bottom of input images.\n    pad_w : int\n        zero-padding width: number of columns of zeros implicitly concatenated\n        onto the left and onto the right of input images.\n    u : int\n        Vertical filter stride.\n    v : int\n        Horizontal filter stride.\n    dilation_h : int\n        Filter height dilation.\n    dilation_w : int\n        Filter width dilation.\n    mode : cudnnConvolutionMode\n        Select between CUDNN_CONVOLUTION or CUDNN_CROSS_CORRELATION.\n    computeType : cudnnDataType\n        Compute precision\n    \"\"\"\n\n    status = _libcudnn.cudnnSetConvolution2dDescriptor(convDesc, pad_h, pad_w, u, v,\n                                                        dilation_h, dilation_w, mode,\n                                                        computeType)\n    cudnnCheckStatus(status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cudnnGetConvolution2dDescriptor(convDesc):\n    pad_h = ctypes.c_int()\n    pad_w = ctypes.c_int()\n    u = ctypes.c_int()\n    v = ctypes.c_int()\n    dilation_h = ctypes.c_int()\n    dilation_w = ctypes.c_int()\n    mode = ctypes.c_int()\n    computeType = ctypes.c_int()\n\n    status = _libcudnn.cudnnGetConvolution2dDescriptor(convDesc, ctypes.byref(pad_h),\n                                                    ctypes.byref(pad_w), ctypes.byref(u),\n                                                    ctypes.byref(v), ctypes.byref(dilation_h),\n                                                    ctypes.byref(dilation_w),\n                                                    ctypes.byref(mode), ctypes.byref(computeType))\n\n    cudnnCheckStatus(status)\n\n    return (pad_h.value, pad_w.value, u.value, v.value, upscalex.value, upscaley.value, mode.value,\n            computeType.value)", "response": "Get a convolution descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the dimensions of the output tensor given a convolution descriptor.", "response": "def cudnnGetConvolution2dForwardOutputDim(convDesc, inputTensorDesc, wDesc):\n    \"\"\"\"\n    Return the dimensions of the output tensor given a convolution descriptor.\n\n    This function returns the dimensions of the resulting 4D tensor of a 2D\n    convolution, given the convolution descriptor, the input tensor descriptor and\n    the filter descriptor. This function can help to setup the output tensor and allocate\n    the proper amount of memory prior to launching the actual convolution.\n\n    Parameters\n    ----------\n    convDesc : cudnnConvolutionDescriptor\n        Handle to a previously created convolution descriptor.\n    inputTensorDesc: cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n    wDesc: cudnnFilterDescriptor\n        Handle to a previously initialized filter descriptor.\n\n    Returns\n    -------\n    n : int\n        Number of output images.\n    c : int\n        Number of output feature maps per image.\n    h : int\n        Height of each output feature map.\n    w : int\n        Width of each output feature map.\n    \"\"\"\n    n = ctypes.c_int()\n    c = ctypes.c_int()\n    h = ctypes.c_int()\n    w = ctypes.c_int()\n\n    status = _libcudnn.cudnnGetConvolution2dForwardOutputDim(convDesc, inputTensorDesc,\n                                                 wDesc, ctypes.byref(n),\n                                                 ctypes.byref(c), ctypes.byref(h),\n                                                 ctypes.byref(w))\n    cudnnCheckStatus(status)\n\n    return n.value, c.value, h.value, w.value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cudnnGetConvolutionForwardWorkspaceSize(handle, srcDesc, wDesc,\n                                            convDesc, destDesc, algo):\n    \"\"\"\"\n    This function returns the amount of GPU memory workspace the user needs\n    to allocate to be able to call cudnnConvolutionForward with the specified algorithm.\n\n    Parameters\n    ----------\n    handle : cudnnHandle\n        Handle to a previously created cuDNN context.\n    srcDesc : cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n    wDesc : cudnnFilterDescriptor\n        Handle to a previously initialized filter descriptor.\n    convDesc : cudnnConvolutionDescriptor\n        Previously initialized convolution descriptor.\n    destDesc : cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n    algo : cudnnConvolutionFwdAlgo\n        Enumerant that specifies the chosen convolution algorithm.\n\n    Returns\n    -------\n    sizeInBytes: c_size_t\n        Amount of GPU memory needed as workspace to be able to execute a\n        forward convolution with the sepcified algo.\n    \"\"\"\n    sizeInBytes = ctypes.c_size_t()\n\n    status = _libcudnn.cudnnGetConvolutionForwardWorkspaceSize(handle, srcDesc, wDesc,\n                                               convDesc, destDesc, algo,\n                                               ctypes.byref(sizeInBytes))\n    cudnnCheckStatus(status)\n\n    return sizeInBytes", "response": "This function returns the amount of GPU memory needed to execute a convolution forward with the specified algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms forward convolution. All of the form \"output = alpha * Op(inputs) + beta * output\". This function executes convolutions or cross-correlations over src using the specified filters, returning results in dest. Scaling factors alpha and beta can be used to scale the input tensor and the output tensor respectively. Parameters ---------- handle : cudnnHandle Handle to a previously created cuDNN context. alpha: float Scaling factor with which every element of the input tensor is multiplied. srcDesc : cudnnTensorDescriptor Handle to a previously initialized tensor descriptor. srcData : void_p Data pointer to GPU memory associated with the tensor descriptor srcDesc. wDesc : cudnnFilterDescriptor Handle to a previously initialized filter descriptor. w : void_p Data pointer to GPU memory associated with the filter descriptor wDesc. convDesc : cudnnConvolutionDescriptor Previously initialized convolution descriptor. algo: cudnnConvolutionFwdAlgo Enumerant that specifies which convolution algorithm shoud be used to compute the results. workSpace: void_p Data pointer to GPU memory to a workspace needed to able to execute the specified algorithm. If no workspace is needed for a particular algorithm, that pointer can be nil. workSpaceSizeInBytes: long Specifies the size in bytes of the provided workSpace. beta: float Scaling factor which is applied on every element of the output tensor prior to adding the result of the convolution. destDesc : cudnnTensorDescriptor Handle to a previously initialized tensor descriptor. destData : void_p Data pointer to GPU memory associated with the tensor descriptor destDesc.", "response": "def cudnnConvolutionForward(handle, alpha, srcDesc, srcData, wDesc, w,\n                            convDesc, algo, workspace, workSpaceSizeInBytes, beta,\n                            destDesc, destData):\n    \"\"\"\"\n    Perform forward convolution. All of the form \"output = alpha * Op(inputs) + beta * output\".\n\n    This function executes convolutions or cross-correlations over src using the specified\n    filters, returning results in dest. Scaling factors alpha and beta can be used to scale\n    the input tensor and the output tensor respectively.\n\n    Parameters\n    ----------\n    handle : cudnnHandle\n        Handle to a previously created cuDNN context.\n    alpha: float\n        Scaling factor with which every element of the input tensor is multiplied.\n    srcDesc : cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n    srcData : void_p\n        Data pointer to GPU memory associated with the tensor descriptor srcDesc.\n    wDesc : cudnnFilterDescriptor\n        Handle to a previously initialized filter descriptor.\n    w : void_p\n        Data pointer to GPU memory associated with the filter descriptor wDesc.\n    convDesc : cudnnConvolutionDescriptor\n        Previously initialized convolution descriptor.\n    algo: cudnnConvolutionFwdAlgo\n        Enumerant that specifies which convolution algorithm shoud be used to\n        compute the results.\n    workSpace: void_p\n        Data pointer to GPU memory to a workspace needed to able to execute\n        the specified algorithm. If no workspace is needed for a particular\n        algorithm, that pointer can be nil.\n    workSpaceSizeInBytes: long\n        Specifies the size in bytes of the provided workSpace.\n    beta: float\n        Scaling factor which is applied on every element of the output tensor prior\n        to adding the result of the convolution.\n    destDesc : cudnnTensorDescriptor\n        Handle to a previously initialized tensor descriptor.\n    destData : void_p\n        Data pointer to GPU memory associated with the tensor descriptor destDesc.\n    \"\"\"\n\n    dataType = cudnnGetTensor4dDescriptor(destDesc)[0]\n    if dataType == cudnnDataType['CUDNN_DATA_DOUBLE']:\n        alphaRef = ctypes.byref(ctypes.c_double(alpha))\n        betaRef = ctypes.byref(ctypes.c_double(beta))\n    else:\n        alphaRef = ctypes.byref(ctypes.c_float(alpha))\n        betaRef = ctypes.byref(ctypes.c_float(beta))\n\n    status = _libcudnn.cudnnConvolutionForward(handle, alphaRef, srcDesc, srcData,\n                                            wDesc, w,\n                                            convDesc, algo, workspace,\n                                            ctypes.c_size_t(workSpaceSizeInBytes),\n                                            betaRef, destDesc, destData)\n    cudnnCheckStatus(status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cudnnCreatePoolingDescriptor():\n\n    poolingDesc = ctypes.c_void_p()\n    status = _libcudnn.cudnnCreatePoolingDescriptor(ctypes.byref(poolingDesc))\n    cudnnCheckStatus(status)\n\n    return poolingDesc.value", "response": "Create pooling descriptor.\n\n    This function creates a pooling descriptor object by allocating the memory needed to\n    hold its opaque structure,\n\n    Returns\n    -------\n    poolingDesc : cudnnPoolingDescriptor\n        Newly allocated pooling descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize a 2D pooling descriptor.", "response": "def cudnnSetPooling2dDescriptor(poolingDesc, mode, windowHeight, windowWidth,\n                                verticalPadding, horizontalPadding, verticalStride, horizontalStride):\n    \"\"\"\"\n    Initialize a 2D pooling descriptor.\n\n    This function initializes a previously created pooling descriptor object.\n\n    Parameters\n    ----------\n    poolingDesc : cudnnPoolingDescriptor\n        Handle to a previously created pooling descriptor.\n    mode : cudnnPoolingMode\n        Enumerant to specify the pooling mode.\n    windowHeight : int\n        Height of the pooling window.\n    windowWidth : int\n        Width of the pooling window.\n    verticalPadding: int\n        Size of vertical padding.\n    horizontalPadding: int\n        Size of horizontal padding.\n    verticalStride : int\n        Pooling vertical stride.\n    horizontalStride : int\n        Pooling horizontal stride.\n    \"\"\"\n\n    status = _libcudnn.cudnnSetPooling2dDescriptor(poolingDesc, mode, windowHeight,\n                                                 windowWidth, verticalPadding, horizontalPadding,\n                                                 verticalStride, horizontalStride)\n    cudnnCheckStatus(status)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cudnnActivationBackward(handle, mode, alpha, srcDesc, srcData, srcDiffDesc, srcDiffData,\n                            destDesc, destData, beta, destDiffDesc, destDiffData):\n    \"\"\"\"\n    Gradient of activation function.\n\n    This routine computes the gradient of a neuron activation function.\n\n    In-place operation is allowed for this routine; i.e., srcData and destData\n    pointers may be equal and srcDiffData and destDiffData pointers may be equal.\n    However, this requires the corresponding tensor descriptors to be identical\n    (particularly, the strides of the input and output must match for in-place operation\n    to be allowed).\n\n    Parameters\n    ----------\n    handle : cudnnHandle\n        Handle to a previously created cuDNN context.\n    mode : cudnnActivationMode\n        Enumerant to specify the activation mode.\n    alpha: float\n        Scaling factor with which every element of the input tensor is multiplied.\n    srcDesc : cudnnTensorDescriptor\n        Handle to the previously initialized input tensor descriptor.\n    srcData : void_p\n        Data pointer to GPU memory associated with the tensor descriptor\n        srcDesc.\n    srcDiffDesc : cudnnTensorDescriptor\n        Handle to the previously initialized input differential tensor descriptor.\n    srcDiffData : void_p\n        Data pointer to GPU memory associated with the tensor descriptor\n        srcDiffData.\n    destDesc : cudnnTensorDescriptor\n        Handle to the previously initialized output tensor descriptor.\n    destData : void_p\n        Data pointer to GPU memory associated with the output tensor descriptor\n        destDesc.\n    beta: float\n        Scaling factor which is applied on every element of the output tensor prior\n        to adding the result of the activation gradient. Note that if beta is zero, the\n        output is not read and can contain any uninitialized data (including Nan numbers).\n    destDiffDesc : cudnnTensorDescriptor\n        Handle to the previously initialized output differential tensor descriptor.\n    destDiffData : void_p\n        Data pointer to GPU memory associated with the output tensor descriptor\n        destDiffDesc.\n    \"\"\"\n\n    dataType = cudnnGetTensor4dDescriptor(destDesc)[0]\n    if dataType == cudnnDataType['CUDNN_DATA_DOUBLE']:\n        alphaRef = ctypes.byref(ctypes.c_double(alpha))\n        betaRef = ctypes.byref(ctypes.c_double(beta))\n    else:\n        alphaRef = ctypes.byref(ctypes.c_float(alpha))\n        betaRef = ctypes.byref(ctypes.c_float(beta))\n\n    status = _libcudnn.cudnnActivationBackward(handle, mode, alphaRef, srcDesc, srcData,\n                                               srcDiffDesc, srcDiffData,\n                                               destDesc, destData, betaRef,\n                                               destDiffDesc, destDiffData)\n    cudnnCheckStatus(status)", "response": "This routine computes the gradient of a neuron activation function in the backward operation of a previously created context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __prefix_key(self, key):\n        # If there isn't a prefix don't bother\n        if self.prefix is None:\n            return key\n\n        # Don't prefix key if it already has it\n        if key.startswith(self.prefix + \"-\"):\n            return key\n\n        return \"{0}-{1}\".format(self.prefix, key)", "response": "This will add the prefix to the key if one exists on the store"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the current dictionary to disk in JSON format.", "response": "def save(self):\n        \"\"\" Saves dictionary to disk in JSON format. \"\"\"\n        if self.filename is None:\n            raise StoreException(\"Filename must be set to write store to disk\")\n\n        # We need an atomic way of re-writing the settings, we also need to\n        # prevent only overwriting part of the settings file (see bug #116).\n        # Create a temp file and only then re-name it to the config\n        filename = \"{filename}.{date}.tmp\".format(\n            filename=self.filename,\n            date=datetime.datetime.utcnow().strftime('%Y-%m-%dT%H_%M_%S.%f')\n        )\n\n        # The `open` built-in doesn't allow us to set the mode\n        mode = stat.S_IRUSR | stat.S_IWUSR  # 0600\n        fd = os.open(filename, os.O_WRONLY | os.O_CREAT, mode)\n        fout = os.fdopen(fd, \"w\")\n        fout.write(json.dumps(self.export()))\n        fout.close()\n\n        # Now we should remove the old config\n        if os.path.isfile(self.filename):\n            os.remove(self.filename)\n\n        # Now rename the temp file to the real config file\n        os.rename(filename, self.filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the filename of the credentials. json file", "response": "def get_filename(cls):\n        \"\"\" Gets filename of store on disk \"\"\"\n        config_home = os.environ.get(\"XDG_CONFIG_HOME\", \"~/.config\")\n        config_home = os.path.expanduser(config_home)\n\n        base_path = os.path.join(config_home, \"PyPump\")\n        if not os.path.isdir(base_path):\n            os.makedirs(base_path)\n\n        return os.path.join(base_path, \"credentials.json\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(cls, webfinger, pypump):\n        filename = cls.get_filename()\n\n        if os.path.isfile(filename):\n            data = open(filename).read()\n            data = json.loads(data)\n            store = cls(data, filename=filename)\n        else:\n            store = cls(filename=filename)\n\n        store.prefix = webfinger\n        return store", "response": "Load the object from disk into a store object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pause(message='Press any key to continue . . . '):\n    if message is not None:\n        print(message, end='')\n        sys.stdout.flush()\n    getch()\n    print()", "response": "Prints the specified message if it s not None and waits for a keypress."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the covalent bonds in a list of Atoms.", "response": "def covalent_bonds(atoms, threshold=1.1):\n    \"\"\"Returns all the covalent bonds in a list of `Atom` pairs.\n\n    Notes\n    -----\n    Uses information `element_data`, which can be accessed directly\n    through this module i.e. `isambard.ampal.interactions.element_data`.\n\n    Parameters\n    ----------\n    atoms : [(`Atom`, `Atom`)]\n        List of pairs of `Atoms`.\n    threshold : float, optional\n        Allows deviation from ideal covalent bond distance to be included.\n        For example, a value of 1.1 would allow interactions up to 10% further\n        from the ideal distance to be included.\n    \"\"\"\n    bonds=[]\n    for a, b in atoms:\n        bond_distance=(\n                element_data[a.element.title()]['atomic radius'] + element_data[\n                b.element.title()]['atomic radius']) / 100\n        dist=distance(a._vector, b._vector)\n        if dist <= bond_distance * threshold:\n            bonds.append(CovalentBond(a, b, dist))\n    return bonds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_covalent_bonds(ampal, max_range=2.2, threshold=1.1, tag=True):\n    sectors=gen_sectors(ampal.get_atoms(), max_range * 1.1)\n    bonds=[]\n    for sector in sectors.values():\n        atoms=itertools.combinations(sector, 2)\n        bonds.extend(covalent_bonds(atoms, threshold=threshold))\n    bond_set=list(set(bonds))\n    if tag:\n        for bond in bond_set:\n            a, b=bond.a, bond.b\n            if 'covalent_bonds' not in a.tags:\n                a.tags['covalent_bonds']=[b]\n            else:\n                a.tags['covalent_bonds'].append(b)\n            if 'covalent_bonds' not in b.tags:\n                b.tags['covalent_bonds']=[a]\n            else:\n                b.tags['covalent_bonds'].append(a)\n    return bond_set", "response": "Returns a list of AMPAL objects that are covalent bonds in the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a graph of the covalent bond network described by the interactions.", "response": "def generate_covalent_bond_graph(covalent_bonds):\n    \"\"\"Generates a graph of the covalent bond network described by the interactions.\n\n    Parameters\n    ----------\n    covalent_bonds: [CovalentBond]\n        List of `CovalentBond`.\n\n    Returns\n    -------\n    bond_graph: networkx.Graph\n        A graph of the covalent bond network.\n    \"\"\"\n    bond_graph=networkx.Graph()\n    for inter in covalent_bonds:\n        bond_graph.add_edge(inter.a, inter.b)\n    return bond_graph"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits the bond graph between two atoms and generates subgraphs.", "response": "def generate_bond_subgraphs_from_break(bond_graph, atom1, atom2):\n    \"\"\"Splits the bond graph between two atoms to producing subgraphs.\n\n    Notes\n    -----\n    This will not work if there are cycles in the bond graph.\n\n    Parameters\n    ----------\n    bond_graph: networkx.Graph\n        Graph of covalent bond network\n    atom1: isambard.ampal.Atom\n        First atom in the bond.\n    atom2: isambard.ampal.Atom\n        Second atom in the bond.\n\n    Returns\n    -------\n    subgraphs: [networkx.Graph]\n        A list of subgraphs generated when a bond is broken in the covalent\n        bond network.\n    \"\"\"\n    bond_graph.remove_edge(atom1, atom2)\n    try:\n        subgraphs=list(networkx.connected_component_subgraphs(\n            bond_graph, copy=False))\n    finally:\n        # Add edge\n        bond_graph.add_edge(atom1, atom2)\n    return subgraphs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshorten string is above certain length.", "response": "def cap(v, l):\n    \"\"\"Shortens string is above certain length.\"\"\"\n    s = str(v)\n    return s if len(s) <= l else s[-l:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_atoms_within_distance(atoms, cutoff_distance, point):\n    return [x for x in atoms if distance(x, point) <= cutoff_distance]", "response": "Returns a list of atoms within the distance from the point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef centre_of_atoms(atoms, mass_weighted=True):\n    points = [x._vector for x in atoms]\n    if mass_weighted:\n        masses = [x.mass for x in atoms]\n    else:\n        masses = []\n    return centre_of_mass(points=points, masses=masses)", "response": "Returns centre point of any list of atoms."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assign_force_field(self, ff, mol2=False):\n        if hasattr(self, 'ligands'):\n            atoms = self.get_atoms(ligands=True, inc_alt_states=True)\n        else:\n            atoms = self.get_atoms(inc_alt_states=True)\n        for atom in atoms:\n            w_str = None\n            a_ff_id = None\n            if atom.element == 'H':\n                continue\n            elif atom.ampal_parent.mol_code in ff:\n                if atom.res_label in ff[atom.ampal_parent.mol_code]:\n                    a_ff_id = (atom.ampal_parent.mol_code, atom.res_label)\n                elif atom.res_label in ff['WLD']:\n                    a_ff_id = ('WLD', atom.res_label)\n                else:\n                    w_str = ('{} atom is not parameterised in the selected '\n                             'force field for {} residues, this will be '\n                             'ignored.').format(\n                        atom.res_label, atom.ampal_parent.mol_code)\n            elif atom.res_label in ff['WLD']:\n                a_ff_id = ('WLD', atom.res_label)\n            elif mol2 and (atom.ampal_parent.mol_code.capitalize() in ff['MOL2']):\n                a_ff_id = ('MOL2', atom.res_label.capitalize())\n            else:\n                if not mol2:\n                    w_str = ('{} ({}) atom is not parameterised in the selected'\n                             ' residue force field. Try activating the heavy '\n                             ' atom force field (haff).').format(\n                        atom.element, atom.res_label)\n                else:\n                    w_str = ('{} ({}) atom is not parameterised in the selected'\n                             ' force field.').format(atom.element, atom.res_label)\n            if w_str:\n                warnings.warn(w_str, NotParameterisedWarning)\n            atom._ff_id = a_ff_id\n        self.tags['assigned_ff'] = True\n        return", "response": "Assigns force field parameters to Atoms in the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the force field of the current object.", "response": "def update_ff(self, ff, mol2=False, force_ff_assign=False):\n        \"\"\"Manages assigning the force field parameters.\n\n        The aim of this method is to avoid unnecessary assignment of the\n        force field.\n\n        Parameters\n        ----------\n        ff: BuffForceField\n            The force field to be used for scoring.\n        mol2: bool, optional\n            If true, mol2 style labels will also be used.\n        force_ff_assign: bool, optional\n            If true, the force field will be completely reassigned, ignoring the\n            cached parameters.\n        \"\"\"\n        aff = False\n        if force_ff_assign:\n            aff = True\n        elif 'assigned_ff' not in self.tags:\n            aff = True\n        elif not self.tags['assigned_ff']:\n            aff = True\n        if aff:\n            self.assign_force_field(ff, mol2=mol2)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_internal_energy(self, assign_ff=True, ff=None, mol2=False,\n                            force_ff_assign=False):\n        \"\"\"Calculates the internal energy of the AMPAL object.\n\n        This method is assigned to the buff_internal_energy property,\n        using the default arguments.\n\n        Parameters\n        ----------\n        assign_ff: bool, optional\n            If true the force field will be updated if required.\n        ff: BuffForceField, optional\n            The force field to be used for scoring.\n        mol2: bool, optional\n            If true, mol2 style labels will also be used.\n        force_ff_assign: bool, optional\n            If true, the force field will be completely reassigned, ignoring the\n            cached parameters.\n\n        Returns\n        -------\n        BUFF_score: BUFFScore\n            A BUFFScore object with information about each of the interactions and\n            the atoms involved.\n        \"\"\"\n        if not ff:\n            ff = global_settings['buff']['force_field']\n        if assign_ff:\n            self.update_ff(ff, mol2=mol2, force_ff_assign=force_ff_assign)\n        interactions = find_intra_ampal(self, ff.distance_cutoff)\n        buff_score = score_interactions(interactions, ff)\n        return buff_score", "response": "Calculates the internal energy of the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rotate(self, angle, axis, point=None, radians=False, inc_alt_states=True):\n        q = Quaternion.angle_and_axis(angle=angle, axis=axis, radians=radians)\n        for atom in self.get_atoms(inc_alt_states=inc_alt_states):\n            atom._vector = q.rotate_vector(v=atom._vector, point=point)\n        return", "response": "Rotates every atom in the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate(self, vector, inc_alt_states=True):\n        vector = numpy.array(vector)\n        for atom in self.get_atoms(inc_alt_states=inc_alt_states):\n            atom._vector += vector\n        return", "response": "Translates every atom in the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rmsd(self, other, backbone=False):\n        assert type(self) == type(other)\n        if backbone and hasattr(self, 'backbone'):\n            points1 = self.backbone.get_atoms()\n            points2 = other.backbone.get_atoms()\n        else:\n            points1 = self.get_atoms()\n            points2 = other.get_atoms()\n        points1 = [x._vector for x in points1]\n        points2 = [x._vector for x in points2]\n        return rmsd(points1=points1, points2=points2)", "response": "Calculates the RMSD between two AMPAL objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, item):\n        if isinstance(item, Monomer):\n            self._monomers.append(item)\n        else:\n            raise TypeError(\n                'Only Monomer objects can be appended to an Polymer.')\n        return", "response": "Appends a Monomer to the Polymer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend(self, polymer):\n        if isinstance(polymer, Polymer):\n            self._monomers.extend(polymer)\n        else:\n            raise TypeError(\n                'Only Polymer objects may be merged with a Polymer using unary operator \"+\".')\n        return", "response": "Extends the Polymer with the contents of another Polymer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve all the Monomers from the AMPAL object.", "response": "def get_monomers(self, ligands=True):\n        \"\"\"Retrieves all the `Monomers` from the AMPAL object.\n\n        Parameters\n        ----------\n        ligands : bool, optional\n            If true, will include ligand `Monomers`.\n        \"\"\"\n        if ligands and self.ligands:\n            monomers = self._monomers + self.ligands._monomers\n        else:\n            monomers = self._monomers\n        return iter(monomers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_atoms(self, ligands=True, inc_alt_states=False):\n        if ligands and self.ligands:\n            monomers = self._monomers + self.ligands._monomers\n        else:\n            monomers = self._monomers\n        atoms = itertools.chain(\n            *(list(m.get_atoms(inc_alt_states=inc_alt_states)) for m in monomers))\n        return atoms", "response": "Returns an iterator of all the Atoms in the Polymer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrelabels the either in numerically or using a list of labels.", "response": "def relabel_monomers(self, labels=None):\n        \"\"\"Relabels the either in numerically or using a list of labels.\n\n        Parameters\n        ----------\n        labels : list, optional\n            A list of new labels.\n\n        Raises\n        ------\n        ValueError\n            Raised if the number of labels does not match the number of\n            component Monoer objects.\n        \"\"\"\n        if labels:\n            if len(self._monomers) == len(labels):\n                for monomer, label in zip(self._monomers, labels):\n                    monomer.id = str(label)\n            else:\n                error_string = (\n                    'Number of Monomers ({}) and number of labels '\n                    '({}) must be equal.')\n                raise ValueError(error_string.format(\n                    len(self._monomers), len(labels)))\n        else:\n            for i, monomer in enumerate(self._monomers):\n                monomer.id = str(i + 1)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrelabel all Atoms in numerical order.", "response": "def relabel_atoms(self, start=1):\n        \"\"\"Relabels all `Atoms` in numerical order.\n\n        Parameters\n        ----------\n        start : int, optional\n            Offset the labelling by `start` residues.\n        \"\"\"\n        counter = start\n        for atom in self.get_atoms():\n            atom.id = counter\n            counter += 1\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a PDB string for the Polymer.", "response": "def make_pdb(self, alt_states=False, inc_ligands=True):\n        \"\"\"Generates a PDB string for the `Polymer`.\n\n        Parameters\n        ----------\n        alt_states : bool, optional\n            Include alternate conformations for `Monomers` in PDB.\n        inc_ligands : bool, optional\n            Includes `Ligands` in PDB.\n\n        Returns\n        -------\n        pdb_str : str\n            String of the pdb for the `Polymer`. Generated using information\n            from the component `Monomers`.\n        \"\"\"\n        if any([False if x.id else True for x in self._monomers]):\n            self.relabel_monomers()\n        if self.ligands and inc_ligands:\n            monomers = self._monomers + self.ligands._monomers\n        else:\n            monomers = self._monomers\n        pdb_str = write_pdb(monomers, self.id, alt_states=alt_states)\n        return pdb_str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_pdb(self):\n        pdb_str = write_pdb(\n            [self], ' ' if not self.ampal_parent else self.ampal_parent.id)\n        return pdb_str", "response": "Generates a PDB string for the Monomer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a unique ID for the Atom based on its parents.", "response": "def unique_id(self):\n        \"\"\"Creates a unique ID for the `Atom` based on its parents.\n\n        Returns\n        -------\n        unique_id : (str, str, str)\n            (polymer.id, residue.id, atom.id)\n        \"\"\"\n        chain = self.ampal_parent.ampal_parent.id\n        residue = self.ampal_parent.id\n        return chain, residue, self.id"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrotate the Atom by angle.", "response": "def rotate(self, angle, axis, point=None, radians=False):\n        \"\"\"Rotates `Atom` by `angle`.\n\n        Parameters\n        ----------\n        angle : float\n            Angle that `Atom` will be rotated.\n        axis : 3D Vector (tuple, list, numpy.array)\n            Axis about which the `Atom` will be rotated.\n        point : 3D Vector (tuple, list, numpy.array), optional\n            Point that the `axis` lies upon. If `None` then the origin is used.\n        radians : bool, optional\n            True is `angle` is define in radians, False is degrees.\n        \"\"\"\n        q = Quaternion.angle_and_axis(angle=angle, axis=axis, radians=radians)\n        self._vector = q.rotate_vector(v=self._vector, point=point)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate the atom to the vector.", "response": "def translate(self, vector):\n        \"\"\"Translates `Atom`.\n\n        Parameters\n        ----------\n        vector : 3D Vector (tuple, list, numpy.array)\n            Vector used for translation.\n        inc_alt_states : bool, optional\n            If true, will rotate atoms in all states i.e. includes\n            alternate conformations for sidechains.\n        \"\"\"\n        vector = numpy.array(vector)\n        for atom in self.get_atoms(inc_alt_states=inc_alt_states):\n            atom._vector += vector\n        return\n        self._vector += numpy.array(vector)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_from_mmcif(mmcif, path=True):\n    if path:\n        with open(mmcif, 'r') as foo:\n            lines = foo.readlines()\n    else:\n        lines = mmcif.splitlines()\n    lines = [' '.join(x.strip().split()) for x in lines]\n\n    # Some of the data in a .cif files are stored between 'loop_' to initiate a loop, and '#' to terminate it.\n    # The variable 'loop' is a flag to keep track of this behaviour.\n    loop = False\n\n    # Set up the dictionary to populate as the lines of the .cif file are iterated over.\n    cif_data = {}\n\n    for i, line in enumerate(lines):\n\n        if not line:\n            continue\n\n        # hash signifies end of a loop. Ensure loop flag is set to False.\n        if line == '#':\n            loop = False\n            continue\n\n        if not loop:\n            # This line initiates a loop section, in which keys are listed first,\n            # followed by lines of data in which the values are listed in the same order as the above keys.\n            # The values in the loop section will be stored as lists - there are multiple values for one key.\n            # An example of this type of data is the 'REVDAT' section, which stores details on the (potentially\n            # numerous) various revisions made to the PDB file during its history.\n\n            if line[:5] == 'loop_':\n                loop = True\n                key_list = []\n                continue\n\n            # Lines beginning with '_' start with data names, i.e. keys in the cif_data dictionary.\n            elif line[0] == '_':\n                # If line consists only of a key, then subsequent lines may contain the associated value.\n                if len(line.split()) == 1:\n                    current_key = line\n                    count = 1\n                    while True:\n                        # Look forward until a key is found, keeping count of the number of lines in between.\n                        try:\n                            if lines[i + count][0] != '_':\n                                count += 1\n\n                            # prevent infinite loop.\n                            elif i + count > len(lines):\n                                break\n\n                            else:\n                                if count > 1:\n                                    try:\n                                        cif_data[current_key] = ' '.join(lines[i + 1: i + count])\n                                    except IndexError:\n                                        cif_data[current_key] = None\n                                else:\n                                    cif_data[current_key] = None\n                                break\n                        except IndexError:\n                            break\n                    continue\n\n                # Simplest case. Line is a key-value pair, with the key identified by its first character, '_'.\n                elif len(line.split()) > 1:\n                    line = line.split()\n                    try:\n                        cif_data[line[0]] = ' '.join(line[1:])\n                    except IndexError:\n                        cif_data[line[0]] = None\n                    continue\n\n            # Line is one of multiple lines that are combined into a value in the while True: loop above.\n            else:\n                continue\n\n        else:\n            # Within a loop section, keys are identified by their first character '_'.\n            # Add them to the list of keys in the loop.\n            if line[0] == '_':\n                if len(line.split()) == 1:\n                    key_list.append(line)\n                    if line not in cif_data.keys():\n                        cif_data[line] = []\n\n            # Within a loop section, the values are listed within a single space-separated line in the same order\n            # that the keys were listed at the start of the loop.\n            else:\n                # Cannot do a simple split if any of the values themselves are strings containing at least one space.\n                if '\\\"' in line and line.count('\\\"') % 2 == 0:\n                    line_parts = [x.strip() for x in line.split('\\\"') if x]\n                    line = []\n                    for part in line_parts:\n                        if line_parts.index(part) % 2 == 0:\n                            for x in part.split():\n                                line.append(x)\n                        else:\n                            line.append(part)\n\n                elif '\\'' in line and line.count('\\'') % 2 == 0:\n                    line = [x.strip() for x in line.split('\\'') if x]\n\n                elif len(key_list) == len(line.split()):\n                    line = line.split()\n\n                if len(key_list) == len(line):\n                    for j, v in enumerate(line):\n                        cif_data[key_list[j]].append(line[j])\n                else:\n                    # CURRENTLY THERE IS A PROBLEM WITH REALLY LONG LOOPS eg _pdbx_refine_tls*, _pdbx_struct_oper_list*\n                    # The values span multiple lines, and therefore do not satisfy\n                    # the condition of the above 'if' statement.\n                    # A correction for this needs to keep track of the value count on subsequent lines,\n                    # until the 'if' condition is met.\n                    continue\n\n    return cif_data", "response": "Parse a mmcif file into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a subset of the data in a cif_data dictionary and return a dictionary containing the keys of the protein_dict.", "response": "def get_protein_dict(cif_data):\n    \"\"\" Parse cif_data dict for a subset of its data.\n\n    Notes\n    -----\n    cif_data dict contains all the data from the .cif file, with values as strings.\n    This function returns a more 'human readable' dictionary of key-value pairs.\n    The keys have simpler (and still often more descriptive!) names, and the values are not restricted to being strings.\n    To add more key-value pairs to the protein_dict, follow the patterns used in this function.\n    Add the key and youre name for it to mmcif_data_names.\n    Will it need further parsing, like with the dates in the function below?\n    If the value is not a string, add it to a list of data-types at the end of the function.\n    More information on what key-value pairs can be obtained can be gleaned by examining cif_data and/or by viewing the\n    mmcif resource on the PDB website: http://mmcif.wwpdb.org/docs/pdb_to_pdbx_correspondences.html\n    WARNING: Do not alter the keys of protein_dict without caution.\n    The keys of protein_dict MUST match the column names of the Protein model in the protgraph database.\n\n    Parameters\n    ----------\n    cif_data : dict\n        Key/value pairs taken directly from a .cif file.\n        Output of the function dict_from_mmcif.\n\n    Returns\n    -------\n    protein_dict : dict\n        A dictionary containing a parsed subset of the data in cif_data.\n        The keys have the same name as fields in the Protein model.\n    \"\"\"\n\n    # Dictionary relating the keys of protein_dict (column names in Protein model) to the keys of cif_data.\n    mmcif_data_names = {\n        'keywords': '_struct_keywords.text',\n        'header': '_struct_keywords.pdbx_keywords',\n        'space_group': '_symmetry.space_group_name_H-M',\n        'experimental_method': '_exptl.method',\n        'crystal_growth': '_exptl_crystal_grow.pdbx_details',\n        'resolution': '_refine.ls_d_res_high',\n        'r_value_obs': '_refine.ls_R_factor_obs',\n        'atoms_protein': '_refine_hist.pdbx_number_atoms_protein',\n        'atoms_solvent': '_refine_hist.number_atoms_solvent',\n        'atoms_ligand': '_refine_hist.pdbx_number_atoms_ligand',\n        'atoms_nucleic_acid': '_refine_hist.pdbx_number_atoms_nucleic_acid',\n        'atoms_total': '_refine_hist.number_atoms_total',\n        'title': '_struct.title',\n        'pdb_descriptor': '_struct.pdbx_descriptor',\n        'model_details': '_struct.pdbx_model_details',\n        'casp_flag': '_struct.pdbx_CASP_flag',\n        'model_type_details': '_struct.pdbx_model_type_details',\n        'ncbi_taxonomy': '_entity_src_nat.pdbx_ncbi_taxonomy_id',\n        'ncbi_taxonomy_gene': '_entity_src_gen.pdbx_gene_src_ncbi_taxonomy_id',\n        'ncbi_taxonomy_host_org': '_entity_src_gen.pdbx_host_org_ncbi_taxonomy_id',\n    }\n\n    # Set up initial protein_dict.\n    protein_dict = {}\n    for column_name, cif_name in mmcif_data_names.items():\n        try:\n            data = cif_data[cif_name]\n        except IndexError:\n            data = None\n        except KeyError:\n            data = None\n        protein_dict[column_name] = data\n\n    # These entries are modified from the mmcif dictionary.\n    # There may be many revision dates in cif_data. We save the original deposition, release and last_modified dates.\n    # If there are many dates, they will be in a list in cif_data, otherwise it's one date in a string\n    # Is there a tidier way to do this?\n    if isinstance(cif_data['_database_PDB_rev.date_original'], str):\n        protein_dict['deposition_date'] = cif_data['_database_PDB_rev.date_original']\n    else:\n        protein_dict['deposition_date'] = cif_data['_database_PDB_rev.date_original'][0]\n    if isinstance(cif_data['_database_PDB_rev.date'], str):\n        protein_dict['release_date'] = cif_data['_database_PDB_rev.date']\n        protein_dict['last_modified_date'] = cif_data['_database_PDB_rev.date']\n    else:\n        protein_dict['release_date'] = cif_data['_database_PDB_rev.date'][0]\n        protein_dict['last_modified_date'] = cif_data['_database_PDB_rev.date'][-1]\n\n    # crystal_growth should be a string or None\n    crystal_growth = protein_dict['crystal_growth']\n    if type(crystal_growth) == list and len(crystal_growth) >= 1:\n        protein_dict['crystal_growth'] = crystal_growth[0]\n    else:\n        protein_dict['crystal_growth'] = None\n\n    # taxonomy data types should be ints, not lists\n    taxonomy_keys = ['ncbi_taxonomy', 'ncbi_taxonomy_gene', 'ncbi_taxonomy_host_org']\n    for taxonomy_key in taxonomy_keys:\n        if protein_dict[taxonomy_key]:\n            if type(protein_dict[taxonomy_key]) == list:\n                try:\n                    protein_dict[taxonomy_key] = int(protein_dict[taxonomy_key][0])\n                except ValueError or IndexError:\n                    protein_dict[taxonomy_key] = None\n\n    # Convert data types from strings to their correct data type.\n    ints = ['atoms_ligand', 'atoms_nucleic_acid', 'atoms_protein', 'atoms_solvent', 'atoms_total']\n    floats = ['r_value_obs', 'resolution']\n    dates = ['deposition_date', 'release_date', 'last_modified_date']\n\n    for k, v in protein_dict.items():\n        if v:\n            if v == '?' or v == 'None' or v == '.':\n                protein_dict[k] = None\n            elif k in ints:\n                protein_dict[k] = int(v)\n            elif k in floats:\n                protein_dict[k] = float(v)\n            elif k in dates:\n                protein_dict[k] = datetime.datetime.strptime(v, '%Y-%m-%d')\n            # Parse awkward strings from cif_data.\n            elif type(v) == str:\n                v = v.replace('loop_', '')\n                v = v.replace(' # ', '')\n                if v[0] == v[-1] == '\\'':\n                    protein_dict[k] = v[1:-1]\n\n    return protein_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake the output of a PISCES cull and returns in a usable dictionary.", "response": "def parse_PISCES_output(pisces_output, path=False):\n    \"\"\" Takes the output list of a PISCES cull and returns in a usable dictionary.\n\n    Notes\n    -----\n    Designed for outputs of protein sequence redundancy culls conducted using the PISCES server.\n    http://dunbrack.fccc.edu/PISCES.php\n    G. Wang and R. L. Dunbrack, Jr. PISCES: a protein sequence culling server. Bioinformatics, 19:1589-1591, 2003.\n\n    Parameters\n    ----------\n    pisces_output : str or path\n        Output list of non-redundant protein chains from PISCES, or path to text file.\n    path : bool\n        True if path given rather than string.\n\n    Returns\n    -------\n    pisces_dict : dict\n        Data output by PISCES in dictionary form.\n    \"\"\"\n    pisces_dict = {}\n    if path:\n        pisces_path = Path(pisces_output)\n        pisces_content = pisces_path.read_text().splitlines()[1:]\n    else:\n        pisces_content = pisces_output.splitlines()[1:]\n    for line in pisces_content:\n        pdb = line.split()[0][:4].lower()\n        chain = line.split()[0][-1]\n        pdb_dict = {'length': line.split()[1],\n                    'method': line.split()[2],\n                    'resolution': line.split()[3],\n                    'R-factor': line.split()[4],\n                    'R-free': line.split()[5]}\n        if pdb in pisces_dict:\n            pisces_dict[pdb]['chains'].append(chain)\n        else:\n            pdb_dict['chains'] = [chain]\n            pisces_dict[pdb] = pdb_dict\n    return pisces_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_decode(URL, encoding='utf-8', verbose=True):\n    if verbose:\n        print(\"Downloading data from \" + URL)\n    req = Request(URL)\n    try:\n        with urlopen(req) as u:\n            decoded_file = u.read().decode(encoding)\n    except URLError as e:\n        if hasattr(e, 'reason'):\n            print('Server could not be reached.')\n            print('Reason: ', e.reason)\n        elif hasattr(e, 'code'):\n            print('The server couldn\\'t fulfill the request.')\n            print('Error code: ', e.code)\n        return None\n    return decoded_file", "response": "Downloads data from URL and returns decoded contents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking Olderado web server and returns the most representative conformation of the PDB NMR structure.", "response": "def olderado_best_model(pdb_id):\n    \"\"\" Checks the Olderado web server and returns the most representative conformation for PDB NMR structures.\n\n    Notes\n    -----\n    Uses OLDERADO from the EBI.\n    See http://www.ebi.ac.uk/pdbe/nmr/olderado/ and citations therein.\n\n    Parameters\n    ----------\n    pdb_id : str\n        The 4-character PDB code for the NMR structure of interest.\n\n    Returns\n    -------\n    model_no : int\n        The conformation number of the most-representative conformation.\n\n    Raises\n    ------\n    ValueError\n        If the model number it finds is not an integer. This might indicate that the website format has changed.\n    \"\"\"\n    pdb_code = pdb_id[:4].lower()\n    olderado_url = 'http://www.ebi.ac.uk/pdbe/nmr/olderado/searchEntry?pdbCode=' + pdb_code\n    olderado_page = download_decode(olderado_url, verbose=False)\n    if olderado_page:\n        parsed_page = BeautifulSoup(olderado_page, 'html.parser')\n    else:\n        return None\n    try:\n        best_model = parsed_page.find_all('td')[1]\n    except IndexError:\n        print(\"No model info could be found for {0} - ensure that it's an NMR structure.\".format(pdb_id))\n        return None\n    try:\n        model_no = int(best_model.string)\n    except ValueError as v:\n        print(\"Did not find a number for best model.\")\n        raise v\n    return model_no"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef buff_eval(params):\n    specification, sequence, parsed_ind = params\n    model = specification(*parsed_ind)\n    model.build()\n    model.pack_new_sequences(sequence)\n    return model.buff_interaction_energy.total_energy", "response": "Builds and evaluates BUFF energy of model in parallelization\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding and evaluates BUFF internal energy of a single node in parallelization", "response": "def buff_internal_eval(params):\n    \"\"\"Builds and evaluates BUFF internal energy of a model in parallelization\n\n    Parameters\n    ----------\n    params: list\n        Tuple containing the specification to be built, the sequence\n        and the parameters for model building.\n\n    Returns\n    -------\n    model.bude_score: float\n        BUFF internal energy score to be assigned to particle fitness\n        value.\n    \"\"\"\n\n    specification, sequence, parsed_ind = params\n    model = specification(*parsed_ind)\n    model.build()\n    model.pack_new_sequences(sequence)\n    return model.buff_internal_energy.total_energy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a model and runs profit against a reference model.", "response": "def rmsd_eval(rmsd_params):\n    \"\"\"Builds a model and runs profit against a reference model.\n\n    Parameters\n    ----------\n    rmsd_params\n\n    Returns\n    -------\n    rmsd: float\n        rmsd against reference model as calculated by profit.\n    \"\"\"\n    specification, sequence, parsed_ind, reference_pdb = rmsd_params\n    model = specification(*parsed_ind)\n    model.pack_new_sequences(sequence)\n    ca, bb, aa = run_profit(model.pdb, reference_pdb, path1=False, path2=False)\n    return bb"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the BUFF score for interaction between two AMPAL objects.", "response": "def comparator_eval(comparator_params):\n    \"\"\"Gets BUFF score for interaction between two AMPAL objects\n    \"\"\"\n    top1, top2, params1, params2, seq1, seq2, movements = comparator_params\n    xrot, yrot, zrot, xtrans, ytrans, ztrans = movements\n    obj1 = top1(*params1)\n    obj2 = top2(*params2)\n    obj2.rotate(xrot, [1, 0, 0])\n    obj2.rotate(yrot, [0, 1, 0])\n    obj2.rotate(zrot, [0, 0, 1])\n    obj2.translate([xtrans, ytrans, ztrans])\n    model = obj1 + obj2\n    model.relabel_all()\n    model.pack_new_sequences(seq1 + seq2)\n    return model.buff_interaction_energy.total_energy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_individual(self, individual):\n        scaled_ind = []\n        for i in range(len(self._params['value_means'])):\n            scaled_ind.append(self._params['value_means'][i] + (\n                individual[i] * self._params['value_ranges'][i]))\n        fullpars = list(self._params['arrangement'])\n        for k in range(len(self._params['variable_parameters'])):\n            for j in range(len(fullpars)):\n                if fullpars[j] == self._params['variable_parameters'][k]:\n                    fullpars[j] = scaled_ind[k]\n        return fullpars", "response": "Converts a deap individual into a full list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_opt(self, popsize, numgen, processors,\n                plot=False, log=False, **kwargs):\n        \"\"\"\n        Runs the optimizer.\n        :param popsize:\n        :param numgen:\n        :param processors:\n        :param plot:\n        :param log:\n        :param kwargs:\n        :return:\n        \"\"\"\n        self._params['popsize'] = popsize\n        self._params['numgen'] = numgen\n        self._params['processors'] = processors\n        self._params['plot'] = plot\n        self._params['log'] = log\n        # allows us to pass in additional arguments e.g. neighbours\n        self._params.update(**kwargs)\n        self.halloffame = tools.HallOfFame(1)\n        self.stats = tools.Statistics(lambda thing: thing.fitness.values)\n        self.stats.register(\"avg\", numpy.mean)\n        self.stats.register(\"std\", numpy.std)\n        self.stats.register(\"min\", numpy.min)\n        self.stats.register(\"max\", numpy.max)\n        self.logbook = tools.Logbook()\n        self.logbook.header = [\"gen\", \"evals\"] + self.stats.fields\n        self._params['model_count'] = 0\n        start_time = datetime.datetime.now()\n        self.initialize_pop()\n        for g in range(self._params['numgen']):\n            self.update_pop()\n            self.halloffame.update(self.population)\n            self.logbook.record(gen=g, evals=self._params['evals'],\n                                **self.stats.compile(self.population))\n            print(self.logbook.stream)\n        end_time = datetime.datetime.now()\n        time_taken = end_time - start_time\n        self._params['time_taken'] = time_taken\n        print(\"Evaluated {0} models in total\".format(\n            self._params['model_count']))\n        print(\"Best fitness is {0}\".format(self.halloffame[0].fitness))\n        print(\"Best parameters are {0}\".format(self.parse_individual(\n            self.halloffame[0])))\n        for i, entry in enumerate(self.halloffame[0]):\n            if entry > 0.95:\n                print(\n                    \"Warning! Parameter {0} is at or near maximum allowed \"\n                    \"value\\n\".format(i + 1))\n            elif entry < -0.95:\n                print(\n                    \"Warning! Parameter {0} is at or near minimum allowed \"\n                    \"value\\n\".format(i + 1))\n        if self._params['log']:\n            self.log_results()\n        if self._params['plot']:\n            print('----Minimisation plot:')\n            plt.figure(figsize=(5, 5))\n            plt.plot(range(len(self.logbook.select('min'))),\n                     self.logbook.select('min'))\n            plt.xlabel('Iteration', fontsize=20)\n            plt.ylabel('Score', fontsize=20)", "response": "Runs the optimizer.\n        :param popsize:\n        :param numgen:\n        :param processors:\n        :param plot:\n        :param log:\n        :param kwargs:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parameters(self, sequence, value_means, value_ranges, arrangement):\n        self._params['sequence'] = sequence\n        self._params['value_means'] = value_means\n        self._params['value_ranges'] = value_ranges\n        self._params['arrangement'] = arrangement\n        if any(x <= 0 for x in self._params['value_ranges']):\n            raise ValueError(\"range values must be greater than zero\")\n        self._params['variable_parameters'] = []\n        for i in range(len(self._params['value_means'])):\n            self._params['variable_parameters'].append(\n                \"\".join(['var', str(i)]))\n        if len(set(arrangement).intersection(\n                self._params['variable_parameters'])) != len(\n                    self._params['value_means']):\n            raise ValueError(\"argument mismatch!\")\n        if len(self._params['value_ranges']) != len(\n                self._params['value_means']):\n            raise ValueError(\"argument mismatch!\")", "response": "Relates the individual to be evolved to the full parameter string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the results of the minimization.", "response": "def log_results(self):\n        \"\"\"Saves files for the minimization.\n\n        Notes\n        -----\n        Currently saves a logfile with best individual and a pdb of\n        the best model.\n        \"\"\"\n        best_ind = self.halloffame[0]\n        model_params = self.parse_individual(\n            best_ind)  # need to change name of 'params'\n        with open(\n                '{0}{1}_log.txt'.format(\n                    self._params['output_path'],\n                    self._params['run_id']), 'a+') as log_file:\n            log_file.write('\\nEvaluated {0} models in total\\n'.format(\n                self._params['model_count']))\n            log_file.write('Run ID is {0}\\n'.format(self._params['run_id']))\n            log_file.write('Best fitness is {0}\\n'.format(\n                self.halloffame[0].fitness))\n            log_file.write(\n                'Parameters of best model are {0}\\n'.format(model_params))\n            log_file.write(\n                'Best individual is {0}\\n'.format(self.halloffame[0]))\n            for i, entry in enumerate(self.halloffame[0]):\n                if entry > 0.95:\n                    log_file.write(\n                        \"Warning! Parameter {0} is at or near maximum allowed \"\n                        \"value\\n\".format(i + 1))\n                elif entry < -0.95:\n                    log_file.write(\n                        \"Warning! Parameter {0} is at or near minimum allowed \"\n                        \"value\\n\".format(i + 1))\n            log_file.write('Minimization history: \\n{0}'.format(self.logbook))\n        with open('{0}{1}_bestmodel.pdb'.format(\n                self._params['output_path'],\n                self._params['run_id']), 'w') as output_file:\n            model = self._params['specification'](*model_params)\n            model.build()\n            model.pack_new_sequences(self._params['sequence'])\n            output_file.write(model.pdb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef best_model(self):\n        if hasattr(self, 'halloffame'):\n            model = self._params['specification'](\n                *self.parse_individual(self.halloffame[0]))\n            model.pack_new_sequences(self._params['sequence'])\n            return model\n        else:\n            raise NameError('No best model found, have you ran the optimiser?')", "response": "Rebuilds the AMPAL model from an optimisation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrebuild a model and compares it to a reference model.", "response": "def funnel_rebuild(psg_trm_spec):\n        \"\"\"Rebuilds a model and compares it to a reference model.\n\n        Parameters\n        ----------\n        psg_trm: (([float], float, int), AMPAL, specification)\n            A tuple containing the parameters, score and generation for a\n            model as well as a model of the best scoring parameters.\n\n        Returns\n        -------\n        energy_rmsd_gen: (float, float, int)\n            A triple containing the BUFF score, RMSD to the top model\n            and generation of a model generated during the minimisation.\n        \"\"\"\n        param_score_gen, top_result_model, specification = psg_trm_spec\n        params, score, gen = param_score_gen\n        model = specification(*params)\n        rmsd = top_result_model.rmsd(model)\n        return rmsd, score, gen"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns indices to individuals in population.", "response": "def initialize_pop(self):\n        \"\"\"Assigns indices to individuals in population.\"\"\"\n        self.toolbox.register(\"individual\", self.generate)\n        self.toolbox.register(\"population\", tools.initRepeat,\n                              list, self.toolbox.individual)\n        self.population = self.toolbox.population(n=self._params['popsize'])\n        if self._params['neighbours']:\n            for i in range(len(self.population)):\n                self.population[i].ident = i\n                self.population[i].neighbours = list(\n                    set(\n                        [(i - x) % len(self.population)\n                         for x in range(1, self._params['neighbours'] + 1)] +\n                        [(i + x) % len(self.population)\n                         for x in range(1, self._params['neighbours'] + 1)]\n                    ))\n        self.assign_fitnesses(self.population)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the population according to crossover and fitness criteria.", "response": "def update_pop(self):\n        \"\"\"Updates the population according to crossover and fitness criteria.\n        \"\"\"\n        candidates = []\n        for ind in self.population:\n            candidates.append(self.crossover(ind))\n        self._params['model_count'] += len(candidates)\n        self.assign_fitnesses(candidates)\n        for i in range(len(self.population)):\n            if candidates[i].fitness > self.population[i].fitness:\n                self.population[i] = candidates[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate initial population with random positions and speeds.", "response": "def initialize_pop(self):\n        \"\"\"Generates initial population with random positions and speeds.\"\"\"\n        self.population = self.toolbox.swarm(n=self._params['popsize'])\n        if self._params['neighbours']:\n            for i in range(len(self.population)):\n                self.population[i].ident = i\n                self.population[i].neighbours = list(\n                    set(\n                        [(i - x) % len(self.population)\n                         for x in range(1, self._params['neighbours'] + 1)] +\n                        [i] +\n                        [(i + x) % len(self.population)\n                         for x in range(1, self._params['neighbours'] + 1)]\n                    ))\n        else:\n            for i in range(len(self.population)):\n                self.population[i].ident = i\n                self.population[i].neighbours = [\n                    x for x in range(len(self.population))]\n        self.assign_fitnesses(self.population)\n        for part in self.population:\n            part.best = creator.Particle(part)\n            part.best.fitness.values = part.fitness.values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(self):\n        part = creator.Particle(\n            [random.uniform(-1, 1)\n             for _ in range(len(self._params['value_means']))])\n        part.speed = [\n            random.uniform(-self._params['max_speed'],\n                           self._params['max_speed'])\n            for _ in range(len(self._params['value_means']))]\n        part.smin = -self._params['max_speed']\n        part.smax = self._params['max_speed']\n        part.ident = None\n        part.neighbours = None\n        return part", "response": "Generates a new particle object from the parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning fitnesses to particles that are within bounds.", "response": "def update_pop(self):\n        \"\"\"Assigns fitnesses to particles that are within bounds.\"\"\"\n        valid_particles = []\n        invalid_particles = []\n        for part in self.population:\n            if any(x > 1 or x < -1 for x in part):\n                invalid_particles.append(part)\n            else:\n                valid_particles.append(part)\n        self._params['model_count'] += len(valid_particles)\n        for part in valid_particles:\n            self.update_particle(part)\n        self.assign_fitnesses(valid_particles)\n        for part in valid_particles:\n            if part.fitness > part.best.fitness:\n                part.best = creator.Particle(part)\n                part.best.fitness = part.fitness\n        for part in invalid_particles:\n            self.update_particle(part)\n        self.population[:] = valid_particles + invalid_particles\n        self.population.sort(key=lambda x: x.ident)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize_pop(self):\n        self.initialize_cma_es(\n            sigma=self._params['sigma'], weights=self._params['weights'],\n            lambda_=self._params['popsize'],\n            centroid=[0] * len(self._params['value_means']))\n        self.toolbox.register(\"individual\", self.make_individual)\n        self.toolbox.register(\"generate\", self.generate,\n                              self.toolbox.individual)\n        self.toolbox.register(\"population\", tools.initRepeat,\n                              list, self.initial_individual)\n        self.toolbox.register(\"update\", self.update)\n        self.population = self.toolbox.population(n=self._params['popsize'])\n        self.assign_fitnesses(self.population)\n        self._params['model_count'] += len(self.population)", "response": "Generates the initial population and assigns fitnesses."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initial_individual(self):\n        ind = creator.Individual(\n            [random.uniform(-1, 1)\n             for _ in range(len(self._params['value_means']))])\n        return ind", "response": "Generates an individual with random parameters within bounds."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_cma_es(self, **kwargs):\n        self.params = kwargs\n\n        # Create a centroid as a numpy array\n        self.centroid = numpy.array([0] * len(self._params['value_means']))\n\n        self.dim = len(self.centroid)\n        self.sigma = self.params.get(\"sigma\", 0.5)\n        self.pc = numpy.zeros(self.dim)\n        self.ps = numpy.zeros(self.dim)\n        self.chiN = numpy.sqrt(self.dim) * (\n            1 - 1. / (4. * self.dim) + 1. / (21. * self.dim ** 2))\n\n        self.C = self.params.get(\"cmatrix\", numpy.identity(self.dim))\n        self.diagD, self.B = numpy.linalg.eigh(self.C)\n\n        indx = numpy.argsort(self.diagD)\n        self.diagD = self.diagD[indx] ** 0.5\n        self.B = self.B[:, indx]\n        self.BD = self.B * self.diagD\n\n        self.cond = self.diagD[indx[-1]] / self.diagD[indx[0]]\n\n        self.lambda_ = self.params.get(\n            \"lambda_\", int(4 + 3 * numpy.log(self.dim)))\n        self.update_count = 0\n        self.computeParams(self.params)\n        return", "response": "A strategy that will keep track of the basic parameters and the initial covariance matrix of the individual."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, population):\n        population.sort(key=lambda ind: ind.fitness, reverse=True)\n\n        old_centroid = self.centroid\n        self.centroid = numpy.dot(self.weights, population[0:self.mu])\n\n        c_diff = self.centroid - old_centroid\n\n        # Cumulation : update evolution path\n        self.ps = (1 - self.cs) * self.ps \\\n            + numpy.sqrt(self.cs * (2 - self.cs) * self.mueff) / self.sigma \\\n            * numpy.dot(self.B, (1. / self.diagD)\n                        * numpy.dot(self.B.T, c_diff))\n\n        hsig = float((numpy.linalg.norm(self.ps) /\n                      numpy.sqrt(1. - (1. - self.cs) **\n                                 (2. * (self.update_count + 1.))) / self.chiN\n                      < (1.4 + 2. / (self.dim + 1.))))\n\n        self.update_count += 1\n\n        self.pc = (1 - self.cc) * self.pc + hsig \\\n            * numpy.sqrt(self.cc * (2 - self.cc) * self.mueff) / self.sigma \\\n            * c_diff\n\n        # Update covariance matrix\n        artmp = population[0:self.mu] - old_centroid\n        self.C = (1 - self.ccov1 - self.ccovmu + (1 - hsig)\n                  * self.ccov1 * self.cc * (2 - self.cc)) * self.C \\\n            + self.ccov1 * numpy.outer(self.pc, self.pc) \\\n            + self.ccovmu * numpy.dot((self.weights * artmp.T), artmp) \\\n            / self.sigma ** 2\n\n        self.sigma *= numpy.exp((numpy.linalg.norm(self.ps) / self.chiN - 1.)\n                                * self.cs / self.damps)\n\n        self.diagD, self.B = numpy.linalg.eigh(self.C)\n        indx = numpy.argsort(self.diagD)\n\n        self.cond = self.diagD[indx[-1]] / self.diagD[indx[0]]\n\n        self.diagD = self.diagD[indx] ** 0.5\n        self.B = self.B[:, indx]\n        self.BD = self.B * self.diagD", "response": "Update the evolution path of the current class based on the given population."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef computeParams(self, params):\n        self.mu = params.get(\"mu\", int(self.lambda_ / 2))\n        rweights = params.get(\"weights\", \"superlinear\")\n        if rweights == \"superlinear\":\n            self.weights = numpy.log(self.mu + 0.5) - \\\n                numpy.log(numpy.arange(1, self.mu + 1))\n        elif rweights == \"linear\":\n            self.weights = self.mu + 0.5 - numpy.arange(1, self.mu + 1)\n        elif rweights == \"equal\":\n            self.weights = numpy.ones(self.mu)\n        else:\n            raise RuntimeError(\"Unknown weights : %s\" % rweights)\n\n        self.weights /= sum(self.weights)\n        self.mueff = 1. / sum(self.weights ** 2)\n\n        self.cc = params.get(\"ccum\", 4. / (self.dim + 4.))\n        self.cs = params.get(\"cs\", (self.mueff + 2.) /\n                             (self.dim + self.mueff + 3.))\n        self.ccov1 = params.get(\n            \"ccov1\", 2. / ((self.dim + 1.3) ** 2 + self.mueff))\n        self.ccovmu = params.get(\"ccovmu\", 2. * (\n            self.mueff - 2. + 1. / self.mueff) / (\n            (self.dim + 2.) ** 2 + self.mueff))\n        self.ccovmu = min(1 - self.ccov1, self.ccovmu)\n        self.damps = 1. + 2. * \\\n            max(0, numpy.sqrt((self.mueff - 1.) / (self.dim + 1.)) - 1.) + \\\n            self.cs\n        self.damps = params.get(\"damps\", self.damps)\n        return", "response": "Computes the parameters of the assessment class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef randomise_proposed_value(self):\n        if self.parameter_type is MMCParameterType.UNIFORM_DIST:\n            (a, b) = self.static_dist_or_list\n            self.proposed_value = random.uniform(a, b)\n        elif self.parameter_type is MMCParameterType.NORMAL_DIST:\n            (mu, sigma) = self.static_dist_or_list\n            self.proposed_value = random.normalvariate(mu, sigma)\n        elif self.parameter_type is MMCParameterType.DISCRETE_RANGE:\n            (min_v, max_v, step) = self.static_dist_or_list\n            self.proposed_value = random.choice(\n                numpy.arange(min_v, max_v, step))\n        elif self.parameter_type is MMCParameterType.LIST:\n            self.proposed_value = random.choice(self.static_dist_or_list)\n        elif self.parameter_type is MMCParameterType.STATIC_VALUE:\n            raise TypeError('This value is static, it cannot be mutated.')\n        else:\n            raise TypeError(\n                'Cannot randomise this parameter, unknown parameter type.')\n        return", "response": "Creates a randomly the proposed value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the current value to the proposed value.", "response": "def accept_proposed_value(self):\n        \"\"\"Changes the current value to the proposed value.\"\"\"\n        if self.proposed_value is not None:\n            self.current_value = self.proposed_value\n            self.proposed_value = None\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the optimisation run.", "response": "def start_optimisation(self, rounds, temp=298.15):\n        \"\"\"Begin the optimisation run.\n\n        Parameters\n        ----------\n        rounds : int\n            The number of rounds of optimisation to perform.\n        temp : float, optional\n            The temperature (in K) used during the optimisation.\n        \"\"\"\n        self._generate_initial_model()\n        self._mmc_loop(rounds, temp=temp)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the initial model for the optimistation.", "response": "def _generate_initial_model(self):\n        \"\"\"Creates the initial model for the optimistation.\n\n        Raises\n        ------\n        TypeError\n            Raised if the model failed to build. This could be due to\n            parameters being passed to the specification in the wrong\n            format.\n        \"\"\"\n        initial_parameters = [p.current_value for p in self.current_parameters]\n        try:\n            initial_model = self.specification(*initial_parameters)\n        except TypeError:\n            raise TypeError(\n                'Failed to build initial model. Make sure that the input '\n                'parameters match the number and order of arguements '\n                'expected by the input specification.')\n        initial_model.pack_new_sequences(self.sequences)\n        self.current_energy = self.eval_function(initial_model)\n        self.best_energy = copy.deepcopy(self.current_energy)\n        self.best_parameters = copy.deepcopy(self.current_parameters)\n        self.best_model = initial_model\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mmc_loop(self, rounds, temp=298.15, verbose=True):\n        # TODO add weighted randomisation of altered variable\n        current_round = 0\n        while current_round < rounds:\n            modifiable = list(filter(\n                lambda p: p.parameter_type is not MMCParameterType.STATIC_VALUE,\n                self.current_parameters))\n            chosen_parameter = random.choice(modifiable)\n            if chosen_parameter.parameter_type is MMCParameterType.UNIFORM_DIST:\n                chosen_parameter.randomise_proposed_value()\n            else:\n                chosen_parameter.randomise_proposed_value()\n            proposed_parameters = [\n                p.current_value\n                if p.proposed_value is None else p.proposed_value\n                for p in self.current_parameters]\n            model = self.specification(*proposed_parameters)\n            model.pack_new_sequences(self.sequences)\n            proposed_energy = self.eval_function(model)\n            # TODO Add proper logging\n            if verbose:\n                sys.stdout.write(\n                    '\\rRound: {}, Current energy: {}, Proposed energy: {} '\n                    '(best {}), {}.       '\n                    .format(current_round, float_f(self.current_energy),\n                            float_f(proposed_energy), float_f(\n                                self.best_energy),\n                            \"ACCEPTED\" if self.check_move(\n                                proposed_energy, self.current_energy, t=temp)\n                            else \"DECLINED\"\n                            ))\n                sys.stdout.flush()\n            if self.check_move(proposed_energy, self.current_energy, t=temp):\n                for p in self.current_parameters:\n                    p.accept_proposed_value()\n                self.current_energy = proposed_energy\n                if self.current_energy < self.best_energy:\n                    self.best_energy = copy.deepcopy(self.current_energy)\n                    self.best_parameters = copy.deepcopy(\n                        self.current_parameters)\n                    self.best_model = model\n            else:\n                for p in self.current_parameters:\n                    p.reject_proposed_value()\n            current_round += 1\n        return", "response": "This function is the main MMC loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _initialize_pop(self, pop_size):\n        self.toolbox.register(\"individual\", self._generate)\n        self.toolbox.register(\"population\", tools.initRepeat,\n                              list, self.toolbox.individual)\n        self.population = self.toolbox.population(n=pop_size)\n        if self.neighbours:\n            for i in range(len(self.population)):\n                self.population[i].ident = i\n                self.population[i].neighbours = list(\n                    set(\n                        [(i - x) % len(self.population)\n                         for x in range(1, self.neighbours + 1)] +\n                        [(i + x) % len(self.population)\n                         for x in range(1, self.neighbours + 1)]\n                    ))\n        self.assign_fitnesses(self.population)\n        return", "response": "Assigns indices to individuals in population."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse by the evolution process to generate a new individual. Notes ----- This is a tweaked version of the classical DE crossover algorithm, the main difference that candidate parameters are generated using a lognormal distribution. Bound handling is achieved by resampling where the candidate solution exceeds +/-1 Parameters ---------- ind : deap individual Returns ------- y : deap individual An individual representing a candidate solution, to be assigned a fitness.", "response": "def _crossover(self, ind):\n        \"\"\"Used by the evolution process to generate a new individual.\n\n        Notes\n        -----\n        This is a tweaked version of the classical DE crossover\n        algorithm, the main difference that candidate parameters are\n        generated using a lognormal distribution. Bound handling is\n        achieved by resampling where the candidate solution exceeds +/-1\n\n        Parameters\n        ----------\n        ind : deap individual\n\n        Returns\n        -------\n        y : deap individual\n            An individual representing a candidate solution, to be\n            assigned a fitness.\n        \"\"\"\n        if self.neighbours:\n            a, b, c = random.sample([self.population[i]\n                                     for i in ind.neighbours], 3)\n        else:\n            a, b, c = random.sample(self.population, 3)\n        y = self.toolbox.clone(a)\n        y.ident = ind.ident\n        y.neighbours = ind.neighbours\n        del y.fitness.values\n        # y should now be a copy of ind with the vector elements from a\n        ident = random.randrange(len(self.value_means))\n        for i, value in enumerate(y):\n            if i == ident or random.random() < self.cxpb:\n                entry = a[i] + random.lognormvariate(-1.2, 0.5) * \\\n                    self.diff_weight * (b[i] - c[i])\n                tries = 0\n                while abs(entry) > 1.0:\n                    tries += 1\n                    entry = a[i] + random.lognormvariate(-1.2, 0.5) * \\\n                        self.diff_weight * (b[i] - c[i])\n                    if tries > 10000:\n                        entry = a[i]\n                y[i] = entry\n        return y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the population according to crossover and fitness criteria.", "response": "def _update_pop(self, pop_size):\n        \"\"\"Updates population according to crossover and fitness criteria.\"\"\"\n        candidates = []\n        for ind in self.population:\n            candidates.append(self._crossover(ind))\n        self._model_count += len(candidates)\n        self.assign_fitnesses(candidates)\n        for i in range(len(self.population)):\n            if candidates[i].fitness > self.population[i].fitness:\n                self.population[i] = candidates[i]\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a particle object from the creator function.", "response": "def _generate(self):\n        \"\"\"Generates a particle using the creator function.\n\n        Notes\n        -----\n        Position and speed are uniformly randomly seeded within\n        allowed bounds. The particle also has speed limit settings\n        taken from global values.\n\n        Returns\n        -------\n        part : particle object\n            A particle used during optimisation.\n        \"\"\"\n        part = creator.Particle(\n            [random.uniform(-1, 1)\n             for _ in range(len(self.value_means))])\n        part.speed = [\n            random.uniform(-self.max_speed, self.max_speed)\n            for _ in range(len(self.value_means))]\n        part.smin = -self.max_speed\n        part.smax = self.max_speed\n        part.ident = None\n        part.neighbours = None\n        return part"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_particle(self, part, chi=0.729843788, c=2.05):\n        neighbour_pool = [self.population[i] for i in part.neighbours]\n        best_neighbour = max(neighbour_pool, key=lambda x: x.best.fitness)\n        ce1 = (c * random.uniform(0, 1) for _ in range(len(part)))\n        ce2 = (c * random.uniform(0, 1) for _ in range(len(part)))\n        ce1_p = map(operator.mul, ce1, map(operator.sub, part.best, part))\n        ce2_g = map(operator.mul, ce2, map(\n            operator.sub, best_neighbour.best, part))\n        chi_list = [chi] * len(part)\n        chi_list2 = [1 - chi] * len(part)\n        a = map(operator.sub,\n                map(operator.mul, chi_list, map(operator.add, ce1_p, ce2_g)),\n                map(operator.mul, chi_list2, part.speed))\n        part.speed = list(map(operator.add, part.speed, a))\n        for i, speed in enumerate(part.speed):\n            if speed < part.smin:\n                part.speed[i] = part.smin\n            elif speed > part.smax:\n                part.speed[i] = part.smax\n        part[:] = list(map(operator.add, part, part.speed))\n        return", "response": "Constriction factor update particle method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_pop(self, pop_size):\n        valid_particles = []\n        invalid_particles = []\n        for part in self.population:\n            if any(x > 1 or x < -1 for x in part):\n                invalid_particles.append(part)\n            else:\n                valid_particles.append(part)\n        self._model_count += len(valid_particles)\n        for part in valid_particles:\n            self.update_particle(part)\n        self.assign_fitnesses(valid_particles)\n        for part in valid_particles:\n            if part.fitness > part.best.fitness:\n                part.best = creator.Particle(part)\n                part.best.fitness = part.fitness\n        for part in invalid_particles:\n            self.update_particle(part)\n        self.population[:] = valid_particles + invalid_particles\n        self.population.sort(key=lambda x: x.ident)  # shouldn't need to sort?\n        return", "response": "Assigns fitnesses to particles that are within bounds."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initialize_pop(self, pop_size):\n        self.toolbox.register(\"individual\", self._generate)\n        self.toolbox.register(\"population\", tools.initRepeat,\n                              list, self.toolbox.individual)\n        self.population = self.toolbox.population(n=pop_size)\n        self.assign_fitnesses(self.population)\n        self._model_count += len(self.population)\n        return", "response": "Assigns indices to individuals in population."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the population according to crossover and fitness criteria.", "response": "def _update_pop(self, pop_size):\n        \"\"\"Updates population according to crossover and fitness criteria.\"\"\"\n        offspring = list(map(self.toolbox.clone, self.population))\n        for _ in range(pop_size // 2):\n            if random.random() < self.cxpb:\n                child1, child2 = self.toolbox.select(self.population, 2, 6)\n                temp1 = self.toolbox.clone(child1)\n                temp2 = self.toolbox.clone(child2)\n                self.toolbox.mate(temp1, temp2)\n                del temp1.fitness.values\n                del temp2.fitness.values\n                offspring.append(temp1)\n                offspring.append(temp2)\n        for mutant in offspring:\n            if random.random() < self.mutpb:\n                self.toolbox.mutate(mutant)\n                del mutant.fitness.values\n        # simple bound checking\n        for i in range(len(offspring)):\n            for j in range(len(offspring[i])):\n                if offspring[i][j] > 1:\n                    offspring[i][j] = 1\n                if offspring[i][j] < -1:\n                    offspring[i][j] = -1\n        self._model_count += len(\n            [ind for ind in offspring if not ind.fitness.values])\n        self.assign_fitnesses(\n            [ind for ind in offspring if not ind.fitness.valid])\n        offspring.sort(reverse=True, key=lambda x: x.fitness)\n        if len(self.halloffame) != 0:\n            # elitism- if none beat best so far it is reinserted\n            if offspring[0].fitness < self.halloffame[0].fitness:\n                offspring.insert(0, self.halloffame[0])\n        self.population[:] = offspring[:pop_size]\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the initial population and assigns fitnesses.", "response": "def _initialize_pop(self, pop_size):\n        \"\"\"Generates the initial population and assigns fitnesses.\"\"\"\n        self.initialize_cma_es(pop_size)\n        self.toolbox.register(\"individual\", self._make_individual)\n        self.toolbox.register(\"generate\", self._generate,\n                              self.toolbox.individual)\n        self.toolbox.register(\"population\", tools.initRepeat,\n                              list, self._initial_individual)\n        self.toolbox.register(\"update\", self.update)\n        self.population = self.toolbox.population(n=pop_size)\n        self.assign_fitnesses(self.population)\n        self._model_count += len(self.population)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initial_individual(self):\n        ind = creator.Individual(\n            [random.uniform(-1, 1)\n             for _ in range(len(self.value_means))])\n        return ind", "response": "Generates an individual with random parameters within bounds."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_pop(self, pop_size):\n        self.toolbox.generate()\n        # simple bound checking\n        for i in range(len(self.population)):\n            for j in range(len(self.population[i])):\n                if self.population[i][j] > 1:\n                    self.population[i][j] = 1\n                if self.population[i][j] < -1:\n                    self.population[i][j] = -1\n        self.assign_fitnesses(self.population)\n        self.toolbox.update(self.population)\n        self._model_count += len(self.population)\n        return", "response": "Updates the population according to crossover and fitness criteria."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_individual(self, paramlist):\n        part = creator.Individual(paramlist)\n        part.ident = None\n        return part", "response": "Makes an individual particle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _generate(self, func):\n        arz = numpy.random.standard_normal((self.lambda_, self.dim))\n        arz = self.centroid + self.sigma * numpy.dot(arz, self.BD.T)\n        self.population = list(map(func, arz))\n        return", "response": "Generate a population of an anonymization of the anonymization of the current strategy."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef number_of_mmols(code):\n    # If num_mmols is already known, return it\n    if mmols_numbers:\n        if code in mmols_numbers.keys():\n            mmol = mmols_numbers[code][0]\n            return mmol\n    counter = 1\n    while True:\n        pdbe_url = \"http://www.ebi.ac.uk/pdbe/static/entry/download/{0}-assembly-{1}.cif.gz\".format(code, counter)\n        r = requests.get(pdbe_url)\n        if r.status_code == 200:\n            counter += 1\n        else:\n            break\n    if counter == 1:\n        while True:\n            pdb_url = \"http://www.rcsb.org/pdb/files/{0}.pdb{1}.gz\".format(code.upper(), counter)\n            r = requests.get(pdb_url)\n            if r.status_code == 200 and r.encoding is None:\n                counter += 1\n            else:\n                break\n    if counter == 1:\n        pdb_url = \"http://files.rcsb.org/download/{0}.pdb\".format(code.upper())\n        r = requests.get(pdb_url)\n        if r.status_code == 200:\n            counter += 1\n    num_mmols = counter - 1\n    if num_mmols == 0:\n        raise ValueError('Could not access ANY .mmol files for {0}'.format(code))\n    return num_mmols", "response": "Returns the number of mmol files associated with a given PDB code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading the mmol file from PDBe and return its content as a string.", "response": "def get_mmol(code, mmol_number=None, outfile=None):\n    \"\"\" Get mmol file from PDBe and return its content as a string. Write to file if outfile given.\n\n    Parameters\n    ----------\n    code : str\n        PDB code.\n    mmol_number : int\n        mmol number (biological assembly number) of file to download. Numbers from PDBe.\n        If None, defaults to the preferred biological assembly listed for code on the PDBe.\n    outfile : str\n        Filepath. Writes returned value to this file.\n\n    Returns\n    -------\n    mmol_string : str, or None\n        Content of the mmol file as a string.\n        None if there are no pdbe files to download, as determined by pdbe_status_code().\n        None if unable to download the mmol_file from the pdbe site.\n\n    Raises\n    ------\n    ValueError\n        If the number of mmols for code is stored in mmols_numbers and if mmol_number is larger than this value.\n    \"\"\"\n    if not mmol_number:\n        try:\n            mmol_number = preferred_mmol(code=code)\n        except (ValueError, TypeError, IOError):\n            print(\"No mmols for {0}\".format(code))\n            return None\n    # sanity check\n    if mmols_numbers:\n        if code in mmols_numbers.keys():\n            num_mmols = mmols_numbers[code][0]\n            if mmol_number > num_mmols:\n                raise ValueError('There are only {0} mmols for code {1}. mmol_number {2} is too big'\n                                 .format(num_mmols, code, mmol_number))\n    # Download mmol file from the PDBE webserver.\n    pdbe_url = \"http://www.ebi.ac.uk/pdbe/entry-files/download/{0}_{1}.mmol\".format(code, mmol_number)\n    r = requests.get(pdbe_url)\n    if r.status_code == 200:\n        mmol_string = r.text\n    else:\n        # Download gz pdb file from the PDB.\n        pdb_url = \"http://www.rcsb.org/pdb/files/{0}.pdb{1}.gz\".format(code.upper(), mmol_number)\n        r = requests.get(pdb_url)\n        if r.status_code == 200:\n            temp_gz = tempfile.NamedTemporaryFile()\n            temp_gz.write(r.content)\n            with gzip.open(temp_gz.name, 'rb') as foo:\n                mmol_string = foo.read().decode()\n        else:\n            print(\"Could not download mmol file for {0}.\\n Got requests status_code {1}\".format(code, r.status_code))\n            return None\n    # Write to file\n    if outfile and mmol_string:\n        with open(outfile, 'w') as foo:\n            foo.write(mmol_string)\n\n    return mmol_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads and return the content of a cif file for a given PDB code and mmol number.", "response": "def get_cif(code, mmol_number, outfile=None):\n    \"\"\"\n    Parameters\n    ----------\n    code : str\n        PDB code.\n    mmol_number : int\n        mmol number (biological assembly number) of file to download. Numbers from PDBe.\n        If None, defaults to the preferred biological assembly listed for code on the PDBe.\n    outfile : str\n        Filepath. Writes returned value to this file.\n\n    Returns\n    -------\n    cif_string : str, or None\n        Content of the cif file as a string.\n        None if unable to download the cif_file from the pdbe site.\n    \"\"\"\n    pdbe_url = \"http://www.ebi.ac.uk/pdbe/static/entry/download/{0}-assembly-{1}.cif.gz\".format(code, mmol_number)\n    r = requests.get(pdbe_url)\n    if r.status_code == 200:\n        temp_gz = tempfile.NamedTemporaryFile()\n        temp_gz.write(r.content)\n        with gzip.open(temp_gz.name, 'rb') as foo:\n            cif_string = foo.read().decode()\n    else:\n        print(\"Could not download cif file for {0}\".format(code))\n        return None\n    # Write to file.\n    if outfile and cif_string:\n        with open(outfile, 'w') as foo:\n            foo.write(cif_string)\n    return cif_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_mmcif(code, outfile=None):\n    pdbe_url = \"http://www.ebi.ac.uk/pdbe/entry-files/download/{0}.cif\".format(code)\n    r = requests.get(pdbe_url)\n    if r.status_code == 200:\n        mmcif_string = r.text\n    else:\n        print(\"Could not download mmcif file for {0}\".format(code))\n        mmcif_string = None\n\n    # Write to file.\n    if outfile and mmcif_string:\n        with open(outfile, 'w') as foo:\n            foo.write(mmcif_string)\n\n    return mmcif_string", "response": "Get the mmcif file associated with code from PDBE."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pdbe_status_code(code):\n    url = 'http://www.ebi.ac.uk/pdbe/entry-files/download/{0}_1.mmol'.format(code)\n    r = requests.head(url=url)\n    return r.status_code", "response": "Check if a PDB code has structure files on the PDBE site."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the preferred biological assembly number for a given PDB code.", "response": "def preferred_mmol(code):\n    \"\"\" Get mmol number of preferred biological assembly as listed in the PDBe.\n\n    Notes\n    -----\n    First checks for code in mmols.json.\n    If code not yet in this json dictionary, uses requests module to scrape the PDBE for the preferred mmol number.\n\n    Parameters\n    ----------\n    code : str\n        A PDB code.\n\n    Returns\n    -------\n    mmol : int\n        mmol number of preferred assembly.\n\n    Raises\n    ------\n    TypeError\n        If 'mmol number' scraped is not an integer.\n    \"\"\"\n    # If preferred mmol number is already known, return it\n    if code in mmols_numbers.keys():\n        mmol = mmols_numbers[code][1]\n        return mmol\n    elif is_obsolete(code):\n        raise ValueError('Obsolete PDB code {0}'.format(code))\n    # Otherwise, use requests to scrape the PDBE.\n    else:\n        url_string = \"http://www.ebi.ac.uk/pdbe/entry/pdb/{0}/analysis\".format(code)\n        r = requests.get(url_string)\n        if not r.ok:\n            raise IOError(\"Could not get to url {0}\".format(url_string))\n        r_content = r.text\n        ass = re.findall('Assembly\\s\\d+\\s\\(preferred\\)', r_content)\n        if len(ass) != 1:\n            # To catch a strange error in the pdbe where preferred assembly is not numbered. See for example\n            # http://www.ebi.ac.uk/pdbe/entry/pdb/7msi/analysis\n            ass = re.findall('Assembly\\s+\\(preferred\\)', r_content)\n            if len(ass) == 1:\n                return 1\n            obs = re.findall('Entry has been obsoleted and replaced by another entry \\(OBS\\)', r_content)\n            if len(obs) == 1:\n                rep = re.findall('by entry <a href=\"/pdbe/entry/pdb/\\w{4}', r_content)\n                if len(rep) == 1:\n                    rep = rep[0][-4:]\n                    raise IOError(\"{0} is obsolete and has been replaced by {1}.\".format(code, rep))\n            raise ValueError(\"More than one match to preferred assembly\")\n        mmol = ass[0].split()[1]\n        try:\n            mmol = int(mmol)\n        except TypeError:\n            raise TypeError(\"Unexpected match: non-integer mmol\")\n        return mmol"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets list of all PDB codes currently listed in the PDB.", "response": "def current_codes_from_pdb():\n    \"\"\" Get list of all PDB codes currently listed in the PDB.\n\n    Returns\n    -------\n    pdb_codes : list(str)\n        List of PDB codes (in lower case).\n    \"\"\"\n    url = 'http://www.rcsb.org/pdb/rest/getCurrent'\n    r = requests.get(url)\n    if r.status_code == 200:\n        pdb_codes = [x.lower() for x in r.text.split('\"') if len(x) == 4]\n    else:\n        print('Request for {0} failed with status code {1}'.format(url, r.status_code))\n        return\n    return pdb_codes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_pdb_codes(data_dir=None):\n    if not data_dir:\n        data_dir = global_settings[\"structural_database\"][\"path\"]\n    p = Path(data_dir)\n    pdb_parent_dirs = [x for x in p.iterdir() if x.is_dir() and len(x.parts[-1]) == 2]\n    pdb_folders = [x for test in pdb_parent_dirs for x in test.iterdir() if x.is_dir()]\n    pdb_code_list = [x.parts[-1] for x in pdb_folders if len(x.parts[-1]) == 4]\n    return pdb_code_list", "response": "Get list of PDB codes stored within data_dir."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving folders associated with PDB accession code to obsolete folder in global_settings [ database_dir ].", "response": "def make_code_obsolete(code):\n    \"\"\" Moves folders associated with PDB code to obsolete folder in global_settings[\"database_dir\"]\n\n    Parameters\n    ----------\n    code : str\n        PDB accession code\n\n    Returns\n    -------\n    None\n    \"\"\"\n    fs = FileSystem(code=code)\n    if os.path.exists(fs.parent_dir):\n        # Move to obsolete folder\n        destination_dir = os.path.join(fs._data_dir, 'obsolete', code[1:3], code)\n        if os.path.exists(destination_dir):\n            shutil.rmtree(destination_dir)\n        shutil.move(fs.parent_dir, destination_dir)\n\n        # Remove containing (two-letter) folder if empty, else pass.\n        two_letter_dir = os.path.dirname(fs.parent_dir)\n        try:\n            os.rmdir(two_letter_dir)\n        except OSError:\n            pass\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of filepaths for all mmol files associated with code.", "response": "def mmols(self):\n        \"\"\" Dict of filepaths for all mmol files associated with code.\n\n        Notes\n        -----\n        Downloads mmol files if not already present.\n\n        Returns\n        -------\n        mmols_dict : dict, or None.\n            Keys : int\n                mmol number\n            Values : str\n                Filepath for the corresponding mmol file.\n        \"\"\"\n        mmols_dict = {}\n        mmol_dir = os.path.join(self.parent_dir, 'structures')\n        if not os.path.exists(mmol_dir):\n            os.makedirs(mmol_dir)\n        mmol_file_names = ['{0}_{1}.mmol'.format(self.code, i) for i in range(1, self.number_of_mmols + 1)]\n        mmol_files = [os.path.join(mmol_dir, x) for x in mmol_file_names]\n        for i, mmol_file in enumerate(mmol_files):\n            mmols_dict[i + 1] = mmol_file\n            # If file does not exist yet, download the mmol and write to mmol_file.\n            if not os.path.exists(mmol_file):\n                get_mmol(self.code, mmol_number=i + 1, outfile=mmol_file)\n        return mmols_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of filepaths for all dssp files associated with code.", "response": "def dssps(self):\n        \"\"\" Dict of filepaths for all dssp files associated with code.\n\n        Notes\n        -----\n        Runs dssp and stores writes output to files if not already present.\n        Also downloads mmol files if not already present.\n        Calls isambard.external_programs.dssp and so needs dssp to be installed.\n\n        Returns\n        -------\n        dssps_dict : dict, or None.\n            Keys : int\n                mmol number\n            Values : str\n                Filepath for the corresponding dssp file.\n\n        Raises\n        ------\n        Warning\n            If any of the dssp files are empty.\n        \"\"\"\n        dssps_dict = {}\n        dssp_dir = os.path.join(self.parent_dir, 'dssp')\n        if not os.path.exists(dssp_dir):\n            os.makedirs(dssp_dir)\n        for i, mmol_file in self.mmols.items():\n            dssp_file_name = '{0}.dssp'.format(os.path.basename(mmol_file))\n            dssp_file = os.path.join(dssp_dir, dssp_file_name)\n            if not os.path.exists(dssp_file):\n                dssp_out = run_dssp(pdb=mmol_file, path=True, outfile=dssp_file)\n                if len(dssp_out) == 0:\n                    raise Warning(\"dssp file {0} is empty\".format(dssp_file))\n            dssps_dict[i] = dssp_file\n        return dssps_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of filepaths for all fasta files associated with this structure.", "response": "def fastas(self, download=False):\n        \"\"\" Dict of filepaths for all fasta files associated with code.\n\n        Parameters\n        ----------\n        download : bool\n            If True, downloads the fasta file from the PDB.\n            If False, uses the ampal Protein.fasta property\n            Defaults to False - this is definitely the recommended behaviour.\n\n        Notes\n        -----\n        Calls self.mmols, and so downloads mmol files if not already present.\n        See .fasta property of isambard.ampal.base_ampal.Protein for more information.\n\n        Returns\n        -------\n        fastas_dict : dict, or None.\n            Keys : int\n                mmol number\n            Values : str\n                Filepath for the corresponding fasta file.\n        \"\"\"\n        fastas_dict = {}\n        fasta_dir = os.path.join(self.parent_dir, 'fasta')\n        if not os.path.exists(fasta_dir):\n            os.makedirs(fasta_dir)\n        for i, mmol_file in self.mmols.items():\n            mmol_name = os.path.basename(mmol_file)\n            fasta_file_name = '{0}.fasta'.format(mmol_name)\n            fasta_file = os.path.join(fasta_dir, fasta_file_name)\n            if not os.path.exists(fasta_file):\n                if download:\n                    pdb_url = \"http://www.rcsb.org/pdb/files/fasta.txt?structureIdList={0}\".format(self.code.upper())\n                    r = requests.get(pdb_url)\n                    if r.status_code == 200:\n                        fasta_string = r.text\n                    else:\n                        fasta_string = None\n                else:\n                    a = convert_pdb_to_ampal(mmol_file)\n                    # take first object if AmpalContainer (i.e. NMR structure).\n                    if type(a) == AmpalContainer:\n                        a = a[0]\n                    fasta_string = a.fasta\n                with open(fasta_file, 'w') as foo:\n                    foo.write(fasta_string)\n            fastas_dict[i] = fasta_file\n        return fastas_dict"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the path to the mmcif file associated with code.", "response": "def mmcif(self):\n        \"\"\" Filepath for mmcif file associated with code.\n\n        Notes\n        -----\n        Downloads mmcif file if not already present.\n\n        Returns\n        -------\n        mmcif_file : str\n            Filepath for the mmcif file.\n        \"\"\"\n        mmcif_dir = os.path.join(self.parent_dir, 'mmcif')\n        if not os.path.exists(mmcif_dir):\n            os.makedirs(mmcif_dir)\n        mmcif_file_name = '{0}.cif'.format(self.code)\n        mmcif_file = os.path.join(mmcif_dir, mmcif_file_name)\n        if not os.path.exists(mmcif_file):\n            get_mmcif(code=self.code, outfile=mmcif_file)\n        return mmcif_file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_profit(pdb1, pdb2, path1=False, path2=False, path_to_cmd_file=None,\n               return_pdb_string=False, align_type=None):\n    \"\"\"Takes 2 PDB strings, carries out rmsd superposition using ProFit.\n\n    Parameters\n    ----------\n    pdb1 : str\n        PDB as string or path\n    pdb2 : str\n        PDB as string or path\n    path1 : bool, optional\n        Whether pdb1 is a string or filepath\n    path2 : bool, optional\n        Whether pdb2 is a string or filepath\n    path_to_cmd_file : None, optional\n        Optional custom command file for ProFit. Do not use if you want\n        to use return_pdb_string=True\n    return_pdb_string : bool, optional\n        Returns fitted pdb structure as a string\n    align_type : None, optional\n        Used in conjunction with return_pdb_string=True and should be\n        set to one of 'all', 'bb', or 'ca to specify alignment of all\n        atoms, backbone atoms or just c-alpha atoms respectively\n\n    Returns\n    -------\n    rmsds : []\n        list of ca, bb and all-atom rmsds from superposition\n    output_pdb : str\n        (Optional) PDB string of overlaid, fitted structure (i.e.,\n        pdb2 superposed onto pdb1)\n\n    Raises\n    ------\n    ValueError\n        Raised if ProFit is ran with both a custom command file and an\n        output PDB string.\n        Raised if align method invalid.\n    \"\"\"\n\n    alignments = {'all': '*', 'bb': 'n,ca,c,o', 'ca': 'ca'}\n    output_pdb = None\n    output_file_path = None\n\n    if (path_to_cmd_file is not None) and return_pdb_string:\n        raise ValueError(\n            \"Cannot run ProFit with a custom command file and output \"\n            \"a PDB string at the same time\")\n\n    try:\n        if not path1:\n            if type(pdb1) == str:\n                pdb1 = pdb1.encode()\n            pdb1_tmp = tempfile.NamedTemporaryFile(delete=False)\n            pdb1_tmp.write(pdb1)\n            pdb1_tmp.seek(0)\n            pdb1 = pdb1_tmp.name\n        if not path2:\n            if type(pdb2) == str:\n                pdb2 = pdb2.encode()\n            pdb2_tmp = tempfile.NamedTemporaryFile(delete=False)\n            pdb2_tmp.write(pdb2)\n            pdb2_tmp.seek(0)\n            pdb2 = pdb2_tmp.name\n\n        if path_to_cmd_file:\n            cmd_file_path = path_to_cmd_file\n        elif return_pdb_string:\n            cmd_list = ['ignoremissing', 'align']\n            if not align_type:\n                cmd_list.append('atoms *')\n            else:\n                if align_type in alignments:\n                    cmd_list.append(\"atoms {}\".format(alignments[align_type]))\n                else:\n                    raise ValueError(\n                        \"align_type should be one of 'ca','bb' or 'all'\")\n            cmd_list.append('fit')\n            output_file_path = tempfile.NamedTemporaryFile(delete=False)\n            cmd_list.append(\"write {}\".format(output_file_path.name))\n            cmd_list.append(\"quit\")\n            tmp_cmd_file = tempfile.NamedTemporaryFile(delete=False)\n            tmp_cmd_file.write((\"\\n\".join(cmd_list)).encode())\n            tmp_cmd_file.seek(0)\n            cmd_file_path = tmp_cmd_file.name\n        else:\n            cmd_file_path = os.path.join(global_settings['package_path'],\n                                         'external_programs',\n                                         'profit_cmd_files',\n                                         'all_atom_cmds.txt')\n        profit_out = subprocess.check_output(\n            [global_settings['profit']['path'],\n             '-f', cmd_file_path, pdb1, pdb2])\n        rmsd_strs = re.findall('RMS: ([0-9.]+)', profit_out.decode())\n        if len(rmsd_strs) != 3 and not return_pdb_string:\n            raise ValueError(\n                'ProFit did not return an RMS value, check command file. '\n                'See ProFit output:\\n\\n{}\\n'\n                'PROFIT FAILED TO RUN: SEE LOG ABOVE'.format(profit_out))\n        # RMSDs should contain the CA, backbone and all atom scores\n\n        if return_pdb_string and (output_file_path is not None):\n            output_pdb = output_file_path.read().decode()\n        rmsds = [float(x) for x in rmsd_strs]\n\n    finally:\n        if not path1:\n            pdb1_tmp.close()\n            os.remove(pdb1_tmp.name)\n        if not path2:\n            pdb2_tmp.close()\n            os.remove(pdb2_tmp.name)\n\n        if return_pdb_string and (output_file_path is not None):\n            output_file_path.close()\n            tmp_cmd_file.close()\n            os.remove(output_file_path.name)\n            os.remove(tmp_cmd_file.name)\n\n    if return_pdb_string and (output_pdb is not None):\n        return rmsds, output_pdb\n    else:\n        return rmsds", "response": "This function runs ProFit on two PDB strings and returns the resulting structure as a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef categories(self):\n        category_dict = {}\n        for ligand in self:\n            if ligand.category in category_dict:\n                category_dict[ligand.category].append(ligand)\n            else:\n                category_dict[ligand.category] = [ligand]\n        return category_dict", "response": "Returns the categories of Ligands in LigandGroup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef category_count(self):\n        category_dict = self.categories\n        count_dict = {category: len(\n            category_dict[category]) for category in category_dict}\n        return count_dict", "response": "Returns the number of categories in categories."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sequence_molecular_weight(seq):\n    if 'X' in seq:\n        warnings.warn(_nc_warning_str, NoncanonicalWarning)\n    return sum(\n        [residue_mwt[aa] * n for aa, n in Counter(seq).items()]) + water_mass", "response": "Returns the molecular weight of the amino acid sequence."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the molar extinction coefficient of the sequence at 280 nm.", "response": "def sequence_molar_extinction_280(seq):\n    \"\"\"Returns the molar extinction coefficient of the sequence at 280 nm.\n\n    Notes\n    -----\n    Units = M/cm\n\n    Parameters\n    ----------\n    seq : str\n        Sequence of amino acids.\n    \"\"\"\n    if 'X' in seq:\n        warnings.warn(_nc_warning_str, NoncanonicalWarning)\n    return sum([residue_ext_280[aa] * n for aa, n in Counter(seq).items()])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef partial_charge(aa, pH):\n    difference = pH - residue_pka[aa]\n    if residue_charge[aa] > 0:\n        difference *= -1\n    ratio = (10 ** difference) / (1 + 10 ** difference)\n    return ratio", "response": "Calculates the partial charge of the amino acid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sequence_charge(seq, pH=7.4):\n    if 'X' in seq:\n        warnings.warn(_nc_warning_str, NoncanonicalWarning)\n    adj_protein_charge = sum(\n        [partial_charge(aa, pH) * residue_charge[aa] * n\n         for aa, n in Counter(seq).items()])\n    adj_protein_charge += (\n        partial_charge('N-term', pH) * residue_charge['N-term'])\n    adj_protein_charge += (\n        partial_charge('C-term', pH) * residue_charge['C-term'])\n    return adj_protein_charge", "response": "Calculates the total charge of the input amino acid sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the charge for pH 1 - 13.", "response": "def charge_series(seq, granularity=0.1):\n    \"\"\"Calculates the charge for pH 1-13.\n\n    Parameters\n    ----------\n    seq : str\n        Sequence of amino acids.\n    granularity : float, optional\n        Granularity of pH values i.e. if 0.1 pH = [1.0, 1.1, 1.2...]\n    \"\"\"\n    if 'X' in seq:\n        warnings.warn(_nc_warning_str, NoncanonicalWarning)\n    ph_range = numpy.arange(1, 13, granularity)\n    charge_at_ph = [sequence_charge(seq, ph) for ph in ph_range]\n    return ph_range, charge_at_ph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the isoelectric point of the sequence for ph 1 - 13.", "response": "def sequence_isoelectric_point(seq, granularity=0.1):\n    \"\"\"Calculates the isoelectric point of the sequence for ph 1-13.\n\n    Parameters\n    ----------\n    seq : str\n        Sequence of amino acids.\n    granularity : float, optional\n        Granularity of pH values i.e. if 0.1 pH = [1.0, 1.1, 1.2...]\n    \"\"\"\n    if 'X' in seq:\n        warnings.warn(_nc_warning_str, NoncanonicalWarning)\n    ph_range, charge_at_ph = charge_series(seq, granularity)\n    abs_charge_at_ph = [abs(ch) for ch in charge_at_ph]\n    pi_index = min(enumerate(abs_charge_at_ph), key=lambda x: x[1])[0]\n    return ph_range[pi_index]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef measure_sidechain_torsion_angles(residue, verbose=True):\n    chi_angles = []\n    aa = residue.mol_code\n    if aa not in side_chain_dihedrals:\n        if verbose:\n            print(\"Amino acid {} has no known side-chain dihedral\".format(aa))\n    else:\n        for set_atoms in side_chain_dihedrals[aa]:\n            required_for_dihedral = set_atoms[0:4]\n            try:\n                angle = dihedral(\n                    residue[required_for_dihedral[0]]._vector,\n                    residue[required_for_dihedral[1]]._vector,\n                    residue[required_for_dihedral[2]]._vector,\n                    residue[required_for_dihedral[3]]._vector)\n                chi_angles.append(angle)\n            except KeyError as k:\n                print(\"{0} atom missing from residue {1} {2} \"\n                      \"- can't assign dihedral\".format(\n                          k, residue.mol_code, residue.id))\n                chi_angles.append(None)\n    return chi_angles", "response": "Calculates the sidechain dihedral angles for a residue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef measure_torsion_angles(residues):\n    if len(residues) < 2:\n        torsion_angles = [(None, None, None)] * len(residues)\n    else:\n        torsion_angles = []\n        for i in range(len(residues)):\n            if i == 0:\n                res1 = residues[i]\n                res2 = residues[i + 1]\n                omega = None\n                phi = None\n                try:\n                    psi = dihedral(\n                        res1['N']._vector, res1['CA']._vector,\n                        res1['C']._vector, res2['N']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign psi\".format(k))\n                    psi = None\n                torsion_angles.append((omega, phi, psi))\n            elif i == len(residues) - 1:\n                res1 = residues[i - 1]\n                res2 = residues[i]\n                try:\n                    omega = dihedral(\n                        res1['CA']._vector, res1['C']._vector,\n                        res2['N']._vector, res2['CA']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign omega\".format(k))\n                    omega = None\n                try:\n                    phi = dihedral(\n                        res1['C']._vector, res2['N']._vector,\n                        res2['CA']._vector, res2['C']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign phi\".format(k))\n                    phi = None\n                psi = None\n                torsion_angles.append((omega, phi, psi))\n            else:\n                res1 = residues[i - 1]\n                res2 = residues[i]\n                res3 = residues[i + 1]\n                try:\n                    omega = dihedral(\n                        res1['CA']._vector, res1['C']._vector,\n                        res2['N']._vector, res2['CA']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign omega\".format(k))\n                    omega = None\n                try:\n                    phi = dihedral(\n                        res1['C']._vector, res2['N']._vector,\n                        res2['CA']._vector, res2['C']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign phi\".format(k))\n                    phi = None\n                try:\n                    psi = dihedral(\n                        res2['N']._vector, res2['CA']._vector,\n                        res2['C']._vector, res3['N']._vector)\n                except KeyError as k:\n                    print(\"{0} atom missing - can't assign psi\".format(k))\n                    psi = None\n                torsion_angles.append((omega, phi, psi))\n    return torsion_angles", "response": "Calculates the dihedral angles for a list of backbone atoms."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cc_to_local_params(pitch, radius, oligo):\n    rloc = numpy.sin(numpy.pi / oligo) * radius\n    alpha = numpy.arctan((2 * numpy.pi * radius) / pitch)\n    alphaloc = numpy.cos((numpy.pi / 2) - ((numpy.pi) / oligo)) * alpha\n    pitchloc = (2 * numpy.pi * rloc) / numpy.tan(alphaloc)\n    return pitchloc, rloc, numpy.rad2deg(alphaloc)", "response": "Converts a CC to a local parameters for an oligomeric assembly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of residues per turn at each Monomer in the Polymer.", "response": "def residues_per_turn(p):\n    \"\"\" The number of residues per turn at each Monomer in the Polymer.\n\n    Notes\n    -----\n    Each element of the returned list is the number of residues\n    per turn, at a point on the Polymer primitive. Calculated using\n    the relative positions of the CA atoms and the primitive of the\n    Polymer. Element i is the calculated from the dihedral angle using\n    the CA atoms of the Monomers with indices [i, i+1] and the\n    corresponding atoms of the primitive. The final value is None.\n\n    Parameters\n    ----------\n    p : ampal.Polypeptide\n        `Polypeptide` from which residues per turn will be calculated.\n\n    Returns\n    -------\n    rpts : [float]\n        Residue per turn values.\n    \"\"\"\n    cas = p.get_reference_coords()\n    prim_cas = p.primitive.coordinates\n    dhs = [abs(dihedral(cas[i], prim_cas[i], prim_cas[i + 1], cas[i + 1]))\n           for i in range(len(prim_cas) - 1)]\n    rpts = [360.0 / dh for dh in dhs]\n    rpts.append(None)\n    return rpts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef polymer_to_reference_axis_distances(p, reference_axis, tag=True, reference_axis_name='ref_axis'):\n    if not len(p) == len(reference_axis):\n        raise ValueError(\n            \"The reference axis must contain the same number of points \"\n            \"as the Polymer primitive.\")\n    prim_cas = p.primitive.coordinates\n    ref_points = reference_axis.coordinates\n    distances = [distance(prim_cas[i], ref_points[i])\n                 for i in range(len(prim_cas))]\n    if tag:\n        p.tags[reference_axis_name] = reference_axis\n        monomer_tag_name = 'distance_to_{0}'.format(reference_axis_name)\n        for m, d in zip(p._monomers, distances):\n            m.tags[monomer_tag_name] = d\n    return distances", "response": "Returns the distances between a Polymer and a reference_axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crick_angles(p, reference_axis, tag=True, reference_axis_name='ref_axis'):\n    if not len(p) == len(reference_axis):\n        raise ValueError(\n            \"The reference axis must contain the same number of points\"\n            \" as the Polymer primitive.\")\n    prim_cas = p.primitive.coordinates\n    p_cas = p.get_reference_coords()\n    ref_points = reference_axis.coordinates\n    cr_angles = [\n        dihedral(ref_points[i], prim_cas[i], prim_cas[i + 1], p_cas[i])\n        for i in range(len(prim_cas) - 1)]\n    cr_angles.append(None)\n\n    if tag:\n        p.tags[reference_axis_name] = reference_axis\n        monomer_tag_name = 'crick_angle_{0}'.format(reference_axis_name)\n        for m, c in zip(p._monomers, cr_angles):\n            m.tags[monomer_tag_name] = c\n    return cr_angles", "response": "Returns the Crick angles for each CA atom in the Polymer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alpha_angles(p, reference_axis, tag=True, reference_axis_name='ref_axis'):\n    if not len(p) == len(reference_axis):\n        raise ValueError(\n            \"The reference axis must contain the same number of points \"\n            \"as the Polymer primitive.\")\n    prim_cas = p.primitive.coordinates\n    ref_points = reference_axis.coordinates\n    alphas = [abs(dihedral(ref_points[i + 1], ref_points[i], prim_cas[i], prim_cas[i + 1]))\n              for i in range(len(prim_cas) - 1)]\n    alphas.append(None)\n\n    if tag:\n        p.tags[reference_axis_name] = reference_axis\n        monomer_tag_name = 'alpha_angle_{0}'.format(reference_axis_name)\n        for m, a in zip(p._monomers, alphas):\n            m.tags[monomer_tag_name] = a\n    return alphas", "response": "Returns a new object that contains all the alpha angles for a Polymer at each point of the primitive and axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef polypeptide_vector(p, start_index=0, end_index=-1, unit=True):\n    if len(p) <= 1:\n        raise ValueError(\n            \"Polymer should have length greater than 1. Polymer length = {0}\".format(len(p)))\n    try:\n        prim_cas = p.primitive.coordinates\n        direction_vector = prim_cas[end_index] - prim_cas[start_index]\n    except ValueError:\n        direction_vector = p[end_index]['CA'].array - \\\n            p[start_index]['CA'].array\n    if unit:\n        direction_vector = unit_vector(direction_vector)\n    return direction_vector", "response": "Vector along the Chain primitive."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reference_axis_from_chains(chains):\n    if not len(set([len(x) for x in chains])) == 1:\n        raise ValueError(\"All chains must be of the same length\")\n\n    # First array in coords is the primitive coordinates of the first chain.\n    # The orientation of the first chain orients the reference_axis.\n    coords = [numpy.array(chains[0].primitive.coordinates)]\n    orient_vector = polypeptide_vector(chains[0])\n    # Append the coordinates for the remaining chains, reversing the\n    # direction in antiparallel arrangements.\n    for i, c in enumerate(chains[1:]):\n        if is_acute(polypeptide_vector(c), orient_vector):\n            coords.append(numpy.array(c.primitive.coordinates))\n        else:\n            coords.append(numpy.flipud(numpy.array(c.primitive.coordinates)))\n\n    # Average across the x, y and z coordinates to get the reference_axis\n    # coordinates\n    reference_axis = numpy.mean(numpy.array(coords), axis=0)\n    return Primitive.from_coordinates(reference_axis)", "response": "Calculates the reference axis of a single Challenge."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflip the reference axis if direction opposes the direction of the Polymer.", "response": "def flip_reference_axis_if_antiparallel(\n        p, reference_axis, start_index=0, end_index=-1):\n    \"\"\"Flips reference axis if direction opposes the direction of the `Polymer`.\n\n    Notes\n    -----\n    If the angle between the vector for the Polymer and the vector\n    for the reference_axis is > 90 degrees, then the reference axis\n    is reversed. This is useful to run before running\n    polymer_to_reference_axis_distances, crick_angles, or alpha_angles.\n    For more information on the start and end indices, see chain_vector.\n\n    Parameters\n    ----------\n    p : ampal.Polymer\n        Reference `Polymer`.\n    reference_axis : list(numpy.array or tuple or list)\n        Length of reference_axis must equal length of the Polymer.\n        Each element of reference_axis represents a point in R^3.\n    start_index : int, optional\n        Default is 0 (start at the N-terminus of the Polymer)\n    end_index : int, optional\n        Default is -1 (start at the C-terminus of the Polymer)\n\n    Returns\n    -------\n    reference_axis : list(numpy.array or tuple or list)\n    \"\"\"\n    p_vector = polypeptide_vector(\n        p, start_index=start_index, end_index=end_index)\n    if is_acute(p_vector,\n                reference_axis[end_index] - reference_axis[start_index]):\n        reference_axis = numpy.flipud(reference_axis)\n    return reference_axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_primitive(cas_coords, window_length=3):\n\n    if len(cas_coords) >= window_length:\n        primitive = []\n        count = 0\n        for _ in cas_coords[:-(window_length - 1)]:\n            group = cas_coords[count:count + window_length]\n            average_x = sum([x[0] for x in group]) / window_length\n            average_y = sum([y[1] for y in group]) / window_length\n            average_z = sum([z[2] for z in group]) / window_length\n            primitive.append(numpy.array([average_x, average_y, average_z]))\n            count += 1\n    else:\n        raise ValueError(\n            'A primitive cannot be generated for {0} atoms using a (too large) '\n            'averaging window_length of {1}.'.format(\n                len(cas_coords), window_length))\n    return primitive", "response": "Generates a primitive list of the number of amino acid classes for a given cas_coords."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a smoothed primitive from a list of coordinates.", "response": "def make_primitive_smoothed(cas_coords, smoothing_level=2):\n    \"\"\" Generates smoothed primitive from a list of coordinates.\n\n    Parameters\n    ----------\n    cas_coords : list(numpy.array or float or tuple)\n        Each element of the list must have length 3.\n    smoothing_level : int, optional\n        Number of times to run the averaging.\n\n    Returns\n    -------\n    s_primitive : list(numpy.array)\n        Each array has length 3.\n\n    Raises\n    ------\n    ValueError\n        If the smoothing level is too great compared to the length\n        of cas_coords.\n    \"\"\"\n    try:\n        s_primitive = make_primitive(cas_coords)\n        for x in range(smoothing_level):\n            s_primitive = make_primitive(s_primitive)\n    except ValueError:\n        raise ValueError(\n            'Smoothing level {0} too high, try reducing the number of rounds'\n            ' or give a longer Chain (curent length = {1}).'.format(\n                smoothing_level, len(cas_coords)))\n    return s_primitive"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_primitive_extrapolate_ends(cas_coords, smoothing_level=2):\n    try:\n        smoothed_primitive = make_primitive_smoothed(\n            cas_coords, smoothing_level=smoothing_level)\n    except ValueError:\n        smoothed_primitive = make_primitive_smoothed(\n            cas_coords, smoothing_level=smoothing_level - 1)\n    # if returned smoothed primitive is too short, lower the smoothing\n    # level and try again.\n    if len(smoothed_primitive) < 3:\n        smoothed_primitive = make_primitive_smoothed(\n            cas_coords, smoothing_level=smoothing_level - 1)\n    final_primitive = []\n    for ca in cas_coords:\n        prim_dists = [distance(ca, p) for p in smoothed_primitive]\n        closest_indices = sorted([x[0] for x in sorted(\n            enumerate(prim_dists), key=lambda k: k[1])[:3]])\n        a, b, c = [smoothed_primitive[x] for x in closest_indices]\n        ab_foot = find_foot(a, b, ca)\n        bc_foot = find_foot(b, c, ca)\n        ca_foot = (ab_foot + bc_foot) / 2\n        final_primitive.append(ca_foot)\n    return final_primitive", "response": "Generates a list of smoothed helix primitives and extrapolates lost ends."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extend(self, ampal_container):\n        if isinstance(ampal_container, AmpalContainer):\n            self._ampal_objects.extend(ampal_container)\n        else:\n            raise TypeError(\n                'Only AmpalContainer objects may be merged with '\n                'an AmpalContainer.')\n        return", "response": "Extends an AmpalContainer with another AmpalContainer."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles the PDB strings for each state into a single file.", "response": "def pdb(self):\n        \"\"\"Compiles the PDB strings for each state into a single file.\"\"\"\n        header_title = '{:<80}\\n'.format('HEADER    {}'.format(self.id))\n        data_type = '{:<80}\\n'.format('EXPDTA    ISAMBARD Model')\n        pdb_strs = []\n        for ampal in self:\n            if isinstance(ampal, Assembly):\n                pdb_str = ampal.make_pdb(header=False, footer=False)\n            else:\n                pdb_str = ampal.make_pdb()\n            pdb_strs.append(pdb_str)\n        merged_strs = 'ENDMDL\\n'.join(pdb_strs) + 'ENDMDL\\n'\n        merged_pdb = ''.join([header_title, data_type, merged_strs])\n        return merged_pdb"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_by_tag(self, tag):\n        return AmpalContainer(sorted(self, key=lambda x: x.tags[tag]))", "response": "Sorts the AmpalContainer by a tag on the component objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append(self, item):\n        if isinstance(item, Polymer):\n            self._molecules.append(item)\n        else:\n            raise TypeError(\n                'Only Polymer objects can be appended to an Assembly.')\n        return", "response": "Adds a Polymer to the Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extend(self, assembly):\n        if isinstance(assembly, Assembly):\n            self._molecules.extend(assembly)\n        else:\n            raise TypeError(\n                'Only Assembly objects may be merged with an Assembly.')\n        return", "response": "Extends the Assembly with the contents of another Assembly."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve all the Monomers from the Assembly object.", "response": "def get_monomers(self, ligands=True, pseudo_group=False):\n        \"\"\"Retrieves all the `Monomers` from the `Assembly` object.\n\n        Parameters\n        ----------\n        ligands : bool, optional\n            If `true`, will include ligand `Monomers`.\n        pseudo_group : bool, optional\n            If `True`, will include pseudo atoms.\n        \"\"\"\n        base_filters = dict(ligands=ligands, pseudo_group=pseudo_group)\n        restricted_mol_types = [x[0] for x in base_filters.items() if not x[1]]\n        in_groups = [x for x in self.filter_mol_types(restricted_mol_types)]\n        monomers = itertools.chain(\n            *(p.get_monomers(ligands=ligands) for p in in_groups))\n        return monomers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ligands(self, solvent=True):\n        if solvent:\n            ligand_list = [x for x in self.get_monomers()\n                           if isinstance(x, Ligand)]\n        else:\n            ligand_list = [x for x in self.get_monomers() if isinstance(\n                x, Ligand) and not x.is_solvent]\n        return LigandGroup(monomers=ligand_list)", "response": "Retrieves all ligands from the Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a flat list of all the Atoms in the Assembly.", "response": "def get_atoms(self, ligands=True, pseudo_group=False, inc_alt_states=False):\n        \"\"\" Flat list of all the `Atoms` in the `Assembly`.\n\n        Parameters\n        ----------\n        ligands : bool, optional\n            Include ligand `Atoms`.\n        pseudo_group : bool, optional\n            Include pseudo_group `Atoms`.\n        inc_alt_states : bool, optional\n            Include alternate sidechain conformations.\n\n        Returns\n        -------\n        atoms : itertools.chain\n            All the `Atoms` as a iterator.\n        \"\"\"\n        atoms = itertools.chain(\n            *(list(m.get_atoms(inc_alt_states=inc_alt_states))\n                for m in self.get_monomers(ligands=ligands,\n                                           pseudo_group=pseudo_group)))\n        return atoms"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all atoms in AMPAL object within the given distance from the point.", "response": "def is_within(self, cutoff_dist, point, ligands=True):\n        \"\"\"Returns all atoms in AMPAL object within `cut-off` distance from the `point`.\"\"\"\n        return find_atoms_within_distance(self.get_atoms(ligands=ligands), cutoff_dist, point)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrelabeling the component Polymers in alphabetical order using a list of labels.", "response": "def relabel_polymers(self, labels=None):\n        \"\"\"Relabels the component Polymers either in alphabetical order or using a list of labels.\n\n        Parameters\n        ----------\n        labels : list, optional\n            A list of new labels.\n\n        Raises\n        ------\n        ValueError\n            Raised if the number of labels does not match the number of component Polymer objects.\n        \"\"\"\n        if labels:\n            if len(self._molecules) == len(labels):\n                for polymer, label in zip(self._molecules, labels):\n                    polymer.id = label\n            else:\n                raise ValueError('Number of polymers ({}) and number of labels ({}) must be equal.'.format(\n                    len(self._molecules), len(labels)))\n        else:\n            for i, polymer in enumerate(self._molecules):\n                polymer.id = chr(i + 65)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef relabel_atoms(self, start=1):\n        counter = start\n        for atom in self.get_atoms(ligands=True):\n            atom.id = counter\n            counter += 1\n        return", "response": "Relabels all Atoms in numerical order offset by the start parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a string for the Assembly.", "response": "def make_pdb(self, ligands=True, alt_states=False, pseudo_group=False, header=True, footer=True):\n        \"\"\"Generates a PDB string for the Assembly.\n\n        Parameters\n        ----------\n        ligands : bool, optional\n            If `True`, will include ligands in the output.\n        alt_states : bool, optional\n            If `True`, will include alternate conformations in the output.\n        pseudo_group : bool, optional\n            If `True`, will include pseudo atoms in the output.\n        header : bool, optional\n            If `True` will write a header for output.\n        footer : bool, optional\n            If `True` will write a footer for output.\n\n        Returns\n        -------\n        pdb_str : str\n            String of the pdb for the Assembly. Generated by collating\n            Polymer().pdb calls for the component Polymers.\n        \"\"\"\n        base_filters = dict(ligands=ligands, pseudo_group=pseudo_group)\n        restricted_mol_types = [x[0] for x in base_filters.items() if not x[1]]\n        in_groups = [x for x in self.filter_mol_types(restricted_mol_types)]\n\n        pdb_header = 'HEADER {:<80}\\n'.format(\n            'ISAMBARD Model {}'.format(self.id)) if header else ''\n        pdb_body = ''.join([x.make_pdb(\n            alt_states=alt_states, inc_ligands=ligands) + '{:<80}\\n'.format('TER') for x in in_groups])\n        pdb_footer = '{:<80}\\n'.format('END') if footer else ''\n        pdb_str = ''.join([pdb_header, pdb_body, pdb_footer])\n        return pdb_str"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a new Assembly containing only the backbone atoms of the original Assembly.", "response": "def backbone(self):\n        \"\"\"Generates a new `Assembly` containing only the backbone atoms.\n\n        Notes\n        -----\n        Metadata is not currently preserved from the parent object.\n        Sequence data is retained, but only the main chain atoms are\n        retained.\n\n        Returns\n        -------\n        bb_assembly : ampal.Protein\n            `Assembly` containing only the backbone atoms of the original\n            `Assembly`.\n        \"\"\"\n        bb_molecules = [\n            p.backbone for p in self._molecules if hasattr(p, 'backbone')]\n        bb_assembly = Assembly(bb_molecules, assembly_id=self.id)\n        return bb_assembly"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef primitives(self):\n        prim_molecules = [\n            p.primitive for p in self._molecules if hasattr(p, 'primitive')]\n        prim_assembly = Assembly(molecules=prim_molecules, assembly_id=self.id)\n        return prim_assembly", "response": "Generates a new Assembly containing only the primitives of each Polymer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef helices(self):\n        hel_molecules = list(itertools.chain(\n            *[p.helices._molecules\n              for p in self._molecules if hasattr(p, 'helices')]))\n        hel_assembly = Assembly(molecules=hel_molecules, assembly_id=self.id)\n        return hel_assembly", "response": "Generates an Assembly containing only the \u03b1 - helices of the original Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strands(self):\n        strand_molecules = list(itertools.chain(\n            *[p.strands._molecules for p in self._molecules if hasattr(p, 'strands')]))\n        strand_assembly = Assembly(\n            molecules=strand_molecules, assembly_id=self.id)\n        return strand_assembly", "response": "Generates a new Assembly containing only the \u03b2 - strands of the original Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the sequence of each Polymer in the Assembly as a list.", "response": "def sequences(self):\n        \"\"\"Returns the sequence of each `Polymer` in the `Assembly` as a list.\n\n        Returns\n        -------\n        sequences : [str]\n            List of sequences.\n        \"\"\"\n        seqs = [x.sequence for x in self._molecules if hasattr(x, 'sequence')]\n        return seqs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fasta(self):\n        fasta_str = ''\n        max_line_length = 79\n        for p in self._molecules:\n            if hasattr(p, 'sequence'):\n                fasta_str += '>{0}:{1}|PDBID|CHAIN|SEQUENCE\\n'.format(\n                    self.id.upper(), p.id)\n                seq = p.sequence\n                split_seq = [seq[i: i + max_line_length]\n                             for i in range(0, len(seq), max_line_length)]\n                for seq_part in split_seq:\n                    fasta_str += '{0}\\n'.format(seq_part)\n        return fasta_str", "response": "Generates a FASTA string for the Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_interaction_energy(self, assign_ff=True, ff=None, mol2=False,\n                               force_ff_assign=False):\n        \"\"\"Calculates the interaction energy of the AMPAL object.\n\n        Parameters\n        ----------\n        assign_ff: bool, optional\n            If true the force field will be updated if required.\n        ff: BuffForceField, optional\n            The force field to be used for scoring.\n        mol2: bool, optional\n            If true, mol2 style labels will also be used.\n        force_ff_assign: bool, optional\n            If true, the force field will be completely reassigned, \n            ignoring the cached parameters.\n\n        Returns\n        -------\n        buff_score: buff.BUFFScore\n            A BUFFScore object with information about each of the\n            interactions and the `Atoms` involved.\n\n        Raises\n        ------\n        AttributeError\n            Raise if a component molecule does not have an `update_ff`\n            method.\n        \"\"\"\n        if not ff:\n            ff = global_settings['buff']['force_field']\n        if assign_ff:\n            for molecule in self._molecules:\n                if hasattr(molecule, 'update_ff'):\n                    molecule.update_ff(\n                        ff, mol2=mol2, force_ff_assign=force_ff_assign)\n                else:\n                    raise AttributeError(\n                        'The following molecule does not have a update_ff'\n                        'method:\\n{}\\nIf this is a custom molecule type it'\n                        'should inherit from BaseAmpal:'.format(molecule))\n        interactions = find_inter_ampal(self, ff.distance_cutoff)\n        buff_score = score_interactions(interactions, ff)\n        return buff_score", "response": "Calculates the interaction energy of the AMPAL object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npacking a new sequence onto each Polymer in the Assembly using Scwrl4.", "response": "def pack_new_sequences(self, sequences):\n        \"\"\"Packs a new sequence onto each Polymer in the Assembly using Scwrl4.\n\n        Notes\n        -----\n        The Scwrl packing score is saved in `Assembly.tags['scwrl_score']`\n        for reference.\n\n        Scwrl must be available to call. Check by running\n        `isambard.external_programs.scwrl.test_scwrl`. If Scwrl is not\n        available, please follow instruction here to add it:\n        https://github.com/woolfson-group/isambard#external-programs\n\n        For more information on Scwrl see [1].\n\n        References\n        ----------\n        .. [1] Krivov GG, Shapovalov MV, and Dunbrack Jr RL (2009) \"Improved\n           prediction of protein side-chain conformations with SCWRL4.\",\n           Proteins.\n\n        Parameters\n        ----------\n        sequences : [str]\n            A list of strings containing the amino acid sequence of each\n            corresponding `Polymer`. These must be the same length as the\n            `Polymer`.\n\n        Raises\n        ------\n        ValueError\n            Raised if the sequence length does not match the number of\n            monomers in the `Polymer`.\n        \"\"\"\n        from ampal.pdb_parser import convert_pdb_to_ampal\n        assembly_bb = self.backbone\n        total_seq_len = sum([len(x) for x in sequences])\n        total_aa_len = sum([len(x) for x in assembly_bb])\n        if total_seq_len != total_aa_len:\n            raise ValueError('Total sequence length ({}) does not match '\n                             'total Polymer length ({}).'.format(\n                                 total_seq_len, total_aa_len))\n        scwrl_out = pack_sidechains(self.backbone.pdb, ''.join(sequences))\n        if scwrl_out is None:\n            return\n        else:\n            packed_structure, scwrl_score = scwrl_out\n        new_assembly = convert_pdb_to_ampal(packed_structure, path=False)\n        self._molecules = new_assembly._molecules[:]\n        self.assign_force_field(global_settings[u'buff'][u'force_field'])\n        self.tags['scwrl_score'] = scwrl_score\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef repack_all(self):\n        non_na_sequences = [s for s in self.sequences if ' ' not in s]\n        self.pack_new_sequences(non_na_sequences)\n        return", "response": "Repacks the side chains of all Polymers in the Assembly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag_secondary_structure(self, force=False):\n        for polymer in self._molecules:\n            if polymer.molecule_type == 'protein':\n                polymer.tag_secondary_structure(force=force)\n        return", "response": "Tags each Monomer in the Assembly with its secondary structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tag_dssp_solvent_accessibility(self, force=False):\n        for polymer in self._molecules:\n            polymer.tag_dssp_solvent_accessibility(force=force)\n        return", "response": "Tags each Monomer in the Assembly with its solvent accessibility."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntag each Monomer in the Assembly with its torsion angles.", "response": "def tag_torsion_angles(self, force=False):\n        \"\"\"Tags each `Monomer` in the `Assembly` with its torsion angles.\n\n        Parameters\n        ----------\n        force : bool, optional\n            If `True`, the tag will be run even if `Monomers` are already\n            tagged.\n        \"\"\"\n        for polymer in self._molecules:\n            if polymer.molecule_type == 'protein':\n                polymer.tag_torsion_angles(force=force)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntag each Monomer in the Assembly with its helical geometry.", "response": "def tag_ca_geometry(self, force=False, reference_axis=None,\n                        reference_axis_name='ref_axis'):\n        \"\"\"Tags each `Monomer` in the `Assembly` with its helical geometry.\n\n        Parameters\n        ----------\n        force : bool, optional\n            If True the tag will be run even if `Monomers` are already tagged.\n        reference_axis : list(numpy.array or tuple or list), optional\n            Coordinates to feed to geometry functions that depend on\n            having a reference axis.\n        reference_axis_name : str, optional\n            Used to name the keys in tags at `Chain` and `Residue` level.\n        \"\"\"\n        for polymer in self._molecules:\n            if polymer.molecule_type == 'protein':\n                polymer.tag_ca_geometry(\n                    force=force, reference_axis=reference_axis,\n                    reference_axis_name=reference_axis_name)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tag_atoms_unique_ids(self, force=False):\n        tagged = ['unique_id' in x.tags.keys() for x in self.get_atoms()]\n        if (not all(tagged)) or force:\n            for m in self.get_monomers():\n                for atom_type, atom in m.atoms.items():\n                    atom.tags['unique_id'] = (m.unique_id, atom_type)\n        return", "response": "Tags each Atom in the Assembly with its unique_id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_pro_to_hyp(pro):\n    with open(str(REF_PATH / 'hydroxyproline_ref_1bkv_0_6.pickle'), 'rb') as inf:\n        hyp_ref = pickle.load(inf)\n    align_nab(hyp_ref, pro)\n    to_remove = ['CB', 'CG', 'CD']\n    for (label, atom) in pro.atoms.items():\n        if atom.element == 'H':\n            to_remove.append(label)\n    for label in to_remove:\n        del pro.atoms[label]\n    for key, val in hyp_ref.atoms.items():\n        if key not in pro.atoms.keys():\n            pro.atoms[key] = val\n    pro.mol_code = 'HYP'\n    pro.mol_letter = 'X'\n    pro.is_hetero = True\n    pro.tags = {}\n    pro.states = {'A': pro.atoms}\n    pro.active_state = 'A'\n    for atom in pro.get_atoms():\n        atom.ampal_parent = pro\n        atom.tags = {'bfactor': 1.0, 'charge': ' ',\n                     'occupancy': 1.0, 'state': 'A'}\n    return", "response": "Converts a pro residue to a hydroxypro residue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\naligns the N - CA and CA - CB vectors of the target monomer.", "response": "def align_nab(tar, ref):\n    \"\"\"Aligns the N-CA and CA-CB vector of the target monomer.\n\n    Parameters\n    ----------\n    tar: ampal.Residue\n        The residue that will be aligned to the reference.\n    ref: ampal.Residue\n        The reference residue for the alignment.\n    \"\"\"\n    rot_trans_1 = find_transformations(\n        tar['N'].array, tar['CA'].array, ref['N'].array, ref['CA'].array)\n    apply_trans_rot(tar, *rot_trans_1)\n    rot_ang_ca_cb = dihedral(tar['CB'], ref['CA'], ref['N'], ref['CB'])\n    tar.rotate(rot_ang_ca_cb, ref['N'].array - ref['CA'].array, ref['N'].array)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies a translation and rotation to an AMPAL object.", "response": "def apply_trans_rot(ampal, translation, angle, axis, point, radians=False):\n    \"\"\"Applies a translation and rotation to an AMPAL object.\"\"\"\n    if not numpy.isclose(angle, 0.0):\n        ampal.rotate(angle=angle, axis=axis, point=point, radians=radians)\n    ampal.translate(vector=translation)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an Assembly containing regions tagged as secondary structure.", "response": "def find_ss_regions_polymer(polymer, ss):\n    \"\"\"Returns an `Assembly` of regions tagged as secondary structure.\n\n    Parameters\n    ----------\n    polymer : Polypeptide\n        `Polymer` object to be searched secondary structure regions.\n    ss : list\n        List of secondary structure tags to be separate i.e. ['H']\n        would return helices, ['H', 'E'] would return helices\n        and strands.\n\n    Returns\n    -------\n    fragments : Assembly\n        `Assembly` containing a `Polymer` for each region of specified\n        secondary structure.\n    \"\"\"\n    if isinstance(ss, str):\n        ss = [ss[:]]\n    tag_key = 'secondary_structure'\n    monomers = [x for x in polymer if tag_key in x.tags.keys()]\n    if len(monomers) == 0:\n        return Assembly()\n    if (len(ss) == 1) and (all([m.tags[tag_key] == ss[0] for m in monomers])):\n        return Assembly(polymer)\n    previous_monomer = None\n    fragment = Polypeptide(ampal_parent=polymer)\n    fragments = Assembly()\n    poly_id = 0\n    for monomer in monomers:\n        current_monomer = monomer.tags[tag_key]\n        if (current_monomer == previous_monomer) or (not previous_monomer):\n            fragment.append(monomer)\n        else:\n            if previous_monomer in ss:\n                fragment.tags[tag_key] = monomer.tags[tag_key]\n                fragment.id = chr(poly_id + 65)\n                fragments.append(fragment)\n                poly_id += 1\n            fragment = Polypeptide(ampal_parent=polymer)\n            fragment.append(monomer)\n        previous_monomer = monomer.tags[tag_key]\n    return fragments"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes a flat list of atom coordinates and converts it to a Polymer object.", "response": "def flat_list_to_polymer(atom_list, atom_group_s=4):\n    \"\"\"Takes a flat list of atomic coordinates and converts it to a `Polymer`.\n\n    Parameters\n    ----------\n    atom_list : [Atom]\n        Flat list of coordinates.\n    atom_group_s : int, optional\n        Size of atom groups.\n\n    Returns\n    -------\n    polymer : Polypeptide\n        `Polymer` object containing atom coords converted `Monomers`.\n\n    Raises\n    ------\n    ValueError\n        Raised if `atom_group_s` != 4 or 5\n    \"\"\"\n    atom_labels = ['N', 'CA', 'C', 'O', 'CB']\n    atom_elements = ['N', 'C', 'C', 'O', 'C']\n    atoms_coords = [atom_list[x:x + atom_group_s]\n                    for x in range(0, len(atom_list), atom_group_s)]\n    atoms = [[Atom(x[0], x[1]) for x in zip(y, atom_elements)]\n             for y in atoms_coords]\n    if atom_group_s == 5:\n        monomers = [Residue(OrderedDict(zip(atom_labels, x)), 'ALA')\n                    for x in atoms]\n    elif atom_group_s == 4:\n        monomers = [Residue(OrderedDict(zip(atom_labels, x)), 'GLY')\n                    for x in atoms]\n    else:\n        raise ValueError(\n            'Parameter atom_group_s must be 4 or 5 so atoms can be labeled correctly.')\n    polymer = Polypeptide(monomers=monomers)\n    return polymer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef align(target, mobile, target_i=0, mobile_i=0):\n    # First, align N->CA vectors.\n    s1, e1, s2, e2 = [x._vector\n                      for x in [mobile[mobile_i]['N'], mobile[mobile_i]['CA'],\n                                target[target_i]['N'], target[target_i]['CA']]]\n    translation, angle, axis, point = find_transformations(\n        s1, e1, s2, e2, radians=False)\n    # Rotation first, Then translation.\n    mobile.rotate(angle=angle, axis=axis, point=point, radians=False)\n    mobile.translate(vector=translation)\n    # Second, rotate about N->CA axis to align CA->C vectors.\n    angle = dihedral(mobile[mobile_i]['C'], mobile[mobile_i]\n                     ['N'], mobile[mobile_i]['CA'], target[target_i]['C'])\n    axis = target[target_i]['CA'] - target[target_i]['N']\n    point = target[target_i]['N']._vector\n    mobile.rotate(angle=angle, axis=axis, point=point)\n    return", "response": "Aligns one Polypeptide to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_slice_from_res_id(self, start, end):\n\n        id_dict = {str(m.id): m for m in self._monomers}\n        slice_polymer = Polypeptide(\n            [id_dict[str(x)] for x in range(int(start), int(end) + 1)], self.id)\n        return slice_polymer", "response": "Returns a new Polypeptide containing the Residues in start and end range."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backbone(self):\n        bb_poly = Polypeptide([x.backbone for x in self._monomers], self.id)\n        return bb_poly", "response": "Returns a new Polymer containing only the backbone atoms."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npacking a new sequence onto the Polymer using Scwrl4.", "response": "def pack_new_sequence(self, sequence):\n        \"\"\"Packs a new sequence onto the polymer using Scwrl4.\n\n        Parameters\n        ----------\n        sequence : str\n            String containing the amino acid sequence. This must\n            be the same length as the Polymer\n\n        Raises\n        ------\n        ValueError\n            Raised if the sequence length does not match the\n            number of monomers in the Polymer.\n        \"\"\"\n        # This import is here to prevent a circular import.\n        from ampal.pdb_parser import convert_pdb_to_ampal\n        polymer_bb = self.backbone\n        if len(sequence) != len(polymer_bb):\n            raise ValueError(\n                'Sequence length ({}) does not match Polymer length ({}).'.format(\n                    len(sequence), len(polymer_bb)))\n        scwrl_out = pack_sidechains(self.backbone.pdb, sequence)\n        if scwrl_out is None:\n            return\n        else:\n            packed_structure, scwrl_score = scwrl_out\n        new_assembly = convert_pdb_to_ampal(packed_structure, path=False)\n        self._monomers = new_assembly[0]._monomers[:]\n        self.tags['scwrl_score'] = scwrl_score\n        self.assign_force_field(global_settings['buff']['force_field'])\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the sequence of the Polymer as a string.", "response": "def sequence(self):\n        \"\"\"Returns the sequence of the `Polymer` as a string.\n\n        Returns\n        -------\n        sequence : str\n            String of the `Residue` sequence of the `Polypeptide`.\n        \"\"\"\n        seq = [x.mol_letter for x in self._monomers]\n        return ''.join(seq)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef backbone_bond_angles(self):\n        bond_angles = dict(\n            n_ca_c=[angle_between_vectors(r['N'] - r['CA'], r['C'] - r['CA'])\n                    for r in self.get_monomers(ligands=False)],\n            ca_c_o=[angle_between_vectors(r['CA'] - r['C'], r['O'] - r['C'])\n                    for r in self.get_monomers(ligands=False)],\n            ca_c_n=[angle_between_vectors(r1['CA'] - r1['C'], r2['N'] - r1['C'])\n                    for r1, r2 in [(self[i], self[i + 1]) for i in range(len(self) - 1)]],\n            c_n_ca=[angle_between_vectors(r1['C'] - r2['N'], r2['CA'] - r2['N'])\n                    for r1, r2 in [(self[i], self[i + 1]) for i in range(len(self) - 1)]],\n        )\n        return bond_angles", "response": "Dictionary containing backbone bond angles as lists of floats."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\njoins other to self at the C-terminus via a peptide bond. Notes ----- This function directly modifies self. It does not return a new object. Parameters ---------- other: Residue or Polypeptide psi: float, optional Psi torsion angle (degrees) between final `Residue` of self and first `Residue` of other. omega: float, optional Omega torsion angle (degrees) between final `Residue` of self and first `Residue` of other. phi: float, optional Phi torsion angle (degrees) between final `Residue` of self and first `Residue` of other. o_c_n_angle: float or None, optional Desired angle between O, C (final `Residue` of self) and N (first `Residue` of other) atoms. If `None`, default value is taken from `ideal_backbone_bond_angles`. c_n_ca_angle: float or None, optional Desired angle between C (final `Residue` of self) and N, CA (first `Residue` of other) atoms. If `None`, default value is taken from `ideal_backbone_bond_angles`. c_n_length: float or None, optional Desired peptide bond length between final `Residue` of self and first `Residue` of other. If `None`, default value is taken from `ideal_backbone_bond_lengths`. relabel: bool, optional If `True`, `relabel_all` is run on self before returning. Raises ------ TypeError: If other is not a `Residue` or a Polypeptide.", "response": "def c_join(self, other, psi=-40.76, omega=-178.25, phi=-65.07,\n               o_c_n_angle=None, c_n_ca_angle=None, c_n_length=None,\n               relabel=True):\n        \"\"\"Joins other to self at the C-terminus via a peptide bond.\n\n        Notes\n        -----\n        This function directly modifies self. It does not return a new object.\n\n        Parameters\n        ----------\n        other: Residue or Polypeptide\n        psi: float, optional\n            Psi torsion angle (degrees) between final `Residue` of self\n            and first `Residue` of other.\n        omega: float, optional\n            Omega torsion angle (degrees) between final `Residue` of\n            self and first `Residue` of other.\n        phi: float, optional\n            Phi torsion angle (degrees) between final `Residue` of self\n            and first `Residue` of other.\n        o_c_n_angle: float or None, optional\n            Desired angle between O, C (final `Residue` of self) and N\n            (first `Residue` of other) atoms. If `None`, default value is\n            taken from `ideal_backbone_bond_angles`.\n        c_n_ca_angle: float or None, optional\n            Desired angle between C (final `Residue` of self) and N, CA\n            (first `Residue` of other) atoms. If `None`, default value is\n            taken from `ideal_backbone_bond_angles`.\n        c_n_length: float or None, optional\n            Desired peptide bond length between final `Residue` of self\n            and first `Residue` of other. If `None`, default value is taken\n            from `ideal_backbone_bond_lengths`.\n        relabel: bool, optional\n            If `True`, `relabel_all` is run on self before returning.\n\n        Raises\n        ------\n        TypeError:\n            If other is not a `Residue` or a Polypeptide.\n        \"\"\"\n        if isinstance(other, Residue):\n            other = Polypeptide([other])\n        if not isinstance(other, Polypeptide):\n            raise TypeError(\n                'Only Polypeptide or Residue objects can be joined to a Polypeptide')\n        if abs(omega) >= 90:\n            peptide_conformation = 'trans'\n        else:\n            peptide_conformation = 'cis'\n        if o_c_n_angle is None:\n            o_c_n_angle = ideal_backbone_bond_angles[peptide_conformation]['o_c_n']\n        if c_n_ca_angle is None:\n            c_n_ca_angle = ideal_backbone_bond_angles[peptide_conformation]['c_n_ca']\n        if c_n_length is None:\n            c_n_length = ideal_backbone_bond_lengths['c_n']\n        r1 = self[-1]\n        r1_ca = r1['CA']._vector\n        r1_c = r1['C']._vector\n        r1_o = r1['O']._vector\n        # p1 is point that will be used to position the N atom of r2.\n        p1 = r1_o[:]\n        # rotate p1 by o_c_n_angle, about axis perpendicular to the\n        # r1_ca, r1_c, r1_o plane, passing through r1_c.\n        axis = numpy.cross((r1_ca - r1_c), (r1_o - r1_c))\n        q = Quaternion.angle_and_axis(angle=o_c_n_angle, axis=axis)\n        p1 = q.rotate_vector(v=p1, point=r1_c)\n        # Ensure p1 is separated from r1_c by the correct distance.\n        p1 = r1_c + (c_n_length * unit_vector(p1 - r1_c))\n        # rotate p1 and r1['O'] by to obtain desired psi value at the join.\n        measured_psi = dihedral(r1['N'], r1['CA'], r1['C'], p1)\n        q = Quaternion.angle_and_axis(\n            angle=(psi - measured_psi), axis=(r1_c - r1_ca))\n        p1 = q.rotate_vector(v=p1, point=r1_c)\n        r1['O']._vector = q.rotate_vector(v=r1_o, point=r1_c)\n        # translate other so that its first N atom is at p1\n        other.translate(vector=(p1 - other[0]['N']._vector))\n        # rotate other so that c_n_ca angle is correct.\n        v1 = r1_c - other[0]['N']._vector\n        v2 = other[0]['CA']._vector - other[0]['N']._vector\n        measured_c_n_ca = angle_between_vectors(v1, v2)\n        axis = numpy.cross(v1, v2)\n        other.rotate(angle=(c_n_ca_angle - measured_c_n_ca),\n                     axis=axis, point=other[0]['N']._vector)\n        # rotate other to obtain desired omega and phi values at the join\n        measured_omega = dihedral(\n            r1['CA'], r1['C'], other[0]['N'], other[0]['CA'])\n        other.rotate(angle=(omega - measured_omega),\n                     axis=(other[0]['N'] - r1['C']), point=other[0]['N']._vector)\n        measured_phi = dihedral(\n            r1['C'], other[0]['N'], other[0]['CA'], other[0]['C'])\n        other.rotate(angle=(phi - measured_phi),\n                     axis=(other[0]['CA'] - other[0]['N']), point=other[0]['CA']._vector)\n        self.extend(other)\n        if relabel:\n            self.relabel_all()\n        self.tags['assigned_ff'] = False\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\njoins other to self at the N-terminus via a peptide bond. Notes ----- This function directly modifies self. It does not return a new object. Parameters ---------- other: Residue or Polypeptide psi: float Psi torsion angle (degrees) between final `Residue` of other and first `Residue` of self. omega: float Omega torsion angle (degrees) between final `Residue` of other and first `Residue` of self. phi: float Phi torsion angle (degrees) between final `Residue` of other and first `Residue` of self. o_c_n_angle: float or None Desired angle between O, C (final `Residue` of other) and N (first `Residue` of self) atoms. If `None`, default value is taken from `ideal_backbone_bond_angles`. c_n_ca_angle: float or None Desired angle between C (final `Residue` of other) and N, CA (first `Residue` of self) atoms. If `None`, default value is taken from `ideal_backbone_bond_angles`. c_n_length: float or None Desired peptide bond length between final `Residue` of other and first `Residue` of self. If None, default value is taken from ideal_backbone_bond_lengths. relabel: bool If True, relabel_all is run on self before returning. Raises ------ TypeError: If other is not a `Residue` or a `Polypeptide`", "response": "def n_join(self, other, psi=-40.76, omega=-178.25, phi=-65.07,\n               o_c_n_angle=None, c_n_ca_angle=None, c_n_length=None, relabel=True):\n        \"\"\"Joins other to self at the N-terminus via a peptide bond.\n\n        Notes\n        -----\n        This function directly modifies self. It does not return a new object.\n\n        Parameters\n        ----------\n        other: Residue or Polypeptide\n        psi: float\n            Psi torsion angle (degrees) between final `Residue` of other\n            and first `Residue` of self.\n        omega: float\n            Omega torsion angle (degrees) between final `Residue` of\n            other and first `Residue` of self.\n        phi: float\n            Phi torsion angle (degrees) between final `Residue` of other\n            and first `Residue` of self.\n        o_c_n_angle: float or None\n            Desired angle between O, C (final `Residue` of other) and N\n            (first `Residue` of self) atoms. If `None`, default value is\n            taken from `ideal_backbone_bond_angles`.\n        c_n_ca_angle: float or None\n            Desired angle between C (final `Residue` of other) and N, CA\n            (first `Residue` of self) atoms. If `None`, default value is taken\n            from `ideal_backbone_bond_angles`.\n        c_n_length: float or None\n            Desired peptide bond length between final `Residue` of other\n            and first `Residue` of self. If None, default value is taken\n            from ideal_backbone_bond_lengths.\n        relabel: bool\n            If True, relabel_all is run on self before returning.\n\n        Raises\n        ------\n        TypeError:\n            If other is not a `Residue` or a `Polypeptide`\n        \"\"\"\n        if isinstance(other, Residue):\n            other = Polypeptide([other])\n        if not isinstance(other, Polypeptide):\n            raise TypeError(\n                'Only Polypeptide or Residue objects can be joined to a Polypeptide')\n        if abs(omega) >= 90:\n            peptide_conformation = 'trans'\n        else:\n            peptide_conformation = 'cis'\n        if o_c_n_angle is None:\n            o_c_n_angle = ideal_backbone_bond_angles[peptide_conformation]['o_c_n']\n        if c_n_ca_angle is None:\n            c_n_ca_angle = ideal_backbone_bond_angles[peptide_conformation]['c_n_ca']\n        if c_n_length is None:\n            c_n_length = ideal_backbone_bond_lengths['c_n']\n        r1 = self[0]\n        r1_n = r1['N']._vector\n        r1_ca = r1['CA']._vector\n        r1_c = r1['C']._vector\n        # p1 is point that will be used to position the C atom of r2.\n        p1 = r1_ca[:]\n        # rotate p1 by c_n_ca_angle, about axis perpendicular to the\n        # r1_n, r1_ca, r1_c plane, passing through r1_ca.\n        axis = numpy.cross((r1_ca - r1_n), (r1_c - r1_n))\n        q = Quaternion.angle_and_axis(angle=c_n_ca_angle, axis=axis)\n        p1 = q.rotate_vector(v=p1, point=r1_n)\n        # Ensure p1 is separated from r1_n by the correct distance.\n        p1 = r1_n + (c_n_length * unit_vector(p1 - r1_n))\n        # translate other so that its final C atom is at p1\n        other.translate(vector=(p1 - other[-1]['C']._vector))\n        # Force CA-C=O-N to be in a plane, and fix O=C-N angle accordingly\n        measured_dihedral = dihedral(\n            other[-1]['CA'], other[-1]['C'], other[-1]['O'], r1['N'])\n        desired_dihedral = 180.0\n        axis = other[-1]['O'] - other[-1]['C']\n        other.rotate(angle=(measured_dihedral - desired_dihedral),\n                     axis=axis, point=other[-1]['C']._vector)\n        axis = (numpy.cross(other[-1]['O'] - other[-1]\n                            ['C'], r1['N'] - other[-1]['C']))\n        measured_o_c_n = angle_between_vectors(\n            other[-1]['O'] - other[-1]['C'], r1['N'] - other[-1]['C'])\n        other.rotate(angle=(measured_o_c_n - o_c_n_angle),\n                     axis=axis, point=other[-1]['C']._vector)\n        # rotate other to obtain desired phi, omega, psi values at the join.\n        measured_phi = dihedral(other[-1]['C'], r1['N'], r1['CA'], r1['C'])\n        other.rotate(angle=(phi - measured_phi),\n                     axis=(r1_n - r1_ca), point=r1_ca)\n        measured_omega = dihedral(\n            other[-1]['CA'], other[-1]['C'], r1['N'], r1['CA'])\n        other.rotate(angle=(measured_omega - omega),\n                     axis=(r1['N'] - other[-1]['C']), point=r1_n)\n        measured_psi = dihedral(\n            other[-1]['N'], other[-1]['CA'], other[-1]['C'], r1['N'])\n        other.rotate(angle=-(measured_psi - psi), axis=(other[-1]['CA'] - other[-1]['C']),\n                     point=other[-1]['CA']._vector)\n        self._monomers = other._monomers + self._monomers\n        if relabel:\n            self.relabel_all()\n        self.tags['assigned_ff'] = False\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag_secondary_structure(self, force=False):\n        tagged = ['secondary_structure' in x.tags.keys()\n                  for x in self._monomers]\n        if (not all(tagged)) or force:\n            dssp_out = run_dssp(self.pdb, path=False)\n            if dssp_out is None:\n                return\n            dssp_ss_list = extract_all_ss_dssp(dssp_out, path=False)\n            for monomer, dssp_ss in zip(self._monomers, dssp_ss_list):\n                monomer.tags['secondary_structure'] = dssp_ss[1]\n        return", "response": "Tags each Residue of the Polypeptide with secondary structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntags the Residues of the Monomer with the relative RSA of the whole side chain of the Monomer and the MSE residue solvent accessibility.", "response": "def tag_residue_solvent_accessibility(self, tag_type=False, tag_total=False,\n                                          force=False, include_hetatms=False):\n        \"\"\"Tags `Residues` wirh relative residue solvent accessibility.\n\n        Notes\n        -----\n        THIS FUNCTIONALITY REQUIRES NACESS.\n        This function tags the Monomer with the *relative* RSA of\n        the *whole side chain*, i.e. column 2 of the .rsa file that\n        NACCESS writes.\n\n        References\n        ----------\n        .. [1] Hubbard,S.J. & Thornton, J.M. (1993), 'NACCESS',\n           Computer Program, Department of Biochemistry and Molecular\n           Biology, University College London.\n\n        Parameters\n        ----------\n        force : bool, optional\n            If `True`, the ta will be run even if `Residues` are\n            already tagged.\n        tag_type : str, optional\n            Specifies the name of the tag. Defaults to\n            'residue_solvent_accessibility'. Useful for specifying more\n            than one tag, e.g. if the Polymer is part of an Assembly.\n        tag_total : bool, optional\n            If True then the total rsa of the Polymer will be tagged\n            in the 'total accessibility' tag.\n        include_hetatms:bool, optional\n            If true then NACCESS will run with the -h flag and will\n            include heteroatom solvent accessibility where it can.\n            Helpful if your file has MSE residues that you don't\n            convert to MET, but best check if they are there\n            before using the flag.\n        \"\"\"\n        if tag_type:\n            tag_type = tag_type\n        else:\n            tag_type = 'residue_solvent_accessibility'\n        tagged = [tag_type in x.tags.keys() for x in self._monomers]\n        if (not all(tagged)) or force:\n            naccess_rsa_list, total = extract_residue_accessibility(run_naccess(\n                self.pdb, mode='rsa', path=False,\n                include_hetatms=include_hetatms), path=False, get_total=tag_total)\n            for monomer, naccess_rsa in zip(self._monomers, naccess_rsa_list):\n                monomer.tags[tag_type] = naccess_rsa\n            if tag_total:\n                self.tags['total_polymer_accessibility'] = total\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tag_dssp_solvent_accessibility(self, force=False):\n        tagged = ['dssp_acc' in x.tags.keys() for x in self._monomers]\n        if (not all(tagged)) or force:\n            dssp_out = run_dssp(self.pdb, path=False)\n            if dssp_out is None:\n                return\n            dssp_acc_list = extract_solvent_accessibility_dssp(\n                dssp_out, path=False)\n            for monomer, dssp_acc in zip(self._monomers, dssp_acc_list):\n                monomer.tags['dssp_acc'] = dssp_acc[-1]\n        return", "response": "Tags each Polymer with its solvent accessibility."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntagging each monomer with side - chain dihedral angles.", "response": "def tag_sidechain_dihedrals(self, force=False):\n        \"\"\"Tags each monomer with side-chain dihedral angles\n\n        force: bool, optional\n            If `True` the tag will be run even if `Residues` are\n            already tagged.\n        \"\"\"\n        tagged = ['chi_angles' in x.tags.keys() for x in self._monomers]\n        if (not all(tagged)) or force:\n            for monomer in self._monomers:\n                chi_angles = measure_sidechain_torsion_angles(\n                    monomer, verbose=False)\n                monomer.tags['chi_angles'] = chi_angles\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tag_torsion_angles(self, force=False):\n        tagged = ['omega' in x.tags.keys() for x in self._monomers]\n        if (not all(tagged)) or force:\n            tas = measure_torsion_angles(self._monomers)\n            for monomer, (omega, phi, psi) in zip(self._monomers, tas):\n                monomer.tags['omega'] = omega\n                monomer.tags['phi'] = phi\n                monomer.tags['psi'] = psi\n                monomer.tags['tas'] = (omega, phi, psi)\n        return", "response": "Tags each Monomer of the Polymer with its omega phi and psi torsion angle."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tag_ca_geometry(self, force=False, reference_axis=None,\n                        reference_axis_name='ref_axis'):\n        \"\"\"Tags each `Residue` with rise_per_residue, radius_of_curvature and residues_per_turn.\n\n        Parameters\n        ----------\n        force : bool, optional\n            If `True` the tag will be run even if `Residues` are already\n            tagged.\n        reference_axis : list(numpy.array or tuple or list), optional\n            Coordinates to feed to geometry functions that depend on\n            having a reference axis.\n        reference_axis_name : str, optional\n            Used to name the keys in tags at `Polypeptide` and `Residue` level.\n        \"\"\"\n        tagged = ['rise_per_residue' in x.tags.keys() for x in self._monomers]\n        if (not all(tagged)) or force:\n            # Assign tags None if Polymer is too short to have a primitive.\n            if len(self) < 7:\n                rprs = [None] * len(self)\n                rocs = [None] * len(self)\n                rpts = [None] * len(self)\n            else:\n                rprs = self.rise_per_residue()\n                rocs = self.radii_of_curvature()\n                rpts = residues_per_turn(self)\n            for monomer, rpr, roc, rpt in zip(self._monomers, rprs, rocs, rpts):\n                monomer.tags['rise_per_residue'] = rpr\n                monomer.tags['radius_of_curvature'] = roc\n                monomer.tags['residues_per_turn'] = rpt\n        # Functions that require a reference_axis.\n        if (reference_axis is not None) and (len(reference_axis) == len(self)):\n            # Set up arguments to pass to functions.\n            ref_axis_args = dict(p=self,\n                                 reference_axis=reference_axis,\n                                 tag=True,\n                                 reference_axis_name=reference_axis_name)\n            # Run the functions.\n            polymer_to_reference_axis_distances(**ref_axis_args)\n            crick_angles(**ref_axis_args)\n            alpha_angles(**ref_axis_args)\n        return", "response": "Tags each Residue in the Polymer with rise_per_residue radius_of_curvature and residues_per_turn and returns a list of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_backbone_bond_lengths(self, atol=0.1):\n        bond_lengths = self.backbone_bond_lengths\n        a1 = numpy.allclose(bond_lengths['n_ca'],\n                            [ideal_backbone_bond_lengths['n_ca']] * len(self),\n                            atol=atol)\n        a2 = numpy.allclose(bond_lengths['ca_c'],\n                            [ideal_backbone_bond_lengths['ca_c']] * len(self),\n                            atol=atol)\n        a3 = numpy.allclose(bond_lengths['c_o'],\n                            [ideal_backbone_bond_lengths['c_o']] * len(self),\n                            atol=atol)\n        a4 = numpy.allclose(bond_lengths['c_n'],\n                            [ideal_backbone_bond_lengths['c_n']] *\n                            (len(self) - 1),\n                            atol=atol)\n        return all([a1, a2, a3, a4])", "response": "True if all backbone bonds are within atol Angstroms of the expected distance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrue if all backbone bond angles are within atol degrees of their expected values.", "response": "def valid_backbone_bond_angles(self, atol=20):\n        \"\"\"True if all backbone bond angles are within atol degrees of their expected values.\n\n        Notes\n        -----\n        Ideal bond angles taken from [1].\n\n        References\n        ----------\n        .. [1] Schulz, G. E, and R. Heiner Schirmer. Principles Of\n           Protein Structure. New York: Springer-Verlag, 1979.\n\n        Parameters\n        ----------\n        atol : float, optional\n            Tolerance value in degrees for the absolute deviation\n            away from ideal backbone bond angles.\n        \"\"\"\n        bond_angles = self.backbone_bond_angles\n        omegas = [x[0] for x in measure_torsion_angles(self)]\n        trans = ['trans' if (omega is None) or (\n            abs(omega) >= 90) else 'cis' for omega in omegas]\n        ideal_n_ca_c = [ideal_backbone_bond_angles[x]['n_ca_c'] for x in trans]\n        ideal_ca_c_o = [ideal_backbone_bond_angles[trans[i + 1]]\n                        ['ca_c_o'] for i in range(len(trans) - 1)]\n        ideal_ca_c_o.append(ideal_backbone_bond_angles['trans']['ca_c_o'])\n        ideal_ca_c_n = [ideal_backbone_bond_angles[x]['ca_c_n']\n                        for x in trans[1:]]\n        ideal_c_n_ca = [ideal_backbone_bond_angles[x]['c_n_ca']\n                        for x in trans[1:]]\n        a1 = numpy.allclose(bond_angles['n_ca_c'], [ideal_n_ca_c], atol=atol)\n        a2 = numpy.allclose(bond_angles['ca_c_o'], [ideal_ca_c_o], atol=atol)\n        a3 = numpy.allclose(bond_angles['ca_c_n'], [ideal_ca_c_n], atol=atol)\n        a4 = numpy.allclose(bond_angles['c_n_ca'], [ideal_c_n_ca], atol=atol)\n        return all([a1, a2, a3, a4])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new cap for the current amino acid sequence.", "response": "def c_cap(self, cap='acid', cap_dihedral=False):\n        \"\"\"Caps C-terminus of polypeptide chain.\n\n        Notes\n        -----\n        Default behaviour is to add an oxygen atom to create a\n        carboxylate function at the C-terminus without changing the\n        psi angle of the C-terminal residue. Alternative psi angles\n        can be accessed through the cap_dihedral parameter. Will not\n        remove an existing cap if one is present, though altering a\n        cap of the same type will overwrite the original one.\n\n        Parameters\n        ----------\n        cap : str, optional\n            Type of cap to be added. Options: 'acid', 'amide'\n        cap_dihedral : bool\n            Alternate psi angle to be used when added cap.\n        \"\"\"\n        if cap == 'acid':\n            acetate = Ligand(atoms=None, mol_code='UNK',\n                             is_hetero=True, ampal_parent=Polypeptide)\n            atoms = OrderedDict()\n            atoms['CA'] = Atom([-1.4210, 0.4120, 0.0000], 'C',\n                               res_label='CA', ampal_parent=Ligand)\n            atoms['C'] = Atom([0.0120, -0.0560, 0.0020], 'C',\n                              res_label='C', ampal_parent=Ligand)\n            atoms['O'] = Atom([0.2610, -1.2380, 0.0000], 'O',\n                              res_label='O', ampal_parent=Ligand)\n            atoms['OXT'] = Atom([1.0110, 0.8400, 0.0000],\n                                'O', res_label='OXT', ampal_parent=Ligand)\n            acetate.atoms = atoms\n            s1, e1, s2, e2 = [\n                x._vector for x in [acetate['CA'],\n                                    acetate['C'],\n                                    self._monomers[-1]['CA'],\n                                    self._monomers[-1]['C']]]\n            translation, angle, axis, point = find_transformations(\n                s1, e1, s2, e2, radians=False)\n            acetate.rotate(angle=angle, axis=axis, point=point, radians=False)\n            acetate.translate(vector=translation)\n            start_angle = dihedral(\n                self._monomers[-1]['N'], self._monomers[-1]['CA'],\n                self._monomers[-1]['C'], acetate['O'])\n            ref_angle = dihedral(\n                self._monomers[-1]['N'], self._monomers[-1]['CA'],\n                self._monomers[-1]['C'], self._monomers[-1]['O'])\n            if cap_dihedral is not False:\n                acetate.rotate(\n                    ref_angle - start_angle + cap_dihedral,\n                    axis=acetate['C']._vector - acetate['CA']._vector,\n                    point=acetate['C']._vector)\n            else:\n                acetate.rotate(\n                    ref_angle - start_angle,\n                    axis=acetate['C']._vector - acetate['CA']._vector,\n                    point=acetate['C']._vector)\n            acetate['OXT'].ampal_parent = self._monomers[-1]\n            self._monomers[-1].atoms['OXT'] = acetate['OXT']\n            diff = acetate['O']._vector - self._monomers[-1]['O']._vector\n            self._monomers[-1]['O']._vector += diff\n        elif cap == 'amide':\n            acetamide = Ligand(atoms=None, mol_code='UNK', is_hetero=True)\n            atoms = OrderedDict()\n            atoms['CA'] = Atom([-0.4040, 0.0000, 1.4030], 'C', res_label='CA')\n            atoms['C'] = Atom([0.0580, 0.0000, -0.0300], 'C', res_label='C')\n            atoms['O'] = Atom([1.2440, 0.0000, -0.2840], 'O', res_label='O')\n            atoms['NH2'] = Atom([-0.8450, 0.0000, -1.0300],\n                                'N', res_label='NH2')\n            acetamide.atoms = atoms\n            s1, e1, s2, e2 = [\n                x._vector for x in [acetamide['CA'],\n                                    acetamide['C'],\n                                    self._monomers[-1]['CA'],\n                                    self._monomers[-1]['C']]]\n            translation, angle, axis, point = find_transformations(\n                s1, e1, s2, e2, radians=False)\n            acetamide.rotate(angle=angle, axis=axis,\n                             point=point, radians=False)\n            acetamide.translate(vector=translation)\n            start_angle = dihedral(\n                self._monomers[-1]['N'], self._monomers[-1]['CA'],\n                self._monomers[-1]['C'], acetamide['O'])\n            ref_angle = dihedral(\n                self._monomers[-1]['N'], self._monomers[-1]['CA'],\n                self._monomers[-1]['C'], self._monomers[-1]['O'])\n            if cap_dihedral is not False:\n                acetamide.rotate(\n                    ref_angle - start_angle + cap_dihedral,\n                    axis=acetamide['C']._vector - acetamide['CA']._vector,\n                    point=acetamide['C']._vector)\n            else:\n                acetamide.rotate(\n                    ref_angle - start_angle,\n                    axis=acetamide['C']._vector - acetamide['CA']._vector,\n                    point=acetamide['C']._vector)\n            if self.ligands is None:\n                self.ligands = LigandGroup(ampal_parent=self)\n            amide = Ligand(mol_code='NH2', ampal_parent=self.ligands)\n            amide_atoms = OrderedDict([('NH2', acetamide['NH2'])])\n            amide_atoms['NH2'].ampal_parent = amide\n            amide.atoms = amide_atoms\n            self.ligands.append(amide)\n        else:\n            pass\n        self.tags['assigned_ff'] = False\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef n_cap(self, n_cap='acetyl', cap_dihedral=None):\n        if n_cap == 'acetyl':\n            methylacetamide = Ligand(\n                atoms=None, mol_code='UNK', is_hetero=True)\n            atoms = OrderedDict()\n            atoms['C'] = Atom([0.9500, -0.2290, 0.5090], 'C', res_label='C')\n            atoms['CA'] = Atom([0.7450, -0.9430, 1.8040], 'C', res_label='CA')\n            atoms['O'] = Atom([0.1660, -2.0230, 1.8130], 'O', res_label='O')\n            atoms['N'] = Atom([1.2540, -0.2750, 2.9010], 'N', res_label='N')\n            atoms['CME'] = Atom([1.1630, -0.7870, 4.2500],\n                                'C', res_label='CME')\n            # these coordinates seem ok, but could review\n            # and use a different fragment if necessary\n            methylacetamide.atoms = atoms\n            s1, e1, s2, e2 = [\n                x._vector for x in [methylacetamide['N'],\n                                    methylacetamide['CME'],\n                                    self._monomers[0]['N'],\n                                    self._monomers[0]['CA']]]\n            translation, angle, axis, point = find_transformations(\n                s1, e1, s2, e2, radians=False)\n            methylacetamide.rotate(\n                angle=angle, axis=axis, point=point, radians=False)\n            methylacetamide.translate(vector=translation)\n            start_angle = dihedral(\n                methylacetamide['C'], self._monomers[0]['N'],\n                self._monomers[0]['CA'], self._monomers[0]['C'])\n            ref_angle = dihedral(\n                self._monomers[0]['C'], self._monomers[1]['N'],\n                self._monomers[1]['CA'], self._monomers[1]['C'])\n            if cap_dihedral is not None:\n                methylacetamide.rotate(ref_angle - start_angle + cap_dihedral,\n                                       axis=methylacetamide['N']._vector -\n                                       self._monomers[0]['CA']._vector,\n                                       point=methylacetamide['N']._vector)\n            else:\n                methylacetamide.rotate(ref_angle - start_angle,\n                                       axis=methylacetamide['N']._vector -\n                                       self._monomers[0]['CA']._vector,\n                                       point=methylacetamide['N']._vector)\n            if self.ligands is None:\n                self.ligands = LigandGroup(ampal_parent=self)\n            acetamide = Ligand(mol_code='ACM', ampal_parent=self.ligands)\n            acetamide_atoms = OrderedDict()\n            acetamide_atoms['C'] = atoms['C']\n            acetamide_atoms['CA'] = atoms['CA']\n            acetamide_atoms['O'] = atoms['O']\n            for atom in acetamide_atoms.values():\n                atom.ampal_parent = acetamide\n            acetamide.atoms = acetamide_atoms\n            self.ligands.append(acetamide)\n        else:\n            pass  # just in case we want to build different caps in later\n        self.tags['assigned_ff'] = False\n        return", "response": "Adds an N - terminal acetamide cap to the structure."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new Residue containing only the backbone atoms of the original .", "response": "def backbone(self):\n        \"\"\"Returns a new `Residue` containing only the backbone atoms.\n\n        Returns\n        -------\n        bb_monomer : Residue\n            `Residue` containing only the backbone atoms of the original\n            `Monomer`.\n\n        Raises\n        ------\n        IndexError\n            Raise if the `atoms` dict does not contain the backbone\n            atoms (N, CA, C, O).\n        \"\"\"\n        try:\n            backbone = OrderedDict([('N', self.atoms['N']),\n                                    ('CA', self.atoms['CA']),\n                                    ('C', self.atoms['C']),\n                                    ('O', self.atoms['O'])])\n        except KeyError:\n            missing_atoms = filter(lambda x: x not in self.atoms.keys(),\n                                   ('N', 'CA', 'C', 'O')\n                                   )\n            raise KeyError('Error in residue {} {} {}, missing ({}) atoms. '\n                           '`atoms` must be an `OrderedDict` with coordinates '\n                           'defined for the backbone (N, CA, C, O) atoms.'\n                           .format(self.ampal_parent.id, self.mol_code,\n                                   self.id, ', '.join(missing_atoms)))\n        bb_monomer = Residue(backbone, self.mol_code, monomer_id=self.id,\n                             insertion_code=self.insertion_code,\n                             is_hetero=self.is_hetero)\n        return bb_monomer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unique_id(self):\n        if self.is_hetero:\n            if self.mol_code == 'HOH':\n                hetero_flag = 'W'\n            else:\n                hetero_flag = 'H_{0}'.format(self.mol_code)\n        else:\n            hetero_flag = ' '\n        return self.ampal_parent.id, (hetero_flag, self.id, self.insertion_code)", "response": "Generates a tuple that uniquely identifies a Monomer in an Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of the side - chain atoms.", "response": "def side_chain(self):\n        \"\"\"List of the side-chain atoms (R-group).\n\n        Notes\n        -----\n        Returns empty list for glycine.\n\n        Returns\n        -------\n        side_chain_atoms: list(`Atoms`)\n        \"\"\"\n        side_chain_atoms = []\n        if self.mol_code != 'GLY':\n            covalent_bond_graph = generate_covalent_bond_graph(\n                find_covalent_bonds(self))\n            try:\n                subgraphs = generate_bond_subgraphs_from_break(\n                    covalent_bond_graph, self['CA'], self['CB'])\n                if len(subgraphs) == 1:\n                    subgraphs = generate_bond_subgraphs_from_break(\n                        subgraphs[0], self['CD'], self['N'])\n                if len(subgraphs) == 2:\n                    for g in subgraphs:\n                        if self['CB'] in g:\n                            side_chain_atoms = g.nodes()\n                            break\n            except:\n                warning_message = \"Malformed PDB for Residue {0}: {1}.\".format(\n                    self.id, self)\n                if 'CB' in self.atoms.keys():\n                    side_chain_atoms.append(self['CB'])\n                    warning_message += \" Side-chain is just the CB atom.\"\n                else:\n                    warning_message += \" Empty side-chain.\"\n                warnings.warn(warning_message, MalformedPDBWarning)\n        return side_chain_atoms"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the environment of the side - chain of the Monomer.", "response": "def side_chain_environment(self, cutoff=4, include_neighbours=True,\n                               inter_chain=True, include_ligands=False, include_solvent=False):\n        \"\"\"Finds `Residues` with any atom within the cutoff distance of side-chain.\n\n        Notes\n        -----\n        Includes the parent residue in the list.\n\n        Parameters\n        ----------\n        cutoff : float, optional\n            Maximum inter-atom distance for residue to be included.\n            Defaults to 4.\n        include_neighbours : bool, optional\n            If `false`, does not return `Residue` at i-1, i+1 positions\n            in same chain as `Residue`.\n        inter_chain : bool, optional\n            If `false`, only includes nearby `Residue` in the same chain\n            as the `Residue`.\n        include_ligands : bool, optional\n            If `true`, `Residue` classed as ligands but not identified as\n            solvent will be included in the environment.\n        include_solvent : bool, optional\n            If `true`, Monomers classed as categorised as solvent\n            will be included in the environment.\n\n        Returns\n        -------\n        sc_environment : list\n            List of monomers within cutoff distance of side-chain.\n        \"\"\"\n        if self.mol_code == 'GLY':\n            return [self]\n        side_chain_dict = {x: {y: self.states[x][y]\n                               for y in self.states[x] if self.states[x][y] in\n                               self.side_chain} for x in self.states}\n        side_chain_monomer = Monomer(\n            atoms=side_chain_dict, monomer_id=self.id,\n            ampal_parent=self.ampal_parent)\n        sc_environment = side_chain_monomer.environment(\n            cutoff=cutoff, include_ligands=include_ligands,\n            include_neighbours=include_neighbours,\n            include_solvent=include_solvent, inter_chain=inter_chain)\n        return sc_environment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the settings file containing paths to dependencies and other optional configuration elements.", "response": "def load_global_settings():\n    \"\"\"Loads settings file containing paths to dependencies and other optional configuration elements.\"\"\"\n    with open(settings_path, 'r') as settings_f:\n        global global_settings\n        settings_json = json.loads(settings_f.read())\n        if global_settings is None:\n            global_settings = settings_json\n            global_settings[u'package_path'] = package_dir\n        else:\n            for k, v in settings_json.items():\n                if type(v) == dict:\n                    global_settings[k].update(v)\n                else:\n                    global_settings[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(self):\n        for i in range(2):\n            self._molecules.append(\n                self.make_helix(self.aas[i], self.axis_distances[i],\n                                self.z_shifts[i], self.phis[i], self.splays[i],\n                                self.off_plane[i]))\n        return", "response": "Builds a HelixPair using the defined attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_helix(aa, axis_distance, z_shift, phi, splay, off_plane):\n        start = numpy.array([axis_distance, 0 + z_shift, 0])\n        end = numpy.array([axis_distance, (aa * 1.52) + z_shift, 0])\n        mid = (start + end) / 2\n\n        helix = Helix.from_start_and_end(start, end, aa=aa)\n        helix.rotate(splay, (0, 0, 1), mid)\n        helix.rotate(off_plane, (1, 0, 0), mid)\n        helix.rotate(phi, helix.axis.unit_tangent, helix.helix_start)\n        return helix", "response": "Builds a helix for a given set of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(self):\n        self._molecules = []\n        if self.handedness == 'l':\n            handedness = -1\n        else:\n            handedness = 1\n        rot_ang = self.rot_ang * handedness\n        for i in range(self.num_of_repeats):\n            dup_unit = copy.deepcopy(self.repeat_unit)\n            z = (self.rise * i) * numpy.array([0, 0, 1])\n            dup_unit.translate(z)\n            dup_unit.rotate(rot_ang * i, [0, 0, 1])\n            self.extend(dup_unit)\n        self.relabel_all()\n        return", "response": "Builds a Solenoid using the defined attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_start_and_end(cls, start, end, sequence, helix_type='b_dna',\n                           phos_3_prime=False):\n        \"\"\"Generates a helical `Polynucleotide` that is built along an axis.\n\n        Parameters\n        ----------\n        start: [float, float, float]\n            Start of the build axis.\n        end: [float, float, float]\n            End of build axis.\n        sequence: str\n            The nucleotide sequence of the nucleic acid.\n        helix_type: str\n            The type of nucleic acid helix to generate.\n        phos_3_prime: bool\n            If false the 5' and the 3' phosphor will be omitted.\n        \"\"\"\n        start = numpy.array(start)\n        end = numpy.array(end)\n        instance = cls(sequence, helix_type=helix_type,\n                       phos_3_prime=phos_3_prime)\n        instance.move_to(start=start, end=end)\n        return instance", "response": "Generates a helical Polynucleotide from start and end positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a single DNA sequence from the base sequence.", "response": "def build(self):\n        \"\"\"Build single DNA strand along z-axis, starting with P on x-axis\"\"\"\n        ang_per_res = (2 * numpy.pi) / self.nucleotides_per_turn\n        atom_offset_coords = _backbone_properties[self.helix_type]['atoms']\n        if self.handedness == 'l':\n            handedness = -1\n        else:\n            handedness = 1\n        base_atom_labels = _backbone_properties[self.helix_type]['labels']\n        monomers = []\n        mol_code_format = _backbone_properties[self.helix_type]['mol_code_format']\n        for i, b in enumerate(self.base_sequence):\n            nucleotide = Nucleotide(\n                mol_code=mol_code_format.format(b), ampal_parent=self)\n            atoms_dict = OrderedDict()\n            if (i == (len(self.base_sequence) - 1)) and not self.phos_3_prime:\n                # Do not include phosphate on last nucleotide\n                atom_labels = base_atom_labels[3:] + [_bases[b]['labels'][2]]\n                atom_offsets = {k: v for k, v in zip(\n                    atom_labels, atom_offset_coords[3:])}\n            else:\n                atom_labels = base_atom_labels + [_bases[b]['labels'][2]]\n                atom_offsets = {k: v for k, v in zip(\n                    atom_labels, atom_offset_coords)}\n            for atom_label in atom_labels:\n                r, zeta, z_shift = atom_offsets[atom_label]\n                rot_ang = ((i * ang_per_res) + zeta) * handedness\n                z = (self.rise_per_nucleotide * i) + z_shift\n                coords = cylindrical_to_cartesian(\n                    radius=r, azimuth=rot_ang, z=z, radians=True)\n                atom = Atom(\n                    coordinates=coords, element=atom_label[0],\n                    ampal_parent=nucleotide, res_label=atom_label)\n                atoms_dict[atom_label] = atom\n            base_ref = _bases[b]['ref_atom']\n            rot_adj = _bases[b]['rot_adj']\n            base_dict = OrderedDict(\n                zip(_bases[b]['labels'], _bases[b]['atoms']))\n            translation, angle, axis, point = find_transformations(\n                base_dict[base_ref], base_dict[\"C1'\"],\n                atoms_dict[base_ref]._vector, atoms_dict[\"C1'\"]._vector)\n            q1 = Quaternion.angle_and_axis(angle, axis)\n            # Align N9 C1'\n            for k, v in base_dict.items():\n                base_dict[k] = q1.rotate_vector(v, point) + translation\n            # Rotate to align O4'\n            axis = numpy.array(base_dict[\"C1'\"]) - base_dict[base_ref]\n            angle = dihedral(base_dict[\"O4'\"], base_dict[base_ref],\n                             base_dict[\"C1'\"], atoms_dict[\"O4'\"]) - rot_adj\n            q2 = Quaternion.angle_and_axis(angle, axis)\n            for k, v in list(base_dict.items()):\n                if k not in atoms_dict:\n                    atom = Atom(q2.rotate_vector(v, base_dict[base_ref]),\n                                element=k[0], ampal_parent=nucleotide,\n                                res_label=k)\n                    atoms_dict[k] = atom\n            nucleotide.atoms = atoms_dict\n            monomers.append(nucleotide)\n        self._monomers = monomers\n        self.relabel_monomers()\n        self.relabel_atoms()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves the Polynucleotide to lie on the start and end vectors.", "response": "def move_to(self, start, end):\n        \"\"\"Moves the `Polynucleotide` to lie on the `start` and `end` vector.\n\n        Parameters\n        ----------\n        start : 3D Vector (tuple or list or numpy.array)\n            The coordinate of the start of the helix primitive.\n        end : 3D Vector (tuple or list or numpy.array)\n            The coordinate of the end of the helix primitive.\n\n        Raises\n        ------\n        ValueError\n            Raised if `start` and `end` are very close together.\n        \"\"\"\n        start = numpy.array(start)\n        end = numpy.array(end)\n        if numpy.allclose(start, end):\n            raise ValueError('start and end must NOT be identical')\n        translation, angle, axis, point = find_transformations(\n            self.helix_start, self.helix_end, start, end)\n        if not numpy.isclose(angle, 0.0):\n            self.rotate(angle=angle, axis=axis, point=point, radians=False)\n        self.translate(vector=translation)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_heptad_register(crangles):\n    crangles = [x if x > 0 else 360 + x for x in crangles]\n    hept_p = [x * (360.0 / 7.0) + ((360.0 / 7.0) / 2.0) for x in range(7)]\n    ideal_crangs = [\n        hept_p[0],\n        hept_p[2],\n        hept_p[4],\n        hept_p[6],\n        hept_p[1],\n        hept_p[3],\n        hept_p[5]\n    ]\n    full_hept = len(crangles) // 7\n    ideal_crang_list = ideal_crangs * (full_hept + 2)  # This is dirty, too long but trimmed with zip\n    fitting = []\n    for i in range(7):\n        ang_pairs = zip(crangles, ideal_crang_list[i:])\n        ang_diffs = [abs(y - x) for x, y in ang_pairs]\n        fitting.append((i, numpy.mean(ang_diffs), numpy.std(ang_diffs)))\n    return sorted(fitting, key=lambda x: x[1])", "response": "Attempts to fit a heptad repeat to a set of Crick angles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gather_layer_info(self):\n        for i in range(len(self.cc[0])):\n            layer_radii = [x[i].tags['distance_to_ref_axis'] for x in self.cc]\n            self.radii_layers.append(layer_radii)\n            layer_alpha = [x[i].tags['alpha_angle_ref_axis'] for x in self.cc]\n            self.alpha_layers.append(layer_alpha)\n            layer_ca = [x[i].tags['crick_angle_ref_axis'] for x in self.cc]\n            self.ca_layers.append(layer_ca)\n        return", "response": "Extracts the tagged coiled - coil parameters for each layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_average_parameters(parameter_layers):\n        mean_layers = [numpy.mean(x) if x[0] else 0 for x in parameter_layers]\n        overall_mean = numpy.mean([x for x in mean_layers if x])\n        return mean_layers, overall_mean", "response": "Takes a group of equal length lists and averages them across each index. Returns a list of lists of values averaged by index\n            Mean of the averaged values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the calculated register of the coiled coil and the fit quality.", "response": "def heptad_register(self):\n        \"\"\"Returns the calculated register of the coiled coil and the fit quality.\"\"\"\n        base_reg = 'abcdefg'\n        exp_base = base_reg * (self.cc_len//7+2)\n        ave_ca_layers = self.calc_average_parameters(self.ca_layers)[0][:-1]\n        reg_fit = fit_heptad_register(ave_ca_layers)\n        hep_pos = reg_fit[0][0]\n        return exp_base[hep_pos:hep_pos+self.cc_len], reg_fit[0][1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_report(self):\n        # Find register\n        lines = ['Register Assignment\\n-------------------']\n        register, fit = self.heptad_register()\n        lines.append('{}\\n{}\\n'.format(register, '\\n'.join(self.cc.sequences)))\n        lines.append('Fit Quality - Mean Angular Discrepancy = {:3.2f} (Std Dev = {:3.2f})\\n'.format(*fit))\n        # Find coiled coil parameters\n        lines.append('Coiled Coil Parameters\\n----------------------')\n        layer_info = (self.radii_layers, self.alpha_layers, self.ca_layers)\n        r_layer_aves, a_layer_aves, c_layer_aves = [self.calc_average_parameters(x) for x in layer_info]\n        start_line = ['Res#'.rjust(5), 'Radius'.rjust(9), 'Alpha'.rjust(9), 'CrAngle'.rjust(9)]\n        lines.append(''.join(start_line))\n        for i in range(len(r_layer_aves[0])):\n            residue = '{:>5}'.format(i+1)\n            average_r = '{:+3.3f}'.format(r_layer_aves[0][i]).rjust(9)\n            average_a = '{:+3.3f}'.format(a_layer_aves[0][i]).rjust(9)\n            average_c = '{:+3.3f}'.format(c_layer_aves[0][i]).rjust(9)\n            line = [residue, average_r, average_a, average_c]\n            lines.append(''.join(line))\n        # Average for assembly\n        lines.append('-'*32)\n        residue = '  Ave'\n        average_r = '{:+3.3f}'.format(r_layer_aves[1]).rjust(9)\n        average_a = '{:+3.3f}'.format(a_layer_aves[1]).rjust(9)\n        average_c = '{:+3.3f}'.format(c_layer_aves[1]).rjust(9)\n        line = [residue, average_r, average_a, average_c]\n        lines.append(''.join(line))\n        # Std dev\n        residue = 'Std D'\n        std_d_r = '{:+3.3f}'.format(numpy.std(r_layer_aves[0])).rjust(9)\n        std_d_a = '{:+3.3f}'.format(numpy.std(a_layer_aves[0][:-1])).rjust(9)\n        std_d_c = '{:+3.3f}'.format(numpy.std(c_layer_aves[0][:-1])).rjust(9)\n        line = [residue, std_d_r, std_d_a, std_d_c]\n        lines.append(''.join(line))\n        return '\\n'.join(lines)", "response": "Generates a report on the coiled coil parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an optimizer with default build and BUFF interaction eval.", "response": "def buff_interaction_eval(cls, specification, sequences, parameters,\n                              **kwargs):\n        \"\"\"Creates optimizer with default build and BUFF interaction eval.\n\n        Notes\n        -----\n        Any keyword arguments will be propagated down to BaseOptimizer.\n\n        Parameters\n        ----------\n        specification : ampal.assembly.specification\n            Any assembly level specification.\n        sequences : [str]\n            A list of sequences, one for each polymer.\n        parameters : [base_ev_opt.Parameter]\n            A list of `Parameter` objects in the same order as the\n            function signature expects.\n        \"\"\"\n        instance = cls(specification,\n                       sequences,\n                       parameters,\n                       build_fn=default_build,\n                       eval_fn=buff_interaction_eval,\n                       **kwargs)\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rmsd_eval(cls, specification, sequences, parameters, reference_ampal,\n                  **kwargs):\n        \"\"\"Creates optimizer with default build and RMSD eval.\n\n        Notes\n        -----\n        Any keyword arguments will be propagated down to BaseOptimizer.\n\n        RMSD eval is restricted to a single core only, due to restrictions\n        on closure pickling.\n\n        Parameters\n        ----------\n        specification : ampal.assembly.specification\n            Any assembly level specification.\n        sequences : [str]\n            A list of sequences, one for each polymer.\n        parameters : [base_ev_opt.Parameter]\n            A list of `Parameter` objects in the same order as the\n            function signature expects.\n        reference_ampal : ampal.Assembly\n            The target structure of the optimisation.\n        \"\"\"\n        eval_fn = make_rmsd_eval(reference_ampal)\n        instance = cls(specification,\n                       sequences,\n                       parameters,\n                       build_fn=default_build,\n                       eval_fn=eval_fn,\n                       mp_disabled=True,\n                       **kwargs)\n        return instance", "response": "Creates an optimizer with default build and RMSD eval."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_individual(self, individual):\n        scaled_ind = []\n        for i in range(len(self.value_means)):\n            scaled_ind.append(self.value_means[i] + (\n                individual[i] * self.value_ranges[i]))\n        fullpars = list(self.arrangement)\n        for k in range(len(self.variable_parameters)):\n            for j in range(len(fullpars)):\n                if fullpars[j] == self.variable_parameters[k]:\n                    fullpars[j] = scaled_ind[k]\n        return fullpars", "response": "Converts a deap individual into a full list of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_opt(self, pop_size, generations, cores=1, plot=False, log=False,\n                log_path=None, run_id=None, store_params=True, **kwargs):\n        \"\"\"Runs the optimizer.\n\n        Parameters\n        ----------\n        pop_size: int\n            Size of the population each generation.\n        generation: int\n            Number of generations in optimisation.\n        cores: int, optional\n            Number of CPU cores used to run the optimisation.\n            If the 'mp_disabled' keyword is passed to the\n            optimizer, this will be ignored and one core will\n            be used.\n        plot: bool, optional\n            If true, matplotlib will be used to plot information\n            about the minimisation.\n        log: bool, optional\n            If true, a log file describing the optimisation will\n            be created. By default it will be written to the\n            current directory and named according to the time the\n            minimisation finished. This can be manually specified\n            by passing the 'output_path' and 'run_id' keyword\n            arguments.\n        log_path : str\n            Path to write output file.\n        run_id : str\n            An identifier used as the name of your log file.\n        store_params: bool, optional\n            If true, the parameters for each model created during\n            the optimisation will be stored. This can be used to\n            create funnel data later on.\n        \"\"\"\n        self._cores = cores\n        self._store_params = store_params\n        self.parameter_log = []\n        self._model_count = 0\n        self.halloffame = tools.HallOfFame(1)\n        self.stats = tools.Statistics(lambda thing: thing.fitness.values)\n        self.stats.register(\"avg\", numpy.mean)\n        self.stats.register(\"std\", numpy.std)\n        self.stats.register(\"min\", numpy.min)\n        self.stats.register(\"max\", numpy.max)\n        self.logbook = tools.Logbook()\n        self.logbook.header = [\"gen\", \"evals\"] + self.stats.fields\n        start_time = datetime.datetime.now()\n        self._initialize_pop(pop_size)\n        for g in range(generations):\n            self._update_pop(pop_size)\n            self.halloffame.update(self.population)\n            self.logbook.record(gen=g, evals=self._evals,\n                                **self.stats.compile(self.population))\n            print(self.logbook.stream)\n        end_time = datetime.datetime.now()\n        time_taken = end_time - start_time\n        print(\"Evaluated {} models in total in {}\".format(\n            self._model_count, time_taken))\n        print(\"Best fitness is {0}\".format(self.halloffame[0].fitness))\n        print(\"Best parameters are {0}\".format(self.parse_individual(\n            self.halloffame[0])))\n        for i, entry in enumerate(self.halloffame[0]):\n            if entry > 0.95:\n                print(\n                    \"Warning! Parameter {0} is at or near maximum allowed \"\n                    \"value\\n\".format(i + 1))\n            elif entry < -0.95:\n                print(\n                    \"Warning! Parameter {0} is at or near minimum allowed \"\n                    \"value\\n\".format(i + 1))\n        if log:\n            self.log_results(output_path=output_path, run_id=run_id)\n        if plot:\n            print('----Minimisation plot:')\n            plt.figure(figsize=(5, 5))\n            plt.plot(range(len(self.logbook.select('min'))),\n                     self.logbook.select('min'))\n            plt.xlabel('Iteration', fontsize=20)\n            plt.ylabel('Score', fontsize=20)\n        return", "response": "Runs the optimisation on the specified population size and number of generations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_parameters(self):\n        self.value_means = []\n        self.value_ranges = []\n        self.arrangement = []\n        self.variable_parameters = []\n        current_var = 0\n        for parameter in self.parameters:\n            if parameter.type == ParameterType.DYNAMIC:\n                self.value_means.append(parameter.value[0])\n                if parameter.value[1] < 0:\n                    raise AttributeError(\n                        '\"{}\" parameter has an invalid range. Range values '\n                        'must be greater than zero'.format(parameter.label))\n                self.value_ranges.append(parameter.value[1])\n                var_label = 'var{}'.format(current_var)\n                self.arrangement.append(var_label)\n                self.variable_parameters.append(var_label)\n                current_var += 1\n            elif parameter.type == ParameterType.STATIC:\n                self.arrangement.append(parameter.value)\n            else:\n                raise AttributeError(\n                    '\"{}\"Unknown parameter type ({}). Parameters can be STATIC or'\n                    ' DYNAMIC.'.format(parameter.type))\n        return", "response": "Converts a list of Parameters into DEAP format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning fitnesses to parameters.", "response": "def assign_fitnesses(self, targets):\n        \"\"\"Assigns fitnesses to parameters.\n\n        Notes\n        -----\n        Uses `self.eval_fn` to evaluate each member of target.\n        Parameters\n        ---------\n\n        targets\n            Parameter values for each member of the population.\n        \"\"\"\n        self._evals = len(targets)\n        px_parameters = zip([self.specification] * len(targets),\n                            [self.sequences] * len(targets),\n                            [self.parse_individual(x) for x in targets])\n        if (self._cores == 1) or (self.mp_disabled):\n            models = map(self.build_fn, px_parameters)\n            fitnesses = map(self.eval_fn, models)\n        else:\n            with futures.ProcessPoolExecutor(\n                    max_workers=self._cores) as executor:\n                models = executor.map(self.build_fn, px_parameters)\n                fitnesses = executor.map(self.eval_fn, models)\n        tars_fits = list(zip(targets, fitnesses))\n        if self._store_params:\n            self.parameter_log.append(\n                [(self.parse_individual(x[0]), x[1]) for x in tars_fits])\n        for ind, fit in tars_fits:\n            ind.fitness.values = (fit,)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the results of the minimization.", "response": "def log_results(self, output_path=None, run_id=None):\n        \"\"\"Saves files for the minimization.\n\n        Notes\n        -----\n        Currently saves a logfile with best individual and a pdb of\n        the best model.\n        \"\"\"\n        best_ind = self.halloffame[0]\n        model_params = self.parse_individual(\n            best_ind)  # need to change name of 'params'\n        if output_path is None:\n            output_path = os.getcwd()\n        if run_id is None:\n            run_id = '{:%Y%m%d-%H%M%S}'.format(\n                datetime.datetime.now())\n        with open('{0}/{1}_opt_log.txt'.format(\n                output_path, run_id), 'w') as log_file:\n            log_file.write('\\nEvaluated {0} models in total\\n'.format(\n                self._model_count))\n            log_file.write('Run ID is {0}\\n'.format(run_id))\n            log_file.write('Best fitness is {0}\\n'.format(\n                self.halloffame[0].fitness))\n            log_file.write(\n                'Parameters of best model are {0}\\n'.format(model_params))\n            log_file.write(\n                'Best individual is {0}\\n'.format(self.halloffame[0]))\n            for i, entry in enumerate(self.halloffame[0]):\n                if entry > 0.95:\n                    log_file.write(\n                        \"Warning! Parameter {0} is at or near maximum allowed \"\n                        \"value\\n\".format(i + 1))\n                elif entry < -0.95:\n                    log_file.write(\n                        \"Warning! Parameter {0} is at or near minimum allowed \"\n                        \"value\\n\".format(i + 1))\n            log_file.write('Minimization history: \\n{0}'.format(self.logbook))\n        with open('{0}/{1}_opt_best_model.pdb'.format(\n                output_path, run_id), 'w') as output_file:\n            output_file.write(self.best_model.pdb)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrebuild the AMPAL model from an optimisation.", "response": "def best_model(self):\n        \"\"\"Rebuilds the top scoring model from an optimisation.\n\n        Returns\n        -------\n        model: AMPAL\n            Returns an AMPAL model of the top scoring parameters.\n\n        Raises\n        ------\n        AttributeError\n            Raises a name error if the optimiser has not been run.\n        \"\"\"\n        if not hasattr(self, 'halloffame'):\n            raise AttributeError(\n                'No best model found, have you ran the optimiser?')\n        model = self.build_fn(\n            (self.specification,\n             self.sequences,\n             self.parse_individual(self.halloffame[0])\n            ))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dynamic(cls, label, val_mean, val_range):\n        return cls(label, ParameterType.DYNAMIC, (val_mean, val_range))", "response": "Creates a static parameter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_scwrl(pdb, sequence, path=True):\n    if path:\n        with open(pdb, 'r') as inf:\n            pdb = inf.read()\n    pdb = pdb.encode()\n    sequence = sequence.encode()\n    try:\n        with tempfile.NamedTemporaryFile(delete=False) as scwrl_tmp,\\\n                tempfile.NamedTemporaryFile(delete=False) as scwrl_seq,\\\n                tempfile.NamedTemporaryFile(delete=False) as scwrl_out:\n            scwrl_tmp.write(pdb)\n            scwrl_tmp.seek(0)  # Resets the buffer back to the first line\n            scwrl_seq.write(sequence)\n            scwrl_seq.seek(0)\n            if not global_settings['scwrl']['rigid_rotamer_model']:\n                scwrl_std_out = subprocess.check_output(\n                    [global_settings['scwrl']['path'],\n                     '-i', scwrl_tmp.name,\n                     '-o', scwrl_out.name,\n                     '-s', scwrl_seq.name])\n            else:\n                scwrl_std_out = subprocess.check_output(\n                    [global_settings['scwrl']['path'],\n                     '-v',  # Rigid rotamer model\n                     '-i', scwrl_tmp.name,\n                     '-o', scwrl_out.name,\n                     '-s', scwrl_seq.name])\n            scwrl_out.seek(0)\n            scwrl_pdb = scwrl_out.read()\n    finally:\n        os.remove(scwrl_tmp.name)\n        os.remove(scwrl_out.name)\n        os.remove(scwrl_seq.name)\n    if not scwrl_pdb:\n        raise IOError('SCWRL failed to run. SCWRL:\\n{}'.format(scwrl_std_out))\n    return scwrl_std_out.decode(), scwrl_pdb.decode()", "response": "Runs SCWRL on input PDB strong or path to PDB and a sequence string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses SCWRL output and returns PDB and SCWRL score.", "response": "def parse_scwrl_out(scwrl_std_out, scwrl_pdb):\n    \"\"\"Parses SCWRL output and returns PDB and SCWRL score.\n\n    Parameters\n    ----------\n    scwrl_std_out : str\n        Std out from SCWRL.\n    scwrl_pdb : str\n        String of packed SCWRL PDB.\n\n    Returns\n    -------\n    fixed_scwrl_str : str\n        String of packed SCWRL PDB, with correct PDB format.\n    score : float\n        SCWRL Score\n    \"\"\"\n    score = re.findall(\n        r'Total minimal energy of the graph = ([-0-9.]+)', scwrl_std_out)[0]\n    # Add temperature factors to SCWRL out\n    split_scwrl = scwrl_pdb.splitlines()\n    fixed_scwrl = []\n    for line in split_scwrl:\n        if len(line) < 80:\n            line += ' ' * (80 - len(line))\n        if re.search(r'H?E?T?ATO?M\\s+\\d+.+', line):\n            front = line[:61]\n            temp_factor = ' 0.00'\n            back = line[66:]\n            fixed_scwrl.append(''.join([front, temp_factor, back]))\n        else:\n            fixed_scwrl.append(line)\n    fixed_scwrl_str = '\\n'.join(fixed_scwrl) + '\\n'\n    return fixed_scwrl_str, float(score)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pack_sidechains(pdb, sequence, path=False):\n    scwrl_std_out, scwrl_pdb = run_scwrl(pdb, sequence, path=path)\n    return parse_scwrl_out(scwrl_std_out, scwrl_pdb)", "response": "Packs sidechains onto a given PDB file or string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the PDB parser.", "response": "def parse_pdb_file(self):\n        \"\"\"Runs the PDB parser.\"\"\"\n        self.pdb_parse_tree = {'info': {},\n                               'data': {\n                                   self.state: {}}\n                               }\n        try:\n            for line in self.pdb_lines:\n                self.current_line = line\n                record_name = line[:6].strip()\n                if record_name in self.proc_functions:\n                    self.proc_functions[record_name]()\n                else:\n                    if record_name not in self.pdb_parse_tree['info']:\n                        self.pdb_parse_tree['info'][record_name] = []\n                    self.pdb_parse_tree['info'][record_name].append(line)\n        except EOFError:\n            # Raised by END record\n            pass\n        if self.new_labels:\n            ampal_data_session.commit()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing an ATOM or HETATM record.", "response": "def proc_atom(self):\n        \"\"\"Processes an \"ATOM\" or \"HETATM\" record.\"\"\"\n        atom_data = self.proc_line_coordinate(self.current_line)\n        (at_type, at_ser, at_name, alt_loc, res_name, chain_id, res_seq,\n         i_code, x, y, z, occupancy, temp_factor, element, charge) = atom_data\n        # currently active state\n        a_state = self.pdb_parse_tree['data'][self.state]\n        res_id = (res_seq, i_code)\n        if chain_id not in a_state:\n            a_state[chain_id] = (set(), OrderedDict())\n        if res_id not in a_state[chain_id][1]:\n            a_state[chain_id][1][res_id] = (set(), OrderedDict())\n        if at_type == 'ATOM':\n            if res_name in standard_amino_acids.values():\n                poly = 'P'\n            else:\n                poly = 'N'\n        else:\n            poly = 'H'\n        a_state[chain_id][0].add((chain_id, at_type, poly))\n        a_state[chain_id][1][res_id][0].add(\n            (at_type, res_seq, res_name, i_code))\n        if at_ser not in a_state[chain_id][1][res_id][1]:\n            a_state[chain_id][1][res_id][1][at_ser] = [atom_data]\n        else:\n            a_state[chain_id][1][res_id][1][at_ser].append(atom_data)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a line of ATOM record coordinates into a tuple.", "response": "def proc_line_coordinate(self, line):\n        \"\"\"Extracts data from columns in ATOM/HETATM record.\"\"\"\n        pdb_atom_col_dict = global_settings['ampal']['pdb_atom_col_dict']\n        at_type = line[0:6].strip()  # 0\n        at_ser = int(line[6:11].strip())  # 1\n        at_name = line[12:16].strip()  # 2\n        alt_loc = line[16].strip()  # 3\n        res_name = line[17:20].strip()  # 4\n        chain_id = line[21].strip()  # 5\n        res_seq = int(line[22:26].strip())  # 6\n        i_code = line[26].strip()  # 7\n        x = float(line[30:38].strip())  # 8\n        y = float(line[38:46].strip())  # 9\n        z = float(line[46:54].strip())  # 10\n        occupancy = float(line[54:60].strip())  # 11\n        temp_factor = float(line[60:66].strip())  # 12\n        element = line[76:78].strip()  # 13\n        charge = line[78:80].strip()  # 14\n        if at_name not in pdb_atom_col_dict:\n            pdb_atom_col_dict[at_name] = line[12:16]\n            pdb_col_e = PDBColFormat(atom_name=at_name, atom_col=line[12:16])\n            ampal_data_session.add(pdb_col_e)\n            self.new_labels = True\n        return (at_type, at_ser, at_name, alt_loc, res_name, chain_id, res_seq,\n                i_code, x, y, z, occupancy, temp_factor, element, charge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_ampal(self):\n        data = self.pdb_parse_tree['data']\n        if len(data) > 1:\n            ac = AmpalContainer(id=self.id)\n            for state, chains in sorted(data.items()):\n                if chains:\n                    ac.append(self.proc_state(chains, self.id +\n                                              '_state_{}'.format(state + 1)))\n            return ac\n        elif len(data) == 1:\n            return self.proc_state(data[0], self.id)\n        else:\n            raise ValueError('Empty parse tree, check input PDB format.')", "response": "Generates an AMPAL object from the parse tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a state into an Assembly.", "response": "def proc_state(self, state_data, state_id):\n        \"\"\"Processes a state into an `Assembly`.\n\n        Parameters\n        ----------\n        state_data : dict\n            Contains information about the state, including all\n            the per line structural data.\n        state_id : str\n            ID given to `Assembly` that represents the state.\n        \"\"\"\n        assembly = Assembly(assembly_id=state_id)\n        for k, chain in sorted(state_data.items()):\n            assembly._molecules.append(self.proc_chain(chain, assembly))\n        return assembly"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a single chain into a Polymer object.", "response": "def proc_chain(self, chain_info, parent):\n        \"\"\"Converts a chain into a `Polymer` type object.\n\n        Parameters\n        ----------\n        chain_info : (set, OrderedDict)\n            Contains a set of chain labels and atom records.\n        parent : ampal.Assembly\n            `Assembly` used to assign `ampal_parent` on created\n            `Polymer`.\n\n        Raises\n        ------\n        ValueError\n            Raised if multiple or unknown atom types found\n            within the same chain.\n        AttributeError\n            Raised if unknown `Monomer` type encountered.\n        \"\"\"\n        hetatom_filters = {\n            'nc_aas': self.check_for_non_canonical\n        }\n\n        polymer = False\n        chain_labels, chain_data = chain_info\n        chain_label = list(chain_labels)[0]\n        monomer_types = {x[2] for x in chain_labels if x[2]}\n        if ('P' in monomer_types) and ('N' in monomer_types):\n            raise ValueError(\n                'Malformed PDB, multiple \"ATOM\" types in a single chain.')\n        # Changes Polymer type based on chain composition\n        if 'P' in monomer_types:\n            polymer_class = Polypeptide\n            polymer = True\n        elif 'N' in monomer_types:\n            polymer_class = Polynucleotide\n            polymer = True\n        elif 'H' in monomer_types:\n            polymer_class = LigandGroup\n        else:\n            raise AttributeError('Malformed parse tree, check inout PDB.')\n        chain = polymer_class(polymer_id=chain_label[0], ampal_parent=parent)\n        # Changes where the ligands should go based on the chain composition\n        if polymer:\n            chain.ligands = LigandGroup(\n                polymer_id=chain_label[0], ampal_parent=parent)\n            ligands = chain.ligands\n        else:\n            ligands = chain\n\n        for residue in chain_data.values():\n            res_info = list(residue[0])[0]\n            if res_info[0] == 'ATOM':\n                chain._monomers.append(self.proc_monomer(residue, chain))\n            elif res_info[0] == 'HETATM':\n                mon_cls = None\n                on_chain = False\n                for filt_func in hetatom_filters.values():\n                    filt_res = filt_func(residue)\n                    if filt_res:\n                        mon_cls, on_chain = filt_res\n                        break\n                    mon_cls = Ligand\n                if on_chain:\n                    chain._monomers.append(self.proc_monomer(\n                        residue, chain, mon_cls=mon_cls))\n                else:\n                    ligands._monomers.append(self.proc_monomer(\n                        residue, chain, mon_cls=mon_cls))\n            else:\n                raise ValueError('Malformed PDB, unknown record type for data')\n        return chain"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing a record into a Monomer.", "response": "def proc_monomer(self, monomer_info, parent, mon_cls=False):\n        \"\"\"Processes a records into a `Monomer`.\n\n        Parameters\n        ----------\n        monomer_info : (set, OrderedDict)\n            Labels and data for a monomer.\n        parent : ampal.Polymer\n            `Polymer` used to assign `ampal_parent` on created\n            `Monomer`.\n        mon_cls : `Monomer class or subclass`, optional\n            A `Monomer` class can be defined explicitly.\n        \"\"\"\n        monomer_labels, monomer_data = monomer_info\n        if len(monomer_labels) > 1:\n            raise ValueError(\n                'Malformed PDB, single monomer id with '\n                'multiple labels. {}'.format(monomer_labels))\n        else:\n            monomer_label = list(monomer_labels)[0]\n        if mon_cls:\n            monomer_class = mon_cls\n            het = True\n        elif monomer_label[0] == 'ATOM':\n            if monomer_label[2] in standard_amino_acids.values():\n                monomer_class = Residue\n            else:\n                monomer_class = Nucleotide\n            het = False\n        else:\n            raise ValueError('Unknown Monomer type.')\n        monomer = monomer_class(\n            atoms=None, mol_code=monomer_label[2], monomer_id=monomer_label[1],\n            insertion_code=monomer_label[3], is_hetero=het, ampal_parent=parent\n        )\n        monomer.states = self.gen_states(monomer_data.values(), monomer)\n        monomer._active_state = sorted(monomer.states.keys())[0]\n        return monomer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the antisense sequence of a DNA strand.", "response": "def generate_antisense_sequence(sequence):\n    \"\"\"Creates the antisense sequence of a DNA strand.\"\"\"\n    dna_antisense = {\n        'A': 'T',\n        'T': 'A',\n        'C': 'G',\n        'G': 'C'\n    }\n    antisense = [dna_antisense[x] for x in sequence[::-1]]\n    return ''.join(antisense)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_sequence(cls, sequence, phos_3_prime=False):\n        strand1 = NucleicAcidStrand(sequence, phos_3_prime=phos_3_prime)\n        duplex = cls(strand1)\n        return duplex", "response": "Creates a DNA duplex from a nucleotide sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_start_and_end(cls, start, end, sequence, phos_3_prime=False):\n        strand1 = NucleicAcidStrand.from_start_and_end(\n            start, end, sequence, phos_3_prime=phos_3_prime)\n        duplex = cls(strand1)\n        return duplex", "response": "Creates a DNA duplex from a start and end point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_complementary_strand(strand1):\n        rise_adjust = (\n            strand1.rise_per_nucleotide * strand1.axis.unit_tangent) * 2\n        strand2 = NucleicAcidStrand.from_start_and_end(\n            strand1.helix_end - rise_adjust, strand1.helix_start - rise_adjust,\n            generate_antisense_sequence(strand1.base_sequence),\n            phos_3_prime=strand1.phos_3_prime)\n        ad_ang = dihedral(strand1[0][\"C1'\"]._vector, strand1.axis.start,\n                          strand2.axis.start + rise_adjust,\n                          strand2[-1][\"C1'\"]._vector)\n        strand2.rotate(\n            225.0 + ad_ang, strand2.axis.unit_tangent,\n            point=strand2.helix_start)  # 225 is the base adjust\n        return strand2", "response": "Takes a SingleStrandHelix and creates the antisense strand."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef total_accessibility(in_rsa, path=True):\n    if path:\n        with open(in_rsa, 'r') as inf:\n            rsa = inf.read()\n    else:\n        rsa = in_rsa[:]\n    all_atoms, side_chains, main_chain, non_polar, polar = [\n        float(x) for x in rsa.splitlines()[-1].split()[1:]]\n    return all_atoms, side_chains, main_chain, non_polar, polar", "response": "Parses the total surface accessibility data from the naccess rsa file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_residue_accessibility(in_rsa, path=True, get_total=False):\n\n    if path:\n        with open(in_rsa, 'r') as inf:\n            rsa = inf.read()\n    else:\n        rsa = in_rsa[:]\n\n    residue_list = [x for x in rsa.splitlines()]\n    rel_solv_acc_all_atoms = [\n        float(x[22:28])\n        for x in residue_list\n        if x[0:3] == \"RES\" or x[0:3] == \"HEM\"]\n\n    if get_total:\n        (all_atoms, side_chains, main_chain,\n         non_polar, polar) = total_accessibility(\n            rsa, path=False)\n        return rel_solv_acc_all_atoms, all_atoms\n\n    else:\n        return rel_solv_acc_all_atoms, None", "response": "Parses the NACCESS rsa file and returns the solvent accessibility of each residue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_aa_code(aa_letter):\n    aa_code = None\n    if aa_letter != 'X':\n        for key, val in standard_amino_acids.items():\n            if key == aa_letter:\n                aa_code = val\n    return aa_code", "response": "Get three - letter amino acid code if possible. If not return None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget one - letter version of aa_code if possible. If not return X.", "response": "def get_aa_letter(aa_code):\n    \"\"\" Get one-letter version of aa_code if possible. If not, return 'X'.\n\n    Parameters\n    ----------\n    aa_code : str\n        Three-letter amino acid code.\n\n    Returns\n    -------\n    aa_letter : str\n        One-letter aa code.\n        Default value is 'X'.\n    \"\"\"\n    aa_letter = 'X'\n    for key, val in standard_amino_acids.items():\n        if val == aa_code:\n            aa_letter = key\n\n    return aa_letter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting dictionary of information relating to a new amino acid code.", "response": "def get_aa_info(code):\n    \"\"\"Get dictionary of information relating to a new amino acid code not currently in the database.\n\n    Notes\n    -----\n    Use this function to get a dictionary that is then to be sent to the function add_amino_acid_to_json().\n    use to fill in rows of amino_acid table for new amino acid code.\n\n    Parameters\n    ----------\n    code : str\n        Three-letter amino acid code.\n\n    Raises\n    ------\n    IOError\n        If unable to locate the page associated with the amino acid name on the PDBE site.\n\n    Returns\n    -------\n    aa_dict : dict\n        Keys are AminoAcidDB field names.\n        Values are the str values for the new amino acid, scraped from the PDBE if possible. None if not found.\n    \"\"\"\n    letter = 'X'\n    # Try to get content from PDBE.\n    url_string = 'http://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/{0}'.format(code)\n    r = requests.get(url_string)\n    # Raise error if content not obtained.\n    if not r.ok:\n        raise IOError(\"Could not get to url {0}\".format(url_string))\n\n    # Parse r.text in an ugly way to get the required information.\n    description = r.text.split('<h3>Molecule name')[1].split('</tr>')[0]\n    description = description.strip().split('\\n')[3].strip()[:255]\n    modified = r.text.split(\"<h3>Standard parent \")[1].split('</tr>')[0]\n    modified = modified.replace(\" \", \"\").replace('\\n', '').split('<')[-3].split('>')[-1]\n    if modified == \"NotAssigned\":\n        modified = None\n    # Add the required information to a dictionary which can then be passed to add_amino_acid_to_json.\n    aa_dict = {'code': code, 'description': description, 'modified': modified, 'letter': letter}\n    return aa_dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_amino_acid_to_json(code, description, letter='X', modified=None, force_add=False):\n    # If code is already in the dictionary, raise an error\n    if (not force_add) and code in amino_acids_dict.keys():\n        raise IOError(\"{0} is already in the amino_acids dictionary, with values: {1}\".format(\n            code, amino_acids_dict[code]))\n\n    # Prepare data to be added.\n    add_code = code\n    add_code_dict = {'description': description, 'letter': letter, 'modified': modified}\n\n    # Check that data does not already exist, and if not, add it to the dictionary.\n    amino_acids_dict[add_code] = add_code_dict\n\n    # Write over json file with updated dictionary.\n    with open(_amino_acids_json_path, 'w') as foo:\n        foo.write(json.dumps(amino_acids_dict))\n\n    return", "response": "Adds an amino acid to the amino acid table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_polymers(cls, polymers):\n        n = len(polymers)\n        instance = cls(n=n, auto_build=False)\n        instance.major_radii = [x.major_radius for x in polymers]\n        instance.major_pitches = [x.major_pitch for x in polymers]\n        instance.major_handedness = [x.major_handedness for x in polymers]\n        instance.aas = [x.num_monomers for x in polymers]\n        instance.minor_helix_types = [x.minor_helix_type for x in polymers]\n        instance.orientations = [x.orientation for x in polymers]\n        instance.phi_c_alphas = [x.phi_c_alpha for x in polymers]\n        instance.minor_repeats = [x.minor_repeat for x in polymers]\n        instance.build()\n        return instance", "response": "Creates a CoiledCoil instance from a list of helical helices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_parameters(cls, n, aa=28, major_radius=None, major_pitch=None,\n                        phi_c_alpha=26.42, minor_helix_type='alpha',\n                        auto_build=True):\n        \"\"\"Creates a `CoiledCoil` from defined super-helical parameters.\n\n        Parameters\n        ----------\n        n : int\n            Oligomeric state\n        aa : int, optional\n            Number of amino acids per minor helix.\n        major_radius : float, optional\n            Radius of super helix.\n        major_pitch : float, optional\n            Pitch of super helix.\n        phi_c_alpha : float, optional\n            Rotation of minor helices relative to the super-helical\n            axis.\n        minor_helix_type : float, optional\n            Helix type of minor helices. Can be: 'alpha', 'pi', '3-10',\n            'PPI', 'PP2', 'collagen'.\n        auto_build : bool, optional\n            If `True`, the model will be built as part of instantiation.\n        \"\"\"\n        instance = cls(n=n, auto_build=False)\n        instance.aas = [aa] * n\n        instance.phi_c_alphas = [phi_c_alpha] * n\n        instance.minor_helix_types = [minor_helix_type] * n\n        if major_pitch is not None:\n            instance.major_pitches = [major_pitch] * n\n        if major_radius is not None:\n            instance.major_radii = [major_radius] * n\n        if auto_build:\n            instance.build()\n        return instance", "response": "Creates a CoiledCoil instance from the specified super - helical parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tropocollagen(\n            cls, aa=28, major_radius=5.0, major_pitch=85.0, auto_build=True):\n        \"\"\"Creates a model of a collagen triple helix.\n\n        Parameters\n        ----------\n        aa : int, optional\n            Number of amino acids per minor helix.\n        major_radius : float, optional\n            Radius of super helix.\n        major_pitch : float, optional\n            Pitch of super helix.\n        auto_build : bool, optional\n            If `True`, the model will be built as part of instantiation.\n        \"\"\"\n        instance = cls.from_parameters(\n            n=3, aa=aa, major_radius=major_radius, major_pitch=major_pitch,\n            phi_c_alpha=0.0, minor_helix_type='collagen', auto_build=False)\n        instance.major_handedness = ['r'] * 3\n        # default z-shifts taken from rise_per_residue of collagen helix\n        rpr_collagen = _helix_parameters['collagen'][1]\n        instance.z_shifts = [-rpr_collagen * 2, -rpr_collagen, 0.0]\n        instance.minor_repeats = [None] * 3\n        if auto_build:\n            instance.build()\n        return instance", "response": "Creates a model of a collagen triple helix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(self):\n        monomers = [HelicalHelix(major_pitch=self.major_pitches[i],\n                                 major_radius=self.major_radii[i],\n                                 major_handedness=self.major_handedness[i],\n                                 aa=self.aas[i],\n                                 minor_helix_type=self.minor_helix_types[i],\n                                 orientation=self.orientations[i],\n                                 phi_c_alpha=self.phi_c_alphas[i],\n                                 minor_repeat=self.minor_repeats[i],\n                                 )\n                    for i in range(self.oligomeric_state)]\n        axis_unit_vector = numpy.array([0, 0, 1])\n        for i, m in enumerate(monomers):\n            m.rotate(angle=self.rotational_offsets[i], axis=axis_unit_vector)\n            m.translate(axis_unit_vector * self.z_shifts[i])\n        self._molecules = monomers[:]\n        self.relabel_all()\n        for m in self._molecules:\n            m.ampal_parent = self\n        return", "response": "Builds a model of a coiled coil."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the maximum radius and npnp in the loaded force field.", "response": "def find_max_rad_npnp(self):\n        \"\"\"Finds the maximum radius and npnp in the force field.\n\n        Returns\n        -------\n        (max_rad, max_npnp): (float, float)\n            Maximum radius and npnp distance in the loaded force field.\n        \"\"\"\n        max_rad = 0\n        max_npnp = 0\n        for res, atoms in self.items():\n            if res != 'KEY':\n                for atom, ff_params in self[res].items():\n                    if max_rad < ff_params[1]:\n                        max_rad = ff_params[1]\n                    if max_npnp < ff_params[4]:\n                        max_npnp = ff_params[4]\n        return max_rad, max_npnp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parameter_struct_dict(self):\n        if self._parameter_struct_dict is None:\n            self._parameter_struct_dict = self._make_ff_params_dict()\n        elif self.auto_update_f_params:\n            new_hash = hash(\n                tuple([tuple(item)\n                       for sublist in self.values()\n                       for item in sublist.values()]))\n            if self._old_hash != new_hash:\n                self._parameter_struct_dict = self._make_ff_params_dict()\n                self._old_hash = new_hash\n        return self._parameter_struct_dict", "response": "Dictionary containing PyAtomData structs for the force field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun Reduce on a file.", "response": "def run_reduce(input_file, path=True):\n    \"\"\" Runs reduce on a pdb or mmol file at the specified path.\n\n    Notes\n    -----\n    Runs Reduce programme to add missing protons to a PDB file.\n\n    Parameters\n    ----------\n    input_file : str\n        Path to file to add protons to or structure in mmol/pdb format.\n    path : bool, optional\n        True if input_file is a path.\n\n    Returns\n    -------\n    reduce_mmol : str\n        Structure file with protons added.\n    reduce_message : str\n        Messages generated while running Reduce.\n\n    Raises\n    ------\n    FileNotFoundError\n        Raised if the executable cannot be found.\n    \"\"\"\n    if path:\n        input_path = Path(input_file)\n        if not input_path.exists():\n            print('No file found at', path)\n            return None, None\n    else:\n        pathf = tempfile.NamedTemporaryFile()\n        encoded_input = input_file.encode()\n        pathf.write(encoded_input)\n        pathf.seek(0)\n        file_path = pathf.name\n        input_path = Path(file_path)\n    reduce_folder = Path(global_settings['reduce']['folder'])\n    reduce_exe = reduce_folder / global_settings['reduce']['path']\n    reduce_dict = reduce_folder / 'reduce_wwPDB_het_dict.txt'\n    try:\n        reduce_output = subprocess.run(\n            [str(reduce_exe), '-build', '-DB',\n             str(reduce_dict), str(input_path)],\n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    except FileNotFoundError as e:\n        raise FileNotFoundError(\n            'The Reduce executable cannot be found. Ensure the '\n            'location and filename are specified in settings.')\n    try:\n        reduced_mmol = reduce_output.stdout.decode()\n    except UnicodeDecodeError:\n        print(\"Reduce could not detect any missing protons in the protein. \"\n              \"Using the original structure.\")\n        if path:\n            reduced_mmol = input_path.read_text()\n        else:\n            reduced_mmol = input_file\n    reduce_message = reduce_output.stderr.decode()\n    if 'could not open' in reduce_message:\n        print('Caution: the Reduce connectivity dictionary could not be '\n              'found. Some protons may be missing. See notes.')\n    return reduced_mmol, reduce_message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reduce_output_path(path=None, pdb_name=None):\n    if not path:\n        if not pdb_name:\n            raise NameError(\n                \"Cannot save an output for a temporary file without a PDB\"\n                \"code specified\")\n        pdb_name = pdb_name.lower()\n        output_path = Path(global_settings['structural_database']['path'],\n                           pdb_name[1:3].lower(), pdb_name[:4].lower(),\n                           'reduce', pdb_name + '_reduced.mmol')\n    else:\n        input_path = Path(path)\n        if len(input_path.parents) > 1:\n            output_path = input_path.parents[1] / 'reduce' / \\\n                (input_path.stem + '_reduced' + input_path.suffix)\n        else:\n            output_path = input_path.parent / \\\n                (input_path.stem + '_reduced' + input_path.suffix)\n    return output_path", "response": "Defines location of Reduce output files relative to input files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_reduce(input_file, path=True, pdb_name=None, force=False):\n    if path:\n        output_path = reduce_output_path(path=input_file)\n    else:\n        output_path = reduce_output_path(pdb_name=pdb_name)\n    if output_path.exists() and not force:\n        return output_path\n    reduce_mmol, reduce_message = run_reduce(input_file, path=path)\n    if not reduce_mmol:\n        return None\n    output_path.parent.mkdir(exist_ok=True)\n    output_path.write_text(reduce_mmol)\n    return output_path", "response": "Runs Reduce on a file and creates a new file with the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_reduce_list(path_list, force=False):\n    output_paths = []\n    for path in path_list:\n        output_path = output_reduce(path, force=force)\n        if output_path:\n            output_paths.append(output_path)\n    return output_paths", "response": "Generates structure file with protons from a list of structure files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assembly_plus_protons(input_file, path=True, pdb_name=None,\n                          save_output=False, force_save=False):\n    \"\"\"Returns an Assembly with protons added by Reduce.\n\n    Notes\n    -----\n    Looks for a pre-existing Reduce output in the standard location before\n    running Reduce. If the protein contains oligosaccharides or glycans,\n    use reduce_correct_carbohydrates.\n\n    Parameters\n    ----------\n    input_file : str or pathlib.Path\n        Location of file to be converted to Assembly or PDB file as string.\n    path : bool\n        Whether we are looking at a file or a pdb string. Defaults to file.\n    pdb_name : str\n        PDB ID of protein. Required if providing string not path.\n    save_output : bool\n        If True will save the generated assembly.\n    force_save : bool\n        If True will overwrite existing reduced assembly.\n\n    Returns\n    -------\n    reduced_assembly : AMPAL Assembly\n        Assembly of protein with protons added by Reduce.\n    \"\"\"\n    from ampal.pdb_parser import convert_pdb_to_ampal\n\n    if path:\n        input_path = Path(input_file)\n        if not pdb_name:\n            pdb_name = input_path.stem[:4]\n        reduced_path = reduce_output_path(path=input_path)\n        if reduced_path.exists() and not save_output and not force_save:\n            reduced_assembly = convert_pdb_to_ampal(\n                str(reduced_path), pdb_id=pdb_name)\n            return reduced_assembly\n    if save_output:\n        reduced_path = output_reduce(\n            input_file, path=path, pdb_name=pdb_name, force=force_save)\n        reduced_assembly = convert_pdb_to_ampal(str(reduced_path), path=True)\n    else:\n        reduce_mmol, reduce_message = run_reduce(input_file, path=path)\n        if not reduce_mmol:\n            return None\n        reduced_assembly = convert_pdb_to_ampal(\n            reduce_mmol, path=False, pdb_id=pdb_name)\n    return reduced_assembly", "response": "Returns an Assembly with protons added by Reduce."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Helix object from start and end coordinates.", "response": "def from_start_and_end(cls, start, end, aa=None, helix_type='alpha'):\n        \"\"\"Creates a `Helix` between `start` and `end`.\n\n        Parameters\n        ----------\n        start : 3D Vector (tuple or list or numpy.array)\n            The coordinate of the start of the helix primitive.\n        end : 3D Vector (tuple or list or numpy.array)\n            The coordinate of the end of the helix primitive.\n        aa : int, optional\n            Number of amino acids in the `Helix`. If `None, an\n            appropriate number of residues are added.\n        helix_type : str, optional\n            Type of helix, can be: 'alpha', 'pi', '3-10',\n            'PPI', 'PPII', 'collagen'.\n        \"\"\"\n        start = numpy.array(start)\n        end = numpy.array(end)\n        if aa is None:\n            rise_per_residue = _helix_parameters[helix_type][1]\n            aa = int((numpy.linalg.norm(end - start) / rise_per_residue) + 1)\n        instance = cls(aa=aa, helix_type=helix_type)\n        instance.move_to(start=start, end=end)\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build(self):\n        ang_per_res = (2 * numpy.pi) / self.residues_per_turn\n        atom_offsets = _atom_offsets[self.helix_type]\n        if self.handedness == 'l':\n            handedness = -1\n        else:\n            handedness = 1\n\n        atom_labels = ['N', 'CA', 'C', 'O']\n        if all([x in atom_offsets.keys() for x in atom_labels]):\n            res_label = 'GLY'\n        else:\n            res_label = 'UNK'\n\n        monomers = []\n        for i in range(self.num_monomers):\n            residue = Residue(mol_code=res_label, ampal_parent=self)\n            atoms_dict = OrderedDict()\n            for atom_label in atom_labels:\n                r, zeta, z_shift = atom_offsets[atom_label]\n                rot_ang = ((i * ang_per_res) + zeta) * handedness\n                z = (self.rise_per_residue * i) + z_shift\n                coords = cylindrical_to_cartesian(\n                    radius=r, azimuth=rot_ang, z=z, radians=True)\n                atom = Atom(\n                    coordinates=coords, element=atom_label[0],\n                    ampal_parent=residue, res_label=atom_label)\n                atoms_dict[atom_label] = atom\n            residue.atoms = atoms_dict\n            monomers.append(residue)\n        self._monomers = monomers\n        self.relabel_monomers()\n        self.relabel_atoms()\n        return", "response": "Build a straight helix along z - axis starting with CA1 on x - axis"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a helical hierarchy from a start and end point.", "response": "def from_start_and_end(cls, start, end, aa=None, major_pitch=225.8,\n                           major_radius=5.07, major_handedness='l',\n                           minor_helix_type='alpha', orientation=1,\n                           phi_c_alpha=0.0, minor_repeat=None):\n        \"\"\"Creates a `HelicalHelix` between a `start` and `end` point.\"\"\"\n        start = numpy.array(start)\n        end = numpy.array(end)\n        if aa is None:\n            minor_rise_per_residue = _helix_parameters[minor_helix_type][1]\n            aa = int((numpy.linalg.norm(end - start) /\n                      minor_rise_per_residue) + 1)\n        instance = cls(\n            aa=aa, major_pitch=major_pitch, major_radius=major_radius,\n            major_handedness=major_handedness,\n            minor_helix_type=minor_helix_type, orientation=orientation,\n            phi_c_alpha=phi_c_alpha, minor_repeat=minor_repeat)\n        instance.move_to(start=start, end=end)\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncurve of the super helix.", "response": "def curve(self):\n        \"\"\"Curve of the super helix.\"\"\"\n        return HelicalCurve.pitch_and_radius(\n            self.major_pitch, self.major_radius,\n            handedness=self.major_handedness)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrising along super - helical axis per monomer.", "response": "def major_rise_per_monomer(self):\n        \"\"\"Rise along super-helical axis per monomer.\"\"\"\n        return numpy.cos(numpy.deg2rad(self.curve.alpha)) * self.minor_rise_per_residue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the number of residues per turn of the minor helix.", "response": "def minor_residues_per_turn(self, minor_repeat=None):\n        \"\"\"Calculates the number of residues per turn of the minor helix.\n\n        Parameters\n        ----------\n        minor_repeat : float, optional\n            Hydrophobic repeat of the minor helix.\n\n        Returns\n        -------\n        minor_rpt : float\n            Residues per turn of the minor helix.\n        \"\"\"\n        if minor_repeat is None:\n            minor_rpt = _helix_parameters[self.minor_helix_type][0]\n        else:\n            # precession angle in radians\n            precession = self.curve.t_from_arc_length(\n                minor_repeat * self.minor_rise_per_residue)\n            if self.orientation == -1:\n                precession = -precession\n            if self.major_handedness != self.minor_handedness:\n                precession = -precession\n            minor_rpt = ((minor_repeat * numpy.pi * 2) /\n                         ((2 * numpy.pi) + precession))\n        return minor_rpt"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the helical class.", "response": "def build(self):\n        \"\"\"Builds the `HelicalHelix`.\"\"\"\n        helical_helix = Polypeptide()\n        primitive_coords = self.curve_primitive.coordinates\n        helices = [Helix.from_start_and_end(start=primitive_coords[i],\n                                            end=primitive_coords[i + 1],\n                                            helix_type=self.minor_helix_type,\n                                            aa=1)\n                   for i in range(len(primitive_coords) - 1)]\n        residues_per_turn = self.minor_residues_per_turn(\n            minor_repeat=self.minor_repeat)\n        if residues_per_turn == 0:\n            residues_per_turn = _helix_parameters[self.minor_helix_type][0]\n        if self.minor_handedness == 'l':\n            residues_per_turn *= -1\n        # initial phi_c_alpha value calculated using the first Helix in helices.\n        if self.orientation != -1:\n            initial_angle = dihedral(numpy.array([0, 0, 0]),\n                                     primitive_coords[0],\n                                     primitive_coords[1],\n                                     helices[0][0]['CA'])\n        else:\n            initial_angle = dihedral(\n                numpy.array([0, 0, primitive_coords[0][2]]),\n                primitive_coords[0],\n                numpy.array([primitive_coords[0][0],\n                             primitive_coords[0][1], primitive_coords[1][2]]),\n                helices[0][0]['CA'])\n        # angle required to achieve desired phi_c_alpha value of self.phi_c_alpha.\n        addition_angle = self.phi_c_alpha - initial_angle\n        for i, h in enumerate(helices):\n            angle = (i * (360.0 / residues_per_turn)) + addition_angle\n            h.rotate(angle=angle, axis=h.axis.unit_tangent,\n                     point=h.helix_start)\n            helical_helix.extend(h)\n        helical_helix.relabel_all()\n        self._monomers = helical_helix._monomers[:]\n        for monomer in self._monomers:\n            monomer.ampal_parent = self\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_orient_angle(self, reference_point=numpy.array([0, 0, 0]),\n                         monomer_index=0, res_label='CA', radians=False):\n        \"\"\" Angle between reference_point and self[monomer_index][res_label].\n\n        Notes\n        -----\n        Angle is calculated using the dihedral angle, with the \n        second and third points coming from the curve_primitive.\n\n        Parameters\n        ----------\n        reference_point : list, tuple or numpy.array of length 3.\n        monomer_index : int\n            Index of the Residue to centre.\n        res_label : str\n            Atom name for centred atom, e.g. \"CA\" or \"OE1\".\n        radians : bool\n            If True, then desired_angle is in radians instead of degrees.\n        \"\"\"\n        if (monomer_index < len(self)) and monomer_index != -1:\n            adjacent_index = monomer_index + 1\n        elif (monomer_index == len(self)) or monomer_index == -1:\n            adjacent_index = monomer_index - 1\n        else:\n            raise ValueError(\n                \"centred_index ({0}) cannot be greater than the \"\n                \"length of the polymer ({1})\".format(\n                    monomer_index, len(self)))\n        angle = dihedral(reference_point,\n                         self.curve_primitive[monomer_index]['CA'],\n                         self.curve_primitive[adjacent_index]['CA'],\n                         self[monomer_index][res_label])\n        if radians:\n            angle = numpy.deg2rad(angle)\n        return angle", "response": "Calculates the angle between the dihedral angle and the specified reference point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrotating each Monomer in the Polypeptide.", "response": "def rotate_monomers(self, angle, radians=False):\n        \"\"\" Rotates each Residue in the Polypeptide.\n\n        Notes\n        -----\n        Each monomer is rotated about the axis formed between its\n        corresponding primitive `PseudoAtom` and that of the \n        subsequent `Monomer`.\n\n        Parameters\n        ----------\n        angle : float\n            Angle by which to rotate each monomer.\n        radians : bool\n            Indicates whether angle is in radians or degrees.\n        \"\"\"\n        if radians:\n            angle = numpy.rad2deg(angle)\n        for i in range(len(self.primitive) - 1):\n            axis = self.primitive[i + 1]['CA'] - self.primitive[i]['CA']\n            point = self.primitive[i]['CA']._vector\n            self[i].rotate(angle=angle, axis=axis, point=point)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a PseudoGroup containing all side - chain centres of each Polypeptide in each Assembly.", "response": "def side_chain_centres(assembly, masses=False):\n    \"\"\" PseudoGroup containing side_chain centres of each Residue in each Polypeptide in Assembly.\n\n    Notes\n    -----\n    Each PseudoAtom is a side-chain centre.\n    There is one PseudoMonomer per chain in ampal (each containing len(chain) PseudoAtoms).\n    The PseudoGroup has len(ampal) PseudoMonomers.\n\n    Parameters\n    ----------\n    assembly : Assembly\n    masses : bool\n        If True, side-chain centres are centres of mass.\n        If False, side-chain centres are centres of coordinates.\n\n    Returns\n    -------\n    PseudoGroup\n        containing all side_chain centres, and with ampal_parent=assembly.\n    \"\"\"\n    if masses:\n        elts = set([x.element for x in assembly.get_atoms()])\n        masses_dict = {e: element_data[e]['atomic mass'] for e in elts}\n    pseudo_monomers = []\n    for chain in assembly:\n        if isinstance(chain, Polypeptide):\n            centres = OrderedDict()\n            for r in chain.get_monomers(ligands=False):\n                side_chain = r.side_chain\n                if masses:\n                    masses_list = [masses_dict[x.element] for x in side_chain]\n                else:\n                    masses_list = None\n                if side_chain:\n                    centre = centre_of_mass(points=[x._vector for x in side_chain], masses=masses_list)\n                # for Glycine residues.\n                else:\n                    centre = r['CA']._vector\n                centres[r.unique_id] = PseudoAtom(coordinates=centre, name=r.unique_id, ampal_parent=r)\n            pseudo_monomers.append(PseudoMonomer(pseudo_atoms=centres, monomer_id=' ', ampal_parent=chain))\n    return PseudoGroup(monomers=pseudo_monomers, ampal_parent=assembly)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclusters helices into a single - cluster dictionary.", "response": "def cluster_helices(helices, cluster_distance=12.0):\n    \"\"\" Clusters helices according to the minimum distance between the line segments representing their backbone.\n\n    Notes\n    -----\n    Each helix is represented as a line segement joining the CA of its first Residue to the CA if its final Residue.\n    The minimal distance between pairwise line segments is calculated and stored in a condensed_distance_matrix.\n    This is clustered using the 'single' linkage metric\n     (all members of cluster i are at < cluster_distance away from at least one other member of cluster i).\n    Helices belonging to the same cluster are grouped together as values of the returned cluster_dict.\n\n    Parameters\n    ----------\n    helices: Assembly\n    cluster_distance: float\n\n    Returns\n    -------\n    cluster_dict: dict\n        Keys: int\n            cluster number\n        Values: [Polymer]\n\n    \"\"\"\n    condensed_distance_matrix = []\n    for h1, h2 in itertools.combinations(helices, 2):\n        md = minimal_distance_between_lines(h1[0]['CA']._vector, h1[-1]['CA']._vector,\n                                            h2[0]['CA']._vector, h2[-1]['CA']._vector, segments=True)\n        condensed_distance_matrix.append(md)\n    z = linkage(condensed_distance_matrix, method='single')\n    clusters = fcluster(z, t=cluster_distance, criterion='distance')\n    cluster_dict = {}\n    for h, k in zip(helices, clusters):\n        if k not in cluster_dict:\n            cluster_dict[k] = [h]\n        else:\n            cluster_dict[k].append(h)\n    return cluster_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_kihs(assembly, hole_size=4, cutoff=7.0):\n    pseudo_group = side_chain_centres(assembly=assembly, masses=False)\n    pairs = itertools.permutations(pseudo_group, 2)\n    kihs = []\n    for pp_1, pp_2 in pairs:\n        for r in pp_1:\n            close_atoms = pp_2.is_within(cutoff, r)\n            # kihs occur between residue and (hole_size) closest side-chains on adjacent polypeptide.\n            if len(close_atoms) < hole_size:\n                continue\n            elif len(close_atoms) > hole_size:\n                close_atoms = sorted(close_atoms, key=lambda x: distance(x, r))[:hole_size]\n            kih = OrderedDict()\n            kih['k'] = r\n            for i, hole_atom in enumerate(close_atoms):\n                kih['h{0}'.format(i)] = hole_atom\n            knob_into_hole = KnobIntoHole(pseudo_atoms=kih)\n            kihs.append(knob_into_hole)\n    return kihs", "response": "Find KnobIntoHoles between residues of different chains in an assembly."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an Assembly containing segments of a given Polypeptide divided according to separation of contiguous residues.", "response": "def find_contiguous_packing_segments(polypeptide, residues, max_dist=10.0):\n    \"\"\" Assembly containing segments of polypeptide, divided according to separation of contiguous residues.\n\n    Parameters\n    ----------\n    polypeptide : Polypeptide\n    residues : iterable containing Residues\n    max_dist : float\n        Separation beyond which splitting of Polymer occurs.\n\n    Returns\n    -------\n    segments : Assembly\n        Each segment contains a subset of residues, each not separated by more than max_dist from the previous Residue.\n    \"\"\"\n    segments = Assembly(assembly_id=polypeptide.ampal_parent.id)\n    residues_in_polypeptide = list(sorted(residues.intersection(set(polypeptide.get_monomers())),\n                                          key=lambda x: int(x.id)))\n    if not residues_in_polypeptide:\n        return segments\n    # residue_pots contains separate pots of residues divided according to their separation distance.\n    residue_pots = []\n    pot = [residues_in_polypeptide[0]]\n    for r1, r2 in zip(residues_in_polypeptide, residues_in_polypeptide[1:]):\n        d = distance(r1['CA'], r2['CA'])\n        if d <= max_dist:\n            pot.append(r2)\n            if sum([len(x) for x in residue_pots] + [len(pot)]) == len(residues_in_polypeptide):\n                residue_pots.append(pot)\n        else:\n            residue_pots.append(pot)\n            pot = [r2]\n    for pot in residue_pots:\n        segment = polypeptide.get_slice_from_res_id(pot[0].id, pot[-1].id)\n        segment.ampal_parent = polypeptide.ampal_parent\n        segments.append(segment)\n    return segments"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Pymol script for viewing classic coiled - coil.", "response": "def make_pymol(pdb_file, cutoff=7.0, min_kihs=2, outfile=None):\n    \"\"\" Pymol script for viewing classic coiled-coil Socket output.\n\n    Notes\n    -----\n    For examples of these views, browse the CC+ database here: http://coiledcoils.chm.bris.ac.uk/ccplus/search/.\n\n    Parameters\n    ----------\n    pdb_file: str\n        Path to a pdb_file.\n    cutoff: float\n        Socket cutoff in Angstroms.\n    min_kihs: int\n        Mininmum number of KnobIntoHole interactions between pairs of helices needed to define a coiled coil.\n    outfile: None or str\n        Path to a output file to save the pml script.\n\n    Returns\n    -------\n    script_string: str\n        Pymol commands for classic coiled-coil view.\n\n    \"\"\"\n    a = convert_pdb_to_ampal(pdb=pdb_file, path=True)\n    kg = KnobGroup.from_helices(a, cutoff=cutoff)\n    g = kg.filter_graph(kg.graph, cutoff=cutoff, min_kihs=min_kihs)\n    ccs = sorted_connected_components(g)\n    # Opens pymol script, initial set up of screen\n    script_lines = ['load {0}'.format(pdb_file)]\n    script_lines.append(\"hide all\")\n    script_lines.append(\"bg_color white\")\n    script_lines.append(\"set antialias, 1\")\n    script_lines.append(\"set cartoon_dumbbell_length, 0.35\")\n    script_lines.append(\"set_color lightgrey, [240,240,240]\")\n    script_lines.append(\"set depth_cue, 0\")\n    script_lines.append(\"color lightgrey, all\")\n    script_lines.append(\"cartoon dumbbell\")\n    script_lines.append(\"show cartoon\")\n    for cc_number, cc in enumerate(ccs):\n        helices = [x for x in g.nodes() if x.number in cc.nodes()]\n        #helices = cc.nodes()\n        cc_region = kg.get_coiledcoil_region(cc_number=cc_number, cutoff=cutoff, min_kihs=min_kihs)\n        tag_residues_with_heptad_register(cc_region)\n        assigned_regions = kg.get_assigned_regions(include_alt_states=False, complementary_only=False, helices=helices)\n        helix_starts = [int(h[0].id) for h in helices]\n        helix_ends = [int(h[-1].id) for h in helices]\n        chains = [h.ampal_parent.id for h in helices]\n        assigned_starts = [assigned_regions[h.number][0] for h in helices]\n        assigned_ends = [assigned_regions[h.number][1] for h in helices]\n        assigned_selections = ['{0}/{1}-{2}/'.format(chain, assigned_start, assigned_end)\n                               for chain, assigned_start, assigned_end in zip(chains, assigned_starts, assigned_ends)]\n        script_lines.append(\"select cc{0}, {1}\".format(cc_number, ' '.join(assigned_selections)))\n        script_lines.append(\"cartoon automatic, cc{0}\".format(cc_number))\n        for h_number, h in enumerate(helices):\n            chain = chains[h_number]\n            helix_start = helix_starts[h_number]\n            helix_end = helix_ends[h_number]\n            assigned_start = assigned_starts[h_number]\n            assigned_end = assigned_ends[h_number]\n            selection = '{0}/{1}-{2}/'.format(chain, helix_start, helix_end)\n            script_lines.append(\"select cc{0}eh{1}, {2}\".format(cc_number, h_number, selection))\n            selection = '{0}/{1}-{2}/'.format(chain, assigned_start, assigned_end)\n            script_lines.append(\"select cc{0}ah{1}, {2}\".format(cc_number, h_number, selection))\n            kihs = [x for x in kg if x.knob_helix == h]\n            for x in kihs:\n                knob_selection_name = 'cc{0}ah{1}k{2}'.format(cc_number, h_number, x.knob_residue.id)\n                hole_selection_name = knob_selection_name + 'hole'\n                knob_selection = '{0}/{1}/'.format(chain, x.knob_residue.id)\n                script_lines.append('select {0}, {1}'.format(knob_selection_name, knob_selection))\n                hole_selection = ' '.join(['{0}/{1}/'.format(x.hole_chain, y.id) for y in x.hole_residues])\n                script_lines.append('select {0}, {1}'.format(hole_selection_name, hole_selection))\n                script_lines.append('show sticks, {0}'.format(knob_selection_name))\n                script_lines.append('show sticks, {0}'.format(hole_selection_name))\n            for r in h.get_monomers():\n                if 'register' in r.tags:\n                    color = _heptad_colours[r.tags['register']]\n                    script_lines.append('color {0}, {1}/{2}/'.format(color, chain, r.id))\n    script_lines.append('deselect')\n    script_lines.append('orient')\n    script_lines.append('rotate z, 90')\n    script_lines.append('zoom complete=1')\n    script_string = '\\n'.join(script_lines)\n    if outfile is not None:\n        if isinstance(outfile, str) and outfile[-3:] == 'pml':\n            with open(outfile, 'w') as foo:\n                foo.write(script_string)\n    return script_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns start and end coordinates for a collection of chains that approximate the reference axis.", "response": "def start_and_end_of_reference_axis(chains):\n    \"\"\" Get start and end coordinates that approximate the reference axis for a collection of chains\n     (not necessarily all the same length).\n\n    Parameters\n    ----------\n    chains : [Polypeptide]\n\n    Returns\n    -------\n    start, end : numpy.array\n        3D start and end coordinates for defining the reference axis.\n    \"\"\"\n    coords = [numpy.array(chains[0].primitive.coordinates)]\n    orient_vector = polypeptide_vector(chains[0])\n    # Append the coordinates for the remaining chains, reversing the direction in antiparallel arrangements.\n    for i, c in enumerate(chains[1:]):\n        if is_acute(polypeptide_vector(c), orient_vector):\n            coords.append(numpy.array(c.primitive.coordinates))\n        else:\n            coords.append(numpy.flipud(numpy.array(c.primitive.coordinates)))\n    start = numpy.mean([x[0] for x in coords], axis=0)\n    end = numpy.mean([x[-1] for x in coords], axis=0)\n    return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_reference_primitive(polypeptide, start, end):\n    prim = polypeptide.primitive\n    q = find_foot(a=start, b=end, p=prim.coordinates[0])\n    ax = Axis(start=q, end=end)\n    # flip axis if antiparallel to polypeptide_vector\n    if not is_acute(polypeptide_vector(polypeptide), ax.unit_tangent):\n        ax = Axis(start=end, end=q)\n    arc_length = 0\n    points = [ax.start]\n    for rise in prim.rise_per_residue()[:-1]:\n        arc_length += rise\n        t = ax.t_from_arc_length(arc_length=arc_length)\n        point = ax.point(t)\n        points.append(point)\n    reference_primitive = Primitive.from_coordinates(points)\n    return reference_primitive", "response": "Generates a reference Primitive for a Polypeptide given start and end coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntags Residues in input helices with heptad register.", "response": "def tag_residues_with_heptad_register(helices):\n    \"\"\" tags Residues in input helices with heptad register. (Helices not required to be the same length).\n\n    Parameters\n    ----------\n    helices : [Polypeptide]\n\n    Returns\n    -------\n    None\n    \"\"\"\n    base_reg = 'abcdefg'\n    start, end = start_and_end_of_reference_axis(helices)\n    for h in helices:\n        ref_axis = gen_reference_primitive(h, start=start, end=end)\n        crangles = crick_angles(h, reference_axis=ref_axis, tag=False)[:-1]\n        reg_fit = fit_heptad_register(crangles)\n        exp_base = base_reg * (len(h) // 7 + 2)\n        hep_pos = reg_fit[0][0]\n        register_string = exp_base[hep_pos:hep_pos + len(h)]\n        for i, register in enumerate(register_string):\n            h[i].tags['register'] = register\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_helices(cls, assembly, cutoff=7.0, min_helix_length=8):\n        cutoff = float(cutoff)\n        helices = Assembly([x for x in assembly.helices if len(x) >= min_helix_length])\n        if len(helices) <= 1:\n            return None\n        # reassign ampal_parents\n        helices.relabel_polymers([x.ampal_parent.id for x in helices])\n        for i, h in enumerate(helices):\n            h.number = i\n            h.ampal_parent = h[0].ampal_parent\n            for r in h.get_monomers():\n                r.tags['helix'] = h\n        all_kihs = []\n        cluster_dict = cluster_helices(helices, cluster_distance=(cutoff + 10))\n        for k, v in cluster_dict.items():\n            if len(v) > 1:\n                kihs = find_kihs(v, cutoff=cutoff, hole_size=4)\n                if len(kihs) == 0:\n                    continue\n                for x in kihs:\n                    all_kihs.append(x)\n        instance = cls(ampal_parent=helices, cutoff=cutoff)\n        for x in all_kihs:\n            x.ampal_parent = instance\n        instance._monomers = all_kihs\n        instance.relabel_monomers()\n        return instance", "response": "Generate a KnobGroup from the helices in the given Assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a KnobGroup containing only the KnobsIntoHoles with max_kh_distance < cutoff.", "response": "def knob_subgroup(self, cutoff=7.0):\n        \"\"\" KnobGroup where all KnobsIntoHoles have max_kh_distance <= cutoff. \"\"\"\n        if cutoff > self.cutoff:\n            raise ValueError(\"cutoff supplied ({0}) cannot be greater than self.cutoff ({1})\".format(cutoff,\n                                                                                                     self.cutoff))\n        return KnobGroup(monomers=[x for x in self.get_monomers()\n                                   if x.max_kh_distance <= cutoff], ampal_parent=self.ampal_parent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a MultiDiGraph from kihs. Nodes are helices and edges are kihs.", "response": "def graph(self):\n        \"\"\" Returns MultiDiGraph from kihs. Nodes are helices and edges are kihs. \"\"\"\n        g = networkx.MultiDiGraph()\n        edge_list = [(x.knob_helix, x.hole_helix, x.id, {'kih': x}) for x in self.get_monomers()]\n        g.add_edges_from(edge_list)\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter out the edges that have max_kh_distance < cutoff.", "response": "def filter_graph(g, cutoff=7.0, min_kihs=2):\n        \"\"\" Get subgraph formed from edges that have max_kh_distance < cutoff.\n\n        Parameters\n        ----------\n        g : MultiDiGraph representing KIHs\n            g is the output from graph_from_protein\n        cutoff : float\n            Socket cutoff in Angstroms.\n            Default is 7.0.\n        min_kihs : int\n            Minimum number of KIHs shared between all pairs of connected nodes in the graph.\n\n        Returns\n        -------\n        networkx.MultiDigraph\n            subgraph formed from edges that have max_kh_distance < cutoff.\n        \"\"\"\n        edge_list = [e for e in g.edges(keys=True, data=True) if e[3]['kih'].max_kh_distance <= cutoff]\n        if min_kihs > 0:\n            c = Counter([(e[0], e[1]) for e in edge_list])\n            # list of nodes that share > min_kihs edges with at least one other node.\n            node_list = set(list(itertools.chain.from_iterable([k for k, v in c.items() if v > min_kihs])))\n            edge_list = [e for e in edge_list if (e[0] in node_list) and (e[1] in node_list)]\n        return networkx.MultiDiGraph(edge_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an Assembly containing only assigned regions with contiguous KnobsIntoHoles.", "response": "def get_coiledcoil_region(self, cc_number=0, cutoff=7.0, min_kihs=2):\n        \"\"\" Assembly containing only assigned regions (i.e. regions with contiguous KnobsIntoHoles. \"\"\"\n        g = self.filter_graph(self.graph, cutoff=cutoff, min_kihs=min_kihs)\n        ccs = sorted(networkx.connected_component_subgraphs(g, copy=True),\n                                 key=lambda x: len(x.nodes()), reverse=True)\n        cc = ccs[cc_number]\n        helices = [x for x in g.nodes() if x.number in cc.nodes()]\n        assigned_regions = self.get_assigned_regions(helices=helices, include_alt_states=False, complementary_only=True)\n        coiledcoil_monomers = [h.get_slice_from_res_id(*assigned_regions[h.number]) for h in helices]\n        return Assembly(coiledcoil_monomers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndirects graph with edges from knob residue to each hole residue for each KnobIntoHole in self.", "response": "def daisy_chain_graph(self):\n        \"\"\" Directed graph with edges from knob residue to each hole residue for each KnobIntoHole in self. \"\"\"\n        g = networkx.DiGraph()\n        for x in self.get_monomers():\n            for h in x.hole:\n                g.add_edge(x.knob, h)\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a list of daisy chains for a given KnobIntoHole.", "response": "def daisy_chains(self, kih, max_path_length=None):\n        \"\"\" Generator for daisy chains (complementary kihs) associated with a knob.\n\n        Notes\n        -----\n        Daisy chain graph is the directed graph with edges from knob residue to each hole residue for each KnobIntoHole\n         in self.\n        Given a KnobIntoHole, the daisy chains are non-trivial paths in this graph (walks along the directed edges)\n        that begin and end at the knob.\n        These paths must be of length  <= max_path_length\n\n        Parameters\n        ----------\n        kih : KnobIntoHole interaction.\n        max_path_length : int or None\n            Maximum length of a daisy chain.\n            Defaults to number of chains in self.ampal_parent.\n            This is the maximum sensible value. Larger values than this will cause slow running of this function.\n        \"\"\"\n        if max_path_length is None:\n            max_path_length = len(self.ampal_parent)\n        g = self.daisy_chain_graph\n        paths = networkx.all_simple_paths(g, source=kih.knob, target=kih.knob, cutoff=max_path_length)\n        return paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncoordinates of the end of the knob residue.", "response": "def knob_end(self):\n        \"\"\" Coordinates of the end of the knob residue (atom in side-chain furthest from CB atom.\n        Returns CA coordinates for GLY.\n        \"\"\"\n        side_chain_atoms = self.knob_residue.side_chain\n        if not side_chain_atoms:\n            return self.knob_residue['CA']\n        distances = [distance(self.knob_residue['CB'], x) for x in side_chain_atoms]\n        max_d = max(distances)\n        knob_end_atoms = [atom for atom, d in zip(side_chain_atoms, distances) if d == max_d]\n        if len(knob_end_atoms) == 1:\n            return knob_end_atoms[0]._vector\n        else:\n            return numpy.mean([x._vector for x in knob_end_atoms], axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the angle between CA - CB of knob and CA h1 - CA h2. Returns None if knob is GLY.", "response": "def packing_angle(self):\n        \"\"\" Angle between CA-CB of knob and CA(h1)-CA(h2). Returns None if knob is GLY. \"\"\"\n        try:\n            knob_vector = self.knob_residue['CB'] - self.knob_residue['CA']\n        # exception for GLY residues (with no CB atom).\n        except KeyError:\n            return None\n        hole_vector = self.hole_residues[2]['CA'] - self.hole_residues[1]['CA']\n        return angle_between_vectors(knob_vector, hole_vector)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating configuration setting for required functionality of ISAMBARD.", "response": "def base_install():\n    \"\"\"Generates configuration setting for required functionality of ISAMBARD.\"\"\"\n    # scwrl\n    scwrl = {}\n    print('{BOLD}{HEADER}Generating configuration files for ISAMBARD.{END_C}\\n'\n          'All required input can use tab completion for paths.\\n'\n          '{BOLD}Setting up SCWRL 4.0 (Recommended){END_C}'.format(**text_colours))\n    scwrl_path = get_user_path('Please provide a path to your SCWRL executable', required=False)\n    scwrl['path'] = str(scwrl_path)\n    pack_mode = get_user_option(\n        'Please choose your packing mode (flexible is significantly slower but is more accurate).',\n        ['flexible', 'rigid'])\n    if pack_mode == 'rigid':\n        scwrl['rigid_rotamer_model'] = True\n    else:\n        scwrl['rigid_rotamer_model'] = False\n    settings['scwrl'] = scwrl\n\n    # dssp\n    print('{BOLD}Setting up DSSP (Recommended){END_C}'.format(**text_colours))\n    dssp = {}\n    dssp_path = get_user_path('Please provide a path to your DSSP executable.', required=False)\n    dssp['path'] = str(dssp_path)\n    settings['dssp'] = dssp\n\n    # buff\n    print('{BOLD}Setting up BUFF (Required){END_C}'.format(**text_colours))\n    buff = {}\n    ffs = []\n    ff_dir = isambard_path / 'buff' / 'force_fields'\n    for ff_file in os.listdir(str(ff_dir)):\n        ff = pathlib.Path(ff_file)\n        ffs.append(ff.stem)\n    force_field_choice = get_user_option(\n        'Please choose the default BUFF force field, this can be modified during runtime.',\n        ffs)\n    buff['default_force_field'] = force_field_choice\n    settings['buff'] = buff\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optional_install():\n    # reduce\n    print('{BOLD}Setting up Reduce (optional){END_C}'.format(**text_colours))\n    reduce = {}\n    reduce_path = get_user_path('Please provide a path to your reduce executable.', required=False)\n    reduce['path'] = str(reduce_path)\n    reduce['folder'] = str(reduce_path.parent) if reduce_path else ''\n    settings['reduce'] = reduce\n\n    # naccess\n    print('{BOLD}Setting up naccess (optional){END_C}'.format(**text_colours))\n    naccess = {}\n    naccess_path = get_user_path('Please provide a path to your naccess executable.', required=False)\n    naccess['path'] = str(naccess_path)\n    settings['naccess'] = naccess\n\n    # profit\n    print('{BOLD}Setting up ProFit (optional){END_C}'.format(**text_colours))\n    profit = {}\n    profit_path = get_user_path('Please provide a path to your ProFit executable.', required=False)\n    profit['path'] = str(profit_path)\n    settings['profit'] = profit\n    return", "response": "Generates configuration settings for optional functionality of ISAMBARD."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a PDB string for the Polymer.", "response": "def pdb(self):\n        \"\"\"Generates a PDB string for the `PseudoMonomer`.\"\"\"\n        pdb_str = write_pdb(\n            [self], ' ' if not self.tags['chain_id'] else self.tags['chain_id'])\n        return pdb_str"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_coordinates(cls, coordinates):\n        prim = cls()\n        for coord in coordinates:\n            pm = PseudoMonomer(ampal_parent=prim)\n            pa = PseudoAtom(coord, ampal_parent=pm)\n            pm.atoms = OrderedDict([('CA', pa)])\n            prim.append(pm)\n        prim.relabel_all()\n        return prim", "response": "Creates a Primitive from a list of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rise_per_residue(self):\n        rprs = [distance(self[i]['CA'], self[i + 1]['CA'])\n                for i in range(len(self) - 1)]\n        rprs.append(None)\n        return rprs", "response": "Returns the rise per residue."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the radius of curvature at each point on the Polymer primitive.", "response": "def radii_of_curvature(self):\n        \"\"\"The radius of curvature at each point on the Polymer primitive.\n\n        Notes\n        -----\n        Each element of the returned list is the radius of curvature,\n        at a point on the Polymer primitive. Element i is the radius\n        of the circumcircle formed from indices [i-1, i, i+1] of the\n        primitve. The first and final values are None.\n        \"\"\"\n        rocs = []\n        for i in range(len(self)):\n            if 0 < i < len(self) - 1:\n                rocs.append(radius_of_circumcircle(\n                    self[i - 1]['CA'], self[i]['CA'], self[i + 1]['CA']))\n            else:\n                rocs.append(None)\n        return rocs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sequence(self):\n        seq = [x.mol_code for x in self._monomers]\n        return ' '.join(seq)", "response": "Returns the sequence of the Polynucleotide as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses DSSP to find helices and extracts helices from a pdb file or string.", "response": "def run_dssp(pdb, path=True, outfile=None):\n    \"\"\"Uses DSSP to find helices and extracts helices from a pdb file or string.\n\n    Parameters\n    ----------\n    pdb : str\n        Path to pdb file or string.\n    path : bool, optional\n        Indicates if pdb is a path or a string.\n    outfile : str, optional\n        Filepath for storing the dssp output.\n\n    Returns\n    -------\n    dssp_out : str\n        Std out from DSSP.\n    \"\"\"\n    if not path:\n        if type(pdb) == str:\n            pdb = pdb.encode()\n        try:\n            temp_pdb = tempfile.NamedTemporaryFile(delete=False)\n            temp_pdb.write(pdb)\n            temp_pdb.seek(0)\n            dssp_out = subprocess.check_output(\n                [global_settings['dssp']['path'], temp_pdb.name])\n            temp_pdb.close()\n        finally:\n            os.remove(temp_pdb.name)\n    else:\n        dssp_out = subprocess.check_output(\n            [global_settings['dssp']['path'], pdb])\n\n    # Python 3 string formatting.\n    dssp_out = dssp_out.decode()\n\n    if outfile:\n        with open(outfile, 'w') as outf:\n            outf.write(dssp_out)\n    return dssp_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_solvent_accessibility_dssp(in_dssp, path=True):\n    if path:\n        with open(in_dssp, 'r') as inf:\n            dssp_out = inf.read()\n    else:\n        dssp_out = in_dssp[:]\n    dssp_residues = []\n    go = False\n    for line in dssp_out.splitlines():\n        if go:\n            try:\n                res_num = int(line[5:10].strip())\n                chain = line[10:12].strip()\n                residue = line[13]\n                acc = int(line[35:38].strip())\n                # It is IMPORTANT that acc remains the final value of the\n                # returned list, due to its usage in\n                # isambard.ampal.base_ampal.tag_dssp_solvent_accessibility\n                dssp_residues.append([res_num, chain, residue, acc])\n            except ValueError:\n                pass\n        else:\n            if line[2] == '#':\n                go = True\n            pass\n    return dssp_residues", "response": "Uses DSSP to extract solvent accessibilty information on every residue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_helices_dssp(in_pdb):\n    from ampal.pdb_parser import split_pdb_lines\n\n    dssp_out = subprocess.check_output(\n        [global_settings['dssp']['path'], in_pdb])\n    helix = 0\n    helices = []\n    h_on = False\n    for line in dssp_out.splitlines():\n        dssp_line = line.split()\n        try:\n            if dssp_line[4] == 'H':\n                if helix not in [x[0] for x in helices]:\n                    helices.append(\n                        [helix, dssp_line[2], {int(dssp_line[1]): None}])\n                else:\n                    helices[helix][2][int(dssp_line[1])] = None\n                h_on = True\n            else:\n                if h_on:\n                    helix += 1\n                    h_on = False\n        except IndexError:\n            pass\n    with open(in_pdb, 'r') as pdb:\n        pdb_atoms = split_pdb_lines(pdb.read())\n    for atom in pdb_atoms:\n        for helix in helices:\n            if (atom[2] == \"CA\") and (atom[5] == helix[1]) and (atom[6] in helix[2].keys()):\n                helix[2][atom[6]] = tuple(atom[8:11])\n    return helices", "response": "Uses DSSP to find alpha - helices and extracts helices from a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_pp_helices(in_pdb):\n    t_phi = -75.0\n    t_phi_d = 29.0\n    t_psi = 145.0\n    t_psi_d = 29.0\n\n    pph_dssp = subprocess.check_output(\n        [global_settings['dssp']['path'], in_pdb])\n    dssp_residues = []\n    go = False\n    for line in pph_dssp.splitlines():\n        if go:\n            res_num = int(line[:5].strip())\n            chain = line[11:13].strip()\n            ss_type = line[16]\n            phi = float(line[103:109].strip())\n            psi = float(line[109:116].strip())\n            dssp_residues.append((res_num, ss_type, chain, phi, psi))\n        else:\n            if line[2] == '#':\n                go = True\n            pass\n    pp_chains = []\n    chain = []\n    ch_on = False\n    for item in dssp_residues:\n        if (item[1] == ' ') and (\n            t_phi - t_phi_d < item[3] < t_phi + t_phi_d) and (\n            t_psi - t_psi_d < item[4] < t_psi + t_psi_d):\n            chain.append(item)\n            ch_on = True\n        else:\n            if ch_on:\n                pp_chains.append(chain)\n                chain = []\n                ch_on = False\n    pp_chains = [x for x in pp_chains if len(x) > 1]\n    pp_helices = []\n    with open(in_pdb, 'r') as pdb:\n        pdb_atoms = split_pdb_lines(pdb.read())\n    for pp_helix in pp_chains:\n        chain_id = pp_helix[0][2]\n        res_range = [x[0] for x in pp_helix]\n        helix = []\n        for atom in pdb_atoms:\n            if (atom[2] == \"CA\") and (\n                    atom[5] == chain_id) and (\n                    atom[6] in res_range):\n                helix.append(tuple(atom[8:11]))\n        pp_helices.append(helix)\n    return pp_helices", "response": "Uses DSSP to find polyproline helices in a PDB file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_ss_regions(dssp_residues):\n\n    loops = [' ', 'B', 'S', 'T']\n    current_ele = None\n    fragment = []\n    fragments = []\n    first = True\n    for ele in dssp_residues:\n        if first:\n            first = False\n            fragment.append(ele)\n        elif current_ele in loops:\n            if ele[1] in loops:\n                fragment.append(ele)\n            else:\n                fragments.append(fragment)\n                fragment = [ele]\n        else:\n            if ele[1] == current_ele:\n                fragment.append(ele)\n            else:\n                fragments.append(fragment)\n                fragment = [ele]\n        current_ele = ele[1]\n    return fragments", "response": "This function returns a list of continuous regions of secondary structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef memory():\n\n    mem_info = {}\n\n    if platform.linux_distribution()[0]:\n        with open('/proc/meminfo') as file:\n            c = 0\n            for line in file:\n                lst = line.split()\n                if str(lst[0]) == 'MemTotal:':\n                    mem_info['total'] = int(lst[1])\n                elif str(lst[0]) in ('MemFree:', 'Buffers:', 'Cached:'):\n                    c += int(lst[1])\n            mem_info['free'] = c\n            mem_info['used'] = (mem_info['total']) - c\n    elif platform.mac_ver()[0]:\n        ps = subprocess.Popen(['ps', '-caxm', '-orss,comm'], stdout=subprocess.PIPE).communicate()[0]\n        vm = subprocess.Popen(['vm_stat'], stdout=subprocess.PIPE).communicate()[0]\n\n        # Iterate processes\n        process_lines = ps.split('\\n')\n        sep = re.compile('[\\s]+')\n        rss_total = 0  # kB\n        for row in range(1, len(process_lines)):\n            row_text = process_lines[row].strip()\n            row_elements = sep.split(row_text)\n            try:\n                rss = float(row_elements[0]) * 1024\n            except:\n                rss = 0  # ignore...\n            rss_total += rss\n\n        # Process vm_stat\n        vm_lines = vm.split('\\n')\n        sep = re.compile(':[\\s]+')\n        vm_stats = {}\n        for row in range(1, len(vm_lines) - 2):\n            row_text = vm_lines[row].strip()\n            row_elements = sep.split(row_text)\n            vm_stats[(row_elements[0])] = int(row_elements[1].strip('\\.')) * 4096\n\n        mem_info['total'] = rss_total\n        mem_info['used'] = vm_stats[\"Pages active\"]\n        mem_info['free'] = vm_stats[\"Pages free\"]\n    else:\n        raise('Unsupported Operating System.\\n')\n        exit(1)\n\n    return mem_info", "response": "Determine the machine s memory specifications."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a dimension of size N determine the number of rows or columns or columns that can fit into memory.", "response": "def get_chunk_size(N, n):\n    \"\"\"Given a dimension of size 'N', determine the number of rows or columns \n       that can fit into memory.\n\n    Parameters\n    ----------\n    N : int\n        The size of one of the dimension of a two-dimensional array.  \n\n    n : int\n        The number of times an 'N' by 'chunks_size' array can fit in memory.\n\n    Returns\n    -------\n    chunks_size : int\n        The size of a dimension orthogonal to the dimension of size 'N'. \n    \"\"\"\n\n    mem_free = memory()['free']\n    if mem_free > 60000000:\n        chunks_size = int(((mem_free - 10000000) * 1000) / (4 * n * N))\n        return chunks_size\n    elif mem_free > 40000000:\n        chunks_size = int(((mem_free - 7000000) * 1000) / (4 * n * N))\n        return chunks_size\n    elif mem_free > 14000000:\n        chunks_size = int(((mem_free - 2000000) * 1000) / (4 * n * N))\n        return chunks_size\n    elif mem_free > 8000000:\n        chunks_size = int(((mem_free - 1400000) * 1000) / (4 * n * N))\n        return chunks_size\n    elif mem_free > 2000000:\n        chunks_size = int(((mem_free - 900000) * 1000) / (4 * n * N))\n        return chunks_size\n    elif mem_free > 1000000:\n        chunks_size = int(((mem_free - 400000) * 1000) / (4 * n * N))\n        return chunks_size\n    else:\n        raise MemoryError(\"\\nERROR: DBSCAN_multiplex @ get_chunk_size:\\n\"\n                          \"this machine does not have enough free memory \"\n                          \"to perform the remaining computations.\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(hdf5_file_name, data, minPts, eps = None, quantile = 50, subsamples_matrix = None, samples_weights = None, \nmetric = 'minkowski', p = 2, verbose = True):\n    \"\"\"Determines the radius 'eps' for DBSCAN clustering of 'data' in an adaptive, data-dependent way.\n\n    Parameters\n    ----------\n    hdf5_file_name : file object or string\n        The handle or name of an HDF5 data structure where any array needed for DBSCAN\n        and too large to fit into memory is to be stored.\n\n    data : array of shape (n_samples, n_features)\n        An array of features retained from the data-set to be analysed. \n        Subsamples of this curated data-set can also be analysed by a call to DBSCAN by providing an appropriate \n        list of selected samples labels, stored in 'subsamples_matrix' (see below).\n\n    subsamples_matrix : array of shape (n_runs, n_subsamples), optional (default = None)\n        Each row of this matrix contains a set of indices identifying the samples selected from the whole data-set\n        for each of 'n_runs' independent rounds of DBSCAN clusterings.\n\n    minPts : int\n        The number of points within an epsilon-radius hypershpere for the said region to qualify as dense.\n\n    eps : float, optional (default = None)\n        Sets the maximum distance separating two data-points for those data-points to be considered \n        as part of the same neighborhood.\n\n    quantile : int, optional (default = 50)\n        If 'eps' is not provided by the user, it will be determined as the 'quantile' of the distribution \n        of the k-nearest distances to each sample, with k set to 'minPts'.\n\n    samples_weights : array of shape (n_runs, n_samples), optional (default = None)\n        Holds the weights of each sample. A sample with weight greater than 'minPts' is guaranteed to be\n        a core sample; a sample with negative weight tends to prevent its 'eps'-neighbors from being core. \n        Weights are absolute and default to 1.\n\n    metric : string or callable, optional (default = 'euclidean')\n        The metric to use for computing the pairwise distances between samples \n        (each sample corresponds to a row in 'data'). If metric is a string or callable, it must be compatible \n        with metrics.pairwise.pairwise_distances.\n\n    p : float, optional (default = 2)\n        If a Minkowski metric is used, 'p' determines its power.\n\n    verbose : Boolean, optional (default = True)\n        Whether to display messages reporting the status of the computations and the time it took \n        to complete each major stage of the algorithm. \n\n    Returns\n    -------\n    eps : float\n        The parameter of DBSCAN clustering specifying if points are density-reachable. \n        This is either a copy of the value provided at input or, if the user did not specify a value of 'eps' at input, \n        the return value if the one determined from k-distance graphs from the data-set.\n\n    References\n    ----------\n    Ester, M., H. P. Kriegel, J. Sander and X. Xu, \"A Density-Based\n    Algorithm for Discovering Clusters in Large Spatial Databases with Noise\".\n    In: Proceedings of the 2nd International Conference on Knowledge Discovery\n    and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n    \"\"\"\n    \n    data = np.array(data, copy = False)\n    if data.ndim > 2:\n        raise ValueError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\" \n                         \"the data array is of dimension %d. Please provide a two-dimensional \"\n                         \"array instead.\\n\" % data.ndim)\n\n    if subsamples_matrix is None:\n        subsamples_matrix = np.arange(data.shape[0], dtype = int)\n        subsamples_matrix = subsamples_matrix.reshape(1, -1)\n \n    else:\n        subsamples_matrix = np.array(subsamples_matrix, copy = False)\n\n    if subsamples_matrix.ndim > 2:\n        raise ValueError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\"\n                         \"the array of subsampled indices is of dimension %d. \"\n                         \"Please provide a two-dimensional array instead.\\n\" % subsamples_matrix.ndim)\n\n    if (data.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(data.sum()) and not np.all(np.isfinite(data))):\n        raise ValueError('\\nERROR: DBSCAN_multiplex @ load:\\n'\n                         'the data vector contains at least one infinite or NaN entry.\\n')\n\n    if (subsamples_matrix.dtype.type is np.int_ and not np.isfinite(subsamples_matrix.sum()) and not np.all(np.isfinite(subsamples_matrix))):\n        raise ValueError('\\nERROR: DBSCAN_multiplex @ load:\\n' \n                         'the array of subsampled indices contains at least one infinite or NaN entry.\\n')\n\n    if not np.all(subsamples_matrix >= 0):\n        raise ValueError('\\nERROR: DBSCAN_multiplex @ load:\\n'\n                         'the sampled indices should all be positive integers.\\n') \n\n    N_samples = data.shape[0]\n    N_runs, N_subsamples = subsamples_matrix.shape\n\n    if N_subsamples > N_samples:\n        raise ValueError('\\nERROR: DBSCAN_multiplex @ load:\\n'\n                         'the number of sampled indices cannot exceed the total number of samples in the whole data-set.\\n')\n\n    for i in range(N_runs):\n        subsamples_matrix[i] = np.unique(subsamples_matrix[i])\n \n    if not isinstance(minPts, int):\n        raise TypeError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\"\n                        \"the parameter 'minPts' must be an integer.\\n\")\n\n    if minPts < 2:\n        raise ValueError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\"\n                         \"the value of 'minPts' must be larger than 1.\\n\")        \n\n    if eps is None:\n        # Determine the parameter 'eps' as the median of the distribution\n        # of the maximum of the minPts-nearest neighbors distances for each sample.\n        if verbose:\n            print((\"INFO: DBSCAN_multiplex @ load:\\n\"\n                  \"starting the determination of an appropriate value of 'eps' for this data-set\"\n                  \" and for the other parameter of the DBSCAN algorithm set to {minPts}.\\n\"\n                  \"This might take a while.\".format(**locals())))\n\n        beg_eps = time.time()\n\n        quantile = np.rint(quantile)\n        quantile = np.clip(quantile, 0, 100)\n\n        k_distances = kneighbors_graph(data, minPts, mode = 'distance', metric = metric, p = p).data\n \n        radii = np.zeros(N_samples, dtype = float)\n        for i in range(0, minPts):\n            radii = np.maximum(radii, k_distances[i::minPts]) \n             \n        if quantile == 50:     \n            eps = round(np.median(radii, overwrite_input = True), 4)\n        else:\n            eps = round(np.percentile(radii, quantile), 4)\n\n        end_eps = time.time()\n\n        if verbose:\n            print((\"\\nINFO: DBSCAN_multiplex @ load:\\n\"\n                  \"done with evaluating parameter 'eps' from the data-set provided.\"\n                  \" This took {} seconds. Value of epsilon: {}.\".format(round(end_eps - beg_eps, 4), eps)))\n\n    else:\n        if not (isinstance(eps, float) or isinstance(eps, int)):\n            raise ValueError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\"\n                             \"please provide a numeric value for the radius 'eps'.\\n\")\n\n        if not eps > 0.0:\n            raise ValueError(\"\\nERROR: DBSCAN_multiplex @ load:\\n\"\n                             \"the radius 'eps' must be positive.\\n\")\n\n        eps = round(eps, 4)\n\n    # For all samples with a large enough neighborhood, 'neighborhoods_indices' \n    # and 'neighborhoods_indptr' help us find the neighbors to every sample. Note\n    # that this definition of neighbors leaves the original point in,\n    # which will be considered later.\n    if verbose:\n       print((\"\\nINFO: DBSCAN_multiplex @ load:\\n\"\n             \"identifying the neighbors within an hypersphere of radius {eps} around each sample,\"\n             \" while at the same time evaluating the number of epsilon-neighbors for each sample.\\n\"\n             \"This might take a fair amount of time.\".format(**locals())))\n\n    beg_neigh = time.time()\n\n    fileh = tables.open_file(hdf5_file_name, mode = 'r+')\n    DBSCAN_group = fileh.create_group(fileh.root, 'DBSCAN_group')\n\n    neighborhoods_indices = fileh.create_earray(DBSCAN_group, 'neighborhoods_indices', tables.Int32Atom(), (0,), \n                                                'Indices array for sparse matrix of neighborhoods', \n                                                expectedrows = int((N_samples ** 2) / 50))\n\n    # 'neighborhoods_indptr' is such that for each of row i of the data-matrix \n    # neighborhoods_indices[neighborhoods_indptr[i]:neighborhoods_indptr[i+1]]\n    # contains the column indices of row i from the array of \n    # 'eps'-neighborhoods.\n    neighborhoods_indptr = np.zeros(1, dtype = np.int64)\n\n    # For each sample, 'neighbors_counts' will keep a tally of the number \n    # of its  neighbors within a hypersphere of radius 'eps'. \n    # Note that the sample itself is counted as part of this neighborhood.\n    neighbors_counts = fileh.create_carray(DBSCAN_group, 'neighbors_counts', tables.Int32Atom(), (N_runs, N_samples), \n                                           'Array of the number of neighbors around each sample of a set of subsampled points', \n                                           filters = None)   \n\n    chunks_size = get_chunk_size(N_samples, 3)\n    for i in range(0, N_samples, chunks_size):\n        chunk = data[i:min(i + chunks_size, N_samples)]\n\n        D = pairwise_distances(chunk, data, metric = metric, p = p, n_jobs = 1)\n            \n        D = (D <= eps)\n\n        if samples_weights is None:\n            for run in range(N_runs):\n                x = subsamples_matrix[run]\n                M = np.take(D, x, axis = 1)\n\n                legit_rows = np.intersect1d(i + np.arange(min(chunks_size, N_samples - i)), x, assume_unique = True)\n                M = np.take(M, legit_rows - i, axis = 0)\n                \n                neighbors_counts[run, legit_rows] = M.sum(axis = 1)\n\n                del M\n        else:\n            for run in range(N_runs):\n                x = subsamples_matrix[run]\n\n                M = np.take(D, x, axis = 1)\n\n                legit_rows = np.intersect1d(i + np.arange(min(chunks_size, N_samples - i)), x, assume_unique = True)\n                M = np.take(M, legit_rows - i, axis = 0)\n\n                neighbors_counts[run, legit_rows] = np.array([np.sum(samples_weights[x[row]]) for row in M])\n\n                del M\n\n        candidates = np.where(D == True)\n\n        del D\n\n        neighborhoods_indices.append(candidates[1])\n\n        _, nbr = np.unique(candidates[0], return_counts = True)\n        counts = np.cumsum(nbr) + neighborhoods_indptr[-1]\n\n        del candidates\n\n        neighborhoods_indptr = np.append(neighborhoods_indptr, counts)\n\n    fileh.create_carray(DBSCAN_group, 'neighborhoods_indptr', tables.Int64Atom(), (N_samples + 1,), \n                        'Array of cumulative number of column indices for each row', filters = None)\n    fileh.root.DBSCAN_group.neighborhoods_indptr[:] = neighborhoods_indptr[:]\n\n    fileh.create_carray(DBSCAN_group, 'subsamples_matrix', tables.Int32Atom(), (N_runs, N_subsamples), \n                        'Array of subsamples indices', filters = None)\n    fileh.root.DBSCAN_group.subsamples_matrix[:] = subsamples_matrix[:]\n\n    fileh.close()\n\n    end_neigh = time.time()\n\n    if verbose:\n        print((\"\\nINFO: DBSCAN_multiplex @ load:\\n\"\n              \"done with the neighborhoods. This step took {} seconds.\".format(round(end_neigh - beg_neigh, 4))))\n\n    gc.collect()\n\n    return eps", "response": "Load the DBSCAN clusterings from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform DBSCAN clustering on a set of data points in a dataset.", "response": "def shoot(hdf5_file_name, minPts, sample_ID = 0, random_state = None, verbose = True): \n    \"\"\"Perform DBSCAN clustering with parameters 'minPts' and 'eps'\n        (as determined by a prior call to 'load' from this module). \n        If multiple subsamples of the dataset were provided in a preliminary call to 'load', \n        'sample_ID' specifies which one of those subsamples is to undergo DBSCAN clustering. \n         \n    Parameters\n    ----------\n    hdf5_file_name : file object or string\n        The handle or name of an HDF5 file where any array needed for DBSCAN and too large to fit into memory \n        is to be stored. Procedure 'shoot' relies on arrays stored in this data structure by a previous\n        call to 'load' (see corresponding documentation)\n\n    sample_ID : int, optional (default = 0)\n        Identifies the particular set of selected data-points on which to perform DBSCAN.\n        If not subsamples were provided in the call to 'load', the whole dataset will be subjected to DBSCAN clustering.\n\n    minPts : int\n        The number of points within a 'eps'-radius hypershpere for this region to qualify as dense.\n\n    random_state: np.RandomState, optional (default = None)\n        The generator used to reorder the samples. If None at input, will be set to np.random.\n\n    verbose : Boolean, optional (default = True)\n        Whether to display messages concerning the status of the computations and the time it took to complete \n        each major stage of the algorithm.\n\n    Returns\n    -------\n    core_samples : array of shape (n_core_samples, )\n        Indices of the core samples.\n\n    labels : array of shape (N_samples, ) \n        Holds the cluster labels of each sample. The points considered as noise have entries -1. \n        The points not initially selected for clustering (i.e. not listed in 'subsampled_indices', if the latter\n        has been provided in the call to 'load' from this module) are labelled -2.\n\n    References\n    ----------\n    Ester, M., H. P. Kriegel, J. Sander and X. Xu, \"A Density-Based\n    Algorithm for Discovering Clusters in Large Spatial Databases with Noise\".\n    In: Proceedings of the 2nd International Conference on Knowledge Discovery\n    and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n    \"\"\"       \n        \n    fileh = tables.open_file(hdf5_file_name, mode = 'r+')\n\n    neighborhoods_indices = fileh.root.DBSCAN_group.neighborhoods_indices\n    neighborhoods_indptr = fileh.root.DBSCAN_group.neighborhoods_indptr[:]\n\n    neighbors_counts = fileh.root.DBSCAN_group.neighbors_counts[sample_ID]\n    subsampled_indices = fileh.root.DBSCAN_group.subsamples_matrix[sample_ID]\n\n    N_samples = neighborhoods_indptr.size - 1\n    N_runs, N_subsamples = fileh.root.DBSCAN_group.subsamples_matrix.shape\n\n    if not isinstance(sample_ID, int):\n        raise ValueError(\"\\nERROR: DBSCAN_multiplex @ shoot:\\n\"\n                         \"'sample_ID' must be an integer identifying the set of subsampled indices \"\n                         \"on which to perform DBSCAN clustering\\n\")    \n\n    if (sample_ID < 0) or (sample_ID >= N_runs):\n        raise ValueError(\"\\nERROR: DBSCAN_multiplex @ shoot:\\n\"\n                 \"'sample_ID' must belong to the interval [0; {}].\\n\".format(N_runs - 1))\n      \n    # points that have not been sampled are labelled with -2\n    labels = np.full(N_samples, -2, dtype = int)\n    # among the points selected for clustering, \n    # all are initally characterized as noise\n    labels[subsampled_indices] = - 1\n    \n    random_state = check_random_state(random_state)\n\n    core_samples = np.flatnonzero(neighbors_counts >= minPts)\n \n    index_order = np.take(core_samples, random_state.permutation(core_samples.size))\n\n    cluster_ID = 0\n\n    # Look at all the selected samples, see if they qualify as core samples\n    # Create a new cluster from those core samples\n    for index in index_order:\n        if labels[index] not in {-1, -2}:\n            continue\n\n        labels[index] = cluster_ID\n\n        candidates = [index]\n        while len(candidates) > 0:\n            candidate_neighbors = np.zeros(0, dtype = np.int32)\n            for k in candidates:\n                candidate_neighbors = np.append(candidate_neighbors, \n                                                neighborhoods_indices[neighborhoods_indptr[k]: neighborhoods_indptr[k+1]])\n                candidate_neighbors = np.unique(candidate_neighbors)\n\n            candidate_neighbors = np.intersect1d(candidate_neighbors, subsampled_indices, assume_unique = True)\n                \n            not_noise_anymore = np.compress(np.take(labels, candidate_neighbors) == -1, candidate_neighbors)\n            \n            labels[not_noise_anymore] = cluster_ID\n\n            # Eliminate as potential candidates the points that have already \n            # been used to expand the current cluster by a trail \n            # of density-reachable points\n            candidates = np.intersect1d(not_noise_anymore, core_samples, assume_unique = True) \n     \n        cluster_ID += 1\n    # Done with building this cluster. \n    # \"cluster_ID\" is now labelling the next cluster.\n\n    fileh.close()\n\n    gc.collect()\n\n    return core_samples, labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming Density - based Spatial Clustering of Applications with Noise.", "response": "def DBSCAN(data, minPts, eps = None, quantile = 50, subsamples_matrix = None, samples_weights = None, \nmetric = 'minkowski', p = 2, verbose = True):\n    \"\"\"Performs Density-Based Spatial Clustering of Applications with Noise,\n        possibly on various subsamples or combinations of data-points extracted from the whole dataset, 'data'.\n        \n        If the radius 'eps' is not provided by the user, it will be determined in an adaptive, data-dependent way \n        by a call to 'load' from this module (see the corresponding documentation for more explanations).\n        \n        Unlike Scikit-learn's and many other versions of DBSCAN, this implementation does not experience failure \n        due to 'MemoryError' exceptions for large data-sets.\n        Indeed, any array too large to fit into memory is stored on disk in an HDF5 data structure.\n    \n    Parameters\n    ----------\n    data : array of shape (n_samples, n_features)\n        The data-set to be analysed. Subsamples of this curated data-set can also be analysed \n        by a call to DBSCAN by providing lits of selected data-points, stored in 'subsamples_matrix' (see below).\n\n    subsamples_matrix : array of shape (n_runs, n_subsamples), optional (default = None)\n        Each row of this matrix contains a set of indices identifying the samples selected from the whole data-set \n        for each of 'n_runs' independent rounds of DBSCAN clusterings.\n\n    minPts : int\n        The number of points within an epsilon-radius hypershpere for the said region to qualify as dense.\n\n    eps : float, optional (default = None)\n        Sets the maximum distance separating two data-points for those data-points to be considered \n        as part of the same neighborhood.\n\n    quantile : int, optional (default = 50)\n        If 'eps' is not provided by the user, it will be determined as the 'quantile' of the distribution\n        of the k-nearest distances to each sample, with k set to 'minPts'.\n\n    samples_weights : array of shape (n_runs, n_samples), optional (default = None)\n        Holds the weights of each sample. A sample with weight greater than 'minPts' is guaranteed \n        to be a core sample; a sample with negative weight tends to prevent its 'eps'-neighbors from being core. \n        Weights are absolute and default to 1.\n\n    metric : string or callable, optional (default = 'euclidean')\n        The metric to use for computing the pairwise distances between samples\n        (each sample corresponds to a row in 'data'). \n        If metric is a string or callable, it must be compatible with metrics.pairwise.pairwise_distances.\n\n    p : float, optional (default = 2)\n        If a Minkowski metric is used, 'p' denotes its power.\n\n    verbose : Boolean, optional (default = True)\n        Whether to display messages reporting the status of the computations and the time it took to complete\n        each major stage of the algorithm. \n    \n    Returns\n    -------\n    eps : float\n        The parameter of DBSCAN clustering specifying if points are density-reachable. \n        This is relevant if the user chose to let our procedures search for a value of this radius as a quantile\n        of the distribution of 'minPts'-nearest distances for each data-point.\n    \n    labels_matrix : array of shape (N_samples, ) \n        For each sample, specifies the identity of the cluster to which it has been\n        assigned by DBSCAN. The points classified as noise have entries -1. The points that have not been\n        considered for clustering are labelled -2.\n        \n    References\n    ----------\n    Ester, M., H. P. Kriegel, J. Sander and X. Xu, \"A Density-Based\n    Algorithm for Discovering Clusters in Large Spatial Databases with Noise\".\n    In: Proceedings of the 2nd International Conference on Knowledge Discovery\n    and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n    \"\"\"\n        \n    assert isinstance(minPts, int) or type(minPts) is np.int_\n    assert minPts > 1\n\n    if subsamples_matrix is None:\n        subsamples_matrix = np.arange(data.shape[0], dtype = int)\n        subsamples_matrix = subsamples_matrix.reshape(1, -1)\n    else:\n        subsamples_matrix = np.array(subsamples_matrix, copy = False)\n\n    N_runs = subsamples_matrix.shape[0]\n    N_samples = data.shape[0]\n\n    labels_matrix = np.zeros((N_runs, N_samples), dtype = int)\n\n    with NamedTemporaryFile('w', suffix = '.h5', delete = True, dir = './') as f:\n        eps = load(f.name, data, minPts, eps, quantile, subsamples_matrix, samples_weights, metric, p, verbose)\n\n        for run in range(N_runs):\n            _, labels = shoot(f.name, minPts, sample_ID = run, verbose = verbose)\n            labels_matrix[run] = labels\n\n    return eps, labels_matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all of the Floating IPs available on the account.", "response": "def all_floating_ips(self):\n        \"\"\"\n        Lists all of the Floating IPs available on the account.\n        \"\"\"\n        if self.api_version == 2:\n            json = self.request('/floating_ips')\n            return json['floating_ips']\n        else:\n            raise DoError(v2_api_required_str)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new Floating IP and assigns it to a Droplet or reserves it to a region.", "response": "def new_floating_ip(self, **kwargs):\n        \"\"\"\n        Creates a Floating IP and assigns it to a Droplet or reserves it to a region.\n        \"\"\"\n        droplet_id = kwargs.get('droplet_id')\n        region = kwargs.get('region')\n\n        if self.api_version == 2:\n            if droplet_id is not None and region is not None:\n                raise DoError('Only one of droplet_id and region is required to create a Floating IP. ' \\\n                    'Set one of the variables and try again.')\n            elif droplet_id is None and region is None:\n                raise DoError('droplet_id or region is required to create a Floating IP. ' \\\n                    'Set one of the variables and try again.')\n            else:\n                if droplet_id is not None:\n                    params = {'droplet_id': droplet_id}\n                else:\n                    params = {'region': region}\n\n                json = self.request('/floating_ips', params=params, method='POST')\n                return json['floating_ip']\n        else:\n            raise DoError(v2_api_required_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef destroy_floating_ip(self, ip_addr):\n        if self.api_version == 2:\n            self.request('/floating_ips/' + ip_addr, method='DELETE')\n        else:\n            raise DoError(v2_api_required_str)", "response": "Deletes a Floating IP and removes it from the account."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_floating_ip(self, ip_addr, droplet_id):\n        if self.api_version == 2:\n            params = {'type': 'assign','droplet_id': droplet_id}\n\n            json = self.request('/floating_ips/' + ip_addr + '/actions', params=params, method='POST')\n            return json['action']\n        else:\n            raise DoError(v2_api_required_str)", "response": "Assign a Floating IP to a Droplet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a list of all actions that have been executed on a Floating IP.", "response": "def list_floating_ip_actions(self, ip_addr):\n        \"\"\"\n        Retrieve a list of all actions that have been executed on a Floating IP.\n        \"\"\"\n        if self.api_version == 2:\n            json = self.request('/floating_ips/' + ip_addr + '/actions')\n            return json['actions']\n        else:\n            raise DoError(v2_api_required_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_floating_ip_action(self, ip_addr, action_id):\n        if self.api_version == 2:\n            json = self.request('/floating_ips/' + ip_addr + '/actions/' + action_id)\n            return json['action']\n        else:\n            raise DoError(v2_api_required_str)", "response": "Get the status of a Floating IP action."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tuple containing a message signature HTTP header message signature.", "response": "def http_signature(message, key_id, signature):\n    \"\"\"Return a tuple (message signature, HTTP header message signature).\"\"\"\n    template = ('Signature keyId=\"%(keyId)s\",algorithm=\"hmac-sha256\",'\n                'headers=\"%(headers)s\",signature=\"%(signature)s\"')\n    headers = ['(request-target)', 'host', 'accept', 'date']\n    return template % {\n        'keyId': key_id,\n        'signature': signature,\n        'headers': ' '.join(headers),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_signature_from_signature_string(self, signature):\n        match = self.SIGNATURE_RE.search(signature)\n        if not match:\n            return None\n        return match.group(1)", "response": "Return the signature from the signature header or None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_headers_from_signature(self, signature):\n        match = self.SIGNATURE_HEADERS_RE.search(signature)\n        if not match:\n            return ['date']\n        headers_string = match.group(1)\n        return headers_string.split()", "response": "Returns a list of headers fields to sign."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate HTTP headers to Django header names.", "response": "def header_canonical(self, header_name):\n        \"\"\"Translate HTTP headers to Django header names.\"\"\"\n        # Translate as stated in the docs:\n        # https://docs.djangoproject.com/en/1.6/ref/request-response/#django.http.HttpRequest.META\n        header_name = header_name.lower()\n        if header_name == 'content-type':\n            return 'CONTENT-TYPE'\n        elif header_name == 'content-length':\n            return 'CONTENT-LENGTH'\n        return 'HTTP_%s' % header_name.replace('-', '_').upper()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a dict with headers and values used in the signature.", "response": "def build_dict_to_sign(self, request, signature_headers):\n        \"\"\"Build a dict with headers and values used in the signature.\n\n        \"signature_headers\" is a list of lowercase header names.\n        \"\"\"\n        d = {}\n        for header in signature_headers:\n            if header == '(request-target)':\n                continue\n            d[header] = request.META.get(self.header_canonical(header))\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the signature for the request.", "response": "def build_signature(self, user_api_key, user_secret, request):\n        \"\"\"Return the signature for the request.\"\"\"\n        path = request.get_full_path()\n        sent_signature = request.META.get(\n            self.header_canonical('Authorization'))\n        signature_headers = self.get_headers_from_signature(sent_signature)\n        unsigned = self.build_dict_to_sign(request, signature_headers)\n\n        # Sign string and compare.\n        signer = HeaderSigner(\n            key_id=user_api_key, secret=user_secret,\n            headers=signature_headers, algorithm=self.ALGORITHM)\n        signed = signer.sign(unsigned, method=request.method, path=path)\n        return signed['authorization']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert string presented in camel case to snake case.", "response": "def camel_to_snake_case(string):\n    \"\"\"Converts 'string' presented in camel case to snake case.\n\n    e.g.: CamelCase => snake_case\n    \"\"\"\n    s = _1.sub(r'\\1_\\2', string)\n    return _2.sub(r'\\1_\\2', s).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nassembles of parameters for building request query.", "response": "def url_assembler(query_string, no_redirect=0, no_html=0, skip_disambig=0):\n    \"\"\"Assembler of parameters for building request query.\n\n    Args:\n        query_string: Query to be passed to DuckDuckGo API.\n        no_redirect: Skip HTTP redirects (for !bang commands). Default - False.\n        no_html: Remove HTML from text, e.g. bold and italics. Default - False.\n        skip_disambig: Skip disambiguation (D) Type. Default - False.\n\n    Returns:\n        A \u201cpercent-encoded\u201d string which is used as a part of the query.\n    \"\"\"\n    params = [('q', query_string.encode(\"utf-8\")), ('format', 'json')]\n\n    if no_redirect:\n        params.append(('no_redirect', 1))\n    if no_html:\n        params.append(('no_html', 1))\n    if skip_disambig:\n        params.append(('skip_disambig', 1))\n\n    return '/?' + urlencode(params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate and sends a query to DuckDuckGo API. Args: query_string: Query to be passed to DuckDuckGo API. secure: Use secure SSL/TLS connection. Default - False. Syntactic sugar is secure_query function which is passed the same parameters. container: Indicates how dict-like objects are serialized. There are two possible options: namedtuple and dict. If 'namedtuple' is passed the objects will be serialized to namedtuple instance of certain class. If 'dict' is passed the objects won't be deserialized. Default value: 'namedtuple'. verbose: Don't raise any exception if error occurs. Default value: False. user_agent: User-Agent header of HTTP requests to DuckDuckGo API. Default value: 'duckduckpy 0.2' no_redirect: Skip HTTP redirects (for !bang commands). Default value: False. no_html: Remove HTML from text, e.g. bold and italics. Default value: False. skip_disambig: Skip disambiguation (D) Type. Default value: False. Raises: DuckDuckDeserializeError: JSON serialization failed. DuckDuckConnectionError: Something went wrong with client operation. DuckDuckArgumentError: Passed argument is wrong. Returns: Container depends on container parameter. Each field in the response is converted to the so-called snake case. Usage: >>> import duckduckpy >>># Namedtuple is used as a container: >>> response = duckduckpy.query('Python') >>> response Response(redirect=u'', definition=u'', image_width=0, ...} >>> type(response) <class 'duckduckpy.api.Response'> >>> response.related_topics[0] Result(first_url=u'https://duckduckgo.com/Python', text=...) >>> type(response.related_topics[0]) <class 'duckduckpy.api.Result'> >>># Dict is used as a container: >>> response = duckduckpy.query('Python', container='dict') >>> type(response) <type 'dict'> >>> response {u'abstract': u'', u'results': [], u'image_is_logo': 0, ...} >>> type(response['related_topics'][0]) <type 'dict'> >>> response['related_topics'][0] {u'first_url': u'https://duckduckgo.com/Python', u'text': ...}", "response": "def query(query_string, secure=False, container='namedtuple', verbose=False,\n          user_agent=api.USER_AGENT, no_redirect=False, no_html=False,\n          skip_disambig=False):\n    \"\"\"\n    Generates and sends a query to DuckDuckGo API.\n\n    Args:\n        query_string: Query to be passed to DuckDuckGo API.\n        secure: Use secure SSL/TLS connection. Default - False.\n            Syntactic sugar is secure_query function which is passed the same\n            parameters.\n        container: Indicates how dict-like objects are serialized. There are\n           two possible options: namedtuple and dict. If 'namedtuple' is passed\n           the objects will be serialized to namedtuple instance of certain\n           class. If 'dict' is passed the objects won't be deserialized.\n           Default value: 'namedtuple'.\n        verbose: Don't raise any exception if error occurs.\n            Default value: False.\n        user_agent: User-Agent header of HTTP requests to DuckDuckGo API.\n            Default value: 'duckduckpy 0.2'\n        no_redirect: Skip HTTP redirects (for !bang commands).\n            Default value: False.\n        no_html: Remove HTML from text, e.g. bold and italics.\n            Default value: False.\n        skip_disambig: Skip disambiguation (D) Type. Default value: False.\n\n    Raises:\n        DuckDuckDeserializeError: JSON serialization failed.\n        DuckDuckConnectionError: Something went wrong with client operation.\n        DuckDuckArgumentError: Passed argument is wrong.\n\n    Returns:\n        Container depends on container parameter. Each field in the response is\n        converted to the so-called snake case.\n\n    Usage:\n        >>> import duckduckpy\n        >>># Namedtuple is used as a container:\n        >>> response = duckduckpy.query('Python')\n        >>> response\n        Response(redirect=u'', definition=u'', image_width=0, ...}\n        >>> type(response)\n        <class 'duckduckpy.api.Response'>\n        >>> response.related_topics[0]\n        Result(first_url=u'https://duckduckgo.com/Python', text=...)\n        >>> type(response.related_topics[0])\n        <class 'duckduckpy.api.Result'>\n\n        >>># Dict is used as a container:\n        >>> response = duckduckpy.query('Python', container='dict')\n        >>> type(response)\n        <type 'dict'>\n        >>> response\n        {u'abstract': u'', u'results': [], u'image_is_logo': 0, ...}\n        >>> type(response['related_topics'][0])\n        <type 'dict'>\n        >>> response['related_topics'][0]\n        {u'first_url': u'https://duckduckgo.com/Python', u'text': ...}\n    \"\"\"\n    if container not in Hook.containers:\n        raise exc.DuckDuckArgumentError(\n            \"Argument 'container' must be one of the values: \"\n            \"{0}\".format(', '.join(Hook.containers)))\n\n    headers = {\"User-Agent\": user_agent}\n    url = url_assembler(\n        query_string,\n        no_redirect=no_redirect,\n        no_html=no_html,\n        skip_disambig=skip_disambig)\n\n    if secure:\n        conn = http_client.HTTPSConnection(api.SERVER_HOST)\n    else:\n        conn = http_client.HTTPConnection(api.SERVER_HOST)\n\n    try:\n        conn.request(\"GET\", url, \"\", headers)\n        resp = conn.getresponse()\n        data = decoder(resp.read())\n    except socket.gaierror as e:\n        raise exc.DuckDuckConnectionError(e.strerror)\n    finally:\n        conn.close()\n\n    hook = Hook(container, verbose=verbose)\n    try:\n        obj = json.loads(data, object_hook=hook)\n    except ValueError:\n        raise exc.DuckDuckDeserializeError(\n            \"Unable to deserialize response to an object\")\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport a class from a module.", "response": "def _import(module, cls):\n    \"\"\"\n    A messy way to import library-specific classes.\n    TODO: I should really make a factory class or something, but I'm lazy.\n    Plus, factories remind me a lot of java...\n    \"\"\"\n    global Scanner\n\n    try:\n        cls = str(cls)\n        mod = __import__(str(module), globals(), locals(), [cls], 1)\n        Scanner = getattr(mod, cls)\n    except ImportError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(type_dict, *type_parameters):\n    assert len(type_parameters) == 1\n    klazz = TypeFactory.new(type_dict, *type_parameters[0])\n    assert isclass(klazz)\n    assert issubclass(klazz, Object)\n    return TypeMetaclass('%sList' % klazz.__name__, (ListContainer,), {'TYPE': klazz})", "response": "Construct a List containing type klazz."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_file(filename):\n    \"Runs the given scent.py file.\"\n    mod_name = '.'.join(os.path.basename(filename).split('.')[:-1])\n    mod_path = os.path.dirname(filename)\n\n    if mod_name in sys.modules:\n        del sys.modules[mod_name]\n    if mod_path not in set(sys.modules.keys()):\n        sys.path.insert(0, mod_path)\n    return ScentModule(__import__(mod_name, g, g), filename)", "response": "Runs the given scent. py file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exec_from_dir(dirname=None, scent=\"scent.py\"):\n    if dirname is None:\n        dirname = os.getcwd()\n    files = os.listdir(dirname)\n\n    if scent not in files:\n        return None\n\n    return load_file(os.path.join(dirname, scent))", "response": "Runs the scent. py file from the given directory. Returns module if loaded a scent None otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new(type_dict, type_factory, *type_parameters):\n    type_tuple = (type_factory,) + type_parameters\n    if type_tuple not in type_dict:\n      factory = TypeFactory.get_factory(type_factory)\n      reified_type = factory.create(type_dict, *type_parameters)\n      type_dict[type_tuple] = reified_type\n    return type_dict[type_tuple]", "response": "Create a fully reified type from a type schema."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a set of types into a new namespace.", "response": "def load(type_tuple, into=None):\n    \"\"\"\n      Determine all types touched by loading the type and deposit them into\n      the particular namespace.\n    \"\"\"\n    type_dict = {}\n    TypeFactory.new(type_dict, *type_tuple)\n    deposit = into if (into is not None and isinstance(into, dict)) else {}\n    for reified_type in type_dict.values():\n      deposit[reified_type.__name__] = reified_type\n    return deposit"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_json(json_list, into=None):\n    def l2t(obj):\n      if isinstance(obj, list):\n        return tuple(l2t(L) for L in obj)\n      elif isinstance(obj, dict):\n        return frozendict(obj)\n      else:\n        return obj\n    return TypeFactory.load(l2t(json_list), into=into)", "response": "Load a JSON list into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(type_dict, *type_parameters):\n    name, values = type_parameters\n    assert isinstance(values, (list, tuple))\n    for value in values:\n      assert isinstance(value, Compatibility.stringy)\n    return TypeMetaclass(str(name), (EnumContainer,), { 'VALUES': values })", "response": "create returns a new TypeMetaclass instance with the given type_dict and type_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a Python class into a type signature.", "response": "def wrap(sig):\n    \"\"\"Convert a Python class into a type signature.\"\"\"\n    if isclass(sig) and issubclass(sig, Object):\n      return TypeSignature(sig)\n    elif isinstance(sig, TypeSignature):\n      return sig"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new TypeMeta class from a dictionary.", "response": "def create(type_dict, *type_parameters):\n    \"\"\"\n      StructFactory.create(*type_parameters) expects:\n\n        class name,\n        ((binding requirement1,),\n          (binding requirement2, bound_to_scope),\n           ...),\n        ((attribute_name1, attribute_sig1 (serialized)),\n         (attribute_name2, attribute_sig2 ...),\n         ...\n         (attribute_nameN, ...))\n    \"\"\"\n    name, parameters = type_parameters\n    for param in parameters:\n      assert isinstance(param, tuple)\n    typemap = dict((attr, TypeSignature.deserialize(param, type_dict))\n                   for attr, param in parameters)\n    attributes = {'TYPEMAP': typemap}\n    return TypeMetaclass(str(name), (Structural,), attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trigger_modified(self, filepath):\n        mod_time = self._get_modified_time(filepath)\n        if mod_time > self._watched_files.get(filepath, 0):\n            self._trigger('modified', filepath)\n            self._watched_files[filepath] = mod_time", "response": "Triggers modified event if the given filepath mod time is newer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trigger_created(self, filepath):\n        if os.path.exists(filepath):\n            self._trigger('created', filepath)", "response": "Triggers created event if file exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntriggers deleted event if the flie doesn t exist.", "response": "def trigger_deleted(self, filepath):\n        \"\"\"Triggers deleted event if the flie doesn't exist.\"\"\"\n        if not os.path.exists(filepath):\n            self._trigger('deleted', filepath)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a messate to a defined io stream if available.", "response": "def log(self, *message):\n        \"\"\"\n        Logs a messate to a defined io stream if available.\n        \"\"\"\n        if self._logger is None:\n            return\n        s = \" \".join([str(m) for m in message])\n        self._logger.write(s+'\\n')\n        self._logger.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntriggering a given event with the following args and kwargs parameters.", "response": "def _trigger(self, event_name, *args, **kwargs):\n        \"\"\"\n        Triggers a given event with the following *args and **kwargs\n        parameters.\n        \"\"\"\n        self.log('event: %s' % event_name, *args)\n        for f in self._events[event_name]:\n            f(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_validator(self, filepath):\n        return filepath.endswith('.py') and \\\n            not os.path.basename(filepath).startswith('.')", "response": "Default validator for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if filepath is in the repository False otherwise.", "response": "def in_repo(self, filepath):\n        \"\"\"\n        This excludes repository directories because they cause some exceptions\n        occationally.\n        \"\"\"\n        filepath = set(filepath.replace('\\\\', '/').split('/'))\n        for p in ('.git', '.hg', '.svn', '.cvs', '.bzr'):\n            if p in filepath:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid_type(self, filepath):\n        if self.in_repo(filepath):\n            return False\n\n        validators = self._validators\n        if len(validators) == 0:\n            validators = [self.default_validator]\n\n        if any([hasattr(v, 'runnable') for v in self._validators]):\n            # case where we select the runnable function by the validator\n            for validator in validators:\n                if validator(filepath):\n                    if hasattr(validator, 'runnable'):\n                        self._scent.set_runner(validator.runnable)\n                        return True\n            return False\n\n        for validator in validators:\n            if not validator(filepath):\n                return False\n        return True", "response": "Returns True if the given filepath is a valid watchable filetype."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap to call a method from one of the events s events and update the object with the result.", "response": "def _modify_event(self, event_name, method, func):\n        \"\"\"\n        Wrapper to call a list's method from one of the events\n        \"\"\"\n        if event_name not in self.ALL_EVENTS:\n            raise TypeError(('event_name (\"%s\") can only be one of the '\n                             'following: %s') % (event_name,\n                                                 repr(self.ALL_EVENTS)))\n        if not isinstance(func, collections.Callable):\n            raise TypeError(('func must be callable to be added as an '\n                             'observer.'))\n        getattr(self._events[event_name], method)(func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef observe(self, event_name, func):\n        if isinstance(event_name, list) or isinstance(event_name, tuple):\n            for name in event_name:\n                self.observe(name, func)\n            return\n        self.log(func.__name__, \"attached to\", event_name)\n        self._modify_event(event_name, 'append', func)", "response": "Attaches a function to run to a specific event."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _watch_file(self, filepath, trigger_event=True):\n        is_new = filepath not in self._watched_files\n        if trigger_event:\n            if is_new:\n                self.trigger_created(filepath)\n            else:\n                self.trigger_modified(filepath)\n        try:\n            self._watched_files[filepath] = self._get_modified_time(filepath)\n        except OSError:\n            return", "response": "Adds the file s modified time into its internal watchlist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _unwatch_file(self, filepath, trigger_event=True):\n        if filepath not in self._watched_files:\n            return\n        if trigger_event:\n            self.trigger_deleted(filepath)\n        del self._watched_files[filepath]", "response": "Removes the file from the internal watchlist if exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the file has been modified since last seen.", "response": "def _is_modified(self, filepath):\n        \"\"\"\n        Returns True if the file has been modified since last seen.\n        Will return False if the file has not been seen before.\n        \"\"\"\n        if self._is_new(filepath):\n            return False\n        mtime = self._get_modified_time(filepath)\n        return self._watched_files[filepath] < mtime"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loop(self, sleep_time=1, callback=None):\n\n        self.log(\"No supported libraries found: using polling-method.\")\n        self._running = True\n        self.trigger_init()\n        self._scan(trigger=False)  # put after the trigger\n        if self._warn:\n            print(\"\"\"\nYou should install a third-party library so I don't eat CPU.\nSupported libraries are:\n  - pyinotify (Linux)\n  - pywin32 (Windows)\n  - MacFSEvents (OSX)\n\nUse pip or easy_install and install one of those libraries above.\n\"\"\")\n        while self._running:\n            self._scan()\n            if isinstance(callback, collections.Callable):\n                callback()\n            time.sleep(sleep_time)", "response": "This method is used to start the main thread of the main thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwalks through the directory to look for changes of the given file types. Returns True if changes occurred False otherwise.", "response": "def _scan(self, trigger=True):\n        \"\"\"\n        Walks through the directory to look for changes of the given file\n        types.\n        Returns True if changes occurred (False otherwise).\n        Returns None if polling method isn't being used.\n        \"\"\"\n        changed = False\n        files_seen = set()\n        os_path_join = os.path.join\n        for path in self.paths:\n            for root, dirs, files in os.walk(path):\n                for f in files:\n                    fpath = os_path_join(root, f)\n                    if not self.is_valid_type(fpath):\n                        continue\n                    files_seen.add(fpath)\n                    if self._requires_new_modtime(fpath):\n                        self._watch_file(fpath, trigger)\n                        changed = True\n            for f in self._watched_files:\n                if f not in files_seen:\n                    self._unwatch_file(f, trigger)\n                    changed = True\n        return changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(sniffer_instance=None, wait_time=0.5, clear=True, args=(),\n        debug=False):\n    \"\"\"\n    Runs the auto tester loop. Internally, the runner instanciates the sniffer_cls and\n    scanner class.\n\n    ``sniffer_instance`` The class to run. Usually this is set to but a subclass of scanner.\n                    Defaults to Sniffer. Sniffer class documentation for more information.\n    ``wait_time``   The time, in seconds, to wait between polls. This is dependent on\n                    the underlying scanner implementation. OS-specific libraries may choose\n                    to ignore this parameter. Defaults to 0.5 seconds.\n    ``clear``       Boolean. Set to True to clear the terminal before running the sniffer,\n                    (alias, the unit tests). Defaults to True.\n    ``args``        The arguments to pass to the sniffer/test runner. Defaults to ().\n    ``debug``       Boolean. Sets the scanner and sniffer in debug mode, printing more internal\n                    information. Defaults to False (and should usually be False).\n    \"\"\"\n    if sniffer_instance is None:\n        sniffer_instance = ScentSniffer()\n\n    if debug:\n        scanner = Scanner(\n            sniffer_instance.watch_paths,\n            scent=sniffer_instance.scent, logger=sys.stdout)\n    else:\n        scanner = Scanner(\n            sniffer_instance.watch_paths, scent=sniffer_instance.scent)\n    #sniffer = sniffer_cls(tuple(args), clear, debug)\n    sniffer_instance.set_up(tuple(args), clear, debug)\n\n    sniffer_instance.observe_scanner(scanner)\n    scanner.loop(wait_time)", "response": "Runs the auto tester loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(sniffer_instance=None, test_args=(), progname=sys.argv[0],\n         args=sys.argv[1:]):\n    \"\"\"\n    Runs the program. This is used when you want to run this program standalone.\n\n    ``sniffer_instance`` A class (usually subclassed of Sniffer) that hooks into the\n                    scanner and handles running the test framework. Defaults to\n                    Sniffer instance.\n    ``test_args``   This function normally extracts args from ``--test-arg ARG`` command. A\n                    preset argument list can be passed. Defaults to an empty tuple.\n    ``program``     Program name. Defaults to sys.argv[0].\n    ``args``        Command line arguments. Defaults to sys.argv[1:]\n    \"\"\"\n    parser = OptionParser(version=\"%prog \" + __version__)\n    parser.add_option('-w', '--wait', dest=\"wait_time\", metavar=\"TIME\",\n                      default=0.5, type=\"float\",\n                      help=\"Wait time, in seconds, before possibly rerunning\"\n                      \"tests. (default: %default)\")\n    parser.add_option('--no-clear', dest=\"clear_on_run\", default=True,\n                      action=\"store_false\",\n                      help=\"Disable the clearing of screen\")\n    parser.add_option('--debug', dest=\"debug\", default=False,\n                      action=\"store_true\",\n                      help=\"Enabled debugging output. (default: %default)\")\n    parser.add_option('-x', '--test-arg', dest=\"test_args\", default=[],\n                      action=\"append\",\n                      help=\"Arguments to pass to nose (use multiple times to \"\n                      \"pass multiple arguments.)\")\n    (options, args) = parser.parse_args(args)\n    test_args = test_args + tuple(options.test_args)\n\n    if options.debug:\n        print(\"Options:\", options)\n        print(\"Test Args:\", test_args)\n    try:\n        print(\"Starting watch...\")\n        run(sniffer_instance, options.wait_time, options.clear_on_run,\n            test_args, options.debug)\n    except KeyboardInterrupt:\n        print(\"Good bye.\")\n    except Exception:\n        import traceback\n        traceback.print_exc()\n        return sys.exit(1)\n    return sys.exit(0)", "response": "Main function for the test framework."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_up(self, test_args=(), clear=True, debug=False):\n        self.test_args = test_args\n        self.debug, self.clear = debug, clear", "response": "Sets properties right before calling run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef absorb_args(self, func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            return func()\n        return wrapper", "response": "A decorator that returns a function without any arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef observe_scanner(self, scanner):\n        scanner.observe(scanner.ALL_EVENTS,\n                        self.absorb_args(self.modules.restore))\n        if self.clear:\n            scanner.observe(scanner.ALL_EVENTS,\n                            self.absorb_args(self.clear_on_run))\n        scanner.observe(scanner.ALL_EVENTS, self.absorb_args(self._run))\n        if self.debug:\n            scanner.observe('created',  echo(\"callback - created  %(file)s\"))\n            scanner.observe('modified', echo(\"callback - changed  %(file)s\"))\n            scanner.observe('deleted',  echo(\"callback - deleted  %(file)s\"))\n        self._scanners.append(scanner)", "response": "Hook into multiple events of a scanner."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_on_run(self, prefix=\"Running Tests:\"):\n        if platform.system() == 'Windows':\n            os.system('cls')\n        else:\n            os.system('clear')\n        if prefix:\n            print(prefix)", "response": "Clears console before running the tests."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls self. run and wraps for errors.", "response": "def _run(self):\n        \"\"\"Calls self.run() and wraps for errors.\"\"\"\n        try:\n            if self.run():\n                broadcaster.success(self)\n            else:\n                broadcaster.failure(self)\n        except StandardError:\n            import traceback\n            traceback.print_exc()\n            self._stop()\n            raise\n        except Exception:\n            self._stop()\n            raise\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the unit test framework.", "response": "def run(self):\n        \"\"\"\n        Runs the unit test framework. Can be overridden to run anything.\n        Returns True on passing and False on failure.\n        \"\"\"\n        try:\n            import nose\n            arguments = [sys.argv[0]] + list(self.test_args)\n            return nose.run(argv=arguments)\n        except ImportError:\n            print()\n            print(\"*** Nose library missing. Please install it. ***\")\n            print()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the CWD s scent file.", "response": "def run(self):\n        \"\"\"\n        Runs the CWD's scent file.\n        \"\"\"\n        if not self.scent or len(self.scent.runners) == 0:\n            print(\"Did not find 'scent.py', running nose:\")\n            return super(ScentSniffer, self).run()\n        else:\n            print(\"Using scent:\")\n            arguments = [sys.argv[0]] + list(self.test_args)\n            return self.scent.run(arguments)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of this object.", "response": "def copy(self):\n    \"\"\"\n      Return a copy of this object.\n    \"\"\"\n    self_copy = self.dup()\n    self_copy._scopes = copy.copy(self._scopes)\n    return self_copy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind(self, *args, **kw):\n    new_self = self.copy()\n    new_scopes = Object.translate_to_scopes(*args, **kw)\n    new_self._scopes = tuple(reversed(new_scopes)) + new_self._scopes\n    return new_self", "response": "Bind environment variables into this object s scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new object with the given arguments and keyword arguments added to the current environment.", "response": "def in_scope(self, *args, **kw):\n    \"\"\"\n      Scope this object to a parent environment (like bind but reversed.)\n    \"\"\"\n    new_self = self.copy()\n    new_scopes = Object.translate_to_scopes(*args, **kw)\n    new_self._scopes = new_self._scopes + new_scopes\n    return new_self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntyping check this object.", "response": "def check(self):\n    \"\"\"\n      Type check this object.\n    \"\"\"\n    try:\n      si, uninterp = self.interpolate()\n    # TODO(wickman) This should probably be pushed out to the interpolate leaves.\n    except (Object.CoercionError, MustacheParser.Uninterpolatable) as e:\n      return TypeCheck(False, \"Unable to interpolate: %s\" % e)\n    return self.checker(si)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore(self):\n        sys = set(self._sys_modules.keys())\n        for mod_name in sys.difference(self._saved_modules):\n            del self._sys_modules[mod_name]", "response": "Unloads all modules that were not loaded when save_modules was called."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef join(cls, splits, *namables):\n    isplits = []\n    unbound = []\n    for ref in splits:\n      if isinstance(ref, Ref):\n        resolved = False\n        for namable in namables:\n          try:\n            value = namable.find(ref)\n            resolved = True\n            break\n          except Namable.Error:\n            continue\n        if resolved:\n          isplits.append(value)\n        else:\n          isplits.append(ref)\n          unbound.append(ref)\n      else:\n        isplits.append(ref)\n    return (''.join(map(str if Compatibility.PY3 else unicode, isplits)), unbound)", "response": "Returns a string that is the concatenation of the input string and the list of unbound object ids."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new type from a dictionary.", "response": "def create(type_dict, *type_parameters):\n    \"\"\"\n    type_parameters should be:\n      (name, (alternative1, alternative2, ...))\n    where name is a string, and the alternatives are all valid serialized\n    types.\n    \"\"\"\n    assert len(type_parameters) == 2\n    name = type_parameters[0]\n    alternatives = type_parameters[1]\n    assert isinstance(name, Compatibility.stringy)\n    assert isinstance(alternatives, (list, tuple))\n    choice_types = []\n    for c in alternatives:\n      choice_types.append(TypeFactory.new(type_dict, *c))\n    return TypeMetaclass(str(name), (ChoiceContainer,), {'CHOICES': choice_types})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unwrap(self, ret_fun, err_fun):\n    for opt in self.CHOICES:\n      if isinstance(self._value, opt):\n        return ret_fun(self._value)\n      else:\n        try:\n          o = opt(self._value)\n          ret = ret_fun(o)\n          if ret:\n            return ret\n        except (self.CoercionError, ValueError):\n          pass\n    return err_fun(self._value)", "response": "Unwrap the value of a node in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noutput formatted as list item.", "response": "def outitem(title, elems, indent=4):\n    \"\"\"Output formatted as list item.\"\"\"\n    out(title)\n    max_key_len = max(len(key) for key, _ in elems) + 1\n    for key, val in elems:\n        key_spaced = ('%s:' % key).ljust(max_key_len)\n        out('%s%s %s' % (indent * ' ', key_spaced, val))\n    out()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns path to FF profile for a given profile name or path.", "response": "def profile_dir(name):\n    \"\"\"Return path to FF profile for a given profile name or path.\"\"\"\n    if name:\n        possible_path = Path(name)\n        if possible_path.exists():\n            return possible_path\n    profiles = list(read_profiles())\n    try:\n        if name:\n            profile = next(p for p in profiles if p.name == name)\n        else:\n            profile = next(p for p in profiles if p.default)\n    except StopIteration:\n        raise ProfileNotFoundError(name)\n    return profile.path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef arg(*args, **kwargs):\n    metadata = {'arg_params': (args, kwargs)}\n    return attrib(default=arg_default(*args, **kwargs), metadata=metadata)", "response": "Return an attrib that can be fed as a command - line argument."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arg_default(*args, **kwargs):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(*args, **kwargs)\n    args = vars(parser.parse_args([]))\n    _, default = args.popitem()\n    return default", "response": "Return default argument value as given by argparse s add_argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef formatter(name, default=False):\n    def decorator(func):\n        func._output_format = dict(name=name, default=default)\n        return func\n    return decorator", "response": "Decorator to register a Feature method to register it as an output formatter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading data from sqlite db and return as list of specified objects.", "response": "def load_sqlite(self, db, query=None, table=None, cls=None,\n                    column_map=None):\n        \"\"\"Load data from sqlite db and return as list of specified objects.\"\"\"\n        if column_map is None:\n            column_map = {}\n        db_path = self.profile_path(db, must_exist=True)\n\n        def obj_factory(cursor, row):\n            dict_ = {}\n            for idx, col in enumerate(cursor.description):\n                new_name = column_map.get(col[0], col[0])\n                dict_[new_name] = row[idx]\n            return cls(**dict_)\n\n        con = sqlite3.connect(str(db_path))\n        con.row_factory = obj_factory\n        cursor = con.cursor()\n        if not query:\n            columns = [f.name for f in attr.fields(cls)]\n            for k, v in column_map.items():\n                columns[columns.index(v)] = k\n            query = 'SELECT %s FROM %s' % (','.join(columns), table)\n        cursor.execute(query)\n        while True:\n            item = cursor.fetchone()\n            if item is None:\n                break\n            yield item\n        con.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_json(self, path):\n        with open(self.profile_path(path, must_exist=True),\n                  encoding='utf-8') as f:\n            data = json.load(f)\n        return data", "response": "Load a JSON file from the user profile."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_mozlz4(self, path):\n        with open(self.profile_path(path, must_exist=True), 'rb') as f:\n            if f.read(8) != b'mozLz40\\0':\n                raise NotMozLz4Error('Not Mozilla LZ4 format.')\n            data = lz4.block.decompress(f.read())\n        return data", "response": "Load a Mozilla LZ4 file from the user profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a list of items to stream in CSV format.", "response": "def csv_from_items(items, stream=None):\n        \"\"\"Write a list of items to stream in CSV format.\n\n        The items need to be attrs-decorated.\n        \"\"\"\n        items = iter(items)\n        first = next(items)\n        cls = first.__class__\n        if stream is None:\n            stream = sys.stdout\n        fields = [f.name for f in attr.fields(cls)]\n        writer = csv.DictWriter(stream, fieldnames=fields)\n        writer.writeheader()\n        writer.writerow(attr.asdict(first))\n        writer.writerows((attr.asdict(x) for x in items))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning path from current profile.", "response": "def profile_path(self, path, must_exist=False):\n        \"\"\"Return path from current profile.\"\"\"\n        full_path = self.session.profile / path\n        if must_exist and not full_path.exists():\n            raise FileNotFoundError(\n                errno.ENOENT,\n                os.strerror(errno.ENOENT),\n                PurePath(full_path).name,\n            )\n        return full_path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_rpc_call(self, rpc_command):\n        # ~~~ hack: ~~~\n        if not self.is_alive():\n            self.close()  # force close for safety\n            self.open()  # reopen\n        # ~~~ end hack ~~~\n        result = self._execute_rpc(rpc_command)\n        return ET.tostring(result)", "response": "Send an RPC command to the device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self):\n        try:\n            self.device = ConnectHandler(device_type='cisco_xr',\n                                         ip=self.hostname,\n                                         port=self.port,\n                                         username=self.username,\n                                         password=self.password,\n                                         **self.netmiko_kwargs)\n            self.device.timeout = self.timeout\n            self._xml_agent_alive = True  # successfully open thus alive\n        except NetMikoTimeoutException as t_err:\n            raise ConnectError(t_err.args[0])\n        except NetMikoAuthenticationException as au_err:\n            raise ConnectError(au_err.args[0])\n\n        self._cli_prompt = self.device.find_prompt()  # get the prompt\n        self._enter_xml_mode()", "response": "Open a connection to an IOS - XR device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_alive(self):\n        if hasattr(self.device, 'remote_conn'):\n            return self.device.remote_conn.transport.is_active() and self._xml_agent_alive\n        return False", "response": "Returns the state of the XML agent and SSH connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _execute_show(self, show_command):\n        rpc_command = '<CLI><Exec>{show_command}</Exec></CLI>'.format(\n            show_command=escape_xml(show_command)\n        )\n        response = self._execute_rpc(rpc_command)\n        raw_response = response.xpath('.//CLI/Exec')[0].text\n        return raw_response.strip() if raw_response else ''", "response": "Executes an operational show - type command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a configuration show - type command.", "response": "def _execute_config_show(self, show_command, delay_factor=.1):\n        \"\"\"\n        Executes a configuration show-type command.\n        \"\"\"\n        rpc_command = '<CLI><Configuration>{show_command}</Configuration></CLI>'.format(\n            show_command=escape_xml(show_command)\n        )\n        response = self._execute_rpc(rpc_command, delay_factor=delay_factor)\n        raw_response = response.xpath('.//CLI/Configuration')[0].text\n        return raw_response.strip() if raw_response else ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close(self):\n        if self.lock_on_connect or self.locked:\n            self.unlock()  # this refers to the config DB\n        self._unlock_xml_agent()  # this refers to the XML agent\n        if hasattr(self.device, 'remote_conn'):\n            self.device.remote_conn.close()", "response": "Closes the IOS - XR device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self):\n        if not self.locked:\n            rpc_command = '<Lock/>'\n            try:\n                self._execute_rpc(rpc_command)\n            except XMLCLIError:\n                raise LockError('Unable to enter in configure exclusive mode!', self)\n            self.locked = True", "response": "Lock the config database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunlock the IOS - XR device config.", "response": "def unlock(self):\n        \"\"\"\n        Unlock the IOS-XR device config.\n\n        Use if Locking/Unlocking is not performaed automatically by lock=False\n        \"\"\"\n        if self.locked:\n            rpc_command = '<Unlock/>'\n            try:\n                self._execute_rpc(rpc_command)\n            except XMLCLIError:\n                raise UnlockError('Unable to unlock the config!', self)\n            self.locked = False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading candidate confguration. Populate the attribute candidate_config with the desired configuration and loads it into the router. You can populate it from a file or from a string. If you send both a filename and a string containing the configuration, the file takes precedence. :param filename: Path to the file containing the desired configuration. By default is None. :param config: String containing the desired configuration.", "response": "def load_candidate_config(self, filename=None, config=None):\n        \"\"\"\n        Load candidate confguration.\n\n        Populate the attribute candidate_config with the desired\n        configuration and loads it into the router. You can populate it from\n        a file or from a string. If you send both a filename and a string\n        containing the configuration, the file takes precedence.\n\n        :param filename:  Path to the file containing the desired\n                          configuration. By default is None.\n        :param config:    String containing the desired configuration.\n        \"\"\"\n        configuration = ''\n\n        if filename is None:\n            configuration = config\n        else:\n            with open(filename) as f:\n                configuration = f.read()\n\n        rpc_command = '<CLI><Configuration>{configuration}</Configuration></CLI>'.format(\n            configuration=escape_xml(configuration)  # need to escape, otherwise will try to load invalid XML\n        )\n\n        try:\n            self._execute_rpc(rpc_command)\n        except InvalidInputError as e:\n            self.discard_config()\n            raise InvalidInputError(e.args[0], self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_candidate_config(self, merge=False, formal=False):\n        command = \"show configuration\"\n        if merge:\n            command += \" merge\"\n        if formal:\n            command += \" formal\"\n        response = self._execute_config_show(command)\n\n        match = re.search(\".*(!! IOS XR Configuration.*)$\", response, re.DOTALL)\n        if match is not None:\n            response = match.group(1)\n\n        return response", "response": "Retrieve the configuration loaded as candidate config in the IOS - XR configuration session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare_config(self):\n        _show_merge = self._execute_config_show('show configuration merge')\n        _show_run = self._execute_config_show('show running-config')\n\n        diff = difflib.unified_diff(_show_run.splitlines(1)[2:-2], _show_merge.splitlines(1)[2:-2])\n        return ''.join([x.replace('\\r', '') for x in diff])", "response": "Compare the loaded config with the running config and return a diff."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit_config(self, label=None, comment=None, confirmed=None):\n        rpc_command = '<Commit'\n        if label:\n            rpc_command += ' Label=\"%s\"' % label\n        if comment:\n            rpc_command += ' Comment=\"%s\"' % comment[:60]\n        if confirmed:\n            if 30 <= int(confirmed) <= 300:\n                rpc_command += ' Confirmed=\"%d\"' % int(confirmed)\n            else:\n                raise InvalidInputError('confirmed needs to be between 30 and 300 seconds', self)\n        rpc_command += '/>'\n\n        self._execute_rpc(rpc_command)", "response": "Commit the candidate config."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ok(prompt='OK ', loc={}, glo={}, cmd=\"\"):\n    '''\n    Invoke the peforth interpreter.\n    An statement: peforth.ok(prompt='OK ', loc=locals(), glo=globals(), cmd=\"\") \n    is like a breakpoint. The prompt indicates which breakpoint it is if there are \n    many. Arguments loc (locals) and glo (globals) along with the prompt are the \n    debuggee's informations that is packed as a tuple (loc,glo,prompt) left on TOS \n    of the FORTH vm when the breakpoint is called. Replace the loc=locals() with\n    loc=dict(locals()) to get a snapshot copy instead of a reference, as well as \n    the glo. 'exit' command to stop debugging.\n    '''\n    if loc or glo: vm.push((loc,glo,prompt))  # parent's data\n    while True:\n        if cmd == \"\":                                    #\n            if vm.tick('accept') and not vm.multiple:    # Input can be single line (default) or\n                vm.execute('accept')                     # multiple lines. Press Ctrl-D to toggle\n                cmd = vm.pop().strip()                   # between the two modes. Place a Ctrl-D\n            elif vm.tick('<accept>') and vm.multiple:    # before the last <Enter> key to end the\n                vm.execute('<accept>')                   # input when in multiple-line mode.\n                cmd = vm.pop().strip()                   #\n            else:                                        #\n                cmd = input(\"\").strip()                  #\n\n        # pass the command line to forth VM\n        if cmd == \"\":\n            print(prompt, end=\"\")\n            continue\n        elif cmd == chr(4):\n            vm.multiple = not vm.multiple\n            if not vm.multiple: print(prompt, end=\"\")\n        else:\n            vm.dictate(cmd)\n            if vm.multiple: vm.multiple = False # switch back to the normal mode\n            print(prompt, end=\"\")\n        cmd = \"\"\n        # Master switch vm.exit is a flag of boolean. When it's True\n        # then exit to the caller that usually is python interpreter.\n        if vm.exit:\n            vm.exit = False # Avoid exit immediately when called again\n            break\n    return(vm) # support function cascade", "response": "Invoke the PEFORTH interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _main():\n    import sys\n\n    def log(message):\n        print(message)\n\n    def print_usage():\n        log('usage: %s <application key> <application secret> send <number> <message> <from_number>' % sys.argv[0])\n        log('       %s <application key> <application secret> status <message_id>' % sys.argv[0])\n\n    if len(sys.argv) > 4 and sys.argv[3] == 'send':\n        key, secret, number, message = sys.argv[1], sys.argv[2], sys.argv[4], sys.argv[5]\n        client = SinchSMS(key, secret)\n        if len(sys.argv) > 6:\n            log(client.send_message(number, message, sys.argv[6]))\n        else:\n            log(client.send_message(number, message))\n    elif len(sys.argv) > 3 and sys.argv[3] == 'status':\n        key, secret, message_id = sys.argv[1], sys.argv[2], sys.argv[4]\n        client = SinchSMS(key, secret)\n        log(client.check_status(message_id))\n    else:\n        print_usage()\n        sys.exit(1)\n\n    sys.exit(0)", "response": "A simple demo to be used from command line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a request and read response.", "response": "def _request(self, url, values=None):\n        \"\"\" Send a request and read response.\n\n            Sends a get request if values are None, post request otherwise.\n        \"\"\"\n        if values:\n            json_data = json.dumps(values)\n            request = urllib2.Request(url, json_data.encode())\n            request.add_header('content-type', 'application/json')\n            request.add_header('authorization', self._auth)\n            connection = urllib2.urlopen(request)\n            response = connection.read()\n            connection.close()\n        else:\n            request = urllib2.Request(url)\n            request.add_header('authorization', self._auth)\n            connection = urllib2.urlopen(request)\n            response = connection.read()\n            connection.close()\n\n        try:\n            result = json.loads(response.decode())\n        except ValueError as exception:\n            return {'errorCode': 1, 'message': str(exception)}\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(self, to_number, message, from_number=None):\n\n        values = {'Message': message}\n        if from_number is not None:\n            values['From'] = from_number\n\n        return self._request(self.SEND_SMS_URL + to_number, values)", "response": "Send a message to the specified number and return a response dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a BigQuery - level descriptor to a BigQuery - level descriptor.", "response": "def convert_descriptor(self, descriptor):\n        \"\"\"Convert descriptor to BigQuery\n        \"\"\"\n\n        # Fields\n        fields = []\n        fallbacks = []\n        schema = tableschema.Schema(descriptor)\n        for index, field in enumerate(schema.fields):\n            converted_type = self.convert_type(field.type)\n            if not converted_type:\n                converted_type = 'STRING'\n                fallbacks.append(index)\n            mode = 'NULLABLE'\n            if field.required:\n                mode = 'REQUIRED'\n            fields.append({\n                'name': _slugify_field_name(field.name),\n                'type': converted_type,\n                'mode': mode,\n            })\n\n        # Descriptor\n        converted_descriptor = {\n            'fields': fields,\n        }\n\n        return (converted_descriptor, fallbacks)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a row to BigQuery", "response": "def convert_row(self, row, schema, fallbacks):\n        \"\"\"Convert row to BigQuery\n        \"\"\"\n        for index, field in enumerate(schema.fields):\n            value = row[index]\n            if index in fallbacks:\n                value = _uncast_value(value, field=field)\n            else:\n                value = field.cast_value(value)\n            row[index] = value\n        return row"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_type(self, type):\n\n        # Mapping\n        mapping = {\n            'any': 'STRING',\n            'array': None,\n            'boolean': 'BOOLEAN',\n            'date': 'DATE',\n            'datetime': 'DATETIME',\n            'duration': None,\n            'geojson': None,\n            'geopoint': None,\n            'integer': 'INTEGER',\n            'number': 'FLOAT',\n            'object': None,\n            'string': 'STRING',\n            'time': 'TIME',\n            'year': 'INTEGER',\n            'yearmonth': None,\n        }\n\n        # Not supported type\n        if type not in mapping:\n            message = 'Type %s is not supported' % type\n            raise tableschema.exceptions.StorageError(message)\n\n        return mapping[type]", "response": "Convert type to BigQuery\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrestores descriptor rom BigQuery", "response": "def restore_descriptor(self, converted_descriptor):\n        \"\"\"Restore descriptor rom BigQuery\n        \"\"\"\n\n        # Convert\n        fields = []\n        for field in converted_descriptor['fields']:\n            field_type = self.restore_type(field['type'])\n            resfield = {\n                'name': field['name'],\n                'type': field_type,\n            }\n            if field.get('mode', 'NULLABLE') != 'NULLABLE':\n                resfield['constraints'] = {'required': True}\n            fields.append(resfield)\n        descriptor = {'fields': fields}\n\n        return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore_row(self, row, schema):\n        for index, field in enumerate(schema.fields):\n            if field.type == 'datetime':\n                row[index] = parse(row[index])\n            if field.type == 'date':\n                row[index] = parse(row[index]).date()\n            if field.type == 'time':\n                row[index] = parse(row[index]).time()\n        return schema.cast_row(row)", "response": "Restore row from BigQuery\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestore type from BigQuery", "response": "def restore_type(self, type):\n        \"\"\"Restore type from BigQuery\n        \"\"\"\n\n        # Mapping\n        mapping = {\n            'BOOLEAN': 'boolean',\n            'DATE': 'date',\n            'DATETIME': 'datetime',\n            'INTEGER': 'integer',\n            'FLOAT': 'number',\n            'STRING': 'string',\n            'TIME': 'time',\n        }\n\n        # Not supported type\n        if type not in mapping:\n            message = 'Type %s is not supported' % type\n            raise tableschema.exceptions.StorageError(message)\n\n        return mapping[type]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all buckets in the dataset.", "response": "def buckets(self):\n        \"\"\"https://github.com/frictionlessdata/tableschema-bigquery-py#storage\n        \"\"\"\n\n        # No cached value\n        if self.__buckets is None:\n\n            # Get response\n            response = self.__service.tables().list(\n                projectId=self.__project,\n                datasetId=self.__dataset).execute()\n\n            # Extract buckets\n            self.__buckets = []\n            for table in response.get('tables', []):\n                table_name = table['tableReference']['tableId']\n                bucket = self.__mapper.restore_bucket(table_name)\n                if bucket is not None:\n                    self.__buckets.append(bucket)\n\n        return self.__buckets"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, bucket, descriptor, force=False):\n\n        # Make lists\n        buckets = bucket\n        if isinstance(bucket, six.string_types):\n            buckets = [bucket]\n        descriptors = descriptor\n        if isinstance(descriptor, dict):\n            descriptors = [descriptor]\n\n        # Iterate over buckets/descriptors\n        for bucket, descriptor in zip(buckets, descriptors):\n\n            # Existent bucket\n            if bucket in self.buckets:\n                if not force:\n                    message = 'Bucket \"%s\" already exists' % bucket\n                    raise tableschema.exceptions.StorageError(message)\n                self.delete(bucket)\n\n            # Prepare job body\n            tableschema.validate(descriptor)\n            table_name = self.__mapper.convert_bucket(bucket)\n            converted_descriptor, fallbacks = self.__mapper.convert_descriptor(descriptor)\n            body = {\n                'tableReference': {\n                    'projectId': self.__project,\n                    'datasetId': self.__dataset,\n                    'tableId': table_name,\n                },\n                'schema': converted_descriptor,\n            }\n\n            # Make request\n            self.__service.tables().insert(\n                projectId=self.__project,\n                datasetId=self.__dataset,\n                body=body).execute()\n\n            # Add to descriptors/fallbacks\n            self.__descriptors[bucket] = descriptor\n            self.__fallbacks[bucket] = fallbacks\n\n        # Remove buckets cache\n        self.__buckets = None", "response": "Create a new object in the storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, bucket=None, ignore=False):\n\n        # Make lists\n        buckets = bucket\n        if isinstance(bucket, six.string_types):\n            buckets = [bucket]\n        elif bucket is None:\n            buckets = reversed(self.buckets)\n\n        # Iterater over buckets\n        for bucket in buckets:\n\n            # Non-existent bucket\n            if bucket not in self.buckets:\n                if not ignore:\n                    message = 'Bucket \"%s\" doesn\\'t exist.' % bucket\n                    raise tableschema.exceptions.StorageError(message)\n                return\n\n            # Remove from descriptors\n            if bucket in self.__descriptors:\n                del self.__descriptors[bucket]\n\n            # Make delete request\n            table_name = self.__mapper.convert_bucket(bucket)\n            self.__service.tables().delete(\n                projectId=self.__project,\n                datasetId=self.__dataset,\n                tableId=table_name).execute()\n\n        # Remove tables cache\n        self.__buckets = None", "response": "Delete the object from the specified bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef describe(self, bucket, descriptor=None):\n\n        # Set descriptor\n        if descriptor is not None:\n            self.__descriptors[bucket] = descriptor\n\n        # Get descriptor\n        else:\n            descriptor = self.__descriptors.get(bucket)\n            if descriptor is None:\n                table_name = self.__mapper.convert_bucket(bucket)\n                response = self.__service.tables().get(\n                    projectId=self.__project,\n                    datasetId=self.__dataset,\n                    tableId=table_name).execute()\n                converted_descriptor = response['schema']\n                descriptor = self.__mapper.restore_descriptor(converted_descriptor)\n\n        return descriptor", "response": "Get descriptor for a bucket."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over the items in a bucket.", "response": "def iter(self, bucket):\n        \"\"\"https://github.com/frictionlessdata/tableschema-bigquery-py#storage\n        \"\"\"\n\n        # Get schema/data\n        schema = tableschema.Schema(self.describe(bucket))\n        table_name = self.__mapper.convert_bucket(bucket)\n        response = self.__service.tabledata().list(\n            projectId=self.__project,\n            datasetId=self.__dataset,\n            tableId=table_name).execute()\n\n        # Collect rows\n        rows = []\n        for fields in response['rows']:\n            row = [field['v'] for field in fields['f']]\n            rows.append(row)\n\n        # Sort rows\n        # TODO: provide proper sorting solution\n        rows = sorted(rows, key=lambda row: row[0] if row[0] is not None else 'null')\n\n        # Emit rows\n        for row in rows:\n            row = self.__mapper.restore_row(row, schema=schema)\n            yield row"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the rows to the bigquery table.", "response": "def write(self, bucket, rows):\n        \"\"\"https://github.com/frictionlessdata/tableschema-bigquery-py#storage\n        \"\"\"\n\n        # Write buffer\n        BUFFER_SIZE = 10000\n\n        # Prepare schema, fallbacks\n        schema = tableschema.Schema(self.describe(bucket))\n        fallbacks = self.__fallbacks.get(bucket, [])\n\n        # Write data\n        rows_buffer = []\n        for row in rows:\n            row = self.__mapper.convert_row(row, schema=schema, fallbacks=fallbacks)\n            rows_buffer.append(row)\n            if len(rows_buffer) > BUFFER_SIZE:\n                self.__write_rows_buffer(bucket, rows_buffer)\n                rows_buffer = []\n        if len(rows_buffer) > 0:\n            self.__write_rows_buffer(bucket, rows_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_securities(self, page=1, **filter_param):\n        url_path = self._build_url_path(None, None)\n        params = {'page': page}\n        # the endpoints respond just fine to invaliid query params,\n        # they just ignore them, but the the real value of the endpoints\n        # is only revealed when using the filters, so let's not waste\n        # requests on filters that don't do anything.\n        if filter_param:\n            query_filter = filter_param.popitem()\n            if query_filter[0] in self.VALID_SECURITY_FILTERS:\n                params[query_filter[0]] = query_filter[1]\n            else:\n                error_msg = 'Invalid filter param. Must be one of: {0}'.format(','.join(self.VALID_SECURITY_FILTERS))\n                raise exceptions.PyChartsRequestException(error_msg)\n\n        return self._get_data(url_path, params)", "response": "Queries the catalythmmss endpoint to return a paged\n        list of securities."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries data from a / security_type > points endpoint.", "response": "def get_points(self, security_symbols, calculation_codes, query_date=None):\n        \"\"\"\n        Queries data from a /<security_type>/points endpoint.\n\n        Args:\n            security_symbols (list): List of string symbols\n            calculation_codes (list): List og string calculation codes\n            query_date\n                (datetime): datetime object on or before which the endpoint will query data for.\n                (int): Negative integer representing relative periods(as it relates to each calc code) in the past.\n\n        Returns:\n            dict of the decoded json from server response.\n\n        Notes:\n            The max length of any list arg is 100\n        \"\"\"\n        security_symbols = self._str_or_list(security_symbols)\n        calculation_codes = self._str_or_list(calculation_codes)\n\n        url_path = self._build_url_path(security_symbols,\n            'points', calculation_codes)\n\n        if query_date:\n            params = {'date': self._format_query_date_for_url(query_date)}\n        else:\n            params = None\n\n        return self._get_data(url_path, params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying a series endpoint.", "response": "def get_series(self, security_symbols, calculation_codes, query_start_date=None, query_end_date=None,\n        resample_frequency=None, resample_function=None, fill_method=None, aggregate_function=None):\n        \"\"\"\n        Queries data from a /<security_type>/series endpoint.\n\n        Args:\n            security_symbols (list): List of string symbols\n            calculation_codes (list): List og string calculation codes\n            query_start_date\n                (datetime): date after which the endpoint will query data for.\n                (int): Negative integer representing relative periods(as it relates to each calc code) in the past.\n            query_end_date\n                (datetime): date on or before which the endpoint will query data for. \n                (int): Negative integer representing relative periods(as it relates to each calc code) in the past.\n\n        Returns:\n            dict of the decoded json from server response.\n\n        Notes:\n            The max length of any list arg is 100\n        \"\"\"\n        security_symbols = self._str_or_list(security_symbols)\n        calculation_codes = self._str_or_list(calculation_codes)\n\n        url_path = self._build_url_path(security_symbols, \n            'series', calculation_codes)\n\n        params = {}\n        if query_start_date:\n            params['start_date'] = self._format_query_date_for_url(query_start_date)\n        if query_end_date:\n            params['end_date'] = self._format_query_date_for_url(query_end_date)\n        if resample_frequency:\n            params['resample_frequency'] = resample_frequency\n        if resample_function:\n            params['resample_function'] = resample_function\n        if fill_method:\n            params['fill_method'] = fill_method\n        if aggregate_function:\n            params['aggregate_function'] = aggregate_function\n\n        return self._get_data(url_path, params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery data from a / info endpoint.", "response": "def get_info(self, security_symbols, info_field_codes):\n        \"\"\"\n        Queries data from a /<security_type>/info endpoint.\n\n        Args:\n            security_symbols (list): List of string symbols\n            info_field_codes (list): List of string info field codes\n\n        Returns:\n            dict of the decoded json from server response.\n\n        Notes:\n            The max length of any list arg is 100\n\n        \"\"\"\n        security_symbols = self._str_or_list(security_symbols)\n        info_field_codes = self._str_or_list(info_field_codes)\n\n        url_path = self._build_url_path(security_symbols,\n            'info', info_field_codes)\n\n        return self._get_data(url_path, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, expr, simplify=False):\n\n        precedence = {self.NOT: 5, self.AND: 10, self.OR: 15, TOKEN_LPAR: 20}\n\n        if isinstance(expr, basestring):\n            tokenized = self.tokenize(expr)\n        else:\n            tokenized = iter(expr)\n\n        if TRACE_PARSE:\n            tokenized = list(tokenized)\n            print('tokens:')\n            map(print, tokenized)\n            tokenized = iter(tokenized)\n\n        # the abstract syntax tree for this expression that will be build as we\n        # process tokens\n        # the first two items are None\n        # symbol items are appended to this structure\n        ast = [None, None]\n\n        def is_sym(_t):\n            return isinstance(_t, Symbol) or _t in (TOKEN_TRUE, TOKEN_FALSE, TOKEN_SYMBOL)\n\n        def is_operator(_t):\n            return _t in (TOKEN_AND, TOKEN_OR)\n\n        prev_token = None\n        for token_type, token_string, token_position in tokenized:\n            if TRACE_PARSE:\n                print('\\nprocessing token_type:', repr(token_type), 'token_string:', repr(token_string), 'token_position:', repr(token_position))\n\n            if prev_token:\n                prev_token_type, _prev_token_string, _prev_token_position = prev_token\n                if TRACE_PARSE:\n                    print('  prev_token:', repr(prev_token))\n\n                if is_sym(prev_token_type) and (is_sym(token_type)):  # or token_type == TOKEN_LPAR) :\n                    raise ParseError(token_type, token_string, token_position, PARSE_INVALID_SYMBOL_SEQUENCE)\n\n                if is_operator(prev_token_type) and (is_operator(token_type) or token_type == TOKEN_RPAR):\n                    raise ParseError(token_type, token_string, token_position, PARSE_INVALID_OPERATOR_SEQUENCE)\n\n            else:\n                if is_operator(token_type):\n                    raise ParseError(token_type, token_string, token_position, PARSE_INVALID_OPERATOR_SEQUENCE)\n\n            if token_type == TOKEN_SYMBOL:\n                ast.append(self.Symbol(token_string))\n                if TRACE_PARSE:\n                    print(' ast: token_type is TOKEN_SYMBOL: append new symbol', repr(ast))\n\n            elif isinstance(token_type, Symbol):\n                ast.append(token_type)\n                if TRACE_PARSE:\n                    print(' ast: token_type is Symbol): append existing symbol', repr(ast))\n\n            elif token_type == TOKEN_TRUE:\n                ast.append(self.TRUE)\n                if TRACE_PARSE: print(' ast: token_type is TOKEN_TRUE:', repr(ast))\n\n            elif token_type == TOKEN_FALSE:\n                ast.append(self.FALSE)\n                if TRACE_PARSE: print(' ast: token_type is TOKEN_FALSE:', repr(ast))\n\n            elif token_type == TOKEN_NOT:\n                ast = [ast, self.NOT]\n                if TRACE_PARSE: print(' ast: token_type is TOKEN_NOT:', repr(ast))\n\n            elif token_type == TOKEN_AND:\n#                if not prev_token or not is_sym(prev_token_type):\n#                    raise ParseError(token_type, token_string, token_position, PARSE_INVALID_OPERATOR_SEQUENCE)\n\n                ast = self._start_operation(ast, self.AND, precedence)\n                if TRACE_PARSE:\n                    print('  ast:token_type is TOKEN_AND: start_operation', ast)\n\n            elif token_type == TOKEN_OR:\n#                if not prev_token or not is_sym(prev_token_type):\n#                    raise ParseError(token_type, token_string, token_position, PARSE_INVALID_OPERATOR_SEQUENCE)\n\n                ast = self._start_operation(ast, self.OR, precedence)\n                if TRACE_PARSE:\n                    print('  ast:token_type is TOKEN_OR: start_operation', ast)\n\n            elif token_type == TOKEN_LPAR:\n                if prev_token:\n                    # Check that an opening parens is preceded by a function\n                    # or an opening parens\n                    if prev_token_type not in (TOKEN_NOT, TOKEN_AND, TOKEN_OR, TOKEN_LPAR):\n                        raise ParseError(token_type, token_string, token_position, PARSE_INVALID_NESTING)\n                ast = [ast, TOKEN_LPAR]\n\n            elif token_type == TOKEN_RPAR:\n                while True:\n                    if ast[0] is None:\n                        raise ParseError(token_type, token_string, token_position, PARSE_UNBALANCED_CLOSING_PARENS)\n\n                    if ast[1] is TOKEN_LPAR:\n                        ast[0].append(ast[2])\n                        if TRACE_PARSE: print('ast9:', repr(ast))\n                        ast = ast[0]\n                        if TRACE_PARSE: print('ast10:', repr(ast))\n                        break\n\n                    if isinstance(ast[1], int):\n                        raise ParseError(token_type, token_string, token_position, PARSE_UNBALANCED_CLOSING_PARENS)\n\n                    # the parens are properly nested\n                    # the top ast node should be a function subclass\n                    if not (inspect.isclass(ast[1]) and issubclass(ast[1], Function)):\n                        raise ParseError(token_type, token_string, token_position, PARSE_INVALID_NESTING)\n\n                    subex = ast[1](*ast[2:])\n                    ast[0].append(subex)\n                    if TRACE_PARSE: print('ast11:', repr(ast))\n                    ast = ast[0]\n                    if TRACE_PARSE: print('ast12:', repr(ast))\n            else:\n                raise ParseError(token_type, token_string, token_position, PARSE_UNKNOWN_TOKEN)\n\n            prev_token = (token_type, token_string, token_position)\n\n        try:\n            while True:\n                if ast[0] is None:\n                    if TRACE_PARSE: print('ast[0] is None:', repr(ast))\n                    if ast[1] is None:\n                        if TRACE_PARSE: print('  ast[1] is None:', repr(ast))\n                        if len(ast) != 3:\n                            raise ParseError(error_code=PARSE_INVALID_EXPRESSION)\n                        parsed = ast[2]\n                        if TRACE_PARSE: print('    parsed = ast[2]:', repr(parsed))\n\n                    else:\n                        # call the function in ast[1] with the rest of the ast as args\n                        parsed = ast[1](*ast[2:])\n                        if TRACE_PARSE: print('  parsed = ast[1](*ast[2:]):', repr(parsed))\n                    break\n                else:\n                    if TRACE_PARSE: print('subex = ast[1](*ast[2:]):', repr(ast))\n                    subex = ast[1](*ast[2:])\n                    ast[0].append(subex)\n                    if TRACE_PARSE: print('  ast[0].append(subex):', repr(ast))\n                    ast = ast[0]\n                    if TRACE_PARSE: print('    ast = ast[0]:', repr(ast))\n        except TypeError:\n            raise ParseError(error_code=PARSE_INVALID_EXPRESSION)\n\n        if simplify:\n            return parsed.simplify()\n\n        if TRACE_PARSE: print('final parsed:', repr(parsed))\n        return parsed", "response": "Parse an expression into a boolean expression."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start_operation(self, ast, operation, precedence):\n        if TRACE_PARSE:\n            print('   start_operation:', repr(operation), 'AST:', ast)\n\n        op_prec = precedence[operation]\n        while True:\n            if ast[1] is None:\n                # [None, None, x]\n                if TRACE_PARSE: print('     start_op: ast[1] is None:', repr(ast))\n                ast[1] = operation\n                if TRACE_PARSE: print('     --> start_op: ast[1] is None:', repr(ast))\n                return ast\n\n            prec = precedence[ast[1]]\n            if prec > op_prec:  # op=&, [ast, |, x, y] -> [[ast, |, x], &, y]\n                if TRACE_PARSE: print('     start_op: prec > op_prec:', repr(ast))\n                ast = [ast, operation, ast.pop(-1)]\n                if TRACE_PARSE: print('     --> start_op: prec > op_prec:', repr(ast))\n                return ast\n\n            if prec == op_prec:  # op=&, [ast, &, x] -> [ast, &, x]\n                if TRACE_PARSE: print('     start_op: prec == op_prec:', repr(ast))\n                return ast\n\n            if not (inspect.isclass(ast[1]) and issubclass(ast[1], Function)):\n                # the top ast node should be a function subclass at this stage\n                raise ParseError(error_code=PARSE_INVALID_NESTING)\n\n            if ast[0] is None:  # op=|, [None, &, x, y] -> [None, |, x&y]\n                if TRACE_PARSE: print('     start_op: ast[0] is None:', repr(ast))\n                subexp = ast[1](*ast[2:])\n                new_ast = [ast[0], operation, subexp]\n                if TRACE_PARSE: print('     --> start_op: ast[0] is None:', repr(new_ast))\n                return new_ast\n\n            else:  # op=|, [[ast, &, x], ~, y] -> [ast, &, x, ~y]\n                if TRACE_PARSE: print('     start_op: else:', repr(ast))\n                ast[0].append(ast[1](*ast[2:]))\n                ast = ast[0]\n                if TRACE_PARSE: print('     --> start_op: else:', repr(ast))", "response": "Return an AST where all operations of lower precedence are finalized."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterable of 3-tuple describing each token given an expression unicode string. This 3-tuple contains (token, token string, position): - token: either a Symbol instance or one of TOKEN_* token types. - token string: the original token unicode string. - position: some simple object describing the starting position of the original token string in the `expr` string. It can be an int for a character offset, or a tuple of starting (row/line, column). The token position is used only for error reporting and can be None or empty. Raise ParseError on errors. The ParseError.args is a tuple of: (token_string, position, error message) You can use this tokenizer as a base to create specialized tokenizers for your custom algebra by subclassing BooleanAlgebra. See also the tests for other examples of alternative tokenizers. This tokenizer has these characteristics: - The `expr` string can span multiple lines, - Whitespace is not significant. - The returned position is the starting character offset of a token. - A TOKEN_SYMBOL is returned for valid identifiers which is a string without spaces. These are valid identifiers: - Python identifiers. - a string even if starting with digits - digits (except for 0 and 1). - dotted names : foo.bar consist of one token. - names with colons: foo:bar consist of one token. These are not identifiers: - quoted strings. - any punctuation which is not an operation - Recognized operators are (in any upper/lower case combinations): - for and: '*', '&', 'and' - for or: '+', '|', 'or' - for not: '~', '!', 'not' - Recognized special symbols are (in any upper/lower case combinations): - True symbols: 1 and True - False symbols: 0, False and None", "response": "def tokenize(self, expr):\n        \"\"\"\n        Return an iterable of 3-tuple describing each token given an expression\n        unicode string.\n\n        This 3-tuple contains (token, token string, position):\n        - token: either a Symbol instance or one of TOKEN_* token types.\n        - token string: the original token unicode string.\n        - position: some simple object describing the starting position of the\n          original token string in the `expr` string. It can be an int for a\n          character offset, or a tuple of starting (row/line, column).\n\n        The token position is used only for error reporting and can be None or\n        empty.\n\n        Raise ParseError on errors. The ParseError.args is a tuple of:\n        (token_string, position, error message)\n\n        You can use this tokenizer as a base to create specialized tokenizers\n        for your custom algebra by subclassing BooleanAlgebra. See also the\n        tests for other examples of alternative tokenizers.\n\n        This tokenizer has these characteristics:\n        - The `expr` string can span multiple lines,\n        - Whitespace is not significant.\n        - The returned position is the starting character offset of a token.\n\n        - A TOKEN_SYMBOL is returned for valid identifiers which is a string\n        without spaces. These are valid identifiers:\n            - Python identifiers.\n            - a string even if starting with digits\n            - digits (except for 0 and 1).\n            - dotted names : foo.bar consist of one token.\n            - names with colons: foo:bar consist of one token.\n            These are not identifiers:\n            - quoted strings.\n            - any punctuation which is not an operation\n\n        - Recognized operators are (in any upper/lower case combinations):\n            - for and:  '*', '&', 'and'\n            - for or: '+', '|', 'or'\n            - for not: '~', '!', 'not'\n\n        - Recognized special symbols are (in any upper/lower case combinations):\n            - True symbols: 1 and True\n            - False symbols: 0, False and None\n        \"\"\"\n        if not isinstance(expr, basestring):\n            raise TypeError('expr must be string but it is %s.' % type(expr))\n\n        # mapping of lowercase token strings to a token type id for the standard\n        # operators, parens and common true or false symbols, as used in the\n        # default tokenizer implementation.\n        TOKENS = {\n            '*': TOKEN_AND, '&': TOKEN_AND, 'and': TOKEN_AND,\n            '+': TOKEN_OR, '|': TOKEN_OR, 'or': TOKEN_OR,\n            '~': TOKEN_NOT, '!': TOKEN_NOT, 'not': TOKEN_NOT,\n            '(': TOKEN_LPAR, ')': TOKEN_RPAR,\n            '[': TOKEN_LPAR, ']': TOKEN_RPAR,\n            'true': TOKEN_TRUE, '1': TOKEN_TRUE,\n            'false': TOKEN_FALSE, '0': TOKEN_FALSE, 'none': TOKEN_FALSE\n        }\n\n        position = 0\n        length = len(expr)\n\n        while position < length:\n            tok = expr[position]\n\n            sym = tok.isalpha() or tok == '_'\n            if sym:\n                position += 1\n                while position < length:\n                    char = expr[position]\n                    if char.isalnum() or char in ('.', ':', '_'):\n                        position += 1\n                        tok += char\n                    else:\n                        break\n                position -= 1\n\n            try:\n                yield TOKENS[tok.lower()], tok, position\n            except KeyError:\n                if sym:\n                    yield TOKEN_SYMBOL, tok, position\n                elif tok not in (' ', '\\t', '\\r', '\\n'):\n                    raise ParseError(token_string=tok, position=position,\n                                     error_code=PARSE_UNKNOWN_TOKEN)\n\n            position += 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _rdistributive(self, expr, op_example):\n        if expr.isliteral:\n            return expr\n\n        expr_class = expr.__class__\n\n        args = (self._rdistributive(arg, op_example) for arg in expr.args)\n        args = tuple(arg.simplify() for arg in args)\n        if len(args) == 1:\n            return args[0]\n\n        expr = expr_class(*args)\n\n        dualoperation = op_example.dual\n        if isinstance(expr, dualoperation):\n            expr = expr.distributive()\n        return expr", "response": "Recursively flatten the expr expression for the op_example and or operation instance exmaple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a normalized expression transformed to its normal form in the given AND or OR operation.", "response": "def normalize(self, expr, operation):\n        \"\"\"\n        Return a normalized expression transformed to its normal form in the\n        given AND or OR operation.\n\n        The new expression arguments will satisfy these conditions:\n        - operation(*args) == expr (here mathematical equality is meant)\n        - the operation does not occur in any of its arg.\n        - NOT is only appearing in literals (aka. Negation normal form).\n\n        The operation must be an AND or OR operation or a subclass.\n        \"\"\"\n        # ensure that the operation is not NOT\n        assert operation in (self.AND, self.OR,)\n        # Move NOT inwards.\n        expr = expr.literalize()\n        # Simplify first otherwise _rdistributive() may take forever.\n        expr = expr.simplify()\n        operation_example = operation(self.TRUE, self.FALSE)\n        expr = self._rdistributive(expr, operation_example)\n        # Canonicalize\n        expr = expr.simplify()\n        return expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_literals(self):\n        if self.isliteral:\n            return [self]\n        if not self.args:\n            return []\n        return list(itertools.chain.from_iterable(arg.get_literals() for arg in self.args))", "response": "Return a list of all the literals contained in this expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef literalize(self):\n        if self.isliteral:\n            return self\n        args = tuple(arg.literalize() for arg in self.args)\n        if all(arg is self.args[i] for i, arg in enumerate(args)):\n            return self\n\n        return self.__class__(*args)", "response": "Return an expression where NOTs are only occurring as literals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all the symbols contained in this expression.", "response": "def get_symbols(self):\n        \"\"\"\n        Return a list of all the symbols contained in this expression.\n        Include recursively subexpressions symbols.\n        This includes duplicates.\n        \"\"\"\n        return [s if isinstance(s, Symbol) else s.args[0] for s in self.get_literals()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an expression where the expression or all subterms equal to a key expression are substituted with the corresponding value expression.", "response": "def subs(self, substitutions, default=None, simplify=False):\n        \"\"\"\n        Return an expression where the expression or all subterms equal to a key\n        expression are substituted with the corresponding value expression using\n        a mapping of: {expr->expr to substitute.}\n\n        Return this expression unmodified if nothing could be substituted.\n\n        Note that this can be used to tested for expression containment.\n        \"\"\"\n        # shortcut: check if we have our whole expression as a possible\n        # subsitution source\n        for expr, substitution in substitutions.items():\n            if expr == self:\n                return substitution\n\n        # otherwise, do a proper substitution of sub expressions\n        expr = self._subs(substitutions, default, simplify)\n        return self if expr is None else expr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an expression where all subterms equal to a key expression are substituted by the corresponding value expression.", "response": "def _subs(self, substitutions, default, simplify):\n        \"\"\"\n        Return an expression where all subterms equal to a key expression are\n        substituted by the corresponding value expression using a mapping of:\n        {expr->expr to substitute.}\n        \"\"\"\n        # track the new list of unchanged args or replaced args through\n        # a substitution\n        new_arguments = []\n        changed_something = False\n\n        # shortcut for basic logic True or False\n        if self is self.TRUE or self is self.FALSE:\n            return self\n\n        # if the expression has no elements, e.g. is empty, do not apply\n        # substitions\n        if not self.args:\n            return default\n\n        # iterate the subexpressions: either plain symbols or a subexpressions\n        for arg in self.args:\n            # collect substitutions for exact matches\n            # break as soon as we have a match\n            for expr, substitution in substitutions.items():\n                if arg == expr:\n                    new_arguments.append(substitution)\n                    changed_something = True\n                    break\n\n            # this will execute only if we did not break out of the\n            # loop, e.g. if we did not change anything and did not\n            # collect any substitutions\n            else:\n                # recursively call _subs on each arg to see if we get a\n                # substituted arg\n                new_arg = arg._subs(substitutions, default, simplify)\n                if new_arg is None:\n                    # if we did not collect a substitution for this arg,\n                    # keep the arg as-is, it is not replaced by anything\n                    new_arguments.append(arg)\n                else:\n                    # otherwise, we add the substitution for this arg instead\n                    new_arguments.append(new_arg)\n                    changed_something = True\n\n        if not changed_something:\n            return\n\n        # here we did some substitution: we return a new expression\n        # built from the new_arguments\n        newexpr = self.__class__(*new_arguments)\n        return newexpr.simplify() if simplify else newexpr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a pretty formatted representation of the object.", "response": "def pretty(self, indent=0, debug=False):\n        \"\"\"\n        Return a pretty formatted representation of self.\n        \"\"\"\n        debug_details = ''\n        if debug:\n            debug_details += '<isliteral=%r, iscanonical=%r>' % (self.isliteral, self.iscanonical)\n\n        obj = \"'%s'\" % self.obj if isinstance(self.obj, basestring) else repr(self.obj)\n        return (' ' * indent) + ('%s(%s%s)' % (self.__class__.__name__, debug_details, obj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pretty(self, indent=0, debug=False):\n        debug_details = ''\n        if debug:\n            debug_details += '<isliteral=%r, iscanonical=%r' % (self.isliteral, self.iscanonical)\n            identity = getattr(self, 'identity', None)\n            if identity is not None:\n                debug_details += ', identity=%r' % (identity)\n\n            annihilator = getattr(self, 'annihilator', None)\n            if annihilator is not None:\n                debug_details += ', annihilator=%r' % (annihilator)\n\n            dual = getattr(self, 'dual', None)\n            if dual is not None:\n                debug_details += ', dual=%r' % (dual)\n            debug_details += '>'\n        cls = self.__class__.__name__\n        args = [a.pretty(indent=indent + 2, debug=debug) for a in self.args]\n        pfargs = ',\\n'.join(args)\n        cur_indent = ' ' * indent\n        new_line = '' if self.isliteral else '\\n'\n        return '{cur_indent}{cls}({debug_details}{new_line}{pfargs}\\n{cur_indent})'.format(**locals())", "response": "Return a pretty formatted representation of self as an indented tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an expression where NOTs are only occurring as literals.", "response": "def literalize(self):\n        \"\"\"\n        Return an expression where NOTs are only occurring as literals.\n        \"\"\"\n        expr = self.demorgan()\n        if isinstance(expr, self.__class__):\n            return expr\n        return expr.literalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simplify(self):\n        if self.iscanonical:\n            return self\n\n        expr = self.cancel()\n        if not isinstance(expr, self.__class__):\n            return expr.simplify()\n\n        if expr.args[0] in (self.TRUE, self.FALSE,):\n            return expr.args[0].dual\n\n        expr = self.__class__(expr.args[0].simplify())\n        expr.iscanonical = True\n        return expr", "response": "Return a simplified version of the expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncanceling itself and following NOTs as far as possible. Returns the simplified expression.", "response": "def cancel(self):\n        \"\"\"\n        Cancel itself and following NOTs as far as possible.\n        Returns the simplified expression.\n        \"\"\"\n        expr = self\n        while True:\n            arg = expr.args[0]\n            if not isinstance(arg, self.__class__):\n                return expr\n            expr = arg.args[0]\n            if not isinstance(expr, self.__class__):\n                return expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef demorgan(self):\n        expr = self.cancel()\n        if expr.isliteral or not isinstance(expr, self.NOT):\n            return expr\n        op = expr.args[0]\n        return op.dual(*(self.__class__(arg).cancel() for arg in op.args))", "response": "Return a expression where the NOT function is moved inward."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a pretty formatted representation of self.", "response": "def pretty(self, indent=1, debug=False):\n        \"\"\"\n        Return a pretty formatted representation of self.\n        Include additional debug details if `debug` is True.\n        \"\"\"\n        debug_details = ''\n        if debug:\n            debug_details += '<isliteral=%r, iscanonical=%r>' % (self.isliteral, self.iscanonical)\n        if self.isliteral:\n            pretty_literal = self.args[0].pretty(indent=0, debug=debug)\n            return (' ' * indent) + '%s(%s%s)' % (self.__class__.__name__, debug_details, pretty_literal)\n        else:\n            return super(NOT, self).pretty(indent=indent, debug=debug)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef simplify(self):\n        # TODO: Refactor DualBase.simplify into different \"sub-evals\".\n\n        # If self is already canonical do nothing.\n        if self.iscanonical:\n            return self\n\n        # Otherwise bring arguments into canonical form.\n        args = [arg.simplify() for arg in self.args]\n\n        # Create new instance of own class with canonical args.\n        # TODO: Only create new class if some args changed.\n        expr = self.__class__(*args)\n\n        # Literalize before doing anything, this also applies De Morgan's Law\n        expr = expr.literalize()\n\n        # Associativity:\n        #     (A & B) & C = A & (B & C) = A & B & C\n        #     (A | B) | C = A | (B | C) = A | B | C\n        expr = expr.flatten()\n\n        # Annihilation: A & 0 = 0, A | 1 = 1\n        if self.annihilator in expr.args:\n            return self.annihilator\n\n        # Idempotence: A & A = A, A | A = A\n        # this boils down to removing duplicates\n        args = []\n        for arg in expr.args:\n            if arg not in args:\n                args.append(arg)\n        if len(args) == 1:\n            return args[0]\n\n        # Identity: A & 1 = A, A | 0 = A\n        if self.identity in args:\n            args.remove(self.identity)\n            if len(args) == 1:\n                return args[0]\n\n        # Complementation: A & ~A = 0, A | ~A = 1\n        for arg in args:\n            if self.NOT(arg) in args:\n                return self.annihilator\n\n        # Elimination: (A & B) | (A & ~B) = A, (A | B) & (A | ~B) = A\n        i = 0\n        while i < len(args) - 1:\n            j = i + 1\n            ai = args[i]\n            if not isinstance(ai, self.dual):\n                i += 1\n                continue\n            while j < len(args):\n                aj = args[j]\n                if not isinstance(aj, self.dual) or len(ai.args) != len(aj.args):\n                    j += 1\n                    continue\n\n                # Find terms where only one arg is different.\n                negated = None\n                for arg in ai.args:\n                    # FIXME: what does this pass Do?\n                    if arg in aj.args:\n                        pass\n                    elif self.NOT(arg).cancel() in aj.args:\n                        if negated is None:\n                            negated = arg\n                        else:\n                            negated = None\n                            break\n                    else:\n                        negated = None\n                        break\n\n                # If the different arg is a negation simplify the expr.\n                if negated is not None:\n                    # Cancel out one of the two terms.\n                    del args[j]\n                    aiargs = list(ai.args)\n                    aiargs.remove(negated)\n                    if len(aiargs) == 1:\n                        args[i] = aiargs[0]\n                    else:\n                        args[i] = self.dual(*aiargs)\n\n                    if len(args) == 1:\n                        return args[0]\n                    else:\n                        # Now the other simplifications have to be redone.\n                        return self.__class__(*args).simplify()\n                j += 1\n            i += 1\n\n        # Absorption: A & (A | B) = A, A | (A & B) = A\n        # Negative absorption: A & (~A | B) = A & B, A | (~A & B) = A | B\n        args = self.absorb(args)\n        if len(args) == 1:\n            return args[0]\n\n        # Commutativity: A & B = B & A, A | B = B | A\n        args.sort()\n\n        # Create new (now canonical) expression.\n        expr = self.__class__(*args)\n        expr.iscanonical = True\n        return expr", "response": "Simplify this expression into a new simplified expression in canonical form."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flatten(self):\n        args = list(self.args)\n        i = 0\n        for arg in self.args:\n            if isinstance(arg, self.__class__):\n                args[i:i + 1] = arg.args\n                i += len(arg.args)\n            else:\n                i += 1\n\n        return self.__class__(*args)", "response": "Return a new expression where nested terms of this expression are flattened as far as possible."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an args sequence of expressions return a new list of expression COOKIE objects.", "response": "def absorb(self, args):\n        \"\"\"\n        Given an `args` sequence of expressions, return a new list of expression\n        applying absorption and negative absorption.\n\n        See https://en.wikipedia.org/wiki/Absorption_law\n\n        Absorption: A & (A | B) = A, A | (A & B) = A\n        Negative absorption: A & (~A | B) = A & B, A | (~A & B) = A | B\n        \"\"\"\n        args = list(args)\n        if not args:\n            args = list(self.args)\n        i = 0\n        while i < len(args):\n            absorber = args[i]\n            j = 0\n            while j < len(args):\n                if j == i:\n                    j += 1\n                    continue\n                target = args[j]\n                if not isinstance(target, self.dual):\n                    j += 1\n                    continue\n\n                # Absorption\n                if absorber in target:\n                    del args[j]\n                    if j < i:\n                        i -= 1\n                    continue\n\n                # Negative absorption\n                neg_absorber = self.NOT(absorber).cancel()\n                if neg_absorber in target:\n                    b = target.subtract(neg_absorber, simplify=False)\n                    if b is None:\n                        del args[j]\n                        if j < i:\n                            i -= 1\n                        continue\n                    else:\n                        args[j] = b\n                        j += 1\n                        continue\n\n                if isinstance(absorber, self.dual):\n                    remove = None\n                    for arg in absorber.args:\n                        narg = self.NOT(arg).cancel()\n                        if arg in target.args:\n                            pass\n                        elif narg in target.args:\n                            if remove is None:\n                                remove = narg\n                            else:\n                                remove = None\n                                break\n                        else:\n                            remove = None\n                            break\n                    if remove is not None:\n                        args[j] = target.subtract(remove, simplify=True)\n                j += 1\n            i += 1\n\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subtract(self, expr, simplify):\n        args = self.args\n        if expr in self.args:\n            args = list(self.args)\n            args.remove(expr)\n        elif isinstance(expr, self.__class__):\n            if all(arg in self.args for arg in expr.args):\n                args = tuple(arg for arg in self.args if arg not in expr)\n        if len(args) == 0:\n            return None\n        if len(args) == 1:\n            return args[0]\n\n        newexpr = self.__class__(*args)\n        if simplify:\n            newexpr = newexpr.simplify()\n        return newexpr", "response": "Returns a new expression where the expr expression has been removed\n        from this expression if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef distributive(self):\n        dual = self.dual\n        args = list(self.args)\n        for i, arg in enumerate(args):\n            if isinstance(arg, dual):\n                args[i] = arg.args\n            else:\n                args[i] = (arg,)\n\n        prod = itertools.product(*args)\n        args = tuple(self.__class__(*arg).simplify() for arg in prod)\n\n        if len(args) == 1:\n            return args[0]\n        else:\n            return dual(*args)", "response": "Return a term where the leading AND or OR terms are switched."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ages(self):\n        match = self._ages_re.match(self.raw_fields.get('ages'))\n        if not match:\n            match = self._ages_re2.match(self.raw_fields.get('ages'))\n            return self.Ages(int(match.group(1)),int(match.group(1)))\n        return self.Ages(int(match.group(1)), int(match.group(2)))", "response": "The age range that the user is interested in."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef single(self):\n        return 'display: none;' not in self._looking_for_xpb.li(id='ajax_single').\\\n            one_(self._profile.profile_tree).attrib['style']", "response": "Whether or not the user is only interested in people that are single."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the looking for attributes of the logged in user.", "response": "def update(self, ages=None, single=None, near_me=None, kinds=None,\n               gentation=None):\n        \"\"\"Update the looking for attributes of the logged in user.\n\n        :param ages: The ages that the logged in user is interested in.\n        :type ages: tuple\n        :param single: Whether or not the user is only interested in people that\n                       are single.\n        :type single: bool\n        :param near_me: Whether or not the user is only interested in\n                        people that are near them.\n        :type near_me: bool\n        :param kinds: What kinds of relationships the user should be updated to\n                      be interested in.\n        :type kinds: list\n        :param gentation: The sex/orientation of people the user is interested\n                          in.\n        :type gentation: str\n        \"\"\"\n        ages = ages or self.ages\n        single = single if single is not None else self.single\n        near_me = near_me if near_me is not None else self.near_me\n        kinds = kinds or self.kinds\n        gentation = gentation or self.gentation\n        data = {\n            'okc_api': '1',\n            'searchprefs.submit': '1',\n            'update_prefs': '1',\n            'lquery': '',\n            'locid': '0',\n            'filter5': '1, 1' # TODO(@IvanMalison) Do this better...\n        }\n        if kinds:\n            kinds_numbers = self._build_kinds_numbers(kinds)\n            if kinds_numbers:\n                data['lookingfor'] = kinds_numbers\n        age_min, age_max = ages\n        data.update(looking_for_filters.legacy_build(\n            status=single, gentation=gentation, radius=25 if near_me else 0,\n            age_min=age_min, age_max=age_max\n        ))\n        log.info(simplejson.dumps({'looking_for_update': data}))\n        util.cached_property.bust_caches(self)\n        response = self._profile.authcode_post('profileedit2', data=data)\n        self._profile.refresh(reload=False)\n        return response.content"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads the file to okcupid and confirm the photo.", "response": "def upload_and_confirm(self, incoming, **kwargs):\n        \"\"\"Upload the file to okcupid and confirm, among other things, its\n        thumbnail position.\n\n        :param incoming: A filepath string, :class:`.Info` object or\n                         a file like object to upload to okcupid.com.\n                         If an info object is provided, its thumbnail\n                         positioning will be used by default.\n        :param caption: The caption to add to the photo.\n        :param thumb_nail_left: For thumb nail positioning.\n        :param thumb_nail_top: For thumb nail positioning.\n        :param thumb_nail_right: For thumb nail positioning.\n        :param thumb_nail_bottom: For thumb nail positioning.\n        \"\"\"\n        response_dict = self.upload(incoming)\n        if 'error' in response_dict:\n            log.warning('Failed to upload photo')\n            return response_dict\n        if isinstance(incoming, Info):\n            kwargs.setdefault('thumb_nail_left', incoming.thumb_nail_left)\n            kwargs.setdefault('thumb_nail_top', incoming.thumb_nail_top)\n            kwargs.setdefault('thumb_nail_right', incoming.thumb_nail_right)\n            kwargs.setdefault('thumb_nail_bottom', incoming.thumb_nail_bottom)\n        kwargs['height'] = response_dict.get('height')\n        kwargs['width'] = response_dict.get('width')\n        self.confirm(response_dict['id'], **kwargs)\n        return response_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, photo_id, album_id=0):\n        if isinstance(photo_id, Info):\n            photo_id = photo_id.id\n        return self._session.okc_post('photoupload', data={\n            'albumid': album_id,\n            'picid': photo_id,\n            'authcode': self._authcode,\n            'picture.delete_ajax': 1\n        })", "response": "Delete a photo from the logged in users account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd command line options to the ArgParser.", "response": "def add_command_line_options(add_argument, use_short_options=True):\n    \"\"\"\n    :param add_argument: The add_argument method of an ArgParser.\n    :param use_short_options: Whether or not to add short options.\n    \"\"\"\n    logger_args = (\"--enable-logger\",)\n    credentials_args = (\"--credentials\",)\n    if use_short_options:\n        logger_args += ('-l',)\n        credentials_args += ('-c',)\n    add_argument(*logger_args, dest='enabled_loggers',\n                 action=\"append\", default=[],\n                 help=\"Enable the specified logger.\")\n    add_argument(*credentials_args, dest='credential_files',\n                 action=\"append\", default=[],\n                 help=\"Use the specified credentials module to update \"\n                 \"the values in okcupyd.settings.\")\n    add_argument('--echo', dest='echo', action='store_true', default=False,\n                 help=\"Echo SQL.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_command_line_options(args):\n    for enabled_log in args.enabled_loggers:\n        enable_logger(enabled_log)\n    for credential_file in args.credential_files:\n        settings.load_credentials_from_filepath(credential_file)\n    if args.echo:\n        from okcupyd import db\n        db.echo = True\n        db.Session.kw['bind'].echo = True\n    return args", "response": "Handles command line options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a REMap from a list of regular expressions.", "response": "def IndexedREMap(*re_strings, **kwargs):\n    \"\"\"Build a :class:`~.REMap` from the provided regular expression string.\n    Each string will be associated with the index corresponding to its position\n    in the argument list.\n\n    :param re_strings: The re_strings that will serve as keys in the map.\n    :param default: The value to return if none of the regular expressions match\n    :param offset: The offset at which to start indexing for regular expressions\n                   defaults to 1.\n    \"\"\"\n    default = kwargs.get('default', 0)\n    offset = kwargs.get('offset', 1)\n    string_index_pairs = []\n    for index, string_or_tuple in enumerate(re_strings, offset):\n        if isinstance(string_or_tuple, six.string_types):\n            string_or_tuple = (string_or_tuple,)\n        for re_string in string_or_tuple:\n            string_index_pairs.append((re_string, index))\n    remap = REMap.from_string_pairs(string_index_pairs,\n                                    default=default)\n    return remap"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bust_self(self, obj):\n        if self.func.__name__ in obj.__dict__:\n            delattr(obj, self.func.__name__)", "response": "Remove the value that is being stored on obj for this\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbusts the cache for all cached_property objects on obj.", "response": "def bust_caches(cls, obj, excludes=()):\n        \"\"\"Bust the cache for all :class:`.cached_property` objects on `obj`\n\n        :param obj: The instance on which to bust the caches.\n        \"\"\"\n        for name, _ in cls.get_cached_properties(obj):\n            if name in obj.__dict__ and not name in excludes:\n                delattr(obj, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_string_pairs(cls, string_value_pairs, **kwargs):\n        return cls(re_value_pairs=[(re.compile(s), v)\n                                   for s, v in string_value_pairs],\n                   **kwargs)", "response": "Build an : class ~. REMap from a list of string value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __get_dbms_version(self, make_connection=True):\n        if not self.connection and make_connection:\n            self.connect()\n        with self.connection.cursor() as cursor:\n            cursor.execute(\"SELECT SERVERPROPERTY('productversion')\")\n            return cursor.fetchone()[0]", "response": "Returns the DBMS Version string or an empty string if the database has not been established."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the UserProfile instance belonging to the sender of this message.", "response": "def sender(self):\n        \"\"\"\n        :returns: A :class:`~okcupyd.profile.Profile` instance belonging\n                  to the sender of this message.\n        \"\"\"\n        return (self._message_thread.user_profile\n                if 'from_me' in self._message_element.attrib['class']\n                else self._message_thread.correspondent_profile)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recipient(self):\n        return (self._message_thread.correspondent_profile\n                if 'from_me' in self._message_element.attrib['class']\n                else self._message_thread.user_profile)", "response": "Returns the UserProfile instance belonging to this message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef content(self):\n        # The code that follows is obviously pretty disgusting.\n        # It seems like it might be impossible to completely replicate\n        # the text of the original message if it has trailing whitespace\n        message = self._content_xpb.one_(self._message_element)\n        first_line = message.text\n        if message.text[:2] == '  ':\n            first_line = message.text[2:]\n        else:\n            log.debug(\"message did not have expected leading whitespace\")\n        subsequent_lines = ''.join([\n            html.tostring(child, encoding='unicode').replace('<br>', '\\n')\n            for child in message.iterchildren()\n        ])\n        message_text = first_line + subsequent_lines\n        if len(message_text) > 0 and message_text[-1] == ' ':\n            message_text = message_text[:-1]\n        else:\n            log.debug(\"message did not have expected leading whitespace\")\n\n        return message_text", "response": "Returns the text body of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting threads from the logged in user.", "response": "def delete_threads(cls, session, thread_ids_or_threads, authcode=None):\n        \"\"\"\n        :param session: A logged in :class:`~okcupyd.session.Session`.\n        :param thread_ids_or_threads: A list whose members are either\n                                      :class:`~.MessageThread` instances\n                                      or okc_ids of message threads.\n        :param authcode: Authcode to use for this request. If none is provided\n                         A request to the logged in user's messages page\n                         will be made to retrieve one.\n        \"\"\"\n        thread_ids = [thread.id if isinstance(thread, cls) else thread\n                      for thread in thread_ids_or_threads]\n        if not authcode:\n            authcode = helpers.get_authcode(html.fromstring(\n                session.okc_get('messages').content\n            ))\n        data = {'access_token': authcode,\n                'threadids': simplejson.dumps(thread_ids)}\n        return session.okc_delete('apitun/messages/threads',\n                                  params=data, data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the id assigned to the correspondent of this message.", "response": "def correspondent_id(self):\n        \"\"\"\n        :returns: The id assigned to the correspondent of this message.\n        \"\"\"\n        try:\n            return int(self._thread_element.attrib['data-personid'])\n        except (ValueError, KeyError):\n            try:\n                return int(self.correspondent_profile.id)\n            except:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the username of the user who is who the logged in user is conversing in this : class : ~. MessageThread.", "response": "def correspondent(self):\n        \"\"\"\n        :returns: The username of the user with whom the logged in user is\n                  conversing in this :class:`~.MessageThread`.\n        \"\"\"\n        try:\n            return self._correspondent_xpb.one_(self._thread_element).strip()\n        except IndexError:\n            raise errors.NoCorrespondentError()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the thread has received a response.", "response": "def got_response(self):\n        \"\"\"\n        :returns: Whether or not the :class:`~.MessageThread`. has received a\n                  response.\n        \"\"\"\n        return any(message.sender != self.initiator\n                   for message in self.messages)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_answer_id_for_question(self, question):\n        assert question.id == self.id\n        for answer_option in self.answer_options:\n            if answer_option.text == question.their_answer:\n                return answer_option.id", "response": "Get the answer_id corresponding to the answer given for question."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of AnswerOption instances representing the available answers to this question.", "response": "def answer_options(self):\n        \"\"\"\n        :returns: A list of :class:`~.AnswerOption` instances representing the\n                  available answers to this question.\n        \"\"\"\n        return [\n            AnswerOption(element)\n            for element in self._answer_option_xpb.apply_(\n                self._question_element\n            )\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef respond_from_user_question(self, user_question, importance):\n        user_response_ids = [option.id\n                             for option in user_question.answer_options\n                             if option.is_users]\n        match_response_ids = [option.id\n                              for option in user_question.answer_options\n                              if option.is_match]\n        if len(match_response_ids) == len(user_question.answer_options):\n            match_response_ids = 'irrelevant'\n        return self.respond(user_question.id, user_response_ids,\n                            match_response_ids, importance,\n                            note=user_question.explanation or '')", "response": "Respond to a question in exactly the way that is described by the given user_question."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying the answer given in question to the logged in user s nacms_profile.", "response": "def respond_from_question(self, question, user_question, importance):\n        \"\"\"Copy the answer given in `question` to the logged in user's\n        profile.\n\n        :param question: A :class:`~.Question` instance to copy.\n        :param user_question: An instance of :class:`~.UserQuestion` that\n                              corresponds to the same question as `question`.\n                              This is needed to retrieve the answer id from\n                              the question text answer on question.\n        :param importance: The importance to assign to the response to the\n                           answered question.\n        \"\"\"\n        option_index = user_question.answer_text_to_option[\n            question.their_answer\n        ].id\n        self.respond(question.id, [option_index], [option_index], importance)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef respond(self, question_id, user_response_ids, match_response_ids,\n                importance, note='', is_public=1, is_new=1):\n        \"\"\"Respond to an okcupid.com question.\n\n        :param question_id: The okcupid id used to identify this question.\n        :param user_response_ids: The answer id(s) to provide to this question.\n        :param match_response_ids: The answer id(s) that the user considers\n                                   acceptable.\n        :param importance: The importance to attribute to this question. See\n                           :attr:`.importance_name_to_number` for details.\n        :param note: The explanation note to add to this question.\n        :param is_public: Whether or not the question answer should be made\n                          public.\n        \"\"\"\n        form_data = {\n            'ajax': 1,\n            'submit': 1,\n            'answer_question': 1,\n            'skip': 0,\n            'show_all': 0,\n            'targetid': self._user_id,\n            'qid': question_id,\n            'answers': user_response_ids,\n            'matchanswers': match_response_ids,\n            'is_new': is_new,\n            'is_public': is_public,\n            'note': note,\n            'importance': importance,\n            'delete_note': 0\n        }\n        return self._session.okc_post(\n            self.path, data=form_data, headers=self.headers\n        )", "response": "Respond to an okcupid. com question."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to a user.", "response": "def message(self, username, message_text):\n        \"\"\"Message an okcupid user. If an existing conversation between the\n        logged in user and the target user can be found, reply to that thread\n        instead of starting a new one.\n\n        :param username: The username of the user to which the message should\n                         be sent.\n        :type username: str\n        :param message_text: The body of the message.\n        :type message_text: str\n        \"\"\"\n        # Try to reply to an existing thread.\n        if not isinstance(username, six.string_types):\n            username = username.username\n        for mailbox in (self.inbox, self.outbox):\n            for thread in mailbox:\n                if thread.correspondent.lower() == username.lower():\n                    thread.reply(message_text)\n                    return\n\n        return self._message_sender.send(username, message_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, **kwargs):\n        kwargs.setdefault('gender', self.profile.gender[0])\n        gentation = helpers.get_default_gentation(self.profile.gender,\n                                                  self.profile.orientation)\n        kwargs.setdefault('gentation', gentation)\n\n        # We are no longer setting location by default because the\n        # query api that okcupid offers seems to have gotten much\n        # stricter. This should be revisited so that search gives good\n        # default results. This is issue #85.\n\n        # kwargs.setdefault('location', self.profile.location)\n\n        kwargs.setdefault('radius', 25)\n        kwargs.setdefault('location_cache', self.location_cache)\n        if 'count' in kwargs:\n            count = kwargs.pop('count')\n            return search(session=self._session, count=count, **kwargs)\n        return SearchFetchable(self._session, **kwargs)", "response": "Search for a set of items in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_question(self, question, fast=False,\n                          bust_questions_cache=False):\n        \"\"\"Get a :class:`~okcupyd.question.UserQuestion` corresponding to the\n        given :class:`~okcupyd.question.Question`.\n\n        HUGE CAVEATS: If the logged in user has not answered the relevant\n        question, it will automatically be answered with whatever the first\n        answer to the question is.\n\n        For the sake of reducing the number of requests made when\n        this function is called repeatedly this function does not\n        bust the cache of this :class:`~.User`'s\n        :attr:`okcupyd.profile.Profile.questions` attribute. That means that\n        a question that HAS been answered could still be answered by\n        this function if this :class:`~.User`'s\n        :attr:`~okcupyd.profile.P:attr:`okcupyd.profile.Profile.questions`\n        was populated previously (This population happens automatically --\n        See :class:`~okcupyd.util.fetchable.Fetchable` for details about when\n        and how this happens).\n\n        :param question: The question for which a\n                         :class:`~okcupyd.question.UserQuestion` should\n                         be retrieved.\n        :type question: :class:`~okcupyd.question.BaseQuestion`\n        :param fast: Don't try to look through the users existing questions to\n                     see if arbitrarily answering the question can be avoided.\n        :type fast: bool\n        :param bust_questions_cache: clear the\n                                     :attr:`~okcupyd.profile.Profile.questions`\n                                     attribute of this users\n                                     :class:`~okcupyd.profile.Profile`\n                                     before looking for an existing answer.\n                                     Be aware that even this does not eliminate\n                                     all race conditions.\n        :type bust_questions_cache: bool\n        \"\"\"\n        if bust_questions_cache:\n            self.profile.questions()\n        user_question = None if fast else self.profile.find_question(\n            question.id\n        )\n        if user_question is None:\n            self.questions.respond(question.id, [1], [1], 3)\n            # Give okcupid some time to update. I wish there were a better\n            # way...\n            for _ in range(10):\n                start_time = time.time()\n                user_question = self.profile.find_question(\n                    question.id,\n                    self.profile.question_fetchable(recent=1)\n                )\n                if user_question is None:\n                    log.debug(\n                        \"Could not find question with id {0} in \"\n                        \"questions.\".format(question.id)\n                    )\n                    if time.time() - start_time < 1:\n                        time.sleep(1)\n                else:\n                    break\n        return user_question", "response": "Get a user question from the user s question list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_question_answer_id(self, question, fast=False,\n                               bust_questions_cache=False):\n        \"\"\"Get the index of the answer that was given to `question`\n\n        See the documentation for :meth:`~.get_user_question` for important\n        caveats about the use of this function.\n\n        :param question: The question whose `answer_id` should be retrieved.\n        :type question: :class:`~okcupyd.question.BaseQuestion`\n        :param fast: Don't try to look through the users existing questions to\n                     see if arbitrarily answering the question can be avoided.\n        :type fast: bool\n        :param bust_questions_cache: :param bust_questions_cache: clear the\n                                     :attr:`~okcupyd.profile.Profile.questions`\n                                     attribute of this users\n                                     :class:`~okcupyd.profile.Profile`\n                                     before looking for an existing answer.\n                                     Be aware that even this does not eliminate\n                                     all race conditions.\n        :type bust_questions_cache: bool\n        \"\"\"\n        if hasattr(question, 'answer_id'):\n            # Guard to handle incoming user_question.\n            return question.answer_id\n\n        user_question = self.get_user_question(\n            question, fast=fast, bust_questions_cache=bust_questions_cache\n        )\n        # Look at recently answered questions\n        return user_question.get_answer_id_for_question(question)", "response": "Get the index of the answer that was given to question."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef quickmatch(self):\n        response = self._session.okc_get('quickmatch', params={'okc_api': 1})\n        return Profile(self._session, response.json()['sn'])", "response": "Return a : class : ~okcupyd. profile. Profile obtained by visiting the\n        quickmatch page."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SearchFetchable(session=None, **kwargs):\n    session = session or Session.login()\n    return util.Fetchable(\n        SearchManager(\n            SearchJSONFetcher(session, **kwargs),\n            ProfileBuilder(session)\n        )\n    )", "response": "Search okcupid. com with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refresh(self, nice_repr=True, **kwargs):\n        for key, value in self._kwargs.items():\n            kwargs.setdefault(key, value)\n        # No real good reason to hold on to this. DONT TOUCH.\n        self._original_iterable = self._fetcher.fetch(**kwargs)\n        self.exhausted = False\n        if nice_repr:\n            self._accumulated = []\n            self._original_iterable = self._make_nice_repr_iterator(\n                self._original_iterable, self._accumulated\n            )\n        else:\n            self._accumulated = None\n        self._clonable, = itertools.tee(self._original_iterable, 1)\n        return self", "response": "Refreshes the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a list of parameter documentation lines that can be appended to the the docstring of a function that uses this instance to build filters.", "response": "def build_documentation_lines(self):\n        \"\"\"Build a parameter documentation string that can appended to the\n        docstring of a function that uses this :class:`~.Filters` instance\n        to build filters.\n        \"\"\"\n        return [\n            line_string for key in sorted(self.keys)\n            for line_string in self.build_paramter_string(key)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a filter function with this instance.", "response": "def register_filter_builder(self, function, **kwargs):\n        \"\"\"Register a filter function with this :class:`~.Filters` instance.\n        This function is curried with :class:`~okcupyd.util.currying.curry`\n        -- that is, it can be invoked partially before it is fully evaluated.\n        This allows us to pass kwargs to this function when it is used as a\n        decorator:\n\n        .. code-block:: python\n\n            @register_filter_builder(keys=('real_name',),\n                                     decider=Filters.any_decider)\n            def my_filter_function(argument):\n                return '4,{0}'.format(argument)\n\n        :param function: The filter function to register.\n        :param keys: Keys that should be used as the argument names for\n                     `function`, if none are provided, the filter functions\n                     argument names will be used instead.\n        :param decider: a function of signature\n                        `(function, incoming_keys, accepted_keys)` that returns\n                        True if the filter function should be called and False\n                        otherwise. Defaults to\n                        :meth:`~.all_not_none_decider`\n        :param acceptable_values: A list of acceptable values for the parameter\n                                  of the filter function (or a list of lists if\n                                  the filter function takes multiple parameters)\n        :param types: The type of the parameter accepted by the incoming filter\n                      function (or a list of types if the function takes\n                      multiple parameters)\n        :param descriptions: A description for the incoming filter function's\n                             argument (or a list of descriptions if the filter\n                             function takes multiple arguments)\n        :param output_key: The key to use to output the provided value. Will\n                           default to the only value in keys if keys has\n                           length 1.\n        \"\"\"\n        kwargs['transform'] = function\n        if kwargs.get('decider'):\n            kwargs['decide'] = kwargs.get('decider')\n        return type('filter', (self.filter_class,), kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_locid(session, location):\n    locid = 0\n    query_parameters = {\n        'func': 'query',\n        'query': location,\n    }\n    loc_query = session.get('http://www.okcupid.com/locquery',\n                            params=query_parameters)\n    p = html.fromstring(loc_query.content.decode('utf8'))\n    js = loads(p.text)\n    if 'results' in js and len(js['results']):\n        locid = js['results'][0]['locid']\n    return locid", "response": "Get a locid from an OKCupid location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the last online time for a node in a log file.", "response": "def format_last_online(last_online):\n    \"\"\"\n    Return the upper limit in seconds that a profile may have been\n    online. If last_online is an int, return that int. Otherwise if\n    last_online is a str, convert the string into an int.\n    Returns\n    ----------\n    int\n    \"\"\"\n    if isinstance(last_online, str):\n        if last_online.lower() in ('day', 'today'):\n            last_online_int = 86400  # 3600 * 24\n        elif last_online.lower() == 'week':\n            last_online_int = 604800  # 3600 * 24 * 7\n        elif last_online.lower() == 'month':\n            last_online_int = 2678400  # 3600 * 24 * 31\n        elif last_online.lower() == 'year':\n            last_online_int = 31536000  # 3600 * 365\n        elif last_online.lower() == 'decade':\n            last_online_int = 315360000  # 3600 * 365 * 10\n        else: # Defaults any other strings to last hour\n            last_online_int = 3600\n    else:\n        last_online_int = last_online\n    return last_online_int"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates looking_for attribute of a Profile.", "response": "def update_looking_for(profile_tree, looking_for):\n    \"\"\"\n    Update looking_for attribute of a Profile.\n    \"\"\"\n    div = profile_tree.xpath(\"//div[@id = 'what_i_want']\")[0]\n    looking_for['gentation'] = div.xpath(\".//li[@id = 'ajax_gentation']/text()\")[0].strip()\n    looking_for['ages'] = replace_chars(div.xpath(\".//li[@id = 'ajax_ages']/text()\")[0].strip())\n    looking_for['near'] = div.xpath(\".//li[@id = 'ajax_near']/text()\")[0].strip()\n    looking_for['single'] = div.xpath(\".//li[@id = 'ajax_single']/text()\")[0].strip()\n    try:\n        looking_for['seeking'] = div.xpath(\".//li[@id = 'ajax_lookingfor']/text()\")[0].strip()\n    except:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_details(profile_tree, details):\n    div = profile_tree.xpath(\"//div[@id = 'profile_details']\")[0]\n    for dl in div.iter('dl'):\n        title = dl.find('dt').text\n        item = dl.find('dd')\n        if title == 'Last Online' and item.find('span') is not None:\n            details[title.lower()] = item.find('span').text.strip()\n        elif title.lower() in details and len(item.text):\n            details[title.lower()] = item.text.strip()\n        else:\n            continue\n        details[title.lower()] = replace_chars(details[title.lower()])", "response": "Update details attribute of a Profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the default gentation for the given gender and orientation.", "response": "def get_default_gentation(gender, orientation):\n    \"\"\"Return the default gentation for the given gender and orientation.\"\"\"\n    gender = gender.lower()[0]\n    orientation = orientation.lower()\n    return gender_to_orientation_to_gentation[gender][orientation]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing certain unicode characters in a string.", "response": "def replace_chars(astring):\n    \"\"\"\n    Replace certain unicode characters to avoid errors when trying\n    to read various strings.\n    Returns\n    ----------\n    str\n    \"\"\"\n    for k, v in CHAR_REPLACE.items():\n        astring = astring.replace(k, v)\n    return astring"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a newline character to the end of each <br > element.", "response": "def add_newlines(tree):\n    \"\"\"\n    Add a newline character to the end of each <br> element.\n    \"\"\"\n    for br in tree.xpath(\"*//br\"):\n        br.tail = u\"\\n\" + br.tail if br.tail else u\"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_attractiveness(self, username, accuracy=1000,\n                            _lower=0, _higher=10000):\n        \"\"\"\n        :param username: The username to lookup attractiveness for.\n        :param accuracy: The accuracy required to return a result.\n        :param _lower: The lower bound of the search.\n        :param _higher: The upper bound of the search.\n        \"\"\"\n        average = (_higher + _lower)//2\n        if _higher - _lower <= accuracy:\n            return average\n\n        results = search(self._session,\n                         count=9,\n                         gentation='everybody',\n                         keywords=username,\n                         attractiveness_min=average,\n                         attractiveness_max=_higher,)\n        found_match = False\n        if results:\n            for profile in results:\n                if profile.username.lower() == username:\n                    found_match = True\n                    break\n\n        if found_match:\n            return self.find_attractiveness(username, accuracy,\n                                            average, _higher)\n        else:\n            return self.find_attractiveness(username, accuracy,\n                                            _lower, average)", "response": "Search for the attractiveness for a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the mailbox associated with the given mailbox name.", "response": "def update_mailbox(self, mailbox_name='inbox'):\n        \"\"\"Update the mailbox associated with the given mailbox name.\n        \"\"\"\n        with txn() as session:\n            last_updated_name = '{0}_last_updated'.format(mailbox_name)\n            okcupyd_user = session.query(model.OKCupydUser).join(model.User).filter(\n                model.User.okc_id == self._user.profile.id\n            ).with_for_update().one()\n            log.info(simplejson.dumps({\n                '{0}_last_updated'.format(mailbox_name): helpers.datetime_to_string(\n                    getattr(okcupyd_user, last_updated_name)\n                )\n            }))\n\n            res = self._sync_mailbox_until(\n                getattr(self._user, mailbox_name)(),\n                getattr(okcupyd_user, last_updated_name)\n            )\n            if not res:\n                return None, None\n\n            last_updated, threads, new_messages = res\n            if last_updated:\n                setattr(okcupyd_user, last_updated_name, last_updated)\n            return threads, new_messages"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef photos(self):\n        # Reverse because pictures appear in inverse chronological order.\n        for photo_info in self.dest_user.profile.photo_infos:\n            self.dest_user.photo.delete(photo_info)\n        return [self.dest_user.photo.upload_and_confirm(info)\n                for info in reversed(self.source_profile.photo_infos)]", "response": "Copy photos to the source user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef essays(self):\n        for essay_name in self.dest_user.profile.essays.essay_names:\n            setattr(self.dest_user.profile.essays, essay_name,\n                    getattr(self.source_profile.essays, essay_name))", "response": "Copy essays from the source profile to the destination profile."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef looking_for(self):\n        looking_for = self.source_profile.looking_for\n        return self.dest_user.profile.looking_for.update(\n            gentation=looking_for.gentation,\n            single=looking_for.single,\n            near_me=looking_for.near_me,\n            kinds=looking_for.kinds,\n            ages=looking_for.ages\n        )", "response": "Copy looking for attributes from the source profile to the destination profile."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef details(self):\n        return self.dest_user.profile.details.convert_and_update(\n            self.source_profile.details.as_dict\n        )", "response": "Copy details from the source profile to the destination profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SearchFetchable(session=None, **kwargs):\n    session = session or Session.login()\n    return util.Fetchable.fetch_marshall(\n        SearchHTMLFetcher(session, **kwargs),\n        util.SimpleProcessor(\n            session,\n            lambda match_card_div: Profile(\n                session=session,\n                **MatchCardExtractor(match_card_div).as_dict\n            ),\n            _match_card_xpb\n        )\n    )", "response": "Search okcupid. com with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh(self, reload=False):\n        util.cached_property.bust_caches(self, excludes=('authcode'))\n        self.questions = self.question_fetchable()\n        if reload:\n            return self.profile_tree", "response": "Refresh the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef photo_infos(self):\n        from . import photo\n        pics_request = self._session.okc_get(\n            u'profile/{0}/album/0'.format(self.username),\n        )\n        pics_tree = html.fromstring(u'{0}{1}{2}'.format(\n            u'<div>', pics_request.json()['fulls'], u'</div>'\n        ))\n        return [photo.Info.from_cdn_uri(uri)\n                for uri in self._photo_info_xpb.apply_(pics_tree)]", "response": "Returns a list of photo. Info instances for each photo in the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef liked(self):\n        if self.is_logged_in_user: return False\n        classes = self._liked_xpb.one_(self.profile_tree).attrib['class'].split()\n        return 'liked' in classes", "response": "Returns True if the logged in user liked this profile\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef contacted(self):\n        try:\n            contacted_span = self._contacted_xpb.one_(self.profile_tree)\n        except:\n            return False\n        else:\n            timestamp = contacted_span.replace('Last contacted ', '')\n            return helpers.parse_date_updated(timestamp)", "response": "Returns a boolean indicating whether the logged in user has contacted the owner of this profile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the frequency with which the user associated with this profile responds to messages.", "response": "def responds(self):\n        \"\"\"\n        :returns: The frequency with which the user associated with this profile\n                  responds to messages.\n        \"\"\"\n        contacted_text = self._contacted_xpb.\\\n                         get_text_(self.profile_tree).lower()\n        if 'contacted' not in contacted_text:\n            return contacted_text.strip().replace('replies ', '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef id(self):\n        if self.is_logged_in_user: return self._current_user_id\n        return int(self._id_xpb.one_(self.profile_tree))", "response": "Returns the id that owns this profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the age of the user associated with this profile.", "response": "def age(self):\n        \"\"\"\n        :returns: The age of the user associated with this profile.\n        \"\"\"\n        if self.is_logged_in_user: \n            # Retrieve the logged-in user's profile age\n            return int(self._user_age_xpb.get_text_(self.profile_tree).strip())\n        else:\n            # Retrieve a non logged-in user's profile age\n            return int(self._age_xpb.get_text_(self.profile_tree))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_percentage(self):\n        return int(self._percentages_and_ratings_xpb.\n                   div.with_class('matchgraph--match').\n                   div.with_class('matchgraph-graph').\n                   canvas.select_attribute_('data-pct').\n                   one_(self.profile_tree))", "response": "Returns the match percentage of the logged in user and the user\n                  associated with this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the location of the user associated with this profile.", "response": "def location(self):\n        \"\"\"\n        :returns: The location of the user associated with this profile.\n        \"\"\"\n        if self.is_logged_in_user: \n            # Retrieve the logged-in user's profile location\n            return self._user_location_xpb.get_text_(self.profile_tree)\n        else:\n            # Retrieve a non logged-in user's profile location\n            return self._location_xpb.get_text_(self.profile_tree)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef message(self, message, thread_id=None):\n        return_value = helpers.Messager(self._session).send(\n            self.username, message, self.authcode, thread_id\n        )\n        self.refresh(reload=False)\n        return return_value", "response": "Send a message to the user associated with this profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrates this profile as the user that was logged in with the session AttributeNames that this object was instantiated with.", "response": "def rate(self, rating):\n        \"\"\"Rate this profile as the user that was logged in with the session\n        that this object was instantiated with.\n\n        :param rating: The rating to give this user.\n        \"\"\"\n        parameters = {\n            'voterid': self._current_user_id,\n            'target_userid': self.id,\n            'type': 'vote',\n            'cf': 'profile2',\n            'target_objectid': 0,\n            'vote_type': 'personality',\n            'score': rating,\n        }\n        response = self._session.okc_post('vote_handler',\n                                          data=parameters)\n        response_json = response.json()\n        log_function = log.info if response_json.get('status', False) \\\n                       else log.error\n        log_function(simplejson.dumps({'rate_response': response_json,\n                                       'sent_parameters': parameters,\n                                       'headers': dict(self._session.headers)}))\n        self.refresh(reload=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch through the available questions and returns the corresponding item.", "response": "def find_question(self, question_id, question_fetchable=None):\n        \"\"\"\n        :param question_id: The id of the question to search for\n        :param question_fetchable: The question fetchable to iterate through\n                                   if none is provided `self.questions`\n                                   will be used.\n        \"\"\"\n        question_fetchable = question_fetchable or self.questions\n        for question in question_fetchable:\n            if int(question.id) == int(question_id):\n                return question"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef question_fetchable(self, **kwargs):\n        return util.Fetchable(QuestionFetcher(\n            self._session, self.username,\n            is_user=self.is_logged_in_user, **kwargs\n        ))", "response": "Returns a Fetchable instance that represents answers that match the user s answers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef authcode_get(self, path, **kwargs):\n        kwargs.setdefault('params', {})['authcode'] = self.authcode\n        return self._session.okc_get(path, **kwargs)", "response": "Perform an HTTP GET to okcupid. com using this profiles session\n        where the authcode is automatically added as a query parameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform an HTTP POST to okcupid. com using this profiles session where the authcode is automatically added as a form item.", "response": "def authcode_post(self, path, **kwargs):\n        \"\"\"Perform an HTTP POST to okcupid.com using this profiles session\n        where the authcode is automatically added as a form item.\n        \"\"\"\n        kwargs.setdefault('data', {})['authcode'] = self.authcode\n        return self._session.okc_post(path, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an evaluation checker that will return True when it is guaranteed that all positional arguments have been accounted for.", "response": "def arity_evaluation_checker(function):\n        \"\"\"Build an evaluation checker that will return True when it is\n        guaranteed that all positional arguments have been accounted for.\n        \"\"\"\n        is_class = inspect.isclass(function)\n        if is_class:\n            function = function.__init__\n        function_info = inspect.getargspec(function)\n        function_args = function_info.args\n        if is_class:\n            # This is to handle the fact that self will get passed in\n            # automatically.\n            function_args = function_args[1:]\n\n        def evaluation_checker(*args, **kwargs):\n            kwarg_keys = set(kwargs.keys())\n            if function_info.keywords is None:\n                acceptable_kwargs = function_args[len(args):]\n                # Make sure that we didn't get an argument we can't handle.\n                if not kwarg_keys.issubset(acceptable_kwargs):\n                    TypeError(\"Unrecognized Arguments: {0}\".format(\n                        [key for key in kwarg_keys\n                         if key not in acceptable_kwargs]\n                    ))\n\n            needed_args = function_args[len(args):]\n            if function_info.defaults:\n                needed_args = needed_args[:-len(function_info.defaults)]\n            return not needed_args or kwarg_keys.issuperset(needed_args)\n        return evaluation_checker"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a session that has authenticated with okcupid. com.", "response": "def login(\n            cls, username=None, password=None, requests_session=None,\n            rate_limit=None\n    ):\n        \"\"\"Get a session that has authenticated with okcupid.com.\n        If no username and password is supplied, the ones stored in\n        :class:`okcupyd.settings` will be used.\n\n        :param username: The username to log in with.\n        :type username: str\n        :param password: The password to log in with.\n        :type password: str\n        :param rate_limit: Average time in seconds to wait between requests to OKC.\n        :type rate_limit: float\n        \"\"\"\n        requests_session = requests_session or requests.Session()\n        session = cls(requests_session, rate_limit)\n        # settings.USERNAME and settings.PASSWORD should not be made\n        # the defaults to their respective arguments because doing so\n        # would prevent this function from picking up any changes made\n        # to those values after import time.\n        username = username or settings.USERNAME\n        password = password or settings.PASSWORD\n        session.do_login(username, password)\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all the roles in this project area.", "response": "def getRoles(self):\n        \"\"\"Get all :class:`rtcclient.models.Role` objects in this project\n        area\n\n        If no :class:`Roles` are retrieved, `None` is returned.\n\n        :return: a :class:`list` that contains all\n            :class:`rtcclient.models.Role` objects\n        :rtype: list\n        \"\"\"\n\n        # no need to retrieve all the entries from _get_paged_resources\n        # role raw data is very simple that contains no other links\n\n        self.log.info(\"Get all the roles in <ProjectArea %s>\",\n                      self)\n        roles_url = \"/\".join([self.rtc_obj.url,\n                              \"process/project-areas/%s/roles\" % self.id])\n        resp = self.get(roles_url,\n                        verify=False,\n                        proxies=self.rtc_obj.proxies,\n                        headers=self.rtc_obj.headers)\n\n        roles_list = list()\n        raw_data = xmltodict.parse(resp.content)\n        roles_raw = raw_data['jp06:roles']['jp06:role']\n        if not roles_raw:\n            self.log.warning(\"There are no roles in <ProjectArea %s>\",\n                             self)\n            return None\n\n        for role_raw in roles_raw:\n            role = Role(role_raw.get(\"jp06:url\"),\n                        self.rtc_obj,\n                        raw_data=role_raw)\n            roles_list.append(role)\n        return roles_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the role object by the label name", "response": "def getRole(self, label):\n        \"\"\"Get the :class:`rtcclient.models.Role` object by the label name\n\n        :param label: the label name of the role\n        :return: the :class:`rtcclient.models.Role` object\n        :rtype: :class:`rtcclient.models.Role`\n        \"\"\"\n\n        if not isinstance(label, six.string_types) or not label:\n            excp_msg = \"Please specify a valid role label\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        roles = self.getRoles()\n        if roles is not None:\n            for role in roles:\n                if role.label == label:\n                    self.log.info(\"Get <Role %s> in <ProjectArea %s>\",\n                                  role, self)\n                    return role\n\n        excp_msg = \"No role's label is %s in <ProjectArea %s>\" % (label,\n                                                                  self)\n        self.log.error(excp_msg)\n        raise exception.NotFound(excp_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the member object by the email address.", "response": "def getMember(self, email, returned_properties=None):\n        \"\"\"Get the :class:`rtcclient.models.Member` object by the\n        email address\n\n        :param email: the email address (e.g. somebody@gmail.com)\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.models.Member` object\n        :rtype: rtcclient.models.Member\n        \"\"\"\n\n        if not isinstance(email, six.string_types) or \"@\" not in email:\n            excp_msg = \"Please specify a valid email address name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get Member whose email is %s>\", email)\n        members = self._getMembers(returned_properties=returned_properties,\n                                   email=email)\n        if members is not None:\n            member = members[0]\n            self.log.info(\"Get <Member %s> in <ProjectArea %s>\",\n                          member, self)\n            return member\n\n        excp_msg = \"No member's email is %s in <ProjectArea %s>\" % (email,\n                                                                    self)\n        self.log.error(excp_msg)\n        raise exception.NotFound(excp_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getItemType(self, title, returned_properties=None):\n\n        if not isinstance(title, six.string_types) or not title:\n            excp_msg = \"Please specify a valid email address name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get <ItemType %s>\", title)\n        itemtypes = self._getItemTypes(returned_properties=returned_properties,\n                                       title=title)\n        if itemtypes is not None:\n            itemtype = itemtypes[0]\n            self.log.info(\"Get <ItemType %s> in <ProjectArea %s>\",\n                          itemtype, self)\n            return itemtype\n\n        excp_msg = \"No itemtype's name is %s in <ProjectArea %s>\" % (title,\n                                                                     self)\n        self.log.error(excp_msg)\n        raise exception.NotFound(excp_msg)", "response": "Get the item type by the title"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the administrator object by the email address.", "response": "def getAdministrator(self, email, returned_properties=None):\n        \"\"\"Get the :class:`rtcclient.models.Administrator` object\n        by the email address\n\n        :param email: the email address (e.g. somebody@gmail.com)\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.models.Administrator` object\n        :rtype: rtcclient.models.Administrator\n        \"\"\"\n\n        if not isinstance(email, six.string_types) or \"@\" not in email:\n            excp_msg = \"Please specify a valid email address name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get Administrator whose email is %s\",\n                       email)\n        rp = returned_properties\n        administrators = self._getAdministrators(returned_properties=rp,\n                                                 email=email)\n        if administrators is not None:\n            administrator = administrators[0]\n            self.log.info(\"Get <Administrator %s> in <ProjectArea %s>\",\n                          administrator, self)\n            return administrator\n\n        msg = \"No administrator's email is %s in <ProjectArea %s>\" % (email,\n                                                                      self)\n        self.log.error(msg)\n        raise exception.NotFound(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the list of workitems in a certain project area with the query string.", "response": "def queryWorkitems(self, query_str, projectarea_id=None,\n                       projectarea_name=None, returned_properties=None,\n                       archived=False):\n        \"\"\"Query workitems with the query string in a certain\n        :class:`rtcclient.project_area.ProjectArea`\n\n        At least either of `projectarea_id` and `projectarea_name` is given\n\n        :param query_str: a valid query string\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the\n            :class:`rtcclient.project_area.ProjectArea` name\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :param archived: (default is False) whether the\n            :class:`rtcclient.workitem.Workitem` is archived\n        :return: a :class:`list` that contains the queried\n            :class:`rtcclient.workitem.Workitem` objects\n        :rtype: list\n        \"\"\"\n\n        pa_id = (self.rtc_obj\n                     ._pre_get_resource(projectarea_id=projectarea_id,\n                                        projectarea_name=projectarea_name))\n\n        self.log.info(\"Start to query workitems with query string: %s\",\n                      query_str)\n        query_str = urlquote(query_str)\n        rp = returned_properties\n\n        return (self.rtc_obj\n                    ._get_paged_resources(\"Query\",\n                                          projectarea_id=pa_id,\n                                          customized_attr=query_str,\n                                          page_size=\"100\",\n                                          returned_properties=rp,\n                                          archived=archived))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getAllSavedQueries(self, projectarea_id=None, projectarea_name=None,\n                           creator=None, saved_query_name=None):\n        \"\"\"Get all saved queries created by somebody (optional)\n        in a certain project area (optional, either `projectarea_id`\n        or `projectarea_name` is needed if specified)\n\n        If `saved_query_name` is specified, only the saved queries match the\n        name will be fetched.\n\n        Note: only if `creator` is added as a member, the saved queries\n        can be found. Otherwise None will be returned.\n\n        WARNING: now the RTC server cannot correctly list all the saved queries\n        It seems to be a bug of RTC. Recommend using `runSavedQueryByUrl` to\n        query all the workitems if the query is saved.\n\n        Note: It will run faster when more attributes are specified.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the\n            :class:`rtcclient.project_area.ProjectArea` name\n        :param creator: the creator email address\n        :param saved_query_name: the saved query name\n        :return: a :class:`list` that contains the saved queried\n            :class:`rtcclient.models.SavedQuery` objects\n        :rtype: list\n        \"\"\"\n\n        pa_id = (self.rtc_obj\n                     ._pre_get_resource(projectarea_id=projectarea_id,\n                                        projectarea_name=projectarea_name))\n\n        filter_rule = None\n        if creator is not None:\n            fcreator = self.rtc_obj.getOwnedBy(creator).url\n            filter_rule = [(\"dc:creator\", \"@rdf:resource\",\n                            fcreator)]\n            self.log.debug(\"Add rules for fetching all saved queries: \"\n                           \"created by %s\", creator)\n\n        if saved_query_name is not None:\n            ftitle_rule = (\"dc:title\", None, saved_query_name)\n            if filter_rule is None:\n                filter_rule = [ftitle_rule]\n            else:\n                filter_rule.append(ftitle_rule)\n            self.log.debug(\"Add rules for fetching all saved queries: \"\n                           \"saved query title is %s\", saved_query_name)\n\n        return (self.rtc_obj\n                    ._get_paged_resources(\"SavedQuery\",\n                                          projectarea_id=pa_id,\n                                          page_size=\"100\",\n                                          filter_rule=filter_rule))", "response": "Get all saved queries in a certain project area."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSavedQueriesByName(self, saved_query_name, projectarea_id=None,\n                              projectarea_name=None, creator=None):\n        \"\"\"Get all saved queries match the name created by somebody (optional)\n        in a certain project area (optional, either `projectarea_id`\n        or `projectarea_name` is needed if specified)\n\n        Note: only if `creator` is added as a member, the saved queries\n        can be found. Otherwise None will be returned.\n\n        WARNING: now the RTC server cannot correctly list all the saved queries\n        It seems to be a bug of RTC. Recommend using `runSavedQueryByUrl` to\n        query all the workitems if the query is saved.\n\n        :param saved_query_name: the saved query name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the\n            :class:`rtcclient.project_area.ProjectArea` name\n        :param creator: the creator email address\n        :return: a :class:`list` that contains the saved queried\n            :class:`rtcclient.models.SavedQuery` objects\n        :rtype: list\n        \"\"\"\n\n        self.log.info(\"Start to fetch all saved queries with the name %s\",\n                      saved_query_name)\n        return self.getAllSavedQueries(projectarea_id=projectarea_id,\n                                       projectarea_name=projectarea_name,\n                                       creator=creator,\n                                       saved_query_name=saved_query_name)", "response": "Get all saved queries that match the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getMySavedQueries(self, projectarea_id=None, projectarea_name=None,\n                          saved_query_name=None):\n        \"\"\"Get all saved queries created by me in a certain project\n        area (optional, either `projectarea_id` or `projectarea_name` is\n        needed if specified)\n\n        Note: only if myself is added as a member, the saved queries\n        can be found. Otherwise None will be returned.\n\n        WARNING: now the RTC server cannot correctly list all the saved queries\n        It seems to be a bug of RTC. Recommend using `runSavedQueryByUrl` to\n        query all the workitems if the query is saved.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the\n            :class:`rtcclient.project_area.ProjectArea` name\n        :param saved_query_name: the saved query name\n        :return: a :class:`list` that contains the saved queried\n            :class:`rtcclient.models.SavedQuery` objects\n        :rtype: list\n        \"\"\"\n\n        self.log.info(\"Start to fetch my saved queries\")\n        return self.getAllSavedQueries(projectarea_id=projectarea_id,\n                                       projectarea_name=projectarea_name,\n                                       creator=self.rtc_obj.username,\n                                       saved_query_name=saved_query_name)", "response": "Get all saved queries created by me in a certain project area."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef runSavedQueryByUrl(self, saved_query_url, returned_properties=None):\n\n        try:\n            if \"=\" not in saved_query_url:\n                raise exception.BadValue()\n            saved_query_id = saved_query_url.split(\"=\")[-1]\n            if not saved_query_id:\n                raise exception.BadValue()\n        except:\n            error_msg = \"No saved query id is found in the url\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n        return self._runSavedQuery(saved_query_id,\n                                   returned_properties=returned_properties)", "response": "Query the workitems using the saved query url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef runSavedQueryByID(self, saved_query_id, returned_properties=None):\n\n        if not isinstance(saved_query_id,\n                          six.string_types) or not saved_query_id:\n            excp_msg = \"Please specify a valid saved query id\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n        return self._runSavedQuery(saved_query_id,\n                                   returned_properties=returned_properties)", "response": "Query workitems using the saved query id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef runSavedQuery(self, saved_query_obj, returned_properties=None):\n\n        try:\n            saved_query_id = saved_query_obj.results.split(\"/\")[-2]\n        except:\n            error_msg = \"Cannot get the correct saved query id\"\n            self.log.error(error_msg)\n            raise exception.RTCException(error_msg)\n        return self._runSavedQuery(saved_query_id,\n                                   returned_properties=returned_properties)", "response": "Query the workitems using the saved query object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a PUT request to the specified URL.", "response": "def put(self, url, data=None, verify=False,\n            headers=None, proxies=None, timeout=60, **kwargs):\n        \"\"\"Sends a PUT request. Refactor from requests module\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, bytes, or file-like object to\n            send in the body of the :class:`Request`.\n        :param verify: (optional) if ``True``, the SSL cert will be verified.\n            A CA_BUNDLE path can also be provided.\n        :param headers: (optional) Dictionary of HTTP Headers to send with\n            the :class:`Request`.\n        :param proxies: (optional) Dictionary mapping protocol to the URL of\n            the proxy.\n        :param timeout: (optional) How long to wait for the server to send data\n            before giving up, as a float, or a :ref:`(connect timeout, read\n            timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :return: :class:`Response <Response>` object\n        :rtype: requests.Response\n        \"\"\"\n\n        self.log.debug(\"Put a request to %s with data: %s\",\n                       url, data)\n        response = requests.put(url, data=data,\n                                verify=verify, headers=headers,\n                                proxies=proxies, timeout=timeout, **kwargs)\n        if response.status_code not in [200, 201]:\n            self.log.error('Failed PUT request at <%s> with response: %s',\n                           url,\n                           response.content)\n            response.raise_for_status()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_url(cls, url):\n\n        if url is None:\n            return None\n\n        url = url.strip()\n        while url.endswith('/'):\n            url = url[:-1]\n        return url", "response": "Strip and trailing slash to validate a url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the object from the request", "response": "def _initialize(self):\n        \"\"\"Initialize the object from the request\"\"\"\n\n        self.log.debug(\"Start initializing data from %s\",\n                       self.url)\n        resp = self.get(self.url,\n                        verify=False,\n                        proxies=self.rtc_obj.proxies,\n                        headers=self.rtc_obj.headers)\n        self.__initialize(resp)\n        self.log.info(\"Finish the initialization for <%s %s>\",\n                      self.__class__.__name__, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __initialize(self, resp):\n\n        raw_data = xmltodict.parse(resp.content)\n        root_key = list(raw_data.keys())[0]\n        self.raw_data = raw_data.get(root_key)\n        self.__initializeFromRaw()", "response": "Initialize from the response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize from raw data.", "response": "def __initializeFromRaw(self):\n        \"\"\"Initialze from raw data (OrderedDict)\"\"\"\n\n        for (key, value) in self.raw_data.items():\n            if key.startswith(\"@\"):\n                # be compatible with IncludedInBuild\n                if \"@oslc_cm:label\" != key:\n                    continue\n\n            attr = key.split(\":\")[-1].replace(\"-\", \"_\")\n            attr_list = attr.split(\".\")\n\n            # ignore long attributes\n            if len(attr_list) > 1:\n                # attr = \"_\".join([attr_list[-2],\n                #                  attr_list[-1]])\n                continue\n\n            self.field_alias[attr] = key\n\n            if isinstance(value, OrderedDict):\n                value_text = value.get(\"#text\")\n                if value_text is not None:\n                    value = value_text\n                else:\n                    # request detailed info using rdf:resource\n                    value = list(value.values())[0]\n\n                    try:\n                        value = self.__get_rdf_resource_title(value)\n                    except (exception.RTCException, Exception):\n                        self.log.error(\"Unable to handle %s\", value)\n            self.setattr(attr, value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getProjectAreas(self, archived=False, returned_properties=None):\n\n        return self._getProjectAreas(archived=archived,\n                                     returned_properties=returned_properties)", "response": "Get all the project areas."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getProjectArea(self, projectarea_name, archived=False,\n                       returned_properties=None):\n        \"\"\"Get :class:`rtcclient.project_area.ProjectArea` object by its name\n\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the project area\n            is archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.project_area.ProjectArea` object\n        :rtype: rtcclient.project_area.ProjectArea\n        \"\"\"\n\n        if not isinstance(projectarea_name,\n                          six.string_types) or not projectarea_name:\n            excp_msg = \"Please specify a valid ProjectArea name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get <ProjectArea %s>\", projectarea_name)\n        rp = returned_properties\n        proj_areas = self._getProjectAreas(archived=archived,\n                                           returned_properties=rp,\n                                           projectarea_name=projectarea_name)\n\n        if proj_areas is not None:\n            proj_area = proj_areas[0]\n            self.log.info(\"Find <ProjectArea %s>\", proj_area)\n            return proj_area\n\n        self.log.error(\"No ProjectArea named %s\", projectarea_name)\n        raise exception.NotFound(\"No ProjectArea named %s\" % projectarea_name)", "response": "Get the project area object by its name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getProjectAreaByID(self, projectarea_id, archived=False,\n                           returned_properties=None):\n        \"\"\"Get :class:`rtcclient.project_area.ProjectArea` object by its id\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param archived: (default is False) whether the project area\n            is archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.project_area.ProjectArea` object\n        :rtype: rtcclient.project_area.ProjectArea\n        \"\"\"\n\n        if not isinstance(projectarea_id,\n                          six.string_types) or not projectarea_id:\n            excp_msg = \"Please specify a valid ProjectArea ID\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get <ProjectArea> by its id: %s\",\n                       projectarea_id)\n        rp = returned_properties\n        proj_areas = self._getProjectAreas(archived=archived,\n                                           returned_properties=rp,\n                                           projectarea_id=projectarea_id)\n        if proj_areas is not None:\n            proj_area = proj_areas[0]\n            self.log.info(\"Find <ProjectArea %s>\", proj_area)\n            return proj_area\n\n        self.log.error(\"No ProjectArea's ID is %s\", projectarea_id)\n        raise exception.NotFound(\"No ProjectArea's ID is %s\" % projectarea_id)", "response": "Get a ProjectArea object by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the project area id by its name.", "response": "def getProjectAreaID(self, projectarea_name, archived=False):\n        \"\"\"Get :class:`rtcclient.project_area.ProjectArea` id by its name\n\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the project area\n            is archived\n        :return: the :class:`string` object\n        :rtype: string\n        \"\"\"\n\n        self.log.debug(\"Get the ProjectArea id by its name: %s\",\n                       projectarea_name)\n        proj_area = self.getProjectArea(projectarea_name,\n                                        archived=archived)\n        if proj_area:\n            return proj_area.id\n        raise exception.NotFound(\"No ProjectArea named %s\" % projectarea_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all the project area ids by project area name.", "response": "def getProjectAreaIDs(self, projectarea_name=None, archived=False):\n        \"\"\"Get all :class:`rtcclient.project_area.ProjectArea` id(s)\n        by project area name\n\n        If `projectarea_name` is `None`, all the\n        :class:`rtcclient.project_area.ProjectArea` id(s) will be returned.\n\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the project area\n            is archived\n        :return: a :class:`list` that contains all the :class:`ProjectArea` ids\n        :rtype: list\n        \"\"\"\n\n        projectarea_ids = list()\n        if projectarea_name and isinstance(projectarea_name,\n                                           six.string_types):\n            projectarea_id = self.getProjectAreaID(projectarea_name,\n                                                   archived=archived)\n            projectarea_ids.append(projectarea_id)\n        elif projectarea_name is None:\n            projectareas = self.getProjectAreas(archived=archived)\n            if projectareas is None:\n                return None\n            projectarea_ids = [proj_area.id for proj_area in projectareas]\n        else:\n            error_msg = \"Invalid ProjectArea name: [%s]\" % projectarea_name\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        return projectarea_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the validity of the project area id", "response": "def checkProjectAreaID(self, projectarea_id, archived=False):\n        \"\"\"Check the validity of :class:`rtcclient.project_area.ProjectArea` id\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param archived: (default is False) whether the project area is\n            archived\n        :return: `True` or `False`\n        :rtype: bool\n        \"\"\"\n\n        self.log.debug(\"Check the validity of the ProjectArea id: %s\",\n                       projectarea_id)\n\n        proj_areas = self._getProjectAreas(archived=archived,\n                                           projectarea_id=projectarea_id)\n        if proj_areas is not None:\n            proj_area = proj_areas[0]\n            self.log.info(\"Find <ProjectArea %s> whose id is: %s\",\n                          proj_area,\n                          projectarea_id)\n            return True\n\n        self.log.error(\"No ProjectArea whose id is: %s\",\n                       projectarea_id)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTeamArea(self, teamarea_name, projectarea_id=None,\n                    projectarea_name=None, archived=False,\n                    returned_properties=None):\n        \"\"\"Get :class:`rtcclient.models.TeamArea` object by its name\n\n        If `projectarea_id` or `projectarea_name` is\n        specified, then the matched :class:`rtcclient.models.TeamArea`\n        in that project area will be returned.\n        Otherwise, only return the first found\n        :class:`rtcclient.models.TeamArea` with that name.\n\n        :param teamarea_name: the team area name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the team area\n            is archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.models.TeamArea` object\n        :rtype: rtcclient.models.TeamArea\n        \"\"\"\n\n        if not isinstance(teamarea_name,\n                          six.string_types) or not teamarea_name:\n            excp_msg = \"Please specify a valid TeamArea name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get <TeamArea %s>\", teamarea_name)\n        teamareas = self._getTeamAreas(projectarea_id=projectarea_id,\n                                       projectarea_name=projectarea_name,\n                                       archived=archived,\n                                       returned_properties=returned_properties,\n                                       teamarea_name=teamarea_name)\n\n        if teamareas is not None:\n            teamarea = teamareas[0]\n            self.log.info(\"Find <TeamArea %s>\", teamarea)\n            return teamarea\n\n        self.log.error(\"No TeamArea named %s\", teamarea_name)\n        raise exception.NotFound(\"No TeamArea named %s\" % teamarea_name)", "response": "Get a specific team area."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTeamAreas(self, projectarea_id=None, projectarea_name=None,\n                     archived=False, returned_properties=None):\n        \"\"\"Get all :class:`rtcclient.models.TeamArea` objects by\n        project area id or name\n\n        If both `projectarea_id` and `projectarea_name` are `None`,\n        all team areas in all project areas will be returned.\n\n        If no :class:`rtcclient.models.TeamArea` objects are retrieved,\n        `None` is returned.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the team areas\n            are archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: a :class:`list` that contains all the\n            :class:`rtcclient.models.TeamArea` objects\n        :rtype: list\n        \"\"\"\n\n        return self._getTeamAreas(projectarea_id=projectarea_id,\n                                  projectarea_name=projectarea_name,\n                                  archived=archived,\n                                  returned_properties=returned_properties)", "response": "Get all the team areas by project area id or name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getPlannedFor(self, plannedfor_name, projectarea_id=None,\n                      projectarea_name=None, archived=False,\n                      returned_properties=None):\n        \"\"\"Get :class:`rtcclient.models.PlannedFor` object by its name\n\n        :param plannedfor_name: the plannedfor name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the plannedfor\n            is archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.models.PlannedFor` object\n        :rtype: rtcclient.models.PlannedFor\n        \"\"\"\n\n        if not isinstance(plannedfor_name,\n                          six.string_types) or not plannedfor_name:\n            excp_msg = \"Please specify a valid PlannedFor name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        self.log.debug(\"Try to get <PlannedFor %s>\", plannedfor_name)\n        rp = returned_properties\n        plannedfors = self._getPlannedFors(projectarea_id=projectarea_id,\n                                           projectarea_name=projectarea_name,\n                                           archived=archived,\n                                           returned_properties=rp,\n                                           plannedfor_name=plannedfor_name)\n\n        if plannedfors is not None:\n            plannedfor = plannedfors[0]\n            self.log.info(\"Find <PlannedFor %s>\", plannedfor)\n            return plannedfor\n\n        self.log.error(\"No PlannedFor named %s\", plannedfor_name)\n        raise exception.NotFound(\"No PlannedFor named %s\" % plannedfor_name)", "response": "Get a PlannedFor object by its name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the planned for objects by project area id or name.", "response": "def getPlannedFors(self, projectarea_id=None, projectarea_name=None,\n                       archived=False, returned_properties=None):\n        \"\"\"Get all :class:`rtcclient.models.PlannedFor` objects by\n        project area id or name\n\n        If both `projectarea_id` and `projectarea_name` are None,\n        all the plannedfors in all project areas will be returned.\n\n        If no :class:`rtcclient.models.PlannedFor` objecs are retrieved,\n        `None` is returned.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the plannedfors\n            are archived\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: a :class:`list` that contains all the\n            :class:`rtcclient.models.PlannedFor` objects\n        :rtype: list\n        \"\"\"\n\n        return self._getPlannedFors(projectarea_id=projectarea_id,\n                                    projectarea_name=projectarea_name,\n                                    archived=archived,\n                                    returned_properties=returned_properties)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a specific severity by its name", "response": "def getSeverity(self, severity_name, projectarea_id=None,\n                    projectarea_name=None):\n        \"\"\"Get :class:`rtcclient.models.Severity` object by its name\n\n        At least either of `projectarea_id` and `projectarea_name` is given\n\n        :param severity_name: the severity name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :return: the :class:`rtcclient.models.Severity` object\n        :rtype: rtcclient.models.Severity\n        \"\"\"\n\n        self.log.debug(\"Try to get <Severity %s>\", severity_name)\n        if not isinstance(severity_name,\n                          six.string_types) or not severity_name:\n            excp_msg = \"Please specify a valid Severity name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        severities = self._getSeverities(projectarea_id=projectarea_id,\n                                         projectarea_name=projectarea_name,\n                                         severity_name=severity_name)\n\n        if severities is not None:\n            severity = severities[0]\n            self.log.info(\"Find <Severity %s>\", severity)\n            return severity\n\n        self.log.error(\"No Severity named %s\", severity_name)\n        raise exception.NotFound(\"No Severity named %s\" % severity_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSeverities(self, projectarea_id=None, projectarea_name=None):\n\n        return self._getSeverities(projectarea_id=projectarea_id,\n                                   projectarea_name=projectarea_name)", "response": "Get all theeverities in a project area."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPriority(self, priority_name, projectarea_id=None,\n                    projectarea_name=None):\n        \"\"\"Get :class:`rtcclient.models.Priority` object by its name\n\n        At least either of `projectarea_id` and `projectarea_name` is given\n\n        :param priority_name: the priority name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :return: the :class:`rtcclient.models.Priority` object\n        :rtype: rtcclient.models.Priority\n        \"\"\"\n\n        self.log.debug(\"Try to get <Priority %s>\", priority_name)\n        if not isinstance(priority_name,\n                          six.string_types) or not priority_name:\n            excp_msg = \"Please specify a valid Priority name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        priorities = self._getPriorities(projectarea_id=projectarea_id,\n                                         projectarea_name=projectarea_name,\n                                         priority_name=priority_name)\n\n        if priorities is not None:\n            priority = priorities[0]\n            self.log.info(\"Find <Priority %s>\", priority)\n            return priority\n\n        self.log.error(\"No Priority named %s\", priority_name)\n        raise exception.NotFound(\"No Priority named %s\" % priority_name)", "response": "Get the priority object by its name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getPriorities(self, projectarea_id=None, projectarea_name=None):\n\n        return self._getPriorities(projectarea_id=projectarea_id,\n                                   projectarea_name=projectarea_name)", "response": "Get all the priority objects by project area id or name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a FoundIn object by its name.", "response": "def getFoundIn(self, foundin_name, projectarea_id=None,\n                   projectarea_name=None, archived=False):\n        \"\"\"Get :class:`rtcclient.models.FoundIn` object by its name\n\n        :param foundin_name: the foundin name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the foundin is archived\n        :return: the :class:`rtcclient.models.FoundIn` object\n        :rtype: rtcclient.models.FoundIn\n        \"\"\"\n\n        self.log.debug(\"Try to get <FoundIn %s>\", foundin_name)\n        if not isinstance(foundin_name,\n                          six.string_types) or not foundin_name:\n            excp_msg = \"Please specify a valid PlannedFor name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        foundins = self._getFoundIns(projectarea_id=projectarea_id,\n                                     projectarea_name=projectarea_name,\n                                     archived=archived,\n                                     foundin_name=foundin_name)\n\n        if foundins is not None:\n            foundin = foundins[0]\n            self.log.info(\"Find <FoundIn %s>\", foundin)\n            return foundin\n\n        self.log.error(\"No FoundIn named %s\", foundin_name)\n        raise exception.NotFound(\"No FoundIn named %s\" % foundin_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all the foundins in a project area.", "response": "def getFoundIns(self, projectarea_id=None, projectarea_name=None,\n                    archived=False):\n        \"\"\"Get all :class:`rtcclient.models.FoundIn` objects by\n        project area id or name\n\n        If both `projectarea_id` and `projectarea_name` are `None`,\n        all the foundins in all project areas will be returned.\n\n        If no :class:`rtcclient.models.FoundIn` objects are retrieved,\n        `None` is returned.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the foundins are archived\n        :return: a :class:`list` that contains all the\n            :class:`rtcclient.models.FoundIn` objects\n        :rtype: list\n        \"\"\"\n\n        return self._getFoundIns(projectarea_id=projectarea_id,\n                                 projectarea_name=projectarea_name,\n                                 archived=archived)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a FiledAgainst object by its name.", "response": "def getFiledAgainst(self, filedagainst_name, projectarea_id=None,\n                        projectarea_name=None, archived=False):\n        \"\"\"Get :class:`rtcclient.models.FiledAgainst` object by its name\n\n        :param filedagainst_name: the filedagainst name\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the filedagainst is\n            archived\n        :return: the :class:`rtcclient.models.FiledAgainst` object\n        :rtype: rtcclient.models.FiledAgainst\n        \"\"\"\n\n        self.log.debug(\"Try to get <FiledAgainst %s>\", filedagainst_name)\n        if not isinstance(filedagainst_name,\n                          six.string_types) or not filedagainst_name:\n            excp_msg = \"Please specify a valid FiledAgainst name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        fas = self._getFiledAgainsts(projectarea_id=projectarea_id,\n                                     projectarea_name=projectarea_name,\n                                     archived=archived,\n                                     filedagainst_name=filedagainst_name)\n\n        if fas is not None:\n            filedagainst = fas[0]\n            self.log.info(\"Find <FiledAgainst %s>\", filedagainst)\n            return filedagainst\n\n        error_msg = \"No FiledAgainst named %s\" % filedagainst_name\n        self.log.error(error_msg)\n        raise exception.NotFound(error_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the FiledAgainst objects in a project area.", "response": "def getFiledAgainsts(self, projectarea_id=None, projectarea_name=None,\n                         archived=False):\n        \"\"\"Get all :class:`rtcclient.models.FiledAgainst` objects by\n        project area id or name\n\n        If both `projectarea_id` and `projectarea_name` are `None`,\n        all the filedagainsts in all project areas will be returned.\n\n        If no :class:`rtcclient.models.FiledAgainst` objects are retrieved,\n        `None` is returned.\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param archived: (default is False) whether the filedagainsts are\n            archived\n        :return: a :class:`list` that contains all the\n            :class:`rtcclient.models.FiledAgainst` objects\n        :rtype: list\n        \"\"\"\n\n        return self._getFiledAgainsts(projectarea_id=projectarea_id,\n                                      projectarea_name=projectarea_name,\n                                      archived=archived)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getTemplate(self, copied_from, template_name=None,\n                    template_folder=None, keep=False, encoding=\"UTF-8\"):\n        \"\"\"Get template from some to-be-copied workitems\n\n        More details, please refer to\n        :class:`rtcclient.template.Templater.getTemplate`\n        \"\"\"\n\n        return self.templater.getTemplate(copied_from,\n                                          template_name=template_name,\n                                          template_folder=template_folder,\n                                          keep=keep,\n                                          encoding=encoding)", "response": "Get a template from some to - be - copied workitems\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting templates from a group of to - be - copied workitems and write them to files named after the names in template_names respectively.", "response": "def getTemplates(self, workitems, template_folder=None,\n                     template_names=None, keep=False, encoding=\"UTF-8\"):\n        \"\"\"Get templates from a group of to-be-copied workitems\n        and write them to files named after the names in `template_names`\n        respectively.\n\n        More details, please refer to\n        :class:`rtcclient.template.Templater.getTemplates`\n        \"\"\"\n\n        self.templater.getTemplates(workitems,\n                                    template_folder=template_folder,\n                                    template_names=template_names,\n                                    keep=keep,\n                                    encoding=encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listFieldsFromWorkitem(self, copied_from, keep=False):\n\n        return self.templater.listFieldsFromWorkitem(copied_from,\n                                                     keep=keep)", "response": "List all the attributes to be rendered directly from someWorkItem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a workitem by its id", "response": "def getWorkitem(self, workitem_id, returned_properties=None):\n        \"\"\"Get :class:`rtcclient.workitem.Workitem` object by its id/number\n\n        :param workitem_id: the workitem id/number\n            (integer or equivalent string)\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :return: the :class:`rtcclient.workitem.Workitem` object\n        :rtype: rtcclient.workitem.Workitem\n        \"\"\"\n\n        try:\n            if isinstance(workitem_id, bool):\n                raise ValueError(\"Invalid Workitem id\")\n            if isinstance(workitem_id, six.string_types):\n                workitem_id = int(workitem_id)\n            if not isinstance(workitem_id, int):\n                raise ValueError(\"Invalid Workitem id\")\n\n            workitem_url = \"/\".join([self.url,\n                                     \"oslc/workitems/%s\" % workitem_id])\n\n            rp = self._validate_returned_properties(returned_properties)\n            if rp is not None:\n                req_url = \"\".join([workitem_url,\n                                   \"?oslc_cm.properties=\",\n                                   urlquote(rp)])\n            else:\n                req_url = workitem_url\n            resp = self.get(req_url,\n                            verify=False,\n                            proxies=self.proxies,\n                            headers=self.headers)\n            raw_data = xmltodict.parse(resp.content)\n            workitem_raw = raw_data[\"oslc_cm:ChangeRequest\"]\n\n            return Workitem(workitem_url,\n                            self,\n                            workitem_id=workitem_id,\n                            raw_data=workitem_raw)\n\n        except ValueError:\n            excp_msg = \"Please input a valid workitem id\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n        except Exception as excp:\n            self.log.error(excp)\n            raise exception.NotFound(\"Not found <Workitem %s>\" % workitem_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getWorkitems(self, projectarea_id=None, projectarea_name=None,\n                     returned_properties=None, archived=False):\n        \"\"\"Get all :class:`rtcclient.workitem.Workitem` objects by\n        project area id or name\n\n        If both `projectarea_id` and `projectarea_name` are `None`,\n        all the workitems in all project areas will be returned.\n\n        If no :class:`rtcclient.workitem.Workitem` objects are retrieved,\n        `None` is returned.\n\n        You can also customize your preferred properties to be returned\n        by specified `returned_properties`\n\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :param archived: (default is False) whether the workitems are archived\n        :return: a :class:`list` that contains all the\n            :class:`rtcclient.workitem.Workitem` objects\n        :rtype: list\n        \"\"\"\n\n        workitems_list = list()\n        projectarea_ids = list()\n        if not isinstance(projectarea_id,\n                          six.string_types) or not projectarea_id:\n            pa_ids = self.getProjectAreaIDs(projectarea_name)\n            if pa_ids is None:\n                self.log.warning(\"Stop getting workitems because of \"\n                                 \"no ProjectAreas\")\n                return None\n            projectarea_ids.extend(pa_ids)\n        else:\n            if self.checkProjectAreaID(projectarea_id):\n                projectarea_ids.append(projectarea_id)\n            else:\n                raise exception.BadValue(\"Invalid ProjectAred ID: \"\n                                         \"%s\" % projectarea_id)\n\n        self.log.warning(\"For a single ProjectArea, only latest 1000 \"\n                         \"workitems can be fetched. \"\n                         \"This may be a bug of Rational Team Concert\")\n\n        rp = self._validate_returned_properties(returned_properties)\n        for projarea_id in projectarea_ids:\n            workitems = self._get_paged_resources(\"Workitem\",\n                                                  projectarea_id=projarea_id,\n                                                  page_size=\"100\",\n                                                  returned_properties=rp,\n                                                  archived=archived)\n            if workitems is not None:\n                workitems_list.extend(workitems)\n\n        if not workitems_list:\n            self.log.warning(\"Cannot find a workitem in the ProjectAreas \"\n                             \"with ids: %s\" % projectarea_ids)\n            return None\n        return workitems_list", "response": "Get all the workitems in a project area."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new workitem in the project area.", "response": "def createWorkitem(self, item_type, title, description=None,\n                       projectarea_id=None, projectarea_name=None,\n                       template=None, copied_from=None, keep=False,\n                       **kwargs):\n        \"\"\"Create a workitem\n\n        :param item_type: the type of the workitem\n            (e.g. task/defect/issue)\n        :param title: the title of the new created workitem\n        :param description: the description of the new created workitem\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param template: The template to render.\n            The template is actually a file, which is usually generated\n            by :class:`rtcclient.template.Templater.getTemplate` and can also\n            be modified by user accordingly.\n        :param copied_from: the to-be-copied workitem id\n        :param keep: refer to `keep` in\n            :class:`rtcclient.template.Templater.getTemplate`. Only works when\n            `template` is not specified\n        :param \\*\\*kwargs: Optional/mandatory arguments when creating a new\n            workitem. More details, please refer to `kwargs` in\n            :class:`rtcclient.template.Templater.render`\n        :return: the :class:`rtcclient.workitem.Workitem` object\n        :rtype: rtcclient.workitem.Workitem\n        \"\"\"\n\n        if not isinstance(projectarea_id,\n                          six.string_types) or not projectarea_id:\n            projectarea = self.getProjectArea(projectarea_name)\n            projectarea_id = projectarea.id\n        else:\n            projectarea = self.getProjectAreaByID(projectarea_id)\n\n        itemtype = projectarea.getItemType(item_type)\n\n        if not template:\n            if not copied_from:\n                self.log.error(\"Please choose either-or between \"\n                               \"template and copied_from\")\n                raise exception.EmptyAttrib(\"At least choose either-or \"\n                                            \"between template and copied_from\")\n\n            self._checkMissingParamsFromWorkitem(copied_from, keep=keep,\n                                                 **kwargs)\n            kwargs = self._retrieveValidInfo(projectarea_id,\n                                             **kwargs)\n            wi_raw = self.templater.renderFromWorkitem(copied_from,\n                                                       keep=keep,\n                                                       encoding=\"UTF-8\",\n                                                       title=title,\n                                                       description=description,\n                                                       **kwargs)\n\n        else:\n            self._checkMissingParams(template, **kwargs)\n            kwargs = self._retrieveValidInfo(projectarea_id,\n                                             **kwargs)\n            wi_raw = self.templater.render(template,\n                                           title=title,\n                                           description=description,\n                                           **kwargs)\n\n        self.log.info(\"Start to create a new <%s> with raw data: %s\",\n                      item_type, wi_raw)\n\n        wi_url_post = \"/\".join([self.url,\n                                \"oslc/contexts\",\n                                projectarea_id,\n                                \"workitems/%s\" % itemtype.identifier])\n        return self._createWorkitem(wi_url_post, wi_raw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new workitem by copying from an existing one", "response": "def copyWorkitem(self, copied_from, title=None, description=None,\n                     prefix=None):\n        \"\"\"Create a workitem by copying from an existing one\n\n        :param copied_from: the to-be-copied workitem id\n        :param title: the new workitem title/summary.\n            If `None`, will copy that from a to-be-copied workitem\n        :param description: the new workitem description.\n            If `None`, will copy that from a to-be-copied workitem\n        :param prefix: used to add a prefix to the copied title and\n            description\n        :return: the :class:`rtcclient.workitem.Workitem` object\n        :rtype: rtcclient.workitem.Workitem\n        \"\"\"\n\n        copied_wi = self.getWorkitem(copied_from)\n        if title is None:\n            title = copied_wi.title\n            if prefix is not None:\n                title = prefix + title\n\n        if description is None:\n            description = copied_wi.description\n            if prefix is not None:\n                description = prefix + description\n\n        self.log.info(\"Start to create a new <Workitem>, copied from \",\n                      \"<Workitem %s>\", copied_from)\n\n        wi_url_post = \"/\".join([self.url,\n                                \"oslc/contexts/%s\" % copied_wi.contextId,\n                                \"workitems\",\n                                \"%s\" % copied_wi.type.split(\"/\")[-1]])\n        wi_raw = self.templater.renderFromWorkitem(copied_from,\n                                                   keep=True,\n                                                   encoding=\"UTF-8\",\n                                                   title=title,\n                                                   description=description)\n        return self._createWorkitem(wi_url_post, wi_raw)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _checkMissingParams(self, template, **kwargs):\n\n        parameters = self.listFields(template)\n        self._findMissingParams(parameters, **kwargs)", "response": "Check the missing parameters for rendering from the template file\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the missing parameters for rendering directly from the workitem copied workitem", "response": "def _checkMissingParamsFromWorkitem(self, copied_from, keep=False,\n                                        **kwargs):\n        \"\"\"Check the missing parameters for rendering directly from the\n        copied workitem\n        \"\"\"\n\n        parameters = self.listFieldsFromWorkitem(copied_from,\n                                                 keep=keep)\n        self._findMissingParams(parameters, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkType(self, item_type, projectarea_id):\n\n        self.log.debug(\"Checking the validity of workitem type: %s\",\n                       item_type)\n        try:\n            project_area = self.getProjectAreaByID(projectarea_id)\n            if project_area.getItemType(item_type):\n                return True\n            else:\n                return False\n        except (exception.NotFound, exception.BadValue):\n            self.log.error(\"Invalid ProjectArea name\")\n            return False", "response": "Check the validity of the workitem type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_resource_entry(self, resource_name, entry,\n                               projectarea_url=None, archived=False,\n                               filter_rule=None):\n        \"\"\"\n        :param filter_rule: a list of filter rules\n            e.g. filter_rule = [(\"dc:creator\", \"@rdf:resource\",\n                                 \"https://test.url:9443/jts/users/me%40mail\"),\n                                (\"dc:modified\", None,\n                                 \"2013-08-28T02:06:26.516Z\")\n                                ]\n            only the entry matches all the rules will be kept\n        \"\"\"\n\n        if projectarea_url is not None:\n            try:\n                if (entry.get(\"rtc_cm:projectArea\")\n                         .get(\"@rdf:resource\")) != projectarea_url:\n                    return None\n            except AttributeError:\n                pass\n\n        if filter_rule is not None:\n            # match all the filter rules\n            for frule in filter_rule:\n                fattr, rdf_resource, fvalue = frule\n                try:\n                    if rdf_resource is not None:\n                        frule_value = entry.get(fattr).get(rdf_resource)\n                    else:\n                        frule_value = entry.get(fattr)\n\n                    if frule_value != fvalue:\n                        return None\n                except AttributeError:\n                    pass\n\n        entry_archived = entry.get(\"rtc_cm:archived\")\n        if (entry_archived is not None and\n                eval(entry_archived.capitalize()) != archived):\n            return None\n\n        if resource_name == \"Subscriber\":\n            resource_cls = Member\n        elif resource_name in [\"Query\", \"RunQuery\", \"Parent\", \"Children\"]:\n            resource_cls = Workitem\n        else:\n            resource_cls = eval(resource_name)\n\n        if resource_name in [\"Workitem\",\n                             \"Query\",\n                             \"RunQuery\",\n                             \"Parent\",\n                             \"Children\"]:\n            resource_url = entry.get(\"@rdf:resource\")\n            resource_url = \"/\".join([self.url,\n                                     \"oslc/workitems\",\n                                     resource_url.split(\"/\")[-1]])\n        else:\n            resource_url = entry.get(\"@rdf:resource\")\n\n        resource = resource_cls(resource_url,\n                                self,\n                                raw_data=entry)\n        return resource", "response": "This function handles the resource entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the list of workitems in a certain project area.", "response": "def queryWorkitems(self, query_str, projectarea_id=None,\n                       projectarea_name=None, returned_properties=None,\n                       archived=False):\n        \"\"\"Query workitems with the query string in a certain project area\n\n        At least either of `projectarea_id` and `projectarea_name` is given\n\n        :param query_str: a valid query string\n        :param projectarea_id: the :class:`rtcclient.project_area.ProjectArea`\n            id\n        :param projectarea_name: the project area name\n        :param returned_properties: the returned properties that you want.\n            Refer to :class:`rtcclient.client.RTCClient` for more explanations\n        :param archived: (default is False) whether the workitems are archived\n        :return: a :class:`list` that contains the queried\n            :class:`rtcclient.workitem.Workitem` objects\n        :rtype: list\n        \"\"\"\n\n        rp = returned_properties\n        return self.query.queryWorkitems(query_str=query_str,\n                                         projectarea_id=projectarea_id,\n                                         projectarea_name=projectarea_name,\n                                         returned_properties=rp,\n                                         archived=archived)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getCommentByID(self, comment_id):\n\n        # check the validity of comment id\n        try:\n            if isinstance(comment_id, bool):\n                raise ValueError()\n            if isinstance(comment_id, six.string_types):\n                comment_id = int(comment_id)\n            if not isinstance(comment_id, int):\n                raise ValueError()\n        except (ValueError, TypeError):\n            raise exception.BadValue(\"Please input valid comment id\")\n\n        comment_url = \"/\".join([self.url,\n                                \"rtc_cm:comments/%s\" % comment_id])\n        try:\n            return Comment(comment_url,\n                           self.rtc_obj)\n        except HTTPError:\n            self.log.error(\"Comment %s does not exist\", comment_id)\n            raise exception.BadValue(\"Comment %s does not exist\" % comment_id)", "response": "Get a Comment object by its id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addComment(self, msg=None):\n\n        origin_comment = '''\n<rdf:RDF\n    xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    xmlns:rtc_ext=\"http://jazz.net/xmlns/prod/jazz/rtc/ext/1.0/\"\n    xmlns:rtc_cm=\"http://jazz.net/xmlns/prod/jazz/rtc/cm/1.0/\"\n    xmlns:oslc_cm=\"http://open-services.net/ns/cm#\"\n    xmlns:dcterms=\"http://purl.org/dc/terms/\"\n    xmlns:oslc_cmx=\"http://open-services.net/ns/cm-x#\"\n    xmlns:oslc=\"http://open-services.net/ns/core#\">\n  <rdf:Description rdf:about=\"{0}\">\n    <rdf:type rdf:resource=\"http://open-services.net/ns/core#Comment\"/>\n    <dcterms:description rdf:parseType=\"Literal\">{1}</dcterms:description>\n  </rdf:Description>\n</rdf:RDF>\n'''\n\n        comments_url = \"/\".join([self.url,\n                                 \"rtc_cm:comments\"])\n        headers = copy.deepcopy(self.rtc_obj.headers)\n        resp = self.get(comments_url,\n                        verify=False,\n                        proxies=self.rtc_obj.proxies,\n                        headers=headers)\n\n        raw_data = xmltodict.parse(resp.content)\n\n        total_cnt = raw_data[\"oslc_cm:Collection\"][\"@oslc_cm:totalCount\"]\n        comment_url = \"/\".join([comments_url,\n                                total_cnt])\n\n        comment_msg = origin_comment.format(comment_url, msg)\n\n        headers[\"Content-Type\"] = self.OSLC_CR_RDF\n        headers[\"Accept\"] = self.OSLC_CR_RDF\n        headers[\"OSLC-Core-Version\"] = \"2.0\"\n        headers[\"If-Match\"] = resp.headers.get(\"etag\")\n        req_url = \"/\".join([comments_url,\n                            \"oslc:comment\"])\n\n        resp = self.post(req_url,\n                         verify=False,\n                         headers=headers,\n                         proxies=self.rtc_obj.proxies,\n                         data=comment_msg)\n        self.log.info(\"Successfully add comment: [%s] for <Workitem %s>\",\n                      msg, self)\n\n        raw_data = xmltodict.parse(resp.content)\n        return Comment(comment_url,\n                       self.rtc_obj,\n                       raw_data=raw_data[\"rdf:RDF\"][\"rdf:Description\"])", "response": "Adds a comment to the workitem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addSubscriber(self, email):\n\n        headers, raw_data = self._perform_subscribe()\n        existed_flag, raw_data = self._add_subscriber(email, raw_data)\n        if existed_flag:\n            return\n\n        self._update_subscribe(headers, raw_data)\n        self.log.info(\"Successfully add a subscriber: %s for <Workitem %s>\",\n                      email, self)", "response": "Add a subscriber to this workitem"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addSubscribers(self, emails_list):\n\n        if not hasattr(emails_list, \"__iter__\"):\n            error_msg = \"Input parameter 'emails_list' is not iterable\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        # overall flag\n        existed_flags = False\n\n        headers, raw_data = self._perform_subscribe()\n        for email in emails_list:\n            existed_flag, raw_data = self._add_subscriber(email, raw_data)\n            existed_flags = existed_flags and existed_flag\n\n        if existed_flags:\n            return\n\n        self._update_subscribe(headers, raw_data)\n        self.log.info(\"Successfully add subscribers: %s for <Workitem %s>\",\n                      emails_list, self)", "response": "Adds subscribers to this workitem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a subscriber from this workitem", "response": "def removeSubscriber(self, email):\n        \"\"\"Remove a subscriber from this workitem\n\n        If the subscriber has not been added, no more actions will be\n        performed.\n\n        :param email: the subscriber's email\n        \"\"\"\n\n        headers, raw_data = self._perform_subscribe()\n        missing_flag, raw_data = self._remove_subscriber(email, raw_data)\n        if missing_flag:\n            return\n\n        self._update_subscribe(headers, raw_data)\n        self.log.info(\"Successfully remove a subscriber: %s for <Workitem %s>\",\n                      email, self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove subscribers from this workitem", "response": "def removeSubscribers(self, emails_list):\n        \"\"\"Remove subscribers from this workitem\n\n        If the subscribers have not been added, no more actions will be\n        performed.\n\n        :param emails_list: a :class:`list`/:class:`tuple`/:class:`set`\n            contains the the subscribers' emails\n        \"\"\"\n\n        if not hasattr(emails_list, \"__iter__\"):\n            error_msg = \"Input parameter 'emails_list' is not iterable\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        # overall flag\n        missing_flags = True\n\n        headers, raw_data = self._perform_subscribe()\n        for email in emails_list:\n            missing_flag, raw_data = self._remove_subscriber(email, raw_data)\n            missing_flags = missing_flags and missing_flag\n\n        if missing_flags:\n            return\n\n        self._update_subscribe(headers, raw_data)\n        self.log.info(\"Successfully remove subscribers: %s for <Workitem %s>\",\n                      emails_list, self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the object by its name", "response": "def getAction(self, action_name):\n        \"\"\"Get the :class:`rtcclient.models.Action` object by its name\n\n        :param action_name: the name/title of the action\n        :return: the :class:`rtcclient.models.Action` object\n        :rtype: rtcclient.models.Action\n        \"\"\"\n\n        self.log.debug(\"Try to get <Action %s>\", action_name)\n        if not isinstance(action_name, six.string_types) or not action_name:\n            excp_msg = \"Please specify a valid action name\"\n            self.log.error(excp_msg)\n            raise exception.BadValue(excp_msg)\n\n        actions = self._getActions(action_name=action_name)\n\n        if actions is not None:\n            action = actions[0]\n            self.log.info(\"Find <Action %s>\", action)\n            return action\n\n        self.log.error(\"No Action named %s\", action_name)\n        raise exception.NotFound(\"No Action named %s\" % action_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getStates(self):\n\n        cust_attr = (self.raw_data.get(\"rtc_cm:state\")\n                         .get(\"@rdf:resource\")\n                         .split(\"/\")[-2])\n        return self.rtc_obj._get_paged_resources(\"State\",\n                                                 projectarea_id=self.contextId,\n                                                 customized_attr=cust_attr,\n                                                 page_size=\"50\")", "response": "Get all the the\n s state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all the IncludedInBuilds objects that have already included this workitem.", "response": "def getIncludedInBuilds(self):\n        \"\"\"Get all :class:`rtcclient.models.IncludedInBuild` objects that\n        have already included this workitem\n\n        WARNING: If one of the IncludedInBuilds is removed or cannot be\n        retrieved/found correctly, then 404 error will be raised.\n\n        :return: a :class:`list` contains all the\n            :class:`rtcclient.models.IncludedInBuild` objects\n        :rtype: list\n        \"\"\"\n\n        build_tag = (\"rtc_cm:com.ibm.team.build.linktype.includedWorkItems.\"\n                     \"com.ibm.team.build.common.link.includedInBuilds\")\n        return self.rtc_obj._get_paged_resources(\"IncludedInBuild\",\n                                                 workitem_id=self.identifier,\n                                                 customized_attr=build_tag,\n                                                 page_size=\"5\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getParent(self, returned_properties=None):\n\n        parent_tag = (\"rtc_cm:com.ibm.team.workitem.linktype.\"\n                      \"parentworkitem.parent\")\n        rp = returned_properties\n        parent = (self.rtc_obj\n                      ._get_paged_resources(\"Parent\",\n                                            workitem_id=self.identifier,\n                                            customized_attr=parent_tag,\n                                            page_size=\"5\",\n                                            returned_properties=rp))\n\n        # No more than one parent\n        if parent:\n            # only one element\n            return parent[0]\n        return None", "response": "Get the parent workitem of this workitem."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getChildren(self, returned_properties=None):\n\n        children_tag = (\"rtc_cm:com.ibm.team.workitem.linktype.\"\n                        \"parentworkitem.children\")\n        rp = returned_properties\n        return (self.rtc_obj\n                    ._get_paged_resources(\"Children\",\n                                          workitem_id=self.identifier,\n                                          customized_attr=children_tag,\n                                          page_size=\"10\",\n                                          returned_properties=rp))", "response": "Get all the children workitems of this workitem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getChangeSets(self):\n\n        changeset_tag = (\"rtc_cm:com.ibm.team.filesystem.workitems.\"\n                         \"change_set.com.ibm.team.scm.ChangeSet\")\n        return (self.rtc_obj\n                    ._get_paged_resources(\"ChangeSet\",\n                                          workitem_id=self.identifier,\n                                          customized_attr=changeset_tag,\n                                          page_size=\"10\"))", "response": "Get all the ChangeSets of this workitem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addParent(self, parent_id):\n\n        if isinstance(parent_id, bool):\n            raise exception.BadValue(\"Please input a valid workitem id\")\n        if isinstance(parent_id, six.string_types):\n            parent_id = int(parent_id)\n        if not isinstance(parent_id, int):\n            raise exception.BadValue(\"Please input a valid workitem id\")\n\n        self.log.debug(\"Try to add a parent <Workitem %s> to current \"\n                       \"<Workitem %s>\",\n                       parent_id,\n                       self)\n\n        headers = copy.deepcopy(self.rtc_obj.headers)\n        headers[\"Content-Type\"] = self.OSLC_CR_JSON\n        req_url = \"\".join([self.url,\n                           \"?oslc_cm.properties=com.ibm.team.workitem.\",\n                           \"linktype.parentworkitem.parent\"])\n\n        parent_tag = (\"rtc_cm:com.ibm.team.workitem.linktype.\"\n                      \"parentworkitem.parent\")\n        parent_url = (\"{0}/resource/itemName/com.ibm.team.\"\n                      \"workitem.WorkItem/{1}\".format(self.rtc_obj.url,\n                                                     parent_id))\n        parent_original = {parent_tag: [{\"rdf:resource\": parent_url}]}\n\n        self.put(req_url,\n                 verify=False,\n                 proxies=self.rtc_obj.proxies,\n                 headers=headers,\n                 data=json.dumps(parent_original))\n        self.log.info(\"Successfully add a parent <Workitem %s> to current \"\n                      \"<Workitem %s>\",\n                      parent_id,\n                      self)", "response": "Add a parent to the current workitem"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addChild(self, child_id):\n\n        self.log.debug(\"Try to add a child <Workitem %s> to current \"\n                       \"<Workitem %s>\",\n                       child_id,\n                       self)\n        self._addChildren([child_id])\n        self.log.info(\"Successfully add a child <Workitem %s> to current \"\n                      \"<Workitem %s>\",\n                      child_id,\n                      self)", "response": "Add a child to the current workitem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addChildren(self, child_ids):\n\n        if not hasattr(child_ids, \"__iter__\"):\n            error_msg = \"Input parameter 'child_ids' is not iterable\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        self.log.debug(\"Try to add children <Workitem %s> to current \"\n                       \"<Workitem %s>\",\n                       child_ids,\n                       self)\n        self._addChildren(child_ids)\n        self.log.info(\"Successfully add children <Workitem %s> to current \"\n                      \"<Workitem %s>\",\n                      child_ids,\n                      self)", "response": "Add children to current workitem"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef removeParent(self):\n\n        self.log.debug(\"Try to remove the parent workitem from current \"\n                       \"<Workitem %s>\",\n                       self)\n\n        headers = copy.deepcopy(self.rtc_obj.headers)\n        headers[\"Content-Type\"] = self.OSLC_CR_JSON\n        req_url = \"\".join([self.url,\n                           \"?oslc_cm.properties=com.ibm.team.workitem.\",\n                           \"linktype.parentworkitem.parent\"])\n\n        parent_tag = (\"rtc_cm:com.ibm.team.workitem.linktype.\"\n                      \"parentworkitem.parent\")\n        parent_original = {parent_tag: []}\n\n        self.put(req_url,\n                 verify=False,\n                 proxies=self.rtc_obj.proxies,\n                 headers=headers,\n                 data=json.dumps(parent_original))\n        self.log.info(\"Successfully remove the parent workitem of current \"\n                      \"<Workitem %s>\",\n                      self)", "response": "Remove the parent workitem from current workitem"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a child from the current workitem", "response": "def removeChild(self, child_id):\n        \"\"\"Remove a child from current workitem\n\n        :param child_id: the child workitem id/number\n            (integer or equivalent string)\n        \"\"\"\n\n        self.log.debug(\"Try to remove a child <Workitem %s> from current \"\n                       \"<Workitem %s>\",\n                       child_id,\n                       self)\n        self._removeChildren([child_id])\n        self.log.info(\"Successfully remove a child <Workitem %s> from \"\n                      \"current <Workitem %s>\",\n                      child_id,\n                      self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves children from current workitem", "response": "def removeChildren(self, child_ids):\n        \"\"\"Remove children from current workitem\n\n        :param child_ids: a :class:`list` contains the children\n            workitem id/number (integer or equivalent string)\n        \"\"\"\n\n        if not hasattr(child_ids, \"__iter__\"):\n            error_msg = \"Input parameter 'child_ids' is not iterable\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        self.log.debug(\"Try to remove children <Workitem %s> from current \"\n                       \"<Workitem %s>\",\n                       child_ids,\n                       self)\n        self._removeChildren(child_ids)\n        self.log.info(\"Successfully remove children <Workitem %s> from \"\n                      \"current <Workitem %s>\",\n                      child_ids,\n                      self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addAttachment(self, filepath):\n\n        proj_id = self.contextId\n\n        fa = self.rtc_obj.getFiledAgainst(self.filedAgainst,\n                                          projectarea_id=proj_id)\n        fa_id = fa.url.split(\"/\")[-1]\n\n        headers = copy.deepcopy(self.rtc_obj.headers)\n        if headers.__contains__(\"Content-Type\"):\n            headers.__delitem__(\"Content-Type\")\n\n        filename = os.path.basename(filepath)\n        fileh = open(filepath, \"rb\")\n        files = {\"attach\": (filename, fileh, \"application/octet-stream\")}\n\n        params = {\"projectId\": proj_id,\n                  \"multiple\": \"true\",\n                  \"category\": fa_id}\n        req_url = \"\".join([self.rtc_obj.url,\n                           \"/service/com.ibm.team.workitem.service.\",\n                           \"internal.rest.IAttachmentRestService/\"])\n        resp = self.post(req_url,\n                         verify=False,\n                         headers=headers,\n                         proxies=self.rtc_obj.proxies,\n                         params=params,\n                         files=files)\n        raw_data = xmltodict.parse(resp.content)\n        json_body = json.loads(raw_data[\"html\"][\"body\"][\"textarea\"])\n        attachment_info = json_body[\"files\"][0]\n        return self._add_attachment_link(attachment_info)", "response": "Uploads an attachment to a workitem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAttachments(self):\n\n        attachment_tag = (\"rtc_cm:com.ibm.team.workitem.linktype.\"\n                          \"attachment.attachment\")\n        return (self.rtc_obj\n                    ._get_paged_resources(\"Attachment\",\n                                          workitem_id=self.identifier,\n                                          customized_attr=attachment_tag,\n                                          page_size=\"10\"))", "response": "Get all the the\n            objects of this workitem"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the containers on the system.", "response": "def list_containers(active=True, defined=True,\n                    as_object=False, config_path=None):\n    \"\"\"\n        List the containers on the system.\n    \"\"\"\n\n    if config_path:\n        if not os.path.exists(config_path):\n            return tuple()\n        try:\n            entries = _lxc.list_containers(active=active, defined=defined,\n                                           config_path=config_path)\n        except ValueError:\n            return tuple()\n    else:\n        try:\n            entries = _lxc.list_containers(active=active, defined=defined)\n        except ValueError:\n            return tuple()\n\n    if as_object:\n        return tuple([Container(name, config_path) for name in entries])\n    else:\n        return entries"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a command when attaching", "response": "def attach_run_command(cmd):\n    \"\"\"\n        Run a command when attaching\n\n        Please do not call directly, this will execvp the command.\n        This is to be used in conjunction with the attach method\n        of a container.\n    \"\"\"\n    if isinstance(cmd, tuple):\n        return _lxc.attach_run_command(cmd)\n    elif isinstance(cmd, list):\n        return _lxc.attach_run_command((cmd[0], cmd))\n    else:\n        return _lxc.attach_run_command((cmd, [cmd]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arch_to_personality(arch):\n    if isinstance(arch, bytes):\n        arch = unicode(arch)\n    return _lxc.arch_to_personality(arch)", "response": "Determine the process personality corresponding to the architecture"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds network device to running container.", "response": "def add_device_net(self, name, destname=None):\n        \"\"\"\n            Add network device to running container.\n        \"\"\"\n\n        if not self.running:\n            return False\n\n        if os.path.exists(\"/sys/class/net/%s/phy80211/name\" % name):\n            with open(\"/sys/class/net/%s/phy80211/name\" % name) as fd:\n                phy = fd.read().strip()\n\n            if subprocess.call(['iw', 'phy', phy, 'set', 'netns',\n                                str(self.init_pid)]) != 0:\n                return False\n\n            if destname:\n                def rename_interface(args):\n                    old, new = args\n\n                    return subprocess.call(['ip', 'link', 'set',\n                                            'dev', old, 'name', new])\n\n                return self.attach_wait(rename_interface, (name, destname),\n                                        namespaces=(CLONE_NEWNET)) == 0\n\n            return True\n\n        if not destname:\n            destname = name\n\n        if not os.path.exists(\"/sys/class/net/%s/\" % name):\n            return False\n\n        return subprocess.call(['ip', 'link', 'set',\n                                'dev', name,\n                                'netns', str(self.init_pid),\n                                'name', destname]) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_config_item(self, key, value):\n\n        return _lxc.Container.set_config_item(self, key, value)", "response": "Append value to key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new rootfs for the container.", "response": "def create(self, template=None, flags=0, args=()):\n        \"\"\"\n            Create a new rootfs for the container.\n\n            \"template\" if passed must be a valid template name.\n\n            \"flags\" (optional) is an integer representing the optional\n            create flags to be passed.\n\n            \"args\" (optional) is a tuple of arguments to pass to the\n            template. It can also be provided as a dict.\n        \"\"\"\n\n        if isinstance(args, dict):\n            template_args = []\n            for item in args.items():\n                template_args.append(\"--%s\" % item[0])\n                template_args.append(\"%s\" % item[1])\n        else:\n            template_args = args\n\n        if template:\n            return _lxc.Container.create(self, template=template,\n                                         flags=flags,\n                                         args=tuple(template_args))\n        else:\n            return _lxc.Container.create(self, flags=flags,\n                                         args=tuple(template_args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncloning the current container.", "response": "def clone(self, newname, config_path=None, flags=0, bdevtype=None,\n              bdevdata=None, newsize=0, hookargs=()):\n        \"\"\"\n            Clone the current container.\n        \"\"\"\n\n        args = {}\n        args['newname'] = newname\n        args['flags'] = flags\n        args['newsize'] = newsize\n        args['hookargs'] = hookargs\n        if config_path:\n            args['config_path'] = config_path\n        if bdevtype:\n            args['bdevtype'] = bdevtype\n        if bdevdata:\n            args['bdevdata'] = bdevdata\n\n        if _lxc.Container.clone(self, **args):\n            return Container(newname, config_path=config_path)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef console(self, ttynum=-1, stdinfd=0, stdoutfd=1, stderrfd=2, escape=1):\n\n        if not self.running:\n            return False\n\n        return _lxc.Container.console(self, ttynum, stdinfd, stdoutfd,\n                                      stderrfd, escape)", "response": "Wrapper for _lxc. Container. console"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the fd of the console.", "response": "def console_getfd(self, ttynum=-1):\n        \"\"\"\n            Attach to console of running container.\n        \"\"\"\n\n        if not self.running:\n            return False\n\n        return _lxc.Container.console_getfd(self, ttynum)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value for a given cgroup entry.", "response": "def get_cgroup_item(self, key):\n        \"\"\"\n            Returns the value for a given cgroup entry.\n            A list is returned when multiple values are set.\n        \"\"\"\n        value = _lxc.Container.get_cgroup_item(self, key)\n\n        if value is False:\n            return False\n        else:\n            return value.rstrip(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the value for a given config key.", "response": "def get_config_item(self, key):\n        \"\"\"\n            Returns the value for a given config key.\n            A list is returned when multiple values are set.\n        \"\"\"\n        value = _lxc.Container.get_config_item(self, key)\n\n        if value is False:\n            return False\n        elif value.endswith(\"\\n\"):\n            return value.rstrip(\"\\n\").split(\"\\n\")\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of valid sub - keys.", "response": "def get_keys(self, key=None):\n        \"\"\"\n            Returns a list of valid sub-keys.\n        \"\"\"\n        if key:\n            value = _lxc.Container.get_keys(self, key)\n        else:\n            value = _lxc.Container.get_keys(self)\n\n        if value is False:\n            return False\n        elif value.endswith(\"\\n\"):\n            return value.rstrip(\"\\n\").split(\"\\n\")\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ips(self, interface=None, family=None, scope=None, timeout=0):\n\n        kwargs = {}\n        if interface:\n            kwargs['interface'] = interface\n        if family:\n            kwargs['family'] = family\n        if scope:\n            kwargs['scope'] = scope\n\n        ips = None\n        timeout = int(os.environ.get('LXC_GETIP_TIMEOUT', timeout))\n\n        while not ips:\n            ips = _lxc.Container.get_ips(self, **kwargs)\n            if timeout == 0:\n                break\n\n            timeout -= 1\n            time.sleep(1)\n\n        return ips", "response": "Get a tuple of IPs for the container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrenaming the container. On success, returns the new Container object. On failure, returns False.", "response": "def rename(self, new_name):\n        \"\"\"\n            Rename the container.\n            On success, returns the new Container object.\n            On failure, returns False.\n        \"\"\"\n\n        if _lxc.Container.rename(self, new_name):\n            return Container(new_name)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_config_item(self, key, value):\n        try:\n            old_value = self.get_config_item(key)\n        except KeyError:\n            old_value = None\n\n        # Get everything to unicode with python2\n        if isinstance(value, str):\n            value = value.decode()\n        elif isinstance(value, list):\n            for i in range(len(value)):\n                if isinstance(value[i], str):\n                    value[i] = value[i].decode()\n\n        # Check if it's a list\n        def set_key(key, value):\n            self.clear_config_item(key)\n            if isinstance(value, list):\n                for entry in value:\n                    if not _lxc.Container.set_config_item(self, key, entry):\n                        return False\n            else:\n                _lxc.Container.set_config_item(self, key, value)\n\n        set_key(key, value)\n        new_value = self.get_config_item(key)\n\n        # loglevel is special and won't match the string we set\n        if key == \"lxc.loglevel\":\n            new_value = value\n\n        if (isinstance(value, unicode) and isinstance(new_value, unicode) and\n                value == new_value):\n            return True\n        elif (isinstance(value, list) and isinstance(new_value, list) and\n                set(value) == set(new_value)):\n            return True\n        elif (isinstance(value, unicode) and isinstance(new_value, list) and\n                set([value]) == set(new_value)):\n            return True\n        elif old_value:\n            set_key(key, old_value)\n            return False\n        else:\n            self.clear_config_item(key)\n            return False", "response": "Set a config key to a provided value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for the container to reach a given state.", "response": "def wait(self, state, timeout=-1):\n        \"\"\"\n            Wait for the container to reach a given state or timeout.\n        \"\"\"\n\n        if isinstance(state, str):\n            state = state.upper()\n\n        return _lxc.Container.wait(self, state, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render(self, template, **kwargs):\n\n        try:\n            temp = self.environment.get_template(template)\n            return temp.render(**kwargs)\n        except AttributeError:\n            err_msg = \"Invalid value for 'template'\"\n            self.log.error(err_msg)\n            raise exception.BadValue(err_msg)", "response": "Renders the template and returns the string representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef renderFromWorkitem(self, copied_from, keep=False,\n                           encoding=\"UTF-8\", **kwargs):\n        \"\"\"Render the template directly from some to-be-copied\n        :class:`rtcclient.workitem.Workitem` without saving to a file\n\n        :param copied_from: the to-be-copied\n            :class:`rtcclient.workitem.Workitem` id\n        :param keep (default is False): If `True`, some of the below fields\n            will remain unchangeable with the to-be-copied\n            :class:`rtcclient.workitem.Workitem`.\n            Otherwise for `False`.\n\n                * teamArea (Team Area)\n                * ownedBy (Owned By)\n                * plannedFor(Planned For)\n                * severity(Severity)\n                * priority(Priority)\n                * filedAgainst(Filed Against)\n        :param encoding (default is \"UTF-8\"): coding format\n        :param kwargs: The `kwargs` dict is used to fill the template.\n            These two parameter are mandatory:\n\n                * description\n                * title\n\n            Some of below parameters (which may not be included in some\n            customized workitem type ) are mandatory if `keep` is set to\n            `False`; Optional for otherwise.\n\n                * teamArea (Team Area)\n                * ownedBy (Owned By)\n                * plannedFor(Planned For)\n                * severity(Severity)\n                * priority(Priority)\n                * filedAgainst(Filed Against)\n\n            Actually all these needed keywords/attributes/fields can be\n            retrieved by\n            :class:`rtcclient.template.Templater.listFieldsFromWorkitem`\n\n        :return: the :class:`string` object\n        :rtype: string\n        \"\"\"\n\n        temp = jinja2.Template(self.getTemplate(copied_from,\n                                                template_name=None,\n                                                template_folder=None,\n                                                keep=keep,\n                                                encoding=encoding))\n        return temp.render(**kwargs)", "response": "Render the template directly from some to - be - copied workitem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listFields(self, template):\n\n        try:\n            temp_source = self.environment.loader.get_source(self.environment,\n                                                             template)\n            return self.listFieldsFromSource(temp_source)\n        except AttributeError:\n            err_msg = \"Invalid value for 'template'\"\n            self.log.error(err_msg)\n            raise exception.BadValue(err_msg)", "response": "List all the needed attributes from the template file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef listFieldsFromWorkitem(self, copied_from, keep=False):\n\n        temp_source = self.getTemplate(copied_from,\n                                       template_name=None,\n                                       template_folder=None,\n                                       keep=keep)\n        return self.listFieldsFromSource(temp_source)", "response": "List all the attributes to be rendered directly from someWorkItem."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all the attributes to be rendered directly from template", "response": "def listFieldsFromSource(self, template_source):\n        \"\"\"List all the attributes to be rendered directly from template\n        source\n\n        :param template_source: the template source (usually represents the\n            template content in string format)\n        :return: a :class:`set` contains all the needed attributes\n        :rtype: set\n        \"\"\"\n\n        ast = self.environment.parse(template_source)\n        return jinja2.meta.find_undeclared_variables(ast)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getTemplate(self, copied_from, template_name=None,\n                    template_folder=None, keep=False, encoding=\"UTF-8\"):\n        \"\"\"Get template from some to-be-copied\n        :class:`rtcclient.workitem.Workitem`\n\n        The resulting XML document is returned as a :class:`string`, but if\n        `template_name` (a string value) is specified,\n        it is written there instead.\n\n        :param copied_from: the to-be-copied\n            :class:`rtcclient.workitem.Workitem` id (integer or\n            equivalent string)\n        :param template_name: the template file name\n        :param template_folder: the folder to store template file\n        :param keep: (default is False) If `True`, some of below parameters\n            (which may not be included in some customized\n            :class:`rtcclient.workitem.Workitem` type ) will remain\n            unchangeable with the to-be-copied\n            :class:`rtcclient.workitem.Workitem`.\n            Otherwise for `False`.\n\n                * teamArea (Team Area)\n                * ownedBy (Owned By)\n                * plannedFor(Planned For)\n                * severity(Severity)\n                * priority(Priority)\n                * filedAgainst(Filed Against)\n        :param encoding: (default is \"UTF-8\") coding format\n        :return:\n\n            * a :class:`string` object: if `template_name` is not specified\n            * write the template to file `template_name`: if `template_name` is\n              specified\n        \"\"\"\n\n        try:\n            if isinstance(copied_from, bool) or isinstance(copied_from, float):\n                raise ValueError()\n            if isinstance(copied_from, six.string_types):\n                copied_from = int(copied_from)\n            if not isinstance(copied_from, int):\n                raise ValueError()\n        except ValueError:\n            err_msg = \"Please input a valid workitem id you want to copy from\"\n            self.log.error(err_msg)\n            raise exception.BadValue(err_msg)\n\n        self.log.info(\"Fetch the template from <Workitem %s> with [keep]=%s\",\n                      copied_from, keep)\n\n        if template_folder is None:\n            template_folder = self.searchpath\n\n        # identify whether output to a file\n        if template_name is not None:\n            template_file_path = os.path.join(template_folder,\n                                              template_name)\n            output = open(template_file_path, \"w\")\n        else:\n            template_file_path = None\n            output = None\n\n        workitem_url = \"/\".join([self.url,\n                                 \"oslc/workitems/%s\" % copied_from])\n        resp = self.get(workitem_url,\n                        verify=False,\n                        proxies=self.rtc_obj.proxies,\n                        headers=self.rtc_obj.headers)\n        raw_data = xmltodict.parse(resp.content)\n\n        # pre-adjust the template:\n        # remove some attribute to avoid being overwritten, which will only be\n        # generated when the workitem is created\n        wk_raw_data = raw_data.get(\"oslc_cm:ChangeRequest\")\n        self._remove_long_fields(wk_raw_data)\n\n        # Be cautious when you want to modify these fields\n        # These fields have been tested as must-removed one\n        remove_fields = [\"@rdf:about\",\n                         \"dc:created\",\n                         \"dc:creator\",\n                         \"dc:identifier\",\n                         \"rtc_cm:contextId\",\n                         \"rtc_cm:comments\",\n                         \"rtc_cm:state\",\n                         \"dc:type\",\n                         \"rtc_cm:subscribers\",\n                         \"dc:modified\",\n                         \"rtc_cm:modifiedBy\",\n                         \"rtc_cm:resolved\",\n                         \"rtc_cm:resolvedBy\",\n                         \"rtc_cm:resolution\",\n                         \"rtc_cm:startDate\",\n                         \"rtc_cm:timeSpent\",\n                         \"rtc_cm:progressTracking\",\n                         \"rtc_cm:projectArea\",\n                         \"oslc_cm:relatedChangeManagement\",\n                         \"oslc_cm:trackedWorkItem\",\n                         \"oslc_cm:tracksWorkItem\",\n                         \"rtc_cm:timeSheet\",\n                         \"oslc_pl:schedule\"]\n\n        for remove_field in remove_fields:\n            try:\n                wk_raw_data.pop(remove_field)\n                self.log.debug(\"Successfully remove field [%s] from the \"\n                               \"template originated from <Workitem %s>\",\n                               remove_field,\n                               copied_from)\n            except:\n                self.log.warning(\"No field named [%s] in this template \"\n                                 \"from <Workitem %s>\", remove_field,\n                                 copied_from)\n                continue\n\n        wk_raw_data[\"dc:description\"] = \"{{ description }}\"\n        wk_raw_data[\"dc:title\"] = \"{{ title }}\"\n\n        if keep:\n            if template_file_path:\n                self.log.info(\"Writing the template to file %s\",\n                              template_file_path)\n            return xmltodict.unparse(raw_data, output=output,\n                                     encoding=encoding,\n                                     pretty=True)\n\n        replace_fields = [(\"rtc_cm:teamArea\", \"{{ teamArea }}\"),\n                          (\"rtc_cm:ownedBy\", \"{{ ownedBy }}\"),\n                          (\"rtc_cm:plannedFor\", \"{{ plannedFor }}\"),\n                          (\"rtc_cm:foundIn\", \"{{ foundIn }}\"),\n                          (\"oslc_cm:severity\", \"{{ severity }}\"),\n                          (\"oslc_cm:priority\", \"{{ priority }}\"),\n                          (\"rtc_cm:filedAgainst\", \"{{ filedAgainst }}\")]\n        for field in replace_fields:\n            try:\n                wk_raw_data[field[0]][\"@rdf:resource\"] = field[1]\n                self.log.debug(\"Successfully replace field [%s] with [%s]\",\n                               field[0], field[1])\n            except:\n                self.log.warning(\"Cannot replace field [%s]\", field[0])\n                continue\n\n        if template_file_path:\n            self.log.info(\"Writing the template to file %s\",\n                          template_file_path)\n\n        return xmltodict.unparse(raw_data, output=output,\n                                 encoding=encoding,\n                                 pretty=True)", "response": "Get the template from some to - be - copied workitem."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving long fields from the workitems.", "response": "def _remove_long_fields(self, wk_raw_data):\n        \"\"\"Remove long fields: These fields are can only customized after\n        the workitems are created\n\n        \"\"\"\n\n        match_str_list = [\"rtc_cm:com.ibm.\",\n                          \"calm:\"]\n        for key in wk_raw_data.keys():\n            for match_str in match_str_list:\n                if key.startswith(match_str):\n                    try:\n                        wk_raw_data.pop(key)\n                        self.log.debug(\"Successfully remove field [%s] from \"\n                                       \"the template\", key)\n                    except:\n                        self.log.warning(\"Cannot remove field [%s] from the \"\n                                         \"template\", key)\n                    continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets templates from a group of to - be - copied Workitems and write them to files named after the names in template_names respectively.", "response": "def getTemplates(self, workitems, template_folder=None,\n                     template_names=None, keep=False, encoding=\"UTF-8\"):\n        \"\"\"Get templates from a group of to-be-copied :class:`Workitems` and\n        write them to files named after the names in `template_names`\n        respectively.\n\n        :param workitems: a :class:`list`/:class:`tuple`/:class:`set`\n            contains the ids (integer or equivalent string) of some\n            to-be-copied :class:`Workitems`\n        :param template_names: a :class:`list`/:class:`tuple`/:class:`set`\n            contains the template file names for copied :class:`Workitems`.\n            If `None`, the new template files will be named after the\n            :class:`rtcclient.workitem.Workitem` id with \"`.template`\" as a\n            postfix\n        :param template_folder: refer to\n            :class:`rtcclient.template.Templater.getTemplate`\n        :param keep: (default is False) refer to\n            :class:`rtcclient.template.Templater.getTemplate`\n        :param encoding: (default is \"UTF-8\") refer to\n            :class:`rtcclient.template.Templater.getTemplate`\n        \"\"\"\n\n        if (not workitems or isinstance(workitems, six.string_types) or\n                isinstance(workitems, int) or\n                isinstance(workitems, float) or\n                not hasattr(workitems, \"__iter__\")):\n            error_msg = \"Input parameter 'workitems' is not iterable\"\n            self.log.error(error_msg)\n            raise exception.BadValue(error_msg)\n\n        if template_names is not None:\n            if not hasattr(template_names, \"__iter__\"):\n                error_msg = \"Input parameter 'template_names' is not iterable\"\n                self.log.error(error_msg)\n                raise exception.BadValue(error_msg)\n\n            if len(workitems) != len(template_names):\n                error_msg = \"\".join([\"Input parameters 'workitems' and \",\n                                     \"'template_names' have different length\"])\n                self.log.error(error_msg)\n                raise exception.BadValue(error_msg)\n\n        for index, wk_id in enumerate(workitems):\n            try:\n                if template_names is not None:\n                    template_name = template_names[index]\n                else:\n                    template_name = \".\".join([wk_id, \"template\"])\n                self.getTemplate(wk_id,\n                                 template_name=template_name,\n                                 template_folder=template_folder,\n                                 keep=keep,\n                                 encoding=encoding)\n            except Exception as excp:\n                self.log.error(\"Exception occurred when fetching\"\n                               \"template from <Workitem %s>: %s\",\n                               str(wk_id), excp)\n                continue\n        self.log.info(\"Successfully fetch all the templates from \"\n                      \"workitems: %s\", workitems)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all the changes in this changeset", "response": "def getChanges(self):\n        \"\"\"Get all :class:`rtcclient.models.Change` objects in this changeset\n\n        :return: a :class:`list` contains all the\n            :class:`rtcclient.models.Change` objects\n        :rtype: list\n        \"\"\"\n\n        identifier = self.url.split(\"/\")[-1]\n        resource_url = \"/\".join([\"%s\" % self.rtc_obj.url,\n                                 \"resource/itemOid\",\n                                 \"com.ibm.team.scm.ChangeSet\",\n                                 \"%s?_mediaType=text/xml\" % identifier])\n        resp = self.get(resource_url,\n                        verify=False,\n                        proxies=self.rtc_obj.proxies,\n                        headers=self.rtc_obj.headers)\n        raw_data = xmltodict.parse(resp.content).get(\"scm:ChangeSet\")\n        common_changes = dict()\n        changes = raw_data.get(\"changes\")\n        for (key, value) in raw_data.items():\n            if key.startswith(\"@\"):\n                continue\n            if \"changes\" != key:\n                common_changes[key] = value\n        return self._handle_changes(changes, common_changes)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetchBeforeStateFile(self, file_folder):\n\n        if u\"true\" == self.before:\n            self.log.info(\"This file is newly added. No previous file\")\n        else:\n            self.log.info(\"Fetching initial file of this Change<%s>:\" % self)\n            return self._fetchFile(self.before, file_folder, override=False)", "response": "Fetch the initial file before the change."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetchAfterStateFile(self, file_folder):\n\n        if u\"true\" == self.after:\n            self.log.info(\"This file has been deleted successfully.\")\n        else:\n            self.log.info(\"Fetching final file of this Change<%s>:\" % self)\n            return self._fetchFile(self.after, file_folder)", "response": "Fetch the final file after the change."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps all the rows of the given table", "response": "def table_dump(self, table):\n        \"\"\"dump all the rows of the given table name\"\"\"\n        if not table: raise ValueError(\"no table\")\n\n        print('------- dumping table {}'.format(table))\n        pipes = [\"gzip\"]\n        outfile_path = self._get_outfile_path(table)\n        cmd = self._get_args(\n            \"pg_dump\",\n            \"--table={}\".format(table),\n            #\"--data-only\",\n            \"--clean\",\n            \"--no-owner\",\n            \"--column-inserts\",\n        )\n        cmd = ' '.join(cmd)\n        cmd += ' | {}'.format(' | '.join(pipes))\n        cmd += ' > {}'.format(outfile_path)\n\n        self._run_cmd(cmd)\n        print('------- dumped table {}'.format(table))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_file(self):\n        '''\n        return an opened tempfile pointer that can be used\n\n        http://docs.python.org/2/library/tempfile.html\n        '''\n        f = tempfile.NamedTemporaryFile(delete=False)\n        self.tmp_files.add(f.name)\n        return f", "response": "return an opened tempfile pointer that can be used\n        http://docs. python. org / 2. 6. 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_args(self, executable, *args):\n        args = list(args)\n        args.insert(0, executable)\n        if self.username:\n            args.append(\"--username={}\".format(self.username))\n        if self.host:\n            args.append(\"--host={}\".format(self.host))\n        if self.port:\n            args.append(\"--port={}\".format(self.port))\n\n        args.append(self.dbname)\n        #args.extend(other_args)\n        return args", "response": "compile all the executable and the arguments combining with common arguments\n        to create a full batch of command args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path for a file we can use to back up the table", "response": "def _get_outfile_path(self, table):\n        \"\"\"return the path for a file we can use to back up the table\"\"\"\n        self.outfile_count += 1\n        outfile = os.path.join(self.directory, '{:03d}_{}.sql.gz'.format(self.outfile_count, table))\n        return outfile"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run_queries(self, queries, *args, **kwargs):\n        # write out all the commands to a temp file and then have psql run that file\n        f = self._get_file()\n        for q in queries:\n            f.write(\"{};\\n\".format(q))\n        f.close()\n\n        psql_args = self._get_args('psql', '-X', '-f {}'.format(f.name))\n        return self._run_cmd(' '.join(psql_args), *args, **kwargs)", "response": "run the queries in the current directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrestore the auto increment value for the table to what it was previously", "response": "def _restore_auto_increment(self, table):\n        \"\"\"restore the auto increment value for the table to what it was previously\"\"\"\n        query, seq_table, seq_column, seq_name = self._get_auto_increment_info(table)\n        if query:\n            queries = [query, \"select nextval('{}')\".format(seq_name)]\n            return self._run_queries(queries)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfigures out the autoincrement value for the given table", "response": "def _get_auto_increment_info(self, table):\n        \"\"\"figure out the the autoincrement value for the given table\"\"\"\n        query = ''\n        seq_table = ''\n        seq_column = ''\n        seq_name = ''\n        find_query = \"\\n\".join([\n            \"SELECT\",\n            \"  t.relname as related_table,\",\n            \"  a.attname as related_column,\",\n            \"  s.relname as sequence_name\",\n            \"FROM pg_class s\",\n            \"JOIN pg_depend d ON d.objid = s.oid\",\n            \"JOIN pg_class t ON d.objid = s.oid AND d.refobjid = t.oid\",\n            \"JOIN pg_attribute a ON (d.refobjid, d.refobjsubid) = (a.attrelid, a.attnum)\",\n            \"JOIN pg_namespace n ON n.oid = s.relnamespace\",\n            \"WHERE\",\n            \"  s.relkind = 'S'\",\n            \"AND\",\n            \"  n.nspname = 'public'\",\n            \"AND\",\n            \"  t.relname = '{}'\".format(table)\n        ])\n\n        pipe = self._run_queries([find_query], popen_kwargs={'stdout': subprocess.PIPE})\n        stdout, stderr = pipe.communicate()\n        if stdout:\n            try:\n                m = re.findall('^\\s*(\\S+)\\s*\\|\\s*(\\S+)\\s*\\|\\s*(\\S+)\\s*$', stdout, flags=re.MULTILINE)\n                seq_table, seq_column, seq_name = m[1]\n                # http://www.postgresql.org/docs/9.2/static/functions-sequence.html\n                # http://www.postgresql.org/docs/9.2/static/functions-conditional.html\n                query = \"\\n\".join([\n                    \"SELECT\",\n                    \"  setval('{}',\".format(seq_name.strip()),\n                    \"  coalesce(max({}), 1),\".format(seq_column.strip()),\n                    \"  max({}) IS NOT null)\".format(seq_column.strip()),\n                    \"FROM \\\"{}\\\"\".format(seq_table.strip())\n                ])\n\n            except IndexError:\n                query = ''\n\n        return query, seq_table, seq_column, seq_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef console():\n    '''\n    cli hook\n\n    return -- integer -- the exit code\n    '''\n    parser = argparse.ArgumentParser(description=\"backup/restore PostgreSQL databases\", add_help=False)\n    parser.add_argument(\"--version\", action='version', version=\"%(prog)s {}\".format(__version__))\n\n    parent_parser = argparse.ArgumentParser(add_help=False)\n    parent_parser.add_argument(\"-d\", \"--dbname\", dest=\"dbname\", help=\"database name to connect to\")\n    parent_parser.add_argument(\"-U\", \"--username\", \"--user\", dest=\"username\", help=\"database user name\")\n    parent_parser.add_argument(\"-W\", \"--password\", dest=\"password\", help=\"database password\")\n    parent_parser.add_argument(\n        \"-h\", \"--host\", \"--hostname\",\n        dest=\"host\",\n        default=\"localhost\",\n        help=\"database server host or socket directory\"\n    )\n    parent_parser.add_argument(\"-p\", \"--port\", type=int, default=5432, dest=\"port\", help=\"database server post\")\n    parent_parser.add_argument(\n        \"--help\",\n        action=\"help\",\n        default=argparse.SUPPRESS,\n        help=\"show this help message and exit\"\n    )\n\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"a sub command\")\n    subparsers.required = True # https://bugs.python.org/issue9253#msg186387\n    backup_parser = subparsers.add_parser(\n        \"backup\",\n        parents=[parent_parser],\n        help=\"backup a PostgreSQL database\",\n        add_help=False\n    )\n    backup_parser.add_argument(\n        \"-D\", \"--dir\", \"--directory\",\n        dest=\"directory\",\n        help=\"directory where the backup files should go\"\n    )\n    backup_parser.add_argument(\n        \"--debug\",\n        dest=\"debug\",\n        action=\"store_true\",\n        help=\"Turn on debugging output\"\n    )\n    backup_parser.add_argument(\"tables\", nargs=\"+\")\n    backup_parser.set_defaults(func=console_backup)\n\n    restore_parser = subparsers.add_parser(\n        \"restore\",\n        parents=[parent_parser],\n        help=\"restore a PostgreSQL database\",\n        add_help=False\n    )\n    restore_parser.add_argument(\n        \"-D\", \"--dir\", \"--directory\",\n        dest=\"directory\",\n        help=\"directory where the backup files are located\"\n    )\n    restore_parser.add_argument(\n        \"--debug\",\n        dest=\"debug\",\n        action=\"store_true\",\n        help=\"Turn on debugging output\"\n    )\n    restore_parser.set_defaults(func=console_restore)\n\n    args = parser.parse_args()\n\n    if args.debug:\n        logging.basicConfig(format=\"[%(levelname).1s] %(message)s\", level=logging.DEBUG, stream=sys.stdout)\n    else:\n        logging.basicConfig(format=\"[%(levelname).1s] %(message)s\", level=logging.INFO, stream=sys.stdout)\n\n    ret_code = args.func(args)\n    return ret_code", "response": "Console command line interface for the\n    database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore(self):\n        sql_files = []\n        for root, dirs, files in os.walk(self.directory):\n            for f in files:\n                if f.endswith(\".sql.gz\"):\n                    path = os.path.join(self.directory, f)\n                    self._run_cmd([\"gunzip\", path])\n                    sql_files.append(f.rstrip(\".gz\"))\n\n                elif f.endswith('.sql'):\n                    sql_files.append(f)\n\n        sql_files.sort() # we want to go in the order the tables were dumped\n        r = re.compile('\\d{3,}_([^\\.]+)')\n        for f in sql_files:\n            path = os.path.join(self.directory, f)\n            m = r.match(f)\n            if m:\n                table = m.group(1)\n                logger.info('------- restoring table {}'.format(table))\n\n                #psql_args = self._get_args('psql', '-X', '--echo-queries', '-f {}'.format(path))\n                psql_args = self._get_args('psql', '-X', '--quiet', '--file={}'.format(path))\n                self._run_cmd(psql_args)\n\n                logger.info('------- restored table {}'.format(table))\n\n        return True", "response": "restore the database from the database"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef table_dump(self, table):\n        if not table: raise ValueError(\"no table\")\n\n        cmds = []\n        logger.info('------- dumping table {}'.format(table))\n        cmd = self._get_args(\n            \"pg_dump\",\n            \"--table={}\".format(table),\n            #\"--data-only\",\n            \"--clean\",\n            \"--no-owner\",\n            \"--column-inserts\",\n        )\n        cmds.append((cmd, {}))\n\n        outfile_path = self._get_outfile_path(table)\n        cmds.append(('gzip > \"{}\"'.format(outfile_path), {\"shell\": True}))\n\n        #cmd += ' | {}'.format(' | '.join(pipes))\n        #cmd += ' > {}'.format(outfile_path)\n\n        self._run_cmds(cmds)\n        logger.info('------- dumped table {}'.format(table))\n        return True", "response": "dump all the rows of the given table"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_env(self):\n        if hasattr(self, 'env'): return self.env\n\n        # create a temporary pgpass file\n        pgpass = self._get_file()\n        # format: http://www.postgresql.org/docs/9.2/static/libpq-pgpass.html\n        pgpass.write('*:*:*:{}:{}\\n'.format(self.username, self.password).encode(\"utf-8\"))\n        pgpass.close()\n        self.env = dict(os.environ)\n        self.env['PGPASSFILE'] = pgpass.name\n\n        # we want to assure a consistent environment\n        if 'PGOPTIONS' in self.env: del self.env['PGOPTIONS']\n        return self.env", "response": "this returns an environment dictionary we want to use to run the command\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_response(**kwargs):\n    if 'code' not in kwargs:\n        kwargs['code'] = 200\n    if 'headers' not in kwargs:\n        kwargs['headers'] = dict()\n    if 'version' not in kwargs:\n        kwargs['version'] = 'HTTP/1.1'\n\n    return dict(**kwargs)", "response": "Get a template response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_transport(self, string):\n        if isinstance(string, str):  # we need to convert to bytes\n            self.transport.write(string.encode('utf-8'))\n        else:\n            self.transport.write(string)", "response": "Convenience function to write to the transport"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the response back to the client", "response": "def _write_response(self, response):\n        \"\"\"Write the response back to the client\n\n        Arguments:\n        response -- the dictionary containing the response.\n        \"\"\"\n        status = '{} {} {}\\r\\n'.format(response['version'],\n                                       response['code'],\n                                       responses[response['code']])\n        self.logger.debug(\"Responding status: '%s'\", status.strip())\n        self._write_transport(status)\n\n        if 'body' in response and 'Content-Length' not in response['headers']:\n            response['headers']['Content-Length'] = len(response['body'])\n\n        response['headers']['Date'] = datetime.utcnow().strftime(\n            \"%a, %d %b %Y %H:%M:%S +0000\")\n\n        for (header, content) in response['headers'].items():\n            self.logger.debug(\"Sending header: '%s: %s'\", header, content)\n            self._write_transport('{}: {}\\r\\n'.format(header, content))\n\n        self._write_transport('\\r\\n')\n        if 'body' in response:\n            self._write_transport(response['body'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connection_made(self, transport):\n        self.logger.info('Connection made at object %s', id(self))\n        self.transport = transport\n        self.keepalive = True\n\n        if self._timeout:\n            self.logger.debug('Registering timeout event')\n            self._timout_handle = self._loop.call_later(\n                self._timeout, self._handle_timeout)", "response": "Called when the connection is made"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when the connection is lost or closed.", "response": "def connection_lost(self, exception):\n        \"\"\"Called when the connection is lost or closed.\n\n        The argument is either an exception object or None. The latter means\n        a regular EOF is received, or the connection was aborted or closed by\n        this side of the connection.\n        \"\"\"\n        if exception:\n            self.logger.exception('Connection lost!')\n        else:\n            self.logger.info('Connection lost')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess incoming data from the socket.", "response": "def data_received(self, data):\n        \"\"\"Process received data from the socket\n\n        Called when we receive data\n        \"\"\"\n        self.logger.debug('Received data: %s', repr(data))\n\n        try:\n            request = self._parse_headers(data)\n            self._handle_request(request)\n        except InvalidRequestError as e:\n            self._write_response(e.get_http_response())\n\n        if not self.keepalive:\n            if self._timeout_handle:\n                self._timeout_handle.cancel()\n            self.transport.close()\n\n        if self._timeout and self._timeout_handle:\n            self.logger.debug('Delaying timeout event')\n            self._timeout_handle.cancel()\n            self._timout_handle = self._loop.call_later(\n                self._timeout, self._handle_timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the request URI into something useful", "response": "def _get_request_uri(self, request):\n        \"\"\"Parse the request URI into something useful\n\n        Server MUST accept full URIs (5.1.2)\"\"\"\n        request_uri = request['target']\n        if request_uri.startswith('/'):  # eg. GET /index.html\n            return (request.get('Host', 'localhost').split(':')[0],\n                    request_uri[1:])\n        elif '://' in request_uri:  # eg. GET http://rded.nl\n            locator = request_uri.split('://', 1)[1]\n            host, path = locator.split('/', 1)\n            return (host.split(':')[0], path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_request(self, request):\n\n        # Check if this is a persistent connection.\n        if request['version'] == 'HTTP/1.1':\n            self.keepalive = not request.get('Connection') == 'close'\n        elif request['version'] == 'HTTP/1.0':\n            self.keepalive = request.get('Connection') == 'Keep-Alive'\n\n        # Check if we're getting a sane request\n        if request['method'] not in ('GET'):\n            raise InvalidRequestError(501, 'Method not implemented')\n        if request['version'] not in ('HTTP/1.0', 'HTTP/1.1'):\n            raise InvalidRequestError(\n                505, 'Version not supported. Supported versions are: {}, {}'\n                .format('HTTP/1.0', 'HTTP/1.1'))\n\n        host, location = self._get_request_uri(request)\n\n        # We must ignore the Host header if a host is specified in GET\n        if host is None:\n            host = request.get('Host')\n\n        # Check if this request is intended for this webserver\n        if host is not None and not host == self.host:\n            self.logger.info('Got a request for unknown host %s', host)\n            raise InvalidRequestError(404, \"We don't serve this host\")\n\n        filename = os.path.join(self.folder, unquote(location))\n        self.logger.debug('trying to serve %s', filename)\n\n        if os.path.isdir(filename):\n            filename = os.path.join(filename, 'index.html')\n\n        if not os.path.isfile(filename):\n            raise InvalidRequestError(404, 'Not Found')\n\n        # Start response with version\n        response = _get_response(version=request['version'])\n\n        # timeout negotiation\n        match = re.match(r'timeout=(\\d+)', request.get('Keep-Alive', ''))\n        if match is not None:\n            requested_timeout = int(match.group(1))\n            if requested_timeout < self._timeout:\n                self._timeout = requested_timeout\n\n        # tell the client our timeout\n        if self.keepalive:\n            response['headers'][\n                'Keep-Alive'] = 'timeout={}'.format(self._timeout)\n\n        # Set Content-Type\n        response['headers']['Content-Type'] = mimetypes.guess_type(\n            filename)[0] or 'text/plain'\n\n        # Generate E-tag\n        sha1 = hashlib.sha1()\n        with open(filename, 'rb') as fp:\n            response['body'] = fp.read()\n            sha1.update(response['body'])\n        etag = sha1.hexdigest()\n\n        # Create 304 response if if-none-match matches etag\n        if request.get('If-None-Match') == '\"{}\"'.format(etag):\n            # 304 responses shouldn't contain many headers we might already\n            # have added.\n            response = _get_response(code=304)\n\n        response['headers']['Etag'] = '\"{}\"'.format(etag)\n\n        self._write_response(response)", "response": "Process the headers and get the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets this exception as an HTTP response suitable for output", "response": "def get_http_response(self):\n        \"\"\"Get this exception as an HTTP response suitable for output\"\"\"\n        return _get_response(\n            code=self.code,\n            body=str(self),\n            headers={\n                'Content-Type': 'text/plain'\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts an asyncio server", "response": "def _start_server(bindaddr, port, hostname, folder):\n    \"\"\"Starts an asyncio server\"\"\"\n    import asyncio\n    from .httpserver import HttpProtocol\n    loop = asyncio.get_event_loop()\n    coroutine = loop.create_server(lambda: HttpProtocol(hostname, folder),\n                                   bindaddr,\n                                   port)\n    server = loop.run_until_complete(coroutine)\n\n    print('Starting server on {}'.format(server.sockets[0].getsockname()))\n    try:\n        loop.run_forever()\n    except KeyboardInterrupt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(argv=None):  # pragma: no cover\n    import sys\n    import os\n    import docopt\n    import textwrap\n\n    # Check for the version\n    if not sys.version_info >= (3, 4):\n        print('This python version is not supported. Please use python 3.4')\n        exit(1)\n\n    argv = argv or sys.argv[1:]\n\n    # remove some RST formatting\n    docblock = run.__doc__.replace('::', ':')\n    args = docopt.docopt(textwrap.dedent(docblock), argv)\n\n    if args['--version']:\n        print(\"httpserver version {} by {}\".format(\n            __version__,\n            __author__))\n        exit(0)\n\n    # Set up logging\n    level = logging.WARNING\n    if args['--verbose']:\n        level = logging.INFO\n    if args['--debug']:\n        level = logging.DEBUG\n    logging.basicConfig(level=level)\n\n    logger = logging.getLogger('run method')\n    logger.debug('CLI args: %s' % args)\n\n    bindaddr = args['--bindaddress'] or '127.0.0.1'\n    port = args['--port'] or '8080'\n    folder = args['<folder>'] or os.getcwd()\n    hostname = args['--host'] or 'localhost'\n    _start_server(bindaddr, port, hostname, folder)", "response": "Run the HTTP server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reading(self):\n        try:\n            # testing proxy\n            proxies = {}\n            try:\n                proxies[\"http_proxy\"] = os.environ['http_proxy']\n            except KeyError:\n                pass\n            try:\n                proxies[\"https_proxy\"] = os.environ['https_proxy']\n            except KeyError:\n                pass\n\n            if len(proxies) != 0:\n                proxy = urllib2.ProxyHandler(proxies)\n                opener = urllib2.build_opener(proxy)\n                urllib2.install_opener(opener)\n\n            # end testing\n            f = urllib2.urlopen(self.link)\n            return f.read()\n        except (urllib2.URLError, ValueError):\n            print(\"\\n{0}Can't read the file '{1}'{2}\".format(\n                self.meta.color[\"RED\"], self.link.split(\"/\")[-1],\n                self.meta.color[\"ENDC\"]))\n            return \" \"", "response": "Open url and read the file and return the content of the file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sbo(self, name):\n        if (self.meta.rsl_deps in [\"on\", \"ON\"] and\n                \"--resolve-off\" not in self.flag):\n            sys.setrecursionlimit(10000)\n            dependencies = []\n            requires = SBoGrep(name).requires()\n            if requires:\n                for req in requires:\n                    status(0.03)\n                    # toolbar_width = status(index, toolbar_width, 1)\n                    # avoid to add %README% as dependency and\n                    # if require in blacklist\n                    if \"%README%\" not in req and req not in self.blacklist:\n                        dependencies.append(req)\n                if dependencies:\n                    self.dep_results.append(dependencies)\n                    for dep in dependencies:\n                        self.sbo(dep)\n            return self.dep_results\n        else:\n            return []", "response": "Build all dependencies of a package"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds packages in a directory that start with find_pkg.", "response": "def find_package(find_pkg, directory):\n    \"\"\"Find packages\n    \"\"\"\n    pkgs = []\n    if os.path.isdir(directory):\n        installed = sorted(os.listdir(directory))\n        blacklist = BlackList().packages(pkgs=installed, repo=\"local\")\n        if os.path.exists(directory):\n            for pkg in installed:\n                if (not pkg.startswith(\".\") and pkg.startswith(find_pkg) and\n                        split_package(pkg)[0] not in blacklist):\n                    pkgs.append(pkg)\n    return pkgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a Latex \\\\ label under the chapter heading.", "response": "def add_sec_label(cell: NotebookNode, nbname) -> Sequence[NotebookNode]:\n    \"\"\"Adds a Latex \\\\label{} under the chapter heading.\n\n    This takes the first cell of a notebook, and expects it to be a Markdown\n    cell starting with a level 1 heading. It inserts a label with the notebook\n    name just underneath this heading.\n    \"\"\"\n    assert cell.cell_type == 'markdown', cell.cell_type\n    lines = cell.source.splitlines()\n    if lines[0].startswith('# '):\n        header_lines = 1\n    elif len(lines) > 1 and lines[1].startswith('==='):\n        header_lines = 2\n    else:\n        raise NoHeader\n\n    header = '\\n'.join(lines[:header_lines])\n    intro_remainder = '\\n'.join(lines[header_lines:]).strip()\n    res = [\n        new_markdown_cell(header),\n        new_latex_cell('\\label{sec:%s}' % nbname)\n    ]\n    res[0].metadata = cell.metadata\n    if intro_remainder:\n        res.append(new_markdown_cell(intro_remainder))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef repos(self):\n        def_cnt, cus_cnt = 0, 0\n        print(\"\")\n        self.msg.template(78)\n        print(\"{0}{1}{2}{3}{4}{5}{6}\".format(\n            \"| Repo id\", \" \" * 2,\n            \"Repo URL\", \" \" * 44,\n            \"Default\", \" \" * 3,\n            \"Status\"))\n        self.msg.template(78)\n        for repo_id, repo_URL in sorted(self.all_repos.iteritems()):\n            status, COLOR = \"disabled\", self.meta.color[\"RED\"]\n            default = \"yes\"\n            if len(repo_URL) > 49:\n                repo_URL = repo_URL[:48] + \"~\"\n            if repo_id in self.meta.repositories:\n                def_cnt += 1\n                status, COLOR = \"enabled\", self.meta.color[\"GREEN\"]\n            if repo_id not in self.meta.default_repositories:\n                cus_cnt += 1\n                default = \"no\"\n            print(\"  {0}{1}{2}{3}{4}{5}{6}{7:>8}{8}\".format(\n                repo_id, \" \" * (9 - len(repo_id)),\n                repo_URL, \" \" * (52 - len(repo_URL)),\n                default, \" \" * (8 - len(default)),\n                COLOR, status, self.meta.color[\"ENDC\"]))\n\n        print(\"\\nRepositories summary\")\n        print(\"=\" * 79)\n        print(\"{0}{1}/{2} enabled default repositories and {3} custom.\".format(\n            self.meta.color[\"GREY\"], def_cnt, len(self.all_repos), cus_cnt))\n        print(\"Edit the file '/etc/slpkg/repositories.conf' for enable \"\n              \"and disable default\\nrepositories or run 'slpkg \"\n              \"repo-enable' command.\\n{0}\".format(self.meta.color[\"ENDC\"]))\n        raise SystemExit()", "response": "List or view repositories"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef view(self):\n        print(\"\")   # new line at start\n        conf_args = [\n            \"RELEASE\",\n            \"SLACKWARE_VERSION\",\n            \"COMP_ARCH\",\n            \"BUILD_PATH\",\n            \"PACKAGES\",\n            \"PATCHES\",\n            \"CHECKMD5\",\n            \"DEL_ALL\",\n            \"DEL_BUILD\",\n            \"SBO_BUILD_LOG\",\n            \"MAKEFLAGS\",\n            \"DEFAULT_ANSWER\",\n            \"REMOVE_DEPS_ANSWER\",\n            \"SKIP_UNST\",\n            \"RSL_DEPS\",\n            \"DEL_DEPS\",\n            \"USE_COLORS\",\n            \"DOWNDER\",\n            \"DOWNDER_OPTIONS\",\n            \"SLACKPKG_LOG\",\n            \"ONLY_INSTALLED\",\n            \"PRG_BAR\",\n            \"EDITOR\",\n            \"NOT_DOWNGRADE\"\n        ]\n        read_conf = Utils().read_file(self.config_file)\n        for line in read_conf.splitlines():\n            if not line.startswith(\"#\") and line.split(\"=\")[0] in conf_args:\n                print(\"{0}\".format(line))\n            else:\n                print(\"{0}{1}{2}\".format(self.meta.color[\"CYAN\"], line,\n                                         self.meta.color[\"ENDC\"]))\n        print(\"\")", "response": "View slpkg config file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nedits the configuration file", "response": "def edit(self):\n        \"\"\"Edit configuration file\n        \"\"\"\n        subprocess.call(\"{0} {1}\".format(self.meta.editor,\n                                         self.config_file), shell=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset slpkg. conf file with default values", "response": "def reset(self):\n        \"\"\"Reset slpkg.conf file with default values\n        \"\"\"\n        shutil.copy2(self.config_file + \".orig\", self.config_file)\n        if filecmp.cmp(self.config_file + \".orig\", self.config_file):\n            print(\"{0}The reset was done{1}\".format(\n                self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"]))\n        else:\n            print(\"{0}Reset failed{1}\".format(self.meta.color[\"RED\"],\n                                              self.meta.color[\"ENDC\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting results of the current assessment.", "response": "def results(self):\n        \"\"\"Print results\n        \"\"\"\n        print(\"\")\n        per = int(round((float(self.cf) / (self.cf + self.cn)) * 100))\n        if per > 90:\n            color = self.meta.color[\"GREEN\"]\n        elif per < 90 and per > 60:\n            color = self.meta.color[\"YELLOW\"]\n        elif per < 60:\n            color = self.meta.color[\"RED\"]\n        health = \"{0}{1}%{2}\".format(color, str(per), self.meta.color[\"ENDC\"])\n        self.msg.template(78)\n        print(\"| {0}{1}{2}{3}{4}\".format(\n            \"Total files\", \" \" * 7, \"Not installed\", \" \" * 40, \"Health\"))\n        self.msg.template(78)\n        print(\"| {0}{1}{2}{3}{4:>4}\".format(\n            self.cf, \" \" * (18-len(str(self.cf))),\n            self.cn, \" \" * (55-len(str(self.cn))),\n            health))\n        self.msg.template(78)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef case_sensitive(self, lst):\n        dictionary = {}\n        for pkg in lst:\n            dictionary[pkg.lower()] = pkg\n        return dictionary", "response": "Create dictionary from list with key in lower case\n        and value with default\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_dbs(self, double):\n        one = []\n        for dup in double:\n            if dup not in one:\n                one.append(dup)\n        return one", "response": "Remove double item from list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the file from the registry", "response": "def read_file(self, registry):\n        \"\"\"Returns reading file\n        \"\"\"\n        with open(registry, \"r\") as file_txt:\n            read_file = file_txt.read()\n            file_txt.close()\n            return read_file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list with all the names of packages repository", "response": "def package_name(self, PACKAGES_TXT):\n        \"\"\"Returns list with all the names of packages repository\n        \"\"\"\n        packages = []\n        for line in PACKAGES_TXT.splitlines():\n            if line.startswith(\"PACKAGE NAME:\"):\n                packages.append(split_package(line[14:].strip())[0])\n        return packages"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if files downloaded and return downloaded xid packages", "response": "def check_downloaded(self, path, maybe_downloaded):\n        \"\"\"Check if files downloaded and return downloaded\n        packages\n        \"\"\"\n        downloaded = []\n        for pkg in maybe_downloaded:\n            if os.path.isfile(path + pkg):\n                downloaded.append(pkg)\n        return downloaded"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_deps(deps_dict):\n    for name, dependencies in deps_dict.iteritems():\n        if find_package(name + _meta_.sp, _meta_.pkg_path):\n            dep_path = _meta_.log_path + \"dep/\"\n            if not os.path.exists(dep_path):\n                os.mkdir(dep_path)\n            if os.path.isfile(dep_path + name):\n                os.remove(dep_path + name)\n            if len(dependencies) >= 1:\n                with open(dep_path + name, \"w\") as f:\n                    for dep in dependencies:\n                        f.write(dep + \"\\n\")\n                    f.close()", "response": "Write dependencies in a log file\n    into a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dependencies(self, deps_dict):\n        try:\n            import pygraphviz as pgv\n        except ImportError:\n            graph_easy, comma = \"\", \"\"\n            if (self.image == \"ascii\" and\n                    not os.path.isfile(\"/usr/bin/graph-easy\")):\n                comma = \",\"\n                graph_easy = \" graph-easy\"\n            print(\"Require 'pygraphviz{0}{1}': Install with 'slpkg -s sbo \"\n                  \"pygraphviz{1}'\".format(comma, graph_easy))\n            raise SystemExit()\n        if self.image != \"ascii\":\n            self.check_file()\n        try:\n            G = pgv.AGraph(deps_dict)\n            G.layout(prog=\"fdp\")\n            if self.image == \"ascii\":\n                G.write(\"{0}.dot\".format(self.image))\n                self.graph_easy()\n            G.draw(self.image)\n        except IOError:\n            raise SystemExit()\n        if os.path.isfile(self.image):\n            print(\"Graph image file '{0}' created\".format(self.image))\n        raise SystemExit()", "response": "Generate graph file with depenndencies map tree\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck for file format and type", "response": "def check_file(self):\n        \"\"\"Check for file format and type\n        \"\"\"\n        try:\n            image_type = \".{0}\".format(self.image.split(\".\")[1])\n            if image_type not in self.file_format:\n                print(\"Format: '{0}' not recognized. Use one of \"\n                      \"them:\\n{1}\".format(self.image.split(\".\")[1],\n                                          \", \".join(self.file_format)))\n                raise SystemExit()\n        except IndexError:\n            print(\"slpkg: Error: Image file suffix missing\")\n            raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef graph_easy(self):\n        if not os.path.isfile(\"/usr/bin/graph-easy\"):\n            print(\"Require 'graph-easy': Install with 'slpkg -s sbo \"\n                  \"graph-easy'\")\n            self.remove_dot()\n            raise SystemExit()\n        subprocess.call(\"graph-easy {0}.dot\".format(self.image), shell=True)\n        self.remove_dot()\n        raise SystemExit()", "response": "Draw ascii diagram. graph - easy perl module require\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving dot files from the local file system.", "response": "def remove_dot(self):\n        \"\"\"Remove .dot files\n        \"\"\"\n        if os.path.isfile(\"{0}.dot\".format(self.image)):\n            os.remove(\"{0}.dot\".format(self.image))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking packages before install or upgrade for security reasons. Configuration file in the / etc / slpkg. pkg_security file.", "response": "def pkg_security(pkgs):\n    \"\"\"Check packages before install or upgrade for security\n    reasons. Configuration file in the /etc/slpkg/pkg_security\"\"\"\n    security_packages = Utils().read_file(\"/etc/slpkg/pkg_security\")\n    packages = []\n    for read in security_packages.splitlines():\n        read = read.lstrip()\n        if not read.startswith(\"#\"):\n            packages.append(read.replace(\"\\n\", \"\"))\n    for p in pkgs:\n        for pkg in packages:\n            if p == pkg:\n                Msg().security_pkg(p)\n                if not Msg().answer() in [\"y\", \"Y\"]:\n                    raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef alien_filter(packages, sizes):\n    cache, npkg, nsize = [], [], []\n    for p, s in zip(packages, sizes):\n        name = split_package(p)[0]\n        if name not in cache:\n            cache.append(name)\n            npkg.append(p)\n            nsize.append(s)\n    return npkg, nsize", "response": "This filter avoid list double packages from\n    alien repository\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupgrading Slackware binary packages with new", "response": "def upgrade(self, flag):\n        \"\"\"Upgrade Slackware binary packages with new\n        \"\"\"\n        for pkg in self.binary:\n            try:\n                subprocess.call(\"upgradepkg {0} {1}\".format(flag, pkg),\n                                shell=True)\n                check = pkg[:-4].split(\"/\")[-1]\n                if os.path.isfile(self.meta.pkg_path + check):\n                    print(\"Completed!\\n\")\n                else:\n                    raise SystemExit()\n            except subprocess.CalledProcessError:\n                self._not_found(\"Can't upgrade\", self.binary, pkg)\n                raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving Slackware binary packages", "response": "def remove(self, flag, extra):\n        \"\"\"Remove Slackware binary packages\n        \"\"\"\n        self.flag = flag\n        self.extra = extra\n        self.dep_path = self.meta.log_path + \"dep/\"\n        dependencies, rmv_list = [], []\n        self.removed = self._view_removed()\n        if not self.removed:\n            print(\"\")   # new line at end\n        else:\n            msg = \"package\"\n            if len(self.removed) > 1:\n                msg = msg + \"s\"\n            try:\n                if self.meta.default_answer in [\"y\", \"Y\"]:\n                    remove_pkg = self.meta.default_answer\n                else:\n                    remove_pkg = raw_input(\n                        \"\\nAre you sure to remove {0} {1} [y/N]? \".format(\n                            str(len(self.removed)), msg))\n            except EOFError:\n                print(\"\")   # new line at exit\n                raise SystemExit()\n            if remove_pkg in [\"y\", \"Y\"]:\n                self._check_if_used(self.binary)\n                for rmv in self.removed:\n                    # If package build and install with \"slpkg -s sbo <package>\"\n                    # then look log file for dependencies in /var/log/slpkg/dep,\n                    # read and remove all else remove only the package.\n                    if (os.path.isfile(self.dep_path + rmv) and\n                            self.meta.del_deps in [\"on\", \"ON\"] or\n                            os.path.isfile(self.dep_path + rmv) and\n                            \"--deps\" in self.extra):\n                        dependencies = self._view_deps(self.dep_path, rmv)\n                        if dependencies and self._rmv_deps_answer() in [\"y\",\n                                                                        \"Y\"]:\n                            rmv_list += self._rmv_deps(dependencies, rmv)\n                        else:\n                            rmv_list += self._rmv_pkg(rmv)\n                    else:\n                        rmv_list += self._rmv_pkg(rmv)\n                # Prints all removed packages\n                self._reference_rmvs(rmv_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmanages removed packages by extra options SetException", "response": "def _get_removed(self):\n        \"\"\"Manage removed packages by extra options\n        \"\"\"\n        removed, packages = [], []\n        if \"--tag\" in self.extra:\n            for pkg in find_package(\"\", self.meta.pkg_path):\n                for tag in self.binary:\n                    if pkg.endswith(tag):\n                        removed.append(split_package(pkg)[0])\n                        packages.append(pkg)\n            if not removed:\n                self.msg.pkg_not_found(\"\", \"'tag'\", \"Can't remove\", \"\\n\")\n                raise SystemExit(1)\n        else:\n            for pkg in self.binary:\n                name = GetFromInstalled(pkg).name()\n                ver = GetFromInstalled(pkg).version()\n                package = find_package(\"{0}{1}{2}\".format(\n                    name, ver, self.meta.sp), self.meta.pkg_path)\n                if pkg and name == pkg:\n                    removed.append(pkg)\n                    packages.append(package[0])\n                else:\n                    self.msg.pkg_not_found(\"\", pkg, \"Can't remove\", \"\\n\")\n                    raise SystemExit(1)\n        return removed, packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _view_removed(self):\n        print(\"\\nPackages with name matching [ {0}{1}{2} ]\\n\".format(\n            self.meta.color[\"CYAN\"], \", \".join(self.binary),\n            self.meta.color[\"ENDC\"]))\n        removed, packages = self._get_removed()\n        if packages and \"--checklist\" in self.extra:\n            removed = []\n            text = \"Press 'spacebar' to unchoose packages from the remove\"\n            backtitle = \"{0} {1}\".format(self.meta.__all__,\n                                         self.meta.__version__)\n            status = True\n            pkgs = DialogUtil(packages, text, \" Remove \", backtitle,\n                              status).checklist()\n            if pkgs:\n                for rmv in pkgs:\n                    removed.append(split_package(rmv)[0])\n                self.meta.default_answer = \"y\"\n        else:\n            for rmv, pkg in zip(removed, packages):\n                print(\"[ {0}delete{1} ] --> {2}\".format(\n                    self.meta.color[\"RED\"], self.meta.color[\"ENDC\"], pkg))\n                self._sizes(pkg)\n            self._calc_sizes()\n            self._remove_summary()\n        return removed", "response": "View packages before removed\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _calc_sizes(self):\n        if self.size > 1024:\n            self.unit = \"Mb\"\n            self.size = (self.size / 1024)\n        if self.size > 1024:\n            self.unit = \"Gb\"\n            self.size = (self.size / 1024)", "response": "Calculate the size of the resource in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving summary of the deleted packages.", "response": "def _remove_summary(self):\n        \"\"\"Removed packge size summary\n        \"\"\"\n        if self.size > 0:\n            print(\"\\nRemoved summary\")\n            print(\"=\" * 79)\n            print(\"{0}Size of removed packages {1} {2}.{3}\".format(\n                self.meta.color[\"GREY\"], round(self.size, 2), self.unit,\n                self.meta.color[\"ENDC\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nview dependencies before remove", "response": "def _view_deps(self, path, package):\n        \"\"\"View dependencies before remove\n        \"\"\"\n        self.size = 0\n        packages = []\n        dependencies = (Utils().read_file(path + package)).splitlines()\n        for dep in dependencies:\n            if GetFromInstalled(dep).name():\n                ver = GetFromInstalled(dep).version()\n                packages.append(dep + ver)\n            else:\n                dependencies.remove(dep)\n        if packages:\n            if \"--checklist\" in self.extra:\n                deps, dependencies = [], []\n                text = \"Found dependencies for the package {0}\".format(package)\n                backtitle = \"{0} {1}\".format(self.meta.__all__,\n                                             self.meta.__version__)\n                status = True\n                deps = DialogUtil(packages, text, \" Remove \", backtitle,\n                                  status).checklist()\n                for d in deps:\n                    dependencies.append(\"-\".join(d.split(\"-\")[:-1]))\n                self.meta.remove_deps_answer = \"y\"\n            else:\n                print(\"\")   # new line at start\n                self.msg.template(78)\n                print(\"| Found dependencies for the package {0}:\".format(\n                    package))\n                self.msg.template(78)\n                for pkg in packages:\n                    find = find_package(pkg + self.meta.sp, self.meta.pkg_path)\n                    self._sizes(find[0])\n                    print(\"| {0}{1}{2}\".format(self.meta.color[\"RED\"], pkg,\n                                               self.meta.color[\"ENDC\"]))\n                self.msg.template(78)\n                self._calc_sizes()\n                print(\"| {0}Size of removed dependencies {1} {2}{3}\".format(\n                    self.meta.color[\"GREY\"], round(self.size, 2), self.unit,\n                    self.meta.color[\"ENDC\"]))\n                self.msg.template(78)\n        return dependencies"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _removepkg(self, package):\n        try:\n            subprocess.call(\"removepkg {0} {1}\".format(self.flag, package),\n                            shell=True)\n            if os.path.isfile(self.dep_path + package):\n                os.remove(self.dep_path + package)  # remove log\n        except subprocess.CalledProcessError as er:\n            print(er)\n            raise SystemExit()", "response": "remove package Slackware command"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _rmv_deps(self, dependencies, package):\n        removes = []\n        dependencies.append(package)\n        self._check_if_used(dependencies)\n        for dep in dependencies:\n            if dep not in self.skip and GetFromInstalled(dep).name():\n                ver = GetFromInstalled(dep).version()\n                removes.append(dep + ver)\n                self._removepkg(dep)\n        return removes", "response": "Remove dependencies from the list of packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves one signle package", "response": "def _rmv_pkg(self, package):\n        \"\"\"Remove one signle package\n        \"\"\"\n        removes = []\n        if GetFromInstalled(package).name() and package not in self.skip:\n            ver = GetFromInstalled(package).version()\n            removes.append(package + ver)\n            self._removepkg(package)\n        return removes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nskipping packages from remove", "response": "def _skip_remove(self):\n        \"\"\"Skip packages from remove\n        \"\"\"\n        if \"--checklist\" not in self.extra:\n            self.msg.template(78)\n            print(\"| Insert packages to exception remove:\")\n            self.msg.template(78)\n            try:\n                self.skip = raw_input(\" > \").split()\n            except EOFError:\n                print(\"\")\n                raise SystemExit()\n        for s in self.skip:\n            if s in self.removed:\n                self.removed.remove(s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_if_used(self, removes):\n        if \"--check-deps\" in self.extra:\n            package, dependency, pkg_dep = [], [], []\n            for pkg in find_package(\"\", self.dep_path):\n                deps = Utils().read_file(self.dep_path + pkg)\n                for rmv in removes:\n                    if GetFromInstalled(rmv).name() and rmv in deps.split():\n                        pkg_dep.append(\n                            \"{0} is dependency of the package --> {1}\".format(\n                                rmv, pkg))\n                        package.append(pkg)\n                        dependency.append(rmv)\n            if package:\n                if \"--checklist\" in self.extra:\n                    text = (\"Press 'spacebar' to choose packages for the remove\"\n                            \" exception\")\n                    backtitle = \"{0} {1}\".format(self.meta.__all__,\n                                                 self.meta.__version__)\n                    status = False\n                    choose = DialogUtil(pkg_dep, text, \" !!! WARNING !!! \",\n                                        backtitle, status).checklist()\n                    for pkg in choose:\n                        self.skip.append(pkg.split()[0])\n                else:\n                    self.msg.template(78)\n                    print(\"| {0}{1}{2}\".format(\n                        self.meta.color[\"RED\"], \" \" * 30 + \"!!! WARNING !!!\",\n                        self.meta.color[\"ENDC\"]))\n                    self.msg.template(78)\n                    for p, d in zip(package, dependency):\n                        print(\"| {0}{1}{2} is dependency of the package --> \"\n                              \"{3}{4}{5}\".format(self.meta.color[\"YELLOW\"], d,\n                                                 self.meta.color[\"ENDC\"],\n                                                 self.meta.color[\"GREEN\"], p,\n                                                 self.meta.color[\"ENDC\"]))\n                    self.msg.template(78)\n                    self._skip_remove()", "response": "Check if dependencies for another package before removed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _reference_rmvs(self, removes):\n        print(\"\")\n        self.msg.template(78)\n        msg_pkg = \"package\"\n        if len(removes) > 1:\n            msg_pkg = \"packages\"\n        print(\"| Total {0} {1} removed\".format(len(removes), msg_pkg))\n        self.msg.template(78)\n        for pkg in removes:\n            if not GetFromInstalled(pkg).name():\n                print(\"| Package {0} removed\".format(pkg))\n            else:\n                print(\"| Package {0} not found\".format(pkg))\n        self.msg.template(78)\n        print(\"\")", "response": "Prints all removed packages\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(self, flag):\n        matching, pkg_cache, match_cache = 0, \"\", \"\"\n        print(\"\\nPackages with matching name [ {0}{1}{2} ]\\n\".format(\n            self.meta.color[\"CYAN\"], \", \".join(self.binary),\n            self.meta.color[\"ENDC\"]))\n        for pkg in self.binary:\n            for match in find_package(\"\", self.meta.pkg_path):\n                if \"--case-ins\" in flag:\n                    pkg_cache = pkg.lower()\n                    match_cache = match.lower()\n                else:\n                    pkg_cache = pkg\n                    match_cache = match\n                if pkg_cache in match_cache:\n                    matching += 1\n                    self._sizes(match)\n                    print(\"[ {0}installed{1} ] [ {2} ] - {3}\".format(\n                        self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"],\n                        self.file_size, match))\n        if matching == 0:\n            message = \"Can't find\"\n            self.msg.pkg_not_found(\"\", \", \".join(self.binary), message, \"\\n\")\n            raise SystemExit(1)\n        else:\n            self._calc_sizes()\n            print(\"\\nFound summary\")\n            print(\"=\" * 79)\n            print(\"{0}Total found {1} matching packages.{2}\".format(\n                self.meta.color[\"GREY\"], matching, self.meta.color[\"ENDC\"]))\n            print(\"{0}Size of installed packages {1} {2}.{3}\\n\".format(\n                self.meta.color[\"GREY\"], round(self.size, 2), self.unit,\n                self.meta.color[\"ENDC\"]))", "response": "Find Slackware packages and print out summary"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the size of the archive from the package.", "response": "def _sizes(self, package):\n        \"\"\"Package size summary\n        \"\"\"\n        data = Utils().read_file(self.meta.pkg_path + package)\n        for line in data.splitlines():\n            if line.startswith(\"UNCOMPRESSED PACKAGE SIZE:\"):\n                digit = float((''.join(re.findall(\n                    \"[-+]?\\d+[\\.]?\\d*[eE]?[-+]?\\d*\", line[26:]))))\n                self.file_size = line[26:].strip()\n                if \"M\" in line[26:]:\n                    self.size += digit * 1024\n                else:\n                    self.size += digit\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint Slackware packages contents", "response": "def display(self):\n        \"\"\"Print the Slackware packages contents\n        \"\"\"\n        for pkg in self.binary:\n            name = GetFromInstalled(pkg).name()\n            ver = GetFromInstalled(pkg).version()\n            find = find_package(\"{0}{1}{2}\".format(name, ver, self.meta.sp),\n                                self.meta.pkg_path)\n            if find:\n                package = Utils().read_file(\n                    self.meta.pkg_path + \"\".join(find))\n                print(package)\n            else:\n                message = \"Can't dislpay\"\n                if len(self.binary) > 1:\n                    bol = eol = \"\"\n                else:\n                    bol = eol = \"\\n\"\n                self.msg.pkg_not_found(bol, pkg, message, eol)\n                raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef package_list(self, repo, name, INDEX, installed):\n        tty_size = os.popen(\"stty size\", \"r\").read().split()\n        row = int(tty_size[0]) - 2\n        try:\n            all_installed_names = []\n            index, page, pkg_list = 0, row, []\n            r = self.list_lib(repo)\n            pkg_list = self.list_greps(repo, r)[0]\n            all_installed_names = self.list_of_installed(repo, name)\n            print(\"\")\n            for pkg in sorted(pkg_list):\n                pkg = self._splitting_packages(pkg, repo, name)\n                if installed:\n                    if repo == \"sbo\":\n                        if pkg in all_installed_names:\n                            pkg = (\"{0}{1}{2}\".format(self.meta.color[\"GREEN\"],\n                                                      pkg,\n                                                      self.meta.color[\"ENDC\"]))\n                    else:\n                        if pkg in all_installed_names:\n                            pkg = (\"{0}{1}{2}\".format(self.meta.color[\"GREEN\"],\n                                                      pkg,\n                                                      self.meta.color[\"ENDC\"]))\n                if INDEX:\n                    index += 1\n                    pkg = self.list_color_tag(pkg)\n                    print(\"{0}{1}:{2} {3}\".format(\n                        self.meta.color[\"GREY\"], index,\n                        self.meta.color[\"ENDC\"], pkg))\n                    if index == page:\n                        read = raw_input(\"\\nPress {0}Enter{1} to \"\n                                         \"continue... \".format(\n                                             self.meta.color[\"CYAN\"],\n                                             self.meta.color[\"ENDC\"]))\n                        if read in [\"Q\", \"q\"]:\n                            break\n                        print(\"\")   # new line after page\n                        page += row\n                else:\n                    print(pkg)\n            print(\"\")   # new line at end\n        except EOFError:\n            print(\"\")   # new line at exit\n            raise SystemExit()", "response": "List with the installed packages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _splitting_packages(self, pkg, repo, name):\n        if name and repo != \"sbo\":\n            pkg = split_package(pkg)[0]\n        elif not name and repo != \"sbo\":\n            pkg = pkg[:-4]\n        return pkg", "response": "Return package name from repositories\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_lib(self, repo):\n        packages = \"\"\n        if repo == \"sbo\":\n            if (os.path.isfile(\n                    self.meta.lib_path + \"{0}_repo/SLACKBUILDS.TXT\".format(\n                        repo))):\n                packages = Utils().read_file(self.meta.lib_path + \"{0}_repo/\"\n                                             \"SLACKBUILDS.TXT\".format(repo))\n        else:\n            if (os.path.isfile(\n                    self.meta.lib_path + \"{0}_repo/PACKAGES.TXT\".format(repo))):\n                packages = Utils().read_file(self.meta.lib_path + \"{0}_repo/\"\n                                             \"PACKAGES.TXT\".format(repo))\n        return packages", "response": "Return package lists of a specific library"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_color_tag(self, pkg):\n        name = GetFromInstalled(pkg).name()\n        find = name + self.meta.sp\n        if pkg.endswith(\".txz\") or pkg.endswith(\".tgz\"):\n            find = pkg[:-4]\n        if find_package(find, self.meta.pkg_path):\n            pkg = \"{0}{1}{2}\".format(self.meta.color[\"GREEN\"], pkg,\n                                     self.meta.color[\"ENDC\"])\n        return pkg", "response": "Tag with color installed packages\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rlw_filter(name, location, size, unsize):\n    arch = _meta_.arch\n    if arch.startswith(\"i\") and arch.endswith(\"86\"):\n        arch = \"i486\"\n    (fname, flocation, fsize, funsize) = ([] for i in range(4))\n    for n, l, s, u in zip(name, location, size, unsize):\n        loc = l.split(\"/\")\n        if arch == loc[-1]:\n            fname.append(n)\n            flocation.append(l)\n            fsize.append(s)\n            funsize.append(u)\n    return [fname, flocation, fsize, funsize]", "response": "Filter rlw repository data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef alien_filter(name, location, size, unsize):\n    (fname, flocation, fsize, funsize) = ([] for i in range(4))\n    for n, l, s, u in zip(name, location, size, unsize):\n        if \"slackbuilds\" != l:\n            fname.append(n)\n            flocation.append(l)\n            fsize.append(s)\n            funsize.append(u)\n    return [fname, flocation, fsize, funsize]", "response": "Fix to avoid packages include in slackbuilds folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rested_filter(name, location, size, unsize):\n    ver = slack_ver()\n    if _meta_.slack_rel == \"current\":\n        ver = \"current\"\n    path_pkg = \"pkg\"\n    if _meta_.arch == \"x86_64\":\n        path_pkg = \"pkg64\"\n    (fname, flocation, fsize, funsize) = ([] for i in range(4))\n    for n, l, s, u in zip(name, location, size, unsize):\n        if path_pkg == l.split(\"/\")[-2] and ver == l.split(\"/\")[-1]:\n            fname.append(n)\n            flocation.append(l)\n            fsize.append(s)\n            funsize.append(u)\n    return [fname, flocation, fsize, funsize]", "response": "Filter Alien s repository data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_deps(self):\n        if self.repo == \"rlw\":\n            dependencies = {}\n            rlw_deps = Utils().read_file(_meta_.conf_path + \"rlworkman.deps\")\n            for line in rlw_deps.splitlines():\n                if line and not line.startswith(\"#\"):\n                    pkgs = line.split(\":\")\n                    dependencies[pkgs[0]] = pkgs[1]\n            if self.name in dependencies.keys():\n                return dependencies[self.name].split()\n            else:\n                return \"\"\n        else:\n            PACKAGES_TXT = Utils().read_file(\"{0}{1}_repo/PACKAGES.TXT\".format(\n                _meta_.lib_path, self.repo))\n            for line in PACKAGES_TXT.splitlines():\n                if line.startswith(\"PACKAGE NAME:\"):\n                    pkg_name = split_package(line[14:].strip())[0]\n                if line.startswith(\"PACKAGE REQUIRED:\"):\n                    if pkg_name == self.name:\n                        if line[18:].strip():\n                            return self._req_fix(line)", "response": "Grap package requirements from repositories\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfix slacky and salix requirements because many dependencies splitting with \",\" and others with \"|\"", "response": "def _req_fix(self, line):\n        \"\"\"Fix slacky and salix requirements because many dependencies splitting\n        with \",\" and others with \"|\"\n        \"\"\"\n        deps = []\n        for dep in line[18:].strip().split(\",\"):\n            dep = dep.split(\"|\")\n            if self.repo == \"slacky\":\n                if len(dep) > 1:\n                    for d in dep:\n                        deps.append(d.split()[0])\n                dep = \"\".join(dep)\n                deps.append(dep.split()[0])\n            else:\n                if len(dep) > 1:\n                    for d in dep:\n                        deps.append(d)\n                deps.append(dep[0])\n        return deps"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints new configuration files", "response": "def run(self):\n        \"\"\"print .new configuration files\n        \"\"\"\n        self.find_new()\n        for n in self.news:\n            print(\"{0}\".format(n))\n        print(\"\")\n        self.msg.template(78)\n        print(\"| Installed {0} new configuration files:\".format(\n            len(self.news)))\n        self.msg.template(78)\n        self.choices()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_new(self):\n        print(\"\\nSearch for .new configuration files:\\n\")\n        for path, dirs, files in os.walk(self.etc):\n            del dirs    # delete unsed\n            for f in files:\n                if f.endswith(\".new\"):\n                    self.news.append(os.path.join(path, f))\n        if not self.news:\n            print(\"  No new configuration files\\n\")\n            raise SystemExit()", "response": "Find all. new files from / etc folder\n        and subfolders\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprompting the user for a new file by file.", "response": "def prompt(self):\n        \"\"\"Select file\n        \"\"\"\n        self.msg.template(78)\n        print(\"| Choose what to do file by file:\")\n        print(\"| {0}K{1}{2}eep, {3}O{4}{5}verwrite, {6}R{7}{8}emove, \"\n              \"{9}D{10}{11}iff, {12}M{13}{14}erge, {15}Q{16}{17}uit\".format(\n                  self.red, self.endc, self.br, self.red, self.endc, self.br,\n                  self.red, self.endc, self.br, self.red, self.endc, self.br,\n                  self.red, self.endc, self.br, self.red, self.endc, self.br))\n        self.msg.template(78)\n        print(\"\")\n        self.i = 0\n        try:\n            while self.i < len(self.news):\n                self.question(self.news[self.i])\n                self.i += 1\n        except EOFError:\n            print(\"\")\n            raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef question(self, n):\n        print(\"\")\n        prompt_ask = raw_input(\"{0} [K/O/R/D/M/Q]? \".format(n))\n        print(\"\")\n        if prompt_ask in (\"K\", \"k\"):\n            self.keep()\n        elif prompt_ask in (\"O\", \"o\"):\n            self._overwrite(n)\n        elif prompt_ask in (\"R\", \"r\"):\n            self._remove(n)\n        elif prompt_ask in (\"D\", \"d\"):\n            self.diff(n)\n            self.i -= 1\n        elif prompt_ask in (\"M\", \"m\"):\n            self.merge(n)\n        elif prompt_ask in (\"Q\", \"q\", \"quit\"):\n            self.quit()", "response": "Prompts user for what do to file by file\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove(self, n):\n        if os.path.isfile(n):\n            os.remove(n)\n        if not os.path.isfile(n):\n            print(\"File '{0}' removed\".format(n))", "response": "Remove one file from the local cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _overwrite(self, n):\n        if os.path.isfile(n[:-4]):\n            shutil.copy2(n[:-4], n[:-4] + \".old\")\n            print(\"Old file {0} saved as {1}.old\".format(\n                n[:-4].split(\"/\")[-1], n[:-4].split(\"/\")[-1]))\n        if os.path.isfile(n):\n            shutil.move(n, n[:-4])\n            print(\"New file {0} overwrite as {1}\".format(\n                n.split(\"/\")[-1], n[:-4].split(\"/\")[-1]))", "response": "Overwrite old file with new and keep file with suffix. old\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the differences between the two files 69", "response": "def diff(self, n):\n        \"\"\"Print the differences between the two files\n        \"\"\"\n        if os.path.isfile(n[:-4]):\n            diff1 = Utils().read_file(n[:-4]).splitlines()\n        if os.path.isfile(n):\n            diff2 = Utils().read_file(n).splitlines()\n        lines, l, c = [], 0, 0\n        for a, b in itertools.izip_longest(diff1, diff2):\n            l += 1\n            if a != b:\n                for s1, s2 in itertools.izip_longest(str(a), str(b)):\n                    c += 1\n                    if s1 != s2:\n                        break\n                print(\"@@ -{0},{1} +{2},{3} @@\\n\".format(l, c, l, c))\n                for line in lines[-3:]:\n                    print(\"{0}\".format(line))\n                if a is None:\n                    a = \"\"\n                print(\"{0}{1}{2}{3}\".format(self.red, \"-\", self.endc, a))\n                if b is None:\n                    b = \"\"\n                print(\"{0}{1}{2}{3}\".format(self.green, \"+\", self.endc, b))\n                lines = []\n                c = 0\n            else:\n                lines.append(a)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges the old file into the new file", "response": "def merge(self, n):\n        \"\"\"Merge new file into old\n        \"\"\"\n        if os.path.isfile(n[:-4]):\n            old = Utils().read_file(n[:-4]).splitlines()\n        if os.path.isfile(n):\n            new = Utils().read_file(n).splitlines()\n        with open(n[:-4], \"w\") as out:\n            for l1, l2 in itertools.izip_longest(old, new):\n                if l1 is None:\n                    l1 = \"\"\n                if l2 is None:\n                    l2 = \"\"\n                if l1 != l2:\n                    out.write(l2 + \"\\n\")\n                else:\n                    out.write(l1 + \"\\n\")\n            print(\"The file {0} merged in file {1}\".format(\n                n.split(\"/\")[-1], n[:-4].split(\"/\")[-1]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntop view bar status", "response": "def status_bar(self):\n        \"\"\"Top view bar status\n        \"\"\"\n        print(\"\")\n        self.msg.template(78)\n        print(\"| Repository         Status\")\n        self.msg.template(78)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns and check if new in ChangeLog. txt", "response": "def run(self):\n        \"\"\"Run and check if new in ChangeLog.txt\n        \"\"\"\n        if (self.repo in self.meta.default_repositories and\n                self.repo in self.meta.repositories):\n            try:\n                self.check = self.all_repos[self.repo]()\n            except OSError:\n                usage(self.repo)\n                raise SystemExit()\n        elif self.repo in self.meta.repositories:\n            self.check = self._init.custom(self.repo)\n        else:\n            usage(self.repo)\n            raise SystemExit()\n        self.status_bar()\n        self.status()\n        self.print_status(self.repo)\n        self.summary()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef status(self):\n        self.count_repo += 1\n        if self.check == 1:\n            self.count_news += 1\n            self.st = \"{0}News in ChangeLog.txt{1}\".format(\n                self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"])\n        elif self.check == 0:\n            self.st = \"No changes in ChangeLog.txt\"", "response": "Set status of the current locale"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints the status of the current locale", "response": "def print_status(self, repo):\n        \"\"\"Print status\n        \"\"\"\n        print(\"  {0}{1}{2}\".format(repo, \" \" * (19 - len(repo)), self.st))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef summary(self):\n        print(\"\\nSummary\")\n        print(\"=\" * 79)\n        cmd = \"All repositories are updated.\"\n        if self.count_repo == 1:\n            cmd = \"Repository is updated.\"\n        if self.count_news > 0:\n            cmd = \"Run the command 'slpkg update'.\"\n        print(\"{0}From {1} repositories need {2} updating. {3}{4}\\n\".format(\n            self.meta.color[\"GREY\"], self.count_repo, self.count_news, cmd,\n            self.meta.color[\"ENDC\"]))", "response": "Print summary of the current count of items from the repository and news."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        self.msg.resolving()\n        self.repositories()\n        if self.find_pkg:\n            self.dependencies_list.reverse()\n            self.requires = Utils().dimensional_list(self.dependencies_list)\n            self.dependencies = Utils().remove_dbs(self.requires)\n            if self.dependencies == []:\n                self.dependencies = [\"No dependencies\"]\n            if \"--graph=\" in self.flag:\n                self.deps_tree()\n            self.msg.done()\n            pkg_len = len(self.name) + 24\n            print(\"\")    # new line at start\n            self.msg.template(pkg_len)\n            print(\"| Package {0}{1}{2} dependencies :\".format(\n                self.cyan, self.name, self.endc))\n            self.msg.template(pkg_len)\n            print(\"\\\\\")\n            print(\" +---{0}[ Tree of dependencies ]{1}\".format(self.yellow,\n                                                               self.endc))\n            index = 0\n            for pkg in self.dependencies:\n                if \"--check-deps\" in self.flag:\n                    used = self.check_used(pkg)\n                    self.deps_used(pkg, used)\n                    used = \"{0} {1}{2}{3}\".format(\n                        \"is dependency -->\", self.cyan,\n                        \", \".join(used), self.endc)\n                else:\n                    used = \"\"\n                index += 1\n                installed = \"\"\n                if find_package(pkg + self.meta.sp, self.meta.pkg_path):\n                    if self.meta.use_colors in [\"off\", \"OFF\"]:\n                        installed = \"* \"\n                    print(\" |\")\n                    print(\" {0}{1}: {2}{3}{4} {5}{6}\".format(\n                        \"+--\", index, self.green, pkg,\n                        self.endc, installed, used))\n                else:\n                    print(\" |\")\n                    print(\" {0}{1}: {2}{3}{4} {5}\".format(\n                        \"+--\", index, self.red, pkg,\n                        self.endc, installed))\n            if self.meta.use_colors in [\"off\", \"OFF\"]:\n                print(\"\\n * = Installed\\n\")\n            else:\n                print(\"\")    # new line at end\n            if \"--graph=\" in self.flag:\n                self.graph()\n        else:\n            self.msg.done()\n            print(\"\\nNo package was found to match\\n\")\n            raise SystemExit(1)", "response": "Runs tracking dependencies for the current application."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting dependencies by repositories", "response": "def repositories(self):\n        \"\"\"Get dependencies by repositories\n        \"\"\"\n        if self.repo == \"sbo\":\n            self.sbo_case_insensitive()\n            self.find_pkg = sbo_search_pkg(self.name)\n            if self.find_pkg:\n                self.dependencies_list = Requires(self.flag).sbo(self.name)\n        else:\n            PACKAGES_TXT = Utils().read_file(\n                self.meta.lib_path + \"{0}_repo/PACKAGES.TXT\".format(self.repo))\n            self.names = Utils().package_name(PACKAGES_TXT)\n            self.bin_case_insensitive()\n            self.find_pkg = search_pkg(self.name, self.repo)\n            if self.find_pkg:\n                self.black = BlackList().packages(self.names, self.repo)\n                self.dependencies_list = Dependencies(\n                    self.repo, self.black).binary(self.name, self.flag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmatch packages distinguish between uppercase and lowercase for sbo repository", "response": "def sbo_case_insensitive(self):\n        \"\"\"Matching packages distinguish between uppercase and\n        lowercase for sbo repository\n        \"\"\"\n        if \"--case-ins\" in self.flag:\n            data = SBoGrep(name=\"\").names()\n            data_dict = Utils().case_sensitive(data)\n            for key, value in data_dict.iteritems():\n                if key == self.name.lower():\n                    self.name = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bin_case_insensitive(self):\n        if \"--case-ins\" in self.flag:\n            data_dict = Utils().case_sensitive(self.names)\n            for key, value in data_dict.iteritems():\n                if key == self.name.lower():\n                    self.name = value", "response": "Matching packages distinguish between uppercase and lowercase"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_used(self, pkg):\n        used = []\n        dep_path = self.meta.log_path + \"dep/\"\n        logs = find_package(\"\", dep_path)\n        for log in logs:\n            deps = Utils().read_file(dep_path + log)\n            for dep in deps.splitlines():\n                if pkg == dep:\n                    used.append(log)\n        return used", "response": "Check if dependencies used by this package"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npackage dependencies image map file tree", "response": "def deps_tree(self):\n        \"\"\"Package dependencies image map file\n        \"\"\"\n        dependencies = self.dependencies + [self.name]\n        if self.repo == \"sbo\":\n            for dep in dependencies:\n                deps = Requires(flag=\"\").sbo(dep)\n                if dep not in self.deps_dict.values():\n                    self.deps_dict[dep] = Utils().dimensional_list(deps)\n        else:\n            for dep in dependencies:\n                deps = Dependencies(self.repo, self.black).binary(dep, flag=\"\")\n                if dep not in self.deps_dict.values():\n                    self.deps_dict[dep] = Utils().dimensional_list(deps)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deps_used(self, pkg, used):\n        if find_package(pkg + self.meta.sp, self.meta.pkg_path):\n            if pkg not in self.deps_dict.values():\n                self.deps_dict[pkg] = used\n            else:\n                self.deps_dict[pkg] += used", "response": "Add the given package to the set of used dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(self):\n        if self.find:\n            return self.meta.sp + split_package(self.find)[1]\n        return \"\"", "response": "Return version from installed packages\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck from GitHub slpkg repository if new version is available download and update itself", "response": "def it_self_update():\n    \"\"\"Check from GitHub slpkg repository if new version is available\n    download and update itself\n    \"\"\"\n    __new_version__ = \"\"\n    repository = \"gitlab\"\n    branch = \"master\"\n    ver_link = (\"https://raw.{0}usercontent.com/{1}/{2}/\"\n                \"{3}/{4}/__metadata__.py\".format(repository, _meta_.__author__,\n                                                 _meta_.__all__, branch,\n                                                 _meta_.__all__))\n    version_data = URL(ver_link).reading()\n    for line in version_data.splitlines():\n        line = line.strip()\n        if line.startswith(\"__version_info__\"):\n            __new_version__ = \".\".join(re.findall(r\"\\d+\", line))\n    if __new_version__ > _meta_.__version__:\n        if _meta_.default_answer in [\"y\", \"Y\"]:\n            answer = _meta_.default_answer\n        else:\n            print(\"\\nNew version '{0}-{1}' is available !\\n\".format(\n                _meta_.__all__, __new_version__))\n            try:\n                answer = raw_input(\"Would you like to upgrade [y/N]? \")\n            except EOFError:\n                print(\"\")\n                raise SystemExit()\n        if answer in [\"y\", \"Y\"]:\n            print(\"\")   # new line after answer\n        else:\n            raise SystemExit()\n        dwn_link = [\"https://{0}.com/{1}/{2}/archive/\"\n                    \"v{3}/{4}-{5}.tar.gz\".format(repository, _meta_.__author__,\n                                                 _meta_.__all__,\n                                                 __new_version__,\n                                                 _meta_.__all__,\n                                                 __new_version__)]\n        if not os.path.exists(_meta_.build_path):\n            os.makedirs(_meta_.build_path)\n        Download(_meta_.build_path, dwn_link, repo=\"\").start()\n        os.chdir(_meta_.build_path)\n        slpkg_tar_file = \"slpkg\" + \"-\" + __new_version__ + \".tar.gz\"\n        tar = tarfile.open(slpkg_tar_file)\n        tar.extractall()\n        tar.close()\n        file_name = \"{0}-{1}\".format(_meta_.__all__, __new_version__)\n        os.chdir(file_name)\n        check_md5(pkg_checksum(slpkg_tar_file, _meta_.__all__),\n                  _meta_.build_path + slpkg_tar_file)\n        subprocess.call(\"chmod +x {0}\".format(\"install.sh\"), shell=True)\n        subprocess.call(\"sh install.sh\", shell=True)\n    else:\n        print(\"\\n{0}: There is no new version, already used the last !\"\n              \"\\n\".format(_meta_.__all__))\n    raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, is_upgrade):\n        self.case_insensitive()\n        # fix if packages is for upgrade\n        self.is_upgrade = is_upgrade\n        mas_sum = dep_sum = sums = [0, 0, 0]\n        self.msg.done()\n        self.dependencies = self.resolving_deps()\n        self.update_deps()\n        (self.dep_dwn, self.dep_install, self.dep_comp_sum,\n            self.dep_uncomp_sum) = self.store(self.dependencies)\n        self.clear_masters()\n        (self.dwn, self.install, self.comp_sum,\n            self.uncomp_sum) = self.store(self.packages)\n        if (self.meta.rsl_deps in [\"on\", \"ON\"] and\n                \"--resolve-off\" not in self.flag):\n            self.msg.done()\n        if self.install:\n            if self.matching and [\"\"] != self.packages:\n                self.msg.matching(self.packages)\n            else:\n                print(\"\\nThe following packages will be automatically \"\n                      \"installed or upgraded \\nwith new version:\\n\")\n            self.top_view()\n            self.msg.upg_inst(self.is_upgrade)\n            mas_sum = self.views(self.install, self.comp_sum)\n            if self.dependencies:\n                print(\"Installing for dependencies:\")\n                dep_sum = self.views(self.dep_install, self.dep_comp_sum)\n            # sums[0] --> installed\n            # sums[1] --> upgraded\n            # sums[2] --> uninstall\n            sums = [sum(i) for i in zip(mas_sum, dep_sum)]\n            unit, size = units(self.comp_sum + self.dep_comp_sum,\n                               self.uncomp_sum + self.dep_uncomp_sum)\n            if self.matching and [\"\"] != self.packages:\n                print(\"\\nMatching summary\")\n                print(\"=\" * 79)\n                print(\"Total {0} matching packages\\n\".format(sum(sums)))\n                raise SystemExit(1)\n            print(\"\\nInstalling summary\")\n            print(\"=\" * 79)\n            print(\"{0}Total {1} {2}.\".format(self.meta.color[\"GREY\"],\n                                             sum(sums),\n                                             self.msg.pkg(sum(sums))))\n            print(\"{0} {1} will be installed, {2} will be upgraded and \"\n                  \"{3} will be reinstalled.\".format(sums[2],\n                                                    self.msg.pkg(sums[2]),\n                                                    sums[1], sums[0]))\n            print(\"Need to get {0} {1} of archives.\".format(size[0],\n                                                            unit[0]))\n            print(\"After this process, {0} {1} of additional disk \"\n                  \"space will be used.{2}\".format(size[1], unit[1],\n                                                  self.meta.color[\"ENDC\"]))\n            print(\"\")\n            self.if_all_installed()\n            if self.msg.answer() in [\"y\", \"Y\"]:\n                for inst, dwn in zip(self.dep_install + self.install,\n                                     self.dep_dwn + self.dwn):\n                    if (self.meta.not_downgrade == \"on\" and\n                            self.not_downgrade(inst) is True):\n                        continue\n                    if (not os.path.isfile(self.meta.pkg_path + inst[:-4]) or\n                            \"--download-only\" in self.flag or\n                            \"--reinstall\" in self.flag):\n                        Download(self.tmp_path, dwn.split(), self.repo).start()\n                    else:\n                        self.msg.template(78)\n                        self.msg.pkg_found(inst)\n                        self.msg.template(78)\n                if \"--download-only\" in self.flag:\n                    raise SystemExit()\n                self.dep_install = Utils().check_downloaded(\n                    self.tmp_path, self.dep_install)\n                self.install = Utils().check_downloaded(\n                    self.tmp_path, self.install)\n                ins, upg = self.install_packages()\n                self.msg.reference(ins, upg)\n                write_deps(self.deps_dict)\n                delete_package(self.tmp_path, self.dep_install + self.install)\n        else:\n            self.msg.not_found(self.is_upgrade)\n            raise SystemExit(1)", "response": "Start the internal method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef if_all_installed(self):\n        count_inst = 0\n        for inst in (self.dep_install + self.install):\n            if (os.path.isfile(self.meta.pkg_path + inst[:-4]) and\n                    \"--download-only\" not in self.flag):\n                count_inst += 1\n        if (count_inst == len(self.dep_install + self.install) and\n                \"--reinstall\" not in self.flag):\n            raise SystemExit()", "response": "Check if all packages are already installed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef case_insensitive(self):\n        if \"--case-ins\" in self.flag:\n            data = []\n            data = Utils().package_name(self.PACKAGES_TXT)\n            data_dict = Utils().case_sensitive(data)\n            for pkg in self.packages:\n                index = self.packages.index(pkg)\n                for key, value in data_dict.iteritems():\n                    if key == pkg.lower():\n                        self.packages[index] = value", "response": "Matching packages distinguish between uppercase and lowercase"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_deps(self):\n        for dep in self.dependencies:\n            deps = Utils().dimensional_list(Dependencies(\n                self.repo, self.blacklist).binary(\n                    dep, self.flag))\n            self.deps_dict[dep] = deps", "response": "Update dependencies dictionary with all package\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing master packages if already exist in dependencies or if added to install two or more times", "response": "def clear_masters(self):\n        \"\"\"Clear master packages if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n        packages = []\n        for mas in Utils().remove_dbs(self.packages):\n            if mas not in self.dependencies:\n                packages.append(mas)\n        self.packages = packages"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_packages(self):\n        installs, upgraded = [], []\n        for inst in (self.dep_install + self.install):\n            package = (self.tmp_path + inst).split()\n            pkg_ver = \"{0}-{1}\".format(split_package(inst)[0],\n                                       split_package(inst)[1])\n            self.checksums(inst)\n            if GetFromInstalled(split_package(inst)[0]).name():\n                print(\"[ {0}upgrading{1} ] --> {2}\".format(\n                    self.meta.color[\"YELLOW\"], self.meta.color[\"ENDC\"], inst))\n                upgraded.append(pkg_ver)\n                if \"--reinstall\" in self.flag:\n                    PackageManager(package).upgrade(\"--reinstall\")\n                else:\n                    PackageManager(package).upgrade(\"--install-new\")\n            else:\n                print(\"[ {0}installing{1} ] --> {2}\".format(\n                    self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"], inst))\n                installs.append(pkg_ver)\n                PackageManager(package).upgrade(\"--install-new\")\n        return [installs, upgraded]", "response": "Install or upgrade packages\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef not_downgrade(self, package):\n        name = split_package(package)[0]\n        rep_ver = split_package(package)[1]\n        ins_ver = GetFromInstalled(name).version()[1:]\n        if not ins_ver:\n            ins_ver = \"0\"\n        if LooseVersion(rep_ver) < LooseVersion(ins_ver):\n            self.msg.template(78)\n            print(\"| Package {0} don't downgrade, \"\n                  \"setting by user\".format(name))\n            self.msg.template(78)\n            return True", "response": "Don t downgrade packages if repository version is lower than installed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfixes store deps include in repository", "response": "def _fix_deps_repos(self, dependencies):\n        \"\"\"Fix store deps include in repository\n        \"\"\"\n        requires = []\n        for dep in dependencies:\n            if dep in self.repo_pkg_names:\n                requires.append(dep)\n        return requires"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nview packages and uninstalled ones", "response": "def views(self, install, comp_sum):\n        \"\"\"Views packages\n        \"\"\"\n        pkg_sum = uni_sum = upg_sum = 0\n        # fix repositories align\n        repo = self.repo + (\" \" * (6 - (len(self.repo))))\n        for pkg, comp in zip(install, comp_sum):\n            pkg_repo = split_package(pkg[:-4])\n            if find_package(pkg[:-4], self.meta.pkg_path):\n                pkg_sum += 1\n                COLOR = self.meta.color[\"GREEN\"]\n            elif pkg_repo[0] == GetFromInstalled(pkg_repo[0]).name():\n                COLOR = self.meta.color[\"YELLOW\"]\n                upg_sum += 1\n            else:\n                COLOR = self.meta.color[\"RED\"]\n                uni_sum += 1\n            ver = GetFromInstalled(pkg_repo[0]).version()\n            print(\"  {0}{1}{2}{3} {4}{5} {6}{7}{8}{9}{10}{11:>11}{12}\".format(\n                COLOR, pkg_repo[0] + ver, self.meta.color[\"ENDC\"],\n                \" \" * (23-len(pkg_repo[0] + ver)), pkg_repo[1],\n                \" \" * (18-len(pkg_repo[1])), pkg_repo[2],\n                \" \" * (8-len(pkg_repo[2])), pkg_repo[3],\n                \" \" * (7-len(pkg_repo[3])), repo,\n                comp, \" K\")).rstrip()\n        return [pkg_sum, upg_sum, uni_sum]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting packages status bar", "response": "def top_view(self):\n        \"\"\"Print packages status bar\n        \"\"\"\n        self.msg.template(78)\n        print(\"{0}{1}{2}{3}{4}{5}{6}{7}{8}{9}{10}\".format(\n            \"| Package\", \" \" * 17,\n            \"New Version\", \" \" * 8,\n            \"Arch\", \" \" * 4,\n            \"Build\", \" \" * 2,\n            \"Repos\", \" \" * 10,\n            \"Size\"))\n        self.msg.template(78)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store(self, packages):\n        dwn, install, comp_sum, uncomp_sum = ([] for i in range(4))\n        # name = data[0]\n        # location = data[1]\n        # size = data[2]\n        # unsize = data[3]\n        for pkg in packages:\n            for pk, loc, comp, uncomp in zip(self.data[0], self.data[1],\n                                             self.data[2], self.data[3]):\n                if (pk and pkg == split_package(pk)[0] and\n                        pk not in install and\n                        split_package(pk)[0] not in self.blacklist):\n                    dwn.append(\"{0}{1}/{2}\".format(self.mirror, loc, pk))\n                    install.append(pk)\n                    comp_sum.append(comp)\n                    uncomp_sum.append(uncomp)\n        if not install:\n            for pkg in packages:\n                for pk, loc, comp, uncomp in zip(self.data[0], self.data[1],\n                                                 self.data[2], self.data[3]):\n                    name = split_package(pk)[0]\n                    if (pk and pkg in name and name not in self.blacklist):\n                        self.matching = True\n                        dwn.append(\"{0}{1}/{2}\".format(self.mirror, loc, pk))\n                        install.append(pk)\n                        comp_sum.append(comp)\n                        uncomp_sum.append(uncomp)\n        dwn.reverse()\n        install.reverse()\n        comp_sum.reverse()\n        uncomp_sum.reverse()\n        if self.repo == \"slack\":\n            dwn, install, comp_sum, uncomp_sum = self.patches(dwn, install,\n                                                              comp_sum,\n                                                              uncomp_sum)\n        return [dwn, install, comp_sum, uncomp_sum]", "response": "Store and return packages for install\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning checksum from CHECKSUMS. md5 file by repository", "response": "def pkg_checksum(binary, repo):\n    \"\"\"Return checksum from CHECKSUMS.md5 file by repository\n    \"\"\"\n    md5 = \"None\"\n    if repo == \"slack_patches\" and _meta_.slack_rel == \"stable\":\n        CHECKSUMS_md5 = URL(mirrors(\"CHECKSUMS.md5\", \"patches/\")).reading()\n    elif repo == \"slack_patches\" and _meta_.slack_rel == \"current\":\n        CHECKSUMS_md5 = URL(mirrors(\"CHECKSUMS.md5\", \"\")).reading()\n    elif repo == \"slpkg\":\n        CHECKSUMS_md5 = URL(_meta_.CHECKSUMS_link).reading()\n    else:\n        lib = \"{0}{1}_repo/CHECKSUMS.md5\".format(_meta_.lib_path, repo)\n        f = open(lib, \"r\")\n        CHECKSUMS_md5 = f.read()\n        f.close()\n    for line in CHECKSUMS_md5.splitlines():\n        if line.endswith(\"/{0}\".format(binary)):\n            md5 = line.split()[0]\n    return md5"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads packages from slpkg library and from local", "response": "def library(repo):\n    \"\"\"Load packages from slpkg library and from local\n    \"\"\"\n    pkg_list, packages = [], \"\"\n    if repo == \"sbo\":\n        if (os.path.isfile(\n                _meta_.lib_path + \"{0}_repo/SLACKBUILDS.TXT\".format(repo))):\n            packages = Utils().read_file(_meta_.lib_path + \"{0}_repo/\"\n                                         \"SLACKBUILDS.TXT\".format(repo))\n    else:\n        if (os.path.isfile(\n                _meta_.lib_path + \"{0}_repo/PACKAGES.TXT\".format(repo))):\n            packages = Utils().read_file(_meta_.lib_path + \"{0}_repo/\"\n                                         \"PACKAGES.TXT\".format(repo))\n    for line in packages.splitlines():\n        if repo == \"sbo\":\n            if line.startswith(\"SLACKBUILD NAME: \"):\n                pkg_list.append(line[17:].strip())\n        elif \"local\" not in repo:\n            if line.startswith(\"PACKAGE NAME: \"):\n                pkg_list.append(line[15:].strip())\n    if repo == \"local\":\n        pkg_list = find_package(\"\", _meta_.pkg_path)\n    return pkg_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild package and fix ordelist per checksum", "response": "def run(self):\n        \"\"\"Build package and fix ordelist per checksum\n        \"\"\"\n        self.files_exist()\n        self.info_file()\n        sources = self.sources\n        if len(sources) > 1 and self.sbo_sources != sources:\n            sources = self.sbo_sources\n        # If the list does not have the same order use from .info\n        # order.\n        BuildPackage(self.script, sources, self.path, auto=True).build()\n        raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef info_file(self):\n        sources = SBoGrep(self.prgnam).source().split()\n        for source in sources:\n            self.sbo_sources.append(source.split(\"/\")[-1])", "response": "Grab sources from. info file and store filename\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if SlackBuild archive. tar. gz and sources exist", "response": "def files_exist(self):\n        \"\"\"Check if SlackBuild archive.tar.gz and sources exist\n        \"\"\"\n        if not os.path.isfile(self.path + self.script):\n            print(\"\\nslpkg: Error: SlackBuild archive.tar.gz not found\\n\")\n            raise SystemExit()\n        for src in self.sources:\n            if not os.path.isfile(self.path + src):\n                print(\"\\nslpkg: Error: Source file '{0}' not found\\n\".format(\n                    src))\n                raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhelping and version info", "response": "def help_version(self):\n        \"\"\"Help and version info\n        \"\"\"\n        if (len(self.args) == 1 and self.args[0] in [\"-h\", \"--help\"] and\n                self.args[1:] == []):\n            options()\n        elif (len(self.args) == 1 and self.args[0] in [\"-v\", \"--version\"] and\n                self.args[1:] == []):\n            prog_version()\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates package lists repositories", "response": "def command_update(self):\n        \"\"\"Update package lists repositories\n        \"\"\"\n        if len(self.args) == 1 and self.args[0] == \"update\":\n            Update().repository(only=\"\")\n        elif (len(self.args) == 2 and self.args[0] == \"update\" and\n                self.args[1].startswith(\"--only=\")):\n            repos = self.args[1].split(\"=\")[-1].split(\",\")\n            for rp in repos:\n                if rp not in self.meta.repositories:\n                    repos.remove(rp)\n            Update().repository(repos)\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrecreating repositories package lists", "response": "def command_upgrade(self):\n        \"\"\"Recreate repositories package lists\n        \"\"\"\n        if len(self.args) == 1 and self.args[0] == \"upgrade\":\n            Initialization(False).upgrade(only=\"\")\n        elif (len(self.args) == 2 and self.args[0] == \"upgrade\" and\n                self.args[1].startswith(\"--only=\")):\n            repos = self.args[1].split(\"=\")[-1].split(\",\")\n            for rp in repos:\n                if rp not in self.meta.repositories:\n                    repos.remove(rp)\n            Initialization(False).upgrade(repos)\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmanage new configuration files", "response": "def command_new_config(self):\n        \"\"\"Manage .new configuration files\n        \"\"\"\n        if len(self.args) == 1 and self.args[0] == \"new-config\":\n            NewConfig().run()\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pkg_list(self):\n        options = [\n            \"-l\",\n            \"--list\"\n        ]\n        flag = [\"--index\", \"--installed\", \"--name\"]\n        name = INDEX = installed = False\n        for arg in self.args[2:]:\n            if flag[0] == arg:\n                INDEX = True\n            if flag[1] in arg:\n                installed = True\n            if flag[2] == arg:\n                name = True\n            if arg not in flag:\n                usage(\"\")\n                raise SystemExit()\n        if (len(self.args) > 1 and len(self.args) <= 5 and\n                self.args[0] in options):\n            if self.args[1] in self.meta.repositories:\n                PackageManager(binary=None).package_list(self.args[1],\n                                                         name,\n                                                         INDEX,\n                                                         installed)\n            else:\n                usage(self.args[1])\n        else:\n            usage(\"\")", "response": "List packages by repository\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck and upgrade packages by repository", "response": "def pkg_upgrade(self):\n        \"\"\"Check and upgrade packages by repository\n        \"\"\"\n        options = [\n            \"-c\",\n            \"--check\"\n        ]\n        flags = [\n            \"--upgrade\",\n            \"--skip=\",\n            \"--resolve-off\",\n            \"--checklist\",\n            \"--rebuild\"\n        ]\n        flag, skip = self.__pkg_upgrade_flags(flags)\n        if (len(self.args) == 3 and self.args[0] in options and\n                self.args[2] == flags[0] and\n                self.args[1] in self.meta.repositories):\n            if self.args[1] not in [\"slack\", \"sbo\"]:\n                BinaryInstall(pkg_upgrade(self.args[1], skip, flag),\n                              self.args[1], flag).start(is_upgrade=True)\n            elif self.args[1] == \"slack\":\n                if self.meta.only_installed in [\"on\", \"ON\"]:\n                    BinaryInstall(pkg_upgrade(\"slack\", skip, flag),\n                                  \"slack\", flag).start(is_upgrade=True)\n                else:\n                    Patches(skip, flag).start()\n            elif self.args[1] == \"sbo\":\n                SBoInstall(sbo_upgrade(skip, flag), flag).start(is_upgrade=True)\n            else:\n                usage(self.args[1])\n        elif len(self.args) == 2 and self.args[0] in options:\n            if self.args[1] == \"ALL\":\n                Updates(repo=\"\").ALL()\n            else:\n                Updates(self.args[1]).run()\n        elif (len(self.args) >= 2 and self.args[0] in options and\n                self.args[1] not in self.meta.repositories):\n            usage(self.args[1])\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __pkg_upgrade_flags(self, flags):\n        flag, skip = [], \"\"\n        if flags[0] in self.args:\n            for arg in self.args[3:]:\n                if arg.startswith(flags[1]):\n                    skip = Regex(arg.split(\"=\")[1]).get()\n                    self.args.remove(arg)\n                if arg in flags:\n                    flag.append(arg)\n                    if arg in self.args:\n                        self.args.remove(arg)\n        return flag, skip", "response": "Manage flags for package upgrade option\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pkg_install(self):\n        flag = []\n        options = [\n            \"-s\",\n            \"--sync\"\n        ]\n        additional_options = [\n            \"--resolve-off\",\n            \"--download-only\",\n            \"--directory-prefix=\",\n            \"--case-ins\",\n            \"--rebuild\",\n            \"--reinstall\",\n            \"--patches\"\n        ]\n        for arg in self.args:\n            if arg.startswith(additional_options[2]):\n                flag.append(arg)\n                arg = \"\"\n            if arg in additional_options:\n                flag.append(arg)\n        # clean from flags\n        for ar in flag:\n            if ar in self.args:\n                self.args.remove(ar)\n        if len(self.args) >= 3 and self.args[0] in options:\n            if (self.args[1] in self.meta.repositories and\n                    self.args[1] not in [\"sbo\"]):\n                BinaryInstall(self.args[2:], self.args[1], flag).start(\n                    is_upgrade=False)\n            elif (self.args[1] == \"sbo\" and\n                    self.args[1] in self.meta.repositories):\n                SBoInstall(self.args[2:], flag).start(is_upgrade=False)\n            else:\n                usage(self.args[1])\n        else:\n            usage(\"\")", "response": "Install packages by repository\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmanage packages in queue AttributeNames", "response": "def pkg_queue(self):\n        \"\"\"Manage packages in queue\n        \"\"\"\n        queue = QueuePkgs()\n        options = [\n            \"-q\",\n            \"--queue\"\n        ]\n        flag = [\n            \"--add\",\n            \"--remove\"\n        ]\n        command = [\n            \"list\",\n            \"build\",\n            \"install\",\n            \"build-install\"\n        ]\n        if (len(self.args) > 2 and self.args[0] in options and\n                flag[0] in self.args):\n            self.args.remove(flag[0])\n            queue.add(self.args[1:])\n        elif (len(self.args) == 3 and self.args[0] in options and\n                \"ALL\" in self.args and flag[1] in self.args):\n            self.args.remove(flag[1])\n            queue.remove(queue.packages())\n        elif (len(self.args) > 2 and self.args[0] in options and\n                flag[1] in self.args):\n            self.args.remove(flag[1])\n            queue.remove(self.args[1:])\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == command[0]):\n            queue.listed()\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == command[1]):\n            queue.build()\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == command[2]):\n            queue.install()\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == command[3]):\n            queue.build()\n            queue.install()\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bin_upgrade(self):\n        packages = self.args[1:]\n        options = [\n            \"-u\",\n            \"--upgradepkg\"\n        ]\n        flag = \"\"\n        flags = [\n            \"--dry-run\",\n            \"--install-new\",\n            \"--reinstall\",\n            \"--verbose\"\n        ]\n        if len(self.args) > 1 and self.args[0] in options:\n            if self.args[1] in flags:\n                flag = self.args[1]\n                packages = self.args[2:]\n            PackageManager(packages).upgrade(flag)\n        else:\n            usage(\"\")", "response": "Install - upgrade Slackware binary packages\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint slack - desc by repository", "response": "def pkg_desc(self):\n        \"\"\"Print slack-desc by repository\n        \"\"\"\n        options = [\n            \"-p\",\n            \"--desc\"\n        ]\n        flag = [\"--color=\"]\n        colors = [\n            \"red\",\n            \"green\",\n            \"yellow\",\n            \"cyan\",\n            \"grey\"\n        ]\n        tag = \"\"\n        for arg in self.args:\n            if arg.startswith(flag[0]):\n                tag = arg[len(flag[0]):]\n                self.args.remove(arg)\n                break\n        if tag and tag not in colors:\n            print(\"\\nslpkg: Error: Available colors {0}\\n\".format(\n                colors))\n            raise SystemExit()\n        if (len(self.args) == 3 and self.args[0] in options and\n                self.args[1] in self.meta.repositories and tag in colors):\n            PkgDesc(self.args[2], self.args[1], tag).view()\n        elif (len(self.args) == 3 and self.args[0] in options and\n                self.args[1] in self.meta.repositories):\n            PkgDesc(self.args[2], self.args[1], paint=\"\").view()\n        elif (len(self.args) > 1 and self.args[0] in options and\n                self.args[1] not in self.meta.repositories):\n            usage(self.args[1])\n        else:\n            usage(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pkg_find(self):\n        flag = []\n        options = [\n            \"-F\",\n            \"--FIND\"\n        ]\n        additional_options = [\"--case-ins\"]\n        for arg in self.args:\n            if arg in additional_options:\n                flag.append(arg)\n                self.args.remove(arg)\n        packages = self.args[1:]\n        if len(self.args) > 1 and self.args[0] in options:\n            FindFromRepos().find(packages, flag)\n        else:\n            usage(\"\")", "response": "Find packages from all enabled repositories\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef congiguration(self):\n        options = [\n            \"-g\",\n            \"--config\"\n        ]\n        command = [\n            \"print\",\n            \"edit\",\n            \"reset\"\n        ]\n        conf = Config()\n        if (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == command[1]):\n            conf.edit()\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == (command[0])):\n            conf.view()\n        elif (len(self.args) == 2 and self.args[0] in options and\n                self.args[1] == (command[2])):\n            conf.reset()\n        else:\n            usage(\"\")", "response": "Manage slpkg configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auto_detect(self, args):\n        suffixes = [\n            \".tgz\",\n            \".txz\",\n            \".tbz\",\n            \".tlz\"\n        ]\n        if (not args[0].startswith(\"-\") and args[0] not in self.commands and\n                args[0].endswith(tuple(suffixes))):\n            packages, not_found = [], []\n            for pkg in args:\n                if pkg.endswith(tuple(suffixes)):\n                    if os.path.isfile(pkg):\n                        packages.append(pkg)\n                    else:\n                        not_found.append(pkg)\n            if packages:\n                Auto(packages).select()\n            if not_found:\n                for ntf in not_found:\n                    self.msg.pkg_not_found(\"\", ntf, \"Not installed\", \"\")\n            raise SystemExit()", "response": "Check for already Slackware binary packages exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_pkg(name, repo):\n    PACKAGES_TXT = Utils().read_file(_meta_.lib_path + \"{0}_repo/\"\n                                     \"PACKAGES.TXT\".format(repo))\n    names = Utils().package_name(PACKAGES_TXT)\n    blacklist = BlackList().packages(pkgs=names, repo=repo)\n    for line in PACKAGES_TXT.splitlines():\n        status(0)\n        if line.startswith(\"PACKAGE NAME:  \") and len(line) > 16:\n            pkg_name = split_package(line[15:])[0].strip()\n            if name == pkg_name and name not in blacklist:\n                return pkg_name", "response": "Search if package exists in PACKAGES. TXT file\n    and return the name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data(self):\n        for pkg in self.installed:\n            if os.path.isfile(self.meta.pkg_path + pkg):\n                name = split_package(pkg)[0]\n                for log in self.logs:\n                    deps = Utils().read_file(self.dep_path + log)\n                    for dep in deps.splitlines():\n                        if name == dep:\n                            if name not in self.dmap.keys():\n                                self.dmap[name] = [log]\n                                if not self.count_pkg:\n                                    self.count_pkg = 1\n                            else:\n                                self.dmap[name] += [log]\n        self.count_packages()", "response": "Check all installed packages and create a dictionary database containing all the log entries for the current package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of packages and dependencies.", "response": "def count_packages(self):\n        \"\"\"Count dependencies and packages\n        \"\"\"\n        packages = []\n        for pkg in self.dmap.values():\n            packages += pkg\n            self.count_dep += 1\n        self.count_pkg = len(set(packages))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes tree view mode", "response": "def tree(self):\n        \"\"\"Like tree view mode\n        \"\"\"\n        self.msg.template(78)\n        print(\"| Dependencies\\n\"\n              \"| -- Packages\")\n        self.msg.template(78)\n        self.data()\n        for pkg, dep in self.dmap.iteritems():\n            print(\"+ {0}{1}{2}\".format(self.green, pkg, self.endc))\n            print(\"|\")\n            for d in dep:\n                print(\"+-- {0}\".format(d))\n                print(\"|\")\n            sys.stdout.write(\"\\x1b[1A{0}\\n\".format(\" \"))\n            sys.stdout.flush()\n        self.summary()\n        if self.image:\n            Graph(self.image).dependencies(self.dmap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef summary(self):\n        print(\"\\nStatus summary\")\n        print(\"=\" * 79)\n        print(\"{0}found {1} dependencies in {2} packages.{3}\\n\".format(\n            self.grey, self.count_dep, self.count_pkg, self.endc))", "response": "Summary by packages and dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind packages and print them to stdout", "response": "def find(self, pkg, flag):\n        \"\"\"Start to find packages and print\n        \"\"\"\n        print(\"\\nPackages with name matching [ {0}{1}{2} ]\\n\".format(\n            self.cyan, \", \".join(pkg), self.endc))\n        Msg().template(78)\n        print(\"| {0}  {1}{2}{3}\".format(\"Repository\", \"Package\", \" \" * 54,\n                                        \"Size\"))\n        Msg().template(78)\n        for repo in _meta_.repositories:\n            PACKAGES_TXT = PackageManager(pkg).list_lib(repo)\n            packages, sizes = PackageManager(pkg).list_greps(repo, PACKAGES_TXT)\n            for find, size in zip(packages, sizes):\n                for p in pkg:\n                    if \"--case-ins\" in flag:\n                        self.p_cache = p.lower()\n                        self.find_cache = find.lower()\n                    else:\n                        self.p_cache = p\n                        self.find_cache = find\n                    if self.p_cache in self.find_cache:\n                        if self.cache != repo:\n                            self.count_repo += 1\n                        self.cache = repo\n                        self.count_pkg += 1\n                        ver = self.sbo_version(repo, find)\n                        print(\"  {0}{1}{2}{3}{4} {5}{6:>11}\".format(\n                            self.cyan, repo, self.endc,\n                            \" \" * (12 - len(repo)),\n                            find + ver, \" \" * (53 - len(find + ver)),\n                            size))\n        print(\"\\nFound summary\")\n        print(\"=\" * 79)\n        print(\"{0}Total found {1} packages in {2} repositories.\"\n              \"{3}\\n\".format(self.grey, self.count_pkg,\n                             self.count_repo, self.endc))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the version of the SBo package", "response": "def sbo_version(self, repo, find):\n        \"\"\"\n        Add version to SBo packages\n        \"\"\"\n        ver = \"\"\n        if repo == \"sbo\":\n            ver = \"-\" + SBoGrep(find).version()\n        return ver"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slack_ver():\n\n    if _meta_.slackware_version in [\"off\", \"OFF\"]:\n        sv = Utils().read_file(\"/etc/slackware-version\")\n        version = re.findall(r\"\\d+\", sv)\n        if len(sv) > 2:\n            return (\".\".join(version[:2]))\n        else:\n            return (\".\".join(version))\n    else:\n        return _meta_.slackware_version", "response": "Return Slackware version as string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite custom repository name and url in a file", "response": "def add(self, repo, url):\n        \"\"\"Write custom repository name and url in a file\n        \"\"\"\n        repo_name = []\n        if not url.endswith(\"/\"):\n            url = url + \"/\"\n        for line in self.custom_repositories_list.splitlines():\n            line = line.lstrip()\n            if line and not line.startswith(\"#\"):\n                repo_name.append(line.split()[0])\n        if (repo in self.meta.repositories or repo in repo_name or\n                repo in self.meta.default_repositories):\n            print(\"\\nRepository name '{0}' exist, select different name.\\n\"\n                  \"View all repositories with command 'slpkg \"\n                  \"repo-list'.\\n\".format(repo))\n            raise SystemExit()\n        elif len(repo) > 6:\n            print(\"\\nslpkg: Error: Maximum repository name length must be \"\n                  \"six (6) characters\\n\")\n            raise SystemExit()\n        with open(self.custom_repo_file, \"a\") as repos:\n            new_line = \"  {0}{1}{2}\\n\".format(repo, \" \" * (10 - len(repo)), url)\n            repos.write(new_line)\n        repos.close()\n        print(\"\\nRepository '{0}' successfully added\\n\".format(repo))\n        raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef custom_repository(self):\n        custom_dict_repo = {}\n        for line in self.custom_repositories_list.splitlines():\n            line = line.lstrip()\n            if not line.startswith(\"#\"):\n                custom_dict_repo[line.split()[0]] = line.split()[1]\n        return custom_dict_repo", "response": "Return dictionary with repo name and url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns dictionary with default repo name and url", "response": "def default_repository(self):\n        \"\"\"Return dictionary with default repo name and url\n        \"\"\"\n        default_dict_repo = {}\n        for line in self.default_repositories_list.splitlines():\n            line = line.lstrip()\n            if not line.startswith(\"#\"):\n                if line.split()[0] in self.DEFAULT_REPOS_NAMES:\n                    default_dict_repo[line.split()[0]] = line.split()[1]\n                else:\n                    print(\"\\nslpkg: Error: Repository name '{0}' is not \"\n                          \"default.\\n              Please check file: \"\n                          \"/etc/slpkg/default-repositories\\n\".format(\n                              line.split()[0]))\n                    raise SystemExit()\n        return default_dict_repo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_md5(pkg_md5, src_file):\n    if _meta_.checkmd5 in [\"on\", \"ON\"]:\n        print(\"\")\n        md5s = md5(src_file)\n        if pkg_md5 != md5s:\n            Msg().template(78)\n            print(\"| MD5SUM check for {0} [ {1}FAILED{2} ]\".format(\n                src_file.split(\"/\")[-1], _meta_.color[\"RED\"],\n                _meta_.color[\"ENDC\"]))\n            Msg().template(78)\n            print(\"| Expected: {0}\".format(pkg_md5))\n            print(\"| Found: {0}\".format(md5s))\n            Msg().template(78)\n            print(\"\")\n            if not Msg().answer() in [\"y\", \"Y\"]:\n                raise SystemExit()\n        else:\n            Msg().template(78)\n            print(\"| MD5SUM check for {0} [ {1}PASSED{2} ]\".format(\n                src_file.split(\"/\")[-1], _meta_.color[\"GREEN\"],\n                _meta_.color[\"ENDC\"]))\n            Msg().template(78)\n        print(\"\")", "response": "Check md5 checksum of a file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef view(self):\n        if self.sbo_url and self.name not in self.blacklist:\n            self.prgnam = (\"{0}-{1}\".format(self.name, self.sbo_version))\n            self.view_sbo()\n            while True:\n                self.read_choice()\n                choice = {\n                    \"r\": self.choice_README,\n                    \"R\": self.choice_README,\n                    \"s\": self.choice_SlackBuild,\n                    \"S\": self.choice_SlackBuild,\n                    \"f\": self.choice_info,\n                    \"F\": self.choice_info,\n                    \"o\": self.choice_doinst,\n                    \"O\": self.choice_doinst,\n                    \"d\": self.choice_download,\n                    \"D\": self.choice_download,\n                    \"download\": self.choice_download,\n                    \"b\": self.choice_build,\n                    \"B\": self.choice_build,\n                    \"build\": self.choice_build,\n                    \"i\": self.choice_install,\n                    \"I\": self.choice_install,\n                    \"install\": self.choice_install,\n                    \"c\": self.choice_clear_screen,\n                    \"C\": self.choice_clear_screen,\n                    \"clear\": self.choice_clear_screen,\n                    \"q\": self.choice_quit,\n                    \"quit\": self.choice_quit,\n                    \"Q\": self.choice_quit\n                }\n                try:\n                    choice[self.choice]()\n                except KeyError:\n                    pass\n        else:\n            self.msg.pkg_not_found(\"\\n\", self.name, \"Can't view\", \"\\n\")\n            raise SystemExit(1)", "response": "View SlackBuild package read or install them from slackbuilds. org"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef case_insensitive(self):\n        if \"--case-ins\" in self.flag:\n            data_dict = Utils().case_sensitive(self.data)\n            for key, value in data_dict.iteritems():\n                if key == self.name.lower():\n                    self.name = value", "response": "Matching packages distinguish between uppercase and lowercase"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_choice(self):\n        commands = {\n            \"r\": \"README\",\n            \"R\": \"README\",\n            \"s\": \"{0}.SlackBuild\".format(self.name),\n            \"S\": \"{0}.SlackBuild\".format(self.name),\n            \"f\": \"{0}.info\".format(self.name),\n            \"F\": \"{0}.info\".format(self.name),\n            \"o\": \"doinst.sh\",\n            \"O\": \"doinst.sh\",\n            \"d\": \"download\",\n            \"D\": \"download\",\n            \"download\": \"download\",\n            \"b\": \"build\",\n            \"B\": \"build\",\n            \"build\": \"build\",\n            \"i\": \"install\",\n            \"I\": \"install\",\n            \"install\": \"install\",\n            \"c\": \"clear\",\n            \"C\": \"clear\",\n            \"clear\": \"clear\",\n            \"q\": \"quit\",\n            \"quit\": \"quit\",\n            \"Q\": \"quit\"\n        }\n        try:\n            message = \"  Choose an option > \"\n            self.choice = raw_input(\"{0}{1}{2}\".format(self.grey, message,\n                                                       self.endc))\n        except EOFError:\n            print(\"\")\n            raise SystemExit()\n        try:\n            sys.stdout.write(\"{0}\\x1b[1A{1}{2}{3}\\n\".format(\n                \" \" * len(message), self.cyan, commands[self.choice],\n                self.endc))\n            sys.stdout.flush()\n        except KeyError:\n            pass", "response": "Read a random choice from the list of available options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef choice_doinst(self):\n        if \"doinst.sh\" in self.sbo_files.split():\n            doinst_sh = ReadSBo(self.sbo_url).doinst(\"doinst.sh\")\n            fill = self.fill_pager(doinst_sh)\n            self.pager(doinst_sh + fill)", "response": "View doinst. sh file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload script. tar. gz and sources", "response": "def choice_download(self):\n        \"\"\"Download script.tar.gz and sources\n        \"\"\"\n        Download(path=\"\", url=self.dwn_srcs, repo=\"sbo\").start()\n        raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef choice_install(self):\n        pkg_security([self.name])\n        if not find_package(self.prgnam, self.meta.pkg_path):\n            self.build()\n            self.install()\n            delete(self.build_folder)\n            raise SystemExit()\n        else:\n            self.msg.template(78)\n            self.msg.pkg_found(self.prgnam)\n            self.msg.template(78)\n            raise SystemExit()", "response": "Download build and install package"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nview slackbuild. org sbo", "response": "def view_sbo(self):\n        \"\"\"View slackbuild.org\n        \"\"\"\n        sbo_url = self.sbo_url.replace(\"/slackbuilds/\", \"/repository/\")\n        br1, br2, fix_sp = \"\", \"\", \" \"\n        if self.meta.use_colors in [\"off\", \"OFF\"]:\n            br1 = \"(\"\n            br2 = \")\"\n            fix_sp = \"\"\n        print(\"\")   # new line at start\n        self.msg.template(78)\n        print(\"| {0}{1}SlackBuilds Repository{2}\".format(\" \" * 28, self.grey,\n                                                         self.endc))\n        self.msg.template(78)\n        print(\"| {0} > {1} > {2}{3}{4}\".format(slack_ver(),\n                                               sbo_url.split(\"/\")[-3].title(),\n                                               self.cyan, self.name, self.endc))\n        self.msg.template(78)\n        print(\"| {0}Package url{1}: {2}\".format(self.green, self.endc, sbo_url))\n        self.msg.template(78)\n        print(\"| {0}Description: {1}{2}\".format(self.green,\n                                                self.endc, self.sbo_desc))\n        print(\"| {0}SlackBuild: {1}{2}\".format(self.green, self.endc,\n                                               self.sbo_dwn.split(\"/\")[-1]))\n        print(\"| {0}Sources: {1}{2}\".format(\n            self.green, self.endc,\n            (\", \".join([src.split(\"/\")[-1] for src in self.source_dwn]))))\n        print(\"| {0}Requirements: {1}{2}\".format(self.yellow,\n                                                 self.endc,\n                                                 \", \".join(self.sbo_req)))\n        self.msg.template(78)\n        print(\"| {0}R{1}{2}EADME               View the README file\".format(\n            self.red, self.endc, br2))\n        print(\"| {0}S{1}{2}lackBuild           View the .SlackBuild \"\n              \"file\".format(self.red, self.endc, br2))\n        print(\"| In{0}{1}f{2}{3}o{4}                View the .info \"\n              \"file\".format(br1, self.red, self.endc, br2, fix_sp))\n        if \"doinst.sh\" in self.sbo_files.split():\n            print(\"| D{0}{1}o{2}{3}inst.sh{4}           View the doinst.sh \"\n                  \"file\".format(br1, self.red, self.endc, br2, fix_sp))\n        print(\"| {0}D{1}{2}ownload             Download this package\".format(\n            self.red, self.endc, br2))\n        print(\"| {0}B{1}{2}uild                Download and build\".format(\n            self.red, self.endc, br2))\n        print(\"| {0}I{1}{2}nstall              Download/Build/Install\".format(\n            self.red, self.endc, br2))\n        print(\"| {0}C{1}{2}lear                Clear screen\".format(self.red,\n                                                                    self.endc,\n                                                                    br2))\n        print(\"| {0}Q{1}{2}uit                 Quit\".format(self.red,\n                                                            self.endc, br2))\n\n        self.msg.template(78)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef with_checklist(self):\n        data = []\n        if self.name == \"ALL\":\n            data = self.data\n        else:\n            for name in self.data:\n                if self.name in name:\n                    data.append(name)\n        if data:\n            text = \"Press 'spacebar' to choose SlackBuild for view\"\n            title = \" SlackBuilds.org \"\n            backtitle = \"{0} {1}\".format(_meta_.__all__, _meta_.__version__)\n            status = False\n            pkg = DialogUtil(data, text, title, backtitle, status).checklist()\n            if pkg and len(pkg) > 1:\n                print(\"\\nslpkg: Error: Choose only one package\")\n                raise SystemExit()\n            if pkg is None:\n                raise SystemExit()\n            self.name = \"\".join(pkg)\n            os.system(\"clear\")", "response": "Using dialog and checklist option\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef error_uns(self):\n        self.FAULT = \"\"\n        UNST = [\"UNSUPPORTED\", \"UNTESTED\"]\n        if \"\".join(self.source_dwn) in UNST:\n            self.FAULT = \"\".join(self.source_dwn)", "response": "Check if package supported by arch\n        before proceed to install\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build(self):\n        pkg_security([self.name])\n        self.error_uns()\n        if self.FAULT:\n            print(\"\")\n            self.msg.template(78)\n            print(\"| Package {0} {1} {2} {3}\".format(self.prgnam, self.red,\n                                                     self.FAULT, self.endc))\n            self.msg.template(78)\n        else:\n            sources = []\n            if not os.path.exists(self.meta.build_path):\n                os.makedirs(self.meta.build_path)\n            if not os.path.exists(self._SOURCES):\n                os.makedirs(self._SOURCES)\n            os.chdir(self.meta.build_path)\n            Download(self.meta.build_path, self.sbo_dwn.split(),\n                     repo=\"sbo\").start()\n            Download(self._SOURCES, self.source_dwn, repo=\"sbo\").start()\n            script = self.sbo_dwn.split(\"/\")[-1]\n            for src in self.source_dwn:\n                sources.append(src.split(\"/\")[-1])\n            BuildPackage(script, sources, self.meta.build_path,\n                         auto=False).build()\n            slack_package(self.prgnam)", "response": "Only build and create Slackware package"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef install(self):\n        binary = slack_package(self.prgnam)\n        print(\"[ {0}Installing{1} ] --> {2}\".format(self.green, self.endc,\n                                                    self.name))\n        PackageManager(binary).upgrade(flag=\"--install-new\")", "response": "Install SBo package found in / tmp directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef packages(self):\n        queue_list = []\n        for read in self.queued.splitlines():\n            read = read.lstrip()\n            if not read.startswith(\"#\"):\n                queue_list.append(read.replace(\"\\n\", \"\"))\n        return queue_list", "response": "Return queue list from / var / lib / queue_list\n        file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listed(self):\n        print(\"\\nPackages in the queue:\\n\")\n        for pkg in self.packages():\n            if pkg:\n                print(\"{0}{1}{2}\".format(self.meta.color[\"GREEN\"], pkg,\n                                         self.meta.color[\"ENDC\"]))\n                self.quit = True\n        if self.quit:\n            print(\"\")", "response": "Print packages in queue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd packages in queue if not exist", "response": "def add(self, pkgs):\n        \"\"\"Add packages in queue if not exist\n        \"\"\"\n        queue_list = self.packages()\n        pkgs = list(OrderedDict.fromkeys(pkgs))\n        print(\"\\nAdd packages in the queue:\\n\")\n        with open(self.queue_list, \"a\") as queue:\n            for pkg in pkgs:\n                find = sbo_search_pkg(pkg)\n                if pkg not in queue_list and find is not None:\n                    print(\"{0}{1}{2}\".format(self.meta.color[\"GREEN\"], pkg,\n                                             self.meta.color[\"ENDC\"]))\n                    queue.write(pkg + \"\\n\")\n                    self.quit = True\n                else:\n                    print(\"{0}{1}{2}\".format(self.meta.color[\"RED\"], pkg,\n                                             self.meta.color[\"ENDC\"]))\n                    self.quit = True\n            queue.close()\n        if self.quit:\n            print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, pkgs):\n        print(\"\\nRemove packages from the queue:\\n\")\n        with open(self.queue_list, \"w\") as queue:\n            for line in self.queued.splitlines():\n                if line not in pkgs:\n                    queue.write(line + \"\\n\")\n                else:\n                    print(\"{0}{1}{2}\".format(self.meta.color[\"RED\"], line,\n                                             self.meta.color[\"ENDC\"]))\n                    self.quit = True\n            queue.close()\n        if self.quit:\n            print(\"\")", "response": "Remove packages from queue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild packages from queue", "response": "def build(self):\n        \"\"\"Build packages from queue\n        \"\"\"\n        packages = self.packages()\n        if packages:\n            for pkg in packages:\n                if not os.path.exists(self.meta.build_path):\n                    os.mkdir(self.meta.build_path)\n                if not os.path.exists(self._SOURCES):\n                    os.mkdir(self._SOURCES)\n                sbo_url = sbo_search_pkg(pkg)\n                sbo_dwn = SBoLink(sbo_url).tar_gz()\n                source_dwn = SBoGrep(pkg).source().split()\n                sources = []\n                os.chdir(self.meta.build_path)\n                script = sbo_dwn.split(\"/\")[-1]\n                Download(self.meta.build_path, sbo_dwn.split(),\n                         repo=\"sbo\").start()\n                for src in source_dwn:\n                    Download(self._SOURCES, src.split(), repo=\"sbo\").start()\n                    sources.append(src.split(\"/\")[-1])\n                BuildPackage(script, sources, self.meta.build_path,\n                             auto=False).build()\n        else:\n            print(\"\\nPackages not found in the queue for building\\n\")\n            raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install(self):\n        packages = self.packages()\n        if packages:\n            print(\"\")   # new line at start\n            for pkg in packages:\n                ver = SBoGrep(pkg).version()\n                prgnam = \"{0}-{1}\".format(pkg, ver)\n                if find_package(prgnam, self.meta.output):\n                    binary = slack_package(prgnam)\n                    PackageManager(binary).upgrade(flag=\"--install-new\")\n                else:\n                    print(\"\\nPackage {0} not found in the {1} for \"\n                          \"installation\\n\".format(prgnam, self.meta.output))\n        else:\n            print(\"\\nPackages not found in the queue for installation\\n\")\n            raise SystemExit(1)", "response": "Install packages from queue\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of packages that can be upgraded from the repository.", "response": "def pkg_upgrade(repo, skip, flag):\n    \"\"\"Checking packages for upgrade\n    \"\"\"\n    Msg().checking()\n    PACKAGES_TXT = RepoInit(repo).fetch()[0]\n    pkgs_for_upgrade = []\n    # name = data[0]\n    # location = data[1]\n    # size = data[2]\n    # unsize = data[3]\n    data = repo_data(PACKAGES_TXT, repo, flag=\"\")\n    for pkg in installed():\n        status(0.0005)\n        inst_pkg = split_package(pkg)\n        for name in data[0]:\n            if name:    # this tips because some pkg_name is empty\n                repo_pkg = split_package(name[:-4])\n            if (repo_pkg[0] == inst_pkg[0] and\n                LooseVersion(repo_pkg[1]) > LooseVersion(inst_pkg[1]) and\n                repo_pkg[3] >= inst_pkg[3] and\n                    inst_pkg[0] not in skip and\n                    repo_pkg[1] != \"blacklist\"):\n                pkgs_for_upgrade.append(repo_pkg[0])\n    Msg().done()\n    if \"--checklist\" in flag:\n        pkgs_for_upgrade = choose_upg(pkgs_for_upgrade)\n    return pkgs_for_upgrade"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split_package(package):\n    name = ver = arch = build = []\n    split = package.split(\"-\")\n    if len(split) > 2:\n        build = split[-1]\n        build_a, build_b = \"\", \"\"\n        build_a = build[:1]\n        if build[1:2].isdigit():\n            build_b = build[1:2]\n        build = build_a + build_b\n        arch = split[-2]\n        ver = split[-3]\n        name = \"-\".join(split[:-3])\n    return [name, ver, arch, build]", "response": "Split package in name version arch and build tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving repositories from a list of default_repositories", "response": "def remove_repositories(repositories, default_repositories):\n    \"\"\"\n    Remove no default repositories\n    \"\"\"\n    repos = []\n    for repo in repositories:\n        if repo in default_repositories:\n            repos.append(repo)\n    return repos"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_repositories(repositories, conf_path):\n    repo_file = \"{0}custom-repositories\".format(conf_path)\n    if os.path.isfile(repo_file):\n        f = open(repo_file, \"r\")\n        repositories_list = f.read()\n        f.close()\n        for line in repositories_list.splitlines():\n            line = line.lstrip()\n            if line and not line.startswith(\"#\"):\n                repositories.append(line.split()[0])\n    return repositories", "response": "Update the list of user custom repositories"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grab_sub_repo(repositories, repos):\n    for i, repo in enumerate(repositories):\n        if repos in repo:\n            sub = repositories[i].replace(repos, \"\")\n            repositories[i] = repos\n            return sub\n    return \"\"", "response": "Grab a sub - repository from a list of repositories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngrab all packages name", "response": "def names(self):\n        \"\"\"Grab all packages name\n        \"\"\"\n        pkg_names = []\n        for line in self.SLACKBUILDS_TXT.splitlines():\n            if line.startswith(self.line_name):\n                pkg_names.append(line[17:].strip())\n        return pkg_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngrabs sources downloads links", "response": "def source(self):\n        \"\"\"Grab sources downloads links\n        \"\"\"\n        source, source64, = \"\", \"\"\n        for line in self.SLACKBUILDS_TXT.splitlines():\n            if line.startswith(self.line_name):\n                sbo_name = line[17:].strip()\n            if line.startswith(self.line_down):\n                if sbo_name == self.name and line[21:].strip():\n                    source = line[21:]\n            if line.startswith(self.line_down_64):\n                if sbo_name == self.name and line[28:].strip():\n                    source64 = line[28:]\n        return self._select_source_arch(source, source64)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nselect sources by arch", "response": "def _select_source_arch(self, source, source64):\n        \"\"\"Return sources by arch\n        \"\"\"\n        src = \"\"\n        if self.meta.arch == \"x86_64\":\n            if source64:\n                src = source64\n            else:\n                src = source\n            if self.meta.skip_unst in self.answer and source64 in self.unst:\n                src = source\n        else:\n            if source:\n                src = source\n            if self.meta.skip_unst in self.answer and source in self.unst:\n                src = source64\n        return src"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _select_md5sum_arch(self, md5sum, md5sum64):\n        if md5sum and md5sum64:\n            if self.meta.arch == \"x86_64\":\n                return md5sum64\n            else:\n                return md5sum\n        if md5sum:\n            return md5sum\n        else:\n            return md5sum64", "response": "Select checksums by arch"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if repositories exists by PACKAGES. TXT file", "response": "def check_exists_repositories(repo):\n    \"\"\"Checking if repositories exists by PACKAGES.TXT file\n    \"\"\"\n    pkg_list = \"PACKAGES.TXT\"\n    if repo == \"sbo\":\n        pkg_list = \"SLACKBUILDS.TXT\"\n    if check_for_local_repos(repo) is True:\n        pkg_list = \"PACKAGES.TXT\"\n        return \"\"\n    if not os.path.isfile(\"{0}{1}{2}\".format(\n            _meta_.lib_path, repo, \"_repo/{0}\".format(pkg_list))):\n        return repo\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if repository is local", "response": "def check_for_local_repos(repo):\n    \"\"\"Check if repository is local\n    \"\"\"\n    repos_dict = Repo().default_repository()\n    if repo in repos_dict:\n        repo_url = repos_dict[repo]\n        if repo_url.startswith(\"file:///\"):\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slack(self):\n        log = self.log_path + \"slack/\"\n        lib = self.lib_path + \"slack_repo/\"\n        repo_name = log[:-1].split(\"/\")[-1]\n        lib_file = \"PACKAGES.TXT\"\n        # lst_file = \"\"\n        md5_file = \"CHECKSUMS.md5\"\n        log_file = \"ChangeLog.txt\"\n        if not os.path.exists(log):\n            os.mkdir(log)\n        if not os.path.exists(lib):\n            os.mkdir(lib)\n        dirs = [\"core/\", \"extra/\", \"pasture/\", \"patches/\"]\n        for d in dirs:\n            if not os.path.exists(lib + d):\n                os.mkdir(lib + d)\n        PACKAGES_TXT = mirrors(lib_file, \"\")\n        FILELIST_TXT = \"\"\n        CHECKSUMS_MD5 = mirrors(md5_file, \"\")\n        self.EXTRA = mirrors(lib_file, dirs[1])\n        self.EXT_CHECKSUMS = mirrors(md5_file, dirs[1])\n        self.PASTURE = mirrors(lib_file, dirs[2])\n        self.PAS_CHECKSUMS = mirrors(md5_file, dirs[2])\n        self.PATCHES = mirrors(lib_file, dirs[3])\n        self.PAT_CHECKSUMS = mirrors(md5_file, dirs[3])\n        ChangeLog_txt = mirrors(log_file, \"\")\n        if self.check:\n            return self.checks_logs(log, ChangeLog_txt)\n        self.down(lib + dirs[0], PACKAGES_TXT, repo_name)\n        self.down(lib + dirs[0], CHECKSUMS_MD5, repo_name)\n        self.down(lib + dirs[1], self.EXTRA, repo_name)\n        self.down(lib + dirs[1], self.EXT_CHECKSUMS, repo_name)\n        if slack_ver() != \"14.0\":   # no pasture/ folder for 14.0 version\n            self.down(lib + dirs[2], self.PASTURE, repo_name)\n            self.down(lib + dirs[2], self.PAS_CHECKSUMS, repo_name)\n        self.down(lib + dirs[3], self.PATCHES, repo_name)\n        self.down(lib + dirs[3], self.PAT_CHECKSUMS, repo_name)\n        self.down(log, ChangeLog_txt, repo_name)\n        self.remote(log, ChangeLog_txt, lib, PACKAGES_TXT, CHECKSUMS_MD5,\n                    FILELIST_TXT, repo_name)\n        self.merge(lib, \"PACKAGES.TXT\", [\"core/PACKAGES.TXT\",\n                                         \"extra/PACKAGES.TXT\",\n                                         \"pasture/PACKAGES.TXT\",\n                                         \"patches/PACKAGES.TXT\"])\n        self.merge(lib, \"CHECKSUMS.md5\", [\"core/CHECKSUMS.md5\",\n                                          \"extra/CHECKSUMS.md5\",\n                                          \"pasture/CHECKSUMS.md5\",\n                                          \"patches/CHECKSUMS_md5\"])", "response": "Create slack local libraries and checks logs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conrad(self):\n        repo = self.def_repos_dict[\"conrad\"]\n        log = self.log_path + \"conrad/\"\n        lib = self.lib_path + \"conrad_repo/\"\n        repo_name = log[:-1].split(\"/\")[-1]\n        lib_file = \"PACKAGES.TXT\"\n        # lst_file = \"\"\n        md5_file = \"CHECKSUMS.md5\"\n        log_file = \"ChangeLog.txt\"\n        if not os.path.exists(log):\n            os.mkdir(log)\n        if not os.path.exists(lib):\n            os.mkdir(lib)\n        PACKAGES_TXT = \"{0}{1}\".format(repo, lib_file)\n        FILELIST_TXT = \"\"\n        CHECKSUMS_MD5 = \"{0}{1}\".format(repo, md5_file)\n        ChangeLog_txt = \"{0}{1}\".format(repo, log_file)\n        if self.check:\n            return self.checks_logs(log, ChangeLog_txt)\n        self.down(lib, PACKAGES_TXT, repo_name)\n        self.down(lib, CHECKSUMS_MD5, repo_name)\n        self.down(log, ChangeLog_txt, repo_name)\n        self.remote(log, ChangeLog_txt, lib, PACKAGES_TXT, CHECKSUMS_MD5,\n                    FILELIST_TXT, repo_name)", "response": "Create slackers local library and checks logs and remote library"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndown the file with the given link.", "response": "def down(self, path, link, repo):\n        \"\"\"Download files\n        \"\"\"\n        filename = link.split(\"/\")[-1]\n        if not os.path.isfile(path + filename):\n            Download(path, link.split(), repo).start()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remote(self, *args):\n        log_path = args[0]\n        ChangeLog_txt = args[1]\n        lib_path = args[2]\n        PACKAGES_TXT = args[3]\n        CHECKSUMS_MD5 = args[4]\n        FILELIST_TXT = args[5]\n        repo = args[6]\n\n        if self.checks_logs(log_path, ChangeLog_txt):\n            # remove old files\n            self.file_remove(log_path, ChangeLog_txt.split(\"/\")[-1])\n            self.file_remove(lib_path, PACKAGES_TXT.split(\"/\")[-1])\n            self.file_remove(lib_path, CHECKSUMS_MD5.split(\"/\")[-1])\n            self.file_remove(lib_path, FILELIST_TXT.split(\"/\")[-1])\n            if repo == \"slack\":\n                dirs = [\"core/\", \"extra/\", \"pasture/\"]\n                for d in dirs:\n                    self.file_remove(lib_path + d, \"PACKAGES.TXT\")\n                    self.file_remove(lib_path + d, \"CHECKSUMS.md5\")\n                self.down(lib_path + \"core/\", PACKAGES_TXT, repo)\n                self.down(lib_path + \"core/\", CHECKSUMS_MD5, repo)\n                self.down(lib_path + \"extra/\", self.EXTRA, repo)\n                self.down(lib_path + \"extra/\", self.EXT_CHECKSUMS, repo)\n                if slack_ver() != \"14.0\":  # no pasture/ folder for 14.0 version\n                    self.down(lib_path + \"pasture/\", self.PASTURE, repo)\n                    self.down(lib_path + \"pasture/\", self.PAS_CHECKSUMS, repo)\n            # download new files\n            if repo != \"slack\":\n                self.down(lib_path, PACKAGES_TXT, repo)\n                self.down(lib_path, CHECKSUMS_MD5, repo)\n            self.down(lib_path, FILELIST_TXT, repo)\n            self.down(log_path, ChangeLog_txt, repo)", "response": "Remove and recreate files\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge(self, path, outfile, infiles):\n        with open(path + outfile, 'w') as out_f:\n            for i in infiles:\n                if os.path.isfile(\"{0}{1}\".format(path, i)):\n                    with open(path + i, \"r\") as in_f:\n                        for line in in_f:\n                            out_f.write(line)", "response": "Merge the files in infiles into outfile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a file from the local file system", "response": "def file_remove(self, path, filename):\n        \"\"\"Check if filename exists and remove\n        \"\"\"\n        if os.path.isfile(path + filename):\n            os.remove(path + filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck ChangeLog. txt for changes", "response": "def checks_logs(self, log_path, url):\n        \"\"\"Checks ChangeLog.txt for changes\n        \"\"\"\n        local = \"\"\n        filename = url.split(\"/\")[-1]\n        server = FileSize(url).server()\n        if os.path.isfile(log_path + filename):\n            local = FileSize(log_path + filename).local()\n        if server != local:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upgrade(self, only):\n        repositories = self.meta.repositories\n        if only:\n            repositories = only\n        for repo in repositories:\n            changelogs = \"{0}{1}{2}\".format(self.log_path, repo,\n                                            \"/ChangeLog.txt\")\n            if os.path.isfile(changelogs):\n                os.remove(changelogs)\n            if os.path.isdir(self.lib_path + \"{0}_repo/\".format(repo)):\n                for f in (os.listdir(self.lib_path + \"{0}_repo/\".format(\n                        repo))):\n                    files = \"{0}{1}_repo/{2}\".format(self.lib_path, repo, f)\n                    if os.path.isfile(files):\n                        os.remove(files)\n                    elif os.path.isdir(files):\n                        shutil.rmtree(files)\n        Update().repository(only)", "response": "Remove all package lists with changelog and checksums files\n            and create lists again"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buildlist(self, enabled):\n        choice = []\n        for item in self.data:\n            choice.append((item, False))\n        for item in enabled:\n            choice.append((item, True))\n        items = [(tag, tag, sta) for (tag, sta) in choice]\n        code, self.tags = self.d.buildlist(\n            text=self.text, items=items, visit_items=True, item_help=False,\n            title=self.title)\n        if code == \"ok\":\n            self.unicode_to_string()\n            return self.ununicode\n        if code in [\"cancel\", \"esc\"]:\n            self.exit()", "response": "Build list of items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert unicode in string", "response": "def unicode_to_string(self):\n        \"\"\"Convert unicode in string\n        \"\"\"\n        for tag in self.tags:\n            self.ununicode.append(str(tag))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sbo_upgrade(skip, flag):\n    Msg().checking()\n    upgrade_names = []\n    data = SBoGrep(name=\"\").names()\n    blacklist = BlackList().packages(pkgs=data, repo=\"sbo\")\n    for pkg in sbo_list():\n        status(0.02)\n        name = split_package(pkg)[0]\n        ver = split_package(pkg)[1]\n        if (name in data and name not in skip and name not in blacklist):\n            sbo_package = (\"{0}-{1}\".format(name, SBoGrep(name).version()))\n            package = (\"{0}-{1}\".format(name, ver))\n            if LooseVersion(sbo_package) > LooseVersion(package):\n                upgrade_names.append(name)\n    Msg().done()\n    if \"--checklist\" in flag:\n        upgrade_names = choose_upg(upgrade_names)\n    return upgrade_names", "response": "Return packages for upgrade\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sbo_list():\n    sbo_packages = []\n    for pkg in os.listdir(_meta_.pkg_path):\n        if pkg.endswith(\"_SBo\"):\n            sbo_packages.append(pkg)\n    return sbo_packages", "response": "Return all SBo packages in the current language"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_package(path, packages):\n    if _meta_.del_all in [\"on\", \"ON\"]:\n        for pkg in packages:\n            os.remove(path + pkg)", "response": "Remove downloaded packages from the given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of packages and their sizes and last update date.", "response": "def repository_data(self, repo):\n        \"\"\"\n        Grap data packages\n        \"\"\"\n        sum_pkgs, size, unsize, last_upd = 0, [], [], \"\"\n        for line in (Utils().read_file(\n                self.meta.lib_path + repo + \"_repo/PACKAGES.TXT\").splitlines()):\n            if line.startswith(\"PACKAGES.TXT;\"):\n                last_upd = line[14:].strip()\n            if line.startswith(\"PACKAGE NAME:\"):\n                sum_pkgs += 1\n            if line.startswith(\"PACKAGE SIZE (compressed):  \"):\n                size.append(line[28:-2].strip())\n            if line.startswith(\"PACKAGE SIZE (uncompressed):  \"):\n                unsize.append(line[30:-2].strip())\n        if repo in [\"salix\", \"slackl\"]:\n            log = Utils().read_file(\n                self.meta.log_path + \"{0}/ChangeLog.txt\".format(repo))\n            last_upd = log.split(\"\\n\", 1)[0]\n        return [sum_pkgs, size, unsize, last_upd]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(build_folder):\n    if _meta_.del_build in [\"on\", \"ON\"] and os.path.exists(build_folder):\n        shutil.rmtree(build_folder)", "response": "Delete build folder and all its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        self.store()\n        self.msg.done()\n        if self.upgrade_all:\n            if \"--checklist\" in self.flag:\n                self.dialog_checklist()\n            print(\"\\nThese packages need upgrading:\\n\")\n            self.msg.template(78)\n            print(\"{0}{1}{2}{3}{4}{5}{6}{7}{8}{9}{10}\".format(\n                \"| Package\", \" \" * 17,\n                \"New Version\", \" \" * 8,\n                \"Arch\", \" \" * 4,\n                \"Build\", \" \" * 2,\n                \"Repos\", \" \" * 10,\n                \"Size\"))\n            self.msg.template(78)\n            print(\"Upgrading:\")\n            self.views()\n            unit, size = units(self.comp_sum, self.uncomp_sum)\n            print(\"\\nInstalling summary\")\n            print(\"=\" * 79)\n            print(\"{0}Total {1} {2} will be upgraded and {3} will be \"\n                  \"installed.\".format(self.meta.color[\"GREY\"],\n                                      self.count_upg,\n                                      self.msg.pkg(self.upgrade_all),\n                                      self.count_added))\n            print(\"Need to get {0} {1} of archives.\".format(size[0],\n                                                            unit[0]))\n            print(\"After this process, {0} {1} of additional disk space \"\n                  \"will be used.{2}\".format(size[1], unit[1],\n                                            self.meta.color[\"ENDC\"]))\n            print(\"\")\n            if self.msg.answer() in [\"y\", \"Y\"]:\n                Download(self.patch_path, self.dwn_links,\n                         repo=\"slack\").start()\n                self.upgrade_all = self.utils.check_downloaded(\n                    self.patch_path, self.upgrade_all)\n                self.upgrade()\n                self.kernel()\n                if self.meta.slackpkg_log in [\"on\", \"ON\"]:\n                    self.slackpkg_update()\n                self.msg.reference(self.installed, self.upgraded)\n                delete_package(self.patch_path, self.upgrade_all)\n                self.update_lists()\n        else:\n            slack_arch = \"\"\n            if self.meta.arch == \"x86_64\":\n                slack_arch = \"64\"\n            print(\"\\nSlackware{0} '{1}' v{2} distribution is up to \"\n                  \"date\\n\".format(slack_arch, self.version, slack_ver()))", "response": "Install new patches from official Slackware mirrors"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef store(self):\n        data = repo_data(self.PACKAGES_TXT, \"slack\", self.flag)\n        black = BlackList().packages(pkgs=data[0], repo=\"slack\")\n        for name, loc, comp, uncomp in zip(data[0], data[1], data[2], data[3]):\n            status(0.0003)\n            repo_pkg_name = split_package(name)[0]\n            if (not os.path.isfile(self.meta.pkg_path + name[:-4]) and\n                    repo_pkg_name not in black and\n                    repo_pkg_name not in self.skip):\n                self.dwn_links.append(\"{0}{1}/{2}\".format(mirrors(\"\", \"\"),\n                                                          loc, name))\n                self.comp_sum.append(comp)\n                self.uncomp_sum.append(uncomp)\n                self.upgrade_all.append(name)\n                self.count_upg += 1\n                if not find_package(repo_pkg_name + self.meta.sp,\n                                    self.meta.pkg_path):\n                    self.count_added += 1\n                    self.count_upg -= 1\n        return self.count_upg", "response": "Store and return packages for upgrading\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating checklist dialog to choose packages for upgrade", "response": "def dialog_checklist(self):\n        \"\"\"Create checklist to choose packages for upgrade\n        \"\"\"\n        data = []\n        for upg in self.upgrade_all:\n            data.append(upg[:-4])\n        text = \"Press 'spacebar' to unchoose packages from upgrade\"\n        title = \" Upgrade \"\n        backtitle = \"{0} {1}\".format(self.meta.__all__,\n                                     self.meta.__version__)\n        status = True\n        pkgs = DialogUtil(data, text, title, backtitle,\n                          status).checklist()\n        index = 0\n        for pkg, comp, uncomp in zip(self.upgrade_all, self.comp_sum,\n                                     self.uncomp_sum):\n            if pkg[:-4] not in pkgs:\n                self.dwn_links.pop(index)\n                self.upgrade_all.pop(index)\n                self.comp_sum.pop(index)\n                self.uncomp_sum.pop(index)\n                self.count_upg -= 1\n                del comp, uncomp\n                index -= 1\n            index += 1\n        if not self.upgrade_all:\n            raise SystemExit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef views(self):\n        for upg, size in sorted(zip(self.upgrade_all, self.comp_sum)):\n            pkg_repo = split_package(upg[:-4])\n            color = self.meta.color[\"RED\"]\n            pkg_inst = GetFromInstalled(pkg_repo[0]).name()\n            if pkg_repo[0] == pkg_inst:\n                color = self.meta.color[\"YELLOW\"]\n            ver = GetFromInstalled(pkg_repo[0]).version()\n            print(\"  {0}{1}{2}{3} {4}{5} {6}{7}{8}{9}{10}{11:>12}{12}\".format(\n                color, pkg_repo[0] + ver, self.meta.color[\"ENDC\"],\n                \" \" * (23-len(pkg_repo[0] + ver)), pkg_repo[1],\n                \" \" * (18-len(pkg_repo[1])), pkg_repo[2],\n                \" \" * (8-len(pkg_repo[2])), pkg_repo[3],\n                \" \" * (7-len(pkg_repo[3])), \"Slack\",\n                size, \" K\")).rstrip()", "response": "Displays the views of the packages that are available in the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupgrades packages in the archive.", "response": "def upgrade(self):\n        \"\"\"\n        Upgrade packages\n        \"\"\"\n        for pkg in self.upgrade_all:\n            check_md5(pkg_checksum(pkg, \"slack_patches\"), self.patch_path + pkg)\n            pkg_ver = \"{0}-{1}\".format(split_package(pkg)[0],\n                                       split_package(pkg)[1])\n            if find_package(split_package(pkg)[0] + self.meta.sp,\n                            self.meta.pkg_path):\n                print(\"[ {0}upgrading{1} ] --> {2}\".format(\n                    self.meta.color[\"YELLOW\"], self.meta.color[\"ENDC\"],\n                    pkg[:-4]))\n                PackageManager((self.patch_path + pkg).split()).upgrade(\n                    \"--install-new\")\n                self.upgraded.append(pkg_ver)\n            else:\n                print(\"[ {0}installing{1} ] --> {2}\".format(\n                    self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"],\n                    pkg[:-4]))\n                PackageManager((self.patch_path + pkg).split()).upgrade(\n                    \"--install-new\")\n                self.installed.append(pkg_ver)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kernel(self):\n        for core in self.upgrade_all:\n            if \"kernel\" in core:\n                if self.meta.default_answer in [\"y\", \"Y\"]:\n                    answer = self.meta.default_answer\n                else:\n                    print(\"\")\n                    self.msg.template(78)\n                    print(\"| {0}*** HIGHLY recommended reinstall 'LILO' \"\n                          \"***{1}\".format(self.meta.color[\"RED\"],\n                                          self.meta.color[\"ENDC\"]))\n                    self.msg.template(78)\n                    try:\n                        answer = raw_input(\"\\nThe kernel has been upgraded, \"\n                                           \"reinstall `LILO` [y/N]? \")\n                    except EOFError:\n                        print(\"\")\n                        raise SystemExit()\n                if answer in [\"y\", \"Y\"]:\n                    subprocess.call(\"lilo\", shell=True)\n                    break", "response": "Check if kernel has been upgraded and reinstall lilo if it has been upgraded"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slackpkg_update(self):\n        NEW_ChangeLog_txt = URL(mirrors(\"ChangeLog.txt\", \"\")).reading()\n        if os.path.isfile(self.meta.slackpkg_lib_path + \"ChangeLog.txt.old\"):\n            os.remove(self.meta.slackpkg_lib_path + \"ChangeLog.txt.old\")\n        if os.path.isfile(self.meta.slackpkg_lib_path + \"ChangeLog.txt\"):\n            shutil.copy2(self.meta.slackpkg_lib_path + \"ChangeLog.txt\",\n                         self.meta.slackpkg_lib_path + \"ChangeLog.txt.old\")\n            os.remove(self.meta.slackpkg_lib_path + \"ChangeLog.txt\")\n        with open(self.meta.slackpkg_lib_path + \"ChangeLog.txt\", \"w\") as log:\n            log.write(NEW_ChangeLog_txt)\n            log.close()", "response": "This method updates slackpkg ChangeLog. txt file with newVersion from Slackware official mirrors after update distribution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_lists(self):\n        print(\"{0}Update the package lists ?{1}\".format(\n            self.meta.color[\"GREEN\"], self.meta.color[\"ENDC\"]))\n        print(\"=\" * 79)\n        if self.msg.answer() in [\"y\", \"Y\"]:\n            Update().repository([\"slack\"])", "response": "Update packages list and ChangeLog. txt file after\n            upgrade distribution\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate checklist to choose packages for upgrade", "response": "def choose_upg(packages):\n    \"\"\"Create checklist to choose packages for upgrade\n    \"\"\"\n    selected_packages, data = [], []\n    if packages:\n        for pkg in packages:\n            name = GetFromInstalled(pkg).name()\n            ver = GetFromInstalled(pkg).version()\n            binary = \"{0}{1}\".format(name, ver)\n            installed = find_package(binary + _meta_.sp, _meta_.pkg_path)[0]\n            data.append(installed)\n        text = \"Press 'spacebar' to unchoose packages from upgrade\"\n        title = \" Upgrade \"\n        backtitle = \"{0} {1}\".format(_meta_.__all__, _meta_.__version__)\n        status = True\n        pkgs = DialogUtil(data, text, title, backtitle,\n                          status).checklist()\n        pkgs = [] if pkgs is None else pkgs\n        for pkg in pkgs:\n            name = split_package(pkg)[0]\n            if name in packages:\n                selected_packages.append(name)\n        if not selected_packages:\n            raise SystemExit()\n        print(\"\")\n    return selected_packages"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites headers to log file", "response": "def log_head(path, log_file, log_time):\n    \"\"\"\n    write headers to log file\n    \"\"\"\n    with open(path + log_file, \"w\") as log:\n        log.write(\"#\" * 79 + \"\\n\\n\")\n        log.write(\"File : \" + log_file + \"\\n\")\n        log.write(\"Path : \" + path + \"\\n\")\n        log.write(\"Date : \" + time.strftime(\"%d/%m/%Y\") + \"\\n\")\n        log.write(\"Time : \" + log_time + \"\\n\\n\")\n        log.write(\"#\" * 79 + \"\\n\\n\")\n        log.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends END tag to a log file", "response": "def log_end(path, log_file, sum_time):\n    \"\"\"\n    append END tag to a log file\n    \"\"\"\n    with open(path + log_file, \"a\") as log:\n        log.seek(2)\n        log.write(\"#\" * 79 + \"\\n\\n\")\n        log.write(\"Time : \" + time.strftime(\"%H:%M:%S\") + \"\\n\")\n        log.write(\"Total build time : {0}\\n\".format(sum_time))\n        log.write(\" \" * 38 + \"E N D\\n\\n\")\n        log.write(\"#\" * 79 + \"\\n\\n\")\n        log.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates build time per package", "response": "def build_time(start_time):\n    \"\"\"\n    Calculate build time per package\n    \"\"\"\n    diff_time = round(time.time() - start_time, 2)\n    if diff_time <= 59.99:\n        sum_time = str(diff_time) + \" Sec\"\n    elif diff_time > 59.99 and diff_time <= 3599.99:\n        sum_time = round(diff_time / 60, 2)\n        sum_time_list = re.findall(r\"\\d+\", str(sum_time))\n        sum_time = (\"{0} Min {1} Sec\".format(sum_time_list[0],\n                                             sum_time_list[1]))\n    elif diff_time > 3599.99:\n        sum_time = round(diff_time / 3600, 2)\n        sum_time_list = re.findall(r\"\\d+\", str(sum_time))\n        sum_time = (\"{0} Hours {1} Min\".format(sum_time_list[0],\n                                               sum_time_list[1]))\n    return sum_time"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild package from source and create log file in path /var / log / slpkg / sbo_build_logs.", "response": "def build(self):\n        \"\"\"\n        Build package from source and create log\n        file in path /var/log/slpkg/sbo/build_logs/.\n        Also check md5sum calculates.\n        \"\"\"\n        try:\n            self._delete_dir()\n            try:\n                tar = tarfile.open(self.script)\n            except Exception as err:\n                print err\n                raise SystemExit()\n            tar.extractall()\n            tar.close()\n            self._makeflags()\n            self._delete_sbo_tar_gz()\n            self._create_md5_dict()\n            if not self.auto:\n                os.chdir(self._SOURCES)\n            for src in self.sources:\n                if not os.path.isfile(src):\n                    continue\n                # fix build sources with spaces\n                src = src.replace(\"%20\", \" \")\n                check_md5(self.sbo_md5[src], src)\n                # copy source and fix passing char '+' from file name\n                shutil.copy2(src.replace(\"%2B\", \"+\"), self.path + self.prgnam)\n            os.chdir(self.path + self.prgnam)\n            # change permissions\n            subprocess.call(\"chmod +x {0}.SlackBuild\".format(self.prgnam),\n                            shell=True)\n            pass_var = self._pass_variable()\n            if self.meta.sbo_build_log in [\"on\", \"ON\"]:\n                if os.path.isfile(self.build_logs + self.log_file):\n                    os.remove(self.build_logs + self.log_file)\n                # start log write\n                log_head(self.build_logs, self.log_file, self.start_log_time)\n                subprocess.Popen(\"{0} ./{1}.SlackBuild 2>&1 | tee -a \"\n                                 \"{2}{3}\".format(\" \".join(pass_var),\n                                                 self.prgnam, self.build_logs,\n                                                 self.log_file), shell=True,\n                                 stdout=sys.stdout).communicate()\n                sum_time = build_time(self.start_time)\n                # write end in log file\n                log_end(self.build_logs, self.log_file, sum_time)\n                print(\"Total build time for the package {0} : {1}\\n\".format(\n                    self.prgnam, sum_time))\n            else:\n                subprocess.call(\"{0} ./{1}.SlackBuild\".format(\n                    \" \".join(pass_var), self.prgnam), shell=True)\n            os.chdir(self.path)\n        except KeyboardInterrupt:   # (OSError, IOError):\n            self.msg.pkg_not_found(\"\\n\", self.prgnam, \"Wrong file\", \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_md5_dict(self):\n        self.sbo_md5 = {}\n        md5_lists = SBoGrep(self.prgnam).checksum()\n        for src, md5 in zip(self.sources, md5_lists):\n            self.sbo_md5[src] = md5", "response": "Create md5 dictionary per source"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the variable MAKEFLAGS with the numbers of processors that are currently running", "response": "def _makeflags(self):\n        \"\"\"Set variable MAKEFLAGS with the numbers of\n        processors\n        \"\"\"\n        if self.meta.makeflags in [\"on\", \"ON\"]:\n            cpus = multiprocessing.cpu_count()\n            os.environ[\"MAKEFLAGS\"] = \"-j{0}\".format(cpus)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning enviroment variables that are passed to the user", "response": "def _pass_variable(self):\n        \"\"\"Return enviroment variables\n        \"\"\"\n        pass_var = []\n        for var in os.environ.keys():\n            expVAR = var.split(\"_\")\n            if expVAR[0] == self.prgnam.upper() and expVAR[1] != \"PATH\":\n                pass_var.append(\"{0}={1}\".format(expVAR[1], os.environ[var]))\n        return pass_var"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes slackbuild tar. gz file after untar", "response": "def _delete_sbo_tar_gz(self):\n        \"\"\"Delete slackbuild tar.gz file after untar\n        \"\"\"\n        if not self.auto and os.path.isfile(self.meta.build_path + self.script):\n            os.remove(self.meta.build_path + self.script)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting old folder if exists before start build", "response": "def _delete_dir(self):\n        \"\"\"Delete old folder if exists before start build\n        \"\"\"\n        if not self.auto and os.path.isdir(self.meta.build_path + self.prgnam):\n            shutil.rmtree(self.meta.build_path + self.prgnam)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_black(self):\n        blacklist = []\n        for read in self.black_conf.splitlines():\n            read = read.lstrip()\n            if not read.startswith(\"#\"):\n                blacklist.append(read.replace(\"\\n\", \"\"))\n        return blacklist", "response": "Return blacklist packages from the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, pkgs):\n        blacklist = self.get_black()\n        pkgs = set(pkgs)\n        print(\"\\nAdd packages in the blacklist:\\n\")\n        with open(self.blackfile, \"a\") as black_conf:\n            for pkg in pkgs:\n                if pkg not in blacklist:\n                    print(\"{0}{1}{2}\".format(self.meta.color[\"GREEN\"], pkg,\n                                             self.meta.color[\"ENDC\"]))\n                    black_conf.write(pkg + \"\\n\")\n                    self.quit = True\n            black_conf.close()\n        if self.quit:\n            print(\"\")", "response": "Add packages to the blacklist if not exist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, pkgs):\n        print(\"\\nRemove packages from the blacklist:\\n\")\n        with open(self.blackfile, \"w\") as remove:\n            for line in self.black_conf.splitlines():\n                if line not in pkgs:\n                    remove.write(line + \"\\n\")\n                else:\n                    print(\"{0}{1}{2}\".format(self.meta.color[\"RED\"], line,\n                                             self.meta.color[\"ENDC\"]))\n                    self.quit = True\n            remove.close()\n        if self.quit:\n            print(\"\")", "response": "Remove packages from blacklist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns packages in blacklist or by repository", "response": "def packages(self, pkgs, repo):\n        \"\"\"Return packages in blacklist or by repository\n        \"\"\"\n        self.black = []\n        for bl in self.get_black():\n            pr = bl.split(\":\")\n            for pkg in pkgs:\n                self.__priority(pr, repo, pkg)\n                self.__blackpkg(bl, repo, pkg)\n        return self.black"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __priority(self, pr, repo, pkg):\n        if (pr[0] == repo and pr[1].startswith(\"*\") and\n                pr[1].endswith(\"*\")):\n            if pr[1][1:-1] in pkg:\n                self.black.append(self.__add(repo, pkg))\n        elif pr[0] == repo and pr[1].endswith(\"*\"):\n            if pkg.startswith(pr[1][:-1]):\n                self.black.append(self.__add(repo, pkg))\n        elif pr[0] == repo and pr[1].startswith(\"*\"):\n            if pkg.endswith(pr[1][1:]):\n                self.black.append(self.__add(repo, pkg))\n        elif pr[0] == repo and \"*\" not in pr[1]:\n            self.black.append(self.__add(repo, pkg))", "response": "Add packages in blacklist by priority"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __blackpkg(self, bl, repo, pkg):\n        if bl.startswith(\"*\") and bl.endswith(\"*\"):\n            if bl[1:-1] in pkg:\n                self.black.append(self.__add(repo, pkg))\n        elif bl.endswith(\"*\"):\n            if pkg.startswith(bl[:-1]):\n                self.black.append(self.__add(repo, pkg))\n        elif bl.startswith(\"*\"):\n            if pkg.endswith(bl[1:]):\n                self.black.append(self.__add(repo, pkg))\n        if bl not in self.black and \"*\" not in bl:\n            self.black.append(bl)", "response": "Add packages in blacklist"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints package description by repository", "response": "def view(self):\n        \"\"\"Print package description by repository\n        \"\"\"\n        print(\"\")   # new line at start\n        description, count = \"\", 0\n        if self.repo == \"sbo\":\n            description = SBoGrep(self.name).description()\n        else:\n            PACKAGES_TXT = Utils().read_file(self.lib)\n            for line in PACKAGES_TXT.splitlines():\n                if line.startswith(self.name + \":\"):\n                    description += line[len(self.name) + 2:] + \"\\n\"\n                    count += 1\n                    if count == 11:\n                        break\n        if description:\n            print(\"{0}{1}{2}\".format(self.COLOR, description,\n                                     self.meta.color[\"ENDC\"]))\n        else:\n            self.msg.pkg_not_found(\"\", self.name, \"No matching\", \"\\n\")\n            raise SystemExit(1)\n        if description and self.repo == \"sbo\":\n            print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading files using wget or other downloader.", "response": "def start(self):\n        \"\"\"Download files using wget or other downloader.\n        Optional curl, aria2c and httpie\n        \"\"\"\n        dwn_count = 1\n        self._directory_prefix()\n        for dwn in self.url:\n            # get file name from url and fix passing char '+'\n            self.file_name = dwn.split(\"/\")[-1].replace(\"%2B\", \"+\")\n\n            if dwn.startswith(\"file:///\"):\n                source_dir = dwn[7:-7].replace(slack_ver(), \"\")\n                self._make_tarfile(self.file_name, source_dir)\n\n            self._check_certificate()\n            print(\"\\n[{0}/{1}][ {2}Download{3} ] --> {4}\\n\".format(\n                dwn_count, len(self.url), self.meta.color[\"GREEN\"],\n                self.meta.color[\"ENDC\"],\n                self.file_name))\n            if self.downder in [\"wget\"]:\n                subprocess.call(\"{0} {1} {2}{3} {4}\".format(\n                                self.downder, self.downder_options,\n                                self.dir_prefix, self.path, dwn),\n                                shell=True)\n            if self.downder in [\"aria2c\"]:\n                subprocess.call(\"{0} {1} {2}{3} {4}\".format(\n                                self.downder, self.downder_options,\n                                self.dir_prefix, self.path[:-1], dwn),\n                                shell=True)\n            elif self.downder in [\"curl\", \"http\"]:\n                subprocess.call(\"{0} {1} {2}{3} {4}\".format(\n                                self.downder, self.downder_options,\n                                self.path, self.file_name, dwn), shell=True)\n            self._check_if_downloaded()\n            dwn_count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_tarfile(self, output_filename, source_dir):\n        with tarfile.open(output_filename, \"w:gz\") as tar:\n            tar.add(source_dir, arcname=os.path.basename(source_dir))", "response": "Create a tar. gz file containing the current version of the user s data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _directory_prefix(self):\n        if self.downder == \"wget\":\n            self.dir_prefix = \"--directory-prefix=\"\n        elif self.downder == \"aria2c\":\n            self.dir_prefix = \"--dir=\"", "response": "Downloader options for specific directory_prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_if_downloaded(self):\n        if not os.path.isfile(self.path + self.file_name):\n            print(\"\")\n            self.msg.template(78)\n            print(\"| Download '{0}' file [ {1}FAILED{2} ]\".format(\n                self.file_name, self.meta.color[\"RED\"],\n                self.meta.color[\"ENDC\"]))\n            self.msg.template(78)\n            print(\"\")\n            if not self.msg.answer() in [\"y\", \"Y\"]:\n                raise SystemExit()", "response": "Check if file downloaded and raise SystemExit if not"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_certificate(self):\n        if (self.file_name.startswith(\"jdk-\") and self.repo == \"sbo\" and\n                self.downder == \"wget\"):\n            certificate = (' --no-check-certificate --header=\"Cookie: '\n                           'oraclelicense=accept-securebackup-cookie\"')\n            self.msg.template(78)\n            print(\"| '{0}' need to go ahead downloading\".format(\n                certificate[:23].strip()))\n            self.msg.template(78)\n            print(\"\")\n            self.downder_options += certificate\n            if not self.msg.answer() in [\"y\", \"Y\"]:\n                raise SystemExit()", "response": "Check for certificates options for wget"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef slack_package(prgnam):\n    binaries, cache, binary = [], \"0\", \"\"\n    for pkg in find_package(prgnam, _meta_.output):\n        if pkg.startswith(prgnam) and pkg[:-4].endswith(\"_SBo\"):\n            binaries.append(pkg)\n    for bins in binaries:\n        if LooseVersion(bins) > LooseVersion(cache):\n            binary = bins\n            cache = binary\n    if not binary:\n        Msg().build_FAILED(prgnam)\n        raise SystemExit(1)\n    return [\"\".join(_meta_.output + binary)]", "response": "Return maximum Slackware package from output directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef server(self):\n        try:\n            tar = urllib2.urlopen(self.registry)\n            meta = tar.info()\n            return int(meta.getheaders(\"Content-Length\")[0])\n        except (urllib2.URLError, IndexError):\n            return \" \"", "response": "Returns the size of remote files in the registry"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef units(comp_sum, uncomp_sum):\n    compressed = round((sum(map(float, comp_sum)) / 1024), 2)\n    uncompressed = round((sum(map(float, uncomp_sum)) / 1024), 2)\n    comp_unit = uncomp_unit = \"Mb\"\n    if compressed > 1024:\n        compressed = round((compressed / 1024), 2)\n        comp_unit = \"Gb\"\n    if uncompressed > 1024:\n        uncompressed = round((uncompressed / 1024), 2)\n        uncomp_unit = \"Gb\"\n    if compressed < 1:\n        compressed = sum(map(int, comp_sum))\n        comp_unit = \"Kb\"\n    if uncompressed < 1:\n        uncompressed = sum(map(int, uncomp_sum))\n        uncomp_unit = \"Kb\"\n    return [comp_unit, uncomp_unit], [compressed, uncompressed]", "response": "Calculate the units of the compressed and uncompressed files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart view build and install SBo packages", "response": "def start(self, is_upgrade):\n        \"\"\"Start view, build and install SBo packages\n        \"\"\"\n        tagc = \"\"\n        self.is_upgrade = is_upgrade\n        self.case_insensitive()\n        for _sbo in self.slackbuilds:\n            status(0.03)\n            if _sbo in self.data and _sbo not in self.blacklist:\n                sbo_deps = Requires(self.flag).sbo(_sbo)\n                self.deps += sbo_deps\n                self.deps_dict[_sbo] = self.one_for_all(sbo_deps)\n                self.package_found.append(_sbo)\n            else:\n                self.package_not_found.append(_sbo)\n        self.update_deps()\n\n        if not self.package_found:\n            self.match = True\n            self.matching()\n\n        self.master_packages, mas_src = self.sbo_version_source(\n            self.package_found)\n        self.msg.done()\n        if (self.meta.rsl_deps in [\"on\", \"ON\"] and\n                self.flag != \"--resolve-off\" and not self.match):\n            self.msg.resolving()\n        self.dependencies, dep_src = self.sbo_version_source(\n            self.one_for_all(self.deps))\n        if (self.meta.rsl_deps in [\"on\", \"ON\"] and\n                self.flag != \"--resolve-off\" and not self.match):\n            self.msg.done()\n        self.clear_masters()\n\n        if self.package_found:\n            if self.match and [\"\"] != self.slackbuilds:\n                self.msg.matching(self.slackbuilds)\n            else:\n                print(\"\\nThe following packages will be automatically \"\n                      \"installed or upgraded \\nwith new version:\\n\")\n            self.top_view()\n            self.msg.upg_inst(self.is_upgrade)\n\n            # view master packages\n            for sbo, arch in zip(self.master_packages, mas_src):\n                tagc = self.tag(sbo)\n                name = \"-\".join(sbo.split(\"-\")[:-1])\n                self.view_packages(tagc, name, sbo.split(\"-\")[-1],\n                                   self.select_arch(arch))\n            self.view_installing_for_deps()\n\n            # view dependencies\n            for dep, arch in zip(self.dependencies, dep_src):\n                tagc = self.tag(dep)\n                name = \"-\".join(dep.split(\"-\")[:-1])\n                self.view_packages(tagc, name, dep.split(\"-\")[-1],\n                                   self.select_arch(arch))\n\n            count_total = sum([self.count_ins, self.count_upg,\n                               self.count_uni])\n            if self.match and [\"\"] != self.slackbuilds:\n                print(\"\\nMatching summary\")\n                print(\"=\" * 79)\n                print(\"Total {0} matching packages\\n\".format(count_total))\n                raise SystemExit(1)\n            print(\"\\nInstalling summary\")\n            print(\"=\" * 79)\n            print(\"{0}Total {1} {2}.\".format(\n                self.meta.color[\"GREY\"], count_total,\n                self.msg.pkg(count_total)))\n            print(\"{0} {1} will be installed, {2} already installed and \"\n                  \"{3} {4}\".format(self.count_uni,\n                                   self.msg.pkg(self.count_uni),\n                                   self.count_ins, self.count_upg,\n                                   self.msg.pkg(self.count_upg)))\n            print(\"will be upgraded.{0}\\n\".format(self.meta.color[\"ENDC\"]))\n            self.continue_to_install()\n        else:\n            self.msg.not_found(self.is_upgrade)\n            raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_deps(self):\n        onelist, dependencies = [], []\n        onelist = Utils().dimensional_list(self.deps)\n        dependencies = Utils().remove_dbs(onelist)\n        for dep in dependencies:\n            deps = Requires(self.flag).sbo(dep)\n            self.deps_dict[dep] = self.one_for_all(deps)", "response": "Update dependencies dictionary with all package - level dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef continue_to_install(self):\n        if (self.count_uni > 0 or self.count_upg > 0 or\n                \"--download-only\" in self.flag or \"--rebuild\" in self.flag):\n            if self.master_packages and self.msg.answer() in [\"y\", \"Y\"]:\n                installs, upgraded = self.build_install()\n                if \"--download-only\" in self.flag:\n                    raise SystemExit()\n                self.msg.reference(installs, upgraded)\n                write_deps(self.deps_dict)\n                delete(self.build_folder)", "response": "Continue to install ?"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear master packages if already exist in dependencies or if added to install two or more times", "response": "def clear_masters(self):\n        \"\"\"Clear master slackbuilds if already exist in dependencies\n        or if added to install two or more times\n        \"\"\"\n        self.master_packages = Utils().remove_dbs(self.master_packages)\n        for mas in self.master_packages:\n            if mas in self.dependencies:\n                self.master_packages.remove(mas)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef matching(self):\n        for sbo in self.package_not_found:\n            for pkg in self.data:\n                if sbo in pkg and pkg not in self.blacklist:\n                    self.package_found.append(pkg)", "response": "Return found matching SBo packages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sbo_version_source(self, slackbuilds):\n        sbo_versions, sources = [], []\n        for sbo in slackbuilds:\n            status(0.02)\n            sbo_ver = \"{0}-{1}\".format(sbo, SBoGrep(sbo).version())\n            sbo_versions.append(sbo_ver)\n            sources.append(SBoGrep(sbo).source())\n        return [sbo_versions, sources]", "response": "Create sbo name with version and source"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef one_for_all(self, deps):\n        requires, dependencies = [], []\n        deps.reverse()\n        # Inverting the list brings the\n        # dependencies in order to be installed.\n        requires = Utils().dimensional_list(deps)\n        dependencies = Utils().remove_dbs(requires)\n        return dependencies", "response": "This method creates a list of lists that contains all the dependencies that depend on other\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef view_packages(self, *args):\n        ver = GetFromInstalled(args[1]).version()\n        print(\"  {0}{1}{2}{3} {4}{5} {6}{7}{8}{9}{10}{11:>11}{12}\".format(\n            args[0], args[1] + ver, self.meta.color[\"ENDC\"],\n            \" \" * (23-len(args[1] + ver)), args[2],\n            \" \" * (18-len(args[2])), args[3],\n            \" \" * (15-len(args[3])), \"\",\n            \"\", \"SBo\", \"\", \"\")).rstrip()", "response": "View slackbuild packages with version and arch\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntag with color green for packages to upgrade and color yellow for packages to upgrade and color red if package already installed and color red otherwise.", "response": "def tag(self, sbo):\n        \"\"\"Tag with color green if package already installed,\n        color yellow for packages to upgrade and color red\n        if not installed.\n        \"\"\"\n        # split sbo name with version and get name\n        sbo_name = \"-\".join(sbo.split(\"-\")[:-1])\n        find = GetFromInstalled(sbo_name).name()\n        if find_package(sbo, self.meta.pkg_path):\n            paint = self.meta.color[\"GREEN\"]\n            self.count_ins += 1\n            if \"--rebuild\" in self.flag:\n                self.count_upg += 1\n        elif sbo_name == find:\n            paint = self.meta.color[\"YELLOW\"]\n            self.count_upg += 1\n        else:\n            paint = self.meta.color[\"RED\"]\n            self.count_uni += 1\n        return paint"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlooks if sources unsupported or untested from arch else select arch.", "response": "def select_arch(self, src):\n        \"\"\"Looks if sources unsupported or untested\n        from arch else select arch.\n        \"\"\"\n        arch = self.arch\n        for item in self.unst:\n            if item in src:\n                arch = item\n        return arch"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning filenames from sources links", "response": "def filenames(self, sources):\n        \"\"\"Return filenames from sources links\n        \"\"\"\n        filename = []\n        for src in sources:\n            filename.append(src.split(\"/\")[-1])\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_install(self):\n        slackbuilds = self.dependencies + self.master_packages\n        installs, upgraded, = [], []\n        if not os.path.exists(self.build_folder):\n            os.makedirs(self.build_folder)\n        if not os.path.exists(self._SOURCES):\n            os.makedirs(self._SOURCES)\n        os.chdir(self.build_folder)\n        for prgnam in slackbuilds:\n            if (self.meta.not_downgrade == \"on\" and\n                    self.not_downgrade(prgnam) is True):\n                continue\n            pkg = \"-\".join(prgnam.split(\"-\")[:-1])\n            installed = \"\".join(find_package(prgnam, self.meta.pkg_path))\n            src_link = SBoGrep(pkg).source().split()\n            if (installed and \"--download-only\" not in self.flag and\n                    \"--rebuild\" not in self.flag):\n                self.msg.template(78)\n                self.msg.pkg_found(prgnam)\n                self.msg.template(78)\n            elif self.unst[0] in src_link or self.unst[1] in src_link:\n                self.msg.template(78)\n                print(\"| Package {0} {1}{2}{3}\".format(\n                    prgnam, self.meta.color[\"RED\"], \"\".join(src_link),\n                    self.meta.color[\"ENDC\"]))\n                self.msg.template(78)\n            else:\n                sbo_url = sbo_search_pkg(pkg)\n                sbo_link = SBoLink(sbo_url).tar_gz()\n                script = sbo_link.split(\"/\")[-1]\n                if self.meta.sbosrcarch in [\"on\", \"ON\"]:\n                    src_link = self.sbosrcarsh(prgnam, sbo_link, src_link)\n                Download(self.build_folder, sbo_link.split(),\n                         repo=\"sbo\").start()\n                Download(self._SOURCES, src_link, repo=\"sbo\").start()\n                if \"--download-only\" in self.flag:\n                    continue\n                sources = self.filenames(src_link)\n                BuildPackage(script, sources, self.build_folder,\n                             auto=False).build()\n                binary = slack_package(prgnam)\n                if os.path.isfile(\"\".join(binary)):\n                    if GetFromInstalled(pkg).name() == pkg:\n                        print(\"[ {0}Upgrading{1} ] --> {2}\".format(\n                            self.meta.color[\"YELLOW\"],\n                            self.meta.color[\"ENDC\"], prgnam))\n                        upgraded.append(prgnam)\n                    else:\n                        print(\"[ {0}Installing{1} ] --> {2}\".format(\n                            self.meta.color[\"GREEN\"],\n                            self.meta.color[\"ENDC\"], prgnam))\n                        installs.append(prgnam)\n                    if (\"--rebuild\" in self.flag and\n                            GetFromInstalled(pkg).name() == pkg):\n                        PackageManager(binary).upgrade(flag=\"--reinstall\")\n                    else:\n                        PackageManager(binary).upgrade(flag=\"--install-new\")\n        return installs, upgraded", "response": "Build and install packages if not already installed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndons t downgrade packages if sbo version is lower than installed", "response": "def not_downgrade(self, prgnam):\n        \"\"\"Don't downgrade packages if sbo version is lower than\n        installed\"\"\"\n        name = \"-\".join(prgnam.split(\"-\")[:-1])\n        sbo_ver = prgnam.split(\"-\")[-1]\n        ins_ver = GetFromInstalled(name).version()[1:]\n        if not ins_ver:\n            ins_ver = \"0\"\n        if LooseVersion(sbo_ver) < LooseVersion(ins_ver):\n            self.msg.template(78)\n            print(\"| Package {0} don't downgrade, \"\n                  \"setting by user\".format(name))\n            self.msg.template(78)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prog_version():\n    print(\"Version   : {0}\\n\"\n          \"Licence   : {1}\\n\"\n          \"Email     : {2}\\n\"\n          \"Maintainer: {3}\".format(_meta_.__version__,\n                                   _meta_.__license__,\n                                   _meta_.__email__,\n                                   _meta_.__maintainer__))", "response": "Print version license and email"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef binary(self, name, flag):\n        if self.meta.rsl_deps in [\"on\", \"ON\"] and \"--resolve-off\" not in flag:\n            sys.setrecursionlimit(10000)\n            dependencies = []\n            requires = Requires(name, self.repo).get_deps()\n            if requires:\n                for req in requires:\n                    status(0)\n                    if req and req not in self.black:\n                        dependencies.append(req)\n                if dependencies:\n                    self.dep_results.append(dependencies)\n                    for dep in dependencies:\n                        self.binary(dep, flag)\n            return self.dep_results\n        else:\n            return []", "response": "Build all dependencies of a package"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pkg_not_found(self, bol, pkg, message, eol):\n        print(\"{0}No such package {1}: {2}{3}\".format(bol, pkg, message, eol))", "response": "Print message when package not found"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints error message if build failed", "response": "def build_FAILED(self, prgnam):\n        \"\"\"Print error message if build failed\n        \"\"\"\n        self.template(78)\n        print(\"| Some error on the package {0} [ {1}FAILED{2} ]\".format(\n            prgnam, self.meta.color[\"RED\"], self.meta.color[\"ENDC\"]))\n        self.template(78)\n        print(\"| See the log file in '{0}/var/log/slpkg/sbo/build_logs{1}' \"\n              \"directory or read the README file\".format(\n                  self.meta.color[\"CYAN\"], self.meta.color[\"ENDC\"]))\n        self.template(78)\n        print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nask user to continue", "response": "def answer(self):\n        \"\"\"Message answer\n        \"\"\"\n        if self.meta.default_answer in [\"y\", \"Y\"]:\n            answer = self.meta.default_answer\n        else:\n            try:\n                answer = raw_input(\"Would you like to continue [y/N]? \")\n            except EOFError:\n                print(\"\")\n                raise SystemExit()\n        return answer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef security_pkg(self, pkg):\n        print(\"\")\n        self.template(78)\n        print(\"| {0}{1}*** WARNING ***{2}\").format(\n            \" \" * 27, self.meta.color[\"RED\"], self.meta.color[\"ENDC\"])\n        self.template(78)\n        print(\"| Before proceed with the package '{0}' will you must read\\n\"\n              \"| the README file. You can use the command \"\n              \"'slpkg -n {1}'\").format(pkg, pkg)\n        self.template(78)\n        print(\"\")", "response": "Warning message for some special reasons\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reference(self, install, upgrade):\n        self.template(78)\n        print(\"| Total {0} {1} installed and {2} {3} upgraded\".format(\n            len(install), self.pkg(len(install)),\n            len(upgrade), self.pkg(len(upgrade))))\n        self.template(78)\n        for installed, upgraded in itertools.izip_longest(install, upgrade):\n            if upgraded:\n                print(\"| Package {0} upgraded successfully\".format(upgraded))\n            if installed:\n                print(\"| Package {0} installed successfully\".format(installed))\n        self.template(78)\n        print(\"\")", "response": "Reference list with packages installed\n        and upgraded\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matching(self, packages):\n        print(\"\\nNot found package with the name [ {0}{1}{2} ]. \"\n              \"Matching packages:\\nNOTE: Not dependenc\"\n              \"ies are resolved\\n\".format(self.meta.color[\"CYAN\"],\n                                          \"\".join(packages),\n                                          self.meta.color[\"ENDC\"]))", "response": "Message for matching packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mirrors(name, location):\n    rel = _meta_.slack_rel\n    ver = slack_ver()\n    repo = Repo().slack()\n    if _meta_.arch == \"x86_64\":\n        if rel == \"stable\":\n            http = repo + \"slackware64-{0}/{1}{2}\".format(ver, location, name)\n        else:\n            http = repo + \"slackware64-{0}/{1}{2}\".format(rel, location, name)\n    elif _meta_.arch.startswith(\"arm\"):\n        if rel == \"stable\":\n            http = repo + \"slackwarearm-{0}/{1}{2}\".format(ver, location, name)\n        else:\n            http = repo + \"slackwarearm-{0}/{1}{2}\".format(rel, location, name)\n    else:\n        if rel == \"stable\":\n            http = repo + \"slackware-{0}/{1}{2}\".format(ver, location, name)\n        else:\n            http = repo + \"slackware-{0}/{1}{2}\".format(rel, location, name)\n    return http", "response": "Select Slackware official mirror packages\n    based architecture and version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchoosing repositories at the right side of the dialog.", "response": "def choose(self):\n        \"\"\"Choose repositories\n        \"\"\"\n        keys = \"\"\"\nChoose repositories at the right side for enable or to the\nleft side for disable.\n\nKeys: SPACE   select or deselect the highlighted repositories,\n             move it between the left and right lists\n          ^       move the focus to the left list\n          $       move the focus to the right list\n        TAB     move focus\n      ENTER   press the focused button\n\n      Disabled  <-------- REPOSITORIES ------->  Enabled\"\"\"\n        self.read_enabled()\n        self.read_disabled()\n        text, title, backtitle, status = keys, \" Repositories \", \"\", False\n        self.selected = DialogUtil(self.disabled, text, title, backtitle,\n                                   status).buildlist(self.enabled)\n        if self.selected is not None:\n            self.update_repos()\n        else:\n            self.selected = self.enabled\n        self.clear_screen()\n        self.reference()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for package path from SLACKBUILDS. TXT file and return url", "response": "def sbo_search_pkg(name):\n    \"\"\"Search for package path from SLACKBUILDS.TXT file and\n    return url\n    \"\"\"\n    repo = Repo().default_repository()[\"sbo\"]\n    sbo_url = \"{0}{1}/\".format(repo, slack_ver())\n    SLACKBUILDS_TXT = Utils().read_file(\n        _meta_.lib_path + \"sbo_repo/SLACKBUILDS.TXT\")\n    for line in SLACKBUILDS_TXT.splitlines():\n        if line.startswith(\"SLACKBUILD LOCATION\"):\n            sbo_name = (line[23:].split(\"/\")[-1].replace(\"\\n\", \"\")).strip()\n            if name == sbo_name:\n                return (sbo_url + line[23:].strip() + \"/\")\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef router_main(self):    \n        '''\n        Main method for router; we stay in a loop in this method, receiving\n        packets until the end of time.\n        '''\n        while True:\n            gotpkt = True\n            try:\n                timestamp,dev,pkt = self.net.recv_packet(timeout=1.0)\n            except NoPackets:\n                log_debug(\"No packets available in recv_packet\")\n                gotpkt = False\n            except Shutdown:\n                log_debug(\"Got shutdown signal\")\n                break\n\n            if gotpkt:\n                log_debug(\"Got a packet: {}\".format(str(pkt)))", "response": "Main method for router ; we loop through packets until the end of time."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds all Java source files within the given directory.", "response": "def find_source_files(input_path, excludes):\n    \"\"\" Get a list of filenames for all Java source files within the given\n    directory.\n\n    \"\"\"\n\n    java_files = []\n\n    input_path = os.path.normpath(os.path.abspath(input_path))\n\n    for dirpath, dirnames, filenames in os.walk(input_path):\n        if is_excluded(dirpath, excludes):\n            del dirnames[:]\n            continue\n\n        for filename in filenames:\n            if filename.endswith(\".java\"):\n                java_files.append(os.path.join(dirpath, filename))\n\n    return java_files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_bytes(rawbytes):\n        '''\n        Takes a byte string as a parameter and returns a list of\n        IPOption objects.\n        '''\n        ipopts = IPOptionList()\n\n        i = 0\n        while i < len(rawbytes):\n            opttype = rawbytes[i]\n            optcopied = opttype >> 7         # high order 1 bit\n            optclass = (opttype >> 5) & 0x03 # next 2 bits\n            optnum = opttype & 0x1f          # low-order 5 bits are optnum\n            optnum = IPOptionNumber(optnum)\n            obj = IPOptionClasses[optnum]()\n            eaten = obj.from_bytes(rawbytes[i:])\n            i += eaten\n            ipopts.append(obj)\n        return ipopts", "response": "Takes a byte string as a parameter and returns a list of IPOption objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a packed byte string of the IPOption objects in the format of a DNS record.", "response": "def to_bytes(self):\n        '''\n        Takes a list of IPOption objects and returns a packed byte string\n        of options, appropriately padded if necessary.\n        '''\n        raw = b''\n        if not self._options:\n            return raw\n        for ipopt in self._options:\n            raw += ipopt.to_bytes()\n        padbytes = 4 - (len(raw) % 4)\n        raw += b'\\x00'*padbytes\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the user code.", "response": "def _start_usercode(entryfunction, netobj, codeargdict):\n    '''\n    figure out how to correctly start the user code.  warn if\n    args are passed on the command line, but the code doesn't \n    accept them.\n    '''\n    # p22, python3 lang ref\n    numargs = entryfunction.__code__.co_argcount\n    takenet = numargs >= 1\n    takestarargs = entryfunction.__code__.co_flags & 0x04 == 0x04\n    takekw = entryfunction.__code__.co_flags & 0x08 == 0x08\n\n    args = codeargdict['args']\n    kwargs = codeargdict['kwargs']\n\n    if args and not takestarargs:\n        log_warn(\"User code arguments passed on command line, \"\n            \"but the user code doesn't take arguments\")\n    if kwargs and not takekw:\n        log_warn(\"User code keyword args passed on command line, \"\n            \"but the user code doesn't take kwargs\")\n\n    if not takenet:\n        raise RuntimeError(\"Your code does not appear to accept at \"\n            \"least one parameter for the net object\")\n\n    # omg, this sucks.\n    if takestarargs and takekw:\n        entryfunction(netobj, *args, **kwargs)\n    elif takestarargs:\n        entryfunction(netobj, *args)\n    elif takekw:\n        entryfunction(netobj, **kwargs)\n    else:\n        entryfunction(netobj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when an interface goes down.", "response": "def intf_down(self, interface):\n        '''\n        Can be called when an interface goes down.\n        FIXME: doesn't really do anything at this point.\n        '''\n        intf = self._devinfo.get(interface, None)\n        if intf and self._devupdown_callback:\n            self._devupdown_callback(intf, 'down')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when an interface is put in service.", "response": "def intf_up(self, interface):\n        '''\n        Can be called when an interface is put in service.\n        FIXME: not currently used; more needs to be done to\n        correctly put a new intf into service.\n        '''\n        if interface.name not in self._devinfo:\n            self._devinfo[interface.name] = interface\n            if self._devupdown_callback:\n                self._devupdown_callback(interface, 'up')\n        else:\n            raise ValueError(\"Interface already registered\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a device name return the corresponding interface object.", "response": "def interface_by_name(self, name):\n        '''\n        Given a device name, return the corresponding interface object\n        '''\n        if name in self._devinfo:\n            return self._devinfo[name]\n        raise KeyError(\"No device named {}\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an IP address return the interface that owns this address", "response": "def interface_by_ipaddr(self, ipaddr):\n        '''\n        Given an IP address, return the interface that 'owns' this address\n        '''\n        ipaddr = IPAddr(ipaddr)\n        for devname,iface in self._devinfo.items():\n            if iface.ipaddr == ipaddr:\n                return iface\n        raise KeyError(\"No device has IP address {}\".format(ipaddr))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a MAC address return the interface that owns this address", "response": "def interface_by_macaddr(self, macaddr):\n        '''\n        Given a MAC address, return the interface that 'owns' this address\n        '''\n        macaddr = EthAddr(macaddr)\n        for devname,iface in self._devinfo.items():\n            if iface.ethaddr == macaddr:\n                return iface\n        raise KeyError(\"No device has MAC address {}\".format(macaddr))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a byte string as a parameter and returns a list of ICMPv6Option objects.", "response": "def from_bytes(rawbytes):\n        '''\n        Takes a byte string as a parameter and returns a list of\n        ICMPv6Option objects.\n        '''\n        icmpv6popts = ICMPv6OptionList()\n\n        i = 0\n        while i < len(rawbytes):\n            opttype = rawbytes[i]\n            optnum = ICMPv6OptionNumber(opttype)\n            obj = ICMPv6OptionClasses[optnum]()\n            eaten = obj.from_bytes(rawbytes[i:])\n            i += eaten\n            icmpv6popts.append(obj)\n        return icmpv6popts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a packed byte string of ICMPv6Option objects.", "response": "def to_bytes(self):\n        '''\n        Takes a list of ICMPv6Option objects and returns a packed byte string\n        of options, appropriately padded if necessary.\n        '''\n        raw = b''\n        if not self._options:\n            return raw\n        for icmpv6popt in self._options:\n            raw += icmpv6popt.to_bytes()\n        # Padding doesn't seem necessary?\n        #   RFC states it should be padded to 'natural 64bit boundaries'\n        #   However, wireshark interprets \\x00 as a malformed option field\n        #   So for now, ignore padding\n        # padbytes = 4 - (len(raw) % 4)\n        # raw += b'\\x00'*padbytes\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef humanize_bandwidth(bits):\n    '''\n    Accept some number of bits/sec (i.e., a link capacity) as an\n    integer, and return a string representing a 'human'(-like)\n    representation of the capacity, e.g., 10 Mb/s, 1.5 Mb/s,\n    900 Gb/s.\n\n    As is the standard in networking, capacity values are assumed\n    to be base-10 values (not base 2), so 1000 is 1 Kb/s.\n    '''\n    unit = ''\n    divisor = 1\n    if bits < 1000:\n        unit = 'bits'\n        divisor = 1\n    elif bits < 1000000:\n        unit = 'Kb'\n        divisor = 1000\n    elif bits < 1000000000:\n        unit = 'Mb'\n        divisor = 1000000\n    elif bits < 1000000000000:\n        unit = 'Gb'\n        divisor = 1000000000\n    elif bits < 1000000000000000:\n        unit = 'Tb'\n        divisor = 1000000000000\n    else:\n        raise Exception(\"Can't humanize that many bits.\")\n\n    if bits % divisor == 0:\n        value = int(bits/divisor)\n    else:\n        value = bits/divisor\n\n    return \"{} {}/s\".format(value, unit)", "response": "Return a human - readable string representing the bandwidth of the link capacity."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unhumanize_bandwidth(bitsstr):\n    '''\n    Take a string representing a link capacity, e.g., 10 Mb/s, and\n    return an integer representing the number of bits/sec.\n    Recognizes:\n        - 'bits/sec' or 'b/s' are treated as plain bits per second\n        - 'Kb' or 'kb' as thousand bits/sec\n        - 'Mb' or 'mb' as million bits/sec\n        - 'Gb' or 'gb' as billion bits/sec\n        - 'Tb' or 'tb' as trillion bits/sec\n        - if second character is 'B', quantity is interpreted as bytes/sec\n        - any subsequent characters after the first two are ignored, so\n          Kb/s Kb/sec Kbps are interpreted identically.\n\n    Returns None if the string doesn't contain anything parseable.\n    '''\n    if isinstance(bitsstr, int):\n        return bitsstr\n\n    mobj = re.match('^\\s*([\\d\\.]+)\\s*(.*)\\s*$', bitsstr)\n    if not mobj:\n        return None\n    value, units = mobj.groups()\n    value = float(value)\n    multipliers = { 'b':1, 'k':1e3, 'm':1e6, 'g':1e9, 't':1e12 }\n    if not units:\n        units = 'bits'\n    mult = multipliers.get(units[0].lower(), 0)\n    bits = 1\n    if len(units) > 1:\n        if units[1] == 'B': bits = 8\n    # print (bitsstr, value, mult, bits)\n    return int(value * mult * bits)", "response": "Takes a string representing a link capacity and returns an integer representing the number of bits per link capacity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef humanize_delay(delay):\n    '''\n    Accept a floating point number presenting link propagation delay\n    in seconds (e.g., 0.1 for 100 milliseconds delay), and return\n    a human(-like) string like '100 milliseconds'.  Handles values as \n    small as 1 microsecond, but no smaller.\n\n    Because of imprecision in floating point numbers, a relatively easy\n    way to handle this is to convert to string, then slice out sections.\n    '''\n    delaystr = '{:1.06f}'.format(delay) \n    decimal = delaystr.find('.') \n    seconds = int(delaystr[:decimal])\n    millis = int(delaystr[-6:-3])\n    micros = int(delaystr[-3:])\n    # print (delay,delaystr,seconds,millis,micros)\n    units = ''\n    microsecs = micros + 1e3 * millis + 1e6 * seconds\n    if micros > 0:\n        units = ' \\u00B5sec'\n        value = int(microsecs)\n    elif millis > 0:\n        units = ' msec'\n        value = int(microsecs / 1000)\n    elif seconds > 0:\n        units = ' sec'\n        value = int(microsecs / 1000000)\n    else:\n        units = ' sec'\n        value = delay\n    if value > 1:\n        units += 's'\n    return '{}{}'.format(value, units)", "response": "Return a human - readable string of the delay."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\naccepting a string representing link propagation delay (e.g., '100 milliseconds' or '100 msec' or 100 millisec') and return a floating point number representing the delay in seconds. Recognizes: - us, usec, micros* all as microseconds - ms, msec, millisec* all as milliseconds - s, sec* as seconds returns None on parse failure.", "response": "def unhumanize_delay(delaystr):\n    '''\n    Accept a string representing link propagation delay (e.g., \n    '100 milliseconds' or '100 msec' or 100 millisec') and return\n    a floating point number representing the delay in seconds.\n    Recognizes:\n        - us, usec, micros* all as microseconds\n        - ms, msec, millisec* all as milliseconds\n        - s, sec* as seconds\n\n    returns None on parse failure.\n    '''\n    if isinstance(delaystr, float):\n        return delaystr\n\n    mobj = re.match('^\\s*([\\d\\.]+)\\s*(\\w*)', delaystr)\n    if not mobj:\n        return None\n    value, units = mobj.groups()\n    value = float(value)\n    if not units:\n        divisor = 1.0\n    elif units == 'us' or units == 'usec' or units.startswith('micros'):\n        divisor = 1e6\n    elif units == 'ms' or units == 'msec' or units.startswith('millis'):\n        divisor = 1e3\n    elif units == 's' or units.startswith('sec'):\n        divisor = 1.0\n    else:\n        return None\n    return value / divisor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive an integer bitmap and an enumerated type build a set that includes zero or more enumerated types corresponding to the bitmap.", "response": "def _unpack_bitmap(bitmap, xenum):\n    '''\n    Given an integer bitmap and an enumerated type, build\n    a set that includes zero or more enumerated type values\n    corresponding to the bitmap.\n    '''\n    unpacked = set()\n    for enval in xenum:\n        if enval.value & bitmap == enval.value:\n            unpacked.add(enval)\n    return unpacked"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a dictionary that maps an attribute name in OpenflowMatch with a non - prefix related wildcard bit from the OpenflowWildcard enumeration.", "response": "def _make_wildcard_attr_map():\n    '''\n    Create a dictionary that maps an attribute name\n    in OpenflowMatch with a non-prefix-related wildcard\n    bit from the above OpenflowWildcard enumeration.\n    '''\n    _xmap = {}\n    for wc in OpenflowWildcard:\n        if not wc.name.endswith('All') and \\\n            not wc.name.endswith('Mask'):\n            translated = ''\n            for ch in wc.name:\n                if ch.isupper():\n                    translated += '_' \n                    translated += ch.lower()\n                else:\n                    translated += ch\n            _xmap[translated] = wc\n    return _xmap"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _unpack_actions(raw):\n    '''\n    deserialize 1 or more actions; return a list of\n    Action* objects\n    '''\n    actions = []\n\n    while len(raw) > 0:\n        atype, alen = struct.unpack('!HH', raw[:4])\n        atype = OpenflowActionType(atype)\n        action = _ActionClassMap.get(atype)()\n        action.from_bytes(raw[:alen])\n        raw = raw[alen:]\n        actions.append(action)\n    return actions", "response": "deserialize 1 or more actions ; return a list of\n    Action* objects\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if this packet overlaps with another packet.", "response": "def overlaps_with(self, othermatch, strict=False):\n        '''\n        Two match objects overlap if the same packet can be matched \n        by both *and* they have the same priority.\n        '''\n        one = self.matches_entry(othermatch, strict)\n        if strict:\n            return one\n        return one and othermatch.matches_entry(self, strict)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if this match object matches another match object.", "response": "def matches_entry(self, othermatch, strict=False):\n        '''\n        Return True if this match object matches another\n        match object (e.g., a flow table entry).\n\n        NB: from OF 1.0 spec:\n        A match occurs \"when a flow entry exactly matches\n        or is more specific than one\" [in a flow_mod command]\n        (likely to be self in this case).\n        '''\n        if strict:\n            return self == othermatch\n\n        attrs = set(self.__slots__)\n        attrs.discard('_wildcards')\n        attrs.discard('_nw_src_wildcard')\n        attrs.discard('_nw_dst_wildcard')\n        matchtest = []\n        for a in attrs:\n            curr = getattr(self, a)\n            other = getattr(othermatch, a)\n\n            if a == '_nw_src' or a == '_nw_dst':\n                # FIXME: clean this up\n                wattr = \"{}_wildcard\".format(a)\n                otherbits = 32 - getattr(othermatch, wattr)\n                othernet = ip_network(\"{}/{}\".format(getattr(othermatch, a), otherbits), strict=False)\n                iswildcarded = curr in othernet\n            else:\n                wc = _wildcard_attr_map[a].name\n                iswildcarded = wc in othermatch.wildcards\n\n            matchtest.append(iswildcarded or curr == other)\n        return all(matchtest)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the given packet matches this match object.", "response": "def matches_packet(self, pkt):\n        '''\n        Return True if the given packet matches this match object.\n        '''\n        match = []\n        wildbits = _make_bitmap(self._wildcards)\n        for mf,pkttuple in OpenflowMatch._match_field_to_packet.items():\n            mf = \"_{}\".format(mf)\n\n            # if the attribute is a network address, respect the bits\n            if mf == '_nw_src' or mf == '_nw_dst':\n                # FIXME: clean me up.  lots of dup w/above and below :(\n                wattr = \"{}_wildcard\".format(mf)\n                bits = 32 - getattr(self, wattr)\n                if bits < 32:\n                    netaddr = ip_network(\"{}/{}\".format(getattr(self, mf), bits), strict=False)\n                    for pktcls,field in pkttuple: \n                        if pkt.has_header(pktcls):\n                            match.append(getattr(pkt[pktcls], field) in netaddr)\n                    continue\n\n            # if attribute is simple wildcard, just ignore the attr\n            elif _wildcard_attr_map[mf].value & wildbits:\n                continue\n\n            # compare concrete values in packet with match object value\n            for pktcls,field in pkttuple:\n                if pkt.has_header(pktcls):\n                    match.append(getattr(pkt[pktcls], field) == getattr(self, mf))\n        return all(match)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_from_packet(pkt):\n        '''\n        Build and return a new OpenflowMatch object based on the\n        packet object passed as a parameter.\n        '''\n        m = OpenflowMatch()\n        for mf,pkttuple in OpenflowMatch._match_field_to_packet.items():\n            for pktcls,field in pkttuple:\n                if pkt.has_header(pktcls):\n                    setattr(m, mf, getattr(pkt[pktcls], field))\n                    continue\n        return m", "response": "Build and return a new OpenflowMatch object based on the passed packet object passed as a parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the length of the header based on the passed in data.", "response": "def pre_serialize(self, raw, pkt, i):\n        '''\n        Set length of the header based on\n        '''\n        self.length = len(raw) + OpenflowHeader._MINLEN"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discoverdevs(self):\n        '''\n        Find all the pcap-eligible devices on the local system.\n        '''\n        if len(self._interfaces):\n            raise PcapException(\"Device discovery should only be done once.\")\n            \n        ppintf = self._ffi.new(\"pcap_if_t * *\")\n        errbuf = self._ffi.new(\"char []\", 128)\n        rv = self._libpcap.pcap_findalldevs(ppintf, errbuf)\n        if rv:\n            raise PcapException(\"pcap_findalldevs returned failure: {}\".format(self._ffi.string(errbuf)))\n        pintf = ppintf[0]\n        tmp = pintf\n        pindex = 0\n        while tmp != self._ffi.NULL:\n            xname = self._ffi.string(tmp.name) # \"internal name\"; still stored as bytes object\n            xname = xname.decode('ascii', 'ignore')\n\n            if self._windoze:\n                ext_name = \"port{}\".format(pindex)\n            else:\n                ext_name = xname\n            pindex += 1\n\n            if tmp.description == self._ffi.NULL:\n                xdesc = ext_name\n            else:\n                xdesc = self._ffi.string(tmp.description)\n                xdesc = xdesc.decode('ascii', 'ignore')\n\n            # NB: on WinPcap, only loop flag is set\n            isloop = (tmp.flags & 0x1) == 0x1\n            isup = (tmp.flags & 0x2) == 0x2\n            isrunning = (tmp.flags & 0x4) == 0x4\n\n            # JS: I've observed that the isup and isrunning flags\n            # are patently false on some systems.  As a result, we\n            # blindly include all interfaces, regardless of their\n            # reported status (though we still include status flags\n            # in the interface object).\n            # if isup and isrunning:\n            xif = PcapInterface(ext_name, xname, xdesc, isloop, isup, isrunning)\n            self._interfaces.append(xif)\n\n            tmp = tmp.next\n        self._libpcap.pcap_freealldevs(pintf)", "response": "Find all the pcap - eligible devices on the local system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_bpf_filter_on_all_devices(filterstr):\n        '''\n        Long method name, but self-explanatory.  Set the bpf\n        filter on all devices that have been opened.\n        '''\n        with PcapLiveDevice._lock:\n            for dev in PcapLiveDevice._OpenDevices.values():\n                _PcapFfi.instance()._set_filter(dev, filterstr)", "response": "Set the bpf\n        filter on all devices opened by this process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_ip_arp_reply(srchw, dsthw, srcip, targetip):\n    '''\n    Create an ARP reply (just change what needs to be changed\n    from a request)\n    '''\n    pkt = create_ip_arp_request(srchw, srcip, targetip)\n    pkt[0].dst = dsthw\n    pkt[1].operation = ArpOperation.Reply\n    pkt[1].targethwaddr = dsthw\n    return pkt", "response": "Create an ARP reply packet"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and return a packet containing an Ethernet header and ARP header.", "response": "def create_ip_arp_request(srchw, srcip, targetip):\n    '''\n    Create and return a packet containing an Ethernet header\n    and ARP header.\n    '''\n    ether = Ethernet()\n    ether.src = srchw\n    ether.dst = SpecialEthAddr.ETHER_BROADCAST.value\n    ether.ethertype = EtherType.ARP\n    arp = Arp()\n    arp.operation = ArpOperation.Request\n    arp.senderhwaddr = srchw\n    arp.senderprotoaddr = srcip\n    arp.targethwaddr = SpecialEthAddr.ETHER_BROADCAST.value\n    arp.targetprotoaddr = targetip\n    return ether + arp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main_real(usercode, netobj, options):\n    '''\n    Entrypoint function for non-test (\"real\") mode.  At this point\n    we assume that we are running as root and have pcap module.\n    '''\n    usercode_entry_point = import_or_die(usercode, ('main', 'switchy_main'))\n    if options.dryrun:\n        log_info(\"Imported your code successfully.  Exiting dry run.\")\n        netobj.shutdown()\n        return\n\n    try:\n        _start_usercode(usercode_entry_point, netobj, options.codearg)\n    except Exception as e:\n        import traceback\n\n        log_failure(\"Exception while running your code: {}\".format(e))\n        message = '''{0}\n\nThis is the Switchyard equivalent of the blue screen of death.\nHere (repeating what's above) is the failure that occurred:\n'''.format('*'*60, textwrap.fill(str(e), 60))\n        with red():\n            print(message)\n            traceback.print_exc(1)\n            print('*'*60)\n\n        if options.nohandle:\n            raise \n            \n        if not options.nopdb:\n            print('''\nI'm throwing you into the Python debugger (pdb) at the point of failure.\nIf you don't want pdb, use the --nopdb flag to avoid this fate.\n''')\n            import pdb\n            pdb.post_mortem()\n    else:\n        netobj.shutdown()", "response": "Main entrypoint function for non - test mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shutdown(self):\n        '''\n        Should be called by Switchyard user code when a network object is\n        being shut down.  (This method cleans up internal threads and network\n        interaction objects.)\n        '''\n        if not LLNetReal.running:\n            return\n\n        LLNetReal.running = False\n        log_debug(\"Joining threads for shutdown\")\n        for t in self._threads:\n            t.join()\n        log_debug(\"Closing pcap devices\")\n        for devname,pdev in self._pcaps.items():\n            pdev.close()\n        for rdev in self._localsend.values():\n            rdev.close()\n        log_debug(\"Done cleaning up\")", "response": "Shut down all threads and local send and pcap devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _assemble_devinfo(self):\n        '''\n        Internal method.  Assemble information on each interface/\n        device that we know about, i.e., its MAC address and configured\n        IP address and prefix.\n        '''\n        devtype = {}\n        for p in pcap_devices():\n            if p.isloop:\n                devtype[p.name] = InterfaceType.Loopback\n            else:\n                if sys.platform == 'linux':\n                    st,output = subprocess.getstatusoutput([\"iwconfig\", p.name])\n                    if \"no wireless extensions\" in output:\n                        devtype[p.name] = InterfaceType.Wired\n                    else:\n                        devtype[p.name] = InterfaceType.Wireless\n                elif sys.platform == 'darwin':\n                    devtype[p.name] = InterfaceType.Unknown\n                else:\n                    devtype[p.name] = InterfaceType.Unknown\n\n        devinfo = {}\n        ifinfo = net_if_addrs()\n        for devname in self._devs:\n            ifaddrs = ifinfo.get(devname, None)\n            if ifaddrs is None:\n                log_warn(\"Address info for interface {} not found! (skipping)\".format(devname))\n\n            if sys.platform == 'darwin':\n                layer2addrfam = socket.AddressFamily.AF_LINK\n            elif sys.platform == 'linux':\n                layer2addrfam = socket.AddressFamily.AF_PACKET\n            else:\n                raise RuntimeException(\"Platform not supported\")\n\n            macaddr = \"00:00:00:00:00:00\"\n            ipaddr = mask = \"0.0.0.0\"\n            for addrinfo in ifaddrs:\n                if addrinfo.family == socket.AddressFamily.AF_INET:\n                    ipaddr = IPv4Address(addrinfo.address)\n                    mask = IPv4Address(addrinfo.netmask)\n                elif addrinfo.family == layer2addrfam:\n                    macaddr = EthAddr(addrinfo.address)\n\n            ifnum = socket.if_nametoindex(devname)\n            devinfo[devname] = Interface(devname, macaddr, ipaddr, netmask=mask, ifnum=ifnum, iftype=devtype[devname])\n        return devinfo", "response": "Assemble information on each device that we know about."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_pcaps(self):\n        '''\n        Internal method.  Create libpcap devices\n        for every network interface we care about and\n        set them in non-blocking mode.\n        '''\n        self._pcaps = {}\n        for devname,intf in self._devinfo.items():\n            if intf.iftype == InterfaceType.Loopback:\n                senddev = _RawSocket(devname, protocol=IPProtocol.UDP)\n                self._localsend[devname] = senddev\n            pdev = PcapLiveDevice(devname) \n            self._pcaps[devname] = pdev", "response": "Internal method. Create libpcap devices\n        for every network interface we care about and set them in non - blocking mode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sig_handler(self, signum, stack):\n        '''\n        Handle process INT signal.\n        '''\n        log_debug(\"Got SIGINT.\")\n        if signum == signal.SIGINT:\n            LLNetReal.running = False\n            if self._pktqueue.qsize() == 0:\n                # put dummy pkt in queue to unblock a \n                # possibly stuck user thread\n                self._pktqueue.put( (None,None,None) )", "response": "Handle process INT signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nthreads entrypoint for doing low-level receive and dispatch for a single pcap device.", "response": "def _low_level_dispatch(pcapdev, devname, pktqueue):\n        '''\n        Thread entrypoint for doing low-level receive and dispatch\n        for a single pcap device.\n        '''\n        while LLNetReal.running:\n            # a non-zero timeout value is ok here; this is an\n            # independent thread that handles input for this\n            # one pcap device.  it throws any packets received\n            # into the shared queue (which is read by the actual\n            # user code)\n            pktinfo = pcapdev.recv_packet(timeout=0.2)\n            if pktinfo is None:\n                continue\n            pktqueue.put( (devname,pcapdev.dlt,pktinfo) )\n\n        log_debug(\"Receiver thread for {} exiting\".format(devname))\n        stats = pcapdev.stats()\n        log_debug(\"Final device statistics {}: {} received, {} dropped, {} dropped/if\".format(devname, stats.ps_recv, stats.ps_drop, stats.ps_ifdrop))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreceive a packet from any device on which one is available.", "response": "def recv_packet(self, timeout=None):\n        '''\n        Receive packets from any device on which one is available.\n        Blocks until it receives a packet, unless a timeout value >=0\n        is given.  Raises Shutdown exception when device(s) are shut \n        down (i.e., on a SIGINT to the process).  Raises NoPackets when \n        there are no packets that can be read.\n\n        Returns a ReceivedPacket named tuple (timestamp, input_port, packet)\n        '''\n        while True:\n            try:\n                dev,dlt,pktinfo = self._pktqueue.get(timeout=timeout)\n                if not LLNetReal.running:\n                    break\n\n                decoder = _dlt_to_decoder.get(dlt, None)\n                if decoder is None:\n                    log_warn(\"Received packet with unparseable encapsulation {}\".format(dlt))\n                    continue\n\n                pkt = decoder(pktinfo.raw) \n                return ReceivedPacket(timestamp=pktinfo.timestamp, \n                    input_port=dev, packet=pkt)\n            except Empty:\n                if not LLNetReal.running:\n                    raise Shutdown()\n                raise NoPackets()\n        raise Shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_packet(self, dev, packet):\n        '''\n        Send a Switchyard Packet object on the given device \n        (string name of device).\n\n        Raises ValueError if packet object isn't valid, or device\n        name isn't recognized.\n        '''\n        if packet is None:\n            raise ValueError(\"No packet object given to send_packet\")\n        if not isinstance(packet, Packet):\n            raise ValueError(\"Object given to send_packet is not a Packet (it is: {})\".format(type(packet)))\n \n        intf = None\n        if isinstance(dev, int):\n           dev = self._lookup_devname(dev)\n\n        if isinstance(dev, Interface):\n            intf = dev\n            dev = dev.name\n        elif dev in self._devinfo:\n            intf = self.interface_by_name(dev)\n        else:\n            raise ValueError(\"Unrecognized device name for packet send: {}\".format(dev))\n\n        if intf.iftype == InterfaceType.Loopback:\n            pdev = self._localsend.get(dev, None)\n            pdev.send_packet(packet)\n        else:\n            pdev = self._pcaps.get(dev, None)\n            rawpkt = packet.to_bytes()\n            log_debug(\"Sending packet on device {}: {}\".format(dev, str(packet)))\n            pdev.send_packet(rawpkt)", "response": "Send a Packet object on the given device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __default_filter(self, node):\n\n        if not isinstance(node, javalang.tree.Declaration):\n            return False\n\n        if 'private' in node.modifiers:\n            return False\n\n        if isinstance(node, javalang.tree.Documented) and node.documentation:\n            doc = javalang.javadoc.parse(node.documentation)\n            if 'hide' in doc.tags or 'exclude' in doc.tags:\n                return False\n\n        return True", "response": "Default filter for the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __output_see(self, see):\n\n        if see.startswith('<a href'):\n            # HTML link -- <a href=\"...\">...</a>\n            return self.__html_to_rst(see)\n        elif '\"' in see:\n            # Plain text\n            return see\n        else:\n            # Type reference (default)\n            return ':java:ref:`%s`' % (see.replace('#', '.').replace(' ', ''),)", "response": "Convert the argument to a @see tag to rest"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompiling a complete type documenting a type and its members.", "response": "def compile_type_document(self, imports_block, package, name, declaration):\n        \"\"\" Compile a complete document, documenting a type and its members \"\"\"\n\n        outer_type = name.rpartition('.')[0]\n\n        document = util.Document()\n        document.add(imports_block)\n        document.add_heading(name, '=')\n\n        method_summary = util.StringBuilder()\n        document.add_object(method_summary)\n\n        package_dir = util.Directive('java:package', package)\n        package_dir.add_option('noindex')\n        document.add_object(package_dir)\n\n        # Add type-level documentation\n        type_dir = self.compile_type(declaration)\n        if outer_type:\n            type_dir.add_option('outertype', outer_type)\n        document.add_object(type_dir)\n\n        if isinstance(declaration, javalang.tree.EnumDeclaration):\n            enum_constants = list(declaration.body.constants)\n            enum_constants.sort(key=lambda c: c.name)\n\n            document.add_heading('Enum Constants')\n            for enum_constant in enum_constants:\n                if self.member_headers:\n                    document.add_heading(enum_constant.name, '^')\n                c = self.compile_enum_constant(name, enum_constant)\n                c.add_option('outertype', name)\n                document.add_object(c)\n\n        fields = list(filter(self.filter, declaration.fields))\n        if fields:\n            document.add_heading('Fields', '-')\n            fields.sort(key=lambda f: f.declarators[0].name)\n            for field in fields:\n                if self.member_headers:\n                    document.add_heading(field.declarators[0].name, '^')\n                f = self.compile_field(field)\n                f.add_option('outertype', name)\n                document.add_object(f)\n\n        constructors = list(filter(self.filter, declaration.constructors))\n        if constructors:\n            document.add_heading('Constructors', '-')\n            constructors.sort(key=lambda c: c.name)\n            for constructor in constructors:\n                if self.member_headers:\n                    document.add_heading(constructor.name, '^')\n                c = self.compile_constructor(constructor)\n                c.add_option('outertype', name)\n                document.add_object(c)\n\n        methods = list(filter(self.filter, declaration.methods))\n        if methods:\n            document.add_heading('Methods', '-')\n            methods.sort(key=lambda m: m.name)\n            for method in methods:\n                if self.member_headers:\n                    document.add_heading(method.name, '^')\n                m = self.compile_method(method)\n                m.add_option('outertype', name)\n                document.add_object(m)\n\n        return document"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncompiling autodocs for the given Java syntax tree.", "response": "def compile(self, ast):\n        \"\"\" Compile autodocs for the given Java syntax tree. Documents will be\n        returned documenting each separate type. \"\"\"\n\n        documents = {}\n\n        imports = util.StringBuilder()\n        for imp in ast.imports:\n            if imp.static or imp.wildcard:\n                continue\n\n            package_parts = []\n            cls_parts = []\n\n            for part in imp.path.split('.'):\n                if cls_parts or part[0].isupper():\n                    cls_parts.append(part)\n                else:\n                    package_parts.append(part)\n\n\n            # If the import's final part wasn't capitalized,\n            # append it to the class parts anyway so sphinx doesn't complain.\n            if cls_parts == []:\n                cls_parts.append(package_parts.pop())\n\n            package = '.'.join(package_parts)\n            cls = '.'.join(cls_parts)\n\n            imports.append(util.Directive('java:import', package + ' ' + cls).build())\n        import_block = imports.build()\n\n        if not ast.package:\n            raise ValueError('File must have package declaration')\n\n        package = ast.package.name\n        type_declarations = []\n        for path, node in ast.filter(javalang.tree.TypeDeclaration):\n            if not self.filter(node):\n                continue\n\n            classes = [n.name for n in path if isinstance(n, javalang.tree.TypeDeclaration)]\n            classes.append(node.name)\n\n            name = '.'.join(classes)\n            type_declarations.append((package, name, node))\n\n        for package, name, declaration in type_declarations:\n            full_name = package + '.' + name\n            document = self.compile_type_document(import_block, package, name, declaration)\n            documents[full_name] = (package, name, document.build())\n        return documents"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning packed byte representation of the UDP header.", "response": "def to_bytes(self):\n        '''\n        Return packed byte representation of the UDP header.\n        '''\n        hdr = struct.pack(RIPv2._PACKFMT, self.command.value, 2)\n        routes = b''.join([r.to_bytes() for r in self._routes])\n        return hdr + routes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate standard internet checksum over data starting at start.", "response": "def checksum (data, start = 0, skip_word = None):\n  \"\"\"\n  Calculate standard internet checksum over data starting at start'th byte\n\n  skip_word: If specified, it's the word offset of a word in data to \"skip\"\n             (as if it were zero).  The purpose is when data is received\n             data which contains a computed checksum that you are trying to\n             verify -- you want to skip that word since it was zero when\n             the checksum was initially calculated.\n  \"\"\"\n  if len(data) % 2 != 0:\n    arr = array.array('H', data[:-1])\n  else:\n    arr = array.array('H', data)\n\n  if skip_word is not None:\n    for i in range(0, len(arr)):\n      if i == skip_word:\n        continue\n      start +=  arr[i]\n  else:\n    for i in range(0, len(arr)):\n      start +=  arr[i]\n\n  if len(data) % 2 != 0:\n    start += struct.unpack('H', data[-1:]+b'\\x00')[0] # Specify order?\n\n  start  = (start >> 16) + (start & 0xffff)\n  start += (start >> 16)\n  #while start >> 16:\n  #  start = (start >> 16) + (start & 0xffff)\n\n  return ntohs(~start & 0xffff)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef javadoc_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n\n    has_explicit_title, title, target = split_explicit_title(text)\n    title = utils.unescape(title)\n    target = utils.unescape(target)\n\n    if not has_explicit_title:\n        target = target.lstrip('~')\n\n        if title[0] == '~':\n            title = title[1:].rpartition('.')[2]\n\n    app = inliner.document.settings.env.app\n    ref = get_javadoc_ref(app, rawtext, target)\n\n    if not ref:\n         raise ValueError(\"no Javadoc source found for %s in javadoc_url_map\" % (target,))\n\n    ref.append(nodes.Text(title, title))\n\n    return [ref], []", "response": "Role for linking to external Javadoc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd new input port + packet to buffer.", "response": "def add(self, port, pkt):\n        '''\n        Add new input port + packet to buffer.\n        '''\n        id = len(self._buffer) + 1\n        if id > self._buffsize:\n            raise FullBuffer()\n\n        self._buffer[id] = (port, deepcopy(pkt))\n        return id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_actions(self, actions, inport, packet):\n        '''\n        Process actions in order, in two stages.  Each action implements a __call__, which\n        applies any packet-level changes or other non-output changes.  The functors\n        can optionally return another function to be applied at the second stage.\n        '''\n        second_stage = []\n        for a in actions:\n            fn = a(packet=packet, net=self._switchyard_net, controllers=self._controller_connections, inport=inport)\n            if (fn):\n                second_stage.append(fn)\n        for fn in second_stage:\n            fn()", "response": "Process the actions in order in two stages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_datapath(self, inport, packet):\n        '''\n        Handle single packet on the data plane.\n        '''\n        inport = self._switchyard_net.port_by_name(inport)\n        portnum = inport.ifnum\n        log_info(\"Processing packet: {}->{}\".format(portnum, packet))\n\n        actions = None\n        for tnum,t in enumerate(self._tables):\n            actions = t.match_packet(portnum, packet)\n\n            # FIXME: this is all wrong/incomplete\n\n            # if match: Update counters Execute instructions:\n            #           update action set\n            #           update packet/match set fields\n            #            update metadata\n            # if no match and table miss entry exists, do the above\n            # otherwise, drop the packet\n        # actions = self._table.match_packet(portnum, packet)\n        if actions is None:\n            self._send_packet_in(portnum, packet)\n        else:\n            self._datapath_action(portnum, packet, actions=actions)", "response": "Handle a single packet on the data plane."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the packed byte representation of the UDP header.", "response": "def to_bytes(self):\n        '''\n        Return packed byte representation of the UDP header.\n        '''\n        return struct.pack(UDP._PACKFMT, self._src, self._dst,\n            self._len, self._checksum)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_bytes(self, raw):\n        '''Return an Ethernet object reconstructed from raw bytes, or an\n           Exception if we can't resurrect the packet.'''\n        if len(raw) < UDP._MINLEN:\n            raise NotEnoughDataError(\"Not enough bytes ({}) to reconstruct an UDP object\".format(len(raw)))\n        fields = struct.unpack(UDP._PACKFMT, raw[:UDP._MINLEN])\n        self._src = fields[0]\n        self._dst = fields[1]\n        self._len = fields[2]\n        self._checksum = fields[3]\n        return raw[UDP._MINLEN:]", "response": "Return an Ethernet object reconstructed from raw bytes or an anomaly exception if we can t resurrect the packet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_bytes(self):\n        '''\n        Return packed byte representation of the TCP header.\n        '''\n        header = self._make_header(self._checksum)\n        return header + self._options.to_bytes()", "response": "Returns the packed byte representation of the TCP header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_bytes(self, raw):\n        '''Return an Ethernet object reconstructed from raw bytes, or an\n           Exception if we can't resurrect the packet.'''\n        if len(raw) < TCP._MINLEN:\n            raise NotEnoughDataError(\"Not enough bytes ({}) to reconstruct an TCP object\".format(len(raw)))\n        fields = struct.unpack(TCP._PACKFMT, raw[:TCP._MINLEN])\n        self._src = fields[0]\n        self._dst = fields[1]\n        self._seq = fields[2]        \n        self._ack = fields[3]\n        offset = fields[4] >> 12\n        self._flags = fields[4] & 0x01ff\n        self._window = fields[5]\n        csum = fields[6]\n        self._urg = fields[7]\n        headerlen = offset * 4\n        optlen = headerlen - TCP._MINLEN\n        self._options.from_bytes(raw[TCP._MINLEN:headerlen])\n        return raw[headerlen:]", "response": "Return an Ethernet object reconstructed from raw bytes or an an\n           Exception if we can t resurrect the packet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the packed byte representation of the ICMP header.", "response": "def to_bytes(self, dochecksum=True):\n        '''\n        Return packed byte representation of the UDP header.\n        '''\n        csum = 0\n        if dochecksum:\n            csum = self.checksum()\n        return b''.join((struct.pack(ICMP._PACKFMT, self._type.value, self._code.value, csum), self._icmpdata.to_bytes()))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_codeargs(argstr):\n    '''\n    Parse and clean up argument to user code; separate *args from\n    **kwargs.\n    '''\n    args = []\n    kwargs = {}\n    if isinstance(argstr, str):\n        for a in argstr.split():\n            if '=' in a:\n                k,attr = a.split('=')\n                kwargs[k] = attr\n            else:\n                args.append(a)\n    rd = {'args':args, 'kwargs':kwargs}\n    return rd", "response": "Parse and clean up argument to user code ; separate args from kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef netmask_to_cidr (dq):\n  if isinstance(dq, str):\n    dq = IPv4Address(dq)\n  v = int(dq)\n  c = 0\n  while v & 0x80000000:\n    c += 1\n    v <<= 1\n  v = v & 0xffFFffFF\n  if v != 0:\n    raise RuntimeError(\"Netmask %s is not CIDR-compatible\" % (dq,))\n  return c", "response": "Takes a netmask as either an IPAddr or a string and returns the number of network bits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking a dotted - quad or plain dotted - quad and returns a tuple of address and count - of - network - bits.", "response": "def parse_cidr (addr, infer=True, allow_host=False):\n  \"\"\"\n  Takes a CIDR address or plain dotted-quad, and returns a tuple of address\n  and count-of-network-bits.\n  Can infer the network bits based on network classes if infer=True.\n  Can also take a string in the form 'address/netmask', as long as the\n  netmask is representable in CIDR.\n\n  FIXME: This function is badly named.\n  \"\"\"\n  def check (r0, r1):\n    a = int(r0)\n    b = r1\n    if (not allow_host) and (a & ((1<<b)-1)):\n      raise RuntimeError(\"Host part of CIDR address is not zero (%s)\"\n                         % (addr,))\n    return (r0,32-r1)\n\n  addr = addr.split('/', 2)\n  if len(addr) == 1:\n    if infer is False:\n      return check(IPAddr(addr[0]), 0)\n    addr = IPAddr(addr[0])\n    b = 32-infer_netmask(addr)\n    m = (1<<b)-1\n    if (int(addr) & m) == 0:\n      # All bits in wildcarded part are 0, so we'll use the wildcard\n      return check(addr, b)\n    else:\n      # Some bits in the wildcarded part are set, so we'll assume it's a host\n      return check(addr, 0)\n  try:\n    wild = 32-int(addr[1])\n  except:\n    # Maybe they passed a netmask\n    m = int(IPAddr(addr[1]))\n    b = 0\n    while m & (1<<31):\n      b += 1\n      m <<= 1\n    if m & 0x7fffffff != 0:\n      raise RuntimeError(\"Netmask \" + str(addr[1]) + \" is not CIDR-compatible\")\n    wild = 32-b\n    if not (wild >= 0 and wild <= 32):\n      raise RuntimeError(\"Invalid mask length\")\n    return check(IPAddr(addr[0]), wild)\n  if not (wild >= 0 and wild <= 32):\n    raise RuntimeError(\"Invalid mask length\")\n  return check(IPAddr(addr[0]), wild)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninfer the network bits of the given network bits.", "response": "def infer_netmask (addr):\n  \"\"\"\n  Uses network classes to guess the number of network bits\n  \"\"\"\n  addr = int(addr)\n  if addr == 0:\n    # Special case -- default network\n    return 32-32 # all bits wildcarded\n  if (addr & (1 << 31)) == 0:\n    # Class A\n    return 32-24\n  if (addr & (3 << 30)) == 2 << 30:\n    # Class B\n    return 32-16\n  if (addr & (7 << 29)) == 6 << 29:\n    # Class C\n    return 32-8\n  if (addr & (15 << 28)) == 14 << 28:\n    # Class D (Multicast)\n    return 32-0 # exact match\n  # Must be a Class E (Experimental)\n  return 32-0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the address is an IEEE 802. 1D MAC Bridge Filtered MAC Group Address", "response": "def isBridgeFiltered (self):\n        \"\"\"\n        Checks if address is an IEEE 802.1D MAC Bridge Filtered MAC Group Address\n\n        This range is 01-80-C2-00-00-00 to 01-80-C2-00-00-0F. MAC frames that\n        have a destination MAC address within this range are not relayed by\n        bridges conforming to IEEE 802.1D\n        \"\"\"\n        return  ((self.__value[0] == 0x01)\n    \t    and (self.__value[1] == 0x80)\n    \t    and (self.__value[2] == 0xC2)\n    \t    and (self.__value[3] == 0x00)\n    \t    and (self.__value[4] == 0x00)\n    \t    and (self.__value[5] <= 0x0F))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the address as string consisting of 12 hex chars separated by separator.", "response": "def toStr (self, separator = ':'):\n        \"\"\"\n        Returns the address as string consisting of 12 hex chars separated\n        by separator.\n        \"\"\"\n        return separator.join(('{:02x}'.format(x) for x in self.__value))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the packed byte representation of the Ethernet header.", "response": "def to_bytes(self):\n        '''\n        Return packed byte representation of the Ethernet header.\n        '''\n        return struct.pack(Ethernet._PACKFMT, self._dst.packed, \n            self._src.packed, self._ethertype.value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an Ethernet object reconstructed from raw bytes or an exception if we can t resurrect the packet.", "response": "def from_bytes(self, raw):\n        '''Return an Ethernet object reconstructed from raw bytes, or an\n        Exception if we can't resurrect the packet.'''\n        if len(raw) < Ethernet._MINLEN:\n            raise NotEnoughDataError(\"Not enough bytes ({}) to reconstruct an \"\n                \"Ethernet object\".format(len(raw)))\n        dst,src,ethertype = struct.unpack(Ethernet._PACKFMT, \n            raw[:Ethernet._MINLEN])\n        self.src = src\n        self.dst = dst\n        if ethertype <= 1500:\n            self.ethertype = EtherType.NoType\n        else:\n            self.ethertype = ethertype\n        return raw[Ethernet._MINLEN:]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the whole switchyard simulation.", "response": "def run_simulation(topo, **kwargs):\n    '''\n    Get the simulation substrate started.  The key things are to set up\n    a series of queues that connect nodes together and get the link emulation\n    objects started (all inside the NodeExecutor class).  The NodePlumbing\n    named tuples hold together threads for each node, the emulation\n    substrate (NodeExecutors), and the ingress queue that each node receives\n    packets from.\n    '''\n    log_debug(\"Threads at startup:\")\n    for t in threading.enumerate():\n        log_debug(\"\\tthread at startup {}\".format(t.name))\n\n    with yellow():\n        log_info(\"Starting up switchyard simulation substrate.\")\n    glue = SyssGlue(topo, **kwargs)\n    cli = Cli(glue, topo)\n    try:\n        cli.cmdloop()\n    except KeyboardInterrupt:\n        print(\"Received SIGINT --- shutting down.\")\n        cli.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default(self, line):\n        '''\n        Implement short-cut commands: any unique command prefix should\n        work.'''\n        cmdargs = line.split()\n        remain = ' '.join(cmdargs[1:])\n        if 'show'.startswith(cmdargs[0]):\n            self.do_show(remain)\n        elif 'set'.startswith(cmdargs[0]):\n            self.do_set(remain)\n        elif 'sendeth'.startswith(cmdargs[0]):\n            self.do_sendeth(remain)\n        elif 'load'.startswith(cmdargs[0]):\n            self.do_load(remain)\n        elif 'save'.startswith(cmdargs[0]):\n            self.do_save(remain)\n        elif 'monitor'.startswith(cmdargs[0]):\n            self.do_monitor(remain)\n        elif 'unmonitor'.startswith(cmdargs[0]):\n            self.do_unmonitor(remain)\n        elif 'exec'.startswith(cmdargs[0]):\n            self.do_exec(remain)\n        elif 'add'.startswith(cmdargs[0]):\n            self.do_add(remain)\n        elif 'remove'.startswith(cmdargs[0]):\n            self.do_remove(remain)\n        elif 'replay'.startswith(cmdargs[0]):\n            self.do_replay(remain)\n        else:\n            print (\"Unrecognized command '{}'\".format(line))", "response": "Implement short - cut commands for any unique command prefix should\n        work."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recv_from_app(timeout=_default_timeout):\n        '''\n        Called by a network stack implementer to receive application-layer\n        data for sending on to a remote location.  \n\n        Can optionally take a timeout value.  If no data are available,\n        raises NoPackets exception.\n\n        Returns a 2-tuple: flowaddr and data.\n        The flowaddr consists of 5 items: protocol, localaddr, localport, \n        remoteaddr, remoteport.\n        '''\n        try:\n            return ApplicationLayer._from_app.get(timeout=timeout)\n        except Empty:\n            pass\n        raise NoPackets()", "response": "Receive application - layer related information from the remote location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the application - layer.", "response": "def send_to_app(proto, local_addr, remote_addr, data):\n        '''\n        Called by a network stack implementer to push application-layer\n        data \"up\" from the stack.\n\n        Arguments are protocol number, local_addr (a 2-tuple of IP address\n        and port), remote_addr (a 2-tuple of IP address and port), and the\n        message.  \n\n        Returns True if a socket was found to which to deliver the message,\n        and False otherwise.  When False is returned, a log warning is also\n        emitted.\n        '''\n        proto = IPProtocol(proto)\n        local_addr = _normalize_addrs(local_addr)\n        remote_addr = _normalize_addrs(remote_addr)\n        xtup = (proto, local_addr[0], local_addr[1])\n        with _lock:\n            sockqueue = ApplicationLayer._to_app.get(xtup, None)\n\n        if sockqueue is not None:\n            sockqueue.put((local_addr,remote_addr,data))\n            return True\n        \n        # no dice, try local IP addr of 0.0.0.0\n        local2 = _normalize_addrs((\"0.0.0.0\", local_addr[1]))\n        xtup = (proto, local2[0], local2[1])\n        with _lock:\n            sockqueue = ApplicationLayer._to_app.get(xtup, None)\n        if sockqueue is not None:    \n            sockqueue.put((local_addr,remote_addr,data))\n            return True\n\n        log_warn(\"No socket queue found for local proto/address: {}\".format(xtup))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _unregister_socket(s):\n        '''\n        Internal method used to remove the socket from AppLayer registry.\n        Warns if the \"upward\" socket queue has any left-over data.  \n        '''\n        with _lock:\n            sock_queue = ApplicationLayer._to_app.pop(s._sockid())\n        if not sock_queue.empty():\n            log_warn(\"Socket being destroyed still has data enqueued for application layer.\")", "response": "Unregisters the given socket from the AppLayer registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbinds to a local address.", "response": "def bind(self, address):\n        '''\n        Alter the local address with which this socket is associated.\n        The address parameter is a 2-tuple consisting of an IP address\n        and port number. \n\n        NB: this method fails and returns -1 if the requested port\n        to bind to is already in use but does *not* check that the\n        address is valid.  \n        '''\n        portset = _gather_ports().union(ApplicationLayer._emuports())\n        if address[1] in portset:\n            log_warn(\"Port is already in use.\")\n            return -1\n\n        oldid = self._sockid()\n        # block firewall port\n        # set stack to only allow packets through for addr/port\n        self._local_addr = _normalize_addrs(address)\n        # update firewall and pcap filters\n        self.__set_fw_rules()\n        ApplicationLayer._registry_update(self, oldid)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recv(self, buffersize, flags=0):\n        '''\n        Receive data on the socket.  The buffersize and flags\n        arguments are currently ignored.  Only returns the data.\n        '''\n        _,_,data = self._recv(buffersize)\n        return data", "response": "Receive data on the socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recvfrom(self, buffersize, flags=0):\n        '''\n        Receive data on the socket.  The buffersize and flags\n        arguments are currently ignored.  Returns the data and\n        an address tuple (IP address and port) of the remote host.\n        '''\n        _,remoteaddr,data = self._recv(buffersize)\n        return data,remoteaddr", "response": "Receive data on the socket and return the data and the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending data on the socket.", "response": "def send(self, data, flags=0):\n        '''\n        Send data on the socket.  A call to connect() must have\n        been previously made for this call to succeed.\n        Flags is currently ignored.\n        '''\n        if self._remote_addr == (None,None):\n            raise sockerr(\"ENOTCONN: socket not connected\")\n        return self._send(data, self._flowaddr())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends data on the socket. Accepts the same parameters as the built - in socket sendto.", "response": "def sendto(self, data, *args):\n        '''\n        Send data on the socket.  Accepts the same parameters as the\n        built-in socket sendto: data[, flags], address\n        where address is a 2-tuple of IP address and port.\n        Any flags are currently ignored.\n        '''\n        remoteaddr = args[-1]\n        remoteaddr = _normalize_addrs(remoteaddr)\n        return self._send(data, (self._proto, self._local_addr[0], \n            self._local_addr[1], remoteaddr[0], remoteaddr[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the timeout value for this socket.", "response": "def settimeout(self, timeout):\n        '''\n        Set the timeout value for this socket.\n        '''\n        if timeout is None:\n            self._block = True\n        elif float(timeout) == 0.0:\n            self._block = False\n        else:\n            self._timeout = float(timeout)\n            self._block = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the packed byte representation of the ARP header.", "response": "def to_bytes(self):\n        '''\n        Return packed byte representation of the ARP header.\n        '''\n        return struct.pack(Arp._PACKFMT, self._hwtype.value, self._prototype.value, self._hwaddrlen, self._protoaddrlen, self._operation.value, self._senderhwaddr.packed, self._senderprotoaddr.packed, self._targethwaddr.packed, self._targetprotoaddr.packed)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an Ethernet object reconstructed from raw bytes or an an Exception if we can t resurrect the packet.", "response": "def from_bytes(self, raw):\n        '''Return an Ethernet object reconstructed from raw bytes, or an\n           Exception if we can't resurrect the packet.'''\n        if len(raw) < Arp._MINLEN:\n            raise NotEnoughDataError(\"Not enough bytes ({}) to reconstruct an Arp object\".format(len(raw)))\n        fields = struct.unpack(Arp._PACKFMT, raw[:Arp._MINLEN])\n        try:\n            self._hwtype = ArpHwType(fields[0])\n            self._prototype = EtherType(fields[1])\n            self._hwaddrlen = fields[2]\n            self._protoaddrlen = fields[3]\n            self.operation = ArpOperation(fields[4])\n            self.senderhwaddr = EthAddr(fields[5])\n            self.senderprotoaddr = IPAddr(fields[6])\n            self.targethwaddr = EthAddr(fields[7])\n            self.targetprotoaddr = IPAddr(fields[8])\n        except Exception as e:\n            raise Exception(\"Error constructing Arp packet object from raw bytes: {}\".format(str(e)))\n        return raw[Arp._MINLEN:]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_table_cells(self, table):\n\n        rows = []\n\n        for i, tr in enumerate(table.find_all('tr')):\n            row = []\n\n            for c in tr.contents:\n                cell_type = getattr(c, 'name', None)\n\n                if cell_type not in ('td', 'th'):\n                    continue\n\n                rowspan = int(c.attrs.get('rowspan', 1))\n                colspan = int(c.attrs.get('colspan', 1))\n                contents = self._process_children(c).strip()\n\n                if cell_type == 'th' and i > 0:\n                    contents = self._inline('**', contents)\n\n                row.append(Cell(cell_type, rowspan, colspan, contents))\n\n            rows.append(row)\n\n        return rows", "response": "Compile all the table cells."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport user code and return reference to usercode function.", "response": "def import_or_die(module_name, entrypoint_names):\n    '''\n    Import user code; return reference to usercode function.\n\n    (str) -> function reference\n    '''\n    log_debug(\"Importing {}\".format(module_name))\n    module_name = os.path.abspath(module_name)\n    if module_name.endswith('.py'):\n        module_name,ext = os.path.splitext(module_name)\n    modname = os.path.basename(module_name)\n    dirname = os.path.dirname(module_name)\n    if dirname and dirname not in sys.path:\n        sys.path.append(dirname)\n\n    # first, try to reload code\n    if modname in sys.modules:\n        user_module = sys.modules.get(modname)\n        user_module = importlib.reload(user_module)\n    # if it isn't in sys.modules, load it for the first time, or\n    # try to.\n    else:\n        try:\n            mypaths = [ x for x in sys.path if (\"Cellar\" not in x and \"packages\" not in x)]\n            # print(\"Loading {} from {} ({})\".format(modname, dirname, mypaths))\n            # user_module = importlib.import_module(modname)\n            user_module = importlib.__import__(modname)\n        except ImportError as e:\n            log_failure(\"Fatal error: couldn't import module (error: {}) while executing {}\".format(str(e), modname))\n            raise ImportError(e)\n\n    # if there aren't any functions to call into, then the caller\n    # just wanted the module/code to be imported, and that's it.\n    if not entrypoint_names:\n        return\n\n    existing_names = dir(user_module)\n    for method in entrypoint_names:\n        if method in existing_names:\n            return getattr(user_module, method)\n\n    if len(entrypoint_names) > 1:\n        entrypoints = \"one of {}\".format(', '.join(entrypoint_names))\n    else:\n        entrypoints = entrypoint_names[0]\n    raise ImportError(\"Required entrypoint function or symbol ({}) not found in your code\".format(entrypoints))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _runcmd(progargs, stdinput=None):\n    '''\n    Run the command progargs with optional input to be fed in to stdin.\n    '''\n    stdin = None\n    if stdinput is not None:\n        assert(isinstance(stdinput, list))\n        stdin=PIPE\n\n    err = 0\n    output = b''\n    log_debug(\"Calling {} with input {}\".format(' '.join(progargs), stdinput))\n    try:\n        p = Popen(progargs, shell=True, stdin=stdin, \n            stderr=STDOUT, stdout=PIPE, universal_newlines=True)\n        if stdinput is not None:\n            for cmd in stdinput:\n                print(cmd, file=p.stdin)\n            p.stdin.close()\n        output = p.stdout.read()\n        p.stdout.close()\n        err = p.wait(timeout=1.0)\n    except OSError as e:\n        err = e.errno\n        log_warn(\"Error calling {}: {}\".format(progargs, e.stderror))\n    except Exception as e:\n        errstr = str(e)\n        log_warn(\"Error calling {}: {}\".format(progargs, errstr))\n        err = -1\n    log_debug(\"Result of command (errcode {}): {}\".format(err, output))\n    return err,output", "response": "Run the command progargs with optional input to be fed in to stdin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall the rules for the current set of rules.", "response": "def block(self):\n        '''\n        pfctl -a switchyard -f- < rules.txt\n        pfctl -a switchyard -F rules\n        pfctl -t switchyard -F r\n        '''\n        st,output = _runcmd(\"/sbin/pfctl -aswitchyard -f -\", self._rules)\n        log_debug(\"Installing rules: {}\".format(output))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_graph(cn_topo, filename, showintfs=False, showaddrs=False):\n    '''\n    Save the topology to an image file \n    '''\n    __do_draw(cn_topo, showintfs=showintfs, showaddrs=showaddrs)\n    pyp.savefig(filename)", "response": "Save the topology to an image file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_from_file(filename):\n    '''\n    Load a topology from filename and return it.\n    '''\n    t = None\n    with open(filename, 'rU') as infile:\n        tdata = infile.read()\n        t = Topology.unserialize(tdata)\n    return t", "response": "Load a topology from filename and return it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_to_file(cn_topo, filename):\n    '''\n    Save a topology to a file.\n    '''\n    jstr = cn_topo.serialize()\n    with open(filename, 'w') as outfile:\n        outfile.write(jstr)", "response": "Save a topology to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __addNode(self, name, cls):\n        '''\n        Add a node to the topology\n        '''\n        if name in self.nodes:\n            raise Exception(\"A node by the name {} already exists.  Can't add a duplicate.\".format(name))\n        self.__nxgraph.add_node(name)\n        self.__nxgraph.node[name]['label'] = name\n        self.__nxgraph.node[name]['nodeobj'] = cls()\n        self.__nxgraph.node[name]['type'] = cls.__name__", "response": "Add a node to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addHost(self, name=None):\n        '''\n        Add a new host node to the topology.\n        '''\n        if name is None:\n            while True:\n                name = 'h' + str(self.__hnum)\n                self.__hnum += 1\n                if name not in self.__nxgraph:\n                    break\n        self.__addNode(name, Host)\n        return name", "response": "Add a new host node to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addSwitch(self, name=None):\n        '''\n        Add a new switch to the topology.\n        '''\n        if name is None:\n            while True:\n                name = 's' + str(self.__snum)\n                self.__snum += 1\n                if name not in self.__nxgraph:\n                    break\n        self.__addNode(name, Switch)\n        return name", "response": "Add a new switch to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addRouter(self, name=None):\n        '''\n        Add a new switch to the topology.\n        '''\n        if name is None:\n            while True:\n                name = 'r' + str(self.__rnum)\n                self.__rnum += 1\n                if name not in self.__nxgraph:\n                    break\n        self.__addNode(name, Router)\n        return name", "response": "Add a new router to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a bidirectional link between node1 and node2 with the given capacity and delay to the topology.", "response": "def addLink(self, node1, node2, capacity, delay):\n        '''\n        Add a bidirectional link between node1 and node2 with the given\n        capacity and delay to the topology.\n        '''\n        for n in (node1, node2):\n            if not self.__nxgraph.has_node(n):\n                raise Exception(\"No node {} exists for building a link\".format(n))\n        macs = [None,None]\n        if self.__auto_macs:\n            for i in range(len(macs)):\n                macstr = '{:012x}'.format(self.__ifnum)\n                self.__ifnum += 1\n                macaddr = ':'.join([ macstr[j:(j+2)] for j in range(0,len(macstr),2)])\n                macs[i] = macaddr\n        node1if = self.__nxgraph.node[node1]['nodeobj'].addInterface(ethaddr=macs[0])\n        node2if = self.__nxgraph.node[node2]['nodeobj'].addInterface(ethaddr=macs[1])\n        self.__nxgraph.add_edge(node1, node2)\n        self.__nxgraph[node1][node2][node1] = node1if\n        self.__nxgraph[node1][node2][node2] = node2if\n        self.setLinkCharacteristics(node1, node2, capacity, delay)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(self):\n        '''\n        Return a JSON string of the serialized topology\n        '''\n        return json.dumps(json_graph.node_link_data(self.__nxgraph), cls=Encoder)", "response": "Return a JSON string of the serialized topology\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unserialize(jsonstr):\n        '''\n        Unserialize a JSON string representation of a topology\n        '''\n        topod = json.loads(jsonstr)\n        G = json_graph.node_link_graph(topod)\n        for n,ndict in G.nodes(data=True):\n            if 'nodeobj' not in ndict or 'type' not in ndict:\n                raise Exception(\"Required type information is not present in serialized node {} :{}\".format(n, ndict))\n            nobj = ndict['nodeobj']\n            cls = eval(ndict['type'])\n            ndict['nodeobj'] = cls(**dict(nobj))\n        t = Topology(nxgraph=G)\n        return t", "response": "Unserialize a JSON string representation of a topology\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign IP addresses to all interfaces on hosts and routers in the network. ArcGIS does not have a prefix.", "response": "def assignIPAddresses(self, prefix=None):\n        '''\n        Assign IP addresses to all interfaces on hosts and routers in the\n        network.  \n        \n        NB: this method assumes that all interfaces are assigned\n        addresses on the same subnet.  If you don't want that behavior,\n        the setInterfaceAddresses method must be used.\n        '''\n        if not prefix:\n            subnet = ipaddress.IPv4Network('10.0.0.0/8')\n        else:\n            subnet = ipaddress.IPv4Network(str(prefix),strict=False)\n\n        ipgenerator = subnet.hosts()\n\n        # collect all links; figure out which ones need to be numbered (i.e., \n        # only interfaces connected to hosts and routers)\n        nodes_to_number = self.hosts + self.routers\n\n        for u,v in sorted(self.links):\n            linkdata = self.getLink(u,v)\n            for node in [u,v]:\n                if node in nodes_to_number:\n                    ifname = linkdata[node]\n                    intf = self.getNode(node)['nodeobj'].getInterface(ifname)\n                    intf.ipaddr = next(ipgenerator)\n                    intf.netmask = subnet.netmask"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving two node names that identify a link return the pair of interface names assigned at each endpoint.", "response": "def getLinkInterfaces(self, node1, node2):\n        '''\n        Given two node names that identify a link, return the pair of\n        interface names assigned at each endpoint (as a tuple in the \n        same order as the nodes given).\n        '''\n        linkdata = self.getLink(node1,node2)\n        return linkdata[node1],linkdata[node1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset any one of Ethernet MAC address IP address or netmask for a given interface on a given node.", "response": "def setInterfaceAddresses(self, node, interface, mac=None, ip=None, netmask=None):\n        '''\n        Set any one of Ethernet (MAC) address, IP address or IP netmask for\n        a given interface on a node.\n        '''\n        if not self.hasNode(node):\n            raise Exception(\"No such node {}\".format(node))\n        nobj = self.getNode(node)['nodeobj']\n        if interface not in nobj:\n            raise Exception(\"No such interface {}\".format(interface))\n\n        intf = nobj.getInterface(interface)\n        if mac:\n            intf.ethaddr = mac\n        if ip:\n            intf.ipaddr = ip\n        if netmask:\n            intf.netmask = netmask"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getInterfaceAddresses(self, node, interface):\n        '''\n        Return the Ethernet and IP+mask addresses assigned to a\n        given interface on a node.\n        '''\n        intf = self.getNode(node)['nodeobj'].getInterface(interface)\n        return intf.ethaddr,intf.ipaddr,intf.netmask", "response": "Returns the Ethernet and IP + mask addresses assigned to a node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addNodeLabelPrefix(self, prefix=None, copy=False):\n        '''\n        Rename all nodes in the network from x to prefix_x.  If no prefix\n        is given, use the name of the graph as the prefix.\n        \n        The purpose of this method is to make node names unique so that\n        composing two graphs is well-defined.\n        '''\n        nxgraph = Topology.__relabel_graph(self.__nxgraph, prefix)\n        if copy:\n            newtopo = copy.deepcopy(self)\n            newtopo.nxgraph = nxgraph\n            return newtopo\n        else:\n            # looks like it was done in place\n            self.__nxgraph = nxgraph", "response": "Rename all nodes in the network from x to prefix_x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Null header object reconstructed from raw bytes or an exception.", "response": "def from_bytes(self, raw):\n        '''Return a Null header object reconstructed from raw bytes, or an\n        Exception if we can't resurrect the packet.'''\n        if len(raw) < 4:\n            raise NotEnoughDataError(\"Not enough bytes ({}) to reconstruct a Null object\".format(len(raw)))\n        fields = struct.unpack('=I', raw[:4])\n        self._af = fields[0]\n        return raw[4:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns serialized bytes object representing all headers and payloads in this packet", "response": "def to_bytes(self):\n        '''\n        Returns serialized bytes object representing all headers/\n        payloads in this packet'''\n        rawlist = []\n        i = len(self._headers)-1\n        while i >= 0:\n            self._headers[i].pre_serialize(b''.join(rawlist), self, i)\n            rawlist.insert(0, self._headers[i].to_bytes())\n            i -= 1\n        self._raw = b''.join(rawlist)\n        return self._raw"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a raw bytes object and construct the list of packet header objects that are part of this packet.", "response": "def _parse(self, raw, next_cls):\n        '''\n        Parse a raw bytes object and construct the list of packet header\n        objects (and possible remaining bytes) that are part of this packet.\n        '''\n        if next_cls is None:\n            from switchyard.lib.packet import Ethernet\n            next_cls = Ethernet\n\n        self._headers = []\n        while issubclass(next_cls, PacketHeaderBase):\n            packet_header_obj = next_cls()\n            raw = packet_header_obj.from_bytes(raw)\n            self.add_header(packet_header_obj)\n            next_cls = packet_header_obj.next_header_class()\n            if next_cls is None:\n                break\n        if raw:\n            self.add_header(RawPacketContents(raw))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a PacketHeaderBase or a raw bytes object as the next header item in this packet.", "response": "def add_header(self, ph):\n        '''\n        Add a PacketHeaderBase derived class object, or a raw bytes object\n        as the next \"header\" item in this packet.  Note that 'header'\n        may be a slight misnomer since the last portion of a packet is\n        considered application payload and not a header per se.\n        '''\n        if isinstance(ph, bytes):\n            ph = RawPacketContents(ph)\n        if isinstance(ph, PacketHeaderBase):\n            self._headers.append(ph)\n            return self\n        raise Exception(\"Payload for a packet header must be an object that is a subclass of PacketHeaderBase, or a bytes object.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the packet has a header of the given hdrclass False otherwise.", "response": "def has_header(self, hdrclass):\n        '''\n        Return True if the packet has a header of the given hdrclass, \n        False otherwise.\n        '''\n        if isinstance(hdrclass, str):\n            return self.get_header_by_name(hdrclass) is not None\n        return self.get_header(hdrclass) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_header_by_name(self, hdrname):\n        '''\n        Return the header object that has the given (string) header\n        class name.  Returns None if no such header exists.\n        '''\n        for hdr in self._headers:\n            if hdr.__class__.__name__ == hdrname:\n                return hdr\n        return None", "response": "Returns the header object that has the given name. Returns None if no such header exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the first header object that is of the given header class.", "response": "def get_header(self, hdrclass, returnval=None):\n        '''\n        Return the first header object that is of\n        class hdrclass, or None if the header class isn't\n        found.\n        '''\n        if isinstance(hdrclass, str):\n            return self.get_header_by_name(hdrclass)\n\n        for hdr in self._headers:\n            if isinstance(hdr, hdrclass):\n                return hdr\n        return returnval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the header class hdrclass starting at startidx.", "response": "def get_header_index(self, hdrclass, startidx=0):\n        '''\n        Return the first index of the header class hdrclass\n        starting at startidx (default=0), or -1 if the\n        header class isn't found in the list of headers.\n        '''\n        for hdridx in range(startidx, len(self._headers)):\n            if isinstance(self._headers[hdridx], hdrclass):\n                return hdridx\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next_header_class(self):\n        '''Return class of next header, if known.'''\n        if self._next_header_class_key == '':\n            return None\n        key = getattr(self, self._next_header_class_key)\n        rv = self._next_header_map.get(key, None)\n        if rv is None:\n            log_warn(\"No class exists to handle next header value {}\".format(key))\n        return rv", "response": "Return class of next header if known."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the value_template of the parameter using context. Basket", "response": "def process(self, **context):\n        \"\"\"\n        Render value_template of the parameter using context.\n        \n        :param context: Processing context\n        \"\"\"\n        env = Environment(extensions=['jinja2_time.TimeExtension'])        \n        value_template = env.from_string(self.value_template)\n        return value_template.render(**context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post(self, request, hook_id):\n        serializer = UpdateSerializer(data=request.data)\n        if serializer.is_valid():\n            try:\n                bot = caching.get_or_set(TelegramBot, hook_id)\n            except TelegramBot.DoesNotExist:\n                logger.warning(\"Hook id %s not associated to an bot\" % hook_id)\n                return Response(serializer.errors, status=status.HTTP_404_NOT_FOUND)\n            try:\n                update = self.create_update(serializer, bot)\n                if bot.enabled:\n                    logger.debug(\"Telegram Bot %s attending request %s\" % (bot.token, request.data))\n                    handle_update.delay(update.id, bot.id)\n                else:\n                    logger.error(\"Update %s ignored by disabled bot %s\" % (update, bot.token))\n            except OnlyTextMessages:\n                logger.warning(\"Not text message %s for bot %s\" % (request.data, hook_id))\n                return Response(status=status.HTTP_200_OK)\n            except:\n                exc_info = sys.exc_info()\n                traceback.print_exception(*exc_info)                \n                logger.error(\"Error processing %s for bot %s\" % (request.data, hook_id))\n                return Response(serializer.errors, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n            else:\n                return Response(serializer.data, status=status.HTTP_200_OK)\n        logger.error(\"Validation error: %s from message %s\" % (serializer.errors, request.data))\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)", "response": "Process Telegram webhook.\n            1. Serialize Telegram message\n            2. Get an enabled Telegram bot\n            3. Create :class:`Update <permabots.models.telegram_api.Update>`\n            5. Delay processing to a task      \n            6. Response provider"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, request, format=None):\n        bots = Bot.objects.filter(owner=request.user)\n        serializer = BotSerializer(bots, many=True)\n        return Response(serializer.data)", "response": "Get list of bots that are owned by the current user"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new bot alid", "response": "def post(self, request, format=None):\n        \"\"\"\n        Add a new bot\n        ---\n        serializer: BotSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        serializer = BotSerializer(data=request.data)\n        if serializer.is_valid():\n            bot = Bot.objects.create(owner=request.user,\n                                     name=serializer.data['name'])\n            return Response(BotSerializer(bot).data, status=status.HTTP_201_CREATED)\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, id, format=None):\n        bot = self.get_bot(id, request.user)\n        serializer = BotSerializer(bot)\n        return Response(serializer.data)", "response": "Get a specific bot by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put(self, request, id, format=None):\n        bot = self.get_bot(id, request.user)\n        serializer = BotUpdateSerializer(bot, data=request.data)\n        if serializer.is_valid():\n            try:\n                bot = serializer.save()\n            except:\n                return Response(status=status.HTTP_400_BAD_REQUEST)\n            else:\n                return Response(BotSerializer(bot).data)\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)", "response": "Update an existing bot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, request, id, format=None):\n        bot = self.get_bot(id, request.user)\n        bot.delete()\n        return Response(status=status.HTTP_204_NO_CONTENT)", "response": "Delete an existing bot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, request, bot_id, format=None):\n        return super(TelegramBotList, self).get(request, bot_id, format)", "response": "Get list of Telegram bots with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post(self, request, bot_id, format=None):\n        try:\n            return super(TelegramBotList, self).post(request, bot_id, format)\n        except:\n            return Response({\"error\": 'Telegram Error. Check Telegram token or try later.'}, status=status.HTTP_400_BAD_REQUEST)", "response": "Telegram Bot Add TelegramBot\nInterruptory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, request, bot_id, id, format=None):\n        return super(TelegramBotDetail, self).get(request, bot_id, id, format)", "response": "Get TelegramBot by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates existing TelegramBot with new id", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing TelegramBot\n        ---\n        serializer: TelegramBotUpdateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"      \n        return super(TelegramBotDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, request, bot_id, id, format=None):\n        return super(TelegramBotDetail, self).delete(request, bot_id, id, format)", "response": "Delete existing Telegram Bot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request, bot_id, format=None):\n        return super(KikBotList, self).get(request, bot_id, format)", "response": "Get list of Kik bots"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, request, bot_id, id, format=None):\n        return super(KikBotDetail, self).get(request, bot_id, id, format)", "response": "Get KikBot by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates existing KikBot with new id", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing KikBot\n        ---\n        serializer: KikBotUpdateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"      \n        return super(KikBotDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes existing Kik Bot Interrupt", "response": "def delete(self, request, bot_id, id, format=None):\n        \"\"\"\n        Delete existing Kik Bot\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(KikBotDetail, self).delete(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget list of Messenger bots", "response": "def get(self, request, bot_id, format=None):\n        \"\"\"\n        Get list of Messenger bots\n        ---\n        serializer: MessengerBotSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(MessengerBotList, self).get(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, request, bot_id, id, format=None):\n        return super(MessengerBotDetail, self).get(request, bot_id, id, format)", "response": "Get MessengerBot by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, request, bot_id, id, format=None):\n        return super(MessengerBotDetail, self).put(request, bot_id, id, format)", "response": "Update existing MessengerBot with new id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, request, bot_id, id, format=None):\n        return super(MessengerBotDetail, self).delete(request, bot_id, id, format)", "response": "Delete existing Messenger Bot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, request, bot_id, format=None):\n        return super(StateList, self).get(request, bot_id, format)", "response": "Get list of states"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new state", "response": "def post(self, request, bot_id, format=None):\n        \"\"\"\n        Add a new state\n        ---\n        serializer: StateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(StateList, self).post(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request, bot_id, id, format=None):\n        return super(StateDetail, self).get(request, bot_id, id, format)", "response": "Get state by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates existing state --- serializer: StateSerializer responseMessages: - code: 401 message: Not authenticated - code: 400 message: Not valid request", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing state\n        ---\n        serializer: StateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"      \n        return super(StateDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete existing state --- responseMessages: - code: 401 message: Not authenticated", "response": "def delete(self, request, bot_id, id, format=None):\n        \"\"\"\n        Delete existing state\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(StateDetail, self).delete(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting list of chat state", "response": "def get(self, request, bot_id, format=None):\n        \"\"\"\n        Get list of chat state\n        ---\n        serializer: TelegramChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(TelegramChatStateList, self).get(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, bot_id, format=None):\n        return super(TelegramChatStateList, self).post(request, bot_id, format)", "response": "Add a new chat state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Telegram chat state by id", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get Telegram chat state by id\n        ---\n        serializer: TelegramChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"        \n        return super(TelegramChatStateDetail, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, request, bot_id, id, format=None):\n        return super(TelegramChatStateDetail, self).put(request, bot_id, id, format)", "response": "Update existing Telegram chat state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting existing Kik chat state", "response": "def delete(self, request, bot_id, id, format=None):\n        \"\"\"\n        Delete existing Kik chat state\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(TelegramChatStateDetail, self).delete(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting list of chat state", "response": "def get(self, request, bot_id, format=None):\n        \"\"\"\n        Get list of chat state\n        ---\n        serializer: KikChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(KikChatStateList, self).get(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new chat state", "response": "def post(self, request, bot_id, format=None):\n        \"\"\"\n        Add a new chat state\n        ---\n        serializer: KikChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(KikChatStateList, self).post(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting Kik chat state by id", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get Kik chat state by id\n        ---\n        serializer: KikChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"        \n        return super(KikChatStateDetail, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate existing Kik chat state with new id", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing Kik chat state\n        ---\n        serializer: KikChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(KikChatStateDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, request, bot_id, id, format=None):\n        return super(KikChatStateDetail, self).delete(request, bot_id, id, format)", "response": "Delete existing Kik chat state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, request, bot_id, format=None):\n        return super(MessengerChatStateList, self).get(request, bot_id, format)", "response": "Get list of chat state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, request, bot_id, format=None):\n        return super(MessengerChatStateList, self).post(request, bot_id, format)", "response": "Add a new chat state"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets Messenger chat state by id", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get Messenger chat state by id\n        ---\n        serializer: MessengerChatStateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"        \n        return super(MessengerChatStateDetail, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(self, request, bot_id, id, format=None):\n        return super(MessengerChatStateDetail, self).put(request, bot_id, id, format)", "response": "Update existing Messenger chat state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting existing Messenger chat state", "response": "def delete(self, request, bot_id, id, format=None):\n        \"\"\"\n        Delete existing Messenger chat state\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(MessengerChatStateDetail, self).delete(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, request, bot_id, format=None):\n        return super(HandlerList, self).get(request, bot_id, format)", "response": "Get list of handlers with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, bot_id, format=None):\n        return super(HandlerList, self).post(request, bot_id, format)", "response": "Add a new handler\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget handler by id", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get handler by id\n        ---\n        serializer: HandlerSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"        \n        return super(HandlerDetail, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates existing handler --- serializer: HandlerUpdateSerializer responseMessages: - code: 401 message: Not authenticated - code: 400 message: Not valid request", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing handler\n        ---\n        serializer: HandlerUpdateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"      \n        return super(HandlerDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting handler with specific id", "response": "def delete(self, request, bot_id, id, format=None):\n        \"\"\"\n        Delete existing handler\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(HandlerDetail, self).delete(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, request, bot_id, id, format=None):\n        return super(UrlParameterList, self).get(request, bot_id, id, format)", "response": "Get list of url parameters of a handler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, request, bot_id, id, format=None):\n        return super(UrlParameterList, self).post(request, bot_id, id, format)", "response": "Add a new url parameter to a handler\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets list of header parameters of a handler", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get list of header parameters of a handler\n        ---\n        serializer: AbsParamSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(HeaderParameterList, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new header parameter to a handler", "response": "def post(self, request, bot_id, id, format=None):\n        \"\"\"\n        Add a new header parameter to a handler\n        ---\n        serializer: AbsParamSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(HeaderParameterList, self).post(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, bot_id, handler_id, id, format=None):\n        return super(UrlParameterDetail, self).get(request, bot_id, handler_id, id, format)", "response": "Get url parameter by id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting list of source states of a handler.", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get list of source state of a handler\n        ---\n        serializer: StateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(SourceStateList, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new source state to a handler.", "response": "def post(self, request, bot_id, id, format=None):\n        \"\"\"\n        Add a new source state to a handler\n        ---\n        serializer: StateSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(SourceStateList, self).post(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the validation token for a given webhook", "response": "def get(self, request, hook_id):\n        \"\"\"\n        Verify token when configuring webhook from facebook dev.\n        \n        MessengerBot.id is used for verification\n        \"\"\"\n        try:\n            bot = caching.get_or_set(MessengerBot, hook_id)\n        except MessengerBot.DoesNotExist:\n            logger.warning(\"Hook id %s not associated to a bot\" % hook_id)\n            return Response(status=status.HTTP_404_NOT_FOUND)\n        if request.query_params.get('hub.verify_token') == str(bot.id):\n            return Response(int(request.query_params.get('hub.challenge')))\n        return Response('Error, wrong validation token')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, request, hook_id):\n        try:\n            bot = caching.get_or_set(MessengerBot, hook_id)\n        except MessengerBot.DoesNotExist:\n            logger.warning(\"Hook id %s not associated to a bot\" % hook_id)\n            return Response(status=status.HTTP_404_NOT_FOUND)\n        logger.debug(\"Messenger Bot %s attending request %s\" % (bot, request.data))\n        webhook = Webhook.from_json(request.data)\n        for webhook_entry in webhook.entries:\n            for webhook_message in webhook_entry.messaging:\n                try:\n                    if webhook_message.is_delivery:\n                        raise OnlyTextMessages\n                    message = self.create_message(webhook_message, bot)\n                    if bot.enabled:\n                        logger.debug(\"Messenger Bot %s attending request %s\" % (bot, message))\n                        handle_messenger_message.delay(message.id, bot.id)\n                    else:\n                        logger.error(\"Message %s ignored by disabled bot %s\" % (message, bot))\n                except OnlyTextMessages:\n                    logger.warning(\"Not text message %s for bot %s\" % (message, hook_id))\n                except:\n                    exc_info = sys.exc_info()\n                    traceback.print_exception(*exc_info)                \n                    logger.error(\"Error processing %s for bot %s\" % (webhook_message, hook_id))\n                    return Response(status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n        return Response(status=status.HTTP_200_OK)", "response": "Process Messenger webhook.\n            1. Get an enabled Messenger bot\n            3. For each message serialize\n            4. For each message create :class:`MessengerMessage <permabots.models.messenger_api.MessengerMessage>`\n            5. Delay processing of each message to a task      \n            6. Response provider"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting list of hooks.", "response": "def get(self, request, bot_id, format=None):\n        \"\"\"\n        Get list of hooks\n        ---\n        serializer: HookSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        return super(HookList, self).get(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new hook to the list", "response": "def post(self, request, bot_id, format=None):\n        \"\"\"\n        Add a new hook\n        ---\n        serializer: HookSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(HookList, self).post(request, bot_id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request, bot_id, id, format=None):\n        return super(HookDetail, self).get(request, bot_id, id, format)", "response": "Get hook by id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put(self, request, bot_id, id, format=None):\n        return super(HookDetail, self).put(request, bot_id, id, format)", "response": "Update existing hook with new id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, request, bot_id, id, format=None):\n        return super(HookDetail, self).delete(request, bot_id, id, format)", "response": "Delete existing hook\n        ---\n        responseMessages:\n            - code: 401\n              message: Not authenticated"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, request, bot_id, id, format=None):\n        return super(TelegramRecipientList, self).get(request, bot_id, id, format)", "response": "Get list of telegram recipients of a hook."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, request, bot_id, id, format=None):\n        return super(TelegramRecipientList, self).post(request, bot_id, id, format)", "response": "Add a new telegram recipient to a handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a specific Telegram recipient by id", "response": "def get(self, request, bot_id, hook_id, id, format=None):\n        \"\"\"\n        Get recipient by id\n        ---\n        serializer: TelegramRecipientSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"\n        bot = self.get_bot(bot_id, request.user)\n        hook = self.get_hook(hook_id, bot, request.user)\n        recipient = self.get_recipient(id, hook, request.user)\n        serializer = self.serializer(recipient)\n        return Response(serializer.data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, request, bot_id, hook_id, id, format=None):\n        bot = self.get_bot(bot_id, request.user)\n        hook = self.get_hook(hook_id, bot, request.user)\n        recipient = self.get_recipient(id, hook, request.user)\n        serializer = self.serializer(recipient, data=request.data)\n        \n        if serializer.is_valid():\n            serializer.save()\n            return Response(serializer.data)\n\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)", "response": "Update existing telegram recipient"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, request, bot_id, hook_id, id, format=None):\n        bot = self.get_bot(bot_id, request.user)\n        hook = self.get_hook(hook_id, bot, request.user)\n        recipient = self.get_recipient(id, hook, request.user)\n        recipient.delete()\n        return Response(status=status.HTTP_204_NO_CONTENT)", "response": "Delete an existing telegram recipient"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, request, bot_id, id, format=None):\n        return super(KikRecipientList, self).get(request, bot_id, id, format)", "response": "Get list of kik recipients of a hook"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, request, bot_id, id, format=None):\n        return super(KikRecipientList, self).post(request, bot_id, id, format)", "response": "Add a new kik recipient to a handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, request, bot_id, id, format=None):\n        return super(MessengerRecipientList, self).get(request, bot_id, id, format)", "response": "Get list of Messenger recipients of a hook."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new messenger recipient to a handler", "response": "def post(self, request, bot_id, id, format=None):\n        \"\"\"\n        Add a new messenger recipient to a handler\n        ---\n        serializer: MessengerRecipientSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"\n        return super(MessengerRecipientList, self).post(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, request, bot_id, format=None):\n        return super(EnvironmentVarList, self).get(request, bot_id, format)", "response": "Get list of environment variables"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post(self, request, bot_id, format=None):\n        return super(EnvironmentVarList, self).post(request, bot_id, format)", "response": "Add a new environment variable to the list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting environment variable by id", "response": "def get(self, request, bot_id, id, format=None):\n        \"\"\"\n        Get environment variable by id\n        ---\n        serializer: EnvironmentVarSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n        \"\"\"        \n        return super(EnvironmentVarDetail, self).get(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates existing environment variable with id", "response": "def put(self, request, bot_id, id, format=None):\n        \"\"\"\n        Update existing environment variable\n        ---\n        serializer: EnvironmentVarSerializer\n        responseMessages:\n            - code: 401\n              message: Not authenticated\n            - code: 400\n              message: Not valid request\n        \"\"\"      \n        return super(EnvironmentVarDetail, self).put(request, bot_id, id, format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, request, bot_id, id, format=None):\n        return super(EnvironmentVarDetail, self).delete(request, bot_id, id, format)", "response": "Delete environment variable with id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses notitication hooks and send a request to a task", "response": "def post(self, request, key):\n        \"\"\"\n        Process notitication hooks:\n            1. Obtain Hook\n            2. Check Auth\n            3. Delay processing to a task\n            4. Respond requester\n        \"\"\"\n        try:\n            hook = Hook.objects.get(key=key, enabled=True)\n        except Hook.DoesNotExist:\n            msg = _(\"Key %s not associated to an enabled hook or bot\") % key\n            logger.warning(msg)\n            return Response(msg, status=status.HTTP_404_NOT_FOUND)\n        if hook.bot.owner != request.user:\n                raise exceptions.AuthenticationFailed()\n        try:\n            parsed_data = request.data\n            logger.debug(\"Hook %s attending request %s\" % (hook, parsed_data))\n            handle_hook.delay(hook.id, parsed_data)\n        except ParseError as e:\n            return Response(str(e), status=status.HTTP_400_BAD_REQUEST)\n        except:\n            exc_info = sys.exc_info()\n            traceback.print_exception(*exc_info)\n            msg = _(\"Error processing %s for key %s\") % (request.data, key)\n            logger.error(msg)\n            return Response(msg, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n        else:\n            return Response(status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess Kik webhook: 1. Get an enabled Kik bot 2. Verify Kik signature 3. Serialize each message 4. For each message create :class:`KikMessage <permabots.models.kik_api.KikMessage>` and :class:`KikUser <permabots.models.kik_api.KikUser>` 5. Delay each message processing to a task 6. Response provider", "response": "def post(self, request, hook_id):\n        \"\"\"\n        Process Kik webhook:\n            1. Get an enabled Kik bot\n            2. Verify Kik signature\n            3. Serialize each message\n            4. For each message create :class:`KikMessage <permabots.models.kik_api.KikMessage>` and :class:`KikUser <permabots.models.kik_api.KikUser>`\n            5. Delay each message processing to a task      \n            6. Response provider\n        \"\"\"\n        try:\n            bot = caching.get_or_set(KikBot, hook_id)\n        except KikBot.DoesNotExist:\n            logger.warning(\"Hook id %s not associated to a bot\" % hook_id)\n            return Response(status=status.HTTP_404_NOT_FOUND)\n        signature = request.META.get('HTTP_X_KIK_SIGNATURE')\n        if signature:\n            signature.encode('utf-8')\n        if not bot._bot.verify_signature(signature, request.stream.body):\n            logger.debug(\"Kik Bot data %s not verified %s\" % (request.data, signature))\n            return Response(status=403)\n        logger.debug(\"Kik Bot data %s verified\" % (request.data))\n        for kik_message in request.data['messages']:\n            serializer = KikMessageSerializer(data=kik_message)   \n            logger.debug(\"Kik message %s serialized\" % (kik_message))\n            if serializer.is_valid():            \n                try:\n                    if not self.accepted_types(serializer):\n                        raise OnlyTextMessages\n                    message = self.create_message(serializer, bot)\n                    if bot.enabled:\n                        logger.debug(\"Kik Bot %s attending request %s\" % (bot, kik_message))\n                        handle_message.delay(message.id, bot.id)\n                    else:\n                        logger.error(\"Message %s ignored by disabled bot %s\" % (message, bot))\n                except OnlyTextMessages:\n                    logger.warning(\"Not text message %s for bot %s\" % (kik_message, hook_id))\n                    return Response(status=status.HTTP_200_OK)\n                except:\n                    exc_info = sys.exc_info()\n                    traceback.print_exception(*exc_info)                \n                    logger.error(\"Error processing %s for bot %s\" % (kik_message, hook_id))\n                    return Response(serializer.errors, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n                   \n            else:\n                logger.error(\"Validation error: %s from kik message %s\" % (serializer.errors, kik_message))\n                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n        return Response(serializer.data, status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride format_name to use renamed format_name if available.", "response": "def _format_value(self, value):\n        \"\"\"This function name was changed in Django 1.10 and removed in 2.0.\"\"\"\n        # Use renamed format_name() for Django versions >= 1.10.\n        if hasattr(self, 'format_value'):\n            return super(DateTimePicker, self).format_value(value)\n        # Use old _format_name() for Django versions < 1.10.\n        else:\n            return super(DateTimePicker, self)._format_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authorize_url(self, client_id, redirect_uri, scope, state=None):\n        params = [\n            ('client_id', client_id),\n            ('redirect_uri', redirect_uri),\n            ('scope', scope)\n        ]\n        if state:\n            params.append(('state', state))\n        return \"%s?%s\" % (CreateSend.oauth_uri, urlencode(params))", "response": "Get the authorization URL for your application given the application s base_url client_id redirect_uri scope and optional state data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exchange_token(self, client_id, client_secret, redirect_uri, code):\n        params = [\n            ('grant_type', 'authorization_code'),\n            ('client_id', client_id),\n            ('client_secret', client_secret),\n            ('redirect_uri', redirect_uri),\n            ('code', code),\n        ]\n        response = self._post('', urlencode(params),\n                              CreateSend.oauth_token_uri, \"application/x-www-form-urlencoded\")\n        access_token, expires_in, refresh_token = None, None, None\n        r = json_to_py(response)\n        if hasattr(r, 'error') and hasattr(r, 'error_description'):\n            err = \"Error exchanging code for access token: \"\n            err += \"%s - %s\" % (r.error, r.error_description)\n            raise Exception(err)\n        access_token, expires_in, refresh_token = r.access_token, r.expires_in, r.refresh_token\n        return [access_token, expires_in, refresh_token]", "response": "Exchange a provided OAuth code for an OAuth access token expires in and refresh token."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrefreshing an OAuth token given a refresh token.", "response": "def refresh_token(self):\n        \"\"\"Refresh an OAuth token given a refresh token.\"\"\"\n        if (not self.auth_details or\n                not 'refresh_token' in self.auth_details or\n                not self.auth_details['refresh_token']):\n            raise Exception(\n                \"auth_details['refresh_token'] does not contain a refresh token.\")\n\n        refresh_token = self.auth_details['refresh_token']\n        params = [\n            ('grant_type', 'refresh_token'),\n            ('refresh_token', refresh_token)\n        ]\n        response = self._post('', urlencode(params),\n                              CreateSend.oauth_token_uri, \"application/x-www-form-urlencoded\")\n        new_access_token, new_expires_in, new_refresh_token = None, None, None\n        r = json_to_py(response)\n        new_access_token, new_expires_in, new_refresh_token = r.access_token, r.expires_in, r.refresh_token\n        self.auth({\n            'access_token': new_access_token,\n            'refresh_token': new_refresh_token})\n        return [new_access_token, new_expires_in, new_refresh_token]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstub a web request for testing.", "response": "def stub_request(self, expected_url, filename, status=None, body=None):\n        \"\"\"Stub a web request for testing.\"\"\"\n        self.fake_web = True\n        self.faker = get_faker(expected_url, filename, status, body)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a request to the ACS API.", "response": "def make_request(self, method, path, params={}, body=\"\", username=None,\n                     password=None, base_uri=None, content_type=None):\n        headers = {\n            'User-Agent': CreateSend.user_agent,\n            'Content-Type': 'application/json; charset=utf-8',\n            'Accept-Encoding': 'gzip, deflate'}\n        if content_type:\n            headers['Content-Type'] = content_type\n        parsed_base_uri = urlparse(\n            CreateSend.base_uri if not base_uri else base_uri)\n        \"\"\"username and password should only be set when it is intended that\n    the default basic authentication mechanism using the API key be\n    overridden (e.g. when using the apikey route with username and password).\"\"\"\n        if username and password:\n            headers['Authorization'] = \"Basic %s\" % base64.b64encode(\n                (\"%s:%s\" % (username, password)).encode()).decode()\n        elif self.auth_details:\n            if 'api_key' in self.auth_details and self.auth_details['api_key']:\n                headers['Authorization'] = \"Basic %s\" % base64.b64encode(\n                    (\"%s:x\" % self.auth_details['api_key']).encode()).decode()\n            elif 'access_token' in self.auth_details and self.auth_details['access_token']:\n                headers['Authorization'] = \"Bearer %s\" % self.auth_details[\n                    'access_token']\n        self.headers = headers\n\n        \"\"\"If in fake web mode (i.e. self.stub_request has been called),\n    self.faker should be set, and this request should be treated as a fake.\"\"\"\n        if self.fake_web:\n            # Check that the actual url which would be requested matches\n            # self.faker.url.\n            actual_url = \"https://%s%s\" % (parsed_base_uri.netloc,\n                                           self.build_url(parsed_base_uri, path, params))\n            self.faker.actual_url = actual_url\n\n            def same_urls(url_a, url_b):\n                a = urlparse(url_a)\n                b = urlparse(url_b)\n                return (a.scheme == b.scheme and\n                        a.netloc == b.netloc and\n                        a.path == b.path and\n                        a.params == b.params and\n                        parse_qs(a.query) == parse_qs(b.query) and\n                        a.fragment == b.fragment\n                        )\n            if not same_urls(self.faker.url, actual_url):\n                raise Exception(\"Faker's expected URL (%s) doesn't match actual URL (%s)\" % (\n                    self.faker.url, actual_url))\n\n            self.faker.actual_body = body\n\n            def same_bodies(body_a, body_b):\n                return json.loads(body_a) == json.loads(body_b)\n            if self.faker.body is not None:\n                if not same_bodies(self.faker.body, body):\n                    raise Exception(\"Faker's expected body (%s) doesn't match actual body (%s)\" % (\n                        self.faker.body, body))\n\n            data = self.faker.open() if self.faker else ''\n            status = self.faker.status if (\n                self.faker and self.faker.status) else 200\n            return self.handle_response(status, data)\n\n        c = VerifiedHTTPSConnection(parsed_base_uri.netloc, timeout=self.timeout)\n        c.request(method, self.build_url(\n            parsed_base_uri, path, params), body, headers)\n        response = c.getresponse()\n        if response.getheader('content-encoding', '') == 'gzip':\n            data = gzip.GzipFile(fileobj=BytesIO(response.read())).read()\n        else:\n            data = response.read()\n        c.close()\n        return self.handle_response(response.status, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a URL which initiates a new external session for the user with the given email.", "response": "def external_session_url(self, email, chrome, url, integrator_id, client_id):\n        \"\"\"\n        Get a URL which initiates a new external session for the user with the\n        given email.\n        Full details: http://www.campaignmonitor.com/api/account/#single_sign_on\n\n        :param email: String The representing the email address of the\n          Campaign Monitor user for whom the login session should be created.\n        :param chrome: String representing which 'chrome' to display - Must be\n          either \"all\", \"tabs\", or \"none\".\n        :param url: String representing the URL to display once logged in.\n          e.g. \"/subscribers/\"\n        :param integrator_id: String representing the Integrator ID. You need to\n          contact Campaign Monitor support to get an Integrator ID.\n        :param client_id: String representing the Client ID of the client which\n          should be active once logged in to the Campaign Monitor account.\n\n        :returns Object containing a single field SessionUrl which represents\n        the URL to initiate the external Campaign Monitor session.\n        \"\"\"\n        body = {\n            \"Email\": email,\n            \"Chrome\": chrome,\n            \"Url\": url,\n            \"IntegratorID\": integrator_id,\n            \"ClientID\": client_id}\n        response = self._put('/externalsession.json', json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a person by client ID and email address.", "response": "def get(self, client_id=None, email_address=None):\n        \"\"\"Gets a person by client ID and email address.\"\"\"\n        params = {\"email\": email_address or self.email_address}\n        response = self._get(\"/clients/%s/people.json\" %\n                             (client_id or self.client_id), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a person to a client.", "response": "def add(self, client_id, email_address, name, access_level, password):\n        \"\"\"Adds a person to a client. Password is optional and if not supplied, an invitation will be emailed to the person\"\"\"\n        body = {\n            \"EmailAddress\": email_address,\n            \"Name\": name,\n            \"AccessLevel\": access_level,\n            \"Password\": password}\n        response = self._post(\"/clients/%s/people.json\" %\n                              client_id, json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, new_email_address, name, access_level, password=None):\n        params = {\"email\": self.email_address}\n        body = {\n            \"EmailAddress\": new_email_address,\n            \"Name\": name,\n            \"AccessLevel\": access_level,\n            \"Password\": password}\n        response = self._put(\"/clients/%s/people.json\" % self.client_id,\n                             body=json.dumps(body), params=params)\n        # Update self.email_address, so this object can continue to be used\n        # reliably\n        self.email_address = new_email_address", "response": "Updates the details for a person."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new campaign for a client.", "response": "def create(self, client_id, subject, name, from_name, from_email, reply_to, html_url,\n               text_url, list_ids, segment_ids):\n        \"\"\"Creates a new campaign for a client.\n\n        :param client_id: String representing the ID of the client for whom the\n          campaign will be created.\n        :param subject: String representing the subject of the campaign.\n        :param name: String representing the name of the campaign.\n        :param from_name: String representing the from name for the campaign.\n        :param from_email: String representing the from address for the campaign.\n        :param reply_to: String representing the reply-to address for the campaign.\n        :param html_url: String representing the URL for the campaign HTML content.\n        :param text_url: String representing the URL for the campaign text content.\n          Note that text_url is optional and if None or an empty string, text\n          content will be automatically generated from the HTML content.\n        :param list_ids: Array of Strings representing the IDs of the lists to\n          which the campaign will be sent.\n        :param segment_ids: Array of Strings representing the IDs of the segments to\n          which the campaign will be sent.\n        :returns String representing the ID of the newly created campaign.\n        \"\"\"\n        body = {\n            \"Subject\": subject,\n            \"Name\": name,\n            \"FromName\": from_name,\n            \"FromEmail\": from_email,\n            \"ReplyTo\": reply_to,\n            \"HtmlUrl\": html_url,\n            \"TextUrl\": text_url,\n            \"ListIDs\": list_ids,\n            \"SegmentIDs\": segment_ids}\n        response = self._post(\"/campaigns/%s.json\" %\n                              client_id, json.dumps(body))\n        self.campaign_id = json_to_py(response)\n        return self.campaign_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_from_template(self, client_id, subject, name, from_name,\n                             from_email, reply_to, list_ids, segment_ids, template_id, template_content):\n        \"\"\"Creates a new campaign for a client, from a template.\n\n        :param client_id: String representing the ID of the client for whom the\n          campaign will be created.\n        :param subject: String representing the subject of the campaign.\n        :param name: String representing the name of the campaign.\n        :param from_name: String representing the from name for the campaign.\n        :param from_email: String representing the from address for the campaign.\n        :param reply_to: String representing the reply-to address for the campaign.\n        :param list_ids: Array of Strings representing the IDs of the lists to\n          which the campaign will be sent.\n        :param segment_ids: Array of Strings representing the IDs of the segments to\n          which the campaign will be sent.\n        :param template_id: String representing the ID of the template on which\n          the campaign will be based.\n        :param template_content: Hash representing the content to be used for the\n          editable areas of the template. See documentation at\n          campaignmonitor.com/api/campaigns/#creating_a_campaign_from_template\n          for full details of template content format.\n        :returns String representing the ID of the newly created campaign.\n        \"\"\"\n        body = {\n            \"Subject\": subject,\n            \"Name\": name,\n            \"FromName\": from_name,\n            \"FromEmail\": from_email,\n            \"ReplyTo\": reply_to,\n            \"ListIDs\": list_ids,\n            \"SegmentIDs\": segment_ids,\n            \"TemplateID\": template_id,\n            \"TemplateContent\": template_content}\n        response = self._post(\"/campaigns/%s/fromtemplate.json\" %\n                              client_id, json.dumps(body))\n        self.campaign_id = json_to_py(response)\n        return self.campaign_id", "response": "Creates a new campaign for a client from a template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a preview of this campaign.", "response": "def send_preview(self, recipients, personalize=\"fallback\"):\n        \"\"\"Sends a preview of this campaign.\"\"\"\n        body = {\n            \"PreviewRecipients\": [recipients] if isinstance(recipients, str) else recipients,\n            \"Personalize\": personalize}\n        response = self._post(self.uri_for(\"sendpreview\"), json.dumps(body))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef opens(self, date=\"\", page=1, page_size=1000, order_field=\"date\", order_direction=\"asc\"):\n        params = {\n            \"date\": date,\n            \"page\": page,\n            \"pagesize\": page_size,\n            \"orderfield\": order_field,\n            \"orderdirection\": order_direction}\n        response = self._get(self.uri_for(\"opens\"), params=params)\n        return json_to_py(response)", "response": "Retrieves the opens for this campaign."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the lists across a client to which a particular email address belongs.", "response": "def lists_for_email(self, email_address):\n        \"\"\"Gets the lists across a client to which a subscriber with a particular\n        email address belongs.\"\"\"\n        params = {\"email\": email_address}\n        response = self._get(self.uri_for(\"listsforemail\"), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets this client s suppression list.", "response": "def suppressionlist(self, page=1, page_size=1000, order_field=\"email\", order_direction=\"asc\"):\n        \"\"\"Gets this client's suppression list.\"\"\"\n        params = {\n            \"page\": page,\n            \"pagesize\": page_size,\n            \"orderfield\": order_field,\n            \"orderdirection\": order_direction}\n        response = self._get(self.uri_for(\"suppressionlist\"), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd email addresses to a client s suppression list", "response": "def suppress(self, email):\n        \"\"\"Adds email addresses to a client's suppression list\"\"\"\n        body = {\n            \"EmailAddresses\": [email] if isinstance(email, str) else email}\n        response = self._post(self.uri_for(\"suppress\"), json.dumps(body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the PAYG billing settings for this client.", "response": "def set_payg_billing(self, currency, can_purchase_credits, client_pays, markup_percentage,\n                         markup_on_delivery=0, markup_per_recipient=0, markup_on_design_spam_test=0):\n        \"\"\"Sets the PAYG billing settings for this client.\"\"\"\n        body = {\n            \"Currency\": currency,\n            \"CanPurchaseCredits\": can_purchase_credits,\n            \"ClientPays\": client_pays,\n            \"MarkupPercentage\": markup_percentage,\n            \"MarkupOnDelivery\": markup_on_delivery,\n            \"MarkupPerRecipient\": markup_per_recipient,\n            \"MarkupOnDesignSpamTest\": markup_on_design_spam_test}\n        response = self._put(self.uri_for('setpaygbilling'), json.dumps(body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_monthly_billing(self, currency, client_pays, markup_percentage, monthly_scheme=None):\n        body = {\n            \"Currency\": currency,\n            \"ClientPays\": client_pays,\n            \"MarkupPercentage\": markup_percentage}\n\n        if monthly_scheme is not None:\n            body[\"MonthlyScheme\"] = monthly_scheme\n\n        response = self._put(self.uri_for(\n            'setmonthlybilling'), json.dumps(body))", "response": "Sets the monthly billing settings for this client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransferring credits to or from this client.", "response": "def transfer_credits(self, credits, can_use_my_credits_when_they_run_out):\n        \"\"\"Transfer credits to or from this client.\n\n        :param credits: An Integer representing the number of credits to transfer.\n          This value may be either positive if you want to allocate credits from\n          your account to the client, or negative if you want to deduct credits\n          from the client back into your account.\n        :param can_use_my_credits_when_they_run_out: A Boolean value representing\n          which, if set to true, will allow the client to continue sending using\n          your credits or payment details once they run out of credits, and if\n          set to false, will prevent the client from using your credits to\n          continue sending until you allocate more credits to them.\n        :returns: An object of the following form representing the result:\n          {\n            AccountCredits # Integer representing credits in your account now\n            ClientCredits # Integer representing credits in this client's\n              account now\n          }\n        \"\"\"\n        body = {\n            \"Credits\": credits,\n            \"CanUseMyCreditsWhenTheyRunOut\": can_use_my_credits_when_they_run_out}\n        response = self._post(self.uri_for('credits'), json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nassigns the primary contact for this client", "response": "def set_primary_contact(self, email):\n        \"\"\"assigns the primary contact for this client\"\"\"\n        params = {\"email\": email}\n        response = self._put(self.uri_for('primarycontact'), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the smart email list.", "response": "def smart_email_list(self, status=\"all\", client_id=None):\n        \"\"\"Gets the smart email list.\"\"\"\n        if client_id is None:\n            response = self._get(\n                \"/transactional/smartEmail?status=%s\" % status)\n        else:\n            response = self._get(\n                \"/transactional/smartEmail?status=%s&clientID=%s\" % (status, client_id))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending the smart email.", "response": "def smart_email_send(self, smart_email_id, to, consent_to_track, cc=None, bcc=None, attachments=None, data=None, add_recipients_to_list=None):\n        \"\"\"Sends the smart email.\"\"\"\n        validate_consent_to_track(consent_to_track)\n        body = {\n            \"To\": to,\n            \"CC\": cc,\n            \"BCC\": bcc,\n            \"Attachments\": attachments,\n            \"Data\": data,\n            \"AddRecipientsToList\": add_recipients_to_list,\n            \"ConsentToTrack\": consent_to_track,\n        }\n        response = self._post(\"/transactional/smartEmail/%s/send\" %\n                              smart_email_id, json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef classic_email_send(self, subject, from_address, to, consent_to_track, client_id=None, cc=None, bcc=None, html=None, text=None, attachments=None, track_opens=True, track_clicks=True, inline_css=True, group=None, add_recipients_to_list=None):\n        validate_consent_to_track(consent_to_track)\n        body = {\n            \"Subject\": subject,\n            \"From\": from_address,\n            \"To\": to,\n            \"CC\": cc,\n            \"BCC\": bcc,\n            \"HTML\": html,\n            \"Text\": text,\n            \"Attachments\": attachments,\n            \"TrackOpens\": track_opens,\n            \"TrackClicks\": track_clicks,\n            \"InlineCSS\": inline_css,\n            \"Group\": group,\n            \"AddRecipientsToList\": add_recipients_to_list,\n            \"ConsentToTrack\": consent_to_track,\n        }\n        if client_id is None:\n            response = self._post(\n                \"/transactional/classicEmail/send\", json.dumps(body))\n        else:\n            response = self._post(\n                \"/transactional/classicEmail/send?clientID=%s\" % client_id, json.dumps(body))\n        return json_to_py(response)", "response": "Sends a classic email."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of classic email groups.", "response": "def classic_email_groups(self, client_id=None):\n        \"\"\"Gets the list of classic email groups.\"\"\"\n        if client_id is None:\n            response = self._get(\"/transactional/classicEmail/groups\")\n        else:\n            response = self._get(\n                \"/transactional/classicEmail/groups?clientID=%s\" % client_id)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the details of a message.", "response": "def message_details(self, message_id, statistics=False):\n        \"\"\"Gets the details of this message.\"\"\"\n        response = self._get(\n            \"/transactional/messages/%s?statistics=%s\" % (message_id, statistics))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, list_id, title, rulegroups):\n        body = {\n            \"Title\": title,\n            \"RuleGroups\": rulegroups}\n        response = self._post(\"/segments/%s.json\" % list_id, json.dumps(body))\n        self.segment_id = json_to_py(response)\n        return self.segment_id", "response": "Creates a new segment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a rulegroup to this segment.", "response": "def add_rulegroup(self, rulegroup):\n        \"\"\"Adds a rulegroup to this segment.\"\"\"\n        body = rulegroup\n        response = self._post(\"/segments/%s/rules.json\" %\n                              self.segment_id, json.dumps(body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the active subscribers in this segment.", "response": "def subscribers(self, date=\"\", page=1, page_size=1000, order_field=\"email\", order_direction=\"asc\", include_tracking_information=False):\n        \"\"\"Gets the active subscribers in this segment.\"\"\"\n        params = {\n            \"date\": date,\n            \"page\": page,\n            \"pagesize\": page_size,\n            \"orderfield\": order_field,\n            \"orderdirection\": order_direction,\n            \"includetrackinginformation\": include_tracking_information\n        }\n        response = self._get(self.uri_for(\"active\"), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new email template.", "response": "def create(self, client_id, name, html_url, zip_url):\n        \"\"\"Creates a new email template.\"\"\"\n        body = {\n            \"Name\": name,\n            \"HtmlPageURL\": html_url,\n            \"ZipFileURL\": zip_url}\n        response = self._post(\"/templates/%s.json\" %\n                              client_id, json.dumps(body))\n        self.template_id = json_to_py(response)\n        return self.template_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, name, html_url, zip_url):\n        body = {\n            \"Name\": name,\n            \"HtmlPageURL\": html_url,\n            \"ZipFileURL\": zip_url}\n        response = self._put(\"/templates/%s.json\" %\n                             self.template_id, json.dumps(body))", "response": "Updates this email template."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an administrator to an account.", "response": "def add(self, email_address, name):\n        \"\"\"Adds an administrator to an account.\"\"\"\n        body = {\n            \"EmailAddress\": email_address,\n            \"Name\": name}\n        response = self._post(\"/admins.json\", json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the details for an administrator.", "response": "def update(self, new_email_address, name):\n        \"\"\"Updates the details for an administrator.\"\"\"\n        params = {\"email\": self.email_address}\n        body = {\n            \"EmailAddress\": new_email_address,\n            \"Name\": name}\n        response = self._put(\"/admins.json\",\n                             body=json.dumps(body), params=params)\n        # Update self.email_address, so this object can continue to be used\n        # reliably\n        self.email_address = new_email_address"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self):\n        params = {\"email\": self.email_address}\n        response = self._delete(\"/admins.json\", params=params)", "response": "Deletes the administrator from the account."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new list for a client.", "response": "def create(self, client_id, title, unsubscribe_page, confirmed_opt_in,\n               confirmation_success_page, unsubscribe_setting=\"AllClientLists\"):\n        \"\"\"Creates a new list for a client.\"\"\"\n        body = {\n            \"Title\": title,\n            \"UnsubscribePage\": unsubscribe_page,\n            \"ConfirmedOptIn\": confirmed_opt_in,\n            \"ConfirmationSuccessPage\": confirmation_success_page,\n            \"UnsubscribeSetting\": unsubscribe_setting}\n        response = self._post(\"/lists/%s.json\" % client_id, json.dumps(body))\n        self.list_id = json_to_py(response)\n        return self.list_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new custom field for this list.", "response": "def create_custom_field(self, field_name, data_type, options=[],\n                            visible_in_preference_center=True):\n        \"\"\"Creates a new custom field for this list.\"\"\"\n        body = {\n            \"FieldName\": field_name,\n            \"DataType\": data_type,\n            \"Options\": options,\n            \"VisibleInPreferenceCenter\": visible_in_preference_center}\n        response = self._post(self.uri_for(\"customfields\"), json.dumps(body))\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_custom_field(self, custom_field_key, field_name,\n                            visible_in_preference_center):\n        \"\"\"Updates a custom field belonging to this list.\"\"\"\n        custom_field_key = quote(custom_field_key, '')\n        body = {\n            \"FieldName\": field_name,\n            \"VisibleInPreferenceCenter\": visible_in_preference_center}\n        response = self._put(self.uri_for(\"customfields/%s\" %\n                                          custom_field_key), json.dumps(body))\n        return json_to_py(response)", "response": "Updates a custom field belonging to this list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a custom field associated with this list.", "response": "def delete_custom_field(self, custom_field_key):\n        \"\"\"Deletes a custom field associated with this list.\"\"\"\n        custom_field_key = quote(custom_field_key, '')\n        response = self._delete(\"/lists/%s/customfields/%s.json\" %\n                                (self.list_id, custom_field_key))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the options of a multi - optioned custom field on this list.", "response": "def update_custom_field_options(self, custom_field_key, new_options,\n                                    keep_existing_options):\n        \"\"\"Updates the options of a multi-optioned custom field on this list.\"\"\"\n        custom_field_key = quote(custom_field_key, '')\n        body = {\n            \"Options\": new_options,\n            \"KeepExistingOptions\": keep_existing_options}\n        response = self._put(self.uri_for(\n            \"customfields/%s/options\" % custom_field_key), json.dumps(body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the active subscribers for this list.", "response": "def active(self, date=\"\", page=1, page_size=1000, order_field=\"email\", order_direction=\"asc\", include_tracking_preference=False):\n        \"\"\"Gets the active subscribers for this list.\"\"\"\n        params = {\n            \"date\": date,\n            \"page\": page,\n            \"pagesize\": page_size,\n            \"orderfield\": order_field,\n            \"orderdirection\": order_direction,\n            \"includetrackingpreference\": include_tracking_preference,\n        }\n        response = self._get(self.uri_for(\"active\"), params=params)\n        return json_to_py(response)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_webhook(self, events, url, payload_format):\n        body = {\n            \"Events\": events,\n            \"Url\": url,\n            \"PayloadFormat\": payload_format}\n        response = self._post(self.uri_for(\"webhooks\"), json.dumps(body))\n        return json_to_py(response)", "response": "Creates a new webhook for the specified events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, list_id=None, email_address=None, include_tracking_preference=False):\n        params = {\n            \"email\": email_address or self.email_address,\n            \"includetrackingpreference\": include_tracking_preference,\n        }\n        response = self._get(\"/subscribers/%s.json\" %\n                             (list_id or self.list_id), params=params)\n        return json_to_py(response)", "response": "Gets a subscriber by list ID and email address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, list_id, email_address, name, custom_fields, resubscribe, consent_to_track, restart_subscription_based_autoresponders=False):\n        validate_consent_to_track(consent_to_track)\n        body = {\n            \"EmailAddress\": email_address,\n            \"Name\": name,\n            \"CustomFields\": custom_fields,\n            \"Resubscribe\": resubscribe,\n            \"ConsentToTrack\": consent_to_track,\n            \"RestartSubscriptionBasedAutoresponders\": restart_subscription_based_autoresponders}\n        response = self._post(\"/subscribers/%s.json\" %\n                              list_id, json.dumps(body))\n        return json_to_py(response)", "response": "Adds a subscriber to a subscriber list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, new_email_address, name, custom_fields, resubscribe, consent_to_track, restart_subscription_based_autoresponders=False):\n        validate_consent_to_track(consent_to_track)\n        params = {\"email\": self.email_address}\n        body = {\n            \"EmailAddress\": new_email_address,\n            \"Name\": name,\n            \"CustomFields\": custom_fields,\n            \"Resubscribe\": resubscribe,\n            \"ConsentToTrack\": consent_to_track,\n            \"RestartSubscriptionBasedAutoresponders\": restart_subscription_based_autoresponders}\n        response = self._put(\"/subscribers/%s.json\" % self.list_id,\n                             body=json.dumps(body), params=params)\n        # Update self.email_address, so this object can continue to be used\n        # reliably\n        self.email_address = new_email_address", "response": "Updates any aspect of a subscriber including email address name and optionally custom field data if supplied."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_subscribers(self, list_id, subscribers, resubscribe, queue_subscription_based_autoresponders=False, restart_subscription_based_autoresponders=False):\n        body = {\n            \"Subscribers\": subscribers,\n            \"Resubscribe\": resubscribe,\n            \"QueueSubscriptionBasedAutoresponders\": queue_subscription_based_autoresponders,\n            \"RestartSubscriptionBasedAutoresponders\": restart_subscription_based_autoresponders}\n        try:\n            response = self._post(\"/subscribers/%s/import.json\" %\n                                  list_id, json.dumps(body))\n        except BadRequest as br:\n            # Subscriber import will throw BadRequest if some subscribers are not imported\n            # successfully. If this occurs, we want to return the ResultData property of\n            # the BadRequest exception (which is of the same \"form\" as the response we'd\n            # receive upon a completely successful import)\n            if hasattr(br.data, 'ResultData'):\n                return br.data.ResultData\n            else:\n                raise br\n        return json_to_py(response)", "response": "Imports subscribers into a subscriber list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef history(self):\n        params = {\"email\": self.email_address}\n        response = self._get(\"/subscribers/%s/history.json\" %\n                             self.list_id, params=params)\n        return json_to_py(response)", "response": "Gets the historical record of this subscriber s trackable actions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mask(n, start, end):\n        columns = []\n        value = 1\n        for i in range(n):\n            if start <= end:\n                columns.append(value if (start <= i < end) else 0)\n            else:\n                columns.append(value if (start <= i or i < end) else 0)\n            value <<= 1\n        return BitColumnMatrix(columns)", "response": "Make a BitColumnMatrix that represents a mask."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering a Django Form with Semantic UI wrappers for each field in form.", "response": "def render_form(form, exclude=None, **kwargs):\r\n\t\"\"\"Render an entire form with Semantic UI wrappers for each field\r\n\t\r\n\tArgs:\r\n\t\tform (form): Django Form\r\n\t\texclude (string): exclude fields by name, separated by commas\r\n\t\tkwargs (dict): other attributes will be passed to fields\r\n\t\r\n\tReturns:\r\n\t\tstring: HTML of Django Form fields with Semantic UI wrappers\r\n\t\"\"\"\r\n\tif hasattr(form, \"Meta\") and hasattr(form.Meta, \"layout\"):\r\n\t\treturn render_layout_form(form, getattr(form.Meta, \"layout\"), **kwargs)\r\n\r\n\tif exclude:\r\n\t\texclude = exclude.split(\",\")\r\n\t\tfor field in exclude:\r\n\t\t\tform.fields.pop(field)\r\n\r\n\treturn mark_safe(\"\".join([\r\n\t\trender_field(field, **kwargs) for field in form\r\n\t]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a form with the given layout.", "response": "def render_layout_form(form, layout=None, **kwargs):\r\n\t\"\"\"Render an entire form with Semantic UI wrappers for each field with\r\n\ta layout provided in the template or in the form class\r\n\t\r\n\tArgs:\r\n\t\tform (form): Django Form\r\n\t\tlayout (tuple): layout design\r\n\t\tkwargs (dict): other attributes will be passed to fields\r\n\t\r\n\tReturns:\r\n\t\tstring: HTML of Django Form fields with Semantic UI wrappers\r\n\t\"\"\"\r\n\tdef make_component(type_, *args):\r\n\t\t\"\"\"Loop through tuples to make field wrappers for fields.\r\n\t\t\"\"\"\r\n\t\tif type_ == \"Text\":\r\n\t\t\treturn \"\".join(args)\r\n\r\n\t\telif type_ == \"Field\":\r\n\t\t\tresult = \"\"\r\n\t\t\tfor c in args:\r\n\t\t\t\tif isinstance(c, tuple):\r\n\t\t\t\t\tresult += make_component(*c)\r\n\t\t\t\telif isinstance(c, str):\r\n\t\t\t\t\tresult += render_field(form.__getitem__(c), **kwargs)\r\n\t\t\treturn result\r\n\t\telse:\r\n\t\t\tif len(args) < 2:\r\n\t\t\t\treturn \"\"\r\n\r\n\t\t\tresult = \"\".join([make_component(*c) for c in args])\r\n\t\t\tif type_:\r\n\t\t\t\treturn \"<div class=\\\"%s\\\">%s</div>\" % (type_.lower(), result)\r\n\t\t\telse:\r\n\t\t\t\treturn result \r\n\r\n\treturn mark_safe(\"\".join([make_component(*component) for component in layout]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_input(self):\r\n\t\tname = self.attrs.get(\"_override\", self.widget.__class__.__name__)\r\n\t\tself.values[\"field\"] = str(FIELDS.get(name, FIELDS.get(None))(self.field, self.attrs))", "response": "Returns form input field of Field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_help(self):\r\n\t\tif not (self.field.help_text and self.attrs.get(\"_help\")):\r\n\t\t\treturn\r\n\r\n\t\tself.values[\"help\"] = HELP_TEMPLATE.format(self.field.help_text)", "response": "Set help text markup."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps current field with icon wrapper.", "response": "def set_icon(self):\r\n\t\t\"\"\"Wrap current field with icon wrapper.\r\n\t\tThis setter must be the last setter called.\r\n\t\t\"\"\"\r\n\t\tif not self.attrs.get(\"_icon\"):\r\n\t\t\treturn\r\n\r\n\t\tif \"Date\" in self.field.field.__class__.__name__:\r\n\t\t\treturn\r\n\r\n\t\tself.values[\"field\"] = INPUT_WRAPPER % {\r\n\t\t\t\"field\": self.values[\"field\"],\r\n\t\t\t\"help\": self.values[\"help\"], \r\n\t\t\t\"style\": \"%sicon \" % escape(pad(self.attrs.get(\"_align\", \"\"))),\r\n\t\t\t\"icon\": format_html(ICON_TEMPLATE, self.attrs.get(\"_icon\")),\r\n\t\t}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_classes(self):\r\n\t\t# Custom field classes on field wrapper\r\n\t\tif self.attrs.get(\"_field_class\"):\r\n\t\t\tself.values[\"class\"].append(escape(self.attrs.get(\"_field_class\")))\r\n\r\n\t\t# Inline class\r\n\t\tif self.attrs.get(\"_inline\"):\r\n\t\t\tself.values[\"class\"].append(\"inline\")\r\n\r\n\t\t# Disabled class\r\n\t\tif self.field.field.disabled:\r\n\t\t\tself.values[\"class\"].append(\"disabled\")\r\n\r\n\t\t# Required class\r\n\t\tif self.field.field.required and not self.attrs.get(\"_no_required\"):\r\n\t\t\tself.values[\"class\"].append(\"required\")\r\n\t\telif self.attrs.get(\"_required\") and not self.field.field.required:\r\n\t\t\tself.values[\"class\"].append(\"required\")", "response": "Set field properties and custom classes on field wrapper."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender field as HTML.", "response": "def render(self):\r\n\t\t\"\"\"Render field as HTML.\r\n\t\t\"\"\"\r\n\t\tself.widget.attrs = {\r\n\t\t\tk: v for k, v in self.attrs.items() if k[0] != \"_\"\r\n\t\t}\r\n\t\tself.set_input()\r\n\r\n\t\tif not self.attrs.get(\"_no_wrapper\"):\r\n\t\t\tself.set_label()\r\n\t\t\tself.set_help()\r\n\t\t\tself.set_errors()\r\n\t\t\tself.set_classes()\r\n\t\t\tself.set_icon()  # Must be the bottom-most setter\r\n\r\n\t\tself.values[\"class\"] = pad(\" \".join(self.values[\"class\"])).lstrip()\r\n\t\tresult = mark_safe(FIELD_WRAPPER % self.values)\r\n\t\tself.widget.attrs = self.attrs  # Re-assign variables\r\n\t\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate test friends for displaying.", "response": "def ready(self):\n\t\t\"\"\"\n\t\tCreate test friends for displaying.\n\t\t\"\"\"\n\t\tfrom .models import Friend\n\n\t\t# Requires migrations, not necessary\n\t\ttry:\n\t\t\tFriend.objects.get_or_create(first_name=\"Michael\", last_name=\"1\", age=22)\n\t\t\tFriend.objects.get_or_create(first_name=\"Joe\", last_name=\"2\", age=21)\n\t\t\tFriend.objects.get_or_create(first_name=\"Bill\", last_name=\"3\", age=20)\n\t\texcept:\n\t\t\tpass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender a BooleanField with label next to instead of above.", "response": "def render_booleanfield(field, attrs):\n\t\"\"\"\n\tRender BooleanField with label next to instead of above.\n\t\"\"\"\n\tattrs.setdefault(\"_no_label\", True)  # No normal label for booleanfields\n\tattrs.setdefault(\"_inline\", True)  # Checkbox should be inline\n\tfield.field.widget.attrs[\"style\"] = \"display:hidden\"  # Hidden field\n\n\treturn wrappers.CHECKBOX_WRAPPER % {\n\t\t\"style\": pad(attrs.get(\"_style\", \"\")),\n\t\t\"field\": field,\n\t\t\"label\": format_html(\n\t\t\twrappers.LABEL_TEMPLATE, field.html_name, mark_safe(field.label)\n\t\t)\n\t}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_choicefield(field, attrs, choices=None):\n\t# Allow custom choice list, but if no custom choice list then wrap all\n\t# choices into the `wrappers.CHOICE_TEMPLATE`\n\tif not choices:\n\t\tchoices = format_html_join(\"\", wrappers.CHOICE_TEMPLATE, get_choices(field))\n\n\t# Accessing the widget attrs directly saves them for a new use after\n\t# a POST request\n\tfield.field.widget.attrs[\"value\"] = field.value() or attrs.get(\"value\", \"\")\n\n\treturn wrappers.DROPDOWN_WRAPPER % {\n\t\t\"name\": field.html_name,\n\t\t\"attrs\": pad(flatatt(field.field.widget.attrs)),\n\t\t\"placeholder\": attrs.get(\"placeholder\") or get_placeholder_text(),\n\t\t\"style\": pad(attrs.get(\"_style\", \"\")),\n\t\t\"icon\": format_html(wrappers.ICON_TEMPLATE, attrs.get(\"_dropdown_icon\") or \"dropdown\"),\n\t\t\"choices\": choices\n\t}", "response": "Render ChoiceField as div dropdown rather than select for more\n\tcustomization."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a ChoiceField with icon support ; where the value is split by a pipe ( | )", "response": "def render_iconchoicefield(field, attrs):\n\t\"\"\"\n\tRender a ChoiceField with icon support; where the value is split by a pipe\n\t(|): first element being the value, last element is the icon.\n\t\"\"\"\n\tchoices = \"\"\n\n\t# Loop over every choice to manipulate\n\tfor choice in field.field._choices:\n\t\tvalue = choice[1].split(\"|\")  # Value|Icon\n\n\t\t# Each choice is formatted with the choice value being split with\n\t\t# the \"|\" as the delimeter. First element is the value, the second\n\t\t# is the icon to be used.\n\t\tchoices += format_html(\n\t\t\twrappers.ICON_CHOICE_TEMPLATE,\n\t\t\tchoice[0],  # Key\n\t\t\tmark_safe(wrappers.ICON_TEMPLATE.format(value[-1])),  # Icon\n\t\t\tvalue[0]  # Value\n\t\t)\n\n\t# Render a dropdown field\n\treturn render_choicefield(field, attrs, choices)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender a custom ChoiceField specific for CountryFields.", "response": "def render_countryfield(field, attrs):\n\t\"\"\"\n\tRender a custom ChoiceField specific for CountryFields.\n\t\"\"\"\n\tchoices = ((k, k.lower(), v)\n\t\tfor k, v in field.field._choices[1:])\n\n\t# Render a `ChoiceField` with all countries\n\treturn render_choicefield(\n\t\tfield, attrs, format_html_join(\"\", wrappers.COUNTRY_TEMPLATE, choices)\n\t)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_multiplechoicefield(field, attrs, choices=None):\n\tchoices = format_html_join(\"\", wrappers.CHOICE_TEMPLATE, get_choices(field))\n\treturn wrappers.MULTIPLE_DROPDOWN_WRAPPER % {\n\t\t\"name\": field.html_name,\n\t\t\"field\": field,\n\t\t\"choices\": choices,\n\t\t\"placeholder\": attrs.get(\"placeholder\") or get_placeholder_text(),\n\t\t\"style\": pad(attrs.get(\"_style\", \"\")),\n\t\t\"icon\": format_html(wrappers.ICON_TEMPLATE, attrs.get(\"_dropdown_icon\") or \"dropdown\"),\n\t}", "response": "Render a multiple choice field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_datefield(field, attrs, style=\"date\"):\n\treturn wrappers.CALENDAR_WRAPPER % {\n\t\t\"field\": field,\n\t\t\"style\": pad(style),\n\t\t\"align\": pad(attrs.get(\"_align\", \"\")),\n\t\t\"icon\": format_html(wrappers.ICON_TEMPLATE, attrs.get(\"_icon\")),\n\t}", "response": "This function renders a date field that uses wrappers. CALENDAR_WRAPPER."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_filefield(field, attrs):\n\tfield.field.widget.attrs[\"style\"] = \"display:none\"\n\n\tif not \"_no_label\" in attrs:\n\t\tattrs[\"_no_label\"] = True\n\n\treturn wrappers.FILE_WRAPPER % {\n\t\t\"field\": field,\n\t\t\"id\": \"id_\" + field.name,\n\t\t\"style\": pad(attrs.get(\"_style\", \"\")),\n\t\t\"text\": escape(attrs.get(\"_text\", \"Select File\")),\n\t\t\"icon\": format_html(wrappers.ICON_TEMPLATE, attrs.get(\"_icon\", \"file outline\"))\n\t}", "response": "Render a typical File Field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over nested containers and iterators.", "response": "def _traverse_iter(o, tree_types=(list, tuple)):\n    \"\"\"Iterate over nested containers and/or iterators.\n    This allows generator __init__() functions to be passed seeds either as\n    a series of arguments, or as a list/tuple.\n    \"\"\"\n    SIMPLERANDOM_BITS = 32\n    SIMPLERANDOM_MOD = 2**SIMPLERANDOM_BITS\n    SIMPLERANDOM_MASK = SIMPLERANDOM_MOD - 1\n    if isinstance(o, tree_types) or getattr(o, '__iter__', False):\n        for value in o:\n            for subvalue in _traverse_iter(value):\n                while True:\n                    yield subvalue & SIMPLERANDOM_MASK\n                    subvalue >>= SIMPLERANDOM_BITS\n                    # If value is negative, then it effectively has infinitely extending\n                    # '1' bits (modelled as a 2's complement representation). So when\n                    # right-shifting it, it will eventually get to -1, and any further\n                    # right-shifting will not change it.\n                    if subvalue == 0 or subvalue == -1:\n                        break\n    else:\n        yield o"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over the input_iter values and repeat the last value CTYPE indefinitely.", "response": "def _repeat_iter(input_iter):\n    \"\"\"Iterate over the input iter values. Then repeat the last value\n    indefinitely. This is useful to repeat seed values when an insufficient\n    number of seeds are provided.\n\n    E.g. KISS(1) effectively becomes KISS(1, 1, 1, 1), rather than (if we just\n    used default values) KISS(1, default-value, default-value, default-value)\n\n    It is better to repeat the last seed value, rather than just using default\n    values. Given two generators seeded with an insufficient number of seeds,\n    repeating the last seed value means their states are more different from\n    each other, with less correlation between their generated outputs.\n    \"\"\"\n    last_value = None\n    for value in input_iter:\n        last_value = value\n        yield value\n    if last_value is not None:\n        while True:\n            yield last_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef seed(self, x=None, *args):\n        if x is None:\n            # Use same random seed code copied from Python's random.Random\n            try:\n                x = long(_hexlify(_urandom(16)), 16)\n            except NotImplementedError:\n                import time\n                x = long(time.time() * 256) # use fractional seconds\n        elif not isinstance(x, _Integral):\n            # Use the hash of the input seed object. Note this does not give\n            # consistent results cross-platform--between Python versions or\n            # between 32-bit and 64-bit systems.\n            x = hash(x)\n        self.rng_iterator.seed(x, *args, mix_extras=True)", "response": "For consistent cross - platform seeding provide an integer seed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setbpf(self, bpf):\n        self._bpf = min(bpf, self.BPF)\n        self._rng_n = int((self._bpf + self.RNG_RANGE_BITS - 1) / self.RNG_RANGE_BITS)", "response": "Set the number of bits per float output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_info(cls):\n        mod = try_import(cls.mod_name)\n        if not mod:\n            return None\n        version = getattr(mod, '__version__', None) or getattr(mod, 'version',\n                                                               None)\n        return BackendInfo(version or 'deprecated', '')", "response": "Return information about backend and its availability."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_choices(field):\n\tempty_label = getattr(field.field, \"empty_label\", False)\n\tneeds_empty_value = False\n\tchoices = []\n\n\t# Data is the choices\n\tif hasattr(field.field, \"_choices\"):\n\t\tchoices = field.field._choices\n\n\t# Data is a queryset\n\telif hasattr(field.field, \"_queryset\"):\n\t\tqueryset = field.field._queryset\n\t\tfield_name = getattr(field.field, \"to_field_name\") or \"pk\"\n\t\tchoices += ((getattr(obj, field_name), str(obj)) for obj in queryset)\n\n\t# Determine if an empty value is needed\n\tif choices and (choices[0][1] == BLANK_CHOICE_DASH[0][1] or choices[0][0]):\n\t\tneeds_empty_value = True\n\n\t\t# Delete empty option\n\t\tif not choices[0][0]:\n\t\t\tdel choices[0]\n\n\t# Remove dashed empty choice\n\tif empty_label == BLANK_CHOICE_DASH[0][1]:\n\t\tempty_label = None\n\n\t# Add custom empty value\n\tif empty_label or not field.field.required:\n\t\tif needs_empty_value:\n\t\t\tchoices.insert(0, (\"\", empty_label or BLANK_CHOICE_DASH[0][1]))\n\n\treturn choices", "response": "Returns a list of choices of a field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _raise_for_status(self, response, explanation=None):\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 404:\n                raise errors.NotFound(e, response, explanation=explanation)\n            raise errors.APIError(e, response, explanation=explanation)", "response": "Raises stored : class : Error if one occurred."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_class_list(cls) -> DOMTokenList:\n        cl = []\n        cl.append(DOMTokenList(cls, cls.class_))\n        if cls.inherit_class:\n            for base_cls in cls.__bases__:\n                if issubclass(base_cls, WdomElement):\n                    cl.append(base_cls.get_class_list())\n        # Reverse order so that parent's class comes to front  <- why?\n        cl.reverse()\n        return DOMTokenList(cls, *cl)", "response": "Get class - level class list including all super classes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving classes from this node.", "response": "def removeClass(self, *classes: str) -> None:\n        \"\"\"[Not Standard] Remove classes from this node.\"\"\"\n        _remove_cl = []\n        for class_ in classes:\n            if class_ not in self.classList:\n                if class_ in self.get_class_list():\n                    logger.warning(\n                        'tried to remove class-level class: '\n                        '{}'.format(class_)\n                    )\n                else:\n                    logger.warning(\n                        'tried to remove non-existing class: {}'.format(class_)\n                    )\n            else:\n                _remove_cl.append(class_)\n        self.classList.remove(*_remove_cl)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend a child node to the last of the child nodes.", "response": "def appendChild(self, child: 'WdomElement') -> Node:\n        \"\"\"Append child node at the last of child nodes.\n\n        If this instance is connected to the node on browser, the child node is\n        also added to it.\n        \"\"\"\n        if self.connected:\n            self._append_child_web(child)\n        return self._append_child(child)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insertBefore(self, child: Node, ref_node: Node) -> Node:\n        if self.connected:\n            self._insert_before_web(child, ref_node)\n        return self._insert_before(child, ref_node)", "response": "Insert new child node before the reference node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef removeChild(self, child: Node) -> Node:\n        if self.connected:\n            self._remove_child_web(child)\n        return self._remove_child(child)", "response": "Remove the child node from this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset textContent both on this node and related browser node.", "response": "def textContent(self, text: str) -> None:  # type: ignore\n        \"\"\"Set textContent both on this node and related browser node.\"\"\"\n        self._set_text_content(text)\n        if self.connected:\n            self._set_text_content_web(text)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef innerHTML(self, html: str) -> None:  # type: ignore\n        df = self._parse_html(html)\n        if self.connected:\n            self._set_inner_html_web(df.html)\n        self._empty()\n        self._append_child(df)", "response": "Set innerHTML both on this node and related browser node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getElementById(id: str) -> Optional[Node]:\n    elm = Element._elements_with_id.get(id)\n    return elm", "response": "Get element with id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget element with wdom_id.", "response": "def getElementByWdomId(id: str) -> Optional[WebEventTarget]:\n    \"\"\"Get element with ``wdom_id``.\"\"\"\n    if not id:\n        return None\n    elif id == 'document':\n        return get_document()\n    elif id == 'window':\n        return get_document().defaultView\n    elm = WdomElement._elements_with_wdom_id.get(id)\n    return elm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_element(tag: str, name: str = None, base: type = None,\n                   attr: dict = None) -> Node:\n    \"\"\"Create element with a tag of ``name``.\n\n    :arg str name: html tag.\n    :arg type base: Base class of the created element\n                       (defatlt: ``WdomElement``)\n    :arg dict attr: Attributes (key-value pairs dict) of the new element.\n    \"\"\"\n    from wdom.web_node import WdomElement\n    from wdom.tag import Tag\n    from wdom.window import customElements\n    if attr is None:\n        attr = {}\n    if name:\n        base_class = customElements.get((name, tag))\n    else:\n        base_class = customElements.get((tag, None))\n    if base_class is None:\n        attr['_registered'] = False\n        base_class = base or WdomElement\n    if issubclass(base_class, Tag):\n        return base_class(**attr)\n    return base_class(tag, **attr)", "response": "Create a new element with a tag of name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_new_document(  # noqa: C901\n        include_wdom_js: bool = True,\n        include_skeleton: bool = False,\n        include_normalizecss: bool = False,\n        autoreload: bool = None,\n        reload_wait: float = None,\n        log_level: Union[int, str] = None,\n        log_prefix: str = None,\n        log_console: bool = False,\n        ws_url: str = None,\n        message_wait: float = None,\n        document_factory: Callable[..., Document] = WdomDocument,\n        **kwargs: Any) -> Document:\n    \"\"\"Create new :class:`Document` object with options.\n\n    :arg bool include_wdom_js: Include wdom.js file. Usually should be True.\n    :arg bool include_skeleton: Include skelton.css.\n    :arg bool include_normalizecss: Include normalize.css.\n    :arg bool autoreload: Enable autoreload flag. This flag overwrites\n        ``--debug`` flag, which automatically enables autoreload.\n    :arg float reload_wait: Seconds to wait until reload when autoreload is\n        enabled.\n    :arg str log_level: Log level string, chosen from DEBUG, INFO, WARN, ERROR.\n        Integer values are also acceptable like ``logging.INFO``. By default\n        use ``wdom.config.options.log_level``, which default is ``INFO``.\n    :arg str log_prefix: Prefix of log outputs.\n    :arg bool log_console: Flag to show wdom log on browser console.\n    :arg str ws_url: URL string to the ws url.\n        Default: ``ws://localhost:8888/wdom_ws``.\n    :arg float message_wait: Duration (seconds) to send WS messages.\n    :arg Callable document_factory: Factory function/class to create Document\n        object.\n    :rtype: Document\n    \"\"\"\n    document = document_factory(\n        autoreload=autoreload,\n        reload_wait=reload_wait,\n        **kwargs\n    )\n\n    if log_level is None:\n        log_level = config.logging\n    if message_wait is None:\n        message_wait = config.message_wait\n\n    log_script = []\n    log_script.append('var WDOM_MESSAGE_WAIT = {}'.format(message_wait))\n    if isinstance(log_level, str):\n        log_script.append('var WDOM_LOG_LEVEL = \\'{}\\''.format(log_level))\n    elif isinstance(log_level, int):\n        log_script.append('var WDOM_LOG_LEVEL = {}'.format(log_level))\n    if log_prefix:\n        log_script.append('var WDOM_LOG_PREFIX = \\'{}\\''.format(log_prefix))\n    if log_console:\n        log_script.append('var WDOM_LOG_CONSOLE = true')\n    if log_script:\n        _s = Script(parent=document.head)\n        _s.textContent = '\\n{}\\n'.format('\\n'.join(log_script))\n\n    if ws_url:\n        _s = Script(parent=document.head)\n        _s.textContent = '\\nvar WDOM_WS_URL = \\'{}\\'\\n'.format(ws_url)\n\n    if include_wdom_js:\n        document.add_jsfile_head('_static/js/wdom.js')\n\n    return document", "response": "Create a new document object with options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef characterSet(self, charset: str) -> None:\n        charset_node = self._find_charset_node() or Meta(parent=self.head)\n        charset_node.setAttribute('charset', charset)", "response": "Set character set of this document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets elements in this document which matches condition.", "response": "def getElementsBy(self, cond: Callable[[Element], bool]) -> NodeList:\n        \"\"\"Get elements in this document which matches condition.\"\"\"\n        return getElementsBy(self, cond)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getElementById(self, id: str) -> Optional[Node]:\n        elm = getElementById(id)\n        if elm and elm.ownerDocument is self:\n            return elm\n        return None", "response": "Get element by id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createElement(self, tag: str) -> Node:\n        return create_element(tag, base=self._default_class)", "response": "Create new element whose tag name is tag."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getElementByWdomId(self, id: Union[str]) -> Optional[WebEventTarget]:\n        elm = getElementByWdomId(id)\n        if elm and elm.ownerDocument is self:\n            return elm\n        return None", "response": "Get an element node with wdom_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a JS file to the bottom of the document.", "response": "def add_jsfile(self, src: str) -> None:\n        \"\"\"Add JS file to load at this document's bottom of the body.\"\"\"\n        self.body.appendChild(Script(src=src))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_jsfile_head(self, src: str) -> None:\n        self.head.appendChild(Script(src=src))", "response": "Add a JS file to the document s header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd CSS file to the document s header.", "response": "def add_cssfile(self, src: str) -> None:\n        \"\"\"Add CSS file to load at this document's header.\"\"\"\n        self.head.appendChild(Link(rel='stylesheet', href=src))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_theme(self, theme: ModuleType) -> None:\n        if not hasattr(theme, 'css_files'):\n            raise ValueError('theme module must include `css_files`.')\n        for css in getattr(theme, 'css_files', []):\n            self.add_cssfile(css)\n        for js in getattr(theme, 'js_files', []):\n            self.add_jsfile(js)\n        for header in getattr(theme, 'headers', []):\n            self.add_header(header)\n        for cls in getattr(theme, 'extended_classes', []):\n            self.defaultView.customElements.define(cls)", "response": "Register a theme module with this docuemnt."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn HTML representation of this document.", "response": "def build(self) -> str:\n        \"\"\"Return HTML representation of this document.\"\"\"\n        self._set_autoreload()\n        return ''.join(child.html for child in self.childNodes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget /chain/blocks/{Block} Use the Block API to retrieve the contents of various blocks from the blockchain. The returned Block message structure is defined inside fabric.proto. ```golang message Block { uint32 version = 1; google.protobuf.Timestamp Timestamp = 2; repeated Transaction transactions = 3; bytes stateHash = 4; bytes previousBlockHash = 5; } ``` :param block: The id of the block to retrieve :return: json body of the block info", "response": "def block_get(self, block):\n        \"\"\" GET /chain/blocks/{Block}\n\n        Use the Block API to retrieve the contents of various blocks from the\n        blockchain. The returned Block message structure is defined inside\n        fabric.proto.\n\n        ```golang\n        message Block {\n            uint32 version = 1;\n            google.protobuf.Timestamp Timestamp = 2;\n            repeated Transaction transactions = 3;\n            bytes stateHash = 4;\n            bytes previousBlockHash = 5;\n        }\n        ```\n\n        :param block: The id of the block to retrieve\n        :return: json body of the block info\n        \"\"\"\n        res = self._get(self._url(\"/chain/blocks/{0}\", block))\n        return self._result(res, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_message() -> None:\n    if not _msg_queue:\n        return\n    msg = json.dumps(_msg_queue)\n    _msg_queue.clear()\n    for conn in module.connections:\n        conn.write_message(msg)", "response": "Send a message via all client connections."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_static_path(prefix: str, path: str, no_watch: bool = False) -> None:\n    app = get_app()\n    app.add_static_path(prefix, path)\n    if not no_watch:\n        watch_dir(path)", "response": "Add a directory to serve static files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts web server on address and port.", "response": "def start_server(address: str = None, port: int = None,\n                 check_time: int = 500, **kwargs: Any) -> module.HTTPServer:\n    \"\"\"Start web server on ``address:port``.\n\n    Use wrapper function :func:`start` instead.\n\n    :arg str address: address of the server [default: localhost].\n    :arg int port: tcp port of the server [default: 8888].\n    :arg int check_time: millisecondes to wait until reload browser when\n        autoreload is enabled [default: 500].\n    \"\"\"\n    # Add application's static files directory\n    from wdom.document import get_document\n    add_static_path('_static', STATIC_DIR)\n    doc = get_document()\n    if os.path.exists(doc.tempdir):\n        add_static_path('tmp', doc.tempdir, no_watch=True)\n    if doc._autoreload or config.autoreload or config.debug:\n        autoreload.start(check_time=check_time)\n    global _server\n    _server = module.start_server(address=address, port=port, **kwargs)\n    logger.info('Start server on {0}:{1:d}'.format(\n        server_config['address'], server_config['port']))\n\n    # start messaging loop\n    asyncio.ensure_future(_message_loop())\n\n    if config.open_browser:\n        open_browser('http://{}:{}/'.format(server_config['address'],\n                                            server_config['port']),\n                     config.browser)\n    return _server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(**kwargs: Any) -> None:\n    start_server(**kwargs)\n    try:\n        asyncio.get_event_loop().run_forever()\n    except KeyboardInterrupt:\n        stop_server()", "response": "Start web server.\n\n    Run until ``Ctrl-c`` pressed, or if auto-shutdown is enabled, until when\n    all browser windows are closed.\n\n    This function accepts keyword areguments same as :func:`start_server` and\n    all arguments passed to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding new custom element.", "response": "def define(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Add new custom element.\"\"\"\n        if isinstance(args[0], str):\n            self._define_orig(*args, **kwargs)\n        elif isinstance(args[0], type):\n            self._define_class(*args, **kwargs)\n        else:\n            raise TypeError(\n                'Invalid argument for define: {}, {}'.format(args, kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_handler(level: str, message: str) -> None:\n    message = 'JS: ' + str(message)\n    if level == 'error':\n        logger.error(message)\n    elif level == 'warn':\n        logger.warning(message)\n    elif level == 'info':\n        logger.info(message)\n    elif level == 'debug':\n        logger.debug(message)", "response": "Handle logs from client ( browser )."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle events emitted on browser.", "response": "def event_handler(msg: EventMsgDict) -> Event:\n    \"\"\"Handle events emitted on browser.\"\"\"\n    e = create_event_from_msg(msg)\n    if e.currentTarget is None:\n        if e.type not in ['mount', 'unmount']:\n            id = msg['currentTarget']['id']\n            logger.warning('No such element: wdom_id={}'.format(id))\n        return e\n    e.currentTarget.on_event_pre(e)\n    e.currentTarget.dispatchEvent(e)\n    return e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef response_handler(msg: Dict[str, str]) -> None:\n    from wdom.document import getElementByWdomId\n    id = msg['id']\n    elm = getElementByWdomId(id)\n    if elm:\n        elm.on_response(msg)\n    else:\n        logger.warning('No such element: wdom_id={}'.format(id))", "response": "Handle response sent by browser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle messages from browser.", "response": "def on_websocket_message(message: str) -> None:\n    \"\"\"Handle messages from browser.\"\"\"\n    msgs = json.loads(message)\n    for msg in msgs:\n        if not isinstance(msg, dict):\n            logger.error('Invalid WS message format: {}'.format(message))\n            continue\n        _type = msg.get('type')\n        if _type == 'log':\n            log_handler(msg['level'], msg['message'])\n        elif _type == 'event':\n            event_handler(msg['event'])\n        elif _type == 'response':\n            response_handler(msg)\n        else:\n            raise ValueError('Unkown message type: {}'.format(message))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses HTML fragment and return DocumentFragment object.", "response": "def parse_html(html: str, parser: FragmentParser = None) -> Node:\n    \"\"\"Parse HTML fragment and return DocumentFragment object.\n\n    DocumentFragment object has parsed Node objects as its child nodes.\n    \"\"\"\n    parser = parser or FragmentParser()\n    parser.feed(html)\n    return parser.root"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of child elements of start_node which matches cond.", "response": "def getElementsBy(start_node: ParentNode,\n                  cond: Callable[['Element'], bool]) -> NodeList:\n    \"\"\"Return list of child elements of start_node which matches ``cond``.\n\n    ``cond`` must be a function which gets a single argument ``Element``,\n    and returns boolean. If the node matches requested condition, ``cond``\n    should return True.\n    This searches all child elements recursively.\n\n    :arg ParentNode start_node:\n    :arg cond: Callable[[Element], bool]\n    :rtype: NodeList[Element]\n    \"\"\"\n    elements = []\n    for child in start_node.children:\n        if cond(child):\n            elements.append(child)\n        elements.extend(child.getElementsBy(cond))\n    return NodeList(elements)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getElementsByTagName(start_node: ParentNode, tag: str) -> NodeList:\n    _tag = tag.upper()\n    return getElementsBy(start_node, lambda node: node.tagName == _tag)", "response": "Get child nodes which tag name is tag."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getElementsByClassName(start_node: ParentNode, class_name: str\n                           ) -> NodeList:\n    \"\"\"Get child nodes which has ``class_name`` class attribute.\"\"\"\n    classes = set(class_name.split(' '))\n    return getElementsBy(\n        start_node,\n        lambda node: classes.issubset(set(node.classList))\n    )", "response": "Get child nodes which has class_name class attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, *tokens: str) -> None:\n        from wdom.web_node import WdomElement\n        _new_tokens = []\n        for token in tokens:\n            self._validate_token(token)\n            if token and token not in self:\n                self._list.append(token)\n                _new_tokens.append(token)\n        if isinstance(self._owner, WdomElement) and _new_tokens:\n            self._owner.js_exec('addClass', _new_tokens)", "response": "Add new tokens to list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, *tokens: str) -> None:\n        from wdom.web_node import WdomElement\n        _removed_tokens = []\n        for token in tokens:\n            self._validate_token(token)\n            if token in self:\n                self._list.remove(token)\n                _removed_tokens.append(token)\n        if isinstance(self._owner, WdomElement) and _removed_tokens:\n            self._owner.js_exec('removeClass', _removed_tokens)", "response": "Removes the specified tokens from the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd or remove a token from the list.", "response": "def toggle(self, token: str) -> None:\n        \"\"\"Add or remove token to/from list.\n\n        If token is in this list, the token will be removed. Otherwise add it\n        to list.\n        \"\"\"\n        self._validate_token(token)\n        if token in self:\n            self.remove(token)\n        else:\n            self.add(token)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns if the token is in the list.", "response": "def contains(self, token: str) -> bool:\n        \"\"\"Return if the token is in the list or not.\"\"\"\n        self._validate_token(token)\n        return token in self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html(self) -> str:\n        if self._owner and self.name in self._owner._special_attr_boolean:\n            return self.name\n        else:\n            value = self.value\n            if isinstance(value, str):\n                value = html_.escape(value)\n            return '{name}=\"{value}\"'.format(name=self.name, value=value)", "response": "Return string representation of this."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef html(self) -> str:\n        if isinstance(self.value, bool):\n            val = 'true' if self.value else 'false'\n        else:\n            val = str(self.value)\n        return 'draggable=\"{}\"'.format(val)", "response": "Return html representation of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getNamedItem(self, name: str) -> Optional[Attr]:\n        return self._dict.get(name, None)", "response": "Get the named attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setNamedItem(self, item: Attr) -> None:\n        from wdom.web_node import WdomElement\n        if not isinstance(item, Attr):\n            raise TypeError('item must be an instance of Attr')\n        if isinstance(self._owner, WdomElement):\n            self._owner.js_exec('setAttribute', item.name,  # type: ignore\n                                item.value)\n        self._dict[item.name] = item\n        item._owner = self._owner", "response": "Set the named attribute in this collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef removeNamedItem(self, item: Attr) -> Optional[Attr]:\n        from wdom.web_node import WdomElement\n        if not isinstance(item, Attr):\n            raise TypeError('item must be an instance of Attr')\n        if isinstance(self._owner, WdomElement):\n            self._owner.js_exec('removeAttribute', item.name)\n        removed_item = self._dict.pop(item.name, None)\n        if removed_item:\n            removed_item._owner = self._owner\n        return removed_item", "response": "Remove an attribute from the set and return it if exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef item(self, index: int) -> Optional[Attr]:\n        if 0 <= index < len(self):\n            return self._dict[tuple(self._dict.keys())[index]]\n        return None", "response": "Return index - th attr node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning string representation of collections.", "response": "def toString(self) -> str:\n        \"\"\"Return string representation of collections.\"\"\"\n        return ' '.join(attr.html for attr in self._dict.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_tag(self) -> str:\n        tag = '<' + self.tag\n        attrs = self._get_attrs_by_string()\n        if attrs:\n            tag = ' '.join((tag, attrs))\n        return tag + '>'", "response": "Return HTML start tag."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insertAdjacentHTML(self, position: str, html: str) -> None:\n        df = self._parse_html(html)\n        pos = position.lower()\n        if pos == 'beforebegin':\n            self.before(df)\n        elif pos == 'afterbegin':\n            self.prepend(df)\n        elif pos == 'beforeend':\n            self.append(df)\n        elif pos == 'afterend':\n            self.after(df)\n        else:\n            raise ValueError(\n                'The value provided ({}) is not one of \"beforeBegin\", '\n                '\"afterBegin\", \"beforeEnd\", or \"afterEnd\".'.format(position)\n            )", "response": "Parse html to DOM and insert to position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget attribute of this node as string format.", "response": "def getAttribute(self, attr: str) -> _AttrValueType:\n        \"\"\"Get attribute of this node as string format.\n\n        If this node does not have ``attr``, return None.\n        \"\"\"\n        if attr == 'class':\n            if self.classList:\n                return self.classList.toString()\n            return None\n        attr_node = self.getAttributeNode(attr)\n        if attr_node is None:\n            return None\n        return attr_node.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets attribute of this node as Attr format.", "response": "def getAttributeNode(self, attr: str) -> Optional[Attr]:\n        \"\"\"Get attribute of this node as Attr format.\n\n        If this node does not have ``attr``, return None.\n        \"\"\"\n        return self.attributes.getNamedItem(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hasAttribute(self, attr: str) -> bool:\n        if attr == 'class':\n            return bool(self.classList)\n        return attr in self.attributes", "response": "Return True if this node has attr."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setAttribute(self, attr: str, value: _AttrValueType) -> None:\n        self._set_attribute(attr, value)", "response": "Set the attribute of this node to the given value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an attribute node from this node.", "response": "def removeAttributeNode(self, attr: Attr) -> Optional[Attr]:\n        \"\"\"Remove ``Attr`` node from this node.\"\"\"\n        return self.attributes.removeNamedItem(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the style attribute of this node.", "response": "def style(self, style: _AttrValueType) -> None:\n        \"\"\"Set style attribute of this node.\n\n        If argument ``style`` is string, it will be parsed to\n        ``CSSStyleDeclaration``.\n        \"\"\"\n        if isinstance(style, str):\n            self.__style._parse_str(style)\n        elif style is None:\n            self.__style._parse_str('')\n        elif isinstance(style, CSSStyleDeclaration):\n            self.__style._owner = None\n            if style._owner is not None:\n                new_style = CSSStyleDeclaration(owner=self)\n                new_style.update(style)\n                self.__style = new_style\n            else:\n                # always making new decl may be better\n                style._owner = self\n                self.__style = style\n        else:\n            raise TypeError('Invalid type for style: {}'.format(type(style)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the draggable property.", "response": "def draggable(self) -> Union[bool, str]:\n        \"\"\"Get ``draggable`` property.\"\"\"\n        if not self.hasAttribute('draggable'):\n            return False\n        return self.getAttribute('draggable')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets ``draggable`` property. ``value`` is boolean or string.", "response": "def draggable(self, value: Union[bool, str]) -> None:\n        \"\"\"Set ``draggable`` property.\n\n        ``value`` is boolean or string.\n        \"\"\"\n        if value is False:\n            self.removeAttribute('draggable')\n        else:\n            self.setAttribute('draggable', value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef form(self) -> Optional['HTMLFormElement']:\n        if self.__form:\n            return self.__form\n        parent = self.parentNode\n        while parent:\n            if isinstance(parent, HTMLFormElement):\n                return parent\n            else:\n                parent = parent.parentNode\n        return None", "response": "Get the HTMLFormElement object related to this node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_event_pre(self, e: Event) -> None:\n        super().on_event_pre(e)\n        ct_msg = e.init.get('currentTarget', dict())\n        if e.type in ('input', 'change'):\n            # Update user inputs\n            if self.type.lower() == 'checkbox':\n                self._set_attribute('checked', ct_msg.get('checked'))\n            elif self.type.lower() == 'radio':\n                self._set_attribute('checked', ct_msg.get('checked'))\n                for other in self._find_grouped_nodes():\n                    if other is not self:\n                        other._remove_attribute('checked')\n            else:\n                self._set_attribute('value', ct_msg.get('value'))", "response": "Set values set on browser before calling event listeners."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef control(self) -> Optional[HTMLElement]:\n        id = self.getAttribute('for')\n        if id:\n            if self.ownerDocument:\n                return self.ownerDocument.getElementById(id)\n            elif isinstance(id, str):\n                from wdom.document import getElementById\n                return getElementById(id)\n            else:\n                raise TypeError('\"for\" attribute must be string')\n        return None", "response": "Return related HTMLElement object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_event_pre(self, e: Event) -> None:\n        super().on_event_pre(e)\n        ct_msg = e.init.get('currentTarget', dict())\n        if e.type in ('input', 'change'):\n            self._set_attribute('value', ct_msg.get('value'))\n            _selected = ct_msg.get('selectedOptions', [])\n            self._selected_options.clear()\n            for opt in self.options:\n                if opt.wdom_id in _selected:\n                    self._selected_options.append(opt)\n                    opt._set_attribute('selected', True)\n                else:\n                    opt._remove_attribute('selected')", "response": "Set values set on browser before calling event listeners."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all selected option nodes.", "response": "def selectedOptions(self) -> NodeList:\n        \"\"\"Return all selected option nodes.\"\"\"\n        return NodeList(list(opt for opt in self.options if opt.selected))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets values set on browser before calling event listeners.", "response": "def on_event_pre(self, e: Event) -> None:\n        \"\"\"Set values set on browser before calling event listeners.\"\"\"\n        super().on_event_pre(e)\n        ct_msg = e.init.get('currentTarget', dict())\n        if e.type in ('input', 'change'):\n            # Update user inputs\n            self._set_text_content(ct_msg.get('value') or '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef NewTagClass(class_name: str, tag: str = None,\n                bases: Union[type, Iterable] = (Tag, ),\n                **kwargs: Any) -> type:\n    \"\"\"Generate and return new ``Tag`` class.\n\n    If ``tag`` is empty, lower case of ``class_name`` is used for a tag name of\n    the new class. ``bases`` should be a tuple of base classes. If it is empty,\n    use ``Tag`` class for a base class. Other keyword arguments are used for\n    class variables of the new class.\n\n    Example::\n\n        MyButton = NewTagClass('MyButton', 'button', (Button,),\n                               class_='btn', is_='my-button')\n        my_button = MyButton('Click!')\n        print(my_button.html)\n\n        >>> <button class=\"btn\" id=\"111111111\" is=\"my-button\">Click!</button>\n    \"\"\"\n    if tag is None:\n        tag = class_name.lower()\n    if not isinstance(type, tuple):\n        if isinstance(bases, Iterable):\n            bases = tuple(bases)\n        elif isinstance(bases, type):\n            bases = (bases, )\n        else:\n            TypeError('Invalid base class: {}'.format(str(bases)))\n    kwargs['tag'] = tag\n    # Here not use type() function, since it does not support\n    # metaclasss (__prepare__) properly.\n    cls = new_class(  # type: ignore\n        class_name, bases, {}, lambda ns: ns.update(kwargs))\n    return cls", "response": "Generate and return a new Tag class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clone_node(self) -> 'Tag':\n        clone = type(self)()\n        for attr in self.attributes:\n            clone.setAttribute(attr, self.getAttribute(attr))\n        for c in self.classList:\n            clone.addClass(c)\n        clone.style.update(self.style)\n        # TODO: should clone event listeners???\n        return clone", "response": "Need to copy class, not tag.\n\n        So need to re-implement copy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef textContent(self, text: str) -> None:  # type: ignore\n        if self._inner_element:\n            self._inner_element.textContent = text\n        else:\n            # Need a trick to call property of super-class\n            super().textContent = text", "response": "Set text content to inner node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html(self) -> str:\n        if self._inner_element:\n            return self.start_tag + self._inner_element.html + self.end_tag\n        return super().html", "response": "Get whole html representation of this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef innerHTML(self) -> str:\n        if self._inner_element:\n            return self._inner_element.innerHTML\n        return super().innerHTML", "response": "Get innerHTML of the inner node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts server with app on localhost : port.", "response": "def start_server(app: web.Application = None, port: int = None,\n                 address: str = None, **kwargs: Any) -> HTTPServer:\n    \"\"\"Start server with ``app`` on ``localhost:port``.\n\n    If port is not specified, use command line option of ``--port``.\n    \"\"\"\n    app = app or get_app()\n    port = port if port is not None else config.port\n    address = address if address is not None else config.address\n\n    server = app.listen(port, address=address)\n    app.server = server\n    app.loop = asyncio.get_event_loop()\n    server_config['address'] = address\n    for sock in server._sockets.values():\n        if sock.family == socket.AF_INET:\n            server_config['port'] = sock.getsockname()[1]\n            break\n    return server"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self) -> None:\n        from wdom.document import get_document\n        logger.info('connected')\n        self.write(get_document().build())", "response": "Return whole html representation of the root document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def terminate(self) -> None:\n        await asyncio.sleep(config.shutdown_wait)\n        # stop server and close loop if no more connection exists\n        if not is_connected():\n            stop_server(self.application.server)\n            self.application.loop.stop()", "response": "Terminate server and loop if no more connection exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_close(self) -> None:\n        logger.info('WebSocket CLOSED')\n        if self in connections:\n            # Remove this connection from connection-list\n            connections.remove(self)\n        # close if auto_shutdown is enabled and there is no more connection\n        if config.auto_shutdown and not is_connected():\n            asyncio.ensure_future(self.terminate())", "response": "Execute when the connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_static_path(self, prefix: str, path: str) -> None:\n        pattern = prefix\n        if not pattern.startswith('/'):\n            pattern = '/' + pattern\n        if not pattern.endswith('/(.*)'):\n            pattern = pattern + '/(.*)'\n        self.add_handlers(\n            r'.*',  # add static path for all virtual host\n            [(pattern, StaticFileHandler, dict(path=path))]\n        )", "response": "Add path to serve static files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd path to serve favicon file.", "response": "def add_favicon_path(self, path: str) -> None:\n        \"\"\"Add path to serve favicon file.\n\n        ``path`` should be a directory, which contains favicon file\n        (``favicon.ico``) for your app.\n        \"\"\"\n        spec = web.URLSpec(\n            '/(favicon.ico)',\n            StaticFileHandler,\n            dict(path=path)\n        )\n        # Need some check\n        handlers = self.handlers[0][1]\n        handlers.append(spec)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeploys a new chaincode", "response": "def chaincode_deploy(self, chaincode_path=DEFAULT_CHAINCODE_PATH,\n                         type=CHAINCODE_LANG_GO,\n                         function=DEFAULT_CHAINCODE_INIT_FUNC,\n                         args=DEFAULT_CHAINCODE_INIT_ARGS, id=1,\n                         secure_context=None,\n                         confidentiality_level=CHAINCODE_CONFIDENTIAL_PUB,\n                         metadata=None,\n                         chaincode_name=None):\n        \"\"\"\n        POST host:port/chaincode\n\n        {\n          \"jsonrpc\": \"2.0\",\n          \"method\": \"deploy\",\n          \"params\": {\n            \"type\": 1,\n            \"chaincodeID\":{\n                \"path\":\"github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\"\n            },\n            \"ctorMsg\": {\n            \"function\":\"init\",\n            \"args\":[\"a\", \"1000\", \"b\", \"2000\"]\n            }\n          },\n          \"id\": 1\n        }\n\n        :param chaincode_path: path of the chaincode in local or repo URL\n        :param type:\n        :param function:\n        :param args:\n        :param id:\n        :param secure_context:\n        :param confidentiality_level:\n        :param metadata:\n        :param chaincode_name: chaincode name is only required in dev mode. If\n        chaincode_name then chaincodeID will use chaincode_name\n        :return: json obj of the chaincode instance\n        \"\"\"\n        chaincodeID = {\"name\": chaincode_name} if chaincode_name else \\\n                      {\"path\": chaincode_path}\n        return self._exec_action(method=\"deploy\", type=type,\n                                 chaincodeID=chaincodeID,\n                                 function=function, args=args, id=id,\n                                 secure_context=secure_context,\n                                 confidentiality_level=confidentiality_level,\n                                 metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chaincode_query(self, chaincode_name, type=CHAINCODE_LANG_GO,\n                        function=\"query\",\n                        args=[\"a\"], id=1,\n                        secure_context=None,\n                        confidentiality_level=CHAINCODE_CONFIDENTIAL_PUB,\n                        metadata=None):\n        \"\"\"\n        {\n          \"jsonrpc\": \"2.0\",\n          \"method\": \"query\",\n          \"params\": {\n              \"type\": 1,\n              \"chaincodeID\":{\n                  \"name\":\"52b0d803fc395b5e34d8d4a7cd69fb6aa00099b8fabed83504ac1c5d61a425aca5b3ad3bf96643ea4fdaac132c417c37b00f88fa800de7ece387d008a76d3586\"\n              },\n              \"ctorMsg\": {\n                 \"function\":\"query\",\n                 \"args\":[\"a\"]\n              }\n          },\n          \"id\": 3\n        }\n        :return: json obj of the chaincode instance\n        \"\"\"\n        return self._exec_action(method=\"query\", type=type,\n                                 chaincodeID={\"name\": chaincode_name},\n                                 function=function, args=args, id=id,\n                                 secure_context=secure_context,\n                                 confidentiality_level=confidentiality_level,\n                                 metadata=metadata)", "response": "This method is used to query the metadata of a specific chaincode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_connection(self, *args, **kwargs):\n        conn = super(SSLAdapter, self).get_connection(*args, **kwargs)\n        if conn.assert_hostname != self.assert_hostname:\n            conn.assert_hostname = self.assert_hostname\n        return conn", "response": "Override get_connection to set the assert_hostname to the current value of the assert_hostname attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget / chain get the current state of the blockchain", "response": "def chain_list(self):\n        \"\"\" GET /chain\n\n        Use the Chain API to retrieve the current state of the blockchain.\n        The returned BlockchainInfo message is defined inside fabric.proto.\n\n        message BlockchainInfo {\n            uint64 height = 1;\n            bytes currentBlockHash = 2;\n            bytes previousBlockHash = 3;\n        }\n        ```\n\n        :return: json body of the blockchain info\n        \"\"\"\n        res = self._get(self._url(\"/chain\"))\n        return self._result(res, True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef peer_list(self):\n        res = self._get(self._url(\"/network/peers\"))\n        return self._result(res, True)", "response": "GET / network / peers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transaction_get(self, tran_uuid):\n        res = self._get(self._url(\"/transactions/{0}\", tran_uuid))\n        return self._result(res, json=True)", "response": "This endpoint returns the JSON body of the individual\n        transaction with the given UUID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd path to watch for autoreload.", "response": "def watch_dir(path: str) -> None:\n    \"\"\"Add ``path`` to watch for autoreload.\"\"\"\n    _compile_exclude_patterns()\n    if config.autoreload or config.debug:\n        # Add files to watch for autoreload\n        p = pathlib.Path(path)\n        p.resolve()\n        _add_watch_path(p)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the enrollment ID info.", "response": "def enrollmentID_get(self, enrollment_id):\n        \"\"\" GET /registrar/{enrollmentID}\n\n        Use the Registrar APIs to manage end user registration with the CA.\n        ```golang\n        message Block {\n            uint32 version = 1;\n            google.protobuf.Timestamp Timestamp = 2;\n            repeated Transaction transactions = 3;\n            bytes stateHash = 4;\n            bytes previousBlockHash = 5;\n        }\n        ```\n\n        :param enrollment_id: The id of the enrollment to retrieve\n        :return: json body of the enrollmentID info\n        \"\"\"\n        res = self._get(self._url(\"/registrar/{0}\", enrollment_id))\n        return self._result(res, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes CSSStyleDeclaration from style string.", "response": "def parse_style_decl(style: str, owner: AbstractNode = None\n                     ) -> CSSStyleDeclaration:\n    \"\"\"Make CSSStyleDeclaration from style string.\n\n    :arg AbstractNode owner: Owner of the style.\n    \"\"\"\n    _style = CSSStyleDeclaration(style, owner=owner)\n    return _style"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_style_rules(styles: str) -> CSSRuleList:\n    rules = CSSRuleList()\n    for m in _style_rule_re.finditer(styles):\n        rules.append(CSSStyleRule(m.group(1), parse_style_decl(m.group(2))))\n    return rules", "response": "Make CSSRuleList object from style string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cssText(self) -> str:\n        text = '; '.join('{0}: {1}'.format(k, v) for k, v in self.items())\n        if text:\n            text += ';'\n        return text", "response": "String - representation of the attributes of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the css property.", "response": "def removeProperty(self, prop: str) -> str:\n        \"\"\"Remove the css property.\"\"\"\n        removed_prop = self.get(prop)\n        # removed_prop may be False or '', so need to check it is None\n        if removed_prop is not None:\n            del self[prop]\n        return removed_prop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setProperty(self, prop: str, value: str, priority: str = None\n                    ) -> None:\n        \"\"\"Set property as the value.\n\n        The third argument ``priority`` is not implemented yet.\n        \"\"\"\n        self[prop] = value", "response": "Set the property as the value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn string representation of this rule.", "response": "def cssText(self) -> str:\n        \"\"\"Return string representation of this rule.\"\"\"\n        _style = self.style.cssText\n        if _style:\n            return '{0} {{{1}}}'.format(self.selectorText, _style)\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_loglevel(level: Union[int, str, None] = None) -> None:\n    if level is not None:\n        lv = level_to_int(level)\n    elif config.logging:\n        lv = level_to_int(config.logging)\n    elif config.debug:\n        lv = logging.DEBUG\n    else:\n        lv = logging.INFO\n    root_logger.setLevel(lv)\n    _log_handler.setLevel(lv)", "response": "Set proper log - level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse command line options and set them to tornado. options. options.", "response": "def parse_command_line() -> Namespace:\n    \"\"\"Parse command line options and set them to ``config``.\n\n    This function skips unknown command line options. After parsing options,\n    set log level and set options in ``tornado.options``.\n    \"\"\"\n    import tornado.options\n    parser.parse_known_args(namespace=config)\n    set_loglevel()  # set new log level based on commanline option\n    for k, v in vars(config).items():\n        if k.startswith('log'):\n            tornado.options.options.__setattr__(k, v)\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsuppress log output to stdout.", "response": "def suppress_logging() -> None:\n    \"\"\"Suppress log output to stdout.\n\n    This function is intended to be used in test's setup. This function removes\n    log handler of ``wdom`` logger and set NullHandler to suppress log.\n    \"\"\"\n    from wdom import options\n    options.root_logger.removeHandler(options._log_handler)\n    options.root_logger.addHandler(logging.NullHandler())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset() -> None:\n    from wdom.document import get_new_document, set_document\n    from wdom.element import Element\n    from wdom.server import _tornado\n    from wdom.window import customElements\n\n    set_document(get_new_document())\n    _tornado.connections.clear()\n    _tornado.set_application(_tornado.Application())\n    Element._elements_with_id.clear()\n    Element._element_buffer.clear()\n    customElements.reset()", "response": "Reset all wdom objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexacting match of IP addresses.", "response": "def _ipaddress_match(ipname, host_ip):\n    \"\"\"Exact matching of IP addresses.\n\n    RFC 6125 explicitly doesn't define an algorithm for this\n    (section 1.7.2 - \"Out of Scope\").\n    \"\"\"\n    # OpenSSL may add a trailing newline to a subjectAltName's IP address\n    ip = ipaddress.ip_address(six.text_type(ipname.rstrip()))\n    return ip == host_ip"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dnsname_match(dn, hostname, max_wildcards=1):\n    pats = []\n    if not dn:\n        return False\n\n    split_dn = dn.split(r'.')\n    leftmost, remainder = split_dn[0], split_dn[1:]\n\n    wildcards = leftmost.count('*')\n    if wildcards > max_wildcards:\n        # Issue #17980: avoid denials of service by refusing more\n        # than one wildcard per fragment.  A survey of established\n        # policy among SSL implementations showed it to be a\n        # reasonable choice.\n        raise CertificateError(\n            \"too many wildcards in certificate DNS name: \" + repr(dn))\n\n    # speed up common case w/o wildcards\n    if not wildcards:\n        return dn.lower() == hostname.lower()\n\n    # RFC 6125, section 6.4.3, subitem 1.\n    # The client SHOULD NOT attempt to match a presented identifier in which\n    # the wildcard character comprises a label other than the left-most label.\n    if leftmost == '*':\n        # When '*' is a fragment by itself, it matches a non-empty dotless\n        # fragment.\n        pats.append('[^.]+')\n    elif leftmost.startswith('xn--') or hostname.startswith('xn--'):\n        # RFC 6125, section 6.4.3, subitem 3.\n        # The client SHOULD NOT attempt to match a presented identifier\n        # where the wildcard character is embedded within an A-label or\n        # U-label of an internationalized domain name.\n        pats.append(re.escape(leftmost))\n    else:\n        # Otherwise, '*' matches any dotless string, e.g. www*\n        pats.append(re.escape(leftmost).replace(r'\\*', '[^.]*'))\n\n    # add the remaining fragments, ignore any wildcards\n    for frag in remainder:\n        pats.append(re.escape(frag))\n\n    pat = re.compile(r'\\A' + r'\\.'.join(pats) + r'\\Z', re.IGNORECASE)\n    return pat.match(hostname)", "response": "Return True if the given DNS name matches the given hostname."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies that the hostname in the certificate matches the hostname in the certificate.", "response": "def match_hostname(cert, hostname):\n    \"\"\"Verify that *cert* (in decoded format as returned by\n    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125\n    rules are followed, but IP addresses are not accepted for *hostname*.\n\n    CertificateError is raised on failure. On success, the function\n    returns nothing.\n    \"\"\"\n    if not cert:\n        raise ValueError(\"empty or no certificate, match_hostname needs a \"\n                         \"SSL socket or SSL context with either \"\n                         \"CERT_OPTIONAL or CERT_REQUIRED\")\n    try:\n        host_ip = ipaddress.ip_address(six.text_type(hostname))\n    except ValueError:\n        # Not an IP address (common case)\n        host_ip = None\n    dnsnames = []\n    san = cert.get('subjectAltName', ())\n    for key, value in san:\n        if key == 'DNS':\n            if host_ip is None and _dnsname_match(value, hostname):\n                return\n            dnsnames.append(value)\n        elif key == 'IP Address':\n            if host_ip is not None and _ipaddress_match(value, host_ip):\n                return\n            dnsnames.append(value)\n    if not dnsnames:\n        # The subject is only checked when there is no dNSName entry\n        # in subjectAltName\n        for sub in cert.get('subject', ()):\n            for key, value in sub:\n                # XXX according to RFC 2818, the most specific Common Name\n                # must be used.\n                if key == 'commonName':\n                    if _dnsname_match(value, hostname):\n                        return\n                    dnsnames.append(value)\n    if len(dnsnames) > 1:\n        raise CertificateError(\n            \"hostname %r doesn't match either of %s\"\n            % (hostname, ', '.join(map(repr, dnsnames))))\n    elif len(dnsnames) == 1:\n        raise CertificateError(\n            \"hostname %r doesn't match %r\"\n            % (hostname, dnsnames[0])\n        )\n    else:\n        raise CertificateError(\n            \"no appropriate commonName or \"\n            \"subjectAltName fields were found\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring to be node.", "response": "def _ensure_node(node: Union[str, AbstractNode]) -> AbstractNode:\n    \"\"\"Ensure to be node.\n\n    If ``node`` is string, convert it to ``Text`` node.\n    \"\"\"\n    if isinstance(node, str):\n        return Text(node)\n    elif isinstance(node, Node):\n        return node\n    else:\n        raise TypeError('Invalid type to append: {}'.format(node))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the previous sibling of this node.", "response": "def previousSibling(self) -> Optional[AbstractNode]:\n        \"\"\"Return the previous sibling of this node.\n\n        If there is no previous sibling, return ``None``.\n        \"\"\"\n        parent = self.parentNode\n        if parent is None:\n            return None\n        return parent.childNodes.item(parent.childNodes.index(self) - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ownerDocument(self) -> Optional[AbstractNode]:\n        if self.nodeType == Node.DOCUMENT_NODE:\n            return self\n        elif self.parentNode:\n            return self.parentNode.ownerDocument\n        return None", "response": "Return the owner document of this node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index(self, node: AbstractNode) -> int:\n        if node in self.childNodes:\n            return self.childNodes.index(node)\n        elif isinstance(node, Text):\n            for i, n in enumerate(self.childNodes):\n                # should consider multiple match?\n                if isinstance(n, Text) and n.data == node:\n                    return i\n        raise ValueError('node is not in this node')", "response": "Return the index of the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a node just before the reference node.", "response": "def insertBefore(self, node: AbstractNode,\n                     ref_node: AbstractNode) -> AbstractNode:\n        \"\"\"Insert a node just before the reference node.\"\"\"\n        return self._insert_before(node, ref_node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing an old child with new child.", "response": "def replaceChild(self, new_child: AbstractNode,\n                     old_child: AbstractNode) -> AbstractNode:\n        \"\"\"Replace an old child with new child.\"\"\"\n        return self._replace_child(new_child, old_child)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a deep copy of this node.", "response": "def cloneNode(self, deep: bool=False) -> AbstractNode:\n        \"\"\"Return new copy of this node.\n\n        If optional argument ``deep`` is specified and is True, new node has\n        clones of child nodes of this node (if presents).\n        \"\"\"\n        if deep:\n            return self._clone_node_deep()\n        return self._clone_node()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the item with the index.", "response": "def item(self, index: int) -> Optional[Node]:\n        \"\"\"Return item with the index.\n\n        If the index is negative number or out of the list, return None.\n        \"\"\"\n        if not isinstance(index, int):\n            raise TypeError(\n                'Indeces must be integer, not {}'.format(type(index)))\n        return self.__nodes[index] if 0 <= index < self.length else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the node with the given name or None if no such node exists.", "response": "def namedItem(self, name: str) -> Optional[Node]:\n        \"\"\"TODO.\"\"\"\n        for n in self:\n            if n.getAttribute('id') == name:\n                return n\n        for n in self:\n            if n.getAttribute('name') == name:\n                return n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of child nodes.", "response": "def children(self) -> NodeList:\n        \"\"\"Return list of child nodes.\n\n        Currently this is not a live object.\n        \"\"\"\n        return NodeList([e for e in self.childNodes\n                         if e.nodeType == Node.ELEMENT_NODE])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first element child node.", "response": "def firstElementChild(self) -> Optional[AbstractNode]:\n        \"\"\"First Element child node.\n\n        If this node has no element child, return None.\n        \"\"\"\n        for child in self.childNodes:\n            if child.nodeType == Node.ELEMENT_NODE:\n                return child\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lastElementChild(self) -> Optional[AbstractNode]:\n        for child in reversed(self.childNodes):  # type: ignore\n            if child.nodeType == Node.ELEMENT_NODE:\n                return child\n        return None", "response": "Return the last element child node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepend(self, *nodes: Union[str, AbstractNode]) -> None:\n        node = _to_node_list(nodes)\n        if self.firstChild:\n            self.insertBefore(node, self.firstChild)\n        else:\n            self.appendChild(node)", "response": "Insert new nodes before first child node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nappending new nodes after last child node.", "response": "def append(self, *nodes: Union[AbstractNode, str]) -> None:\n        \"\"\"Append new nodes after last child node.\"\"\"\n        node = _to_node_list(nodes)\n        self.appendChild(node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the next element node in this node.", "response": "def nextElementSibling(self) -> Optional[AbstractNode]:\n        \"\"\"Next Element Node.\n\n        If this node has no next element node, return None.\n        \"\"\"\n        if self.parentNode is None:\n            return None\n        siblings = self.parentNode.childNodes\n        for i in range(siblings.index(self) + 1, len(siblings)):\n            n = siblings[i]\n            if n.nodeType == Node.ELEMENT_NODE:\n                return n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef before(self, *nodes: Union[AbstractNode, str]) -> None:\n        if self.parentNode:\n            node = _to_node_list(nodes)\n            self.parentNode.insertBefore(node, self)", "response": "Insert nodes before this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends nodes after this node.", "response": "def after(self, *nodes: Union[AbstractNode, str]) -> None:\n        \"\"\"Append nodes after this node.\n\n        If nodes contains ``str``, it will be converted to Text node.\n        \"\"\"\n        if self.parentNode:\n            node = _to_node_list(nodes)\n            _next_node = self.nextSibling\n            if _next_node is None:\n                self.parentNode.appendChild(node)\n            else:\n                self.parentNode.insertBefore(node, _next_node)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreplacing this node with nodes.", "response": "def replaceWith(self, *nodes: Union[AbstractNode, str]) -> None:\n        \"\"\"Replace this node with nodes.\n\n        If nodes contains ``str``, it will be converted to Text node.\n        \"\"\"\n        if self.parentNode:\n            node = _to_node_list(nodes)\n            self.parentNode.replaceChild(node, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insertData(self, offset: int, string: str) -> None:\n        self._insert_data(offset, string)", "response": "Insert string at offset on this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete data by offset to count letters.", "response": "def deleteData(self, offset: int, count: int) -> None:\n        \"\"\"Delete data by offset to count letters.\"\"\"\n        self._delete_data(offset, count)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replaceData(self, offset: int, count: int, string: str) -> None:\n        self._replace_data(offset, count, string)", "response": "Replace data from offset to count by string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef html(self) -> str:\n        if self.parentNode and self.parentNode._should_escape_text:\n            return html.escape(self.data)\n        return self.data", "response": "Return html - escaped string representation of this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate Event from JSOM msg and set target nodes.", "response": "def create_event(msg: EventMsgDict) -> Event:\n    \"\"\"Create Event from JSOM msg and set target nodes.\n\n    :arg EventTarget currentTarget: Current event target node.\n    :arg EventTarget target: Node which emitted this event first.\n    :arg dict init: Event options.\n    \"\"\"\n    proto = msg.get('proto', '')\n    cls = proto_dict.get(proto, Event)\n    e = cls(msg['type'], msg)\n    return e"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getData(self, type: str) -> str:\n        return self.__data.get(normalize_type(type), '')", "response": "Get data of type format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setData(self, type: str, data: str) -> None:\n        type = normalize_type(type)\n        if type in self.__data:\n            del self.__data[type]\n        self.__data[type] = data", "response": "Set the data of type format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clearData(self, type: str = '') -> None:\n        type = normalize_type(type)\n        if not type:\n            self.__data.clear()\n        elif type in self.__data:\n            del self.__data[type]", "response": "Remove data of type foramt."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an event listener to this node.", "response": "def addEventListener(self, event: str, listener: _EventListenerType\n                         ) -> None:\n        \"\"\"Add event listener to this node.\n\n        ``event`` is a string which determines the event type when the new\n        listener called. Acceptable events are same as JavaScript, without\n        ``on``. For example, to add a listener which is called when this node\n        is clicked, event is ``'click``.\n        \"\"\"\n        self._add_event_listener(event, listener)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an event listener of this node.", "response": "def removeEventListener(self, event: str, listener: _EventListenerType\n                            ) -> None:\n        \"\"\"Remove an event listener of this node.\n\n        The listener is removed only when both event type and listener is\n        matched.\n        \"\"\"\n        self._remove_event_listener(event, listener)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_response(self, msg: Dict[str, str]) -> None:\n        response = msg.get('data', False)\n        if response:\n            task = self.__tasks.pop(msg.get('reqid'), False)\n            if task and not task.cancelled() and not task.done():\n                task.set_result(msg.get('data'))", "response": "Run when get response from browser."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes method in the related node on browser.", "response": "def js_exec(self, method: str, *args: Union[int, str, bool]) -> None:\n        \"\"\"Execute ``method`` in the related node on browser.\n\n        Other keyword arguments are passed to ``params`` attribute.\n        If this node is not in any document tree (namely, this node does not\n        have parent node), the ``method`` is not executed.\n        \"\"\"\n        if self.connected:\n            self.ws_send(dict(method=method, params=args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a query to related DOM on browser.", "response": "def js_query(self, query: str) -> Awaitable:\n        \"\"\"Send query to related DOM on browser.\n\n        :param str query: single string which indicates query type.\n        \"\"\"\n        if self.connected:\n            self.js_exec(query, self.__reqid)\n            fut = Future()  # type: Future[str]\n            self.__tasks[self.__reqid] = fut\n            self.__reqid += 1\n            return fut\n        f = Future()  # type: Future[None]\n        f.set_result(None)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ws_send(self, obj: Dict[str, Union[Iterable[_T_MsgItem], _T_MsgItem]]\n                ) -> None:\n        \"\"\"Send ``obj`` as message to the related nodes on browser.\n\n        :arg dict obj: Message is serialized by JSON object and send via\n            WebSocket connection.\n        \"\"\"\n        from wdom import server\n        if self.ownerDocument is not None:\n            obj['target'] = 'node'\n            obj['id'] = self.wdom_id\n            server.push_message(obj)", "response": "Send a message to the related nodes on the browser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_url(query, first, recent, country_code):\n    query = '+'.join(query.split())\n    url = 'http://www.bing.com/search?q=' + query + '&first=' + first\n    if recent in ['h', 'd', 'w', 'm', 'y']: # A True/False would be enough. This is just to maintain consistancy with google.\n        url = url + '&filters=ex1%3a%22ez1%22'\n    if country_code is not None:\n        url += '&cc=' + country_code\n    return url", "response": "Generate a url to search for a given query."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_news_url(query, first, recent, country_code):\n    query = '+'.join(query.split())\n    url = 'http://www.bing.com/news/search?q=' + query + '&first' + first\n    if recent in ['h', 'd', 'w', 'm', 'y']: # A True/False would be enough. This is just to maintain consistancy with google.\n        url = url + '&qft=sortbydate%3d%221%22'\n    if country_code is not None:\n        url += '&cc=' + country_code\n    return url", "response": "Generate a url to search for a given query."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to cast a string to an integer.", "response": "def try_cast_int(s):\n    \"\"\"(str) -> int\n    All the digits in a given string are concatenated and converted into a single number.\n    \"\"\"\n    try:\n        temp = re.findall('\\d', str(s))\n        temp = ''.join(temp)\n        return int(temp)\n    except:\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_url(query, num, start, recent, country_code):\n    query = '+'.join(query.split())\n    url = 'https://www.google.com/search?q=' + query + '&num=' + num + '&start=' + start\n    if recent in ['h', 'd', 'w', 'm', 'y']:\n        url += '&tbs=qdr:' + recent\n    if country_code is not None:\n        url += '&gl=' + country_code\n    return url", "response": "Generate url for a new node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef estimate_cp(ts, method=\"mean\", Q=1, penalty_value=0.175):\n\n    \"\"\" \n        ts: time series\n        method: look for a single changepoint in 'mean' , 'var', 'mean and var'\n                or use binary segmentatiom to detect multiple changepoints in\n                mean (binseg).\n        Q: Number of change points to look for (only for binseg)\n        penalty_value: Penalty to use as threshold (only for binseg)\n\n        Returns: returns indices of the changepoints\n    \"\"\"\n    robjects.r(\"library(changepoint)\")\n    method_map = {\n        \"mean\": \"cpt.mean({})\",\n        \"var\": \"cpt.var({})\",\n        \"meanvar\": \"cpt.meanvar({})\",\n        \"binseg.mean.CUSUM\": \"cpt.mean({},penalty='Manual', test.stat='CUSUM',method='BinSeg',Q={},pen.value={})\"\n    }\n    mt = robjects.FloatVector(ts)\n    robjects.globalenv[\"mt\"] = mt\n    if method == \"binseg.mean.CUSUM\":\n        cmd = method_map[method].format(\"mt\", Q, penalty_value)\n    else:\n        cmd = method_map[method].format(\"mt\")\n    robjects.globalenv[\"mycpt\"] = robjects.r(cmd)\n    ecp = robjects.r(\"cpts(mycpt)\")\n    return ecp", "response": "Estimate the changepoints in a time series by using R."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef estimate_cp_pval(ts, method=\"mean\"):\n\n    \"\"\" \n        ts: time series\n        method: look for a single changepoint in 'mean' , 'var', 'mean and var'\n        Returns: returns index of the changepoint, and pvalue. Here pvalue = 1\n                 means statistically significant\n    \"\"\"\n    robjects.r(\"library(changepoint)\")\n    method_map = {\n        \"mean\": \"cpt.mean({}, class=FALSE)\",\n        \"var\": \"cpt.var({}, class=FALSE)\",\n        \"meanvar\": \"cpt.meanvar({}, class=FALSE)\",\n    }\n    mt = robjects.FloatVector(ts)\n    robjects.globalenv[\"mt\"] = mt\n    cmd = method_map[method].format(\"mt\")\n    robjects.globalenv[\"mycpt\"] = robjects.r(cmd)\n    ecp_pval = robjects.r(\"mycpt\")\n    ecp = ecp_pval[0]\n    pval = ecp_pval[1]\n    return ecp, pval", "response": "Estimate the changepoint and pvalue for a given time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ts_stats_significance(self, x, ts, stat_ts_func, null_ts_func, B=1000, permute_fast=False, label_ts=''):\n        stats_ts, pvals, nums = ts_stats_significance(\n            ts, stat_ts_func, null_ts_func, B=B, permute_fast=permute_fast)\n        return stats_ts, pvals, nums", "response": "Returns the statistics pvalues and the actual number of bootstrap\n            samples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a time series with a given mu and sigma. This serves as the NULL distribution.", "response": "def generate_null_timeseries(self, ts, mu, sigma):\n        \"\"\" Generate a time series with a given mu and sigma. This serves as the\n        NULL distribution. \"\"\"\n        l = len(ts)\n        return np.random.normal(mu, sigma, l)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the balance of the mean of the changed words.", "response": "def compute_balance_mean(self, ts, t):\n        \"\"\" Compute the balance. The right end - the left end.\"\"\"\n        \"\"\" For changed words we expect an increase in the mean, and so only 1 \"\"\"\n        return np.mean(ts[t + 1:]) - np.mean(ts[:t + 1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the balance at each time t of the time series.", "response": "def compute_balance_mean_ts(self, ts):\n        \"\"\" Compute the balance at each time 't' of the time series.\"\"\"\n        balance = [self.compute_balance_mean(ts, t) for t in np.arange(0, len(ts) - 1)]\n        return balance"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the balance at either end of the time series.", "response": "def compute_balance_median(self, ts, t):\n        \"\"\" Compute the balance at either end.\"\"\"\n        return np.median(ts[t + 1:]) - np.median(ts[:t + 1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the balance at each time t of the time series.", "response": "def compute_balance_median_ts(self, ts):\n        \"\"\" Compute the balance at each time 't' of the time series.\"\"\"\n        balance = [self.compute_balance_median(ts, t) for t in np.arange(0, len(ts) - 1)]\n        return balance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_cusum_ts(self, ts):\n        mean = np.mean(ts)\n        cusums = np.zeros(len(ts))\n        cusum[0] = (ts[0] - mean)\n        for i in np.arange(1, len(ts)):\n            cusums[i] = cusums[i - 1] + (ts[i] - mean)\n\n        assert(np.isclose(cumsum[-1], 0.0))\n        return cusums", "response": "Compute the Cumulative Sum at each point t of the time series."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detect_mean_shift(self, ts, B=1000):\n        x = np.arange(0, len(ts))\n        stat_ts_func = self.compute_balance_mean_ts\n        null_ts_func = self.shuffle_timeseries\n        stats_ts, pvals, nums = self.get_ts_stats_significance(x, ts, stat_ts_func, null_ts_func, B=B, permute_fast=True)\n        return stats_ts, pvals, nums", "response": "Detect mean shift in a time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ts_stats_significance(ts, ts_stat_func, null_ts_func, B=1000, permute_fast=False):\n    stats_ts = ts_stat_func(ts)\n    if permute_fast:\n        # Permute it in 1 shot\n        null_ts = map(np.random.permutation, np.array([ts, ] * B))\n    else:\n        null_ts = np.vstack([null_ts_func(ts) for i in np.arange(0, B)])\n    stats_null_ts = np.vstack([ts_stat_func(nts) for nts in null_ts])\n    pvals = []\n    nums = []\n    for i in np.arange(0, len(stats_ts)):\n        num_samples = np.sum((stats_null_ts[:, i] >= stats_ts[i]))\n        nums.append(num_samples)\n        pval = num_samples / float(B)\n        pvals.append(pval)\n\n    return stats_ts, pvals, nums", "response": "Compute the statistical significance of a test statistic at each point in the time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bootstrap_ts(y, func, B=1000, b=3):\n    beta_star = np.empty(B)\n    z = y\n    z_star = np.empty(len(z))\n    for boot_i in range(B):\n        for block_i, start in enumerate(np.random.randint(len(z) - b + 1, size=len(z) / b)):\n            z_star[block_i * b:(block_i + 1) * b] = z[start:start + b]\n            beta_star[boot_i] = func(z_star)\n    return beta_star", "response": "Bootstrap a timeseries using a window size B."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the confidence interval of a node.", "response": "def get_ci(theta_star, blockratio=1.0):\n    \"\"\" Get the confidence interval. \"\"\"\n    # get rid of nans while we sort\n    b_star = np.sort(theta_star[~np.isnan(theta_star)])\n    se = np.std(b_star) * np.sqrt(blockratio)\n    # bootstrap 95% CI based on empirical percentiles\n    ci = [b_star[int(len(b_star) * .025)], b_star[int(len(b_star) * .975)]]\n    return ci"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the p - value from the confidence interval.", "response": "def get_pvalue(value, ci):\n    \"\"\" Get the p-value from the confidence interval.\"\"\"\n    from scipy.stats import norm\n    se = (ci[1] - ci[0]) / (2.0 * 1.96)\n    z = value / se\n    pvalue = -2 * norm.cdf(-np.abs(z))\n    return pvalue"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the statistical significance of a test statistic at each point in the time series by using timeseries boootstrap.", "response": "def ts_stats_significance_bootstrap(ts, stats_ts, stats_func, B=1000, b=3):\n    \"\"\" Compute  the statistical significance of a test statistic at each point\n        of the time series by using timeseries boootstrap.\n    \"\"\"\n    pvals = []\n    for tp in np.arange(0, len(stats_ts)):\n        pf = partial(stats_func, t=tp)\n        bs = bootstrap_ts(ts, pf, B=B, b=b)\n        ci = get_ci(bs, blockratio=b / len(stats_ts))\n        pval = abs(get_pvalue(stats_ts[tp], ci))\n        pvals.append(pval)\n    return pvals"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_traceback(extracted_tb,\n                     exc_type,\n                     exc_value,\n                     cwd='',\n                     term=None,\n                     function_color=12,\n                     dim_color=8,\n                     editor='vi',\n                     template=DEFAULT_EDITOR_SHORTCUT_TEMPLATE):\n    \"\"\"Return an iterable of formatted Unicode traceback frames.\n\n    Also include a pseudo-frame at the end representing the exception itself.\n\n    Format things more compactly than the stock formatter, and make every\n    frame an editor shortcut.\n\n    \"\"\"\n    def format_shortcut(editor,\n                        path,\n                        line_number,\n                        function=None):\n        \"\"\"Return a pretty-printed editor shortcut.\"\"\"\n        return template.format(editor=editor,\n                               line_number=line_number or 0,\n                               path=path,\n                               function=function or u'',\n                               hash_if_function=u'  # ' if function else u'',\n                               function_format=term.color(function_color),\n                               # Underline is also nice and doesn't make us\n                               # worry about appearance on different background\n                               # colors.\n                               normal=term.normal,\n                               dim_format=term.color(dim_color) + term.bold,\n                               line_number_max_width=line_number_max_width,\n                               term=term)\n\n    template += '\\n'  # Newlines are awkward to express on the command line.\n    extracted_tb = _unicode_decode_extracted_tb(extracted_tb)\n    if not term:\n        term = Terminal()\n\n    if extracted_tb:\n        # Shorten file paths:\n        for i, (file, line_number, function, text) in enumerate(extracted_tb):\n            extracted_tb[i] = human_path(src(file), cwd), line_number, function, text\n\n        line_number_max_width = len(unicode(max(the_line for _, the_line, _, _ in extracted_tb)))\n\n        # Stack frames:\n        for i, (path, line_number, function, text) in enumerate(extracted_tb):\n            text = (text and text.strip()) or u''\n\n            yield (format_shortcut(editor, path, line_number, function) +\n                   (u'    %s\\n' % text))\n\n    # Exception:\n    if exc_type is SyntaxError:\n        # Format a SyntaxError to look like our other traceback lines.\n        # SyntaxErrors have a format different from other errors and include a\n        # file path which looks out of place in our newly highlit, editor-\n        # shortcutted world.\n        if hasattr(exc_value, 'filename') and hasattr(exc_value, 'lineno'):\n            exc_lines = [format_shortcut(editor, exc_value.filename, exc_value.lineno)]\n            formatted_exception = format_exception_only(SyntaxError, exc_value)[1:]\n        else:\n            # The logcapture plugin may format exceptions as strings,\n            # stripping them of the full filename and lineno\n            exc_lines = []\n            formatted_exception = format_exception_only(SyntaxError, exc_value)\n            formatted_exception.append(u'(Try --nologcapture for a more detailed traceback)\\n')\n    else:\n        exc_lines = []\n        formatted_exception = format_exception_only(exc_type, exc_value)\n    exc_lines.extend([_decode(f) for f in formatted_exception])\n    yield u''.join(exc_lines)", "response": "Return an iterable of Unicode traceback frames."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_relevant_tb(tb, exctype, is_test_failure):\n    # Skip test runner traceback levels:\n    while tb and _is_unittest_frame(tb):\n        tb = tb.tb_next\n    if is_test_failure:\n        # Skip assert*() traceback levels:\n        length = _count_relevant_tb_levels(tb)\n        return extract_tb(tb, length)\n    return extract_tb(tb)", "response": "Return extracted traceback frame 4 - tuples that aren t unittest ones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unicode_decode_extracted_tb(extracted_tb):\n    return [(_decode(file), line_number, _decode(function), _decode(text))\n            for file, line_number, function, text in extracted_tb]", "response": "Return a traceback with the string elements translated into Unicode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _count_relevant_tb_levels(tb):\n    length = contiguous_unittest_frames = 0\n    while tb:\n        length += 1\n        if _is_unittest_frame(tb):\n            contiguous_unittest_frames += 1\n        else:\n            contiguous_unittest_frames = 0\n        tb = tb.tb_next\n    return length - contiguous_unittest_frames", "response": "Return the number of frames in tb before all that s left is unittest frames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling pdb s cmdloop and return the result.", "response": "def cmdloop(self, *args, **kwargs):\n    \"\"\"Call pdb's cmdloop, making readline work.\n\n    Patch raw_input so it sees the original stdin and stdout, lest\n    readline refuse to work.\n\n    The C implementation of raw_input uses readline functionality only if\n    both stdin and stdout are from a terminal AND are FILE*s (not\n    PyObject*s): http://bugs.python.org/issue5727 and\n    https://bugzilla.redhat.com/show_bug.cgi?id=448864\n\n    \"\"\"\n    def unwrapping_raw_input(*args, **kwargs):\n        \"\"\"Call raw_input(), making sure it finds an unwrapped stdout.\"\"\"\n        wrapped_stdout = sys.stdout\n        sys.stdout = wrapped_stdout.stream\n\n        ret = orig_raw_input(*args, **kwargs)\n\n        sys.stdout = wrapped_stdout\n        return ret\n\n    try:\n        orig_raw_input = raw_input\n    except NameError:\n        orig_raw_input = input\n    if hasattr(sys.stdout, 'stream'):\n        __builtin__.raw_input = unwrapping_raw_input\n    # else if capture plugin has replaced it with a StringIO, don't bother.\n    try:\n        # Interesting things happen when you try to not reference the\n        # superclass explicitly.\n        ret = cmd.Cmd.cmdloop(self, *args, **kwargs)\n    finally:\n        __builtin__.raw_input = orig_raw_input\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_trace(*args, **kwargs):\n    # There's no stream attr if capture plugin is enabled:\n    out = sys.stdout.stream if hasattr(sys.stdout, 'stream') else None\n\n    # Python 2.5 can't put an explicit kwarg and **kwargs in the same function\n    # call.\n    kwargs['stdout'] = out\n    debugger = pdb.Pdb(*args, **kwargs)\n\n    # Ordinarily (and in a silly fashion), pdb refuses to use raw_input() if\n    # you pass it a stream on instantiation. Fix that:\n    debugger.use_rawinput = True\n\n    debugger.set_trace(sys._getframe().f_back)", "response": "Call pdb. set_trace making sure it receives the unwrapped stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef begin(self):\n        # The calls to begin/finalize end up like this: a call to begin() on\n        # instance A of the plugin, then a paired begin/finalize for each test\n        # on instance B, then a final call to finalize() on instance A.\n\n        # TODO: Do only if isatty.\n        self._stderr.append(sys.stderr)\n        sys.stderr = StreamWrapper(sys.stderr, self)  # TODO: Any point?\n\n        self._stdout.append(sys.stdout)\n        sys.stdout = StreamWrapper(sys.stdout, self)\n\n        self._set_trace.append(pdb.set_trace)\n        pdb.set_trace = set_trace\n\n        self._cmdloop.append(pdb.Pdb.cmdloop)\n        pdb.Pdb.cmdloop = cmdloop\n\n        # nosetests changes directories to the tests dir when run from a\n        # distribution dir, so save the original cwd for relativizing paths.\n        self._cwd = '' if self.conf.options.absolute_paths else getcwd()", "response": "Begin the dodge progress bar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef finalize(self, result):\n        sys.stderr = self._stderr.pop()\n        sys.stdout = self._stdout.pop()\n        pdb.set_trace = self._set_trace.pop()\n        pdb.Pdb.cmdloop = self._cmdloop.pop()", "response": "Put monkeypatches back as we found them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn style -forcing on if bar -forcing is on.", "response": "def configure(self, options, conf):\n        \"\"\"Turn style-forcing on if bar-forcing is on.\n\n        It'd be messy to position the bar but still have the rest of the\n        terminal capabilities emit ''.\n\n        \"\"\"\n        super(ProgressivePlugin, self).configure(options, conf)\n        if (getattr(options, 'verbosity', 0) > 1 and\n            getattr(options, 'enable_plugin_id', False)):\n            # TODO: Can we forcibly disable the ID plugin?\n            print ('Using --with-id and --verbosity=2 or higher with '\n                   'nose-progressive causes visualization errors. Remove one '\n                   'or the other to avoid a mess.')\n        if options.with_bar:\n            options.with_styling = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, test_path, number):\n        # TODO: Play nicely with absurdly narrow terminals. (OS X's won't even\n        # go small enough to hurt us.)\n\n        # Figure out graph:\n        GRAPH_WIDTH = 14\n        # min() is in case we somehow get the total test count wrong. It's tricky.\n        num_filled = int(round(min(1.0, float(number) / self.max) * GRAPH_WIDTH))\n        graph = ''.join([self._fill_cap(' ' * num_filled),\n                         self._empty_cap(self._empty_char * (GRAPH_WIDTH - num_filled))])\n\n        # Figure out the test identifier portion:\n        cols_for_path = self.cols - GRAPH_WIDTH - 2  # 2 spaces between path & graph\n        if len(test_path) > cols_for_path:\n            test_path = test_path[len(test_path) - cols_for_path:]\n        else:\n            test_path += ' ' * (cols_for_path - len(test_path))\n\n        # Put them together, and let simmer:\n        self.last = self._term.bold(test_path) + '  ' + graph\n        with self._at_last_line():\n            self.stream.write(self.last)\n        self.stream.flush()", "response": "Draw an updated progress bar for the given test identifier and number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwhiting out the progress bar.", "response": "def erase(self):\n        \"\"\"White out the progress bar.\"\"\"\n        with self._at_last_line():\n            self.stream.write(self._term.clear_eol)\n        self.stream.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a context manager which erases the bar and redraws the last saved state of the progress bar.", "response": "def dodging(bar):\n        \"\"\"Return a context manager which erases the bar, lets you output things, and then redraws the bar.\n\n        It's reentrant.\n\n        \"\"\"\n        class ShyProgressBar(object):\n            \"\"\"Context manager that implements a progress bar that gets out of the way\"\"\"\n\n            def __enter__(self):\n                \"\"\"Erase the progress bar so bits of disembodied progress bar don't get scrolled up the terminal.\"\"\"\n                # My terminal has no status line, so we make one manually.\n                bar._is_dodging += 1  # Increment before calling erase(), which\n                                      # calls dodging() again.\n                if bar._is_dodging <= 1:  # It *was* 0.\n                    bar.erase()\n\n            def __exit__(self, type, value, tb):\n                \"\"\"Redraw the last saved state of the progress bar.\"\"\"\n                if bar._is_dodging == 1:  # Can't decrement yet; write() could\n                                          # read it.\n                    # This is really necessary only because we monkeypatch\n                    # stderr; the next test is about to start and will redraw\n                    # the bar.\n                    with bar._at_last_line():\n                        bar.stream.write(bar.last)\n                    bar.stream.flush()\n                bar._is_dodging -= 1\n\n        return ShyProgressBar()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a ResultProxy that doesn t print dots.", "response": "def _makeResult(self):\n        \"\"\"Return a Result that doesn't print dots.\n\n        Nose's ResultProxy will wrap it, and other plugins can still print\n        stuff---but without smashing into our progress bar, care of\n        ProgressivePlugin's stderr/out wrapping.\n\n        \"\"\"\n        return ProgressiveResult(self._cwd,\n                                 self._totalTests,\n                                 self.stream,\n                                 config=self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the given test case or test suite... quietly.", "response": "def run(self, test):\n        \"Run the given test case or test suite...quietly.\"\n        # These parts of Nose's pluggability are baked into\n        # nose.core.TextTestRunner. Reproduce them:\n        wrapper = self.config.plugins.prepareTest(test)\n        if wrapper is not None:\n            test = wrapper\n        wrapped = self.config.plugins.setOutputStream(self.stream)\n        if wrapped is not None:\n            self.stream = wrapped\n\n        result = self._makeResult()\n        startTime = time()\n        try:\n            test(result)\n        except KeyboardInterrupt:\n            # we need to ignore these exception to not\n            # show traceback when user intentionally\n            # interrupted test suite execution, and\n            # to output some reasonable results on\n            # already passed and failed tests.\n            pass\n        stopTime = time()\n\n        # We don't care to hear about errors again at the end; we take care of\n        # that in result.addError(), while the tests run.\n        # result.printErrors()\n        #\n        # However, we do need to call this one useful line from\n        # nose.result.TextTestResult's implementation of printErrors() to make\n        # sure other plugins get a chance to report:\n        self.config.plugins.report(self.stream)\n\n        result.printSummary(startTime, stopTime)\n        self.config.plugins.finalize(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _printTraceback(self, test, err):\n        # Don't bind third item to a local var; that can create\n        # circular refs which are expensive to collect. See the\n        # sys.exc_info() docs.\n        exception_type, exception_value = err[:2]\n        # TODO: In Python 3, the traceback is attached to the exception\n        # instance through the __traceback__ attribute. If the instance\n        # is saved in a local variable that persists outside the except\n        # block, the traceback will create a reference cycle with the\n        # current frame and its dictionary of local variables. This will\n        # delay reclaiming dead resources until the next cyclic garbage\n        # collection pass.\n\n        extracted_tb = extract_relevant_tb(\n            err[2],\n            exception_type,\n            exception_type is test.failureException)\n        test_frame_index = index_of_test_frame(\n            extracted_tb,\n            exception_type,\n            exception_value,\n            test)\n        if test_frame_index:\n            # We have a good guess at which frame is the test, so\n            # trim everything until that. We don't care to see test\n            # framework frames.\n            extracted_tb = extracted_tb[test_frame_index:]\n\n        with self.bar.dodging():\n            self.stream.write(''.join(\n                format_traceback(\n                    extracted_tb,\n                    exception_type,\n                    exception_value,\n                    self._cwd,\n                    self._term,\n                    self._options.function_color,\n                    self._options.dim_color,\n                    self._options.editor,\n                    self._options.editor_shortcut_template)))", "response": "Print a nicely formatted traceback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noutputting a 1 - line error summary to the stream if appropriate.", "response": "def _printHeadline(self, kind, test, is_failure=True):\n        \"\"\"Output a 1-line error summary to the stream if appropriate.\n\n        The line contains the kind of error and the pathname of the test.\n\n        :arg kind: The (string) type of incident the precipitated this call\n        :arg test: The test that precipitated this call\n\n        \"\"\"\n        if is_failure or self._options.show_advisories:\n            with self.bar.dodging():\n                self.stream.writeln(\n                        '\\n' +\n                        (self._term.bold if is_failure else '') +\n                        '%s: %s' % (kind, nose_selector(test)) +\n                        (self._term.normal if is_failure else ''))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _recordAndPrintHeadline(self, test, error_class, artifact):\n        # We duplicate the errorclass handling from super rather than calling\n        # it and monkeying around with showAll flags to keep it from printing\n        # anything.\n        is_error_class = False\n        for cls, (storage, label, is_failure) in self.errorClasses.items():\n            if isclass(error_class) and issubclass(error_class, cls):\n                if is_failure:\n                    test.passed = False\n                storage.append((test, artifact))\n                is_error_class = True\n        if not is_error_class:\n            self.errors.append((test, artifact))\n            test.passed = False\n\n        is_any_failure = not is_error_class or is_failure\n        self._printHeadline(label if is_error_class else 'ERROR',\n                            test,\n                            is_failure=is_any_failure)\n        return is_any_failure", "response": "Record that an error - like thing occurred and print a summary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncatch skipped tests in Python 2. 7 and above.", "response": "def addSkip(self, test, reason):\n        \"\"\"Catch skipped tests in Python 2.7 and above.\n\n        Though ``addSkip()`` is deprecated in the nose plugin API, it is very\n        much not deprecated as a Python 2.7 ``TestResult`` method. In Python\n        2.7, this will get called instead of ``addError()`` for skips.\n\n        :arg reason: Text describing why the test was skipped\n\n        \"\"\"\n        self._recordAndPrintHeadline(test, SkipTest, reason)\n        # Python 2.7 users get a little bonus: the reason the test was skipped.\n        if isinstance(reason, Exception):\n            reason = getattr(reason, 'message', None) or getattr(\n                reason, 'args')[0]\n        if reason and self._options.show_advisories:\n            with self.bar.dodging():\n                self.stream.writeln(reason)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nose_selector(test):\n    address = test_address(test)\n    if address:\n        file, module, rest = address\n\n        if module:\n            if rest:\n                try:\n                    return '%s:%s%s' % (module, rest, test.test.arg or '')\n                except AttributeError:\n                    return '%s:%s' % (module, rest)\n            else:\n                return module\n    return 'Unknown test'", "response": "Return the string you can pass to nose to run a test."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the most human - readable representation of the given path.", "response": "def human_path(path, cwd):\n    \"\"\"Return the most human-readable representation of the given path.\n\n    If an absolute path is given that's within the current directory, convert\n    it to a relative path to shorten it. Otherwise, return the absolute path.\n\n    \"\"\"\n    # TODO: Canonicalize the path to remove /kitsune/../kitsune nonsense.\n    path = abspath(path)\n    if cwd and path.startswith(cwd):\n        path = path[len(cwd) + 1:]  # Make path relative. Remove leading slash.\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef know(self, what, confidence):\n        if confidence > self.confidence:\n            self.best = what\n            self.confidence = confidence\n        return self", "response": "Know something with the given confidence and return self for chaining."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_arg_types(coordlist_length, shape_name):\n    from .ds9_region_parser import ds9_shape_defs\n    from .ds9_attr_parser import ds9_shape_in_comment_defs\n\n    if shape_name in ds9_shape_defs:\n        shape_def = ds9_shape_defs[shape_name]\n    else:\n        shape_def = ds9_shape_in_comment_defs[shape_name]\n\n    initial_arg_types = shape_def.args_list\n    arg_repeats = shape_def.args_repeat\n\n    if arg_repeats is None:\n        return initial_arg_types\n\n    # repeat args between n1 and n2\n    n1, n2 = arg_repeats\n    arg_types = list(initial_arg_types[:n1])\n    num_of_repeats = coordlist_length - (len(initial_arg_types) - n2)\n    arg_types.extend((num_of_repeats - n1) //\n                     (n2 - n1) * initial_arg_types[n1:n2])\n    arg_types.extend(initial_arg_types[n2:])\n    return arg_types", "response": "This function returns a list of coordinate types based on shape name and coordlist length."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_to_imagecoord(shape, header):\n    arg_types = _generate_arg_types(len(shape.coord_list), shape.name)\n\n    new_coordlist = []\n    is_even_distance = True\n    coord_list_iter = iter(zip(shape.coord_list, arg_types))\n\n    new_wcs = WCS(header)\n    pixel_scales = proj_plane_pixel_scales(new_wcs)\n\n    for coordinate, coordinate_type in coord_list_iter:\n        if coordinate_type == CoordOdd:\n            even_coordinate = next(coord_list_iter)[0]\n\n            old_coordinate = SkyCoord(coordinate, even_coordinate,\n                                      frame=shape.coord_format, unit='degree',\n                                      obstime='J2000')\n            new_coordlist.extend(\n                np.asscalar(x)\n                for x in old_coordinate.to_pixel(new_wcs, origin=1)\n            )\n\n        elif coordinate_type == Distance:\n            if arg_types[-1] == Angle:\n                degree_per_pixel = pixel_scales[0 if is_even_distance else 1]\n\n                is_even_distance = not is_even_distance\n            else:\n                degree_per_pixel = np.sqrt(proj_plane_pixel_area(new_wcs))\n\n            new_coordlist.append(coordinate / degree_per_pixel)\n\n        elif coordinate_type == Angle:\n            new_angle = _estimate_angle(coordinate,\n                                        shape.coord_format,\n                                        header)\n            new_coordlist.append(new_angle)\n\n        else:\n            new_coordlist.append(coordinate)\n\n    return new_coordlist", "response": "Convert the coordlist of shape to image coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_auth_info():\n    env_username = os.environ.get('JOTTACLOUD_USERNAME')\n    env_password = os.environ.get('JOTTACLOUD_PASSWORD')\n    netrc_auth = None\n    try:\n        netrc_file = netrc.netrc()\n        netrc_auth = netrc_file.authenticators('jottacloud.com')\n    except IOError:\n        # .netrc file doesn't exist\n        pass\n    netrc_username = None\n    netrc_password = None\n    if netrc_auth:\n        netrc_username, _, netrc_password = netrc_auth\n    username = env_username or netrc_username\n    password = env_password or netrc_password\n    if not (username and password):\n        raise JFSError('Could not find username and password in either env or ~/.netrc, '\n            'you need to add one of these to use these tools')\n    return (username, password)", "response": "Get authentication details to jottacloud."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deleted(self):\n        'Return datetime.datetime or None if the file isnt deleted'\n        _d = self.folder.attrib.get('deleted', None)\n        if _d is None: return None\n        return dateutil.parser.parse(str(_d))", "response": "Return datetime. datetime or None if the file isnt deleted"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating state of folder from Jottacloud server", "response": "def sync(self):\n        'Update state of folder from Jottacloud server'\n        log.info(\"syncing %r\" % self.path)\n        self.folder = self.jfs.get(self.path)\n        self.synced = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mkdir(self, foldername):\n        'Create a new subfolder and return the new JFSFolder'\n        #url = '%s?mkDir=true' % posixpath.join(self.path, foldername)\n        url = posixpath.join(self.path, foldername)\n        params = {'mkDir':'true'}\n        r = self.jfs.post(url, params)\n        self.sync()\n        return r", "response": "Create a new subfolder and return the new JFSFolder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete this folder and return a deleted JFSFolder", "response": "def delete(self):\n        'Delete this folder and return a deleted JFSFolder'\n        #url = '%s?dlDir=true' % self.path\n        params = {'dlDir':'true'}\n        r = self.jfs.post(self.path, params)\n        self.sync()\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hard_delete(self):\n        'Deletes without possibility to restore'\n        url = 'https://www.jottacloud.com/rest/webrest/%s/action/delete' % self.jfs.username\n        data = {'paths[]': self.path.replace(JFS_ROOT, ''),\n                'web': 'true',\n                'ts': int(time.time()),\n                'authToken': 0}\n        r = self.jfs.post(url, content=data)\n        return r", "response": "Deletes without possibility to restore"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove folder to a new name possibly a whole new path", "response": "def rename(self, newpath):\n        \"Move folder to a new name, possibly a whole new path\"\n        # POST https://www.jottacloud.com/jfs/**USERNAME**/Jotta/Sync/Ny%20mappe?mvDir=/**USERNAME**/Jotta/Sync/testFolder\n        #url = '%s?mvDir=/%s%s' % (self.path, self.jfs.username, newpath)\n        params = {'mvDir':'/%s%s' % (self.jfs.username, newpath)}\n        r = self.jfs.post(self.path,\n                          extra_headers={'Content-Type':'application/octet-stream'},\n                          params=params)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef up(self, fileobj_or_path, filename=None, upload_callback=None):\n        'Upload a file to current folder and return the new JFSFile'\n        close_on_done = False\n\n        if isinstance(fileobj_or_path, six.string_types):\n            filename = filename or os.path.basename(fileobj_or_path)\n            fileobj_or_path = open(fileobj_or_path, 'rb')\n            close_on_done = True\n        elif hasattr(fileobj_or_path, 'read'):  # file like\n            pass\n        else:\n            # TODO: handle generators here?\n            raise JFSError(\"Need filename or file-like object\")\n\n        if filename is None:\n            if hasattr(fileobj_or_path, 'name'):\n                filename = os.path.basename(fileobj_or_path.name)\n            else:\n                raise JFSError(\"Unable to guess filename\")\n\n        log.debug('.up %s ->  %s %s', repr(fileobj_or_path), repr(self.path), repr(filename))\n        r = self.jfs.up(posixpath.join(self.path, filename), fileobj_or_path,\n            upload_callback=upload_callback)\n        if close_on_done:\n            fileobj_or_path.close()\n        self.sync()\n        return r", "response": "Upload a file to current folder and return the new JFSFile"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef factory(fileobject, jfs, parentpath): # fileobject from lxml.objectify\n        'Class method to get the correct file class instatiated'\n        if hasattr(fileobject, 'currentRevision'): # a normal file\n            return JFSFile(fileobject, jfs, parentpath)\n        elif str(fileobject.latestRevision.state) == ProtoFile.STATE_INCOMPLETE:\n            return JFSIncompleteFile(fileobject, jfs, parentpath)\n        elif str(fileobject.latestRevision.state) == ProtoFile.STATE_CORRUPT:\n            return JFSCorruptFile(fileobject, jfs, parentpath)\n        else:\n            raise NotImplementedError('No JFS*File support for state %r. Please file a bug!' % fileobject.latestRevision.state)", "response": "Class method to get the correct file class instatiated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresume uploading an incomplete file after a previous upload was interrupted. Returns new file object", "response": "def resume(self, data):\n        'Resume uploading an incomplete file, after a previous upload was interrupted. Returns new file object'\n        if not hasattr(data, 'read'):\n            data = six.BytesIO(data)#StringIO(data)\n\n        #Check that we actually know from what byte to resume.\n        #If self.size === -1, it means we never got the value from the server.\n        #This is perfectly normal if the file was instatiated via e.g. a file listing,\n        #and not directly via JFS.getObject()\n        if self.size == -1:\n            log.debug('%r is an incomplete file, but .size is unknown. Refreshing the file object from server', self.path)\n            self.f = self.jfs.get(self.path)\n\n        #check if what we're asked to upload is actually the right file\n        md5 = calculate_md5(data)\n        if md5 != self.md5:\n            raise JFSError('''MD5 hashes don't match! Are you trying to resume with the wrong file?''')\n        log.debug('Resuming %s from offset %s', self.path, self.size)\n        return self.jfs.up(self.path, data, resume_offset=self.size)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the size of the file so far.", "response": "def size(self):\n        \"\"\"Bytes uploaded of the file so far.\n\n        Note that we only have the file size if the file was requested directly,\n        not if it's part of a folder listing.\n        \"\"\"\n        if hasattr(self.f.latestRevision, 'size'):\n            return int(self.f.latestRevision.size)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream(self, chunk_size=64*1024):\n        'Returns a generator to iterate over the file contents'\n        #return self.jfs.stream(url='%s?mode=bin' % self.path, chunk_size=chunk_size)\n        return self.jfs.stream(url=self.path, params={'mode':'bin'}, chunk_size=chunk_size)", "response": "Returns a generator to iterate over the file contents"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a part of the file from start byte to end byte ( integers )", "response": "def readpartial(self, start, end):\n        'Get a part of the file, from start byte to end byte (integers)'\n        #return self.jfs.raw('%s?mode=bin' % self.path,\n        return self.jfs.raw(url=self.path, params={'mode':'bin'},\n                            # note that we deduct 1 from end because\n                            # in http Range requests, the end value is included in the slice,\n                            # whereas in python, it is not\n                            extra_headers={'Range':'bytes=%s-%s' % (start, end-1)})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, data):\n        'Put, possibly replace, file contents with (new) data'\n        if not hasattr(data, 'read'):\n            data = six.BytesIO(data)#StringIO(data)\n        self.jfs.up(self.path, data)", "response": "Put possibly replace file contents with ( new ) data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self):\n        'Delete this file and return the new, deleted JFSFile'\n        #url = '%s?dl=true' % self.path\n        r = self.jfs.post(url=self.path, params={'dl':'true'})\n        return r", "response": "Delete this file and return the new deleted JFSFile"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef thumb(self, size=BIGTHUMB):\n        '''Get a thumbnail as string or None if the file isnt an image\n\n        size would be one of JFSFile.BIGTHUMB, .MEDIUMTHUMB, .SMALLTHUMB or .XLTHUMB'''\n        if not self.is_image():\n            return None\n        if not size in (self.BIGTHUMB, self.MEDIUMTHUMB, self.SMALLTHUMB, self.XLTHUMB):\n            raise JFSError('Invalid thumbnail size: %s for image %s' % (size, self.path))\n        #return self.jfs.raw('%s?mode=thumb&ts=%s' % (self.path, size))\n        return self.jfs.raw(url=self.path,\n                            params={'mode':'thumb', 'ts':size})", "response": "Get a thumbnail as string or None if the file isnt an image"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contents(self, path=None):\n        if isinstance(path, object) and hasattr(path, 'name'):\n            log.debug(\"passed an object, use .'name' as path value\")\n            # passed an object, use .'name' as path value\n            path = '/%s' % path.name\n        c = self._jfs.get('%s%s' % (self.path, path or '/'))\n        return c", "response": "Get all metadata for this device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef files(self, mountPoint):\n        if isinstance(mountPoint, six.string_types):\n            # shortcut: pass a mountpoint name\n            mountPoint = self.mountPoints[mountPoint]\n        try:\n            return [JFSFile(f, self, parentpath='%s/%s' % (self.path, mountPoint.name)) for f in self.contents(mountPoint).files.iterchildren()]\n        except AttributeError as err:\n            # no files at all\n            return [x for x in []]", "response": "Get an iterator of JFSFile objects from the given mountPoint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an iterator of JFSFolder objects from the given mountPoint.", "response": "def folders(self, mountPoint):\n        \"\"\"Get an iterator of JFSFolder() from the given mountPoint.\n\n        \"mountPoint\" may be either an actual mountPoint element from JFSDevice.mountPoints{} or its .name. \"\"\"\n        if isinstance(mountPoint, six.string_types):\n            # shortcut: pass a mountpoint name\n            mountPoint = self.mountPoints[mountPoint]\n        try:\n            return [JFSFolder(f, self, parentpath='%s/%s' % (self.path, mountPoint.name)) for f in self.contents(mountPoint).folders.iterchildren()]\n        except AttributeError as err:\n            # no files at all\n            return [x for x in []]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new mountpoint", "response": "def new_mountpoint(self, name):\n        \"\"\"Create a new mountpoint\"\"\"\n        url = posixpath.join(self.path, name)\n        r = self._jfs.post(url, extra_headers={'content-type': 'application/x-www-form-urlencoded'})\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sharedFiles(self):\n        'iterate over shared files and get their public URI'\n        for f in self.sharing.files.iterchildren():\n            yield (f.attrib['name'], f.attrib['uuid'],\n                'https://www.jottacloud.com/p/%s/%s' % (self.jfs.username, f.publicURI.text))", "response": "iterate over shared files and get their public URI"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over found files", "response": "def files(self):\n        'iterate over found files'\n        for _f in self.searchresult.files.iterchildren():\n            yield ProtoFile.factory(_f, jfs=self.jfs, parentpath=unicode(_f.abspath))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef request(self, url, extra_headers=None, params=None):\n        'Make a GET request for url, with or without caching'\n        if not url.startswith('http'):\n            # relative url\n            url = self.rootpath + url\n        log.debug(\"getting url: %r, extra_headers=%r, params=%r\", url, extra_headers, params)\n        if extra_headers is None: extra_headers={}\n        r = self.session.get(url, headers=extra_headers, params=params, timeout=1800) #max retries is set in __init__\n\n        if r.status_code in ( 500, ):\n            raise JFSError(r.reason)\n        return r", "response": "Make a GET request for url with or without caching"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a GET request for url and return whatever content we get", "response": "def raw(self, url, extra_headers=None, params=None):\n        'Make a GET request for url and return whatever content we get'\n        r = self.request(url, extra_headers=extra_headers, params=params)\n        # uncomment to dump raw xml\n#         with open('/tmp/%s.xml' % time.time(), 'wb') as f:\n#             f.write(r.content)\n\n        if not r.ok:\n            o = lxml.objectify.fromstring(r.content)\n            JFSError.raiseError(o, url)\n        return r.content"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a GET request for url and return the response content as a generic lxml. objectify object", "response": "def get(self, url, params=None):\n        'Make a GET request for url and return the response content as a generic lxml.objectify object'\n        url = self.escapeUrl(url)\n\n        content = six.BytesIO(self.raw(url, params=params))\n        # We need to make sure that the xml fits in available memory before we parse\n        # with lxml.objectify.fromstring(), or else it will bomb out.\n        # If it is too big, we need to buffer it to disk before we run it through objectify. see #87\n        #\n        # get length of buffer\n        content.seek(0,2)\n        contentlen = content.tell()\n        content.seek(0)\n\n        MAX_BUFFER_SIZE=1024*1024*200 # 200MB. TODO: find a way to compute this\n        if contentlen > MAX_BUFFER_SIZE:\n            # xml is too big to parse with lxml.objectify.fromstring()\n            contentfile = tempfile.NamedTemporaryFile()\n            contentfile.write(content.read())\n            o = lxml.objectify.parse(contentfile)\n        else:\n            o = lxml.objectify.fromstring(content.getvalue())\n        if o.tag == 'error':\n            JFSError.raiseError(o, url)\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getObject(self, url_or_requests_response, params=None):\n        'Take a url or some xml response from JottaCloud and wrap it up with the corresponding JFS* class'\n        if isinstance(url_or_requests_response, requests.models.Response):\n            # this is a raw xml response that we need to parse\n            url = url_or_requests_response.url\n            o = lxml.objectify.fromstring(url_or_requests_response.content)\n        else:\n            # this is an url that we need to fetch\n            url = url_or_requests_response\n            o = self.get(url, params=params) # (.get() will parse this for us)\n\n        parent = os.path.dirname(url).replace('up.jottacloud.com', 'www.jottacloud.com')\n        if o.tag == 'error':\n            JFSError.raiseError(o, url)\n        elif o.tag == 'device': return JFSDevice(o, jfs=self, parentpath=parent)\n        elif o.tag == 'folder': return JFSFolder(o, jfs=self, parentpath=parent)\n        elif o.tag == 'mountPoint': return JFSMountPoint(o, jfs=self, parentpath=parent)\n        elif o.tag == 'restoredFiles': return JFSFile(o, jfs=self, parentpath=parent)\n        elif o.tag == 'deleteFiles': return JFSFile(o, jfs=self, parentpath=parent)\n        elif o.tag == 'file':\n            return ProtoFile.factory(o, jfs=self, parentpath=parent)\n#             try:\n#                 if o.latestRevision.state == 'INCOMPLETE':\n#                     return JFSIncompleteFile(o, jfs=self, parentpath=parent)\n#                 elif o.latestRevision.state == 'CORRUPT':\n#                     return JFSCorruptFile(o, jfs=self, parentpath=parent)\n#             except AttributeError:\n#                 return JFSFile(o, jfs=self, parentpath=parent)\n        elif o.tag == 'enableSharing': return JFSenableSharing(o, jfs=self)\n        elif o.tag == 'user':\n            self.fs = o\n            return self.fs\n        elif o.tag == 'filedirlist': return JFSFileDirList(o, jfs=self, parentpath=parent)\n        elif o.tag == 'searchresult': return JFSsearchresult(o, jfs=self)\n        raise JFSError(\"invalid object: %s <- %s\" % (repr(o), url_or_requests_response))", "response": "Take a url or some xml response from JottaCloud and wrap it up with the corresponding JFS * class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post(self, url, content='', files=None, params=None, extra_headers={}, upload_callback=None):\n        'HTTP Post files[] or content (unicode string) to url'\n        if not url.startswith('http'):\n            # relative url\n            url = self.rootpath + url\n\n        log.debug('posting content (len %s) to url %s', len(content) if content is not None else '?', url)\n        headers = self.session.headers.copy()\n        headers.update(**extra_headers)\n\n        if not files is None:\n            m = requests_toolbelt.MultipartEncoder(fields=files)\n            if upload_callback is not None:\n                m_len = m.len # compute value for callback closure\n                def callback(monitor):\n                    upload_callback(monitor, m_len)\n\n                m = requests_toolbelt.MultipartEncoderMonitor(m, callback)\n            headers['content-type'] = m.content_type\n        else:\n            m = content\n        url = self.escapeUrl(url)\n        r = self.session.post(url, data=m, params=params, headers=headers)\n        if not r.ok:\n            log.warning('HTTP POST failed: %s', r.text)\n            raise JFSError(r.reason)\n        return self.getObject(r)", "response": "HTTP Post files [] or content ( unicode string to url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a fileobject to path HTTP POST - ing to up. jottacloud. com using the JottaCloud API", "response": "def up(self, path, fileobject, upload_callback=None, resume_offset=None):\n        \"Upload a fileobject to path, HTTP POST-ing to up.jottacloud.com, using the JottaCloud API\"\n        \"\"\"\n\n        *** WHAT DID I DO?: created file\n        ***\n\n        POST https://up.jottacloud.com/jfs/**USERNAME**/Jotta/Sync/testFolder/testFile.txt?cphash=d41d8cd98f00b204e9800998ecf8427e HTTP/1.1\n        User-Agent: Desktop_Jottacloud 3.0.22.203 Windows_8 6.2.9200 x86_64\n        Authorization: Basic ******************\n        X-JottaAPIVersion: 2.2\n        X-Jfs-DeviceName: **CENSORED**\n        JCreated: 2014-10-26T12:33:09Z+00:00\n        JModified: 2014-10-26T12:33:09Z+00:00\n        JMd5: d41d8cd98f00b204e9800998ecf8427e\n        JSize: 0\n        jx_csid: dOq1NCRer6uxuR/bFxihasj4QzBU3Tn7S2jVF1CE71YW1fGhxPFYYsw2T0XYjnJBtxKQzhWixmg+u5kp8bJtvMpIFHbhSDmPPSk+PVBf2UdFhXxli4YEII9a97eO4XBfn5QWAV1LJ2Z9l59jmnLkJQgfOyexkuQbxHdSLgQPXu8=\n        jx_lisence: M1v3p31oQf2OXvyAn2GvfS2I2oiMXrw+cofuMVHHI/2K+wlxhj22VkON6fN6fJMsGNcMzvcFYfmKPgL0Yf8TCO5A/6ULk6N8LctY3+fPegx+Jgbyc4hh0IXwnOdqa+UZ6Lg1ub4VXr5XnX3P3IxeVDg0VbcJnzv4TbFA+oMXmfM=\n        Content-Type: application/octet-stream\n        Content-Length: 0\n        Connection: Keep-Alive\n        Accept-Encoding: gzip\n        Accept-Language: nb-NO,en,*\n        Host: up.jottacloud.com\n        \"\"\"\n        url = path.replace('www.jottacloud.com', 'up.jottacloud.com')\n        # Calculate file length\n        fileobject.seek(0,2)\n        contentlen = fileobject.tell()\n\n        # Rewind read head to correct offset\n        # If we're resuming an incomplete upload, continue from that offset\n        try:\n            fileobject.seek(resume_offset)\n        except TypeError as e:\n            if resume_offset is None:\n                fileobject.seek(0)\n        except IOError as e:\n            log.exception(e)\n            log.warning('Could not seek to file offset %r, re-starting upload of %r from 0',\n                        resume_offset,\n                        url)\n            fileobject.seek(0)\n\n\n        # Calculate file md5 hash\n        md5hash = calculate_md5(fileobject)\n\n        log.debug('posting content (len %s, hash %s) to url %r', contentlen, md5hash, url)\n        try:\n            mtime = os.path.getmtime(fileobject.name)\n            timestamp = datetime.datetime.fromtimestamp(mtime).isoformat()\n        except Exception as e:\n            if hasattr(fileobject, 'name'):\n                log.exception('Problems getting mtime from fileobjet: %r', e)\n            timestamp = datetime.datetime.now().isoformat()\n        params = {'cphash': md5hash}\n        m = requests_toolbelt.MultipartEncoder({\n             'md5': ('', md5hash),\n             'modified': ('', timestamp),\n             'created': ('', timestamp),\n             'file': (os.path.basename(url), fileobject, 'application/octet-stream'),\n        })\n        headers = {'JMd5':md5hash,\n                   'JCreated': timestamp,\n                   'JModified': timestamp,\n                   'X-Jfs-DeviceName': 'Jotta',\n                   'JSize': str(contentlen), # headers have to be strings or bytes , cf #122\n                   'jx_csid': '',\n                   'jx_lisence': '',\n                   'content-type': m.content_type,\n                   }\n        fileobject.seek(0) # rewind read index for requests.post\n        files = {'md5': ('', md5hash),\n                 'modified': ('', timestamp),\n                 'created': ('', timestamp),\n                 'file': (os.path.basename(url), fileobject, 'application/octet-stream')}\n        return self.post(url, None, files=files, params=params, extra_headers=headers, upload_callback=upload_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new_device(self, name, type):\n        # at least android client also includes a \"cid\" with is derived from the unique device id\n        # and encrypted with a public key in the apk.  The field appears to be optional\n        url = posixpath.join(self.rootpath, name)\n        r = self.post(url, {'type': type})\n        return r", "response": "Create a new device on jottacloud."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn generator of configured devices", "response": "def devices(self):\n        'return generator of configured devices'\n        return self.fs is not None and [JFSDevice(d, self, parentpath=self.rootpath) for d in self.fs.devices.iterchildren()] or [x for x in []]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_region_filter(shape_list, origin=1):\n\n    filter_list = []\n    for shape in shape_list:\n\n        if shape.name == \"composite\":\n            continue\n\n        if shape.name == \"polygon\":\n            xy = np.array(shape.coord_list) - origin\n            f = region_filter.Polygon(xy[::2], xy[1::2])\n\n        elif shape.name == \"rotbox\" or shape.name == \"box\":\n            xc, yc, w, h, rot = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f = region_filter.Rotated(region_filter.Box(xc, yc, w, h),\n                                      rot, xc, yc)\n\n        elif shape.name == \"ellipse\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            angle = shape.coord_list[-1]\n\n            maj_list, min_list = shape.coord_list[2:-1:2], shape.coord_list[3:-1:2]\n\n            if len(maj_list) > 1:\n                w1, h1 = max(maj_list), max(min_list)\n                w2, h2 = min(maj_list), min(min_list)\n\n                f1 = region_filter.Ellipse(xc, yc, w1, h1) \\\n                     & ~region_filter.Ellipse(xc, yc, w2, h2)\n                f = region_filter.Rotated(f1, angle, xc, yc)\n            else:\n                w, h = maj_list[0], min_list[0]\n                f = region_filter.Rotated(region_filter.Ellipse(xc, yc, w, h),\n                                          angle, xc, yc)\n\n        elif shape.name == \"annulus\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            r_list = shape.coord_list[2:]\n\n            r1 = max(r_list)\n            r2 = min(r_list)\n\n            f = region_filter.Circle(xc, yc, r1) & ~region_filter.Circle(xc, yc, r2)\n\n        elif shape.name == \"circle\":\n            xc, yc, r = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f = region_filter.Circle(xc, yc, r)\n\n        elif shape.name == \"panda\":\n            xc, yc, a1, a2, an, r1, r2, rn = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f1 = region_filter.Circle(xc, yc, r2) & ~region_filter.Circle(xc, yc, r1)\n            f = f1 & region_filter.AngleRange(xc, yc, a1, a2)\n\n        elif shape.name == \"pie\":\n            xc, yc, r1, r2, a1, a2 = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f1 = region_filter.Circle(xc, yc, r2) & ~region_filter.Circle(xc, yc, r1)\n            f = f1 & region_filter.AngleRange(xc, yc, a1, a2)\n\n        elif shape.name == \"epanda\":\n            xc, yc, a1, a2, an, r11, r12, r21, r22, rn, angle = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f1 = region_filter.Ellipse(xc, yc, r21, r22) & ~region_filter.Ellipse(xc, yc, r11, r12)\n            f2 = f1 & region_filter.AngleRange(xc, yc, a1, a2)\n            f = region_filter.Rotated(f2, angle, xc, yc)\n            # f = f2 & region_filter.AngleRange(xc, yc, a1, a2)\n\n        elif shape.name == \"bpanda\":\n            xc, yc, a1, a2, an, r11, r12, r21, r22, rn, angle = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            f1 = region_filter.Box(xc, yc, r21, r22) & ~region_filter.Box(xc, yc, r11, r12)\n            f2 = f1 & region_filter.AngleRange(xc, yc, a1, a2)\n            f = region_filter.Rotated(f2, angle, xc, yc)\n            # f = f2 & region_filter.AngleRange(xc, yc, a1, a2)\n\n        else:\n            warnings.warn(\"'as_region_filter' does not know how to convert {0}\"\n                          \" to a region filter.\".format(shape.name))\n            continue\n\n        if shape.exclude:\n            filter_list = [region_filter.RegionOrList(*filter_list) & ~f]\n        else:\n            filter_list.append(f)\n\n    return region_filter.RegionOrList(*filter_list)", "response": "Returns a list of region_filter objects for the given shape_list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse DS9 region string into a ShapeList.", "response": "def parse(region_string):\n    \"\"\"Parse DS9 region string into a ShapeList.\n\n    Parameters\n    ----------\n    region_string : str\n        Region string\n\n    Returns\n    -------\n    shapes : `ShapeList`\n        List of `~pyregion.Shape`\n    \"\"\"\n    rp = RegionParser()\n    ss = rp.parse(region_string)\n    sss1 = rp.convert_attr(ss)\n    sss2 = _check_wcs(sss1)\n\n    shape_list, comment_list = rp.filter_shape2(sss2)\n    return ShapeList(shape_list, comment_list=comment_list)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open(fname):\n    with _builtin_open(fname) as fh:\n        region_string = fh.read()\n    return parse(region_string)", "response": "Open and read and parse DS9 region file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a region string and return a list of shapes.", "response": "def read_region(s):\n    \"\"\"Read region.\n\n    Parameters\n    ----------\n    s : str\n        Region string\n\n    Returns\n    -------\n    shapes : `ShapeList`\n        List of `~pyregion.Shape`\n    \"\"\"\n    rp = RegionParser()\n    ss = rp.parse(s)\n    sss1 = rp.convert_attr(ss)\n    sss2 = _check_wcs(sss1)\n\n    shape_list = rp.filter_shape(sss2)\n    return ShapeList(shape_list)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread region as image coordinates.", "response": "def read_region_as_imagecoord(s, header):\n    \"\"\"Read region as image coordinates.\n\n    Parameters\n    ----------\n    s : str\n        Region string\n    header : `~astropy.io.fits.Header`\n        FITS header\n\n    Returns\n    -------\n    shapes : `~pyregion.ShapeList`\n        List of `~pyregion.Shape`\n    \"\"\"\n    rp = RegionParser()\n    ss = rp.parse(s)\n    sss1 = rp.convert_attr(ss)\n    sss2 = _check_wcs(sss1)\n    sss3 = rp.sky_to_image(sss2, header)\n\n    shape_list = rp.filter_shape(sss3)\n    return ShapeList(shape_list)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting mask for a given region.", "response": "def get_mask(region, hdu, origin=1):\n    \"\"\"Get mask.\n\n    Parameters\n    ----------\n    region : `~pyregion.ShapeList`\n        List of `~pyregion.Shape`\n    hdu : `~astropy.io.fits.ImageHDU`\n        FITS image HDU\n    origin : float\n        TODO: document me\n\n    Returns\n    -------\n    mask : `~numpy.array`\n        Boolean mask\n\n    Examples\n    --------\n    >>> from astropy.io import fits\n    >>> from pyregion import read_region_as_imagecoord, get_mask\n    >>> hdu = fits.open(\"test.fits\")[0]\n    >>> region = \"test01.reg\"\n    >>> reg = read_region_as_imagecoord(open(region), f[0].header)\n    >>> mask = get_mask(reg, hdu)\n    \"\"\"\n    from pyregion.region_to_filter import as_region_filter\n\n    data = hdu.data\n    region_filter = as_region_filter(region, origin=origin)\n    mask = region_filter.mask(data)\n    return mask"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new shape list in image coordinates.", "response": "def as_imagecoord(self, header):\n        \"\"\"New shape list in image coordinates.\n\n        Parameters\n        ----------\n        header : `~astropy.io.fits.Header`\n            FITS header\n\n        Returns\n        -------\n        shape_list : `ShapeList`\n            New shape list, with coordinates of the each shape\n            converted to the image coordinate using the given header\n            information.\n        \"\"\"\n\n        comment_list = self._comment_list\n        if comment_list is None:\n            comment_list = cycle([None])\n\n        r = RegionParser.sky_to_image(zip(self, comment_list),\n                                      header)\n        shape_list, comment_list = zip(*list(r))\n        return ShapeList(shape_list, comment_list=comment_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the patches and txts for the current image.", "response": "def get_mpl_patches_texts(self, properties_func=None,\n                              text_offset=5.0,\n                              origin=1):\n        \"\"\"\n        Often, the regions files implicitly assume the lower-left\n        corner of the image as a coordinate (1,1). However, the python\n        convetion is that the array index starts from 0. By default\n        (``origin=1``), coordinates of the returned mpl artists have\n        coordinate shifted by (1, 1). If you do not want this shift,\n        use ``origin=0``.\n        \"\"\"\n        from .mpl_helper import as_mpl_artists\n        patches, txts = as_mpl_artists(self, properties_func,\n                                       text_offset,\n                                       origin=origin)\n\n        return patches, txts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a new filter object for the current image.", "response": "def get_filter(self, header=None, origin=1):\n        \"\"\"Get filter.\n        Often, the regions files implicitly assume the lower-left\n        corner of the image as a coordinate (1,1). However, the python\n        convetion is that the array index starts from 0. By default\n        (``origin=1``), coordinates of the returned mpl artists have\n        coordinate shifted by (1, 1). If you do not want this shift,\n        use ``origin=0``.\n\n        Parameters\n        ----------\n        header : `astropy.io.fits.Header`\n            FITS header\n        origin : {0, 1}\n            Pixel coordinate origin\n\n        Returns\n        -------\n        filter : TODO\n            Filter object\n        \"\"\"\n\n        from .region_to_filter import as_region_filter\n\n        if header is None:\n            if not self.check_imagecoord():\n                raise RuntimeError(\"the region has non-image coordinate. header is required.\")\n            reg_in_imagecoord = self\n        else:\n            reg_in_imagecoord = self.as_imagecoord(header)\n\n        region_filter = as_region_filter(reg_in_imagecoord, origin=origin)\n\n        return region_filter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mask(self, hdu=None, header=None, shape=None):\n\n        if hdu and header is None:\n            header = hdu.header\n        if hdu and shape is None:\n            shape = hdu.data.shape\n\n        region_filter = self.get_filter(header=header)\n        mask = region_filter.mask(shape)\n\n        return mask", "response": "Create a 2 - d mask."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite this shape list to a region file.", "response": "def write(self, outfile):\n        \"\"\"Write this shape list to a region file.\n\n        Parameters\n        ----------\n        outfile : str\n            File name\n        \"\"\"\n        if len(self) < 1:\n            print(\"WARNING: The region list is empty. The region file \"\n                  \"'{:s}' will be empty.\".format(outfile))\n            try:\n                outf = _builtin_open(outfile, 'w')\n                outf.close()\n                return\n            except IOError as e:\n                cmsg = \"Unable to create region file '{:s}'.\".format(outfile)\n                if e.args:\n                    e.args = (e.args[0] + '\\n' + cmsg,) + e.args[1:]\n                else:\n                    e.args = (cmsg,)\n                raise e\n\n        prev_cs = self[0].coord_format\n\n        outf = None\n        try:\n            outf = _builtin_open(outfile, 'w')\n\n            attr0 = self[0].attr[1]\n            defaultline = \" \".join([\"{:s}={:s}\".format(a, attr0[a])\n                                    for a in attr0 if a != 'text'])\n\n            # first line is globals\n            outf.write(\"global {0}\\n\".format(defaultline))\n            # second line must be a coordinate format\n            outf.write(\"{0}\\n\".format(prev_cs))\n\n            for shape in self:\n                shape_attr = '' if prev_cs == shape.coord_format \\\n                    else shape.coord_format + \"; \"\n                shape_excl = '-' if shape.exclude else ''\n                text_coordlist = [\"{:f}\".format(f) for f in shape.coord_list]\n                shape_coords = \"(\" + \",\".join(text_coordlist) + \")\"\n                shape_comment = \" # \" + shape.comment if shape.comment else ''\n\n                shape_str = (shape_attr + shape_excl + shape.name +\n                             shape_coords + shape_comment)\n\n                outf.write(\"{0}\\n\".format(shape_str))\n\n        except IOError as e:\n            cmsg = \"Unable to create region file \\'{:s}\\'.\".format(outfile)\n            if e.args:\n                e.args = (e.args[0] + '\\n' + cmsg,) + e.args[1:]\n            else:\n                e.args = (cmsg,)\n            raise e\n        finally:\n            if outf:\n                outf.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_active(feature):\n\n  if current_app:\n    feature_flagger = current_app.extensions.get(EXTENSION_NAME)\n    if feature_flagger:\n      return feature_flagger.check(feature)\n    else:\n      raise AssertionError(\"Oops. This application doesn't have the Flask-FeatureFlag extention installed.\")\n\n  else:\n    log.warn(u\"Got a request to check for {feature} but we're running outside the request context. Check your setup. Returning False\".format(feature=feature))\n    return False", "response": "Check if a feature is active"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_active_feature(feature, redirect_to=None, redirect=None):\n  def _is_active_feature(func):\n    @wraps(func)\n    def wrapped(*args, **kwargs):\n\n      if not is_active(feature):\n        url = redirect_to\n        if redirect:\n          url = url_for(redirect)\n\n        if url:\n          log.debug(u'Feature {feature} is off, redirecting to {url}'.format(feature=feature, url=url))\n          return _redirect(url, code=302)\n        else:\n          log.debug(u'Feature {feature} is off, aborting request'.format(feature=feature))\n          abort(404)\n\n      return func(*args, **kwargs)\n    return wrapped\n  return _is_active_feature", "response": "Decorator for views that checks if a feature is off and redirects to a URL if you d rather."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the application with our configuration and setup and add a jinja function test", "response": "def init_app(self, app):\n    \"\"\" Add ourselves into the app config and setup, and add a jinja function test \"\"\"\n\n    app.config.setdefault(FEATURE_FLAGS_CONFIG, {})\n    app.config.setdefault(RAISE_ERROR_ON_MISSING_FEATURES, False)\n\n    if hasattr(app, \"add_template_test\"):\n      # flask 0.10 and higher has a proper hook\n      app.add_template_test(self.check, name=self.JINJA_TEST_NAME)\n    else:\n      app.jinja_env.tests[self.JINJA_TEST_NAME] = self.check\n\n    if not hasattr(app, 'extensions'):\n      app.extensions = {}\n    app.extensions[EXTENSION_NAME] = self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a feature flag is set.", "response": "def check(self, feature):\n    \"\"\" Loop through all our feature flag checkers and return true if any of them are true.\n\n    The order of handlers matters - we will immediately return True if any handler returns true.\n\n    If you want to a handler to return False and stop the chain, raise the StopCheckingFeatureFlags exception.\"\"\"\n    found = False\n    for handler in self.handlers:\n      try:\n        if handler(feature):\n           return True\n      except StopCheckingFeatureFlags:\n        return False\n      except NoFeatureFlagFound:\n        pass\n      else:\n        found = True\n\n    if not found:\n      message = u\"No feature flag defined for {feature}\".format(feature=feature)\n      if current_app.debug and current_app.config.get(RAISE_ERROR_ON_MISSING_FEATURES, False):\n        raise KeyError(message)\n      else:\n        log.info(message)\n        missing_feature.send(self, feature=feature)\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_attr(attr_list, global_attrs):\n    local_attr = [], {}\n    for kv in attr_list:\n        keyword = kv[0]\n        if len(kv) == 1:\n            local_attr[0].append(keyword)\n            continue\n        elif len(kv) == 2:\n            value = kv[1]\n        elif len(kv) > 2:\n            value = kv[1:]\n\n        if keyword == 'tag':\n            local_attr[1].setdefault(keyword, set()).add(value)\n        else:\n            local_attr[1][keyword] = value\n\n    attr0 = copy.copy(global_attrs[0])\n    attr1 = copy.copy(global_attrs[1])\n\n    if local_attr[0]:\n        attr0.extend(local_attr[0])\n\n    if local_attr[1]:\n        attr1.update(local_attr[1])\n\n    return attr0, attr1", "response": "Returns a tuple of attributes and the values of the local attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear cache of results from a specific path", "response": "def yank_path(self, path):\n        \"\"\"Clear cache of results from a specific path\"\"\"\n        for func in self._caches:\n            cache = {}\n            for key in self._caches[func].keys():\n                log.debug(\"cache key %s for func %s\", key, func)\n                if path in key[0]:\n                    log.debug(\"del cache key %s\", key)\n                    del self._caches[func][key]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getpath(self, path):\n        \"A wrapper of JFS.getObject(), with some tweaks that make sense in a file system.\"\n        if is_blacklisted(path):\n            raise JottaFuseError('Blacklisted file, refusing to retrieve it')\n\n        return self.client.getObject(path)", "response": "A wrapper of JFS. getObject with some tweaks that make sense in a file system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning after a read or write operation has finished. This is where we upload on writes", "response": "def release(self, path, fh):\n        \"Run after a read or write operation has finished. This is where we upload on writes\"\n        #print \"release! inpath:\", path in self.__newfiles.keys()\n        # if the path exists in self.__newfiles.keys(), we have a new version to upload\n        try:\n            f = self.__newfiles[path] # make a local shortcut to Stringio object\n            f.seek(0, os.SEEK_END)\n            if f.tell() > 0: # file has length\n                self.client.up(path, f) # upload to jottacloud\n            del self.__newfiles[path]\n            del f\n            self._dirty(path)\n        except KeyError:\n            pass\n        return ESUCCESS"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a statvfs ( 3 ) structure for stat and df and friends", "response": "def statfs(self, path):\n        \"Return a statvfs(3) structure, for stat and df and friends\"\n        # from fuse.py source code:\n        #\n        # class c_statvfs(Structure):\n        # _fields_ = [\n        # ('f_bsize', c_ulong), # preferred size of file blocks, in bytes\n        # ('f_frsize', c_ulong), # fundamental size of file blcoks, in bytes\n        # ('f_blocks', c_fsblkcnt_t), # total number of blocks in the filesystem\n        # ('f_bfree', c_fsblkcnt_t), # number of free blocks\n        # ('f_bavail', c_fsblkcnt_t), # free blocks avail to non-superuser\n        # ('f_files', c_fsfilcnt_t), # total file nodes in file system\n        # ('f_ffree', c_fsfilcnt_t), # free file nodes in fs\n        # ('f_favail', c_fsfilcnt_t)] #\n        #\n        # On Mac OS X f_bsize and f_frsize must be a power of 2\n        # (minimum 512).\n\n        _blocksize = 512\n        _usage = self.client.usage\n        _fs_size = self.client.capacity\n        if _fs_size == -1: # unlimited\n            # Since backend is supposed to be unlimited,\n            # always return a half-full filesystem, but at least 1 TB)\n            _fs_size = max(2 * _usage, 1024 ** 4)\n        _bfree = ( _fs_size - _usage ) // _blocksize\n        return {\n            'f_bsize': _blocksize,\n            'f_frsize': _blocksize,\n            'f_blocks': _fs_size // _blocksize,\n            'f_bfree': _bfree,\n            'f_bavail': _bfree,\n            # 'f_files': c_fsfilcnt_t,\n            # 'f_ffree': c_fsfilcnt_t,\n            # 'f_favail': c_fsfilcnt_t\n\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a symlink in jottafuse.", "response": "def symlink(self, linkname, existing_file):\n        \"\"\"Called to create a symlink `target -> source` (e.g. ln -s existing_file linkname). In jottafuse, we upload the _contents_ of source.\n\n        This is a handy shortcut for streaming uploads directly from disk, without reading the file\n        into memory first\"\"\"\n        log.info(\"***SYMLINK* %s (link) -> %s (existing)\", linkname, existing_file)\n        sourcepath = os.path.abspath(existing_file)\n        if not os.path.exists(sourcepath): # broken symlink\n            raise OSError(errno.ENOENT, '')\n        try:\n            with open(sourcepath) as sourcefile:\n                self.client.up(linkname, sourcefile)\n                return ESUCCESS\n        except Exception as e:\n            log.exception(e)\n\n        raise OSError(errno.ENOENT, '')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef truncate(self, path, length, fh=None):\n        \"Download existing path, truncate and reupload\"\n        try:\n            f = self._getpath(path)\n        except JFS.JFSError:\n            raise OSError(errno.ENOENT, '')\n        if isinstance(f, (JFS.JFSFile, JFS.JFSFolder)) and f.is_deleted():\n            raise OSError(errno.ENOENT)\n        data = StringIO(f.read())\n        data.truncate(length)\n        try:\n            self.client.up(path, data) # replace file contents\n            self._dirty(path)\n            return ESUCCESS\n        except:\n            raise OSError(errno.ENOENT, '')", "response": "Download existing path truncate and reupload"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert bytestring from command line to unicode using default file system encoding", "response": "def commandline_text(bytestring):\n    'Convert bytestring from command line to unicode, using default file system encoding'\n    if six.PY3:\n        return bytestring\n    unicode_string = bytestring.decode(sys.getfilesystemencoding())\n    return unicode_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a ShapeList into shapes with coordinates in image coordinates and comments in the original WCS header.", "response": "def sky_to_image(shape_list, header):\n        \"\"\"Converts a `ShapeList` into shapes with coordinates in image coordinates\n\n        Parameters\n        ----------\n        shape_list : `pyregion.ShapeList`\n            The ShapeList to convert\n        header : `~astropy.io.fits.Header`\n            Specifies what WCS transformations to use.\n\n        Yields\n        -------\n        shape, comment : Shape, str\n            Shape with image coordinates and the associated comment\n\n        Note\n        ----\n        The comments in the original `ShapeList` are unaltered\n\n        \"\"\"\n\n        for shape, comment in shape_list:\n            if isinstance(shape, Shape) and \\\n                    (shape.coord_format not in image_like_coordformats):\n\n                new_coords = convert_to_imagecoord(shape, header)\n\n                l1n = copy.copy(shape)\n\n                l1n.coord_list = new_coords\n                l1n.coord_format = \"image\"\n                yield l1n, comment\n\n            elif isinstance(shape, Shape) and shape.coord_format == \"physical\":\n\n                if header is None:\n                    raise RuntimeError(\"Physical coordinate is not known.\")\n\n                new_coordlist = convert_physical_to_imagecoord(shape, header)\n\n                l1n = copy.copy(shape)\n\n                l1n.coord_list = new_coordlist\n                l1n.coord_format = \"image\"\n                yield l1n, comment\n\n            else:\n                yield shape, comment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when a file or directory is modified.", "response": "def on_modified(self, event, dry_run=False, remove_uploaded=True):\n        'Called when a file (or directory) is modified. '\n        super(ArchiveEventHandler, self).on_modified(event)\n        src_path = event.src_path\n        if event.is_directory:\n            if not platform.is_darwin():\n                log.info(\"event is a directory, safe to ignore\")\n                return\n            # OSX is behaving erratically and we need to paper over it.\n            # the OS only reports every other file event,\n            # but always fires off a directory event when a file has changed. (OSX 10.9 tested)\n            # so we need to find the actual file changed and then go on from there\n            files = [event.src_path+\"/\"+f for f in os.listdir(event.src_path)]\n            try:\n                src_path = max(files, key=os.path.getmtime)\n            except (OSError, ValueError) as e: # broken symlink or directory empty\n                return\n        log.info('Modified file detectd: %s', src_path)\n        #\n        # we're receiving events at least two times: on file open and on file close.\n        # OSes might report even more\n        # we're only interested in files that are closed (finished), so we try to\n        # open it. if it is locked, we can infer that someone is still writing to it.\n        # this works on platforms: windows, ... ?\n        # TODO: investigate http://stackoverflow.com/a/3876461 for POSIX support\n        try:\n            open(src_path)   # win exclusively\n            os.open(src_path, os.O_EXLOCK) # osx exclusively\n        except IOError: # file is not finished\n            log.info('File is not finished')\n            return\n        except AttributeError: # no suuport for O_EXLOCK (only BSD)\n            pass\n        return self._new(src_path, dry_run, remove_uploaded)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when a file ( or directory is created.", "response": "def on_created(self, event, dry_run=False, remove_uploaded=True):\n        'Called when a file (or directory) is created. '\n        super(ArchiveEventHandler, self).on_created(event)\n        log.info(\"created: %s\", event)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _new(self, src_path, dry_run=False, remove_uploaded=False):\n            'Code to upload'\n            # are we getting a symbolic link?\n            if os.path.islink(src_path):\n                sourcefile = os.path.normpath(os.path.join(self.topdir, os.readlink(src_path)))\n                if not os.path.exists(sourcefile): # broken symlink\n                    log.error(\"broken symlink %s->%s\", src_path, sourcefile)\n                    raise IOError(\"broken symliknk %s->%s\", src_path, sourcefile)\n                jottapath = self.get_jottapath(src_path, filename=os.path.basename(sourcefile))\n            elif os.path.splitext(src_path)[1].lower() == '.lnk':\n                # windows .lnk\n                sourcefile = os.path.normpath(readlnk(src_path))\n                if not os.path.exists(sourcefile): # broken symlink\n                    log.error(\"broken fat32lnk %s->%s\", src_path, sourcefile)\n                    raise IOError(\"broken fat32lnk %s->%s\", src_path, sourcefile)\n                jottapath = self.get_jottapath(src_path, filename=os.path.basename(sourcefile))\n            else:\n                sourcefile = src_path\n                if not os.path.exists(sourcefile): # file not exis\n                    log.error(\"file does not exist: %s\", sourcefile)\n                    raise IOError(\"file does not exist: %s\", sourcefile)\n                jottapath = self.get_jottapath(src_path)\n\n            log.info('Uploading file %s to %s', sourcefile, jottapath)\n            if not dry_run:\n                if not jottacloud.new(sourcefile, jottapath, self.jfs):\n                    log.error('Uploading file %s failed', sourcefile)\n                    raise\n            if remove_uploaded:\n                log.info('Removing file after upload: %s', src_path)\n                if not dry_run:\n                    os.remove(src_path)", "response": "Upload a file to the jotta cloud"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _estimate_angle(angle, reg_coordinate_frame, header):\n    y_axis_rot = _calculate_rotation_angle(reg_coordinate_frame, header)\n    return angle - y_axis_rot", "response": "Transform an angle into a different frame\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the rotation angle from the region to the header s frame", "response": "def _calculate_rotation_angle(reg_coordinate_frame, header):\n    \"\"\"Calculates the rotation angle from the region to the header's frame\n\n    This attempts to be compatible with the implementation used by SAOImage\n    DS9. In particular, this measures the rotation of the north axis as\n    measured at the center of the image, and therefore requires a\n    `~astropy.io.fits.Header` object with defined 'NAXIS1' and 'NAXIS2'\n    keywords.\n\n    Parameters\n    ----------\n    reg_coordinate_frame : str\n        Coordinate frame used by the region file\n\n    header : `~astropy.io.fits.Header` instance\n        Header describing the image\n\n    Returns\n    -------\n    y_axis_rot : float\n        Degrees by which the north axis in the region's frame is rotated when\n        transformed to pixel coordinates\n    \"\"\"\n    new_wcs = WCS(header)\n    region_frame = SkyCoord(\n        '0d 0d',\n        frame=reg_coordinate_frame,\n        obstime='J2000')\n    region_frame = SkyCoord(\n        '0d 0d',\n        frame=reg_coordinate_frame,\n        obstime='J2000',\n        equinox=region_frame.equinox)\n\n    origin = SkyCoord.from_pixel(\n        header['NAXIS1'] / 2,\n        header['NAXIS2'] / 2,\n        wcs=new_wcs,\n        origin=1).transform_to(region_frame)\n\n    offset = proj_plane_pixel_scales(new_wcs)[1]\n\n    origin_x, origin_y = origin.to_pixel(new_wcs, origin=1)\n    origin_lon = origin.data.lon.degree\n    origin_lat = origin.data.lat.degree\n\n    offset_point = SkyCoord(\n        origin_lon, origin_lat + offset, unit='degree',\n        frame=origin.frame.name, obstime='J2000')\n    offset_x, offset_y = offset_point.to_pixel(new_wcs, origin=1)\n\n    north_rot = np.arctan2(\n        offset_y - origin_y,\n        offset_x - origin_x) / np.pi * 180.\n\n    cdelt = new_wcs.wcs.get_cdelt()\n    if (cdelt > 0).all() or (cdelt < 0).all():\n        return north_rot - 90\n    else:\n        return -(north_rot - 90)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a shape list to a list of patches and artists.", "response": "def as_mpl_artists(shape_list,\n                   properties_func=None,\n                   text_offset=5.0, origin=1):\n    \"\"\"\n    Converts a region list to a list of patches and a list of artists.\n\n\n    Optional Keywords:\n    [ text_offset ] - If there is text associated with the regions, add\n    some vertical offset (in pixels) to the text so that it doesn't overlap\n    with the regions.\n\n    Often, the regions files implicitly assume the lower-left corner\n    of the image as a coordinate (1,1). However, the python convetion\n    is that the array index starts from 0. By default (origin = 1),\n    coordinates of the returned mpl artists have coordinate shifted by\n    (1, 1). If you do not want this shift, set origin=0.\n    \"\"\"\n\n    patch_list = []\n    artist_list = []\n\n    if properties_func is None:\n        properties_func = properties_func_default\n\n    # properties for continued(? multiline?) regions\n    saved_attrs = None\n\n    for shape in shape_list:\n\n        patches = []\n\n        if saved_attrs is None:\n            _attrs = [], {}\n        else:\n            _attrs = copy.copy(saved_attrs[0]), copy.copy(saved_attrs[1])\n\n        kwargs = properties_func(shape, _attrs)\n\n        if shape.name == \"composite\":\n            saved_attrs = shape.attr\n            continue\n\n        if saved_attrs is None and shape.continued:\n            saved_attrs = shape.attr\n        #         elif (shape.name in shape.attr[1]):\n        #             if (shape.attr[1][shape.name] != \"ignore\"):\n        #                 saved_attrs = shape.attr\n\n        if not shape.continued:\n            saved_attrs = None\n\n        # text associated with the shape\n        txt = shape.attr[1].get(\"text\")\n\n        if shape.name == \"polygon\":\n            xy = np.array(shape.coord_list)\n            xy.shape = -1, 2\n\n            # -1 for change origin to 0,0\n            patches = [mpatches.Polygon(xy - origin, closed=True, **kwargs)]\n\n        elif shape.name == \"rotbox\" or shape.name == \"box\":\n            xc, yc, w, h, rot = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            _box = np.array([[-w / 2., -h / 2.],\n                             [-w / 2., h / 2.],\n                             [w / 2., h / 2.],\n                             [w / 2., -h / 2.]])\n            box = _box + [xc, yc]\n            rotbox = rotated_polygon(box, xc, yc, rot)\n            patches = [mpatches.Polygon(rotbox, closed=True, **kwargs)]\n\n        elif shape.name == \"ellipse\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            angle = shape.coord_list[-1]\n\n            maj_list, min_list = shape.coord_list[2:-1:2], shape.coord_list[3:-1:2]\n\n            patches = [mpatches.Ellipse((xc, yc), 2 * maj, 2 * min,\n                                        angle=angle, **kwargs)\n                       for maj, min in zip(maj_list, min_list)]\n\n        elif shape.name == \"annulus\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            r_list = shape.coord_list[2:]\n\n            patches = [mpatches.Ellipse((xc, yc), 2 * r, 2 * r, **kwargs) for r in r_list]\n\n        elif shape.name == \"circle\":\n            xc, yc, major = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            patches = [mpatches.Ellipse((xc, yc), 2 * major, 2 * major, angle=0, **kwargs)]\n\n        elif shape.name == \"panda\":\n            xc, yc, a1, a2, an, r1, r2, rn = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            patches = [mpatches.Arc((xc, yc), rr * 2, rr * 2, angle=0,\n                                    theta1=a1, theta2=a2, **kwargs)\n                       for rr in np.linspace(r1, r2, rn + 1)]\n\n            for aa in np.linspace(a1, a2, an + 1):\n                xx = np.array([r1, r2]) * np.cos(aa / 180. * np.pi) + xc\n                yy = np.array([r1, r2]) * np.sin(aa / 180. * np.pi) + yc\n                p = Path(np.transpose([xx, yy]))\n                patches.append(mpatches.PathPatch(p, **kwargs))\n\n        elif shape.name == \"pie\":\n            xc, yc, r1, r2, a1, a2 = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            patches = [mpatches.Arc((xc, yc), rr * 2, rr * 2, angle=0,\n                                    theta1=a1, theta2=a2, **kwargs)\n                       for rr in [r1, r2]]\n\n            for aa in [a1, a2]:\n                xx = np.array([r1, r2]) * np.cos(aa / 180. * np.pi) + xc\n                yy = np.array([r1, r2]) * np.sin(aa / 180. * np.pi) + yc\n                p = Path(np.transpose([xx, yy]))\n                patches.append(mpatches.PathPatch(p, **kwargs))\n\n        elif shape.name == \"epanda\":\n            xc, yc, a1, a2, an, r11, r12, r21, r22, rn, angle = shape.coord_list\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            # mpl takes angle a1, a2 as angle as in circle before\n            # transformation to ellipse.\n\n            x1, y1 = cos(a1 / 180. * pi), sin(a1 / 180. * pi) * r11 / r12\n            x2, y2 = cos(a2 / 180. * pi), sin(a2 / 180. * pi) * r11 / r12\n\n            a1, a2 = atan2(y1, x1) / pi * 180., atan2(y2, x2) / pi * 180.\n\n            patches = [mpatches.Arc((xc, yc), rr1 * 2, rr2 * 2,\n                                    angle=angle, theta1=a1, theta2=a2,\n                                    **kwargs)\n                       for rr1, rr2 in zip(np.linspace(r11, r21, rn + 1),\n                                           np.linspace(r12, r22, rn + 1))]\n\n            for aa in np.linspace(a1, a2, an + 1):\n                xx = np.array([r11, r21]) * np.cos(aa / 180. * np.pi)\n                yy = np.array([r11, r21]) * np.sin(aa / 180. * np.pi)\n                p = Path(np.transpose([xx, yy]))\n                tr = Affine2D().scale(1, r12 / r11).rotate_deg(angle).translate(xc, yc)\n                p2 = tr.transform_path(p)\n                patches.append(mpatches.PathPatch(p2, **kwargs))\n\n        elif shape.name == \"text\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n\n            if txt:\n                _t = _get_text(txt, xc, yc, 0, 0, **kwargs)\n                artist_list.append(_t)\n\n        elif shape.name == \"point\":\n            xc, yc = shape.coord_list[:2]\n            # -1 for change origin to 0,0\n            xc, yc = xc - origin, yc - origin\n            artist_list.append(Line2D([xc], [yc],\n                                      **kwargs))\n\n            if txt:\n                textshape = copy.copy(shape)\n                textshape.name = \"text\"\n                textkwargs = properties_func(textshape, _attrs)\n                _t = _get_text(txt, xc, yc, 0, text_offset,\n                               va=\"bottom\",\n                               **textkwargs)\n                artist_list.append(_t)\n\n        elif shape.name in [\"line\", \"vector\"]:\n            if shape.name == \"line\":\n                x1, y1, x2, y2 = shape.coord_list[:4]\n                # -1 for change origin to 0,0\n                x1, y1, x2, y2 = x1 - origin, y1 - origin, x2 - origin, y2 - origin\n\n                a1, a2 = shape.attr[1].get(\"line\", \"0 0\").strip().split()[:2]\n\n                arrowstyle = \"-\"\n                if int(a1):\n                    arrowstyle = \"<\" + arrowstyle\n                if int(a2):\n                    arrowstyle = arrowstyle + \">\"\n\n            else:  # shape.name == \"vector\"\n                x1, y1, l, a = shape.coord_list[:4]\n                # -1 for change origin to 0,0\n                x1, y1 = x1 - origin, y1 - origin\n                x2, y2 = x1 + l * np.cos(a / 180. * np.pi), y1 + l * np.sin(a / 180. * np.pi)\n                v1 = int(shape.attr[1].get(\"vector\", \"0\").strip())\n\n                if v1:\n                    arrowstyle = \"->\"\n                else:\n                    arrowstyle = \"-\"\n\n            patches = [mpatches.FancyArrowPatch(posA=(x1, y1),\n                                                posB=(x2, y2),\n                                                arrowstyle=arrowstyle,\n                                                arrow_transmuter=None,\n                                                connectionstyle=\"arc3\",\n                                                patchA=None, patchB=None,\n                                                shrinkA=0, shrinkB=0,\n                                                connector=None,\n                                                **kwargs)]\n\n        else:\n            warnings.warn(\"'as_mpl_artists' does not know how to convert {0} \"\n                          \"to mpl artist\".format(shape.name))\n\n        patch_list.extend(patches)\n\n        if txt and patches:\n            # the text associated with a shape uses different\n            # matplotlib keywords than the shape itself for, e.g.,\n            # color\n            textshape = copy.copy(shape)\n            textshape.name = \"text\"\n            textkwargs = properties_func(textshape, _attrs)\n\n            # calculate the text position\n            _bb = [p.get_window_extent() for p in patches]\n\n            # this is to work around backward-incompatible change made\n            # in matplotlib 1.2. This change is later reverted so only\n            # some versions are affected. With affected version of\n            # matplotlib, get_window_extent method calls get_transform\n            # method which sets the _transformSet to True, which is\n            # not desired.\n            for p in patches:\n                p._transformSet = False\n\n            _bbox = Bbox.union(_bb)\n            x0, y0, x1, y1 = _bbox.extents\n            xc = .5 * (x0 + x1)\n\n            _t = _get_text(txt, xc, y1, 0, text_offset,\n                           va=\"bottom\",\n                           **textkwargs)\n            artist_list.append(_t)\n\n    return patch_list, artist_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates and return a SyncFile tuple from filename.", "response": "def sf(f, dirpath, jottapath):\n    \"\"\"Create and return a SyncFile tuple from filename.\n\n            localpath will be a byte string with utf8 code points\n            jottapath will be a unicode string\"\"\"\n    log.debug('Create SyncFile from %s', repr(f))\n    log.debug('Got encoded filename %r, joining with dirpath %r', _encode_filename_to_filesystem(f), dirpath)\n    return SyncFile(localpath=os.path.join(dirpath, _encode_filename_to_filesystem(f)),\n                  jottapath=posixpath.join(_decode_filename_to_unicode(jottapath), _decode_filename_to_unicode(f)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates localtopdir to jottapath. Returns unicode string", "response": "def get_jottapath(localtopdir, dirpath, jottamountpoint):\n    \"\"\"Translate localtopdir to jottapath. Returns unicode string\"\"\"\n    log.debug(\"get_jottapath %r %r %r\", localtopdir, dirpath, jottamountpoint)\n    normpath =  posixpath.normpath(posixpath.join(jottamountpoint, posixpath.basename(localtopdir),\n                                   posixpath.relpath(dirpath, localtopdir)))\n    return _decode_filename_to_unicode(normpath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_file(jottapath, JFS):\n    log.debug(\"is_file %r\", jottapath)\n    try:\n        jf = JFS.getObject(jottapath)\n    except JFSNotFoundError:\n        return False\n    return isinstance(jf, JFSFile)", "response": "Check if a file exists on jottacloud"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filelist(jottapath, JFS):\n    log.debug(\"filelist %r\", jottapath)\n    try:\n        jf = JFS.getObject(jottapath)\n    except JFSNotFoundError:\n        return set() # folder does not exist, so pretend it is an empty folder\n    if not isinstance(jf, JFSFolder):\n        return False\n    return set([f.name for f in jf.files() if not f.is_deleted()])", "response": "Get a set of files from a jottacloud folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef folderlist(jottapath, JFS):\n    logging.debug(\"folderlist %r\", jottapath)\n    try:\n        jf = JFS.getObject(jottapath)\n    except JFSNotFoundError:\n        return set() # folder does not exist, so pretend it is an empty folder\n    if not isinstance(jf, JFSFolder):\n        return False\n    return set([f.name for f in jf.folders() if not f.is_deleted()])", "response": "Get a set of folders from a jottacloud folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare(localtopdir, jottamountpoint, JFS, followlinks=False, exclude_patterns=None):\n    def excluded(unicodepath, fname):\n        fpath = os.path.join(unicodepath, _decode_filename_to_unicode(fname))\n        # skip FIFOs, block devices, character devices and the like, see bug#129\n        mode = os.stat(fpath).st_mode\n        if not (stat.S_ISREG(mode) or \n                stat.S_ISLNK(mode) or\n                stat.S_ISDIR(mode)): # we only like regular files, dirs or symlinks\n            return True\n        if exclude_patterns is None:\n            return False\n        for p in exclude_patterns:\n            if p.search(fpath):\n                log.debug(\"%r excluded by pattern %r\", fpath, p.pattern)\n                return True\n        return False\n    bytestring_localtopdir = _encode_filename_to_filesystem(localtopdir)\n    for dirpath, dirnames, filenames in os.walk(bytestring_localtopdir, followlinks=followlinks):\n        # to keep things explicit, and avoid encoding/decoding issues,\n        # keep a bytestring AND a unicode variant of dirpath\n        dirpath = _encode_filename_to_filesystem(dirpath)\n        unicodepath = _decode_filename_to_unicode(dirpath)\n        log.debug(\"compare walk: %r -> %s files \", unicodepath, len(filenames))\n\n        # create set()s of local files and folders\n        # paths will be unicode strings\n        localfiles = set([f for f in filenames if not excluded(unicodepath, f)]) # these are on local disk\n        localfolders = set([f for f in dirnames if not excluded(unicodepath, f)]) # these are on local disk\n        jottapath = get_jottapath(localtopdir, unicodepath, jottamountpoint) # translate to jottapath\n        log.debug(\"compare jottapath: %r\", jottapath)\n\n        # create set()s of remote files and folders\n        # paths will be unicode strings\n        cloudfiles = filelist(jottapath, JFS) # set(). these are on jottacloud\n        cloudfolders = folderlist(jottapath, JFS)\n\n        log.debug(\"--cloudfiles: %r\", cloudfiles)\n        log.debug(\"--localfiles: %r\", localfiles)\n        log.debug(\"--cloudfolders: %r\", cloudfolders)\n\n        onlylocal = [ sf(f, dirpath, jottapath) for f in localfiles.difference(cloudfiles)]\n        onlyremote = [ sf(f, dirpath, jottapath) for f in cloudfiles.difference(localfiles)]\n        bothplaces = [ sf(f, dirpath, jottapath) for f in localfiles.intersection(cloudfiles)]\n        onlyremotefolders = [ sf(f, dirpath, jottapath) for f in cloudfolders.difference(localfolders)]\n        yield dirpath, onlylocal, onlyremote, bothplaces, onlyremotefolders", "response": "Compare the local top directory with the JottaCloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget bytestring filename and return unicode.", "response": "def _decode_filename_to_unicode(f):\n    '''Get bytestring filename and return unicode.\n    First, try to decode from default file system encoding\n    If that fails, use ``chardet`` module to guess encoding.\n    As a last resort, try to decode as utf-8.\n\n    If the argument already is unicode, return as is'''\n\n    log.debug('_decode_filename_to_unicode(%s)', repr(f))\n    if isinstance(f, unicode):\n        return f\n    try:\n        return f.decode(sys.getfilesystemencoding())\n    except UnicodeDecodeError:\n        charguess = chardet.detect(f)\n        log.debug(\"chardet filename: %r -> %r\", f, charguess)\n        if charguess['encoding'] is not None:\n            try:\n                return f.decode(charguess['encoding'])\n            except UnicodeDecodeError:\n                pass\n        log.warning('Cannot understand decoding of this filename: %r (guessed %r, but was wrong)',\n                    f, charguess)\n        log.debug('Trying utf-8 to decode %r', f)\n        try:\n            return f.decode('utf-8')\n        except UnicodeDecodeError:\n            pass\n        log.debug('Trying latin1 to decode %r', f)\n        try:\n            return f.decode('latin1')\n        except UnicodeDecodeError:\n            log.warning('Exhausted all options. Decoding %r to safe ascii', f)\n            return f.decode('ascii', errors='ignore')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _encode_filename_to_filesystem(f):\n    '''Get a unicode filename and return bytestring, encoded to file system default.\n\n    If the argument already is a bytestring, return as is'''\n    log.debug('_encode_filename_to_filesystem(%s)', repr(f))\n    if isinstance(f, str):\n        return f\n    try:\n        return f.encode(sys.getfilesystemencoding())\n    except UnicodeEncodeError:\n        raise", "response": "Get a unicode filename and return bytestring encoded to file system default."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new(localfile, jottapath, JFS):\n    with open(localfile) as lf:\n        _new = JFS.up(jottapath, lf)\n    return _new", "response": "Upload a new file from local disk."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resume(localfile, jottafile, JFS):\n    with open(localfile) as lf:\n        _complete = jottafile.resume(lf)\n    return _complete", "response": "Continue uploading a new file from local file on JottaCloud"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_if_changed(localfile, jottapath, JFS):\n    jf = JFS.getObject(jottapath)\n    lf_hash = getxattrhash(localfile) # try to read previous hash, stored in xattr\n    if lf_hash is None:               # no valid hash found in xattr,\n        with open(localfile) as lf:\n            lf_hash = calculate_md5(lf) # (re)calculate it\n    if type(jf) == JFSIncompleteFile:\n        log.debug(\"Local file %s is incompletely uploaded, continue\", localfile)\n        return resume(localfile, jf, JFS)\n    elif jf.md5 == lf_hash: # hashes are the same\n        log.debug(\"hash match (%s), file contents haven't changed\", lf_hash)\n        setxattrhash(localfile, lf_hash)\n        return jf         # return the version from jottaclouds\n    else:\n        setxattrhash(localfile, lf_hash)\n        return new(localfile, jottapath, JFS)", "response": "Replace a file on JottaCloud if the md5 hash of the file contents have changed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a new directory on JottaCloud. Returns boolean", "response": "def mkdir(jottapath, JFS):\n    \"\"\"Make a new directory (a.k.a. folder) on JottaCloud.\n    Returns boolean\"\"\"\n    jf = JFS.post('%s?mkDir=true' % jottapath)\n    return instanceof(jf, JFSFolder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_tree(jottapath, JFS):\n    filedirlist = JFS.getObject('%s?mode=list' % jottapath)\n    log.debug(\"got tree: %s\", filedirlist)\n    if not isinstance(filedirlist, JFSFileDirList):\n        yield ( '', tuple(), tuple() )\n    for path in filedirlist.tree:\n        yield path", "response": "Get a tree of files and folders. use as an iterator you get something like os. walk"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _query(self, filename):\n        #  - Query metadata of one file\n        #  - Return a dict with a 'size' key, and a file size value (-1 for not found)\n        #  - Retried if an exception is thrown\n        log.Info('Querying size of %s' % filename)\n        from jottalib.JFS import JFSNotFoundError, JFSIncompleteFile\n        remote_path = posixpath.join(self.folder.path, filename)\n        try:\n            remote_file = self.client.getObject(remote_path)\n        except JFSNotFoundError:\n            return {'size': -1}\n        return {\n            'size': remote_file.size,\n        }", "response": "Query the metadata of a file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_drawing(document, container, elem):\n\n    _blip = elem.xpath('.//a:blip', namespaces=NAMESPACES)\n\n    if len(_blip) > 0:\n        blip = _blip[0]\n        _rid = blip.attrib[_name('{{{r}}}embed')]\n\n        img = doc.Image(_rid)\n        container.elements.append(img)", "response": "Parse drawing element.\n\n    We don't do much with drawing element. We can find embeded image but we don't do more than that."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the footnote element.", "response": "def parse_footnote(document, container, elem):\n    \"Parse the footnote element.\"\n\n    _rid = elem.attrib[_name('{{{w}}}id')]\n    foot = doc.Footnote(_rid)\n    container.elements.append(foot)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_endnote(document, container, elem):\n    \"Parse the endnote element.\"\n\n    _rid = elem.attrib[_name('{{{w}}}id')]\n    note = doc.Endnote(_rid)\n    container.elements.append(note)", "response": "Parse the endnote element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_smarttag(document, container, tag_elem):\n    \"Parse the endnote element.\"\n\n    tag = doc.SmartTag()\n\n    tag.element = tag_elem.attrib[_name('{{{w}}}element')]\n\n    for elem in tag_elem:\n        if elem.tag == _name('{{{w}}}r'):\n            parse_text(document, tag, elem)\n\n        if elem.tag == _name('{{{w}}}smartTag'):\n            parse_smarttag(document, tag, elem)\n\n    container.elements.append(tag)\n\n    return", "response": "Parse the endnote element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_paragraph(document, par):\n\n    paragraph = doc.Paragraph()\n    paragraph.document = document\n\n    for elem in par:\n        if elem.tag == _name('{{{w}}}pPr'):\n            parse_paragraph_properties(document, paragraph, elem)\n\n        if elem.tag == _name('{{{w}}}r'):\n            parse_text(document, paragraph, elem)\n\n        if elem.tag == _name('{{{m}}}oMath'):\n            _m = doc.Math()\n            paragraph.elements.append(_m)\n\n        if elem.tag == _name('{{{m}}}oMathPara'):\n            _m = doc.Math()\n            paragraph.elements.append(_m)\n\n        if elem.tag == _name('{{{w}}}commentRangeStart'):\n            _m = doc.Comment(elem.attrib[_name('{{{w}}}id')], 'start')\n            paragraph.elements.append(_m)\n\n        if elem.tag == _name('{{{w}}}commentRangeEnd'):\n            _m = doc.Comment(elem.attrib[_name('{{{w}}}id')], 'end')\n            paragraph.elements.append(_m)\n\n        if elem.tag == _name('{{{w}}}hyperlink'):\n            try:\n                t = doc.Link(elem.attrib[_name('{{{r}}}id')])\n\n                parse_text(document, t, elem)\n\n                paragraph.elements.append(t)\n            except:\n                logger.error('Error with with hyperlink [%s].', str(elem.attrib.items()))\n\n        if elem.tag == _name('{{{w}}}smartTag'):\n            parse_smarttag(document, paragraph, elem)\n\n    return paragraph", "response": "Parse a paragraph element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing table column properties.", "response": "def parse_table_column_properties(doc, cell, prop):\n    \"Parse table column properties.\"\n\n    if not cell:\n        return\n\n    grid = prop.find(_name('{{{w}}}gridSpan'))\n\n    if grid is not None:\n        cell.grid_span = int(grid.attrib[_name('{{{w}}}val')])\n\n    vmerge = prop.find(_name('{{{w}}}vMerge'))\n\n    if vmerge is not None:\n        if _name('{{{w}}}val') in vmerge.attrib:\n            cell.vmerge = vmerge.attrib[_name('{{{w}}}val')]\n        else:\n            cell.vmerge = \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses document with content.", "response": "def parse_document(xmlcontent):\n    \"\"\"Parse document with content.\n\n    Content is placed in file 'document.xml'.\n    \"\"\"\n\n    document = etree.fromstring(xmlcontent)\n\n    body = document.xpath('.//w:body', namespaces=NAMESPACES)[0]\n\n    document = doc.Document()\n\n    for elem in body:\n        if elem.tag == _name('{{{w}}}p'):\n            document.elements.append(parse_paragraph(document, elem))\n\n        if elem.tag == _name('{{{w}}}tbl'):\n            document.elements.append(parse_table(document, elem))\n\n        if elem.tag == _name('{{{w}}}sdt'):\n            document.elements.append(doc.TOC())\n\n    return document"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_relationship(document, xmlcontent, rel_type):\n\n    doc = etree.fromstring(xmlcontent)\n\n    for elem in doc:\n        if elem.tag == _name('{{{pr}}}Relationship'):\n            rel = {'target': elem.attrib['Target'],\n                   'type': elem.attrib['Type'],\n                   'target_mode': elem.attrib.get('TargetMode', 'Internal')}\n\n            document.relationships[rel_type][elem.attrib['Id']] = rel", "response": "Parse a relationship document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_style(document, xmlcontent):\n\n    styles = etree.fromstring(xmlcontent)\n\n    _r = styles.xpath('.//w:rPrDefault', namespaces=NAMESPACES)\n\n    if len(_r) > 0:\n        rpr = _r[0].find(_name('{{{w}}}rPr'))\n\n        if rpr is not None:\n            st = doc.Style()\n            parse_previous_properties(document, st, rpr)\n            document.default_style = st\n\n    # rest of the styles\n    for style in styles.xpath('.//w:style', namespaces=NAMESPACES):\n        st = doc.Style()\n\n        st.style_id = style.attrib[_name('{{{w}}}styleId')]\n\n        style_type = style.attrib[_name('{{{w}}}type')]\n        if style_type is not None:\n            st.style_type = style_type\n\n        if _name('{{{w}}}default') in style.attrib:\n            is_default = style.attrib[_name('{{{w}}}default')]\n            if is_default is not None:\n                st.is_default = is_default == '1'\n\n        name = style.find(_name('{{{w}}}name'))\n        if name is not None:\n            st.name = name.attrib[_name('{{{w}}}val')]\n\n        based_on = style.find(_name('{{{w}}}basedOn'))\n\n        if based_on is not None:\n            st.based_on = based_on.attrib[_name('{{{w}}}val')]\n\n        document.styles.styles[st.style_id] = st\n\n        if st.is_default:\n            document.styles.default_styles[st.style_type] = st.style_id\n\n        rpr = style.find(_name('{{{w}}}rPr'))\n\n        if rpr is not None:\n            parse_previous_properties(document, st, rpr)\n\n        ppr = style.find(_name('{{{w}}}pPr'))\n\n        if ppr is not None:\n            parse_paragraph_properties(document, st, ppr)", "response": "Parse the styles. xml file and add them to the document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_comments(document, xmlcontent):\n\n    comments = etree.fromstring(xmlcontent)\n    document.comments = {}\n\n    for comment in comments.xpath('.//w:comment', namespaces=NAMESPACES):\n        # w:author\n        # w:id\n        # w: date\n        comment_id = comment.attrib[_name('{{{w}}}id')]\n\n        comm = doc.CommentContent(comment_id)\n        comm.author = comment.attrib.get(_name('{{{w}}}author'), None)\n        comm.date = comment.attrib.get(_name('{{{w}}}date'), None)\n\n        comm.elements = [parse_paragraph(document, para) for para in comment.xpath('.//w:p', namespaces=NAMESPACES)]\n\n        document.comments[comment_id] = comm", "response": "Parse comments document.\n    Comments are defined in file comments. xml"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the Footnotes XML content into a single object.", "response": "def parse_footnotes(document, xmlcontent):\n    \"\"\"Parse footnotes document.\n\n    Footnotes are defined in file 'footnotes.xml'\n    \"\"\"\n\n    footnotes = etree.fromstring(xmlcontent)\n    document.footnotes = {}\n\n    for footnote in footnotes.xpath('.//w:footnote', namespaces=NAMESPACES):\n        _type = footnote.attrib.get(_name('{{{w}}}type'), None)\n\n        # don't know what to do with these now\n        if _type in ['separator', 'continuationSeparator', 'continuationNotice']:\n            continue\n\n        paragraphs = [parse_paragraph(document, para) for para in footnote.xpath('.//w:p', namespaces=NAMESPACES)]\n\n        document.footnotes[footnote.attrib[_name('{{{w}}}id')]] = paragraphs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_endnotes(document, xmlcontent):\n\n    endnotes = etree.fromstring(xmlcontent)\n    document.endnotes = {}\n\n    for note in endnotes.xpath('.//w:endnote', namespaces=NAMESPACES):\n        paragraphs = [parse_paragraph(document, para) for para in note.xpath('.//w:p', namespaces=NAMESPACES)]\n\n        document.endnotes[note.attrib[_name('{{{w}}}id')]] = paragraphs", "response": "Parse endnotes document. endnotes is defined in file endnotes. xml"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse numbering document. Numbering is defined in file numbering. xml.", "response": "def parse_numbering(document, xmlcontent):\n    \"\"\"Parse numbering document.\n\n    Numbering is defined in file 'numbering.xml'.\n    \"\"\"\n\n    numbering = etree.fromstring(xmlcontent)\n\n    document.abstruct_numbering = {}\n    document.numbering = {}\n\n    for abstruct_num in numbering.xpath('.//w:abstractNum', namespaces=NAMESPACES):\n        numb = {}\n        for lvl in abstruct_num.xpath('./w:lvl', namespaces=NAMESPACES):\n            ilvl = int(lvl.attrib[_name('{{{w}}}ilvl')])\n\n            fmt = lvl.find(_name('{{{w}}}numFmt'))\n            numb[ilvl] = {'numFmt': fmt.attrib[_name('{{{w}}}val')]}\n\n        document.abstruct_numbering[abstruct_num.attrib[_name('{{{w}}}abstractNumId')]] = numb\n\n    for num in numbering.xpath('.//w:num', namespaces=NAMESPACES):\n        num_id = num.attrib[_name('{{{w}}}numId')]\n\n        abs_num = num.find(_name('{{{w}}}abstractNumId'))\n\n        if abs_num is not None:\n            number_id = abs_num.attrib[_name('{{{w}}}val')]\n            document.numbering[int(num_id)] = number_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse an OOXML file into a set of nodes.", "response": "def parse_from_file(file_object):\n    \"\"\"Parses existing OOXML file.\n\n    :Args:\n      - file_object (:class:`ooxml.docx.DOCXFile`): OOXML file object\n\n    :Returns:\n      Returns parsed document of type :class:`ooxml.doc.Document`\n    \"\"\"\n\n    logger.info('Parsing %s file.', file_object.file_name)\n\n    # Read the files\n    doc_content = file_object.read_file('document.xml')\n\n    # Parse the document\n    document = parse_document(doc_content)\n\n    try:\n        style_content = file_object.read_file('styles.xml')\n        parse_style(document, style_content)\n    except KeyError:\n        logger.warning('Could not read styles.')\n\n    try:\n        doc_rel_content = file_object.read_file('_rels/document.xml.rels')\n        parse_relationship(document, doc_rel_content, 'document')\n    except KeyError:\n        logger.warning('Could not read document relationships.')\n\n    try:\n        doc_rel_content = file_object.read_file('_rels/endnotes.xml.rels')\n        parse_relationship(document, doc_rel_content, 'endnotes')\n    except KeyError:\n        logger.warning('Could not read endnotes relationships.')\n\n    try:\n        doc_rel_content = file_object.read_file('_rels/footnotes.xml.rels')\n        parse_relationship(document, doc_rel_content, 'footnotes')\n    except KeyError:\n        logger.warning('Could not read footnotes relationships.')\n\n    try:\n        comments_content = file_object.read_file('comments.xml')\n        parse_comments(document, comments_content)\n    except KeyError:\n        logger.warning('Could not read comments.')\n\n    try:\n        footnotes_content = file_object.read_file('footnotes.xml')\n        parse_footnotes(document, footnotes_content)\n    except KeyError:\n        logger.warning('Could not read footnotes.')\n\n    try:\n        endnotes_content = file_object.read_file('endnotes.xml')\n        parse_endnotes(document, endnotes_content)\n    except KeyError:\n        logger.warning('Could not read endnotes.')\n\n    try:\n        numbering_content = file_object.read_file('numbering.xml')\n        parse_numbering(document, numbering_content)\n    except KeyError:\n        logger.warning('Could not read numbering.')\n\n    return document"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_by_name(self, name, style_type = None):\n        for st in self.styles.values():\n            if st:\n                if st.name == name:\n                    return st\n\n        if style_type and not st:\n            st = self.styles.get(self.default_styles[style_type], None)            \n        return st", "response": "Find style by it s descriptive name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding style by it s unique identifier.", "response": "def get_by_id(self, style_id, style_type = None):\n        \"\"\"Find style by it's unique identifier\n\n        :Returns:\n          Returns found style of type :class:`ooxml.doc.Style`.\n        \"\"\"\n\n        for st in self.styles.values():\n            if st:\n                if st.style_id == style_id:\n                    return st\n\n        if style_type:\n            return self.styles.get(self.default_styles[style_type], None)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_affinity(affinity=None):\n    if affinity is not None:\n        affinity = CPUSet(affinity)\n        if not affinity.issubset(system_affinity()):\n            raise ValueError(\"unknown cpus: %s\" % affinity)\n    return system_affinity()", "response": "Get or set the CPU affinity set for the current process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nattempt to acquire a lock.", "response": "def acquire(self,blocking=True,timeout=None):\n        \"\"\"Attempt to acquire this lock.\n\n        If the optional argument \"blocking\" is True and \"timeout\" is None,\n        this methods blocks until is successfully acquires the lock.  If\n        \"blocking\" is False, it returns immediately if the lock could not\n        be acquired.  Otherwise, it blocks for at most \"timeout\" seconds\n        trying to acquire the lock.\n\n        In all cases, this methods returns True if the lock was successfully\n        acquired and False otherwise.\n        \"\"\"\n        if timeout is None:\n            return self.__lock.acquire(blocking)\n        else:\n            #  Simulated timeout using progressively longer sleeps.\n            #  This is the same timeout scheme used in the stdlib Condition\n            #  class.  If there's lots of contention on the lock then there's\n            #  a good chance you won't get it; but then again, Python doesn't\n            #  guarantee fairness anyway.  We hope that platform-specific\n            #  extensions can provide a better mechanism.\n            endtime = _time() + timeout\n            delay = 0.0005\n            while not self.__lock.acquire(False):\n                remaining = endtime - _time()\n                if remaining <= 0:\n                    return False\n                delay = min(delay*2,remaining,0.05)\n                _sleep(delay)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_thread(cls,thread):\n        new_classes = []\n        for new_cls in cls.__mro__:\n            if new_cls not in thread.__class__.__mro__:\n                new_classes.append(new_cls)\n        if isinstance(thread,cls):\n            pass\n        elif issubclass(cls,thread.__class__):\n            thread.__class__ = cls\n        else:\n            class UpgradedThread(thread.__class__,cls):\n                pass\n            thread.__class__ = UpgradedThread\n        for new_cls in new_classes:\n            if hasattr(new_cls,\"_upgrade_thread\"):\n                new_cls._upgrade_thread(thread)\n        return thread", "response": "Convert a vanilla thread object into an instance of this class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nacquires the lock in shared or exclusive mode.", "response": "def acquire(self,blocking=True,timeout=None,shared=False):\n        \"\"\"Acquire the lock in shared or exclusive mode.\"\"\"\n        with self._lock:\n            if shared:\n                self._acquire_shared(blocking,timeout)\n            else:\n                self._acquire_exclusive(blocking,timeout)\n            assert not (self.is_shared and self.is_exclusive)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the file and returns a parsed document.", "response": "def read_from_file(file_name):\n    \"\"\"Parser OOXML file and returns parsed document.\n    \n    :Args:\n      - file_name (str): Path to OOXML file\n\n    :Returns:\n      Returns object of type :class:`ooxml.docx.DOCXFile`.\n    \"\"\"\n    from .docxfile import DOCXFile\n\n    dfile = DOCXFile(file_name)\n    dfile.parse()\n\n    return dfile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget font size defined for this style.", "response": "def _get_font_size(document, style):\n    \"\"\"Get font size defined for this style.\n\n    It will try to get font size from it's parent style if it is not defined by original style. \n\n    :Args:\n      - document (:class:`ooxml.doc.Document`): Document object\n      - style (:class:`ooxml.doc.Style`): Style object\n\n    :Returns:\n      Returns font size as a number. -1 if it can not get font size.\n    \"\"\"\n\n    font_size = style.get_font_size()\n\n    if  font_size == -1:\n        if style.based_on:\n            based_on = document.styles.get_by_id(style.based_on)\n            if based_on:\n                return _get_font_size(document, based_on)\n\n    return font_size"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the type of the list.", "response": "def _get_numbering(document, numid, ilvl):\n    \"\"\"Returns type for the list.\n\n    :Returns:\n      Returns type for the list. Returns \"bullet\" by default or in case of an error.\n    \"\"\"\n\n    try:\n        abs_num = document.numbering[numid]\n        return document.abstruct_numbering[abs_num][ilvl]['numFmt']\n    except:\n        return 'bullet'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_parent(root):\n\n    elem = root\n\n    while True:\n        elem = elem.getparent()\n\n        if elem.tag in ['ul', 'ol']:\n            return elem", "response": "Returns the parent element of a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_list(ctx, root):\n\n    try:\n        n = len(ctx.in_list)\n        if n <= 0:\n            return root\n\n        elem = root\n\n        while n > 0:\n            while True:\n                if elem.tag in ['ul', 'ol', 'td']:                    \n                    elem = elem.getparent()\n                    break\n\n                elem = elem.getparent()\n\n            n -= 1\n\n        ctx.in_list = []\n\n        return elem\n    except:\n        return None", "response": "Close already opened list if needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens list if it is needed and place current element as first member of a list.", "response": "def open_list(ctx, document, par, root, elem):\n    \"\"\"Open list if it is needed and place current element as first member of a list.\n\n    :Args:\n      - ctx (:class:`Context`): Context object\n      - document (:class:`ooxml.doc.Document`): Document object\n      - par (:class:`ooxml.doc.Paragraph`): Paragraph element\n      - root (Element): lxml element of current location\n      - elem (Element): lxml element representing current element we are trying to insert\n\n    :Returns:\n        lxml element where future content should be placed.\n    \"\"\"\n\n    _ls = None\n\n    if par.ilvl != ctx.ilvl or par.numid != ctx.numid:\n        # start\n\n        if ctx.ilvl is not None and (par.ilvl > ctx.ilvl):\n            fmt = _get_numbering(document, par.numid, par.ilvl)\n\n            if par.ilvl > 0:\n                # get last <li> in <ul>\n                # could be nicer\n                _b = list(root)[-1]\n                _ls = etree.SubElement(_b, _get_numbering_tag(fmt))\n                root = _ls\n            else:\n                _ls = etree.SubElement(root, _get_numbering_tag(fmt))\n                root = _ls\n\n            fire_hooks(ctx, document, par, _ls, ctx.get_hook(_get_numbering_tag(fmt)))\n\n            ctx.in_list.append((par.numid, par.ilvl))\n        elif ctx.ilvl is not None and par.ilvl < ctx.ilvl:\n            fmt = _get_numbering(document, ctx.numid, ctx.ilvl)\n\n            try:\n                while True:\n                    numid, ilvl = ctx.in_list[-1]\n\n                    if numid == par.numid and ilvl == par.ilvl:\n                        break\n\n                    root = _get_parent(root)\n                    ctx.in_list.pop()\n            except:\n                pass\n\n#        if ctx.numid is not None and par.numid > ctx.numid:\n#            if ctx.numid != None:   \n        if par.numid > ctx.numid:\n            fmt = _get_numbering(document, par.numid, par.ilvl)\n            _ls = etree.SubElement(root, _get_numbering_tag(fmt))\n            fire_hooks(ctx, document, par, _ls, ctx.get_hook(_get_numbering_tag(fmt)))\n\n            ctx.in_list.append((par.numid, par.ilvl))\n            root = _ls\n                \n    ctx.ilvl = par.ilvl\n    ctx.numid = par.numid\n\n    _a = etree.SubElement(root, 'li')\n    _a.text = elem.text\n\n    for a in list(elem):\n        _a.append(a)\n\n    fire_hooks(ctx, document, par, _a, ctx.get_hook('li'))\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nserialize math element. Math objects are not supported at the moment. This is wht we only show error message.", "response": "def serialize_math(ctx, document, elem, root):\n    \"\"\"Serialize math element.\n\n    Math objects are not supported at the moment. This is wht we only show error message.\n    \"\"\"\n\n    _div = etree.SubElement(root, 'span')\n    if ctx.options['embed_styles']:\n        _div.set('style', 'border: 1px solid red')\n    _div.text = 'We do not support Math blocks at the moment.'\n\n    fire_hooks(ctx, document, elem, _div, ctx.get_hook('math'))\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize_link(ctx, document, elem, root):\n\n    _a = etree.SubElement(root, 'a')\n\n    for el in elem.elements:\n        _ser = ctx.get_serializer(el)\n\n        if _ser:\n            _td = _ser(ctx, document, el, _a)\n        else:\n            if isinstance(el, doc.Text):\n                children = list(_a)\n\n                if len(children) == 0:\n                    _text = _a.text or u''\n\n                    _a.text = u'{}{}'.format(_text, el.value())\n                else:\n                    _text = children[-1].tail or u''\n\n                    children[-1].tail = u'{}{}'.format(_text, el.value())\n   \n    if elem.rid in document.relationships[ctx.options['relationship']]:\n        _a.set('href', document.relationships[ctx.options['relationship']][elem.rid].get('target', ''))\n\n    fire_hooks(ctx, document, elem, _a, ctx.get_hook('a'))\n\n    return root", "response": "Serialize a link element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing image element. This is not abstract enough.", "response": "def serialize_image(ctx, document, elem, root):\n    \"\"\"Serialize image element.\n\n    This is not abstract enough.\n    \"\"\"\n\n    _img = etree.SubElement(root, 'img')\n    # make path configurable\n\n    if elem.rid in document.relationships[ctx.options['relationship']]:\n        img_src = document.relationships[ctx.options['relationship']][elem.rid].get('target', '')\n        img_name, img_extension = os.path.splitext(img_src)\n\n        _img.set('src', 'static/{}{}'.format(elem.rid, img_extension))\n\n    fire_hooks(ctx, document, elem, _img, ctx.get_hook('img'))\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfires hooks on newly created element.", "response": "def fire_hooks(ctx, document, elem, element, hooks):\n    \"\"\"Fire hooks on newly created element.\n\n    For each newly created element we will try to find defined hooks and execute them.\n\n    :Args:\n      - ctx (:class:`Context`): Context object\n      - document (:class:`ooxml.doc.Document`): Document object\n      - elem (:class:`ooxml.doc.Element`): Element which we serialized\n      - element (Element): lxml element which we created\n      - hooks (list): List of hooks\n    \"\"\"\n\n    if not hooks:\n        return\n\n    for hook in hooks:\n        hook(ctx, document, elem, element)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntelling us if node element has defined styling.", "response": "def has_style(node):    \n    \"\"\"Tells us if node element has defined styling.\n\n    :Args:\n      - node (:class:`ooxml.doc.Element`): Element\n\n    :Returns:\n      True or False\n\n    \"\"\"\n\n    elements = ['b', 'i', 'u', 'strike', 'color', 'jc', 'sz', 'ind', 'superscript', 'subscript', 'small_caps']\n\n    return any([True for elem in elements if elem in node.rpr])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_style_css(ctx, node, embed=True, fontsize=-1):\n\n    style = []\n\n    if not node:\n        return\n\n    if fontsize in [-1, 2]:\n        if 'sz' in node.rpr:\n            size = int(node.rpr['sz']) / 2\n\n            if ctx.options['embed_fontsize']:\n                if ctx.options['scale_to_size']:                \n                    multiplier = size-ctx.options['scale_to_size']\n                    scale = 100 + int(math.trunc(8.3*multiplier))\n                    style.append('font-size: {}%'.format(scale))\n                else:\n                    style.append('font-size: {}pt'.format(size))\n\n    if fontsize in [-1, 1]:\n        # temporarily\n        if not embed:\n            if 'b' in node.rpr:\n                style.append('font-weight: bold')\n\n            if 'i' in node.rpr:\n                style.append('font-style: italic')\n\n            if 'u' in node.rpr:\n                style.append('text-decoration: underline')\n\n        if 'small_caps' in node.rpr:\n            style.append('font-variant: small-caps')\n\n        if 'strike' in node.rpr:\n            style.append('text-decoration: line-through')\n\n        if 'color' in node.rpr:\n            if node.rpr['color'] != '000000':\n                style.append('color: #{}'.format(node.rpr['color']))\n\n        if 'jc' in node.ppr:\n            # left right both\n            align = node.ppr['jc']\n            if align.lower() == 'both':\n                align = 'justify'\n\n            style.append('text-align: {}'.format(align))\n\n        if 'ind' in node.ppr:\n            if 'left' in node.ppr['ind']:\n                size = int(node.ppr['ind']['left']) / 10\n                style.append('margin-left: {}px'.format(size))\n\n            if 'right' in node.ppr['ind']:\n                size = int(node.ppr['ind']['right']) / 10\n                style.append('margin-right: {}px'.format(size))\n\n            if 'first_line' in node.ppr['ind']:\n                size = int(node.ppr['ind']['first_line']) / 10\n                style.append('text-indent: {}px'.format(size))\n\n    if len(style) == 0:\n        return ''\n\n    return '; '.join(style) + ';'", "response": "Returns as string defined CSS for this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of styles on which specified style is based on.", "response": "def get_all_styles(document, style):\n    \"\"\"Returns list of styles on which specified style is based on.\n\n    :Args:\n      - document (:class:`ooxml.doc.Document`): Document object\n      - style (:class:`ooxml.doc.Style`): Style object\n\n    :Returns:\n      List of style objects.\n    \"\"\"\n\n    classes = []\n\n    while True:\n        classes.insert(0, get_style_name(style))\n\n        if style.based_on:\n            style = document.styles.get_by_id(style.based_on)\n        else:\n            break\n\n    return classes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all the CSS classes for this style.", "response": "def get_css_classes(document, style):\n    \"\"\"Returns CSS classes for this style.\n\n    This function will check all the styles specified style is based on and return their CSS classes.\n\n    :Args:\n      - document (:class:`ooxml.doc.Document`): Document object\n      - style (:class:`ooxml.doc.Style`): Style object\n\n    :Returns:\n      String representing all the CSS classes for this element.\n\n    >>> get_css_classes(doc, st)\n    'header1 normal'\n    \"\"\"\n    lst = [st.lower() for st in get_all_styles(document, style)[-1:]] + \\\n        ['{}-fontsize'.format(st.lower()) for st in get_all_styles(document, style)[-1:]]\n\n    return ' '.join(lst)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize a paragraph element.", "response": "def serialize_paragraph(ctx, document, par, root, embed=True):\n    \"\"\"Serializes paragraph element.\n\n    This is the most important serializer of them all.    \n    \"\"\"\n\n    style = get_style(document, par)\n\n    elem = etree.Element('p')\n\n    if ctx.options['embed_styles']:\n        _style = get_style_css(ctx, par)\n\n        if _style != '':\n            elem.set('style', _style)\n\n    else:\n        _style = ''\n\n    if style:\n        elem.set('class', get_css_classes(document, style))\n\n    max_font_size = get_style_fontsize(par)\n\n    if style:\n        max_font_size = _get_font_size(document, style)\n\n    for el in par.elements:\n        _serializer =  ctx.get_serializer(el)\n\n        if _serializer:\n            _serializer(ctx, document, el, elem)\n\n        if isinstance(el, doc.Text):\n            children = list(elem)\n            _text_style = get_style_css(ctx, el)\n            _text_class = el.rpr.get('style', '').lower()\n\n            if _text_class == '':\n                __s = get_style(document, par)\n                if __s is not None:\n                    _text_class = get_style_name(__s).lower()\n\n            if get_style_fontsize(el) > max_font_size:\n                max_font_size = get_style_fontsize(el)\n\n            if 'superscript' in el.rpr:\n                new_element = etree.Element('sup')\n                new_element.text = el.value()\n            elif 'subscript' in el.rpr:\n                new_element = etree.Element('sub')\n                new_element.text = el.value()               \n            elif 'b' in el.rpr or 'i' in el.rpr or 'u' in el.rpr:                \n                new_element = None\n                _element = None\n\n                def _add_formatting(f, new_element, _element):\n                    if f in el.rpr:\n                        _t = etree.Element(f)\n\n                        if new_element is not None:\n                            _element.append(_t)\n                            _element = _t\n                        else:\n                            new_element = _t\n                            _element = new_element\n\n                    return new_element, _element\n\n                new_element, _element = _add_formatting('b', new_element, _element)\n                new_element, _element = _add_formatting('i', new_element, _element)\n                new_element, _element = _add_formatting('u', new_element, _element)\n                \n                _element.text = el.value()\n\n                for comment_id in ctx.opened_comments:\n                    document.comments[comment_id].text += ' ' + el.value()\n            else:\n                new_element = etree.Element('span')\n                new_element.text = el.value()\n                if ctx.options['embed_styles']:\n                    try:\n                        new_element.set('class', _text_class)\n                    except:\n                        pass\n\n                for comment_id in ctx.opened_comments:\n                    if comment_id in document.comments:\n                        document.comments[comment_id].text += ' ' + el.value()\n\n            if ctx.options['embed_styles']:\n                if _text_style != '' and _style != _text_style:\n                    new_element.set('style', _text_style)\n\n            # This is for situations when style has options and\n            # text is trying to unset them\n            # else:            \n            #     new_element.set('class', 'noformat')\n\n            was_inserted = False\n\n            if len(children) > 0:\n                _child_style = children[-1].get('style') or ''\n                _child_class = children[-1].get('class', '')\n\n                if new_element.tag == children[-1].tag and ((_text_class == _child_class or _child_class == '') and (_text_style == _child_style or _child_style == '')) and children[-1].tail is None:\n                    txt = children[-1].text or ''\n                    txt2 = new_element.text or ''\n                    children[-1].text = u'{}{}'.format(txt, txt2)  \n                    was_inserted = True\n\n                if not was_inserted:\n                    if _style == _text_style  and new_element.tag == 'span' and (_text_class == _child_class or _child_class == ''):\n                        _e = children[-1]\n\n                        txt = _e.tail or ''\n                        _e.tail = u'{}{}'.format(txt, new_element.text)\n                        was_inserted = True\n  \n                    if not was_inserted and new_element.tag == 'span' and (_text_class != _child_class):\n                        _e = children[-1]\n                        txt = _e.tail or ''\n                        _e.tail = u'{}{}'.format(txt, new_element.text)\n                        was_inserted = True       \n\n            if not was_inserted:\n                _child_class = new_element.get('class', '')\n                try:\n                    _child_class = children[-1].get('class', '')\n                except:\n                    _child_class = ''\n\n                if _style ==  _text_style  and new_element.tag == 'span' and (_text_class == _child_class):\n                    txt = elem.text or ''\n                    elem.text = u'{}{}'.format(txt, new_element.text)\n                else:\n                    if new_element.text != u'':\n                        elem.append(new_element)\n    \n    if not par.is_dropcap() and par.ilvl == None:\n        if style:\n            if ctx.header.is_header(par, max_font_size, elem, style=style):\n                elem.tag = ctx.header.get_header(par, style, elem)\n                if par.ilvl == None:        \n                    root = close_list(ctx, root)\n                    ctx.ilvl, ctx.numid = None, None\n\n                if root is not None:\n                    root.append(elem)\n\n                fire_hooks(ctx, document, par, elem, ctx.get_hook('h'))\n                return root\n        else:\n#            Commented part where we only checked for heading if font size\n#            was bigger than default font size. In many cases this did not\n#            work out well.\n#            if max_font_size > ctx.header.default_font_size:\n            if True:\n                if ctx.header.is_header(par, max_font_size, elem, style=style):\n                    if elem.text != '' and len(list(elem)) != 0:\n                        elem.tag = ctx.header.get_header(par, max_font_size, elem)\n\n                        if par.ilvl == None:        \n                            root = close_list(ctx, root)\n                            ctx.ilvl, ctx.numid = None, None\n\n\n                        if root is not None:\n                            root.append(elem)\n\n                        fire_hooks(ctx, document, par, elem, ctx.get_hook('h'))\n                        return root\n\n    if len(list(elem)) == 0 and elem.text is None:\n        if ctx.options['empty_paragraph_as_nbsp']:\n            elem.append(etree.Entity('nbsp'))\n\n    # Indentation is different. We are starting or closing list.\n    if par.ilvl != None:        \n        root = open_list(ctx, document, par, root, elem)\n        return root\n    else:\n        root = close_list(ctx, root)\n        ctx.ilvl, ctx.numid = None, None\n\n    # Add new elements to our root element.\n    if root is not None:\n        root.append(elem)\n\n    fire_hooks(ctx, document, par, elem, ctx.get_hook('p'))\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize a table element.", "response": "def serialize_table(ctx, document, table, root):\n    \"\"\"Serializes table element.\n    \"\"\"\n\n    # What we should check really is why do we pass None as root element\n    # There is a good chance some content is missing after the import\n\n    if root is None:\n        return root\n\n    if ctx.ilvl != None:\n        root = close_list(ctx, root)\n        ctx.ilvl, ctx.numid = None, None\n\n    _table = etree.SubElement(root, 'table')\n    _table.set('border', '1')\n    _table.set('width', '100%')\n\n    style = get_style(document, table)\n\n    if style:\n        _table.set('class', get_css_classes(document, style))\n\n    for rows in table.rows:\n        _tr = etree.SubElement(_table, 'tr')\n\n        for cell in rows:\n            _td = etree.SubElement(_tr, 'td')\n\n            if cell.grid_span != 1:\n                _td.set('colspan', str(cell.grid_span))\n\n            if cell.row_span != 1:\n                _td.set('rowspan', str(cell.row_span))\n\n            for elem in cell.elements:\n                if isinstance(elem, doc.Paragraph):\n                    _ser = ctx.get_serializer(elem)\n                    _td = _ser(ctx, document, elem, _td, embed=False)\n\n            if ctx.ilvl != None:\n#                root = close_list(ctx, root)\n                _td = close_list(ctx, _td)\n\n                ctx.ilvl, ctx.numid = None, None\n\n            fire_hooks(ctx, document, table, _td, ctx.get_hook('td'))\n        fire_hooks(ctx, document, table, _td, ctx.get_hook('tr'))\n\n    fire_hooks(ctx, document, table, _table, ctx.get_hook('table'))\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize_elements(document, elements, options=None):\n    ctx = Context(document, options)\n\n    tree_root = root = etree.Element('div')\n\n    for elem in elements:\n        _ser = ctx.get_serializer(elem)\n\n        if _ser:\n            root = _ser(ctx, document, elem, root)\n\n    # TODO:\n    # - create footnotes now\n\n    return etree.tostring(tree_root, pretty_print=ctx.options.get('pretty_print', True), encoding=\"utf-8\", xml_declaration=False)", "response": "Serialize list of elements into HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_header(self, elem, font_size, node, style=None):\n        \n        # This logic has been disabled for now. Mark this as header if it has\n        # been marked during the parsing or mark.\n        # if hasattr(elem, 'possible_header'):\n        #     if elem.possible_header:                \n        #         return True\n\n        # if not style:\n        #     return False\n\n        if hasattr(style, 'style_id'):\n            fnt_size = _get_font_size(self.doc, style)\n\n            from .importer import calculate_weight\n            weight = calculate_weight(self.doc, elem)\n            \n            if weight > 50:\n                return False\n\n            if fnt_size in self.doc.possible_headers_style:                \n                return True\n\n            return font_size in self.doc.possible_headers\n        else:\n            list_of_sizes = {}\n            for el in elem.elements:\n                try:\n                    fs = get_style_fontsize(el)\n                    weight = len(el.value()) if el.value() else 0\n\n                    list_of_sizes[fs] = list_of_sizes.setdefault(fs, 0) + weight\n                except:\n                    pass\n\n            sorted_list_of_sizes = list(collections.OrderedDict(sorted(six.iteritems(list_of_sizes), key=lambda t: t[0])))\n            font_size_to_check = font_size\n\n            if len(sorted_list_of_sizes) > 0:\n                if sorted_list_of_sizes[0] != font_size:\n                    return sorted_list_of_sizes[0] in self.doc.possible_headers\n\n            return font_size in self.doc.possible_headers", "response": "Checks if specific element is a header or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the string representation of the specific header for this element.", "response": "def get_header(self, elem, style, node):\n        \"\"\"Returns HTML tag representing specific header for this element.\n\n        :Returns:\n          String representation of HTML tag.\n\n        \"\"\"\n        font_size = style\n        if hasattr(elem, 'possible_header'):\n            if elem.possible_header:\n                return 'h1'\n\n        if not style:\n            return 'h6'\n\n        if hasattr(style, 'style_id'):\n            font_size = _get_font_size(self.doc, style)\n\n        try:\n            if font_size in self.doc.possible_headers_style:\n                return 'h{}'.format(self.doc.possible_headers_style.index(font_size)+1)\n\n            return 'h{}'.format(self.doc.possible_headers.index(font_size)+1)\n        except ValueError:\n            return 'h6'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function which will be used for serialization for specific element.", "response": "def get_serializer(self, node):\n        \"\"\"Returns serializer for specific element.\n\n        :Args:\n          - node (:class:`ooxml.doc.Element`): Element object \n\n        :Returns:\n          Returns reference to a function which will be used for serialization.\n        \"\"\"\n\n        return self.options['serializers'].get(type(node), None)\n\n        if type(node) in self.options['serializers']:\n            return self.options['serializers'][type(node)]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the priority for all threads in this group.", "response": "def priority(self,priority):\n        \"\"\"Set the priority for all threads in this group.\n\n        If setting priority fails on any thread, the priority of all threads\n        is restored to its previous value.\n        \"\"\"\n        with self.__lock:\n            old_priorities = {}\n            try:\n                for thread in self.__threads:\n                    old_priorities[thread] = thread.priority\n                    thread.priority = priority\n            except Exception:\n                for (thread,old_priority) in old_priorities.iteritems():\n                    try:\n                        thread.priority = old_priority\n                    except Exception:\n                        pass\n                raise\n            else:\n                self.__priority = priority"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef affinity(self,affinity):\n        with self.__lock:\n            old_affinities = {}\n            try:\n                for thread in self.__threads:\n                    old_affinities[thread] = thread.affinity\n                    thread.affinity = affinity\n            except Exception:\n                for (thread,old_affinity) in old_affinities.iteritems():\n                    try:\n                        thread.affinity = old_affinity\n                    except Exception:\n                        pass\n                raise\n            else:\n                self.__affinity = affinity", "response": "Sets the affinity for all threads in this group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef join(self,timeout=None):\n        if timeout is None:\n            for thread in self.__threads:\n                thread.join()\n        else:\n            deadline = _time() + timeout\n            for thread in self.__threads:\n                delay = deadline - _time()\n                if delay <= 0:\n                    return False\n                if not thread.join(delay):\n                    return False\n        return True", "response": "Join all threads in this group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the length of the content in this element.", "response": "def text_length(elem):\n    \"\"\"Returns length of the content in this element.\n\n    Return value is not correct but it is **good enough***.\n    \"\"\"\n\n    if not elem:\n        return 0\n\n    value = elem.value()\n\n    try:\n        value = len(value)\n    except:\n        value = 0\n\n    try:\n        for a in elem.elements:\n            value += len(a.value())\n    except:\n        pass\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking all elements and creates a list of diferent markers for styles or different elements.", "response": "def mark_styles(ctx, doc, elements):\n    \"\"\"\n    Checks all elements and creates a list of diferent markers for styles or different elements.\n    \"\"\"\n\n    not_using_styles = False\n\n    if ctx.options['not_using_styles']:\n        if len(doc.used_styles) < ctx.options['minimum_used_styles'] and len(doc.possible_headers) < ctx.options['minimum_possible_headers']:\n            not_using_styles = True\n            doc.possible_headers = [POSSIBLE_HEADER_SIZE] + doc.possible_headers\n\n            logger.info('   => not using styles')\n\n    markers = [{'name': '', 'weight': 0, 'index': 0, 'font_size': 0}]\n\n    for pos, elem in enumerate(elements):\n        try:\n            style = doc.styles.get_by_id(elem.style_id)\n        except AttributeError:\n            style = None\n\n        if isinstance(elem, Paragraph):\n            # Ignore if it is dropcap. \n            # What we should do here is also calculate weight, which we do not do at the moment.\n            if elem.is_dropcap():\n                continue\n\n            for el in elem.elements:\n                # insert it inside\n                if isinstance(el, Break):\n                    markers.append({'name': '', 'weight': 0, 'index': pos, 'font_size': 0, 'page_break': True})\n\n        weight = calculate_weight(doc, elem)\n        if weight == 0:\n            continue\n\n        font_size = -1\n        has_found = False\n\n        if isinstance(elem, TOC):\n            markers.append({'name': '', 'weight': weight, 'index': pos, 'font_size': fnt_size, 'is_toc': True})\n            continue                \n\n        if style:\n            markers.append({'name': elem.style_id, 'weight': weight, 'index': pos})\n            if elem.style_id == 'ContentsHeading':\n                markers[-1]['is_toc'] = True\n\n            has_found = True\n        else:\n            if ctx.options['header_as_text']:\n                if hasattr(elem, 'rpr') and 'sz' in elem.rpr:\n\n                    t_length = text_length(elem)\n\n                    if  t_length < ctx.options['header_as_text_length'] and t_length >= ctx.options['header_as_text_length_minimum']:\n                        markers.append({'name': '', 'weight': weight, 'index': pos, 'font_size': int(elem.rpr['sz']) / 2})\n                        font_size = int(elem.rpr['sz'])/2\n                        has_found = True\n\n            if ctx.options['header_as_bold_centered']:\n                if not_using_styles:\n                    if hasattr(elem, 'rpr') and ('jc' in elem.ppr or 'b' in elem.rpr or 'i' in elem.rpr):\n                        if text_length(elem) < 30:\n\n                            elements[pos].possible_header = True\n\n                            markers.append({'name': '', 'weight': weight+100, 'index': pos, 'font_size': POSSIBLE_HEADER_SIZE})\n                            font_size = POSSIBLE_HEADER_SIZE\n                            has_found = True\n\n        if ctx.options['header_as_text_in_elements']:\n            if hasattr(elem, 'elements'):\n                for e in elem.elements:\n                    # TODO\n                    # check if this is empty element\n                    if hasattr(e, 'rpr') and 'sz' in e.rpr:\n                        t_length = text_length(elem)\n                        if  t_length < ctx.options['header_as_text_length'] and t_length >= ctx.options['header_as_text_length_minimum']: \n                            fnt_size = int(e.rpr['sz'])/2\n\n                            if fnt_size != font_size:\n                                markers.append({'name': '', 'weight': weight, 'index': pos, 'font_size': fnt_size})\n                                has_found = True\n\n        if not has_found and len(markers) > 0:\n            markers[-1]['weight'] += weight\n\n    return markers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _priority_range(policy=None):\n    if policy is None:\n        policy = libc.sched_getscheduler(0)\n        if policy < 0:\n            raise OSError(get_errno(),\"sched_getscheduler\")\n    max = libc.sched_get_priority_max(policy)\n    if max < 0:\n        raise OSError(get_errno(),\"sched_get_priority_max\")\n    min = libc.sched_get_priority_min(policy)\n    if min < 0:\n        raise OSError(get_errno(),\"sched_get_priority_min\")\n    return (min,max)", "response": "Determine the priority range for the given scheduler policy."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the dynamic attribute of the object.", "response": "def _get_dynamic_attr(self, attname, obj, default=None):\n        \"\"\"\n        Copied from django.contrib.syndication.views.Feed (v1.7.1)\n        \"\"\"\n        try:\n            attr = getattr(self, attname)\n        except AttributeError:\n            return default\n        if callable(attr):\n            # Check co_argcount rather than try/excepting the function and\n            # catching the TypeError, because something inside the function\n            # may raise the TypeError. This technique is more accurate.\n            try:\n                code = six.get_function_code(attr)\n            except AttributeError:\n                code = six.get_function_code(attr.__call__)\n            if code.co_argcount == 2:       # one argument is 'self'\n                return attr(obj)\n            else:\n                return attr()\n        return attr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild rrule dictionary for vRecur class.", "response": "def build_rrule(count=None, interval=None, bysecond=None, byminute=None,\n                byhour=None, byweekno=None, bymonthday=None, byyearday=None,\n                bymonth=None, until=None, bysetpos=None, wkst=None, byday=None,\n                freq=None):\n    \"\"\"\n    Build rrule dictionary for vRecur class.\n\n    :param count: int\n    :param interval: int\n    :param bysecond: int\n    :param byminute: int\n    :param byhour: int\n    :param byweekno: int\n    :param bymonthday: int\n    :param byyearday: int\n    :param bymonth: int\n    :param until: datetime\n    :param bysetpos: int\n    :param wkst: str, two-letter weekday\n    :param byday: weekday\n    :param freq: str, frequency name ('WEEK', 'MONTH', etc)\n    :return: dict\n    \"\"\"\n    result = {}\n\n    if count is not None:\n        result['COUNT'] = count\n\n    if interval is not None:\n        result['INTERVAL'] = interval\n\n    if bysecond is not None:\n        result['BYSECOND'] = bysecond\n\n    if byminute is not None:\n        result['BYMINUTE'] = byminute\n\n    if byhour is not None:\n        result['BYHOUR'] = byhour\n\n    if byweekno is not None:\n        result['BYWEEKNO'] = byweekno\n\n    if bymonthday is not None:\n        result['BYMONTHDAY'] = bymonthday\n\n    if byyearday is not None:\n        result['BYYEARDAY'] = byyearday\n\n    if bymonth is not None:\n        result['BYMONTH'] = bymonth\n\n    if until is not None:\n        result['UNTIL'] = until\n\n    if bysetpos is not None:\n        result['BYSETPOS'] = bysetpos\n\n    if wkst is not None:\n        result['WKST'] = wkst\n\n    if byday is not None:\n        result['BYDAY'] = byday\n\n    if freq is not None:\n        if freq not in vRecur.frequencies:\n            raise ValueError('Frequency value should be one of: {0}'\n                             .format(vRecur.frequencies))\n        result['FREQ'] = freq\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_rrule_from_recurrences_rrule(rule):\n    from recurrence import serialize\n    line = serialize(rule)\n    if line.startswith('RRULE:'):\n        line = line[6:]\n    return build_rrule_from_text(line)", "response": "Build rrule dictionary for vRecur class from a django_recurrences rrule."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_rrule_from_dateutil_rrule(rule):\n    lines = str(rule).splitlines()\n    for line in lines:\n        if line.startswith('DTSTART:'):\n            continue\n        if line.startswith('RRULE:'):\n            line = line[6:]\n        return build_rrule_from_text(line)", "response": "Build rrule dictionary for vRecur class from a dateutil rrule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_items(self, calendar):\n        for item in self.items:\n            event = Event()\n            for ifield, efield in ITEM_EVENT_FIELD_MAP:\n                val = item.get(ifield)\n                if val is not None:\n                    event.add(efield, val)\n            calendar.add_component(event)", "response": "Write all items to the calendar"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of text strings contained within an element and its sub - elements.", "response": "def _textlist(self, _addtail=False):\n    '''Returns a list of text strings contained within an element and its sub-elements.\n\n    Helpful for extracting text from prose-oriented XML (such as XHTML or DocBook).\n    '''\n    result = []\n    if (not _addtail) and (self.text is not None):\n        result.append(self.text)\n    for elem in self:\n        result.extend(elem.textlist(True))\n    if _addtail and self.tail is not None:\n        result.append(self.tail)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the existing indentation from each line of a chunk of text, s, and then prefix each line with a new indent string. Also removes trailing whitespace from each line, and leading and trailing blank lines.", "response": "def _reindent(s, indent, reformat=True):\n    \"\"\"\n    Remove the existing indentation from each line of a chunk of\n    text, s, and then prefix each line with a new indent string.\n\n    Also removes trailing whitespace from each line, and leading and\n    trailing blank lines.\n\n    \"\"\"\n    s = textwrap.dedent(s)\n    s = s.split('\\n')\n    s = [x.rstrip() for x in s]\n    while s and (not s[0]):\n        s = s[1:]\n    while s and (not s[-1]):\n        s = s[:-1]\n    if reformat:\n        s = '\\n'.join(s)\n        s = textwrap.wrap(s, initial_indent=indent, subsequent_indent=indent)\n    else:\n        s = [indent + x for x in s]\n    return '\\n'.join(s) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_docstr(element, indent='', wrap=None):\n    result = []\n\n    txt = element.text and element.text.rstrip()\n    if txt:\n        result.append(_reindent(txt, indent))\n        result.append(indent)\n\n    for d in element.findall('doc') + element.findall('rule'):\n        docval = ''.join(d.textlist()).rstrip()\n        if not docval:\n            continue\n        reformat = True\n        if 'name' in d.attrib:\n            result.append(indent + d.attrib['name'].upper() + ':')\n            result.append(indent)\n            extra_indent = '    '\n            if d.attrib['name'] == 'grammar':\n                reformat = False # Don't want re-indenting to mess this up\n        elif d.tag == 'rule':\n            result.append(indent + 'RULE:')\n            result.append(indent)\n            extra_indent = '    '\n        else:\n            extra_indent = ''\n        result.append(_reindent(docval, indent + extra_indent, reformat))\n        result.append(indent)\n\n    fields = element.findall('field')\n    if fields:\n        result.append(indent + 'PARAMETERS:')\n        for f in fields:\n            result.append(indent + '    ' + _fixup_field_name(f) + ': ' + _field_type(f))\n            field_docs = generate_docstr(f, indent + '        ')\n            if field_docs:\n                result.append(indent)\n                result.append(field_docs)\n            result.append(indent)\n\n    if not result:\n        return None\n\n    if wrap is not None:\n        result = [wrap] + result + [wrap]\n\n    return '\\n'.join(x.rstrip() for x in result) + '\\n'", "response": "Generates a Python docstr for a given element in the AMQP\n    XML spec file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a python module from an AMQP spec.", "response": "def generate_module(spec, out):\n    \"\"\"\n    Given an AMQP spec parsed into an xml.etree.ElemenTree,\n    and a file-like 'out' object to write to, generate\n    the skeleton of a Python module.\n\n    \"\"\"\n    #\n    # HACK THE SPEC so that 'access' is handled by 'channel' instead of 'connection'\n    #\n    for amqp_class in spec.findall('class'):\n        if amqp_class.attrib['name'] == 'access':\n            amqp_class.attrib['handler'] = 'channel'\n\n    #\n    # Build up some helper dictionaries\n    #\n    for domain in spec.findall('domain'):\n        domains[domain.attrib['name']] = domain.attrib['type']\n\n    for amqp_class in spec.findall('class'):\n        for amqp_method in amqp_class.findall('method'):\n            method_name_map[(amqp_class.attrib['name'], amqp_method.attrib['name'])] = \\\n                (\n                    amqp_class.attrib['index'],\n                    amqp_method.attrib['index'],\n                    amqp_class.attrib['handler'].capitalize() + '.' +\n                        _fixup_method_name(amqp_class, amqp_method),\n                )\n\n    #### Actually generate output\n\n    for amqp_class in spec.findall('class'):\n        if amqp_class.attrib['handler'] == amqp_class.attrib['name']:\n            generate_class(spec, amqp_class, out)\n\n    out.write('_METHOD_MAP = {\\n')\n    for amqp_class in spec.findall('class'):\n        print amqp_class.attrib\n#        for chassis in amqp_class.findall('chassis'):\n#            print '  ', chassis.attrib\n        for amqp_method in amqp_class.findall('method'):\n#            print '  ', amqp_method.attrib\n#            for chassis in amqp_method.findall('chassis'):\n#                print '      ', chassis.attrib\n            chassis = [x.attrib['name'] for x in amqp_method.findall('chassis')]\n            if 'client' in chassis:\n                out.write(\"    (%s, %s): (%s, %s._%s),\\n\" % (\n                    amqp_class.attrib['index'],\n                    amqp_method.attrib['index'],\n                    amqp_class.attrib['handler'].capitalize(),\n                    amqp_class.attrib['handler'].capitalize(),\n                    _fixup_method_name(amqp_class, amqp_method)))\n    out.write('}\\n\\n')\n\n    out.write('_METHOD_NAME_MAP = {\\n')\n    for amqp_class in spec.findall('class'):\n        for amqp_method in amqp_class.findall('method'):\n            out.write(\"    (%s, %s): '%s.%s',\\n\" % (\n                amqp_class.attrib['index'],\n                amqp_method.attrib['index'],\n                amqp_class.attrib['handler'].capitalize(),\n                _fixup_method_name(amqp_class, amqp_method)))\n    out.write('}\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _next_method(self):\n        while self.queue.empty():\n            try:\n                frame_type, channel, payload = self.source.read_frame()\n            except Exception, e:\n                #\n                # Connection was closed?  Framing Error?\n                #\n                self.queue.put(e)\n                break\n\n            if self.expected_types[channel] != frame_type:\n                self.queue.put((\n                    channel,\n                    Exception('Received frame type %s while expecting type: %s' %\n                        (frame_type, self.expected_types[channel])\n                        )\n                    ))\n            elif frame_type == 1:\n                self._process_method_frame(channel, payload)\n            elif frame_type == 2:\n                self._process_content_header(channel, payload)\n            elif frame_type == 3:\n                self._process_content_body(channel, payload)", "response": "Read the next method from the source and process it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_content_header(self, channel, payload):\n        partial = self.partial_messages[channel]\n        partial.add_header(payload)\n\n        if partial.complete:\n            #\n            # a bodyless message, we're done\n            #\n            self.queue.put((channel, partial.method_sig, partial.args, partial.msg))\n            del self.partial_messages[channel]\n            self.expected_types[channel] = 1\n        else:\n            #\n            # wait for the content-body\n            #\n            self.expected_types[channel] = 3", "response": "Process the content - header frames and add the payload to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_content_body(self, channel, payload):\n        partial = self.partial_messages[channel]\n        partial.add_payload(payload)\n        if partial.complete:\n            #\n            # Stick the message in the queue and go back to\n            # waiting for method frames\n            #\n            self.queue.put((channel, partial.method_sig, partial.args, partial.msg))\n            del self.partial_messages[channel]\n            self.expected_types[channel] = 1", "response": "Process the content body of a message and put it to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_method(self):\n        self._next_method()\n        m = self.queue.get()\n        if isinstance(m, Exception):\n            raise m\n        return m", "response": "Read a method from the peer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntearing down this object, after we've agreed to close with the server.", "response": "def _do_close(self):\n        \"\"\"\n        Tear down this object, after we've agreed to close with the server.\n\n        \"\"\"\n        AMQP_LOGGER.debug('Closed channel #%d' % self.channel_id)\n        self.is_open = False\n        del self.connection.channels[self.channel_id]\n        self.channel_id = self.connection = None\n        self.callbacks = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self, reply_code=0, reply_text='', method_sig=(0, 0)):\n        if not self.is_open:\n            # already closed\n            return\n\n        args = AMQPWriter()\n        args.write_short(reply_code)\n        args.write_shortstr(reply_text)\n        args.write_short(method_sig[0]) # class_id\n        args.write_short(method_sig[1]) # method_id\n        self._send_method((20, 40), args)\n        return self.wait(allowed_methods=[\n                          (20, 41),    # Channel.close_ok\n                        ])", "response": "This method is used to request a close of the current channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest a channel close This method indicates that the sender wants to close the channel. This may be due to internal conditions (e.g. a forced shut-down) or due to an error handling a specific method, i.e. an exception. When a close is due to an exception, the sender provides the class and method id of the method which caused the exception. RULE: After sending this method any received method except Channel.Close-OK MUST be discarded. RULE: The peer sending this method MAY use a counter or timeout to detect failure of the other peer to respond correctly with Channel.Close-OK.. PARAMETERS: reply_code: short The reply code. The AMQ reply codes are defined in AMQ RFC 011. reply_text: shortstr The localised reply text. This text can be logged as an aid to resolving issues. class_id: short failing method class When the close is provoked by a method exception, this is the class of the method. method_id: short failing method ID When the close is provoked by a method exception, this is the ID of the method.", "response": "def _close(self, args):\n        \"\"\"\n        request a channel close\n\n        This method indicates that the sender wants to close the\n        channel. This may be due to internal conditions (e.g. a forced\n        shut-down) or due to an error handling a specific method, i.e.\n        an exception.  When a close is due to an exception, the sender\n        provides the class and method id of the method which caused\n        the exception.\n\n        RULE:\n\n            After sending this method any received method except\n            Channel.Close-OK MUST be discarded.\n\n        RULE:\n\n            The peer sending this method MAY use a counter or timeout\n            to detect failure of the other peer to respond correctly\n            with Channel.Close-OK..\n\n        PARAMETERS:\n            reply_code: short\n\n                The reply code. The AMQ reply codes are defined in AMQ\n                RFC 011.\n\n            reply_text: shortstr\n\n                The localised reply text.  This text can be logged as an\n                aid to resolving issues.\n\n            class_id: short\n\n                failing method class\n\n                When the close is provoked by a method exception, this\n                is the class of the method.\n\n            method_id: short\n\n                failing method ID\n\n                When the close is provoked by a method exception, this\n                is the ID of the method.\n\n        \"\"\"\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        class_id = args.read_short()\n        method_id = args.read_short()\n\n#        self.close_ok()\n\n\n#    def close_ok(self):\n#        \"\"\"\n#        confirm a channel close\n#\n#        This method confirms a Channel.Close method and tells the\n#        recipient that it is safe to release resources for the channel\n#        and close the socket.\n#\n#        RULE:\n#\n#            A peer that detects a socket closure without having\n#            received a Channel.Close-Ok handshake method SHOULD log\n#            the error.\n#\n#        \"\"\"\n        self._send_method((20, 41))\n        self._do_close()\n\n        raise AMQPChannelException(reply_code, reply_text,\n            (class_id, method_id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndeclare exchange, create if needed This method creates an exchange if it does not already exist, and if the exchange exists, verifies that it is of the correct and expected class. RULE: The server SHOULD support a minimum of 16 exchanges per virtual host and ideally, impose no limit except as defined by available resources. PARAMETERS: exchange: shortstr RULE: Exchange names starting with \"amq.\" are reserved for predeclared and standardised exchanges. If the client attempts to create an exchange starting with \"amq.\", the server MUST raise a channel exception with reply code 403 (access refused). type: shortstr exchange type Each exchange belongs to one of a set of exchange types implemented by the server. The exchange types define the functionality of the exchange - i.e. how messages are routed through it. It is not valid or meaningful to attempt to change the type of an existing exchange. RULE: If the exchange already exists with a different type, the server MUST raise a connection exception with a reply code 507 (not allowed). RULE: If the server does not support the requested exchange type it MUST raise a connection exception with a reply code 503 (command invalid). passive: boolean do not create exchange If set, the server will not create the exchange. The client can use this to check whether an exchange exists without modifying the server state. RULE: If set, and the exchange does not already exist, the server MUST raise a channel exception with reply code 404 (not found). durable: boolean request a durable exchange If set when creating a new exchange, the exchange will be marked as durable. Durable exchanges remain active when a server restarts. Non-durable exchanges (transient exchanges) are purged if/when a server restarts. RULE: The server MUST support both durable and transient exchanges. RULE: The server MUST ignore the durable field if the exchange already exists. auto_delete: boolean auto-delete when unused If set, the exchange is deleted when all queues have finished using it. RULE: The server SHOULD allow for a reasonable delay between the point when it determines that an exchange is not being used (or no longer used), and the point when it deletes the exchange. At the least it must allow a client to create an exchange and then bind a queue to it, with a small but non-zero delay between these two actions. RULE: The server MUST ignore the auto-delete field if the exchange already exists. internal: boolean create internal exchange If set, the exchange may not be used directly by publishers, but only when bound to other exchanges. Internal exchanges are used to construct wiring that is not visible to applications. nowait: boolean do not send a reply method If set, the server will not respond to the method. The client should not wait for a reply method. If the server could not complete the method it will raise a channel or connection exception. arguments: table arguments for declaration A set of arguments for the declaration. The syntax and semantics of these arguments depends on the server implementation. This field is ignored if passive is True. ticket: short When a client defines a new exchange, this belongs to the access realm of the ticket used. All further work done with that exchange must be done with an access ticket for the same realm. RULE: The client MUST provide a valid access ticket giving \"active\" access to the realm in which the exchange exists or will be created, or \"passive\" access if the if-exists flag is set.", "response": "def exchange_declare(self, exchange, type, passive=False, durable=False,\n        auto_delete=True, internal=False, nowait=False,\n        arguments=None, ticket=None):\n        \"\"\"\n        declare exchange, create if needed\n\n        This method creates an exchange if it does not already exist,\n        and if the exchange exists, verifies that it is of the correct\n        and expected class.\n\n        RULE:\n\n            The server SHOULD support a minimum of 16 exchanges per\n            virtual host and ideally, impose no limit except as\n            defined by available resources.\n\n        PARAMETERS:\n            exchange: shortstr\n\n                RULE:\n\n                    Exchange names starting with \"amq.\" are reserved\n                    for predeclared and standardised exchanges.  If\n                    the client attempts to create an exchange starting\n                    with \"amq.\", the server MUST raise a channel\n                    exception with reply code 403 (access refused).\n\n            type: shortstr\n\n                exchange type\n\n                Each exchange belongs to one of a set of exchange\n                types implemented by the server.  The exchange types\n                define the functionality of the exchange - i.e. how\n                messages are routed through it.  It is not valid or\n                meaningful to attempt to change the type of an\n                existing exchange.\n\n                RULE:\n\n                    If the exchange already exists with a different\n                    type, the server MUST raise a connection exception\n                    with a reply code 507 (not allowed).\n\n                RULE:\n\n                    If the server does not support the requested\n                    exchange type it MUST raise a connection exception\n                    with a reply code 503 (command invalid).\n\n            passive: boolean\n\n                do not create exchange\n\n                If set, the server will not create the exchange.  The\n                client can use this to check whether an exchange\n                exists without modifying the server state.\n\n                RULE:\n\n                    If set, and the exchange does not already exist,\n                    the server MUST raise a channel exception with\n                    reply code 404 (not found).\n\n            durable: boolean\n\n                request a durable exchange\n\n                If set when creating a new exchange, the exchange will\n                be marked as durable.  Durable exchanges remain active\n                when a server restarts. Non-durable exchanges\n                (transient exchanges) are purged if/when a server\n                restarts.\n\n                RULE:\n\n                    The server MUST support both durable and transient\n                    exchanges.\n\n                RULE:\n\n                    The server MUST ignore the durable field if the\n                    exchange already exists.\n\n            auto_delete: boolean\n\n                auto-delete when unused\n\n                If set, the exchange is deleted when all queues have\n                finished using it.\n\n                RULE:\n\n                    The server SHOULD allow for a reasonable delay\n                    between the point when it determines that an\n                    exchange is not being used (or no longer used),\n                    and the point when it deletes the exchange.  At\n                    the least it must allow a client to create an\n                    exchange and then bind a queue to it, with a small\n                    but non-zero delay between these two actions.\n\n                RULE:\n\n                    The server MUST ignore the auto-delete field if\n                    the exchange already exists.\n\n            internal: boolean\n\n                create internal exchange\n\n                If set, the exchange may not be used directly by\n                publishers, but only when bound to other exchanges.\n                Internal exchanges are used to construct wiring that\n                is not visible to applications.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n            arguments: table\n\n                arguments for declaration\n\n                A set of arguments for the declaration. The syntax and\n                semantics of these arguments depends on the server\n                implementation.  This field is ignored if passive is\n                True.\n\n            ticket: short\n\n                When a client defines a new exchange, this belongs to\n                the access realm of the ticket used.  All further work\n                done with that exchange must be done with an access\n                ticket for the same realm.\n\n                RULE:\n\n                    The client MUST provide a valid access ticket\n                    giving \"active\" access to the realm in which the\n                    exchange exists or will be created, or \"passive\"\n                    access if the if-exists flag is set.\n\n        \"\"\"\n        if arguments is None:\n            arguments = {}\n\n        args = AMQPWriter()\n        if ticket is not None:\n            args.write_short(ticket)\n        else:\n            args.write_short(self.default_ticket)\n        args.write_shortstr(exchange)\n        args.write_shortstr(type)\n        args.write_bit(passive)\n        args.write_bit(durable)\n        args.write_bit(auto_delete)\n        args.write_bit(internal)\n        args.write_bit(nowait)\n        args.write_table(arguments)\n        self._send_method((40, 10), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                              (40, 11),    # Channel.exchange_declare_ok\n                            ])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exchange_delete(self, exchange, if_unused=False,\n        nowait=False, ticket=None):\n        \"\"\"\n        delete an exchange\n\n        This method deletes an exchange.  When an exchange is deleted\n        all queue bindings on the exchange are cancelled.\n\n        PARAMETERS:\n            exchange: shortstr\n\n                RULE:\n\n                    The exchange MUST exist. Attempting to delete a\n                    non-existing exchange causes a channel exception.\n\n            if_unused: boolean\n\n                delete only if unused\n\n                If set, the server will only delete the exchange if it\n                has no queue bindings. If the exchange has queue\n                bindings the server does not delete it but raises a\n                channel exception instead.\n\n                RULE:\n\n                    If set, the server SHOULD delete the exchange but\n                    only if it has no queue bindings.\n\n                RULE:\n\n                    If set, the server SHOULD raise a channel\n                    exception if the exchange is in use.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n            ticket: short\n\n                RULE:\n\n                    The client MUST provide a valid access ticket\n                    giving \"active\" access rights to the exchange's\n                    access realm.\n\n        \"\"\"\n        args = AMQPWriter()\n        if ticket is not None:\n            args.write_short(ticket)\n        else:\n            args.write_short(self.default_ticket)\n        args.write_shortstr(exchange)\n        args.write_bit(if_unused)\n        args.write_bit(nowait)\n        self._send_method((40, 20), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                              (40, 21),    # Channel.exchange_delete_ok\n                            ])", "response": "This method deletes an exchange."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind queue to an exchange This method binds a queue to an exchange. Until a queue is bound it will not receive any messages. In a classic messaging model, store-and-forward queues are bound to a dest exchange and subscription queues are bound to a dest_wild exchange. RULE: A server MUST allow ignore duplicate bindings - that is, two or more bind methods for a specific queue, with identical arguments - without treating these as an error. RULE: If a bind fails, the server MUST raise a connection exception. RULE: The server MUST NOT allow a durable queue to bind to a transient exchange. If the client attempts this the server MUST raise a channel exception. RULE: Bindings for durable queues are automatically durable and the server SHOULD restore such bindings after a server restart. RULE: If the client attempts to an exchange that was declared as internal, the server MUST raise a connection exception with reply code 530 (not allowed). RULE: The server SHOULD support at least 4 bindings per queue, and ideally, impose no limit except as defined by available resources. PARAMETERS: queue: shortstr Specifies the name of the queue to bind. If the queue name is empty, refers to the current queue for the channel, which is the last declared queue. RULE: If the client did not previously declare a queue, and the queue name in this method is empty, the server MUST raise a connection exception with reply code 530 (not allowed). RULE: If the queue does not exist the server MUST raise a channel exception with reply code 404 (not found). exchange: shortstr The name of the exchange to bind to. RULE: If the exchange does not exist the server MUST raise a channel exception with reply code 404 (not found). routing_key: shortstr message routing key Specifies the routing key for the binding. The routing key is used for routing messages depending on the exchange configuration. Not all exchanges use a routing key - refer to the specific exchange documentation. If the routing key is empty and the queue name is empty, the routing key will be the current queue for the channel, which is the last declared queue. nowait: boolean do not send a reply method If set, the server will not respond to the method. The client should not wait for a reply method. If the server could not complete the method it will raise a channel or connection exception. arguments: table arguments for binding A set of arguments for the binding. The syntax and semantics of these arguments depends on the exchange class. ticket: short The client provides a valid access ticket giving \"active\" access rights to the queue's access realm.", "response": "def queue_bind(self, queue, exchange, routing_key='',\n        nowait=False, arguments=None, ticket=None):\n        \"\"\"\n        bind queue to an exchange\n\n        This method binds a queue to an exchange.  Until a queue is\n        bound it will not receive any messages.  In a classic\n        messaging model, store-and-forward queues are bound to a dest\n        exchange and subscription queues are bound to a dest_wild\n        exchange.\n\n        RULE:\n\n            A server MUST allow ignore duplicate bindings - that is,\n            two or more bind methods for a specific queue, with\n            identical arguments - without treating these as an error.\n\n        RULE:\n\n            If a bind fails, the server MUST raise a connection\n            exception.\n\n        RULE:\n\n            The server MUST NOT allow a durable queue to bind to a\n            transient exchange. If the client attempts this the server\n            MUST raise a channel exception.\n\n        RULE:\n\n            Bindings for durable queues are automatically durable and\n            the server SHOULD restore such bindings after a server\n            restart.\n\n        RULE:\n\n            If the client attempts to an exchange that was declared as\n            internal, the server MUST raise a connection exception\n            with reply code 530 (not allowed).\n\n        RULE:\n\n            The server SHOULD support at least 4 bindings per queue,\n            and ideally, impose no limit except as defined by\n            available resources.\n\n        PARAMETERS:\n            queue: shortstr\n\n                Specifies the name of the queue to bind.  If the queue\n                name is empty, refers to the current queue for the\n                channel, which is the last declared queue.\n\n                RULE:\n\n                    If the client did not previously declare a queue,\n                    and the queue name in this method is empty, the\n                    server MUST raise a connection exception with\n                    reply code 530 (not allowed).\n\n                RULE:\n\n                    If the queue does not exist the server MUST raise\n                    a channel exception with reply code 404 (not\n                    found).\n\n            exchange: shortstr\n\n                The name of the exchange to bind to.\n\n                RULE:\n\n                    If the exchange does not exist the server MUST\n                    raise a channel exception with reply code 404 (not\n                    found).\n\n            routing_key: shortstr\n\n                message routing key\n\n                Specifies the routing key for the binding.  The\n                routing key is used for routing messages depending on\n                the exchange configuration. Not all exchanges use a\n                routing key - refer to the specific exchange\n                documentation.  If the routing key is empty and the\n                queue name is empty, the routing key will be the\n                current queue for the channel, which is the last\n                declared queue.\n\n            nowait: boolean\n\n                do not send a reply method\n\n                If set, the server will not respond to the method. The\n                client should not wait for a reply method.  If the\n                server could not complete the method it will raise a\n                channel or connection exception.\n\n            arguments: table\n\n                arguments for binding\n\n                A set of arguments for the binding.  The syntax and\n                semantics of these arguments depends on the exchange\n                class.\n\n            ticket: short\n\n                The client provides a valid access ticket giving\n                \"active\" access rights to the queue's access realm.\n\n        \"\"\"\n        if arguments is None:\n            arguments = {}\n\n        args = AMQPWriter()\n        if ticket is not None:\n            args.write_short(ticket)\n        else:\n            args.write_short(self.default_ticket)\n        args.write_shortstr(queue)\n        args.write_shortstr(exchange)\n        args.write_shortstr(routing_key)\n        args.write_bit(nowait)\n        args.write_table(arguments)\n        self._send_method((50, 20), args)\n\n        if not nowait:\n            return self.wait(allowed_methods=[\n                              (50, 21),    # Channel.queue_bind_ok\n                            ])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _queue_declare_ok(self, args):\n        queue = args.read_shortstr()\n        message_count = args.read_long()\n        consumer_count = args.read_long()\n\n        return queue, message_count, consumer_count", "response": "This method is called when the user checks that the queue name and message count of the queue and consumer count of the active consumers for the queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _basic_deliver(self, args, msg):\n        consumer_tag = args.read_shortstr()\n        delivery_tag = args.read_longlong()\n        redelivered = args.read_bit()\n        exchange = args.read_shortstr()\n        routing_key = args.read_shortstr()\n\n        msg.delivery_info = {\n            'channel': self,\n            'consumer_tag': consumer_tag,\n            'delivery_tag': delivery_tag,\n            'redelivered': redelivered,\n            'exchange': exchange,\n            'routing_key': routing_key,\n            }\n\n        func = self.callbacks.get(consumer_tag, None)\n        if func is not None:\n            func(msg)", "response": "Basic delivery of a message to a dead - in - queue."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef basic_get(self, queue='', no_ack=False, ticket=None):\n        args = AMQPWriter()\n        if ticket is not None:\n            args.write_short(ticket)\n        else:\n            args.write_short(self.default_ticket)\n        args.write_shortstr(queue)\n        args.write_bit(no_ack)\n        self._send_method((60, 70), args)\n        return self.wait(allowed_methods=[\n                          (60, 71),    # Channel.basic_get_ok\n                          (60, 72),    # Channel.basic_get_empty\n                        ])", "response": "This method returns a message object for a specific queue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a failed message This method returns an undeliverable message that was published with the \"immediate\" flag set, or an unroutable message published with the \"mandatory\" flag set. The reply code and text provide information about the reason that the message was undeliverable. PARAMETERS: reply_code: short The reply code. The AMQ reply codes are defined in AMQ RFC 011. reply_text: shortstr The localised reply text. This text can be logged as an aid to resolving issues. exchange: shortstr Specifies the name of the exchange that the message was originally published to. routing_key: shortstr Message routing key Specifies the routing key name specified when the message was published.", "response": "def _basic_return(self, args, msg):\n        \"\"\"\n        return a failed message\n\n        This method returns an undeliverable message that was\n        published with the \"immediate\" flag set, or an unroutable\n        message published with the \"mandatory\" flag set. The reply\n        code and text provide information about the reason that the\n        message was undeliverable.\n\n        PARAMETERS:\n            reply_code: short\n\n                The reply code. The AMQ reply codes are defined in AMQ\n                RFC 011.\n\n            reply_text: shortstr\n\n                The localised reply text.  This text can be logged as an\n                aid to resolving issues.\n\n            exchange: shortstr\n\n                Specifies the name of the exchange that the message\n                was originally published to.\n\n            routing_key: shortstr\n\n                Message routing key\n\n                Specifies the routing key name specified when the\n                message was published.\n\n        \"\"\"\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        exchange = args.read_shortstr()\n        routing_key = args.read_shortstr()\n\n        self.returned_messages.put(\n            (reply_code, reply_text, exchange, routing_key, msg)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wait_method(self, channel_id, allowed_methods):\n        #\n        # Check the channel's deferred methods\n        #\n        method_queue = self.channels[channel_id].method_queue\n\n        for queued_method in method_queue:\n            method_sig = queued_method[0]\n            if (allowed_methods is None) \\\n            or (method_sig in allowed_methods) \\\n            or (method_sig == (20, 40)):\n                method_queue.remove(queued_method)\n                return queued_method\n\n        #\n        # Nothing queued, need to wait for a method from the peer\n        #\n        while True:\n            channel, method_sig, args, content = \\\n                self.method_reader.read_method()\n\n            if (channel == channel_id) \\\n            and ((allowed_methods is None) \\\n                or (method_sig in allowed_methods) \\\n                or (method_sig == (20, 40))):\n                return method_sig, args, content\n\n            #\n            # Certain methods like basic_return should be dispatched\n            # immediately rather than being queued, even if they're not\n            # one of the 'allowed_methods' we're looking for.\n            #\n            if (channel != 0) and (method_sig in Channel._IMMEDIATE_METHODS):\n                self.channels[channel].dispatch_method(method_sig, args, content)\n                continue\n\n            #\n            # Not the channel and/or method we were looking for.  Queue\n            # this method for later\n            #\n            self.channels[channel].method_queue.append((method_sig, args, content))\n\n            #\n            # If we just queued up a method for channel 0 (the Connection\n            # itself) it's probably a close method in reaction to some\n            # error, so deal with it right away.\n            #\n            if channel == 0:\n                self.wait()", "response": "Wait for a method from the server destined for a particular channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef channel(self, channel_id=None):\n        if channel_id in self.channels:\n            return self.channels[channel_id]\n\n        return Channel(self, channel_id)", "response": "Fetch a Channel object identified by the numeric channel_id or create it if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _close(self, args):\n        reply_code = args.read_short()\n        reply_text = args.read_shortstr()\n        class_id = args.read_short()\n        method_id = args.read_short()\n\n        self._x_close_ok()\n\n        raise AMQPConnectionException(reply_code, reply_text, (class_id, method_id))", "response": "This method is called by the server to request a connection close from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a connection to a specific virtual host.", "response": "def _x_open(self, virtual_host, capabilities='', insist=False):\n        \"\"\"\n        open connection to virtual host\n\n        This method opens a connection to a virtual host, which is a\n        collection of resources, and acts to separate multiple\n        application domains within a server.\n\n        RULE:\n\n            The client MUST open the context before doing any work on\n            the connection.\n\n        PARAMETERS:\n            virtual_host: shortstr\n\n                virtual host name\n\n                The name of the virtual host to work with.\n\n                RULE:\n\n                    If the server supports multiple virtual hosts, it\n                    MUST enforce a full separation of exchanges,\n                    queues, and all associated entities per virtual\n                    host. An application, connected to a specific\n                    virtual host, MUST NOT be able to access resources\n                    of another virtual host.\n\n                RULE:\n\n                    The server SHOULD verify that the client has\n                    permission to access the specified virtual host.\n\n                RULE:\n\n                    The server MAY configure arbitrary limits per\n                    virtual host, such as the number of each type of\n                    entity that may be used, per connection and/or in\n                    total.\n\n            capabilities: shortstr\n\n                required capabilities\n\n                The client may specify a number of capability names,\n                delimited by spaces.  The server can use this string\n                to how to process the client's connection request.\n\n            insist: boolean\n\n                insist on connecting to server\n\n                In a configuration with multiple load-sharing servers,\n                the server may respond to a Connection.Open method\n                with a Connection.Redirect. The insist option tells\n                the server that the client is insisting on a\n                connection to the specified server.\n\n                RULE:\n\n                    When the client uses the insist option, the server\n                    SHOULD accept the client connection unless it is\n                    technically unable to do so.\n\n        \"\"\"\n        args = AMQPWriter()\n        args.write_shortstr(virtual_host)\n        args.write_shortstr(capabilities)\n        args.write_bit(insist)\n        self._send_method((10, 40), args)\n        return self.wait(allowed_methods=[\n                          (10, 41),    # Connection.open_ok\n                          (10, 50),    # Connection.redirect\n                        ])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsignal that the connection is ready This method signals to the client that the connection is ready for use. PARAMETERS: known_hosts: shortstr", "response": "def _open_ok(self, args):\n        \"\"\"\n        signal that the connection is ready\n\n        This method signals to the client that the connection is ready\n        for use.\n\n        PARAMETERS:\n            known_hosts: shortstr\n\n        \"\"\"\n        self.known_hosts = args.read_shortstr()\n        AMQP_LOGGER.debug('Open OK! known_hosts [%s]' % self.known_hosts)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nask the client to use a different server This method redirects the client to another server, based on the requested virtual host and/or capabilities. RULE: When getting the Connection.Redirect method, the client SHOULD reconnect to the host specified, and if that host is not present, to any of the hosts specified in the known-hosts list. PARAMETERS: host: shortstr server to connect to Specifies the server to connect to. This is an IP address or a DNS name, optionally followed by a colon and a port number. If no port number is specified, the client should use the default port number for the protocol. known_hosts: shortstr", "response": "def _redirect(self, args):\n        \"\"\"\n        asks the client to use a different server\n\n        This method redirects the client to another server, based on\n        the requested virtual host and/or capabilities.\n\n        RULE:\n\n            When getting the Connection.Redirect method, the client\n            SHOULD reconnect to the host specified, and if that host\n            is not present, to any of the hosts specified in the\n            known-hosts list.\n\n        PARAMETERS:\n            host: shortstr\n\n                server to connect to\n\n                Specifies the server to connect to.  This is an IP\n                address or a DNS name, optionally followed by a colon\n                and a port number. If no port number is specified, the\n                client should use the default port number for the\n                protocol.\n\n            known_hosts: shortstr\n\n        \"\"\"\n        host = args.read_shortstr()\n        self.known_hosts = args.read_shortstr()\n        AMQP_LOGGER.debug('Redirected to [%s], known_hosts [%s]' % (host, self.known_hosts))\n        return host"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _start(self, args):\n        self.version_major = args.read_octet()\n        self.version_minor = args.read_octet()\n        self.server_properties = args.read_table()\n        self.mechanisms = args.read_longstr().split(' ')\n        self.locales = args.read_longstr().split(' ')\n\n        AMQP_LOGGER.debug('Start from server, version: %d.%d, properties: %s, mechanisms: %s, locales: %s'\n                % (self.version_major, self.version_minor,\n                   str(self.server_properties), self.mechanisms, self.locales))", "response": "This method is called by the server to start the connection negotiation process by the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting security mechanism and locale This method selects a SASL security mechanism. ASL uses SASL (RFC2222) to negotiate authentication and encryption. PARAMETERS: client_properties: table client properties mechanism: shortstr selected security mechanism A single security mechanisms selected by the client, which must be one of those specified by the server. RULE: The client SHOULD authenticate using the highest- level security profile it can handle from the list provided by the server. RULE: The mechanism field MUST contain one of the security mechanisms proposed by the server in the Start method. If it doesn't, the server MUST close the socket. response: longstr security response data A block of opaque data passed to the security mechanism. The contents of this data are defined by the SASL security mechanism. For the PLAIN security mechanism this is defined as a field table holding two fields, LOGIN and PASSWORD. locale: shortstr selected message locale A single message local selected by the client, which must be one of those specified by the server.", "response": "def _x_start_ok(self, client_properties, mechanism, response, locale):\n        \"\"\"\n        select security mechanism and locale\n\n        This method selects a SASL security mechanism. ASL uses SASL\n        (RFC2222) to negotiate authentication and encryption.\n\n        PARAMETERS:\n            client_properties: table\n\n                client properties\n\n            mechanism: shortstr\n\n                selected security mechanism\n\n                A single security mechanisms selected by the client,\n                which must be one of those specified by the server.\n\n                RULE:\n\n                    The client SHOULD authenticate using the highest-\n                    level security profile it can handle from the list\n                    provided by the server.\n\n                RULE:\n\n                    The mechanism field MUST contain one of the\n                    security mechanisms proposed by the server in the\n                    Start method. If it doesn't, the server MUST close\n                    the socket.\n\n            response: longstr\n\n                security response data\n\n                A block of opaque data passed to the security\n                mechanism. The contents of this data are defined by\n                the SASL security mechanism.  For the PLAIN security\n                mechanism this is defined as a field table holding two\n                fields, LOGIN and PASSWORD.\n\n            locale: shortstr\n\n                selected message locale\n\n                A single message local selected by the client, which\n                must be one of those specified by the server.\n\n        \"\"\"\n        args = AMQPWriter()\n        args.write_table(client_properties)\n        args.write_shortstr(mechanism)\n        args.write_longstr(response)\n        args.write_shortstr(locale)\n        self._send_method((10, 11), args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _tune(self, args):\n        self.channel_max = args.read_short() or self.channel_max\n        self.frame_max = args.read_long() or self.frame_max\n        self.method_writer.frame_max = self.frame_max\n        self.heartbeat = args.read_short()\n\n        self._x_tune_ok(self.channel_max, self.frame_max, 0)", "response": "proposes connection tuning parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send_method(self, method_sig, args=bytes(), content=None):\n        if isinstance(args, AMQPWriter):\n            args = args.getvalue()\n\n        self.connection.method_writer.write_method(self.channel_id,\n            method_sig, args, content)", "response": "Send a method to our channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads an AMQP frame.", "response": "def read_frame(self):\n        \"\"\"\n        Read an AMQP frame.\n\n        \"\"\"\n        frame_type, channel, size = unpack('>BHI', self._read(7))\n        payload = self._read(size)\n        ch = ord(self._read(1))\n        if ch == 206: # '\\xce'\n            return frame_type, channel, payload\n        else:\n            raise Exception('Framing Error, received 0x%02x while expecting 0xce' % ch)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_frame(self, frame_type, channel, payload):\n        size = len(payload)\n        self._write(pack('>BHI%dsB' % size,\n            frame_type, channel, size, payload, 0xce))", "response": "Write out an AMQP frame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _setup_transport(self):\n        if HAVE_PY26_SSL:\n            if hasattr(self, 'sslopts'):\n                self.sslobj = ssl.wrap_socket(self.sock, **self.sslopts)\n            else:\n                self.sslobj = ssl.wrap_socket(self.sock)\n            self.sslobj.do_handshake()\n        else:\n            self.sslobj = socket.ssl(self.sock)", "response": "Wrap the socket in an SSL object and do the handshake."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _shutdown_transport(self):\n        if HAVE_PY26_SSL and (self.sslobj is not None):\n            self.sock = self.sslobj.unwrap()\n            self.sslobj = None", "response": "Unwrap a Python 2. 6 SSL socket and then shutdown the transport."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read(self, n):\n        result = self.sslobj.read(n)\n\n        while len(result) < n:\n            s = self.sslobj.read(n - len(result))\n            if not s:\n                raise IOError('Socket closed')\n            result += s\n\n        return result", "response": "Read n bytes from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write(self, s):\n        while s:\n            n = self.sslobj.write(s)\n            if not n:\n                raise IOError('Socket closed')\n            s = s[n:]", "response": "Write a string out to the SSL socket fully."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setup_transport(self):\n        self._write = self.sock.sendall\n        self._read_buffer = bytes()", "response": "Setup the transport for writing to the socket and reading buffered data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread exactly n bytes from the socket.", "response": "def _read(self, n):\n        \"\"\"\n        Read exactly n bytes from the socket\n\n        \"\"\"\n        while len(self._read_buffer) < n:\n            s = self.sock.recv(65536)\n            if not s:\n                raise IOError('Socket closed')\n            self._read_buffer += s\n\n        result = self._read_buffer[:n]\n        self._read_buffer = self._read_buffer[n:]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads an AMQP table and return as a Python dictionary.", "response": "def read_table(self):\n        \"\"\"\n        Read an AMQP table, and return as a Python dictionary.\n\n        \"\"\"\n        self.bitcount = self.bits = 0\n        tlen = unpack('>I', self.input.read(4))[0]\n        table_data = AMQPReader(self.input.read(tlen))\n        result = {}\n        while table_data.input.tell() < tlen:\n            name = table_data.read_shortstr()\n            ftype = ord(table_data.input.read(1))\n            if ftype == 83: # 'S'\n                val = table_data.read_longstr()\n            elif ftype == 73: # 'I'\n                val = unpack('>i', table_data.input.read(4))[0]\n            elif ftype == 68: # 'D'\n                d = table_data.read_octet()\n                n = unpack('>i', table_data.input.read(4))[0]\n                val = Decimal(n) / Decimal(10 ** d)\n            elif ftype == 84: # 'T'\n                val = table_data.read_timestamp()\n            elif ftype == 70: # 'F'\n                val = table_data.read_table() # recurse\n            else:\n                raise ValueError('Unknown table item type: %s' % repr(ftype))\n            result[name] = val\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_bit(self, b):\n        if b:\n            b = 1\n        else:\n            b = 0\n        shift = self.bitcount % 8\n        if shift == 0:\n            self.bits.append(0)\n        self.bits[-1] |= (b << shift)\n        self.bitcount += 1", "response": "Write a boolean value to the internal bit array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites an integer as an unsigned 8 - bit value.", "response": "def write_octet(self, n):\n        \"\"\"\n        Write an integer as an unsigned 8-bit value.\n\n        \"\"\"\n        if (n < 0) or (n > 255):\n            raise ValueError('Octet out of range 0..255')\n        self._flushbits()\n        self.out.write(pack('B', n))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting an unsigned 16 - bit integer to the underlying output stream.", "response": "def write_short(self, n):\n        \"\"\"\n        Write an integer as an unsigned 16-bit value.\n\n        \"\"\"\n        if (n < 0) or (n > 65535):\n            raise ValueError('Octet out of range 0..65535')\n        self._flushbits()\n        self.out.write(pack('>H', n))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_long(self, n):\n        if (n < 0) or (n >= (2**32)):\n            raise ValueError('Octet out of range 0..2**31-1')\n        self._flushbits()\n        self.out.write(pack('>I', n))", "response": "Writes an integer as an unsigned 2 32 - bit value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites an unsigned 64 - bit integer as an unsigned 64 - bit value.", "response": "def write_longlong(self, n):\n        \"\"\"\n        Write an integer as an unsigned 64-bit value.\n\n        \"\"\"\n        if (n < 0) or (n >= (2**64)):\n            raise ValueError('Octet out of range 0..2**64-1')\n        self._flushbits()\n        self.out.write(pack('>Q', n))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_shortstr(self, s):\n        self._flushbits()\n        if isinstance(s, unicode):\n            s = s.encode('utf-8')\n        if len(s) > 255:\n            raise ValueError('String too long')\n        self.write_octet(len(s))\n        self.out.write(s)", "response": "Write a short string to the underlying output stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite out a dictionary made of up string keys and values that are strings signed integers Decimal datetime. datetime or tuples that are sub - dictionaries.", "response": "def write_table(self, d):\n        \"\"\"\n        Write out a Python dictionary made of up string keys, and values\n        that are strings, signed integers, Decimal, datetime.datetime, or\n        sub-dictionaries following the same constraints.\n\n        \"\"\"\n        self._flushbits()\n        table_data = AMQPWriter()\n        for k, v in d.items():\n            table_data.write_shortstr(k)\n            if isinstance(v, basestring):\n                if isinstance(v, unicode):\n                    v = v.encode('utf-8')\n                table_data.write(byte(83)) # 'S'\n                table_data.write_longstr(v)\n            elif isinstance(v, (int, long)):\n                table_data.write(byte(73)) # 'I'\n                table_data.write(pack('>i', v))\n            elif isinstance(v, Decimal):\n                table_data.write(byte(68)) # 'D'\n                sign, digits, exponent = v.as_tuple()\n                v = 0\n                for d in digits:\n                    v = (v * 10) + d\n                if sign:\n                    v = -v\n                table_data.write_octet(-exponent)\n                table_data.write(pack('>i', v))\n            elif isinstance(v, datetime):\n                table_data.write(byte(84)) # 'T'\n                table_data.write_timestamp(v)\n                ## FIXME: timezone ?\n            elif isinstance(v, dict):\n                table_data.write(byte(70)) # 'F'\n                table_data.write_table(v)\n            else:\n                raise ValueError('%s not serializable in AMQP' % repr(v))\n        table_data = table_data.getvalue()\n        self.write_long(len(table_data))\n        self.out.write(table_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_timestamp(self, v):\n        self.out.write(pack('>q', long(mktime(v.timetuple()))))", "response": "Writes out a Python datetime. datetime object as a 64 - bit integer representing seconds since the Unix epoch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_unexpected_error(e):  # pragma: no cover\n    sys.stderr.write('Unexpected error: {} ({})\\n'.format(\n        str(e), e.__class__.__name__))\n    sys.stderr.write('See file slam_error.log for additional details.\\n')\n    sys.exit(1)", "response": "Catch - all error handler\n    Unexpected errors will be handled by this function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a new configuration file.", "response": "def init(name, description, bucket, timeout, memory, stages, requirements,\n         function, runtime, config_file, **kwargs):\n    \"\"\"Generate a configuration file.\"\"\"\n    if os.path.exists(config_file):\n        raise RuntimeError('Please delete the old version {} if you want to '\n                           'reconfigure your project.'.format(config_file))\n\n    module, app = function.split(':')\n    if not name:\n        name = module.replace('_', '-')\n    if not re.match('^[a-zA-Z][-a-zA-Z0-9]*$', name):\n        raise ValueError('The name {} is invalid, only letters, numbers and '\n                         'dashes are allowed.'.format(name))\n    if not bucket:\n        random_suffix = ''.join(\n            random.choice(string.ascii_uppercase + string.digits)\n            for n in range(8))\n        bucket = '{}-{}'.format(name, random_suffix)\n\n    stages = [s.strip() for s in stages.split(',')]\n\n    if runtime is None:\n        if sys.version_info[0] == 2:  # pragma: no cover\n            runtime = 'python2.7'\n        else:\n            runtime = 'python3.6'\n\n    # generate slam.yaml\n    template_file = os.path.join(os.path.dirname(__file__),\n                                 'templates/slam.yaml')\n    with open(template_file) as f:\n        template = f.read()\n    template = render_template(template, name=name, description=description,\n                               module=module, app=app, bucket=bucket,\n                               timeout=timeout, memory=memory,\n                               requirements=requirements, stages=stages,\n                               devstage=stages[0], runtime=runtime)\n    with open(config_file, 'wt') as f:\n        f.write(template)\n\n    # plugins\n    config = _load_config(config_file)\n    for name, plugin in plugins.items():\n        # write plugin documentation as a comment in config file\n        with open(config_file, 'at') as f:\n            f.write('\\n\\n# ' + (plugin.__doc__ or name).replace(\n                '\\n', '\\n# ') + '\\n')\n        if hasattr(plugin, 'init'):\n            arguments = {k: v for k, v in kwargs.items()\n                         if k in getattr(plugin.init, '_argnames', [])}\n            plugin_config = plugin.init.func(config=config, **arguments)\n            if plugin_config:\n                with open(config_file, 'at') as f:\n                    yaml.dump({name: plugin_config}, f,\n                              default_flow_style=False)\n\n    print('The configuration file for your project has been generated. '\n          'Remember to add {} to source control.'.format(config_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the function. This is the default when no plugins are defined in the Wsgi app.", "response": "def _run_lambda_function(event, context, app, config):  # pragma: no cover\n    \"\"\"Run the function. This is the default when no plugins (such as wsgi)\n    define an alternative run function.\"\"\"\n    args = event.get('args', [])\n    kwargs = event.get('kwargs', {})\n\n    # first attempt to invoke the function passing the lambda event and context\n    try:\n        ret = app(*args, event=event, context=context, **kwargs)\n    except TypeError:\n        # try again without passing the event and context\n        ret = app(*args, **kwargs)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a handler. py file for the lambda function start up.", "response": "def _generate_lambda_handler(config, output='.slam/handler.py'):\n    \"\"\"Generate a handler.py file for the lambda function start up.\"\"\"\n    # Determine what the start up code is. The default is to just run the\n    # function, but it can be overriden by a plugin such as wsgi for a more\n    # elaborated way to run the function.\n    run_function = _run_lambda_function\n    for name, plugin in plugins.items():\n        if name in config and hasattr(plugin, 'run_lambda_function'):\n            run_function = plugin.run_lambda_function\n    run_code = ''.join(inspect.getsourcelines(run_function)[0][1:])\n\n    # generate handler.py\n    with open(os.path.join(os.path.dirname(__file__),\n                           'templates/handler.py.template')) as f:\n        template = f.read()\n    template = render_template(template, module=config['function']['module'],\n                               app=config['function']['app'],\n                               run_lambda_function=run_code,\n                               config_json=json.dumps(config,\n                                                      separators=(',', ':')))\n    with open(output, 'wt') as f:\n        f.write(template + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deploy(stage, lambda_package, no_lambda, rebuild_deps, config_file):\n    config = _load_config(config_file)\n    if stage is None:\n        stage = config['devstage']\n\n    s3 = boto3.client('s3')\n    cfn = boto3.client('cloudformation')\n    region = _get_aws_region()\n\n    # obtain previous deployment if it exists\n    previous_deployment = None\n    try:\n        previous_deployment = cfn.describe_stacks(\n            StackName=config['name'])['Stacks'][0]\n    except botocore.exceptions.ClientError:\n        pass\n\n    # build lambda package if required\n    built_package = False\n    new_package = True\n    if lambda_package is None and not no_lambda:\n        print(\"Building lambda package...\")\n        lambda_package = _build(config, rebuild_deps=rebuild_deps)\n        built_package = True\n    elif lambda_package is None:\n        # preserve package from previous deployment\n        new_package = False\n        lambda_package = _get_from_stack(previous_deployment, 'Parameter',\n                                         'LambdaS3Key')\n\n    # create S3 bucket if it doesn't exist yet\n    bucket = config['aws']['s3_bucket']\n    _ensure_bucket_exists(s3, bucket, region)\n\n    # upload lambda package to S3\n    if new_package:\n        s3.upload_file(lambda_package, bucket, lambda_package)\n        if built_package:\n            # we created the package, so now that is on S3 we can delete it\n            os.remove(lambda_package)\n\n    # prepare cloudformation template\n    template_body = get_cfn_template(config)\n    parameters = [\n        {'ParameterKey': 'LambdaS3Bucket', 'ParameterValue': bucket},\n        {'ParameterKey': 'LambdaS3Key', 'ParameterValue': lambda_package},\n    ]\n    stages = list(config['stage_environments'].keys())\n    stages.sort()\n    for s in stages:\n        param = s.title() + 'Version'\n        if s != stage:\n            v = _get_from_stack(previous_deployment, 'Parameter', param) \\\n                if previous_deployment else '$LATEST'\n            v = v or '$LATEST'\n        else:\n            v = '$LATEST'\n        parameters.append({'ParameterKey': param, 'ParameterValue': v})\n\n    # run the cloudformation template\n    if previous_deployment is None:\n        print('Deploying {}:{}...'.format(config['name'], stage))\n        cfn.create_stack(StackName=config['name'], TemplateBody=template_body,\n                         Parameters=parameters,\n                         Capabilities=['CAPABILITY_IAM'])\n        waiter = cfn.get_waiter('stack_create_complete')\n    else:\n        print('Updating {}:{}...'.format(config['name'], stage))\n        cfn.update_stack(StackName=config['name'], TemplateBody=template_body,\n                         Parameters=parameters,\n                         Capabilities=['CAPABILITY_IAM'])\n        waiter = cfn.get_waiter('stack_update_complete')\n\n    # wait for cloudformation to do its thing\n    try:\n        waiter.wait(StackName=config['name'])\n    except botocore.exceptions.ClientError:\n        # the update failed, so we remove the lambda package from S3\n        if built_package:\n            s3.delete_object(Bucket=bucket, Key=lambda_package)\n        raise\n    else:\n        if previous_deployment and new_package:\n            # the update succeeded, so it is safe to delete the lambda package\n            # used by the previous deployment\n            old_pkg = _get_from_stack(previous_deployment, 'Parameter',\n                                      'LambdaS3Key')\n            s3.delete_object(Bucket=bucket, Key=old_pkg)\n\n    # we are done, show status info and exit\n    _print_status(config)", "response": "Deploy the project to the development stage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef publish(version, stage, config_file):\n    config = _load_config(config_file)\n    cfn = boto3.client('cloudformation')\n\n    if version is None:\n        version = config['devstage']\n    elif version not in config['stage_environments'].keys() and \\\n            not version.isdigit():\n        raise ValueError('Invalid version. Use a stage name or a numeric '\n                         'version number.')\n    if version == stage:\n        raise ValueError('Cannot deploy a stage into itself.')\n\n    # obtain previous deployment\n    try:\n        previous_deployment = cfn.describe_stacks(\n            StackName=config['name'])['Stacks'][0]\n    except botocore.exceptions.ClientError:\n        raise RuntimeError('This project has not been deployed yet.')\n\n    # preserve package from previous deployment\n    bucket = _get_from_stack(previous_deployment, 'Parameter',\n                             'LambdaS3Bucket')\n    lambda_package = _get_from_stack(previous_deployment, 'Parameter',\n                                     'LambdaS3Key')\n\n    # prepare cloudformation template\n    template_body = get_cfn_template(config)\n    parameters = [\n        {'ParameterKey': 'LambdaS3Bucket', 'ParameterValue': bucket},\n        {'ParameterKey': 'LambdaS3Key', 'ParameterValue': lambda_package},\n    ]\n    stages = list(config['stage_environments'].keys())\n    stages.sort()\n    for s in stages:\n        param = s.title() + 'Version'\n        if s != stage:\n            v = _get_from_stack(previous_deployment, 'Parameter', param) \\\n                if previous_deployment else '$LATEST'\n            v = v or '$LATEST'\n        else:\n            if version.isdigit():\n                # explicit version number\n                v = version\n            else:\n                # publish version from a stage\n                v = _get_from_stack(previous_deployment, 'Parameter',\n                                    version.title() + 'Version')\n                if v == '$LATEST':\n                    # publish a new version from $LATEST\n                    lmb = boto3.client('lambda')\n                    v = lmb.publish_version(FunctionName=_get_from_stack(\n                        previous_deployment, 'Output', 'FunctionArn'))[\n                            'Version']\n        parameters.append({'ParameterKey': param, 'ParameterValue': v})\n\n    # run the cloudformation template\n    print('Publishing {}:{} to {}...'.format(config['name'], version, stage))\n    cfn.update_stack(StackName=config['name'], TemplateBody=template_body,\n                     Parameters=parameters,\n                     Capabilities=['CAPABILITY_IAM'])\n    waiter = cfn.get_waiter('stack_update_complete')\n\n    # wait for cloudformation to do its thing\n    try:\n        waiter.wait(StackName=config['name'])\n    except botocore.exceptions.ClientError:\n        raise\n\n    # we are done, show status info and exit\n    _print_status(config)", "response": "Publish a version of the project to a stage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef invoke(stage, async, dry_run, config_file, args):\n    config = _load_config(config_file)\n    if stage is None:\n        stage = config['devstage']\n\n    cfn = boto3.client('cloudformation')\n    lmb = boto3.client('lambda')\n\n    try:\n        stack = cfn.describe_stacks(StackName=config['name'])['Stacks'][0]\n    except botocore.exceptions.ClientError:\n        raise RuntimeError('This project has not been deployed yet.')\n    function = _get_from_stack(stack, 'Output', 'FunctionArn')\n\n    if dry_run:\n        invocation_type = 'DryRun'\n    elif async:\n        invocation_type = 'Event'\n    else:\n        invocation_type = 'RequestResponse'\n\n    # parse input arguments\n    data = {}\n    for arg in args:\n        s = arg.split('=', 1)\n        if len(s) != 2:\n            raise ValueError('Invalid argument ' + arg)\n        if s[0][-1] == ':':\n            # JSON argument\n            data[s[0][:-1]] = json.loads(s[1])\n        else:\n            # string argument\n            data[s[0]] = s[1]\n\n    rv = lmb.invoke(FunctionName=function, InvocationType=invocation_type,\n                    Qualifier=stage,\n                    Payload=json.dumps({'kwargs': data}, sort_keys=True))\n    if rv['StatusCode'] != 200 and rv['StatusCode'] != 202:\n        raise RuntimeError('Unexpected error. Status code = {}.'.format(\n            rv['StatusCode']))\n    if invocation_type == 'RequestResponse':\n        payload = json.loads(rv['Payload'].read().decode('utf-8'))\n        if 'FunctionError' in rv:\n            if 'stackTrace' in payload:\n                print('Traceback (most recent call last):')\n                for frame in payload['stackTrace']:\n                    print('  File \"{}\", line {}, in {}'.format(\n                        frame[0], frame[1], frame[2]))\n                    print('    ' + frame[3])\n                print('{}: {}'.format(payload['errorType'],\n                                      payload['errorMessage']))\n            else:\n                raise RuntimeError('Unknown error')\n        else:\n            print(str(payload))", "response": "Invoke the lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps logs to the console.", "response": "def logs(stage, period, tail, config_file):\n    \"\"\"Dump logs to the console.\"\"\"\n    config = _load_config(config_file)\n    if stage is None:\n        stage = config['devstage']\n\n    cfn = boto3.client('cloudformation')\n    try:\n        stack = cfn.describe_stacks(StackName=config['name'])['Stacks'][0]\n    except botocore.exceptions.ClientError:\n        print('{} has not been deployed yet.'.format(config['name']))\n        return\n    function = _get_from_stack(stack, 'Output', 'FunctionArn').split(':')[-1]\n    version = _get_from_stack(stack, 'Parameter', stage.title() + 'Version')\n    api_id = _get_from_stack(stack, 'Output', 'ApiId')\n\n    try:\n        start = float(period[:-1])\n    except ValueError:\n        raise ValueError('Invalid period ' + period)\n    if period[-1] == 's':\n        start = time.time() - start\n    elif period[-1] == 'm':\n        start = time.time() - start * 60\n    elif period[-1] == 'h':\n        start = time.time() - start * 60 * 60\n    elif period[-1] == 'd':\n        start = time.time() - start * 60 * 60 * 24\n    elif period[-1] == 'w':\n        start = time.time() - start * 60 * 60 * 24 * 7\n    else:\n        raise ValueError('Invalid period ' + period)\n    start = int(start * 1000)\n\n    logs = boto3.client('logs')\n    lambda_log_group = '/aws/lambda/' + function\n    log_groups = [lambda_log_group]\n    if api_id:\n        log_groups.append('API-Gateway-Execution-Logs_' + api_id + '/' + stage)\n    log_version = '[' + version + ']'\n    log_start = {g: start for g in log_groups}\n    while True:\n        kwargs = {}\n        events = []\n        for log_group in log_groups:\n            while True:\n                try:\n                    l = logs.filter_log_events(logGroupName=log_group,\n                                               startTime=log_start[log_group],\n                                               interleaved=True, **kwargs)\n                except botocore.exceptions.ClientError:\n                    # the log group does not exist yet\n                    l = {'events': []}\n                if log_group == lambda_log_group:\n                    events += [ev for ev in l['events']\n                               if log_version in ev['logStreamName']]\n                else:\n                    events += l['events']\n                if len(l['events']):\n                    log_start[log_group] = l['events'][-1]['timestamp'] + 1\n                if 'nextToken' not in l:\n                    break\n                kwargs['nextToken'] = l['nextToken']\n        events.sort(key=lambda ev: ev['timestamp'])\n        for ev in events:\n            tm = datetime.fromtimestamp(ev['timestamp'] / 1000)\n            print(tm.strftime('%b %d %X ') + ev['message'].strip())\n        if not tail:\n            break\n        time.sleep(5)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the default Cloudformation deployment template.", "response": "def template(config_file):\n    \"\"\"Print the default Cloudformation deployment template.\"\"\"\n    config = _load_config(config_file)\n    print(get_cfn_template(config, pretty=True))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_plugins():\n    if pkg_resources:  # pragma: no cover\n        for ep in pkg_resources.iter_entry_points('slam_plugins'):\n            plugin = ep.load()\n\n            # add any init options to the main init command\n            if hasattr(plugin, 'init') and hasattr(plugin.init, '_arguments'):\n                for arg in plugin.init._arguments:\n                    init.parser.add_argument(*arg[0], **arg[1])\n                init._arguments += plugin.init._arguments\n                init._argnames += plugin.init._argnames\n\n            plugins[ep.name] = plugin", "response": "find any installed plugins and register them."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef synchronise_device_state(self, device_state, authentication_headers):\n\n        payload = {\n            'context': device_state,\n            'event': {\n                'header': {\n                    'namespace': 'System',\n                    'name': 'SynchronizeState',\n                    'messageId': ''\n                },\n                'payload': {}\n            }\n        }\n        multipart_data = MultipartEncoder(\n            fields=[\n                (\n                    'metadata', (\n                        'metadata',\n                        json.dumps(payload),\n                        'application/json',\n                        {'Content-Disposition': \"form-data; name='metadata'\"}\n                    )\n                ),\n            ],\n            boundary='boundary'\n        )\n        headers = {\n            **authentication_headers,\n            'Content-Type': multipart_data.content_type\n        }\n        stream_id = self.connection.request(\n            'GET',\n            '/v20160207/events',\n            body=multipart_data,\n            headers=headers,\n        )\n        response = self.connection.get_response(stream_id)\n        assert response.status in [http.client.NO_CONTENT, http.client.OK]", "response": "Synchronise the state of a device with AVS."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending audio to AVS.", "response": "def send_audio_file(\n        self, audio_file, device_state, authentication_headers,\n        dialog_request_id, distance_profile, audio_format\n    ):\n        \"\"\"\n        Send audio to AVS\n\n        The file-like object are steaming uploaded for improved latency.\n\n        Returns:\n            bytes -- wav audio bytes returned from AVS\n\n        \"\"\"\n\n        payload = {\n            'context': device_state,\n            'event': {\n                'header': {\n                    'namespace': 'SpeechRecognizer',\n                    'name': 'Recognize',\n                    'messageId': self.generate_message_id(),\n                    'dialogRequestId': dialog_request_id,\n                },\n                'payload': {\n                    'profile': distance_profile,\n                    'format': audio_format\n                }\n            }\n        }\n        multipart_data = MultipartEncoder(\n            fields=[\n                (\n                    'request', (\n                        'request',\n                        json.dumps(payload),\n                        'application/json;',\n                        {'Content-Disposition': \"form-data; name='request'\"}\n                    ),\n                ),\n                (\n                    'audio', (\n                        'audio',\n                        audio_file,\n                        'application/octet-stream',\n                        {'Content-Disposition': \"form-data; name='audio'\"}\n                    )\n                ),\n            ],\n            boundary='boundary',\n        )\n        headers = {\n            **authentication_headers,\n            'Content-Type': multipart_data.content_type\n        }\n        stream_id = self.connection.request(\n            'POST',\n            '/v20160207/events',\n            headers=headers,\n            body=multipart_data,\n        )\n        response = self.connection.get_response(stream_id)\n        return self.parse_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the access token from AVS.", "response": "def retrieve_api_token(self):\n        \"\"\"\n        Retrieve the access token from AVS.\n\n        This function is memoized, so the\n        value returned by the function will be remembered and returned by\n        subsequent calls until the memo expires. This is because the access\n        token lasts for one hour, then a new token needs to be requested.\n\n        Decorators:\n            helpers.expiring_memo\n\n        Returns:\n            str -- The access token for communicating with AVS\n\n        \"\"\"\n\n        payload = self.oauth2_manager.get_access_token_params(\n            refresh_token=self.refresh_token\n        )\n        response = requests.post(\n            self.oauth2_manager.access_token_url, json=payload\n        )\n        response.raise_for_status()\n        response_json = json.loads(response.text)\n        return response_json['access_token']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_permission_full_codename(perm):\n    User = get_user_model()\n    return '%s.%s_%s' % (User._meta.app_label, perm, User._meta.module_name)", "response": "Returns full codename for given permission."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommit the current transaction.", "response": "def commit(using=None):\n    \"\"\"\n    Possibility of calling transaction.commit() in new Django versions (in atomic block).\n    \"\"\"\n    try:\n        django.db.transaction.commit(using)\n    except django.db.transaction.TransactionManagementError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rollback(using=None, sid=None):\n    if sid:\n        django.db.transaction.savepoint_rollback(sid)\n    else:\n        try:\n             django.db.transaction.rollback(using)\n        except django.db.transaction.TransactionManagementError:\n             django.db.transaction.set_rollback(True, using)", "response": "Rollbacks the current transaction."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_template_loaders():\n    try:\n        from django.template.engine import Engine\n    except ImportError:  # Django < 1.8\n        Engine = None\n\n    if Engine:\n        try:\n            engine = Engine.get_default()\n        except ImproperlyConfigured:\n            loaders = []\n        else:\n            loaders = engine.template_loaders\n    else:  # Django < 1.8\n        from django.template.loader import find_template_loader\n        loaders = [\n            find_template_loader(loader_name)\n            for loader_name in settings.TEMPLATE_LOADERS]\n    return loaders", "response": "Returns a list of template loaders that are available for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_url(to, *args, **kwargs):\n    from compat import six, force_text\n\n    # If it's a model, use get_absolute_url()\n    if hasattr(to, 'get_absolute_url'):\n        return to.get_absolute_url()\n\n    if isinstance(to, Promise):\n        # Expand the lazy instance, as it can cause issues when it is passed\n        # further to some Python functions like urlparse.\n        to = force_text(to)\n\n    if isinstance(to, six.string_types):\n        # Handle relative URLs\n        if any(to.startswith(path) for path in ('./', '../')):\n            return to\n\n    # Next try a reverse URL resolution.\n    try:\n        return urlresolvers.reverse(to, args=args, kwargs=kwargs)\n    except urlresolvers.NoReverseMatch:\n        # If this is a callable, re-raise.\n        if callable(to):\n            raise\n        # If this doesn't \"feel\" like a URL, re-raise.\n        if '/' not in to and '.' not in to:\n            raise\n\n    # Finally, fall back and assume it's a URL\n    return to", "response": "Resolve a URL to a view name or URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares a key for use in a cache key.", "response": "def _prepare_key(key, *args, **kwargs):\n    \"\"\"\n    if arguments are given, adds a hash of the args to the key.\n    \"\"\"\n\n    if not args and not kwargs:\n        return key\n\n    items = sorted(kwargs.items())\n    hashable_args = (args, tuple(items))\n    args_key = hashlib.md5(pickle.dumps(hashable_args)).hexdigest()\n\n    return \"%s/args:%s\" % (key, args_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets up dual logging to console and to logfile. When this function is called, it first creates the given directory. It then creates a logfile and passes all log messages to come to it. The logfile name encodes the date and time when it was created, for example \"20181115-153559.txt\". All messages with a log level of at least \"WARNING\" are also forwarded to the console. Args: logdir: path of the directory where to store the log files. Both a relative or an absolute path may be specified. If a relative path is specified, it is interpreted relative to the working directory. If no directory is given, the logs are written to a folder called \"log\" in the working directory.", "response": "def setup(logdir='log'):\n    \"\"\" Set up dual logging to console and to logfile.\n\n    When this function is called, it first creates the given directory. It then \n    creates a logfile and passes all log messages to come to it. The logfile\n    name encodes the date and time when it was created, for example \n    \"20181115-153559.txt\". All messages with a log level of at least \"WARNING\" \n    are also forwarded to the console.\n\n    Args:\n        logdir: path of the directory where to store the log files. Both a\n            relative or an absolute path may be specified. If a relative path is\n            specified, it is interpreted relative to the working directory.\n            If no directory is given, the logs are written to a folder called \n            \"log\" in the working directory. \n    \"\"\"\n\n    # Create the root logger.\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n\n    # Validate the given directory.\n    logdir = os.path.normpath(logdir)\n\n    # Create a folder for the logfiles.\n    if not os.path.exists(logdir):\n        os.makedirs(logdir)\n\n    # Construct the logfile name.\n    t = datetime.datetime.now()\n    logfile = '{year:04d}{mon:02d}{day:02d}-' \\\n        '{hour:02d}{min:02d}{sec:02d}.log'.format(\n            year=t.year, mon=t.month, day=t.day, \n            hour=t.hour, min=t.minute, sec=t.second)\n    logfile = os.path.join(logdir, logfile)\n\n    # Set up logging to the logfile.\n    filehandler = logging.handlers.RotatingFileHandler(\n        filename=logfile,\n        maxBytes=10*1024*1024,\n        backupCount=100)\n    filehandler.setLevel(logging.DEBUG)\n    fileformatter = logging.Formatter(\n        '%(asctime)s %(levelname)-8s: %(message)s')\n    filehandler.setFormatter(fileformatter)\n    logger.addHandler(filehandler)\n    \n    # Set up logging to the console.\n    streamhandler = logging.StreamHandler()\n    streamhandler.setLevel(logging.WARNING)\n    streamformatter = logging.Formatter('%(levelname)s: %(message)s')\n    streamhandler.setFormatter(streamformatter)\n    logger.addHandler(streamhandler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches specific project files and extract versions to check.", "response": "def get_versions() -> FileVersionResult:\n    \"\"\"\n    Search specific project files and extract versions to check.\n\n    :return: A FileVersionResult object for reporting.\n    \"\"\"\n\n    version_counter = Counter()\n    versions_match = False\n    version_str = None\n    versions_discovered = OrderedDict()\n\n    for version_obj in version_objects:\n        discovered = version_obj.get_version()\n        versions_discovered[version_obj.key_name] = discovered\n        version_counter.update([discovered])\n\n    if len(version_counter) == 1:\n        versions_match = True\n        version_str = list(version_counter.keys())[0]\n\n    return FileVersionResult(\n        uniform=versions_match,\n        version_details=versions_discovered,\n        version_result=version_str,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the project s version string without any beta build labels.", "response": "def get_version_without_beta(version_info: FileVersionResult) -> str:\n    \"\"\"\n    Get the project's version string *without* any test or beta build labels.\n\n    :param version_info: The current version_info of the project.\n    :return: The current version string, without any beta build string values.\n    \"\"\"\n\n    if not version_info:\n        raise TypeError(\"version_info cannot be 'None'!\")\n\n    if not version_info.uniform:\n        raise ValueError(\"version_info is not uniform!\")\n\n    beta_flag = \".123.\"\n    current_version = version_info.version_result\n\n    # We can just split and take the first value since:\n    #\n    #  - If the flag *is not there*, we get the entire string back.\n    #\n    #    OR\n    #\n    #  - If the flag *is there*, we want everything before it,\n    #    AKA the first value.\n    #\n    return current_version.split(beta_flag)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the project s version string with a beta build number.", "response": "def get_version_with_beta(version_info: FileVersionResult) -> str:\n    \"\"\"\n    Get the project's version string *with* a beta build label based on UTC.\n\n    :param version_info: The current version_info of the project.\n    :return: The project's version string, with a beta build number.\n    \"\"\"\n\n    if not version_info:\n        raise TypeError(\"version_info cannot be 'None'!\")\n\n    if not version_info.uniform:\n        raise ValueError(\"version_info is not uniform!\")\n\n    # Capture datetime as UTC for build timestamp\n    utc_datetime = datetime.datetime.utcnow()\n\n    # Setup version string information\n    beta_flag = \".123.\"\n    build_number = utc_datetime.strftime(\"%Y%m%d.%H%M%S\")\n    cleaned_version = get_version_without_beta(version_info)\n\n    # Return the new version string for the build.\n    return \"{base}{flag}{build}\".format(\n        base=cleaned_version,\n        flag=beta_flag,\n        build=build_number,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake any number of strings and returns the first one that supports the terminal encoding.", "response": "def supportedChars(*tests):\n    \"\"\"\n        Takes any number of strings, and returns the first one\n            the terminal encoding supports. If none are supported\n            it returns '?' the length of the first string.\n    \"\"\"\n    for test in tests:\n        try:\n            test.encode(sys.stdout.encoding)\n            return test\n        except UnicodeEncodeError:\n            pass\n    return '?' * len(tests[0])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef app_templates_dirs(self):\n        app_templates_dirs = OrderedDict()\n        for app_config in apps.get_app_configs():\n            templates_dir = os.path.join(\n                getattr(app_config, 'path', '/'), 'templates')\n            if os.path.isdir(templates_dir):\n                templates_dir = upath(templates_dir)\n                app_templates_dirs[app_config.name] = templates_dir\n                app_templates_dirs[app_config.label] = templates_dir\n        return app_templates_dirs", "response": "Build a dictionary with the names of each application and the templates directory of each application as keys\n        and the templates directory of each application as values\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to load the origin. and return the contents of the file.", "response": "def get_contents(self, origin):\n        \"\"\"\n        Try to load the origin.\n        \"\"\"\n        try:\n            path = self.get_app_template_path(\n                origin.app_name, origin.template_name)\n            with io.open(path, encoding=self.engine.file_charset) as fp:\n                return fp.read()\n        except KeyError:\n            raise TemplateDoesNotExist(origin)\n        except IOError as error:\n            if error.errno == errno.ENOENT:\n                raise TemplateDoesNotExist(origin)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_template_sources(self, template_name):\n        if ':' not in template_name:\n            self.reset(True)\n            return\n\n        app, template_path = template_name.split(':')\n        if app:\n            yield NamespaceOrigin(\n                app_name=app,\n                name='app_namespace:%s:%s' % (app, template_name),\n                template_name=template_path,\n                loader=self)\n            return\n\n        self.reset(False)\n        for app in self.app_templates_dirs:\n            file_path = self.get_app_template_path(app, template_path)\n            if file_path in self._already_used:\n                continue\n            self._already_used.append(file_path)\n            yield NamespaceOrigin(\n                app_name=app,\n                name='app_namespace:%s:%s' % (app, template_name),\n                template_name=template_path,\n                loader=self)", "response": "Yields a list of Origin objects that are available for the specified template_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_template_source(self, *ka):\n        template_name = ka[0]\n        for origin in self.get_template_sources(template_name):\n            try:\n                return self.get_contents(origin), origin.name\n            except TemplateDoesNotExist:\n                pass\n        raise TemplateDoesNotExist(template_name)", "response": "Load the contents of a template source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef image(self):\n        self._image = self.genImage()\n        self._image = funcs.rotateImage(self._image, self.direction)\n        return self._image", "response": "Generates and rotates the image using self. direction and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrotates a 2d array to a multiple of 90 deg.", "response": "def rotateImage(image, angle):\n    \"\"\"\n        rotates a 2d array to a multiple of 90 deg.\n        0 = default\n        1 = 90 deg. cw\n        2 = 180 deg.\n        3 = 90 deg. ccw\n    \"\"\"\n    image = [list(row) for row in image]\n\n    for n in range(angle % 4):\n        image = list(zip(*image[::-1]))\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move(self, direction=0):\n        direction = int(direction)\n        self.position = list(self.position)\n\n        if direction == 0:\n            self.position[1] += 1\n        elif direction == 1:\n            self.position[0] -= 1\n        elif direction == 2:\n            self.position[1] -= 1\n        elif direction == 3:\n            self.position[0] += 1", "response": "Moves the current object in the specified direction."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef touching(self, canvas, side=None):\n        try:\n            sides = list(side)\n        except TypeError:\n            if side is None:\n                sides = list(range(4))\n            else:\n                sides = [side]\n\n        # Generate rotated images for each direction.\n        images = {}\n        image = self.image.image()\n        for side in sides:\n            images.update({\n                (side + 2) % 4:\n                    funcs.rotateImage(image, (side + 2) % 4)\n            })\n\n        # Go through each image finding top edge,\n        #   then rotate coordinates to match original image.\n        edges = []\n        for side, image in images.items():\n\n            for x in range(len(image[0])):\n                y = 0\n                # If the first pixel is True, no look any further.\n                if not image[0][x]:\n                    while not image[y][x]:\n                        y += 1\n                        if y >= len(image):\n                            # Fallen off bottom of image, therefore no edge.\n                            y = None\n                            break\n\n                # Don't do anything if no pixels in column.\n                if not y is None:\n                    y -= 1  # To get pixel next to pixel which is on.\n\n                    # Get coordinates the right way around.\n                    pos = (x, y)\n                    size = [len(image), len(image[0])]\n                    for i in range(4 - side):\n                        size.reverse()\n                        pos = funcs.rotatePosition(pos, size)\n                    edges.append(pos)\n\n        # Find if any other sprites are in our edge coordinates.\n        for pixel in edges:\n            pixel = (int(self.position[0] + pixel[0]),\n                     int(self.position[1] + pixel[1]))\n            if canvas.testPixel(pixel):\n                return True\n        return False", "response": "Returns True if any pixels are touching the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if sprite is touching any other sprite.", "response": "def overlaps(self, canvas, exclude=[]):\n        \"\"\"\n            Returns True if sprite is touching any other sprite.\n        \"\"\"\n        try:\n            exclude = list(exclude)\n        except TypeError:\n            exclude = [exclude]\n        exclude.append(self)\n\n        for selfY, row in enumerate(self.image.image()):\n            for selfX, pixel in enumerate(row):\n                canvasPixelOn = canvas.testPixel(\n                    (selfX + self.position[0], selfY + self.position[1]),\n                    excludedSprites=exclude\n                )\n                if pixel and canvasPixelOn:\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of the sides of the sprite which are touching the edge of the canvas.", "response": "def onEdge(self, canvas):\n        \"\"\"\n            Returns a list of the sides of the sprite\n                which are touching the edge of the canvas.\n\n            0 = Bottom\n            1 = Left\n            2 = Top\n            3 = Right\n        \"\"\"\n        sides = []\n        if int(self.position[0]) <= 0:\n            sides.append(1)\n\n        if (int(self.position[0]) + self.image.width) >= canvas.width:\n            sides.append(3)\n\n        if int(self.position[1]) <= 0:\n            sides.append(2)\n\n        if (int(self.position[1]) + self.image.height) >= canvas.height:\n            sides.append(0)\n\n        return sides"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sendCommand(self, command):\n        command_data = [ord(x) for x in buffer(command)]\n        self.hid.write(command_data)\n        response_data = ''.join(chr(x) for x in self.hid.read(64))\n        response = command.RESPONSE.from_buffer_copy(response_data)\n        if response.status != 0:\n            raise CommandException(response.status)\n        return response", "response": "Sends a command to the MCP2210 and returns its response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransferring data over the SPI device.", "response": "def transfer(self, data):\n        \"\"\"Transfers data over SPI.\n\n        Arguments:\n            data: The data to transfer.\n\n        Returns:\n            The data returned by the SPI device.\n        \"\"\"\n        settings = self.transfer_settings\n        settings.spi_tx_size = len(data)\n        self.transfer_settings = settings\n\n        response = ''\n        for i in range(0, len(data), 60):\n            response += self.sendCommand(commands.SPITransferCommand(data[i:i + 60])).data\n            time.sleep(0.01)\n\n        while len(response) < len(data):\n            response += self.sendCommand(commands.SPITransferCommand('')).data\n\n        return ''.join(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_json_response(self, context_dict, status=200):\n        json_context = json.dumps(\n            context_dict,\n            cls=DjangoJSONEncoder,\n            **self.get_json_dumps_kwargs()\n        ).encode(u'utf-8')\n        return HttpResponse(\n            json_context,\n            content_type=self.get_content_type(),\n            status=status\n        )", "response": "Render a JSON response for the given context dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef form_valid(self, form):\n        self.object = form.save(commit=False)\n        self.pre_save()\n        self.object.save()\n        if hasattr(form, 'save_m2m'):\n            form.save_m2m()\n        self.post_save()\n\n        if self.request.is_ajax():\n            return self.render_json_response(self.get_success_result())\n        return HttpResponseRedirect(self.get_success_url())", "response": "Save the object and return a json response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore a function s assumptions as an attribute.", "response": "def assumes(*args):\n    '''Stores a function's assumptions as an attribute.'''\n    args = tuple(args)\n\n    def decorator(func):\n        func.assumptions = args\n        return func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef overridden_by_assumptions(*args):\n    '''Stores what assumptions a function is overridden by as an attribute.'''\n    args = tuple(args)\n\n    def decorator(func):\n        func.overridden_by_assumptions = args\n        return func\n    return decorator", "response": "Stores what assumptions a function is overridden by as an attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef equation_docstring(quantity_dict, assumption_dict,\n                       equation=None, references=None, notes=None):\n    '''\nCreates a decorator that adds a docstring to an equation function.\n\nParameters\n----------\n\nquantity_dict : dict\n    A dictionary describing the quantities used in the equations. Its keys\n    should be abbreviations for the quantities, and its values should be a\n    dictionary of the form {'name': string, 'units': string}.\nassumption_dict : dict\n    A dictionary describing the assumptions used by the equations. Its keys\n    should be short forms of the assumptions, and its values should be long\n    forms of the assumptions, as you would insert into the sentence\n    'Calculates (quantity) assuming (assumption 1), (assumption 2), and\n    (assumption 3).'\nequation : string, optional\n    A string describing the equation the function uses. Should be wrapped\n    to be no more than 80 characters in length.\nreferences : string, optional\n    A string providing references for the function. Should be wrapped to be\n    no more than 80 characters in length.\n\nRaises\n------\n\nValueError:\n    If the function name does not follow (varname)_from_(any text here), or\n    if an argument of the function or the varname (as above) is not present\n    in quantity_dict, or if an assumption in func.assumptions is not present\n    in the assumption_dict.\n    '''\n    # Now we have our utility functions, let's define the decorator itself\n    def decorator(func):\n        out_name_end_index = func.__name__.find('_from_')\n        if out_name_end_index == -1:\n            raise ValueError('equation_docstring decorator must be applied to '\n                             'function whose name contains \"_from_\"')\n        out_quantity = func.__name__[:out_name_end_index]\n        in_quantities = inspect.getargspec(func).args\n        docstring = 'Calculates {0}'.format(\n            quantity_string(out_quantity, quantity_dict))\n        try:\n            if len(func.assumptions) > 0:\n                docstring += ' assuming {0}'.format(\n                    assumption_list_string(func.assumptions, assumption_dict))\n        except AttributeError:\n            pass\n        docstring += '.'\n        docstring = doc_paragraph(docstring)\n        docstring += '\\n\\n'\n        if equation is not None:\n            func.equation = equation\n            docstring += doc_paragraph(':math:`' + equation.strip() + '`')\n            docstring += '\\n\\n'\n        docstring += 'Parameters\\n'\n        docstring += '----------\\n\\n'\n        docstring += '\\n'.join([quantity_spec_string(q, quantity_dict)\n                                for q in in_quantities])\n        docstring += '\\n\\n'\n        docstring += 'Returns\\n'\n        docstring += '-------\\n\\n'\n        docstring += quantity_spec_string(out_quantity, quantity_dict)\n        if notes is not None:\n            docstring += '\\n\\n'\n            docstring += 'Notes\\n'\n            docstring += '-----\\n\\n'\n            docstring += notes.strip()\n        if references is not None:\n            if notes is None:  # still need notes header for references\n                docstring += '\\n\\n'\n                docstring += 'Notes\\n'\n                docstring += '-----\\n\\n'\n            func.references = references\n            docstring += '\\n\\n'\n            docstring += '**References**\\n\\n'\n            docstring += references.strip()\n        docstring += '\\n'\n        func.__doc__ = docstring\n        return func\n\n    return decorator", "response": "This function creates a decorator that adds a docstring to an equation function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sma(array, window_size, axis=-1, mode='reflect', **kwargs):\n    kwargs['axis'] = axis\n    kwargs['mode'] = mode\n    if not isinstance(window_size, int):\n        raise TypeError('window_size must be an integer')\n    if not isinstance(kwargs['axis'], int):\n        raise TypeError('axis must be an integer')\n    return convolve1d(array, np.repeat(1.0, window_size)/window_size, **kwargs)", "response": "Compute a 1D simple moving average of a given array along a given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes in an abbreviation for a quantity and a quantity dictionary and returns a more descriptive string of the quantity as name ( units.", "response": "def quantity_string(name, quantity_dict):\n    '''Takes in an abbreviation for a quantity and a quantity dictionary,\n       and returns a more descriptive string of the quantity as \"name (units).\"\n       Raises ValueError if the name is not in quantity_dict\n    '''\n    if name not in quantity_dict.keys():\n        raise ValueError('{0} is not present in quantity_dict'.format(name))\n    return '{0} ({1})'.format(quantity_dict[name]['name'],\n                              quantity_dict[name]['units'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a list of strings presumably containing words and phrases and returns a list of those strings like a cat dogs and pizza and chips and cat and dogs and cat and dogs and cat and dogs and cat and dogs and chips.", "response": "def strings_to_list_string(strings):\n    '''Takes a list of strings presumably containing words and phrases,\n       and returns a \"list\" form of those strings, like:\n\n       >>> strings_to_list_string(('cats', 'dogs'))\n       >>> 'cats and dogs'\n\n       or\n\n       >>> strings_to_list_string(('pizza', 'pop', 'chips'))\n       >>> 'pizza, pop, and chips'\n\n       Raises ValueError if strings is empty.\n    '''\n    if isinstance(strings, six.string_types):\n        raise TypeError('strings must be an iterable of strings, not a string '\n                        'itself')\n    if len(strings) == 0:\n        raise ValueError('strings may not be empty')\n    elif len(strings) == 1:\n        return strings[0]\n    elif len(strings) == 2:\n        return ' and '.join(strings)\n    else:\n        return '{0}, and {1}'.format(', '.join(strings[:-1]),\n                                     strings[-1])"}
