{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_type(value, types, **kwargs):\n    if not is_value_of_any_type(value, types):\n        raise ValidationError(MESSAGES['type']['invalid'].format(\n            repr(value), get_type_for_value(value), types,\n        ))", "response": "Validate that the value is one of the types provided."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_type_validator(type_, **kwargs):\n    if is_non_string_iterable(type_):\n        types = tuple(type_)\n    else:\n        types = (type_,)\n    # support x-nullable since Swagger 2.0 doesn't support null type\n    # (see https://github.com/OAI/OpenAPI-Specification/issues/229)\n    if kwargs.get('x-nullable', False) and NULL not in types:\n        types = types + (NULL,)\n    return functools.partial(validate_type, types=types)", "response": "Generates a callable validator for the given type or iterable of types."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_multiple_of(value, divisor, **kwargs):\n    if not decimal.Decimal(str(value)) % decimal.Decimal(str(divisor)) == 0:\n        raise ValidationError(\n            MESSAGES['multiple_of']['invalid'].format(divisor, value),\n        )", "response": "Validate that a value is divisible by a divisor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_minimum(value, minimum, is_exclusive, **kwargs):\n    if is_exclusive:\n        comparison_text = \"greater than\"\n        compare_fn = operator.gt\n    else:\n        comparison_text = \"greater than or equal to\"\n        compare_fn = operator.ge\n\n    if not compare_fn(value, minimum):\n        raise ValidationError(\n            MESSAGES['minimum']['invalid'].format(value, comparison_text, minimum),\n        )", "response": "Validator function for validating that a value violates the minimum allowed value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a function that returns a callable for minimum value validation.", "response": "def generate_minimum_validator(minimum, exclusiveMinimum=False, **kwargs):\n    \"\"\"\n    Generator function returning a callable for minimum value validation.\n    \"\"\"\n    return functools.partial(validate_minimum, minimum=minimum, is_exclusive=exclusiveMinimum)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_maximum_validator(maximum, exclusiveMaximum=False, **kwargs):\n    return functools.partial(validate_maximum, maximum=maximum, is_exclusive=exclusiveMaximum)", "response": "Generates a function that returns a callable for maximum value validation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_min_items(value, minimum, **kwargs):\n    if len(value) < minimum:\n        raise ValidationError(\n            MESSAGES['min_items']['invalid'].format(\n                minimum, len(value),\n            ),\n        )", "response": "Validator for ARRAY types to enforce a minimum number of items allowed for the ARRAY."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_unique_items(value, **kwargs):\n    # we can't just look at the items themselves since 0 and False are treated\n    # the same as dictionary keys, and objects aren't hashable.\n\n    counter = collections.Counter((\n        json.dumps(v, sort_keys=True) for v in value\n    ))\n    dupes = [json.loads(v) for v, count in counter.items() if count > 1]\n    if dupes:\n        raise ValidationError(\n            MESSAGES['unique_items']['invalid'].format(\n                repr(dupes),\n            ),\n        )", "response": "Validator for ARRAY types to enforce that all array items must be unique."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_object(obj, field_validators=None, non_field_validators=None,\n                    schema=None, context=None):\n    \"\"\"\n    Takes a mapping and applies a mapping of validator functions to it\n    collecting and reraising any validation errors that occur.\n    \"\"\"\n    if schema is None:\n        schema = {}\n    if context is None:\n        context = {}\n    if field_validators is None:\n        field_validators = ValidationDict()\n    if non_field_validators is None:\n        non_field_validators = ValidationList()\n\n    from flex.validation.schema import (\n        construct_schema_validators,\n    )\n    schema_validators = construct_schema_validators(schema, context)\n    if '$ref' in schema_validators and hasattr(schema_validators['$ref'], 'validators'):\n        ref_ = field_validators.pop('$ref')\n        for k, v in ref_.validators.items():\n            if k not in schema_validators:\n                schema_validators.add_validator(k, v)\n\n    if 'discriminator' in schema:\n        schema_validators = add_polymorphism_requirements(obj, schema, context, schema_validators)\n        # delete resolved discriminator to avoid infinite recursion\n        del schema['discriminator']\n\n    schema_validators.update(field_validators)\n    schema_validators.validate_object(obj, context=context)\n    non_field_validators.validate_object(obj, context=context)\n    return obj", "response": "Takes a mapping and applies a mapping of validator functions to it\n    collecting and reraising any validation errors that occur."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a callable that will take the string value of a header and cast it to the appropriate type.", "response": "def generate_value_processor(type_, collectionFormat=None, items=None, **kwargs):\n    \"\"\"\n    Create a callable that will take the string value of a header and cast it\n    to the appropriate type.  This can involve:\n\n    - splitting a header of type 'array' by its delimeters.\n    - type casting the internal elements of the array.\n    \"\"\"\n    processors = []\n    if is_non_string_iterable(type_):\n        assert False, \"This should not be possible\"\n    else:\n        if type_ == ARRAY and collectionFormat:\n            if collectionFormat in DELIMETERS:\n                delimeter = DELIMETERS[collectionFormat]\n                # split the string based on the delimeter specified by the\n                # `collectionFormat`\n                processors.append(operator.methodcaller('split', delimeter))\n            else:\n                if collectionFormat != MULTI:\n                    raise TypeError(\"collectionFormat not implemented\")\n                processors.append(add_string_into_list)\n            # remove any Falsy values like empty strings.\n            processors.append(functools.partial(filter, bool))\n            # strip off any whitespace\n            processors.append(functools.partial(map, operator.methodcaller('strip')))\n            if items is not None:\n                if isinstance(items, collections.Mapping):\n                    items_processors = itertools.repeat(\n                        generate_value_processor(**items)\n                    )\n                elif isinstance(items, collections.Sequence):\n                    items_processors = itertools.chain(\n                        (generate_value_processor(**item) for item in items),\n                        itertools.repeat(lambda v: v),\n                    )\n                elif isinstance(items, six.string_types):\n                    raise NotImplementedError(\"Not implemented\")\n                else:\n                    assert False, \"Should not be possible\"\n                # 1. zip the processor and the array items together\n                # 2. apply the processor to each array item.\n                # 3. cast the starmap generator to a list.\n                processors.append(\n                    chain_reduce_partial(\n                        functools.partial(zip, items_processors),\n                        functools.partial(itertools.starmap, lambda fn, v: fn(v)),\n                        list,\n                    )\n                )\n        else:\n            processors.append(\n                functools.partial(cast_value_to_type, type_=type_)\n            )\n\n    def processor(value, **kwargs):\n        try:\n            return chain_reduce_partial(*processors)(value)\n        except (ValueError, TypeError):\n            return value\n\n    return processor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_request_method_to_operation(request_method, path_definition):\n    try:\n        operation_definition = path_definition[request_method]\n    except KeyError:\n        allowed_methods = set(REQUEST_METHODS).intersection(path_definition.keys())\n        raise ValidationError(\n            MESSAGES['request']['invalid_method'].format(\n                request_method, allowed_methods,\n            ),\n        )\n    return operation_definition", "response": "Validate that the request method is valid for the base resource path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a path find the api_path it matches.", "response": "def validate_path_to_api_path(path, paths, basePath='', context=None, **kwargs):\n    \"\"\"\n    Given a path, find the api_path it matches.\n    \"\"\"\n    if context is None:\n        context = {}\n    try:\n        api_path = match_path_to_api_path(\n            path_definitions=paths,\n            target_path=path,\n            base_path=basePath,\n            context=context,\n        )\n    except LookupError as err:\n        raise ValidationError(str(err))\n    except MultiplePathsFound as err:\n        raise ValidationError(str(err))\n\n    return api_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_path_parameters(target_path, api_path, path_parameters, context):\n    base_path = context.get('basePath', '')\n    full_api_path = re.sub(NORMALIZE_SLASH_REGEX, '/', base_path + api_path)\n    parameter_values = get_path_parameter_values(\n        target_path, full_api_path, path_parameters, context,\n    )\n    validate_parameters(parameter_values, path_parameters, context=context)", "response": "Validate a request path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct_parameter_validators(parameter, context):\n    validators = ValidationDict()\n    if '$ref' in parameter:\n        validators.add_validator(\n            '$ref', ParameterReferenceValidator(parameter['$ref'], context),\n        )\n    for key in parameter:\n        if key in validator_mapping:\n            validators.add_validator(\n                key,\n                validator_mapping[key](context=context, **parameter),\n            )\n    if 'schema' in parameter:\n        schema_validators = construct_schema_validators(parameter['schema'], context=context)\n        for key, value in schema_validators.items():\n            validators.setdefault(key, value)\n    return validators", "response": "Constructs a dictionary of validator functions for the provided parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an iterable of parameters returns a dictionary of validator functions for each parameter.", "response": "def construct_multi_parameter_validators(parameters, context):\n    \"\"\"\n    Given an iterable of parameters, returns a dictionary of validator\n    functions for each parameter.  Note that this expects the parameters to be\n    unique in their name value, and throws an error if this is not the case.\n    \"\"\"\n    validators = ValidationDict()\n    for parameter in parameters:\n        key = parameter['name']\n        if key in validators:\n            raise ValueError(\"Duplicate parameter name {0}\".format(key))\n        parameter_validators = construct_parameter_validators(parameter, context=context)\n        validators.add_validator(\n            key,\n            generate_object_validator(field_validators=parameter_validators),\n        )\n\n    return validators"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_path_parameters_validator(api_path, path_parameters, context):\n    path_parameter_validator = functools.partial(\n        validate_path_parameters,\n        api_path=api_path,\n        path_parameters=path_parameters,\n        context=context,\n    )\n    return path_parameter_validator", "response": "Generates a validator function that given a path validates that it against the path parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns the non prametrized path components into strings subtable for using as a regex pattern.", "response": "def escape_regex_special_chars(api_path):\n    \"\"\"\n    Turns the non prametrized path components into strings subtable for using\n    as a regex pattern.  This primarily involves escaping special characters so\n    that the actual character is matched in the regex.\n    \"\"\"\n    def substitute(string, replacements):\n        pattern, repl = replacements\n        return re.sub(pattern, repl, string)\n\n    return functools.reduce(substitute, REGEX_REPLACEMENTS, api_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs a regex pattern that will match the path of a parameter.", "response": "def construct_parameter_pattern(parameter):\n    \"\"\"\n    Given a parameter definition returns a regex pattern that will match that\n    part of the path.\n    \"\"\"\n    name = parameter['name']\n    type = parameter['type']\n\n    repeated = '[^/]'\n\n    if type == 'integer':\n        repeated = '\\d'\n\n    return \"(?P<{name}>{repeated}+)\".format(name=name, repeated=repeated)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_path_part(part, parameters):\n    if PARAMETER_REGEX.match(part):\n        parameter_name = part.strip('{}')\n        try:\n            parameter = find_parameter(\n                parameters,\n                name=parameter_name,\n                in_=PATH\n            )\n        except ValueError:\n            pass\n        else:\n            return construct_parameter_pattern(parameter)\n    return escape_regex_special_chars(part)", "response": "Process a path part into a regex group"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef path_to_pattern(api_path, parameters):\n    parts = re.split(PARAMETER_REGEX, api_path)\n    pattern = ''.join((process_path_part(part, parameters) for part in parts))\n\n    if not pattern.startswith('^'):\n        pattern = \"^{0}\".format(pattern)\n    if not pattern.endswith('$'):\n        pattern = \"{0}$\".format(pattern)\n\n    return pattern", "response": "Given an api path and a list of parameters return a regular expression that can be used to match the request path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match_path_to_api_path(path_definitions, target_path, base_path='',\n                           context=None):\n    \"\"\"\n    Match a request or response path to one of the api paths.\n\n    Anything other than exactly one match is an error condition.\n    \"\"\"\n    if context is None:\n        context = {}\n    assert isinstance(context, collections.Mapping)\n    if target_path.startswith(base_path):\n        # Convert all of the api paths into Path instances for easier regex\n        # matching.\n        normalized_target_path = re.sub(NORMALIZE_SLASH_REGEX, '/',\n                                        target_path)\n        matching_api_paths = list()\n        matching_api_paths_regex = list()\n        for p, v in path_definitions.items():\n            # Doing this to help with case where we might have base_path\n            # being just /, and then the path starts with / as well.\n            full_path = re.sub(NORMALIZE_SLASH_REGEX, '/', base_path + p)\n            r = path_to_regex(\n                api_path=full_path,\n                path_parameters=extract_path_parameters(v),\n                operation_parameters=extract_operation_parameters(v),\n                context=context,\n            )\n            if full_path == normalized_target_path:\n                matching_api_paths.append(p)\n            elif r.match(normalized_target_path):\n                matching_api_paths_regex.\\\n                    append((p, r.match(normalized_target_path)))\n\n        # Keep it consistent with the previous behavior\n        target_path = target_path[len(base_path):]\n    else:\n        matching_api_paths = []\n        matching_api_paths_regex = []\n\n    if not matching_api_paths and not matching_api_paths_regex:\n        fstr = MESSAGES['path']['no_matching_paths_found'].format(target_path)\n        raise LookupError(fstr)\n    elif len(matching_api_paths) == 1:\n        return matching_api_paths[0]\n    elif len(matching_api_paths) > 1:\n        raise MultiplePathsFound(\n            MESSAGES['path']['multiple_paths_found'].format(\n                target_path, [v[0] for v in matching_api_paths],\n            )\n        )\n    elif len(matching_api_paths_regex) == 1:\n        return matching_api_paths_regex[0][0]\n    elif len(matching_api_paths_regex) > 1:\n        # TODO: This area needs improved logic.\n        # We check to see if any of the matched paths is longers than\n        # the others.  If so, we *assume* it is the correct match.  This is\n        # going to be prone to false positives. in certain cases.\n        matches_by_path_size = collections.defaultdict(list)\n        for path, match in matching_api_paths_regex:\n            matches_by_path_size[len(path)].append(path)\n        longest_match = max(matches_by_path_size.keys())\n        if len(matches_by_path_size[longest_match]) == 1:\n            return matches_by_path_size[longest_match][0]\n        raise MultiplePathsFound(\n            MESSAGES['path']['multiple_paths_found'].format(\n                target_path, [v[0] for v in matching_api_paths_regex],\n            )\n        )\n    else:\n        return matching_api_paths_regex[0][0]", "response": "Match a request or response path to one of the api paths."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the request against the schema.", "response": "def validate_request(request, schema):\n    \"\"\"\n    Request validation does the following steps.\n\n       1. validate that the path matches one of the defined paths in the schema.\n       2. validate that the request method conforms to a supported methods for the given path.\n       3. validate that the request parameters conform to the parameter\n          definitions for the operation definition.\n    \"\"\"\n    with ErrorDict() as errors:\n        # 1\n        try:\n            api_path = validate_path_to_api_path(\n                path=request.path,\n                context=schema,\n                **schema\n            )\n        except ValidationError as err:\n            errors['path'].add_error(err.detail)\n            return  # this causes an exception to be raised since errors is no longer falsy.\n\n        path_definition = schema['paths'][api_path] or {}\n\n        if not path_definition:\n            # TODO: is it valid to not have a definition for a path?\n            return\n\n        # 2\n        try:\n            operation_definition = validate_request_method_to_operation(\n                request_method=request.method,\n                path_definition=path_definition,\n            )\n        except ValidationError as err:\n            errors['method'].add_error(err.detail)\n            return\n\n        if operation_definition is None:\n            # TODO: is this compliant with swagger, can path operations have a null\n            # definition?\n            return\n\n        # 3\n        operation_validators = construct_operation_validators(\n            api_path=api_path,\n            path_definition=path_definition,\n            operation_definition=operation_definition,\n            context=schema,\n        )\n        try:\n            validate_operation(request, operation_validators, context=schema)\n        except ValidationError as err:\n            errors['method'].add_error(err.detail)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize_request(request):\n    if isinstance(request, Request):\n        return request\n\n    for normalizer in REQUEST_NORMALIZERS:\n        try:\n            return normalizer(request)\n        except TypeError:\n            continue\n\n    raise ValueError(\"Unable to normalize the provided request\")", "response": "Given a request normalize it to the internal Request class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_response(response, request=None):\n    if isinstance(response, Response):\n        return response\n    if request is not None and not isinstance(request, Request):\n        request = normalize_request(request)\n\n    for normalizer in RESPONSE_NORMALIZERS:\n        try:\n            return normalizer(response, request=request)\n        except TypeError:\n            continue\n\n    raise ValueError(\"Unable to normalize the provided response\")", "response": "Given a response normalize it to the internal Response class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the data of the object.", "response": "def data(self):\n        \"\"\"\n        TODO: What is the right way to do this?\n        \"\"\"\n        if not self.body:\n            return self.body\n        elif self.body is EMPTY:\n            return EMPTY\n        elif self.content_type and self.content_type.startswith('application/json'):\n            try:\n                if isinstance(self.body, six.binary_type):\n                    return json.loads(self.body.decode('utf-8'))\n                else:\n                    return json.loads(self.body)\n            except ValueError as e:\n                if isinstance(e, JSONDecodeError):\n                    # this will only be True for Python3+\n                    raise e\n                raise JSONDecodeError(str(e))\n        elif self.content_type == 'application/x-www-form-urlencoded':\n            return dict(urlparse.parse_qsl(self.body))\n        else:\n            raise NotImplementedError(\"No parser for content type\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_error(self, error):\n        if is_non_string_iterable(error) and not isinstance(error, collections.Mapping):\n            for value in error:\n                self.add_error(value)\n        else:\n            self.append(error)", "response": "Adds an error to the internal list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deep_equal(a, b):\n    if is_any_string_type(a) and is_any_string_type(b):\n        if isinstance(a, six.binary_type):\n            a = six.text_type(a, encoding='utf-8')\n        if isinstance(b, six.binary_type):\n            b = six.text_type(b, encoding='utf-8')\n        return a == b\n    return a == b and isinstance(a, type(b)) and isinstance(b, type(a))", "response": "A simple comparison of two objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the errors in a tree structure.", "response": "def format_errors(errors, indent=0, prefix='', suffix=''):\n    \"\"\"\n    string: \"example\"\n\n        \"example\"\n\n    dict:\n        \"example\":\n            -\n\n    \"\"\"\n    if is_single_item_iterable(errors):\n        errors = errors[0]\n    if isinstance(errors, SINGULAR_TYPES):\n        yield indent_message(repr(errors), indent, prefix=prefix, suffix=suffix)\n\n    elif isinstance(errors, collections.Mapping):\n        for key, value in errors.items():\n            assert isinstance(key, SINGULAR_TYPES), type(key)\n            if isinstance(value, SINGULAR_TYPES):\n                message = \"{0}: {1}\".format(repr(key), repr(value))\n                yield indent_message(message, indent, prefix=prefix, suffix=suffix)\n            else:\n                yield indent_message(repr(key), indent, prefix=prefix, suffix=':')\n                for message in format_errors(value, indent + 4, prefix='- '):\n                    yield message\n\n    elif is_non_string_iterable(errors):\n        # for making the rhs of the numbers line up\n        extra_indent = int(math.ceil(math.log10(len(errors)))) + 2\n        for index, value in enumerate(errors):\n            list_prefix = \"{0}. \".format(index)\n            messages = format_errors(\n                value,\n                indent=indent + extra_indent - len(list_prefix),\n                prefix=list_prefix,\n            )\n            for message in messages:\n                yield message\n    else:\n        assert False, \"should not be possible\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_header_validator(headers, context, **kwargs):\n    validators = ValidationDict()\n    for header_definition in headers:\n        header_processor = generate_value_processor(\n            context=context,\n            **header_definition\n        )\n        header_validator = generate_object_validator(\n            field_validators=construct_header_validators(header_definition, context=context),\n        )\n        validators.add_property_validator(\n            header_definition['name'],\n            chain_reduce_partial(\n                header_processor,\n                header_validator,\n            ),\n        )\n    return generate_object_validator(field_validators=validators)", "response": "Generates a validation function that will validate a dictionary of headers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a validator function to validate the parameters of the current resource.", "response": "def generate_parameters_validator(api_path, path_definition, parameters,\n                                  context, **kwargs):\n    \"\"\"\n    Generates a validator function to validate.\n\n    - request.path against the path parameters.\n    - request.query against the query parameters.\n    - request.headers against the header parameters.\n    - TODO: request.body against the body parameters.\n    - TODO: request.formData against any form data.\n    \"\"\"\n    # TODO: figure out how to merge this with the same code in response\n    # validation.\n    validators = ValidationDict()\n    path_level_parameters = dereference_parameter_list(\n        path_definition.get('parameters', []),\n        context,\n    )\n    operation_level_parameters = dereference_parameter_list(\n        parameters,\n        context,\n    )\n\n    all_parameters = merge_parameter_lists(\n        path_level_parameters,\n        operation_level_parameters,\n    )\n\n    # PATH\n    in_path_parameters = filter_parameters(all_parameters, in_=PATH)\n    validators.add_validator(\n        'path',\n        chain_reduce_partial(\n            attrgetter('path'),\n            generate_path_parameters_validator(api_path, in_path_parameters, context),\n        ),\n    )\n\n    # QUERY\n    in_query_parameters = filter_parameters(all_parameters, in_=QUERY)\n    validators.add_validator(\n        'query',\n        chain_reduce_partial(\n            attrgetter('query_data'),\n            functools.partial(\n                validate_query_parameters,\n                query_parameters=in_query_parameters,\n                context=context,\n            ),\n        ),\n    )\n\n    # HEADERS\n    in_header_parameters = filter_parameters(all_parameters, in_=HEADER)\n    validators.add_validator(\n        'headers',\n        chain_reduce_partial(\n            attrgetter('headers'),\n            generate_header_validator(in_header_parameters, context),\n        ),\n    )\n\n    # FORM_DATA\n    # in_form_data_parameters = filter_parameters(all_parameters, in_=FORM_DATA)\n    # validators.add_validator(\n    #     'form_data',\n    #     chain_reduce_partial(\n    #         attrgetter('data'),\n    #         generate_form_data_validator(in_form_data_parameters, context),\n    #     )\n    # )\n\n    # REQUEST_BODY\n    in_request_body_parameters = filter_parameters(all_parameters, in_=BODY)\n    validators.add_validator(\n        'request_body',\n        chain_reduce_partial(\n            attrgetter('data'),\n            generate_request_body_validator(in_request_body_parameters, context),\n        )\n    )\n\n    return generate_object_validator(field_validators=validators)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct the list of validators that can be used to validate the request.", "response": "def construct_operation_validators(api_path, path_definition, operation_definition, context):\n    \"\"\"\n    - consumes (did the request conform to the content types this api consumes)\n    - produces (did the response conform to the content types this endpoint produces)\n    - parameters (did the parameters of this request validate)\n      TODO: move path parameter validation to here, because each operation\n            can override any of the path level parameters.\n    - schemes (was the request scheme correct)\n    - security: TODO since security isn't yet implemented.\n    \"\"\"\n    validators = {}\n\n    # sanity check\n    assert 'context' not in operation_definition\n    assert 'api_path' not in operation_definition\n    assert 'path_definition' not in operation_definition\n\n    for key in operation_definition.keys():\n        if key not in validator_mapping:\n            # TODO: is this the right thing to do?\n            continue\n        validators[key] = validator_mapping[key](\n            context=context,\n            api_path=api_path,\n            path_definition=path_definition,\n            **operation_definition\n        )\n\n    # Global defaults\n    if 'consumes' in context and 'consumes' not in validators:\n        validators['consumes'] = validator_mapping['consumes'](**context)\n    if 'parameters' in path_definition and 'parameters' not in validators:\n        validators['parameters'] = validator_mapping['parameters'](\n            context=context,\n            api_path=api_path,\n            path_definition=path_definition,\n            parameters=path_definition['parameters'],\n            **operation_definition\n        )\n\n    return validators"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef partial_safe_wraps(wrapped_func, *args, **kwargs):\n    if isinstance(wrapped_func, functools.partial):\n        return partial_safe_wraps(wrapped_func.func)\n    else:\n        return functools.wraps(wrapped_func)", "response": "A version of functools. wraps that is safe to wrap a partial in.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef skip_if_empty(func):\n    @partial_safe_wraps(func)\n    def inner(value, *args, **kwargs):\n        if value is EMPTY:\n            return\n        else:\n            return func(value, *args, **kwargs)\n    return inner", "response": "Decorator for validation functions which makes them pass if the value passed in is the EMPTY sentinal value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rewrite_reserved_words(func):\n    @partial_safe_wraps(func)\n    def inner(*args, **kwargs):\n        for word in RESERVED_WORDS:\n            key = \"{0}_\".format(word)\n            if key in kwargs:\n                kwargs[word] = kwargs.pop(key)\n        return func(*args, **kwargs)\n    return inner", "response": "A decorator that rewrites the keyword arguments of a function to use the reserved word."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef any_validator(obj, validators, **kwargs):\n    if not len(validators) > 1:\n        raise ValueError(\n            \"any_validator requires at least 2 validator.  Only got \"\n            \"{0}\".format(len(validators))\n        )\n    errors = ErrorDict()\n    for key, validator in validators.items():\n        try:\n            validator(obj, **kwargs)\n        except ValidationError as err:\n            errors[key] = err.detail\n        else:\n            break\n    else:\n        if len(errors) == 1:\n            # Special case for a single error.  Just raise it as if it was the\n            # only validator run.\n            error = errors.values()[0]\n            raise ValidationError(error)\n        else:\n            # Raise all of the errors with the key namespaces.\n            errors.raise_()", "response": "Attempts multiple validators on an object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _extract_to_tempdir(archive_filename):\n    if not os.path.exists(archive_filename):\n        raise Exception(\"Archive '%s' does not exist\" % (archive_filename))\n\n    tempdir = tempfile.mkdtemp(prefix=\"metaextract_\")\n    current_cwd = os.getcwd()\n    try:\n        if tarfile.is_tarfile(archive_filename):\n            with tarfile.open(archive_filename) as f:\n                f.extractall(tempdir)\n        elif zipfile.is_zipfile(archive_filename):\n            with zipfile.ZipFile(archive_filename) as f:\n                f.extractall(tempdir)\n        else:\n            raise Exception(\"Can not extract '%s'. \"\n                            \"Not a tar or zip file\" % archive_filename)\n        os.chdir(tempdir)\n        yield tempdir\n    finally:\n        os.chdir(current_cwd)\n        shutil.rmtree(tempdir)", "response": "extract the given tarball or zipfile to a tempdir and change the cwd to the new tempdir at the end"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nentering a single subdirectory of the given directory", "response": "def _enter_single_subdir(root_dir):\n    \"\"\"if the given directory has just a single subdir, enter that\"\"\"\n    current_cwd = os.getcwd()\n    try:\n        dest_dir = root_dir\n        dir_list = os.listdir(root_dir)\n        if len(dir_list) == 1:\n            first = os.path.join(root_dir, dir_list[0])\n            if os.path.isdir(first):\n                dest_dir = first\n        else:\n            dest_dir = root_dir\n        os.chdir(dest_dir)\n        yield dest_dir\n    finally:\n        os.chdir(current_cwd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a encoding header as suggested in PEP - 0263", "response": "def _set_file_encoding_utf8(filename):\n    \"\"\"set a encoding header as suggested in PEP-0263. This\n    is not entirely correct because we don't know the encoding of the\n    given file but it's at least a chance to get metadata from the setup.py\"\"\"\n    with open(filename, 'r+') as f:\n        content = f.read()\n        f.seek(0, 0)\n        f.write(\"# -*- coding: utf-8 -*-\\n\" + content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the extractmeta command via the setup. py in the given root_dir and return the json file", "response": "def _setup_py_run_from_dir(root_dir, py_interpreter):\n    \"\"\"run the extractmeta command via the setup.py in the given root_dir.\n    the output of extractmeta is json and is stored in a tempfile\n    which is then read in and returned as data\"\"\"\n    data = {}\n    with _enter_single_subdir(root_dir) as single_subdir:\n        if not os.path.exists(\"setup.py\"):\n            raise Exception(\"'setup.py' does not exist in '%s'\" % (\n                single_subdir))\n        # generate a temporary json file which contains the metadata\n        output_json = tempfile.NamedTemporaryFile()\n        cmd = \"%s setup.py -q --command-packages metaextract \" \\\n              \"metaextract -o %s \" % (py_interpreter, output_json.name)\n        try:\n            subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True)\n        except subprocess.CalledProcessError:\n            # try again with a encoding in setup.py\n            _set_file_encoding_utf8(\"setup.py\")\n            subprocess.check_output(cmd, shell=True)\n\n        # read json file and return data\n        with open(output_json.name, \"r\") as f:\n            data = json.loads(f.read())\n\n        # sort some of the keys if the dict values are lists\n        for key in ['data_files', 'entry_points', 'extras_require',\n                    'install_requires', 'setup_requires', 'scripts',\n                    'tests_require', 'tests_suite']:\n            if key in data['data'] and isinstance(data['data'][key], list):\n                data['data'][key] = sorted(data['data'][key])\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting metadata from a given sdist archive file", "response": "def from_archive(archive_filename, py_interpreter=sys.executable):\n    \"\"\"extract metadata from a given sdist archive file\n\n    :param archive_filename: a sdist archive file\n    :param py_interpreter: The full path to the used python interpreter\n\n    :returns: a json blob with metadata\n\"\"\"\n    with _extract_to_tempdir(archive_filename) as root_dir:\n        data = _setup_py_run_from_dir(root_dir, py_interpreter)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a CIM - style XML file into a dictionary of UUIDs and CIM objects.", "response": "def cimread(source, packageMap=None, nsURI=None, start_dict=None):\n    \"\"\" CIM RDF/XML parser.\n\n    @type source: File-like object or a path to a file.\n    @param source: CIM RDF/XML file.\n    @type profile: dict\n    @param packageMap: Map of class name to PyCIM package name. All CIM\n    classes are under the one namespace, but are arranged into sub-packages\n    so a map from class name to package name is required. Defaults to the\n    latest CIM version, but may be set to a map from a profile to return\n    a profile model.\n    @type profile: string\n    @param nsURI: CIM namespace URI used in the RDF/XML file. For example:\n    http://iec.ch/TC57/2010/CIM-schema-cim15\n    @rtype: dict\n    @return: Map of UUID to CIM object.\n\n    @author: Richard Lincoln <r.w.lincoln@gmail.com>\n    \"\"\"\n    # Start the clock.\n    t0 = time()\n\n    #logger.info('##########################################################################')\n    logger.info('START of parsing file \\\"%s\\\"', source)\n    logger_errors_grouped = {}\n\n    # A map of uuids to CIM objects to be returned.\n    d = start_dict if start_dict is not None else {}\n\n    # Obtain the namespaces from the input file\n    namespaces = xmlns(source)\n    ns_rdf = get_rdf_ns(namespaces)\n    if bool(nsURI) != bool(packageMap):\n        raise ValueError(\n                'Either pass \"packageMap\" AND \"nsURI\" or none of them.')\n    elif (nsURI is None) and (packageMap is None):\n        nsURI, packageMap = get_cim_ns(namespaces)\n\n    # CIM element tag base (e.g. {http://iec.ch/TC57/2009/CIM-schema-cim14#}).\n    base = \"{%s#}\" % nsURI\n    # Length of element tag base.\n    m = len(base)\n\n    # First pass instantiates the classes.\n    context = iterparse(source, (\"start\", \"end\"))\n\n    # Turn it into an iterator (required for cElementTree).\n    context = iter(context)\n\n    # Get the root element ({http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF).\n    _, root = next(context)\n\n    for event, elem in context:\n        # Process 'end' elements in the CIM namespace.\n        if event == \"end\" and elem.tag[:m] == base:\n\n            # Unique resource identifier for the CIM object.\n            uuid = elem.get(\"{%s}ID\" % ns_rdf)\n            if uuid is not None: # class\n                # Element tag without namespace (e.g. VoltageLevel).\n                tag = elem.tag[m:]\n                try:\n                    mname = packageMap[tag]\n                except KeyError:\n                    logger.error(\"Unable to locate module for: %s (%s)\",\n                                 tag, uuid)\n                    root.clear()\n                    continue\n                # Import the module for the CIM object.\n                module = __import__(mname, globals(), locals(), [tag], 0)\n                # Get the CIM class from the module.\n                klass = getattr(module, tag)\n\n                # Instantiate the class and map it to the uuid.\n                d[uuid] = klass(UUID=uuid)\n\n        # Clear children of the root element to minimise memory usage.\n        root.clear()\n\n    # Reset stream\n    if hasattr(source, \"seek\"):\n        source.seek(0)\n\n    ## Second pass sets attributes and references.\n    context = iter( iterparse(source, (\"start\", \"end\")) )\n\n    # Get the root element ({http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF).\n    _, root = next(context)\n\n    for event, elem in context:\n        # Process 'start' elements in the CIM namespace.\n        if event == \"start\" and elem.tag[:m] == base:\n            uuid = elem.get(\"{%s}ID\" % ns_rdf)\n            if uuid is None:\n                uuid = elem.get(\"{%s}about\" % ns_rdf)\n                if uuid is not None:\n                    uuid = uuid[1:]\n            if uuid is not None:\n                # Locate the CIM object using the uuid.\n                try:\n                    obj = d[uuid]\n                except KeyError:\n                    logger.error(\"Missing '%s' object with uuid: %s\",\n                                 elem.tag[m:], uuid)\n                    root.clear()\n                    continue\n\n                # Iterate over attributes/references.\n                for event, elem in context:\n                    # Process end events with elements in the CIM namespace.\n                    if event == \"end\" and elem.tag[:m] == base:\n                        # Break if class closing element (e.g. </cim:Terminal>).\n                        if elem.get(\"{%s}ID\" % ns_rdf) is None and \\\n                                elem.get(\"{%s}about\" % ns_rdf) is None:\n                            # Get the attribute/reference name.\n                            attr = elem.tag[m:].rsplit(\".\")[-1]\n\n                            if not hasattr(obj, attr):\n                                error_msg = \"'%s' has not attribute '%s'\" %(obj.__class__.__name__, attr)\n                                try:\n                                    logger_errors_grouped[error_msg] += 1\n                                except KeyError:\n                                    logger_errors_grouped[error_msg] = 1\n                                # logger.error(\"'%s' has not attribute '%s'\",\n                                #              obj.__class__.__name__, attr)\n                                continue\n\n                            # Use the rdf:resource attribute to distinguish\n                            # between attributes and references/enums.\n                            uuid2 = elem.get(\"{%s}resource\" % ns_rdf)\n\n                            if uuid2 is None: # attribute\n                                # Convert value type using the default value.\n                                try:\n                                    typ = type( getattr(obj, attr) )\n                                    if typ == type(True): # KKG: Test if it is boolean value\n                                        # KKG: NB: The function bool(\"false\") returns True, because it is called upon non-empty string!\n                                        # This means that it wrongly reads \"false\" value as boolean True and this is why this special case testing is necessary\n                                        if str.title(elem.text) == 'True':\n                                            setattr(obj, attr, True)\n                                        else:\n                                            setattr(obj, attr, False)\n                                    else:\n                                        setattr(obj, attr, typ(elem.text))\n                                except TypeError:\n                                    pass\n                            else:  # reference or enum\n                                # Use the '#' prefix to distinguish between\n                                # references and enumerations.\n                                if uuid2[0] == \"#\": # reference\n                                    try:\n                                        val = d[uuid2[1:]] # remove '#' prefix\n                                    except KeyError:\n                                        logger.error(\"Referenced '%s' [%s] \"\n                                                     \"object missing.\",\n                                                     obj.__class__.__name__,\n                                                     uuid2[1:])\n                                        continue\n\n                                    default = getattr(obj, attr)\n                                    if default == None: # 1..1 or 1..n\n                                        # Rely on properties to set any\n                                        # bi-directional references.\n                                        setattr(obj, attr, val)\n                                    elif isinstance(default, list): # many\n                                        # Use 'add*' method to set reference.\n                                        getattr(obj, (\"add%s\" % attr))(val)\n#                                    else:\n#                                        logger.error(\"Reference error [%s].\",\n#                                                     default)\n\n                                else: # enum\n                                    val = uuid2.rsplit(\".\", 1)[1]\n                                    setattr(obj, attr, val)\n\n                        else:\n                            # Finished setting object attributes.\n                            break\n\n        # Clear children of the root element to minimise memory usage.\n        root.clear()\n\n    if logger_errors_grouped:\n        for error, count in logger_errors_grouped.items():\n            logging_message = '%s : %d times' %(error, count)\n            logger.warn(logging_message)\n\n    # logging_message = 'Created totally %d CIM objects in %.2fs.' %(len(d), time() - t0)\n    logger.info('Created totally %d CIM objects in %.2fs.' %(len(d), time() - t0))\n    # logging_message = 'END of parsing file \\\"%s\\\"\\n' % source\n    logger.info('END of parsing file \\\"%s\\\"\\n' % source)\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a map of prefix to namespace for the given XML file.", "response": "def xmlns(source):\n    \"\"\"\n    Returns a map of prefix to namespace for the given XML file.\n\n    \"\"\"\n    namespaces = {}\n    events=(\"end\", \"start-ns\", \"end-ns\")\n    for (event, elem) in iterparse(source, events):\n        if event == \"start-ns\":\n            prefix, ns = elem\n            namespaces[prefix] = ns\n        elif event == \"end\":\n            break\n\n    # Reset stream\n    if hasattr(source, \"seek\"):\n        source.seek(0)\n\n    return namespaces"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cim_ns(namespaces):\n    try:\n        ns = namespaces['cim']\n        if ns.endswith('#'):\n            ns = ns[:-1]\n    except KeyError:\n        ns = ''\n        logger.error('No CIM namespace defined in input file.')\n\n    CIM16nsURI = 'http://iec.ch/TC57/2013/CIM-schema-cim16'\n\n    nsuri = ns\n\n    import CIM14, CIM15\n    if ns == CIM14.nsURI:\n        ns = 'CIM14'\n    elif ns == CIM15.nsURI:\n        ns = 'CIM15'\n    elif ns == CIM16nsURI:\n        ns  = 'CIM15'\n    else:\n        ns = 'CIM15'\n        logger.warn('Could not detect CIM version. Using %s.' % ns)\n\n    cim = __import__(ns, globals(), locals(), ['nsURI', 'packageMap'])\n\n    return nsuri, cim.packageMap", "response": "Tries to obtain the CIM version from the given map of namespaces and\n    returns the appropriate nsURI and packageMap*."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cimwrite(d, source, encoding=\"utf-8\"):\n    # Start the clock\n    t0 = time()\n\n    w = XMLWriter(source, encoding)\n\n    # Write the XML declaration.\n    w.declaration()\n\n    # Add a '#' suffix to the CIM namespace URI if not present.\n    nsCIM = nsURI if nsURI[-1] == \"#\" else nsURI + \"#\"\n\n    # Start the root RDF element and declare namespaces.\n    xmlns = {u\"xmlns:%s\" % nsPrefixRDF: nsRDF, u\"xmlns:%s\" % nsPrefix: nsCIM}\n    rdf = w.start(u\"%s:RDF\" % nsPrefixRDF, xmlns)\n\n    # Iterate over all UUID, CIM object pairs in the given dictionary.\n    for uuid, obj in d.items():\n        w.start(u\"%s:%s\" % (nsPrefix, obj.__class__.__name__),\n                {u\"%s:ID\" % nsPrefixRDF: obj.UUID})\n\n        mro = obj.__class__.mro()\n        mro.reverse()\n\n        # Serialise attributes.\n        for klass in mro[2:]: # skip 'object' and 'Element'\n            attrs = [a for a in klass._attrs if a not in klass._enums]\n            for attr in attrs:\n                val = getattr(obj, attr)\n                if val != klass._defaults[attr]:\n                    w.element(u\"%s:%s.%s\" % (nsPrefix, klass.__name__, attr),\n                              str(val))\n\n        # Serialise enumeration data-types.\n        for klass in mro[2:]: # skip 'object' and 'Element'\n            enums = [a for a in klass._attrs if a in klass._enums]\n            for enum in enums:\n                val = getattr(obj, enum)\n                dt = klass._enums[enum]\n                w.element(u\"%s:%s.%s\" % (nsPrefix, klass.__name__, enum),\n                          attrib={u\"%s:resource\" % nsPrefixRDF:\n                                  u\"%s%s.%s\" % (nsCIM, dt, val)})\n\n        # Serialise references.\n        for klass in mro[2:]: # skip 'object' and 'Element'\n            # FIXME: serialise 'many' references.\n            refs = [r for r in klass._refs if r not in klass._many_refs]\n            for ref in refs:\n                val = getattr(obj, ref)\n                if val is not None:\n                    w.element(u\"%s:%s.%s\" % (nsPrefix, klass.__name__, ref),\n                          attrib={u\"%s:resource\" % nsPrefixRDF:\n                                  u\"#%s\" % val.UUID})\n\n        w.end()\n\n    # Close the root RDF element.\n    w.close(rdf)\n\n    # Flush the output stream.\n    w.flush()\n\n    logger.info(\"%d CIM objects serialised in %.2fs.\", len(d), time() - t0)", "response": "Write a dictionary of URIs to a CIM RDF / XML file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_block(mc, block_id, subtype=None):\n    # Get player tile position and real position.\n    ptx, pty, ptz = mc.player.getTilePos()\n    px, py, pz = mc.player.getPos()\n    # Create block at current player tile location.\n    if subtype is None:\n        mc.setBlock(ptx, pty, ptz, block_id)\n    else:\n        mc.setBlock(ptx, pty, ptz, block_id, subtype)\n    # Move the player's real positon up one block.\n    mc.player.setPos(px, py+1, pz)", "response": "Create a block with the specified id and subtype under the player in the Minecraft world."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _busy_wait_ms(self, ms):\n        start = time.time()\n        delta = ms/1000.0\n        while (time.time() - start) <= delta:\n            pass", "response": "Busy wait for the specified number of milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a frame to the PN532 with the specified data bytearray.", "response": "def _write_frame(self, data):\n        \"\"\"Write a frame to the PN532 with the specified data bytearray.\"\"\"\n        assert data is not None and 0 < len(data) < 255, 'Data must be array of 1 to 255 bytes.'\n        # Build frame to send as:\n        # - SPI data write (0x01)\n        # - Preamble (0x00)\n        # - Start code  (0x00, 0xFF)\n        # - Command length (1 byte)\n        # - Command length checksum\n        # - Command bytes\n        # - Checksum\n        # - Postamble (0x00)\n        length = len(data)\n        frame = bytearray(length+8)\n        frame[0] = PN532_SPI_DATAWRITE\n        frame[1] = PN532_PREAMBLE\n        frame[2] = PN532_STARTCODE1\n        frame[3] = PN532_STARTCODE2\n        frame[4] = length & 0xFF\n        frame[5] = self._uint8_add(~length, 1)\n        frame[6:-2] = data\n        checksum = reduce(self._uint8_add, data, 0xFF)\n        frame[-2] = ~checksum & 0xFF\n        frame[-1] = PN532_POSTAMBLE\n        # Send frame.\n        logger.debug('Write frame: 0x{0}'.format(binascii.hexlify(frame)))\n        self._gpio.set_low(self._cs)\n        self._busy_wait_ms(2)\n        self._spi.write(frame)\n        self._gpio.set_high(self._cs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_data(self, count):\n        # Build a read request frame.\n        frame = bytearray(count)\n        frame[0] = PN532_SPI_DATAREAD\n        # Send the frame and return the response, ignoring the SPI header byte.\n        self._gpio.set_low(self._cs)\n        self._busy_wait_ms(2)\n        response = self._spi.transfer(frame)\n        self._gpio.set_high(self._cs)\n        return response", "response": "Read a specified number of bytes from the PN532."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_frame(self, length):\n        # Read frame with expected length of data.\n        response = self._read_data(length+8)\n        logger.debug('Read frame: 0x{0}'.format(binascii.hexlify(response)))\n        # Check frame starts with 0x01 and then has 0x00FF (preceeded by optional\n        # zeros).\n        if response[0] != 0x01:\n            raise RuntimeError('Response frame does not start with 0x01!')\n        # Swallow all the 0x00 values that preceed 0xFF.\n        offset = 1\n        while response[offset] == 0x00:\n            offset += 1\n            if offset >= len(response):\n                raise RuntimeError('Response frame preamble does not contain 0x00FF!')\n        if response[offset] != 0xFF:\n            raise RuntimeError('Response frame preamble does not contain 0x00FF!')\n        offset += 1\n        if offset >= len(response):\n                raise RuntimeError('Response contains no data!')\n        # Check length & length checksum match.\n        frame_len = response[offset]\n        if (frame_len + response[offset+1]) & 0xFF != 0:\n            raise RuntimeError('Response length checksum did not match length!')\n        # Check frame checksum value matches bytes.\n        checksum = reduce(self._uint8_add, response[offset+2:offset+2+frame_len+1], 0)\n        if checksum != 0:\n            raise RuntimeError('Response checksum did not match expected value!')\n        # Return frame data.\n        return response[offset+2:offset+2+frame_len]", "response": "Read a response frame from the PN532."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting until the PN532 is ready to receive commands.", "response": "def _wait_ready(self, timeout_sec=1):\n        \"\"\"Wait until the PN532 is ready to receive commands.  At most wait\n        timeout_sec seconds for the PN532 to be ready.  If the PN532 is ready\n        before the timeout is exceeded then True will be returned, otherwise\n        False is returned when the timeout is exceeded.\n        \"\"\"\n        start = time.time()\n        # Send a SPI status read command and read response.\n        self._gpio.set_low(self._cs)\n        self._busy_wait_ms(2)\n        response = self._spi.transfer([PN532_SPI_STATREAD, 0x00])\n        self._gpio.set_high(self._cs)\n        # Loop until a ready response is received.\n        while response[1] != PN532_SPI_READY:\n            # Check if the timeout has been exceeded.\n            if time.time() - start >= timeout_sec:\n                return False\n            # Wait a little while and try reading the status again.\n            time.sleep(0.01)\n            self._gpio.set_low(self._cs)\n            self._busy_wait_ms(2)\n            response = self._spi.transfer([PN532_SPI_STATREAD, 0x00])\n            self._gpio.set_high(self._cs)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a command to the PN532 and expect up to response_length bytes back in a response.", "response": "def call_function(self, command, response_length=0, params=[], timeout_sec=1):\n        \"\"\"Send specified command to the PN532 and expect up to response_length\n        bytes back in a response.  Note that less than the expected bytes might\n        be returned!  Params can optionally specify an array of bytes to send as\n        parameters to the function call.  Will wait up to timeout_secs seconds\n        for a response and return a bytearray of response bytes, or None if no\n        response is available within the timeout.\n        \"\"\"\n        # Build frame data with command and parameters.\n        data = bytearray(2+len(params))\n        data[0]  = PN532_HOSTTOPN532\n        data[1]  = command & 0xFF\n        data[2:] = params\n        # Send frame and wait for response.\n        self._write_frame(data)\n        if not self._wait_ready(timeout_sec):\n            return None\n        # Verify ACK response and wait to be ready for function response.\n        response = self._read_data(len(PN532_ACK))\n        if response != PN532_ACK:\n            raise RuntimeError('Did not receive expected ACK from PN532!')\n        if not self._wait_ready(timeout_sec):\n            return None\n        # Read response bytes.\n        response = self._read_frame(response_length+2)\n        # Check that response is for the called function.\n        if not (response[0] == PN532_PN532TOHOST and response[1] == (command+1)):\n            raise RuntimeError('Received unexpected command response!')\n        # Return response data.\n        return response[2:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the communication with the PN532.", "response": "def begin(self):\n        \"\"\"Initialize communication with the PN532.  Must be called before any\n        other calls are made against the PN532.\n        \"\"\"\n        # Assert CS pin low for a second for PN532 to be ready.\n        self._gpio.set_low(self._cs)\n        time.sleep(1.0)\n        # Call GetFirmwareVersion to sync up with the PN532.  This might not be\n        # required but is done in the Arduino library and kept for consistency.\n        self.get_firmware_version()\n        self._gpio.set_high(self._cs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling PN532 GetFirmwareVersion function and return a tuple with the IC Ver Rev and Support values.", "response": "def get_firmware_version(self):\n        \"\"\"Call PN532 GetFirmwareVersion function and return a tuple with the IC,\n        Ver, Rev, and Support values.\n        \"\"\"\n        response = self.call_function(PN532_COMMAND_GETFIRMWAREVERSION, 4)\n        if response is None:\n            raise RuntimeError('Failed to detect the PN532!  Make sure there is sufficient power (use a 1 amp or greater power supply), the PN532 is wired correctly to the device, and the solder joints on the PN532 headers are solidly connected.')\n        return (response[0], response[1], response[2], response[3])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the MiFare card from the device and return its UID when found.", "response": "def read_passive_target(self, card_baud=PN532_MIFARE_ISO14443A, timeout_sec=1):\n        \"\"\"Wait for a MiFare card to be available and return its UID when found.\n        Will wait up to timeout_sec seconds and return None if no card is found,\n        otherwise a bytearray with the UID of the found card is returned.\n        \"\"\"\n        # Send passive read command for 1 card.  Expect at most a 7 byte UUID.\n        response = self.call_function(PN532_COMMAND_INLISTPASSIVETARGET,\n                                      params=[0x01, card_baud],\n                                      response_length=17)\n        # If no response is available return None to indicate no card is present.\n        if response is None:\n            return None\n        # Check only 1 card with up to a 7 byte UID is present.\n        if response[0] != 0x01:\n            raise RuntimeError('More than one card detected!')\n        if response[5] > 7:\n            raise RuntimeError('Found card with unexpectedly long UID!')\n        # Return UID of card.\n        return response[6:6+response[5]]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mifare_classic_authenticate_block(self, uid, block_number, key_number, key):\n        # Build parameters for InDataExchange command to authenticate MiFare card.\n        uidlen = len(uid)\n        keylen = len(key)\n        params = bytearray(3+uidlen+keylen)\n        params[0] = 0x01  # Max card numbers\n        params[1] = key_number & 0xFF\n        params[2] = block_number & 0xFF\n        params[3:3+keylen] = key\n        params[3+keylen:]  = uid\n        # Send InDataExchange request and verify response is 0x00.\n        response = self.call_function(PN532_COMMAND_INDATAEXCHANGE,\n                                      params=params,\n                                      response_length=1)\n        return response[0] == 0x00", "response": "Authenticate specified block number for a MiFare classic card."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mifare_classic_read_block(self, block_number):\n        # Send InDataExchange request to read block of MiFare data.\n        response = self.call_function(PN532_COMMAND_INDATAEXCHANGE,\n                                      params=[0x01, MIFARE_CMD_READ, block_number & 0xFF],\n                                      response_length=17)\n        # Check first response is 0x00 to show success.\n        if response[0] != 0x00:\n            return None\n        # Return first 4 bytes since 16 bytes are always returned.\n        return response[1:]", "response": "Read a block of data from the card."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mifare_classic_write_block(self, block_number, data):\n        assert data is not None and len(data) == 16, 'Data must be an array of 16 bytes!'\n        # Build parameters for InDataExchange command to do MiFare classic write.\n        params = bytearray(19)\n        params[0] = 0x01  # Max card numbers\n        params[1] = MIFARE_CMD_WRITE\n        params[2] = block_number & 0xFF\n        params[3:] = data\n        # Send InDataExchange request.\n        response = self.call_function(PN532_COMMAND_INDATAEXCHANGE,\n                                      params=params,\n                                      response_length=1)\n        return response[0] == 0x00", "response": "Write a block of data to the card."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if path is within matchwith s tree.", "response": "def _dirmatch(path, matchwith):\n    \"\"\"Check if path is within matchwith's tree.\n\n    >>> _dirmatch('/home/foo/bar', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar/', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar/etc', '/home/foo/bar')\n    True\n    >>> _dirmatch('/home/foo/bar2', '/home/foo/bar')\n    False\n    >>> _dirmatch('/home/foo/bar2/etc', '/home/foo/bar')\n    False\n    \"\"\"\n    matchlen = len(matchwith)\n    if (path.startswith(matchwith)\n        and path[matchlen:matchlen + 1] in [os.sep, '']):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _virtualenv_sys(venv_path):\n    \"obtain version and path info from a virtualenv.\"\n    executable = os.path.join(venv_path, env_bin_dir, 'python')\n    # Must use \"executable\" as the first argument rather than as the\n    # keyword argument \"executable\" to get correct value from sys.path\n    p = subprocess.Popen([executable,\n        '-c', 'import sys;'\n              'print (sys.version[:3]);'\n              'print (\"\\\\n\".join(sys.path));'],\n        env={},\n        stdout=subprocess.PIPE)\n    stdout, err = p.communicate()\n    assert not p.returncode and stdout\n    lines = stdout.decode('utf-8').splitlines()\n    return lines[0], list(filter(bool, lines[1:]))", "response": "obtain version and path info from a virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef int_to_ef(n):\n\n    flags = {}\n    for name, value in libarchive.constants.archive_entry.FILETYPES.items():\n        flags[name] = (n & value) > 0\n\n    return ENTRY_FILETYPE(**flags)", "response": "Convert an integer to an entry type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an archive enumerator from a user - defined source using a user - defined entry type.", "response": "def _enumerator(opener, entry_cls, format_code=None, filter_code=None):\n    \"\"\"Return an archive enumerator from a user-defined source, using a user-\n    defined entry type.\n    \"\"\"\n\n    archive_res = _archive_read_new()\n\n    try:\n        r = _set_read_context(archive_res, format_code, filter_code)\n        opener(archive_res)\n\n        def it():\n            while 1:\n                with _archive_read_next_header(archive_res) as entry_res:\n                    if entry_res is None:\n                        break\n\n                    e = entry_cls(archive_res, entry_res)\n                    yield e\n                    if e.is_consumed is False:\n                        _archive_read_data_skip(archive_res)\n        yield it()\n    finally:\n        _archive_read_free(archive_res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file_enumerator(filepath, block_size=10240, *args, **kwargs):\n\n    _LOGGER.debug(\"Enumerating through archive file: %s\", filepath)\n\n    def opener(archive_res):\n        _LOGGER.debug(\"Opening from file (file_enumerator): %s\", filepath)\n        _archive_read_open_filename(archive_res, filepath, block_size)\n\n    if 'entry_cls' not in kwargs:\n        kwargs['entry_cls'] = _ArchiveEntryItReadable\n\n    return _enumerator(opener,\n                       *args,\n                       **kwargs)", "response": "Return an enumerator that knows how to read a physical file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an enumerator that knows how to read raw memory.", "response": "def memory_enumerator(buffer_, *args, **kwargs):\n    \"\"\"Return an enumerator that knows how to read raw memory.\"\"\"\n\n    _LOGGER.debug(\"Enumerating through (%d) bytes of archive data.\",\n                  len(buffer_))\n\n    def opener(archive_res):\n        _LOGGER.debug(\"Opening from (%d) bytes (memory_enumerator).\",\n                      len(buffer_))\n\n        _archive_read_open_memory(archive_res, buffer_)\n\n    if 'entry_cls' not in kwargs:\n        kwargs['entry_cls'] = _ArchiveEntryItReadable\n\n    return _enumerator(opener,\n                       *args,\n                       **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pour(opener, flags=0, *args, **kwargs):\n\n    with _enumerator(opener,\n                     *args,\n                     entry_cls=_ArchiveEntryItState,\n                     **kwargs) as r:\n        ext = libarchive.calls.archive_write.c_archive_write_disk_new()\n        libarchive.calls.archive_write.c_archive_write_disk_set_options(\n                ext,\n                flags\n            )\n\n        for state in r:\n            yield state\n\n            if state.selected is False:\n                continue\n\n            r = libarchive.calls.archive_write.c_archive_write_header(\n                    ext,\n                    state.entry_res)\n\n            buff = ctypes.c_void_p()\n            size = ctypes.c_size_t()\n            offset = ctypes.c_longlong()\n\n            while 1:\n                r = libarchive.calls.archive_read.\\\n                        c_archive_read_data_block(\n                            state.reader_res,\n                            ctypes.byref(buff),\n                            ctypes.byref(size),\n                            ctypes.byref(offset))\n\n                if r == libarchive.constants.archive.ARCHIVE_EOF:\n                    break\n                elif r != libarchive.constants.archive.ARCHIVE_OK:\n                    message = c_archive_error_string(state.reader_res)\n                    raise libarchive.exception.ArchiveError(\n                            \"Pour failed: (%d) [%s]\" % (r, message))\n\n                r = libarchive.calls.archive_write.c_archive_write_data_block(\n                        ext,\n                        buff,\n                        size,\n                        offset)\n\n            r = libarchive.calls.archive_write.\\\n                    c_archive_write_finish_entry(ext)", "response": "A flexible pouring facility that knows how to enumerate entry data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites physical files from entries.", "response": "def file_pour(filepath, block_size=10240, *args, **kwargs):\n    \"\"\"Write physical files from entries.\"\"\"\n\n    def opener(archive_res):\n        _LOGGER.debug(\"Opening from file (file_pour): %s\", filepath)\n        _archive_read_open_filename(archive_res, filepath, block_size)\n\n    return _pour(opener, *args, flags=0, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield data from entries.", "response": "def memory_pour(buffer_, *args, **kwargs):\n    \"\"\"Yield data from entries.\"\"\"\n\n    def opener(archive_res):\n        _LOGGER.debug(\"Opening from (%d) bytes (memory_pour).\", len(buffer_))\n        _archive_read_open_memory(archive_res, buffer_)\n\n    return _pour(opener, *args, flags=0, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite data to archive.", "response": "def _archive_write_data(archive, data):\n    \"\"\"Write data to archive. This will only be called with a non-empty string.\n    \"\"\"\n\n    n = libarchive.calls.archive_write.c_archive_write_data(\n            archive,\n            ctypes.cast(ctypes.c_char_p(data), ctypes.c_void_p),\n            len(data))\n\n    if n == 0:\n        message = c_archive_error_string(archive)\n        raise ValueError(\"No bytes were written. Error? [%s]\" % (message))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an archive from a collection of files.", "response": "def _create(opener,\n            format_code,\n            files,\n            filter_code=None,\n            block_size=16384):\n    \"\"\"Create an archive from a collection of files (not recursive).\"\"\"\n\n    a = _archive_write_new()\n    _set_write_context(a, format_code, filter_code)\n\n    _LOGGER.debug(\"Opening archive (create).\")\n    opener(a)\n\n# Use the standard uid/gid lookup mechanisms.\n# This was set on an instance of *disk* that wasn't used. Do we still need it?\n#_archive_read_disk_set_standard_lookup(disk)\n\n    # We used to yield this, but that necessitated users always flattening the\n    # response. This means we don't have to, but we still have to return an\n    # enumerable in order to maintain compatibility.\n    added = []\n\n    for filepath in files:\n        filepath = filepath.encode('utf-8')\n\n        disk = libarchive.calls.archive_read.c_archive_read_disk_new()\n        libarchive.calls.archive_read.c_archive_read_disk_open(\n            disk,\n            filepath)\n\n        while 1:\n            entry = libarchive.calls.archive_entry.c_archive_entry_new()\n            r = libarchive.calls.archive_read.c_archive_read_next_header2(\n                    disk,\n                    entry)\n\n            if r == libarchive.constants.archive.ARCHIVE_EOF:\n                break\n            elif r != libarchive.constants.archive.ARCHIVE_OK:\n                message = c_archive_error_string(disk)\n                raise libarchive.exception.ArchiveError(\n                        \"Could not build header from physical source file \"\n                        \"during create: (%d) [%s]\" %\n                        (r, message))\n\n            ae = libarchive.adapters.archive_entry.ArchiveEntry(\n                        disk,\n                        entry)\n\n            # print(\"WRITING: [{}] {}\".format(ae, ae.filetype))\n\n            # Strip leading slash so it stores as a relative path.\n            if os.path.isabs(ae.pathname) is True:\n                ae.pathname = ae.pathname[1:]\n\n            added.append(ae)\n\n            libarchive.calls.archive_read.c_archive_read_disk_descend(disk)\n\n            # NOTE: There's a `archive_entry_set_size()` on the underlying\n            # entry type, but it doesn't appear to be necessary. The sizes\n            # report perfectly fine with the [probably automatic] counting that\n            # occurs just with `_archive_write_data()`.\n\n            r = _archive_write_header(a, entry)\n\n            if ae.filetype.IFLNK is True and os.path.islink(ae.sourcepath) is True:\n                target_path = os.readlink(ae.sourcepath)\n                ae.symlink_targetpath = target_path\n            else:\n                with open(ae.sourcepath, 'rb') as f:\n                    while 1:\n                        data = f.read(block_size)\n                        if not data:\n                            break\n\n                        _archive_write_data(a, data)\n\n            libarchive.calls.archive_entry.c_archive_entry_free(entry)\n\n        libarchive.calls.archive_read.c_archive_read_close(disk)\n        libarchive.calls.archive_read.c_archive_read_free(disk)\n\n    _LOGGER.debug(\"Closing archive (create).\")\n\n    _archive_write_close(a)\n    _archive_write_free(a)\n\n    return added"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_ctrl_meas(self):\n        self._write_register_byte(_BME280_REGISTER_CTRL_HUM, self.overscan_humidity)\n        self._write_register_byte(_BME280_REGISTER_CTRL_MEAS, self._ctrl_meas)", "response": "Write the values to the ctrl_meas and ctrl_hum registers in the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the value to the config register in the device", "response": "def _write_config(self):\n        \"\"\"Write the value to the config register in the device \"\"\"\n        normal_flag = False\n        if self._mode == MODE_NORMAL:\n            #Writes to the config register may be ignored while in Normal mode\n            normal_flag = True\n            self.mode = MODE_SLEEP #So we switch to Sleep mode first\n        self._write_register_byte(_BME280_REGISTER_CONFIG, self._config)\n        if normal_flag:\n            self.mode = MODE_NORMAL"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value to be written to the device s config register", "response": "def _config(self):\n        \"\"\"Value to be written to the device's config register \"\"\"\n        config = 0\n        if self.mode == MODE_NORMAL:\n            config += (self._t_standby << 5)\n        if self._iir_filter:\n            config += (self._iir_filter << 2)\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the value to be written to the device s ctrl_meas register", "response": "def _ctrl_meas(self):\n        \"\"\"Value to be written to the device's ctrl_meas register \"\"\"\n        ctrl_meas = (self.overscan_temperature << 5)\n        ctrl_meas += (self.overscan_pressure << 2)\n        ctrl_meas += self.mode\n        return ctrl_meas"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measurement_time_typical(self):\n        meas_time_ms = 1.0\n        if self.overscan_temperature != OVERSCAN_DISABLE:\n            meas_time_ms += (2 * _BME280_OVERSCANS.get(self.overscan_temperature))\n        if self.overscan_pressure != OVERSCAN_DISABLE:\n            meas_time_ms += (2 * _BME280_OVERSCANS.get(self.overscan_pressure) + 0.5)\n        if self.overscan_humidity != OVERSCAN_DISABLE:\n            meas_time_ms += (2 * _BME280_OVERSCANS.get(self.overscan_humidity) + 0.5)\n        return meas_time_ms", "response": "Typical time in milliseconds required to complete a measurement in normal mode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the compensated pressure in hectoPascals.", "response": "def pressure(self):\n        \"\"\"\n        The compensated pressure in hectoPascals.\n        returns None if pressure measurement is disabled\n        \"\"\"\n        self._read_temperature()\n\n        # Algorithm from the BME280 driver\n        # https://github.com/BoschSensortec/BME280_driver/blob/master/bme280.c\n        adc = self._read24(_BME280_REGISTER_PRESSUREDATA) / 16  # lowest 4 bits get dropped\n        var1 = float(self._t_fine) / 2.0 - 64000.0\n        var2 = var1 * var1 * self._pressure_calib[5] / 32768.0\n        var2 = var2 + var1 * self._pressure_calib[4] * 2.0\n        var2 = var2 / 4.0 + self._pressure_calib[3] * 65536.0\n        var3 = self._pressure_calib[2] * var1 * var1 / 524288.0\n        var1 = (var3 + self._pressure_calib[1] * var1) / 524288.0\n        var1 = (1.0 + var1 / 32768.0) * self._pressure_calib[0]\n        if var1 == 0:\n            return 0\n        if var1:\n            pressure = 1048576.0 - adc\n            pressure = ((pressure - var2 / 4096.0) * 6250.0) / var1\n            var1 = self._pressure_calib[8] * pressure * pressure / 2147483648.0\n            var2 = pressure * self._pressure_calib[7] / 32768.0\n            pressure = pressure + (var1 + var2 + self._pressure_calib[6]) / 16.0\n\n            pressure /= 100\n            if pressure < _BME280_PRESSURE_MIN_HPA:\n                return _BME280_PRESSURE_MIN_HPA\n            if pressure > _BME280_PRESSURE_MAX_HPA:\n                return _BME280_PRESSURE_MAX_HPA\n            return pressure\n        else:\n            return _BME280_PRESSURE_MIN_HPA"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef humidity(self):\n        self._read_temperature()\n        hum = self._read_register(_BME280_REGISTER_HUMIDDATA, 2)\n        #print(\"Humidity data: \", hum)\n        adc = float(hum[0] << 8 | hum[1])\n        #print(\"adc:\", adc)\n\n        # Algorithm from the BME280 driver\n        # https://github.com/BoschSensortec/BME280_driver/blob/master/bme280.c\n        var1 = float(self._t_fine) - 76800.0\n        #print(\"var1 \", var1)\n        var2 = (self._humidity_calib[3] * 64.0 + (self._humidity_calib[4] / 16384.0) * var1)\n        #print(\"var2 \",var2)\n        var3 = adc - var2\n        #print(\"var3 \",var3)\n        var4 = self._humidity_calib[1] / 65536.0\n        #print(\"var4 \",var4)\n        var5 = (1.0 + (self._humidity_calib[2] / 67108864.0) * var1)\n        #print(\"var5 \",var5)\n        var6 = 1.0 + (self._humidity_calib[5] / 67108864.0) * var1 * var5\n        #print(\"var6 \",var6)\n        var6 = var3 * var4 * (var5 * var6)\n        humidity = var6 * (1.0 - self._humidity_calib[0] * var6 / 524288.0)\n\n        if humidity > _BME280_HUMIDITY_MAX:\n            return _BME280_HUMIDITY_MAX\n        if humidity < _BME280_HUMIDITY_MIN:\n            return _BME280_HUMIDITY_MIN\n        # else...\n        return humidity", "response": "Returns the relative humidity in RH"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef altitude(self):\n        pressure = self.pressure # in Si units for hPascal\n        return 44330 * (1.0 - math.pow(pressure / self.sea_level_pressure, 0.1903))", "response": "The altitude of the sea level in the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading & save the calibration coefficients", "response": "def _read_coefficients(self):\n        \"\"\"Read & save the calibration coefficients\"\"\"\n        coeff = self._read_register(_BME280_REGISTER_DIG_T1, 24)\n        coeff = list(struct.unpack('<HhhHhhhhhhhh', bytes(coeff)))\n        coeff = [float(i) for i in coeff]\n        self._temp_calib = coeff[:3]\n        self._pressure_calib = coeff[3:]\n\n        self._humidity_calib = [0]*6\n        self._humidity_calib[0] = self._read_byte(_BME280_REGISTER_DIG_H1)\n        coeff = self._read_register(_BME280_REGISTER_DIG_H2, 7)\n        coeff = list(struct.unpack('<hBBBBb', bytes(coeff)))\n        self._humidity_calib[1] = float(coeff[0])\n        self._humidity_calib[2] = float(coeff[1])\n        self._humidity_calib[3] = float((coeff[2] << 4) |  (coeff[3] & 0xF))\n        self._humidity_calib[4] = float((coeff[4] << 4) | (coeff[3] >> 4))\n        self._humidity_calib[5] = float(coeff[5])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read24(self, register):\n        ret = 0.0\n        for b in self._read_register(register, 3):\n            ret *= 256.0\n            ret += float(b & 0xFF)\n        return ret", "response": "Read an unsigned 24 - bit value and return it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create(self, postData) :\n        if self.infos is None :\n            r = self.connection.session.post(self.indexesURL, params = {\"collection\" : self.collection.name}, data = json.dumps(postData, default=str))\n            data = r.json()\n            if (r.status_code >= 400) or data['error'] :\n                raise CreationError(data['errorMessage'], data)\n            self.infos = data", "response": "Creates an index of any type according to postData"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a vertex to the graph and returns it", "response": "def createVertex(self, collectionName, docAttributes, waitForSync = False) :\n        \"\"\"adds a vertex to the graph and returns it\"\"\"\n        url = \"%s/vertex/%s\" % (self.URL, collectionName)\n\n        store = DOC.DocumentStore(self.database[collectionName], validators=self.database[collectionName]._fields, initDct=docAttributes)\n        # self.database[collectionName].validateDct(docAttributes)\n        store.validate()\n\n        r = self.connection.session.post(url, data = json.dumps(docAttributes, default=str), params = {'waitForSync' : waitForSync})\n\n        data = r.json()\n        if r.status_code == 201 or r.status_code == 202 :\n            return self.database[collectionName][data[\"vertex\"][\"_key\"]]\n\n        raise CreationError(\"Unable to create vertice, %s\" % data[\"errorMessage\"], data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a vertex from the graph as well as al linked edges", "response": "def deleteVertex(self, document, waitForSync = False) :\n        \"\"\"deletes a vertex from the graph as well as al linked edges\"\"\"\n        url = \"%s/vertex/%s\" % (self.URL, document._id)\n\n        r = self.connection.session.delete(url, params = {'waitForSync' : waitForSync})\n        data = r.json()\n        if r.status_code == 200 or r.status_code == 202 :\n            return True\n\n        raise DeletionError(\"Unable to delete vertice, %s\" % document._id, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createEdge(self, collectionName, _fromId, _toId, edgeAttributes, waitForSync = False) :\n\n        if not _fromId :\n            raise ValueError(\"Invalid _fromId: %s\" % _fromId)\n\n        if not _toId :\n            raise ValueError(\"Invalid _toId: %s\" % _toId)\n\n        if collectionName not in self.definitions :\n            raise KeyError(\"'%s' is not among the edge definitions\" % collectionName)\n\n        url = \"%s/edge/%s\" % (self.URL, collectionName)\n        self.database[collectionName].validatePrivate(\"_from\", _fromId)\n        self.database[collectionName].validatePrivate(\"_to\", _toId)\n        \n        ed = self.database[collectionName].createEdge()\n        ed.set(edgeAttributes)\n        ed.validate()\n\n        payload = ed.getStore()\n        payload.update({'_from' : _fromId, '_to' : _toId})\n\n        r = self.connection.session.post(url, data = json.dumps(payload, default=str), params = {'waitForSync' : waitForSync})\n        data = r.json()\n        if r.status_code == 201 or r.status_code == 202 :\n            return self.database[collectionName][data[\"edge\"][\"_key\"]]\n        # print \"\\ngraph 160, \", data, payload, _fromId\n        raise CreationError(\"Unable to create edge, %s\" % r.json()[\"errorMessage\"], data)", "response": "creates an edge between two documents"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef link(self, definition, doc1, doc2, edgeAttributes, waitForSync = False) :\n        \"A shorthand for createEdge that takes two documents as input\"\n        if type(doc1) is DOC.Document :\n            if not doc1._id :\n                doc1.save()\n            doc1_id = doc1._id\n        else :\n            doc1_id = doc1\n\n        if type(doc2) is DOC.Document :\n            if not doc2._id :\n                doc2.save()\n            doc2_id = doc2._id\n        else :\n            doc2_id = doc2\n\n        return self.createEdge(definition, doc1_id, doc2_id, edgeAttributes, waitForSync)", "response": "A shorthand for createEdge that takes two documents as input"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unlink(self, definition, doc1, doc2) :\n        \"deletes all links between doc1 and doc2\"\n        links = self.database[definition].fetchByExample( {\"_from\": doc1._id,\"_to\" : doc2._id}, batchSize = 100)\n        for l in links :\n            self.deleteEdge(l)", "response": "deletes all links between doc1 and doc2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deleteEdge(self, edge, waitForSync = False) :\n        url = \"%s/edge/%s\" % (self.URL, edge._id)\n        r = self.connection.session.delete(url, params = {'waitForSync' : waitForSync})\n        if r.status_code == 200 or r.status_code == 202 :\n            return True\n        raise DeletionError(\"Unable to delete edge, %s\" % edge._id, r.json())", "response": "Removes an edge from the graph"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, _key) :\n        \"removes a document from the cache\"\n        try :\n            doc = self.cacheStore[_key]\n            doc.prev.nextDoc = doc.nextDoc\n            doc.nextDoc.prev = doc.prev\n            del(self.cacheStore[_key])\n        except KeyError :\n            raise KeyError(\"Document with _key %s is not available in cache\" % _key)", "response": "removes a document from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of keys representing the chain of documents", "response": "def getChain(self) :\n        \"returns a list of keys representing the chain of documents\"\n        l = []\n        h = self.head\n        while h :\n            l.append(h._key)\n            h = h.nextDoc\n        return l"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stringify(self) :\n        \"a pretty str version of getChain()\"\n        l = []\n        h = self.head\n        while h :\n            l.append(str(h._key))\n            h = h.nextDoc\n        return \"<->\".join(l)", "response": "a pretty str version of getChain"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(self, value) :\n        for v in self.validators :\n            v.validate(value)\n        return True", "response": "checks the validity of value given the lits of validators"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the class object of a collection given its name", "response": "def getCollectionClass(cls, name) :\n        \"\"\"Return the class object of a collection given its 'name'\"\"\"\n        try :\n            return cls.collectionClasses[name]\n        except KeyError :\n            raise KeyError( \"There is no Collection Class of type: '%s'; currently supported values: [%s]\" % (name, ', '.join(getCollectionClasses().keys())) )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isDocumentCollection(cls, name) :\n        try :\n            col = cls.getCollectionClass(name)\n            return issubclass(col, Collection)\n        except KeyError :\n            return False", "response": "return true or false wether name is the name of a document collection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true or false wether name is the name of an edge collection.", "response": "def isEdgeCollection(cls, name) :\n        \"\"\"return true or false wether 'name' is the name of an edge collection.\"\"\"\n        try :\n            col = cls.getCollectionClass(name)\n            return issubclass(col, Edges)\n        except KeyError :\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getIndexes(self) :\n        url = \"%s/index\" % self.database.URL\n        r = self.connection.session.get(url, params = {\"collection\": self.name})\n        data = r.json()\n        for ind in data[\"indexes\"] :\n            self.indexes[ind[\"type\"]][ind[\"id\"]] = Index(collection = self, infos = ind)\n\n        return self.indexes", "response": "Fills self. indexes with all the indexes associates with the collection and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self) :\n        r = self.connection.session.delete(self.URL)\n        data = r.json()\n        if not r.status_code == 200 or data[\"error\"] :\n            raise DeletionError(data[\"errorMessage\"], data)", "response": "deletes the collection from the database"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createDocument(self, initDict = None) :\n        if initDict is not None :\n            return self.createDocument_(initDict)\n        else :\n            if self._validation[\"on_load\"] :\n                self._validation[\"on_load\"] = False\n                return self.createDocument_(self.defaultDocument)\n                self._validation[\"on_load\"] = True\n            else :\n                return self.createDocument_(self.defaultDocument)", "response": "create and returns a document populated with the defaults or with the values in initDict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createDocument_(self, initDict = None) :\n        \"create and returns a completely empty document or one populated with initDict\"\n        if initDict is None :\n            initV = {}\n        else :\n            initV = initDict\n\n        return self.documentClass(self, initV)", "response": "create and returns a completely empty document or one populated with initDict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a hash index if it does not already exist and returns it", "response": "def ensureHashIndex(self, fields, unique = False, sparse = True, deduplicate = False) :\n        \"\"\"Creates a hash index if it does not already exist, and returns it\"\"\"\n        data = {\n            \"type\" : \"hash\",\n            \"fields\" : fields,\n            \"unique\" : unique,\n            \"sparse\" : sparse,\n            \"deduplicate\": deduplicate\n        }\n        ind = Index(self, creationData = data)\n        self.indexes[\"hash\"][ind.infos[\"id\"]] = ind\n        return ind"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a geo index if it does not already exist and returns it", "response": "def ensureGeoIndex(self, fields) :\n        \"\"\"Creates a geo index if it does not already exist, and returns it\"\"\"\n        data = {\n            \"type\" : \"geo\",\n            \"fields\" : fields,\n        }\n        ind = Index(self, creationData = data)\n        self.indexes[\"geo\"][ind.infos[\"id\"]] = ind\n        return ind"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a fulltext index if it does not already exist and returns it", "response": "def ensureFulltextIndex(self, fields, minLength = None) :\n        \"\"\"Creates a fulltext index if it does not already exist, and returns it\"\"\"\n        data = {\n            \"type\" : \"fulltext\",\n            \"fields\" : fields,\n        }\n        if minLength is not None :\n            data[\"minLength\"] = minLength\n\n        ind = Index(self, creationData = data)\n        self.indexes[\"fulltext\"][ind.infos[\"id\"]] = ind\n        return ind"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating a private field value", "response": "def validatePrivate(self, field, value) :\n        \"\"\"validate a private field value\"\"\"\n        if field not in self.arangoPrivates :\n            raise ValueError(\"%s is not a private field of collection %s\" % (field, self))\n\n        if field in self._fields :\n            self._fields[field].validate(value)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the collection has field K in it s schema False otherwise", "response": "def hasField(cls, fieldName) :\n        \"\"\"returns True/False wether the collection has field K in it's schema. Use the dot notation for the nested fields: address.street\"\"\"\n        path = fieldName.split(\".\")\n        v = cls._fields\n        for k in path :\n            try :\n                v = v[k]\n            except KeyError :\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching a document from the collection given it s key.", "response": "def fetchDocument(self, key, rawResults = False, rev = None) :\n        \"\"\"Fetches a document from the collection given it's key. This function always goes straight to the db and bypasses the cache. If you\n        want to take advantage of the cache use the __getitem__ interface: collection[key]\"\"\"\n        url = \"%s/%s/%s\" % (self.documentsURL, self.name, key)\n        if rev is not None :\n            r = self.connection.session.get(url, params = {'rev' : rev})\n        else :\n            r = self.connection.session.get(url)\n\n        if r.status_code < 400 :\n            if rawResults :\n                return r.json()\n            return self.documentClass(self, r.json())\n        elif r.status_code == 404 :\n            raise DocumentNotFoundError(\"Unable to find document with _key: %s\" % key, r.json())\n        else :\n            raise DocumentNotFoundError(\"Unable to find document with _key: %s, response: %s\" % (key, r.json()), r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetchByExample(self, exampleDict, batchSize, rawResults = False, **queryArgs) :\n        return self.simpleQuery('by-example', rawResults, example = exampleDict, batchSize = batchSize, **queryArgs)", "response": "Fetch all records by example"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetchFirstExample(self, exampleDict, rawResults = False) :\n        return self.simpleQuery('first-example', rawResults = rawResults, example = exampleDict)", "response": "fetchFirstExample returns the first example found that matches the exampleDict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetchAll(self, rawResults = False, **queryArgs) :\n        return self.simpleQuery('all', rawResults = rawResults, **queryArgs)", "response": "Returns all the documents in the collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bulkImport_json(self, filename, onDuplicate=\"error\", formatType=\"auto\", **params) :\n\n        url = \"%s/import\" % self.database.URL\n        params[\"onDuplicate\"] = onDuplicate\n        params[\"collection\"] = self.name\n        params[\"type\"] = formatType\n        with open(filename) as f:\n            data = f.read()\n            r = self.connection.session.post(URL, params = params, data = data)\n\n            try :\n                errorMessage = \"At least: %d errors. The first one is: '%s'\\n\\n more in <this_exception>.data\" % (len(data), data[0][\"errorMessage\"])\n            except KeyError:\n                raise UpdateError(data['errorMessage'], data)", "response": "bulk import from a file repecting arango s key value format"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a word describing the type of the collection", "response": "def getType(self) :\n        \"\"\"returns a word describing the type of the collection (edges or ducments) instead of a number, if you prefer the number it's in self.type\"\"\"\n        if self.type == CONST.COLLECTION_DOCUMENT_TYPE :\n            return \"document\"\n        elif self.type == CONST.COLLECTION_EDGE_TYPE :\n            return \"edge\"\n        else :\n            raise ValueError(\"The collection is of Unknown type %s\" % self.type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string describing the status of the collection", "response": "def getStatus(self) :\n        \"\"\"returns a word describing the status of the collection (loaded, loading, deleted, unloaded, newborn) instead of a number, if you prefer the number it's in self.status\"\"\"\n        if self.status == CONST.COLLECTION_LOADING_STATUS :\n            return \"loading\"\n        elif self.status == CONST.COLLECTION_LOADED_STATUS :\n            return \"loaded\"\n        elif self.status == CONST.COLLECTION_DELETED_STATUS :\n            return \"deleted\"\n        elif self.status == CONST.COLLECTION_UNLOADED_STATUS :\n            return \"unloaded\"\n        elif self.status == CONST.COLLECTION_NEWBORN_STATUS :\n            return \"newborn\"\n        else :\n            raise ValueError(\"The collection has an Unknown status %s\" % self.status)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validateField(cls, fieldName, value) :\n        try :\n            valValue = Collection.validateField(fieldName, value)\n        except SchemaViolation as e:\n            if fieldName == \"_from\" or fieldName == \"_to\" :\n                return True\n            else :\n                raise e\n        return valValue", "response": "checks if value is valid for field fieldName raises a SchemaViolation or a ValidationError."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the out edges of a given vertex", "response": "def getOutEdges(self, vertex, rawResults = False) :\n        \"\"\"An alias for getEdges() that returns only the out Edges\"\"\"\n        return self.getEdges(vertex, inEdges = False, outEdges = True, rawResults = rawResults)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getEdges(self, vertex, inEdges = True, outEdges = True, rawResults = False) :\n        if isinstance(vertex, Document):\n            vId = vertex._id\n        elif (type(vertex) is str) or (type(vertex) is bytes):\n            vId = vertex\n        else :\n            raise ValueError(\"Vertex is neither a Document nor a String\")\n\n        params = {\"vertex\" : vId}\n        if inEdges and outEdges :\n            pass\n        elif inEdges :\n            params[\"direction\"] = \"in\"\n        elif outEdges :\n            params[\"direction\"] = \"out\"\n        else :\n            raise ValueError(\"inEdges, outEdges or both must have a boolean value\")\n\n        r = self.connection.session.get(self.edgesURL, params = params)\n        data = r.json()\n        if r.status_code == 200 :\n            if not rawResults :\n                ret = []\n                for e in data[\"edges\"] :\n                    ret.append(Edge(self, e))\n                return ret\n            else :\n                return data[\"edges\"]\n        else :\n            raise CreationError(\"Unable to return edges for vertex: %s\" % vId, data)", "response": "returns in out or both edges liked to a given document"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reloadCollections(self) :\n        \"reloads the collection list.\"\n        r = self.connection.session.get(self.collectionsURL)\n        data = r.json()\n        if r.status_code == 200 :\n            self.collections = {}\n\n            for colData in data[\"result\"] :\n                colName = colData['name']\n                if colData['isSystem'] :\n                    colObj = COL.SystemCollection(self, colData)\n                else :\n                    try :\n                        colClass = COL.getCollectionClass(colName)\n                        colObj = colClass(self, colData)\n                    except KeyError :\n                        if colData[\"type\"] == CONST.COLLECTION_EDGE_TYPE :\n                            colObj = COL.Edges(self, colData)\n                        elif colData[\"type\"] == CONST.COLLECTION_DOCUMENT_TYPE :\n                            colObj = COL.Collection(self, colData)\n                        else :\n                            print((\"Warning!! Collection of unknown type: %d, trying to load it as Collection nonetheless.\" % colData[\"type\"]))\n                            colObj = COL.Collection(self, colData)\n\n                self.collections[colName] = colObj\n        else :\n            raise UpdateError(data[\"errorMessage\"], data)", "response": "reloads the collection list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reloadGraphs(self) :\n        \"reloads the graph list\"\n        r = self.connection.session.get(self.graphsURL)\n        data = r.json()\n        if r.status_code == 200 :\n            self.graphs = {}\n            for graphData in data[\"graphs\"] :\n                try :\n                    self.graphs[graphData[\"_key\"]] = GR.getGraphClass(graphData[\"_key\"])(self, graphData)\n                except KeyError :\n                    self.graphs[graphData[\"_key\"]] = Graph(self, graphData)\n        else :\n            raise UpdateError(data[\"errorMessage\"], data)", "response": "reloads the graph list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new collection and returns it.", "response": "def createCollection(self, className = 'Collection', **colProperties) :\n        \"\"\"Creates a collection and returns it.\n        ClassName the name of a class inheriting from Collection or Egdes, it can also be set to 'Collection' or 'Edges' in order to create untyped collections of documents or edges.\n        Use colProperties to put things such as 'waitForSync = True' (see ArangoDB's doc\n        for a full list of possible arugments). If a '_properties' dictionary is defined in the collection schema, arguments to this function overide it\"\"\"\n\n        colClass = COL.getCollectionClass(className)\n\n        if len(colProperties) > 0 :\n            colProperties = dict(colProperties)\n        else :\n            try :\n                colProperties = dict(colClass._properties)\n            except AttributeError :\n                colProperties = {}\n\n        if className != 'Collection' and className != 'Edges' :\n            colProperties['name'] = className\n        else :\n            if 'name' not in colProperties :\n                raise ValueError(\"a 'name' argument mush be supplied if you want to create a generic collection\")\n\n        if colProperties['name'] in self.collections :\n            raise CreationError(\"Database %s already has a collection named %s\" % (self.name, colProperties['name']) )\n\n        if issubclass(colClass, COL.Edges) or colClass.__class__ is COL.Edges:\n            colProperties[\"type\"] = CONST.COLLECTION_EDGE_TYPE\n        else :\n            colProperties[\"type\"] = CONST.COLLECTION_DOCUMENT_TYPE\n\n        payload = json.dumps(colProperties, default=str)\n        r = self.connection.session.post(self.collectionsURL, data = payload)\n        data = r.json()\n\n        if r.status_code == 200 and not data[\"error\"] :\n            col = colClass(self, data)\n            self.collections[col.name] = col\n            return self.collections[col.name]\n        else :\n            raise CreationError(data[\"errorMessage\"], data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createGraph(self, name, createCollections = True, isSmart = False, numberOfShards = None, smartGraphAttribute = None) :\n\n        def _checkCollectionList(lst) :\n            for colName in lst :\n                if not COL.isCollection(colName) :\n                    raise ValueError(\"'%s' is not a defined Collection\" % colName)\n\n        graphClass = GR.getGraphClass(name)\n\n        ed = []\n        for e in graphClass._edgeDefinitions :\n            if not COL.isEdgeCollection(e.edgesCollection) :\n                raise ValueError(\"'%s' is not a defined Edge Collection\" % e.edgesCollection)\n            _checkCollectionList(e.fromCollections)\n            _checkCollectionList(e.toCollections)\n\n            ed.append(e.toJson())\n\n        _checkCollectionList(graphClass._orphanedCollections)\n\n        options = {}\n        if numberOfShards:\n            options['numberOfShards'] = numberOfShards\n        if smartGraphAttribute:\n            options['smartGraphAttribute'] = smartGraphAttribute\n\n        payload = {\n                \"name\": name,\n                \"edgeDefinitions\": ed,\n                \"orphanCollections\": graphClass._orphanedCollections\n            }\n\n        if isSmart :\n                payload['isSmart'] = isSmart\n\n        if options:\n            payload['options'] = options\n\n        payload = json.dumps(payload)\n\n        r = self.connection.session.post(self.graphsURL, data = payload)\n        data = r.json()\n\n        if r.status_code == 201 or r.status_code == 202 :\n            self.graphs[name] = graphClass(self, data[\"graph\"])\n        else :\n            raise CreationError(data[\"errorMessage\"], data)\n        return self.graphs[name]", "response": "Creates a new graph and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dropAllCollections(self):\n        for graph_name in self.graphs:\n            self.graphs[graph_name].delete()\n        for collection_name in self.collections:\n            # Collections whose name starts with '_' are system collections\n            if not collection_name.startswith('_'):\n                self[collection_name].delete()\n        return", "response": "drops all public collections from the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AQLQuery(self, query, batchSize = 100, rawResults = False, bindVars = {}, options = {}, count = False, fullCount = False,\n                 json_encoder = None, **moreArgs) :\n        \"\"\"Set rawResults = True if you want the query to return dictionnaries instead of Document objects.\n        You can use **moreArgs to pass more arguments supported by the api, such as ttl=60 (time to live)\"\"\"\n        return AQLQuery(self, query, rawResults = rawResults, batchSize = batchSize, bindVars  = bindVars, options = options, count = count, fullCount = fullCount,\n                        json_encoder = json_encoder, **moreArgs)", "response": "AQL Query for the current version of the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an explanation of the query", "response": "def explainAQLQuery(self, query, bindVars={}, allPlans = False) :\n        \"\"\"Returns an explanation of the query. Setting allPlans to True will result in ArangoDB returning all possible plans. False returns only the optimal plan\"\"\"\n        payload = {'query' : query, 'bindVars' : bindVars, 'allPlans' : allPlans}\n        request = self.connection.session.post(self.explainURL, data = json.dumps(payload, default=str))\n        return request.json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the server answer is the query is valid. Raises an AQLQueryError if not", "response": "def validateAQLQuery(self, query, bindVars = None, options = None) :\n        \"returns the server answer is the query is valid. Raises an AQLQueryError if not\"\n        if bindVars is None :\n            bindVars = {}\n        if options is None :\n            options = {}\n        payload = {'query' : query, 'bindVars' : bindVars, 'options' : options}\n        r = self.connection.session.post(self.cursorsURL, data = json.dumps(payload, default=str))\n        data = r.json()\n        if r.status_code == 201 and not data[\"error\"] :\n            return data\n        else :\n            raise AQLQueryError(data[\"errorMessage\"], query, data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transaction(self, collections, action, waitForSync = False, lockTimeout = None, params = None) :\n        payload = {\n                \"collections\": collections,\n                \"action\": action,\n                \"waitForSync\": waitForSync}\n        if lockTimeout is not None:\n                payload[\"lockTimeout\"] = lockTimeout\n        if params is not None:\n            payload[\"params\"] = params\n\n        self.connection.reportStart(action)\n\n        r = self.connection.session.post(self.transactionURL, data = json.dumps(payload, default=str))\n\n        self.connection.reportItem()\n\n        data = r.json()\n\n        if (r.status_code == 200 or r.status_code == 201 or r.status_code == 202) and not data.get(\"error\") :\n            return data\n        else :\n            raise TransactionError(data[\"errorMessage\"], action, data)", "response": "Execute a server - side transaction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget patches as a dictionary", "response": "def getPatches(self) :\n        \"\"\"get patches as a dictionary\"\"\"\n        if not self.mustValidate :\n            return self.getStore()\n\n        res = {}\n        res.update(self.patchStore)\n        for k, v in self.subStores.items() :\n            res[k] = v.getPatches()\n        \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the inner store as dictionary", "response": "def getStore(self) :\n        \"\"\"get the inner store as dictionary\"\"\"\n        res = {}\n        res.update(self.store)\n        for k, v in self.subStores.items() :\n            res[k] = v.getStore()\n        \n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the whole document", "response": "def validate(self) :\n        \"\"\"Validate the whole document\"\"\"\n        if not self.mustValidate :\n            return True\n\n        res = {}\n        for field in self.validators.keys() :\n            try :\n                if isinstance(self.validators[field], dict) and field not in self.store :\n                    self.store[field] = DocumentStore(self.collection, validators = self.validators[field], initDct = {}, subStore=True, validateInit=self.validateInit)\n                self.validateField(field)\n            except InvalidDocument as e :\n                res.update(e.errors)\n            except (ValidationError, SchemaViolation) as e:\n                res[field] = str(e)\n\n        if len(res) > 0 :\n            raise InvalidDocument(res)\n        \n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the store using a dictionary", "response": "def set(self, dct) :\n        \"\"\"Set the store using a dictionary\"\"\"\n        # if not self.mustValidate :\n        #     self.store = dct\n        #     self.patchStore = dct\n        #     return\n\n        for field, value in dct.items() :\n            if field not in self.collection.arangoPrivates :\n                if isinstance(value, dict) :\n                    if field in self.validators and isinstance(self.validators[field], dict):\n                        vals = self.validators[field]\n                    else :\n                        vals = {}\n                    self[field] = DocumentStore(self.collection, validators = vals, initDct = value, patch = self.patching, subStore=True, validateInit=self.validateInit)\n                    self.subStores[field] = self.store[field]\n                else :\n                    self[field] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self, collection, jsonFieldInit = None) :\n        if not jsonFieldInit:\n            jsonFieldInit = {}\n        \"\"\"replaces the current values in the document by those in jsonFieldInit\"\"\"\n        self.collection = collection\n        self.connection = self.collection.connection\n        self.documentsURL = self.collection.documentsURL\n\n\n        self.URL = None\n        self.setPrivates(jsonFieldInit)\n        self._store = DocumentStore(self.collection, validators=self.collection._fields, initDct=jsonFieldInit)\n        if self.collection._validation['on_load']:\n            self.validate()\n\n        self.modified = True", "response": "reset the document to the original state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the document to the database by either performing a POST or PUT.", "response": "def save(self, waitForSync = False, **docArgs) :\n        \"\"\"Saves the document to the database by either performing a POST (for a new document) or a PUT (complete document overwrite).\n        If you want to only update the modified fields use the .patch() function.\n        Use docArgs to put things such as 'waitForSync = True' (for a full list cf ArangoDB's doc).\n        It will only trigger a saving of the document if it has been modified since the last save. If you want to force the saving you can use forceSave()\"\"\"\n        payload = self._store.getStore()\n        self._save(payload, waitForSync = False, **docArgs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves a copy of the object and become that copy. returns a tuple ( old _key new _key )", "response": "def saveCopy(self) :\n        \"saves a copy of the object and become that copy. returns a tuple (old _key, new _key)\"\n        old_key = self._key\n        self.reset(self.collection)\n        self.save()\n        return (old_key, self._key)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the document by only updating the modified fields.", "response": "def patch(self, keepNull = True, **docArgs) :\n        \"\"\"Saves the document by only updating the modified fields.\n        The default behaviour concening the keepNull parameter is the opposite of ArangoDB's default, Null values won't be ignored\n        Use docArgs for things such as waitForSync = True\"\"\"\n\n        if self.URL is None :\n            raise ValueError(\"Cannot patch a document that was not previously saved\")\n\n        payload = self._store.getPatches()\n        \n        if self.collection._validation['on_save'] :\n            self.validate()\n\n        if len(payload) > 0 :\n            params = dict(docArgs)\n            params.update({'collection': self.collection.name, 'keepNull' : keepNull})\n            payload = json.dumps(payload, default=str)\n\n            r = self.connection.session.patch(self.URL, params = params, data = payload)\n            data = r.json()\n            if (r.status_code == 201 or r.status_code == 202) and \"error\" not in data :\n                self._rev = data['_rev']\n            else :\n                raise UpdateError(data['errorMessage'], data)\n\n            self.modified = False\n\n        self._store.resetPatch()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self) :\n        \"deletes the document from the database\"\n        if self.URL is None :\n            raise DeletionError(\"Can't delete a document that was not saved\")\n        r = self.connection.session.delete(self.URL)\n        data = r.json()\n\n        if (r.status_code != 200 and r.status_code != 202) or 'error' in data :\n            raise DeletionError(data['errorMessage'], data)\n        self.reset(self.collection)\n\n        self.modified = True", "response": "deletes the document from the database"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getEdges(self, edges, inEdges = True, outEdges = True, rawResults = False) :\n        try :\n            return edges.getEdges(self, inEdges, outEdges, rawResults)\n        except AttributeError :\n            raise AttributeError(\"%s does not seem to be a valid Edges object\" % edges)", "response": "returns in out or both edges linked to self belonging the collection edges."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the store in a dict format", "response": "def getStore(self) :\n        \"\"\"return the store in a dict format\"\"\"\n        store = self._store.getStore()\n        for priv in self.privates :\n            v = getattr(self, priv)\n            if v :\n                store[priv] = v\n        return store"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the links between two tables.", "response": "def links(self, fromVertice, toVertice, **edgeArgs) :\n        \"\"\"\n        An alias to save that updates the _from and _to attributes.\n        fromVertice and toVertice, can be either strings or documents. It they are unsaved documents, they will be automatically saved.\n        \"\"\"\n        if isinstance(fromVertice, Document) or isinstance(getattr(fromVertice, 'document', None), Document):\n            if not fromVertice._id :\n                fromVertice.save()\n            self._from = fromVertice._id\n        elif (type(fromVertice) is bytes) or (type(fromVertice) is str):\n            self._from  = fromVertice\n        elif not self._from:\n            raise CreationError('fromVertice %s is invalid!' % str(fromVertice))\n        \n        if isinstance(toVertice, Document) or isinstance(getattr(toVertice, 'document', None), Document):\n            if not toVertice._id:\n                toVertice.save()\n            self._to = toVertice._id\n        elif (type(toVertice) is bytes) or (type(toVertice) is str):\n            self._to = toVertice\n        elif not self._to:\n            raise CreationError('toVertice %s is invalid!' % str(toVertice))\n        \n        self.save(**edgeArgs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nworking like Document s except that you must specify _from and _to vertices before saving.", "response": "def save(self, **edgeArgs) :\n        \"\"\"Works like Document's except that you must specify '_from' and '_to' vertices before.\n        There's also a links() function especially for first saves.\"\"\"\n\n        if not getattr(self, \"_from\") or not getattr(self, \"_to\") :\n            raise AttributeError(\"You must specify '_from' and '_to' attributes before saving. You can also use the function 'links()'\")\n\n        payload = self._store.getStore()\n        payload[\"_from\"] = self._from\n        payload[\"_to\"] = self._to\n        Document._save(self, payload, **edgeArgs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set(self, jsonData) :\n        \n        self[\"username\"] = jsonData[\"user\"]\n        self[\"active\"] = jsonData[\"active\"]\n        self[\"extra\"] = jsonData[\"extra\"]\n        try:\n            self[\"changePassword\"] = jsonData[\"changePassword\"]\n        except Exception as e:\n            pass\n            # self[\"changePassword\"] = \"\"\n        \n        try :\n            self[\"password\"] = jsonData[\"passwd\"]\n        except KeyError :\n            self[\"password\"] = \"\"\n\n        self.URL = \"%s/user/%s\" % (self.connection.URL, self[\"username\"])", "response": "Initialize all fields at once."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngranting revoke rights on a database.", "response": "def setPermissions(self, dbName, access) :\n        \"\"\"Grant revoke rights on a database, 'access' is supposed to be boolean. ArangoDB grants/revokes both read and write rights at the same time\"\"\"\n        import json\n\n        if not self.URL :\n            raise CreationError(\"Please save user first\", None, None)\n\n        rights = []\n        if access :\n            rights.append(\"rw\")\n\n        rights = ''.join(rights)\n\n        if not self.connection.hasDatabase(dbName) :\n            raise KeyError(\"Unknown database: %s\" % dbName)\n\n        url = \"%s/database/%s\" % (self.URL, dbName)\n        r = self.connection.session.put(url, data = json.dumps({\"grant\": rights}, default=str))\n        if r.status_code < 200 or r.status_code > 202 :\n            raise CreationError(\"Unable to grant rights\", r.content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetchAllUsers(self, rawResults = False) :\n        r = self.connection.session.get(self.URL)\n        if r.status_code == 200 :\n            data = r.json()\n            if rawResults :\n                return data[\"result\"]\n            else :\n                res = []\n                for resu in data[\"result\"] :\n                    u = User(self, resu)\n                    res.append(u)\n                return res\n        else :\n            raise ConnectionError(\"Unable to get user list\", r.url, r.status_code)", "response": "Returns all available users."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a single user.", "response": "def fetchUser(self, username, rawResults = False) :\n        \"\"\"Returns a single user. if rawResults, the result will be a list of python dicts instead of User objects\"\"\"\n        url = \"%s/%s\" % (self.URL, username)\n\n        r = self.connection.session.get(url)\n        if r.status_code == 200 :\n            data = r.json()\n            if rawResults :\n                return data[\"result\"]\n            else :\n                u = User(self, data)\n                return u\n        else :\n            raise KeyError(\"Unable to get user: %s\" % username)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreloads the database list.", "response": "def reload(self) :\n        \"\"\"Reloads the database list.\n        Because loading a database triggers the loading of all collections and graphs within,\n        only handles are loaded when this function is called. The full databases are loaded on demand when accessed\n        \"\"\"\n\n        r = self.session.get(self.databasesURL)\n\n        data = r.json()\n        if r.status_code == 200 and not data[\"error\"] :\n            self.databases = {}\n            for dbName in data[\"result\"] :\n                if dbName not in self.databases :\n                    self.databases[dbName] = DBHandle(self, dbName)\n        else :\n            raise ConnectionError(data[\"errorMessage\"], self.databasesURL, r.status_code, r.content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing dbArgs for arguments other than name. for a full list of arguments please have a look at arangoDB s doc", "response": "def createDatabase(self, name, **dbArgs) :\n        \"use dbArgs for arguments other than name. for a full list of arguments please have a look at arangoDB's doc\"\n        dbArgs['name'] = name\n        payload = json.dumps(dbArgs, default=str)\n        url = self.URL + \"/database\"\n        r = self.session.post(url, data = payload)\n        data = r.json()\n        if r.status_code == 201 and not data[\"error\"] :\n            db = Database(self, name)\n            self.databases[name] = db\n            return self.databases[name]\n        else :\n            raise CreationError(data[\"errorMessage\"], r.content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an explanation of the query", "response": "def explain(self, bindVars={}, allPlans = False) :\n        \"\"\"Returns an explanation of the query. Setting allPlans to True will result in ArangoDB returning all possible plans. False returns only the optimal plan\"\"\"\n        return self.database.explainAQLQuery(self.query, bindVars, allPlans)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef output(self, args):\n        '''\n        Print the output message.\n        '''\n        print(\"SensuPlugin: {}\".format(' '.join(str(a) for a in args)))", "response": "Print the output message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a dynamic method for each of the exit codes.", "response": "def __make_dynamic(self, method):\n        '''\n        Create a method for each of the exit codes.\n        '''\n        def dynamic(*args):\n            self.plugin_info['status'] = method\n            if not args:\n                args = None\n            self.output(args)\n            sys.exit(getattr(self.exit_code, method))\n\n        method_lc = method.lower()\n        dynamic.__doc__ = \"%s method\" % method_lc\n        dynamic.__name__ = method_lc\n        setattr(self, dynamic.__name__, dynamic)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the event object and run the event handler.", "response": "def run(self):\n        '''\n        Set up the event object, global settings and command line\n        arguments.\n        '''\n\n        # Parse the stdin into a global event object\n        stdin = self.read_stdin()\n        self.event = self.read_event(stdin)\n\n        # Prepare global settings\n        self.settings = get_settings()\n        self.api_settings = self.get_api_settings()\n\n        # Prepare command line arguments and\n        self.parser = argparse.ArgumentParser()\n\n        # set up the 2.x to 1.x event mapping argument\n        self.parser.add_argument(\"--map-v2-event-into-v1\",\n                                 action=\"store_true\",\n                                 default=False,\n                                 dest=\"v2event\")\n\n        if hasattr(self, 'setup'):\n            self.setup()\n        (self.options, self.remain) = self.parser.parse_known_args()\n\n        # map the event if required\n        if (self.options.v2event or\n                os.environ.get(\"SENSU_MAP_V2_EVENT_INTO_V1\")):\n            self.event = map_v2_event_into_v1(self.event)\n\n        # Filter (deprecated) and handle\n        self.filter()\n        self.handle()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the event from a piped check result into a global event dict.", "response": "def read_event(self, check_result):\n        '''\n        Convert the piped check result (json) into a global 'event' dict\n        '''\n        try:\n            event = json.loads(check_result)\n            event['occurrences'] = event.get('occurrences', 1)\n            event['check'] = event.get('check', {})\n            event['client'] = event.get('client', {})\n            return event\n        except Exception:\n            raise ValueError('error reading event: ' + check_result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self):\n        '''\n        Filters exit the proccess if the event should not be handled.\n        Filtering events is deprecated and will be removed in a future release.\n        '''\n\n        if self.deprecated_filtering_enabled():\n            print('warning: event filtering in sensu-plugin is deprecated,' +\n                  'see http://bit.ly/sensu-plugin')\n            self.filter_disabled()\n            self.filter_silenced()\n            self.filter_dependencies()\n\n            if self.deprecated_occurrence_filtering():\n                print('warning: occurrence filtering in sensu-plugin is' +\n                      'deprecated, see http://bit.ly/sensu-plugin')\n                self.filter_repeated()", "response": "Filter the event for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bail(self, msg):\n        '''\n        Gracefully terminate with message\n        '''\n        client_name = self.event['client'].get('name', 'error:no-client-name')\n        check_name = self.event['check'].get('name', 'error:no-check-name')\n        print('{}: {}/{}'.format(msg, client_name, check_name))\n        sys.exit(0)", "response": "Gracefully terminate with message\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict of API settings derived from the current environment variable SENSU_API_URL and SENSU_API_PORT if set otherwise fall back to ipv4 localhost address on default API port.", "response": "def get_api_settings(self):\n        '''\n        Return a dict of API settings derived first from ENV['SENSU_API_URL']\n        if set, then Sensu config `api` scope if configured, and finally\n        falling back to to ipv4 localhost address on default API port.\n\n        return dict\n        '''\n\n        sensu_api_url = os.environ.get('SENSU_API_URL')\n        if sensu_api_url:\n            uri = urlparse(sensu_api_url)\n            api_settings = {\n                'host': '{0}://{1}'.format(uri.scheme, uri.hostname),\n                'port': uri.port,\n                'user': uri.username,\n                'password': uri.password\n            }\n        else:\n            api_settings = self.settings.get('api', {})\n            api_settings['host'] = api_settings.get(\n                'host', '127.0.0.1')\n            api_settings['port'] = api_settings.get(\n                'port', 4567)\n\n        return api_settings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nquery Sensu api for information.", "response": "def api_request(self, method, path):\n        '''\n        Query Sensu api for information.\n        '''\n        if not hasattr(self, 'api_settings'):\n            ValueError('api.json settings not found')\n\n        if method.lower() == 'get':\n            _request = requests.get\n        elif method.lower() == 'post':\n            _request = requests.post\n\n        domain = self.api_settings['host']\n        uri = '{}:{}/{}'.format(domain, self.api_settings['port'], path)\n        if self.api_settings.get('user') and self.api_settings.get('password'):\n            auth = (self.api_settings['user'], self.api_settings['password'])\n        else:\n            auth = ()\n        req = _request(uri, auth=auth)\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef event_exists(self, client, check):\n        '''\n        Query Sensu API for event.\n        '''\n        return self.api_request(\n            'get',\n            'events/{}/{}'.format(client, check)\n            ).status_code == 200", "response": "Check if an event exists in the specified client."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering out any alerts that have been silenced.", "response": "def filter_silenced(self):\n        '''\n        Determine whether a check is silenced and shouldn't handle.\n        '''\n        stashes = [\n            ('client', '/silence/{}'.format(self.event['client']['name'])),\n            ('check', '/silence/{}/{}'.format(\n                self.event['client']['name'],\n                self.event['check']['name'])),\n            ('check', '/silence/all/{}'.format(self.event['check']['name']))\n        ]\n        for scope, path in stashes:\n            if self.stash_exists(path):\n                self.bail(scope + ' alerts silenced')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_dependencies(self):\n        '''\n        Determine whether a check has dependencies.\n        '''\n        dependencies = self.event['check'].get('dependencies', None)\n        if dependencies is None or not isinstance(dependencies, list):\n            return\n        for dependency in self.event['check']['dependencies']:\n            if not str(dependency):\n                continue\n            dependency_split = tuple(dependency.split('/'))\n            # If there's a dependency on a check from another client, then use\n            # that client name, otherwise assume same client.\n            if len(dependency_split) == 2:\n                client, check = dependency_split\n            else:\n                client = self.event['client']['name']\n                check = dependency_split[0]\n            if self.event_exists(client, check):\n                self.bail('check dependency event exists')", "response": "Filter out the check s dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine whether a check is repeating.", "response": "def filter_repeated(self):\n        '''\n        Determine whether a check is repeating.\n        '''\n        defaults = {\n            'occurrences': 1,\n            'interval': 30,\n            'refresh': 1800\n        }\n\n        # Override defaults with anything defined in the settings\n        if isinstance(self.settings['sensu_plugin'], dict):\n            defaults.update(self.settings['sensu_plugin'])\n\n        occurrences = int(self.event['check'].get(\n            'occurrences', defaults['occurrences']))\n        interval = int(self.event['check'].get(\n            'interval', defaults['interval']))\n        refresh = int(self.event['check'].get(\n            'refresh', defaults['refresh']))\n\n        if self.event['occurrences'] < occurrences:\n            self.bail('not enough occurrences')\n\n        if (self.event['occurrences'] > occurrences and\n                self.event['action'] == 'create'):\n            return\n\n        number = int(refresh / interval)\n        if (number == 0 or\n                (self.event['occurrences'] - occurrences) % number == 0):\n            return\n\n        self.bail('only handling every ' + str(number) + ' occurrences')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_files():\n    '''\n    Get list of currently used config files.\n    '''\n    sensu_loaded_tempfile = os.environ.get('SENSU_LOADED_TEMPFILE')\n    sensu_config_files = os.environ.get('SENSU_CONFIG_FILES')\n    sensu_v1_config = '/etc/sensu/config.json'\n    sensu_v1_confd = '/etc/sensu/conf.d'\n    if sensu_loaded_tempfile and os.path.isfile(sensu_loaded_tempfile):\n        with open(sensu_loaded_tempfile, 'r') as tempfile:\n            contents = tempfile.read()\n            return contents.split(':')\n    elif sensu_config_files:\n        return sensu_config_files.split(':')\n    else:\n        files = []\n        filenames = []\n        if os.path.isfile(sensu_v1_config):\n            files = [sensu_v1_config]\n        if os.path.isdir(sensu_v1_confd):\n            filenames = [f for f in os.listdir(sensu_v1_confd)\n                         if os.path.splitext(f)[1] == '.json']\n            for filename in filenames:\n                files.append('{}/{}'.format(sensu_v1_confd, filename))\n        return files", "response": "Get list of currently used config files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_settings():\n    '''\n    Get all currently loaded settings.\n    '''\n    settings = {}\n    for config_file in config_files():\n        config_contents = load_config(config_file)\n        if config_contents is not None:\n            settings = deep_merge(settings, config_contents)\n    return settings", "response": "Get all currently loaded settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_config(filename):\n    '''\n    Read contents of config file.\n    '''\n    try:\n        with open(filename, 'r') as config_file:\n            return json.loads(config_file.read())\n    except IOError:\n        pass", "response": "Load the contents of a config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_name(self, name=None):\n        '''\n        Checks the plugin name and sets it accordingly.\n        Uses name if specified, class name if not set.\n        '''\n        if name:\n            self.plugin_info['check_name'] = name\n\n        if self.plugin_info['check_name'] is not None:\n            return self.plugin_info['check_name']\n\n        return self.__class__.__name__", "response": "Checks the plugin name and sets it accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes an instance and save it to db.", "response": "def create(cls, path_name=None, name=None, project_id=None,\n               log_modified_at=None, crawlable=True):\n        \"\"\"Initialize an instance and save it to db.\"\"\"\n        result = cls(path_name, name, project_id, log_modified_at, crawlable)\n\n        db.session.add(result)\n        db.session.commit()\n\n        crawl_result(result, True)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sampled_logs(self, logs_limit=-1):\n        logs_count = len(self.logs)\n        if logs_limit == -1 or logs_count <= logs_limit:\n            return self.logs\n        elif logs_limit == 0:\n            return []\n        elif logs_limit == 1:\n            return [self.logs[-1]]\n        else:\n            def get_sampled_log(idx):\n                # always include the first and last element of `self.logs`\n                return self.logs[idx * (logs_count - 1) // (logs_limit - 1)]\n            return [get_sampled_log(i) for i in range(logs_limit)]", "response": "Return up to logs_limit logs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialize_with_sampled_logs(self, logs_limit=-1):\n\n        return {\n            'id': self.id,\n            'pathName': self.path_name,\n            'name': self.name,\n            'isUnregistered': self.is_unregistered,\n            'logs': [log.serialize for log in self.sampled_logs(logs_limit)],\n            'args': self.args.serialize if self.args is not None else [],\n            'commands': [cmd.serialize for cmd in self.commands],\n            'snapshots': [cmd.serialize for cmd in self.snapshots],\n            'logModifiedAt': self.log_modified_at.isoformat()\n        }", "response": "serialize a result with up to logs_limit logs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reporter(prefix=None, out=None, subdir='', timeout=5, **kwargs):\n\n    report = _Reporter(prefix, out, subdir, **kwargs)\n    yield report\n    report.save(timeout)", "response": "A context manager which returns a context manager which collects and displays the media assets in same row as the current ChainerUI summary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef audio(audio, sample_rate, name=None, out=None, subdir='', timeout=5,\n          **kwargs):\n    \"\"\"summary audio files to listen on a browser.\n\n    An sampled array is converted as WAV audio file, saved to output directory,\n    and reported to the ChainerUI server. The audio file is saved every called\n    this function. The audio file will be listened on `assets` endpoint\n    vertically. If need to aggregate audio files in row, use\n    :func:`~chainerui.summary.reporter`.\n\n    Example of how to set arguments::\n\n       >>> from chainerui import summary\n       >>> summary.set_out('/path/to/output')\n       >>> rate = 44100\n       >>>\n       >>> summary.audio(sampled_array, rate, name='test')\n       >>> # sampled_array can be listened on a browser.\n\n    Add description about the audio file::\n\n       >>> summary.image(\n       >>>     sampled_array, rate, name='test', epoch=1, iteration=100)\n       >>> # 'epoch' and 'iteration' column will be shown.\n\n    Args:\n        audio (:class:`numpy.ndarray` or :class:`cupy.ndarray` or \\\n            :class:`chainer.Variable`): sampled wave array.\n        sample_rate (int): sampling rate.\n        name (str): name of image. set as column name. when not setting,\n            assigned ``'audio'``.\n        out (str): directory path of output.\n        subdir (str): sub-directory path of output.\n        **kwargs (dict): key-value pair to show as description. regardless of\n            empty or not, timestamp on created the image is added.\n    \"\"\"\n\n    from chainerui.report.audio_report import check_available\n    if not check_available():\n        return\n    from chainerui.report.audio_report import report as _audio\n\n    out_root = _chainerui_asset_observer.get_outpath(out)\n    out_path = os.path.join(out_root, subdir)\n    if not os.path.isdir(out_path):\n        os.makedirs(out_path)\n    col_name = name\n    if col_name is None:\n        col_name = 'audio'\n    filename, created_at = _audio(audio, sample_rate, out_path, col_name)\n\n    value = kwargs\n    value['timestamp'] = created_at.isoformat()\n    value['audios'] = {col_name: os.path.join(subdir, filename)}\n    _chainerui_asset_observer.add(value)\n    _chainerui_asset_observer.save(out_root, timeout)", "response": "This function will create a summary audio file for the given audio array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef image(self, images, name=None, ch_axis=1, row=0, mode=None,\n              batched=True, subdir=''):\n        \"\"\"Summary images to visualize.\n\n        Args:\n            images (:class:`numpy.ndarray` or :class:`cupy.ndarray` or \\\n                :class:`chainer.Variable`): batch of images. If Number of\n                dimension is 3 (or 2 when set `batched=False`), the pixels\n                assume as black and white image.\n            name (str): name of image. set as column name. when not setting,\n                assigned ``'image'`` + sequential number.\n            ch_axis (int): index number of channel dimension. set 1 by default.\n                if the images don't have channel axis, this parameter is\n                ignored.\n            row (int): row size to visualize batched images. when set 0,\n                show on unstuck. if images set only one image, the row size\n                will be ignored.\n            mode (str): if the images are not RGB or RGBA space, set their\n                color space code. ChainerUI supports 'HSV'.\n            batched (bool): if the image is not batched, set ``False``.\n            subdir (str): sub-directory path of output.\n        \"\"\"\n        from chainerui.report.image_report import check_available\n        if not check_available():\n            return\n        from chainerui.report.image_report import report as _image\n\n        col_name = self.get_col_name(name, 'image')\n        out_dir, rel_out_dir = self.get_subdir(subdir)\n        filename, _ = _image(\n            images, out_dir, col_name, ch_axis, row, mode, batched)\n        self.images[col_name] = os.path.join(rel_out_dir, filename)\n\n        self.count += 1", "response": "Summary images to visualize."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_app():\n\n    app = Flask(__name__)\n    app.logger.disabled = True\n    for h in app.logger.handlers[:]:\n        app.logger.removeHandler(h)\n    app.config['JSONIFY_PRETTYPRINT_REGULAR'] = False\n\n    def dated_url_for(endpoint, **values):\n        \"\"\"dated_url_for.\"\"\"\n        if endpoint == 'static':\n            filename = values.get('filename', None)\n            if filename:\n                file_path = os.path.join(app.root_path, endpoint, filename)\n                values['_'] = int(os.stat(file_path).st_mtime)\n        return url_for(endpoint, **values)\n\n    @app.context_processor\n    def override_url_for():\n        \"\"\"override_url_for.\"\"\"\n        return dict(url_for=dated_url_for)\n\n    @app.teardown_appcontext\n    def shutdown_session(exception=None):\n        db.session.remove()\n\n    @app.route('/')\n    @app.route('/projects/<int:project_id>')\n    @app.route('/projects/<int:project_id>/results/<int:result_id>')\n    @app.route('/projects/<int:project_id>/results/<int:result_id>/assets')\n    def index(**kwargs):\n        \"\"\"render react app.\"\"\"\n        return render_template('index.html')\n\n    @app.route('/favicon.ico')\n    def favicon():\n        return send_from_directory(\n            os.path.join(app.root_path, 'static', 'dist'),\n            'favicon.ico', mimetype='image/vnd.microsoft.icon')\n\n    # error handling\n    @app.errorhandler(OperationalError)\n    def handle_invalid_usage(error):\n        \"\"\"handle errors caused by db query.\"\"\"\n        logger.error('caught exception from db: %s' % error.args)\n        response = jsonify({\n            'error': {\n                'type': 'DBOperationalError',\n                'message': 'Failed to send request to the database.'\n            }\n        })\n        response.status_code = 400  # Bad Request\n\n        return response\n\n    @app.before_request\n    def add_timestamp():\n        request._comming_at = datetime.datetime.now()\n\n    @app.after_request\n    def output_log(response):\n        now = datetime.datetime.now()\n        log_msg = '%s - - [%s] \"%s %s %s\" %d' % (\n            request.remote_addr, now.replace(microsecond=0),\n            request.method, request.full_path,\n            request.environ.get('SERVER_PROTOCOL'), response.status_code)\n        if response.content_length is not None:\n            log_msg += ' %d' % response.content_length\n        if request._comming_at is not None:\n            delta = (now - request._comming_at).total_seconds()\n            log_msg += ' %.6f' % delta\n        logger.info(log_msg)\n        return response\n\n    from chainerui.views.argument import ArgumentAPI\n    from chainerui.views.log import LogAPI\n    from chainerui.views.project import ProjectAPI\n    from chainerui.views.result import ResultAPI\n    from chainerui.views.result_asset import ResultAssetAPI\n    from chainerui.views.result_command import ResultCommandAPI\n\n    project_resource = ProjectAPI.as_view('project_resource')\n    result_resource = ResultAPI.as_view('result_resource')\n    log_resource = LogAPI.as_view('log_resource')\n    arg_resource = ArgumentAPI.as_view('arg_resource')\n    result_command_resource = ResultCommandAPI.as_view(\n        'result_command_resource')\n    result_assets_resource = ResultAssetAPI.as_view('result_assets_resource')\n\n    # project API\n    app.add_url_rule(\n        '/api/v1/projects',\n        defaults={'id': None}, view_func=project_resource, methods=['GET'])\n    app.add_url_rule(\n        '/api/v1/projects', view_func=project_resource, methods=['POST'])\n    app.add_url_rule(\n        '/api/v1/projects/<int:id>',\n        view_func=project_resource, methods=['GET', 'PUT', 'DELETE'])\n\n    # result API\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results',\n        defaults={'id': None}, view_func=result_resource, methods=['GET'])\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results',\n        view_func=result_resource, methods=['POST'])\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:id>',\n        view_func=result_resource, methods=['GET', 'PUT', 'DELETE'])\n\n    # result log API\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:result_id>/logs',\n        view_func=log_resource, methods=['POST'])\n    # result argument API\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:result_id>/args',\n        view_func=arg_resource, methods=['POST'])\n\n    # result command API\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:result_id>/commands',\n        view_func=result_command_resource, methods=['POST'])\n\n    # result image API\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:result_id>/assets',\n        view_func=result_assets_resource, methods=['GET'])\n    app.add_url_rule(\n        '/api/v1/projects/<int:project_id>/results/<int:result_id>/assets/<int:content_id>',  # NOQA\n        view_func=result_assets_resource, methods=['GET'])\n\n    return app", "response": "create app with all routes and views"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialize(self):\n\n        if self.request is None:\n            request = None\n        else:\n            request = json.loads(self.request)\n\n        if self.response is None:\n            response = None\n        else:\n            response = json.loads(self.response)\n\n        return {\n            'id': self.id,\n            'name': self.name,\n            'request': request,\n            'response': response\n        }", "response": "Serialize the object to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post(self, result_id, project_id):\n\n        result = db.session.query(Result).filter_by(id=result_id).first()\n\n        if result is None:\n            return jsonify({\n                'result': None,\n                'message': 'No interface defined for URL.'\n            }), 404\n\n        job_status = CommandsState.job_status(result.path_name)\n        if job_status != JobStatus.RUNNING:\n            if job_status == JobStatus.NO_EXTENSION_ERROR:\n                return jsonify({\n                    'message': '\\'CommandsExtension\\' is not set or disabled.'\n                }), 400\n            elif job_status == JobStatus.INITIALIZED:\n                return jsonify({\n                    'message': 'The target training job has not run, yet'\n                }), 400\n            elif job_status == JobStatus.STOPPED:\n                return jsonify({\n                    'message': 'The target training job has already stopped'\n                }), 400\n            else:\n                return jsonify({\n                    'message': 'Cannot get the target training job status'\n                }), 400\n\n        request_json = request.get_json()\n        if request_json is None:\n            return jsonify({\n                'message': 'Empty request.'\n            }), 400\n\n        command_name = request_json.get('name', None)\n        if command_name is None:\n            return jsonify({\n                'message': 'Name is required.'\n            }), 400\n\n        schedule = request_json.get('schedule', None)\n        if not CommandItem.is_valid_schedule(schedule):\n            return jsonify({\n                'message': 'Schedule is invalid.'\n            }), 400\n\n        command = CommandItem(\n            name=command_name,\n        )\n\n        command.set_request(\n            CommandItem.REQUEST_OPEN,\n            request_json.get('body', None),\n            request_json.get('schedule', None)\n        )\n\n        commands = CommandItem.load_commands(result.path_name)\n        commands.append(command)\n\n        CommandItem.dump_commands(commands, result.path_name)\n\n        new_result = crawl_result(result, force=True)\n        new_result_dict = new_result.serialize\n\n        return jsonify({'commands': new_result_dict['commands']})", "response": "POST method for the CommandItem."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes an instance and save it to db.", "response": "def create(cls, result_id=None, summary=None, file_modified_at=None):\n        \"\"\"Initialize an instance and save it to db.\"\"\"\n        asset = cls(result_id, summary, file_modified_at)\n\n        db.session.add(asset)\n        db.session.commit()\n\n        return asset"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes an instance and save it to db.", "response": "def create(cls, path_name=None, name=None, crawlable=True):\n        \"\"\"initialize an instance and save it to db.\"\"\"\n\n        project = cls(path_name, name, crawlable)\n\n        db.session.add(project)\n        db.session.commit()\n\n        return collect_results(project, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning migrations in online mode.", "response": "def run_migrations_online(config):\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine and associate a\n    connection with the context.\n\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section),\n        prefix='sqlalchemy.',\n        poolclass=pool.NullPool)\n\n    with connectable.connect() as connection:\n        alembic.context.configure(connection=connection)\n\n        with alembic.context.begin_transaction():\n            alembic.context.run_migrations()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    config = context.config\n    config.set_main_option(\"sqlalchemy.url\", config.get_main_option('url'))\n    run_migrations_online(config)", "response": "Main function for the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, id=None):\n\n        if id is None:\n            path = request.args.get('path_name', default=None)\n            if path is not None:\n                project = db.session.query(Project).filter_by(\n                    path_name=path).first()\n                if project is None:\n                    return jsonify({\n                        'project': None,\n                        'message': 'Project path \\'%s\\' is not found' % path\n                    }), 400\n                return jsonify({'project': project.serialize})\n\n            projects = db.session.query(Project).all()\n            return jsonify({\n                'projects': [p.serialize for p in projects]\n            })\n\n        else:\n            project = db.session.query(Project).filter_by(id=id).first()\n            if project is None:\n                return jsonify({\n                    'project': None,\n                    'message': 'No interface defined for URL.'\n                }), 404\n            return jsonify({\n                'project': project.serialize\n            })", "response": "Get a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the resource with the given ID.", "response": "def put(self, id):\n        \"\"\"put.\"\"\"\n\n        project = db.session.query(Project).filter_by(id=id).first()\n\n        if project is None:\n            return jsonify({\n                'project': None,\n                'message': 'No interface defined for URL.'\n            }), 404\n\n        request_project = request.get_json().get('project')\n        project_name = request_project.get('name', None)\n\n        if project_name is not None:\n            project.name = project_name\n\n        db.session.add(project)\n        db.session.commit()\n\n        return jsonify({\n            'project': project.serialize\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, id):\n        project = db.session.query(Project).filter_by(id=id).first()\n\n        if project is None:\n            response = jsonify({\n                'projects': None,\n                'message': 'No interface defined for URL.'\n            })\n            return response, 404\n\n        db.session.delete(project)\n        db.session.commit()\n\n        return jsonify({\n            'project': project.serialize\n        })", "response": "Delete a resource from the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollecting assets from meta file", "response": "def collect_assets(result, force=False):\n    \"\"\"collect assets from meta file\n\n    Collecting assets only when the metafile is updated. If number of assets\n    are decreased, assets are reset and re-collect the assets.\n    \"\"\"\n    path_name = result.path_name\n    info_path = os.path.join(path_name, summary.CHAINERUI_ASSETS_METAFILE_NAME)\n    if not os.path.isfile(info_path):\n        return\n    start_idx = len(result.assets)\n    file_modified_at = datetime.datetime.fromtimestamp(os.path.getmtime(\n        info_path))\n    if start_idx > 0:\n        if result.assets[-1].file_modified_at == file_modified_at:\n            return\n\n    with open(info_path, 'r') as f:\n        info_list = json.load(f, object_pairs_hook=OrderedDict)\n\n    if len(info_list) < start_idx:\n        start_idx = 0\n        result.assets = []\n\n    for base_info in info_list[start_idx:]:\n        asset_path = base_info.pop('images', {})\n        asset_path.update(base_info.pop('audios', {}))\n        asset = Asset.create(\n            result_id=result.id, summary=base_info,\n            file_modified_at=file_modified_at)\n        for key, path in asset_path.items():\n            with open(os.path.join(path_name, path), 'rb') as f:\n                data = f.read()\n            content = Bindata(\n                asset_id=asset.id, name=path, tag=key, content=data)\n            asset.content_list.append(content)\n        result.assets.append(asset)\n\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_args(conditions, out_path):\n\n    if isinstance(conditions, argparse.Namespace):\n        args = vars(conditions)\n    else:\n        args = conditions\n\n    try:\n        os.makedirs(out_path)\n    except OSError:\n        pass\n\n    with tempdir(prefix='args', dir=out_path) as tempd:\n        path = os.path.join(tempd, 'args.json')\n        with open(path, 'w') as f:\n            json.dump(args, f, indent=4)\n\n        new_path = os.path.join(out_path, 'args')\n        shutil.move(path, new_path)", "response": "A utility function to save experiment conditions for a job table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist the paths of the log files in the target_path.", "response": "def _list_result_paths(target_path, log_file_name='log'):\n    \"\"\"list_result_paths.\"\"\"\n\n    result_list = []\n\n    for root, _dirs, _files in os.walk(os.path.abspath(target_path)):\n        for name in _files:\n            if name == log_file_name:\n                result_list.append(root)\n\n    return result_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a single object from the database.", "response": "def get(self, id=None, project_id=None):\n        \"\"\"get.\"\"\"\n        logs_limit = request.args.get('logs_limit', default=-1, type=int)\n\n        project = db.session.query(Project).filter_by(\n            id=project_id).first()\n        if project is None:\n            return jsonify({\n                'project': None,\n                'message': 'No interface defined for URL.'\n            }), 404\n\n        if id is None:\n            path = request.args.get('path_name', default=None)\n            if path is not None:\n                result = db.session.query(Result).filter_by(\n                    path_name=path).first()\n                if result is None:\n                    return jsonify({\n                        'result': None,\n                        'message': 'Result path \\'%s\\' is not found' % path\n                    }), 400\n                return jsonify({'result': result.serialize})\n\n            collect_results(project)\n\n            results = db.session.query(Result).\\\n                filter_by(project_id=project_id).\\\n                filter_by(is_unregistered=False).\\\n                all()\n\n            # NOTE: To improve performance, aggregate commit phase. By set\n            # `commit=False`, implicit transaction is not closed, UPDATE query\n            # is not committed. Consequently a process of serializing does not\n            # have to call SELECT query again.\n            for result in results:\n                crawl_result(result, commit=False)\n            db.session.commit()\n            rs = [r.serialize_with_sampled_logs(logs_limit) for r in results]\n\n            return jsonify({'results': rs})\n\n        else:\n\n            result = db.session.query(Result).\\\n                filter_by(id=id).\\\n                filter_by(is_unregistered=False).\\\n                first()\n\n            if result is None:\n                return jsonify({\n                    'result': None,\n                    'message': 'No interface defined for URL.'\n                }), 404\n\n            result = crawl_result(result)\n\n            return jsonify({\n                'result': result.serialize_with_sampled_logs(logs_limit)\n            })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put(self, id, project_id=None):\n        result = db.session.query(Result).filter_by(id=id).first()\n        if result is None:\n            response = jsonify({\n                'result': None, 'message': 'No interface defined for URL.'\n            })\n            return response, 404\n\n        request_json = request.get_json()\n        request_result = request_json.get('result')\n\n        name = request_result.get('name', None)\n        if name is not None:\n            result.name = name\n\n        is_unregistered = request_result.get('isUnregistered', None)\n        if is_unregistered is not None:\n            result.is_unregistered = is_unregistered\n\n        db.session.add(result)\n        db.session.commit()\n\n        return jsonify({'result': result.serialize})", "response": "Update a resource in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a resource from the database.", "response": "def delete(self, id, project_id=None):\n        \"\"\"delete.\"\"\"\n        result = db.session.query(Result).filter_by(id=id).first()\n        if result is None:\n            response = jsonify({\n                'result': None, 'message': 'No interface defined for URL.'\n            })\n            return response, 404\n\n        db.session.delete(result)\n        db.session.commit()\n\n        return jsonify({'result': result.serialize})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_is_alive(url):\n    request = urllib.request.Request(url)\n    request.get_method = lambda: 'HEAD'\n\n    try:\n        urllib.request.urlopen(request)\n        return True\n    except urllib.request.HTTPError:\n        return False", "response": "Checks that a given URL is reachable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef form_option(str_opt):\n    '''generate option name based suffix for URL\n\n    :param str_opt: opt name\n    :type str_opt: str\n    :return: URL suffix for the specified option\n    :rtype: str\n    '''\n\n    str_base = '#cmdoption-arg-'\n    str_opt_x = str_base+str_opt.lower()\\\n        .replace('_', '-')\\\n        .replace('(', '-')\\\n        .replace(')', '')\n    return str_opt_x", "response": "generate option name based suffix for URL\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a URL for option based on source", "response": "def gen_url_option(\n    str_opt, \n    set_site=set_site, \n    set_runcontrol=set_runcontrol, \n    set_initcond=set_initcond, \n    source='docs'):\n    '''construct a URL for option based on source \n\n    :param str_opt: option name, defaults to ''\n    :param str_opt: str, optional\n    :param source: URL source: 'docs' for readthedocs.org; 'github' for github repo, defaults to 'docs'\n    :param source: str, optional\n    :return: a valid URL pointing to the option related resources\n    :rtype: urlpath.URL\n    '''\n    dict_base = {\n        'docs': URL('https://suews-docs.readthedocs.io/en/latest/input_files/'),\n        'github': URL('https://github.com/Urban-Meteorology-Reading/SUEWS-Docs/raw/master/docs/source/input_files/'),\n    }\n    url_base = dict_base[source]\n\n    url_page = choose_page(\n        str_opt, set_site, set_runcontrol, set_initcond, source=source)\n    # print('str_opt', str_opt, url_base, url_page)\n    str_opt_x = form_option(str_opt)\n    url_opt = url_base/(url_page+str_opt_x)\n    return url_opt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating description info of supy forcing data into a dataframe", "response": "def gen_df_forcing(\n        path_csv_in='SSss_YYYY_data_tt.csv',\n        url_base=url_repo_input,)->pd.DataFrame:\n    '''Generate description info of supy forcing data into a dataframe\n\n    Parameters\n    ----------\n    path_csv_in : str, optional\n        path to the input csv file relative to url_base (the default is '/input_files/SSss_YYYY_data_tt.csv'])\n    url_base : urlpath.URL, optional\n        URL to the input files of repo base (the default is url_repo_input, which is defined at the top of this file)\n\n    Returns\n    -------\n    pd.DataFrame\n        Description info of supy forcing data\n    '''\n\n    try:\n        # load info from SUEWS docs repo\n        # this is regarded as the official source\n        urlpath_table = url_base/path_csv_in\n        df_var_info = pd.read_csv(urlpath_table)\n    except:\n        print(f'{urlpath_table} not existing!')\n    else:\n        # clean info dataframe\n        df_var_forcing = df_var_info.drop(['No.', 'Use'], axis=1)\n\n        # set index with `Column name`\n        df_var_forcing = df_var_forcing.set_index('Column Name')\n        df_var_forcing.index = df_var_forcing.index\\\n            .map(lambda x: x.replace('`', ''))\\\n            .rename('variable')\n\n        # add `Second` info\n        df_var_forcing.loc['isec'] = 'Second [S]'\n\n        return df_var_forcing"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_df_output(\n        list_csv_in=[\n            'SSss_YYYY_SUEWS_TT.csv',\n            'SSss_DailyState.csv',\n            'SSss_YYYY_snow_TT.csv',\n        ],\n        url_base=url_repo_output)->Path:\n    '''Generate description info of supy output results into dataframe\n\n    Parameters\n    ----------\n    list_csv_in : list, optional\n        list of file names for csv files with meta info (the default is ['SSss_YYYY_SUEWS_TT.csv','SSss_DailyState.csv','SSss_YYYY_snow_TT.csv',], which [default_description])\n    url_base : [type], optional\n        URL to the output dir of repo base (the default is url_repo_output, which is defined at the top of this file)\n\n    Returns\n    -------\n    pd.DataFrame\n         Description info of supy output results\n    '''\n\n    # list of URLs\n    list_url_table = [\n        url_base/table for table in list_csv_in\n    ]\n    try:\n        df_var_info = pd.concat(\n            [pd.read_csv(f) for f in list_url_table],\n            sort=False)\n    except:\n        for url in list_url_table:\n            if not url.get().ok:\n                print(f'{url} not existing!')\n    else:\n        # clean meta info\n        df_var_info_x = df_var_info\\\n            .set_index('Name')\\\n            .loc[:, ['Description']]\\\n            .drop_duplicates()\n\n        df_var_output = df_var_info_x\\\n            .copy()\\\n            .assign(lower=df_var_info_x.index.str.lower())\\\n            .reset_index()\\\n            .set_index('lower')\n\n        df_var_group = df_output_sample.columns.to_frame()\n        df_var_group.index = df_var_group.index.droplevel(0).rename('Name')\n\n        # wrap into a dataframe\n        df_var_output = df_var_group\\\n            .merge(\n                df_var_output.set_index('Name'),\n                left_on='Name',\n                right_on='Name')\\\n            .rename(columns={\n                'var': 'variable',\n                'group': 'Group',\n            })\\\n            .set_index('variable')\\\n            .drop_duplicates()\n\n        return df_var_output", "response": "Generate description info of supy output results into dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gen_opt_str(ser_rec: pd.Series)->str:\n    '''generate rst option string\n\n    Parameters\n    ----------\n    ser_rec : pd.Series\n        record for specifications\n\n    Returns\n    -------\n    str\n        rst string\n    '''\n\n    name = ser_rec.name\n    indent = r'    '\n    str_opt = f'.. option:: {name}'+'\\n\\n'\n    for spec in ser_rec.sort_index().index:\n        str_opt += indent+f':{spec}:'+'\\n'\n        spec_content = ser_rec[spec]\n        str_opt += indent+indent+f'{spec_content}'+'\\n'\n    return str_opt", "response": "generate rst option string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_day_clm(df_var, fig=None, ax=None, **kwargs):\n    if fig is None and ax is None:\n        fig, ax = plt.subplots()\n    elif fig is None:\n        fig = ax.get_figure()\n    elif ax is None:\n        ax = fig.gca()\n    # plt.clf()\n    # group by hour and minute\n    grp_sdf_var = df_var.groupby(\n        [df_var.index.hour.rename('hr'),\n         df_var.index.minute.rename('min')])\n    # get index\n    idx = [pd.datetime(2014, 1, 1, h, m)\n           for h, m in sorted(grp_sdf_var.groups.keys())]\n    idx = pd.date_range(idx[0], idx[-1], periods=len(idx))\n    idx = mdates.date2num(idx)\n\n    # calculate quartiles\n    quar_sel_pos_clm = grp_sdf_var.quantile(\n        [.75, .5, .25]).unstack().set_index(idx)\n    # fig, ax = plt.subplots(1)\n\n    for var in quar_sel_pos_clm.columns.levels[0]:\n        df_x = quar_sel_pos_clm.loc[:, var]\n        y0 = df_x[0.5]\n        y1, y2 = df_x[0.75], df_x[0.25]\n        y0.plot(ax=ax, label=var).fill_between(\n            quar_sel_pos_clm.index, y1, y2, alpha=0.3)\n    # add legend\n    ax.legend(title='variable')\n    # adjust xticks formar\n    ax.xaxis.set_major_locator(mdates.HourLocator(byhour=np.arange(0, 23, 3)))\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n\n    return fig, ax", "response": "Short summary.\n\n    Parameters\n    ----------\n    df_var : pd.DataFrame\n        DataFrame containing variables to plot with datetime as index\n\n    Returns\n    -------\n    MPL.figure\n        figure showing median lines and IQR in shadings"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_comp(df_var, fig=None, ax=None, **kwargs):\n    if fig is None and ax is None:\n        fig, ax = plt.subplots()\n    elif fig is None:\n        fig = ax.get_figure()\n    elif ax is None:\n        ax = fig.gca()\n    # plt.clf()\n    # plt.cla()\n    # ax = sns.regplot(\n    #     x='Obs', y='Sim',\n    #     data=df_var,\n    #     fit_reg=True)\n\n    # add regression expression\n    df_var_fit = df_var.dropna(how='any')\n    # regr = linear_model.LinearRegression()\n    # val_x = df_var_fit['Obs'].values.reshape(-1, 1)\n    # val_y = df_var_fit['Sim'].values.reshape(-1, 1)\n    # regr.fit(val_x, val_y)\n    val_x = df_var_fit['Obs']\n    val_y = df_var_fit['Sim']\n    slope, intercept, r_value, p_value, std_err = stats.linregress(\n        val_x, val_y)\n    mae = (val_y - val_x).abs().mean()\n\n    sns.regplot(\n        x='Obs', y='Sim',\n        data=df_var,\n        ax=ax,\n        fit_reg=True,\n        line_kws={\n            'label': \"y={0:.2f}x{1}{2:.2f}\".format(slope, '+' if intercept>0 else '', intercept) +\n            '\\n' + '$R^2$={0:.4f}'.format(r_value) +\n            '\\n' + 'MAE={0:.2f}'.format(mae) +\n            '\\n' + 'n={}'.format(df_var.shape[0])\n        },\n        **kwargs\n    )\n    # ax.plot(val_x, y_pred, color='red', linewidth=2,\n    #         label='r2= ' + str(\"%.3f\" % r2) + '\\n' +\n    #         'y=' + str(\"%.3f\" % a[0][0]) + 'x+' + str(\"%.2f\" % b[0]))\n\n    # ax.legend(fontsize=15)\n    ax.legend()\n    # ax.set_title(var + '_' + title)\n\n    # set equal plotting range\n    x0, x1 = ax.get_xlim()\n    y0, y1 = ax.get_ylim()\n    lim_low, lim_high = np.min([x0, y0]), np.max([x1, y1])\n    ax.set_xlim(lim_low, lim_high)\n    ax.set_ylim(lim_low, lim_high)\n\n    # set 1:1 aspect ratio\n    ax.set_aspect('equal')\n\n    # add 1:1 line\n    ax.plot([lim_low, lim_high], [lim_low, lim_high],\n            color='red', linewidth=1, zorder=0)\n\n    # fig = ax.figure\n\n    return fig, ax", "response": "Short summary.\n\n    Parameters\n    ----------\n    df_var : pd.DataFrame\n        DataFrame containing variables to plot with datetime as index\n\n    Returns\n    -------\n    MPL.figure\n        figure showing 1:1 line plot"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_supy(path_init: str)->pd.DataFrame:\n    '''Initialise supy by loading initial model states.\n\n    Parameters\n    ----------\n    path_init : str\n        Path to a file that can initialise SuPy, which can be either of the follows:\n            * SUEWS :ref:`RunControl.nml<suews:RunControl.nml>`: a namelist file for SUEWS configurations\n            * SuPy `df_state.csv`: a CSV file including model states produced by a SuPy run via :py:func:`supy.save_supy`\n\n    Returns\n    -------\n    df_state_init: pandas.DataFrame\n        Initial model states.\n        See `df_state_var` for details.\n\n    Examples\n    --------\n    1. Use :ref:`RunControl.nml<suews:RunControl.nml>` to initialise SuPy\n\n    >>> path_init = \"~/SUEWS_sims/RunControl.nml\"\n    >>> df_state_init = supy.init_supy(path_init)\n\n    2. Use ``df_state.csv`` to initialise SuPy\n\n    >>> path_init = \"~/SuPy_res/df_state_test.csv\"\n    >>> df_state_init = supy.init_supy(path_init)\n\n    '''\n\n    try:\n        path_init_x = Path(path_init).expanduser().resolve()\n    except FileNotFoundError:\n        print('{path} does not exists!'.format(path=path_init_x))\n    else:\n        if path_init_x.suffix == '.nml':\n            # SUEWS `RunControl.nml`:\n            df_state_init = load_InitialCond_grid_df(path_init_x)\n        elif path_init_x.suffix == '.csv':\n            # SuPy `df_state.csv`:\n            df_state_init = load_df_state(path_init_x)\n        else:\n            print('{path} is NOT a valid file to initialise SuPy!'.format(\n                path=path_init_x))\n            sys.exit()\n        return df_state_init", "response": "Initialise a single SuPy by loading initial model states."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_forcing_grid(path_runcontrol: str, grid: int)->pd.DataFrame:\n    '''Load forcing data for a specific grid included in the index of `df_state_init </data-structure/supy-io.ipynb#df_state_init:-model-initial-states>`.\n\n    Parameters\n    ----------\n    path_runcontrol : str\n        Path to SUEWS :ref:`RunControl.nml <suews:RunControl.nml>`\n    grid : int\n        Grid number\n\n    Returns\n    -------\n    df_forcing: pandas.DataFrame\n        Forcing data. See `df_forcing_var` for details.\n\n    Examples\n    --------\n    >>> path_runcontrol = \"~/SUEWS_sims/RunControl.nml\"  # a valid path to `RunControl.nml`\n    >>> df_state_init = supy.init_supy(path_runcontrol) # get `df_state_init`\n    >>> grid = df_state_init.index[0] # first grid number included in `df_state_init`\n    >>> df_forcing = supy.load_forcing_grid(path_runcontrol, grid) # get df_forcing\n\n\n    '''\n\n    try:\n        path_runcontrol = Path(path_runcontrol).expanduser().resolve()\n    except FileNotFoundError:\n        print('{path} does not exists!'.format(path=path_runcontrol))\n    else:\n        dict_mod_cfg = load_SUEWS_dict_ModConfig(path_runcontrol)\n        df_state_init = init_supy(path_runcontrol)\n\n        # load setting variables from dict_mod_cfg\n        (\n            filecode,\n            kdownzen,\n            tstep_met_in,\n            tstep_ESTM_in,\n            multiplemetfiles,\n            multipleestmfiles,\n            dir_input_cfg\n        ) = (dict_mod_cfg[x] for x in\n             [\n            'filecode',\n            'kdownzen',\n            'resolutionfilesin',\n            'resolutionfilesinestm',\n            'multiplemetfiles',\n            'multipleestmfiles',\n            'fileinputpath'\n        ]\n        )\n        tstep_mod, lat, lon, alt, timezone = df_state_init.loc[\n            grid,\n            [(x, '0') for x in ['tstep', 'lat', 'lng', 'alt', 'timezone']]\n        ].values\n\n        path_site = path_runcontrol.parent\n        path_input = path_site / dict_mod_cfg['fileinputpath']\n\n        # load raw data\n        # met forcing\n        df_forcing_met = load_SUEWS_Forcing_met_df_raw(\n            path_input, filecode, grid, tstep_met_in, multiplemetfiles)\n\n        # resample raw data from tstep_in to tstep_mod\n        df_forcing_met_tstep = resample_forcing_met(\n            df_forcing_met, tstep_met_in, tstep_mod,\n            lat, lon, alt, timezone, kdownzen)\n\n        # merge forcing datasets (met and ESTM)\n        df_forcing_tstep = df_forcing_met_tstep.copy()\n\n        # disable the AnOHM and ESTM components for now and for better performance\n        # |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n        # TS 28 Dec 2018\n        # pack all records of `id` into `metforcingdata_grid` for AnOHM\n        # df_grp = df_forcing_tstep.groupby('id')\n        # dict_id_all = {xid: df_grp.get_group(xid)\n        #                for xid in df_forcing_tstep['id'].unique()}\n        # id_all = df_forcing_tstep['id'].apply(lambda xid: dict_id_all[xid])\n        # df_forcing_tstep = df_forcing_tstep.merge(\n        #     id_all.to_frame(name='metforcingdata_grid'),\n        #     left_index=True,\n        #     right_index=True)\n        # # add Ts forcing for ESTM\n        # if np.asscalar(df_state_init.iloc[0]['storageheatmethod'].values) == 4:\n        #     # load ESTM forcing\n        #     df_forcing_estm = load_SUEWS_Forcing_ESTM_df_raw(\n        #         path_input, filecode, grid, tstep_ESTM_in, multipleestmfiles)\n        #     # resample raw data from tstep_in to tstep_mod\n        #     df_forcing_estm_tstep = resample_linear(\n        #         df_forcing_estm, tstep_met_in, tstep_mod)\n        #     df_forcing_tstep = df_forcing_tstep.merge(\n        #         df_forcing_estm_tstep,\n        #         left_on=['iy', 'id', 'it', 'imin'],\n        #         right_on=['iy', 'id', 'it', 'imin'])\n        #     # insert `ts5mindata_ir` into df_forcing_tstep\n        #     ts_col = df_forcing_estm.columns[4:]\n        #     df_forcing_tstep['ts5mindata_ir'] = (\n        #         df_forcing_tstep.loc[:, ts_col].values.tolist())\n        #     df_forcing_tstep['ts5mindata_ir'] = df_forcing_tstep[\n        #         'ts5mindata_ir'].map(lambda x: np.array(x, order='F'))\n        # else:\n        #     # insert some placeholder values\n        #     df_forcing_tstep['ts5mindata_ir'] = df_forcing_tstep['Tair']\n        # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        # disable the AnOHM and ESTM components for now and for better performance\n\n        # coerced precision here to prevent numerical errors inside Fortran\n        df_forcing = np.around(df_forcing_tstep, decimals=10)\n        # new columns for later use in main calculation\n        df_forcing[['iy', 'id', 'it', 'imin']] = df_forcing[[\n            'iy', 'id', 'it', 'imin']].astype(np.int64)\n\n    return df_forcing", "response": "Load forcing data for a specific grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_SampleData()->Tuple[pandas.DataFrame, pandas.DataFrame]:\n    '''Load sample data for quickly starting a demo run.\n\n    Returns\n    -------\n    df_state_init, df_forcing: Tuple[pandas.DataFrame, pandas.DataFrame]\n        - df_state_init: `initial model states <df_state_var>`\n        - df_forcing: `forcing data <df_forcing_var>`\n\n    Examples\n    --------\n\n    >>> df_state_init, df_forcing = supy.load_SampleData()\n\n    '''\n\n    path_SampleData = Path(path_supy_module) / 'sample_run'\n    path_runcontrol = path_SampleData / 'RunControl.nml'\n    df_state_init = init_supy(path_runcontrol)\n    # path_input = path_runcontrol.parent / ser_mod_cfg['fileinputpath']\n    df_forcing = load_forcing_grid(\n        path_runcontrol,\n        df_state_init.index[0]\n    )\n    return df_state_init, df_forcing", "response": "Load sample data for quickly starting a demo run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming supy simulation. Parameters ---------- df_forcing : pandas.DataFrame forcing data for all grids in `df_state_init`. df_state_init : pandas.DataFrame initial model states; or a collection of model states with multiple timestamps, whose last temporal record will be used as the initial model states. save_state : bool, optional flag for saving model states at each time step, which can be useful in diagnosing model runtime performance or performing a restart run. (the default is False, which instructs supy not to save runtime model states). n_yr : int, optional chunk size (`n_yr` years) to split simulation periods so memory usage can be reduced. (the default is 10, which implies 10-year forcing chunks used in simulations). Returns ------- df_output, df_state_final : Tuple[pandas.DataFrame, pandas.DataFrame] - df_output: `output results <df_output_var>` - df_state_final: `final model states <df_state_var>` Examples -------- >>> df_output, df_state_final = supy.run_supy(df_forcing, df_state_init)", "response": "def run_supy(\n        df_forcing: pandas.DataFrame,\n        df_state_init: pandas.DataFrame,\n        save_state=False,\n        n_yr=10,\n)->Tuple[pandas.DataFrame, pandas.DataFrame]:\n    '''Perform supy simulation.\n\n    Parameters\n    ----------\n    df_forcing : pandas.DataFrame\n        forcing data for all grids in `df_state_init`.\n    df_state_init : pandas.DataFrame\n        initial model states;\n        or a collection of model states with multiple timestamps, whose last temporal record will be used as the initial model states.\n    save_state : bool, optional\n        flag for saving model states at each time step, which can be useful in diagnosing model runtime performance or performing a restart run.\n        (the default is False, which instructs supy not to save runtime model states).\n    n_yr : int, optional\n        chunk size (`n_yr` years) to split simulation periods so memory usage can be reduced.\n        (the default is 10, which implies 10-year forcing chunks used in simulations).\n\n    Returns\n    -------\n    df_output, df_state_final : Tuple[pandas.DataFrame, pandas.DataFrame]\n        - df_output: `output results <df_output_var>`\n        - df_state_final: `final model states <df_state_var>`\n\n    Examples\n    --------\n\n    >>> df_output, df_state_final = supy.run_supy(df_forcing, df_state_init)\n\n\n    '''\n\n    # save df_init without changing its original data\n    # df.copy() in pandas does work as a standard python deepcopy\n    df_init = df_state_init.copy()\n\n    # retrieve the last temporal record as `df_init`\n    # if a `datetime` level existing in the index\n    if df_init.index.nlevels > 1:\n        idx_dt = df_init.index.get_level_values('datetime').unique()\n        dt_last = idx_dt.max()\n        df_init = df_init.loc[dt_last]\n    # add placeholder variables for df_forcing\n    # `metforcingdata_grid` and `ts5mindata_ir` are used by AnOHM and ESTM, respectively\n    # they are now temporarily disabled in supy\n    df_forcing = df_forcing\\\n        .assign(\n            metforcingdata_grid=0,\n            ts5mindata_ir=0,\n        )\\\n        .rename(\n            # remanae is a workaround to resolve naming inconsistency between\n            # suews fortran code interface and input forcing file hearders\n            columns={\n                '%' + 'iy': 'iy',\n                'id': 'id',\n                'it': 'it',\n                'imin': 'imin',\n                'qn': 'qn1_obs',\n                'qh': 'qh_obs',\n                'qe': 'qe',\n                'qs': 'qs_obs',\n                'qf': 'qf_obs',\n                'U': 'avu1',\n                'RH': 'avrh',\n                'Tair': 'temp_c',\n                'pres': 'press_hpa',\n                'rain': 'precip',\n                'kdown': 'avkdn',\n                'snow': 'snow_obs',\n                'ldown': 'ldown_obs',\n                'fcld': 'fcld_obs',\n                'Wuh': 'wu_m3',\n                'xsmd': 'xsmd',\n                'lai': 'lai_obs',\n                'kdiff': 'kdiff',\n                'kdir': 'kdir',\n                'wdir': 'wdir',\n            }\n        )\n    # grid list determined by initial states\n    list_grid = df_init.index\n\n    # initialise dicts for holding results and model states\n    dict_state = {}\n    dict_output = {}\n\n    # initial and final tsteps retrieved from forcing data\n    tstep_init = df_forcing.index[0]\n    tstep_final = df_forcing.index[-1]\n    # tstep size retrieved from forcing data\n    freq = df_forcing.index.freq\n\n    # dict_state is used to save model states for later use\n    dict_state = {\n        # (t_start, grid): series_state_init.to_dict()\n        (tstep_init, grid): pack_grid_dict(series_state_init)\n        for grid, series_state_init\n        in df_init.iterrows()\n    }\n\n    # remove 'problems.txt'\n    if Path('problems.txt').exists():\n        os.remove('problems.txt')\n\n    if save_state:\n        # use slower more functional single step wrapper\n\n        # convert df to dict with `itertuples` for better performance\n        dict_forcing = {row.Index: row._asdict()\n                        for row in df_forcing.itertuples()}\n\n        for tstep in df_forcing.index:\n            # temporal loop\n            # initialise output of tstep:\n            # load met_forcing if the same across all grids:\n            met_forcing_tstep = dict_forcing[tstep]\n            # spatial loop\n            for grid in list_grid:\n                dict_state_start = dict_state[(tstep, grid)]\n                # calculation at one step:\n                # series_state_end, series_output_tstep = suews_cal_tstep_df(\n                #     series_state_start, met_forcing_tstep)\n                dict_state_end, dict_output_tstep = suews_cal_tstep(\n                    dict_state_start, met_forcing_tstep)\n\n                # update output & model state at tstep for the current grid\n                dict_output.update({(tstep, grid): dict_output_tstep})\n                dict_state.update({(tstep + 1*freq, grid): dict_state_end})\n\n        # pack results as easier DataFrames\n        df_output = pack_df_output(dict_output).swaplevel(0, 1)\n        # drop unnecessary 'datetime' as it is already included in the index\n        df_output = df_output.drop(columns=['datetime'], level=0)\n        df_state_final = pack_df_state(dict_state).swaplevel(0, 1)\n\n    else:\n        # for multi-year run, reduce the whole df_forcing into {n_yr}-year chunks for less memory consumption\n        grp_forcing_yr = df_forcing.groupby(df_forcing.index.year // n_yr)\n        if len(grp_forcing_yr) > 1:\n            df_state_init_yr = df_state_init.copy()\n            list_df_output = []\n            list_df_state = []\n            for grp in grp_forcing_yr.groups:\n                # get forcing of a specific year\n                df_forcing_yr = grp_forcing_yr.get_group(grp)\n                # run supy: actual execution done in the `else` clause below\n                df_output_yr, df_state_final_yr = run_supy(\n                    df_forcing_yr, df_state_init_yr)\n                df_state_init_yr = df_state_final_yr.copy()\n                # collect results\n                list_df_output.append(df_output_yr)\n                list_df_state.append(df_state_final_yr)\n\n            # re-organise results of each year\n            df_output = pd.concat(list_df_output).sort_index()\n            df_state_final = pd.concat(\n                list_df_state).sort_index().drop_duplicates()\n            return df_output, df_state_final\n\n        else:\n            # for single-chunk run (1 chunk = {n_yr} years), directly put df_forcing into supy_driver for calculation\n            # use higher level wrapper that calculate at a `block` level\n            # for better performance\n\n            # for grid in list_grid:\n            #     dict_state_start_grid = dict_state[(tstep_init, grid)]\n            #     dict_state_end, dict_output_array = suews_cal_tstep_multi(\n            #         dict_state_start_grid,\n            #         df_forcing)\n            #     # update output & model state at tstep for the current grid\n            #     dict_output.update({grid: dict_output_array})\n            #     # model state for the next run\n            #     dict_state.update({(tstep_final + freq, grid): dict_state_end})\n\n\n            # # parallel run of grid_list for better efficiency\n            # if os.name == 'nt':\n            #     if __name__ == '__main__':\n            #         p = Pool(min([len(list_grid), cpu_count()]))\n            # else:\n            #     p = Pool(min([len(list_grid), cpu_count()]))\n\n            # # construct input list for `Pool.starmap`\n            # construct input list for `dask.bag`\n            list_input = [\n                # (dict_state[(tstep_init, grid)], df_forcing)\n                dict_state[(tstep_init, grid)]\n                for grid in list_grid\n            ]\n\n            # on windows `processes` has issues when importing\n            # so set `threads` here\n            method_parallel = 'threads' if os.name == 'nt' else 'processes'\n            list_res = db.from_sequence(list_input)\\\n                .map(suews_cal_tstep_multi, df_forcing)\\\n                .compute(scheduler=method_parallel)\n            list_state_end, list_output_array = zip(*list_res)\n\n            # collect output arrays\n            dict_output = {\n                grid: dict_output_array\n                for grid, dict_output_array in zip(list_grid, list_output_array)\n            }\n\n            # collect final states\n            dict_state_final_tstep = {\n                (tstep_final + freq, grid): dict_state_end\n                for grid, dict_state_end in zip(list_grid, list_state_end)\n            }\n            dict_state.update(dict_state_final_tstep)\n\n            # save results as time-aware DataFrame\n            df_output0 = pack_df_output_array(dict_output, df_forcing)\n            df_output = df_output0.replace(-999., np.nan)\n            df_state_final = pack_df_state(dict_state).swaplevel(0, 1)\n\n    # drop ESTM for now as it is not supported yet\n    # select only those supported output groups\n    df_output = df_output.loc[:, ['SUEWS', 'snow', 'DailyState']]\n    # trim multiindex based columns\n    df_output.columns = df_output.columns.remove_unused_levels()\n\n    # pack final model states into a proper dataframe\n    df_state_final = pack_df_state_final(df_state_final, df_init)\n\n    return df_output, df_state_final"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_supy(\n        df_output: pandas.DataFrame,\n        df_state_final: pandas.DataFrame,\n        freq_s: int = 3600,\n        site: str = '',\n        path_dir_save: str = Path('.'),\n        path_runcontrol: str = None,)->list:\n    '''Save SuPy run results to files\n\n    Parameters\n    ----------\n    df_output : pandas.DataFrame\n        DataFrame of output\n    df_state_final : pandas.DataFrame\n        DataFrame of final model states\n    freq_s : int, optional\n        Output frequency in seconds (the default is 3600, which indicates hourly output)\n    site : str, optional\n        Site identifier (the default is '', which indicates site identifier will be left empty)\n    path_dir_save : str, optional\n        Path to directory to saving the files (the default is Path('.'), which indicates the current working directory)\n    path_runcontrol : str, optional\n        Path to SUEWS :ref:`RunControl.nml <suews:RunControl.nml>`, which, if set, will be preferably used to derive `freq_s`, `site` and `path_dir_save`.\n        (the default is None, which is unset)\n\n    Returns\n    -------\n    list\n        a list of paths of saved files\n\n    Examples\n    --------\n    1. save results of a supy run to the current working directory with default settings\n\n    >>> list_path_save = supy.save_supy(df_output, df_state_final)\n\n\n    2. save results according to settings in :ref:`RunControl.nml <suews:RunControl.nml>`\n\n    >>> list_path_save = supy.save_supy(df_output, df_state_final, path_runcontrol='path/to/RunControl.nml')\n\n\n    3. save results of a supy run at resampling frequency of 1800 s (i.e., half-hourly results) under the site code ``Test`` to a customised location 'path/to/some/dir'\n\n    >>> list_path_save = supy.save_supy(df_output, df_state_final, freq_s=1800, site='Test', path_dir_save='path/to/some/dir')\n    '''\n\n    # get necessary information for saving procedure\n    if path_runcontrol is not None:\n        freq_s, path_dir_save, site = get_save_info(path_runcontrol)\n\n    # save df_output to several files\n    list_path_save = save_df_output(df_output, freq_s, site, path_dir_save)\n\n    # save df_state\n    path_state_save = save_df_state(df_state_final, site, path_dir_save)\n\n    # update list_path_save\n    list_path_save.append(path_state_save)\n    return list_path_save", "response": "Save the SuPy run results to files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshorts summary. Parameters ---------- forcingfile_met_pattern : type Description of parameter `forcingfile_met_pattern`. Returns ------- type Description of returned object.", "response": "def load_SUEWS_Forcing_met_df_pattern(path_input, forcingfile_met_pattern):\n    \"\"\"Short summary.\n\n    Parameters\n    ----------\n    forcingfile_met_pattern : type\n        Description of parameter `forcingfile_met_pattern`.\n\n    Returns\n    -------\n    type\n        Description of returned object.\n\n    \"\"\"\n\n    # list of met forcing files\n    path_input = path_input.resolve()\n    # forcingfile_met_pattern = os.path.abspath(forcingfile_met_pattern)\n    list_file_MetForcing = sorted([\n        f for f in path_input.glob(forcingfile_met_pattern)\n        if 'ESTM' not in f.name])\n\n    # print(forcingfile_met_pattern)\n    # print(list_file_MetForcing)\n    # load raw data\n    # read in forcing with dask.dataframe in parallel\n    dd_forcing_met = dd.read_csv(\n        list_file_MetForcing,\n        delim_whitespace=True,\n        comment='!',\n        error_bad_lines=True\n    )\n    # convert to normal pandas dataframe\n    df_forcing_met = dd_forcing_met.compute()\n    # `drop_duplicates` in case some duplicates mixed\n    df_forcing_met = df_forcing_met.drop_duplicates()\n    col_suews_met_forcing = [\n        'iy', 'id', 'it', 'imin',\n        'qn', 'qh', 'qe', 'qs', 'qf',\n        'U', 'RH', 'Tair', 'pres', 'rain', 'kdown',\n        'snow', 'ldown', 'fcld',\n        'Wuh', 'xsmd', 'lai', 'kdiff', 'kdir', 'wdir'\n    ]\n    # rename these columns to match variables via the driver interface\n    df_forcing_met.columns = col_suews_met_forcing\n\n    # convert unit from kPa to hPa\n    df_forcing_met['pres'] *= 10\n\n    # add `isec` for WRF-SUEWS interface\n    df_forcing_met['isec'] = 0\n\n    # set correct data types\n    df_forcing_met[['iy', 'id', 'it', 'imin', 'isec']] = df_forcing_met[[\n        'iy', 'id', 'it', 'imin', 'isec']].astype(np.int64)\n\n    # set timestamp as index\n    idx_dt = pd.date_range(\n        *df_forcing_met.iloc[[0, -1], :4].astype(int).astype(str).apply(\n            lambda ser: ser.str.cat(sep=' '), axis=1).map(\n            lambda dt: pd.Timestamp.strptime(dt, '%Y %j %H %M')),\n        periods=df_forcing_met.shape[0])\n\n    df_forcing_met = df_forcing_met.set_index(idx_dt)\n\n    return df_forcing_met"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads df_state from path_csv", "response": "def load_df_state(path_csv: Path)->pd.DataFrame:\n    '''load `df_state` from `path_csv`\n\n    Parameters\n    ----------\n    path_csv : Path\n        path to the csv file that stores `df_state` produced by a supy run\n\n    Returns\n    -------\n    pd.DataFrame\n        `df_state` produced by a supy run\n    '''\n\n    df_state = pd.read_csv(\n        path_csv,\n        header=[0, 1],\n        index_col=[0, 1],\n        parse_dates=True,\n        infer_datetime_format=True,\n    )\n    return df_state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_var_suews(dict_var_full: dict, var_supy: str)->list:\n    '''extract related SUEWS variables for a supy variable `var_supy`\n\n    Parameters\n    ----------\n    dict_var_full : dict\n        dict_var_full = sp.supy_load.exp_dict_full(sp.supy_load.dict_var2SiteSelect)\n    var_supy : str\n        supy variable name\n\n    Returns\n    -------\n    list\n        related SUEWS variables for `var_supy`\n    '''\n\n    x = sp.supy_load.flatten_list(dict_var_full[var_supy])\n    x = np.unique(x)\n    x = [\n        xx for xx in x\n        if xx not in ['base', 'const', '0.0'] + [str(x) for x in range(24)]\n    ]\n    x = [xx for xx in x if 'Code' not in xx]\n    return x", "response": "extract related SUEWS variables for a supy variable var_supy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate description info of supy output results as a dataframe", "response": "def gen_df_site(\n        list_csv_in=list_table,\n        url_base=url_repo_input_site)->pd.DataFrame:\n    '''Generate description info of supy output results as a dataframe\n\n    Parameters\n    ----------\n    path_csv_out : str, optional\n        path to the output csv file (the default is 'df_output.csv')\n    list_csv_in : list, optional\n        list of file names for csv files with meta info (the default is url_repo_input_site, which is defined at the top of this file)\n    url_base : URL, optional\n        URL to the input dir of repo base (the default is url_repo_input, which is defined at the top of this file)\n\n    Returns\n    -------\n    pd.DataFrame\n        full path to the output csv file\n    '''\n\n    # list of URLs\n    list_url_table = [\n        url_base/table for table in list_csv_in\n    ]\n    try:\n        df_var_info = pd.concat([pd.read_csv(f) for f in list_url_table])\n\n        # df_var_info = pd.concat(\n        #     [pd.read_csv(f) for f in list_url_table],\n        #     sort=False)\n    except:\n        for url in list_url_table:\n            if not url.get().ok:\n                print(f'{url} not existing!')\n    else:\n        # clean meta info\n        df_var_info_x = df_var_info\\\n            .drop(['No.', 'Use'], axis=1)\\\n            .set_index('Column Name')\n        df_var_info_x.index = df_var_info_x.index.map(\n            lambda x: x.replace('`', ''))\n\n        # retrieve SUEWS-related variables\n        dict_var_full = sp.supy_load.exp_dict_full(\n            sp.supy_load.dict_var2SiteSelect)\n        dict_var_ref_suews = {\n            k: extract_var_suews(dict_var_full, k)\n            for k in dict_var_full\n        }\n        df_var_ref_suews = pd.DataFrame(\n            {k: ', '.join(dict_var_ref_suews[k])\n             for k in dict_var_ref_suews},\n            index=[0]).T.rename({\n                0: 'SUEWS-related variables'\n            }, axis=1)\n\n        # retrive supy variable description\n        dict_var_desc = {\n            k: '\\n'.join(df_var_info_x.loc[v].values.flatten())\n            for k, v in dict_var_ref_suews.items()\n        }\n        df_var_desc = pd.DataFrame(dict_var_desc, index=[0]).T\\\n            .rename(columns={0: 'Description'})\n\n        # retrieve variable dimensionality\n        df_var_dim = gen_df_dim(df_init_sample)\n\n        df_var_site_raw = pd.concat(\n            [df_var_dim, df_var_desc, df_var_ref_suews],\n            axis=1, sort=False)\n\n        df_var_site = df_var_site_raw.filter(items=set_input, axis=0).dropna()\n\n        return df_var_site"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_rst_url_split_opts(opts_str):\n    if opts_str is not 'None':\n        list_opts = opts_str.split(',')\n        # list_rst = [gen_rst_url_opt(opt.strip()) for opt in list_opts]\n        list_rst = [opt.strip() for opt in list_opts]\n        # list_rst = [f'`{opt}`' for opt in list_rst]\n        # more properly handle SUEWS options by explicitly adding prefix `suews`:\n        list_rst = [f':option:`{opt} <suews:{opt}>`' for opt in list_rst]\n        list_url_rst = ', '.join(list_rst)\n    else:\n        list_url_rst = 'None'\n    return list_url_rst", "response": "generate option list for RST docs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate dataframe of all state variables used by supy", "response": "def gen_df_state(\n        list_table: list,\n        set_initcond: set,\n        set_runcontrol: set,\n        set_input_runcontrol: set)->pd.DataFrame:\n    '''generate dataframe of all state variables used by supy\n\n    Parameters\n    ----------\n    list_table : list\n        csv files for site info: `SUEWS_xx.csv` on github SUEWS-docs repo\n    set_initcond : set\n        initial condition related variables\n    set_runcontrol : set\n        runcontrol related variables\n    set_input_runcontrol : set\n        runcontrol related variables used as supy input\n\n    Returns\n    -------\n    pd.DataFrame\n        Description of all state variables used by supy\n    '''\n\n    # generate a base df for site characteristics related variables\n    df_var_site = gen_df_site(list_table)\n    # generate a base df for runcontrol related variables\n    df_var_runcontrol = gen_df_runcontrol(\n        set_initcond, set_runcontrol, set_input_runcontrol)\n    # generate a base df for initial condition related variables\n    df_var_initcond = gen_df_initcond(set_initcond, set_runcontrol)\n    # further processing by modifying several entries\n    df_var_state = proc_df_state(\n        df_var_site, df_var_runcontrol, df_var_initcond)\n\n    # reorganising the result:\n    df_var_state = df_var_state.sort_index()\n    # delete duplicates while considering the variable name (stored as index)\n    df_var_state = df_var_state.reset_index()\n    df_var_state = df_var_state.drop_duplicates()\n    # convert index back\n    df_var_state = df_var_state.set_index('variable')\n    return df_var_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a dataframe for saving a single group and grid", "response": "def gen_df_save(df_grid_group: pd.DataFrame)->pd.DataFrame:\n    '''generate a dataframe for saving\n\n    Parameters\n    ----------\n    df_output_grid_group : pd.DataFrame\n        an output dataframe of a single group and grid\n\n    Returns\n    -------\n    pd.DataFrame\n        a dataframe with date time info prepended for saving\n    '''\n    # generate df_datetime for prepending\n    idx_dt = df_grid_group.index\n    ser_year = pd.Series(idx_dt.year, index=idx_dt, name='Year')\n    ser_DOY = pd.Series(idx_dt.dayofyear, index=idx_dt, name='DOY')\n    ser_hour = pd.Series(idx_dt.hour, index=idx_dt, name='Hour')\n    ser_min = pd.Series(idx_dt.minute, index=idx_dt, name='Min')\n    df_datetime = pd.concat([\n        ser_year,\n        ser_DOY,\n        ser_hour,\n        ser_min,\n    ], axis=1)\n    df_datetime['Dectime'] = ser_DOY-1+idx_dt.to_perioddelta(\n        'd').total_seconds()/(24*60*60)\n    df_save = pd.concat([df_datetime, df_grid_group], axis=1)\n    return df_save"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_df_output(\n        df_output: pd.DataFrame,\n        freq_s: int = 3600,\n        site: str = '',\n        path_dir_save: Path = Path('.'),)->list:\n    '''save supy output dataframe to txt files\n\n    Parameters\n    ----------\n    df_output : pd.DataFrame\n        output dataframe of supy simulation\n    freq_s : int, optional\n        output frequency in second (the default is 3600, which indicates the a txt with hourly values)\n    path_dir_save : Path, optional\n        directory to save txt files (the default is '.', which the current working directory)\n    site : str, optional\n        site code used for filename (the default is '', which indicates no site name prepended to the filename)\n    path_runcontrol : str or anything that can be parsed as `Path`, optional\n        path to SUEWS 'RunControl.nml' file (the default is None, which indicates necessary saving options should be specified via other parameters)\n\n    Returns\n    -------\n    list\n        a list of `Path` objects for saved txt files\n    '''\n\n    list_path_save = []\n    list_group = df_output.columns.get_level_values('group').unique()\n    list_grid = df_output.index.get_level_values('grid').unique()\n    for grid in list_grid:\n        for group in list_group:\n            df_output_grid_group = df_output\\\n                .loc[grid, group]\\\n                .dropna(how='all', axis=0)\n            # save output at the runtime frequency (usually 5 min)\n            # 'DailyState' group will be save a daily frequency\n            path_save = save_df_grid_group(\n                df_output_grid_group, grid, group,\n                site=site, dir_save=path_dir_save)\n            list_path_save.append(path_save)\n\n    # resample output if freq_s is different from runtime freq (usually 5 min)\n    freq_save = pd.Timedelta(freq_s, 's')\n    # resample `df_output` at `freq_save`\n    df_rsmp = resample_output(df_output, freq_save)\n    # 'DailyState' group will be dropped in `resample_output` as resampling is not needed\n    df_rsmp = df_rsmp.drop(columns='DailyState')\n\n    list_group = df_rsmp.columns.get_level_values('group').unique()\n    list_grid = df_rsmp.index.get_level_values('grid').unique()\n    # save output at the resampling frequency\n    for grid in list_grid:\n        for group in list_group:\n            df_output_grid_group = df_rsmp.loc[grid, group]\n            path_save = save_df_grid_group(\n                df_output_grid_group, grid, group,\n                site=site, dir_save=path_dir_save)\n            list_path_save.append(path_save)\n\n    return list_path_save", "response": "save supy output dataframe to txt files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_df_state(\n        df_state: pd.DataFrame,\n        site: str = '',\n        path_dir_save: Path = Path('.'),)->Path:\n    '''save `df_state` to a csv file\n\n    Parameters\n    ----------\n    df_state : pd.DataFrame\n        a dataframe of model states produced by a supy run\n    site : str, optional\n        site identifier (the default is '', which indicates an empty site code)\n    path_dir_save : Path, optional\n        path to directory to save results (the default is Path('.'), which the current working directory)\n\n    Returns\n    -------\n    Path\n        path to the saved csv file\n    '''\n\n    file_state_save = 'df_state_{site}.csv'.format(site=site)\n    # trim filename if site == ''\n    file_state_save = file_state_save.replace('_.csv', '.csv')\n    path_state_save = path_dir_save/file_state_save\n    print('writing out: {path_out}'.format(path_out=path_state_save))\n    df_state.to_csv(path_state_save)\n    return path_state_save", "response": "save df_state to a csv file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting necessary information for saving supy results", "response": "def get_save_info(path_runcontrol: str)->Tuple[int, Path, str]:\n    '''get necessary information for saving supy results, which are (freq_s, dir_save, site)\n\n    Parameters\n    ----------\n    path_runcontrol : Path\n        Path to SUEWS :ref:`RunControl.nml <suews:RunControl.nml>`\n\n    Returns\n    -------\n    tuple\n        A tuple including (freq_s, dir_save, site):\n        freq_s: output frequency in seconds\n        dir_save: directory name to save results\n        site: site identifier\n    '''\n\n    try:\n        path_runcontrol = Path(path_runcontrol).expanduser().resolve()\n    except FileNotFoundError:\n        print('{path} does not exists!'.format(path=path_runcontrol))\n    else:\n        dict_mod_cfg = load_SUEWS_dict_ModConfig(path_runcontrol)\n        freq_s, dir_save, site = [\n            dict_mod_cfg[x] for x in\n            [\n                'resolutionfilesout',\n                'fileoutputpath',\n                'filecode',\n            ]\n        ]\n        dir_save = path_runcontrol.parent/dir_save\n        if not dir_save.exists():\n            dir_save.mkdir()\n        return freq_s, dir_save, site"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gen_FS_DF(df_output):\n    df_day = pd.pivot_table(\n        df_output,\n        values=['T2', 'U10', 'Kdown', 'RH2'],\n        index=['Year', 'Month', 'Day'],\n        aggfunc=[min, max, np.mean, ])\n    df_day_all_year = pd.pivot_table(\n        df_output,\n        values=['T2', 'U10', 'Kdown', 'RH2'],\n        index=['Month', 'Day'],\n        aggfunc=[min, max, np.mean, ])\n\n    array_yr_mon = df_day.index.droplevel(\n        'Day').to_frame().drop_duplicates().values\n\n    df_fs = pd.DataFrame(\n        {(yr, mon):\n         (df_day.loc[(yr, mon)].apply(gen_score_ser) -\n          df_day_all_year.loc[mon].apply(gen_score_ser)).abs().mean()\n         for yr, mon in array_yr_mon})\n\n    return df_fs", "response": "generate DataFrame of scores."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate DataFrame of weighted sums.", "response": "def gen_WS_DF(df_WS_data):\n    \"\"\"generate DataFrame of weighted sums.\n\n    Parameters\n    ----------\n    df_WS_data : type\n        Description of parameter `df_WS_data`.\n\n    Returns\n    -------\n    type\n        Description of returned object.\n\n    \"\"\"\n    df_fs = gen_FS_DF(df_WS_data)\n\n    list_index = [('mean', 'T2'), ('max', 'T2'), ('min', 'T2'),\n                  ('mean', 'U10'), ('max', 'U10'), ('min', 'U10'),\n                  ('mean', 'RH2'), ('max', 'RH2'), ('min', 'RH2'),\n                  ('mean', 'Kdown')]\n\n    list_const = [getattr(const, attr)\n                  for attr in ['T_MEAN', 'T_MAX', 'T_MIN',\n                               'WIND_MEAN', 'WIND_MAX', 'WIND_MIN',\n                               'RH_MEAN', 'RH_MAX', 'RH_MIN',\n                               'SOLAR_RADIATION_GLOBAL']]\n    list_ws = [df_fs.loc[idx] * cst\n               for idx, cst\n               in zip(list_index, list_const)]\n    df_ws = pd.concat(list_ws, axis=1).sum(axis=1).unstack().dropna()\n\n    return df_ws"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gen_TMY(df_output):\n    '''generate TMY (typical meteorological year) from SuPy output.\n\n    Parameters\n    ----------\n    df_output : pandas.DataFrame\n        Output from `run_supy`: longterm (e.g., >10 years) simulation results, otherwise not very useful.\n\n    '''\n\n    # calculate weighted score\n    ws = gen_WS_DF(df_output)\n\n    # select year\n    year_sel = pick_year(ws, df_output, n=5)\n\n    # generate TMY data\n    df_TMY = pd.concat(\n        # shift(1) here is to conform the convention that\n        # timestamps refer to the preceding period\n        # [df_output.shift(1).groupby(['Month', 'Year']).get_group(grp)\n        # shift(1) is not necessary\n        [df_output.groupby(['Month', 'Year']).get_group(grp)\n         for grp in year_sel.items()])\n\n    # df_TMY = df_TMY.rename(columns=dict_supy_epw)\n\n    return df_TMY", "response": "generate TMY from SuPy output."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the GEOID radius at a given latitude", "response": "def _geoid_radius(latitude: float) -> float:\n    \"\"\"Calculates the GEOID radius at a given latitude\n\n    Parameters\n    ----------\n    latitude : float\n        Latitude (degrees)\n\n    Returns\n    -------\n    R : float\n        GEOID Radius (meters)\n    \"\"\"\n    lat = deg2rad(latitude)\n    return sqrt(1/(cos(lat) ** 2 / Rmax_WGS84 ** 2 + sin(lat) ** 2 / Rmin_WGS84 ** 2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef geometric2geopotential(z: float, latitude: float) -> float:\n    twolat = deg2rad(2 * latitude)\n    g = 9.80616 * (1 - 0.002637*cos(twolat) + 0.0000059*cos(twolat)**2)\n    re = _geoid_radius(latitude)\n    return z * g * re / (re + z)", "response": "Converts geometric height to geopoential height"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a geopoential height to a geometric height.", "response": "def geopotential2geometric(h: float, latitude: float) -> float:\n    \"\"\"Converts geopoential height to geometric height\n\n    Parameters\n    ----------\n    h : float\n        Geopotential height (meters)\n    latitude : float\n        Latitude (degrees)\n\n    Returns\n    -------\n    z : float\n        Geometric Height (meters) above the reference ellipsoid\n    \"\"\"\n    twolat = deg2rad(2 * latitude)\n    g = 9.80616 * (1 - 0.002637*cos(twolat) + 0.0000059*cos(twolat)**2)\n    re = _geoid_radius(latitude)\n    return h * re / (g * re - h)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ser_val_alt(lat: float, lon: float,\n                    da_alt_x: xr.DataArray,\n                    da_alt: xr.DataArray, da_val: xr.DataArray)->pd.Series:\n    '''interpolate atmospheric variable to a specified altitude\n\n    Parameters\n    ----------\n    lat : float\n        latitude of specified site\n    lon : float\n        longitude of specified site\n    da_alt_x : xr.DataArray\n        desired altitude to interpolate variable at\n    da_alt : xr.DataArray\n        altitude associated with `da_val`: variable array to interpolate\n    da_val : xr.DataArray\n        atmospheric varialble to interpolate\n\n    Returns\n    -------\n    pd.Series\n        interpolated values at the specified altitude of site positioned by [`lat`, `lon`]\n    '''\n\n    alt_t_1d = da_alt.sel(\n        latitude=lat, longitude=lon, method='nearest')\n    val_t_1d = da_val.sel(\n        latitude=lat, longitude=lon, method='nearest')\n    alt_x = da_alt_x.sel(\n        latitude=lat, longitude=lon, method='nearest')[0]\n    val_alt = np.array(\n        [interp1d(alt_1d, val_1d)(alt_x)\n         for alt_1d, val_1d\n         in zip(alt_t_1d, val_t_1d)])\n    ser_alt = pd.Series(\n        val_alt,\n        index=da_val.time.values,\n        name=da_val.name,\n    )\n    return ser_alt", "response": "interpolate atmospheric variable to a specified altitude"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninterpolate atmospheric variables to a specified altitude", "response": "def get_df_val_alt(lat: float, lon: float, da_alt_meas: xr.DataArray, ds_val: xr.Dataset):\n    '''interpolate atmospheric variables to a specified altitude\n\n    Parameters\n    ----------\n    lat : float\n        latitude of specified site\n    lon : float\n        longitude of specified site\n    da_alt_x : xr.DataArray\n        desired altitude to interpolate variable at\n    da_alt : xr.DataArray\n        altitude associated with `da_val`: variable array to interpolate\n    da_val : xr.DataArray\n        atmospheric varialble to interpolate\n\n    Returns\n    -------\n    pd.DataFrame\n        interpolated values at the specified altitude of site positioned by [`lat`, `lon`]\n    '''\n    da_alt = geopotential2geometric(ds_val.z, ds_val.latitude)\n    # generate pressure series for grid x\n    da_alt_x = da_alt.sel(\n        latitude=lat, longitude=lon, method='nearest')\n    alt_meas_x = da_alt_meas.sel(\n        latitude=lat, longitude=lon, method='nearest')[0]\n\n    val_pres = np.array([interp1d(alt, da_alt_x.level)(alt_meas_x)\n                         for alt in da_alt_x])\n    df_val_alt = pd.concat(\n        [get_ser_val_alt(\n            lat, lon, da_alt_meas, da_alt, ds_val[var])\n         for var in ds_val.data_vars],\n        axis=1\n    )\n    #     add pressure\n    df_val_alt['p'] = val_pres\n    df_val_alt.index = df_val_alt.index.set_names('time')\n    df_val_alt.columns = df_val_alt.columns.set_names('var')\n\n    return df_val_alt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_req_sfc(lat_x, lon_x, start, end, grid=[0.125, 0.125], scale=0):\n    '''generate a dict of reqs kwargs for (lat_x,lon_x) spanning [start, end]\n\n    Parameters\n    ----------\n    lat_x : [type]\n        [description]\n    lon_x : [type]\n        [description]\n    start : [type]\n        [description]\n    end : [type]\n        [description]\n    grid : list, optional\n        [description] (the default is [0.125, 0.125], which [default_description])\n    scale : int, optional\n        [description] (the default is 0, which [default_description])\n\n    Returns\n    -------\n    [type]\n        [description]\n\n    Examples\n    --------\n    >>> gen_req_sfc(28, 116, '2015-01', '2015-01-31 23', grid=[0.125, 0.125], scale=0)\n\n    '''\n\n    # scale is a factor to rescale grid size\n    size = grid[0]*scale\n    # generate pd.Series for timestamps\n    ser_datetime = pd.date_range(start, end, freq='1h').to_series()\n    # surface requests\n    lat_c, lon_c = (roundPartial(x, grid[0]) for x in [lat_x, lon_x])\n    area = [lat_c+size, lon_c-size, lat_c-size, lon_c+size]\n    dict_req_sfc = {\n        'variable': list_var_sfc,\n        'product_type': 'reanalysis',\n        'area': area,\n        'grid': grid,\n        'format': 'netcdf'\n    }\n    list_dict_req_sfc = [\n        {**dict_req_sfc, **dict_dt}\n        for dict_dt\n        in list(gen_dict_dt_sub(ser_datetime).values())\n    ]\n    dict_req_sfc = {\n        gen_fn(dict_req): gen_dict_proc(dict_req)\n        for dict_req in list_dict_req_sfc\n    }\n    return dict_req_sfc", "response": "generate a dict of reqs kwargs for lat_x lon_x start end"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sel_list_pres(ds_sfc_x):\n    '''\n    select proper levels for model level data download\n    '''\n    p_min, p_max = ds_sfc_x.sp.min().values, ds_sfc_x.sp.max().values\n    list_pres_level = [\n        '1', '2', '3',\n        '5', '7', '10',\n        '20', '30', '50',\n        '70', '100', '125',\n        '150', '175', '200',\n        '225', '250', '300',\n        '350', '400', '450',\n        '500', '550', '600',\n        '650', '700', '750',\n        '775', '800', '825',\n        '850', '875', '900',\n        '925', '950', '975',\n        '1000',\n    ]\n    ser_pres_level = pd.Series(list_pres_level).map(int)*100\n    pos_lev_max, pos_lev_min = (\n        ser_pres_level[ser_pres_level > p_max].idxmin(),\n        ser_pres_level[ser_pres_level < p_min].idxmax()\n    )\n    list_pres_sel = ser_pres_level.loc[pos_lev_min:pos_lev_max]/100\n    list_pres_sel = list_pres_sel.map(int).map(str).to_list()\n    return list_pres_sel", "response": "select proper levels for model level data download\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_world(filename):\n    import ecell4_base\n\n    vinfo = ecell4_base.core.load_version_information(filename)\n    if vinfo.startswith(\"ecell4-bd\"):\n        return ecell4_base.bd.World(filename)\n    elif vinfo.startswith(\"ecell4-egfrd\"):\n        return ecell4_base.egfrd.World(filename)\n    elif vinfo.startswith(\"ecell4-meso\"):\n        return ecell4_base.meso.World(filename)\n    elif vinfo.startswith(\"ecell4-ode\"):\n        return ecell4_base.ode.World(filename)\n    elif vinfo.startswith(\"ecell4-gillespie\"):\n        return ecell4_base.gillespie.World(filename)\n    elif vinfo.startswith(\"ecell4-spatiocyte\"):\n        return ecell4_base.spatiocyte.World(filename)\n    elif vinfo == \"\":\n        raise RuntimeError(\"No version information was found in [{0}]\".format(filename))\n    raise RuntimeError(\"Unkown version information [{0}]\".format(vinfo))", "response": "Loads a single world from the given HDF5 filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a simulation with the given model and plot the result on IPython notebook with matplotlib.", "response": "def run_simulation(\n        t, y0=None, volume=1.0, model=None, solver='ode',\n        is_netfree=False, species_list=None, without_reset=False,\n        return_type='matplotlib', opt_args=(), opt_kwargs=None,\n        structures=None, observers=(), progressbar=0, rndseed=None,\n        factory=None, ## deprecated\n        **kwargs):\n    \"\"\"Run a simulation with the given model and plot the result on IPython\n    notebook with matplotlib.\n\n    Parameters\n    ----------\n    t : array or Real\n        A sequence of time points for which to solve for 'm'.\n    y0 : dict\n        Initial condition.\n    volume : Real or Real3, optional\n        A size of the simulation volume.\n        Keyword 'v' is a shortcut for specifying 'volume'.\n    model : Model, optional\n        Keyword 'm' is a shortcut for specifying 'model'.\n    solver : str, tuple or Factory, optional\n        Solver type. Choose one from 'ode', 'gillespie', 'spatiocyte', 'meso',\n        'bd' and 'egfrd'. Default is 'ode'.\n        When tuple is given, the first value must be str as explained above.\n        All the rest is used as arguments for the corresponding factory class.\n        Keyword 's' is a shortcut for specifying 'solver'.\n    species_list : list of str, optional\n        A list of names of Species observed. If None, log all.\n        Default is None.\n    return_type : str, optional\n        Choose a type of return value from 'array', 'observer',\n        'matplotlib', 'nyaplot', 'world', 'dataframe', 'none' or None.\n        If None or 'none', return and plot nothing. Default is 'matplotlib'.\n        'dataframe' requires numpy and pandas libraries.\n        Keyword 'r' is a shortcut for specifying 'return_type'.\n    opt_args: list, tuple or dict, optional\n        Arguments for plotting. If return_type suggests no plotting, just ignored.\n    opt_kwargs: dict, optional\n        Arguments for plotting. If return_type suggests no plotting or\n        opt_args is a list or tuple, just ignored.\n        i.e.) viz.plot_number_observer(obs, *opt_args, **opt_kwargs)\n    is_netfree: bool, optional\n        Whether the model is netfree or not. When a model is given as an\n        argument, just ignored. Default is False.\n    structures : list or dict, optional\n        A dictionary which gives pairs of a name and shape of structures.\n        Not fully supported yet.\n    observers : Observer or list, optional\n        A list of extra observer references.\n    progressbar : float, optional\n        A timeout for a progress bar in seconds.\n        When the value is not more than 0, show nothing.\n        Default is 0.\n    rndseed : int, optional\n        A random seed for a simulation.\n        This argument will be ignored when 'solver' is given NOT as a string.\n\n    Returns\n    -------\n    value : list, TimingNumberObserver, World or None\n        Return a value suggested by ``return_type``.\n        When ``return_type`` is 'array', return a time course data.\n        When ``return_type`` is 'observer', return an observer.\n        When ``return_type`` is 'world', return the last state of ``World``.\n        Return nothing if else.\n\n    \"\"\"\n    y0 = y0 or {}\n    opt_kwargs = opt_kwargs or {}\n    structures = structures or {}\n\n    for key, value in kwargs.items():\n        if key == 'r':\n            return_type = value\n        elif key == 'v':\n            volume = value\n        elif key == 's':\n            solver = value\n        elif key == 'm':\n            model = value\n        else:\n            raise ValueError(\n                \"An unknown keyword argument was given [{}={}]\".format(key, value))\n\n    import ecell4_base\n\n    if unit.HAS_PINT:\n        if isinstance(t, unit._Quantity):\n            if unit.STRICT and not unit.check_dimensionality(t, '[time]'):\n                raise ValueError(\"Cannot convert [t] from '{}' ({}) to '[time]'\".format(t.dimensionality, t.u))\n            t = t.to_base_units().magnitude\n\n        if isinstance(volume, unit._Quantity):\n            if unit.STRICT:\n                if isinstance(volume.magnitude, ecell4_base.core.Real3) and not unit.check_dimensionality(volume, '[length]'):\n                    raise ValueError(\"Cannot convert [volume] from '{}' ({}) to '[length]'\".format(\n                        volume.dimensionality, volume.u))\n                elif not unit.check_dimensionality(volume, '[volume]'):\n                    raise ValueError(\"Cannot convert [volume] from '{}' ({}) to '[volume]'\".format(\n                        volume.dimensionality, volume.u))\n            volume = volume.to_base_units().magnitude\n\n        if not isinstance(solver, str) and isinstance(solver, collections.Iterable):\n            solver = [\n                value.to_base_units().magnitude if isinstance(value, unit._Quantity) else value\n                for value in solver]\n\n    if factory is not None:\n        # f = factory  #XXX: will be deprecated in the future. just use solver\n        raise ValueError(\n            \"Argument 'factory' is no longer available. Use 'solver' instead.\")\n    elif isinstance(solver, str):\n        f = get_factory(solver)\n    elif isinstance(solver, collections.Iterable):\n        f = get_factory(*solver)\n    else:\n        f = solver\n\n    if rndseed is not None:\n        f = f.rng(ecell4_base.core.GSLRandomNumberGenerator(rndseed))\n\n    if model is None:\n        model = get_model(is_netfree, without_reset)\n\n    w = f.world(volume)\n    edge_lengths = w.edge_lengths()\n\n    if unit.HAS_PINT:\n        y0 = y0.copy()\n        for key, value in y0.items():\n            if isinstance(value, unit._Quantity):\n                if not unit.STRICT:\n                    y0[key] = value.to_base_units().magnitude\n                elif unit.check_dimensionality(value, '[substance]'):\n                    y0[key] = value.to_base_units().magnitude\n                elif unit.check_dimensionality(value, '[concentration]'):\n                    volume = w.volume() if not isinstance(w, ecell4_base.spatiocyte.SpatiocyteWorld) else w.actual_volume()\n                    y0[key] = value.to_base_units().magnitude * volume\n                else:\n                    raise ValueError(\n                        \"Cannot convert a quantity for [{}] from '{}' ({}) to '[substance]'\".format(\n                            key, value.dimensionality, value.u))\n\n    if not isinstance(w, ecell4_base.ode.ODEWorld):\n        w.bind_to(model)\n\n    for (name, shape) in (structures.items() if isinstance(structures, dict) else structures):\n        if isinstance(shape, str):\n            w.add_structure(ecell4_base.core.Species(name), get_shape(shape))\n        elif isinstance(shape, collections.Iterable):\n            w.add_structure(ecell4_base.core.Species(name), get_shape(*shape))\n        else:\n            w.add_structure(ecell4_base.core.Species(name), shape)\n\n    if isinstance(w, ecell4_base.ode.ODEWorld):\n        # w.bind_to(model)  # stop binding for ode\n        for serial, n in y0.items():\n            w.set_value(ecell4_base.core.Species(serial), n)\n    else:\n        # w.bind_to(model)\n        for serial, n in y0.items():\n            w.add_molecules(ecell4_base.core.Species(serial), n)\n\n    if not isinstance(t, collections.Iterable):\n        t = [float(t) * i / 100 for i in range(101)]\n\n    if species_list is not None:\n        obs = ecell4_base.core.TimingNumberObserver(t, species_list)\n    else:\n        obs = ecell4_base.core.TimingNumberObserver(t)\n    sim = f.simulator(w, model)\n    # sim = f.simulator(w)\n\n    if not isinstance(observers, collections.Iterable):\n        observers = (observers, )\n    if return_type not in ('world', 'none', None):\n        observers = (obs, ) + tuple(observers)\n\n    if progressbar > 0:\n        from .progressbar import progressbar as pb\n        pb(sim, timeout=progressbar, flush=True).run(t[-1], observers)\n    else:\n        sim.run(t[-1], observers)\n\n    if return_type in ('matplotlib', 'm'):\n        if isinstance(opt_args, (list, tuple)):\n            viz.plot_number_observer(obs, *opt_args, **opt_kwargs)\n        elif isinstance(opt_args, dict):\n            # opt_kwargs is ignored\n            viz.plot_number_observer(obs, **opt_args)\n        else:\n            raise ValueError('opt_args [{}] must be list or dict.'.format(\n                repr(opt_args)))\n    elif return_type in ('nyaplot', 'n'):\n        if isinstance(opt_args, (list, tuple)):\n            viz.plot_number_observer_with_nya(obs, *opt_args, **opt_kwargs)\n        elif isinstance(opt_args, dict):\n            # opt_kwargs is ignored\n            viz.plot_number_observer_with_nya(obs, **opt_args)\n        else:\n            raise ValueError('opt_args [{}] must be list or dict.'.format(\n                repr(opt_args)))\n    elif return_type in ('observer', 'o'):\n        return obs\n    elif return_type in ('array', 'a'):\n        return obs.data()\n    elif return_type in ('dataframe', 'd'):\n        import pandas\n        import numpy\n        data = numpy.array(obs.data()).T\n        return pandas.concat([\n            pandas.DataFrame(dict(Time=data[0], Value=data[i + 1],\n                                  Species=sp.serial(), **opt_kwargs))\n            for i, sp in enumerate(obs.targets())])\n    elif return_type in ('world', 'w'):\n        return sim.world()\n    elif return_type is None or return_type in ('none', ):\n        return\n    else:\n        raise ValueError(\n            'An invald value for \"return_type\" was given [{}].'.format(str(return_type))\n            + 'Use \"none\" if you need nothing to be returned.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef number_observer(t=None, targets=None):\n    from ecell4_base.core import NumberObserver, FixedIntervalNumberObserver, TimingNumberObserver\n\n    if t is None:\n        return NumberObserver(targets)\n    elif isinstance(t, numbers.Number):\n        return FixedIntervalNumberObserver(t, targets)\n    elif hasattr(t, '__iter__'):\n        if targets is not None:\n            return TimingNumberObserver(t, targets)\n        else:\n            return TimingNumberObserver(t)\n    else:\n        raise TypeError(\"An invalid type was given. Either number or iterable is required.\")", "response": "Returns a number observer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the simulation. Parameters ---------- duration : Real a duration for running a simulation. A simulation is expected to be stopped at t() + duration. observers : list of Obeservers, optional observers", "response": "def run(self, duration, obs):\n        \"\"\"Run the simulation.\n\n        Parameters\n        ----------\n        duration : Real\n            a duration for running a simulation.\n                A simulation is expected to be stopped at t() + duration.\n        observers : list of Obeservers, optional\n            observers\n\n        \"\"\"\n        from ecell4_base.core import TimeoutObserver\n\n        timeout = TimeoutObserver(self.__timeout)\n        if isinstance(obs, collections.Iterable):\n            obs = tuple(obs) + (timeout, )\n        else:\n            obs = (obs, timeout)\n        p = ProgressBar(**self.__kwargs)\n        p.animate(0.0)\n        tstart = self.__sim.t()\n        upto = tstart + duration\n        while self.__sim.t() < upto:\n            self.__sim.run(upto - self.__sim.t(), obs)\n            p.animate((self.__sim.t() - tstart) / duration, timeout.accumulation())\n        if self.__flush:\n            p.flush()\n        else:\n            print()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, duration, obs=None):\n        from ecell4_base.core import TimeoutObserver\n\n        timeout = TimeoutObserver(self.__timeout)\n        if obs is None:\n            obs = (timeout, )\n        elif isinstance(obs, collections.Iterable):\n            obs = tuple(obs) + (timeout, )\n        else:\n            obs = (obs, timeout)\n\n        from ipywidgets import FloatProgress, HBox, HTML\n        from IPython.display import display\n        from time import sleep\n\n        fp = FloatProgress(min=0, max=100)\n        ptext = HTML()\n        display(HBox(children=[fp, ptext]))\n\n        tstart = self.__sim.t()\n        upto = tstart + duration\n        while self.__sim.t() < upto:\n            self.__sim.run(upto - self.__sim.t(), obs)\n            value = (self.__sim.t() - tstart) / duration\n            fp.value = value * 100\n            ptext.value = self.get_text(value, timeout.accumulation())\n            sleep(self.__wait)\n\n        fp.value = 100\n        ptext.value = self.get_text(1, timeout.accumulation())", "response": "Run the simulation.\n\n        Parameters\n        ----------\n        duration : Real\n            a duration for running a simulation.\n                A simulation is expected to be stopped at t() + duration.\n        obs : list of Obeservers, optional\n            observers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the contents of the specified Batch exception.", "response": "def print_batch_exception(batch_exception):\n    \"\"\"Prints the contents of the specified Batch exception.\n\n    :param batch_exception:\n    \"\"\"\n    _log.error('-------------------------------------------')\n    _log.error('Exception encountered:')\n    if batch_exception.error and \\\n            batch_exception.error.message and \\\n            batch_exception.error.message.value:\n        _log.error(batch_exception.error.message.value)\n        if batch_exception.error.values:\n            _log.error('')\n            for mesg in batch_exception.error.values:\n                _log.error('{}:\\t{}'.format(mesg.key, mesg.value))\n    _log.error('-------------------------------------------')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a local file to an Azure Blob storage container.", "response": "def upload_file_to_container(block_blob_client, container_name, file_path):\n    \"\"\"Uploads a local file to an Azure Blob storage container.\n\n    :param block_blob_client: A blob service client.\n    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n    :param str container_name: The name of the Azure Blob storage container.\n    :param str file_path: The local path to the file.\n    :rtype: `azure.batch.models.ResourceFile`\n    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n    tasks.\n    \"\"\"\n    blob_name = os.path.basename(file_path)\n\n    _log.info('Uploading file {} to container [{}]...'.format(file_path, container_name))\n\n    block_blob_client.create_blob_from_path(container_name,\n                                            blob_name,\n                                            file_path)\n\n    sas_token = block_blob_client.generate_blob_shared_access_signature(\n        container_name,\n        blob_name,\n        permission=azureblob.BlobPermissions.READ,\n        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=2))\n\n    sas_url = block_blob_client.make_blob_url(container_name,\n                                              blob_name,\n                                              sas_token=sas_token)\n\n    return batchmodels.ResourceFile(http_url=sas_url, file_path=blob_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_container_sas_token(block_blob_client,\n                            container_name, blob_permissions):\n    \"\"\"Obtains a shared access signature granting the specified permissions to the\n    container.\n\n    :param block_blob_client: A blob service client.\n    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n    :param str container_name: The name of the Azure Blob storage container.\n    :param BlobPermissions blob_permissions:\n    :rtype: str\n    :return: A SAS token granting the specified permissions to the container.\n    \"\"\"\n    # Obtain the SAS token for the container, setting the expiry time and\n    # permissions. In this case, no start time is specified, so the shared\n    # access signature becomes valid immediately.\n    container_sas_token = \\\n        block_blob_client.generate_container_shared_access_signature(\n            container_name,\n            permission=blob_permissions,\n            expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=2))\n\n    return container_sas_token", "response": "Returns a SAS token for the specified container."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps commands in a shell", "response": "def wrap_commands_in_shell(ostype, commands):\n    \"\"\"Wrap commands in a shell\n    Originally in azure-batch-samples.Python.Batch.common.helpers\n\n    :param list commands: list of commands to wrap\n    :param str ostype: OS type, linux or windows\n    :rtype: str\n    :return: a shell wrapping commands\n    \"\"\"\n    if ostype.lower() == 'linux':\n        return '/bin/bash -c \\'set -e; set -o pipefail; {}; wait\\''.format(\n            ';'.join(commands))\n    elif ostype.lower() == 'windows':\n        return 'cmd.exe /c \"{}\"'.format('&'.join(commands))\n    else:\n        raise ValueError('unknown ostype: {}'.format(ostype))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new pool of compute nodes with the specified OS settings.", "response": "def create_pool(batch_service_client, pool_id,\n                resource_files, publisher, offer, sku,\n                task_file, vm_size, node_count):\n    \"\"\"Creates a pool of compute nodes with the specified OS settings.\n\n    :param batch_service_client: A Batch service client.\n    :type batch_service_client: `azure.batch.BatchServiceClient`\n    :param str pool_id: An ID for the new pool.\n    :param list resource_files: A collection of resource files for the pool's\n    start task.\n    :param str publisher: Marketplace image publisher\n    :param str offer: Marketplace image offer\n    :param str sku: Marketplace image sku\n    :param str task_file: A file name of the script\n    :param str vm_size: A type of vm\n    :param str node_count: The number of nodes\n    \"\"\"\n    _log.info('Creating pool [{}]...'.format(pool_id))\n\n    # Create a new pool of Linux compute nodes using an Azure Virtual Machines\n    # Marketplace image. For more information about creating pools of Linux\n    # nodes, see:\n    # https://azure.microsoft.com/documentation/articles/batch-linux-nodes/\n\n    # Specify the commands for the pool's start task. The start task is run\n    # on each node as it joins the pool, and when it's rebooted or re-imaged.\n    # We use the start task to prep the node for running our task script.\n    task_commands = [\n        # Copy the python_tutorial_task.py script to the \"shared\" directory\n        # that all tasks that run on the node have access to. Note that\n        # we are using the -p flag with cp to preserve the file uid/gid,\n        # otherwise since this start task is run as an admin, it would not\n        # be accessible by tasks run as a non-admin user.\n        'cp -p {} $AZ_BATCH_NODE_SHARED_DIR'.format(os.path.basename(task_file)),\n        # Install pip\n        'curl -fSsL https://bootstrap.pypa.io/get-pip.py | python',\n        # Install the azure-storage module so that the task script can access\n        # Azure Blob storage, pre-cryptography version\n        'pip install azure-storage==0.32.0',\n        # Install E-Cell 4\n        'pip install https://1028-6348303-gh.circle-artifacts.com/0/root/circle/wheelhouse/ecell-4.1.2-cp27-cp27mu-manylinux1_x86_64.whl']\n\n    # Get the node agent SKU and image reference for the virtual machine\n    # configuration.\n    # For more information about the virtual machine configuration, see:\n    # https://azure.microsoft.com/documentation/articles/batch-linux-nodes/\n    sku_to_use, image_ref_to_use = \\\n        select_latest_verified_vm_image_with_node_agent_sku(\n            batch_service_client, publisher, offer, sku)\n    user = batchmodels.AutoUserSpecification(\n        scope=batchmodels.AutoUserScope.pool,\n        elevation_level=batchmodels.ElevationLevel.admin)\n    new_pool = batch.models.PoolAddParameter(\n        id=pool_id,\n        virtual_machine_configuration=batchmodels.VirtualMachineConfiguration(\n            image_reference=image_ref_to_use,\n            node_agent_sku_id=sku_to_use),\n        vm_size=vm_size,\n        target_dedicated_nodes=0,\n        target_low_priority_nodes=node_count,\n        start_task=batch.models.StartTask(\n            command_line=wrap_commands_in_shell('linux', task_commands),\n            user_identity=batchmodels.UserIdentity(auto_user=user),\n            wait_for_success=True,\n            resource_files=resource_files),\n    )\n\n    try:\n        batch_service_client.pool.add(new_pool)\n    except batchmodels.BatchErrorException as err:\n        print_batch_exception(err)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a job with the specified ID associated with the specified pool.", "response": "def create_job(batch_service_client, job_id, pool_id):\n    \"\"\"Creates a job with the specified ID, associated with the specified pool.\n\n    :param batch_service_client: A Batch service client.\n    :type batch_service_client: `azure.batch.BatchServiceClient`\n    :param str job_id: The ID for the job.\n    :param str pool_id: The ID for the pool.\n    \"\"\"\n    print('Creating job [{}]...'.format(job_id))\n\n    job = batch.models.JobAddParameter(\n        id=job_id,\n        pool_info=batch.models.PoolInformation(pool_id=pool_id))\n\n    try:\n        batch_service_client.job.add(job)\n    except batchmodels.batch_error.BatchErrorException as err:\n        print_batch_exception(err)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_tasks(batch_service_client, job_id, loads,\n              output_container_name, output_container_sas_token,\n              task_file, acount_name):\n    \"\"\"Adds a task for each input file in the collection to the specified job.\n\n    :param batch_service_client: A Batch service client.\n    :type batch_service_client: `azure.batch.BatchServiceClient`\n    :param str job_id: The ID of the job to which to add the tasks.\n    :param list input_files: A collection of input files. One task will be\n     created for each input file.\n    :param output_container_name: The ID of an Azure Blob storage container to\n    which the tasks will upload their results.\n    :param output_container_sas_token: A SAS token granting write access to\n    the specified Azure Blob storage container.\n    :param str task_file: A file name of the script\n    :param str account_name: A storage account\n    \"\"\"\n\n    _log.info('Adding {} tasks to job [{}]...'.format(len(loads), job_id))\n    # _log.info('Adding {} tasks to job [{}]...'.format(len(input_files), job_id))\n\n    tasks = list()\n\n    for (input_file, output_file, i, j) in loads:\n        command = ['python $AZ_BATCH_NODE_SHARED_DIR/{} '\n                   '--filepath {} --output {} --storageaccount {} '\n                   '--task_id {} --job_id {} '\n                   '--storagecontainer {} --sastoken \"{}\"'.format(\n                       os.path.basename(task_file),\n                       input_file.file_path,\n                       output_file,\n                       acount_name,\n                       i, j,\n                       output_container_name,\n                       output_container_sas_token)]\n        _log.debug('CMD : \"{}\"'.format(command[0]))\n\n        tasks.append(batch.models.TaskAddParameter(\n                id='topNtask{}-{}'.format(i, j),\n                command_line=command,\n                resource_files=[input_file]\n                )\n        )\n\n    batch_service_client.task.add_collection(job_id, tasks)\n\n    task_ids = [task.id for task in tasks]\n    _log.info('{} tasks were added.'.format(len(task_ids)))\n    return task_ids", "response": "Adds a task for each input file in the collection to the specified job."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwaits for all tasks in the specified job to reach the Completed state.", "response": "def wait_for_tasks_to_complete(batch_service_client, job_ids, timeout):\n    \"\"\"Returns when all tasks in the specified job reach the Completed state.\n\n    :param batch_service_client: A Batch service client.\n    :type batch_service_client: `azure.batch.BatchServiceClient`\n    :param str job_id: The id of the job whose tasks should be to monitored.\n    :param timedelta timeout: The duration to wait for task completion. If all\n    tasks in the specified job do not reach Completed state within this time\n    period, an exception will be raised.\n    \"\"\"\n    timeout_expiration = datetime.datetime.now() + timeout\n\n    print(\"Monitoring all tasks for 'Completed' state, timeout in {}...\".format(timeout), end='')\n\n    while datetime.datetime.now() < timeout_expiration:\n        print('.', end='')\n        sys.stdout.flush()\n        # tasks = batch_service_client.task.list(job_id)\n        # incomplete_tasks = [task for task in tasks if\n        #                     task.state != batchmodels.TaskState.completed]\n        for (job_id, _) in job_ids:\n            tasks = batch_service_client.task.list(job_id)\n            incomplete_tasks = [task for task in tasks if\n                                task.state != batchmodels.TaskState.completed]\n            if incomplete_tasks:\n                break\n        if not incomplete_tasks:\n            print()\n            return True\n        else:\n            time.sleep(1)\n\n    raise RuntimeError(\"ERROR: Tasks did not reach 'Completed' state within \"\n                       \"timeout period of \" + str(timeout))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload all blobs from the specified container.", "response": "def download_blobs_from_container(block_blob_client,\n                                  container_name, directory_path,\n                                  prefix=None):\n    \"\"\"Downloads all blobs from the specified Azure Blob storage container.\n\n    :param block_blob_client: A blob service client.\n    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n    :param container_name: The Azure Blob storage container from which to\n     download files.\n    :param directory_path: The local directory to which to download the files.\n    :param str prefix: A name prefix to filter blobs. None as its default\n    \"\"\"\n    _log.info('Downloading all files from container [{}]...'.format(container_name))\n\n    container_blobs = block_blob_client.list_blobs(container_name, prefix=None)\n    _log.info('{} blobs are found [{}]'.format(len(tuple(container_blobs)), ', '.join(blob.name for blob in container_blobs.items)))\n\n    for blob in container_blobs.items:\n        destination_file_path = os.path.join(directory_path, blob.name)\n\n        block_blob_client.get_blob_to_path(container_name,\n                                           blob.name,\n                                           destination_file_path)\n\n        _log.info('  Downloaded blob [{}] from container [{}] to {}'.format(\n            blob.name,\n            container_name,\n            destination_file_path))\n\n    _log.info('  Download complete!')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_stream_as_string(stream, encoding):\n    output = io.BytesIO()\n    try:\n        for data in stream:\n            output.write(data)\n        if encoding is None:\n            encoding = 'utf-8'\n        return output.getvalue().decode(encoding)\n    finally:\n        output.close()\n    raise RuntimeError('could not write data to stream or decode bytes')", "response": "Read the contents of the input stream as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_task_file_as_string(\n        batch_client, job_id, task_id, file_name, encoding=None):\n    \"\"\"Reads the specified file as a string.\n    Originally in azure-batch-samples.Python.Batch.common.helpers\n\n    :param batch_client: The batch client to use.\n    :type batch_client: `batchserviceclient.BatchServiceClient`\n    :param str job_id: The id of the job.\n    :param str task_id: The id of the task.\n    :param str file_name: The name of the file to read.\n    :param str encoding: The encoding of the file. The default is utf-8.\n    :return: The file content.\n    :rtype: str\n    \"\"\"\n    stream = batch_client.file.get_from_task(job_id, task_id, file_name)\n    return _read_stream_as_string(stream, encoding)", "response": "Reads the specified file as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_task_output(batch_client, job_id, task_ids, encoding=None):\n    for task_id in task_ids:\n        file_text = read_task_file_as_string(\n            batch_client,\n            job_id,\n            task_id,\n            _STANDARD_OUT_FILE_NAME,\n            encoding)\n        print(\"{} content for task {}: \".format(\n            _STANDARD_OUT_FILE_NAME,\n            task_id))\n        print(file_text)\n\n        file_text = read_task_file_as_string(\n            batch_client,\n            job_id,\n            task_id,\n            _STANDARD_ERROR_FILE_NAME,\n            encoding)\n        print(\"{} content for task {}: \".format(\n            _STANDARD_ERROR_FILE_NAME,\n            task_id))\n        print(file_text)", "response": "Prints the stdout and stderr for each task specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a function for multiple sets of arguments on Microsoft Azure and return the results as a list.", "response": "def run_azure(target, jobs, n=1, path='.', delete=True, config=None):\n    \"\"\"Execute a function for multiple sets of arguments on Microsoft Azure,\n    and return the results as a list.\n\n    :param function target: A target function.\n    :param list jobs: A list of sets of arguments given to the target.\n    :param int n: The number of repeats running the target. 1 as default.\n    :param str path: A path to save temp files. The current path as default.\n    :param bool delete: Delete temp files after finishing jobs, or not. True as default.\n    :param config: str or configparser.ConfigParser. A config file. An example is the following:\n\n    ```\n    [azure]\n    batch.name = foo\n    batch.key = bar\n    batch.url = hoge\n    storage.name = fuga\n    storage.key = spam\n    pool.nodecount = 2\n    # pool.id = MyPool\n    # pool.vmsize = Standard_D11_v2\n    # os.publisher = Canonical\n    # os.offer = UbuntuServer\n    # os.sku = 16\n    # job.id = MyJob\n    ```\n\n    :return: A list of results corresponding the `jobs` list.\n    :rtype: list\n    \"\"\"\n\n    if config is None:\n        raise ValueError('Argument \\'config\\' must be given.')\n    elif isinstance(config, str):\n        if not os.path.isfile(config):\n            raise FileNotFoundError('A file [{}] could not be found.'.format(config))\n        config_filename = config\n        config = configparser.ConfigParser()\n        config.sections()\n        config.read(config_filename)\n        config.sections()\n    elif not isinstance(config, configparser.ConfigParser):\n        raise ValueError('\\'config\\' must be eighter str or ConfigParser. [{}] was given.'.format(repr(config)))\n\n    if 'azure' not in config:\n        raise KeyError('Key \\'azure\\' could not be found in the given config.')\n\n    for key in ('batch.name', 'batch.key', 'batch.url', 'storage.name', 'storage.key', 'pool.nodecount'):\n        if key not in config['azure']:\n            raise KeyError('Key \\'{}\\' could not be found in the \\'azure\\' section.'.format(key))\n\n    # Update the Batch and Storage account credential strings below with the values\n    # unique to your accounts. These are used when constructing connection strings\n    # for the Batch and Storage client objects.\n    _BATCH_ACCOUNT_NAME   = config['azure']['batch.name']\n    _BATCH_ACCOUNT_KEY    = config['azure']['batch.key']\n    _BATCH_ACCOUNT_URL    = config['azure']['batch.url']\n    _STORAGE_ACCOUNT_NAME = config['azure']['storage.name']\n    _STORAGE_ACCOUNT_KEY  = config['azure']['storage.key']\n    _POOL_NODE_COUNT      = config['azure']['pool.nodecount']\n    _POOL_ID              = config['azure'].get('pool.id', 'MyPool')\n    _POOL_VM_SIZE         = config['azure'].get('pool.vmsize', 'Standard_D11_v2')\n    _NODE_OS_PUBLISHER    = config['azure'].get('os.publisher', 'Canonical')\n    _NODE_OS_OFFER        = config['azure'].get('os.offer', 'UbuntuServer')\n    _NODE_OS_SKU          = config['azure'].get('os.sku', '16')\n    _JOB_ID               = config['azure'].get('job.id', 'MyJob')\n\n    if not _POOL_NODE_COUNT.isdigit():\n        raise ValueError('The wrong pool node count was given [{}]. This must be an integer'.format(_POOL_NODE_COUNT))\n\n    proc_per_node = 2  #XXX: Does this depend on pool vm?\n    nproc = int(_POOL_NODE_COUNT) * proc_per_node\n\n    code_header = \"\"\"\nfrom __future__ import print_function\nimport argparse\nimport os\nimport string\nimport azure.storage.blob as azureblob\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--filepath', required=True,\n                    help='The path to the text file to process. The path'\n                         'may include a compute node\\\\'s environment'\n                         'variables, such as'\n                         '$AZ_BATCH_NODE_SHARED_DIR/filename.txt')\nparser.add_argument('--output', required=True,\n                    help='The path to the output.')\nparser.add_argument('--job_id', type=int, required=True)\nparser.add_argument('--task_id', type=int, required=True)\nparser.add_argument('--storageaccount', required=True,\n                    help='The name the Azure Storage account that owns the'\n                         'blob storage container to which to upload'\n                         'results.')\nparser.add_argument('--storagecontainer', required=True,\n                    help='The Azure Blob storage container to which to'\n                         'upload results.')\nparser.add_argument('--sastoken', required=True,\n                    help='The SAS token providing write access to the'\n                         'Storage container.')\nargs = parser.parse_args()\n\ninput_file = os.path.realpath(args.filepath)\noutput_file = args.output\n\nimport pickle\nwith open(input_file, mode='rb') as fin:\n    inputs = pickle.load(fin)\n\n\"\"\"\n    code_footer = \"\"\"\n\nwith open(output_file, mode='wb') as fout:\n    pickle.dump(res, fout, protocol=2)\n\n# Create the blob client using the container's SAS token.\n# This allows us to create a client that provides write\n# access only to the container.\nblob_client = azureblob.BlockBlobService(account_name=args.storageaccount,\n                                         sas_token=args.sastoken)\noutput_file_path = os.path.realpath(output_file)\nblob_client.create_blob_from_path(args.storagecontainer,\n                                  output_file,\n                                  output_file_path)\n\"\"\"\n\n    # src = textwrap.dedent(inspect.getsource(target)).replace(r'\"', r'\\\"')\n    src = textwrap.dedent(inspect.getsource(target))\n    if re.match('[\\s\\t]+', src.split('\\n')[0]) is not None:\n        raise RuntimeError(\n            \"Wrong indentation was found in the source translated\")\n\n    code = code_header\n    code += src\n    code += 'res = {}(inputs, args.task_id, args.job_id)'.format(target.__name__)\n    code += code_footer\n    target = code\n\n    suffix = binascii.hexlify(os.urandom(4)).decode()\n\n    start_time = datetime.datetime.now().replace(microsecond=0)\n    _log.info('Sample start: {}'.format(start_time))\n\n    if not os.path.isdir(path):\n        os.mkdir(path)\n\n    # task_file = target\n    # task_file = 'task-{}.py'.format(suffix)\n    task_file = '{}/task-{}.py'.format(path, suffix)\n    with open(task_file, 'w') as fout:\n        fout.write(target)\n\n    # Prepare input pickle files\n    input_file_names = []\n    output_file_names = []\n    for i, job in enumerate(jobs):\n        filename = '{}/input-{}_{}.pickle'.format(path, suffix, i)\n        input_file_names.append(filename)\n        for j in range(n):\n            output_file_names.append('output-{}_{}.{}.pickle'.format(suffix, i, j + 1))\n        with open(filename, mode='wb') as fout:\n            pickle.dump(job, fout, protocol=2)\n\n    # Create the blob client, for use in obtaining references to\n    # blob storage containers and uploading files to containers.\n    blob_client = azureblob.BlockBlobService(\n        account_name=_STORAGE_ACCOUNT_NAME,\n        account_key=_STORAGE_ACCOUNT_KEY)\n\n    n_jobs = -(-(len(jobs) * n) // nproc)  # ceil for int\n    _log.info('{} jobs will be created.'.format(n_jobs))\n    res = None\n\n    try:\n        # Use the blob client to create the containers in Azure Storage if they\n        # don't yet exist.\n        app_container_name = 'application-{}'.format(suffix)\n        input_container_name = 'input-{}'.format(suffix)\n        output_container_name = 'output-{}'.format(suffix)\n        # app_container_name = 'application'\n        # input_container_name = 'input'\n        # output_container_name = 'output'\n        blob_client.create_container(app_container_name, fail_on_exist=False)\n        blob_client.create_container(input_container_name, fail_on_exist=False)\n        blob_client.create_container(output_container_name, fail_on_exist=False)\n\n        # Paths to the task script. This script will be executed by the tasks that\n        # run on the compute nodes.\n        application_file_paths = [os.path.realpath(task_file)]\n\n        # The collection of data files that are to be processed by the tasks.\n        input_file_paths = [os.path.realpath(filename) for filename in input_file_names]\n\n        # Upload the application script to Azure Storage. This is the script that\n        # will process the data files, and is executed by each of the tasks on the\n        # compute nodes.\n        application_files = [\n            upload_file_to_container(blob_client, app_container_name, file_path)\n            for file_path in application_file_paths]\n\n        # Upload the data files. This is the data that will be processed by each of\n        # the tasks executed on the compute nodes in the pool.\n        input_files = [\n            upload_file_to_container(blob_client, input_container_name, file_path)\n            for file_path in input_file_paths]\n\n        # Obtain a shared access signature that provides write access to the output\n        # container to which the tasks will upload their output.\n        output_container_sas_token = get_container_sas_token(\n            blob_client,\n            output_container_name,\n            azureblob.BlobPermissions.WRITE)\n\n        # Create a Batch service client. We'll now be interacting with the Batch\n        # service in addition to Storage\n        credentials = batchauth.SharedKeyCredentials(_BATCH_ACCOUNT_NAME,\n                                                     _BATCH_ACCOUNT_KEY)\n        #print(_BATCH_ACCOUNT_URL)\n        batch_client = batch.BatchServiceClient(\n            credentials,\n            batch_url=_BATCH_ACCOUNT_URL)\n\n        # Create the pool that will contain the compute nodes that will execute the\n        # tasks. The resource files we pass in are used for configuring the pool's\n        # start task, which is executed each time a node first joins the pool (or\n        # is rebooted or re-imaged).\n        create_pool(batch_client,\n                    _POOL_ID + '-' + suffix,\n                    application_files,\n                    _NODE_OS_PUBLISHER,\n                    _NODE_OS_OFFER,\n                    _NODE_OS_SKU,\n                    task_file,\n                    _POOL_VM_SIZE, _POOL_NODE_COUNT)\n\n        # Create the job that will run the tasks.\n        loads = []\n        for i, input_file in enumerate(input_files):\n            for j, output_file in enumerate(output_file_names[i * n: (i + 1) * n]):\n                loads.append((input_file, output_file, i + 1, j + 1))\n\n        assert n_jobs == -(-len(loads) // nproc)  # ceil for int\n        job_names = []\n        for i in range(n_jobs):\n            job_name = '{}-{}-{}'.format(_JOB_ID, suffix, i + 1)\n\n            create_job(batch_client, job_name, _POOL_ID + '-' + suffix)\n\n            # Add the tasks to the job. We need to supply a container shared access\n            # signature (SAS) token for the tasks so that they can upload their output\n            # to Azure Storage.\n            task_ids = add_tasks(batch_client,\n                                 job_name,\n                                 loads[i * nproc: (i + 1) * nproc],\n                                 output_container_name,\n                                 output_container_sas_token,\n                                 task_file,\n                                 _STORAGE_ACCOUNT_NAME)\n\n            job_names.append((job_name, task_ids))\n\n        # Pause execution until tasks reach Completed state.\n        wait_for_tasks_to_complete(batch_client,\n                                   job_names,\n                                   datetime.timedelta(minutes=20))\n\n        _log.info(\"  Success! All tasks reached the 'Completed' state within the specified timeout period.\")\n\n        # Download the task output files from the output Storage container to a\n        # local directory. Note that we could have also downloaded the output\n        # files directly from the compute nodes themselves.\n        download_blobs_from_container(blob_client,\n                                      output_container_name,\n                                      os.path.abspath(path))\n\n        for job_id, task_ids in job_names:\n            print_task_output(batch_client, job_id, task_ids)\n\n        # Print out some timing info\n        end_time = datetime.datetime.now().replace(microsecond=0)\n        _log.info('Sample end: {}'.format(end_time))\n        _log.info('Elapsed time: {}'.format(end_time - start_time))\n\n        res = []\n        for output_file in output_file_names:\n            with open(os.path.join(path, output_file), mode='rb') as fin:\n                res.append(pickle.load(fin))\n        res = [res[i * n: (i + 1) * n] for i in range(len(jobs))]\n    finally:\n        # Clean up storage resources\n        _log.info('Deleting containers...')\n        blob_client.delete_container(app_container_name)\n        blob_client.delete_container(input_container_name)\n        blob_client.delete_container(output_container_name)\n\n        # Clean up Batch resources (if the user so chooses).\n        for i in range(n_jobs):\n            job_name = '{}-{}-{}'.format(_JOB_ID, suffix, i + 1)\n            _log.info('Deleting job [{}] ...'.format(job_name))\n            batch_client.job.delete(job_name)\n\n        _log.info('Deleting pool...')\n        batch_client.pool.delete(_POOL_ID + '-' + suffix)\n\n        if delete:\n            _log.info('Deleting temporary files...')\n            for filename in output_file_names:\n                filename = os.path.join(path, filename)\n                if os.path.isfile(filename):\n                    os.remove(filename)\n            for filename in itertools.chain(input_file_paths, application_file_paths):\n                if os.path.isfile(filename):\n                    os.remove(filename)\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef singlerun(job, task_id=0, job_id=0):\n\n    import ecell4_base\n    import ecell4\n    import ecell4.util.simulation\n    import ecell4.util.decorator\n    print('ecell4_base.__version__ = {:s}'.format(ecell4_base.__version__))\n    print('ecell4.__version__ = {:s}'.format(ecell4.__version__))\n    print('job={}, task_id={}, job_id={}'.format(str(job), task_id, job_id))\n\n    with ecell4.util.decorator.reaction_rules():\n        A + B == C | (0.01, 0.3)\n\n    res = ecell4.util.simulation.run_simulation(\n        1.0,\n        y0={'A': job[0], 'B': job[1], 'C': job[2]},\n        rndseed=job_id,\n        solver='gillespie',\n        return_type='array')\n\n    print('A simulation was successfully done.')\n    return res", "response": "This task is for an example."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_number_observer(*args, **kwargs):\n    interactive = kwargs.pop('interactive', False)\n    if interactive:\n        plot_number_observer_with_nya(*args, **kwargs)\n    # elif __on_ipython_notebook():\n    #     kwargs['to_png'] = True\n    #     plot_number_observer_with_nya(*args, **kwargs)\n    else:\n        if kwargs.pop('to_png', None) is not None:\n            #XXX: Remove an option available only on nyaplot for the consistency\n            import warnings\n            warnings.warn(\n                \"An option 'to_png' is not available with matplotlib. Just ignored.\")\n        plot_number_observer_with_matplotlib(*args, **kwargs)", "response": "Generate a plot from NumberObservers and show it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a plot from received instance of World and show it.", "response": "def plot_world(*args, **kwargs):\n    \"\"\"\n    Generate a plot from received instance of World and show it.\n    See also plot_world_with_elegans and plot_world_with_matplotlib.\n\n    Parameters\n    ----------\n    world : World or str\n        World or a HDF5 filename to render.\n    interactive : bool, default True\n        Choose a visualizer. If False, show the plot with matplotlib.\n        If True (only available on IPython Notebook), show it with elegans.\n\n    Examples\n    --------\n    >>> plot_world(w)\n    >>> plot_world(w, interactive=False)\n\n    \"\"\"\n    interactive = kwargs.pop('interactive', True)\n    if interactive:\n        plot_world_with_elegans(*args, **kwargs)\n    else:\n        plot_world_with_matplotlib(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_movie(*args, **kwargs):\n    interactive = kwargs.pop('interactive', False)\n    if interactive:\n        plot_movie_with_elegans(*args, **kwargs)\n    else:\n        plot_movie_with_matplotlib(*args, **kwargs)", "response": "Generates a movie from received instances of World and show them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_trajectory(*args, **kwargs):\n    interactive = kwargs.pop('interactive', True)\n    if interactive:\n        plot_trajectory_with_elegans(*args, **kwargs)\n    else:\n        plot_trajectory_with_matplotlib(*args, **kwargs)", "response": "Generate a plot from received instance of TrajectoryObserver and show it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a plot from NumberObservers and show it on IPython notebook with matplotlib.", "response": "def plot_number_observer_with_matplotlib(*args, **kwargs):\n    \"\"\"\n    Generate a plot from NumberObservers and show it on IPython notebook\n    with matplotlib.\n\n    Parameters\n    ----------\n    obs : NumberObserver (e.g. FixedIntervalNumberObserver)\n    fmt : str, optional\n    opt : dict, optional\n        matplotlib plot options.\n\n    Examples\n    --------\n    >>> plot_number_observer(obs1)\n    >>> plot_number_observer(obs1, 'o')\n    >>> plot_number_observer(obs1, obs2, obs3, {'linewidth': 2})\n    >>> plot_number_observer(obs1, 'k-', obs2, 'k--')\n\n    \"\"\"\n    import matplotlib.pylab as plt\n    import numpy\n    import collections\n\n    special_keys = (\"xlim\", \"ylim\", \"xlabel\", \"ylabel\", \"legend\", \"x\", \"y\", \"filename\")\n    plot_opts = {key: value for key, value in kwargs.items()\n                 if key not in special_keys}\n\n    if 'axes.prop_cycle' in plt.rcParams.keys():\n        color_cycle = [prop['color'] for prop in plt.rcParams['axes.prop_cycle']]\n    else:\n        color_cycle = plt.rcParams['axes.color_cycle']\n\n    if \"y\" in kwargs.keys() and isinstance(kwargs[\"y\"], str):\n        kwargs[\"y\"] = (kwargs[\"y\"], )\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n\n    if len(args) > 1 and isinstance(args[1], str):\n        if len(args) % 2 == 0:\n            observers = [(args[i], args[i + 1]) for i in range(0, len(args), 2)]\n        else:\n            observers = [(args[i], args[i + 1]) for i in range(0, len(args) - 1, 2)]\n            observers.append(args[-1], None)\n    else:\n        observers = [(obs, None) for obs in args]\n\n    color_map = {}\n    data, xidx = None, 0\n    for obs, fmt in observers:\n        if isinstance(obs, types.FunctionType):\n            if data is None:\n                raise ValueError(\"A function must be given after an observer.\")\n            y = [obs(xi) for xi in data[xidx]]\n            opts = plot_opts.copy()\n            label = obs.__name__\n            opts[\"label\"] = label\n            if label not in color_map.keys():\n                color_map[label] = color_cycle[len(color_map) % len(color_cycle)]\n                opts[\"label\"] = label\n            opts[\"color\"] = color_map[label]\n            if fmt is None:\n                ax.plot(data[xidx], y, **opts)\n            else:\n                ax.plot(data[xidx], y, fmt, **opts)\n            continue\n\n        data = numpy.array(obs.data()).T\n\n        try:\n            err = obs.error().T\n        except AttributeError:\n            err = None\n\n        if \"x\" in kwargs.keys():\n            targets = [sp.serial() for sp in obs.targets()]\n            if kwargs[\"x\"] not in targets:\n                raise ValueError(\"[{0}] given as 'x' was not found.\".fomrat(kwargs[\"x\"]))\n            xidx = targets.index(kwargs[\"x\"]) + 1\n        else:\n            xidx = 0\n\n        if \"y\" in kwargs.keys():\n            targets = [sp.serial() for sp in obs.targets()]\n            targets = [(targets.index(serial), serial)\n                       for serial in kwargs[\"y\"] if serial in targets]\n        else:\n            targets = [sp.serial() for sp in obs.targets()]\n            targets = list(enumerate(targets))\n            # targets.sort(key=lambda x: x[1])\n\n        for idx, serial in targets:\n            opts = plot_opts.copy()\n\n            label = serial\n            if len(label) > 0 and label[0] == '_':\n                label = '$\\_$' + label[1:]  # XXX: lazy escaping for a special character\n            if label not in color_map.keys():\n                color_map[label] = color_cycle[len(color_map) % len(color_cycle)]\n                opts[\"label\"] = label\n            opts[\"color\"] = color_map[label]\n\n            if err is None:\n                if fmt is None:\n                    ax.plot(data[xidx], data[idx + 1], **opts)\n                else:\n                    ax.plot(data[xidx], data[idx + 1], fmt, **opts)\n            else:\n                if fmt is None:\n                    ax.errorbar(data[xidx], data[idx + 1],\n                        xerr=(None if xidx == 0 else err[xidx]), yerr=err[idx + 1],\n                        **opts)\n                else:\n                    ax.errorbar(data[xidx], data[idx + 1],\n                        xerr=(None if xidx == 0 else err[xidx]), yerr=err[idx + 1],\n                        fmt=fmt, **opts)\n\n    # if \"legend\" not in kwargs.keys() or kwargs[\"legend\"]:\n    #     ax.legend(*ax.get_legend_handles_labels(), loc=\"best\", shadow=True)\n    if \"legend\" not in kwargs.keys() or (kwargs[\"legend\"] is not None and kwargs[\"legend\"] is not False):\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if \"legend\" in kwargs and isinstance(kwargs[\"legend\"], dict):\n            legend_opts.update(kwargs[\"legend\"])\n        ax.legend(*ax.get_legend_handles_labels(), **legend_opts)\n\n    if \"xlabel\" in kwargs.keys():\n        ax.set_xlabel(kwargs[\"xlabel\"])\n    elif \"x\" in kwargs.keys():\n        ax.set_xlabel(\"The Number of Molecules [{0}]\".format(kwargs[\"x\"]))\n    else:\n        ax.set_xlabel(\"Time\")\n    if \"ylabel\" in kwargs.keys():\n        ax.set_ylabel(kwargs[\"ylabel\"])\n    else:\n        ax.set_ylabel(\"The Number of Molecules\")\n    if \"xlim\" in kwargs.keys():\n        ax.set_xlim(kwargs[\"xlim\"])\n    if \"ylim\" in kwargs.keys():\n        ax.set_ylim(kwargs[\"ylim\"])\n\n    if \"filename\" in kwargs.keys():\n        plt.savefig(kwargs[\"filename\"])\n    else:\n        plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a plot from NumberObservers and displays it on IPython notebook.", "response": "def plot_number_observer_with_nya(obs, config=None, width=600, height=400, x=None, y=None, to_png=False):\n    \"\"\"\n    Generate a plot from NumberObservers and show it on IPython notebook\n    with nyaplot.\n\n    Parameters\n    ----------\n    obs : NumberObserver (e.g. FixedIntervalNumberObserver)\n    config : dict, optional\n        A config data for coloring. The dictionary will be updated during this plot.\n    width : int, optional\n    height : int, optional\n    x : str, optional\n        A serial for x-axis. If None, x-axis corresponds time.\n    y : str or list of str\n        Serials for y axis.\n\n    \"\"\"\n    config = config or {}\n\n    from IPython.core.display import display, HTML\n    import numpy\n\n    config = {}\n    color_scale = default_color_scale(config=config)\n\n    data1, data2 = [], []\n    data = numpy.array(obs.data())\n\n    if x is None:\n        xidx = 0\n    else:\n        tmp = [sp.serial() for sp in obs.targets()]\n        if x not in tmp:\n            raise ValueError(\"[{0}] given as 'x' was not found.\".fomrat(x))\n        xidx = tmp.index(x) + 1\n\n    if y is None:\n        targets = [sp.serial() for sp in obs.targets()]\n        targets = list(enumerate(targets))\n        # targets.sort(key=lambda x: x[1])\n    else:\n        if isinstance(y, str):\n            y = (y, )\n        targets = [sp.serial() for sp in obs.targets()]\n        targets = [(targets.index(serial), serial)\n                   for serial in y if serial in targets]\n\n    for line in data:\n        tmp = {\"x\": line[xidx]}\n        for i, (idx, serial) in enumerate(targets):\n            tmp[\"y{0}\".format(i + 1)] = line[idx + 1]\n        data1.append(tmp)\n    for i, (idx, serial) in enumerate(targets):\n        label = serial\n        tmp = {\"type\": \"line\", \"data\": \"data1\",\n               \"options\": {\"x\": \"x\", \"y\": \"y{0}\".format(i + 1),\n                           \"stroke_width\": 2, \"title\": label,\n                           \"color\": color_scale.get_color(label)}}\n        data2.append(tmp)\n\n    xmin, xmax = data.T[xidx].min(), data.T[xidx].max()\n    yview = data.T.take([idx + 1 for idx, serial in targets], axis=0)\n    ymin, ymax = yview.min(), yview.max()\n\n    model = {\n        \"data\": {\"data1\": data1},\n        \"panes\": [{\"type\": 'rectangular',\n                   \"diagrams\": data2,\n                   \"options\": {\"width\": width, \"height\": height, \"xrange\": [xmin, xmax],\n                               \"yrange\": [ymin, ymax], \"legend\": True, \"zoom\": True}}]}\n    model_id = 'viz{0:s}'.format(str(uuid.uuid4()))\n    display(HTML(generate_html(\n        {'model': json.dumps(model), 'model_id': model_id, 'to_png': json.dumps(to_png)},\n        'templates/nya.tmpl')))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_movie_with_elegans(\n        worlds, radius=None, width=500, height=500, config=None, grid=False,\n        species_list=None):\n    \"\"\"\n    Generate a movie from received instances of World and show them\n    on IPython notebook.\n\n    Parameters\n    ----------\n    worlds : list of World\n        Worlds to render.\n    radius : float, default None\n        If this value is set, all particles in the world will be rendered\n        as if their radius are the same.\n    width : float, default 500\n        Width of the plotting area.\n    height : float, default 500\n        Height of the plotting area.\n    config : dict, default {}\n        Dict for configure default colors. Its values are colors unique\n        to each speices. The dictionary will be updated during this plot.\n        Colors included in config dict will never be used for other speices.\n    species_list : array of string, default None\n        If set, plot_movie will not search the list of species\n\n    \"\"\"\n    config = config or {}\n\n    from IPython.core.display import display, HTML\n    from jinja2 import Template\n\n    data = {}\n    sizes = {}\n    for i, world in enumerate(worlds):\n        species = __parse_world(world, radius, species_list)\n        for species_info in species:\n            if data.get(species_info['name']) is None:\n                data[species_info['name']] = []\n            data[species_info['name']].append({\n                'df': species_info['data'],\n                't': i\n            })\n            sizes[species_info['name']] = species_info['size']\n\n    options = {\n        'player': True,\n        'autorange': False,\n        'space_mode': 'wireframe',\n        'grid': grid,\n        'range': __get_range_of_world(worlds[0])\n    }\n\n    model_id = '\"movie' + str(uuid.uuid4()) + '\"'\n    color_scale = default_color_scale(config=config)\n\n    display(HTML(generate_html({\n        'model_id': model_id,\n        'names': json.dumps(list(data.keys())),\n        'data': json.dumps(list(data.values())),\n        'colors': json.dumps([color_scale.get_color(name)\n                              for name in data.keys()]),\n        'sizes': json.dumps([sizes[name] for name in data.keys()]),\n        'options': json.dumps(options)\n    }, 'templates/movie.tmpl')))", "response": "Generate a movie from received instances of World and show them on IPython notebook."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a plot from received instance of World and show it on IPython notebook. This method returns the instance of dict that indicates color setting for each speices. You can use the dict as the parameter of plot_world, in order to use the same colors in another plot. Parameters ---------- world : World or str World or a HDF5 filename to render. radius : float, default None If this value is set, all particles in the world will be rendered as if their radius are the same. width : float, default 350 Width of the plotting area. height : float, default 350 Height of the plotting area. config : dict, default {} Dict for configure default colors. Its values are colors unique to each speices. The dictionary will be updated during this plot. Colors included in config dict will never be used for other speices. species_list : array of string, default None If set, plot_world will not search the list of species. max_count : Integer, default 1000 The maximum number of particles to show for each species. debug : array of dict, default [] *** EXPERIMENTAL IMPRIMENTATION *** Example: >> [{'type': 'box', 'x': 10, 'y': 10, 'z': 10, 'options': {'width': 1, 'height': 1}}] type: 'box', 'plane', 'sphere', and 'cylinder' x, y, z: float options: box: width, height, depth plane: width, height sphere: radius cylinder: radius, height camera_position : tuple, default (-22, 23, 32) camera_rotaiton : tuple, default (-0.6, 0.5, 0.6) Initial position and rotation of camera. return_id : bool, default False If True, return a model id, which is required for `to_png` function.", "response": "def plot_world_with_elegans(\n        world, radius=None, width=350, height=350, config=None, grid=True,\n        wireframe=False, species_list=None, debug=None, max_count=1000,\n        camera_position=(-22, 23, 32), camera_rotation=(-0.6, 0.5, 0.6),\n        return_id=False, predicator=None):\n    \"\"\"\n    Generate a plot from received instance of World and show it on IPython notebook.\n    This method returns the instance of dict that indicates color setting\n    for each speices. You can use the dict as the parameter of plot_world,\n    in order to use the same colors in another plot.\n\n    Parameters\n    ----------\n    world : World or str\n        World or a HDF5 filename to render.\n    radius : float, default None\n        If this value is set, all particles in the world will be rendered\n        as if their radius are the same.\n    width : float, default 350\n        Width of the plotting area.\n    height : float, default 350\n        Height of the plotting area.\n    config : dict, default {}\n        Dict for configure default colors. Its values are colors unique\n        to each speices. The dictionary will be updated during this plot.\n        Colors included in config dict will never be used for other speices.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default 1000\n        The maximum number of particles to show for each species.\n    debug : array of dict, default []\n        *** EXPERIMENTAL IMPRIMENTATION ***\n        Example:\n        >> [{'type': 'box', 'x': 10, 'y': 10, 'z': 10, 'options': {'width': 1, 'height': 1}}]\n        type: 'box', 'plane', 'sphere', and 'cylinder'\n        x, y, z: float\n        options:\n            box: width, height, depth\n            plane: width, height\n            sphere: radius\n            cylinder: radius, height\n    camera_position : tuple, default (-22, 23, 32)\n    camera_rotaiton : tuple, default (-0.6, 0.5, 0.6)\n        Initial position and rotation of camera.\n    return_id : bool, default False\n        If True, return a model id, which is required for `to_png` function.\n\n    \"\"\"\n    config = config or {}\n\n    from IPython.core.display import display, HTML\n    from .simulation import load_world\n\n    if isinstance(world, str):\n        world = load_world(world)\n\n    species = __parse_world(world, radius, species_list, max_count, predicator)\n    color_scale = default_color_scale(config=config)\n    plots = []\n\n    for species_info in species:\n        plots.append({\n            'type': 'Particles',\n            'data': species_info['data'],\n            'options': {\n                'name': species_info['name'],\n                'color': color_scale.get_color(species_info['name']),\n                'size': species_info['size']\n            }\n        })\n\n    if debug is not None:\n        data = {'type': [], 'x': [], 'y': [], 'z': [], 'options': []}\n        for obj in debug:\n            for k, v in obj.items():\n                data[k].append(v)\n\n        plots.append({\n            'type': 'DebugObject',\n            'data': data,\n            'options': {}\n        })\n\n    model = {\n        'plots': plots,\n        'options': {\n            'world_width': width,\n            'world_height': height,\n            'range': __get_range_of_world(world),\n            'autorange': False,\n            'grid': grid,\n            'save_image': True\n            # 'save_image': False\n        }\n    }\n\n    if wireframe:\n        model['options']['space_mode'] = 'wireframe'\n\n    model_id = '\"viz' + str(uuid.uuid4()) + '\"'\n    display(HTML(generate_html(\n        {'model': json.dumps(model), 'model_id': model_id,\n        'px': camera_position[0], 'py': camera_position[1], 'pz': camera_position[2],\n        'rx': camera_rotation[0], 'ry': camera_rotation[1], 'rz': camera_rotation[2]},\n        'templates/particles.tmpl')))\n\n    if return_id:\n        return model_id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot a dense array of the species available in the current image.", "response": "def plot_dense_array(\n        arr, length=256, ranges=None, colors=(\"#a6cee3\", \"#fb9a99\"), grid=False, camera_position=(-22, 23, 32), camera_rotation=(-0.6, 0.5, 0.6)):\n    \"\"\"\n    Volume renderer\n\n    Parameters\n    ----------\n    arr : list of numpy.array\n        i.e. [array([[1,2,3], [2,3,4]]), array([[1,2,3]])]\n    ranges : list of tuple\n        ranges for x, y, and z axis\n        i.e. [(-100, 100), (-100, 100), (-100, 100)]\n    colors : list of string\n        colors for species\n    length : int\n        length of the texture\n        256 or 64\n    camera_position : tuple, default (-22, 23, 32)\n    camera_rotaiton : tuple, default (-0.6, 0.5, 0.6)\n        Initial position and rotation of camera.\n\n    \"\"\"\n    import numpy\n    from PIL import Image\n    from base64 import b64encode\n    from tempfile import TemporaryFile\n    from math import sqrt\n    from IPython.core.display import display, HTML\n    from functools import reduce\n\n    # unfold 3d box into 2d grid\n    def unfold(arr, dtype=None):\n        dtype = arr.dtype if dtype is None else dtype\n        i = sqrt(arr.shape[2])\n        f_per_row, f_per_column = i, i\n        # single channel (luminance)\n        try:\n            depth, height, width = arr.shape[:]\n            arr = arr.reshape((depth*height, width))\n            new_arr = numpy.empty((height*f_per_column, width*f_per_row), dtype=dtype)\n        # multi channel (RGB)\n        except ValueError:\n            depth, height, width, channel = arr.shape\n            arr = arr.reshape((depth*height, width, channel))\n            new_arr = numpy.empty((height*f_per_column, width*f_per_row, channel), dtype=dtype)\n        for h in range(0, int(f_per_column)):\n            for w in range(0, int(f_per_row)):\n                val = arr[(f_per_row*h+w)*height : (f_per_row*h+w+1)*height]\n                new_arr[h*height : (h+1)*height, w*width : (w+1)*width] = val\n        return new_arr\n\n    def hist(arr, ranges, length, color):\n        # create sample\n        hist, bins = numpy.histogramdd(arr, bins=tuple([length]*3), range=tuple(ranges))\n        # standardize value\n        colors = [int(color[1:][i*2:(i+1)*2], 16) for i in range(0, 3)]\n        len1d = reduce(lambda val, memo: memo*val, hist.shape, 1)\n        arr = [((val/numpy.max(hist))*(hist.copy())).reshape(len1d) for val in colors]\n        # add blue and green\n        return numpy.array(arr, dtype=numpy.int8).transpose().reshape(tuple(list(hist.shape) + [3]))\n    ranges = ranges if ranges is not None else [(numpy.min(a), numpy.max(a)) for a in numpy.array(arr).reshape((sum(map(len, arr)), 3)).transpose()]\n\n    hist_arr = [hist(a, ranges, length, colors[i]) for i, a in enumerate(arr)]\n    compressed = reduce(lambda p, n: p+n, hist_arr)\n\n    img = Image.fromarray(unfold(compressed), \"RGB\")\n    fp = TemporaryFile(\"r+b\")\n    img.save(fp, \"PNG\")\n    fp.seek(0)\n    encoded_url = \"data:image/png;base64,\" + b64encode(fp.read())\n\n    model = {\n        'plots': [{\n            'type': 'Volume',\n            'data': encoded_url,\n            'options': {\n                'name': \"\",\n                'width': length,\n                'height': length,\n                'depth': length,\n                'f_per_row': sqrt(length),\n                'f_per_column': sqrt(length)\n            }\n        }],\n        'options': {\n            'grid': grid,\n            'save_image': True\n        }\n    }\n\n    model_id = '\"viz' + str(uuid.uuid4()) + '\"'\n    display(HTML(generate_html(\n        {'model': json.dumps(model), 'model_id': model_id,\n        'px': camera_position[0], 'py': camera_position[1], 'pz': camera_position[2],\n        'rx': camera_rotation[0], 'ry': camera_rotation[1], 'rz': camera_rotation[2]},\n        'templates/particles.tmpl')))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_html(keywords, tmpl_path, package_name='ecell4.util'):\n    from jinja2 import Template\n\n    import pkgutil\n    template = Template(pkgutil.get_data(package_name, tmpl_path).decode())\n    # path = os.path.abspath(os.path.dirname(__file__)) + tmpl_path\n    # template = Template(open(path).read())\n    html = template.render(**keywords)\n    return html", "response": "Generate static html file from JSON model and its own id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_trajectory_with_elegans(\n        obs, width=350, height=350, config=None, grid=True, wireframe=False,\n        max_count=10, camera_position=(-22, 23, 32), camera_rotation=(-0.6, 0.5, 0.6),\n        plot_range=None):\n    \"\"\"\n    Generate a plot from received instance of TrajectoryObserver and show it\n    on IPython notebook.\n\n    Parameters\n    ----------\n    obs : TrajectoryObserver\n        TrajectoryObserver to render.\n    width : float, default 350\n        Width of the plotting area.\n    height : float, default 350\n        Height of the plotting area.\n    config : dict, default {}\n        Dict for configure default colors. Its values are colors unique\n        to each particle. The dictionary will be updated during this plot.\n        Colors included in config dict will never be used for other particles.\n    camera_position : tuple, default (-30, 31, 42)\n    camera_rotaiton : tuple, default (-0.6, 0.5, 0.6)\n        Initial position and rotation of camera.\n    plot_range : tuple, default None\n        Range for plotting. A triplet of pairs suggesting (rangex, rangey, rangez).\n        If None, the minimum volume containing all the trajectories is used.\n\n    \"\"\"\n    config = config or {}\n\n    from IPython.core.display import display, HTML\n\n    color_scale = default_color_scale(config=config)\n    plots = []\n\n    xmin, xmax, ymin, ymax, zmin, zmax = None, None, None, None, None, None\n\n    data = obs.data()\n    if max_count is not None and len(data) > max_count:\n        data = random.sample(data, max_count)\n\n    for i, y in enumerate(data):\n        xarr, yarr, zarr = [], [], []\n        for pos in y:\n            xarr.append(pos[0])\n            yarr.append(pos[1])\n            zarr.append(pos[2])\n\n        if xmin is None:\n            if len(y) > 0:\n                xmin, xmax = min(xarr), max(xarr)\n                ymin, ymax = min(yarr), max(yarr)\n                zmin, zmax = min(zarr), max(zarr)\n        else:\n            xmin, xmax = min([xmin] + xarr), max([xmax] + xarr)\n            ymin, ymax = min([ymin] + yarr), max([ymax] + yarr)\n            zmin, zmax = min([zmin] + zarr), max([zmax] + zarr)\n\n        name = str(i + 1)\n        c = color_scale.get_color(name)\n        plots.append({\n            'type': 'Line',\n            'data': {'x': xarr, 'y': yarr, 'z': zarr},\n            'options': {\n                'name': name,\n                'thickness': 2,  # XXX: 'thikness' doesn't work on Windows\n                'colors': [c, c]}\n        })\n\n    if plot_range is None:\n        if xmin is None:\n            xmin, xmax, ymin, ymax, zmin, zmax = 0, 1, 0, 1, 0, 1\n\n        max_length = max(xmax - xmin, ymax - ymin, zmax - zmin)\n        rangex = [(xmin + xmax - max_length) * 0.5,\n                  (xmin + xmax + max_length) * 0.5]\n        rangey = [(ymin + ymax - max_length) * 0.5,\n                  (ymin + ymax + max_length) * 0.5]\n        rangez = [(zmin + zmax - max_length) * 0.5,\n                  (zmin + zmax + max_length) * 0.5]\n        wrange = {'x': rangex, 'y': rangey, 'z': rangez}\n    else:\n        wrange = __get_range_of_trajectories(None, plot_range)\n\n    model = {\n        'plots': plots,\n        'options': {\n            'world_width': width,\n            'world_height': height,\n            'range': wrange,\n            'autorange': False,\n            'grid': grid,\n            'save_image': True\n        }\n    }\n\n    if wireframe:\n        model['options']['space_mode'] = 'wireframe'\n\n    model_id = '\"viz' + str(uuid.uuid4()) + '\"'\n    display(HTML(generate_html(\n        {'model': json.dumps(model), 'model_id': model_id,\n        'px': camera_position[0], 'py': camera_position[1], 'pz': camera_position[2],\n        'rx': camera_rotation[0], 'ry': camera_rotation[1], 'rz': camera_rotation[2]},\n        'templates/particles.tmpl')))", "response": "Generates a plot of a trajectory with a set of trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a scatter plot from a received instance of World and show it on IPython notebook notebook.", "response": "def plot_world_with_matplotlib(\n        world, marker_size=3, figsize=6, grid=True,\n        wireframe=False, species_list=None, max_count=1000, angle=None,\n        legend=True, noaxis=False, **kwargs):\n    \"\"\"\n    Generate a plot from received instance of World and show it on IPython notebook.\n\n    Parameters\n    ----------\n    world : World or str\n        World to render. A HDF5 filename is also acceptable.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default 1000\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    legend : bool, default True\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if species_list is None:\n        species_list = [p.species().serial() for pid, p in world.list_particles()]\n        species_list = sorted(\n            set(species_list), key=species_list.index)  # XXX: pick unique ones\n\n    fig, ax = __prepare_mplot3d_with_matplotlib(\n        __get_range_of_world(world), figsize, grid, wireframe, angle, noaxis)\n    scatters, plots = __scatter_world_with_matplotlib(\n        world, ax, species_list, marker_size, max_count, **kwargs)\n\n    # if legend:\n    #     ax.legend(handles=plots, labels=species_list, loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(handles=plots, labels=species_list,  **legend_opts)\n\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_trajectory_with_matplotlib(\n        obs, max_count=10, figsize=6, legend=True, angle=None,\n        wireframe=False, grid=True, noaxis=False, plot_range=None, **kwargs):\n    \"\"\"\n    Generate a plot from received instance of TrajectoryObserver and show it\n    on IPython notebook.\n\n    Parameters\n    ----------\n    obs : TrajectoryObserver\n        TrajectoryObserver to render.\n    max_count : Integer, default 10\n        The maximum number of particles to show. If None, show all.\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    legend : bool, default True\n    plot_range : tuple, default None\n        Range for plotting. A triplet of pairs suggesting (rangex, rangey, rangez).\n        If None, the minimum volume containing all the trajectories is used.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    data = obs.data()\n    if max_count is not None and len(data) > max_count:\n        data = random.sample(data, max_count)\n\n    fig, ax = __prepare_mplot3d_with_matplotlib(\n        __get_range_of_trajectories(data, plot_range),\n        figsize, grid, wireframe, angle, noaxis)\n\n    lines = []\n    for i, y in enumerate(data):\n        xarr, yarr, zarr = [], [], []\n        for pos in y:\n            xarr.append(pos[0])\n            yarr.append(pos[1])\n            zarr.append(pos[2])\n\n        lines.append((xarr, yarr, zarr))\n\n    __plot_trajectory_with_matplotlib(lines, ax, **kwargs)\n\n    # if legend:\n    #     ax.legend(loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n    plt.show()", "response": "Generates a plot from a TrajectoryObserver and show it on IPython notebook notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a trajectory from a TrajectoryObserver and show it on IPython notebook notebook.", "response": "def plot_trajectory2d_with_matplotlib(\n        obs, plane='xy', max_count=10, figsize=6, legend=True,\n        wireframe=False, grid=True, noaxis=False, plot_range=None, **kwargs):\n    \"\"\"\n    Make a 2D plot from received instance of TrajectoryObserver and show it\n    on IPython notebook.\n\n    Parameters\n    ----------\n    obs : TrajectoryObserver\n        TrajectoryObserver to render.\n    plane : str, default 'xy'\n        'xy', 'yz', 'zx'.\n    max_count : Integer, default 10\n        The maximum number of particles to show. If None, show all.\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    legend : bool, default True\n    plot_range : tuple, default None\n        Range for plotting. A triplet of pairs suggesting (rangex, rangey, rangez).\n        If None, the minimum volume containing all the trajectories is used.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    plane = plane.lower()\n    if len(plane) != 2 or plane[0] not in ('x', 'y', 'z') or plane[1] not in ('x', 'y', 'z'):\n        raise ValueError(\"invalid 'plane' argument [{}] was given.\".format(repr(plane)))\n    xidx = 0 if plane[0] == 'x' else (1 if plane[0] == 'y' else 2)\n    yidx = 0 if plane[1] == 'x' else (1 if plane[1] == 'y' else 2)\n\n    data = obs.data()\n    if max_count is not None and len(data) > max_count:\n        data = random.sample(data, max_count)\n\n    wrange = __get_range_of_trajectories(data, plot_range)\n    wrange = (wrange['x'], wrange['y'], wrange['z'])\n    wrange = {'x': wrange[xidx], 'y': wrange[yidx]}\n    fig, ax = __prepare_plot_with_matplotlib(\n        wrange, figsize, grid, wireframe, noaxis)\n    ax.set_xlabel(plane[0].upper())\n    ax.set_ylabel(plane[1].upper())\n\n    lines = []\n    for i, y in enumerate(data):\n        xarr, yarr, zarr = [], [], []\n        for pos in y:\n            xarr.append(pos[xidx])\n            yarr.append(pos[yidx])\n\n        lines.append((xarr, yarr))\n\n    __plot_trajectory2d_with_matplotlib(lines, ax, **kwargs)\n\n    # if legend:\n    #     ax.legend(loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a movie of a list of trajectories from a set of Worlds and returns a list of objects.", "response": "def plot_movie_of_trajectory2d_with_matplotlib(\n        obs, plane='xy', figsize=6, grid=True,\n        wireframe=False, max_count=None, angle=None, noaxis=False,\n        interval=0.16, repeat_delay=3000, stride=1, rotate=None,\n        legend=True, output=None, crf=10, bitrate='1M', plot_range=None, **kwargs):\n    \"\"\"\n    Generate a move from the received list of instances of World,\n    and show it on IPython notebook. This function may require ffmpeg.\n\n    Parameters\n    ----------\n    worlds : list or FixedIntervalHDF5Observer\n        A list of Worlds to render.\n    plane : str, default 'xy'\n        'xy', 'yz', 'zx'.\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    max_count : Integer, default None\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    interval : Integer, default 0.16\n        Parameters for matplotlib.animation.ArtistAnimation.\n    stride : Integer, default 1\n        Stride per frame.\n    legend : bool, default True\n    output : str, default None\n        An output filename. '.webm' or '.mp4' is only accepted.\n        If None, display a movie on IPython Notebook.\n    crf : int, default 10\n        The CRF value can be from 4-63. Lower values mean better quality.\n    bitrate : str, default '1M'\n        Target bitrate\n    plot_range : tuple, default None\n        Range for plotting. A triplet of pairs suggesting (rangex, rangey, rangez).\n        If None, the minimum volume containing all the trajectories is used.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import matplotlib.animation as animation\n    from IPython.display import display, HTML\n    from ecell4_base.core import Species, FixedIntervalHDF5Observer\n    from .simulation import load_world\n    import math\n\n    # print(\"Taking all data ...\")\n\n    plane = plane.lower()\n    if len(plane) != 2 or plane[0] not in ('x', 'y', 'z') or plane[1] not in ('x', 'y', 'z'):\n        raise ValueError(\"invalid 'plane' argument [{}] was given.\".format(repr(plane)))\n    xidx = 0 if plane[0] == 'x' else (1 if plane[0] == 'y' else 2)\n    yidx = 0 if plane[1] == 'x' else (1 if plane[1] == 'y' else 2)\n\n    data = obs.data()\n    if max_count is not None and len(data) > max_count:\n        data = random.sample(data, max_count)\n\n    lines = []\n    num_frames = 0\n    for i, y in enumerate(data):\n        xarr, yarr, zarr = [], [], []\n        for pos in y:\n            xarr.append(pos[xidx])\n            yarr.append(pos[yidx])\n\n        lines.append((xarr, yarr))\n        num_frames = max(num_frames, len(y))\n    num_frames = int(math.ceil(float(num_frames) / stride))\n\n    # print(\"Start preparing mplot3d ...\")\n\n    wrange = __get_range_of_trajectories(data, plot_range)\n    wrange = (wrange['x'], wrange['y'], wrange['z'])\n    wrange = {'x': wrange[xidx], 'y': wrange[yidx]}\n    fig, ax = __prepare_plot_with_matplotlib(\n        wrange, figsize, grid, wireframe, noaxis)\n    ax.set_xlabel(plane[0].upper())\n    ax.set_ylabel(plane[1].upper())\n\n    def _update_plot(i, plots, lines):\n        upto = i * stride\n        for plot, line in zip(plots, lines):\n            plot.set_xdata(line[0][: upto])\n            plot.set_ydata(line[1][: upto])\n\n        fig.canvas.draw()\n\n    # print(\"Start making animation ...\")\n\n    plots = __plot_trajectory2d_with_matplotlib(lines, ax, 0, **kwargs)\n\n    # if legend:\n    #     ax.legend(loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n\n    ani = animation.FuncAnimation(\n        fig, _update_plot, fargs=(plots, lines),\n        frames=num_frames, interval=interval, blit=False)\n\n    plt.close(ani._fig)\n    # print(\"Start generating a movie ...\")\n    display_anim(ani, output, fps=1.0 / interval, crf=crf, bitrate=bitrate)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_movie_of_trajectory_with_matplotlib(\n        obs, figsize=6, grid=True,\n        wireframe=False, max_count=None, angle=None, noaxis=False,\n        interval=0.16, repeat_delay=3000, stride=1, rotate=None,\n        legend=True, output=None, crf=10, bitrate='1M', plot_range=None, **kwargs):\n    \"\"\"\n    Generate a move from the received list of instances of World,\n    and show it on IPython notebook. This function may require ffmpeg.\n\n    Parameters\n    ----------\n    worlds : list or FixedIntervalHDF5Observer\n        A list of Worlds to render.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    max_count : Integer, default None\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    interval : Integer, default 0.16\n        Parameters for matplotlib.animation.ArtistAnimation.\n    stride : Integer, default 1\n        Stride per frame.\n    rotate : tuple, default None\n        A pair of rotation angles, elev and azim, for animation.\n        None means no rotation, same as (0, 0).\n    legend : bool, default True\n    output : str, default None\n        An output filename. '.webm' or '.mp4' is only accepted.\n        If None, display a movie on IPython Notebook.\n    crf : int, default 10\n        The CRF value can be from 4-63. Lower values mean better quality.\n    bitrate : str, default '1M'\n        Target bitrate\n    plot_range : tuple, default None\n        Range for plotting. A triplet of pairs suggesting (rangex, rangey, rangez).\n        If None, the minimum volume containing all the trajectories is used.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import matplotlib.animation as animation\n    from ecell4_base.core import Species, FixedIntervalHDF5Observer\n    from .simulation import load_world\n    import math\n\n    # print(\"Taking all data ...\")\n\n    data = obs.data()\n    if max_count is not None and len(data) > max_count:\n        data = random.sample(data, max_count)\n\n    lines = []\n    num_frames = 0\n    for i, y in enumerate(data):\n        xarr, yarr, zarr = [], [], []\n        for pos in y:\n            xarr.append(pos[0])\n            yarr.append(pos[1])\n            zarr.append(pos[2])\n\n        lines.append((xarr, yarr, zarr))\n        num_frames = max(num_frames, len(y))\n    num_frames = int(math.ceil(float(num_frames) / stride))\n\n    # print(\"Start preparing mplot3d ...\")\n\n    fig, ax = __prepare_mplot3d_with_matplotlib(\n        __get_range_of_trajectories(data, plot_range),\n        figsize, grid, wireframe, angle, noaxis)\n\n    def _update_plot(i, plots, lines):\n        upto = i * stride\n        for plot, line in zip(plots, lines):\n            plot.set_data(line[0][: upto], line[1][: upto])\n            plot.set_3d_properties(line[2][: upto])\n\n        if rotate is not None:\n            ax.elev += rotate[0]\n            ax.azim += rotate[1]\n\n        fig.canvas.draw()\n\n    # print(\"Start making animation ...\")\n\n    plots = __plot_trajectory_with_matplotlib(lines, ax, 0, **kwargs)\n\n    # if legend:\n    #     ax.legend(loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {\"loc\": \"best\", \"shadow\": True}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n\n    ani = animation.FuncAnimation(\n        fig, _update_plot, fargs=(plots, lines),\n        frames=num_frames, interval=interval, blit=False)\n\n    plt.close(ani._fig)\n    # print(\"Start generating a movie ...\")\n    display_anim(ani, output, fps=1.0 / interval, crf=crf, bitrate=bitrate)", "response": "This function generates a move from the received list of instances of World and displays a movie on IPython Notebook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a scatter plot from a World and show it on IPython notebook.", "response": "def plot_world_with_attractive_mpl(\n        world, marker_size=6, figsize=6, grid=True,\n        wireframe=False, species_list=None, max_count=1000, angle=None,\n        legend=True, noaxis=False, whratio=1.33, scale=1.0, **kwargs):\n    \"\"\"\n    Generate a plot from received instance of World and show it on IPython notebook.\n\n    Parameters\n    ----------\n    world : World or str\n        World to render. A HDF5 filename is also acceptable.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default 1000\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    legend : bool, default True\n    whratio : float, default 1.33\n        A ratio between figure width and height.\n        Customize this to keep a legend within the figure.\n    scale : float, default 1\n        A length-scaling factor\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if species_list is None:\n        species_list = [p.species().serial() for pid, p in world.list_particles()]\n        species_list = sorted(\n            set(species_list), key=species_list.index)  # XXX: pick unique ones\n\n    fig, ax = __prepare_mplot3d_with_attractive_mpl(\n        __get_range_of_world(world, scale), figsize, grid, wireframe, angle,\n        noaxis, whratio)\n    scatters, plots = __scatter_world_with_attractive_mpl(\n        world, ax, species_list, marker_size, max_count, scale, **kwargs)\n\n    # if legend:\n    #     ax.legend(handles=plots, labels=species_list, loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {'loc': 'center left', 'bbox_to_anchor': (1.0, 0.5),\n                       'shadow': False, 'frameon': False, 'fontsize': 'x-large',\n                       'scatterpoints': 1}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n        # ax.legend(handles=plots, labels=species_list,  **legend_opts)\n\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to plot a movie with attractive matplotlib.", "response": "def plot_movie_with_attractive_mpl(\n        worlds, marker_size=6, figsize=6, grid=True,\n        wireframe=False, species_list=None, max_count=None, angle=None, noaxis=False,\n        interval=0.16, repeat_delay=3000, stride=1, rotate=None,\n        legend=True, whratio=1.33, scale=1, output=None, crf=10, bitrate='1M', **kwargs):\n    \"\"\"\n    Generate a move from the received list of instances of World,\n    and show it on IPython notebook. This function may require ffmpeg.\n\n    Parameters\n    ----------\n    worlds : list or FixedIntervalHDF5Observer\n        A list of Worlds to render.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default None\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    interval : Integer, default 0.16\n        Parameters for matplotlib.animation.ArtistAnimation.\n    stride : Integer, default 1\n        Stride per frame.\n    rotate : tuple, default None\n        A pair of rotation angles, elev and azim, for animation.\n        None means no rotation, same as (0, 0).\n    legend : bool, default True\n    whratio : float, default 1.33\n        A ratio between figure width and height.\n        Customize this to keep a legend within the figure.\n    scale : float, default 1\n        A length-scaling factor\n    crf : int, default 10\n        The CRF value can be from 4-63. Lower values mean better quality.\n    bitrate : str, default '1M'\n        Target bitrate\n    output : str, default None\n        An output filename. '.webm' or '.mp4' is only accepted.\n        If None, display a movie on IPython Notebook.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import matplotlib.animation as animation\n    from ecell4_base.core import Species, FixedIntervalHDF5Observer\n    from .simulation import load_world\n    import os.path\n\n    # print(\"Start generating species_list ...\")\n\n    if isinstance(worlds, FixedIntervalHDF5Observer):\n        obs = worlds\n        worlds = []\n        for i in range(0, obs.num_steps(), stride):\n            filename = obs.filename(i)\n            if os.path.isfile(filename):\n                worlds.append(load_world(filename))\n            elif len(worlds) >0:\n                worlds.append(worlds[-1])\n    else:\n        worlds = worlds[:: stride]\n\n    if species_list is None:\n        species_list = []\n        for world in worlds:\n            species_list.extend(\n                [p.species().serial() for pid, p in world.list_particles()])\n            species_list = sorted(\n                set(species_list), key=species_list.index)  # XXX: pick unique ones\n\n    # print(\"Start preparing mplot3d ...\")\n\n    fig, ax = __prepare_mplot3d_with_attractive_mpl(\n        __get_range_of_world(worlds[0], scale), figsize, grid, wireframe, angle,\n        noaxis, whratio)\n\n    from mpl_toolkits.mplot3d.art3d import juggle_axes\n\n    def _update_plot(i, scatters, worlds, species_list):\n        world = worlds[i]\n        for i, name in enumerate(species_list):\n            xs, ys, zs = [], [], []\n            particles = world.list_particles_exact(Species(name))\n            if max_count is not None and len(particles) > max_count:\n                particles = random.sample(particles, max_count)\n            for pid, p in particles:\n                pos = p.position() * scale\n                xs.append(pos[0])\n                ys.append(pos[1])\n                zs.append(pos[2])\n            scatters[i]._offsets3d = juggle_axes(xs, ys, zs, 'z')\n\n        if rotate is not None:\n            ax.elev += rotate[0]\n            ax.azim += rotate[1]\n\n        fig.canvas.draw()\n\n    # print(\"Start making animation ...\")\n\n    color_scale = attractive_mpl_color_scale({})\n    scatters = []\n    for i, name in enumerate(species_list):\n        opts = dict(marker='o', s=(2 ** marker_size), edgecolors='white', alpha=0.7)\n        opts.update(kwargs)\n        scatters.append(\n            ax.scatter(\n                [], [], [], facecolor=color_scale.get_color(name), label=name, **opts))\n\n    # if legend:\n    #     ax.legend(loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {'loc': 'center left', 'bbox_to_anchor': (1.0, 0.5),\n                       'shadow': False, 'frameon': False, 'fontsize': 'x-large',\n                       'scatterpoints': 1}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n\n    ani = animation.FuncAnimation(\n        fig, _update_plot, fargs=(scatters, worlds, species_list),\n        frames=len(worlds), interval=interval, blit=False)\n\n    plt.close(ani._fig)\n\n    # print(\"Start generating a movie ...\")\n    display_anim(ani, output, fps=1.0 / interval, crf=crf, bitrate=bitrate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting a 2D plot from a World and show it on IPython notebook notebook.", "response": "def plot_world2d_with_matplotlib(\n        world, plane='xy', marker_size=3, figsize=6, grid=True,\n        wireframe=False, species_list=None, max_count=1000, angle=None,\n        legend=True, noaxis=False, scale=1.0, **kwargs):\n    \"\"\"\n    Make a 2D plot from received instance of World and show it on IPython notebook.\n\n    Parameters\n    ----------\n    world : World or str\n        World to render. A HDF5 filename is also acceptable.\n    plane : str, default 'xy'\n        'xy', 'yz', 'zx'.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default 1000\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    legend : bool, default True\n    scale : float, default 1\n        A length-scaling factor\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    plane = plane.lower()\n    if len(plane) != 2 or plane[0] not in ('x', 'y', 'z') or plane[1] not in ('x', 'y', 'z'):\n        raise ValueError(\"invalid 'plane' argument [{}] was given.\".format(repr(plane)))\n    xidx = 0 if plane[0] == 'x' else (1 if plane[0] == 'y' else 2)\n    yidx = 0 if plane[1] == 'x' else (1 if plane[1] == 'y' else 2)\n\n    if species_list is None:\n        species_list = [p.species().serial() for pid, p in world.list_particles()]\n        species_list = sorted(\n            set(species_list), key=species_list.index)  # XXX: pick unique ones\n\n    wrange = __get_range_of_world(world, scale)\n    wrange = (wrange['x'], wrange['y'], wrange['z'])\n    wrange = {'x': wrange[xidx], 'y': wrange[yidx]}\n\n    fig, ax = __prepare_plot_with_matplotlib(\n        wrange, figsize, grid, wireframe, noaxis)\n    scatters, plots = __scatter_world2d_with_matplotlib(\n        world, (xidx, yidx), ax, species_list, marker_size, max_count, scale, **kwargs)\n    ax.set_xlabel(plane[0].upper())\n    ax.set_ylabel(plane[1].upper())\n\n    # if legend:\n    #     ax.legend(handles=plots, labels=species_list, loc='best', shadow=True)\n    if legend is not None and legend is not False:\n        legend_opts = {'loc': 'center left', 'bbox_to_anchor': (1.0, 0.5),\n                       'shadow': False, 'frameon': False, 'fontsize': 'x-large',\n                       'scatterpoints': 1}\n        if isinstance(legend, dict):\n            legend_opts.update(legend)\n        ax.legend(**legend_opts)\n        # ax.legend(handles=plots, labels=species_list,  **legend_opts)\n\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to plot a movie on IPython notebook with matplotlib.", "response": "def plot_movie2d_with_matplotlib(\n        worlds, plane='xy', marker_size=3, figsize=6, grid=True,\n        wireframe=False, species_list=None, max_count=None, angle=None, noaxis=False,\n        interval=0.16, repeat_delay=3000, stride=1, rotate=None,\n        legend=True, scale=1, output=None, crf=10, bitrate='1M', **kwargs):\n    \"\"\"\n    Generate a movie projected on the given plane from the received list\n    of instances of World, and show it on IPython notebook.\n    This function may require ffmpeg.\n\n    Parameters\n    ----------\n    worlds : list or FixedIntervalHDF5Observer\n        A list of Worlds to render.\n    plane : str, default 'xy'\n        'xy', 'yz', 'zx'.\n    marker_size : float, default 3\n        Marker size for all species. Size is passed to scatter function\n        as argument, s=(2 ** marker_size).\n    figsize : float, default 6\n        Size of the plotting area. Given in inch.\n    species_list : array of string, default None\n        If set, plot_world will not search the list of species.\n    max_count : Integer, default None\n        The maximum number of particles to show for each species.\n        None means no limitation.\n    angle : tuple, default None\n        A tuple of view angle which is given as (azim, elev, dist).\n        If None, use default assumed to be (-60, 30, 10).\n    interval : Integer, default 0.16\n        Parameters for matplotlib.animation.ArtistAnimation.\n    stride : Integer, default 1\n        Stride per frame.\n    rotate : tuple, default None\n        A pair of rotation angles, elev and azim, for animation.\n        None means no rotation, same as (0, 0).\n    legend : bool, default True\n    scale : float, default 1\n        A length-scaling factor\n    output : str, default None\n        An output filename. '.webm' or '.mp4' is only accepted.\n        If None, display a movie on IPython Notebook.\n    crf : int, default 10\n        The CRF value can be from 4-63. Lower values mean better quality.\n    bitrate : str, default '1M'\n        Target bitrate\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import matplotlib.animation as animation\n    from ecell4_base.core import Species, FixedIntervalHDF5Observer\n    from .simulation import load_world\n\n    plane = plane.lower()\n    if len(plane) != 2 or plane[0] not in ('x', 'y', 'z') or plane[1] not in ('x', 'y', 'z'):\n        raise ValueError(\"invalid 'plane' argument [{}] was given.\".format(repr(plane)))\n    xidx = 0 if plane[0] == 'x' else (1 if plane[0] == 'y' else 2)\n    yidx = 0 if plane[1] == 'x' else (1 if plane[1] == 'y' else 2)\n\n    if isinstance(worlds, FixedIntervalHDF5Observer):\n        obs = worlds\n        worlds = []\n        for i in range(0, obs.num_steps(), stride):\n            filename = obs.filename(i)\n            if os.path.isfile(filename):\n                worlds.append(load_world(filename))\n            elif len(worlds) >0:\n                worlds.append(worlds[-1])\n    else:\n        worlds = worlds[:: stride]\n\n    if species_list is None:\n        species_list = []\n        for world in worlds:\n            species_list.extend(\n                [p.species().serial() for pid, p in world.list_particles()])\n            species_list = sorted(\n                set(species_list), key=species_list.index)  # XXX: pick unique ones\n\n    wrange = __get_range_of_world(worlds[0], scale)\n    wrange = (wrange['x'], wrange['y'], wrange['z'])\n    wrange = {'x': wrange[xidx], 'y': wrange[yidx]}\n\n    fig = plt.figure(figsize=(figsize, figsize))\n    ax = fig.gca()\n\n    color_scale = matplotlib_color_scale()\n\n    def _update_plot(i, worlds, species_list):\n        ax.cla()\n\n        ax.set_aspect('equal')\n        ax.grid(grid)\n        ax.set_xlim(*wrange['x'])\n        ax.set_ylim(*wrange['y'])\n        ax.set_xlabel(plane[0].upper())\n        ax.set_ylabel(plane[1].upper())\n\n        if noaxis:\n            ax.set_axis_off()\n\n        _legend = False\n\n        world = worlds[i]\n        for i, name in enumerate(species_list):\n            offsets = ([], [])\n            particles = world.list_particles_exact(Species(name))\n            if len(particles) == 0:\n                continue\n            _legend = True\n\n            if max_count is not None and len(particles) > max_count:\n                particles = random.sample(particles, max_count)\n            for pid, p in particles:\n                pos = p.position() * scale\n                offsets[0].append(pos[xidx])\n                offsets[1].append(pos[yidx])\n\n            ax.scatter(\n                offsets[0], offsets[1], marker='o', s=(2 ** marker_size),\n                lw=0, facecolor=color_scale.get_color(name), label=name)\n\n        if legend is not None and legend is not False and _legend:\n            legend_opts = {\"loc\": \"upper right\", \"shadow\": True}\n            if isinstance(legend, dict):\n                legend_opts.update(legend)\n            ax.legend(**legend_opts)\n\n        fig.canvas.draw()\n\n    ani = animation.FuncAnimation(\n        fig, _update_plot, fargs=(worlds, species_list),\n        frames=len(worlds), interval=interval, blit=False)\n\n    plt.close(ani._fig)\n    display_anim(ani, output, fps=1.0 / interval, crf=crf, bitrate=bitrate)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_world_with_plotly(world, species_list=None, max_count=1000):\n    if isinstance(world, str):\n        from .simulation import load_world\n        world = load_world(world)\n\n    if species_list is None:\n        species_list = [sp.serial() for sp in world.list_species()]\n        species_list.sort()\n\n    import random\n    from ecell4_base.core import Species\n\n    positions = {}\n    for serial in species_list:\n        x, y, z = [], [], []\n        particles = world.list_particles_exact(Species(serial))\n        if max_count is not None and len(particles) > max_count:\n            particles = random.sample(particles, max_count)\n        for pid, p in particles:\n            pos = p.position()\n            x.append(pos[0])\n            y.append(pos[1])\n            z.append(pos[2])\n\n        positions[serial] = (x, y, z)\n\n    import plotly\n    import plotly.graph_objs as go\n\n    plotly.offline.init_notebook_mode()\n\n    marker = dict(size=6, line=dict(color='rgb(204, 204, 204)', width=1),\n                  opacity=0.9, symbol='circle')\n\n    data = []\n    for serial, (x, y, z) in positions.items():\n        trace = go.Scatter3d(\n            x=x, y=y, z=z, mode='markers',\n            marker=marker, name=serial)\n        data.append(trace)\n\n    layout = go.Layout(margin=dict(l=0, r=0, b=0, t=0))\n    fig = go.Figure(data=data, layout=layout)\n    plotly.offline.iplot(fig)", "response": "Plot a World on IPython Notebook"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getUnitRegistry(length=\"meter\", time=\"second\", substance=\"item\", volume=None, other=()):\n    ureg = pint.UnitRegistry()\n    ureg.define('item = mole / (avogadro_number * 1 mole)')\n\n    try:\n        pint.molar\n    # except UndefinedUnitError:\n    except AttributeError:\n        # https://github.com/hgrecco/pint/blob/master/pint/default_en.txt#L75-L77\n        ureg.define('[concentration] = [substance] / [volume]')\n        ureg.define('molar = mol / (1e-3 * m ** 3) = M')\n\n    base_units = [unit for unit in (length, time, substance, volume) if unit is not None]\n    base_units.extend(other)\n    _ = ureg.System.from_lines(\n        [\"@system local using international\"] + base_units,\n        ureg.get_base_units)\n    ureg.default_system = 'local'\n\n    wrap_quantity(ureg.Quantity)\n\n    pint.set_application_registry(ureg)  # for pickling\n    return ureg", "response": "Returns a pint. UnitRegistry that can be used to create a new ecell4."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of unique item.", "response": "def interactor(self, geneList=None, org=None):\n        \"\"\"\n        Supposing geneList returns an unique item.\n        \"\"\"\n        geneList = geneList or []\n        organisms = organisms or []\n\n        querydata = self.interactions(geneList, org)\n        returnData = {}\n        for i in querydata:\n            if not returnData.get(i[\"symB\"][\"name\"]):\n                returnData[i[\"symB\"][\"name\"]] = {\"interactions\": []}\n            returnData[i[\"symB\"][\"name\"]][\"interactions\"].append(i)\n        return returnData"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the PsimiTab27 format table - 2 file.", "response": "def parse_psimitab(content, fmt='tab27'):\n    \"\"\"https://code.google.com/archive/p/psimi/wikis/PsimiTab27Format.wiki\n    \"\"\"\n    columns = [\n        'Unique identifier for interactor A',\n        'Unique identifier for interactor B',\n        'Alternative identifier for interactor A',\n        'Alternative identifier for interactor B',\n        'Aliases for A',\n        'Aliases for B',\n        'Interaction detection methods',\n        'First author',\n        'Identifier of the publication',\n        'NCBI Taxonomy identifier for interactor A',\n        'NCBI Taxonomy identifier for interactor B',\n        'Interaction types',\n        'Source databases',\n        'Interaction identifier(s)',\n        'Confidence score']\n    columns += [\n        'Complex expansion',\n        'Biological role A', 'Biological role B',\n        'Experimental role A', 'Experimental role B',\n        'Interactor type A', 'Interactor type B',\n        'Xref for interactor A', 'Xref for interactor B',\n        'Xref for the interaction',\n        'Annotaions for interactor A', 'Annotations for interactor B',\n        'Annotations for the interaction',\n        'NCBI Taxonomy identifier for the host organism',\n        'Prameters of the interaction',\n        'Creaction date', 'Update date',\n        'Checksum for the interactor A', 'Checksum for the interactor B',\n        'Checksum for the interaction',\n        'negative',\n        'Feature(s) for interactor A', 'Feature(s) for interactor B',\n        'Stoichiometry for interactor A', 'Stoichiometroy for interactor B',\n        'Participant identification method for interactor A',\n        'Participant identification method for interactor B'\n        ]\n    if fmt == 'tab25':\n        columns = columns[: 15]\n\n    rexp = re.compile(r\"(?P<fields>((\\\"([^\\\"]|((?<=\\\\)\\\"))*\\\")|([^\\t\\\"])|((?<=\\\\)\\\"))+)(\\t|$)\")\n\n    retval = []\n    for line in content.split('\\n'):\n        line = line.strip()\n        if line == '' or line[0] == '#':\n            continue\n\n        start = 0\n        tmp = []\n        for mobj in rexp.finditer(line):\n            if mobj.start() != start:\n                print(repr(line))\n            assert mobj.start() == start\n            start = mobj.end()\n            tmp.append(mobj.group('fields'))\n        assert len(tmp) == len(columns)\n        retval.append(dict(zip(columns, tmp)))\n    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_sbml(model, y0=None, volume=1.0, is_valid=True):\n    y0 = y0 or {}\n\n    import libsbml\n\n    document = libsbml.SBMLDocument(3, 1)\n\n    # ns = libsbml.XMLNamespaces()\n    # ns.add(\"http://www.ecell.org/ns/ecell4\", \"ecell4\")  #XXX: DUMMY URI\n    # document.setNamespaces(ns)\n\n    m = document.createModel()\n\n    comp1 = m.createCompartment()\n    comp1.setId('world')\n    comp1.setConstant(True)\n\n    if unit.HAS_PINT:\n        if isinstance(volume, unit._Quantity):\n            if unit.STRICT:\n                if isinstance(volume.magnitude, ecell4_base.core.Real3) and not unit.check_dimensionality(volume, '[length]'):\n                    raise ValueError(\"Cannot convert [volume] from '{}' ({}) to '[length]'\".format(\n                        volume.dimensionality, volume.u))\n                elif not unit.check_dimensionality(volume, '[volume]'):\n                    raise ValueError(\"Cannot convert [volume] from '{}' ({}) to '[volume]'\".format(\n                        volume.dimensionality, volume.u))\n            volume = volume.to_base_units().magnitude\n\n        y0 = y0.copy()\n        for key, value in y0.items():\n            if isinstance(value, unit._Quantity):\n                if not unit.STRICT:\n                    y0[key] = value.to_base_units().magnitude\n                elif unit.check_dimensionality(value, '[substance]'):\n                    y0[key] = value.to_base_units().magnitude\n                elif unit.check_dimensionality(value, '[concentration]'):\n                    volume = w.volume() if not isinstance(w, ecell4_base.spatiocyte.SpatiocyteWorld) else w.actual_volume()\n                    y0[key] = value.to_base_units().magnitude * volume\n                else:\n                    raise ValueError(\n                        \"Cannot convert a quantity for [{}] from '{}' ({}) to '[substance]'\".format(\n                            key, value.dimensionality, value.u))\n\n    if isinstance(volume, ecell4_base.core.Real3):\n        comp1.setSize(volume[0] * volume[1] * volume[2])\n    else:\n        comp1.setSize(volume)\n\n    comp1.setSpatialDimensions(3)\n\n    species_list = []\n    for rr in model.reaction_rules():\n        for sp in itertools.chain(rr.reactants(), rr.products()):\n            species_list.append(sp)\n    species_list = list(set(species_list))\n    species_list.sort()\n\n    sid_map = {}\n    for cnt, sp in enumerate(species_list):\n        sid_map[sp.serial()] = \"s{:d}\".format(cnt)\n\n    for sp in species_list:\n        sid = sid_map[sp.serial()]\n        s1 = m.createSpecies()\n        s1.setId(sid)\n        s1.setName(sp.serial())\n        s1.setCompartment('world')\n        s1.setConstant(False)\n        if sp.serial() in y0.keys():\n            s1.setInitialAmount(y0[sp.serial()])\n        else:\n            s1.setInitialAmount(0)\n\n        s1.setBoundaryCondition(False)\n        s1.setHasOnlySubstanceUnits(False)\n\n        # s1.appendAnnotation('<annotation><ecell4:extension><ecell4:species serial=\"{:s}\"/></ecell4:extension></annotation>'.format(sp.serial()))\n\n    for cnt, rr in enumerate(model.reaction_rules()):\n        desc = rr.get_descriptor()\n\n        r1 = m.createReaction()\n        r1.setId(\"r{:d}\".format(cnt))\n        r1.setReversible(True)\n        r1.setFast(False)\n\n        kinetic_law = r1.createKineticLaw()\n\n        species_coef_map = {}\n        if desc is None:\n            for sp in rr.reactants():\n                if sp not in species_coef_map.keys():\n                    species_coef_map[sp] = 1\n                else:\n                    species_coef_map[sp] += 1\n        else:\n            for sp, coef in zip(rr.reactants(), desc.reactant_coefficients()):\n                if sp not in species_coef_map.keys():\n                    species_coef_map[sp] = coef\n                else:\n                    species_coef_map[sp] += coef\n\n        if desc is None or isinstance(desc, ecell4_base.core.ReactionRuleDescriptorMassAction):\n            p1 = m.createParameter()\n            p1.setId(\"k{:d}\".format(cnt))\n            # p1 = kinetic_law.createLocalParameter()\n            # p1.setId(\"k\")\n            p1.setConstant(True)\n            p1.setValue(rr.k() if desc is None else desc.k())\n            # math_exp = \"k\"\n            math_exp = \"k{:d}\".format(cnt)\n            for sp, coef in species_coef_map.items():\n                sid = sid_map[sp.serial()]\n                if coef == 1.0:\n                    math_exp += \"*{:s}\".format(sid)\n                else:\n                    math_exp += \"*pow({:s},{:g})\".format(sid, coef)\n        elif isinstance(desc, ecell4_base.core.ReactionRuleDescriptorPyfunc):\n            math_exp = desc.as_string()\n            if math_exp in ('', '<lambda>'):\n                warnings.warn(\n                    \"The given ReactionRuleDescriptorPyfunc [{:s}] might be invalid.\".format(\n                        rr.as_string()))\n            math_exp = replace_parseobj(math_exp, sid_map)\n        else:\n            raise RuntimeError('Unknown derived type of ReactionRuleDescriptor was given [{}].'.format(type(desc)))\n\n        for sp, coef in species_coef_map.items():\n            sid = sid_map[sp.serial()]\n            s1 = r1.createReactant()\n            s1.setSpecies(sid)\n            s1.setConstant(False)\n            s1.setStoichiometry(coef)\n\n        if desc is None:\n            for sp in rr.products():\n                if sp not in species_coef_map.keys():\n                    species_coef_map[sp] = 1\n                else:\n                    species_coef_map[sp] += 1\n        else:\n            species_coef_map = {}\n            for sp, coef in zip(rr.products(), desc.product_coefficients()):\n                if sp not in species_coef_map.keys():\n                    species_coef_map[sp] = coef\n                else:\n                    species_coef_map[sp] += coef\n\n        for sp, coef in species_coef_map.items():\n            sid = sid_map[sp.serial()]\n            s1 = r1.createProduct()\n            s1.setSpecies(sid)\n            s1.setConstant(False)\n            s1.setStoichiometry(coef)\n\n        math_ast = libsbml.parseL3Formula(math_exp)\n        kinetic_law.setMath(math_ast)\n\n    if is_valid:\n        document.validateSBML()\n        num_errors = (document.getNumErrors(libsbml.LIBSBML_SEV_ERROR)\n                      + document.getNumErrors(libsbml.LIBSBML_SEV_FATAL))\n        if num_errors > 0:\n            messages = \"The generated document is not valid.\"\n            messages += \" {} errors were found:\\n\".format(num_errors)\n            for i in range(document.getNumErrors(libsbml.LIBSBML_SEV_ERROR)):\n                err = document.getErrorWithSeverity(i, libsbml.LIBSBML_SEV_ERROR)\n                messages += \"{}: {}\\n\".format(err.getSeverityAsString(), err.getShortMessage())\n            for i in range(document.getNumErrors(libsbml.LIBSBML_SEV_FATAL)):\n                err = document.getErrorWithSeverity(i, libsbml.LIBSBML_SEV_FATAL)\n                messages += \"{}: {}\\n\".format(err.getSeverityAsString(), err.getShortMessage())\n            raise RuntimeError(messages)\n\n    return document", "response": "Export a model as a SBMLDocument."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave a model in the SBML format.", "response": "def save_sbml(filename, model, y0=None, volume=1.0, is_valid=True):\n    \"\"\"\n    Save a model in the SBML format.\n\n    Parameters\n    ----------\n    model : NetworkModel\n    y0 : dict\n        Initial condition.\n    volume : Real or Real3, optional\n        A size of the simulation volume.\n    is_valid : bool, optional\n        Check if the generated model is valid. True as a default.\n\n    \"\"\"\n    y0 = y0 or {}\n\n    import libsbml\n\n    document = export_sbml(model, y0, volume, is_valid)\n\n    # with open(filename, 'w') as fout:\n    #     fout.write(libsbml.writeSBMLToString(document))\n    # writer = libsbml.SBMLWriter()\n    # writer.writeSBML(document, filename)\n    libsbml.writeSBML(document, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_sbml(document):\n    from ecell4.util.decorator import generate_ratelaw\n\n    m = document.getModel()\n\n    if m.getNumCompartments() == 0:\n        raise RuntimeError(\"No compartment was found.\")\n    elif m.getNumCompartments() > 1:\n        warnings.warn(\n            \"[{:d}] compartments were found.\".format(m.getNumCompartments())\n            + \" The second or later ones would be omitted.\")\n\n    comp1 = m.getCompartment(0)\n    volume = comp1.getVolume()\n\n    y0 = {}\n    sid_map = {}\n    for s1 in m.getListOfSpecies():\n        sid = s1.getId()\n        serial = s1.getName()\n        sid_map[sid] = serial\n        value = s1.getInitialAmount()\n        if value != 0:\n            y0[serial] = value\n\n    kmap = {}\n    for p1 in m.getListOfParameters():\n        pid = p1.getId()\n        if not re.match(\"^k[0-9]+$\", pid):\n            warnings.warn(\n                \"Parameter [{:s}] was just ommited.\".format(pid))\n        rid = \"r{:s}\".format(pid[1: ])\n        kmap[rid] = p1.getValue()\n\n    is_ode = False\n    rrs = []\n\n    for r1 in m.getListOfReactions():\n        rid = r1.getId()\n        print(rid)\n\n        is_massaction = (rid in kmap.keys())\n        if is_massaction:\n            k = kmap[rid]\n        else:\n            kinetic_law = r1.getKineticLaw()\n            formula = kinetic_law.getFormula()\n            k = replace_parseobj(formula, sid_map)\n\n        reactants, products = [], []\n\n        #XXX: The order of reactants is not consistent\n        for s1 in r1.getListOfReactants():\n            sid = s1.getSpecies()\n            if sid not in sid_map:\n                raise RuntimeError(\n                    \"Unknown Species' Id [{:s}] was given\".format(sid))\n            serial = sid_map[sid]\n            coef = s1.getStoichiometry()\n            reactants.append((serial, coef))\n\n        #XXX: The order of products is not consistent\n        for s1 in r1.getListOfProducts():\n            sid = s1.getSpecies()\n            if sid not in sid_map:\n                raise RuntimeError(\n                    \"Unknown Species' Id [{:s}] was given\".format(sid))\n            serial = sid_map[sid]\n            coef = s1.getStoichiometry()\n            products.append((serial, coef))\n\n        if (not is_massaction\n            or len(reactants) > 2\n            or any([coef not in (1, 2) for sp, coef in reactants])\n            or any([not coef.is_integer() for sp, coef in products])\n            or (len(reactants) == 2 and (reactants[0][1] == 2 or reactants[1][1] == 2))):\n            rr = ecell4_base.core.ReactionRule()\n\n            if is_massaction:\n                desc = ecell4_base.core.ReactionRuleDescriptorMassAction(k)\n            else:\n                func = generate_ratelaw(k, rr)\n                desc = ecell4_base.core.ReactionRuleDescriptorPyfunc(func, k)\n\n            desc.set_reactant_coefficients([coef for _, coef in reactants])\n            desc.set_product_coefficients([coef for _, coef in products])\n\n            rr.set_descriptor(desc)\n        else:\n            if len(reactants) == 1 and reactants[0][1] == 2:\n                reactants[0] = (reactants[0][0], 1)\n                reactants.append(reactants[0])\n\n            rr = ecell4_base.core.ReactionRule()\n            for serial, coef in reactants:\n                rr.add_reactant(ecell4_base.core.Species(serial))\n            for serial, coef in products:\n                for _ in range(int(coef)):\n                    rr.add_product(ecell4_base.core.Species(serial))\n            rr.set_k(k)\n\n        rrs.append(rr)\n\n    m = ecell4_base.core.NetworkModel()\n    for rr in rrs:\n        m.add_reaction_rule(rr)\n\n    return m, y0, volume", "response": "Imports a model from a SBML document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_sbml(filename):\n    import libsbml\n\n    document = libsbml.readSBML(filename)\n    document.validateSBML()\n    num_errors = (document.getNumErrors(libsbml.LIBSBML_SEV_ERROR)\n                  + document.getNumErrors(libsbml.LIBSBML_SEV_FATAL))\n    if num_errors > 0:\n        messages = \"The generated document is not valid.\"\n        messages += \" {} errors were found:\\n\".format(num_errors)\n        for i in range(document.getNumErrors(libsbml.LIBSBML_SEV_ERROR)):\n            err = document.getErrorWithSeverity(i, libsbml.LIBSBML_SEV_ERROR)\n            messages += \"{}: {}\\n\".format(err.getSeverityAsString(), err.getShortMessage())\n        for i in range(document.getNumErrors(libsbml.LIBSBML_SEV_FATAL)):\n            err = document.getErrorWithSeverity(i, libsbml.LIBSBML_SEV_FATAL)\n            messages += \"{}: {}\\n\".format(err.getSeverityAsString(), err.getShortMessage())\n        raise RuntimeError(messages)\n    return import_sbml(document)", "response": "Loads a model from a SBML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_model(is_netfree=False, without_reset=False, seeds=None, effective=False):\n    try:\n        if seeds is not None or is_netfree:\n            m = ecell4_base.core.NetfreeModel()\n        else:\n            m = ecell4_base.core.NetworkModel()\n\n        for sp in SPECIES_ATTRIBUTES:\n            m.add_species_attribute(sp)\n        for rr in REACTION_RULES:\n            m.add_reaction_rule(rr)\n\n        if not without_reset:\n            reset_model()\n\n        if seeds is not None:\n            return m.expand(seeds)\n\n        if isinstance(m, ecell4_base.core.NetfreeModel):\n            m.set_effective(effective)\n    except Exception as e:\n        reset_model()\n        raise e\n\n    return m", "response": "Generate a new model with parameters in the global scope SPECIES_ATTRIBUTES and REACTIONRULES."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_serial(target, jobs, n=1, **kwargs):\n    return [[target(copy.copy(job), i + 1, j + 1) for j in range(n)] for i, job in enumerate(jobs)]", "response": "Evaluate the given function with each set of arguments and return a list of results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the given function with each set of arguments and return a list of results.", "response": "def run_multiprocessing(target, jobs, n=1, nproc=None, **kwargs):\n    \"\"\"\n    Evaluate the given function with each set of arguments, and return a list of results.\n    This function does in parallel by using `multiprocessing`.\n\n    Parameters\n    ----------\n    target : function\n        A function to be evaluated. The function must accepts three arguments,\n        which are a list of arguments given as `jobs`, a job and task id (int).\n    jobs : list\n        A list of arguments passed to the function.\n        All the argument must be picklable.\n    n : int, optional\n        A number of tasks. Repeat the evaluation `n` times for each job.\n        1 for default.\n    nproc : int, optional\n        A number of cores available once.\n        If nothing is given, all available cores are used.\n\n    Returns\n    -------\n    results : list\n        A list of results. Each element is a list containing `n` results.\n\n    Examples\n    --------\n    >>> jobs = ((1, 'spam'), (2, 'ham'), (3, 'eggs'))\n\n    >>> target = lambda args, job_id, task_id: (args[1] * args[0])\n    >>> run_multiprocessing(target, jobs, nproc=2)\n    [['spam'], ['hamham'], ['eggseggseggs']]\n\n    >>> target = lambda args, job_id, task_id: \"{:d} {}\".format(task_id, args[1] * args[0])\n    >>> run_multiprocessing(target, jobs, n=2, nproc=2)\n    [['1 spam', '2 spam'], ['1 hamham', '2 hamham'], ['1 eggseggseggs', '2 eggseggseggs']]\n\n    See Also\n    --------\n    ecell4.extra.ensemble.run_serial\n    ecell4.extra.ensemble.run_sge\n    ecell4.extra.ensemble.run_slurm\n    ecell4.extra.ensemble.run_multiprocessing\n    ecell4.extra.ensemble.run_azure\n\n    \"\"\"\n    def consumer(f, q_in, q_out):\n        while True:\n            val = q_in.get()\n            if val is None:\n                q_in.task_done()\n                break\n            i, x = val\n            res = (i, f(*x))\n            q_in.task_done()\n            q_out.put(res)\n\n    def mulpmap(f, X, nproc):\n        nproc = nproc or multiprocessing.cpu_count()\n\n        q_in = multiprocessing.JoinableQueue()\n        q_out = multiprocessing.Queue()\n        workers = [multiprocessing.Process(target=consumer, args=(f, q_in, q_out), daemon=True) for _ in range(nproc)]\n        sent = [q_in.put((i, x)) for i, x in enumerate(X)]\n        num_tasks = len(sent)\n        [q_in.put(None) for _ in range(nproc)]  #XXX: poison pill\n        [w.start() for w in workers]\n        # [w.join() for w in workers]\n        q_in.join()\n        res = [q_out.get() for _ in range(num_tasks)]\n        return [x for (_, x) in sorted(res)]\n\n    res = mulpmap(\n        target, ((job, i + 1, j + 1) for (i, job), j in itertools.product(enumerate(jobs), range(n))), nproc)\n    return [res[i: i + n] for i in range(0, len(res), n)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a function on the Sun Grid Engine einvironment.", "response": "def run_sge(target, jobs, n=1, nproc=None, path='.', delete=True, wait=True, environ=None, modules=(), **kwargs):\n    \"\"\"\n    Evaluate the given function with each set of arguments, and return a list of results.\n    This function does in parallel on the Sun Grid Engine einvironment.\n\n    Parameters\n    ----------\n    target : function\n        A function to be evaluated. The function must accepts three arguments,\n        which are a list of arguments given as `jobs`, a job and task id (int).\n        This function can not be a lambda.\n    jobs : list\n        A list of arguments passed to the function.\n        All the argument must be picklable.\n    n : int, optional\n        A number of tasks. Repeat the evaluation `n` times for each job.\n        1 for default.\n    nproc : int, optional\n        A number of cores available once.\n        If nothing is given, it runs with no limit.\n    path : str, optional\n        A path for temporary files to be saved. The path is created if not exists.\n        The current directory is used as its default.\n    delete : bool, optional\n        Whether it removes temporary files after the successful execution.\n        True for default.\n    wait : bool, optional\n        Whether it waits until all jobs are finished. If False, it just submits jobs.\n        True for default.\n    environ : dict, optional\n        An environment variables used when running jobs.\n        \"PYTHONPATH\" and \"LD_LIBRARY_PATH\" is inherited when no `environ` is given.\n    modules : list, optional\n        A list of module names imported before evaluating the given function.\n        The modules are loaded as: `from [module] import *`.\n\n    Returns\n    -------\n    results : list\n        A list of results. Each element is a list containing `n` results.\n\n    Examples\n    --------\n    >>> jobs = ((1, 'spam'), (2, 'ham'), (3, 'eggs'))\n\n    >>> def target(args, job_id, task_id):\n    ...     return (args[1] * args[0])\n    ...\n    >>> run_sge(target, jobs, nproc=2, path='.tmp')\n    [['spam'], ['hamham'], ['eggseggseggs']]\n\n    >>> def target(args, job_id, task_id):\n    ...     return \"{:d} {}\".format(task_id, args[1] * args[0])\n    ...\n    >>> run_sge(target, jobs, n=2, nproc=2, path='.tmp')\n    [['1 spam', '2 spam'], ['1 hamham', '2 hamham'], ['1 eggseggseggs', '2 eggseggseggs']]\n\n    See Also\n    --------\n    ecell4.extra.ensemble.run_serial\n    ecell4.extra.ensemble.run_sge\n    ecell4.extra.ensemble.run_slurm\n    ecell4.extra.ensemble.run_multiprocessing\n    ecell4.extra.ensemble.run_azure\n\n    \"\"\"\n    logging.basicConfig(level=logging.DEBUG)\n\n    if isinstance(target, types.LambdaType) and target.__name__ == \"<lambda>\":\n        raise RuntimeError(\"A lambda function is not accepted\")\n\n    # src = textwrap.dedent(inspect.getsource(singlerun)).replace(r'\"', r'\\\"')\n    src = textwrap.dedent(inspect.getsource(target)).replace(r'\"', r'\\\"')\n    if re.match('[\\s\\t]+', src.split('\\n')[0]) is not None:\n        raise RuntimeError(\n            \"Wrong indentation was found in the source translated\")\n\n    if not os.path.isdir(path):\n        os.makedirs(path)  #XXX: MYOB\n\n    if environ is None:\n        environ = {}\n        keys = (\"LD_LIBRARY_PATH\", \"PYTHONPATH\")\n        for key in keys:\n            if key in os.environ.keys():\n                environ[key] = os.environ[key]\n        if \"PYTHONPATH\" in environ.keys() and environ[\"PYTHONPATH\"].strip() != \"\":\n            environ[\"PYTHONPATH\"] = \"{}:{}\".format(os.getcwd(), environ[\"PYTHONPATH\"])\n        else:\n            environ[\"PYTHONPATH\"] = os.getcwd()\n\n    cmds = []\n    pickleins = []\n    pickleouts = []\n    scripts = []\n    for i, job in enumerate(jobs):\n        (fd, picklein) = tempfile.mkstemp(suffix='.pickle', prefix='sge-', dir=path)\n        with os.fdopen(fd, 'wb') as fout:\n            pickle.dump(job, fout)\n        pickleins.append(picklein)\n\n        pickleouts.append([])\n        for j in range(n):\n            fd, pickleout = tempfile.mkstemp(suffix='.pickle', prefix='sge-', dir=path)\n            os.close(fd)\n            pickleouts[-1].append(pickleout)\n        # pickleouts.append(\n        #     [tempfile.mkstemp(suffix='.pickle', prefix='sge-', dir=path)[1]\n        #      for j in range(n)])\n\n        code = 'import sys\\n'\n        code += 'import os\\n'\n        code += 'import pickle\\n'\n        code += 'with open(\\'{}\\', \\'rb\\') as fin:\\n'.format(picklein)\n        code += '    job = pickle.load(fin)\\n'\n        code += 'pass\\n'\n        for m in modules:\n            code += \"from {} import *\\n\".format(m)\n        code += src\n        code += '\\ntid = int(os.environ[\\'SGE_TASK_ID\\'])'\n        code += '\\nretval = {:s}(job, {:d}, tid)'.format(target.__name__, i + 1)\n        code += '\\nfilenames = {:s}'.format(str(pickleouts[-1]))\n        code += '\\npickle.dump(retval, open(filenames[tid - 1], \\'wb\\'))\\n'\n\n        (fd, script) = tempfile.mkstemp(suffix='.py', prefix='sge-', dir=path, text=True)\n        with os.fdopen(fd, 'w') as fout:\n            fout.write(code)\n        scripts.append(script)\n\n        cmd = '#!/bin/bash\\n'\n        for key, value in environ.items():\n            cmd += 'export {:s}={:s}\\n'.format(key, value)\n        cmd += 'python3 {}'.format(script)  #XXX: Use the same executer, python\n        # cmd += 'python3 -c \"\\n'\n        # cmd += 'import sys\\n'\n        # cmd += 'import os\\n'\n        # cmd += 'import pickle\\n'\n        # cmd += 'with open(sys.argv[1], \\'rb\\') as fin:\\n'\n        # cmd += '    job = pickle.load(fin)\\n'\n        # cmd += 'pass\\n'\n        # for m in modules:\n        #     cmd += \"from {} import *\\n\".format(m)\n        # cmd += src\n        # cmd += '\\ntid = int(os.environ[\\'SGE_TASK_ID\\'])'\n        # cmd += '\\nretval = {:s}(job, {:d}, tid)'.format(target.__name__, i + 1)\n        # cmd += '\\nfilenames = {:s}'.format(str(pickleouts[-1]))\n        # cmd += '\\npickle.dump(retval, open(filenames[tid - 1], \\'wb\\'))'\n        # cmd += '\" {:s}\\n'.format(picklein)\n        cmds.append(cmd)\n\n    if isinstance(wait, bool):\n        sync = 0 if not wait else 10\n    elif isinstance(wait, int):\n        sync = wait\n    else:\n        raise ValueError(\"'wait' must be either 'int' or 'bool'.\")\n\n    jobids = sge.run(cmds, n=n, path=path, delete=delete, sync=sync, max_running_tasks=nproc, **kwargs)\n\n    if not (sync > 0):\n        return None\n\n    for jobid, name in jobids:\n        outputs = sge.collect(jobid, name, n=n, path=path, delete=delete)\n        for output in outputs:\n            print(output, end='')\n\n    retval = [[pickle.load(open(pickleout, 'rb')) for pickleout in tasks]\n              for tasks in pickleouts]\n\n    if delete:\n        for tmpname in itertools.chain(pickleins, scripts, *pickleouts):\n            os.remove(tmpname)\n\n    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the given function with each set of arguments and return a list of results.", "response": "def run_azure(target, jobs, n=1, nproc=None, path='.', delete=True, config=None, **kwargs):\n    \"\"\"\n    Evaluate the given function with each set of arguments, and return a list of results.\n    This function does in parallel with Microsoft Azure Batch.\n\n    This function is the work in progress.\n    The argument `nproc` doesn't work yet.\n    See `ecell4.extra.azure_batch.run_azure` for details.\n\n    See Also\n    --------\n    ecell4.extra.ensemble.run_serial\n    ecell4.extra.ensemble.run_sge\n    ecell4.extra.ensemble.run_slurm\n    ecell4.extra.ensemble.run_multiprocessing\n    ecell4.extra.ensemble.run_azure\n    ecell4.extra.azure_batch.run_azure\n\n    \"\"\"\n    import ecell4.extra.azure_batch as azure_batch\n    return azure_batch.run_azure(target, jobs, n, path, delete, config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a single seed from a long seed given by genseeds.", "response": "def getseed(myseed, i):\n    \"\"\"\n    Return a single seed from a long seed given by `genseeds`.\n\n    Parameters\n    ----------\n    myseed : bytes\n        A long seed given by `genseeds(n)`.\n    i : int\n        An index less than n.\n\n    Returns\n    -------\n    rndseed : int\n        A seed (less than (2 ** 31))\n\n    \"\"\"\n    rndseed = int(myseed[(i - 1) * 8: i * 8], 16)\n    rndseed = rndseed % (2 ** 31)  #XXX: trancate the first bit\n    return rndseed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensemble_simulations(\n    t, y0=None, volume=1.0, model=None, solver='ode',\n    is_netfree=False, species_list=None, without_reset=False,\n    return_type='matplotlib', opt_args=(), opt_kwargs=None,\n    structures=None, rndseed=None,\n    n=1, nproc=None, method=None, errorbar=True,\n    **kwargs):\n    \"\"\"\n    Run simulations multiple times and return its ensemble.\n    Arguments are almost same with ``ecell4.util.simulation.run_simulation``.\n    `observers` and `progressbar` is not available here.\n\n    Parameters\n    ----------\n    n : int, optional\n        A number of runs. Default is 1.\n    nproc : int, optional\n        A number of processors. Ignored when method='serial'.\n        Default is None.\n    method : str, optional\n        The way for running multiple jobs.\n        Choose one from 'serial', 'multiprocessing', 'sge', 'slurm', 'azure'.\n        Default is None, which works as 'serial'.\n    **kwargs : dict, optional\n        Optional keyword arugments are passed through to `run_serial`,\n        `run_sge`, or `run_multiprocessing`.\n        See each function for more details.\n\n    Returns\n    -------\n    value : list, DummyObserver, or None\n        Return a value suggested by ``return_type``.\n        When ``return_type`` is 'array', return a time course data.\n        When ``return_type`` is 'observer', return a DummyObserver.\n        DummyObserver is a wrapper, which has the almost same interface\n        with NumberObservers.\n        Return nothing if else.\n\n    See Also\n    --------\n    ecell4.util.simulation.run_simulation\n    ecell4.extra.ensemble.run_serial\n    ecell4.extra.ensemble.run_sge\n    ecell4.extra.ensemble.run_slurm\n    ecell4.extra.ensemble.run_multiprocessing\n    ecell4.extra.ensemble.run_azure\n\n    \"\"\"\n    y0 = y0 or {}\n    opt_kwargs = opt_kwargs or {}\n    structures = structures or {}\n\n    for key, value in kwargs.items():\n        if key == 'r':\n            return_type = value\n        elif key == 'v':\n            volume = value\n        elif key == 's':\n            solver = value\n        elif key == 'm':\n            model = value\n\n    if model is None:\n        model = ecell4.util.decorator.get_model(is_netfree, without_reset)\n\n    if species_list is None:\n        species_list = list_species(model, y0.keys())\n\n    if rndseed is None:\n        myseed = genseeds(n)\n    elif (not isinstance(rndseed, bytes) or len(rndseed) != n * 4 * 2):\n        raise ValueError(\n            \"A wrong seed for the random number generation was given. Use 'genseeds'.\")\n\n    jobs = [{'t': t, 'y0': y0, 'volume': volume, 'model': model, 'solver': solver, 'species_list': species_list, 'structures': structures, 'myseed': myseed}]\n\n    if method is None or method.lower() == \"serial\":\n        retval = run_serial(singlerun, jobs, n=n, **kwargs)\n    elif method.lower() == \"sge\":\n        retval = run_sge(singlerun, jobs, n=n, nproc=nproc, **kwargs)\n    elif method.lower() == \"slurm\":\n        retval = run_slurm(singlerun, jobs, n=n, nproc=nproc, **kwargs)\n    elif method.lower() == \"multiprocessing\":\n        retval = run_multiprocessing(singlerun, jobs, n=n, nproc=nproc, **kwargs)\n    elif method.lower() == \"azure\":\n        retval = run_azure(singlerun, jobs, n=n, nproc=nproc, **kwargs)\n    else:\n        raise ValueError(\n            'Argument \"method\" must be one of \"serial\", \"multiprocessing\", \"slurm\" and \"sge\".')\n\n    if return_type is None or return_type in (\"none\", ):\n        return\n\n    assert len(retval) == len(jobs) == 1\n\n    if return_type in (\"array\", 'a'):\n        return retval[0]\n\n    import numpy\n\n    class DummyObserver:\n\n        def __init__(self, inputs, species_list, errorbar=True):\n            if len(inputs) == 0:\n                raise ValueError(\"No input was given.\")\n\n            t = numpy.array(inputs[0], numpy.float64).T[0]\n            mean = sum([numpy.array(data, numpy.float64).T[1: ] for data in inputs])\n            mean /= len(inputs)\n\n            self.__data = numpy.vstack([t, mean]).T\n\n            if errorbar:\n                var = sum([(numpy.array(data, numpy.float64).T[1: ] - mean) ** 2\n                             for data in inputs]) / len(inputs)\n                stdev = numpy.sqrt(var)\n                stder = stdev / numpy.sqrt(len(inputs))\n                # self.__error = numpy.vstack([t, stdev]).T\n                self.__error = numpy.vstack([t, stder]).T\n            else:\n                self.__error = None\n\n            self.__species_list = [ecell4_base.core.Species(serial) for serial in species_list]\n\n        def targets(self):\n            return self.__species_list\n\n        def data(self):\n            return self.__data\n\n        def t(self):\n            return self.__data.T[0]\n\n        def error(self):\n            return self.__error\n\n        def save(self, filename):\n            with open(filename, 'w') as fout:\n                writer = csv.writer(fout, delimiter=',', lineterminator='\\n')\n                writer.writerow(['\"{}\"'.format(sp.serial()) for sp in self.__species_list])\n                writer.writerows(self.data())\n\n    if return_type in (\"matplotlib\", 'm'):\n        if isinstance(opt_args, (list, tuple)):\n            ecell4.util.viz.plot_number_observer_with_matplotlib(\n                DummyObserver(retval[0], species_list, errorbar), *opt_args, **opt_kwargs)\n        elif isinstance(opt_args, dict):\n            # opt_kwargs is ignored\n            ecell4.util.viz.plot_number_observer_with_matplotlib(\n                DummyObserver(retval[0], species_list, errorbar), **opt_args)\n        else:\n            raise ValueError('opt_args [{}] must be list or dict.'.format(\n                repr(opt_args)))\n    elif return_type in (\"nyaplot\", 'n'):\n        if isinstance(opt_args, (list, tuple)):\n            ecell4.util.viz.plot_number_observer_with_nya(\n                DummyObserver(retval[0], species_list, errorbar), *opt_args, **opt_kwargs)\n        elif isinstance(opt_args, dict):\n            # opt_kwargs is ignored\n            ecell4.util.viz.plot_number_observer_with_nya(\n                DummyObserver(retval[0], species_list, errorbar), **opt_args)\n        else:\n            raise ValueError('opt_args [{}] must be list or dict.'.format(\n                repr(opt_args)))\n    elif return_type in (\"observer\", 'o'):\n        return DummyObserver(retval[0], species_list, errorbar)\n    elif return_type in (\"dataframe\", 'd'):\n        import pandas\n        return [\n            pandas.concat([\n                pandas.DataFrame(dict(Time=numpy.array(data).T[0],\n                                      Value=numpy.array(data).T[i + 1],\n                                      Species=serial))\n                for i, serial in enumerate(species_list)])\n            for data in retval[0]]\n    else:\n        raise ValueError(\n            'An invald value for \"return_type\" was given [{}].'.format(str(return_type))\n            + 'Use \"none\" if you need nothing to be returned.')", "response": "Run simulations multiple times and return its ensemble."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_bd5(\n        space, filename,\n        group_index=0, object_name=\"molecule\", spatial_unit=\"meter\", time_unit=\"second\",\n        trunc=False, with_radius=False):\n    \"\"\"Save a space in the BDML-BD5 format (https://github.com/openssbd/BDML-BD5).\n\n    Open file for read/write, if it already exists, and create a new file, otherwise.\n    If trunc is True, always create a new file.\n    A new group named `group_name` is created. If the group already exists, returns\n    an exception.\n\n    Parameters\n    ----------\n    space : Space, str, pathlib.PurePath, list, tuple or set\n        A Space or World to be saved. If str or pathlib.PurePath is given, a space is\n        loaded from the given path. If this is an iterable (list, tuple, set), apply\n        this function to each element of the given.\n    filename : str\n        A HDF5 filename.\n    group_index : int, optional\n        An index of the group written (0, 1, ..., n). Defaults to 0.\n    object_name : str, optional\n        A name of the object. Its length must be less than 128. Defaults to \"molecule\".\n    spatial_unit : str, optional\n        An unit of the length scale. Its length must be less than 16. Defaults to \"meter\".\n    time_unit : str, optional\n        An unit of the time scale. Its length must be less than 16. Defaults to \"second\".\n    trunc : bool, optional\n        Whether truncate file or not. If True, always overwrite the file when open it.\n        Defaults to False.\n    with_radius : bool, optional\n        Whether save the radius of particles. If True, particles are saved as 'sphere',\n        otherwise, as 'point'. Defaults to False.\n\n    \"\"\"\n    if isinstance(space, (list, tuple, set)):\n        for i, space_ in enumerate(space):\n            assert not isinstance(space_, (list, tuple, set))\n            save_bd5(\n                space_, filename, group_index + i, object_name, spatial_unit, time_unit,\n                trunc if i == 0 else False, with_radius)\n    elif isinstance(space, str):\n        save_bd5(load_world(space), filename, group_index, object_name, spatial_unit, time_unit, trunc, with_radius)\n    elif isinstance(space, pathlib.PurePath):\n        save_bd5(str(space), filename, group_index, object_name, spatial_unit, time_unit, trunc, with_radius)\n    else:\n        # space is expected to be either Space or World.\n        _save_bd5(space.as_base(), filename, group_index, object_name, spatial_unit, time_unit, trunc, with_radius)", "response": "Save a single BD5 file for read or write."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _escapeCharacters(tag):\n\tfor i,c in enumerate(tag.contents):\n\t\tif type(c) != bs4.element.NavigableString:\n\t\t\tcontinue\n\t\tc.replace_with(_escapeCharSub(r'\\\\\\1', c))", "response": "non - recursively escape underlines and asterisks in the tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _markdownify(tag, _listType=None, _blockQuote=False, _listIndex=1):\n\tchildren = tag.find_all(recursive=False)\n\n\tif tag.name == '[document]':\n\t\tfor child in children:\n\t\t\t_markdownify(child)\n\t\treturn\n\n\tif tag.name not in _supportedTags or not _supportedAttrs(tag):\n\t\tif tag.name not in _inlineTags:\n\t\t\ttag.insert_before('\\n\\n')\n\t\t\ttag.insert_after('\\n\\n')\n\t\telse:\n\t\t\t_escapeCharacters(tag)\n\t\t\tfor child in children:\n\t\t\t\t_markdownify(child)\n\t\treturn\n\tif tag.name not in ('pre', 'code'):\n\t\t_escapeCharacters(tag)\n\t\t_breakRemNewlines(tag)\n\tif tag.name == 'p':\n\t\tif tag.string != None:\n\t\t\tif tag.string.strip() == u'':\n\t\t\t\ttag.string = u'\\xa0'\n\t\t\t\ttag.unwrap()\n\t\t\t\treturn\n\t\tif not _blockQuote:\n\t\t\ttag.insert_before('\\n\\n')\n\t\t\ttag.insert_after('\\n\\n')\n\t\telse:\n\t\t\ttag.insert_before('\\n')\n\t\t\ttag.insert_after('\\n')\n\t\ttag.unwrap()\n\n\t\tfor child in children:\n\t\t\t_markdownify(child)\n\telif tag.name == 'br':\n\t\ttag.string = '  \\n'\n\t\ttag.unwrap()\n\telif tag.name == 'img':\n\t\talt = ''\n\t\ttitle = ''\n\t\tif tag.has_attr('alt'):\n\t\t\talt = tag['alt']\n\t\tif tag.has_attr('title') and tag['title']:\n\t\t\ttitle = ' \"%s\"' % tag['title']\n\t\ttag.string = '![%s](%s%s)' % (alt, tag['src'], title)\n\t\ttag.unwrap()\n\telif tag.name == 'hr':\n\t\ttag.string = '\\n---\\n'\n\t\ttag.unwrap()\n\telif tag.name == 'pre':\n\t\ttag.insert_before('\\n\\n')\n\t\ttag.insert_after('\\n\\n')\n\t\tif tag.code:\n\t\t\tif not _supportedAttrs(tag.code):\n\t\t\t\treturn\n\t\t\tfor child in tag.code.find_all(recursive=False):\n\t\t\t\tif child.name != 'br':\n\t\t\t\t\treturn\n\t\t\t# code block\n\t\t\tfor br in tag.code.find_all('br'):\n\t\t\t\tbr.string = '\\n'\n\t\t\t\tbr.unwrap()\n\t\t\ttag.code.unwrap()\n\t\t\tlines = unicode(tag).strip().split('\\n')\n\t\t\tlines[0] = lines[0][5:]\n\t\t\tlines[-1] = lines[-1][:-6]\n\t\t\tif not lines[-1]:\n\t\t\t\tlines.pop()\n\t\t\tfor i,line in enumerate(lines):\n\t\t\t\tline = line.replace(u'\\xa0', ' ')\n\t\t\t\tlines[i] = '    %s' % line\n\t\t\ttag.replace_with(BeautifulSoup('\\n'.join(lines), 'html.parser'))\n\t\treturn\n\telif tag.name == 'code':\n\t\t# inline code\n\t\tif children:\n\t\t\treturn\n\t\ttag.insert_before('`` ')\n\t\ttag.insert_after(' ``')\n\t\ttag.unwrap()\n\telif _recursivelyValid(tag):\n\t\tif tag.name == 'blockquote':\n\t\t\t# ! FIXME: hack\n\t\t\ttag.insert_before('<<<BLOCKQUOTE: ')\n\t\t\ttag.insert_after('>>>')\n\t\t\ttag.unwrap()\n\t\t\tfor child in children:\n\t\t\t\t_markdownify(child, _blockQuote=True)\n\t\t\treturn\n\t\telif tag.name == 'a':\n\t\t\t# process children first\n\t\t\tfor child in children:\n\t\t\t\t_markdownify(child)\n\t\t\tif not tag.has_attr('href'):\n\t\t\t\treturn\n\t\t\tif tag.string != tag.get('href') or tag.has_attr('title'):\n\t\t\t\ttitle = ''\n\t\t\t\tif tag.has_attr('title'):\n\t\t\t\t\ttitle = ' \"%s\"' % tag['title']\n\t\t\t\ttag.string = '[%s](%s%s)' % (BeautifulSoup(unicode(tag), 'html.parser').string,\n\t\t\t\t\ttag.get('href', ''),\n\t\t\t\t\ttitle)\n\t\t\telse:\n\t\t\t\t# ! FIXME: hack\n\t\t\t\ttag.string = '<<<FLOATING LINK: %s>>>' % tag.string\n\t\t\ttag.unwrap()\n\t\t\treturn\n\t\telif tag.name == 'h1':\n\t\t\ttag.insert_before('\\n\\n# ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name == 'h2':\n\t\t\ttag.insert_before('\\n\\n## ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name == 'h3':\n\t\t\ttag.insert_before('\\n\\n### ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name == 'h4':\n\t\t\ttag.insert_before('\\n\\n#### ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name == 'h5':\n\t\t\ttag.insert_before('\\n\\n##### ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name == 'h6':\n\t\t\ttag.insert_before('\\n\\n###### ')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\telif tag.name in ('ul', 'ol'):\n\t\t\ttag.insert_before('\\n\\n')\n\t\t\ttag.insert_after('\\n\\n')\n\t\t\ttag.unwrap()\n\t\t\tfor i, child in enumerate(children):\n\t\t\t\t_markdownify(child, _listType=tag.name, _listIndex=i+1)\n\t\t\treturn\n\t\telif tag.name == 'li':\n\t\t\tif not _listType:\n\t\t\t\t# <li> outside of list; ignore\n\t\t\t\treturn\n\t\t\tif _listType == 'ul':\n\t\t\t\ttag.insert_before('*   ')\n\t\t\telse:\n\t\t\t\ttag.insert_before('%d.   ' % _listIndex)\n\t\t\tfor child in children:\n\t\t\t\t_markdownify(child)\n\t\t\tfor c in tag.contents:\n\t\t\t\tif type(c) != bs4.element.NavigableString:\n\t\t\t\t\tcontinue\n\t\t\t\tc.replace_with('\\n    '.join(c.split('\\n')))\n\t\t\ttag.insert_after('\\n')\n\t\t\ttag.unwrap()\n\t\t\treturn\n\t\telif tag.name in ('strong','b'):\n\t\t\ttag.insert_before('__')\n\t\t\ttag.insert_after('__')\n\t\t\ttag.unwrap()\n\t\telif tag.name in ('em','i'):\n\t\t\ttag.insert_before('_')\n\t\t\ttag.insert_after('_')\n\t\t\ttag.unwrap()\n\t\tfor child in children:\n\t\t\t_markdownify(child)", "response": "recursively converts a tag into markdown"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert(html):\n\tbs = BeautifulSoup(html, 'html.parser')\n\t_markdownify(bs)\n\tret = unicode(bs).replace(u'\\xa0', '&nbsp;')\n\tret = re.sub(r'\\n{3,}', r'\\n\\n', ret)\n\t# ! FIXME: hack\n\tret = re.sub(r'&lt;&lt;&lt;FLOATING LINK: (.+)&gt;&gt;&gt;', r'<\\1>', ret)\n\t# ! FIXME: hack\n\tsp = re.split(r'(&lt;&lt;&lt;BLOCKQUOTE: .*?&gt;&gt;&gt;)', ret, flags=re.DOTALL)\n\tfor i,e in enumerate(sp):\n\t\tif e[:len('&lt;&lt;&lt;BLOCKQUOTE:')] == '&lt;&lt;&lt;BLOCKQUOTE:':\n\t\t\tsp[i] = '> ' + e[len('&lt;&lt;&lt;BLOCKQUOTE:') : -len('&gt;&gt;&gt;')]\n\t\t\tsp[i] = sp[i].replace('\\n', '\\n> ')\n\tret = ''.join(sp)\n\treturn ret.strip('\\n')", "response": "converts an html string to markdown while preserving unsupported markup."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, type):\n        if type == 0: return FilterDropShadow(id)\n        elif type == 1: return FilterBlur(id)\n        elif type == 2: return FilterGlow(id)\n        elif type == 3: return FilterBevel(id)\n        elif type == 4: return FilterGradientGlow(id)\n        elif type == 5: return FilterConvolution(id)\n        elif type == 6: return FilterColorMatrix(id)\n        elif type == 7: return FilterGradientBevel(id)\n        else:\n            raise Exception(\"Unknown filter type: %d\" % type)", "response": "Create a new filter object of the specified type"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dimensions(self):\n        return (self.xmax - self.xmin, self.ymax - self.ymin)", "response": "Returns the dimensions of the current region as tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexporting this SWF using the specified exporter.", "response": "def export(self, exporter=None, force_stroke=False):\n        \"\"\"\n        Export this SWF using the specified exporter. \n        When no exporter is passed in the default exporter used \n        is swf.export.SVGExporter.\n        \n        Exporters should extend the swf.export.BaseExporter class.\n        \n        @param exporter : the exporter to use\n        @param force_stroke : set to true to force strokes on fills,\n                              useful for some edge cases.\n        \"\"\"\n        exporter = SVGExporter() if exporter is None else exporter\n        if self._data is None:\n            raise Exception(\"This SWF was not loaded! (no data)\")\n        if len(self.tags) == 0:\n            raise Exception(\"This SWF doesn't contain any tags!\")\n        return exporter.export(self, force_stroke)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the SWF. The data parameter can be a SWFStream or a SWFHeader object.", "response": "def parse(self, data):\n        \"\"\" \n        Parses the SWF.\n        \n        The @data parameter can be a file object or a SWFStream\n        \"\"\"\n        self._data = data = data if isinstance(data, SWFStream) else SWFStream(data)\n        self._header = SWFHeader(self._data)\n        if self._header.compressed:\n            temp = BytesIO()\n            if self._header.compressed_zlib:\n                import zlib\n                data = data.f.read()\n                zip = zlib.decompressobj()\n                temp.write(zip.decompress(data))\n            else:\n                import pylzma\n                data.readUI32() #consume compressed length\n                data = data.f.read()\n                temp.write(pylzma.decompress(data))\n            temp.seek(0)\n            data = SWFStream(temp)\n        self._header._frame_size = data.readRECT()\n        self._header._frame_rate = data.readFIXED8()\n        self._header._frame_count = data.readUI16()\n        self.parse_tags(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a signed or unsigned int", "response": "def int32(x):\n    \"\"\" Return a signed or unsigned int \"\"\"\n    if x>0xFFFFFFFF:\n        raise OverflowError\n    if x>0x7FFFFFFF:\n        x=int(0x100000000-x)\n        if x<2147483648:\n            return -x\n        else:\n            return -2147483648\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a value as a binary string", "response": "def bin(self, s):\n        \"\"\" Return a value as a binary string \"\"\"\n        return str(s) if s<=1 else bin(s>>1) + str(s&1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the maximum number of bits needed to represent a value", "response": "def calc_max_bits(self, signed, values):\n        \"\"\" Calculates the maximim needed bits to represent a value \"\"\"\n        b = 0\n        vmax = -10000000\n        \n        for val in values:\n            if signed:\n                b = b | val if val >= 0 else b | ~val << 1\n                vmax = val if vmax < val else vmax\n            else:\n                b |= val;\n        bits = 0\n        if b > 0:\n            bits = len(self.bin(b)) - 2\n            if signed and vmax > 0 and len(self.bin(vmax)) - 2 >= bits:\n                bits += 1\n        return bits"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the specified number of bits from the stream.", "response": "def readbits(self, bits):\n        \"\"\"\n        Read the specified number of bits from the stream.\n        Returns 0 for bits == 0.\n        \"\"\"\n        \n        if bits == 0:\n            return 0\n        \n        # fast byte-aligned path\n        if bits % 8 == 0 and self._bits_pending == 0:\n            return self._read_bytes_aligned(bits // 8)\n        \n        out = 0\n        masks = self._masks\n        \n        def transfer_bits(x, y, n, t):\n            \"\"\"\n            transfers t bits from the top of y_n to the bottom of x.\n            then returns x and the remaining bits in y\n            \"\"\"\n            if n == t:\n                # taking all\n                return (x << t) | y, 0\n            \n            mask = masks[t]           # (1 << t) - 1\n            remainmask = masks[n - t] # (1 << n - t) - 1\n            taken = ((y >> n - t) & mask)\n            return (x << t) | taken, y & remainmask\n        \n        while bits > 0:\n            if self._bits_pending > 0:\n                assert self._partial_byte is not None\n                take = min(self._bits_pending, bits)\n                out, self._partial_byte = transfer_bits(out, self._partial_byte, self._bits_pending, take)\n                \n                if take == self._bits_pending:\n                    # we took them all\n                    self._partial_byte = None\n                self._bits_pending -= take\n                bits -= take\n                continue\n            \n            r = self.f.read(1)\n            if r == b'':\n                raise EOFError\n            self._partial_byte = ord(r)\n            self._bits_pending = 8\n        \n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a signed int using the specified number of bits.", "response": "def readSB(self, bits):\n        \"\"\" Read a signed int using the specified number of bits \"\"\"\n        shift = 32 - bits\n        return int32(self.readbits(bits) << shift) >> shift"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread an encoded unsigned int from the internal memory.", "response": "def readEncodedU32(self):\n        \"\"\" Read a encoded unsigned int \"\"\"\n        self.reset_bits_pending();\n        result = self.readUI8();\n        if result & 0x80 != 0:\n            result = (result & 0x7f) | (self.readUI8() << 7)\n            if result & 0x4000 != 0:\n                result = (result & 0x3fff) | (self.readUI8() << 14)\n                if result & 0x200000 != 0:\n                    result = (result & 0x1fffff) | (self.readUI8() << 21)\n                    if result & 0x10000000 != 0:\n                        result = (result & 0xfffffff) | (self.readUI8() << 28)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a 2 byte float from the internal buffer.", "response": "def readFLOAT16(self):\n        \"\"\" Read a 2 byte float \"\"\"\n        self.reset_bits_pending()\n        word = self.readUI16()\n        sign = -1 if ((word & 0x8000) != 0) else 1\n        exponent = (word >> 10) & 0x1f\n        significand = word & 0x3ff\n        if exponent == 0:\n            if significand == 0:\n                return 0.0\n            else:\n                return sign * math.pow(2, 1 - SWFStream.FLOAT16_EXPONENT_BASE) * (significand / 1024.0)\n        if exponent == 31:\n            if significand == 0:\n                return float('-inf') if sign < 0 else float('inf')\n            else:\n                return float('nan')\n        # normal number\n        return sign * math.pow(2, exponent - SWFStream.FLOAT16_EXPONENT_BASE) * (1 + significand / 1024.0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a SWFTextRecord from the file.", "response": "def readTEXTRECORD(self, glyphBits, advanceBits, previousRecord=None, level=1):\n        \"\"\" Read a SWFTextRecord \"\"\"\n        if self.readUI8() == 0:\n            return None\n        else:\n            self.seek(self.tell() - 1)\n            return SWFTextRecord(self, glyphBits, advanceBits, previousRecord, level)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readACTIONRECORD(self):\n        action = None\n        actionCode = self.readUI8()\n        if actionCode != 0:\n            actionLength = self.readUI16() if actionCode >= 0x80 else 0\n            #print \"0x%x\"%actionCode, actionLength\n            action = SWFActionFactory.create(actionCode, actionLength)\n            action.parse(self)\n        return action", "response": "Reads a SWFActionRecord from the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readACTIONRECORDs(self):\n        out = []\n        while 1:\n            action = self.readACTIONRECORD()\n            if action:\n                out.append(action)\n            else:\n                break\n        return out", "response": "Read zero or more button records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readCLIPACTIONRECORD(self, version):\n        pos = self.tell()\n        flags = self.readUI32() if version >= 6 else self.readUI16()\n        if flags == 0:\n            return None\n        else:\n            self.seek(pos)\n            return SWFClipActionRecord(self, version)", "response": "Read a SWFClipActionRecord from the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readRGB(self):\n        self.reset_bits_pending();\n        r = self.readUI8()\n        g = self.readUI8()\n        b = self.readUI8()\n        return (0xff << 24) | (r << 16) | (g << 8) | b", "response": "Read a RGB color from the stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef readRGBA(self):\n        self.reset_bits_pending();\n        r = self.readUI8()\n        g = self.readUI8()\n        b = self.readUI8()\n        a = self.readUI8()\n        return (a << 24) | (r << 16) | (g << 8) | b", "response": "Read a RGBA color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a string from the file.", "response": "def readString(self):\n        \"\"\" Read a string \"\"\"\n        s = self.f.read(1)\n        string = b\"\"\n        while ord(s) > 0:\n            string += s\n            s = self.f.read(1)\n        return string.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readFILTER(self):\n        filterId = self.readUI8()\n        filter = SWFFilterFactory.create(filterId)\n        filter.parse(self)\n        return filter", "response": "Read a SWFFilter from the packet"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef readFILTERLIST(self):\n        number = self.readUI8()\n        return [self.readFILTER() for _ in range(number)]", "response": "Read a length - prefixed list of FILTERs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readBUTTONRECORDs(self, version):\n        out = []\n        while 1:\n            button = self.readBUTTONRECORD(version)\n            if button:\n                out.append(button)\n            else:\n                break\n        return out", "response": "Read zero or more button records."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readBUTTONCONDACTIONSs(self):\n        out = []\n        while 1:\n            action = self.readBUTTONCONDACTION()\n            if action:\n                out.append(action)\n            else:\n                break\n        return out", "response": "Read zero or more button - condition actions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a tag header from the stream.", "response": "def readtag_header(self):\n        \"\"\" Read a tag header \"\"\"\n        pos = self.tell()\n        tag_type_and_length = self.readUI16()\n        tag_length = tag_type_and_length & 0x003f\n        if tag_length == 0x3f:\n            # The SWF10 spec sez that this is a signed int.\n            # Shouldn't it be an unsigned int?\n            tag_length = self.readSI32();\n        return SWFRecordHeader(tag_type_and_length >> 6, tag_length, self.tell() - pos)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading - Read the specified number of bytes", "response": "def read(self, count=0):\n        \"\"\" Read \"\"\"\n        return self.f.read(count) if count > 0 else self.f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, type):\n        if type == 0: return TagEnd()\n        elif type == 1: return TagShowFrame()\n        elif type == 2: return TagDefineShape()\n        elif type == 4: return TagPlaceObject()\n        elif type == 5: return TagRemoveObject()\n        elif type == 6: return TagDefineBits()\n        elif type == 7: return TagDefineButton()\n        elif type == 8: return TagJPEGTables()\n        elif type == 9: return TagSetBackgroundColor()\n        elif type == 10: return TagDefineFont()\n        elif type == 11: return TagDefineText()\n        elif type == 12: return TagDoAction()\n        elif type == 13: return TagDefineFontInfo()\n        elif type == 14: return TagDefineSound()\n        elif type == 15: return TagStartSound()\n        elif type == 17: return TagDefineButtonSound()\n        elif type == 18: return TagSoundStreamHead()\n        elif type == 19: return TagSoundStreamBlock()\n        elif type == 20: return TagDefineBitsLossless()\n        elif type == 21: return TagDefineBitsJPEG2()\n        elif type == 22: return TagDefineShape2()\n        elif type == 24: return TagProtect()\n        elif type == 26: return TagPlaceObject2()\n        elif type == 28: return TagRemoveObject2()\n        elif type == 32: return TagDefineShape3()\n        elif type == 33: return TagDefineText2()\n        elif type == 34: return TagDefineButton2()\n        elif type == 35: return TagDefineBitsJPEG3()\n        elif type == 36: return TagDefineBitsLossless2()\n        elif type == 37: return TagDefineEditText()\n        elif type == 39: return TagDefineSprite()\n        elif type == 41: return TagProductInfo()\n        elif type == 43: return TagFrameLabel()\n        elif type == 45: return TagSoundStreamHead2()\n        elif type == 46: return TagDefineMorphShape()\n        elif type == 48: return TagDefineFont2()\n        elif type == 56: return TagExportAssets()\n        elif type == 58: return TagEnableDebugger()\n        elif type == 59: return TagDoInitAction()\n        elif type == 60: return TagDefineVideoStream()\n        elif type == 61: return TagVideoFrame()\n        elif type == 63: return TagDebugID()\n        elif type == 64: return TagEnableDebugger2()\n        elif type == 65: return TagScriptLimits()\n        elif type == 69: return TagFileAttributes()\n        elif type == 70: return TagPlaceObject3()\n        elif type == 73: return TagDefineFontAlignZones()\n        elif type == 74: return TagCSMTextSettings()\n        elif type == 75: return TagDefineFont3()\n        elif type == 76: return TagSymbolClass()\n        elif type == 77: return TagMetadata()\n        elif type == 78: return TagDefineScalingGrid()\n        elif type == 82: return TagDoABC()\n        elif type == 83: return TagDefineShape4()\n        elif type == 84: return TagDefineMorphShape2()\n        elif type == 86: return TagDefineSceneAndFrameLabelData()\n        elif type == 87: return TagDefineBinaryData()\n        elif type == 88: return TagDefineFontName()\n        elif type == 89: return TagStartSound2()\n        else: return None", "response": "Create a new tag by specifying an integer type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the character ids this tag refers to.", "response": "def get_dependencies(self):\n        \"\"\" Returns the character ids this tag refers to \"\"\"\n        s = super(SWFTimelineContainer, self).get_dependencies()\n        for dt in self.all_tags_of_type(DefinitionTag):\n            s.update(dt.get_dependencies())\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_tags_of_type(self, type_or_types, recurse_into_sprites = True):\n        for t in self.tags:\n            if isinstance(t, type_or_types):\n                yield t\n        if recurse_into_sprites:\n            for t in self.tags:\n                # recurse into nested sprites\n                if isinstance(t, SWFTimelineContainer):\n                    for containedtag in t.all_tags_of_type(type_or_types):\n                        yield containedtag", "response": "Generator for all tags of the given type_or_types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a dictionary of characterIds to their defining tags.", "response": "def build_dictionary(self):\n        \"\"\"\n        Return a dictionary of characterIds to their defining tags.\n        \"\"\"\n        d = {}\n        for t in self.all_tags_of_type(DefinitionTag, recurse_into_sprites = False):\n            if t.characterId in d:\n                #print 'redefinition of characterId %d:' % (t.characterId)\n                #print '  was:', d[t.characterId]\n                #print 'redef:', t\n                raise ValueError('illegal redefinition of character')\n            d[t.characterId] = t\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of sound streams in this timeline and its children.", "response": "def collect_sound_streams(self):\n        \"\"\"\n        Return a list of sound streams in this timeline and its children.\n        The streams are returned in order with respect to the timeline.\n\n        A stream is returned as a list: the first element is the tag\n        which introduced that stream; other elements are the tags\n        which made up the stream body (if any).\n        \"\"\"\n        rc = []\n        current_stream = None\n        # looking in all containers for frames\n        for tag in self.all_tags_of_type((TagSoundStreamHead, TagSoundStreamBlock)):\n            if isinstance(tag, TagSoundStreamHead):\n                # we have a new stream\n                current_stream = [ tag ]\n                rc.append(current_stream)\n            if isinstance(tag, TagSoundStreamBlock):\n                # we have a frame for the current stream\n                current_stream.append(tag)\n        return rc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of video streams in this timeline and its children.", "response": "def collect_video_streams(self):\n        \"\"\"\n        Return a list of video streams in this timeline and its children.\n        The streams are returned in order with respect to the timeline.\n\n        A stream is returned as a list: the first element is the tag\n        which introduced that stream; other elements are the tags\n        which made up the stream body (if any).\n        \"\"\"\n        rc = []\n        streams_by_id = {}\n\n        # scan first for all streams\n        for t in self.all_tags_of_type(TagDefineVideoStream):\n            stream = [ t ]\n            streams_by_id[t.characterId] = stream\n            rc.append(stream)\n\n        # then find the frames\n        for t in self.all_tags_of_type(TagVideoFrame):\n            # we have a frame for the /named/ stream\n            assert t.streamId in streams_by_id\n            streams_by_id[t.streamId].append(t)\n\n        return rc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, data, length, version=1):\n        pos = data.tell()\n        self.characterId = data.readUI16()\n        self.depth = data.readUI16();\n        self.matrix = data.readMATRIX();\n        self.hasCharacter = True;\n        self.hasMatrix = True;\n        if data.tell() - pos < length:\n            colorTransform = data.readCXFORM()\n            self.hasColorTransform = True", "response": "Parses a ISO - 8601 tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexporting the specified SWF to SVG.", "response": "def export(self, swf, force_stroke=False):\n        \"\"\" Exports the specified SWF to SVG.\n\n        @param swf  The SWF.\n        @param force_stroke Whether to force strokes on non-stroked fills.\n        \"\"\"\n        self.svg = self._e.svg(version=SVG_VERSION)\n        self.force_stroke = force_stroke\n        self.defs = self._e.defs()\n        self.root = self._e.g()\n        self.svg.append(self.defs)\n        self.svg.append(self.root)\n        self.shape_exporter.defs = self.defs\n        self._num_filters = 0\n        self.fonts = dict([(x.characterId,x) for x in swf.all_tags_of_type(TagDefineFont)])\n        self.fontInfos = dict([(x.characterId,x) for x in swf.all_tags_of_type(TagDefineFontInfo)])\n\n        # GO!\n        super(SVGExporter, self).export(swf, force_stroke)\n\n        # Setup svg @width, @height and @viewBox\n        # and add the optional margin\n        self.bounds = SVGBounds(self.svg)\n        self.svg.set(\"width\", \"%dpx\" % round(self.bounds.width))\n        self.svg.set(\"height\", \"%dpx\" % round(self.bounds.height))\n        if self._margin > 0:\n            self.bounds.grow(self._margin)\n        vb = [self.bounds.minx, self.bounds.miny,\n              self.bounds.width, self.bounds.height]\n        self.svg.set(\"viewBox\", \"%s\" % \" \".join(map(str,vb)))\n\n        # Return the SVG as StringIO\n        return self._serialize()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export(self, swf, shape, **export_opts):\n\n        # If `shape` is given as int, find corresponding shape tag.\n        if isinstance(shape, Tag):\n            shape_tag = shape\n        else:\n            shapes = [x for x in swf.all_tags_of_type((TagDefineShape, TagDefineSprite)) if x.characterId == shape]\n            if len(shapes):\n                shape_tag = shapes[0]\n            else:\n                raise Exception(\"Shape %s not found\" % shape)\n\n        from swf.movie import SWF\n\n        # find a typical use of this shape\n        example_place_objects = [x for x in swf.all_tags_of_type(TagPlaceObject) if x.hasCharacter and x.characterId == shape_tag.characterId]\n\n        if len(example_place_objects):\n            place_object = example_place_objects[0]\n            characters = swf.build_dictionary()\n            ids_to_export = place_object.get_dependencies()\n            ids_exported = set()\n            tags_to_export = []\n\n            # this had better form a dag!\n            while len(ids_to_export):\n                id = ids_to_export.pop()\n                if id in ids_exported or id not in characters:\n                    continue\n                tag = characters[id]\n                ids_to_export.update(tag.get_dependencies())\n                tags_to_export.append(tag)\n                ids_exported.add(id)\n            tags_to_export.reverse()\n            tags_to_export.append(place_object)\n        else:\n            place_object = TagPlaceObject()\n            place_object.hasCharacter = True\n            place_object.characterId = shape_tag.characterId\n            tags_to_export = [ shape_tag, place_object ]\n\n        stunt_swf = SWF()\n        stunt_swf.tags = tags_to_export\n\n        return super(SingleShapeSVGExporterMixin, self).export(stunt_swf, **export_opts)", "response": "Exports the specified shape of the SWF to SVG."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(self, swf, frame, **export_opts):\n        self.wanted_frame = frame\n        return super(FrameSVGExporterMixin, self).export(swf, *export_opts)", "response": "Exports a frame of the specified SWF to SVG."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting dictionary of keyword argument and value to positional argument equivalent to:: vnames = describe(f) return tuple([kwd[k] for k in vnames[offset:]])", "response": "def parse_arg(f, kwd, offset=0):\n    \"\"\"\n    convert dictionary of keyword argument and value to positional argument\n    equivalent to::\n\n        vnames = describe(f)\n        return tuple([kwd[k] for k in vnames[offset:]])\n\n    \"\"\"\n    vnames = describe(f)\n    return tuple([kwd[k] for k in vnames[offset:]])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget argument and error from args and errors", "response": "def _get_args_and_errors(self, minuit=None, args=None, errors=None):\n    \"\"\"\n    consistent algorithm to get argument and errors\n    1) get it from minuit if minuit is available\n    2) if not get it from args and errors\n    2.1) if args is dict parse it.\n    3) if all else fail get it from self.last_arg\n    \"\"\"\n    ret_arg = None\n    ret_error = None\n    if minuit is not None:  # case 1\n        ret_arg = minuit.args\n        ret_error = minuit.errors\n        return ret_arg, ret_error\n\n    # no minuit specified use args and errors\n    if args is not None:\n        if isinstance(args, dict):\n            ret_arg = parse_arg(self, args)\n        else:\n            ret_arg = args\n    else:  # case 3\n        ret_arg = self.last_arg\n\n    if errors is not None:\n        ret_error = errors\n\n    return ret_arg, ret_error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw_residual(x, y, yerr, xerr,\n                  show_errbars=True, ax=None,\n                  zero_line=True, grid=True,\n                  **kwargs):\n    \"\"\"Draw a residual plot on the axis.\n\n    By default, if show_errbars if True, residuals are drawn as blue points\n    with errorbars with no endcaps. If show_errbars is False, residuals are\n    drawn as a bar graph with black bars.\n\n    **Arguments**\n\n        - **x** array of numbers, x-coordinates\n\n        - **y** array of numbers, y-coordinates\n\n        - **yerr** array of numbers, the uncertainty on the y-values\n\n        - **xerr** array of numbers, the uncertainty on the x-values\n\n        - **show_errbars** If True, draw the data as a bar plot, else as an\n          errorbar plot\n\n        - **ax** Optional matplotlib axis instance on which to draw the plot\n\n        - **zero_line** If True, draw a red line at :math:`y = 0` along the\n          full extent in :math:`x`\n\n        - **grid** If True, draw gridlines\n\n        - **kwargs** passed to ``ax.errorbar`` (if ``show_errbars`` is True) or\n          ``ax.bar`` (if ``show_errbars`` if False)\n\n    **Returns**\n\n    The matplotlib axis instance the plot was drawn on.\n    \"\"\"\n    from matplotlib import pyplot as plt\n\n    ax = plt.gca() if ax is None else ax\n\n    if show_errbars:\n        plotopts = dict(fmt='b.', capsize=0)\n        plotopts.update(kwargs)\n        pp = ax.errorbar(x, y, yerr, xerr, zorder=0, **plotopts)\n    else:\n        plotopts = dict(color='k')\n        plotopts.update(kwargs)\n        pp = ax.bar(x - xerr, y, width=2*xerr, **plotopts)\n\n    if zero_line:\n        ax.plot([x[0] - xerr[0], x[-1] + xerr[-1]], [0, 0], 'r-', zorder=2)\n\n    # Take the `grid` kwarg to mean 'add a grid if True'; if grid is False and\n    # we called ax.grid(False) then any existing grid on ax would be turned off\n    if grid:\n        ax.grid(grid)\n\n    return ax", "response": "Draw a residual plot on the axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the compare function", "response": "def draw_compare(f, arg, edges, data, errors=None, ax=None, grid=True, normed=False, parts=False):\n    \"\"\"\n    TODO: this needs to be rewritten\n    \"\"\"\n    from matplotlib import pyplot as plt\n\n    # arg is either map or tuple\n    ax = plt.gca() if ax is None else ax\n    arg = parse_arg(f, arg, 1) if isinstance(arg, dict) else arg\n    x = (edges[:-1] + edges[1:]) / 2.0\n    bw = np.diff(edges)\n    yf = vector_apply(f, x, *arg)\n    total = np.sum(data)\n    if normed:\n        ax.errorbar(x, data / bw / total, errors / bw / total, fmt='.b',\n                    zorder=0)\n        ax.plot(x, yf, 'r', lw=2, zorder=2)\n    else:\n        ax.errorbar(x, data, errors, fmt='.b', zorder=0)\n        ax.plot(x, yf * bw, 'r', lw=2, zorder=2)\n\n    # now draw the parts\n    if parts:\n        if not hasattr(f, 'eval_parts'):\n            warn(RuntimeWarning('parts is set to True but function does '\n                                'not have eval_parts method'))\n        else:\n            scale = bw if not normed else 1.\n            parts_val = list()\n            for tx in x:\n                val = f.eval_parts(tx, *arg)\n                parts_val.append(val)\n            py = zip(*parts_val)\n            for y in py:\n                tmpy = np.array(y)\n                ax.plot(x, tmpy * scale, lw=2, alpha=0.5)\n    plt.grid(grid)\n    return x, yf, data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw a pdf with given argument and bounds.", "response": "def draw_pdf(f, arg, bound, bins=100, scale=1.0, density=True,\n             normed_pdf=False, ax=None, **kwds):\n    \"\"\"\n    draw pdf with given argument and bounds.\n\n    **Arguments**\n\n        * **f** your pdf. The first argument is assumed to be independent\n          variable\n\n        * **arg** argument can be tuple or list\n\n        * **bound** tuple(xmin,xmax)\n\n        * **bins** number of bins to plot pdf. Default 100.\n\n        * **scale** multiply pdf by given number. Default 1.0.\n\n        * **density** plot density instead of expected count in each bin\n          (pdf*bin width). Default True.\n\n        * **normed_pdf** Normalize pdf in given bound. Default False\n\n        * The rest of keyword argument will be pass to pyplot.plot\n\n    **Returns**\n\n        x, y of what's being plot\n    \"\"\"\n    edges = np.linspace(bound[0], bound[1], bins)\n    return draw_pdf_with_edges(f, arg, edges, ax=ax, scale=scale, density=density,\n                               normed_pdf=normed_pdf, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_compare_hist(f, arg, data, bins=100, bound=None, ax=None, weights=None,\n                      normed=False, use_w2=False, parts=False, grid=True):\n    \"\"\"\n    draw histogram of data with poisson error bar and f(x,*arg).\n\n    ::\n\n        data = np.random.rand(10000)\n        f = gaussian\n        draw_compare_hist(f, {'mean':0,'sigma':1}, data, normed=True)\n\n    **Arguments**\n\n        - **f**\n        - **arg** argument pass to f. Can be dictionary or list.\n        - **data** data array\n        - **bins** number of bins. Default 100.\n        - **bound** optional boundary of plot in tuple form. If `None` is\n          given, the bound is determined from min and max of the data. Default\n          `None`\n        - **weights** weights array. Default None.\n        - **normed** optional normalized data flag. Default False.\n        - **use_w2** scaled error down to the original statistics instead of\n          weighted statistics.\n        - **parts** draw parts of pdf. (Works with AddPdf and Add2PdfNorm).\n          Default False.\n    \"\"\"\n    from matplotlib import pyplot as plt\n\n    ax = plt.gca() if ax is None else ax\n    bound = minmax(data) if bound is None else bound\n    h, e = np.histogram(data, bins=bins, range=bound, weights=weights)\n    err = None\n    if weights is not None and use_w2:\n        err, _ = np.histogram(data, bins=bins, range=bound,\n                              weights=weights * weights)\n        err = np.sqrt(err)\n    else:\n        err = np.sqrt(h)\n    return draw_compare(f, arg, e, h, err, ax=ax, grid=grid, normed=normed, parts=parts)", "response": "Draw histogram of data with poisson error bar and f."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_toyn(f, nsample, ntoy, bound, accuracy=10000, quiet=True, **kwd):\n    return gen_toy(f, nsample * ntoy, bound, accuracy, quiet, **kwd).reshape((ntoy, nsample))", "response": "Generate a ntoy random variates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gen_toy(f, nsample, bound, accuracy=10000, quiet=True, **kwd):\n    # based on inverting cdf this is fast but you will need to give it a reasonable range\n    # unlike roofit which is based on accept reject\n\n    vnames = describe(f)\n    if not quiet:\n        print(vnames)\n    my_arg = [kwd[v] for v in vnames[1:]]\n    # random number\n    # if accuracy is None: accuracy=10*numtoys\n    r = npr.random_sample(nsample)\n    x = np.linspace(bound[0], bound[1], accuracy)\n    pdf = _vector_apply(f, x, tuple(my_arg))\n    cdf = compute_cdf(pdf, x)\n    if cdf[-1] < 0.01:\n        warn(SmallIntegralWarning('Integral for given funcition is'\n                                  ' really low. Did you give it a reasonable range?'))\n    cdfnorm = cdf[-1]\n    cdf /= cdfnorm\n\n    # now convert that to toy\n    ret = invert_cdf(r, cdf, x)\n\n    if not quiet:\n        # move this to plotting\n        from matplotlib import pyplot as plt\n        plt.figure()\n        plt.title('comparison')\n        numbin = 100\n        h, e = np.histogram(ret, bins=numbin)\n        mp = (e[1:] + e[:-1]) / 2.\n        err = np.sqrt(h)\n        plt.errorbar(mp, h, err, fmt='.b')\n        bw = e[1] - e[0]\n        y = pdf * len(ret) / cdfnorm * bw\n        ylow = y + np.sqrt(y)\n        yhigh = y - np.sqrt(y)\n        plt.plot(x, y, label='pdf', color='r')\n        plt.fill_between(x, yhigh, ylow, color='g', alpha=0.2)\n        plt.grid(True)\n        plt.xlim(bound)\n        plt.ylim(ymin=0)\n    return ret", "response": "generate ntoy n to"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_uml(f, data, quiet=False, print_level=0, *arg, **kwd):\n    uml = UnbinnedLH(f, data)\n    minuit = Minuit(uml, print_level=print_level, **kwd)\n    minuit.set_strategy(2)\n    minuit.migrad()\n    if not minuit.migrad_ok() or not minuit.matrix_accurate():\n        if not quiet:\n            from matplotlib import pyplot as plt\n            plt.figure()\n            uml.show()\n            print(minuit.values)\n    return (uml, minuit)", "response": "fit a UML file to a single UML file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform chi^2 fit on a N - dimensional object.", "response": "def fit_binx2(f, data, bins=30, bound=None, print_level=0, quiet=False, *arg, **kwd):\n    \"\"\"\n    perform chi^2 fit\n    :param f:\n    :param data:\n    :param bins:\n    :param range:\n    :param printlevel:\n    :param quiet:\n    :param arg:\n    :param kwd:\n    :return:\n    \"\"\"\n    uml = BinnedChi2(f, data, bins=bins, bound=bound)\n    minuit = Minuit(uml, print_level=print_level, **kwd)\n    minuit.set_strategy(2)\n    minuit.migrad()\n    if not minuit.migrad_ok() or not minuit.matrix_accurate():\n        if not quiet:\n            from matplotlib import pyplot as plt\n            plt.figure()\n            uml.show()\n            print(minuit.values)\n\n    return (uml, minuit)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit_binlh(f, data, bins=30,\n              bound=None, quiet=False, weights=None, use_w2=False,\n              print_level=0, pedantic=True, extended=False,\n              *arg, **kwd):\n    \"\"\"\n    perform bin likelihood fit\n    :param f:\n    :param data:\n    :param bins:\n    :param range:\n    :param quiet:\n    :param weights:\n    :param use_w2:\n    :param printlevel:\n    :param pedantic:\n    :param extended:\n    :param arg:\n    :param kwd:\n    :return:\n    \"\"\"\n    uml = BinnedLH(f, data, bins=bins, bound=bound,\n                   weights=weights, use_w2=use_w2, extended=extended)\n    minuit = Minuit(uml, print_level=print_level, pedantic=pedantic, **kwd)\n    minuit.set_strategy(2)\n    minuit.migrad()\n    if not minuit.migrad_ok() or not minuit.matrix_accurate():\n        if not quiet:\n            from matplotlib import pyplot as plt\n            plt.figure()\n            uml.show()\n            print(minuit.values)\n    return (uml, minuit)", "response": "Perform bin likelihood fit on a N - term UML file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pprint_arg(vnames, value):\n    ret = ''\n    for name, v in zip(vnames, value):\n        ret += '%s=%s;' % (name, str(v))\n    return ret;", "response": "pretty print argument\n    :param vnames:\n    :param value:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_chunks(sequence, chunk_size):\n    return [\n        sequence[idx:idx + chunk_size]\n        for idx in range(0, len(sequence), chunk_size)\n    ]", "response": "Split a sequence into chunks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_kwargs(kwargs):\n    return {\n        key: value for key, value in six.iteritems(kwargs)\n        if key != 'self'\n    }", "response": "Get all keys and values from dictionary where key is not self."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck HTTP status code and raise exception if incorrect.", "response": "def check_status_code(response, codes=None):\n    \"\"\"Check HTTP status code and raise exception if incorrect.\n\n    :param Response response: HTTP response\n    :param codes: List of accepted codes or callable\n    :raises: ApiError if code invalid\n    \"\"\"\n    codes = codes or [httplib.OK]\n    checker = (\n        codes\n        if callable(codes)\n        else lambda resp: resp.status_code in codes\n    )\n    if not checker(response):\n        raise exceptions.ApiError(response, response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets result field from Betfair response or raise exception if not found.", "response": "def result_or_error(response):\n    \"\"\"Get `result` field from Betfair response or raise exception if not\n    found.\n\n    :param Response response:\n    :raises: ApiError if no results passed\n    \"\"\"\n    data = response.json()\n    result = data.get('result')\n    if result is not None:\n        return result\n    raise exceptions.ApiError(response, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_result(result, model=None):\n    if model is None:\n        return result\n    if isinstance(result, collections.Sequence):\n        return [model(**item) for item in result]\n    return model(**result)", "response": "Cast response JSON to Betfair model s.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_payload(base, method, params):\n    payload = {\n        'jsonrpc': '2.0',\n        'method': '{base}APING/v1.0/{method}'.format(**locals()),\n        'params': utils.serialize_dict(params),\n        'id': 1,\n    }\n    return payload", "response": "Build Betfair JSON - RPC payload."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nearest_price(price, cutoffs=CUTOFFS):\n    if price <= MIN_PRICE:\n        return MIN_PRICE\n    if price > MAX_PRICE:\n        return MAX_PRICE\n\n    price = as_dec(price)\n    for cutoff, step in cutoffs:\n        if price < cutoff:\n            break\n    step = as_dec(step)\n    return float((price * step).quantize(2, ROUND_HALF_UP) / step)", "response": "Returns the nearest Befair price to price."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ticks_difference(price_1, price_2):\n    price_1_index = PRICES.index(as_dec(price_1))\n    price_2_index = PRICES.index(as_dec(price_2))\n    return abs(price_1_index - price_2_index)", "response": "Returns the absolute difference between two prices in terms of ticks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an exact valid Betfair price that is n_ticks ticks away from the given price.", "response": "def price_ticks_away(price, n_ticks):\n    \"\"\"Returns an exact, valid Betfair price that is n_ticks \"ticks\" away from\n    the given price. n_ticks may positive, negative or zero (in which case the\n    same price is returned) but if there is no price n_ticks away from the\n    given price then an exception will be thrown.\n\n    :param float price: An exact, valid Betfair price\n    :param float n_ticks: The number of ticks away from price the new price is\n    :returns: An exact, valid Betfair price\n    :rtype: float\n    \"\"\"\n    price_index = PRICES.index(as_dec(price))\n    return float(PRICES[price_index + n_ticks])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog in to Betfair. Sets session_token if successful.", "response": "def login(self, username, password):\n        \"\"\"Log in to Betfair. Sets `session_token` if successful.\n\n        :param str username: Username\n        :param str password: Password\n        :raises: BetfairLoginError\n        \"\"\"\n        response = self.session.post(\n            os.path.join(self.identity_url, 'certlogin'),\n            cert=self.cert_file,\n            data=urllib.urlencode({\n                'username': username,\n                'password': password,\n            }),\n            headers={\n                'X-Application': self.app_key,\n                'Content-Type': 'application/x-www-form-urlencoded',\n            },\n            timeout=self.timeout,\n        )\n        utils.check_status_code(response, [httplib.OK])\n        data = response.json()\n        if data.get('loginStatus') != 'SUCCESS':\n            raise exceptions.LoginError(response, data)\n        self.session_token = data['sessionToken']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves profit and loss for a given list of markets. :param list market_ids: List of markets to calculate profit and loss :param bool include_settled_bets: Option to include settled bets :param bool include_bsp_bets: Option to include BSP bets :param bool net_of_commission: Option to return profit and loss net of users current commission rate for this market including any special tariffs", "response": "def list_market_profit_and_loss(\n            self, market_ids, include_settled_bets=False,\n            include_bsp_bets=None, net_of_commission=None):\n        \"\"\"Retrieve profit and loss for a given list of markets.\n\n        :param list market_ids: List of markets to calculate profit and loss\n        :param bool include_settled_bets: Option to include settled bets\n        :param bool include_bsp_bets: Option to include BSP bets\n        :param bool net_of_commission: Option to return profit and loss net of\n            users current commission rate for this market including any special\n            tariffs\n        \"\"\"\n        return self.make_api_request(\n            'Sports',\n            'listMarketProfitAndLoss',\n            utils.get_kwargs(locals()),\n            model=models.MarketProfitAndLoss,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_list_market_book(self, market_ids, chunk_size, **kwargs):\n        return itertools.chain(*(\n            self.list_market_book(market_chunk, **kwargs)\n            for market_chunk in utils.get_chunks(market_ids, chunk_size)\n        ))", "response": "Split call to list_market_book into separate requests."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits call to list_market_profit_and_loss into separate requests.", "response": "def iter_list_market_profit_and_loss(\n            self, market_ids, chunk_size, **kwargs):\n        \"\"\"Split call to `list_market_profit_and_loss` into separate requests.\n\n        :param list market_ids: List of market IDs\n        :param int chunk_size: Number of records per chunk\n        :param dict kwargs: Arguments passed to `list_market_profit_and_loss`\n        \"\"\"\n        return itertools.chain(*(\n            self.list_market_profit_and_loss(market_chunk, **kwargs)\n            for market_chunk in utils.get_chunks(market_ids, chunk_size)\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef place_orders(self, market_id, instructions, customer_ref=None):\n        return self.make_api_request(\n            'Sports',\n            'placeOrders',\n            utils.get_kwargs(locals()),\n            model=models.PlaceExecutionReport,\n        )", "response": "Place new orders into market."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncanceling all bets on a market or fully orange specific orders on a market.", "response": "def cancel_orders(self, market_id, instructions, customer_ref=None):\n        \"\"\"Cancel all bets OR cancel all bets on a market OR fully or\n        partially cancel particular orders on a market.\n\n        :param str market_id: If not supplied all bets are cancelled\n        :param list instructions: List of `CancelInstruction` objects\n        :param str customer_ref: Optional order identifier string\n        \"\"\"\n        return self.make_api_request(\n            'Sports',\n            'cancelOrders',\n            utils.get_kwargs(locals()),\n            model=models.CancelExecutionReport,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates non - exposure changing fields.", "response": "def update_orders(self, market_id, instructions, customer_ref=None):\n        \"\"\"Update non-exposure changing fields.\n\n        :param str market_id: The market id these orders are to be placed on\n        :param list instructions: List of `UpdateInstruction` objects\n        :param str customer_ref: Optional order identifier string\n        \"\"\"\n        return self.make_api_request(\n            'Sports',\n            'updateOrders',\n            utils.get_kwargs(locals()),\n            model=models.UpdateExecutionReport,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_account_funds(self, wallet=None):\n        return self.make_api_request(\n            'Account',\n            'getAccountFunds',\n            utils.get_kwargs(locals()),\n            model=models.AccountFundsResponse,\n        )", "response": "Get available to bet amount."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the account statement for a specific locale.", "response": "def get_account_statement(\n            self, locale=None, from_record=None, record_count=None,\n            item_date_range=None, include_item=None, wallet=None):\n        \"\"\"Get account statement.\n\n        :param str locale: The language to be used where applicable\n        :param int from_record: Specifies the first record that will be returned\n        :param int record_count: Specifies the maximum number of records to be returned\n        :param TimeRange item_date_range: Return items with an itemDate within this date range\n        :param IncludeItem include_item: Which items to include\n        :param Wallet wallte: Which wallet to return statementItems for\n        \"\"\"\n        return self.make_api_request(\n            'Account',\n            'getAccountStatement',\n            utils.get_kwargs(locals()),\n            model=models.AccountStatementReport,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the details relating your account including your discount rate and Betfair point balance.", "response": "def get_account_details(self):\n        \"\"\"Returns the details relating your account, including your discount\n        rate and Betfair point balance.\n        \"\"\"\n        return self.make_api_request(\n            'Account',\n            'getAccountDetails',\n            utils.get_kwargs(locals()),\n            model=models.AccountDetailsResponse,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_currency_rates(self, from_currency=None):\n        return self.make_api_request(\n            'Account',\n            'listCurrencyRates',\n            utils.get_kwargs(locals()),\n            model=models.CurrencyRate,\n        )", "response": "Returns a list of currency rates based on given currency"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transfer_funds(self, from_, to, amount):\n        return self.make_api_request(\n            'Account',\n            'transferFunds',\n            utils.get_kwargs(locals()),\n            model=models.TransferResponse,\n        )", "response": "Transfer funds between the UK Exchange and Australian Exchange wallets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of comments in the object", "response": "def comment_count(object):\n    \"\"\"\n    Usage:\n        {% comment_count obj %}\n    or\n        {% comment_count obj as var %}\n    \"\"\"\n    return Comment.objects.filter(\n        object_id=object.pk,\n        content_type=ContentType.objects.get_for_model(object)\n    ).count()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef comments(object):\n    return Comment.objects.filter(\n        object_id=object.pk,\n        content_type=ContentType.objects.get_for_model(object)\n    )", "response": "Return a QuerySet of comments for the given object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef comment_form(context, object):\n    user = context.get(\"user\")\n    form_class = context.get(\"form\", CommentForm)\n    form = form_class(obj=object, user=user)\n    return form", "response": "Returns the comment form for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the url to comment on the object", "response": "def comment_target(object):\n    \"\"\"\n    Usage:\n        {% comment_target obj [as varname] %}\n    \"\"\"\n    return reverse(\"pinax_comments:post_comment\", kwargs={\n        \"content_type_id\": ContentType.objects.get_for_model(object).pk,\n        \"object_id\": object.pk\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the text and return a ParseResult instance.", "response": "def parse(self, text, html=True):\n        '''Parse the text and return a ParseResult instance.'''\n        self._urls = []\n        self._users = []\n        self._lists = []\n        self._tags = []\n\n        reply = REPLY_REGEX.match(text)\n        reply = reply.groups(0)[0] if reply is not None else None\n\n        parsed_html = self._html(text) if html else self._text(text)\n        return ParseResult(self._urls, self._users, reply,\n                           self._lists, self._tags, parsed_html)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a Tweet without generating HTML.", "response": "def _text(self, text):\n        '''Parse a Tweet without generating HTML.'''\n        URL_REGEX.sub(self._parse_urls, text)\n        USERNAME_REGEX.sub(self._parse_users, text)\n        LIST_REGEX.sub(self._parse_lists, text)\n        HASHTAG_REGEX.sub(self._parse_tags, text)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _html(self, text):\n        '''Parse a Tweet and generate HTML.'''\n        html = URL_REGEX.sub(self._parse_urls, text)\n        html = USERNAME_REGEX.sub(self._parse_users, html)\n        html = LIST_REGEX.sub(self._parse_lists, html)\n        return HASHTAG_REGEX.sub(self._parse_tags, html)", "response": "Parse a Tweet and generate HTML."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshortens a URL and make sure to not cut of html entities.", "response": "def _shorten_url(self, text):\n        '''Shorten a URL and make sure to not cut of html entities.'''\n\n        if len(text) > self._max_url_length and self._max_url_length != -1:\n            text = text[0:self._max_url_length - 3]\n            amp = text.rfind('&')\n            close = text.rfind(';')\n            if amp != -1 and (close == -1 or close < amp):\n                text = text[0:amp]\n\n            return text + '...'\n\n        else:\n            return text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning formatted HTML for a list.", "response": "def format_list(self, at_char, user, list_name):\n        '''Return formatted HTML for a list.'''\n        return '<a href=\"https://twitter.com/%s/lists/%s\">%s%s/%s</a>' \\\n               % (user, list_name, at_char, user, list_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfollow redirects in list of shortlinks return dict of resulting URLs", "response": "def follow_shortlinks(shortlinks):\n    \"\"\"Follow redirects in list of shortlinks, return dict of resulting URLs\"\"\"\n    links_followed = {}\n    for shortlink in shortlinks:\n        url = shortlink\n        request_result = requests.get(url)\n        redirect_history = request_result.history\n        # history might look like:\n        # (<Response [301]>, <Response [301]>)\n        # where each response object has a URL\n        all_urls = []\n        for redirect in redirect_history:\n            all_urls.append(redirect.url)\n        # append the final URL that we finish with\n        all_urls.append(request_result.url)\n        links_followed[shortlink] = all_urls\n    return links_followed"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecomposes a ProtoRPC message field into the needed arguments to pass to the constructor.", "response": "def _GetFieldAttributes(field):\n  \"\"\"Decomposes field into the needed arguments to pass to the constructor.\n\n  This can be used to create copies of the field or to compare if two fields\n  are \"equal\" (since __eq__ is not implemented on messages.Field).\n\n  Args:\n    field: A ProtoRPC message field (potentially to be copied).\n\n  Raises:\n    TypeError: If the field is not an instance of messages.Field.\n\n  Returns:\n    A pair of relevant arguments to be passed to the constructor for the field\n      type. The first element is a list of positional arguments for the\n      constructor and the second is a dictionary of keyword arguments.\n  \"\"\"\n  if not isinstance(field, messages.Field):\n    raise TypeError('Field %r to be copied not a ProtoRPC field.' % (field,))\n\n  positional_args = []\n  kwargs = {\n      'required': field.required,\n      'repeated': field.repeated,\n      'variant': field.variant,\n      'default': field._Field__default,  # pylint: disable=protected-access\n  }\n\n  if isinstance(field, messages.MessageField):\n    # Message fields can't have a default\n    kwargs.pop('default')\n    if not isinstance(field, message_types.DateTimeField):\n      positional_args.insert(0, field.message_type)\n  elif isinstance(field, messages.EnumField):\n    positional_args.insert(0, field.type)\n\n  return positional_args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _CompareFields(field, other_field):\n  field_attrs = _GetFieldAttributes(field)\n  other_field_attrs = _GetFieldAttributes(other_field)\n  if field_attrs != other_field_attrs:\n    return False\n  return field.__class__ == other_field.__class__", "response": "Checks if two ProtoRPC message fields are equal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _CopyField(field, number=None):\n  positional_args, kwargs = _GetFieldAttributes(field)\n  number = number or field.number\n  positional_args.append(number)\n  return field.__class__(*positional_args, **kwargs)", "response": "Copies a ( potentially ) owned ProtoRPC message field into a new copy."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef combined_message_class(self):\n    if self.__combined_message_class is not None:\n      return self.__combined_message_class\n\n    fields = {}\n    # We don't need to preserve field.number since this combined class is only\n    # used for the protorpc remote.method and is not needed for the API config.\n    # The only place field.number matters is in parameterOrder, but this is set\n    # based on container.parameters_message_class which will use the field\n    # numbers originally passed in.\n\n    # Counter for fields.\n    field_number = 1\n    for field in self.body_message_class.all_fields():\n      fields[field.name] = _CopyField(field, number=field_number)\n      field_number += 1\n    for field in self.parameters_message_class.all_fields():\n      if field.name in fields:\n        if not _CompareFields(field, fields[field.name]):\n          raise TypeError('Field %r contained in both parameters and request '\n                          'body, but the fields differ.' % (field.name,))\n        else:\n          # Skip a field that's already there.\n          continue\n      fields[field.name] = _CopyField(field, number=field_number)\n      field_number += 1\n\n    self.__combined_message_class = type('CombinedContainer',\n                                         (messages.Message,), fields)\n    return self.__combined_message_class", "response": "A ProtoRPC message class with both request and parameters fields."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_to_cache(cls, remote_info, container):  # pylint: disable=g-bad-name\n    if not isinstance(container, cls):\n      raise TypeError('%r not an instance of %r, could not be added to cache.' %\n                      (container, cls))\n    if remote_info in cls.__remote_info_cache:\n      raise KeyError('Cache has collision but should not.')\n    cls.__remote_info_cache[remote_info] = container", "response": "Adds a ResourceContainer to a protorpc. remote. MethodInfo object in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_request_message(cls, remote_info):  # pylint: disable=g-bad-name\n    if remote_info in cls.__remote_info_cache:\n      return cls.__remote_info_cache[remote_info]\n    else:\n      return remote_info.request_type()", "response": "Gets the request message or container from the remote info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_user():\n  if not _is_auth_info_available():\n    raise InvalidGetUserCall('No valid endpoints user in environment.')\n\n  if _ENDPOINTS_USER_INFO in os.environ:\n    user_info = os.environ[_ENDPOINTS_USER_INFO]\n    return users.User(user_info.email)\n\n  if _ENV_USE_OAUTH_SCOPE in os.environ:\n    # We can get more information from the oauth.get_current_user function,\n    # as long as we know what scope to use.  Since that scope has been\n    # cached, we can just return this:\n    return oauth.get_current_user(os.environ[_ENV_USE_OAUTH_SCOPE].split())\n\n  if (_ENV_AUTH_EMAIL in os.environ and\n      _ENV_AUTH_DOMAIN in os.environ):\n    if not os.environ[_ENV_AUTH_EMAIL]:\n      # Either there was no id token or we were unable to validate it,\n      # so there's no user.\n      return None\n\n    return users.User(os.environ[_ENV_AUTH_EMAIL],\n                      os.environ[_ENV_AUTH_DOMAIN] or None)\n\n  # Shouldn't hit this, because all the _is_auth_info_available cases were\n  # checked, but just in case.\n  return None", "response": "Get the current user from the id_token or oauth token in the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if user auth info has been set in environment variables.", "response": "def _is_auth_info_available():\n  \"\"\"Check if user auth info has been set in environment variables.\"\"\"\n  return (_ENDPOINTS_USER_INFO in os.environ or\n          (_ENV_AUTH_EMAIL in os.environ and _ENV_AUTH_DOMAIN in os.environ) or\n          _ENV_USE_OAUTH_SCOPE in os.environ)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting environment variables for the current user.", "response": "def _maybe_set_current_user_vars(method, api_info=None, request=None):\n  \"\"\"Get user information from the id_token or oauth token in the request.\n\n  Used internally by Endpoints to set up environment variables for user\n  authentication.\n\n  Args:\n    method: The class method that's handling this request.  This method\n      should be annotated with @endpoints.method.\n    api_info: An api_config._ApiInfo instance. Optional. If None, will attempt\n      to parse api_info from the implicit instance of the method.\n    request: The current request, or None.\n  \"\"\"\n  if _is_auth_info_available():\n    return\n\n  # By default, there's no user.\n  os.environ[_ENV_AUTH_EMAIL] = ''\n  os.environ[_ENV_AUTH_DOMAIN] = ''\n\n  # Choose settings on the method, if specified.  Otherwise, choose settings\n  # from the API.  Specifically check for None, so that methods can override\n  # with empty lists.\n  try:\n    api_info = api_info or method.im_self.api_info\n  except AttributeError:\n    # The most common case for this is someone passing an unbound method\n    # to this function, which most likely only happens in our unit tests.\n    # We could propagate the exception, but this results in some really\n    # difficult to debug behavior.  Better to log a warning and pretend\n    # there are no API-level settings.\n    _logger.warning('AttributeError when accessing %s.im_self.  An unbound '\n                    'method was probably passed as an endpoints handler.',\n                    method.__name__)\n    scopes = method.method_info.scopes\n    audiences = method.method_info.audiences\n    allowed_client_ids = method.method_info.allowed_client_ids\n  else:\n    scopes = (method.method_info.scopes\n              if method.method_info.scopes is not None\n              else api_info.scopes)\n    audiences = (method.method_info.audiences\n                 if method.method_info.audiences is not None\n                 else api_info.audiences)\n    allowed_client_ids = (method.method_info.allowed_client_ids\n                          if method.method_info.allowed_client_ids is not None\n                          else api_info.allowed_client_ids)\n\n  if not scopes and not audiences and not allowed_client_ids:\n    # The user hasn't provided any information to allow us to parse either\n    # an id_token or an Oauth token.  They appear not to be interested in\n    # auth.\n    return\n\n  token = _get_token(request)\n  if not token:\n    return None\n\n  if allowed_client_ids and _is_local_dev():\n    allowed_client_ids = (constants.API_EXPLORER_CLIENT_ID,) + tuple(allowed_client_ids)\n\n  # When every item in the acceptable scopes list is\n  # \"https://www.googleapis.com/auth/userinfo.email\", and there is a non-empty\n  # allowed_client_ids list, the API code will first attempt OAuth 2/OpenID\n  # Connect ID token processing for any incoming bearer token.\n  if ((scopes == [_EMAIL_SCOPE] or scopes == (_EMAIL_SCOPE,)) and\n      allowed_client_ids):\n    _logger.debug('Checking for id_token.')\n    issuers = api_info.issuers\n    if issuers is None:\n      issuers = _DEFAULT_GOOGLE_ISSUER\n    elif 'google_id_token' not in issuers:\n      issuers.update(_DEFAULT_GOOGLE_ISSUER)\n    time_now = long(time.time())\n    user = _get_id_token_user(token, issuers, audiences, allowed_client_ids,\n                              time_now, memcache)\n    if user:\n      os.environ[_ENV_AUTH_EMAIL] = user.email()\n      os.environ[_ENV_AUTH_DOMAIN] = user.auth_domain()\n      return\n\n  # Check if the user is interested in an oauth token.\n  if scopes:\n    _logger.debug('Checking for oauth token.')\n    if _is_local_dev():\n      _set_bearer_user_vars_local(token, allowed_client_ids, scopes)\n    else:\n      _set_bearer_user_vars(allowed_client_ids, scopes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the auth token for this request.", "response": "def _get_token(\n    request=None, allowed_auth_schemes=('OAuth', 'Bearer'),\n    allowed_query_keys=('bearer_token', 'access_token')):\n  \"\"\"Get the auth token for this request.\n\n  Auth token may be specified in either the Authorization header or\n  as a query param (either access_token or bearer_token).  We'll check in\n  this order:\n    1. Authorization header.\n    2. bearer_token query param.\n    3. access_token query param.\n\n  Args:\n    request: The current request, or None.\n\n  Returns:\n    The token in the request or None.\n  \"\"\"\n  allowed_auth_schemes = _listlike_guard(\n      allowed_auth_schemes, 'allowed_auth_schemes', iterable_only=True)\n  # Check if the token is in the Authorization header.\n  auth_header = os.environ.get('HTTP_AUTHORIZATION')\n  if auth_header:\n    for auth_scheme in allowed_auth_schemes:\n      if auth_header.startswith(auth_scheme):\n        return auth_header[len(auth_scheme) + 1:]\n    # If an auth header was specified, even if it's an invalid one, we won't\n    # look for the token anywhere else.\n    return None\n\n  # Check if the token is in the query string.\n  if request:\n    allowed_query_keys = _listlike_guard(\n        allowed_query_keys, 'allowed_query_keys', iterable_only=True)\n    for key in allowed_query_keys:\n      token, _ = request.get_unrecognized_field_info(key)\n      if token:\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_id_token_user(token, issuers, audiences, allowed_client_ids, time_now, cache):\n  # Verify that the token is valid before we try to extract anything from it.\n  # This verifies the signature and some of the basic info in the token.\n  for issuer_key, issuer in issuers.items():\n    issuer_cert_uri = convert_jwks_uri(issuer.jwks_uri)\n    try:\n      parsed_token = _verify_signed_jwt_with_certs(\n          token, time_now, cache, cert_uri=issuer_cert_uri)\n    except Exception:  # pylint: disable=broad-except\n      _logger.debug(\n          'id_token verification failed for issuer %s', issuer_key, exc_info=True)\n      continue\n\n    issuer_values = _listlike_guard(issuer.issuer, 'issuer', log_warning=False)\n    if isinstance(audiences, _Mapping):\n      audiences = audiences[issuer_key]\n    if _verify_parsed_token(\n        parsed_token, issuer_values, audiences, allowed_client_ids,\n        # There's some special handling we do for Google issuers.\n        # ESP doesn't do this, and it's both unnecessary and invalid for other issuers.\n        # So we'll turn it off except in the Google issuer case.\n        is_legacy_google_auth=(issuer.issuer == _ISSUERS)):\n      email = parsed_token['email']\n      # The token might have an id, but it's a Gaia ID that's been\n      # obfuscated with the Focus key, rather than the AppEngine (igoogle)\n      # key.  If the developer ever put this email into the user DB\n      # and retrieved the ID from that, it'd be different from the ID we'd\n      # return here, so it's safer to not return the ID.\n      # Instead, we'll only return the email.\n      return users.User(email)", "response": "Verify that the given id token is valid and return a User object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a scopes list into a set of all scopes and a set of sufficient scope sets.", "response": "def _process_scopes(scopes):\n  \"\"\"Parse a scopes list into a set of all scopes and a set of sufficient scope sets.\n\n     scopes: A list of strings, each of which is a space-separated list of scopes.\n       Examples: ['scope1']\n                 ['scope1', 'scope2']\n                 ['scope1', 'scope2 scope3']\n\n     Returns:\n       all_scopes: a set of strings, each of which is one scope to check for\n       sufficient_scopes: a set of sets of strings; each inner set is\n         a set of scopes which are sufficient for access.\n         Example: {{'scope1'}, {'scope2', 'scope3'}}\n  \"\"\"\n  all_scopes = set()\n  sufficient_scopes = set()\n  for scope_set in scopes:\n    scope_set_scopes = frozenset(scope_set.split())\n    all_scopes.update(scope_set_scopes)\n    sufficient_scopes.add(scope_set_scopes)\n  return all_scopes, sufficient_scopes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a list of authorized scopes satisfies any set of sufficient scopes.", "response": "def _are_scopes_sufficient(authorized_scopes, sufficient_scopes):\n  \"\"\"Check if a list of authorized scopes satisfies any set of sufficient scopes.\n\n     Args:\n       authorized_scopes: a list of strings, return value from oauth.get_authorized_scopes\n       sufficient_scopes: a set of sets of strings, return value from _process_scopes\n  \"\"\"\n  for sufficient_scope_set in sufficient_scopes:\n    if sufficient_scope_set.issubset(authorized_scopes):\n      return True\n  return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the bearer token and set endpoints auth user variables.", "response": "def _set_bearer_user_vars(allowed_client_ids, scopes):\n  \"\"\"Validate the oauth bearer token and set endpoints auth user variables.\n\n  If the bearer token is valid, this sets ENDPOINTS_USE_OAUTH_SCOPE.  This\n  provides enough information that our endpoints.get_current_user() function\n  can get the user.\n\n  Args:\n    allowed_client_ids: List of client IDs that are acceptable.\n    scopes: List of acceptable scopes.\n  \"\"\"\n  all_scopes, sufficient_scopes = _process_scopes(scopes)\n  try:\n    authorized_scopes = oauth.get_authorized_scopes(sorted(all_scopes))\n  except oauth.Error:\n    _logger.debug('Unable to get authorized scopes.', exc_info=True)\n    return\n  if not _are_scopes_sufficient(authorized_scopes, sufficient_scopes):\n    _logger.warning('Authorized scopes did not satisfy scope requirements.')\n    return\n  client_id = oauth.get_client_id(authorized_scopes)\n\n  # The client ID must be in allowed_client_ids.  If allowed_client_ids is\n  # empty, don't allow any client ID.  If allowed_client_ids is set to\n  # SKIP_CLIENT_ID_CHECK, all client IDs will be allowed.\n  if (list(allowed_client_ids) != SKIP_CLIENT_ID_CHECK and\n      client_id not in allowed_client_ids):\n    _logger.warning('Client ID is not allowed: %s', client_id)\n    return\n\n  os.environ[_ENV_USE_OAUTH_SCOPE] = ' '.join(authorized_scopes)\n  _logger.debug('get_current_user() will return user from matched oauth_user.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates the bearer token on the dev server and set the user variables that are set in the local environment.", "response": "def _set_bearer_user_vars_local(token, allowed_client_ids, scopes):\n  \"\"\"Validate the oauth bearer token on the dev server.\n\n  Since the functions in the oauth module return only example results in local\n  development, this hits the tokeninfo endpoint and attempts to validate the\n  token.  If it's valid, we'll set _ENV_AUTH_EMAIL and _ENV_AUTH_DOMAIN so we\n  can get the user from the token.\n\n  Args:\n    token: String with the oauth token to validate.\n    allowed_client_ids: List of client IDs that are acceptable.\n    scopes: List of acceptable scopes.\n  \"\"\"\n  # Get token info from the tokeninfo endpoint.\n  result = urlfetch.fetch(\n      '%s?%s' % (_TOKENINFO_URL, urllib.urlencode({'access_token': token})))\n  if result.status_code != 200:\n    try:\n      error_description = json.loads(result.content)['error_description']\n    except (ValueError, KeyError):\n      error_description = ''\n    _logger.error('Token info endpoint returned status %s: %s',\n                  result.status_code, error_description)\n    return\n  token_info = json.loads(result.content)\n\n  # Validate email.\n  if 'email' not in token_info:\n    _logger.warning('Oauth token doesn\\'t include an email address.')\n    return\n  if token_info.get('email_verified') != 'true':\n    _logger.warning('Oauth token email isn\\'t verified.')\n    return\n\n  # Validate client ID.\n  client_id = token_info.get('azp')\n  if (list(allowed_client_ids) != SKIP_CLIENT_ID_CHECK and\n      client_id not in allowed_client_ids):\n    _logger.warning('Client ID is not allowed: %s', client_id)\n    return\n\n  # Verify at least one of the scopes matches.\n  _, sufficient_scopes = _process_scopes(scopes)\n  authorized_scopes = token_info.get('scope', '').split(' ')\n  if not _are_scopes_sufficient(authorized_scopes, sufficient_scopes):\n    _logger.warning('Oauth token scopes don\\'t match any acceptable scopes.')\n    return\n\n  os.environ[_ENV_AUTH_EMAIL] = token_info['email']\n  os.environ[_ENV_AUTH_DOMAIN] = ''\n  _logger.debug('Local dev returning user from token.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _verify_parsed_token(parsed_token, issuers, audiences, allowed_client_ids, is_legacy_google_auth=True):\n  # Verify the issuer.\n  if parsed_token.get('iss') not in issuers:\n    _logger.warning('Issuer was not valid: %s', parsed_token.get('iss'))\n    return False\n\n  # Check audiences.\n  aud = parsed_token.get('aud')\n  if not aud:\n    _logger.warning('No aud field in token')\n    return False\n  # Special legacy handling if aud == cid.  This occurs with iOS and browsers.\n  # As long as audience == client_id and cid is allowed, we need to accept\n  # the audience for compatibility.\n  cid = parsed_token.get('azp')\n  audience_allowed = (aud in audiences) or (is_legacy_google_auth and aud == cid)\n  if not audience_allowed:\n    _logger.warning('Audience not allowed: %s', aud)\n    return False\n\n  # Check allowed client IDs, for legacy auth.\n  if is_legacy_google_auth:\n    if list(allowed_client_ids) == SKIP_CLIENT_ID_CHECK:\n      _logger.warning('Client ID check can\\'t be skipped for ID tokens.  '\n                      'Id_token cannot be verified.')\n      return False\n    elif not cid or cid not in allowed_client_ids:\n      _logger.warning('Client ID is not allowed: %s', cid)\n      return False\n\n  if 'email' not in parsed_token:\n    return False\n\n  return True", "response": "Verify a parsed user ID token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_cert_expiration_time(headers):\n  # Check the max age of the cert.\n  cache_control = headers.get('Cache-Control', '')\n  # http://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.2 indicates only\n  # a comma-separated header is valid, so it should be fine to split this on\n  # commas.\n  for entry in cache_control.split(','):\n    match = _MAX_AGE_REGEX.match(entry)\n    if match:\n      cache_time_seconds = int(match.group(1))\n      break\n  else:\n    return 0\n\n  # Subtract the cert's age.\n  age = headers.get('Age')\n  if age is not None:\n    try:\n      age = int(age)\n    except ValueError:\n      age = 0\n    cache_time_seconds -= age\n\n  return max(0, cache_time_seconds)", "response": "Get the expiration time for a certificate given the response headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_cached_certs(cert_uri, cache):\n  certs = cache.get(cert_uri, namespace=_CERT_NAMESPACE)\n  if certs is None:\n    _logger.debug('Cert cache miss for %s', cert_uri)\n    try:\n      result = urlfetch.fetch(cert_uri)\n    except AssertionError:\n      # This happens in unit tests.  Act as if we couldn't get any certs.\n      return None\n\n    if result.status_code == 200:\n      certs = json.loads(result.content)\n      expiration_time_seconds = _get_cert_expiration_time(result.headers)\n      if expiration_time_seconds:\n        cache.set(cert_uri, certs, time=expiration_time_seconds,\n                  namespace=_CERT_NAMESPACE)\n    else:\n      _logger.error(\n          'Certs not available, HTTP request returned %d', result.status_code)\n\n  return certs", "response": "Get certs from cache if present. If not gets from URI and caches them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying a signed JWT against a set of public certs.", "response": "def _verify_signed_jwt_with_certs(\n    jwt, time_now, cache,\n    cert_uri=_DEFAULT_CERT_URI):\n  \"\"\"Verify a JWT against public certs.\n\n  See http://self-issued.info/docs/draft-jones-json-web-token.html.\n\n  The PyCrypto library included with Google App Engine is severely limited and\n  so you have to use it very carefully to verify JWT signatures. The first\n  issue is that the library can't read X.509 files, so we make a call to a\n  special URI that has the public cert in modulus/exponent form in JSON.\n\n  The second issue is that the RSA.verify method doesn't work, at least for\n  how the JWT tokens are signed, so we have to manually verify the signature\n  of the JWT, which means hashing the signed part of the JWT and comparing\n  that to the signature that's been encrypted with the public key.\n\n  Args:\n    jwt: string, A JWT.\n    time_now: The current time, as a long (eg. long(time.time())).\n    cache: Cache to use (eg. the memcache module).\n    cert_uri: string, URI to get cert modulus and exponent in JSON format.\n\n  Returns:\n    dict, The deserialized JSON payload in the JWT.\n\n  Raises:\n    _AppIdentityError: if any checks are failed.\n  \"\"\"\n\n  segments = jwt.split('.')\n\n  if len(segments) != 3:\n    # Note that anywhere we print the jwt or its json body, we need to use\n    # %r instead of %s, so that non-printable characters are escaped safely.\n    raise _AppIdentityError('Token is not an id_token (Wrong number of '\n                            'segments)')\n  signed = '%s.%s' % (segments[0], segments[1])\n\n  signature = _urlsafe_b64decode(segments[2])\n\n  # pycrypto only deals in integers, so we have to convert the string of bytes\n  # into a long.\n  lsignature = long(signature.encode('hex'), 16)\n\n  # Verify expected header.\n  header_body = _urlsafe_b64decode(segments[0])\n  try:\n    header = json.loads(header_body)\n  except:\n    raise _AppIdentityError(\"Can't parse header\")\n  if header.get('alg') != 'RS256':\n    raise _AppIdentityError('Unexpected encryption algorithm: %r' %\n                            header.get('alg'))\n\n  # Formerly we would parse the token body here.\n  # However, it's not safe to do that without first checking the signature.\n\n  certs = _get_cached_certs(cert_uri, cache)\n  if certs is None:\n    raise _AppIdentityError(\n        'Unable to retrieve certs needed to verify the signed JWT')\n\n  # Verify that we were able to load the Crypto libraries, before we try\n  # to use them.\n  if not _CRYPTO_LOADED:\n    raise _AppIdentityError('Unable to load pycrypto library.  Can\\'t verify '\n                            'id_token signature.  See http://www.pycrypto.org '\n                            'for more information on pycrypto.')\n\n  # SHA256 hash of the already 'signed' segment from the JWT. Since a SHA256\n  # hash, will always have length 64.\n  local_hash = SHA256.new(signed).hexdigest()\n\n  # Check signature.\n  verified = False\n  for keyvalue in certs['keyvalues']:\n    try:\n      modulus = _b64_to_long(keyvalue['modulus'])\n      exponent = _b64_to_long(keyvalue['exponent'])\n      key = RSA.construct((modulus, exponent))\n\n      # Encrypt, and convert to a hex string.\n      hexsig = '%064x' % key.encrypt(lsignature, '')[0]\n      # Make sure we have only last 64 base64 chars\n      hexsig = hexsig[-64:]\n\n      # Check the signature on 'signed' by encrypting 'signature' with the\n      # public key and confirming the result matches the SHA256 hash of\n      # 'signed'. hmac.compare_digest(a, b) is used to avoid timing attacks.\n      verified = hmac.compare_digest(hexsig, local_hash)\n      if verified:\n        break\n    except Exception, e:  # pylint: disable=broad-except\n      # Log the exception for debugging purpose.\n      _logger.debug(\n          'Signature verification error: %s; continuing with the next cert.', e)\n      continue\n  if not verified:\n    raise _AppIdentityError('Invalid token signature')\n\n  # Parse token.\n  json_body = _urlsafe_b64decode(segments[1])\n  try:\n    parsed = json.loads(json_body)\n  except:\n    raise _AppIdentityError(\"Can't parse token body\")\n\n  # Check creation timestamp.\n  iat = parsed.get('iat')\n  if iat is None:\n    raise _AppIdentityError('No iat field in token')\n  earliest = iat - _CLOCK_SKEW_SECS\n\n  # Check expiration timestamp.\n  exp = parsed.get('exp')\n  if exp is None:\n    raise _AppIdentityError('No exp field in token')\n  if exp >= time_now + _MAX_TOKEN_LIFETIME_SECS:\n    raise _AppIdentityError('exp field too far in future')\n  latest = exp + _CLOCK_SKEW_SECS\n\n  if time_now < earliest:\n    raise _AppIdentityError('Token used too early, %d < %d' %\n                            (time_now, earliest))\n  if time_now > latest:\n    raise _AppIdentityError('Token used too late, %d > %d' %\n                            (time_now, latest))\n\n  return parsed"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a JWKS URI to a special URI that is used in the X. 509 certificate file.", "response": "def convert_jwks_uri(jwks_uri):\n  \"\"\"\n  The PyCrypto library included with Google App Engine is severely limited and\n  can't read X.509 files, so we change the URI to a special URI that has the\n  public cert in modulus/exponent form in JSON.\n  \"\"\"\n  if not jwks_uri.startswith(_TEXT_CERT_PREFIX):\n    return jwks_uri\n  return jwks_uri.replace(_TEXT_CERT_PREFIX, _JSON_CERT_PREFIX)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_verified_jwt(\n    providers, audiences,\n    check_authorization_header=True, check_query_arg=True,\n    request=None, cache=memcache):\n  \"\"\"\n  This function will extract, verify, and parse a JWT token from the\n  Authorization header or access_token query argument.\n\n  The JWT is assumed to contain an issuer and audience claim, as well\n  as issued-at and expiration timestamps. The signature will be\n  cryptographically verified, the claims and timestamps will be\n  checked, and the resulting parsed JWT body is returned.\n\n  If at any point the JWT is missing or found to be invalid, the\n  return result will be None.\n\n  Arguments:\n  providers - An iterable of dicts each containing 'issuer' and 'cert_uri' keys\n  audiences - An iterable of valid audiences\n\n  check_authorization_header - Boolean; check 'Authorization: Bearer' header\n  check_query_arg - Boolean; check 'access_token' query arg\n\n  request - Must be the request object if check_query_arg is true; otherwise ignored.\n  cache - In testing, override the certificate cache\n  \"\"\"\n  if not (check_authorization_header or check_query_arg):\n      raise ValueError(\n          'Either check_authorization_header or check_query_arg must be True.')\n  if check_query_arg and request is None:\n      raise ValueError(\n          'Cannot check query arg without request object.')\n  schemes = ('Bearer',) if check_authorization_header else ()\n  keys = ('access_token',) if check_query_arg else ()\n  token = _get_token(\n      request=request, allowed_auth_schemes=schemes, allowed_query_keys=keys)\n  if token is None:\n    return None\n  time_now = long(time.time())\n  for provider in providers:\n    parsed_token = _parse_and_verify_jwt(\n        token, time_now, (provider['issuer'],), audiences, provider['cert_uri'], cache)\n    if parsed_token is not None:\n      return parsed_token\n  return None", "response": "This function will extract verify and parse a JWT token from the specified providers and audiences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _listlike_guard(obj, name, iterable_only=False, log_warning=True):\n  required_type = (_Iterable,) if iterable_only else (_Container, _Iterable)\n  required_type_name = ' or '.join(t.__name__ for t in required_type)\n\n  if not isinstance(obj, required_type):\n    raise ValueError('{} must be of type {}'.format(name, required_type_name))\n  # at this point it is definitely the right type, but might be a string\n  if isinstance(obj, basestring):\n    if log_warning:\n      _logger.warning('{} passed as a string; should be list-like'.format(name))\n    return (obj,)\n  return obj", "response": "A list - like guard for objects that are not iterable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __item_descriptor(self, config):\n    descriptor = {\n        'kind': 'discovery#directoryItem',\n        'icons': {\n            'x16': 'https://www.gstatic.com/images/branding/product/1x/'\n                   'googleg_16dp.png',\n            'x32': 'https://www.gstatic.com/images/branding/product/1x/'\n                   'googleg_32dp.png',\n        },\n        'preferred': True,\n    }\n\n    description = config.get('description')\n    root_url = config.get('root')\n    name = config.get('name')\n    version = config.get('api_version')\n    relative_path = '/apis/{0}/{1}/rest'.format(name, version)\n\n    if description:\n      descriptor['description'] = description\n\n    descriptor['name'] = name\n    descriptor['version'] = version\n    descriptor['discoveryLink'] = '.{0}'.format(relative_path)\n\n    root_url_port = urlparse.urlparse(root_url).port\n\n    original_path = self.__request.reconstruct_full_url(\n        port_override=root_url_port)\n    descriptor['discoveryRestUrl'] = '{0}/{1}/{2}/rest'.format(\n        original_path, name, version)\n\n    if name and version:\n      descriptor['id'] = '{0}:{1}'.format(name, version)\n\n    return descriptor", "response": "Builds a dictionary that describes the service configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __directory_list_descriptor(self, configs):\n    descriptor = {\n        'kind': 'discovery#directoryList',\n        'discoveryVersion': 'v1',\n    }\n\n    items = []\n    for config in configs:\n      item_descriptor = self.__item_descriptor(config)\n      if item_descriptor:\n        items.append(item_descriptor)\n\n    if items:\n      descriptor['items'] = items\n\n    return descriptor", "response": "Builds a directory list for an API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a JSON dict description of a protorpc. remote. Service in list format.", "response": "def get_directory_list_doc(self, configs):\n    \"\"\"JSON dict description of a protorpc.remote.Service in list format.\n\n    Args:\n      configs: Either a single dict or a list of dicts containing the service\n        configurations to list.\n\n    Returns:\n      dict, The directory list document as a JSON dict.\n    \"\"\"\n\n    if not isinstance(configs, (tuple, list)):\n      configs = [configs]\n\n    util.check_list_type(configs, dict, 'configs', allow_none=False)\n\n    return self.__directory_list_descriptor(configs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty_print_config_to_json(self, configs):\n    descriptor = self.get_directory_list_doc(configs)\n    return json.dumps(descriptor, sort_keys=True, indent=2,\n                      separators=(',', ': '))", "response": "Pretty print a list of configurations to a JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __format_error(self, error_list_tag):\n    error = {'domain': self.domain(),\n             'reason': self.reason(),\n             'message': self.message()}\n    error.update(self.extra_fields() or {})\n    return {'error': {error_list_tag: [error],\n                      'code': self.status_code(),\n                      'message': self.message()}}", "response": "Format this error into a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rest_error(self):\n    error_json = self.__format_error('errors')\n    return json.dumps(error_json, indent=1, sort_keys=True)", "response": "Format this error into a REST response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the HTTP status code from an HTTP status string.", "response": "def _get_status_code(self, http_status):\n    \"\"\"Get the HTTP status code from an HTTP status string.\n\n    Args:\n      http_status: A string containing a HTTP status code and reason.\n\n    Returns:\n      An integer with the status code number from http_status.\n    \"\"\"\n    try:\n      return int(http_status.split(' ', 1)[0])\n    except TypeError:\n      _logger.warning('Unable to find status code in HTTP status %r.',\n                      http_status)\n    return 500"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a JSON API config response and registers all the methods for dispatch.", "response": "def process_api_config_response(self, config_json):\n    \"\"\"Parses a JSON API config and registers methods for dispatch.\n\n    Side effects:\n      Parses method name, etc. for all methods and updates the indexing\n      data structures with the information.\n\n    Args:\n      config_json: A dict, the JSON body of the getApiConfigs response.\n    \"\"\"\n    with self._config_lock:\n      self._add_discovery_config()\n      for config in config_json.get('items', []):\n        lookup_key = config.get('name', ''), config.get('version', '')\n        self._configs[lookup_key] = config\n\n      for config in self._configs.itervalues():\n        name = config.get('name', '')\n        api_version = config.get('api_version', '')\n        path_version = config.get('path_version', '')\n        sorted_methods = self._get_sorted_methods(config.get('methods', {}))\n\n\n        for method_name, method in sorted_methods:\n          self._save_rest_method(method_name, name, path_version, method)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a copy of the given methods sorted alphabetically by the number of times the path text is used for comparison.", "response": "def _get_sorted_methods(self, methods):\n    \"\"\"Get a copy of 'methods' sorted the way they would be on the live server.\n\n    Args:\n      methods: JSON configuration of an API's methods.\n\n    Returns:\n      The same configuration with the methods sorted based on what order\n      they'll be checked by the server.\n    \"\"\"\n    if not methods:\n      return methods\n\n    # Comparison function we'll use to sort the methods:\n    def _sorted_methods_comparison(method_info1, method_info2):\n      \"\"\"Sort method info by path and http_method.\n\n      Args:\n        method_info1: Method name and info for the first method to compare.\n        method_info2: Method name and info for the method to compare to.\n\n      Returns:\n        Negative if the first method should come first, positive if the\n        first method should come after the second.  Zero if they're\n        equivalent.\n      \"\"\"\n\n      def _score_path(path):\n        \"\"\"Calculate the score for this path, used for comparisons.\n\n        Higher scores have priority, and if scores are equal, the path text\n        is sorted alphabetically.  Scores are based on the number and location\n        of the constant parts of the path.  The server has some special handling\n        for variables with regexes, which we don't handle here.\n\n        Args:\n          path: The request path that we're calculating a score for.\n\n        Returns:\n          The score for the given path.\n        \"\"\"\n        score = 0\n        parts = path.split('/')\n        for part in parts:\n          score <<= 1\n          if not part or part[0] != '{':\n            # Found a constant.\n            score += 1\n        # Shift by 31 instead of 32 because some (!) versions of Python like\n        # to convert the int to a long if we shift by 32, and the sorted()\n        # function that uses this blows up if it receives anything but an int.\n        score <<= 31 - len(parts)\n        return score\n\n      # Higher path scores come first.\n      path_score1 = _score_path(method_info1[1].get('path', ''))\n      path_score2 = _score_path(method_info2[1].get('path', ''))\n      if path_score1 != path_score2:\n        return path_score2 - path_score1\n\n      # Compare by path text next, sorted alphabetically.\n      path_result = cmp(method_info1[1].get('path', ''),\n                        method_info2[1].get('path', ''))\n      if path_result != 0:\n        return path_result\n\n      # All else being equal, sort by HTTP method.\n      method_result = cmp(method_info1[1].get('httpMethod', ''),\n                          method_info2[1].get('httpMethod', ''))\n      return method_result\n\n    return sorted(methods.items(), _sorted_methods_comparison)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the path parameters from a regular expression match.", "response": "def _get_path_params(match):\n    \"\"\"Gets path parameters from a regular expression match.\n\n    Args:\n      match: A regular expression Match object for a path.\n\n    Returns:\n      A dictionary containing the variable names converted from base64.\n    \"\"\"\n    result = {}\n    for var_name, value in match.groupdict().iteritems():\n      actual_var_name = ApiConfigManager._from_safe_path_param_name(var_name)\n      result[actual_var_name] = urllib.unquote_plus(value)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lookup_rest_method(self, path, request_uri, http_method):\n    method_key = http_method.lower()\n    with self._config_lock:\n      for compiled_path_pattern, unused_path, methods in self._rest_methods:\n        if method_key not in methods:\n          continue\n        candidate_method_info = methods[method_key]\n        match_against = request_uri if candidate_method_info[1].get('useRequestUri') else path\n        match = compiled_path_pattern.match(match_against)\n        if match:\n          params = self._get_path_params(match)\n          method_name, method = candidate_method_info\n          break\n      else:\n        _logger.warn('No endpoint found for path: %r, method: %r', path, http_method)\n        method_name = None\n        method = None\n        params = None\n    return method_name, method, params", "response": "Look up the rest method at call time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_discovery_config(self):\n    lookup_key = (discovery_service.DiscoveryService.API_CONFIG['name'],\n                  discovery_service.DiscoveryService.API_CONFIG['version'])\n    self._configs[lookup_key] = discovery_service.DiscoveryService.API_CONFIG", "response": "Add the Discovery configuration to our list of configs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a configuration to the cache of configs.", "response": "def save_config(self, lookup_key, config):\n    \"\"\"Save a configuration to the cache of configs.\n\n    Args:\n      lookup_key: A string containing the cache lookup key.\n      config: The dict containing the configuration to save to the cache.\n    \"\"\"\n    with self._config_lock:\n      self._configs[lookup_key] = config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _from_safe_path_param_name(safe_parameter):\n    assert safe_parameter.startswith('_')\n    safe_parameter_as_base32 = safe_parameter[1:]\n\n    padding_length = - len(safe_parameter_as_base32) % 8\n    padding = '=' * padding_length\n    return base64.b32decode(safe_parameter_as_base32 + padding)", "response": "Takes a safe regex group name and converts it back to the original value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the rest api method for the given method name and version.", "response": "def _save_rest_method(self, method_name, api_name, version, method):\n    \"\"\"Store Rest api methods in a list for lookup at call time.\n\n    The list is self._rest_methods, a list of tuples:\n      [(<compiled_path>, <path_pattern>, <method_dict>), ...]\n    where:\n      <compiled_path> is a compiled regex to match against the incoming URL\n      <path_pattern> is a string representing the original path pattern,\n        checked on insertion to prevent duplicates.     -and-\n      <method_dict> is a dict of httpMethod => (method_name, method)\n\n    This structure is a bit complex, it supports use in two contexts:\n      Creation time:\n        - SaveRestMethod is called repeatedly, each method will have a path,\n          which we want to be compiled for fast lookup at call time\n        - We want to prevent duplicate incoming path patterns, so store the\n          un-compiled path, not counting on a compiled regex being a stable\n          comparison as it is not documented as being stable for this use.\n        - Need to store the method that will be mapped at calltime.\n        - Different methods may have the same path but different http method.\n      Call time:\n        - Quickly scan through the list attempting .match(path) on each\n          compiled regex to find the path that matches.\n        - When a path is matched, look up the API method from the request\n          and get the method name and method config for the matching\n          API method and method name.\n\n    Args:\n      method_name: A string containing the name of the API method.\n      api_name: A string containing the name of the API.\n      version: A string containing the version of the API.\n      method: A dict containing the method descriptor (as in the api config\n        file).\n    \"\"\"\n    path_pattern = '/'.join((api_name, version, method.get('path', '')))\n    http_method = method.get('httpMethod', '').lower()\n    for _, path, methods in self._rest_methods:\n      if path == path_pattern:\n        methods[http_method] = method_name, method\n        break\n    else:\n      self._rest_methods.append(\n          (self._compile_path_pattern(path_pattern),\n           path_pattern,\n           {http_method: (method_name, method)}))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef api_server(api_services, **kwargs):\n  # Disallow protocol configuration for now, Lily is json-only.\n  if 'protocols' in kwargs:\n    raise TypeError(\"__init__() got an unexpected keyword argument 'protocols'\")\n\n  from . import _logger as endpoints_logger\n  from . import __version__ as endpoints_version\n  endpoints_logger.info('Initializing Endpoints Framework version %s', endpoints_version)\n\n  # Construct the api serving app\n  apis_app = _ApiServer(api_services, **kwargs)\n  dispatcher = endpoints_dispatcher.EndpointsDispatcherMiddleware(apis_app)\n\n  # Determine the service name\n  service_name = os.environ.get('ENDPOINTS_SERVICE_NAME')\n  if not service_name:\n    _logger.warn('Did not specify the ENDPOINTS_SERVICE_NAME environment'\n                 ' variable so service control is disabled.  Please specify'\n                 ' the name of service in ENDPOINTS_SERVICE_NAME to enable'\n                 ' it.')\n    return dispatcher\n\n  # If we're using a local server, just return the dispatcher now to bypass\n  # control client.\n  if control_wsgi.running_on_devserver():\n    _logger.warn('Running on local devserver, so service control is disabled.')\n    return dispatcher\n\n  from endpoints_management import _logger as management_logger\n  from endpoints_management import __version__ as management_version\n  management_logger.info('Initializing Endpoints Management Framework version %s', management_version)\n\n  # The DEFAULT 'config' should be tuned so that it's always OK for python\n  # App Engine workloads.  The config can be adjusted, but that's probably\n  # unnecessary on App Engine.\n  controller = control_client.Loaders.DEFAULT.load(service_name)\n\n  # Start the GAE background thread that powers the control client's cache.\n  control_client.use_gae_thread()\n  controller.start()\n\n  return control_wsgi.add_all(\n      dispatcher,\n      app_identity.get_application_id(),\n      controller)", "response": "Create an api server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a single API and its config contents.", "response": "def register_backend(self, config_contents):\n    \"\"\"Register a single API and its config contents.\n\n    Args:\n      config_contents: Dict containing API configuration.\n    \"\"\"\n    if config_contents is None:\n      return\n    self.__register_class(config_contents)\n    self.__api_configs.append(config_contents)\n    self.__register_methods(config_contents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters the class implementing this config so we only add it once.", "response": "def __register_class(self, parsed_config):\n    \"\"\"Register the class implementing this config, so we only add it once.\n\n    Args:\n      parsed_config: The JSON object with the API configuration being added.\n\n    Raises:\n      ApiConfigurationError: If the class has already been registered.\n    \"\"\"\n    methods = parsed_config.get('methods')\n    if not methods:\n      return\n\n    # Determine the name of the class that implements this configuration.\n    service_classes = set()\n    for method in methods.itervalues():\n      rosy_method = method.get('rosyMethod')\n      if rosy_method and '.' in rosy_method:\n        method_class = rosy_method.split('.', 1)[0]\n        service_classes.add(method_class)\n\n    for service_class in service_classes:\n      if service_class in self.__registered_classes:\n        raise api_exceptions.ApiConfigurationError(\n            'API class %s has already been registered.' % service_class)\n      self.__registered_classes.add(service_class)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister all methods from the given api config file.", "response": "def __register_methods(self, parsed_config):\n    \"\"\"Register all methods from the given api config file.\n\n    Methods are stored in a map from method_name to rosyMethod,\n    the name of the ProtoRPC method to be called on the backend.\n    If no rosyMethod was specified the value will be None.\n\n    Args:\n      parsed_config: The JSON object with the API configuration being added.\n    \"\"\"\n    methods = parsed_config.get('methods')\n    if not methods:\n      return\n\n    for method_name, method in methods.iteritems():\n      self.__api_methods[method_name] = method.get('rosyMethod')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __create_name_version_map(api_services):\n    api_name_version_map = {}\n    for service_factory in api_services:\n      try:\n        service_class = service_factory.service_class\n      except AttributeError:\n        service_class = service_factory\n        service_factory = service_class.new_factory()\n\n      key = service_class.api_info.name, service_class.api_info.api_version\n      service_factories = api_name_version_map.setdefault(key, [])\n      if service_factory in service_factories:\n        raise api_config.ApiConfigurationError(\n            'Can\\'t add the same class to an API twice: %s' %\n            service_factory.service_class.__name__)\n\n      service_factories.append(service_factory)\n    return api_name_version_map", "response": "Create a map from an API name and version to a list of remote. Service objects that implement that API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __register_services(api_name_version_map, api_config_registry):\n    generator = api_config.ApiConfigGenerator()\n    protorpc_services = []\n    for service_factories in api_name_version_map.itervalues():\n      service_classes = [service_factory.service_class\n                         for service_factory in service_factories]\n      config_dict = generator.get_config_dict(service_classes)\n      api_config_registry.register_backend(config_dict)\n\n      for service_factory in service_factories:\n        protorpc_class_name = service_factory.service_class.__name__\n        root = '%s%s' % (service_factory.service_class.api_info.base_path,\n                         protorpc_class_name)\n        if any(service_map[0] == root or service_map[1] == service_factory\n               for service_map in protorpc_services):\n          raise api_config.ApiConfigurationError(\n              'Can\\'t reuse the same class in multiple APIs: %s' %\n              protorpc_class_name)\n        protorpc_services.append((root, service_factory))\n    return protorpc_services", "response": "Register & return a list of each URL and class that handles that URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the response is an error.", "response": "def __is_json_error(self, status, headers):\n    \"\"\"Determine if response is an error.\n\n    Args:\n      status: HTTP status code.\n      headers: Dictionary of (lowercase) header name to value.\n\n    Returns:\n      True if the response was an error, else False.\n    \"\"\"\n    content_header = headers.get('content-type', '')\n    content_type, unused_params = cgi.parse_header(content_header)\n    return (status.startswith('400') and\n            content_type.lower() in _ALL_JSON_CONTENT_TYPES)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __write_error(self, status_code, error_message=None):\n    if error_message is None:\n      error_message = httplib.responses[status_code]\n    status = '%d %s' % (status_code, httplib.responses[status_code])\n    message = EndpointsErrorMessage(\n        state=EndpointsErrorMessage.State.APPLICATION_ERROR,\n        error_message=error_message)\n    return status, self.__PROTOJSON.encode_message(message)", "response": "Write an error message to the HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a ProtoRPC error to the format expected by Google Endpoints frontend.", "response": "def protorpc_to_endpoints_error(self, status, body):\n    \"\"\"Convert a ProtoRPC error to the format expected by Google Endpoints.\n\n    If the body does not contain an ProtoRPC message in state APPLICATION_ERROR\n    the status and body will be returned unchanged.\n\n    Args:\n      status: HTTP status of the response from the backend\n      body: JSON-encoded error in format expected by Endpoints frontend.\n\n    Returns:\n      Tuple of (http status, body)\n    \"\"\"\n    try:\n      rpc_error = self.__PROTOJSON.decode_message(remote.RpcStatus, body)\n    except (ValueError, messages.ValidationError):\n      rpc_error = remote.RpcStatus()\n\n    if rpc_error.state == remote.RpcStatus.State.APPLICATION_ERROR:\n\n      # Try to map to HTTP error code.\n      error_class = _ERROR_NAME_MAP.get(rpc_error.error_name)\n      if error_class:\n        status, body = self.__write_error(error_class.http_status,\n                                          rpc_error.error_message)\n    return status, body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a request path and dispatch handler.", "response": "def _add_dispatcher(self, path_regex, dispatch_function):\n    \"\"\"Add a request path and dispatch handler.\n\n    Args:\n      path_regex: A string regex, the path to match against incoming requests.\n      dispatch_function: The function to call for these requests.  The function\n        should take (request, start_response) as arguments and\n        return the contents of the response body.\n    \"\"\"\n    self._dispatchers.append((re.compile(path_regex), dispatch_function))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch(self, request, start_response):\n    # Check if this matches any of our special handlers.\n    dispatched_response = self.dispatch_non_api_requests(request,\n                                                         start_response)\n    if dispatched_response is not None:\n      return dispatched_response\n\n    # Call the service.\n    try:\n      return self.call_backend(request, start_response)\n    except errors.RequestError as error:\n      return self._handle_request_error(request, error, start_response)", "response": "Handles dispatch to the API server handlers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dispatch_non_api_requests(self, request, start_response):\n    for path_regex, dispatch_function in self._dispatchers:\n      if path_regex.match(request.relative_url):\n        return dispatch_function(request, start_response)\n\n    if request.http_method == 'OPTIONS':\n      cors_handler = self._create_cors_handler(request)\n      if cors_handler.allow_cors_request:\n        # The server returns 200 rather than 204, for some reason.\n        return util.send_wsgi_response('200', [], '', start_response,\n                                       cors_handler)\n\n    return None", "response": "Dispatch this request if this is a request to a reserved URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_api_explorer_request(self, request, start_response):\n    redirect_url = self._get_explorer_redirect_url(\n        request.server, request.port, request.base_path)\n    return util.send_wsgi_redirect_response(redirect_url, start_response)", "response": "This function handles the API explorer request."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_response(response, status_code, content_type=None):\n    status = int(response.status.split(' ', 1)[0])\n    if status != status_code:\n      return False\n\n    if content_type is None:\n      return True\n\n    for header, value in response.headers:\n      if header.lower() == 'content-type':\n        return value == content_type\n\n    # If we fall through to here, the verification has failed, so return False.\n    return False", "response": "Verifies that a ResponseTuple has the expected status and content type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare_backend_environ(self, host, method, relative_url, headers, body,\n                              source_ip, port):\n    \"\"\"Build an environ object for the backend to consume.\n\n    Args:\n      host: A string containing the host serving the request.\n      method: A string containing the HTTP method of the request.\n      relative_url: A string containing path and query string of the request.\n      headers: A list of (key, value) tuples where key and value are both\n               strings.\n      body: A string containing the request body.\n      source_ip: The source IP address for the request.\n      port: The port to which to direct the request.\n\n    Returns:\n      An environ object with all the information necessary for the backend to\n      process the request.\n    \"\"\"\n    if isinstance(body, unicode):\n      body = body.encode('ascii')\n\n    url = urlparse.urlsplit(relative_url)\n    if port != 80:\n      host = '%s:%s' % (host, port)\n    else:\n      host = host\n    environ = {'CONTENT_LENGTH': str(len(body)),\n               'PATH_INFO': url.path,\n               'QUERY_STRING': url.query,\n               'REQUEST_METHOD': method,\n               'REMOTE_ADDR': source_ip,\n               'SERVER_NAME': host,\n               'SERVER_PORT': str(port),\n               'SERVER_PROTOCOL': 'HTTP/1.1',\n               'wsgi.version': (1, 0),\n               'wsgi.url_scheme': 'http',\n               'wsgi.errors': cStringIO.StringIO(),\n               'wsgi.multithread': True,\n               'wsgi.multiprocess': True,\n               'wsgi.input': cStringIO.StringIO(body)}\n    util.put_headers_in_environ(headers, environ)\n    environ['HTTP_HOST'] = host\n    return environ", "response": "Prepare the environ object for the backend to consume the request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call_backend(self, orig_request, start_response):\n    method_config, params = self.lookup_rest_method(orig_request)\n    if not method_config:\n      cors_handler = self._create_cors_handler(orig_request)\n      return util.send_wsgi_not_found_response(start_response,\n                                               cors_handler=cors_handler)\n\n    # Prepare the request for the back end.\n    transformed_request = self.transform_request(\n        orig_request, params, method_config)\n\n    # Check if this call is for the Discovery service.  If so, route\n    # it to our Discovery handler.\n    discovery = discovery_service.DiscoveryService(\n        self.config_manager, self._backend)\n    discovery_response = discovery.handle_discovery_request(\n        transformed_request.path, transformed_request, start_response)\n    if discovery_response:\n      return discovery_response\n\n    url = transformed_request.base_path + transformed_request.path\n    transformed_request.headers['Content-Type'] = 'application/json'\n    transformed_environ = self.prepare_backend_environ(\n        orig_request.server, 'POST', url, transformed_request.headers.items(),\n        transformed_request.body, transformed_request.source_ip,\n        orig_request.port)\n\n    # Send the transformed request to the backend app and capture the response.\n    with util.StartResponseProxy() as start_response_proxy:\n      body_iter = self._backend(transformed_environ, start_response_proxy.Proxy)\n      status = start_response_proxy.response_status\n      headers = start_response_proxy.response_headers\n\n      # Get response body\n      body = start_response_proxy.response_body\n      # In case standard WSGI behavior is implemented later...\n      if not body:\n        body = ''.join(body_iter)\n\n    return self.handle_backend_response(orig_request, transformed_request,\n                                        status, headers, body, method_config,\n                                        start_response)", "response": "This method calls the backend app and returns the response body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_backend_response(self, orig_request, backend_request,\n                              response_status, response_headers,\n                              response_body, method_config, start_response):\n    \"\"\"Handle backend response, transforming output as needed.\n\n    This calls start_response and returns the response body.\n\n    Args:\n      orig_request: An ApiRequest, the original request from the user.\n      backend_request: An ApiRequest, the transformed request that was\n                       sent to the backend handler.\n      response_status: A string, the status from the response.\n      response_headers: A dict, the headers from the response.\n      response_body: A string, the body of the response.\n      method_config: A dict, the API config of the method to be called.\n      start_response: A function with semantics defined in PEP-333.\n\n    Returns:\n      A string containing the response body.\n    \"\"\"\n    # Verify that the response is json.  If it isn't treat, the body as an\n    # error message and wrap it in a json error response.\n    for header, value in response_headers:\n      if (header.lower() == 'content-type' and\n          not value.lower().startswith('application/json')):\n        return self.fail_request(orig_request,\n                                 'Non-JSON reply: %s' % response_body,\n                                 start_response)\n\n    self.check_error_response(response_body, response_status)\n\n    # Check if the response from the API was empty.  Empty REST responses\n    # generate a HTTP 204.\n    empty_response = self.check_empty_response(orig_request, method_config,\n                                                 start_response)\n    if empty_response is not None:\n      return empty_response\n\n    body = self.transform_rest_response(response_body)\n\n    cors_handler = self._create_cors_handler(orig_request)\n    return util.send_wsgi_response(response_status, response_headers, body,\n                                   start_response, cors_handler=cors_handler)", "response": "This function handles the backend response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fail_request(self, orig_request, message, start_response):\n    cors_handler = self._create_cors_handler(orig_request)\n    return util.send_wsgi_error_response(\n        message, start_response, cors_handler=cors_handler)", "response": "Write an immediate failure response to outfile no redirect."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlooks up and returns the rest method for the currently - pending request.", "response": "def lookup_rest_method(self, orig_request):\n    \"\"\"Looks up and returns rest method for the currently-pending request.\n\n    Args:\n      orig_request: An ApiRequest, the original request from the user.\n\n    Returns:\n      A tuple of (method descriptor, parameters), or (None, None) if no method\n      was found for the current request.\n    \"\"\"\n    method_name, method, params = self.config_manager.lookup_rest_method(\n        orig_request.path, orig_request.request_uri, orig_request.http_method)\n    orig_request.method_name = method_name\n    return method, params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming orig_request to apiserving request.", "response": "def transform_request(self, orig_request, params, method_config):\n    \"\"\"Transforms orig_request to apiserving request.\n\n    This method uses orig_request to determine the currently-pending request\n    and returns a new transformed request ready to send to the backend.  This\n    method accepts a rest-style or RPC-style request.\n\n    Args:\n      orig_request: An ApiRequest, the original request from the user.\n      params: A dictionary containing path parameters for rest requests, or\n        None for an RPC request.\n      method_config: A dict, the API config of the method to be called.\n\n    Returns:\n      An ApiRequest that's a copy of the current request, modified so it can\n      be sent to the backend.  The path is updated and parts of the body or\n      other properties may also be changed.\n    \"\"\"\n    method_params = method_config.get('request', {}).get('parameters', {})\n    request = self.transform_rest_request(orig_request, params, method_params)\n    request.path = method_config.get('rosyMethod', '')\n    return request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a. delimitied field name to a message field in parameters.", "response": "def _add_message_field(self, field_name, value, params):\n    \"\"\"Converts a . delimitied field name to a message field in parameters.\n\n    This adds the field to the params dict, broken out so that message\n    parameters appear as sub-dicts within the outer param.\n\n    For example:\n      {'a.b.c': ['foo']}\n    becomes:\n      {'a': {'b': {'c': ['foo']}}}\n\n    Args:\n      field_name: A string containing the '.' delimitied name to be converted\n        into a dictionary.\n      value: The value to be set.\n      params: The dictionary holding all the parameters, where the value is\n        eventually set.\n    \"\"\"\n    if '.' not in field_name:\n      params[field_name] = value\n      return\n\n    root, remaining = field_name.split('.', 1)\n    sub_params = params.setdefault(root, {})\n    self._add_message_field(remaining, value, sub_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the destination dict with the values from the request body.", "response": "def _update_from_body(self, destination, source):\n    \"\"\"Updates the dictionary for an API payload with the request body.\n\n    The values from the body should override those already in the payload, but\n    for nested fields (message objects) the values can be combined\n    recursively.\n\n    Args:\n      destination: A dictionary containing an API payload parsed from the\n        path and query parameters in a request.\n      source: A dictionary parsed from the body of the request.\n    \"\"\"\n    for key, value in source.iteritems():\n      destination_value = destination.get(key)\n      if isinstance(value, dict) and isinstance(destination_value, dict):\n        self._update_from_body(destination_value, value)\n      else:\n        destination[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates a Rest request into an apiserving request.", "response": "def transform_rest_request(self, orig_request, params, method_parameters):\n    \"\"\"Translates a Rest request into an apiserving request.\n\n    This makes a copy of orig_request and transforms it to apiserving\n    format (moving request parameters to the body).\n\n    The request can receive values from the path, query and body and combine\n    them before sending them along to the backend. In cases of collision,\n    objects from the body take precedence over those from the query, which in\n    turn take precedence over those from the path.\n\n    In the case that a repeated value occurs in both the query and the path,\n    those values can be combined, but if that value also occurred in the body,\n    it would override any other values.\n\n    In the case of nested values from message fields, non-colliding values\n    from subfields can be combined. For example, if '?a.c=10' occurs in the\n    query string and \"{'a': {'b': 11}}\" occurs in the body, then they will be\n    combined as\n\n    {\n      'a': {\n        'b': 11,\n        'c': 10,\n      }\n    }\n\n    before being sent to the backend.\n\n    Args:\n      orig_request: An ApiRequest, the original request from the user.\n      params: A dict with URL path parameters extracted by the config_manager\n        lookup.\n      method_parameters: A dictionary containing the API configuration for the\n        parameters for the request.\n\n    Returns:\n      A copy of the current request that's been modified so it can be sent\n      to the backend.  The body is updated to include parameters from the\n      URL.\n    \"\"\"\n    request = orig_request.copy()\n    body_json = {}\n\n    # Handle parameters from the URL path.\n    for key, value in params.iteritems():\n      # Values need to be in a list to interact with query parameter values\n      # and to account for case of repeated parameters\n      body_json[key] = [value]\n\n    # Add in parameters from the query string.\n    if request.parameters:\n      # For repeated elements, query and path work together\n      for key, value in request.parameters.iteritems():\n        if key in body_json:\n          body_json[key] = value + body_json[key]\n        else:\n          body_json[key] = value\n\n    # Validate all parameters we've merged so far and convert any '.' delimited\n    # parameters to nested parameters.  We don't use iteritems since we may\n    # modify body_json within the loop.  For instance, 'a.b' is not a valid key\n    # and would be replaced with 'a'.\n    for key, value in body_json.items():\n      current_parameter = method_parameters.get(key, {})\n      repeated = current_parameter.get('repeated', False)\n\n      if not repeated:\n        body_json[key] = body_json[key][0]\n\n      # Order is important here.  Parameter names are dot-delimited in\n      # parameters instead of nested in dictionaries as a message field is, so\n      # we need to call transform_parameter_value on them before calling\n      # _add_message_field.\n      body_json[key] = parameter_converter.transform_parameter_value(\n          key, body_json[key], current_parameter)\n      # Remove the old key and try to convert to nested message value\n      message_value = body_json.pop(key)\n      self._add_message_field(key, message_value, body_json)\n\n    # Add in values from the body of the request.\n    if request.body_json:\n      self._update_from_body(body_json, request.body_json)\n\n    request.body_json = body_json\n    request.body = json.dumps(request.body_json)\n    return request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nraising an exception if the response from the backend was an error.", "response": "def check_error_response(self, body, status):\n    \"\"\"Raise an exception if the response from the backend was an error.\n\n    Args:\n      body: A string containing the backend response body.\n      status: A string containing the backend response status.\n\n    Raises:\n      BackendError if the response is an error.\n    \"\"\"\n    status_code = int(status.split(' ', 1)[0])\n    if status_code >= 300:\n      raise errors.BackendError(body, status)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_empty_response(self, orig_request, method_config, start_response):\n    response_config = method_config.get('response', {}).get('body')\n    if response_config == 'empty':\n      # The response to this function should be empty.  We should return a 204.\n      # Note that it's possible that the backend returned something, but we'll\n      # ignore it.  This matches the behavior in the Endpoints server.\n      cors_handler = self._create_cors_handler(orig_request)\n      return util.send_wsgi_no_content_response(start_response, cors_handler)", "response": "Check if the backend response is empty."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_rest_response(self, response_body):\n    body_json = json.loads(response_body)\n    return json.dumps(body_json, indent=1, sort_keys=True)", "response": "Translates an apiserving REST response so it s ready to return."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a request error and returns a WSGI response.", "response": "def _handle_request_error(self, orig_request, error, start_response):\n    \"\"\"Handle a request error, converting it to a WSGI response.\n\n    Args:\n      orig_request: An ApiRequest, the original request from the user.\n      error: A RequestError containing information about the error.\n      start_response: A function with semantics defined in PEP-333.\n\n    Returns:\n      A string containing the response body.\n    \"\"\"\n    headers = [('Content-Type', 'application/json')]\n    status_code = error.status_code()\n    body = error.rest_error()\n\n    response_status = '%d %s' % (status_code,\n                                 httplib.responses.get(status_code,\n                                                       'Unknown Error'))\n    cors_handler = self._create_cors_handler(orig_request)\n    return util.send_wsgi_response(response_status, headers, body,\n                                   start_response, cors_handler=cors_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _WriteFile(output_path, name, content):\n  path = os.path.join(output_path, name)\n  with open(path, 'wb') as f:\n    f.write(content)\n  return path", "response": "Writes given content to a file in a given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GenApiConfig(service_class_names, config_string_generator=None,\n                 hostname=None, application_path=None, **additional_kwargs):\n  \"\"\"Write an API configuration for endpoints annotated ProtoRPC services.\n\n  Args:\n    service_class_names: A list of fully qualified ProtoRPC service classes.\n    config_string_generator: A generator object that produces API config strings\n      using its pretty_print_config_to_json method.\n    hostname: A string hostname which will be used as the default version\n      hostname. If no hostname is specificied in the @endpoints.api decorator,\n      this value is the fallback.\n    application_path: A string with the path to the AppEngine application.\n\n  Raises:\n    TypeError: If any service classes don't inherit from remote.Service.\n    messages.DefinitionNotFoundError: If a service can't be found.\n\n  Returns:\n    A map from service names to a string containing the API configuration of the\n      service in JSON format.\n  \"\"\"\n  # First, gather together all the different APIs implemented by these\n  # classes.  There may be fewer APIs than service classes.  Each API is\n  # uniquely identified by (name, version).  Order needs to be preserved here,\n  # so APIs that were listed first are returned first.\n  api_service_map = collections.OrderedDict()\n  resolved_services = []\n\n  for service_class_name in service_class_names:\n    module_name, base_service_class_name = service_class_name.rsplit('.', 1)\n    module = __import__(module_name, fromlist=base_service_class_name)\n    service = getattr(module, base_service_class_name)\n    if hasattr(service, 'get_api_classes'):\n      resolved_services.extend(service.get_api_classes())\n    elif (not isinstance(service, type) or\n          not issubclass(service, remote.Service)):\n      raise TypeError('%s is not a ProtoRPC service' % service_class_name)\n    else:\n      resolved_services.append(service)\n\n  for resolved_service in resolved_services:\n    services = api_service_map.setdefault(\n        (resolved_service.api_info.name, resolved_service.api_info.api_version), [])\n    services.append(resolved_service)\n\n  # If hostname isn't specified in the API or on the command line, we'll\n  # try to build it from information in app.yaml.\n  app_yaml_hostname = _GetAppYamlHostname(application_path)\n\n  service_map = collections.OrderedDict()\n  config_string_generator = (\n      config_string_generator or api_config.ApiConfigGenerator())\n  for api_info, services in api_service_map.iteritems():\n    assert services, 'An API must have at least one ProtoRPC service'\n    # Only override hostname if None.  Hostname will be the same for all\n    # services within an API, since it's stored in common info.\n    hostname = services[0].api_info.hostname or hostname or app_yaml_hostname\n\n    # Map each API by name-version.\n    service_map['%s-%s' % api_info] = (\n        config_string_generator.pretty_print_config_to_json(\n            services, hostname=hostname, **additional_kwargs))\n\n  return service_map", "response": "Generates an API configuration for the given list of ProtoRPC services."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the hostname for this app based on the name in the app. yaml file.", "response": "def _GetAppYamlHostname(application_path, open_func=open):\n  \"\"\"Build the hostname for this app based on the name in app.yaml.\n\n  Args:\n    application_path: A string with the path to the AppEngine application.  This\n      should be the directory containing the app.yaml file.\n    open_func: Function to call to open a file.  Used to override the default\n      open function in unit tests.\n\n  Returns:\n    A hostname, usually in the form of \"myapp.appspot.com\", based on the\n    application name in the app.yaml file.  If the file can't be found or\n    there's a problem building the name, this will return None.\n  \"\"\"\n  try:\n    app_yaml_file = open_func(os.path.join(application_path or '.', 'app.yaml'))\n    config = yaml.safe_load(app_yaml_file.read())\n  except IOError:\n    # Couldn't open/read app.yaml.\n    return None\n\n  application = config.get('application')\n  if not application:\n    return None\n\n  if ':' in application:\n    # Don't try to deal with alternate domains.\n    return None\n\n  # If there's a prefix ending in a '~', strip it.\n  tilde_index = application.rfind('~')\n  if tilde_index >= 0:\n    application = application[tilde_index + 1:]\n    if not application:\n      return None\n\n  return '%s.appspot.com' % application"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GenDiscoveryDoc(service_class_names,\n                     output_path, hostname=None,\n                     application_path=None):\n  \"\"\"Write discovery documents generated from the service classes to file.\n\n  Args:\n    service_class_names: A list of fully qualified ProtoRPC service names.\n    output_path: The directory to output the discovery docs to.\n    hostname: A string hostname which will be used as the default version\n      hostname. If no hostname is specificied in the @endpoints.api decorator,\n      this value is the fallback. Defaults to None.\n    application_path: A string containing the path to the AppEngine app.\n\n  Returns:\n    A list of discovery doc filenames.\n  \"\"\"\n  output_files = []\n  service_configs = GenApiConfig(\n      service_class_names, hostname=hostname,\n      config_string_generator=discovery_generator.DiscoveryGenerator(),\n      application_path=application_path)\n  for api_name_version, config in service_configs.iteritems():\n    discovery_name = api_name_version + '.discovery'\n    output_files.append(_WriteFile(output_path, discovery_name, config))\n\n  return output_files", "response": "Generates the discovery documents from the service classes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating OpenAPI specs from the service classes.", "response": "def _GenOpenApiSpec(service_class_names, output_path, hostname=None,\n                    application_path=None, x_google_api_name=False):\n  \"\"\"Write openapi documents generated from the service classes to file.\n\n  Args:\n    service_class_names: A list of fully qualified ProtoRPC service names.\n    output_path: The directory to which to output the OpenAPI specs.\n    hostname: A string hostname which will be used as the default version\n      hostname. If no hostname is specified in the @endpoints.api decorator,\n      this value is the fallback. Defaults to None.\n    application_path: A string containing the path to the AppEngine app.\n\n  Returns:\n    A list of OpenAPI spec filenames.\n  \"\"\"\n  output_files = []\n  service_configs = GenApiConfig(\n      service_class_names, hostname=hostname,\n      config_string_generator=openapi_generator.OpenApiGenerator(),\n      application_path=application_path,\n      x_google_api_name=x_google_api_name)\n  for api_name_version, config in service_configs.iteritems():\n    openapi_name = api_name_version.replace('-', '') + 'openapi.json'\n    output_files.append(_WriteFile(output_path, openapi_name, config))\n\n  return output_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a client library from a discovery doc.", "response": "def _GenClientLib(discovery_path, language, output_path, build_system):\n  \"\"\"Write a client library from a discovery doc.\n\n  Args:\n    discovery_path: Path to the discovery doc used to generate the client\n      library.\n    language: The client library language to generate. (java)\n    output_path: The directory to output the client library zip to.\n    build_system: The target build system for the client library language.\n\n  Raises:\n    IOError: If reading the discovery doc fails.\n    ServerRequestException: If fetching the generated client library fails.\n\n  Returns:\n    The path to the zipped client library.\n  \"\"\"\n  with open(discovery_path) as f:\n    discovery_doc = f.read()\n\n  client_name = re.sub(r'\\.discovery$', '.zip',\n                       os.path.basename(discovery_path))\n\n  return _GenClientLibFromContents(discovery_doc, language, output_path,\n                                   build_system, client_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a client library from a discovery doc.", "response": "def _GenClientLibFromContents(discovery_doc, language, output_path,\n                              build_system, client_name):\n  \"\"\"Write a client library from a discovery doc.\n\n  Args:\n    discovery_doc: A string, the contents of the discovery doc used to\n      generate the client library.\n    language: A string, the client library language to generate. (java)\n    output_path: A string, the directory to output the client library zip to.\n    build_system: A string, the target build system for the client language.\n    client_name: A string, the filename used to save the client lib.\n\n  Raises:\n    IOError: If reading the discovery doc fails.\n    ServerRequestException: If fetching the generated client library fails.\n\n  Returns:\n    The path to the zipped client library.\n  \"\"\"\n\n  body = urllib.urlencode({'lang': language, 'content': discovery_doc,\n                           'layout': build_system})\n  request = urllib2.Request(CLIENT_LIBRARY_BASE, body)\n  try:\n    with contextlib.closing(urllib2.urlopen(request)) as response:\n      content = response.read()\n      return _WriteFile(output_path, client_name, content)\n  except urllib2.HTTPError, error:\n    raise ServerRequestException(error)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating client libraries from a list of ProtoRPC service classes.", "response": "def _GetClientLib(service_class_names, language, output_path, build_system,\n                  hostname=None, application_path=None):\n  \"\"\"Fetch client libraries from a cloud service.\n\n  Args:\n    service_class_names: A list of fully qualified ProtoRPC service names.\n    language: The client library language to generate. (java)\n    output_path: The directory to output the discovery docs to.\n    build_system: The target build system for the client library language.\n    hostname: A string hostname which will be used as the default version\n      hostname. If no hostname is specificied in the @endpoints.api decorator,\n      this value is the fallback. Defaults to None.\n    application_path: A string containing the path to the AppEngine app.\n\n  Returns:\n    A list of paths to client libraries.\n  \"\"\"\n  client_libs = []\n  service_configs = GenApiConfig(\n      service_class_names, hostname=hostname,\n      config_string_generator=discovery_generator.DiscoveryGenerator(),\n      application_path=application_path)\n  for api_name_version, config in service_configs.iteritems():\n    client_name = api_name_version + '.zip'\n    client_libs.append(\n        _GenClientLibFromContents(config, language, output_path,\n                                  build_system, client_name))\n  return client_libs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an api file.", "response": "def _GenApiConfigCallback(args, api_func=GenApiConfig):\n  \"\"\"Generate an api file.\n\n  Args:\n    args: An argparse.Namespace object to extract parameters from.\n    api_func: A function that generates and returns an API configuration\n      for a list of services.\n  \"\"\"\n  service_configs = api_func(args.service,\n                             hostname=args.hostname,\n                             application_path=args.application)\n\n  for api_name_version, config in service_configs.iteritems():\n    _WriteFile(args.output, api_name_version + '.api', config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetClientLibCallback(args, client_func=_GetClientLib):\n  client_paths = client_func(\n      args.service, args.language, args.output, args.build_system,\n      hostname=args.hostname, application_path=args.application)\n\n  for client_path in client_paths:\n    print 'API client library written to %s' % client_path", "response": "Generates discovery docs and client libraries to files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates discovery docs to files.", "response": "def _GenDiscoveryDocCallback(args, discovery_func=_GenDiscoveryDoc):\n  \"\"\"Generate discovery docs to files.\n\n  Args:\n    args: An argparse.Namespace object to extract parameters from\n    discovery_func: A function that generates discovery docs and stores them to\n      files, accepting a list of service names, a discovery doc format, and an\n      output directory.\n  \"\"\"\n  discovery_paths = discovery_func(args.service, args.output,\n                                   hostname=args.hostname,\n                                   application_path=args.application)\n  for discovery_path in discovery_paths:\n    print 'API discovery document written to %s' % discovery_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GenOpenApiSpecCallback(args, openapi_func=_GenOpenApiSpec):\n  openapi_paths = openapi_func(args.service, args.output,\n                               hostname=args.hostname,\n                               application_path=args.application,\n                               x_google_api_name=args.x_google_api_name)\n  for openapi_path in openapi_paths:\n    print 'OpenAPI spec written to %s' % openapi_path", "response": "Generates OpenAPI specs to files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _GenClientLibCallback(args, client_func=_GenClientLib):\n  client_path = client_func(args.discovery_doc[0], args.language, args.output,\n                            args.build_system)\n  print 'API client library written to %s' % client_path", "response": "Generates a client library to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an argument parser for the specified program.", "response": "def MakeParser(prog):\n  \"\"\"Create an argument parser.\n\n  Args:\n    prog: The name of the program to use when outputting help text.\n\n  Returns:\n    An argparse.ArgumentParser built to specification.\n  \"\"\"\n\n  def AddStandardOptions(parser, *args):\n    \"\"\"Add common endpoints options to a parser.\n\n    Args:\n      parser: The parser to add options to.\n      *args: A list of option names to add. Possible names are: application,\n        format, output, language, service, and discovery_doc.\n    \"\"\"\n    if 'application' in args:\n      parser.add_argument('-a', '--application', default='.',\n                          help='The path to the Python App Engine App')\n    if 'format' in args:\n      # This used to be a valid option, allowing the user to select 'rest' or 'rpc',\n      # but now 'rest' is the only valid type. The argument remains so scripts using it\n      # won't break.\n      parser.add_argument('-f', '--format', default='rest',\n                          choices=['rest'],\n                          help='The requested API protocol type (ignored)')\n    if 'hostname' in args:\n      help_text = ('Default application hostname, if none is specified '\n                   'for API service.')\n      parser.add_argument('--hostname', help=help_text)\n    if 'output' in args:\n      parser.add_argument('-o', '--output', default='.',\n                          help='The directory to store output files')\n    if 'language' in args:\n      parser.add_argument('language',\n                          help='The target output programming language')\n    if 'service' in args:\n      parser.add_argument('service', nargs='+',\n                          help='Fully qualified service class name')\n    if 'discovery_doc' in args:\n      parser.add_argument('discovery_doc', nargs=1,\n                          help='Path to the discovery document')\n    if 'build_system' in args:\n      parser.add_argument('-bs', '--build_system', default='default',\n                          help='The target build system')\n\n  parser = _EndpointsParser(prog=prog)\n  subparsers = parser.add_subparsers(\n      title='subcommands', metavar='{%s}' % ', '.join(_VISIBLE_COMMANDS))\n\n  get_client_lib = subparsers.add_parser(\n      'get_client_lib', help=('Generates discovery documents and client '\n                              'libraries from service classes'))\n  get_client_lib.set_defaults(callback=_GetClientLibCallback)\n  AddStandardOptions(get_client_lib, 'application', 'hostname', 'output',\n                     'language', 'service', 'build_system')\n\n  get_discovery_doc = subparsers.add_parser(\n      'get_discovery_doc',\n      help='Generates discovery documents from service classes')\n  get_discovery_doc.set_defaults(callback=_GenDiscoveryDocCallback)\n  AddStandardOptions(get_discovery_doc, 'application', 'format', 'hostname',\n                     'output', 'service')\n\n  get_openapi_spec = subparsers.add_parser(\n      'get_openapi_spec',\n      help='Generates OpenAPI (Swagger) specs from service classes')\n  get_openapi_spec.set_defaults(callback=_GenOpenApiSpecCallback)\n  AddStandardOptions(get_openapi_spec, 'application', 'hostname', 'output',\n                     'service')\n  get_openapi_spec.add_argument('--x-google-api-name', action='store_true',\n                                help=\"Add the 'x-google-api-name' field to the generated spec\")\n\n  # Create an alias for get_openapi_spec called get_swagger_spec to support\n  # the old-style naming. This won't be a visible command, but it will still\n  # function to support legacy scripts.\n  get_swagger_spec = subparsers.add_parser(\n      'get_swagger_spec',\n      help='Generates OpenAPI (Swagger) specs from service classes')\n  get_swagger_spec.set_defaults(callback=_GenOpenApiSpecCallback)\n  AddStandardOptions(get_swagger_spec, 'application', 'hostname', 'output',\n                     'service')\n\n  # By removing the help attribute, the following three actions won't be\n  # displayed in usage message\n  gen_api_config = subparsers.add_parser('gen_api_config')\n  gen_api_config.set_defaults(callback=_GenApiConfigCallback)\n  AddStandardOptions(gen_api_config, 'application', 'hostname', 'output',\n                     'service')\n\n  gen_discovery_doc = subparsers.add_parser('gen_discovery_doc')\n  gen_discovery_doc.set_defaults(callback=_GenDiscoveryDocCallback)\n  AddStandardOptions(gen_discovery_doc, 'application', 'format', 'hostname',\n                     'output', 'service')\n\n  gen_client_lib = subparsers.add_parser('gen_client_lib')\n  gen_client_lib.set_defaults(callback=_GenClientLibCallback)\n  AddStandardOptions(gen_client_lib, 'output', 'language', 'discovery_doc',\n                     'build_system')\n\n  return parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef error(self, message):\n    # subcommands_quoted is the same as subcommands, except each value is\n    # surrounded with double quotes. This is done to match the standard\n    # output of the ArgumentParser, while hiding commands we don't want users\n    # to use, as they are no longer documented and only here for legacy use.\n    subcommands_quoted = ', '.join(\n        [repr(command) for command in _VISIBLE_COMMANDS])\n    subcommands = ', '.join(_VISIBLE_COMMANDS)\n    message = re.sub(\n        r'(argument {%s}: invalid choice: .*) \\(choose from (.*)\\)$'\n        % subcommands, r'\\1 (choose from %s)' % subcommands_quoted, message)\n    super(_EndpointsParser, self).error(message)", "response": "Override to support customized error message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up the sys. path with special directories for endpointscfg. py.", "response": "def _SetupPaths():\n  \"\"\"Sets up the sys.path with special directories for endpointscfg.py.\"\"\"\n  sdk_path = _FindSdkPath()\n  if sdk_path:\n    sys.path.append(sdk_path)\n    try:\n      import dev_appserver  # pylint: disable=g-import-not-at-top\n      if hasattr(dev_appserver, 'fix_sys_path'):\n        dev_appserver.fix_sys_path()\n      else:\n        logging.warning(_NO_FIX_SYS_PATH_WARNING)\n    except ImportError:\n      logging.warning(_IMPORT_ERROR_WARNING)\n  else:\n    logging.warning(_NOT_FOUND_WARNING)\n\n  # Add the path above this directory, so we can import the endpoints package\n  # from the user's app code (rather than from another, possibly outdated SDK).\n  # pylint: disable=g-import-not-at-top\n  from google.appengine.ext import vendor\n  vendor.add(os.path.dirname(os.path.dirname(__file__)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Enum(docstring, *names):\n  enums = dict(zip(names, range(len(names))))\n  reverse = dict((value, key) for key, value in enums.iteritems())\n  enums['reverse_mapping'] = reverse\n  enums['__doc__'] = docstring\n  return type('Enum', (object,), enums)", "response": "Utility to generate enum classes used by annotations."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the type of an object is acceptable.", "response": "def _CheckType(value, check_type, name, allow_none=True):\n  \"\"\"Check that the type of an object is acceptable.\n\n  Args:\n    value: The object whose type is to be checked.\n    check_type: The type that the object must be an instance of.\n    name: Name of the object, to be placed in any error messages.\n    allow_none: True if value can be None, false if not.\n\n  Raises:\n    TypeError: If value is not an acceptable type.\n  \"\"\"\n  if value is None and allow_none:\n    return\n  if not isinstance(value, check_type):\n    raise TypeError('%s type doesn\\'t match %s.' % (name, check_type))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef api(name, version, description=None, hostname=None, audiences=None,\n        scopes=None, allowed_client_ids=None, canonical_name=None,\n        auth=None, owner_domain=None, owner_name=None, package_path=None,\n        frontend_limits=None, title=None, documentation=None, auth_level=None,\n        issuers=None, namespace=None, api_key_required=None, base_path=None,\n        limit_definitions=None, use_request_uri=None):\n  \"\"\"Decorate a ProtoRPC Service class for use by the framework above.\n\n  This decorator can be used to specify an API name, version, description, and\n  hostname for your API.\n\n  Sample usage (python 2.7):\n    @endpoints.api(name='guestbook', version='v0.2',\n                   description='Guestbook API')\n    class PostService(remote.Service):\n      ...\n\n  Sample usage (python 2.5):\n    class PostService(remote.Service):\n      ...\n    endpoints.api(name='guestbook', version='v0.2',\n                  description='Guestbook API')(PostService)\n\n  Sample usage if multiple classes implement one API:\n    api_root = endpoints.api(name='library', version='v1.0')\n\n    @api_root.api_class(resource_name='shelves')\n    class Shelves(remote.Service):\n      ...\n\n    @api_root.api_class(resource_name='books', path='books')\n    class Books(remote.Service):\n      ...\n\n  Args:\n    name: string, Name of the API.\n    version: string, Version of the API.\n    description: string, Short description of the API (Default: None)\n    hostname: string, Hostname of the API (Default: app engine default host)\n    audiences: list of strings, Acceptable audiences for authentication.\n    scopes: list of strings, Acceptable scopes for authentication.\n    allowed_client_ids: list of strings, Acceptable client IDs for auth.\n    canonical_name: string, the canonical name for the API, a more human\n      readable version of the name.\n    auth: ApiAuth instance, the authentication configuration information\n      for this API.\n    owner_domain: string, the domain of the person or company that owns\n      this API.  Along with owner_name, this provides hints to properly\n      name client libraries for this API.\n    owner_name: string, the name of the owner of this API.  Along with\n      owner_domain, this provides hints to properly name client libraries\n      for this API.\n    package_path: string, the \"package\" this API belongs to.  This '/'\n      delimited value specifies logical groupings of APIs.  This is used by\n      client libraries of this API.\n    frontend_limits: ApiFrontEndLimits, optional query limits for unregistered\n      developers.\n    title: string, the human readable title of your API. It is exposed in the\n      discovery service.\n    documentation: string, a URL where users can find documentation about this\n      version of the API. This will be surfaced in the API Explorer and GPE\n      plugin to allow users to learn about your service.\n    auth_level: enum from AUTH_LEVEL, frontend authentication level.\n    issuers: dict, mapping auth issuer names to endpoints.Issuer objects.\n    namespace: endpoints.Namespace, the namespace for the API.\n    api_key_required: bool, whether a key is required to call into this API.\n    base_path: string, the base path for all endpoints in this API.\n    limit_definitions: list of endpoints.LimitDefinition objects, quota metric\n      definitions for this API.\n    use_request_uri: if true, match requests against REQUEST_URI instead of PATH_INFO\n\n\n  Returns:\n    Class decorated with api_info attribute, an instance of ApiInfo.\n  \"\"\"\n  if auth_level is not None:\n    _logger.warn(_AUTH_LEVEL_WARNING)\n\n  return _ApiDecorator(name, version, description=description,\n                       hostname=hostname, audiences=audiences, scopes=scopes,\n                       allowed_client_ids=allowed_client_ids,\n                       canonical_name=canonical_name, auth=auth,\n                       owner_domain=owner_domain, owner_name=owner_name,\n                       package_path=package_path,\n                       frontend_limits=frontend_limits, title=title,\n                       documentation=documentation, auth_level=auth_level,\n                       issuers=issuers, namespace=namespace,\n                       api_key_required=api_key_required, base_path=base_path,\n                       limit_definitions=limit_definitions,\n                       use_request_uri=use_request_uri)", "response": "Decorator for creating a ProtoRPC Service class for use by the framework above."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef method(request_message=message_types.VoidMessage,\n           response_message=message_types.VoidMessage,\n           name=None,\n           path=None,\n           http_method='POST',\n           scopes=None,\n           audiences=None,\n           allowed_client_ids=None,\n           auth_level=None,\n           api_key_required=None,\n           metric_costs=None,\n           use_request_uri=None):\n  \"\"\"Decorate a ProtoRPC Method for use by the framework above.\n\n  This decorator can be used to specify a method name, path, http method,\n  scopes, audiences, client ids and auth_level.\n\n  Sample usage:\n    @api_config.method(RequestMessage, ResponseMessage,\n                       name='insert', http_method='PUT')\n    def greeting_insert(request):\n      ...\n      return response\n\n  Args:\n    request_message: Message type of expected request.\n    response_message: Message type of expected response.\n    name: string, Name of the method, prepended with <apiname>. to make it\n      unique. (Default: python method name)\n    path: string, Path portion of the URL to the method, for RESTful methods.\n    http_method: string, HTTP method supported by the method. (Default: POST)\n    scopes: list of string, OAuth2 token must contain one of these scopes.\n    audiences: list of string, IdToken must contain one of these audiences.\n    allowed_client_ids: list of string, Client IDs allowed to call the method.\n      If None and auth_level is REQUIRED, no calls will be allowed.\n    auth_level: enum from AUTH_LEVEL, Frontend auth level for the method.\n    api_key_required: bool, whether a key is required to call the method\n    metric_costs: dict with keys matching an API limit metric and values\n      representing the cost for each successful call against that metric.\n    use_request_uri: if true, match requests against REQUEST_URI instead of PATH_INFO\n\n  Returns:\n    'apiserving_method_wrapper' function.\n\n  Raises:\n    TypeError: if the request_type or response_type parameters are not\n      proper subclasses of messages.Message.\n  \"\"\"\n  if auth_level is not None:\n    _logger.warn(_AUTH_LEVEL_WARNING)\n\n  # Default HTTP method if one is not specified.\n  DEFAULT_HTTP_METHOD = 'POST'\n\n  def apiserving_method_decorator(api_method):\n    \"\"\"Decorator for ProtoRPC method that configures Google's API server.\n\n    Args:\n      api_method: Original method being wrapped.\n\n    Returns:\n      Function responsible for actual invocation.\n      Assigns the following attributes to invocation function:\n        remote: Instance of RemoteInfo, contains remote method information.\n        remote.request_type: Expected request type for remote method.\n        remote.response_type: Response type returned from remote method.\n        method_info: Instance of _MethodInfo, api method configuration.\n      It is also assigned attributes corresponding to the aforementioned kwargs.\n\n    Raises:\n      TypeError: if the request_type or response_type parameters are not\n        proper subclasses of messages.Message.\n      KeyError: if the request_message is a ResourceContainer and the newly\n          created remote method has been reference by the container before. This\n          should never occur because a remote method is created once.\n    \"\"\"\n    request_body_class = None\n    request_params_class = None\n    if isinstance(request_message, resource_container.ResourceContainer):\n      remote_decorator = remote.method(request_message.combined_message_class,\n                                       response_message)\n      request_body_class = request_message.body_message_class()\n      request_params_class = request_message.parameters_message_class()\n    else:\n      remote_decorator = remote.method(request_message, response_message)\n    remote_method = remote_decorator(api_method)\n\n    def invoke_remote(service_instance, request):\n      # If the server didn't specify any auth information, build it now.\n      # pylint: disable=protected-access\n      users_id_token._maybe_set_current_user_vars(\n          invoke_remote, api_info=getattr(service_instance, 'api_info', None),\n          request=request)\n      # pylint: enable=protected-access\n      return remote_method(service_instance, request)\n\n    invoke_remote.remote = remote_method.remote\n    if isinstance(request_message, resource_container.ResourceContainer):\n      resource_container.ResourceContainer.add_to_cache(\n          invoke_remote.remote, request_message)\n\n    invoke_remote.method_info = _MethodInfo(\n        name=name or api_method.__name__, path=path or api_method.__name__,\n        http_method=http_method or DEFAULT_HTTP_METHOD,\n        scopes=scopes, audiences=audiences,\n        allowed_client_ids=allowed_client_ids, auth_level=auth_level,\n        api_key_required=api_key_required, metric_costs=metric_costs,\n        use_request_uri=use_request_uri,\n        request_body_class=request_body_class,\n        request_params_class=request_params_class)\n    invoke_remote.__name__ = invoke_remote.method_info.name\n    return invoke_remote\n\n  endpoints_util.check_list_type(scopes, (basestring, endpoints_types.OAuth2Scope), 'scopes')\n  endpoints_util.check_list_type(allowed_client_ids, basestring,\n                                 'allowed_client_ids')\n  _CheckEnum(auth_level, AUTH_LEVEL, 'auth_level')\n\n  _CheckAudiences(audiences)\n\n  _CheckType(metric_costs, dict, 'metric_costs')\n\n  return apiserving_method_decorator", "response": "This function is used to decorate a ProtoRPC Method for use by the framework above."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_same_api(self, other):\n    if not isinstance(other, _ApiInfo):\n      return False\n    # pylint: disable=protected-access\n    return self.__common_info is other.__common_info", "response": "Check if this implements the same API as another _ApiInfo instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_class(self, resource_name=None, path=None, audiences=None,\n                scopes=None, allowed_client_ids=None, auth_level=None,\n                api_key_required=None):\n    \"\"\"Get a decorator for a class that implements an API.\n\n    This can be used for single-class or multi-class implementations.  It's\n    used implicitly in simple single-class APIs that only use @api directly.\n\n    Args:\n      resource_name: string, Resource name for the class this decorates.\n        (Default: None)\n      path: string, Base path prepended to any method paths in the class this\n        decorates. (Default: None)\n      audiences: list of strings, Acceptable audiences for authentication.\n        (Default: None)\n      scopes: list of strings, Acceptable scopes for authentication.\n        (Default: None)\n      allowed_client_ids: list of strings, Acceptable client IDs for auth.\n        (Default: None)\n      auth_level: enum from AUTH_LEVEL, Frontend authentication level.\n        (Default: None)\n      api_key_required: bool, Whether a key is required to call into this API.\n        (Default: None)\n\n    Returns:\n      A decorator function to decorate a class that implements an API.\n    \"\"\"\n    if auth_level is not None:\n      _logger.warn(_AUTH_LEVEL_WARNING)\n\n    def apiserving_api_decorator(api_class):\n      \"\"\"Decorator for ProtoRPC class that configures Google's API server.\n\n      Args:\n        api_class: remote.Service class, ProtoRPC service class being wrapped.\n\n      Returns:\n        Same class with API attributes assigned in api_info.\n      \"\"\"\n      self.__classes.append(api_class)\n      api_class.api_info = _ApiInfo(\n          self.__common_info, resource_name=resource_name,\n          path=path, audiences=audiences, scopes=scopes,\n          allowed_client_ids=allowed_client_ids, auth_level=auth_level,\n          api_key_required=api_key_required)\n      return api_class\n\n    return apiserving_api_decorator", "response": "Returns a function that creates a new class that can be used to configure Google s API server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __safe_name(self, method_name):\n    # Endpoints backend restricts what chars are allowed in a method name.\n    safe_name = re.sub(r'[^\\.a-zA-Z0-9_]', '', method_name)\n\n    # Strip any number of leading underscores.\n    safe_name = safe_name.lstrip('_')\n\n    # Ensure the first character is lowercase.\n    # Slice from 0:1 rather than indexing [0] in case safe_name is length 0.\n    return safe_name[0:1].lower() + safe_name[1:]", "response": "Restrict method name to a - zA - Z0 - 9_ first char lowercase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the path portion of the URL to the API.", "response": "def get_path(self, api_info):\n    \"\"\"Get the path portion of the URL to the method (for RESTful methods).\n\n    Request path can be specified in the method, and it could have a base\n    path prepended to it.\n\n    Args:\n      api_info: API information for this API, possibly including a base path.\n        This is the api_info property on the class that's been annotated for\n        this API.\n\n    Returns:\n      This method's request path (not including the http://.../{base_path}\n      prefix).\n\n    Raises:\n      ApiConfigurationError: If the path isn't properly formatted.\n    \"\"\"\n    path = self.__path or ''\n    if path and path[0] == '/':\n      # Absolute path, ignoring any prefixes.  Just strip off the leading /.\n      path = path[1:]\n    else:\n      # Relative path.\n      if api_info.path:\n        path = '%s%s%s' % (api_info.path, '/' if path else '', path)\n\n    # Verify that the path seems valid.\n    parts = path.split('/')\n    for n, part in enumerate(parts):\n      r = _VALID_PART_RE if n < len(parts) - 1 else _VALID_LAST_PART_RE\n      if part and '{' in part and '}' in part:\n        if not r.match(part):\n          raise api_exceptions.ApiConfigurationError(\n              'Invalid path segment: %s (part of %s)' % (part, path))\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __field_to_subfields(self, field):\n    # Termination condition\n    if not isinstance(field, messages.MessageField):\n      return [[field]]\n\n    result = []\n    for subfield in sorted(field.message_type.all_fields(),\n                           key=lambda f: f.number):\n      subfield_results = self.__field_to_subfields(subfield)\n      for subfields_list in subfield_results:\n        subfields_list.insert(0, field)\n        result.append(subfields_list)\n    return result", "response": "Fully describes data represented by field including the nested case."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __field_to_parameter_type(self, field):\n    # We use lowercase values for types (e.g. 'string' instead of 'STRING').\n    variant = field.variant\n    if variant == messages.Variant.MESSAGE:\n      raise TypeError('A message variant can\\'t be used in a parameter.')\n\n    custom_variant_map = {\n        messages.Variant.SINT32: 'int32',\n        messages.Variant.SINT64: 'int64',\n        messages.Variant.BOOL: 'boolean',\n        messages.Variant.ENUM: 'string',\n    }\n    return custom_variant_map.get(variant) or variant.name.lower()", "response": "Converts the field variant type into a string describing the parameter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a path parameter string and organizes them by parameter.", "response": "def __get_path_parameters(self, path):\n    \"\"\"Parses path paremeters from a URI path and organizes them by parameter.\n\n    Some of the parameters may correspond to message fields, and so will be\n    represented as segments corresponding to each subfield; e.g. first.second if\n    the field \"second\" in the message field \"first\" is pulled from the path.\n\n    The resulting dictionary uses the first segments as keys and each key has as\n    value the list of full parameter values with first segment equal to the key.\n\n    If the match path parameter is null, that part of the path template is\n    ignored; this occurs if '{}' is used in a template.\n\n    Args:\n      path: String; a URI path, potentially with some parameters.\n\n    Returns:\n      A dictionary with strings as keys and list of strings as values.\n    \"\"\"\n    path_parameters_by_segment = {}\n    for format_var_name in re.findall(_PATH_VARIABLE_PATTERN, path):\n      first_segment = format_var_name.split('.', 1)[0]\n      matches = path_parameters_by_segment.setdefault(first_segment, [])\n      matches.append(format_var_name)\n\n    return path_parameters_by_segment"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that a proposed subfield actually exists and is a simple field.", "response": "def __validate_simple_subfield(self, parameter, field, segment_list,\n                                 _segment_index=0):\n    \"\"\"Verifies that a proposed subfield actually exists and is a simple field.\n\n    Here, simple means it is not a MessageField (nested).\n\n    Args:\n      parameter: String; the '.' delimited name of the current field being\n          considered. This is relative to some root.\n      field: An instance of a subclass of messages.Field. Corresponds to the\n          previous segment in the path (previous relative to _segment_index),\n          since this field should be a message field with the current segment\n          as a field in the message class.\n      segment_list: The full list of segments from the '.' delimited subfield\n          being validated.\n      _segment_index: Integer; used to hold the position of current segment so\n          that segment_list can be passed as a reference instead of having to\n          copy using segment_list[1:] at each step.\n\n    Raises:\n      TypeError: If the final subfield (indicated by _segment_index relative\n        to the length of segment_list) is a MessageField.\n      TypeError: If at any stage the lookup at a segment fails, e.g if a.b\n        exists but a.b.c does not exist. This can happen either if a.b is not\n        a message field or if a.b.c is not a property on the message class from\n        a.b.\n    \"\"\"\n    if _segment_index >= len(segment_list):\n      # In this case, the field is the final one, so should be simple type\n      if isinstance(field, messages.MessageField):\n        field_class = field.__class__.__name__\n        raise TypeError('Can\\'t use messages in path. Subfield %r was '\n                        'included but is a %s.' % (parameter, field_class))\n      return\n\n    segment = segment_list[_segment_index]\n    parameter += '.' + segment\n    try:\n      field = field.type.field_by_name(segment)\n    except (AttributeError, KeyError):\n      raise TypeError('Subfield %r from path does not exist.' % (parameter,))\n\n    self.__validate_simple_subfield(parameter, field, segment_list,\n                                    _segment_index=_segment_index + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __validate_path_parameters(self, field, path_parameters):\n    for param in path_parameters:\n      segment_list = param.split('.')\n      if segment_list[0] != field.name:\n        raise TypeError('Subfield %r can\\'t come from field %r.'\n                        % (param, field.name))\n      self.__validate_simple_subfield(field.name, field, segment_list[1:])", "response": "Verifies that all path parameters correspond to an existing subfield."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning default value of final subfield if it has one.", "response": "def __parameter_default(self, final_subfield):\n    \"\"\"Returns default value of final subfield if it has one.\n\n    If this subfield comes from a field list returned from __field_to_subfields,\n    none of the fields in the subfield list can have a default except the final\n    one since they all must be message fields.\n\n    Args:\n      final_subfield: A simple field from the end of a subfield list.\n\n    Returns:\n      The default value of the subfield, if any exists, with the exception of an\n          enum field, which will have its value cast to a string.\n    \"\"\"\n    if final_subfield.default:\n      if isinstance(final_subfield, messages.EnumField):\n        return final_subfield.default.name\n      else:\n        return final_subfield.default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the enum descriptor of the final subfield if it is an enum.", "response": "def __parameter_enum(self, final_subfield):\n    \"\"\"Returns enum descriptor of final subfield if it is an enum.\n\n    An enum descriptor is a dictionary with keys as the names from the enum and\n    each value is a dictionary with a single key \"backendValue\" and value equal\n    to the same enum name used to stored it in the descriptor.\n\n    The key \"description\" can also be used next to \"backendValue\", but protorpc\n    Enum classes have no way of supporting a description for each value.\n\n    Args:\n      final_subfield: A simple field from the end of a subfield list.\n\n    Returns:\n      The enum descriptor for the field, if it's an enum descriptor, else\n          returns None.\n    \"\"\"\n    if isinstance(final_subfield, messages.EnumField):\n      enum_descriptor = {}\n      for enum_value in final_subfield.type.to_dict().keys():\n        enum_descriptor[enum_value] = {'backendValue': enum_value}\n      return enum_descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __parameter_descriptor(self, subfield_list):\n    descriptor = {}\n    final_subfield = subfield_list[-1]\n\n    # Required\n    if all(subfield.required for subfield in subfield_list):\n      descriptor['required'] = True\n\n    # Type\n    descriptor['type'] = self.__field_to_parameter_type(final_subfield)\n\n    # Default\n    default = self.__parameter_default(final_subfield)\n    if default is not None:\n      descriptor['default'] = default\n\n    # Repeated\n    if any(subfield.repeated for subfield in subfield_list):\n      descriptor['repeated'] = True\n\n    # Enum\n    enum_descriptor = self.__parameter_enum(final_subfield)\n    if enum_descriptor is not None:\n      descriptor['enum'] = enum_descriptor\n\n    return descriptor", "response": "Creates a descriptor for a parameter using the subfields that define it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds all parameters in a field to a method parameters descriptor.", "response": "def __add_parameters_from_field(self, field, path_parameters,\n                                  params, param_order):\n    \"\"\"Adds all parameters in a field to a method parameters descriptor.\n\n    Simple fields will only have one parameter, but a message field 'x' that\n    corresponds to a message class with fields 'y' and 'z' will result in\n    parameters 'x.y' and 'x.z', for example. The mapping from field to\n    parameters is mostly handled by __field_to_subfields.\n\n    Args:\n      field: Field from which parameters will be added to the method descriptor.\n      path_parameters: A list of parameters matched from a path for this field.\n         For example for the hypothetical 'x' from above if the path was\n         '/a/{x.z}/b/{other}' then this list would contain only the element\n         'x.z' since 'other' does not match to this field.\n      params: Dictionary with parameter names as keys and parameter descriptors\n          as values. This will be updated for each parameter in the field.\n      param_order: List of required parameter names to give them an order in the\n          descriptor. All required parameters in the field will be added to this\n          list.\n    \"\"\"\n    for subfield_list in self.__field_to_subfields(field):\n      descriptor = self.__parameter_descriptor(subfield_list)\n\n      qualified_name = '.'.join(subfield.name for subfield in subfield_list)\n      in_path = qualified_name in path_parameters\n      if descriptor.get('required', in_path):\n        descriptor['required'] = True\n        param_order.append(qualified_name)\n\n      params[qualified_name] = descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndescribing the parameters of a method.", "response": "def __params_descriptor(self, message_type, request_kind, path, method_id):\n    \"\"\"Describe the parameters of a method.\n\n    If the message_type is not a ResourceContainer, will fall back to\n    __params_descriptor_without_container (which will eventually be deprecated).\n\n    If the message type is a ResourceContainer, then all path/query parameters\n    will come from the ResourceContainer This method will also make sure all\n    path parameters are covered by the message fields.\n\n    Args:\n      message_type: messages.Message or ResourceContainer class, Message with\n        parameters to describe.\n      request_kind: The type of request being made.\n      path: string, HTTP path to method.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n\n    Returns:\n      A tuple (dict, list of string): Descriptor of the parameters, Order of the\n        parameters.\n    \"\"\"\n    path_parameter_dict = self.__get_path_parameters(path)\n\n    if not isinstance(message_type, resource_container.ResourceContainer):\n      if path_parameter_dict:\n        _logger.warning('Method %s specifies path parameters but you are not '\n                        'using a ResourceContainer; instead, you are using %r. '\n                        'This will fail in future releases; please switch to '\n                        'using ResourceContainer as soon as possible.',\n                        method_id, type(message_type))\n      return self.__params_descriptor_without_container(\n          message_type, request_kind, path)\n\n    # From here, we can assume message_type is a ResourceContainer\n    message_type = message_type.parameters_message_class()\n\n    params = {}\n    param_order = []\n\n    # Make sure all path parameters are covered.\n    for field_name, matched_path_parameters in path_parameter_dict.iteritems():\n      field = message_type.field_by_name(field_name)\n      self.__validate_path_parameters(field, matched_path_parameters)\n\n    # Add all fields, sort by field.number since we have parameterOrder.\n    for field in sorted(message_type.all_fields(), key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      self.__add_parameters_from_field(field, matched_path_parameters,\n                                       params, param_order)\n\n    return params, param_order"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndescribe the parameters and body of the request.", "response": "def __request_message_descriptor(self, request_kind, message_type, method_id,\n                                   path):\n    \"\"\"Describes the parameters and body of the request.\n\n    Args:\n      request_kind: The type of request being made.\n      message_type: messages.Message or ResourceContainer class. The message to\n          describe.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n      path: string, HTTP path to method.\n\n    Returns:\n      Dictionary describing the request.\n\n    Raises:\n      ValueError: if the method path and request required fields do not match\n    \"\"\"\n    descriptor = {}\n\n    params, param_order = self.__params_descriptor(message_type, request_kind,\n                                                   path, method_id)\n\n    if isinstance(message_type, resource_container.ResourceContainer):\n      message_type = message_type.body_message_class()\n\n    if (request_kind == self.__NO_BODY or\n        message_type == message_types.VoidMessage()):\n      descriptor['body'] = 'empty'\n    else:\n      descriptor['body'] = 'autoTemplate(backendRequest)'\n      descriptor['bodyName'] = 'resource'\n      self.__request_schema[method_id] = self.__parser.add_message(\n          message_type.__class__)\n\n    if params:\n      descriptor['parameters'] = params\n\n    if param_order:\n      descriptor['parameterOrder'] = param_order\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndescribe a method. Args: service: endpoints.Service, Implementation of the API as a service. method_info: _MethodInfo, Configuration for the method. rosy_method: string, ProtoRPC method name prefixed with the name of the service. protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC description of the method. Returns: Dictionary describing the method.", "response": "def __method_descriptor(self, service, method_info,\n                          rosy_method, protorpc_method_info):\n    \"\"\"Describes a method.\n\n    Args:\n      service: endpoints.Service, Implementation of the API as a service.\n      method_info: _MethodInfo, Configuration for the method.\n      rosy_method: string, ProtoRPC method name prefixed with the\n        name of the service.\n      protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC\n        description of the method.\n\n    Returns:\n      Dictionary describing the method.\n    \"\"\"\n    descriptor = {}\n\n    request_message_type = (resource_container.ResourceContainer.\n                            get_request_message(protorpc_method_info.remote))\n    request_kind = self.__get_request_kind(method_info)\n    remote_method = protorpc_method_info.remote\n\n    descriptor['path'] = method_info.get_path(service.api_info)\n    descriptor['httpMethod'] = method_info.http_method\n    descriptor['rosyMethod'] = rosy_method\n    descriptor['request'] = self.__request_message_descriptor(\n        request_kind, request_message_type,\n        method_info.method_id(service.api_info),\n        descriptor['path'])\n    descriptor['response'] = self.__response_message_descriptor(\n        remote_method.response_type(), method_info.method_id(service.api_info))\n\n    # Audiences, scopes, allowed_client_ids and auth_level could be set at\n    # either the method level or the API level.  Allow an empty list at the\n    # method level to override the setting at the API level.\n    scopes = (method_info.scopes\n              if method_info.scopes is not None\n              else service.api_info.scopes)\n    if scopes:\n      descriptor['scopes'] = scopes\n    audiences = (method_info.audiences\n                 if method_info.audiences is not None\n                 else service.api_info.audiences)\n    if audiences:\n      descriptor['audiences'] = audiences\n    allowed_client_ids = (method_info.allowed_client_ids\n                          if method_info.allowed_client_ids is not None\n                          else service.api_info.allowed_client_ids)\n    if allowed_client_ids:\n      descriptor['clientIds'] = allowed_client_ids\n\n    if remote_method.method.__doc__:\n      descriptor['description'] = remote_method.method.__doc__\n\n    auth_level = (method_info.auth_level\n                  if method_info.auth_level is not None\n                  else service.api_info.auth_level)\n    if auth_level is not None:\n      descriptor['authLevel'] = AUTH_LEVEL.reverse_mapping[auth_level]\n\n    descriptor['useRequestUri'] = method_info.use_request_uri(service.api_info)\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __schema_descriptor(self, services):\n    methods_desc = {}\n\n    for service in services:\n      protorpc_methods = service.all_remote_methods()\n      for protorpc_method_name in protorpc_methods.iterkeys():\n        rosy_method = '%s.%s' % (service.__name__, protorpc_method_name)\n        method_id = self.__id_from_name[rosy_method]\n\n        request_response = {}\n\n        request_schema_id = self.__request_schema.get(method_id)\n        if request_schema_id:\n          request_response['request'] = {\n              '$ref': request_schema_id\n              }\n\n        response_schema_id = self.__response_schema.get(method_id)\n        if response_schema_id:\n          request_response['response'] = {\n              '$ref': response_schema_id\n              }\n\n        methods_desc[rosy_method] = request_response\n\n    descriptor = {\n        'methods': methods_desc,\n        'schemas': self.__parser.schemas(),\n        }\n\n    return descriptor", "response": "Returns a dictionary containing all the JSON Schema used in the given services."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a description of an API.", "response": "def __get_merged_api_info(self, services):\n    \"\"\"Builds a description of an API.\n\n    Args:\n      services: List of protorpc.remote.Service instances implementing an\n        api/version.\n\n    Returns:\n      The _ApiInfo object to use for the API that the given services implement.\n\n    Raises:\n      ApiConfigurationError: If there's something wrong with the API\n        configuration, such as a multiclass API decorated with different API\n        descriptors (see the docstring for api()).\n    \"\"\"\n    merged_api_info = services[0].api_info\n\n    # Verify that, if there are multiple classes here, they're allowed to\n    # implement the same API.\n    for service in services[1:]:\n      if not merged_api_info.is_same_api(service.api_info):\n        raise api_exceptions.ApiConfigurationError(\n            _MULTICLASS_MISMATCH_ERROR_TEMPLATE % (service.api_info.name,\n                                                   service.api_info.api_version))\n\n    return merged_api_info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild an auth descriptor from API info.", "response": "def __auth_descriptor(self, api_info):\n    \"\"\"Builds an auth descriptor from API info.\n\n    Args:\n      api_info: An _ApiInfo object.\n\n    Returns:\n      A dictionary with 'allowCookieAuth' and/or 'blockedRegions' keys.\n    \"\"\"\n    if api_info.auth is None:\n      return None\n\n    auth_descriptor = {}\n    if api_info.auth.allow_cookie_auth is not None:\n      auth_descriptor['allowCookieAuth'] = api_info.auth.allow_cookie_auth\n    if api_info.auth.blocked_regions:\n      auth_descriptor['blockedRegions'] = api_info.auth.blocked_regions\n\n    return auth_descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __frontend_limit_descriptor(self, api_info):\n    if api_info.frontend_limits is None:\n      return None\n\n    descriptor = {}\n    for propname, descname in (('unregistered_user_qps', 'unregisteredUserQps'),\n                               ('unregistered_qps', 'unregisteredQps'),\n                               ('unregistered_daily', 'unregisteredDaily')):\n      if getattr(api_info.frontend_limits, propname) is not None:\n        descriptor[descname] = getattr(api_info.frontend_limits, propname)\n\n    rules = self.__frontend_limit_rules_descriptor(api_info)\n    if rules:\n      descriptor['rules'] = rules\n\n    return descriptor", "response": "Builds a frontend limit descriptor from API info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a frontend limit rules descriptor from API info.", "response": "def __frontend_limit_rules_descriptor(self, api_info):\n    \"\"\"Builds a frontend limit rules descriptor from API info.\n\n    Args:\n      api_info: An _ApiInfo object.\n\n    Returns:\n      A list of dictionaries with frontend limit rules information.\n    \"\"\"\n    if not api_info.frontend_limits.rules:\n      return None\n\n    rules = []\n    for rule in api_info.frontend_limits.rules:\n      descriptor = {}\n      for propname, descname in (('match', 'match'),\n                                 ('qps', 'qps'),\n                                 ('user_qps', 'userQps'),\n                                 ('daily', 'daily'),\n                                 ('analytics_id', 'analyticsId')):\n        if getattr(rule, propname) is not None:\n          descriptor[descname] = getattr(rule, propname)\n      if descriptor:\n        rules.append(descriptor)\n\n    return rules"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a description document for an API.", "response": "def __api_descriptor(self, services, hostname=None):\n    \"\"\"Builds a description of an API.\n\n    Args:\n      services: List of protorpc.remote.Service instances implementing an\n        api/version.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      A dictionary that can be deserialized into JSON and stored as an API\n      description document.\n\n    Raises:\n      ApiConfigurationError: If there's something wrong with the API\n        configuration, such as a multiclass API decorated with different API\n        descriptors (see the docstring for api()), or a repeated method\n        signature.\n    \"\"\"\n    merged_api_info = self.__get_merged_api_info(services)\n    descriptor = self.get_descriptor_defaults(merged_api_info,\n                                              hostname=hostname)\n    description = merged_api_info.description\n    if not description and len(services) == 1:\n      description = services[0].__doc__\n    if description:\n      descriptor['description'] = description\n\n    auth_descriptor = self.__auth_descriptor(merged_api_info)\n    if auth_descriptor:\n      descriptor['auth'] = auth_descriptor\n\n    frontend_limit_descriptor = self.__frontend_limit_descriptor(\n        merged_api_info)\n    if frontend_limit_descriptor:\n      descriptor['frontendLimits'] = frontend_limit_descriptor\n\n    method_map = {}\n    method_collision_tracker = {}\n    rest_collision_tracker = {}\n\n    for service in services:\n      remote_methods = service.all_remote_methods()\n      for protorpc_meth_name, protorpc_meth_info in remote_methods.iteritems():\n        method_info = getattr(protorpc_meth_info, 'method_info', None)\n        # Skip methods that are not decorated with @method\n        if method_info is None:\n          continue\n        method_id = method_info.method_id(service.api_info)\n        rosy_method = '%s.%s' % (service.__name__, protorpc_meth_name)\n        self.__id_from_name[rosy_method] = method_id\n        method_map[method_id] = self.__method_descriptor(\n            service, method_info, rosy_method, protorpc_meth_info)\n\n        # Make sure the same method name isn't repeated.\n        if method_id in method_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              'Method %s used multiple times, in classes %s and %s' %\n              (method_id, method_collision_tracker[method_id],\n               service.__name__))\n        else:\n          method_collision_tracker[method_id] = service.__name__\n\n        # Make sure the same HTTP method & path aren't repeated.\n        rest_identifier = (method_info.http_method,\n                           method_info.get_path(service.api_info))\n        if rest_identifier in rest_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              '%s path \"%s\" used multiple times, in classes %s and %s' %\n              (method_info.http_method, method_info.get_path(service.api_info),\n               rest_collision_tracker[rest_identifier],\n               service.__name__))\n        else:\n          rest_collision_tracker[rest_identifier] = service.__name__\n\n    if method_map:\n      descriptor['methods'] = method_map\n      descriptor['descriptor'] = self.__schema_descriptor(services)\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary with the default configuration for a given API.", "response": "def get_descriptor_defaults(self, api_info, hostname=None):\n    \"\"\"Gets a default configuration for a service.\n\n    Args:\n      api_info: _ApiInfo object for this service.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      A dictionary with the default configuration.\n    \"\"\"\n    hostname = (hostname or endpoints_util.get_app_hostname() or\n                api_info.hostname)\n    protocol = 'http' if ((hostname and hostname.startswith('localhost')) or\n                          endpoints_util.is_running_on_devserver()) else 'https'\n    base_path = api_info.base_path.strip('/')\n    defaults = {\n        'extends': 'thirdParty.api',\n        'root': '{0}://{1}/{2}'.format(protocol, hostname, base_path),\n        'name': api_info.name,\n        'version': api_info.api_version,\n        'api_version': api_info.api_version,\n        'path_version': api_info.path_version,\n        'defaultVersion': True,\n        'abstract': False,\n        'adapter': {\n            'bns': '{0}://{1}/{2}'.format(protocol, hostname, base_path),\n            'type': 'lily',\n            'deadline': 10.0\n        }\n    }\n    if api_info.canonical_name:\n      defaults['canonicalName'] = api_info.canonical_name\n    if api_info.owner_domain:\n      defaults['ownerDomain'] = api_info.owner_domain\n    if api_info.owner_name:\n      defaults['ownerName'] = api_info.owner_name\n    if api_info.package_path:\n      defaults['packagePath'] = api_info.package_path\n    if api_info.title:\n      defaults['title'] = api_info.title\n    if api_info.documentation:\n      defaults['documentation'] = api_info.documentation\n    return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_config_dict(self, services, hostname=None):\n    if not isinstance(services, (tuple, list)):\n      services = [services]\n    # The type of a class that inherits from remote.Service is actually\n    # remote._ServiceClass, thanks to metaclass strangeness.\n    # pylint: disable=protected-access\n    endpoints_util.check_list_type(services, remote._ServiceClass, 'services',\n                                   allow_none=False)\n\n    return self.__api_descriptor(services, hostname=hostname)", "response": "Returns a JSON dict description of a protorpc. remote. Service in API format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pretty_print_config_to_json(self, services, hostname=None):\n    descriptor = self.get_config_dict(services, hostname)\n    return json.dumps(descriptor, sort_keys=True, indent=2,\n                      separators=(',', ': '))", "response": "Pretty print a list of services to JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the field variant type into a tuple describing the parameter type and format of the field.", "response": "def __field_to_parameter_type_and_format(self, field):\n    \"\"\"Converts the field variant type into a tuple describing the parameter.\n\n    Args:\n      field: An instance of a subclass of messages.Field.\n\n    Returns:\n      A tuple with the type and format of the field, respectively.\n\n    Raises:\n      TypeError: if the field variant is a message variant.\n    \"\"\"\n    # We use lowercase values for types (e.g. 'string' instead of 'STRING').\n    variant = field.variant\n    if variant == messages.Variant.MESSAGE:\n      raise TypeError('A message variant cannot be used in a parameter.')\n\n    # Note that the 64-bit integers are marked as strings -- this is to\n    # accommodate JavaScript, which would otherwise demote them to 32-bit\n    # integers.\n\n    return CUSTOM_VARIANT_MAP.get(variant) or (variant.name.lower(), None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __parameter_default(self, field):\n    if field.default:\n      if isinstance(field, messages.EnumField):\n        return field.default.name\n      elif isinstance(field, messages.BooleanField):\n        # The Python standard representation of a boolean value causes problems\n        # when generating client code.\n        return 'true' if field.default else 'false'\n      else:\n        return str(field.default)", "response": "Returns default value of the field if any exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning enum descriptor of a parameter if it is an enum.", "response": "def __parameter_enum(self, param):\n    \"\"\"Returns enum descriptor of a parameter if it is an enum.\n\n    An enum descriptor is a list of keys.\n\n    Args:\n      param: A simple field.\n\n    Returns:\n      The enum descriptor for the field, if it's an enum descriptor, else\n          returns None.\n    \"\"\"\n    if isinstance(param, messages.EnumField):\n      return [enum_entry[0] for enum_entry in sorted(\n          param.type.to_dict().items(), key=lambda v: v[1])]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a descriptor for a parameter.", "response": "def __parameter_descriptor(self, param):\n    \"\"\"Creates descriptor for a parameter.\n\n    Args:\n      param: The parameter to be described.\n\n    Returns:\n      Dictionary containing a descriptor for the parameter.\n    \"\"\"\n    descriptor = {}\n\n    param_type, param_format = self.__field_to_parameter_type_and_format(param)\n\n    # Required\n    if param.required:\n      descriptor['required'] = True\n\n    # Type\n    descriptor['type'] = param_type\n\n    # Format (optional)\n    if param_format:\n      descriptor['format'] = param_format\n\n    # Default\n    default = self.__parameter_default(param)\n    if default is not None:\n      descriptor['default'] = default\n\n    # Repeated\n    if param.repeated:\n      descriptor['repeated'] = True\n\n    # Enum\n    # Note that enumDescriptions are not currently supported using the\n    # framework's annotations, so just insert blank strings.\n    enum_descriptor = self.__parameter_enum(param)\n    if enum_descriptor is not None:\n      descriptor['enum'] = enum_descriptor\n      descriptor['enumDescriptions'] = [''] * len(enum_descriptor)\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __add_parameter(self, param, path_parameters, params):\n    # If this is a simple field, just build the descriptor and append it.\n    # Otherwise, build a schema and assign it to this descriptor\n    descriptor = None\n    if not isinstance(param, messages.MessageField):\n      name = param.name\n      descriptor = self.__parameter_descriptor(param)\n      descriptor['location'] = 'path' if name in path_parameters else 'query'\n\n      if descriptor:\n        params[name] = descriptor\n    else:\n      for subfield_list in self.__field_to_subfields(param):\n        name = '.'.join(subfield.name for subfield in subfield_list)\n        descriptor = self.__parameter_descriptor(subfield_list[-1])\n        if name in path_parameters:\n          descriptor['required'] = True\n          descriptor['location'] = 'path'\n        else:\n          descriptor.pop('required', None)\n          descriptor['location'] = 'query'\n\n        if descriptor:\n          params[name] = descriptor", "response": "Adds a parameter to the method parameters descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndescribing parameters of a method which does not use a ResourceContainer.", "response": "def __params_descriptor_without_container(self, message_type,\n                                            request_kind, path):\n    \"\"\"Describe parameters of a method which does not use a ResourceContainer.\n\n    Makes sure that the path parameters are included in the message definition\n    and adds any required fields and URL query parameters.\n\n    This method is to preserve backwards compatibility and will be removed in\n    a future release.\n\n    Args:\n      message_type: messages.Message class, Message with parameters to describe.\n      request_kind: The type of request being made.\n      path: string, HTTP path to method.\n\n    Returns:\n      A list of dicts: Descriptors of the parameters\n    \"\"\"\n    params = {}\n\n    path_parameter_dict = self.__get_path_parameters(path)\n    for field in sorted(message_type.all_fields(), key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      self.__validate_path_parameters(field, matched_path_parameters)\n      if matched_path_parameters or request_kind == self.__NO_BODY:\n        self.__add_parameter(field, matched_path_parameters, params)\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __params_descriptor(self, message_type, request_kind, path, method_id,\n                          request_params_class):\n    \"\"\"Describe the parameters of a method.\n\n    If the message_type is not a ResourceContainer, will fall back to\n    __params_descriptor_without_container (which will eventually be deprecated).\n\n    If the message type is a ResourceContainer, then all path/query parameters\n    will come from the ResourceContainer. This method will also make sure all\n    path parameters are covered by the message fields.\n\n    Args:\n      message_type: messages.Message or ResourceContainer class, Message with\n        parameters to describe.\n      request_kind: The type of request being made.\n      path: string, HTTP path to method.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n      request_params_class: messages.Message, the original params message when\n        using a ResourceContainer. Otherwise, this should be null.\n\n    Returns:\n      A tuple (dict, list of string): Descriptor of the parameters, Order of the\n        parameters.\n    \"\"\"\n    path_parameter_dict = self.__get_path_parameters(path)\n\n    if request_params_class is None:\n      if path_parameter_dict:\n        _logger.warning('Method %s specifies path parameters but you are not '\n                        'using a ResourceContainer; instead, you are using %r. '\n                        'This will fail in future releases; please switch to '\n                        'using ResourceContainer as soon as possible.',\n                        method_id, type(message_type))\n      return self.__params_descriptor_without_container(\n          message_type, request_kind, path)\n\n    # From here, we can assume message_type is from a ResourceContainer.\n    message_type = request_params_class\n\n    params = {}\n\n    # Make sure all path parameters are covered.\n    for field_name, matched_path_parameters in path_parameter_dict.iteritems():\n      field = message_type.field_by_name(field_name)\n      self.__validate_path_parameters(field, matched_path_parameters)\n\n    # Add all fields, sort by field.number since we have parameterOrder.\n    for field in sorted(message_type.all_fields(), key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      self.__add_parameter(field, matched_path_parameters, params)\n\n    return params", "response": "Describe the parameters of a method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndescribe the order of path parameters.", "response": "def __params_order_descriptor(self, message_type, path, is_params_class=False):\n    \"\"\"Describe the order of path parameters.\n\n    Args:\n      message_type: messages.Message class, Message with parameters to describe.\n      path: string, HTTP path to method.\n      is_params_class: boolean, Whether the message represents URL parameters.\n\n    Returns:\n      Descriptor list for the parameter order.\n    \"\"\"\n    path_params = []\n    query_params = []\n    path_parameter_dict = self.__get_path_parameters(path)\n\n    for field in sorted(message_type.all_fields(), key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      if not isinstance(field, messages.MessageField):\n        name = field.name\n        if name in matched_path_parameters:\n          path_params.append(name)\n        elif is_params_class and field.required:\n          query_params.append(name)\n      else:\n        for subfield_list in self.__field_to_subfields(field):\n          name = '.'.join(subfield.name for subfield in subfield_list)\n          if name in matched_path_parameters:\n            path_params.append(name)\n          elif is_params_class and field.required:\n            query_params.append(name)\n\n    return path_params + sorted(query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __schemas_descriptor(self):\n    # Filter out any keys that aren't 'properties', 'type', or 'id'\n    result = {}\n    for schema_key, schema_value in self.__parser.schemas().iteritems():\n      field_keys = schema_value.keys()\n      key_result = {}\n\n      # Some special processing for the properties value\n      if 'properties' in field_keys:\n        key_result['properties'] = schema_value['properties'].copy()\n        # Add in enumDescriptions for any enum properties and strip out\n        # the required tag for consistency with Java framework\n        for prop_key, prop_value in schema_value['properties'].iteritems():\n          if 'enum' in prop_value:\n            num_enums = len(prop_value['enum'])\n            key_result['properties'][prop_key]['enumDescriptions'] = (\n                [''] * num_enums)\n          elif 'default' in prop_value:\n            # stringify default values\n            if prop_value.get('type') == 'boolean':\n              prop_value['default'] = 'true' if prop_value['default'] else 'false'\n            else:\n              prop_value['default'] = str(prop_value['default'])\n          key_result['properties'][prop_key].pop('required', None)\n\n      for key in ('type', 'id', 'description'):\n        if key in field_keys:\n          key_result[key] = schema_value[key]\n\n      if key_result:\n        result[schema_key] = key_result\n\n    # Add 'type': 'object' to all object properties\n    for schema_value in result.itervalues():\n      for field_value in schema_value.itervalues():\n        if isinstance(field_value, dict):\n          if '$ref' in field_value:\n            field_value['type'] = 'object'\n\n    return result", "response": "Describes the schemas section of the discovery document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __request_message_descriptor(self, request_kind, message_type, method_id,\n                                   request_body_class):\n    \"\"\"Describes the parameters and body of the request.\n\n    Args:\n      request_kind: The type of request being made.\n      message_type: messages.Message or ResourceContainer class. The message to\n          describe.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n      request_body_class: messages.Message of the original body when using\n          a ResourceContainer. Otherwise, this should be null.\n\n    Returns:\n      Dictionary describing the request.\n\n    Raises:\n      ValueError: if the method path and request required fields do not match\n    \"\"\"\n    if request_body_class:\n      message_type = request_body_class\n\n    if (request_kind != self.__NO_BODY and\n        message_type != message_types.VoidMessage()):\n      self.__request_schema[method_id] = self.__parser.add_message(\n          message_type.__class__)\n      return {\n          '$ref': self.__request_schema[method_id],\n          'parameterName': 'resource',\n      }", "response": "Describes the parameters and body of the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndescribe a method. Args: service: endpoints.Service, Implementation of the API as a service. method_info: _MethodInfo, Configuration for the method. protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC description of the method. Returns: Dictionary describing the method.", "response": "def __method_descriptor(self, service, method_info,\n                          protorpc_method_info):\n    \"\"\"Describes a method.\n\n    Args:\n      service: endpoints.Service, Implementation of the API as a service.\n      method_info: _MethodInfo, Configuration for the method.\n      protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC\n        description of the method.\n\n    Returns:\n      Dictionary describing the method.\n    \"\"\"\n    descriptor = {}\n\n    request_message_type = (resource_container.ResourceContainer.\n                            get_request_message(protorpc_method_info.remote))\n    request_kind = self.__get_request_kind(method_info)\n    remote_method = protorpc_method_info.remote\n\n    method_id = method_info.method_id(service.api_info)\n\n    path = method_info.get_path(service.api_info)\n\n    description = protorpc_method_info.remote.method.__doc__\n\n    descriptor['id'] = method_id\n    descriptor['path'] = path\n    descriptor['httpMethod'] = method_info.http_method\n\n    if description:\n      descriptor['description'] = description\n\n    descriptor['scopes'] = [\n        'https://www.googleapis.com/auth/userinfo.email'\n    ]\n\n    parameters = self.__params_descriptor(\n        request_message_type, request_kind, path, method_id,\n        method_info.request_params_class)\n    if parameters:\n      descriptor['parameters'] = parameters\n\n    if method_info.request_params_class:\n      parameter_order = self.__params_order_descriptor(\n        method_info.request_params_class, path, is_params_class=True)\n    else:\n      parameter_order = self.__params_order_descriptor(\n        request_message_type, path, is_params_class=False)\n    if parameter_order:\n      descriptor['parameterOrder'] = parameter_order\n\n    request_descriptor = self.__request_message_descriptor(\n        request_kind, request_message_type, method_id,\n        method_info.request_body_class)\n    if request_descriptor is not None:\n      descriptor['request'] = request_descriptor\n\n    response_descriptor = self.__response_message_descriptor(\n        remote_method.response_type(), method_info.method_id(service.api_info))\n    if response_descriptor is not None:\n      descriptor['response'] = response_descriptor\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __resource_descriptor(self, resource_path, methods):\n    descriptor = {}\n    method_map = {}\n    sub_resource_index = collections.defaultdict(list)\n    sub_resource_map = {}\n\n    resource_path_tokens = resource_path.split('.')\n    for service, protorpc_meth_info in methods:\n      method_info = getattr(protorpc_meth_info, 'method_info', None)\n      path = method_info.get_path(service.api_info)\n      method_id = method_info.method_id(service.api_info)\n      canonical_method_id = self._get_canonical_method_id(method_id)\n\n      current_resource_path = self._get_resource_path(method_id)\n\n      # Sanity-check that this method belongs to the resource path\n      if (current_resource_path[:len(resource_path_tokens)] !=\n          resource_path_tokens):\n        raise api_exceptions.ToolError(\n            'Internal consistency error in resource path {0}'.format(\n                current_resource_path))\n\n      # Remove the portion of the current method's resource path that's already\n      # part of the resource path at this level.\n      effective_resource_path = current_resource_path[\n          len(resource_path_tokens):]\n\n      # If this method is part of a sub-resource, note it and skip it for now\n      if effective_resource_path:\n        sub_resource_name = effective_resource_path[0]\n        new_resource_path = '.'.join([resource_path, sub_resource_name])\n        sub_resource_index[new_resource_path].append(\n            (service, protorpc_meth_info))\n      else:\n        method_map[canonical_method_id] = self.__method_descriptor(\n            service, method_info, protorpc_meth_info)\n\n    # Process any sub-resources\n    for sub_resource, sub_resource_methods in sub_resource_index.items():\n      sub_resource_name = sub_resource.split('.')[-1]\n      sub_resource_map[sub_resource_name] = self.__resource_descriptor(\n          sub_resource, sub_resource_methods)\n\n    if method_map:\n      descriptor['methods'] = method_map\n\n    if sub_resource_map:\n      descriptor['resources'] = sub_resource_map\n\n    return descriptor", "response": "Describes a resource.\n\n    Args:\n      resource_path: string, the path of the resource (e.g., 'entries.items')\n      methods: list of tuples of type\n        (endpoints.Service, protorpc.remote._RemoteMethodInfo), the methods\n        that serve this resource.\n\n    Returns:\n      Dictionary describing the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a description of an API.", "response": "def __get_merged_api_info(self, services):\n    \"\"\"Builds a description of an API.\n\n    Args:\n      services: List of protorpc.remote.Service instances implementing an\n        api/version.\n\n    Returns:\n      The _ApiInfo object to use for the API that the given services implement.\n    \"\"\"\n    base_paths = sorted(set(s.api_info.base_path for s in services))\n    if len(base_paths) != 1:\n      raise api_exceptions.ApiConfigurationError(\n          'Multiple base_paths found: {!r}'.format(base_paths))\n    names_versions = sorted(set(\n        (s.api_info.name, s.api_info.api_version) for s in services))\n    if len(names_versions) != 1:\n      raise api_exceptions.ApiConfigurationError(\n          'Multiple apis/versions found: {!r}'.format(names_versions))\n    return services[0].api_info"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __discovery_doc_descriptor(self, services, hostname=None):\n    merged_api_info = self.__get_merged_api_info(services)\n    descriptor = self.get_descriptor_defaults(merged_api_info,\n                                              hostname=hostname)\n\n    description = merged_api_info.description\n    if not description and len(services) == 1:\n      description = services[0].__doc__\n    if description:\n      descriptor['description'] = description\n\n    descriptor['parameters'] = self.__standard_parameters_descriptor()\n    descriptor['auth'] = self.__standard_auth_descriptor(services)\n\n    # Add namespace information, if provided\n    if merged_api_info.namespace:\n      descriptor['ownerDomain'] = merged_api_info.namespace.owner_domain\n      descriptor['ownerName'] = merged_api_info.namespace.owner_name\n      descriptor['packagePath'] = merged_api_info.namespace.package_path or ''\n    else:\n      if merged_api_info.owner_domain is not None:\n        descriptor['ownerDomain'] = merged_api_info.owner_domain\n      if merged_api_info.owner_name is not None:\n        descriptor['ownerName'] = merged_api_info.owner_name\n      if merged_api_info.package_path is not None:\n        descriptor['packagePath'] = merged_api_info.package_path\n\n    method_map = {}\n    method_collision_tracker = {}\n    rest_collision_tracker = {}\n\n    resource_index = collections.defaultdict(list)\n    resource_map = {}\n\n    # For the first pass, only process top-level methods (that is, those methods\n    # that are unattached to a resource).\n    for service in services:\n      remote_methods = service.all_remote_methods()\n\n      for protorpc_meth_name, protorpc_meth_info in remote_methods.iteritems():\n        method_info = getattr(protorpc_meth_info, 'method_info', None)\n        # Skip methods that are not decorated with @method\n        if method_info is None:\n          continue\n        path = method_info.get_path(service.api_info)\n        method_id = method_info.method_id(service.api_info)\n        canonical_method_id = self._get_canonical_method_id(method_id)\n        resource_path = self._get_resource_path(method_id)\n\n        # Make sure the same method name isn't repeated.\n        if method_id in method_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              'Method %s used multiple times, in classes %s and %s' %\n              (method_id, method_collision_tracker[method_id],\n               service.__name__))\n        else:\n          method_collision_tracker[method_id] = service.__name__\n\n        # Make sure the same HTTP method & path aren't repeated.\n        rest_identifier = (method_info.http_method, path)\n        if rest_identifier in rest_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              '%s path \"%s\" used multiple times, in classes %s and %s' %\n              (method_info.http_method, path,\n               rest_collision_tracker[rest_identifier],\n               service.__name__))\n        else:\n          rest_collision_tracker[rest_identifier] = service.__name__\n\n        # If this method is part of a resource, note it and skip it for now\n        if resource_path:\n          resource_index[resource_path[0]].append((service, protorpc_meth_info))\n        else:\n          method_map[canonical_method_id] = self.__method_descriptor(\n              service, method_info, protorpc_meth_info)\n\n    # Do another pass for methods attached to resources\n    for resource, resource_methods in resource_index.items():\n      resource_map[resource] = self.__resource_descriptor(resource,\n          resource_methods)\n\n    if method_map:\n      descriptor['methods'] = method_map\n\n    if resource_map:\n      descriptor['resources'] = resource_map\n\n    # Add schemas, if any\n    schemas = self.__schemas_descriptor()\n    if schemas:\n      descriptor['schemas'] = schemas\n\n    return descriptor", "response": "Builds a discovery doc for an API."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary with the default configuration for a service.", "response": "def get_descriptor_defaults(self, api_info, hostname=None):\n    \"\"\"Gets a default configuration for a service.\n\n    Args:\n      api_info: _ApiInfo object for this service.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      A dictionary with the default configuration.\n    \"\"\"\n    if self.__request:\n      hostname = self.__request.reconstruct_hostname()\n      protocol = self.__request.url_scheme\n    else:\n      hostname = (hostname or util.get_app_hostname() or\n                  api_info.hostname)\n      protocol = 'http' if ((hostname and hostname.startswith('localhost')) or\n                            util.is_running_on_devserver()) else 'https'\n    full_base_path = '{0}{1}/{2}/'.format(api_info.base_path,\n                                          api_info.name,\n                                          api_info.path_version)\n    base_url = '{0}://{1}{2}'.format(protocol, hostname, full_base_path)\n    root_url = '{0}://{1}{2}'.format(protocol, hostname, api_info.base_path)\n    defaults = {\n        'kind': 'discovery#restDescription',\n        'discoveryVersion': 'v1',\n        'id': '{0}:{1}'.format(api_info.name, api_info.path_version),\n        'name': api_info.name,\n        'version': api_info.api_version,\n        'icons': {\n            'x16': 'https://www.gstatic.com/images/branding/product/1x/googleg_16dp.png',\n            'x32': 'https://www.gstatic.com/images/branding/product/1x/googleg_32dp.png'\n        },\n        'protocol': 'rest',\n        'servicePath': '{0}/{1}/'.format(api_info.name, api_info.path_version),\n        'batchPath': 'batch',\n        'basePath': full_base_path,\n        'rootUrl': root_url,\n        'baseUrl': base_url,\n        'description': 'This is an API',\n    }\n    if api_info.description:\n        defaults['description'] = api_info.description\n    if api_info.title:\n        defaults['title'] = api_info.title\n    if api_info.documentation:\n        defaults['documentationLink'] = api_info.documentation\n    if api_info.canonical_name:\n        defaults['canonicalName'] = api_info.canonical_name\n\n    return defaults"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON dict description of a protorpc. remote. Service in discovery format.", "response": "def get_discovery_doc(self, services, hostname=None):\n    \"\"\"JSON dict description of a protorpc.remote.Service in discovery format.\n\n    Args:\n      services: Either a single protorpc.remote.Service or a list of them\n        that implements an api/version.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      dict, The discovery document as a JSON dict.\n    \"\"\"\n\n    if not isinstance(services, (tuple, list)):\n      services = [services]\n\n    # The type of a class that inherits from remote.Service is actually\n    # remote._ServiceClass, thanks to metaclass strangeness.\n    # pylint: disable=protected-access\n    util.check_list_type(services, remote._ServiceClass, 'services',\n                         allow_none=False)\n\n    return self.__discovery_doc_descriptor(services, hostname=hostname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_wsgi_response(status, headers, content, start_response,\n                       cors_handler=None):\n  \"\"\"Dump reformatted response to CGI start_response.\n\n  This calls start_response and returns the response body.\n\n  Args:\n    status: A string containing the HTTP status code to send.\n    headers: A list of (header, value) tuples, the headers to send in the\n      response.\n    content: A string containing the body content to write.\n    start_response: A function with semantics defined in PEP-333.\n    cors_handler: A handler to process CORS request headers and update the\n      headers in the response.  Or this can be None, to bypass CORS checks.\n\n  Returns:\n    A string containing the response body.\n  \"\"\"\n  if cors_handler:\n    cors_handler.update_headers(headers)\n\n  # Update content length.\n  content_len = len(content) if content else 0\n  headers = [(header, value) for header, value in headers\n             if header.lower() != 'content-length']\n  headers.append(('Content-Length', '%s' % content_len))\n\n  start_response(status, headers)\n  return content", "response": "Dump reformatted response to WSGI start_response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_headers_from_environ(environ):\n  headers = wsgiref.headers.Headers([])\n  for header, value in environ.iteritems():\n    if header.startswith('HTTP_'):\n      headers[header[5:].replace('_', '-')] = value\n  # Content-Type is special; it does not start with 'HTTP_'.\n  if 'CONTENT_TYPE' in environ:\n    headers['CONTENT-TYPE'] = environ['CONTENT_TYPE']\n  return headers", "response": "Returns a wsgiref. headers. Headers object with headers from the environ dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put_headers_in_environ(headers, environ):\n  for key, value in headers:\n    environ['HTTP_%s' % key.upper().replace('-', '_')] = value", "response": "Given a list of headers put them into the environ dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the hostname prefix of a running Endpoints service.", "response": "def get_hostname_prefix():\n  \"\"\"Returns the hostname prefix of a running Endpoints service.\n\n  The prefix is the portion of the hostname that comes before the API name.\n  For example, if a non-default version and a non-default service are in use,\n  the returned result would be '{VERSION}-dot-{SERVICE}-'.\n\n  Returns:\n    str, the hostname prefix.\n  \"\"\"\n  parts = []\n\n  # Check if this is the default version\n  version = modules.get_current_version_name()\n  default_version = modules.get_default_version()\n  if version != default_version:\n    parts.append(version)\n\n  # Check if this is the default module\n  module = modules.get_current_module_name()\n  if module != 'default':\n    parts.append(module)\n\n  # If there is anything to prepend, add an extra blank entry for the trailing\n  # -dot-\n  if parts:\n    parts.append('')\n\n  return '-dot-'.join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the hostname of an App Engine or first - party Endpoints API.", "response": "def get_app_hostname():\n  \"\"\"Return hostname of a running Endpoints service.\n\n  Returns hostname of an running Endpoints API. It can be 1) \"localhost:PORT\"\n  if running on development server, or 2) \"app_id.appspot.com\" if running on\n  external app engine prod, or \"app_id.googleplex.com\" if running as Google\n  first-party Endpoints API, or 4) None if not running on App Engine\n  (e.g. Tornado Endpoints API).\n\n  Returns:\n    A string representing the hostname of the service.\n  \"\"\"\n  if not is_running_on_app_engine() or is_running_on_localhost():\n    return None\n\n  app_id = app_identity.get_application_id()\n\n  prefix = get_hostname_prefix()\n  suffix = 'appspot.com'\n\n  if ':' in app_id:\n    tokens = app_id.split(':')\n    api_name = tokens[1]\n    if tokens[0] == 'google.com':\n      suffix = 'googleplex.com'\n  else:\n    api_name = app_id\n\n  return '{0}{1}.{2}'.format(prefix, api_name, suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_list_type(objects, allowed_type, name, allow_none=True):\n  if objects is None:\n    if not allow_none:\n      raise TypeError('%s is None, which is not allowed.' % name)\n    return objects\n  if not isinstance(objects, (tuple, list)):\n    raise TypeError('%s is not a list.' % name)\n  if not all(isinstance(i, allowed_type) for i in objects):\n    type_list = sorted(list(set(type(obj) for obj in objects)))\n    raise TypeError('%s contains types that don\\'t match %s: %s' %\n                    (name, allowed_type.__name__, type_list))\n  return objects", "response": "Verify that objects in list are of the allowed type or raise TypeError."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert snake_case to headlessCamelCase.", "response": "def snake_case_to_headless_camel_case(snake_string):\n  \"\"\"Convert snake_case to headlessCamelCase.\n\n  Args:\n    snake_string: The string to be converted.\n  Returns:\n    The input string converted to headlessCamelCase.\n  \"\"\"\n  return ''.join([snake_string.split('_')[0]] +\n                 list(sub_string.capitalize()\n                      for sub_string in snake_string.split('_')[1:]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Proxy(self, status, headers, exc_info=None):\n    self.call_context['status'] = status\n    self.call_context['headers'] = headers\n    self.call_context['exc_info'] = exc_info\n\n    return self.body_buffer.write", "response": "Proxy method for handling HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a HTTP 200 json success response.", "response": "def _send_success_response(self, response, start_response):\n    \"\"\"Sends an HTTP 200 json success response.\n\n    This calls start_response and returns the response body.\n\n    Args:\n      response: A string containing the response body to return.\n      start_response: A function with semantics defined in PEP-333.\n\n    Returns:\n      A string, the response body.\n    \"\"\"\n    headers = [('Content-Type', 'application/json; charset=UTF-8')]\n    return util.send_wsgi_response('200 OK', headers, response, start_response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_rest_doc(self, request, start_response):\n    api = request.body_json['api']\n    version = request.body_json['version']\n\n    generator = discovery_generator.DiscoveryGenerator(request=request)\n    services = [s for s in self._backend.api_services if\n                s.api_info.name == api and s.api_info.api_version == version]\n    doc = generator.pretty_print_config_to_json(services)\n    if not doc:\n      error_msg = ('Failed to convert .api to discovery doc for '\n                   'version %s of api %s') % (version, api)\n      _logger.error('%s', error_msg)\n      return util.send_wsgi_error_response(error_msg, start_response)\n    return self._send_success_response(doc, start_response)", "response": "Returns the rest doc for the requested api and version."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _generate_api_config_with_root(self, request):\n    actual_root = self._get_actual_root(request)\n    generator = api_config.ApiConfigGenerator()\n    api = request.body_json['api']\n    version = request.body_json['version']\n    lookup_key = (api, version)\n\n    service_factories = self._backend.api_name_version_map.get(lookup_key)\n    if not service_factories:\n      return None\n\n    service_classes = [service_factory.service_class\n                       for service_factory in service_factories]\n    config_dict = generator.get_config_dict(\n        service_classes, hostname=actual_root)\n\n    # Save to cache\n    for config in config_dict.get('items', []):\n      lookup_key_with_root = (\n          config.get('name', ''), config.get('version', ''), actual_root)\n      self._config_manager.save_config(lookup_key_with_root, config)\n\n    return config_dict", "response": "Generate an API config with a specific root hostname."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending HTTP response containing the API directory.", "response": "def _list(self, request, start_response):\n    \"\"\"Sends HTTP response containing the API directory.\n\n    This calls start_response and returns the response body.\n\n    Args:\n      request: An ApiRequest, the transformed request sent to the Discovery API.\n      start_response: A function with semantics defined in PEP-333.\n\n    Returns:\n      A string containing the response body.\n    \"\"\"\n    configs = []\n    generator = directory_list_generator.DirectoryListGenerator(request)\n    for config in self._config_manager.configs.itervalues():\n      if config != self.API_CONFIG:\n        configs.append(config)\n    directory = generator.pretty_print_config_to_json(configs)\n    if not directory:\n      _logger.error('Failed to get API directory')\n      # By returning a 404, code explorer still works if you select the\n      # API in the URL\n      return util.send_wsgi_not_found_response(start_response)\n    return self._send_success_response(directory, start_response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling a discovery request.", "response": "def handle_discovery_request(self, path, request, start_response):\n    \"\"\"Returns the result of a discovery service request.\n\n    This calls start_response and returns the response body.\n\n    Args:\n      path: A string containing the API path (the portion of the path\n        after /_ah/api/).\n      request: An ApiRequest, the transformed request sent to the Discovery API.\n      start_response: A function with semantics defined in PEP-333.\n\n    Returns:\n      The response body.  Or returns False if the request wasn't handled by\n      DiscoveryService.\n    \"\"\"\n    if path == self._GET_REST_API:\n      return self._get_rest_doc(request, start_response)\n    elif path == self._GET_RPC_API:\n      error_msg = ('RPC format documents are no longer supported with the '\n                   'Endpoints Framework for Python. Please use the REST '\n                   'format.')\n      _logger.error('%s', error_msg)\n      return util.send_wsgi_error_response(error_msg, start_response)\n    elif path == self._LIST_API:\n      return self._list(request, start_response)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_req_body(self, body):\n    try:\n      return json.loads(body)\n    except ValueError:\n      return urlparse.parse_qs(body, keep_blank_values=True)", "response": "Process the HTTP request body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reconstruct_relative_url(self, environ):\n    url = urllib.quote(environ.get('SCRIPT_NAME', ''))\n    url += urllib.quote(environ.get('PATH_INFO', ''))\n    if environ.get('QUERY_STRING'):\n      url += '?' + environ['QUERY_STRING']\n    return url", "response": "Reconstruct the relative URL of this request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconstruct_hostname(self, port_override=None):\n    url = self.server\n    port = port_override or self.port\n    if port and ((self.url_scheme == 'https' and str(port) != '443') or\n                 (self.url_scheme != 'https' and str(port) != '80')):\n      url += ':{0}'.format(port)\n\n    return url", "response": "Reconstruct the hostname of a request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreconstructing the full URL of a request.", "response": "def reconstruct_full_url(self, port_override=None):\n    \"\"\"Reconstruct the full URL of a request.\n\n    This is based on the URL reconstruction code in Python PEP 333:\n    http://www.python.org/dev/peps/pep-0333/#url-reconstruction.  Rebuild the\n    hostname from the pieces available in the environment.\n\n    Args:\n      port_override: str, An override for the port on the returned full URL.\n\n    Returns:\n      The full URL from the request, including the URL scheme.\n    \"\"\"\n    return '{0}://{1}{2}'.format(self.url_scheme,\n                                  self.reconstruct_hostname(port_override),\n                                  self.relative_url)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_def_paths(self, prop_dict):\n    for prop_key, prop_value in prop_dict.iteritems():\n      if prop_key == '$ref' and not 'prop_value'.startswith('#'):\n        prop_dict[prop_key] = '#/definitions/' + prop_dict[prop_key]\n      elif isinstance(prop_value, dict):\n        self._add_def_paths(prop_value)", "response": "Recursive method to add relative paths for any $ref objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _construct_operation_id(self, service_name, protorpc_method_name):\n\n    # camelCase the ProtoRPC method name\n    method_name_camel = util.snake_case_to_headless_camel_case(\n        protorpc_method_name)\n\n    return '{0}_{1}'.format(service_name, method_name_camel)", "response": "Construct an operation id for a service method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the field variant type into a tuple describing the parameter type and format of the field.", "response": "def __field_to_parameter_type_and_format(self, field):\n    \"\"\"Converts the field variant type into a tuple describing the parameter.\n\n    Args:\n      field: An instance of a subclass of messages.Field.\n\n    Returns:\n      A tuple with the type and format of the field, respectively.\n\n    Raises:\n      TypeError: if the field variant is a message variant.\n    \"\"\"\n    # We use lowercase values for types (e.g. 'string' instead of 'STRING').\n    variant = field.variant\n    if variant == messages.Variant.MESSAGE:\n      raise TypeError('A message variant can\\'t be used in a parameter.')\n\n    # Note that the 64-bit integers are marked as strings -- this is to\n    # accommodate JavaScript, which would otherwise demote them to 32-bit\n    # integers.\n\n    custom_variant_map = {\n        messages.Variant.DOUBLE: ('number', 'double'),\n        messages.Variant.FLOAT: ('number', 'float'),\n        messages.Variant.INT64: ('string', 'int64'),\n        messages.Variant.SINT64: ('string', 'int64'),\n        messages.Variant.UINT64: ('string', 'uint64'),\n        messages.Variant.INT32: ('integer', 'int32'),\n        messages.Variant.SINT32: ('integer', 'int32'),\n        messages.Variant.UINT32: ('integer', 'uint32'),\n        messages.Variant.BOOL: ('boolean', None),\n        messages.Variant.STRING: ('string', None),\n        messages.Variant.BYTES: ('string', 'byte'),\n        messages.Variant.ENUM: ('string', None),\n    }\n    return custom_variant_map.get(variant) or (variant.name.lower(), None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning default value of the field if any exists.", "response": "def __parameter_default(self, field):\n    \"\"\"Returns default value of field if it has one.\n\n    Args:\n      field: A simple field.\n\n    Returns:\n      The default value of the field, if any exists, with the exception of an\n          enum field, which will have its value cast to a string.\n    \"\"\"\n    if field.default:\n      if isinstance(field, messages.EnumField):\n        return field.default.name\n      else:\n        return field.default"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __non_body_parameter_descriptor(self, param):\n    descriptor = {}\n\n    descriptor['name'] = param.name\n\n    param_type, param_format = self.__field_to_parameter_type_and_format(param)\n\n    # Required\n    if param.required:\n      descriptor['required'] = True\n\n    # Type\n    descriptor['type'] = param_type\n\n    # Format (optional)\n    if param_format:\n      descriptor['format'] = param_format\n\n    # Default\n    default = self.__parameter_default(param)\n    if default is not None:\n      descriptor['default'] = default\n\n    # Repeated\n    if param.repeated:\n      descriptor['repeated'] = True\n\n    # Enum\n    enum_descriptor = self.__parameter_enum(param)\n    if enum_descriptor is not None:\n      descriptor['enum'] = enum_descriptor\n\n    return descriptor", "response": "Creates a descriptor for a non - body parameter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __add_parameter(self, param, path_parameters, params):\n    # If this is a simple field, just build the descriptor and append it.\n    # Otherwise, build a schema and assign it to this descriptor\n    if not isinstance(param, messages.MessageField):\n      if param.name in path_parameters:\n        descriptor = self.__path_parameter_descriptor(param)\n      else:\n        descriptor = self.__query_parameter_descriptor(param)\n\n      params.append(descriptor)\n    else:\n      # If a subfield of a MessageField is found in the path, build a descriptor\n      # for the path parameter.\n      for subfield_list in self.__field_to_subfields(param):\n        qualified_name = '.'.join(subfield.name for subfield in subfield_list)\n        if qualified_name in path_parameters:\n          descriptor = self.__path_parameter_descriptor(subfield_list[-1])\n          descriptor['required'] = True\n\n          params.append(descriptor)", "response": "Adds a parameter to the method parameters descriptor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndescribes parameters of a method which does not use a ResourceContainer.", "response": "def __params_descriptor_without_container(self, message_type,\n                                            request_kind, method_id, path):\n    \"\"\"Describe parameters of a method which does not use a ResourceContainer.\n\n    Makes sure that the path parameters are included in the message definition\n    and adds any required fields and URL query parameters.\n\n    This method is to preserve backwards compatibility and will be removed in\n    a future release.\n\n    Args:\n      message_type: messages.Message class, Message with parameters to describe.\n      request_kind: The type of request being made.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n      path: string, HTTP path to method.\n\n    Returns:\n      A list of dicts: Descriptors of the parameters\n    \"\"\"\n    params = []\n\n    path_parameter_dict = self.__get_path_parameters(path)\n    for field in sorted(message_type.all_fields(), key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      self.__validate_path_parameters(field, matched_path_parameters)\n\n      if matched_path_parameters or request_kind == self.__NO_BODY:\n        self.__add_parameter(field, matched_path_parameters, params)\n\n    # If the request has a body, add the body parameter\n    if (message_type != message_types.VoidMessage() and\n        request_kind == self.__HAS_BODY):\n      params.append(self.__body_parameter_descriptor(method_id))\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __params_descriptor(self, message_type, request_kind, path, method_id):\n    path_parameter_dict = self.__get_path_parameters(path)\n\n    if not isinstance(message_type, resource_container.ResourceContainer):\n      if path_parameter_dict:\n        _logger.warning('Method %s specifies path parameters but you are not '\n                        'using a ResourceContainer; instead, you are using %r. '\n                        'This will fail in future releases; please switch to '\n                        'using ResourceContainer as soon as possible.',\n                        method_id, type(message_type))\n      return self.__params_descriptor_without_container(\n          message_type, request_kind, method_id, path)\n\n    # From here, we can assume message_type is a ResourceContainer.\n    params = []\n\n    # Process body parameter, if any\n    if message_type.body_message_class != message_types.VoidMessage:\n      params.append(self.__body_parameter_descriptor(method_id))\n\n    # Process path/querystring parameters\n    params_message_type = message_type.parameters_message_class()\n\n    # Make sure all path parameters are covered.\n    for field_name, matched_path_parameters in path_parameter_dict.iteritems():\n      field = params_message_type.field_by_name(field_name)\n      self.__validate_path_parameters(field, matched_path_parameters)\n\n    # Add all fields, sort by field.number since we have parameterOrder.\n    for field in sorted(params_message_type.all_fields(),\n                        key=lambda f: f.number):\n      matched_path_parameters = path_parameter_dict.get(field.name, [])\n      self.__add_parameter(field, matched_path_parameters, params)\n\n    return params", "response": "Describe the parameters of a method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndescribe the parameters and body of the request.", "response": "def __request_message_descriptor(self, request_kind, message_type, method_id,\n                                   path):\n    \"\"\"Describes the parameters and body of the request.\n\n    Args:\n      request_kind: The type of request being made.\n      message_type: messages.Message or ResourceContainer class. The message to\n          describe.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n      path: string, HTTP path to method.\n\n    Returns:\n      Dictionary describing the request.\n\n    Raises:\n      ValueError: if the method path and request required fields do not match\n    \"\"\"\n    if isinstance(message_type, resource_container.ResourceContainer):\n      base_message_type = message_type.body_message_class()\n      if (request_kind == self.__NO_BODY and\n          base_message_type != message_types.VoidMessage()):\n        msg = ('Method %s specifies a body message in its ResourceContainer, but '\n               'is a HTTP method type that cannot accept a body.') % method_id\n        raise api_exceptions.ApiConfigurationError(msg)\n    else:\n      base_message_type = message_type\n\n    if (request_kind != self.__NO_BODY and\n        base_message_type != message_types.VoidMessage()):\n      self.__request_schema[method_id] = self.__parser.add_message(\n          base_message_type.__class__)\n\n    params = self.__params_descriptor(message_type, request_kind, path,\n                                      method_id)\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndescribe the definitions section of the OpenAPI spec.", "response": "def __definitions_descriptor(self):\n    \"\"\"Describes the definitions section of the OpenAPI spec.\n\n    Returns:\n      Dictionary describing the definitions of the spec.\n    \"\"\"\n    # Filter out any keys that aren't 'properties' or 'type'\n    result = {}\n    for def_key, def_value in self.__parser.schemas().iteritems():\n      if 'properties' in def_value or 'type' in def_value:\n        key_result = {}\n        required_keys = set()\n        if 'type' in def_value:\n          key_result['type'] = def_value['type']\n        if 'properties' in def_value:\n          for prop_key, prop_value in def_value['properties'].items():\n            if isinstance(prop_value, dict) and 'required' in prop_value:\n              required_keys.add(prop_key)\n              del prop_value['required']\n          key_result['properties'] = def_value['properties']\n        # Add in the required fields, if any\n        if required_keys:\n          key_result['required'] = sorted(required_keys)\n        result[def_key] = key_result\n\n    # Add 'type': 'object' to all object properties\n    # Also, recursively add relative path to all $ref values\n    for def_value in result.itervalues():\n      for prop_value in def_value.itervalues():\n        if isinstance(prop_value, dict):\n          if '$ref' in prop_value:\n            prop_value['type'] = 'object'\n          self._add_def_paths(prop_value)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndescribing the response. Args: message_type: messages.Message class, The message to describe. method_id: string, Unique method identifier (e.g. 'myapi.items.method') Returns: Dictionary describing the response.", "response": "def __response_message_descriptor(self, message_type, method_id):\n    \"\"\"Describes the response.\n\n    Args:\n      message_type: messages.Message class, The message to describe.\n      method_id: string, Unique method identifier (e.g. 'myapi.items.method')\n\n    Returns:\n      Dictionary describing the response.\n    \"\"\"\n\n    # Skeleton response descriptor, common to all response objects\n    descriptor = {'200': {'description': 'A successful response'}}\n\n    if message_type != message_types.VoidMessage():\n      self.__parser.add_message(message_type.__class__)\n      self.__response_schema[method_id] = self.__parser.ref_for_message_type(\n          message_type.__class__)\n      descriptor['200']['schema'] = {'$ref': '#/definitions/{0}'.format(\n          self.__response_schema[method_id])}\n\n    return dict(descriptor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndescribes the metric costs for a call.", "response": "def __x_google_quota_descriptor(self, metric_costs):\n    \"\"\"Describes the metric costs for a call.\n\n    Args:\n      metric_costs: Dict of metric definitions to the integer cost value against\n        that metric.\n\n    Returns:\n      A dict descriptor describing the Quota limits for the endpoint.\n    \"\"\"\n    return {\n        'metricCosts': {\n            metric: cost for (metric, cost) in metric_costs.items()\n        }\n    } if metric_costs else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __x_google_quota_definitions_descriptor(self, limit_definitions):\n    if not limit_definitions:\n      return None\n\n    definitions_list = [{\n        'name': ld.metric_name,\n        'metric': ld.metric_name,\n        'unit': '1/min/{project}',\n        'values': {'STANDARD': ld.default_limit},\n        'displayName': ld.display_name,\n    } for ld in limit_definitions]\n\n    metrics = [{\n        'name': ld.metric_name,\n        'valueType': 'INT64',\n        'metricKind': 'GAUGE',\n    } for ld in limit_definitions]\n\n    return {\n        'quota': {'limits': definitions_list},\n        'metrics': metrics,\n    }", "response": "Describes the quota limit definitions for an API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __method_descriptor(self, service, method_info, operation_id,\n                          protorpc_method_info, security_definitions):\n    \"\"\"Describes a method.\n\n    Args:\n      service: endpoints.Service, Implementation of the API as a service.\n      method_info: _MethodInfo, Configuration for the method.\n      operation_id: string, Operation ID of the method\n      protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC\n        description of the method.\n      security_definitions: list of dicts, security definitions for the API.\n\n    Returns:\n      Dictionary describing the method.\n    \"\"\"\n    descriptor = {}\n\n    request_message_type = (resource_container.ResourceContainer.\n                            get_request_message(protorpc_method_info.remote))\n    request_kind = self.__get_request_kind(method_info)\n    remote_method = protorpc_method_info.remote\n\n    path = method_info.get_path(service.api_info)\n\n    descriptor['parameters'] = self.__request_message_descriptor(\n        request_kind, request_message_type,\n        method_info.method_id(service.api_info),\n        path)\n    descriptor['responses'] = self.__response_message_descriptor(\n        remote_method.response_type(), method_info.method_id(service.api_info))\n    descriptor['operationId'] = operation_id\n\n    # Insert the auth audiences, if any\n    api_key_required = method_info.is_api_key_required(service.api_info)\n    if method_info.audiences is not None:\n      descriptor['security'] = self.__security_descriptor(\n          method_info.audiences, security_definitions,\n          api_key_required=api_key_required)\n    elif service.api_info.audiences is not None or api_key_required:\n      descriptor['security'] = self.__security_descriptor(\n          service.api_info.audiences, security_definitions,\n          api_key_required=api_key_required)\n\n    # Insert the metric costs, if any\n    if method_info.metric_costs:\n      descriptor['x-google-quota'] = self.__x_google_quota_descriptor(\n          method_info.metric_costs)\n\n    return descriptor", "response": "Describes a method.\n\n    Args:\n      service: endpoints.Service, Implementation of the API as a service.\n      method_info: _MethodInfo, Configuration for the method.\n      operation_id: string, Operation ID of the method\n      protorpc_method_info: protorpc.remote._RemoteMethodInfo, ProtoRPC\n        description of the method.\n      security_definitions: list of dicts, security definitions for the API.\n\n    Returns:\n      Dictionary describing the method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a descriptor for the security definitions.", "response": "def __security_definitions_descriptor(self, issuers):\n    \"\"\"Create a descriptor for the security definitions.\n\n    Args:\n      issuers: dict, mapping issuer names to Issuer tuples\n\n    Returns:\n      The dict representing the security definitions descriptor.\n    \"\"\"\n    if not issuers:\n      result = {\n          _DEFAULT_SECURITY_DEFINITION: {\n              'authorizationUrl': '',\n              'flow': 'implicit',\n              'type': 'oauth2',\n              'x-google-issuer': 'https://accounts.google.com',\n              'x-google-jwks_uri': 'https://www.googleapis.com/oauth2/v3/certs',\n          }\n      }\n      return result\n\n    result = {}\n\n    for issuer_key, issuer_value in issuers.items():\n      result[issuer_key] = {\n          'authorizationUrl': '',\n          'flow': 'implicit',\n          'type': 'oauth2',\n          'x-google-issuer': issuer_value.issuer,\n      }\n\n      # If jwks_uri is omitted, the auth library will use OpenID discovery\n      # to find it. Otherwise, include it in the descriptor explicitly.\n      if issuer_value.jwks_uri:\n        result[issuer_key]['x-google-jwks_uri'] = issuer_value.jwks_uri\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding an OpenAPI description document for the given list of services.", "response": "def __api_openapi_descriptor(self, services, hostname=None, x_google_api_name=False):\n    \"\"\"Builds an OpenAPI description of an API.\n\n    Args:\n      services: List of protorpc.remote.Service instances implementing an\n        api/version.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      A dictionary that can be deserialized into JSON and stored as an API\n      description document in OpenAPI format.\n\n    Raises:\n      ApiConfigurationError: If there's something wrong with the API\n        configuration, such as a multiclass API decorated with different API\n        descriptors (see the docstring for api()), or a repeated method\n        signature.\n    \"\"\"\n    merged_api_info = self.__get_merged_api_info(services)\n    descriptor = self.get_descriptor_defaults(merged_api_info,\n                                              hostname=hostname,\n                                              x_google_api_name=x_google_api_name)\n\n    description = merged_api_info.description\n    if not description and len(services) == 1:\n      description = services[0].__doc__\n    if description:\n      descriptor['info']['description'] = description\n\n    security_definitions = self.__security_definitions_descriptor(\n        merged_api_info.issuers)\n\n    method_map = {}\n    method_collision_tracker = {}\n    rest_collision_tracker = {}\n\n    for service in services:\n      remote_methods = service.all_remote_methods()\n\n      for protorpc_meth_name in sorted(remote_methods.iterkeys()):\n        protorpc_meth_info = remote_methods[protorpc_meth_name]\n        method_info = getattr(protorpc_meth_info, 'method_info', None)\n        # Skip methods that are not decorated with @method\n        if method_info is None:\n          continue\n        method_id = method_info.method_id(service.api_info)\n        is_api_key_required = method_info.is_api_key_required(service.api_info)\n        path = '/{0}/{1}/{2}'.format(merged_api_info.name,\n                                     merged_api_info.path_version,\n                                     method_info.get_path(service.api_info))\n        verb = method_info.http_method.lower()\n\n        if path not in method_map:\n          method_map[path] = {}\n\n        # If an API key is required and the security definitions don't already\n        # have the apiKey issuer, add the appropriate notation now\n        if is_api_key_required and _API_KEY not in security_definitions:\n          security_definitions[_API_KEY] = {\n              'type': 'apiKey',\n              'name': _API_KEY_PARAM,\n              'in': 'query'\n          }\n\n        # Derive an OperationId from the method name data\n        operation_id = self._construct_operation_id(\n            service.__name__, protorpc_meth_name)\n\n        method_map[path][verb] = self.__method_descriptor(\n            service, method_info, operation_id, protorpc_meth_info,\n            security_definitions)\n\n        # Make sure the same method name isn't repeated.\n        if method_id in method_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              'Method %s used multiple times, in classes %s and %s' %\n              (method_id, method_collision_tracker[method_id],\n               service.__name__))\n        else:\n          method_collision_tracker[method_id] = service.__name__\n\n        # Make sure the same HTTP method & path aren't repeated.\n        rest_identifier = (method_info.http_method,\n                           method_info.get_path(service.api_info))\n        if rest_identifier in rest_collision_tracker:\n          raise api_exceptions.ApiConfigurationError(\n              '%s path \"%s\" used multiple times, in classes %s and %s' %\n              (method_info.http_method, method_info.get_path(service.api_info),\n               rest_collision_tracker[rest_identifier],\n               service.__name__))\n        else:\n          rest_collision_tracker[rest_identifier] = service.__name__\n\n    if method_map:\n      descriptor['paths'] = method_map\n\n    # Add request and/or response definitions, if any\n    definitions = self.__definitions_descriptor()\n    if definitions:\n      descriptor['definitions'] = definitions\n\n    descriptor['securityDefinitions'] = security_definitions\n\n    # Add quota limit metric definitions, if any\n    limit_definitions = self.__x_google_quota_definitions_descriptor(\n        merged_api_info.limit_definitions)\n    if limit_definitions:\n      descriptor['x-google-management'] = limit_definitions\n\n    return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary with the default configuration for a service.", "response": "def get_descriptor_defaults(self, api_info, hostname=None, x_google_api_name=False):\n    \"\"\"Gets a default configuration for a service.\n\n    Args:\n      api_info: _ApiInfo object for this service.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      A dictionary with the default configuration.\n    \"\"\"\n    hostname = (hostname or util.get_app_hostname() or\n                api_info.hostname)\n    protocol = 'http' if ((hostname and hostname.startswith('localhost')) or\n                          util.is_running_on_devserver()) else 'https'\n    base_path = api_info.base_path\n    if base_path != '/':\n        base_path = base_path.rstrip('/')\n    defaults = {\n        'swagger': '2.0',\n        'info': {\n            'version': api_info.api_version,\n            'title': api_info.name\n        },\n        'host': hostname,\n        'consumes': ['application/json'],\n        'produces': ['application/json'],\n        'schemes': [protocol],\n        'basePath': base_path,\n    }\n\n    if x_google_api_name:\n        defaults['x-google-api-name'] = _validate_api_name(api_info.name)\n\n    return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a JSON dict description of a protorpc. remote. Service in OpenAPI format.", "response": "def get_openapi_dict(self, services, hostname=None, x_google_api_name=False):\n    \"\"\"JSON dict description of a protorpc.remote.Service in OpenAPI format.\n\n    Args:\n      services: Either a single protorpc.remote.Service or a list of them\n        that implements an api/version.\n      hostname: string, Hostname of the API, to override the value set on the\n        current service. Defaults to None.\n\n    Returns:\n      dict, The OpenAPI descriptor document as a JSON dict.\n    \"\"\"\n\n    if not isinstance(services, (tuple, list)):\n      services = [services]\n\n    # The type of a class that inherits from remote.Service is actually\n    # remote._ServiceClass, thanks to metaclass strangeness.\n    # pylint: disable=protected-access\n    util.check_list_type(services, remote._ServiceClass, 'services',\n                         allow_none=False)\n\n    return self.__api_openapi_descriptor(services, hostname=hostname, x_google_api_name=x_google_api_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pretty_print_config_to_json(self, services, hostname=None, x_google_api_name=False):\n    descriptor = self.get_openapi_dict(services, hostname, x_google_api_name=x_google_api_name)\n    return json.dumps(descriptor, sort_keys=True, indent=2,\n                      separators=(',', ': '))", "response": "Pretty print a config object to JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_field(self, field, value):\n    # Override the handling of 64-bit integers, so they're always encoded\n    # as strings.\n    if (isinstance(field, messages.IntegerField) and\n        field.variant in (messages.Variant.INT64,\n                          messages.Variant.UINT64,\n                          messages.Variant.SINT64)):\n      if value not in (None, [], ()):\n        # Convert and replace the value.\n        if isinstance(value, list):\n          value = [str(subvalue) for subvalue in value]\n        else:\n          value = str(value)\n        return value\n\n    return super(EndpointsProtoJson, self).encode_field(field, value)", "response": "Encode a python value to a JSON value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds padding characters to the value if needed.", "response": "def __pad_value(value, pad_len_multiple, pad_char):\n    \"\"\"Add padding characters to the value if needed.\n\n    Args:\n      value: The string value to be padded.\n      pad_len_multiple: Pad the result so its length is a multiple\n          of pad_len_multiple.\n      pad_char: The character to use for padding.\n\n    Returns:\n      The string value with padding characters added.\n    \"\"\"\n    assert pad_len_multiple > 0\n    assert len(pad_char) == 1\n    padding_length = (pad_len_multiple -\n                      (len(value) % pad_len_multiple)) % pad_len_multiple\n    return value + pad_char * padding_length"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decode_field(self, field, value):\n    # Override BytesField handling.  Client libraries typically use a url-safe\n    # encoding.  b64decode doesn't handle these gracefully.  urlsafe_b64decode\n    # handles both cases safely.  Also add padding if the padding is incorrect.\n    if isinstance(field, messages.BytesField):\n      try:\n        # Need to call str(value) because ProtoRPC likes to pass values\n        # as unicode, and urlsafe_b64decode can only handle bytes.\n        padded_value = self.__pad_value(str(value), 4, '=')\n        return base64.urlsafe_b64decode(padded_value)\n      except (TypeError, UnicodeEncodeError), err:\n        raise messages.DecodeError('Base64 decoding error: %s' % err)\n\n    return super(EndpointsProtoJson, self).decode_field(field, value)", "response": "Decode a JSON value to a python value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new message to the schema tree.", "response": "def add_message(self, message_type):\n    \"\"\"Add a new message.\n\n    Args:\n      message_type: protorpc.message.Message class to be parsed.\n\n    Returns:\n      string, The JSON Schema id.\n\n    Raises:\n      KeyError if the Schema id for this message_type would collide with the\n      Schema id of a different message_type that was already added.\n    \"\"\"\n    name = self.__normalized_name(message_type)\n    if name not in self.__schemas:\n      # Set a placeholder to prevent infinite recursion.\n      self.__schemas[name] = None\n      schema = self.__message_to_schema(message_type)\n      self.__schemas[name] = schema\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the JSON Schema id for the given message type.", "response": "def ref_for_message_type(self, message_type):\n    \"\"\"Returns the JSON Schema id for the given message.\n\n    Args:\n      message_type: protorpc.message.Message class to be parsed.\n\n    Returns:\n      string, The JSON Schema id.\n\n    Raises:\n      KeyError: if the message hasn't been parsed via add_message().\n    \"\"\"\n    name = self.__normalized_name(message_type)\n    if name not in self.__schemas:\n      raise KeyError('Message has not been parsed: %s', name)\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a normalized schema name.", "response": "def __normalized_name(self, message_type):\n    \"\"\"Normalized schema name.\n\n    Generate a normalized schema name, taking the class name and stripping out\n    everything but alphanumerics, and camel casing the remaining words.\n    A normalized schema name is a name that matches [a-zA-Z][a-zA-Z0-9]*\n\n    Args:\n      message_type: protorpc.message.Message class being parsed.\n\n    Returns:\n      A string, the normalized schema name.\n\n    Raises:\n      KeyError: A collision was found between normalized names.\n    \"\"\"\n    # Normalization is applied to match the constraints that Discovery applies\n    # to Schema names.\n    name = message_type.definition_name()\n\n    split_name = re.split(r'[^0-9a-zA-Z]', name)\n    normalized = ''.join(\n        part[0].upper() + part[1:] for part in split_name if part)\n\n    previous = self.__normalized_names.get(normalized)\n    if previous:\n      if previous != name:\n        raise KeyError('Both %s and %s normalize to the same schema name: %s' %\n                       (name, previous, normalized))\n    else:\n      self.__normalized_names[normalized] = name\n\n    return normalized"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __message_to_schema(self, message_type):\n    name = self.__normalized_name(message_type)\n    schema = {\n        'id': name,\n        'type': 'object',\n        }\n    if message_type.__doc__:\n      schema['description'] = message_type.__doc__\n    properties = {}\n    for field in message_type.all_fields():\n      descriptor = {}\n      # Info about the type of this field.  This is either merged with\n      # the descriptor or it's placed within the descriptor's 'items'\n      # property, depending on whether this is a repeated field or not.\n      type_info = {}\n\n      if type(field) == messages.MessageField:\n        field_type = field.type().__class__\n        type_info['$ref'] = self.add_message(field_type)\n        if field_type.__doc__:\n          descriptor['description'] = field_type.__doc__\n      else:\n        schema_type = self.__FIELD_TO_SCHEMA_TYPE_MAP.get(\n            type(field), self.__DEFAULT_SCHEMA_TYPE)\n        # If the map pointed to a dictionary, check if the field's variant\n        # is in that dictionary and use the type specified there.\n        if isinstance(schema_type, dict):\n          variant_map = schema_type\n          variant = getattr(field, 'variant', None)\n          if variant in variant_map:\n            schema_type = variant_map[variant]\n          else:\n            # The variant map needs to specify a default value, mapped by None.\n            schema_type = variant_map[None]\n        type_info['type'] = schema_type[0]\n        if schema_type[1]:\n          type_info['format'] = schema_type[1]\n\n      if type(field) == messages.EnumField:\n        sorted_enums = sorted([enum_info for enum_info in field.type],\n                              key=lambda enum_info: enum_info.number)\n        type_info['enum'] = [enum_info.name for enum_info in sorted_enums]\n\n      if field.required:\n        descriptor['required'] = True\n\n      if field.default:\n        if type(field) == messages.EnumField:\n          descriptor['default'] = str(field.default)\n        else:\n          descriptor['default'] = field.default\n\n      if field.repeated:\n        descriptor['items'] = type_info\n        descriptor['type'] = 'array'\n      else:\n        descriptor.update(type_info)\n\n      properties[field.name] = descriptor\n\n    schema['properties'] = properties\n\n    return schema", "response": "Parse a single message into a JSON Schema."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_enum(parameter_name, value, parameter_config):\n  enum_values = [enum['backendValue']\n                 for enum in parameter_config['enum'].values()\n                 if 'backendValue' in enum]\n  if value not in enum_values:\n    raise errors.EnumRejectionError(parameter_name, value, enum_values)", "response": "Checks if the given value is valid for an enum parameter."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_boolean(parameter_name, value, parameter_config):\n  if parameter_config.get('type') != 'boolean':\n    return\n\n  if value.lower() not in ('1', 'true', '0', 'false'):\n    raise errors.BasicTypeParameterError(parameter_name, value, 'boolean')", "response": "Checks if a given value is a valid boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_parameter_conversion_entry(parameter_config):\n  entry = _PARAM_CONVERSION_MAP.get(parameter_config.get('type'))\n\n  # Special handling for enum parameters.  An enum's type is 'string', so we\n  # need to detect them by the presence of an 'enum' property in their\n  # configuration.\n  if entry is None and 'enum' in parameter_config:\n    entry = _PARAM_CONVERSION_MAP['enum']\n\n  return entry", "response": "Get information needed to convert the given parameter to its API type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform_parameter_value(parameter_name, value, parameter_config):\n  if isinstance(value, list):\n    # We're only expecting to handle path and query string parameters here.\n    # The way path and query string parameters are passed in, they'll likely\n    # only be single values or singly-nested lists (no lists nested within\n    # lists).  But even if there are nested lists, we'd want to preserve that\n    # structure.  These recursive calls should preserve it and convert all\n    # parameter values.  See the docstring for information about the parameter\n    # renaming done here.\n    return [transform_parameter_value('%s[%d]' % (parameter_name, index),\n                                      element, parameter_config)\n            for index, element in enumerate(value)]\n\n  # Validate and convert the parameter value.\n  entry = _get_parameter_conversion_entry(parameter_config)\n  if entry:\n    validation_func, conversion_func, type_name = entry\n    if validation_func:\n      validation_func(parameter_name, value, parameter_config)\n    if conversion_func:\n      try:\n        return conversion_func(value)\n      except ValueError:\n        raise errors.BasicTypeParameterError(parameter_name, value, type_name)\n\n  return value", "response": "Validates and transforms the parameter value to the type expected by the API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort_dependencies(app_list):\n    # Process the list of models, and get the list of dependencies\n    model_dependencies = []\n    models = set()\n    for app_config, model_list in app_list:\n        if model_list is None:\n            model_list = app_config.get_models()\n\n        for model in model_list:\n            models.add(model)\n            # Add any explicitly defined dependencies\n            if hasattr(model, 'natural_key'):\n                deps = getattr(model.natural_key, 'dependencies', [])\n                if deps:\n                    deps = [apps.get_model(dep) for dep in deps]\n            else:\n                deps = []\n\n            # Now add a dependency for any FK or M2M relation with\n            # a model that defines a natural key\n            for field in model._meta.fields:\n                if hasattr(field.rel, 'to'):\n                    rel_model = field.rel.to\n                    if hasattr(rel_model, 'natural_key') and rel_model != model:\n                        deps.append(rel_model)\n            for field in model._meta.many_to_many:\n                rel_model = field.rel.to\n                if hasattr(rel_model, 'natural_key') and rel_model != model:\n                    deps.append(rel_model)\n            model_dependencies.append((model, deps))\n\n    model_dependencies.reverse()\n    # Now sort the models to ensure that dependencies are met. This\n    # is done by repeatedly iterating over the input list of models.\n    # If all the dependencies of a given model are in the final list,\n    # that model is promoted to the end of the final list. This process\n    # continues until the input list is empty, or we do a full iteration\n    # over the input models without promoting a model to the final list.\n    # If we do a full iteration without a promotion, that means there are\n    # circular dependencies in the list.\n    model_list = []\n    while model_dependencies:\n        skipped = []\n        changed = False\n        while model_dependencies:\n            model, deps = model_dependencies.pop()\n\n            # If all of the models in the dependency list are either already\n            # on the final model list, or not on the original serialization list,\n            # then we've found another model with all it's dependencies satisfied.\n            found = True\n            for candidate in ((d not in models or d in model_list) for d in deps):\n                if not candidate:\n                    found = False\n            if found:\n                model_list.append(model)\n                changed = True\n            else:\n                skipped.append((model, deps))\n        if not changed:\n            raise CommandError(\"Can't resolve dependencies for %s in serialized app list.\" %\n                ', '.join('%s.%s' % (model._meta.app_label, model._meta.object_name)\n                for model, deps in sorted(skipped, key=lambda obj: obj[0].__name__))\n            )\n        model_dependencies = skipped\n\n    return model_list", "response": "Sort a list of models into a single list of models."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_items(self, items):\n        '''perform filtering items by specific criteria'''\n        items = self._filter_active(items)\n        items = self._filter_in_nav(items)\n        return items", "response": "perform filtering items by specific criteria"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_formset(self):\n        if self.folder:\n            queryset = self.folder.files.all()\n        else:\n            queryset = File.objects.none()\n        if self._formset is None:\n            self._formset = self.formset_class(\n                self.request.POST or None,\n                initial=self._get_formset_data(),\n                prefix=self._meta.name,\n                queryset=queryset)\n        return self._formset", "response": "Provide the formset corresponding to this DataTable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_file(self, file_obj, folder):\n        created = False\n        for cls in MEDIA_MODELS:\n            if cls.matches_file_type(file_obj.name):\n\n                obj, created = cls.objects.get_or_create(\n                    original_filename=file_obj.name,\n                    file=file_obj,\n                    folder=folder,\n                    is_public=FILER_IS_PUBLIC_DEFAULT)\n                if created:\n                    self.image_created += 1\n        if not created:\n            obj, created = File.objects.get_or_create(\n                original_filename=file_obj.name,\n                file=file_obj,\n                folder=folder,\n                is_public=FILER_IS_PUBLIC_DEFAULT)\n            if created:\n                self.file_created += 1\n        if self.verbosity >= 2:\n            print(\"file_created #%s / image_created #%s -- file : %s -- created : %s\" % (self.file_created,\n                                                                                         self.image_created,\n                                                                                         obj, created))\n        return obj", "response": "Create a File or Image into the given folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_leonardo_module(mod):\n\n    if hasattr(mod, 'default') \\\n            or hasattr(mod, 'leonardo_module_conf'):\n        return True\n    for key in dir(mod):\n        if 'LEONARDO' in key:\n            return True\n    return False", "response": "returns True if is leonardo module"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating a page into a specific language.", "response": "def _translate_page_into(page, language, default=None):\n    \"\"\"\n    Return the translation for a given page\n    \"\"\"\n    # Optimisation shortcut: No need to dive into translations if page already what we want\n    if page.language == language:\n        return page\n\n    translations = dict((t.language, t) for t in page.available_translations())\n    translations[page.language] = page\n\n    if language in translations:\n        return translations[language]\n    else:\n        if hasattr(default, '__call__'):\n            return default(page=page)\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feincms_breadcrumbs(page, include_self=True):\n\n    if not page or not isinstance(page, Page):\n        raise ValueError(\"feincms_breadcrumbs must be called with a valid Page object\")\n\n    ancs = page.get_ancestors()\n\n    bc = [(anc.get_absolute_url(), anc.short_title()) for anc in ancs]\n\n    if include_self:\n        bc.append((None, page.short_title()))\n\n    return {\"trail\": bc}", "response": "Generate a list of the page s ancestors suitable for use as breadcrumb navigation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining whether a given page is the parent of another page.", "response": "def is_parent_of(page1, page2):\n    \"\"\"\n    Determines whether a given page is the parent of another page\n\n    Example::\n\n        {% if page|is_parent_of:feincms_page %} ... {% endif %}\n    \"\"\"\n\n    try:\n        return page1.tree_id == page2.tree_id and page1.lft < page2.lft and page1.rght > page2.rght\n    except AttributeError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parent(self):\n        '''We use parent for some initial data'''\n\n        if not hasattr(self, '_parent'):\n\n            if 'parent' in self.kwargs:\n\n                try:\n                    self._parent = Page.objects.get(id=self.kwargs[\"parent\"])\n                except Exception as e:\n                    raise e\n            else:\n                if hasattr(self.request, 'leonardo_page'):\n                    self._parent = self.request.leonardo_page\n                else:\n                    return None\n\n        return self._parent", "response": "We use parent for some initial data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the head title of the page.", "response": "def head_title(request):\n    \"\"\"\n    {% head_title request %}\n    \"\"\"\n    try:\n        fragments = request._feincms_fragments\n    except:\n        fragments = {}\n\n    if '_head_title' in fragments and fragments.get(\"_head_title\"):\n        return fragments.get(\"_head_title\")\n    else:\n        # append site name\n        site_name = getattr(settings, 'LEONARDO_SITE_NAME', '')\n\n        if site_name != '':\n            return getattr(request.leonardo_page,\n                           \"page_title\", request.leonardo_page.title) \\\n                + ' | ' + site_name\n\n        return getattr(request.leonardo_page,\n                       \"page_title\", request.leonardo_page.title)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef meta_description(request):\n    try:\n        fragments = request._feincms_fragments\n    except:\n        fragments = {}\n\n    if '_meta_description' in fragments and fragments.get(\"_meta_description\"):\n        return fragments.get(\"_meta_description\")\n    else:\n        # append desc\n        site_desc = getattr(settings, 'META_DESCRIPTION', '')\n\n        if site_desc != '':\n            return getattr(request.leonardo_page,\n                           \"meta_description\", request.leonardo_page.meta_description) \\\n                + ' - ' + site_desc\n\n        return getattr(request.leonardo_page,\n                       \"meta_description\", request.leonardo_page.meta_description)", "response": "Return the meta_description of the current page."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders the region tools for a given feincms object.", "response": "def render_region_tools(context, feincms_object, region, request=None):\n    \"\"\"\n    {% render_region_tools feincms_page \"main\" request %}\n\n    skip rendering in standalone mode\n    \"\"\"\n\n    if context.get('standalone', False) or not feincms_object:\n        return {}\n\n    edit = False\n\n    if getattr(settings, 'LEONARDO_USE_PAGE_ADMIN', False):\n        request = context.get('request', None)\n        frontend_edit = request.COOKIES.get(\n            'frontend_editing', False)\n        if frontend_edit:\n            edit = True\n\n    return {\n        'edit': edit,\n        'feincms_object': feincms_object,\n        'region': region,\n        'region_name': get_page_region(region),\n        'widget_add_url': reverse_lazy(\n            'widget_create',\n            args=[feincms_object.id,\n                  region,\n                  '%s.%s' % (feincms_object._meta.app_label,\n                             feincms_object.__class__.__name__)\n                  ])\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a single region in the current context", "response": "def feincms_render_region(context, feincms_object, region, request=None,\n                          classes='', wrapper=True):\n    \"\"\"\n    {% feincms_render_region feincms_page \"main\" request %}\n\n    Support for rendering Page without some regions especialy for modals\n    this feature is driven by context variable\n    \"\"\"\n    if not feincms_object:\n        return ''\n\n    if not context.get('standalone', False) or region in STANDALONE_REGIONS:\n        region_content = ''.join(\n            _render_content(content, request=request, context=context)\n            for content in getattr(feincms_object.content, region))\n    else:\n        region_content = ''\n\n    if not wrapper:\n        return region_content\n\n    _classes = \"leonardo-region leonardo-region-%(region)s %(classes)s\" % {\n        'region': region,\n        'classes': classes\n    }\n\n    _id = \"%(region)s-%(id)s\" % {\n        'id': feincms_object.id,\n        'region': region,\n    }\n\n    return '<div class=\"%(classes)s\" id=%(id)s>%(content)s</div>' % {\n        'id': _id,\n        'classes': _classes,\n        'content': region_content\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef app_reverse(parser, token):\n    bits = token.split_contents()\n    if len(bits) < 3:\n        raise TemplateSyntaxError(\n            \"'%s' takes at least two arguments\"\n            \" (path to a view and a urlconf)\" % bits[0])\n    viewname = parser.compile_filter(bits[1])\n    urlconf = parser.compile_filter(bits[2])\n    args = []\n    kwargs = {}\n    asvar = None\n    bits = bits[3:]\n    if len(bits) >= 2 and bits[-2] == 'as':\n        asvar = bits[-1]\n        bits = bits[:-2]\n\n    if len(bits):\n        for bit in bits:\n            match = kwarg_re.match(bit)\n            if not match:\n                raise TemplateSyntaxError(\n                    \"Malformed arguments to app_reverse tag\")\n            name, value = match.groups()\n            if name:\n                kwargs[name] = parser.compile_filter(value)\n            else:\n                args.append(parser.compile_filter(value))\n\n    return AppReverseNode(viewname, urlconf, args, kwargs, asvar)", "response": "Returns an absolute URL for applications integrated with ApplicationContent."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feincms_object_tools(context, cls_name):\n    if context.get('standalone', False):\n        return {}\n    edit = False\n    if getattr(settings, 'LEONARDO_USE_PAGE_ADMIN', False):\n        request = context.get('request', None)\n        frontend_edit = request.COOKIES.get(\n            'frontend_editing', False)\n        if frontend_edit:\n            edit = True\n\n    return {\n        'edit': edit,\n        'add_entry_url': reverse_lazy(\n            'horizon:contrib:forms:create',\n            args=[cls_name])\n    }", "response": "Return a dictionary of feincms object tools."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef image_name(image, key='name', clear=True):\n    if hasattr(image, 'translation') and image.translation:\n        return getattr(image.translation, key)\n\n    if hasattr(image, key) and getattr(image, key):\n        return getattr(image, key)\n\n    try:\n        name = IMAGE_NAME.match(image.original_filename).group()\n    except IndexError:\n        return ''\n    else:\n        name = name[:-1]\n        if clear:\n            return name.replace(\"_\", \" \").replace(\"-\", \" \")\n        return name", "response": "Return the name of an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tree_label(self):\n        '''render tree label like as `root > child > child`'''\n        titles = []\n        page = self\n        while page:\n            titles.append(page.title)\n            page = page.parent\n        return smart_text(' > '.join(reversed(titles)))", "response": "render tree label like as root > child > child"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flush_ct_inventory(self):\n        if hasattr(self, '_ct_inventory'):\n\n            # skip self from update\n            self._ct_inventory = None\n            self.update_view = False\n            self.save()", "response": "internal method used only if ct_inventory is enabled"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_default_processors(cls, frontend_editing=None):\n        super(Page, cls).register_default_processors()\n\n        if frontend_editing:\n            cls.register_request_processor(\n                edit_processors.frontendediting_request_processor,\n                key='frontend_editing')\n            cls.register_response_processor(\n                edit_processors.frontendediting_response_processor,\n                key='frontend_editing')", "response": "Register our default request and response processors for the out - of - the - box page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_request_processors(self, request):\n        if not getattr(self, 'request_processors', None):\n            return\n\n        for fn in reversed(list(self.request_processors.values())):\n            r = fn(self, request)\n            if r:\n                return r", "response": "Runs all request processors for the current page and returns a HttpResponse object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a technical 404 error response. The exception should be the Http404.", "response": "def technical_404_response(request, exception):\n    \"Create a technical 404 error response. The exception should be the Http404.\"\n    try:\n        error_url = exception.args[0]['path']\n    except (IndexError, TypeError, KeyError):\n        error_url = request.path_info[1:]  # Trim leading slash\n\n    try:\n        tried = exception.args[0]['tried']\n    except (IndexError, TypeError, KeyError):\n        tried = []\n    else:\n        if (not tried                           # empty URLconf\n            or (request.path == '/'\n                and len(tried) == 1             # default URLconf\n                and len(tried[0]) == 1\n                and getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin')):\n            return default_urlconf(request)\n\n    urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n    if isinstance(urlconf, types.ModuleType):\n        urlconf = urlconf.__name__\n\n    caller = ''\n    try:\n        resolver_match = resolve(request.path)\n    except Resolver404:\n        pass\n    else:\n        obj = resolver_match.func\n\n        if hasattr(obj, '__name__'):\n            caller = obj.__name__\n        elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n            caller = obj.__class__.__name__\n\n        if hasattr(obj, '__module__'):\n            module = obj.__module__\n            caller = '%s.%s' % (module, caller)\n\n    feincms_page = slug = template = None\n\n    try:\n        from leonardo.module.web.models import Page\n        feincms_page = Page.objects.for_request(request, best_match=True)\n        template = feincms_page.theme.template\n    except:\n        if Page.objects.exists():\n            feincms_page = Page.objects.filter(parent=None).first()\n            template = feincms_page.theme.template\n    else:\n        # nested path is not allowed for this time\n        try:\n            slug = request.path_info.split(\"/\")[-2:-1][0]\n        except KeyError:\n            raise Exception(\"Nested path is not allowed !\")\n\n    c = RequestContext(request, {\n        'urlconf': urlconf,\n        'root_urlconf': settings.ROOT_URLCONF,\n        'request_path': error_url,\n        'urlpatterns': tried,\n        'reason': force_bytes(exception, errors='replace'),\n        'request': request,\n        'settings': get_safe_settings(),\n        'raising_view_name': caller,\n        'feincms_page': feincms_page,\n        'template': template or 'base.html',\n        'standalone': True,\n        'slug': slug,\n    })\n\n    try:\n        t = render_to_string('404_technical.html', c)\n    except:\n        from django.views.debug import TECHNICAL_404_TEMPLATE\n        t = Template(TECHNICAL_404_TEMPLATE).render(c)\n    return HttpResponseNotFound(t, content_type='text/html')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response_change(self, request, obj):\n        r = super(FileAdmin, self).response_change(request, obj)\n        if 'Location' in r and r['Location']:\n            # it was a successful save\n            if (r['Location'] in ['../'] or\n                    r['Location'] == self._get_post_url(obj)):\n                # this means it was a save: redirect to the directory view\n                if obj.folder:\n                    url = reverse('admin:filer-directory_listing',\n                                  kwargs={'folder_id': obj.folder.id})\n                else:\n                    url = reverse(\n                        'admin:filer-directory_listing-unfiled_images')\n                url = \"%s%s%s\" % (url, popup_param(request),\n                                  selectfolder_param(request, \"&\"))\n                return HttpResponseRedirect(url)\n            else:\n                # this means it probably was a save_and_continue_editing\n                pass\n        else:\n            # this means it was a save: redirect to the directory view\n            if obj.folder:\n                url = reverse('admin:filer-directory_listing',\n                              kwargs={'folder_id': obj.folder.id})\n            else:\n                url = reverse(\n                    'admin:filer-directory_listing-unfiled_images')\n            url = \"%s%s%s\" % (url, popup_param(request),\n                              selectfolder_param(request, \"&\"))\n            return HttpResponseRedirect(url)\n\n        return r", "response": "Override the default response_change method to redirect to the directory listing if the user is not able to continue editing the file listing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_view(self, request, object_id, extra_context=None):\n        parent_folder = None\n        try:\n            obj = self.get_queryset(request).get(pk=unquote(object_id))\n            parent_folder = obj.folder\n        except self.model.DoesNotExist:\n            obj = None\n\n        r = super(FileAdmin, self).delete_view(\n            request=request, object_id=object_id,\n            extra_context=extra_context)\n\n        url = r.get(\"Location\", None)\n\n        # Check against filer_file_changelist as file deletion is always made by\n        # the base class\n        if (url in [\"../../../../\", \"../../\"] or\n                url == reverse(\"admin:media_file_changelist\") or\n                url == reverse(\"admin:media_image_changelist\")):\n            if parent_folder:\n                url = reverse('admin:filer-directory_listing',\n                              kwargs={'folder_id': parent_folder.id})\n            else:\n                url = reverse('admin:filer-directory_listing-unfiled_images')\n            url = \"%s%s%s\" % (url, popup_param(request),\n                              selectfolder_param(request, \"&\"))\n            return HttpResponseRedirect(url)\n        return r", "response": "Override the default delete_view to allow redirecting to the directory view after deletion of an image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naccessing for filtered items", "response": "def items(self):\n        '''access for filtered items'''\n        if hasattr(self, '_items'):\n            return self.filter_items(self._items)\n        self._items = self.get_items()\n        return self.filter_items(self._items)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating and returns filtered items", "response": "def populate_items(self, request):\n        '''populate and returns filtered items'''\n        self._items = self.get_items(request)\n        return self.items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning rows with items", "response": "def get_rows(self):\n        '''returns rows with items\n        [[item1 item2], [item3 item4], [item5]]'''\n        rows = []\n        row = []\n        for i, item in enumerate(self.items):\n            if i > 0 and i % self.objects_per_row == 0:\n                rows.append(row)\n                row = []\n            row.append(item)\n        rows.append(row)\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn pages with rows", "response": "def get_pages(self):\n        '''returns pages with rows'''\n        pages = []\n        page = []\n        for i, item in enumerate(self.get_rows):\n            if i > 0 and i % self.objects_per_page == 0:\n                pages.append(page)\n                page = []\n            page.append(item)\n        pages.append(page)\n        return pages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_item_template(self):\n        '''returns template for signle object from queryset\n        If you have a template name my_list_template.html\n        then template for a single object will be\n        _my_list_template.html\n\n        Now only for default generates _item.html\n        _item.html is obsolete use _default.html\n        '''\n        content_template = self.content_theme.name\n\n        # _item.html is obsolete use _default.html\n        # TODO: remove this condition after all _item.html will be converted\n        if content_template == \"default\":\n            return \"widget/%s/_item.html\" % self.widget_name\n\n        # TODO: support more template suffixes\n        return \"widget/%s/_%s.html\" % (self.widget_name, content_template)", "response": "returns template for signle object from queryset\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_obsolete(self):\n        if self.cache_updated:\n            now = timezone.now()\n            delta = now - self.cache_updated\n            if delta.seconds < self.cache_validity:\n                return False\n        return True", "response": "returns True is data is obsolete and needs revalidation\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall with new data or set data to self. cache_data and call this", "response": "def update_cache(self, data=None):\n        \"\"\"call with new data or set data to self.cache_data and call this\n        \"\"\"\n        if data:\n            self.cache_data = data\n        self.cache_updated = timezone.now()\n        self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads and cache data in json format", "response": "def data(self):\n        \"\"\"load and cache data in json format\n        \"\"\"\n\n        if self.is_obsolete():\n            data = self.get_data()\n            for datum in data:\n                if 'published_parsed' in datum:\n                    datum['published_parsed'] = \\\n                        self.parse_time(datum['published_parsed'])\n\n            try:\n                dumped_data = json.dumps(data)\n            except:\n                self.update_cache(data)\n            else:\n                self.update_cache(dumped_data)\n                return data\n\n        try:\n            return json.loads(self.cache_data)\n        except:\n            return self.cache_data\n\n        return self.get_data()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads modules and order it by ordering key", "response": "def get_loaded_modules(modules):\n    '''load modules and order it by ordering key'''\n\n    _modules = []\n    for mod in modules:\n        mod_cfg = get_conf_from_module(mod)\n\n        _modules.append((mod, mod_cfg,))\n\n    _modules = sorted(_modules, key=lambda m: m[1].get('ordering'))\n\n    return _modules"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge two lists of items", "response": "def merge(a, b):\n    \"\"\"return merged tuples or lists without duplicates\n    note: ensure if admin theme is before admin\n    \"\"\"\n    if isinstance(a, CONFIG_VALID) \\\n            and isinstance(b, CONFIG_VALID):\n        # dict update\n        if isinstance(a, dict) and isinstance(b, dict):\n            a.update(b)\n            return a\n        # list update\n        _a = list(a)\n        for x in list(b):\n            if x not in _a:\n                _a.append(x)\n        return _a\n    if a and b:\n        raise Exception(\"Cannot merge\")\n    raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if is leonardo module", "response": "def _is_leonardo_module(whatever):\n    '''check if is leonardo module'''\n\n    # check if is python module\n    if hasattr(whatever, 'default') \\\n            or hasattr(whatever, 'leonardo_module_conf'):\n        return True\n\n    # check if is python object\n    for key in dir(whatever):\n        if 'LEONARDO' in key:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_conf_from(mod, conf=ModuleConfig(CONF_SPEC), depth=0, max_depth=2):\n\n    # extract config keys from module or object\n    for key, default_value in six.iteritems(conf):\n        conf[key] = _get_key_from_module(mod, key, default_value)\n\n    # support for recursive dependecies\n    try:\n        filtered_apps = [app for app in conf['apps'] if app not in BLACKLIST]\n    except TypeError:\n        pass\n    except Exception as e:\n        warnings.warn('Error %s during loading %s' % (e, conf['apps']))\n\n    for app in filtered_apps:\n        try:\n            app_module = import_module(app)\n            if app_module != mod:\n                app_module = _get_correct_module(app_module)\n                if depth < max_depth:\n                    mod_conf = extract_conf_from(app_module, depth=depth+1)\n                    for k, v in six.iteritems(mod_conf):\n                        # prevent config duplicity\n                        # skip config merge\n                        if k == 'config':\n                            continue\n                        if isinstance(v, dict):\n                            conf[k].update(v)\n                        elif isinstance(v, (list, tuple)):\n                            conf[k] = merge(conf[k], v)\n        except Exception as e:\n            pass  # swallow, but maybe log for info what happens\n    return conf", "response": "recursively extract keys from module or object\n    by passed config scheme"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning imported module check if is leonardo module_conf specified and then import them check if is leonardo config compliant and then import them", "response": "def _get_correct_module(mod):\n    \"\"\"returns imported module\n    check if is ``leonardo_module_conf`` specified and then import them\n    \"\"\"\n\n    module_location = getattr(\n        mod, 'leonardo_module_conf',\n        getattr(mod, \"LEONARDO_MODULE_CONF\", None))\n    if module_location:\n        mod = import_module(module_location)\n\n    elif hasattr(mod, 'default_app_config'):\n        # use django behavior\n        mod_path, _, cls_name = mod.default_app_config.rpartition('.')\n        _mod = import_module(mod_path)\n        config_class = getattr(_mod, cls_name)\n        # check if is leonardo config compliant\n        if _is_leonardo_module(config_class):\n            mod = config_class\n\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns configuration from module with defaults no worry about None type", "response": "def get_conf_from_module(mod):\n    \"\"\"return configuration from module with defaults no worry about None type\n\n    \"\"\"\n\n    conf = ModuleConfig(CONF_SPEC)\n\n    # get imported module\n    mod = _get_correct_module(mod)\n\n    conf.set_module(mod)\n\n    # extarct from default object or from module\n    if hasattr(mod, 'default'):\n        default = mod.default\n        conf = extract_conf_from(default, conf)\n    else:\n        conf = extract_conf_from(mod, conf)\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef webfont_cookie(request):\n    '''Adds WEBFONT Flag to the context'''\n\n    if hasattr(request, 'COOKIES') and request.COOKIES.get(WEBFONT_COOKIE_NAME, None):\n\n        return {\n            WEBFONT_COOKIE_NAME.upper(): True\n        }\n\n    return {\n        WEBFONT_COOKIE_NAME.upper(): False\n    }", "response": "Adds WEBFONT Flag to the context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a message with the DEBUG level.", "response": "def debug(request, message, extra_tags='', fail_silently=False, async=False):\n    \"\"\"Adds a message with the ``DEBUG`` level.\"\"\"\n    if ASYNC and async:\n        messages.debug(_get_user(request), message)\n    else:\n        add_message(request, constants.DEBUG, message, extra_tags=extra_tags,\n                    fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info(request, message, extra_tags='', fail_silently=False, async=False):\n    if ASYNC and async:\n        messages.info(_get_user(request), message)\n    else:\n        add_message(request, constants.INFO, message, extra_tags=extra_tags,\n                    fail_silently=fail_silently)", "response": "Adds a message with the INFO level."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a message with the SUCCESS level.", "response": "def success(request, message, extra_tags='', fail_silently=False, async=False):\n    \"\"\"Adds a message with the ``SUCCESS`` level.\"\"\"\n    if ASYNC and async:\n        messages.success(_get_user(request), message)\n    else:\n        add_message(request, constants.SUCCESS, message, extra_tags=extra_tags,\n                    fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a message with the WARNING level.", "response": "def warning(request, message, extra_tags='', fail_silently=False, async=False):\n    \"\"\"Adds a message with the ``WARNING`` level.\"\"\"\n    if ASYNC and async:\n        messages.debug(_get_user(request), message)\n    else:\n        add_message(request, constants.WARNING, message, extra_tags=extra_tags,\n                    fail_silently=fail_silently)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error(request, message, extra_tags='', fail_silently=False, async=False):\n    if ASYNC and async:\n        messages.debug(_get_user(request), message)\n    else:\n        add_message(request, constants.ERROR, message, extra_tags=extra_tags,\n                    fail_silently=fail_silently)", "response": "Adds a message with the ERROR level."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning collected Leonardo Widgets if not declared in settings is used __subclasses__ which does not support widget subclassing", "response": "def get_all_widget_classes():\n    \"\"\"returns collected Leonardo Widgets\n\n    if not declared in settings is used __subclasses__\n    which not supports widget subclassing\n\n    \"\"\"\n    from leonardo.module.web.models import Widget\n    _widgets = getattr(settings,\n                       'WIDGETS', Widget.__subclasses__())\n    widgets = []\n    if isinstance(_widgets, dict):\n        for group, widget_cls in six.iteritems(_widgets):\n            widgets.extend(widget_cls)\n    elif isinstance(_widgets, list):\n        widgets = _widgets\n    return load_widget_classes(widgets)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn tuple of choices grouped ungrouped and ungrouped content types", "response": "def get_grouped_widgets(feincms_object, request=None):\n    '''returns tuple(choices, grouped, ungrouped)\n\n    requires feincms_object for getting content types\n\n    request optionaly for checking permissions, but not required\n\n    grouped = {'web': (id, label, icon)}\n    '''\n\n    grouped = {}\n    ungrouped = []\n    choices = []\n\n    for ct in feincms_object._feincms_content_types:\n        # Skip cts that we shouldn't be adding anyway\n        opts = ct._meta\n        # check permissions\n        if request and request.user:\n            from django.contrib.auth import get_permission_codename\n            perm = opts.app_label + \".\" + \\\n                get_permission_codename('add', opts)\n            if not request.user.has_perm(perm):\n                continue\n\n        ct_info = ('.'.join([ct._meta.app_label,\n                             ct.__name__.lower()]),\n                   ct._meta.verbose_name,\n                   ct.get_widget_icon)\n        if hasattr(ct, 'optgroup'):\n            if ct.optgroup in grouped:\n                grouped[ct.optgroup].append(ct_info)\n            else:\n                grouped[ct.optgroup] = [ct_info]\n        else:\n            ungrouped.append(ct_info)\n        choices.append(ct_info)\n\n    return choices, grouped, ungrouped"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_region(widget=None, request=None, view=None,\n                  page=None, region=None):\n    \"\"\"returns rendered content\n    this is not too clear and little tricky,\n    because external apps needs calling process method\n    \"\"\"\n\n    # change the request\n    if not isinstance(request, dict):\n        request.query_string = None\n        request.method = \"GET\"\n\n    if not hasattr(request, '_feincms_extra_context'):\n        request._feincms_extra_context = {}\n\n    leonardo_page = widget.parent if widget else page\n    render_region = widget.region if widget else region\n\n    # call processors\n    for fn in reversed(list(leonardo_page.request_processors.values())):\n        try:\n            r = fn(leonardo_page, request)\n        except:\n            pass\n\n    contents = {}\n\n    for content in leonardo_page.content.all_of_type(tuple(\n            leonardo_page._feincms_content_types_with_process)):\n\n        try:\n            r = content.process(request, view=view)\n        except:\n            pass\n        else:\n            # this is HttpResponse object or string\n            if not isinstance(r, six.string_types):\n                r.render()\n                contents[content.fe_identifier] = getattr(r, 'content', r)\n            else:\n                contents[content.fe_identifier] = r\n\n    from leonardo.templatetags.leonardo_tags import _render_content\n\n    region_content = ''.join(\n        contents[content.fe_identifier] if content.fe_identifier in contents else _render_content(\n            content, request=request, context={})\n        for content in getattr(leonardo_page.content, render_region))\n\n    return region_content", "response": "returns rendered content for a given region"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles dimensions of widgets", "response": "def handle_dimensions(self, obj):\n        \"\"\"save dimensions\n        \"\"\"\n        from .tables import WidgetDimensionFormset\n        from ..models import WidgetDimension\n        formset = WidgetDimensionFormset(\n            self.request.POST, prefix='dimensions')\n\n        if formset.is_valid():\n            formset.save()\n        else:\n            for form in formset.forms:\n                if form.is_valid():\n                    if 'id' in form.cleaned_data:\n                        form.save()\n                else:\n                    # little ugly\n                    data = form.cleaned_data\n                    data['widget_type'] = \\\n                        ContentType.objects.get_for_model(obj)\n                    data['widget_id'] = obj.id\n                    data.pop('DELETE', None)\n                    wd = WidgetDimension(**data)\n                    # do not update widget view\n                    wd.update_view = False\n                    wd.save()\n\n        if formset.is_valid():\n            # delete objects\n            for obj in formset.deleted_objects:\n                if obj.id != None:\n                    obj.delete()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_form(self, form_class):\n        if not hasattr(self, '_form'):\n            kwargs = self.get_form_kwargs()\n            self._form = form_class(**kwargs)\n        return self._form", "response": "Returns an instance of the form to be used in this view."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_form(self, form_class):\n        kwargs = self.kwargs\n        kwargs.update(self.get_form_kwargs())\n        kwargs.update({\n            'request': self.request,\n            'next_view': WidgetCreateView\n        })\n        return form_class(**kwargs)", "response": "Returns an instance of the form to be used in this view."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_form(self, form_class):\n        if not hasattr(self, '_form'):\n            kwargs = self.get_form_kwargs()\n            self._form = form_class(instance=self.object, **kwargs)\n        return self._form", "response": "Returns an instance of the form to be used in this view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_edit_handler(self):\n        '''TODO: Fix add-to-field'''\n        # just a flag\n        self.generic = 'false'\n\n        return '''\n\n        <span class=\"input-group-btn\">\n            <a href=\"#\" id=\"item-edit-%(id)s\" data-add-to-field=\"id_file\" class=\"btn btn-default disabled\"><span class=\"fa fa-pencil\"></span></a></span>\n        <script>\n\n        if ($('*[data-add-item-url=\"%(url)s\"]').val()) {\n            $('#item-edit-%(id)s').removeClass('disabled');\n        }\n\n        $('*[data-add-item-url=\"%(url)s\"]').on('change', function (e) {\n            if ($('*[data-add-item-url=\"%(url)s\"]').val()) {\n                $('#item-edit-%(id)s').removeClass('disabled');\n            } else {\n                $('#item-edit-%(id)s').addClass('disabled');\n            }\n        });\n\n        $(\"#item-edit-%(id)s\").click(function() {\n\n            var generic = %(generic)s;\n            var ajax_opts = {};\n            var id = $('*[data-add-item-url=\"%(url)s\"]').val();\n\n            if (generic) {\n\n                ajax_opts = {\n                  url: \"/widget/js-reverse/\",\n                  method: 'POST',\n                  data: {\n                    viewname: '%(update_viewname)s',\n                    kwargs:  JSON.stringify({\n                        cls_name: '%(cls_name)s',\n                        id: id,\n                        form_cls: '%(form_cls)s'\n                        })\n                    }\n                };\n\n            } else {\n                ajax_opts = {\n                  url: \"/widget/js-reverse/\",\n                  method: 'POST',\n                  data: {\n                    viewname: '%(update_viewname)s',\n                    args: JSON.stringify({id: id})\n                    }\n                };\n            }\n            $.ajax(ajax_opts)\n              .done(function( data ) {\n\n                horizon.modals._request = $.ajax(data.url, {\n                  beforeSend: function () {\n                    horizon.modals.modal_spinner(gettext(\"Loading\"));\n                  },\n                  complete: function () {\n                    // Clear the global storage;\n                    horizon.modals._request = null;\n                    horizon.modals.spinner.modal('hide');\n                  },\n                  error: function(jqXHR, status, errorThrown) {\n                    if (jqXHR.status === 401){\n                      var redir_url = jqXHR.getResponseHeader(\"X-Horizon-Location\");\n                      if (redir_url){\n                        location.href = redir_url;\n                      } else {\n                        location.reload(true);\n                      }\n                    }\n                    else {\n                      if (!horizon.ajax.get_messages(jqXHR)) {\n                        // Generic error handler. Really generic.\n                        horizon.alert(\"danger\", gettext(\n                            \"An error occurred. Please try again later.\"));\n                      }\n                    }\n                  },\n                  success: function (data, textStatus, jqXHR) {\n                    var update_field_id = 'data-add-to-field',\n                      modal,\n                      form;\n                    modal = horizon.modals.success(\n                        data, textStatus, jqXHR);\n                    if (update_field_id) {\n                      form = modal.find(\"form\");\n                      if (form.length) {\n                        form.attr(\"data-add-to-field\", update_field_id);\n                      }\n                    }\n                  }\n                });\n              });\n        });\n        </script>\n        ''' % {'update_viewname': self.get_update_view_name(),\n               'cls_name': self.get_cls_name(),\n               'url': self.get_add_item_url(),\n               'form_cls': self.get_form_cls(),\n               'id': self.__hash__(),\n               'generic': self.generic}", "response": "Returns a handler for editing the item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_feincms_inlines(self, model, request):\n        model._needs_content_types()\n\n        inlines = []\n        for content_type in model._feincms_content_types:\n            if not self.can_add_content(request, content_type):\n                continue\n\n            attrs = {\n                '__module__': model.__module__,\n                'model': content_type,\n            }\n\n            if hasattr(content_type, 'feincms_item_editor_inline'):\n                inline = content_type.feincms_item_editor_inline\n                attrs['form'] = inline.form\n\n                #if hasattr(content_type, 'feincms_item_editor_form'):\n                #    warnings.warn(\n                #        'feincms_item_editor_form on %s is ignored because '\n                #        'feincms_item_editor_inline is set too' % content_type,\n                #        RuntimeWarning)\n\n            else:\n                inline = FeinCMSInline\n                attrs['form'] = getattr(\n                    content_type, 'feincms_item_editor_form', inline.form)\n\n            name = '%sFeinCMSInline' % content_type.__name__\n            # TODO: We generate a new class every time. Is that really wanted?\n            inline_class = type(str(name), (inline,), attrs)\n            inlines.append(inline_class)\n        return inlines", "response": "Generate genuine django inlines for registered content types."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies initial data from parent", "response": "def get_changeform_initial_data(self, request):\n        '''Copy initial data from parent'''\n        initial = super(PageAdmin, self).get_changeform_initial_data(request)\n        if ('translation_of' in request.GET):\n            original = self.model._tree_manager.get(\n                pk=request.GET.get('translation_of'))\n            initial['layout'] = original.layout\n            initial['theme'] = original.theme\n            initial['color_scheme'] = original.color_scheme\n\n            # optionaly translate title and make slug\n            old_lang = translation.get_language()\n            translation.activate(request.GET.get('language'))\n            title = _(original.title)\n            if title != original.title:\n                initial['title'] = title\n                initial['slug'] = slugify(title)\n            translation.activate(old_lang)\n\n        return initial"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling a package on PyPi. Accepts pip compatible package strings. Returns boolean if install successful.", "response": "def install_package(package, upgrade=True,\n                    target=None):\n    \"\"\"Install a package on PyPi. Accepts pip compatible package strings.\n\n    Return boolean if install successful.\n    \"\"\"\n    # Not using 'import pip; pip.main([])' because it breaks the logger\n    with INSTALL_LOCK:\n        if check_package_exists(package, target):\n            return True\n\n        _LOGGER.info('Attempting install of %s', package)\n        args = [sys.executable, '-m', 'pip', 'install', '--quiet', package]\n        if upgrade:\n            args.append('--upgrade')\n        if target:\n            args += ['--target', os.path.abspath(target)]\n\n        try:\n            return subprocess.call(args) == 0\n        except subprocess.SubprocessError:\n            _LOGGER.exception('Unable to install pacakge %s', package)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_package_exists(package, lib_dir):\n    try:\n        req = pkg_resources.Requirement.parse(package)\n    except ValueError:\n        # This is a zip file\n        req = pkg_resources.Requirement.parse(urlparse(package).fragment)\n\n    # Check packages from lib dir\n    if lib_dir is not None:\n        if any(dist in req for dist in\n               pkg_resources.find_distributions(lib_dir)):\n            return True\n\n    # Check packages from global + virtual environment\n    # pylint: disable=not-an-iterable\n    return any(dist in req for dist in pkg_resources.working_set)", "response": "Check if a package exists globally or in lib_dir."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_widget(self, request, widget_id):\n        '''Returns rendered widget in JSON response'''\n\n        widget = get_widget_from_id(widget_id)\n\n        response = widget.render(**{'request': request})\n\n        return JsonResponse({'result': response, 'id': widget_id})", "response": "Returns rendered widget in JSON response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns rendered region in JSON response", "response": "def render_region(self, request):\n        '''Returns rendered region in JSON response'''\n\n        page = self.get_object()\n\n        try:\n            region = request.POST['region']\n        except KeyError:\n            region = request.GET['region']\n\n        request.query_string = None\n\n        from leonardo.utils.widgets import render_region\n\n        result = render_region(page=page, request=request, region=region)\n\n        return JsonResponse({'result': result, 'region': region})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle ajax methods and return serialized response", "response": "def handle_ajax_method(self, request, method):\n        \"\"\"handle ajax methods and return serialized reponse\n        in the default state allows only authentificated users\n\n        - Depends on method parameter render whole region or single widget\n\n        - If widget_id is present then try to load this widget\n          and call method on them\n\n        - If class_name is present then try to load class\n          and then call static method on this class\n\n        - If class_name is present then try to load class\n          and if method_name == render_preview then\n          render widget preview without instance\n\n        \"\"\"\n\n        response = {}\n\n        def get_param(request, name):\n\n            try:\n                return request.POST[name]\n            except KeyError:\n                return request.GET.get(name, None)\n\n        widget_id = get_param(request, \"widget_id\")\n        class_name = get_param(request, \"class_name\")\n\n        if method in 'widget_content':\n            return self.render_widget(request, widget_id)\n\n        if method == 'region':\n            return self.render_region(request)\n\n        # handle methods called directly on widget\n        if widget_id:\n\n            widget = get_widget_from_id(widget_id)\n\n            try:\n                func = getattr(widget, method)\n            except AttributeError:\n                response[\"exception\"] = \"%s method is not implmented on %s\" % (\n                    method, widget)\n            else:\n                response[\"result\"] = func(request)\n\n        elif class_name:\n            # handle calling classmethod without instance\n\n            try:\n                cls = get_model(*class_name.split('.'))\n            except Exception as e:\n                response[\"exception\"] = str(e)\n                return JsonResponse(data=response)\n\n            if method == \"render_preview\":\n\n                # TODO: i think that we need only simple form\n                # for loading relations but maybe this would be need it\n                # custom_form_cls = getattr(\n                #     cls, 'feincms_item_editor_form', None)\n\n                # if custom_form_cls:\n                #     FormCls = modelform_factory(cls, form=custom_form_cls,\n                #                                 exclude=('pk', 'id'))\n\n                FormCls = modelform_factory(cls, exclude=('pk', 'id'))\n\n                form = FormCls(request.POST)\n\n                if form.is_valid():\n\n                    widget = cls(**form.cleaned_data)\n\n                    request.frontend_editing = False\n\n                    try:\n                        content = widget.render(**{'request': request})\n                    except Exception as e:\n                        response['result'] = widget.handle_exception(request, e)\n                    else:\n                        response['result'] = content\n\n                    response['id'] = widget_id\n\n                else:\n                    response['result'] = form.errors\n                    response['id'] = widget_id\n\n            else:\n                # standard method\n                try:\n                    func = getattr(cls, method)\n                except Exception as e:\n                    response[\"exception\"] = str(e)\n                else:\n                    response[\"result\"] = func(request)\n\n        return JsonResponse(data=response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a few fields from FeinCMS admin inlines, those being ``id``, ``DELETE`` and ``ORDER`` currently. Additionally, it ensures that dynamically added fields (i.e. ``ApplicationContent``'s ``admin_fields`` option) are shown.", "response": "def post_process_fieldsets(context, fieldset):\n    \"\"\"\n    Removes a few fields from FeinCMS admin inlines, those being\n    ``id``, ``DELETE`` and ``ORDER`` currently.\n    Additionally, it ensures that dynamically added fields (i.e.\n    ``ApplicationContent``'s ``admin_fields`` option) are shown.\n    \"\"\"\n    # abort if fieldset is customized\n    if fieldset.model_admin.fieldsets:\n        return fieldset\n\n    fields_to_include = set(fieldset.form.fields.keys())\n    for f in ('id', 'DELETE', 'ORDER'):\n        fields_to_include.discard(f)\n\n    def _filter_recursive(fields):\n        ret = []\n        for f in fields:\n            if isinstance(f, (list, tuple)):\n                # Several fields on one line\n                sub = _filter_recursive(f)\n                # Only add if there's at least one field left\n                if sub:\n                    ret.append(sub)\n            elif f in fields_to_include:\n                ret.append(f)\n                fields_to_include.discard(f)\n        return ret\n\n    new_fields = _filter_recursive(fieldset.fields)\n    # Add all other fields (ApplicationContent's admin_fields) to\n    # the end of the fieldset\n    for f in fields_to_include:\n        new_fields.append(f)\n\n    if context.get('request'):\n        new_fields.extend(list(\n            fieldset.model_admin.get_readonly_fields(\n                context.get('request'),\n                context.get('original'),\n            )\n        ))\n\n    fieldset.fields = new_fields\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_bootstrap_class(field):\n    if not isinstance(field.field.widget, (\n        django.forms.widgets.CheckboxInput,\n        django.forms.widgets.CheckboxSelectMultiple,\n        django.forms.widgets.RadioSelect,\n        django.forms.widgets.FileInput,\n        str\n    )):\n        field_classes = set(field.field.widget.attrs.get('class', '').split())\n        field_classes.add('form-control')\n        field.field.widget.attrs['class'] = ' '.join(field_classes)\n    return field", "response": "Add a form - control CSS class to the field s widget."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles an ajax upload.", "response": "def ajax_upload(self, request, folder_id=None):\n        \"\"\"\n        receives an upload from the uploader. Receives only one file at the time.\n        \"\"\"\n        mimetype = \"application/json\" if request.is_ajax() else \"text/html\"\n        content_type_key = 'content_type'\n        response_params = {content_type_key: mimetype}\n        folder = None\n        if folder_id:\n            try:\n                # Get folder\n                folder = Folder.objects.get(pk=folder_id)\n            except Folder.DoesNotExist:\n                return HttpResponse(json.dumps({'error': NO_FOLDER_ERROR}),\n                                    **response_params)\n\n        # check permissions\n        if folder and not folder.has_add_children_permission(request):\n            return HttpResponse(\n                json.dumps({'error': NO_PERMISSIONS_FOR_FOLDER}),\n                **response_params)\n        try:\n            if len(request.FILES) == 1:\n                # dont check if request is ajax or not, just grab the file\n                upload, filename, is_raw = handle_request_files_upload(request)\n            else:\n                # else process the request as usual\n                upload, filename, is_raw = handle_upload(request)\n\n            # Get clipboad\n            # TODO: Deprecated/refactor\n            # clipboard = Clipboard.objects.get_or_create(user=request.user)[0]\n\n            # find the file type\n            for filer_class in media_settings.MEDIA_FILE_MODELS:\n                FileSubClass = load_object(filer_class)\n                # TODO: What if there are more than one that qualify?\n                if FileSubClass.matches_file_type(filename, upload, request):\n                    FileForm = modelform_factory(\n                        model=FileSubClass,\n                        fields=('original_filename', 'owner', 'file')\n                    )\n                    break\n            uploadform = FileForm({'original_filename': filename,\n                                   'owner': request.user.pk},\n                                  {'file': upload})\n            if uploadform.is_valid():\n                file_obj = uploadform.save(commit=False)\n                # Enforce the FILER_IS_PUBLIC_DEFAULT\n                file_obj.is_public = settings.MEDIA_IS_PUBLIC_DEFAULT\n                file_obj.folder = folder\n                file_obj.save()\n                # TODO: Deprecated/refactor\n                # clipboard_item = ClipboardItem(\n                #    clipboard=clipboard, file=file_obj)\n                # clipboard_item.save()\n                json_response = {\n                    'thumbnail': file_obj.icons['32'],\n                    'alt_text': '',\n                    'label': str(file_obj),\n                    'file_id': file_obj.pk,\n                }\n                return HttpResponse(json.dumps(json_response),\n                                    **response_params)\n            else:\n                form_errors = '; '.join(['%s: %s' % (\n                    field,\n                    ', '.join(errors)) for field, errors in list(uploadform.errors.items())\n                ])\n                raise UploadException(\n                    \"AJAX request not valid: form invalid '%s'\" % (form_errors,))\n        except UploadException as e:\n            return HttpResponse(json.dumps({'error': str(e)}),\n                                **response_params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_options(self, **options):\n        self.interactive = False\n        self.verbosity = options['verbosity']\n        self.symlink = \"\"\n        self.clear = False\n        ignore_patterns = []\n        self.ignore_patterns = list(set(ignore_patterns))\n        self.page_themes_updated = 0\n        self.skins_updated = 0", "response": "Set instance variables based on an options dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect(self):\n\n        self.ignore_patterns = [\n            '*.png', '*.jpg', '*.js', '*.gif', '*.ttf', '*.md', '*.rst',\n            '*.svg']\n        page_themes = PageTheme.objects.all()\n\n        for finder in get_finders():\n            for path, storage in finder.list(self.ignore_patterns):\n                for t in page_themes:\n                    static_path = 'themes/{0}'.format(t.name.split('/')[-1])\n                    if static_path in path:\n                        try:\n                            page_theme = PageTheme.objects.get(id=t.id)\n                        except PageTheme.DoesNotExist:\n                            raise Exception(\n                                \"Run sync_themes before this command\")\n                        except Exception as e:\n                            self.stdout.write(\n                                \"Cannot load {} into database original error: {}\".format(t, e))\n\n                        # find and load skins\n                        skins_path = os.path.join(\n                            storage.path('/'.join(path.split('/')[0:-1])))\n                        for dirpath, skins, filenames in os.walk(skins_path):\n                            for skin in [s for s in skins if s not in ['fonts']]:\n                                for skin_dirpath, skins, filenames in os.walk(os.path.join(dirpath, skin)):\n                                    skin, created = PageColorScheme.objects.get_or_create(\n                                        theme=page_theme, label=skin, name=skin.title())\n                                    for f in filenames:\n                                        if 'styles' in f:\n                                            with codecs.open(os.path.join(skin_dirpath, f)) as style_file:\n                                                skin.styles = style_file.read()\n                                        elif 'variables' in f:\n                                            with codecs.open(os.path.join(skin_dirpath, f)) as variables_file:\n                                                skin.variables = variables_file.read()\n                                    skin.save()\n                                    self.skins_updated += 1\n\n        self.page_themes_updated += len(page_themes)", "response": "Load and save every PageTheme in database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dbtemplate_save(sender, instance, created, **kwargs):\n\n    if created:\n        if 'widget' in instance.name:\n            name = instance.name.split('/')[-1]\n            kwargs = {\n                'name': name.split('.')[0],\n                'label': name.split('.')[0].capitalize(),\n                'template': instance,\n            }\n            if 'base/widget' in instance.name:\n                from leonardo.module.web.models import WidgetBaseTheme\n                theme_cls = WidgetBaseTheme\n            else:\n                from leonardo.module.web.models import WidgetContentTheme\n                theme_cls = WidgetContentTheme\n                from leonardo.utils.widgets import find_widget_class\n                w_cls_name = instance.name.split('/')[-2]\n                w_cls = find_widget_class(w_cls_name)\n                if w_cls is None:\n                    raise Exception('widget class for %s not found' % w_cls_name)\n                kwargs['widget_class'] = w_cls.__name__\n            theme_cls(**kwargs).save()\n\n        if 'base/page' in instance.name:\n            from leonardo.module.web.models import PageTheme\n            page_theme = PageTheme()\n            page_theme.label = '{} layout'.format(\n                instance.name.split(\"/\")[-1].split('.')[0].title())\n            page_theme.name = instance.name.split(\"/\")[-1]\n            page_theme.template = instance\n            page_theme.save()", "response": "save widget and page themes from given db template"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the current user has permission on this ArcGIS image.", "response": "def has_generic_permission(self, request, permission_type):\n        \"\"\"\n        Return true if the current user has permission on this\n        image. Return the string 'ALL' if the user has all rights.\n        \"\"\"\n        user = request.user\n        if not user.is_authenticated():\n            return False\n        elif user.is_superuser:\n            return True\n        elif user == self.owner:\n            return True\n        elif self.folder:\n            return self.folder.has_generic_permission(request, permission_type)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode(self, packet):\n\n        ssu=packet.retrieve(\"Complete uuids\")\n        found=False\n        for x in ssu:\n            if EDDY_UUID in x:\n                found=True\n                break\n        if not found:\n            return None\n\n        found=False\n        adv=packet.retrieve(\"Advertised Data\")\n        for x in adv:\n            luuid=x.retrieve(\"Service Data uuid\")\n            for uuid in luuid:\n                if EDDY_UUID == uuid:\n                    found=x\n                    break\n            if found:\n                break\n\n\n        if not found:\n            return None\n\n        try:\n            top=found.retrieve(\"Adv Payload\")[0]\n        except:\n            return None\n        #Rebuild that part of the structure\n        found.payload.remove(top)\n        #Now decode\n        result={}\n        data=top.val\n        etype = aios.EnumByte(\"type\",self.type.val,{ESType.uid.value:\"Eddystone-UID\",\n                                                ESType.url.value:\"Eddystone-URL\",\n                                                ESType.tlm.value:\"Eddystone-TLM\",\n                                                ESType.eid.value:\"Eddystone-EID\"})\n        data=etype.decode(data)\n        found.payload.append(etype)\n        if etype.val== ESType.uid.value:\n            power=aios.IntByte(\"tx_power\")\n            data=power.decode(data)\n            found.payload.append(power)\n            result[\"tx_power\"]=power.val\n\n            nspace=aios.Itself(\"namespace\")\n            xx=nspace.decode(data[:10])  #According to https://github.com/google/eddystone/tree/master/eddystone-uid\n            data=data[10:]\n            found.payload.append(nspace)\n            result[\"name space\"]=nspace.val\n\n            nspace=aios.Itself(\"instance\")\n            xx=nspace.decode(data[:6])  #According to https://github.com/google/eddystone/tree/master/eddystone-uid\n            data=data[6:]\n            found.payload.append(nspace)\n            result[\"instance\"]=nspace.val\n\n        elif etype.val== ESType.url.value:\n            power=aios.IntByte(\"tx_power\")\n            data=power.decode(data)\n            found.payload.append(power)\n            result[\"tx_power\"]=power.val\n\n            url=aios.EnumByte(\"type\",0,{0x00:\"http://www.\",0x01:\"https://www.\",0x02:\"http://\",0x03:\"https://\"})\n            data=url.decode(data)\n            result[\"url\"]=url.strval\n            for x in data:\n                if bytes([x]) == b\"\\x00\":\n                    result[\"url\"]+=\".com/\"\n                elif bytes([x]) == b\"\\x01\":\n                    result[\"url\"]+=\".org/\"\n                elif bytes([x]) == b\"\\x02\":\n                    result[\"url\"]+=\".edu/\"\n                elif bytes([x]) == b\"\\x03\":\n                    result[\"url\"]+=\".net/\"\n                elif bytes([x]) == b\"\\x04\":\n                    result[\"url\"]+=\".info/\"\n                elif bytes([x]) == b\"\\x05\":\n                    result[\"url\"]+=\".biz/\"\n                elif bytes([x]) == b\"\\x06\":\n                    result[\"url\"]+=\".gov/\"\n                elif bytes([x]) == b\"\\x07\":\n                    result[\"url\"]+=\".com\"\n                elif bytes([x]) == b\"\\x08\":\n                    result[\"url\"]+=\".org\"\n                elif bytes([x]) == b\"\\x09\":\n                    result[\"url\"]+=\".edu\"\n                elif bytes([x]) == b\"\\x10\":\n                    result[\"url\"]+=\".net\"\n                elif bytes([x]) == b\"\\x11\":\n                    result[\"url\"]+=\".info\"\n                elif bytes([x]) == b\"\\x12\":\n                    result[\"url\"]+=\".biz\"\n                elif bytes([x]) == b\"\\x13\":\n                    result[\"url\"]+=\".gov\"\n                else:\n                    result[\"url\"]+=chr(x) #x.decode(\"ascii\") #Yep ASCII only\n                    url=aios.String(\"url\")\n            url.decode(result[\"url\"])\n            found.payload.append(url)\n        elif etype.val== ESType.tlm.value:\n            myinfo=aios.IntByte(\"version\")\n            data=myinfo.decode(data)\n            found.payload.append(myinfo)\n            myinfo=aios.ShortInt(\"battery\")\n            data=myinfo.decode(data)\n            result[\"battery\"]=myinfo.val\n            found.payload.append(myinfo)\n            myinfo=aios.Float88(\"temperature\")\n            data=myinfo.decode(data)\n            found.payload.append(myinfo)\n            result[\"temperature\"]=myinfo.val\n            myinfo=aios.LongInt(\"pdu count\")\n            data=myinfo.decode(data)\n            found.payload.append(myinfo)\n            result[\"pdu count\"]=myinfo.val\n            myinfo=aios.LongInt(\"uptime\")\n            data=myinfo.decode(data)\n            found.payload.append(myinfo)\n            result[\"uptime\"]=myinfo.val*100 #in msecs\n            return result\n        #elif etype.val== ESType.tlm.eid:\n        else:\n            result[\"data\"]=data\n            xx=Itself(\"data\")\n            xx.decode(data)\n            found.payload.append(xx)\n\n        rssi=packet.retrieve(\"rssi\")\n        if rssi:\n            result[\"rssi\"]=rssi[-1].val\n        mac=packet.retrieve(\"peer\")\n        if mac:\n            result[\"mac address\"]=mac[-1].val\n        return result", "response": "Decode a packet and return the relevant data as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_directories(self, request):\n\n        queryset = self.folder.media_folder_children.all().order_by(*config.MEDIA_FOLDERS_ORDER_BY.split(\",\"))\n\n        paginator = Paginator(queryset, self.objects_per_page)\n\n        page = request.GET.get('page', None)\n\n        try:\n            object_list = paginator.page(page)\n        except PageNotAnInteger:\n\n            if page == \"all\":\n                object_list = queryset\n            else:\n                object_list = paginator.page(1)\n\n        except EmptyPage:\n            object_list = paginator.page(paginator.num_pages)\n\n        return object_list", "response": "Return directories that are in the folder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_template_data(self, request, *args, **kwargs):\n        '''Add image dimensions'''\n\n        # little tricky with vertical centering\n        dimension = int(self.get_size().split('x')[0])\n\n        data = {}\n\n        if dimension <= 356:\n            data['image_dimension'] = \"row-md-13\"\n\n        if self.get_template_name().name.split(\"/\")[-1] == \"directories.html\":\n            data['directories'] = self.get_directories(request)\n\n        return data", "response": "Add image dimensions and directories"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming user authentication check. Similar to Django's `login_required` decorator, except that this throws :exc:`~leonardo.exceptions.NotAuthenticated` exception if the user is not signed-in.", "response": "def staff_member(view_func):\n    \"\"\"Performs user authentication check.\n\n    Similar to Django's `login_required` decorator, except that this throws\n    :exc:`~leonardo.exceptions.NotAuthenticated` exception if the user is not\n    signed-in.\n    \"\"\"\n\n    @functools.wraps(view_func, assigned=available_attrs(view_func))\n    def dec(request, *args, **kwargs):\n        if request.user.is_staff:\n            return view_func(request, *args, **kwargs)\n        raise PermissionDenied(_(\"You haven't permissions to do this action.\"))\n    return dec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decorate_urlconf(urlpatterns, decorator=require_auth, *args, **kwargs):\n    '''Decorate all urlpatterns by specified decorator'''\n\n    if isinstance(urlpatterns, (list, tuple)):\n\n        for pattern in urlpatterns:\n            if getattr(pattern, 'callback', None):\n                pattern._callback = decorator(\n                    pattern.callback, *args, **kwargs)\n            if getattr(pattern, 'url_patterns', []):\n                _decorate_urlconf(\n                    pattern.url_patterns, decorator, *args, **kwargs)\n    else:\n        if getattr(urlpatterns, 'callback', None):\n            urlpatterns._callback = decorator(\n                urlpatterns.callback, *args, **kwargs)", "response": "Decorate all urlpatterns by specified decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef catch_result(task_func):\n\n    @functools.wraps(task_func, assigned=available_attrs(task_func))\n    def dec(*args, **kwargs):\n        # inicialize\n        orig_stdout = sys.stdout\n        sys.stdout = content = StringIO()\n        task_response = task_func(*args, **kwargs)\n        # catch\n        sys.stdout = orig_stdout\n        content.seek(0)\n        # propagate to the response\n        task_response['stdout'] = content.read()\n        return task_response\n    return dec", "response": "Catch printed result from Celery Task and return it in task response\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compress_monkey_patch():\n    from compressor.templatetags import compress as compress_tags\n    from compressor import base as compress_base\n\n    compress_base.Compressor.filter_input = filter_input\n    compress_base.Compressor.output = output\n    compress_base.Compressor.hunks = hunks\n    compress_base.Compressor.precompile = precompile\n\n    compress_tags.CompressorMixin.render_compressed = render_compressed\n\n    from django_pyscss import compressor as pyscss_compressor\n\n    pyscss_compressor.DjangoScssFilter.input = input", "response": "patch all compress\n    we need access to variables from widget scss\n\n    but only if is cyborg active"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef input(self, **kwargs):\n\n    with_variables = None\n\n    context = kwargs.get('context', {})\n\n    if context.get('leonardo_page', None):\n        try:\n            context['leonardo_page']['theme']\n            context['leonardo_page']['color_scheme']\n        except Exception as e:\n            LOG.exception(str(e))\n        else:\n            with_variables = \"\"\"\n            @import \"/themes/{}/{}/_variables\";\n            {}\n            \"\"\".format(\n                context['leonardo_page']['theme']['name'],\n                context['leonardo_page']['color_scheme']['name'],\n                self.content)\n\n    return self.compiler.compile_string(\n        with_variables or self.content,\n        filename=self.filename)", "response": "main override which append variables import to all scss content\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hunks(self, forced=False, context=None):\n    enabled = settings.COMPRESS_ENABLED or forced\n\n    for kind, value, basename, elem in self.split_contents():\n        precompiled = False\n        attribs = self.parser.elem_attribs(elem)\n        charset = attribs.get(\"charset\", self.charset)\n        options = {\n            'method': METHOD_INPUT,\n            'elem': elem,\n            'kind': kind,\n            'basename': basename,\n            'charset': charset,\n            'context': context\n        }\n\n        if kind == SOURCE_FILE:\n            options = dict(options, filename=value)\n            value = self.get_filecontent(value, charset)\n\n        if self.precompiler_mimetypes:\n            precompiled, value = self.precompile(value, **options)\n\n        if enabled:\n            yield self.filter(value, self.cached_filters, **options)\n        elif precompiled:\n            # since precompiling moves files around, it breaks url()\n            # statements in css files. therefore we run the absolute filter\n            # on precompiled css files even if compression is disabled.\n            if CssAbsoluteFilter in self.cached_filters:\n                value = self.filter(value, [CssAbsoluteFilter], **options)\n            yield self.handle_output(kind, value, forced=True,\n                                     basename=basename)\n        else:\n            yield self.parser.elem_str(elem)", "response": "Yields all the hunks that can be parsed into a single base object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all input files that can be filtered by the compressor.", "response": "def filter_input(self, forced=False, context=None):\n    \"\"\"\n    Passes each hunk (file or code) to the 'input' methods\n    of the compressor filters.\n    \"\"\"\n    content = []\n    for hunk in self.hunks(forced, context=context):\n        content.append(hunk)\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef precompile(self, content, kind=None, elem=None, filename=None,\n               charset=None, **kwargs):\n    \"\"\"\n    Processes file using a pre compiler.\n    This is the place where files like coffee script are processed.\n    \"\"\"\n    if not kind:\n        return False, content\n    attrs = self.parser.elem_attribs(elem)\n    mimetype = attrs.get(\"type\", None)\n    if mimetype is None:\n        return False, content\n\n    filter_or_command = self.precompiler_mimetypes.get(mimetype)\n    if filter_or_command is None:\n        if mimetype in (\"text/css\", \"text/javascript\"):\n            return False, content\n        raise CompressorError(\"Couldn't find any precompiler in \"\n                              \"COMPRESS_PRECOMPILERS setting for \"\n                              \"mimetype '%s'.\" % mimetype)\n\n    mod_name, cls_name = get_mod_func(filter_or_command)\n    try:\n        mod = import_module(mod_name)\n    except (ImportError, TypeError):\n        filter = CachedCompilerFilter(\n            content=content, filter_type=self.type, filename=filename,\n            charset=charset, command=filter_or_command, mimetype=mimetype)\n        return True, filter.input(**kwargs)\n    try:\n        precompiler_class = getattr(mod, cls_name)\n    except AttributeError:\n        raise FilterDoesNotExist('Could not find \"%s\".' % filter_or_command)\n    filter = precompiler_class(\n        content, attrs=attrs, filter_type=self.type, charset=charset,\n        filename=filename, **kwargs)\n    return True, filter.input(**kwargs)", "response": "Processes a file using a precompiler."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(self,data):\n        self.val=':'.join(\"%02x\" % x for x in reversed(data[:6]))\n        return data[6:]", "response": "Decode the MAC address from a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a list of specifc class names in the packet", "response": "def retrieve(self,aclass):\n        \"\"\"Look for a specifc class/name in the packet\"\"\"\n        resu=[]\n        for x in self.payload:\n            try:\n                if isinstance(aclass,str):\n                    if x.name == aclass:\n                        resu.append(x)\n                else:\n                    if isinstance(x,aclass):\n                        resu.append(x)\n\n                resu+=x.retrieve(aclass)\n            except:\n                pass\n        return resu"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend LE scan request to the device.", "response": "def send_scan_request(self):\n        '''Sending LE scan request'''\n        command=HCI_Cmd_LE_Scan_Enable(True,False)\n        self.transport.write(command.encode())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_scan_request(self):\n        '''Sending LE scan request'''\n        command=HCI_Cmd_LE_Scan_Enable(False,False)\n        self.transport.write(command.encode())", "response": "Send LE scan request to the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef thumbnail(parser, token):\n    '''\n    This template tag supports both syntax for declare thumbanil in template\n    '''\n\n    thumb = None\n\n    if SORL:\n        try:\n            thumb = sorl_thumb(parser, token)\n        except Exception:\n            thumb = False\n\n    if EASY and not thumb:\n        thumb = easy_thumb(parser, token)\n\n    return thumb", "response": "This template tag supports both syntax for declare thumbanil in template\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_widgets():\n\n    # special case\n    # register external apps\n    Page.create_content_type(\n        ApplicationWidget, APPLICATIONS=settings.APPLICATION_CHOICES)\n\n    for _optgroup, _widgets in six.iteritems(settings.WIDGETS):\n        optgroup = _optgroup if _optgroup != 'ungrouped' else None\n        for widget in _widgets:\n\n            kwargs = {'optgroup': optgroup}\n\n            # load class from strings\n            if isinstance(widget, six.string_types):\n                try:\n                    WidgetCls = get_class_from_string(widget)\n                except:\n                    exc_info = sys.exc_info()\n                    raise six.reraise(*exc_info)\n            elif isinstance(widget, tuple):\n                try:\n                    WidgetCls = get_class_from_string(widget[0])\n                    if len(widget) > 1:\n                        kwargs.update(widget[1])\n                except Exception as e:\n                    raise Exception('%s: %s' % (mod, e))\n            else:\n                WidgetCls = widget\n\n            Page.create_content_type(\n                WidgetCls, **kwargs)", "response": "Register all collected widgets from settings. WIDGETS"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles uploaded file to folder match first media type and create media object and return it", "response": "def handle_uploaded_file(file, folder=None, is_public=True):\n    '''handle uploaded file to folder\n    match first media type and create media object and returns it\n\n    file: File object\n    folder: str or Folder isinstance\n    is_public: boolean\n    '''\n    _folder = None\n\n    if folder and isinstance(folder, Folder):\n        _folder = folder\n    elif folder:\n        _folder, folder_created = Folder.objects.get_or_create(\n            name=folder)\n\n    for cls in MEDIA_MODELS:\n        if cls.matches_file_type(file.name):\n\n            obj, created = cls.objects.get_or_create(\n                original_filename=file.name,\n                file=file,\n                folder=_folder,\n                is_public=is_public)\n\n            if created:\n                return obj\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling uploaded files to folder", "response": "def handle_uploaded_files(files, folder=None, is_public=True):\n    '''handle uploaded files to folder\n\n    files: array of File objects or single object\n    folder: str or Folder isinstance\n    is_public: boolean\n    '''\n    results = []\n\n    for f in files:\n        result = handle_uploaded_file(f, folder, is_public)\n        results.append(result)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serve_protected_file(request, path):\n    path = path.rstrip('/')\n    try:\n        file_obj = File.objects.get(file=path)\n    except File.DoesNotExist:\n        raise Http404('File not found %s' % path)\n    if not file_obj.has_read_permission(request):\n        if settings.DEBUG:\n            raise PermissionDenied\n        else:\n            raise Http404('File not found %s' % path)\n    return server.serve(request, file_obj=file_obj.file, save_as=False)", "response": "Serve protected files to authenticated users with read permissions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serve_protected_thumbnail(request, path):\n    source_path = thumbnail_to_original_filename(path)\n    if not source_path:\n        raise Http404('File not found')\n    try:\n        file_obj = File.objects.get(file=source_path)\n    except File.DoesNotExist:\n        raise Http404('File not found %s' % path)\n    if not file_obj.has_read_permission(request):\n        if settings.DEBUG:\n            raise PermissionDenied\n        else:\n            raise Http404('File not found %s' % path)\n    try:\n        thumbnail = ThumbnailFile(name=path, storage=file_obj.file.thumbnail_storage)\n        return thumbnail_server.serve(request, thumbnail, save_as=False)\n    except Exception:\n        raise Http404('File not found %s' % path)", "response": "Serve protected thumbnails to authenticated users."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns array of imported leonardo modules for apps", "response": "def get_app_modules(self, apps):\n        \"\"\"return array of imported leonardo modules for apps\n        \"\"\"\n        modules = getattr(self, \"_modules\", [])\n\n        if not modules:\n            from django.utils.module_loading import module_has_submodule\n\n            # Try importing a modules from the module package\n            package_string = '.'.join(['leonardo', 'module'])\n\n            for app in apps:\n                exc = '...'\n                try:\n                    # check if is not full app\n                    _app = import_module(app)\n                except Exception as e:\n                    _app = False\n                    exc = e\n\n                if module_has_submodule(\n                        import_module(package_string), app) or _app:\n                    if _app:\n                        mod = _app\n                    else:\n                        mod = import_module('.{0}'.format(app), package_string)\n                    if mod:\n                        modules.append(mod)\n                        continue\n\n                warnings.warn('%s was skipped because %s ' % (app, exc))\n\n            self._modules = modules\n        return self._modules"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads and decorate urls from all modules then store it as cached property for less loading", "response": "def urlpatterns(self):\n        '''load and decorate urls from all modules\n        then store it as cached property for less loading\n        '''\n        if not hasattr(self, '_urlspatterns'):\n            urlpatterns = []\n            # load all urls\n            # support .urls file and urls_conf = 'elephantblog.urls' on default module\n            # decorate all url patterns if is not explicitly excluded\n            for mod in leonardo.modules:\n                # TODO this not work\n                if is_leonardo_module(mod):\n\n                    conf = get_conf_from_module(mod)\n\n                    if module_has_submodule(mod, 'urls'):\n                        urls_mod = import_module('.urls', mod.__name__)\n                        if hasattr(urls_mod, 'urlpatterns'):\n                            # if not public decorate all\n\n                            if conf['public']:\n                                urlpatterns += urls_mod.urlpatterns\n                            else:\n                                _decorate_urlconf(urls_mod.urlpatterns,\n                                                  require_auth)\n                                urlpatterns += urls_mod.urlpatterns\n            # avoid circural dependency\n            # TODO use our loaded modules instead this property\n            from django.conf import settings\n            for urls_conf, conf in six.iteritems(getattr(settings, 'MODULE_URLS', {})):\n                # is public ?\n                try:\n                    if conf['is_public']:\n                        urlpatterns += \\\n                            patterns('',\n                                     url(r'', include(urls_conf)),\n                                     )\n                    else:\n                        _decorate_urlconf(\n                            url(r'', include(urls_conf)),\n                            require_auth)\n                        urlpatterns += patterns('',\n                                                url(r'', include(urls_conf)))\n                except Exception as e:\n                    raise Exception('raised %s during loading %s' %\n                                    (str(e), urls_conf))\n\n            self._urlpatterns = urlpatterns\n\n        return self._urlpatterns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing not really empty the cache ; instead it adds a random element to the availabe cache key generation which ensures that the availabe cache does not yet contain all newly generated keys.", "response": "def cycle_app_reverse_cache(*args, **kwargs):\n    \"\"\"Does not really empty the cache; instead it adds a random element to the\n    cache key generation which guarantees that the cache does not yet contain\n    values for all newly generated keys\"\"\"\n    value = '%07x' % (SystemRandom().randint(0, 0x10000000))\n    cache.set(APP_REVERSE_CACHE_GENERATION_KEY, value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreversing the URL of the current application content.", "response": "def app_reverse(viewname, urlconf=None, args=None, kwargs=None,\n                *vargs, **vkwargs):\n    \"\"\"\n    Reverse URLs from application contents\n    Works almost like Django's own reverse() method except that it resolves\n    URLs from application contents. The second argument, ``urlconf``, has to\n    correspond to the URLconf parameter passed in the ``APPLICATIONS`` list\n    to ``Page.create_content_type``::\n        app_reverse('mymodel-detail', 'myapp.urls', args=...)\n        or\n        app_reverse('mymodel-detail', 'myapp.urls', kwargs=...)\n    The second argument may also be a request object if you want to reverse\n    an URL belonging to the current application content.\n    \"\"\"\n\n    # First parameter might be a request instead of an urlconf path, so\n    # we'll try to be helpful and extract the current urlconf from it\n    extra_context = getattr(urlconf, '_feincms_extra_context', {})\n    appconfig = extra_context.get('app_config', {})\n    urlconf = appconfig.get('urlconf_path', urlconf)\n    appcontent_class = ApplicationWidget._feincms_content_models[0]\n    cache_key = appcontent_class.app_reverse_cache_key(urlconf)\n    url_prefix = cache.get(cache_key)\n\n    if url_prefix is None:\n\n        clear_script_prefix()\n\n        content = appcontent_class.closest_match(urlconf)\n\n        if content is not None:\n            if urlconf in appcontent_class.ALL_APPS_CONFIG:\n                # We have an overridden URLconf\n                app_config = appcontent_class.ALL_APPS_CONFIG[urlconf]\n                urlconf = app_config['config'].get('urls', urlconf)\n\n            prefix = content.parent.get_absolute_url()\n            prefix += '/' if prefix[-1] != '/' else ''\n\n            url_prefix = (urlconf, prefix)\n\n            cache.set(cache_key, url_prefix, timeout=APP_REVERSE_CACHE_TIMEOUT)\n\n    if url_prefix:\n        # vargs and vkwargs are used to send through additional parameters\n        # which are uninteresting to us (such as current_app)\n        prefix = get_script_prefix()\n        try:\n            set_script_prefix(url_prefix[1])\n            return reverse(\n                viewname,\n                url_prefix[0],\n                args=args,\n                kwargs=kwargs,\n                *vargs, **vkwargs)\n        finally:\n            set_script_prefix(prefix)\n\n    raise NoReverseMatch(\"Unable to find ApplicationContent for %(app)s\"\n                         \" usually it is due to the fact that you haven't mapped external application %(app)s\" % {\n                             'app': urlconf})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef permalink(func):\n    def inner(*args, **kwargs):\n        return app_reverse(*func(*args, **kwargs))\n    return wraps(func)(inner)", "response": "Decorator that returns a function that returns the permalink of the current model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreverse a view name.", "response": "def reverse(viewname, urlconf=None, args=None, kwargs=None, current_app=None):\n    \"\"\"monkey patched reverse\n\n    path supports easy patching 3rd party urls\n    if 3rd party app has namespace for example ``catalogue`` and\n    you create FeinCMS plugin with same name as this namespace reverse\n    returns url from ApplicationContent !\n\n    \"\"\"\n\n    if not urlconf:\n        urlconf = get_urlconf()\n    resolver = get_resolver(urlconf)\n    args = args or []\n    kwargs = kwargs or {}\n\n    prefix = get_script_prefix()\n\n    if not isinstance(viewname, six.string_types):\n        view = viewname\n    else:\n        parts = viewname.split(':')\n        parts.reverse()\n        view = parts[0]\n        path = parts[1:]\n\n        resolved_path = []\n        ns_pattern = ''\n        while path:\n            ns = path.pop()\n\n            # Lookup the name to see if it could be an app identifier\n            try:\n                app_list = resolver.app_dict[ns]\n                # Yes! Path part matches an app in the current Resolver\n                if current_app and current_app in app_list:\n                    # If we are reversing for a particular app,\n                    # use that namespace\n                    ns = current_app\n                elif ns not in app_list:\n                    # The name isn't shared by one of the instances\n                    # (i.e., the default) so just pick the first instance\n                    # as the default.\n                    ns = app_list[0]\n            except KeyError:\n                pass\n\n            try:\n                extra, resolver = resolver.namespace_dict[ns]\n                resolved_path.append(ns)\n                ns_pattern = ns_pattern + extra\n            except KeyError as key:\n\n                for urlconf, config in six.iteritems(\n                        ApplicationWidget._feincms_content_models[0].ALL_APPS_CONFIG):\n\n                    partials = viewname.split(':')\n                    app = partials[0]\n                    partials = partials[1:]\n\n                    # check if namespace is same as app name and try resolve\n                    if urlconf.split(\".\")[-1] == app:\n\n                        try:\n                            return app_reverse(\n                                ':'.join(partials),\n                                urlconf, args=args, kwargs=kwargs,\n                                current_app=current_app)\n                        except NoReverseMatch:\n                            pass\n\n                if resolved_path:\n                    raise NoReverseMatch(\n                        \"%s is not a registered namespace inside '%s'\" %\n                        (key, ':'.join(resolved_path)))\n                else:\n                    raise NoReverseMatch(\"%s is not a registered namespace\" %\n                                         key)\n        if ns_pattern:\n            resolver = get_ns_resolver(ns_pattern, resolver)\n\n    return iri_to_uri(resolver._reverse_with_prefix(view, prefix, *args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nproviding the formset corresponding to this DataTable.", "response": "def get_formset(self):\n        \"\"\"Provide the formset corresponding to this DataTable.\n\n        Use this to validate the formset and to get the submitted data back.\n        \"\"\"\n        if self.widget:\n            queryset = self.widget.dimensions\n        else:\n            queryset = WidgetDimension.objects.none()\n        if self._formset is None:\n            self._formset = self.formset_class(\n                self.request.POST or None,\n                initial=self._get_formset_data(),\n                prefix=self._meta.name,\n                queryset=queryset)\n        return self._formset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning feincms_page for request. Returns {} if no page is found.", "response": "def add_page_if_missing(request):\n    \"\"\"\n    Returns ``feincms_page`` for request.\n    \"\"\"\n\n    try:\n        page = Page.objects.for_request(request, best_match=True)\n        return {\n            'leonardo_page': page,\n            # DEPRECATED\n            'feincms_page': page,\n        }\n    except Page.DoesNotExist:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_in_page(request, template):\n    from leonardo.module.web.models import Page\n\n    page = request.leonardo_page if hasattr(\n        request, 'leonardo_page') else Page.objects.filter(parent=None).first()\n\n    if page:\n        try:\n            slug = request.path_info.split(\"/\")[-2:-1][0]\n        except KeyError:\n            slug = None\n\n        try:\n            body = render_to_string(template, RequestContext(request, {\n                'request_path': request.path,\n                'feincms_page': page,\n                'slug': slug,\n                'standalone': True}))\n            response = http.HttpResponseNotFound(\n                body, content_type=CONTENT_TYPE)\n        except TemplateDoesNotExist:\n            response = False\n\n        return response\n\n    return False", "response": "Render a template in a page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef page_not_found(request, template_name='404.html'):\n    response = render_in_page(request, template_name)\n\n    if response:\n        return response\n\n    template = Template(\n        '<h1>Not Found</h1>'\n        '<p>The requested URL {{ request_path }} was not found on this server.</p>')\n    body = template.render(RequestContext(\n        request, {'request_path': request.path}))\n    return http.HttpResponseNotFound(body, content_type=CONTENT_TYPE)", "response": "Default 404 handler.\n\n    Templates: :template:`404.html`\n    Context:\n        request_path\n            The path of the requested URL (e.g., '/app/pages/bad_page/')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds data necessary for Horizon to function to the request.", "response": "def process_request(self, request):\n        \"\"\"Adds data necessary for Horizon to function to the request.\"\"\"\n        # Activate timezone handling\n        tz = request.session.get('django_timezone')\n        if tz:\n            timezone.activate(tz)\n\n        # Check for session timeout\n        try:\n            timeout = settings.SESSION_TIMEOUT\n        except AttributeError:\n            timeout = 1800\n\n        last_activity = request.session.get('last_activity', None)\n        timestamp = int(time.time())\n        request.horizon = {'dashboard': None,\n                           'panel': None,\n                           'async_messages': []}\n\n        if not hasattr(request, \"user\") or not request.user.is_authenticated():\n            # proceed no further if the current request is already known\n            # not to be authenticated\n            return None\n        if request.is_ajax():\n            # if the request is Ajax we do not want to proceed, as clients can\n            #  1) create pages with constant polling, which can create race\n            #     conditions when a page navigation occurs\n            #  2) might leave a user seemingly left logged in forever\n            #  3) thrashes db backed session engines with tons of changes\n            return None\n        # If we use cookie-based sessions, check that the cookie size does not\n        # reach the max size accepted by common web browsers.\n        if (\n            settings.SESSION_ENGINE ==\n            'django.contrib.sessions.backends.signed_cookies'\n        ):\n            max_cookie_size = getattr(\n                settings, 'SESSION_COOKIE_MAX_SIZE', None)\n            session_cookie_name = getattr(\n                settings, 'SESSION_COOKIE_NAME', None)\n            session_key = request.COOKIES.get(session_cookie_name)\n            if max_cookie_size is not None and session_key is not None:\n                cookie_size = sum((\n                    len(key) + len(value)\n                    for key, value in six.iteritems(request.COOKIES)\n                ))\n                if cookie_size >= max_cookie_size:\n                    LOG.error(\n                        'Total Cookie size for user_id: %(user_id)s is '\n                        '%(cookie_size)sB >= %(max_cookie_size)sB. '\n                        'You need to configure file-based or database-backed '\n                        'sessions instead of cookie-based sessions: '\n                        'http://docs.openstack.org/developer/horizon/topics/'\n                        'deployment.html#session-storage'\n                        % {\n                            'user_id': request.session.get(\n                                'user_id', 'Unknown'),\n                            'cookie_size': cookie_size,\n                            'max_cookie_size': max_cookie_size,\n                        }\n                    )\n\n        request.session['last_activity'] = timestamp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts HttpResponseRedirect to HttpResponse if request is via ajax and allow ajax request to redirect url", "response": "def process_response(self, request, response):\n        \"\"\"Convert HttpResponseRedirect to HttpResponse if request is via ajax\n        to allow ajax request to redirect url\n        \"\"\"\n\n        if request.is_ajax() and hasattr(request, 'horizon'):\n            queued_msgs = request.horizon['async_messages']\n            if type(response) == http.HttpResponseRedirect:\n                # Drop our messages back into the session as per usual so they\n                # don't disappear during the redirect. Not that we explicitly\n                # use django's messages methods here.\n                for tag, message, extra_tags in queued_msgs:\n                    getattr(django_messages, tag)(request, message, extra_tags)\n                # if response['location'].startswith(settings.LOGOUT_URL):\n                #     redirect_response = http.HttpResponse(status=401)\n                #     # This header is used for handling the logout in JS\n                #     redirect_response['logout'] = True\n                #     if self.logout_reason is not None:\n                #         utils.add_logout_reason(\n                #             request, redirect_response, self.logout_reason)\n                # else:\n                redirect_response = http.HttpResponse()\n                # Use a set while checking if we want a cookie's attributes\n                # copied\n                cookie_keys = set(('max_age', 'expires', 'path', 'domain',\n                                   'secure', 'httponly', 'logout_reason'))\n                # Copy cookies from HttpResponseRedirect towards HttpResponse\n                for cookie_name, cookie in six.iteritems(response.cookies):\n                    cookie_kwargs = dict((\n                        (key, value) for key, value in six.iteritems(cookie)\n                        if key in cookie_keys and value\n                    ))\n                    redirect_response.set_cookie(\n                        cookie_name, cookie.value, **cookie_kwargs)\n                redirect_response['X-Horizon-Location'] = response['location']\n                upload_url_key = 'X-File-Upload-URL'\n                if upload_url_key in response:\n                    self.copy_headers(response, redirect_response,\n                                      (upload_url_key, 'X-Auth-Token'))\n                return redirect_response\n            if queued_msgs:\n                # TODO(gabriel): When we have an async connection to the\n                # client (e.g. websockets) this should be pushed to the\n                # socket queue rather than being sent via a header.\n                # The header method has notable drawbacks (length limits,\n                # etc.) and is not meant as a long-term solution.\n                response['X-Horizon-Messages'] = json.dumps(queued_msgs)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_exception(self, request, exception):\n\n        if isinstance(exception, (exceptions.NotAuthorized,\n                                  exceptions.NotAuthenticated)):\n            auth_url = settings.LOGIN_URL\n            next_url = None\n            # prevent submiting forms after login and\n            # use http referer\n            if request.method in (\"POST\", \"PUT\"):\n\n                referrer = request.META.get('HTTP_REFERER')\n\n                if referrer and is_safe_url(referrer, request.get_host()):\n                    next_url = referrer\n\n            if not next_url:\n                next_url = iri_to_uri(request.get_full_path())\n\n            if next_url != auth_url:\n                field_name = REDIRECT_FIELD_NAME\n            else:\n                field_name = None\n\n            login_url = request.build_absolute_uri(auth_url)\n            response = redirect_to_login(next_url, login_url=login_url,\n                                         redirect_field_name=field_name)\n            if isinstance(exception, exceptions.NotAuthorized):\n                logout_reason = _(\"Unauthorized. Please try logging in again.\")\n                utils.add_logout_reason(request, response, logout_reason)\n                # delete messages, created in get_data() method\n                # since we are going to redirect user to the login page\n                response.delete_cookie('messages')\n\n            if request.is_ajax():\n                response_401 = http.HttpResponse(status=401)\n                response_401['X-Horizon-Location'] = response['location']\n                return response_401\n\n            return response\n\n        # If an internal \"NotFound\" error gets this far, return a real 404.\n        if isinstance(exception, exceptions.NotFound):\n            raise http.Http404(exception)\n\n        if isinstance(exception, exceptions.Http302):\n            # TODO(gabriel): Find a way to display an appropriate message to\n            # the user *on* the login form...\n            return shortcuts.redirect(exception.location)", "response": "Catches internal Horizon exception classes such as NotAuthorized NotAuthenticated and Http302 and handles them gracefully."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nredirecting to the current url of a public file.", "response": "def canonical(request, uploaded_at, file_id):\n    \"\"\"\n    Redirect to the current url of a public file\n    \"\"\"\n    filer_file = get_object_or_404(File, pk=file_id, is_public=True)\n    if (uploaded_at != filer_file.uploaded_at.strftime('%s') or\n            not filer_file.file):\n        raise Http404('No %s matches the given query.' %\n                      File._meta.object_name)\n    return redirect(filer_file.url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_message(keywords, message):\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n    if set(str(exc_value).split(\" \")).issuperset(set(keywords)):\n        exc_value.message = message\n        raise", "response": "Checks an exception for given keywords and raises a new ActionError if the keywords are found."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the switchable form field attributes for the switchable theme form", "response": "def get_switched_form_field_attrs(self, prefix, input_type, name):\n        \"\"\"Creates attribute dicts for the switchable theme form\n        \"\"\"\n        attributes = {'class': 'switched', 'data-switch-on': prefix + 'field'}\n        attributes['data-' + prefix + 'field-' + input_type] = name\n        return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_slug(self):\n        slug = self.cleaned_data.get('slug', None)\n        if slug is None or len(slug) == 0 and 'title' in self.cleaned_data:\n            slug = slugify(self.cleaned_data['title'])\n        return slug", "response": "clean_slug - Removes the slug from the cleaned_data if it is not provided"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns widget object by id", "response": "def get_widget_from_id(id):\n    \"\"\"returns widget object by id\n\n    example web-htmltextwidget-2-2\n    \"\"\"\n\n    res = id.split('-')\n    try:\n        model_cls = apps.get_model(res[0], res[1])\n        obj = model_cls.objects.get(parent=res[2], id=res[3])\n    except:\n        obj = None\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_widget_class_from_id(id):\n\n    res = id.split('-')\n    try:\n        model_cls = apps.get_model(res[1], res[2])\n    except:\n        model_cls = None\n    return model_cls", "response": "returns widget class by id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, request, *args, **kwargs):\n        self.widget = self.get_widget_or_404()\n\n        if not self.widget:\n            LOG.warning('Select2 field was not found, check your CACHE')\n\n        self.term = kwargs.get('term', request.GET.get('term', ''))\n        self.object_list = self.get_queryset()\n        context = self.get_context_data()\n        label_fn = self.widget.label_from_instance if hasattr(\n            self.widget, 'label_from_instance') else smart_text\n\n        return JsonResponse({\n            'results': [\n                {\n                    'text': label_fn(obj),\n                    'id': obj.pk,\n                }\n                for obj in context['object_list']\n            ],\n        })", "response": "Return a list of objects in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing when the entire index for model is updated.", "response": "def index_queryset(self, using=None):\n        \"\"\"Used when the entire index for model is updated.\"\"\"\n\n        kwargs = {\"active\": True}\n\n        # if permissions are enabled then we want only public pages\n        # https://github.com/leonardo-modules/leonardo-module-pagepermissions\n        if hasattr(Page(), 'permissions'):\n            kwargs['permissions__isnull'] = True\n\n        # https://github.com/leonardo-modules/leonardo-page-search\n        if hasattr(Page(), 'search_exclude'):\n            kwargs['search_exclude'] = False\n\n        return self.get_model().objects.filter(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef frontendediting_request_processor(page, request):\n    if 'frontend_editing' not in request.GET:\n        return\n\n    response = HttpResponseRedirect(request.path)\n\n    if request.user.has_module_perms('page'):\n\n        if 'frontend_editing' in request.GET:\n\n            try:\n                enable_fe = int(request.GET['frontend_editing']) > 0\n            except ValueError:\n                enable_fe = False\n\n            if enable_fe:\n                response.set_cookie(str('frontend_editing'), enable_fe)\n                clear_cache()\n            else:\n                response.delete_cookie(str('frontend_editing'))\n                clear_cache()\n    else:\n        response.delete_cookie(str('frontend_editing'))\n\n    # Redirect to cleanup URLs\n    return response", "response": "This is the request processor for frontendediting page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n        '''Check to make sure password fields match.'''\n        data = super(SignupForm, self).clean()\n\n        # basic check for now\n        if 'username' in data:\n            if User.objects.filter(\n                    username=data['username'],\n                    email=data['email']).exists():\n                raise validators.ValidationError(\n                    _('Username or email exists in database.'))\n\n        if 'password' in data:\n            if data['password'] != data.get('confirm_password', None):\n                raise validators.ValidationError(_('Passwords do not match.'))\n            else:\n                data.pop('confirm_password')\n        return data", "response": "Check to make sure password fields match."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Form class for use in the admin add view and change view. This is used by the admin add view and change_view.", "response": "def get_form(self, request, obj=None, **kwargs):\n        \"\"\"\n        Returns a Form class for use in the admin add view. This is used by\n        add_view and change_view.\n        \"\"\"\n        parent_id = request.REQUEST.get('parent_id', None)\n        if parent_id:\n            return FolderForm\n        else:\n            folder_form = super(FolderAdmin, self).get_form(\n                request, obj=None, **kwargs)\n\n            def folder_form_clean(form_obj):\n                cleaned_data = form_obj.cleaned_data\n                folders_with_same_name = Folder.objects.filter(\n                    parent=form_obj.instance.parent,\n                    name=cleaned_data['name'])\n                if form_obj.instance.pk:\n                    folders_with_same_name = folders_with_same_name.exclude(\n                        pk=form_obj.instance.pk)\n                if folders_with_same_name.exists():\n                    raise ValidationError(\n                        'Folder with this name already exists.')\n                return cleaned_data\n\n            # attach clean to the default form rather than defining a new form\n            # class\n            folder_form.clean = folder_form_clean\n            return folder_form"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_form(self, request, form, change):\n        r = form.save(commit=False)\n        parent_id = request.REQUEST.get('parent_id', None)\n        if parent_id:\n            parent = Folder.objects.get(id=parent_id)\n            r.parent = parent\n        return r", "response": "Save a ModelForm and return an unsaved instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride the default response_change method to return a redirect to the directory listing page if the user is trying to edit the object.", "response": "def response_change(self, request, obj):\n        \"\"\"\n        Overrides the default to be able to forward to the directory listing\n        instead of the default change_list_view\n        \"\"\"\n        r = super(FolderAdmin, self).response_change(request, obj)\n        # Code borrowed from django ModelAdmin to determine changelist on the\n        # fly\n        if r['Location']:\n            # it was a successful save\n            if (r['Location'] in ['../'] or\n                    r['Location'] == self._get_post_url(obj)):\n                if obj.parent:\n                    url = reverse('admin:filer-directory_listing',\n                                  kwargs={'folder_id': obj.parent.id})\n                else:\n                    url = reverse('admin:filer-directory_listing-root')\n                url = \"%s%s%s\" % (url, popup_param(request),\n                                  selectfolder_param(request, \"&\"))\n                return HttpResponseRedirect(url)\n            else:\n                # this means it probably was a save_and_continue_editing\n                pass\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride the default delete_view to redirect to the directory view after deletion of a folder.", "response": "def delete_view(self, request, object_id, extra_context=None):\n        \"\"\"\n        Overrides the default to enable redirecting to the directory view after\n        deletion of a folder.\n\n        we need to fetch the object and find out who the parent is\n        before super, because super will delete the object and make it\n        impossible to find out the parent folder to redirect to.\n        \"\"\"\n        parent_folder = None\n        try:\n            obj = self.queryset(request).get(pk=unquote(object_id))\n            parent_folder = obj.parent\n        except self.model.DoesNotExist:\n            obj = None\n\n        r = super(FolderAdmin, self).delete_view(\n            request=request, object_id=object_id,\n            extra_context=extra_context)\n        url = r.get(\"Location\", None)\n        if url in [\"../../../../\", \"../../\"] or url == self._get_post_url(obj):\n            if parent_folder:\n                url = reverse('admin:filer-directory_listing',\n                              kwargs={'folder_id': parent_folder.id})\n            else:\n                url = reverse('admin:filer-directory_listing-root')\n            url = \"%s%s%s\" % (url, popup_param(request),\n                              selectfolder_param(request, \"&\"))\n            return HttpResponseRedirect(url)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary mapping the names of all actions for this ModelAdmin to a tuple of name description for each action.", "response": "def get_actions(self, request):\n        \"\"\"\n        Return a dictionary mapping the names of all actions for this\n        ModelAdmin to a tuple of (callable, name, description) for each action.\n        \"\"\"\n        # If self.actions is explicitly set to None that means that we don't\n        # want *any* actions enabled on this page.\n        if self.actions is None:\n            return OrderedDict()\n\n        actions = []\n\n        # Gather actions from the admin site first\n        for (name, func) in self.admin_site.actions:\n            description = getattr(\n                func, 'short_description', name.replace('_', ' '))\n            actions.append((func, name, description))\n\n        # Then gather them from the model admin and all parent classes,\n        # starting with self and working back up.\n        for klass in self.__class__.mro()[::-1]:\n            class_actions = getattr(klass, 'actions', [])\n            # Avoid trying to iterate over None\n            if not class_actions:\n                continue\n            actions.extend(self.get_action(action) for action in class_actions)\n\n        # get_action might have returned None, so filter any of those out.\n        actions = filter(None, actions)\n\n        # Convert the actions into an OrderedDict keyed by name.\n        actions = OrderedDict(\n            (name, (func, name, desc))\n            for func, name, desc in actions\n        )\n\n        if 'delete_selected' in actions:\n            del actions['delete_selected']\n        return actions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef files_set_public_or_private(self, request, set_public, files_queryset, folders_queryset):\n\n        if not self.has_change_permission(request):\n            raise PermissionDenied\n\n        if request.method != 'POST':\n            return None\n\n        check_files_edit_permissions(request, files_queryset)\n        check_folder_edit_permissions(request, folders_queryset)\n\n        # We define it like that so that we can modify it inside the set_files\n        # function\n        files_count = [0]\n\n        def set_files(files):\n            for f in files:\n                if f.is_public != set_public:\n                    f.is_public = set_public\n                    f.save()\n                    files_count[0] += 1\n\n        def set_folders(folders):\n            for f in folders:\n                set_files(f.files)\n                set_folders(f.children.all())\n\n        set_files(files_queryset)\n        set_folders(folders_queryset)\n\n        if set_public:\n            self.message_user(request, _(\"Successfully disabled permissions for %(count)d files.\") % {\n                \"count\": files_count[0],\n            })\n        else:\n            self.message_user(request, _(\"Successfully enabled permissions for %(count)d files.\") % {\n                \"count\": files_count[0],\n            })\n\n        return None", "response": "Sets the public or private permissions for selected files and folders to clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extra_context(self):\n        from django.conf import settings\n\n        return {\n            \"site_name\": (lambda r: settings.LEONARDO_SITE_NAME\n                          if getattr(settings, 'LEONARDO_SITE_NAME', '') != ''\n                          else settings.SITE_NAME),\n            \"debug\": lambda r: settings.TEMPLATE_DEBUG\n        }", "response": "Add site_name to context\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexpecting Django Conf property", "response": "def get_property(self, key):\n        \"\"\"Expect Django Conf property\"\"\"\n        _key = DJANGO_CONF[key]\n        return getattr(self, _key, CONF_SPEC[_key])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nindicating whater module needs sync.", "response": "def needs_sync(self):\n        \"\"\"Indicates whater module needs templates, static etc.\"\"\"\n\n        affected_attributes = [\n            'css_files', 'js_files',\n            'scss_files', 'widgets']\n\n        for attr in affected_attributes:\n            if len(getattr(self, attr)) > 0:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef demo_paths(self):\n        base_path = os.path.join(self.module.__path__[0], 'demo')\n        paths = []\n        if os.path.isdir(base_path):\n            for item in os.listdir(base_path):\n                # TODO: support examples which is not auto-loaded\n                if not os.path.isdir(os.path.join(base_path, 'examples')):\n                    paths.append(os.path.join(base_path, item))\n        return paths", "response": "returns collected demo paths excluding examples"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_attr(self, name, default=None, fail_silently=True):\n        try:\n            return getattr(self, name)\n        except KeyError:\n            extra_context = getattr(self, \"extra_context\")\n\n            if name in extra_context:\n                value = extra_context[name]\n\n                if callable(value):\n                    return value(request=None)\n\n            return default", "response": "Get an attribute from the extra context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_all_templates(pattern='*.html', ignore_private=True):\n    templates = []\n    template_loaders = flatten_template_loaders(settings.TEMPLATE_LOADERS)\n    for loader_name in template_loaders:\n        module, klass = loader_name.rsplit('.', 1)\n        if loader_name in (\n            'django.template.loaders.app_directories.Loader',\n            'django.template.loaders.filesystem.Loader',\n        ):\n            loader_class = getattr(import_module(module), klass)\n            if getattr(loader_class, '_accepts_engine_in_init', False):\n                loader = loader_class(Engine.get_default())\n            else:\n                loader = loader_class()\n            for dir in loader.get_template_sources(''):\n                for root, dirnames, filenames in os.walk(dir):\n                    for basename in filenames:\n                        if ignore_private and basename.startswith(\"_\"):\n                            continue\n                        filename = os.path.join(root, basename)\n                        rel_filename = filename[len(dir)+1:]\n                        if fnmatch.fnmatch(filename, pattern) or \\\n                           fnmatch.fnmatch(basename, pattern) or \\\n                           fnmatch.fnmatch(rel_filename, pattern):\n                            templates.append(rel_filename)\n        else:\n            LOGGER.debug('%s is not supported' % loader_name)\n    return sorted(set(templates))", "response": "Find all Django templates matching given glob in all TEMPLATE_LOADERS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flatten_template_loaders(templates):\n    for loader in templates:\n        if not isinstance(loader, string_types):\n            for subloader in flatten_template_loaders(loader):\n                yield subloader\n        else:\n            yield loader", "response": "Given a collection of template loaders unwrap them into one flat iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef template_choices(templates, display_names=None, suffix=False):\n    # allow for global template names, as well as usage-local ones.\n    if display_names is None:\n        display_names = getattr(settings, 'TEMPLATEFINDER_DISPLAY_NAMES', {})\n\n    to_space_re = re.compile(r'[^a-zA-Z0-9\\-]+')\n\n    def fix_display_title(template_path):\n        if template_path in display_names:\n            return display_names[template_path]\n        # take the last part from the template path; works even if there is no /\n        lastpart = template_path.rpartition('/')[-1]\n        # take everything to the left of the rightmost . (the file extension)\n        if suffix:\n            lastpart_with_suffix = lastpart\n            return capfirst(lastpart_with_suffix)\n        else:\n            lastpart_minus_suffix = lastpart.rpartition('.')[0]\n            # convert most non-alphanumeric characters into spaces, with the\n            # exception of hyphens.\n            lastpart_spaces = to_space_re.sub(' ', lastpart_minus_suffix)\n        return capfirst(lastpart_spaces)\n\n    return ((template, fix_display_title(template)) for template in templates)", "response": "Given an iterable of templates returns a generator that yields the key - value pairs representing the display text of each template in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef readlines(self, sizehint=None):\n        wrapped = self.wrapped\n        try:\n            readlines = wrapped.readlines\n        except AttributeError:\n            lines = []\n            while 1:\n                line = wrapped.readline()\n                if line:\n                    lines.append(line)\n                else:\n                    break\n            return lines\n        return readlines() if sizehint is None else readlines(sizehint)", "response": "Reads until EOF using : meth : readlines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the file s current position.", "response": "def seek(self, offset, whence=os.SEEK_SET):\n        \"\"\"Sets the file's current position.\n\n        :param offset: the offset to set\n        :type offset: :class:`numbers.Integral`\n        :param whence: see the docs of :meth:`file.seek()`.\n                       default is :const:`os.SEEK_SET`\n\n        \"\"\"\n        self.wrapped.seek(offset, whence)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_context_id():\n    global get_current_context_id\n    if greenlet is not None:\n        if stackless is None:\n            get_current_context_id = greenlet.getcurrent\n            return greenlet.getcurrent()\n        return greenlet.getcurrent(), stackless.getcurrent()\n    elif stackless is not None:\n        get_current_context_id = stackless.getcurrent\n        return stackless.getcurrent()\n    get_current_context_id = _thread.get_ident\n    return _thread.get_ident()", "response": "Identifis which context it is ( greenlet stackless or thread."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef store_context(store):\n    if not isinstance(store, Store):\n        raise TypeError('store must be an instance of sqlalchemy_imageattach.'\n                        'store.Store, not ' + repr(store))\n    push_store_context(store)\n    yield store\n    pop_store_context()", "response": "Context manager that sets the new nested context of the current image storage."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef migrate(session, declarative_base, source, destination):\n    if not isinstance(session, Session):\n        raise TypeError('session must be an instance of sqlalchemy.orm.'\n                        'session.Session, not ' + repr(session))\n    elif not isinstance(declarative_base, DeclarativeMeta):\n        raise TypeError('declarative_base must be an instance of sqlalchemy.'\n                        'ext.declarative.api.DeclarativeMeta, not ' +\n                        repr(declarative_base))\n    elif not isinstance(source, Store):\n        raise TypeError('source must be an instance of sqlalchemy_imageattach'\n                        '.store.Store, not ' + repr(source))\n    elif not isinstance(destination, Store):\n        raise TypeError('destination must be an instance of '\n                        'sqlalchemy_imageattach.store.Store, not ' +\n                        repr(source))\n    classes = set(\n        cls\n        for cls in declarative_base._decl_class_registry.values()\n        if isinstance(cls, type) and issubclass(cls, Image)\n    )\n\n    # FIXME: it's not aware of single table inheritance\n    @MigrationPlan\n    def result():\n        for cls in classes:\n            for instance in migrate_class(session, cls, source, destination):\n                yield instance\n    return result", "response": "Migrate all image data from source storage to destination storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmigrating all image data of cls from source storage to destination storage.", "response": "def migrate_class(session, cls, source, destination):\n    \"\"\"Migrate all image data of ``cls`` from ``source`` storage to\n    ``destination`` storage.  All data in ``source`` storage are *not*\n    deleted.\n\n    It does not execute migration by itself alone.  You need to\n    :meth:`~MigrationPlan.execute()` the plan it returns::\n\n        migrate_class(session, UserPicture, source, destination).execute()\n\n    Or iterate it using :keyword:`for` statement::\n\n        for i in migrate_class(session, UserPicture, source, destination):\n            # i is an image just done migration\n            print(i)\n\n    :param session: SQLAlchemy session\n    :type session: :class:`sqlalchemy.orm.session.Session`\n    :param cls: declarative mapper class\n    :type cls: :class:`sqlalchemy.ext.declarative.api.DeclarativeMeta`\n    :param source: the storage to copy image data from\n    :type source: :class:`~sqlalchemy_imageattach.store.Store`\n    :param destination: the storage to copy image data to\n    :type destination: :class:`~sqlalchemy_imageattach.store.Store`\n    :returns: iterable migration plan which is not executed yet\n    :rtype: :class:`MigrationPlan`\n\n    \"\"\"\n    if not isinstance(session, Session):\n        raise TypeError('session must be an instance of sqlalchemy.orm.'\n                        'session.Session, not ' + repr(session))\n    elif not isinstance(cls, DeclarativeMeta):\n        raise TypeError('cls must be an instance of sqlalchemy.'\n                        'ext.declarative.api.DeclarativeMeta, not ' +\n                        repr(cls))\n    elif not isinstance(source, Store):\n        raise TypeError('source must be an instance of sqlalchemy_imageattach'\n                        '.store.Store, not ' + repr(source))\n    elif not isinstance(destination, Store):\n        raise TypeError('destination must be an instance of '\n                        'sqlalchemy_imageattach.store.Store, not ' +\n                        repr(source))\n\n    @MigrationPlan\n    def result():\n        for instance in session.query(cls):\n            with source.open(instance) as f:\n                destination.store(instance, f)\n                yield instance\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self, callback=None):\n        if callback is None:\n            for _ in self:\n                pass\n        elif not callable(callback):\n            raise TypeError('callback must be callable, not ' +\n                            repr(callback))\n        else:\n            for instance in self:\n                callback(instance)", "response": "Execute the plan.  If optional ``callback`` is present,\n        it is invoked with an :class:`~sqlalchemy_imageattach.entity.Image`\n        instance for every migrated image.\n\n        :param callback: an optional callback that takes\n                         an :class:`~sqlalchemy_imageattach.entity.Image`\n                         instance.  it's called zero or more times\n        :type callback: :class:`~typing.Callable`\\ [[:class:`~.entity.Image`],\n                                                     :const:`None`]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nputting the ``file`` of the image. :param file: the image file to put :type file: file-like object, :class:`file` :param object_type: the object type of the image to put e.g. ``'comics.cover'`` :type object_type: :class:`str` :param object_id: the object identifier number of the image to put :type object_id: :class:`numbers.Integral` :param width: the width of the image to put :type width: :class:`numbers.Integral` :param height: the height of the image to put :type height: :class:`numbers.Integral` :param mimetype: the mimetype of the image to put e.g. ``'image/jpeg'`` :type mimetype: :class:`str` :param reproducible: :const:`True` only if it's reproducible by computing e.g. resized thumbnails. :const:`False` if it cannot be reproduced e.g. original images :type reproducible: :class:`bool` .. note:: This is an abstract method which has to be implemented (overridden) by subclasses. It's not for consumers but implementations, so consumers should use :meth:`store()` method instead of this.", "response": "def put_file(self, file, object_type, object_id, width, height, mimetype,\n                 reproducible):\n        \"\"\"Puts the ``file`` of the image.\n\n        :param file: the image file to put\n        :type file: file-like object, :class:`file`\n        :param object_type: the object type of the image to put\n                            e.g. ``'comics.cover'``\n        :type object_type: :class:`str`\n        :param object_id: the object identifier number of the image to put\n        :type object_id: :class:`numbers.Integral`\n        :param width: the width of the image to put\n        :type width: :class:`numbers.Integral`\n        :param height: the height of the image to put\n        :type height: :class:`numbers.Integral`\n        :param mimetype: the mimetype of the image to put\n                         e.g. ``'image/jpeg'``\n        :type mimetype: :class:`str`\n        :param reproducible: :const:`True` only if it's reproducible by\n                             computing e.g. resized thumbnails.\n                             :const:`False` if it cannot be reproduced\n                             e.g. original images\n        :type reproducible: :class:`bool`\n\n        .. note::\n\n           This is an abstract method which has to be implemented\n           (overridden) by subclasses.\n\n           It's not for consumers but implementations, so consumers\n           should use :meth:`store()` method instead of this.\n\n        \"\"\"\n        raise NotImplementedError('put_file() has to be implemented')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store(self, image, file):\n        from .entity import Image\n        if not isinstance(image, Image):\n            raise TypeError('image must be a sqlalchemy_imageattach.entity.'\n                            'Image instance, not ' + repr(image))\n        elif not callable(getattr(file, 'read', None)):\n            raise TypeError('file must be a readable file-like object that '\n                            'implements read() method, not ' + repr(file))\n        self.put_file(file, image.object_type, image.object_id,\n                      image.width, image.height, image.mimetype,\n                      not image.original)", "response": "Stores the actual data of the given image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the file of the given image.", "response": "def delete(self, image):\n        \"\"\"Delete the file of the given ``image``.\n\n        :param image: the image to delete\n        :type image: :class:`sqlalchemy_imageattach.entity.Image`\n\n        \"\"\"\n        from .entity import Image\n        if not isinstance(image, Image):\n            raise TypeError('image must be a sqlalchemy_imageattach.entity.'\n                            'Image instance, not ' + repr(image))\n        self.delete_file(image.object_type, image.object_id,\n                         image.width, image.height, image.mimetype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open(self, image, use_seek=False):\n        from .entity import Image\n        if not isinstance(image, Image):\n            raise TypeError('image must be a sqlalchemy_imageattach.entity.'\n                            'Image instance, not ' + repr(image))\n        elif image.object_id is None:\n            raise TypeError('image.object_id must be set; it is currently '\n                            'None however')\n        elif not isinstance(image.object_id, numbers.Integral):\n            raise TypeError('image.object_id must be integer, not ' +\n                            repr(image.object_id))\n        f = self.get_file(image.object_type, image.object_id,\n                          image.width, image.height, image.mimetype)\n        for method in 'read', 'readline', 'readlines':\n            if not callable(getattr(f, method, None)):\n                raise TypeError(\n                    '{0!r}.get_file() must return file-like object which '\n                    'has {1}() method, not {2!r}'.format(self, method, f)\n                )\n        ctxt = (callable(getattr(f, '__enter__', None)) and\n                callable(getattr(f, '__exit__', None)))\n        if use_seek:\n            if not callable(getattr(f, 'seek', None)):\n                f2 = io.BytesIO()\n                shutil.copyfileobj(f, f2)\n                f2.seek(0)\n                return f2\n            if ctxt:\n                return f\n            return SeekableFileProxy(f)\n        if ctxt:\n            return f\n        return FileProxy(f)", "response": "Opens the file - like object of the given image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the URL of the given image.", "response": "def locate(self, image):\n        \"\"\"Gets the URL of the given ``image``.\n\n        :param image: the image to get its url\n        :type image: :class:`sqlalchemy_imageattach.entity.Image`\n        :returns: the url of the image\n        :rtype: :class:`str`\n\n        \"\"\"\n        from .entity import Image\n        if not isinstance(image, Image):\n            raise TypeError('image must be a sqlalchemy_imageattach.entity.'\n                            'Image instance, not ' + repr(image))\n        url = self.get_url(image.object_type, image.object_id,\n                           image.width, image.height, image.mimetype)\n        if '?' in url:\n            fmt = '{0}&_ts={1}'\n        else:\n            fmt = '{0}?_ts={1}'\n        return fmt.format(url, image.created_at.strftime('%Y%m%d%H%M%S%f'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_minimum_indent(docstring, ignore_before=1):\n    indent_re = re.compile(r'^\\s*')\n    indents = [indent_re.match(line).group(0)\n               for line in docstring.splitlines()[ignore_before:]\n               if line.strip()]\n    return min(indents, key=len) if indents else ''", "response": "r Gets the minimum indent string from the docstring."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef append_docstring(docstring, *lines):\n    shallowest = get_minimum_indent(docstring)\n    appender = []\n    for line in lines:\n        appender.append('\\n')\n        if line.strip():\n            appender.append(shallowest)\n            appender.append(line)\n    return docstring + ''.join(appender)", "response": "Appends the docstring with given lines of trailing docstring."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the identifier number of the image.", "response": "def object_id(self):\n        \"\"\"(:class:`numbers.Integral`) The identifier number of the image.\n        It uses the primary key if it's integer, but can be overridden,\n        and must be implemented when the primary key is not integer or\n        composite key.\n\n        .. versionchanged:: 1.1.0\n           Since 1.1.0, it provides a more default implementation for\n           :class:`~uuid.UUID` primary keys.  If a primary key is not\n           composite and :class:`~uuid.UUID` type, :attr:`object_id\n           <sqlalchemy_imageattach.entity.Image.object_id>` for that doesn't\n           have to be implemented.\n\n        \"\"\"\n        pk = self.identity_attributes()\n        if len(pk) == 1:\n            pk_value = getattr(self, pk[0])\n            if isinstance(pk_value, numbers.Integral):\n                return pk_value\n            elif isinstance(pk_value, uuid.UUID):\n                return pk_value.int\n        raise NotImplementedError('object_id property has to be implemented')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef identity_attributes(cls):\n        columns = inspect(cls).primary_key\n        names = [c.name for c in columns if c.name not in ('width', 'height')]\n        return names", "response": "A list of the names of primary key fields."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef identity_map(self):\n        pk = self.identity_attributes()\n        values = {}\n        for name in pk:\n            values[name] = getattr(self, name)\n        return values", "response": "Returns a dictionary of the values of primary key fields with their names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the byte string of the image from the store.", "response": "def make_blob(self, store=current_store):\n        \"\"\"Gets the byte string of the image from the ``store``.\n\n        :param store: the storage which contains the image.\n                      :data:`~sqlalchemy_imageattach.context.current_store`\n                      by default\n        :type store: :class:`~sqlalchemy_imageattach.store.Store`\n        :returns: the binary data of the image\n        :rtype: :class:`str`\n\n        \"\"\"\n        with self.open_file(store) as f:\n            return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_file(self, store=current_store, use_seek=False):\n        if not isinstance(store, Store):\n            raise TypeError('store must be an instance of '\n                            'sqlalchemy_imageattach.store.Store, not ' +\n                            repr(store))\n\n        if Session.object_session(self) is None:\n            try:\n                file = self.file\n            except AttributeError:\n                raise IOError('no stored original image file')\n            return ReusableFileProxy(file)\n\n        return store.open(self, use_seek)", "response": "Opens the file - like object which is a context manager which can only be seekable if use_seek is True."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef locate(self, store=current_store):\n        if not isinstance(store, Store):\n            raise TypeError('store must be an instance of '\n                            'sqlalchemy_imageattach.store.Store, not ' +\n                            repr(store))\n        return store.locate(self)", "response": "Gets the URL of the image from the store."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the files of the images that were deleted from the store and clears the set .", "response": "def _images_failed(cls, session, previous_transaction):\n        \"\"\"Deletes the files of :attr:`_stored_images` back and clears\n        the :attr:`_stored_images` and :attr:`_deleted_images` set\n        when the ongoing transaction has done rollback.\n\n        \"\"\"\n        for image, store in cls._stored_images:\n            store.delete(image)\n        cls._stored_images.clear()\n        cls._deleted_images.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear the set of actual files that have been marked as deleted in the storage and deletes the actual files that have been marked as deleted in the storage .", "response": "def _images_succeeded(cls, session):\n        \"\"\"Clears the :attr:`_stored_images` set and deletes actual\n        files that are marked as deleted in the storage\n        if the ongoing transaction has committed.\n\n        \"\"\"\n        for image, store in cls._deleted_images:\n            for stored_image, _ in cls._stored_images:\n                if stored_image.object_type == image.object_type and \\\n                   stored_image.object_id == image.object_id and \\\n                   stored_image.width == image.width and \\\n                   stored_image.height == image.height and \\\n                   stored_image.mimetype == image.mimetype:\n                    break\n            else:\n                store.delete(image)\n        cls._stored_images.clear()\n        cls._deleted_images.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_raw_file(self, raw_file, store=current_store, size=None,\n                      mimetype=None, original=True, extra_args=None,\n                      extra_kwargs=None):\n        \"\"\"Similar to :meth:`from_file()` except it's lower than that.\n        It assumes that ``raw_file`` is readable and seekable while\n        :meth:`from_file()` only assumes the file is readable.\n        Also it doesn't make any in-memory buffer while\n        :meth:`from_file()` always makes an in-memory buffer and copy\n        the file into the buffer.\n\n        If ``size`` and ``mimetype`` are passed, it won't try to read\n        image and will use these values instead.\n\n        It's used for implementing :meth:`from_file()` and\n        :meth:`from_blob()` methods that are higher than it.\n\n        :param raw_file: the seekable and readable file of the image\n        :type raw_file: file-like object, :class:`file`\n        :param store: the storage to store the file.\n                      :data:`~sqlalchemy_imageattach.context.current_store`\n                      by default\n        :type store: :class:`~sqlalchemy_imageattach.store.Store`\n        :param size: an optional size of the image.\n                     automatically detected if it's omitted\n        :type size: :class:`tuple`\n        :param mimetype: an optional mimetype of the image.\n                         automatically detected if it's omitted\n        :type mimetype: :class:`str`\n        :param original: an optional flag which represents whether\n                         it is an original image or not.\n                         defualt is :const:`True` (meaning original)\n        :type original: :class:`bool`\n        :param extra_args: additional arguments to pass to the model's\n                           constructor.\n        :type extra_args: :class:`collections.abc.Sequence`\n        :param extra_kwargs: additional keyword arguments to pass to the\n                             model's constructor.\n        :type extra_kwargs: :class:`typing.Mapping`\\ [:class:`str`,\n                                                      :class:`object`]\n        :returns: the created image instance\n        :rtype: :class:`Image`\n\n        .. versionadded:: 1.0.0\n           The ``extra_args`` and ``extra_kwargs`` options.\n\n        \"\"\"\n        query = self.query\n        cls = query.column_descriptions[0]['type']\n        if not (isinstance(cls, type) and issubclass(cls, Image)):\n            raise TypeError('the first entity must be a subtype of '\n                            'sqlalchemy_imageattach.entity.Image')\n\n        if original and query.session:\n            if store is current_store:\n                for existing in query:\n                    test_data = existing.identity_map.copy()\n                    test_data.update(self.identity_map)\n                    if existing.identity_map == test_data:\n                        query.remove(existing)\n                query.session.flush()\n            else:\n                with store_context(store):\n                    for existing in query:\n                        test_data = existing.identity_map.copy()\n                        test_data.update(self.identity_map)\n                        if existing.identity_map == test_data:\n                            query.remove(existing)\n                    query.session.flush()\n        if size is None or mimetype is None:\n            with WandImage(file=raw_file) as wand:\n                size = size or wand.size\n                mimetype = mimetype or wand.mimetype\n        if mimetype.startswith('image/x-'):\n            mimetype = 'image/' + mimetype[8:]\n\n        if extra_kwargs is None:\n            extra_kwargs = {}\n        extra_kwargs.update(self.identity_map)\n\n        if extra_args is None:\n            extra_args = ()\n\n        image = cls(size=size, mimetype=mimetype, original=original,\n                    *extra_args, **extra_kwargs)\n        raw_file.seek(0)\n        image.file = raw_file\n        image.store = store\n        query.append(image)\n        return image", "response": "Creates an image from a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_blob(self, blob, store=current_store,\n                  extra_args=None, extra_kwargs=None):\n        \"\"\"Stores the ``blob`` (byte string) for the image\n        into the ``store``.\n\n        :param blob: the byte string for the image\n        :type blob: :class:`str`\n        :param store: the storage to store the image data.\n                      :data:`~sqlalchemy_imageattach.context.current_store`\n                      by default\n        :type store: :class:`~sqlalchemy_imageattach.store.Store`\n        :param extra_args: additional arguments to pass to the model's\n                           constructor.\n        :type extra_args: :class:`collections.abc.Sequence`\n        :param extra_kwargs: additional keyword arguments to pass to the\n                             model's constructor.\n        :type extra_kwargs: :class:`typing.Mapping`\\ [:class:`str`,\n                                                      :class:`object`]\n        :returns: the created image instance\n        :rtype: :class:`Image`\n\n        .. versionadded:: 1.0.0\n           The ``extra_args`` and ``extra_kwargs`` options.\n\n        \"\"\"\n        data = io.BytesIO(blob)\n        return self.from_raw_file(data, store, original=True,\n                                  extra_args=extra_args,\n                                  extra_kwargs=extra_kwargs)", "response": "Creates an image from a blob."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_file(self, file, store=current_store,\n                  extra_args=None, extra_kwargs=None):\n        \"\"\"Stores the ``file`` for the image into the ``store``.\n\n        :param file: the readable file of the image\n        :type file: file-like object, :class:`file`\n        :param store: the storage to store the file.\n                      :data:`~sqlalchemy_imageattach.context.current_store`\n                      by default\n        :type store: :class:`~sqlalchemy_imageattach.store.Store`\n        :param extra_args: additional arguments to pass to the model's\n                           constructor.\n        :type extra_args: :class:`collections.abc.Sequence`\n        :param extra_kwargs: additional keyword arguments to pass to the\n                             model's constructor.\n        :type extra_kwargs: :class:`typing.Mapping`\\ [:class:`str`,\n                                                      :class:`object`]\n        :returns: the created image instance\n        :rtype: :class:`Image`\n\n        .. versionadded:: 1.0.0\n           The ``extra_args`` and ``extra_kwargs`` options.\n\n        \"\"\"\n\n        if isinstance(file, cgi.FieldStorage):\n            file = file.file\n\n        data = io.BytesIO()\n        shutil.copyfileobj(file, data)\n        data.seek(0)\n        return self.from_raw_file(data, store, original=True,\n                                  extra_args=extra_args,\n                                  extra_kwargs=extra_kwargs)", "response": "Stores the file for the image into the store."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a resized thumbnail image.", "response": "def generate_thumbnail(self, ratio=None, width=None, height=None,\n                           filter='undefined', store=current_store,\n                           _preprocess_image=None, _postprocess_image=None):\n        \"\"\"Resizes the :attr:`original` (scales up or down) and\n        then store the resized thumbnail into the ``store``.\n\n        :param ratio: resize by its ratio.  if it's greater than 1\n                      it scales up, and if it's less than 1 it scales\n                      down.  exclusive for ``width`` and ``height``\n                      parameters\n        :type ratio: :class:`numbers.Real`\n        :param width: resize by its width.  exclusive for ``ratio``\n                      and ``height`` parameters\n        :type width: :class:`numbers.Integral`\n        :param height: resize by its height.  exclusive for ``ratio``\n                       and ``width`` parameters\n        :type height: :class:`numbers.Integral`\n        :param filter: a filter type to use for resizing.  choose one in\n                       :const:`wand.image.FILTER_TYPES`.  default is\n                       ``'undefined'`` which means ImageMagick will try\n                       to guess best one to use\n        :type filter: :class:`str`, :class:`numbers.Integral`\n        :param store: the storage to store the resized image file.\n                      :data:`~sqlalchemy_imageattach.context.current_store`\n                      by default\n        :type store: :class:`~sqlalchemy_imageattach.store.Store`\n        :param _preprocess_image: internal-use only option for preprocessing\n                                  original image before resizing\n        :type _preprocess_image:\n            :class:`typing.Callable`\\ [[:class:`wand.image.Image`],\n                                        :class:`wand.image.Image`]\n        :param _postprocess_image: internal-use only option for preprocessing\n                                   original image before resizing\n        :type _postprocess_image:\n            :class:`typing.Callable`\\ [[:class:`wand.image.Image`],\n                                        :class:`wand.image.Image`]\n        :returns: the resized thumbnail image.  it might be an already\n                  existing image if the same size already exists\n        :rtype: :class:`Image`\n        :raise IOError: when there's no :attr:`original` image yet\n\n        \"\"\"\n        params = ratio, width, height\n        param_count = sum(p is not None for p in params)\n        if not param_count:\n            raise TypeError('pass an argument ratio, width, or height')\n        elif param_count > 1:\n            raise TypeError('pass only one argument in ratio, width, or '\n                            'height; these parameters are exclusive for '\n                            'each other')\n\n        query = self.query\n        transient = Session.object_session(query.instance) is None\n        state = instance_state(query.instance)\n        try:\n            added = state.committed_state[query.attr.key].added_items\n        except KeyError:\n            added = []\n        if width is not None:\n            if not isinstance(width, numbers.Integral):\n                raise TypeError('width must be integer, not ' + repr(width))\n            elif width < 1:\n                raise ValueError('width must be natural number, not ' +\n                                 repr(width))\n            # find the same-but-already-generated thumbnail\n            for image in added:\n                if image.width == width:\n                    return image\n            if not transient:\n                q = query.filter_by(width=width)\n                try:\n                    return q.one()\n                except NoResultFound:\n                    pass\n\n            def height(sz):\n                return sz[1] * (width / sz[0])\n        elif height is not None:\n            if not isinstance(height, numbers.Integral):\n                raise TypeError('height must be integer, not ' + repr(height))\n            elif height < 1:\n                raise ValueError('height must be natural number, not ' +\n                                 repr(height))\n            # find the same-but-already-generated thumbnail\n            for image in added:\n                if image.height == height:\n                    return image\n            if not transient:\n                q = query.filter_by(height=height)\n                try:\n                    return q.one()\n                except NoResultFound:\n                    pass\n\n            def width(sz):\n                return sz[0] * (height / sz[1])\n        elif ratio is not None:\n            if not isinstance(ratio, numbers.Real):\n                raise TypeError('ratio must be an instance of numbers.Real, '\n                                'not ' + repr(ratio))\n\n            def width(sz):\n                return sz[0] * ratio\n\n            def height(sz):\n                return sz[1] * ratio\n        data = io.BytesIO()\n        image = self.require_original()\n        with image.open_file(store=store) as f:\n            if _preprocess_image is None:\n                img = WandImage(file=f)\n            else:\n                with WandImage(file=f) as img:\n                    img = _preprocess_image(img)\n            with img:\n                if img.mimetype in VECTOR_TYPES:\n                    img.format = 'png'\n                original_size = img.size\n                if callable(width):\n                    width = width(original_size)\n                if callable(height):\n                    height = height(original_size)\n                width = int(width)\n                height = int(height)\n                # find the same-but-already-generated thumbnail\n                for image in added:\n                    if image.width == width and image.height == height:\n                        return image\n                if not transient:\n                    q = query.filter_by(width=width, height=height)\n                    try:\n                        return q.one()\n                    except NoResultFound:\n                        pass\n                if len(img.sequence) > 1:\n                    img_ctx = img.sequence[0].clone()\n                    img_ctx.resize(width, height, filter=filter)\n                    img_ctx.strip()\n                else:\n                    img_ctx = NoopContext(img)\n                with img_ctx as single_img:\n                    single_img.resize(width, height, filter=filter)\n                    single_img.strip()\n                    if _postprocess_image is None:\n                        mimetype = img.mimetype\n                        single_img.save(file=data)\n                    else:\n                        with _postprocess_image(img) as img:\n                            mimetype = img.mimetype\n                            single_img.save(file=data)\n        return self.from_raw_file(data, store,\n                                  size=(width, height),\n                                  mimetype=mimetype,\n                                  original=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the original image.", "response": "def original(self):\n        \"\"\"(:class:`Image`) The original image.  It could be :const:`None`\n        if there are no stored images yet.\n\n        \"\"\"\n        images = self.query._original_images(**self.identity_map)\n        if images:\n            return images[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_thumbnail(self, width=None, height=None):\n        if width is None and height is None:\n            raise TypeError('required width and/or height')\n        q = self\n        if width is not None:\n            q = q.filter_by(width=width)\n        if height is not None:\n            q = q.filter_by(height=height)\n        try:\n            return q.one()\n        except NoResultFound:\n            if width is not None and height is not None:\n                msg = 'size: ' + repr((width, height))\n            elif width is not None:\n                msg = 'width: ' + repr(width)\n            else:\n                msg = 'height: ' + repr(height)\n            raise NoResultFound('no thumbnail image of such ' + msg)", "response": "Finds the thumbnail of the image with the given width and height."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image_sets(self):\n        images = self._original_images()\n        for image in images:\n            yield ImageSubset(self, **image.identity_map)", "response": "Returns an iterable of ImageSubset objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wsgi_middleware(self, app, cors=False):\n        _app = StaticServerMiddleware(app, '/' + self.prefix, self.path,\n                                      cors=self.cors)\n\n        def app(environ, start_response):\n            if not hasattr(self, 'host_url'):\n                self.host_url = (environ['wsgi.url_scheme'] + '://' +\n                                 environ['HTTP_HOST'] + '/')\n            return _app(environ, start_response)\n        return app", "response": "WSGI middleware that wraps the given app and serves\n        actual image files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all Entities and Components from the World.", "response": "def clear_database(self) -> None:\n        \"\"\"Remove all Entities and Components from the World.\"\"\"\n        self._next_entity_id = 0\n        self._dead_entities.clear()\n        self._components.clear()\n        self._entities.clear()\n        self.clear_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a Processor instance to the World.", "response": "def add_processor(self, processor_instance: Processor, priority=0) -> None:\n        \"\"\"Add a Processor instance to the World.\n\n        :param processor_instance: An instance of a Processor,\n        subclassed from the Processor class\n        :param priority: A higher number is processed first.\n        \"\"\"\n        assert issubclass(processor_instance.__class__, Processor)\n        processor_instance.priority = priority\n        processor_instance.world = self\n        self._processors.append(processor_instance)\n        self._processors.sort(key=lambda proc: proc.priority, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a Processor from the World by type.", "response": "def remove_processor(self, processor_type: Processor) -> None:\n        \"\"\"Remove a Processor from the World, by type.\n\n        :param processor_type: The class type of the Processor to remove.\n        \"\"\"\n        for processor in self._processors:\n            if type(processor) == processor_type:\n                processor.world = None\n                self._processors.remove(processor)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_processor(self, processor_type: Type[P]) -> P:\n        for processor in self._processors:\n            if type(processor) == processor_type:\n                return processor", "response": "Get a Processor instance by type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Entity.", "response": "def create_entity(self, *components) -> int:\n        \"\"\"Create a new Entity.\n\n        This method returns an Entity ID, which is just a plain integer.\n        You can optionally pass one or more Component instances to be\n        assigned to the Entity.\n\n        :param components: Optional components to be assigned to the\n        entity on creation.\n        :return: The next Entity ID in sequence.\n        \"\"\"\n        self._next_entity_id += 1\n\n        # TODO: duplicate add_component code here for performance\n        for component in components:\n            self.add_component(self._next_entity_id, component)\n\n        # self.clear_cache()\n        return self._next_entity_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_entity(self, entity: int, immediate=False) -> None:\n        if immediate:\n            for component_type in self._entities[entity]:\n                self._components[component_type].discard(entity)\n\n                if not self._components[component_type]:\n                    del self._components[component_type]\n\n            del self._entities[entity]\n            self.clear_cache()\n\n        else:\n            self._dead_entities.add(entity)", "response": "Deletes an Entity from the World."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves a Component instance for a specific Entity.", "response": "def component_for_entity(self, entity: int, component_type: Type[C]) -> C:\n        \"\"\"Retrieve a Component instance for a specific Entity.\n\n        Retrieve a Component instance for a specific Entity. In some cases,\n        it may be necessary to access a specific Component instance.\n        For example: directly modifying a Component to handle user input.\n\n        Raises a KeyError if the given Entity and Component do not exist.\n        :param entity: The Entity ID to retrieve the Component for.\n        :param component_type: The Component instance you wish to retrieve.\n        :return: The Component instance requested for the given Entity ID.\n        \"\"\"\n        return self._entities[entity][component_type]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves all Components for a specific Entity as a Tuple.", "response": "def components_for_entity(self, entity: int) -> Tuple[C, ...]:\n        \"\"\"Retrieve all Components for a specific Entity, as a Tuple.\n\n        Retrieve all Components for a specific Entity. The method is probably\n        not appropriate to use in your Processors, but might be useful for\n        saving state, or passing specific Components between World instances.\n        Unlike most other methods, this returns all of the Components as a\n        Tuple in one batch, instead of returning a Generator for iteration.\n\n        Raises a KeyError if the given entity does not exist in the database.\n        :param entity: The Entity ID to retrieve the Components for.\n        :return: A tuple of all Component instances that have been\n        assigned to the passed Entity ID.\n        \"\"\"\n        return tuple(self._entities[entity].values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_component(self, entity: int, component_type: Any) -> bool:\n        return component_type in self._entities[entity]", "response": "Check if a specific Entity has a Component of a certain type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_component(self, entity: int, component_instance: Any) -> None:\n        component_type = type(component_instance)\n\n        if component_type not in self._components:\n            self._components[component_type] = set()\n\n        self._components[component_type].add(entity)\n\n        if entity not in self._entities:\n            self._entities[entity] = {}\n\n        self._entities[entity][component_type] = component_instance\n        self.clear_cache()", "response": "Add a new Component instance to an Entity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_component(self, entity: int, component_type: Any) -> int:\n        self._components[component_type].discard(entity)\n\n        if not self._components[component_type]:\n            del self._components[component_type]\n\n        del self._entities[entity][component_type]\n\n        if not self._entities[entity]:\n            del self._entities[entity]\n\n        self.clear_cache()\n        return entity", "response": "Removes a Component instance from an Entity by type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an iterator for Entity and Component pairs.", "response": "def _get_component(self, component_type: Type[C]) -> Iterable[Tuple[int, C]]:\n        \"\"\"Get an iterator for Entity, Component pairs.\n\n        :param component_type: The Component type to retrieve.\n        :return: An iterator for (Entity, Component) tuples.\n        \"\"\"\n        entity_db = self._entities\n\n        for entity in self._components.get(component_type, []):\n            yield entity, entity_db[entity][component_type]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an iterator for Entity and multiple Component sets.", "response": "def _get_components(self, *component_types: Type)-> Iterable[Tuple[int, ...]]:\n        \"\"\"Get an iterator for Entity and multiple Component sets.\n\n        :param component_types: Two or more Component types.\n        :return: An iterator for Entity, (Component1, Component2, etc)\n        tuples.\n        \"\"\"\n        entity_db = self._entities\n        comp_db = self._components\n\n        try:\n            for entity in set.intersection(*[comp_db[ct] for ct in component_types]):\n                yield entity, [entity_db[entity][ct] for ct in component_types]\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef try_component(self, entity: int, component_type: Type):\n            if component_type in self._entities[entity]:\n                yield self._entities[entity][component_type]\n            else:\n                return None", "response": "Try to get a single Component instance for an Entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinalizing deletion of any Entities that are marked dead.", "response": "def _clear_dead_entities(self):\n        \"\"\"Finalize deletion of any Entities that are marked dead.\n        \n        In the interest of performance, this method duplicates code from the\n        `delete_entity` method. If that method is changed, those changes should\n        be duplicated here as well.\n        \"\"\"\n        for entity in self._dead_entities:\n\n            for component_type in self._entities[entity]:\n                self._components[component_type].discard(entity)\n\n                if not self._components[component_type]:\n                    del self._components[component_type]\n\n            del self._entities[entity]\n\n        self._dead_entities.clear()\n        self.clear_cache()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntracks Processor execution time for benchmarking.", "response": "def _timed_process(self, *args, **kwargs):\n        \"\"\"Track Processor execution time for benchmarking.\"\"\"\n        for processor in self._processors:\n            start_time = _time.process_time()\n            processor.process(*args, **kwargs)\n            process_time = int(round((_time.process_time() - start_time) * 1000, 2))\n            self.process_times[processor.__class__.__name__] = process_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process(self, *args, **kwargs):\n        self._clear_dead_entities()\n        self._process(*args, **kwargs)", "response": "Calls the process method on all assigned Processors in order of their priority."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef texture_from_image(renderer, image_name):\n    soft_surface = ext.load_image(image_name)\n    texture = SDL_CreateTextureFromSurface(renderer.renderer, soft_surface)\n    SDL_FreeSurface(soft_surface)\n    return texture", "response": "Create an SDL2 Texture from an image file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets up the SDSS tree enviroment", "response": "def setup_tree(ctx, verbose=None, root=None, tree_dir=None, modules_dir=None):\n    ''' Sets up the SDSS tree enviroment '''\n    print('Setting up the tree')\n    ctx.run('python bin/setup_tree.py -t {0} -r {1} -m {2}'.format(tree_dir, root, modules_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_roots(self, uproot_with=None):\n        ''' Set the roots of the tree in the os environment\n\n        Parameters:\n            uproot_with (str):\n                A new TREE_DIR path used to override an existing TREE_DIR environment variable\n\n        '''\n\n        # Check for TREE_DIR\n        self.treedir = os.environ.get('TREE_DIR', None) if not uproot_with else uproot_with\n        if not self.treedir:\n            treefilepath = os.path.dirname(os.path.abspath(__file__))\n            if 'python/' in treefilepath:\n                self.treedir = treefilepath.rsplit('/', 2)[0]\n            else:\n                self.treedir = treefilepath\n            self.treedir = treefilepath\n            os.environ['TREE_DIR'] = self.treedir\n\n        # Check sas_base_dir\n        if 'SAS_BASE_DIR' in os.environ:\n            self.sasbasedir = os.environ[\"SAS_BASE_DIR\"]\n        else:\n            self.sasbasedir = os.path.expanduser('~/sas')\n\n        # make the directories\n        if not os.path.isdir(self.sasbasedir):\n            os.makedirs(self.sasbasedir)", "response": "Set the roots of the tree in the os environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a manual config file and sets the environment variables to the local tree environment variables.", "response": "def load_config(self, config=None):\n        ''' loads a config file\n\n        Parameters:\n            config (str):\n                Optional name of manual config file to load\n        '''\n\n        # Read the config file\n        cfgname = (config or self.config_name)\n        cfgname = 'sdsswork' if cfgname is None else cfgname\n        assert isinstance(cfgname, six.string_types), 'config name must be a string'\n        config_name = cfgname if cfgname.endswith('.cfg') else '{0}.cfg'.format(cfgname)\n        self.configfile = os.path.join(self.treedir, 'data', config_name)\n\n        assert os.path.isfile(self.configfile) is True, 'configfile {0} must exist in the proper directory'.format(self.configfile)\n\n        self._cfg = SafeConfigParser()\n\n        try:\n            self._cfg.read(self.configfile.decode('utf-8'))\n        except AttributeError:\n            self._cfg.read(self.configfile)\n\n        # create the local tree environment\n        self.environ = OrderedDict()\n        self.environ['default'] = self._cfg.defaults()\n        # set the filesystem envvar to sas_base_dir\n        self._file_replace = '@FILESYSTEM@'\n        if self.environ['default']['filesystem'] == self._file_replace:\n            self.environ['default']['filesystem'] = self.sasbasedir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef branch_out(self, limb=None):\n        ''' Set the individual section branches\n\n        This adds the various sections of the config file into the\n        tree environment for access later. Optically can specify a specific\n        branch.  This does not yet load them into the os environment.\n\n        Parameters:\n            limb (str/list):\n                The name of the section of the config to add into the environ\n                or a list of strings\n\n        '''\n\n        # Filter on sections\n        if not limb:\n            limbs = self._cfg.sections()\n        else:\n            # we must have the general always + secton\n            limb = limb if isinstance(limb, list) else [limb]\n            limbs = ['general']\n            limbs.extend(limb)\n\n        # add all limbs into the tree environ\n        for leaf in limbs:\n            leaf = leaf if leaf in self._cfg.sections() else leaf.upper()\n            self.environ[leaf] = OrderedDict()\n            options = self._cfg.options(leaf)\n\n            for opt in options:\n                if opt in self.environ['default']:\n                    continue\n                val = self._cfg.get(leaf, opt)\n                if val.find(self._file_replace) == 0:\n                    val = val.replace(self._file_replace, self.sasbasedir)\n                self.environ[leaf][opt] = val", "response": "Set the individual section branches\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_limbs(self, key=None):\n        ''' Add a new section from the tree into the existing os environment\n\n        Parameters:\n            key (str):\n                The section name to grab from the environment\n\n        '''\n        self.branch_out(limb=key)\n        self.add_paths_to_os(key=key)", "response": "Add a new section from the tree into the os environment"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a set of environment paths from the config file.", "response": "def get_paths(self, key):\n        ''' Retrieve a set of environment paths from the config\n\n        Parameters:\n            key (str):\n                The section name to grab from the environment\n\n        Returns:\n            self.environ[newkey] (OrderedDict):\n                An ordered dict containing all of the paths from the\n                specified section, as key:val = name:path\n        '''\n        newkey = key if key in self.environ else key.upper() if key.upper() \\\n            in self.environ else None\n        if newkey:\n            return self.environ[newkey]\n        else:\n            raise KeyError('Key {0} not found in tree environment'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the paths in tree environ into the os environ", "response": "def add_paths_to_os(self, key=None, update=None):\n        ''' Add the paths in tree environ into the os environ\n\n        This code goes through the tree environ and checks\n        for existence in the os environ, then adds them\n\n        Parameters:\n            key (str):\n                The section name to check against / add\n            update (bool):\n                If True, overwrites existing tree environment variables in your\n                local environment.  Default is False.\n        '''\n\n        if key is not None:\n            allpaths = key if isinstance(key, list) else [key]\n        else:\n            allpaths = [k for k in self.environ.keys() if 'default' not in k]\n\n        for key in allpaths:\n            paths = self.get_paths(key)\n            self.check_paths(paths, update=update)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the path is in the os environ and if not add it", "response": "def check_paths(self, paths, update=None):\n        ''' Check if the path is in the os environ, and if not add it\n\n        Paramters:\n            paths (OrderedDict):\n                An ordered dict containing all of the paths from the\n                a given section, as key:val = name:path\n            update (bool):\n                If True, overwrites existing tree environment variables in your\n                local environment.  Default is False.\n        '''\n\n        # set up the exclusion list\n        exclude = [] if not self.exclude else self.exclude \\\n            if isinstance(self.exclude, list) else [self.exclude]\n\n        # check the path names\n        for pathname, path in paths.items():\n            if update and pathname.upper() not in exclude:\n                os.environ[pathname.upper()] = os.path.normpath(path)\n            elif pathname.upper() not in os.environ:\n                os.environ[pathname.upper()] = os.path.normpath(path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_exception_formatted(type, value, tb):\n\n    tbtext = ''.join(traceback.format_exception(type, value, tb))\n    lexer = get_lexer_by_name('pytb', stripall=True)\n    formatter = TerminalFormatter()\n    sys.stderr.write(highlight(tbtext, lexer, formatter))", "response": "A custom hook for printing tracebacks with colours."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint log messages with colours.", "response": "def colored_formatter(record):\n    \"\"\"Prints log messages with colours.\"\"\"\n\n    colours = {'info': ('blue', 'normal'),\n               'debug': ('magenta', 'normal'),\n               'warning': ('yellow', 'normal'),\n               'print': ('green', 'normal'),\n               'error': ('red', 'bold')}\n\n    levelname = record.levelname.lower()\n\n    if levelname == 'error':\n        return\n\n    if levelname.lower() in colours:\n        levelname_color = colours[levelname][0]\n        header = color_text('[{}]: '.format(levelname.upper()), levelname_color)\n\n    message = '{0}'.format(record.msg)\n\n    warning_category = re.match(r'^(\\w+Warning:).*', message)\n    if warning_category is not None:\n        warning_category_colour = color_text(warning_category.groups()[0], 'cyan')\n        message = message.replace(warning_category.groups()[0], warning_category_colour)\n\n    sub_level = re.match(r'(\\[.+\\]:)(.*)', message)\n    if sub_level is not None:\n        sub_level_name = color_text(sub_level.groups()[0], 'red')\n        message = '{}{}'.format(sub_level_name, ''.join(sub_level.groups()[1:]))\n\n    # if len(message) > 79:\n    #     tw = TextWrapper()\n    #     tw.width = 79\n    #     tw.subsequent_indent = ' ' * (len(record.levelname) + 2)\n    #     tw.break_on_hyphens = False\n    #     message = '\\n'.join(tw.wrap(message))\n\n    sys.__stdout__.write('{}{}\\n'.format(header, message))\n    sys.__stdout__.flush()\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _catch_exceptions(self, exctype, value, tb):\n\n        # Now we log it.\n        self.error('Uncaught exception', exc_info=(exctype, value, tb))\n\n        # First, we print to stdout with some colouring.\n        print_exception_formatted(exctype, value, tb)", "response": "Catches all exceptions and logs them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_defaults(self, log_level=logging.INFO, redirect_stdout=False):\n\n        # Remove all previous handlers\n        for handler in self.handlers[:]:\n            self.removeHandler(handler)\n\n        # Set levels\n        self.setLevel(logging.DEBUG)\n\n        # Set up the stdout handler\n        self.fh = None\n        self.sh = logging.StreamHandler()\n        self.sh.emit = colored_formatter\n        self.addHandler(self.sh)\n\n        self.sh.setLevel(log_level)\n\n        # warnings.showwarning = self._show_warning\n\n        # Redirects all stdout to the logger\n        if redirect_stdout:\n            sys.stdout = LoggerStdout(self._print)\n\n        # Catches exceptions\n        sys.excepthook = self._catch_exceptions", "response": "Reset the logger to its initial state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_index_table(environ, envdir):\n    ''' create an html table\n    \n    Parameters:\n        environ (dict):\n            A tree environment dictionary\n        envdir (str):\n            The filepath for the env directory\n    Returns:\n        An html table definition string\n    '''\n\n    table_header = \"\"\"<table id=\"list\" cellpadding=\"0.1em\" cellspacing=\"0\">\n<colgroup><col width=\"55%\"/><col width=\"20%\"/><col width=\"25%\"/></colgroup>\n<thead>\n    <tr><th><a href=\"?C=N&O=A\">File Name</a>&nbsp;<a href=\"?C=N&O=D\">&nbsp;&darr;&nbsp;</a></th><th><a href=\"?C=S&O=A\">File Size</a>&nbsp;<a href=\"?C=S&O=D\">&nbsp;&darr;&nbsp;</a></th><th><a href=\"?C=M&O=A\">Date</a>&nbsp;<a href=\"?C=M&O=D\">&nbsp;&darr;&nbsp;</a></th></tr>\n</thead><tbody>\n    <tr><td><a href=\"../\">Parent directory/</a></td><td>-</td><td>-</td></tr>\"\"\"\n    table_footer = \"\"\"</tbody></table>\"\"\"\n\n    # create table\n    table = table_header\n\n    # loop over the environment\n    for section, values in environ.items():\n        if section == 'default':\n            continue\n\n        for tree_name, tree_path in values.items():\n            skipmsg = 'Skipping {0} for {1}'.format(tree_name, section)\n            if '_root' in tree_name:\n                continue\n\n            # create the src and target links\n            src = tree_path\n            link = os.path.join(envdir, tree_name.upper())\n\n            # get the local time of the symlink\n            try:\n                stattime = time.strftime('%d-%b-%Y %H:%M', time.localtime(os.stat(src).st_mtime))\n            except OSError:\n                print(\"{0} does not appear to exist, skipping...\".format(src))\n                _remove_link(link)\n                continue\n\n            # skip the sas_base_dir\n            if section == 'general' and 'sas_base_dir' in tree_name:\n                print(skipmsg)\n                continue\n\n            # only create symlinks\n            if section == 'general' and tree_name in ['cas_load', 'staging_data']:\n                # only create links here if the target exist\n                if os.path.exists(src):\n                    make_symlink(src, link)\n                else:\n                    print(skipmsg)\n            else:\n                print('Processing {0} for {1}'.format(tree_name, section))\n                make_symlink(src, link)\n            \n            # create the table entry\n            if os.path.exists(link):\n                table += '    <tr><td><a href=\"{0}/\">{0}/</a></td><td>-</td><td>{1}</td></tr>\\n'.format(tree_name.upper(), stattime)\n\n    table += table_footer\n    return table", "response": "Create an html table definition for the tree item in the environment dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the env index html page", "response": "def create_index_page(environ, defaults, envdir):\n    ''' create the env index html page\n    \n    Builds the index.html page containing a table of symlinks\n    to datamodel directories\n\n    Parameters:\n        environ (dict):\n            A tree environment dictionary\n        defaults (dict):\n            The defaults dictionary from environ['default']\n        envdir (str):\n            The filepath for the env directory\n    Returns:\n        A string defintion of an html page\n    '''\n\n    # header of index file\n    header = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n<head><meta name=\"viewport\" content=\"width=device-width\"/><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style type=\"text/css\">body,html {{background:#fff;font-family:\"Bitstream Vera Sans\",\"Lucida Grande\",\"Lucida Sans Unicode\",Lucidux,Verdana,Lucida,sans-serif;}}tr:nth-child(even) {{background:#f4f4f4;}}th,td {{padding:0.1em 0.5em;}}th {{text-align:left;font-weight:bold;background:#eee;border-bottom:1px solid #aaa;}}#list {{border:1px solid #aaa;width:100%%;}}a {{color:#a33;}}a:hover {{color:#e33;}}</style>\n<link rel=\"stylesheet\" href=\"{url}/css/sas.css\" type=\"text/css\"/>\n<title>Index of /sas/{name}/env/</title>\n</head><body><h1>Index of /sas/{name}/env/</h1>\n\"\"\"\n\n    # footer of index file\n    footer = \"\"\"<h3><a href='{url}/sas/'>{location}</a></h3>\n<p>This directory contains links to the contents of\nenvironment variables defined by the tree product, version {name}.\nTo examine the <em>types</em> of files contained in each environment variable\ndirectory, visit <a href=\"/datamodel/files/\">the datamodel.</a></p>\n</body></html>\n\"\"\"\n    # create index html file\n    index = header.format(**defaults)\n    index += create_index_table(environ, envdir)\n    index += footer.format(**defaults)\n\n    return index"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the env symlink directory structure containing the datamodel directories and the index file.", "response": "def create_env(environ, mirror=None, verbose=None):\n    ''' create the env symlink directory structure\n    \n    Creates the env folder filled with symlinks to datamodel directories\n    for a given tree config file.  \n\n    Parameters:\n        environ (dict):\n            A tree environment dictionary\n        mirror (bool):\n            If True, use the SAM url location\n        verbose (bool):\n            If True, print more information\n    '''\n\n    defaults = environ['default'].copy()\n    defaults['url'] = \"https://data.mirror.sdss.org\" if mirror else \"https://data.sdss.org\"\n    defaults['location'] = \"SDSS-IV Science Archive Mirror (SAM)\" if mirror else \"SDSS-IV Science Archive Server (SAS)\"\n\n    if not os.path.exists(environ['general']['sas_root']):\n        if verbose:\n            print(\"{0} doesn't exist, skipping env link creation.\".format(environ['general']['sas_root']))\n        return\n\n    if verbose:\n        print(\"Found {0}.\".format(environ['general']['sas_root']))\n\n    # sets and creates envdir\n    envdir = os.path.join(environ['general']['sas_root'], 'env')\n    if not os.path.exists(envdir):\n        os.makedirs(envdir)\n    if not os.access(envdir, os.W_OK):\n        return\n\n    # create index html\n    index = create_index_page(environ, defaults, envdir)\n\n    # write the index file\n    indexfile = os.path.join(envdir, 'index.html')\n    with open(indexfile, 'w') as f:\n        f.write(index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck for the SAS_BASE_DIR environment variable and set it in the local environment variable if it is undefined", "response": "def check_sas_base_dir(root=None):\n    ''' Check for the SAS_BASE_DIR environment variable\n\n    Will set the SAS_BASE_DIR in your local environment\n    or prompt you to define one if is undefined\n\n    Parameters:\n        root (str):\n            Optional override of the SAS_BASE_DIR envvar\n\n    '''\n    sasbasedir = root or os.getenv(\"SAS_BASE_DIR\")\n    if not sasbasedir:\n        sasbasedir = input('Enter a path for SAS_BASE_DIR: ')\n    os.environ['SAS_BASE_DIR'] = sasbasedir"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a proper file header in a given shell format", "response": "def write_header(term='bash', tree_dir=None, name=None):\n    ''' Write proper file header in a given shell format\n\n    Parameters:\n        term (str):\n            The type of shell header to write, can be \"bash\", \"tsch\", or \"modules\"\n        tree_dir (str):\n            The path to this repository\n        name (str):\n            The name of the configuration\n\n    Returns:\n        A string header to insert\n    '''\n\n    assert term in ['bash', 'tsch', 'modules'], 'term must be either bash, tsch, or module'\n\n    product_dir = tree_dir.rstrip('/')\n    base = 'export' if term == 'bash' else 'setenv'\n\n    if term != 'modules':\n        hdr = \"\"\"# Set up tree/{0} for {1}\n{2} TREE_DIR {3}\n{2} TREE_VER {1}\n{2} PATH $TREE_DIR/bin:$PATH\n{2} PYTHONPATH $TREE_DIR/python:$PYTHONPATH\n                \"\"\".format(name, term, base, product_dir)\n    else:\n        hdr = \"\"\"#%Module1.0\nproc ModulesHelp {{ }} {{\n    global product version\n    puts stderr \"This module adds $product/$version to various paths\"\n}}\nset name tree\nset product tree\nset version {1}\nconflict $product\nmodule-whatis \"Sets up $product/$version in your environment\"\n\nset PRODUCT_DIR {0}\nsetenv [string toupper $product]_DIR $PRODUCT_DIR\nsetenv [string toupper $product]_VER $version\nprepend-path PATH $PRODUCT_DIR/bin\nprepend-path PYTHONPATH $PRODUCT_DIR/python\n\n                \"\"\".format(product_dir, name)\n\n    return hdr.strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_file(environ, term='bash', out_dir=None, tree_dir=None):\n    ''' Write a tree environment file\n\n    Loops over the tree environ and writes them out to a bash, tsch, or\n    modules file\n\n    Parameters:\n        environ (dict):\n            The tree dictionary environment\n        term (str):\n            The type of shell header to write, can be \"bash\", \"tsch\", or \"modules\"\n        tree_dir (str):\n            The path to this repository\n        out_dir (str):\n            The output path to write the files (default is etc/)\n\n    '''\n\n    # get the proper name, header and file extension\n    name = environ['default']['name']\n    header = write_header(term=term, name=name, tree_dir=tree_dir)\n    exts = {'bash': '.sh', 'tsch': '.csh', 'modules': '.module'}\n    ext = exts[term]\n\n    # shell command\n    if term == 'bash':\n        cmd = 'export {0}={1}\\n'\n    else:\n        cmd = 'setenv {0} {1}\\n'\n\n    # write the environment config files\n    filename = os.path.join(out_dir, name + ext)\n    with open(filename, 'w') as f:\n        f.write(header + '\\n')\n        for key, values in environ.items():\n            if key != 'default':\n                # write separator\n                f.write('#\\n# {0}\\n#\\n'.format(key))\n                # write tree names and paths\n                for tree_name, tree_path in values.items():\n                    f.write(cmd.format(tree_name.upper(), tree_path))\n\n    # write default .version file for modules\n    modules_version = write_version(name)\n    if term == 'modules' and environ['default']['current']:\n        version_name = os.path.join(out_dir, '.version')\n        with open(version_name, 'w') as f:\n            f.write(modules_version)", "response": "Writes a tree environment file to a bash tsch or modules file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the tree for a given config", "response": "def get_tree(config=None):\n    ''' Get the tree for a given config\n\n    Parameters:\n        config (str):\n            The name of the tree config to load\n\n    Returns:\n        a Python Tree instance\n    '''\n    path = os.path.dirname(os.path.abspath(__file__))\n    pypath = os.path.realpath(os.path.join(path, '..', 'python'))\n    if pypath not in sys.path:\n        sys.path.append(pypath)\n    os.chdir(pypath)\n    from tree.tree import Tree\n    tree = Tree(config=config)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy over the tree module files into your path", "response": "def copy_modules(filespath=None, modules_path=None, verbose=None):\n    ''' Copy over the tree module files into your path '''\n\n    # find or define a modules path\n    if not modules_path:\n        modulepath = os.getenv(\"MODULEPATH\")\n        if not modulepath:\n            modules_path = input('Enter the root path for your module files:')\n        else:\n            split_mods = modulepath.split(':')\n            if len(split_mods) > 1:\n                if verbose:\n                    print('Multiple module paths found.  Finding all that contain a tree directory.')\n                for mfile in split_mods:\n                    if os.path.exists(os.path.join(mfile, 'tree')):\n                        copy_modules(filespath=filespath, modules_path=mfile, verbose=verbose)\n                    else:\n                        return\n            else:\n                modules_path = split_mods[0]\n\n    # check for the tree module directory\n    tree_mod = os.path.join(modules_path, 'tree')\n    if not os.path.isdir(tree_mod):\n        os.makedirs(tree_mod)\n\n    # copy the modules into the tree\n    if verbose:\n        print('Copying modules from etc/ into {0}'.format(tree_mod))\n    module_files = glob.glob(os.path.join(filespath, '*.module'))\n    for mfile in module_files:\n        base = os.path.splitext(os.path.basename(mfile))[0]\n        tree_out = os.path.join(tree_mod, base)\n        shutil.copy2(mfile, tree_out)\n\n    # copy the default version into the tree\n    version = os.path.join(filespath, '.version')\n    if os.path.isfile(version):\n        shutil.copy2(version, tree_mod)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_args():\n    ''' Parse the arguments '''\n\n    parser = argparse.ArgumentParser(prog='setup_tree_modules', usage='%(prog)s [opts]')\n    parser.add_argument('-v', '--verbose', action='store_true', dest='verbose',\n                        help='Print extra information.', default=False)\n    parser.add_argument('-r', '--root', action='store', dest='root', default=os.getenv('SAS_BASE_DIR'),\n                        help='Override the value of $SAS_BASE_DIR.', metavar='SAS_BASE_DIR')\n    parser.add_argument('-t', '--treedir', action='store', dest='treedir', default=os.getenv('TREE_DIR'),\n                        help='Override the value of $TREE_DIR.', metavar='TREE_DIR')\n    parser.add_argument('-m', '--modulesdir', action='store', dest='modulesdir', default=os.getenv('MODULES_DIR'),\n                        help='Your modules directory', metavar='MODULES_DIR')\n    parser.add_argument('-e', '--env', action='store_true', dest='env',\n                        help='Create tree environment symlinks.', default=False)\n    parser.add_argument('-i', '--mirror', action='store_true', dest='mirror',\n                        help='Use the mirror site (SAM) instead.')\n    parser.add_argument('-o', '--only', action='store', dest='only', metavar='[xxx].cfg',\n                        default=None, help='create links for only the specified tree config.')\n\n    opts = parser.parse_args()\n\n    return opts", "response": "Parse the command line arguments and return the options."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _indent(text, level=1):\n    ''' Does a proper indenting for Sphinx rst '''\n\n    prefix = ' ' * (4 * level)\n\n    def prefixed_lines():\n        for line in text.splitlines(True):\n            yield (prefix + line if line.strip() else line)\n\n    return ''.join(prefixed_lines())", "response": "Does a proper indenting for Sphinx rst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the command line for the config section and environment variables.", "response": "def _format_command(name, envvars, base=None):\n    ''' Creates a list-table directive\n\n    for a set of defined environment variables\n\n    Parameters:\n        name (str):\n            The name of the config section\n        envvars (dict):\n            A dictionary of the environment variable definitions from the config\n        base (str):\n            The SAS_BASE to remove from the filepaths\n\n    Yields:\n        A string rst-formated list-table directive\n\n    '''\n\n    yield '.. list-table:: {0}'.format(name)\n    yield _indent(':widths: 20 50')\n    yield _indent(':header-rows: 1')\n    yield ''\n    yield _indent('* - Name')\n    yield _indent('  - Path')\n    for envvar, path in envvars.items():\n        tail = path.split(base)[1] if base and base in path else path\n        tail = envvar.upper() if envvar.upper() == 'SAS_BASE_DIR' else tail\n        yield _indent('* - {0}'.format(envvar.upper()))\n        yield _indent('  - {0}'.format(tail))\n    yield ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the relevant Sphinx nodes.", "response": "def _generate_section(self, name, config, cfg_section='default', remove_sasbase=False):\n        \"\"\"Generate the relevant Sphinx nodes.\n\n        Generates a section for the Tree datamodel.  Formats a tree section\n        as a list-table directive.\n\n        Parameters:\n            name (str):\n                The name of the config to be documented, e.g. 'sdsswork'\n            config (dict):\n                The tree dictionary of the loaded config environ\n            cfg_section (str):\n                The section of the config to load\n            remove_sasbase (bool):\n                If True, removes the SAS_BASE_DIR from the beginning of each path\n\n        Returns:\n            A section docutil node\n\n        \"\"\"\n\n        # the source name\n        source_name = name\n\n        # Title\n        section = nodes.section(\n            '',\n            nodes.title(text=cfg_section),\n            ids=[nodes.make_id(cfg_section)],\n            names=[nodes.fully_normalize_name(cfg_section)])\n\n        # Summarize\n        result = statemachine.ViewList()\n        base = config['default']['filesystem'] if remove_sasbase else None\n        lines = _format_command(cfg_section, config[cfg_section], base=base)\n        for line in lines:\n            result.append(line, source_name)\n\n        self.state.nested_parse(result, 0, section)\n\n        return [section]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_requirements(opts):\n    ''' Get the proper requirements file based on the optional argument '''\n\n    if opts.dev:\n        name = 'requirements_dev.txt'\n    elif opts.doc:\n        name = 'requirements_doc.txt'\n    else:\n        name = 'requirements.txt'\n\n    requirements_file = os.path.join(os.path.dirname(__file__), name)\n    install_requires = [line.strip().replace('==', '>=') for line in open(requirements_file)\n                        if not line.strip().startswith('#') and line.strip() != '']\n    return install_requires", "response": "Get the proper requirements file based on the optional argument"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_args(parser):\n    ''' Remove custom arguments from the parser '''\n\n    arguments = []\n    for action in list(parser._get_optional_actions()):\n        if '--help' not in action.option_strings:\n            arguments += action.option_strings\n\n    for arg in arguments:\n        if arg in sys.argv:\n            sys.argv.remove(arg)", "response": "Remove custom arguments from the parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean(ctx):\n    ctx.run(f'python setup.py clean')\n    dist = ROOT.joinpath('dist')\n    print(f'[clean] Removing {dist}')\n    if dist.exists():\n        shutil.rmtree(str(dist))", "response": "Clean previously built package artifacts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _render_log():\n    config = load_config(ROOT)\n    definitions = config['types']\n    fragments, fragment_filenames = find_fragments(\n        pathlib.Path(config['directory']).absolute(),\n        config['sections'],\n        None,\n        definitions,\n    )\n    rendered = render_fragments(\n        pathlib.Path(config['template']).read_text(encoding='utf-8'),\n        config['issue_format'],\n        split_fragments(fragments, definitions),\n        definitions,\n        config['underlines'][1:],\n    )\n    return rendered", "response": "Totally tap into Towncrier internals to get an in - memory result.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef adjust_name_for_printing(name):\n    if name is not None:\n        name2 = name\n        name = name.replace(\" \", \"_\").replace(\".\", \"_\").replace(\"-\", \"_m_\")\n        name = name.replace(\"+\", \"_p_\").replace(\"!\", \"_I_\")\n        name = name.replace(\"**\", \"_xx_\").replace(\"*\", \"_x_\")\n        name = name.replace(\"/\", \"_l_\").replace(\"@\", '_at_')\n        name = name.replace(\"(\", \"_of_\").replace(\")\", \"\")\n        if re.match(r'^[a-zA-Z_][a-zA-Z0-9-_]*$', name) is None:\n            raise NameError(\"name {} converted to {} cannot be further converted to valid python variable name!\".format(name2, name))\n        return name\n    return ''", "response": "Adjusts a name for printing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the name of this object.", "response": "def name(self, name):\n        \"\"\"\n        Set the name of this object.\n        Tell the parent if the name has changed.\n        \"\"\"\n        from_name = self.name\n        assert isinstance(name, str)\n        self._name = name\n        if self.has_parent():\n            self._parent_._name_changed(self, from_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hierarchy_name(self, adjust_for_printing=True):\n        if adjust_for_printing: adjust = lambda x: adjust_name_for_printing(x)\n        else: adjust = lambda x: x\n        if self.has_parent():\n            return self._parent_.hierarchy_name() + \".\" + adjust(self.name)\n        return adjust(self.name)", "response": "return the name of this object with the parents names attached by dots."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlink a parameter to another parameter in the hierarchy.", "response": "def link_parameter(self, param, index=None):\n        \"\"\"\n        :param parameters:  the parameters to add\n        :type parameters:   list of or one :py:class:`paramz.param.Param`\n        :param [index]:     index of where to put parameters\n\n        Add all parameters to this param class, you can insert parameters\n        at any given index using the :func:`list.insert` syntax\n        \"\"\"\n        if param in self.parameters and index is not None:\n            self.unlink_parameter(param)\n            return self.link_parameter(param, index)\n        # elif param.has_parent():\n        #    raise HierarchyError, \"parameter {} already in another model ({}), create new object (or copy) for adding\".format(param._short(), param._highest_parent_._short())\n        elif param not in self.parameters:\n            if param.has_parent():\n                def visit(parent, self):\n                    if parent is self:\n                        raise HierarchyError(\"You cannot add a parameter twice into the hierarchy\")\n                param.traverse_parents(visit, self)\n                param._parent_.unlink_parameter(param)\n            # make sure the size is set\n            if index is None:\n                start = sum(p.size for p in self.parameters)\n                for name, iop in self._index_operations.items():\n                    iop.shift_right(start, param.size)\n                    iop.update(param._index_operations[name], self.size)\n                param._parent_ = self\n                param._parent_index_ = len(self.parameters)\n                self.parameters.append(param)\n            else:\n                start = sum(p.size for p in self.parameters[:index])\n                for name, iop in self._index_operations.items():\n                    iop.shift_right(start, param.size)\n                    iop.update(param._index_operations[name], start)\n                param._parent_ = self\n                param._parent_index_ = index if index>=0 else len(self.parameters[:index])\n                for p in self.parameters[index:]:\n                    p._parent_index_ += 1\n                self.parameters.insert(index, param)\n\n            param.add_observer(self, self._pass_through_notify_observers, -np.inf)\n\n            parent = self\n            while parent is not None:\n                parent.size += param.size\n                parent = parent._parent_\n            self._notify_parent_change()\n\n            if not self._in_init_ and self._highest_parent_._model_initialized_:\n                #self._connect_parameters()\n                #self._notify_parent_change()\n\n                self._highest_parent_._connect_parameters()\n                self._highest_parent_._notify_parent_change()\n                self._highest_parent_._connect_fixes()\n            return param\n        else:\n            raise HierarchyError(\"\"\"Parameter exists already, try making a copy\"\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a parameter from this object.", "response": "def unlink_parameter(self, param):\n        \"\"\"\n        :param param: param object to remove from being a parameter of this parameterized object.\n        \"\"\"\n        if not param in self.parameters:\n            try:\n                raise HierarchyError(\"{} does not belong to this object {}, remove parameters directly from their respective parents\".format(param._short(), self.name))\n            except AttributeError:\n                raise HierarchyError(\"{} does not seem to be a parameter, remove parameters directly from their respective parents\".format(str(param)))\n\n        start = sum([p.size for p in self.parameters[:param._parent_index_]])\n        self.size -= param.size\n        del self.parameters[param._parent_index_]\n        self._remove_parameter_name(param)\n\n\n        param._disconnect_parent()\n        param.remove_observer(self, self._pass_through_notify_observers)\n        for name, iop in self._index_operations.items():\n            iop.shift_left(start, param.size)\n\n        self._connect_parameters()\n        self._notify_parent_change()\n\n        parent = self._parent_\n        while parent is not None:\n            parent.size -= param.size\n            parent = parent._parent_\n\n        self._highest_parent_._connect_parameters()\n        self._highest_parent_._connect_fixes()\n        self._highest_parent_._notify_parent_change()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a list of parameters matching regular expression regexp", "response": "def grep_param_names(self, regexp):\n        \"\"\"\n        create a list of parameters, matching regular expression regexp\n        \"\"\"\n        if not isinstance(regexp, _pattern_type): regexp = compile(regexp)\n        found_params = []\n        def visit(innerself, regexp):\n            if (innerself is not self) and regexp.match(innerself.hierarchy_name().partition('.')[2]):\n                found_params.append(innerself)\n        self.traverse(visit, regexp)\n        return found_params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _repr_html_(self, header=True):\n        name = adjust_name_for_printing(self.name) + \".\"\n        names = self.parameter_names()\n        desc = self._description_str\n        iops = OrderedDict()\n        for opname in self._index_operations:\n            iop = []\n            for p in self.parameters:\n                iop.extend(p.get_property_string(opname))\n            iops[opname] = iop\n\n        format_spec = self._format_spec(name, names, desc, iops, False)\n        to_print = []\n\n        if header:\n            to_print.append(\"<tr><th><b>\" + '</b></th><th><b>'.join(format_spec).format(name=name, desc='value', **dict((name, name) for name in iops)) + \"</b></th></tr>\")\n\n        format_spec = \"<tr><td class=tg-left>\" + format_spec[0] + '</td><td class=tg-right>' + format_spec[1] + '</td><td class=tg-center>' + '</td><td class=tg-center>'.join(format_spec[2:]) + \"</td></tr>\"\n        for i in range(len(names)):\n            to_print.append(format_spec.format(name=names[i], desc=desc[i], **dict((name, iops[name][i]) for name in iops)))\n\n        style = \"\"\"<style type=\"text/css\">\n.tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n.tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n.tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n.tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n.tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n.tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n</style>\"\"\"\n        return style + '\\n' + '<table class=\"tg\">' + '\\n'.join(to_print) + '\\n</table>'", "response": "Representation of the parameters in html for notebook display."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a pydot representation of this object.", "response": "def build_pydot(self, G=None): # pragma: no cover\n        \"\"\"\n        Build a pydot representation of this model. This needs pydot installed.\n\n        Example Usage::\n\n            np.random.seed(1000)\n            X = np.random.normal(0,1,(20,2))\n            beta = np.random.uniform(0,1,(2,1))\n            Y = X.dot(beta)\n            m = RidgeRegression(X, Y)\n            G = m.build_pydot()\n            G.write_png('example_hierarchy_layout.png')\n\n        The output looks like:\n\n        .. image:: ./example_hierarchy_layout.png\n\n        Rectangles are parameterized objects (nodes or leafs of hierarchy).\n\n        Trapezoids are param objects, which represent the arrays for parameters.\n\n        Black arrows show parameter hierarchical dependence. The arrow points\n        from parents towards children.\n\n        Orange arrows show the observer pattern. Self references (here) are\n        the references to the call to parameters changed and references upwards\n        are the references to tell the parents they need to update.\n        \"\"\"\n        import pydot  # @UnresolvedImport\n        iamroot = False\n        if G is None:\n            G = pydot.Dot(graph_type='digraph', bgcolor=None)\n            iamroot=True\n        node = pydot.Node(id(self), shape='box', label=self.name)#, color='white')\n\n        G.add_node(node)\n        for child in self.parameters:\n            child_node = child.build_pydot(G)\n            G.add_edge(pydot.Edge(node, child_node))#, color='white'))\n\n        for _, o, _ in self.observers:\n            label = o.name if hasattr(o, 'name') else str(o)\n            observed_node = pydot.Node(id(o), label=label)\n            if str(id(o)) not in G.obj_dict['nodes']:\n                G.add_node(observed_node)\n            edge = pydot.Edge(str(id(self)), str(id(o)), color='darkorange2', arrowhead='vee')\n            G.add_edge(edge)\n\n        if iamroot:\n            return G\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gradient(self):\n        if getattr(self, '_gradient_array_', None) is None:\n            self._gradient_array_ = np.empty(self._realshape_, dtype=np.float64)\n        return self._gradient_array_", "response": "Return a view on the gradient array which is in the same shape as this parameter is."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup_observers(self):\n        if self.has_parent():\n            self.add_observer(self._parent_, self._parent_._pass_through_notify_observers, -np.inf)", "response": "Setup the default observers for the current instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _repr_html_(self, indices=None, iops=None, lx=None, li=None, lls=None):\n        filter_ = self._current_slice_\n        vals = self.flat\n        if indices is None: indices = self._indices(filter_)\n        if iops is None:\n            ravi = self._raveled_index(filter_)\n            iops = OrderedDict([name, iop.properties_for(ravi)] for name, iop in self._index_operations.items())\n        if lls is None: lls = [self._max_len_names(iop, name) for name, iop in iops.items()]\n\n        header_format = \"\"\"\n<tr>\n  <th><b>{i}</b></th>\n  <th><b>{x}</b></th>\n  <th><b>{iops}</b></th>\n</tr>\"\"\"\n        header = header_format.format(x=self.hierarchy_name(), i=__index_name__, iops=\"</b></th><th><b>\".join(list(iops.keys())))  # nice header for printing\n\n        to_print = [\"\"\"<style type=\"text/css\">\n.tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n.tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n.tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n.tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n.tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n</style>\"\"\"]\n        to_print.append('<table class=\"tg\">')\n        to_print.append(header)\n\n        format_spec = self._format_spec(indices, iops, lx, li, lls, False)\n        format_spec[:2] = [\"<tr><td class=tg-left>{i}</td>\".format(i=format_spec[0]), \"<td class=tg-right>{i}</td>\".format(i=format_spec[1])]\n        for i in range(2, len(format_spec)):\n            format_spec[i] = '<td class=tg-left>{c}</td>'.format(c=format_spec[i])\n        format_spec = \"\".join(format_spec) + '</tr>'\n\n        for i in range(self.size):\n            to_print.append(format_spec.format(index=indices[i], value=\"{1:.{0}f}\".format(__precision__, vals[i]), **dict((name, ' '.join(map(str, iops[name][i]))) for name in iops)))\n        return '\\n'.join(to_print)", "response": "Representation of the parameter in html for notebook display."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_pydot(self,G): # pragma: no cover\n        import pydot\n        node = pydot.Node(id(self), shape='trapezium', label=self.name)#, fontcolor='white', color='white')\n        G.add_node(node)\n        for _, o, _ in self.observers:\n            label = o.name if hasattr(o, 'name') else str(o)\n            observed_node = pydot.Node(id(o), label=label)\n            if str(id(o)) not in G.obj_dict['nodes']: # pragma: no cover\n                G.add_node(observed_node)\n            edge = pydot.Edge(str(id(self)), str(id(o)), color='darkorange2', arrowhead='vee')\n            G.add_edge(edge)\n\n        return node", "response": "Build a pydot representation of this model. This needs pydot installed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an observer with the callback callble to the observers list.", "response": "def add_observer(self, observer, callble, priority=0):\n        \"\"\"\n        Add an observer `observer` with the callback `callble`\n        and priority `priority` to this observers list.\n        \"\"\"\n        self.observers.add(priority, observer, callble)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an observer from the cache.", "response": "def remove_observer(self, observer, callble=None):\n        \"\"\"\n        Either (if callble is None) remove all callables,\n        which were added alongside observer,\n        or remove callable `callble` which was added alongside\n        the observer `observer`.\n        \"\"\"\n        to_remove = []\n        for poc in self.observers:\n            _, obs, clble = poc\n            if callble is not None:\n                if (obs is observer) and (callble == clble):\n                    to_remove.append(poc)\n            else:\n                if obs is observer:\n                    to_remove.append(poc)\n        for r in to_remove:\n            self.observers.remove(*r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify_observers(self, which=None, min_priority=None):\n        if self._update_on:\n            if which is None:\n                which = self\n            if min_priority is None:\n                [callble(self, which=which) for _, _, callble in self.observers]\n            else:\n                for p, _, callble in self.observers:\n                    if p <= min_priority:\n                        break\n                    callble(self, which=which)", "response": "Notifies all observers. Which is the element, which kicked off this\n        notification loop. The first argument will be self, the second `which`.\n\n        .. note::\n           \n           notifies only observers with priority p > min_priority!\n           \n        :param min_priority: only notify observers with priority > min_priority\n                             if min_priority is None, notify all observers in order"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstrain this set to be fixed to the current value.", "response": "def constrain_fixed(self, value=None, warning=True, trigger_parent=True):\n        \"\"\"\n        Constrain this parameter to be fixed to the current value it carries.\n\n        This does not override the previous constraints, so unfixing will\n        restore the constraint set before fixing.\n\n        :param warning: print a warning for overwriting constraints.\n        \"\"\"\n        if value is not None:\n            self[:] = value\n\n        #index = self.unconstrain()\n        index = self._add_to_index_operations(self.constraints, np.empty(0), __fixed__, warning)\n        self._highest_parent_._set_fixed(self, index)\n        self.notify_observers(self, None if trigger_parent else -np.inf)\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unconstrain_fixed(self):\n        unconstrained = self.unconstrain(__fixed__)\n        self._highest_parent_._set_unfixed(self, unconstrained)\n        #if self._default_constraint_ is not None:\n        #    return self.constrain(self._default_constraint_)\n        return unconstrained", "response": "Returns the unconstrained version of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef constrain(self, transform, warning=True, trigger_parent=True):\n        if isinstance(transform, Transformation):\n            self.param_array[...] = transform.initialize(self.param_array)\n        elif transform == __fixed__:\n            return self.fix(warning=warning, trigger_parent=trigger_parent)\n        else:\n            raise ValueError('Can only constrain with paramz.transformations.Transformation object')\n        reconstrained = self.unconstrain()\n        added = self._add_to_index_operations(self.constraints, reconstrained, transform, warning)\n        self.trigger_update(trigger_parent)\n        return added", "response": "Constrain the parameter to the given transformation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstrain this entry to the default positive constraint.", "response": "def constrain_positive(self, warning=True, trigger_parent=True):\n        \"\"\"\n        :param warning: print a warning if re-constraining parameters.\n\n        Constrain this parameter to the default positive constraint.\n        \"\"\"\n        self.constrain(Logexp(), warning=warning, trigger_parent=trigger_parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef constrain_negative(self, warning=True, trigger_parent=True):\n        self.constrain(NegativeLogexp(), warning=warning, trigger_parent=trigger_parent)", "response": "Constrain this log entry to the default negative constraint."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstrains this parameter to be within the given limits.", "response": "def constrain_bounded(self, lower, upper, warning=True, trigger_parent=True):\n        \"\"\"\n        :param lower, upper: the limits to bound this parameter to\n        :param warning: print a warning if re-constraining parameters.\n\n        Constrain this parameter to lie within the given range.\n        \"\"\"\n        self.constrain(Logistic(lower, upper), warning=warning, trigger_parent=trigger_parent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a previously pickled version of a sequence of objects.", "response": "def load(file_or_path):\n    \"\"\"\n    Load a previously pickled model, using `m.pickle('path/to/file.pickle)'`\n\n    :param file_name: path/to/file.pickle\n    \"\"\"\n    from pickle import UnpicklingError\n    _python3 = True\n    try: \n        import cPickle as pickle\n        _python3 = False\n    except ImportError: #python3\n        import pickle\n   \n    try:\n        if _python3:\n            strcl = str\n            p3kw = dict(encoding='latin1')\n            return _unpickle(file_or_path, pickle, strcl, p3kw)\n        else:\n            strcl = basestring\n            p3kw = {}\n            return _unpickle(file_or_path, pickle, strcl, p3kw)\n    \n    except UnpicklingError: # pragma: no coverage\n        import pickle\n        return _unpickle(file_or_path, pickle, strcl, p3kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the gradient of this parameter with respect to the highest parent s objective function.", "response": "def checkgrad(self, verbose=0, step=1e-6, tolerance=1e-3, df_tolerance=1e-12):\n        \"\"\"\n        Check the gradient of this parameter with respect to the highest parent's\n        objective function.\n        This is a three point estimate of the gradient, wiggling at the parameters\n        with a stepsize step.\n        The check passes if either the ratio or the difference between numerical and\n        analytical gradient is smaller then tolerance.\n\n        :param bool verbose: whether each parameter shall be checked individually.\n        :param float step: the stepsize for the numerical three point gradient estimate.\n        :param float tolerance: the tolerance for the gradient ratio or difference.\n        :param float df_tolerance: the tolerance for df_tolerance\n\n        .. note::\n           The *dF_ratio* indicates the limit of accuracy of numerical gradients.\n           If it is too small, e.g., smaller than 1e-12, the numerical gradients\n           are usually not accurate enough for the tests (shown with blue).\n        \"\"\"\n        # Make sure we always call the gradcheck on the highest parent\n        # This ensures the assumption of the highest parent to hold the fixes\n        # In the checkgrad function we take advantage of that, so it needs\n        # to be set in place here.\n        if self.has_parent():\n            return self._highest_parent_._checkgrad(self, verbose=verbose, step=step, tolerance=tolerance, df_tolerance=df_tolerance)\n        return self._checkgrad(self, verbose=verbose, step=step, tolerance=tolerance, df_tolerance=df_tolerance)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the TNC optimizer and store the results in self. x_opt self. f_opt self. funct_eval self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_opt self. f_fp self. f_f self. f_f self. f_f self. f", "response": "def opt(self, x_init, f_fp=None, f=None, fp=None):\n        \"\"\"\n        Run the TNC optimizer\n\n        \"\"\"\n        tnc_rcstrings = ['Local minimum', 'Converged', 'XConverged', 'Maximum number of f evaluations reached',\n             'Line search failed', 'Function is constant']\n\n        assert f_fp != None, \"TNC requires f_fp\"\n\n        opt_dict = {}\n        if self.xtol is not None:\n            opt_dict['xtol'] = self.xtol\n        if self.ftol is not None:\n            opt_dict['ftol'] = self.ftol\n        if self.gtol is not None:\n            opt_dict['pgtol'] = self.gtol\n\n        opt_result = optimize.fmin_tnc(f_fp, x_init, messages=self.messages,\n                       maxfun=self.max_f_eval, **opt_dict)\n        self.x_opt = opt_result[0]\n        self.f_opt = f_fp(self.x_opt)[0]\n        self.funct_eval = opt_result[1]\n        self.status = tnc_rcstrings[opt_result[2]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef opt(self, x_init, f_fp=None, f=None, fp=None):\n        rcstrings = ['Converged', 'Maximum number of f evaluations reached', 'Error']\n\n        assert f_fp != None, \"BFGS requires f_fp\"\n\n        opt_dict = {}\n        if self.xtol is not None:\n            print(\"WARNING: l-bfgs-b doesn't have an xtol arg, so I'm going to ignore it\")\n        if self.ftol is not None:\n            print(\"WARNING: l-bfgs-b doesn't have an ftol arg, so I'm going to ignore it\")\n        if self.gtol is not None:\n            opt_dict['pgtol'] = self.gtol\n        if self.bfgs_factor is not None:\n            opt_dict['factr'] = self.bfgs_factor\n\n        opt_result = optimize.fmin_l_bfgs_b(f_fp, x_init, maxfun=self.max_iters, maxiter=self.max_iters, **opt_dict)\n        self.x_opt = opt_result[0]\n        self.f_opt = f_fp(self.x_opt)[0]\n        self.funct_eval = opt_result[2]['funcalls']\n        self.status = rcstrings[opt_result[2]['warnflag']]\n\n        #a more helpful error message is available in opt_result in the Error case\n        if opt_result[2]['warnflag']==2: # pragma: no coverage, this is not needed to be covered\n            self.status = 'Error' + str(opt_result[2]['task'])", "response": "Run the optimizer on the current set of terms."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the optimizer for the current set of parameters.", "response": "def opt(self, x_init, f_fp=None, f=None, fp=None):\n        \"\"\"\n        Run the optimizer\n\n        \"\"\"\n        rcstrings = ['','Maximum number of iterations exceeded', 'Gradient and/or function calls not changing']\n\n        opt_dict = {}\n        if self.xtol is not None:\n            print(\"WARNING: bfgs doesn't have an xtol arg, so I'm going to ignore it\")\n        if self.ftol is not None:\n            print(\"WARNING: bfgs doesn't have an ftol arg, so I'm going to ignore it\")\n        if self.gtol is not None:\n            opt_dict['gtol'] = self.gtol\n\n        opt_result = optimize.fmin_bfgs(f, x_init, fp, disp=self.messages,\n                                            maxiter=self.max_iters, full_output=True, **opt_dict)\n        self.x_opt = opt_result[0]\n        self.f_opt = f_fp(self.x_opt)[0]\n        self.funct_eval = opt_result[4]\n        self.status = rcstrings[opt_result[6]]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noptimize the simplex with respect to the given parameters.", "response": "def opt(self, x_init, f_fp=None, f=None, fp=None):\n        \"\"\"\n        The simplex optimizer does not require gradients.\n        \"\"\"\n\n        statuses = ['Converged', 'Maximum number of function evaluations made', 'Maximum number of iterations reached']\n\n        opt_dict = {}\n        if self.xtol is not None:\n            opt_dict['xtol'] = self.xtol\n        if self.ftol is not None:\n            opt_dict['ftol'] = self.ftol\n        if self.gtol is not None:\n            print(\"WARNING: simplex doesn't have an gtol arg, so I'm going to ignore it\")\n\n        opt_result = optimize.fmin(f, x_init, (), disp=self.messages,\n                   maxfun=self.max_f_eval, full_output=True, **opt_dict)\n\n        self.x_opt = opt_result[0]\n        self.f_opt = opt_result[1]\n        self.funct_eval = opt_result[3]\n        self.status = statuses[opt_result[4]]\n        self.trace = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncombines the args and kw in a unique way such that ordering of kwargs does not lead to recompute", "response": "def combine_inputs(self, args, kw, ignore_args):\n        \"Combines the args and kw in a unique way, such that ordering of kwargs does not lead to recompute\"\n        inputs= args + tuple(c[1] for c in sorted(kw.items(), key=lambda x: x[0]))\n        # REMOVE the ignored arguments from input and PREVENT it from being checked!!!\n        return [a for i,a in enumerate(inputs) if i not in ignore_args]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_cache_id(self, combined_args_kw):\n        \"get the cacheid (conc. string of argument self.ids in order)\"\n        cache_id = \"\".join(self.id(a) for a in combined_args_kw)\n        return cache_id", "response": "get the cacheid ( conc. string of argument self. ids in order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_cache_length(self):\n        \"Ensures the cache is within its limits and has one place free\"\n        if len(self.order) == self.limit:\n            # we have reached the limit, so lets release one element\n            cache_id = self.order.popleft()\n            combined_args_kw = self.cached_inputs[cache_id]\n            for ind in combined_args_kw:\n                ind_id = self.id(ind)\n                tmp = self.cached_input_ids.get(ind_id, None)\n                if tmp is not None:\n                    ref, cache_ids = tmp\n                    if len(cache_ids) == 1 and ref() is not None:\n                        ref().remove_observer(self, self.on_cache_changed)\n                        del self.cached_input_ids[ind_id]\n                    else:\n                        cache_ids.remove(cache_id)\n                        self.cached_input_ids[ind_id] = [ref, cache_ids]\n            try:\n                del self.cached_outputs[cache_id]\n            except KeyError:\n                # Was not cached before, possibly a keyboard interrupt\n                pass\n            try:\n                del self.inputs_changed[cache_id]\n            except KeyError:\n                # Was not cached before, possibly a keyboard interrupt\n                pass\n            try:\n                del self.cached_inputs[cache_id]\n            except KeyError:\n                # Was not cached before, possibly a keyboard interrupt\n                pass", "response": "Ensures the cache is within its limits and has one place free"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_cache_changed(self, direct, which=None):\n        for what in [direct, which]:\n            ind_id = self.id(what)\n            _, cache_ids = self.cached_input_ids.get(ind_id, [None, []])\n            for cache_id in cache_ids:\n                self.inputs_changed[cache_id] = True", "response": "A callback funtion which sets local flags when the elements of some cached inputs have changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self):\n        [a().remove_observer(self, self.on_cache_changed) if (a() is not None) else None for [a, _] in self.cached_input_ids.values()]\n\n        self.order = collections.deque()\n        self.cached_inputs = {}  # point from cache_ids to a list of [ind_ids], which where used in cache cache_id\n\n        #=======================================================================\n        # point from each ind_id to [ref(obj), cache_ids]\n        # 0: a weak reference to the object itself\n        # 1: the cache_ids in which this ind_id is used (len will be how many times we have seen this ind_id)\n        self.cached_input_ids = {}\n        #=======================================================================\n\n        self.cached_outputs = {}  # point from cache_ids to outputs\n        self.inputs_changed = {}", "response": "Reset the cache to the original state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disable_caching(self):\n        \"Disable the cache of this object. This also removes previously cached results\"\n        self.caching_enabled = False\n        for c in self.values():\n            c.disable_cacher()", "response": "Disable the cache of this object. This also removes previously cached results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables the cache of this object.", "response": "def enable_caching(self):\n        \"Enable the cache of this object.\"\n        self.caching_enabled = True\n        for c in self.values():\n            c.enable_cacher()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SCG(f, gradf, x, optargs=(), maxiters=500, max_f_eval=np.inf, xtol=None, ftol=None, gtol=None):\n    if xtol is None:\n        xtol = 1e-6\n    if ftol is None:\n        ftol = 1e-6\n    if gtol is None:\n        gtol = 1e-5\n\n    sigma0 = 1.0e-7\n    fold = f(x, *optargs) # Initial function value.\n    function_eval = 1\n    fnow = fold\n    gradnew = gradf(x, *optargs) # Initial gradient.\n    function_eval += 1\n    #if any(np.isnan(gradnew)):\n    #    raise UnexpectedInfOrNan, \"Gradient contribution resulted in a NaN value\"\n    current_grad = np.dot(gradnew, gradnew)\n    gradold = gradnew.copy()\n    d = -gradnew # Initial search direction.\n    success = True # Force calculation of directional derivs.\n    nsuccess = 0 # nsuccess counts number of successes.\n    beta = 1.0 # Initial scale parameter.\n    betamin = 1.0e-15 # Lower bound on scale.\n    betamax = 1.0e15 # Upper bound on scale.\n    status = \"Not converged\"\n\n    flog = [fold]\n\n    iteration = 0\n\n    # Main optimization loop.\n    while iteration < maxiters:\n\n        # Calculate first and second directional derivatives.\n        if success:\n            mu = np.dot(d, gradnew)\n            if mu >= 0:  # pragma: no cover\n                d = -gradnew\n                mu = np.dot(d, gradnew)\n            kappa = np.dot(d, d)\n            sigma = sigma0 / np.sqrt(kappa)\n            xplus = x + sigma * d\n            gplus = gradf(xplus, *optargs)\n            function_eval += 1\n            theta = np.dot(d, (gplus - gradnew)) / sigma\n\n        # Increase effective curvature and evaluate step size alpha.\n        delta = theta + beta * kappa\n        if delta <= 0: # pragma: no cover\n            delta = beta * kappa\n            beta = beta - theta / kappa\n\n        alpha = -mu / delta\n\n        # Calculate the comparison ratio.\n        xnew = x + alpha * d\n        fnew = f(xnew, *optargs)\n        function_eval += 1\n\n        Delta = 2.*(fnew - fold) / (alpha * mu)\n        if Delta >= 0.:\n            success = True\n            nsuccess += 1\n            x = xnew\n            fnow = fnew\n        else:\n            success = False\n            fnow = fold\n\n        # Store relevant variables\n        flog.append(fnow) # Current function value\n\n        iteration += 1\n\n        if success:\n            # Test for termination\n\n            if (np.abs(fnew - fold) < ftol):\n                status = 'converged - relative reduction in objective'\n                break\n#                 return x, flog, function_eval, status\n            elif (np.max(np.abs(alpha * d)) < xtol):\n                status = 'converged - relative stepsize'\n                break\n            else:\n                # Update variables for new position\n                gradold = gradnew\n                gradnew = gradf(x, *optargs)\n                function_eval += 1\n                current_grad = np.dot(gradnew, gradnew)\n                fold = fnew\n                # If the gradient is zero then we are done.\n                if current_grad <= gtol:\n                    status = 'converged - relative reduction in gradient'\n                    break\n                    # return x, flog, function_eval, status\n\n        # Adjust beta according to comparison ratio.\n        if Delta < 0.25:\n            beta = min(4.0 * beta, betamax)\n        if Delta > 0.75:\n            beta = max(0.25 * beta, betamin)\n\n        # Update search direction using Polak-Ribiere formula, or re-start\n        # in direction of negative gradient after nparams steps.\n        if nsuccess == x.size:\n            d = -gradnew\n            beta = 1. # This is not in the original paper\n            nsuccess = 0\n        elif success:\n            Gamma = np.dot(gradold - gradnew, gradnew) / (mu)\n            d = Gamma * d - gradnew\n    else:\n        # If we get here, then we haven't terminated in the given number of\n        # iterations.\n        status = \"maxiter exceeded\"\n\n    return x, flog, function_eval, status", "response": "This function is used to optimize a Scaled Conjugate Gradients."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving one observer which had priority and callble.", "response": "def remove(self, priority, observer, callble):\n        \"\"\"\n        Remove one observer, which had priority and callble.\n        \"\"\"\n        self.flush()\n        for i in range(len(self) - 1, -1, -1):\n            p,o,c = self[i]\n            if priority==p and observer==o and callble==c:\n                del self._poc[i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an observer with priority and callble.", "response": "def add(self, priority, observer, callble):\n        \"\"\"\n        Add an observer with priority and callble\n        \"\"\"\n        #if observer is not None:\n        ins = 0\n        for pr, _, _ in self:\n            if priority > pr:\n                break\n            ins += 1\n        self._poc.insert(ins, (priority, weakref.ref(observer), callble))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef properties_for(self, index):\n        return vectorize(lambda i: [prop for prop in self.properties() if i in self[prop]], otypes=[list])(index)", "response": "Returns a list of properties such that each entry in the list corresponds to the element of index given."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef properties_dict_for(self, index):\n        props = self.properties_for(index)\n        prop_index = extract_properties_to_index(index, props)\n        return prop_index", "response": "Return a dictionary containing properties as keys and indices as index\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noptimizing the model using the specified optimizer.", "response": "def optimize(self, optimizer=None, start=None, messages=False, max_iters=1000, ipython_notebook=True, clear_after_finish=False, **kwargs):\n        \"\"\"\n        Optimize the model using self.log_likelihood and self.log_likelihood_gradient, as well as self.priors.\n\n        kwargs are passed to the optimizer. They can be:\n\n        :param max_iters: maximum number of function evaluations\n        :type max_iters: int\n        :messages: True: Display messages during optimisation, \"ipython_notebook\":\n        :type messages: bool\"string\n        :param optimizer: which optimizer to use (defaults to self.preferred optimizer)\n        :type optimizer: string\n\n        Valid optimizers are:\n          - 'scg': scaled conjugate gradient method, recommended for stability.\n                   See also GPy.inference.optimization.scg\n          - 'fmin_tnc': truncated Newton method (see scipy.optimize.fmin_tnc)\n          - 'simplex': the Nelder-Mead simplex method (see scipy.optimize.fmin),\n          - 'lbfgsb': the l-bfgs-b method (see scipy.optimize.fmin_l_bfgs_b),\n          - 'lbfgs': the bfgs method (see scipy.optimize.fmin_bfgs),\n          - 'sgd': stochastic gradient decsent (see scipy.optimize.sgd). For experts only!\n\n\n        \"\"\"\n        if self.is_fixed or self.size == 0:\n            print('nothing to optimize')\n            return\n\n        if not self.update_model():\n            print(\"updates were off, setting updates on again\")\n            self.update_model(True)\n\n        if start is None:\n            start = self.optimizer_array\n\n        if optimizer is None:\n            optimizer = self.preferred_optimizer\n\n        if isinstance(optimizer, optimization.Optimizer):\n            opt = optimizer\n            opt.model = self\n        else:\n            optimizer = optimization.get_optimizer(optimizer)\n            opt = optimizer(max_iters=max_iters, **kwargs)\n\n        with VerboseOptimization(self, opt, maxiters=max_iters, verbose=messages, ipython_notebook=ipython_notebook, clear_after_finish=clear_after_finish) as vo:\n            opt.run(start, f_fp=self._objective_grads, f=self._objective, fp=self._grads)\n\n        self.optimizer_array = opt.x_opt\n\n        self.optimization_runs.append(opt)\n        return opt"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms random restarts of the model and set the model to the best seen solution.", "response": "def optimize_restarts(self, num_restarts=10, robust=False, verbose=True, parallel=False, num_processes=None, **kwargs):\n        \"\"\"\n        Perform random restarts of the model, and set the model to the best\n        seen solution.\n\n        If the robust flag is set, exceptions raised during optimizations will\n        be handled silently.  If _all_ runs fail, the model is reset to the\n        existing parameter values.\n\n        \\*\\*kwargs are passed to the optimizer.\n\n        :param num_restarts: number of restarts to use (default 10)\n        :type num_restarts: int\n        :param robust: whether to handle exceptions silently or not (default False)\n        :type robust: bool\n        :param parallel: whether to run each restart as a separate process. It relies on the multiprocessing module.\n        :type parallel: bool\n        :param num_processes: number of workers in the multiprocessing pool\n        :type numprocesses: int\n        :param max_f_eval: maximum number of function evaluations\n        :type max_f_eval: int\n        :param max_iters: maximum number of iterations\n        :type max_iters: int\n        :param messages: whether to display during optimisation\n        :type messages: bool\n\n        .. note::\n\n            If num_processes is None, the number of workes in the\n            multiprocessing pool is automatically set to the number of processors\n            on the current machine.\n\n        \"\"\"\n        initial_length = len(self.optimization_runs)\n        initial_parameters = self.optimizer_array.copy()\n\n        if parallel: #pragma: no cover\n            try:\n                pool = mp.Pool(processes=num_processes)\n                obs = [self.copy() for i in range(num_restarts)]\n                [obs[i].randomize() for i in range(num_restarts-1)]\n                jobs = pool.map(opt_wrapper, [(o,kwargs) for o in obs])\n                pool.close()\n                pool.join()\n            except KeyboardInterrupt:\n                print(\"Ctrl+c received, terminating and joining pool.\")\n                pool.terminate()\n                pool.join()\n\n        for i in range(num_restarts):\n            try:\n                if not parallel:\n                    if i > 0:\n                        self.randomize()\n                    self.optimize(**kwargs)\n                else:#pragma: no cover\n                    self.optimization_runs.append(jobs[i])\n\n                if verbose:\n                    print((\"Optimization restart {0}/{1}, f = {2}\".format(i + 1, num_restarts, self.optimization_runs[-1].f_opt)))\n            except Exception as e:\n                if robust:\n                    print((\"Warning - optimization restart {0}/{1} failed\".format(i + 1, num_restarts)))\n                else:\n                    raise e\n\n        if len(self.optimization_runs) > initial_length:\n            # This works, since failed jobs don't get added to the optimization_runs.\n            i = np.argmin([o.f_opt for o in self.optimization_runs[initial_length:]])\n            self.optimizer_array = self.optimization_runs[initial_length + i].x_opt\n        else:\n            self.optimizer_array = initial_parameters\n        return self.optimization_runs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _grads(self, x):\n        try:\n            # self._set_params_transformed(x)\n            self.optimizer_array = x\n            self.obj_grads = self._transform_gradients(self.objective_function_gradients())\n            self._fail_count = 0\n        except (LinAlgError, ZeroDivisionError, ValueError): #pragma: no cover\n            if self._fail_count >= self._allowed_failures:\n                raise\n            self._fail_count += 1\n            self.obj_grads = np.clip(self._transform_gradients(self.objective_function_gradients()), -1e100, 1e100)\n        return self.obj_grads", "response": "Gets the gradients from the likelihood and priors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _objective(self, x):\n        try:\n            self.optimizer_array = x\n            obj = self.objective_function()\n            self._fail_count = 0\n        except (LinAlgError, ZeroDivisionError, ValueError):#pragma: no cover\n            if self._fail_count >= self._allowed_failures:\n                raise\n            self._fail_count += 1\n            return np.inf\n        return obj", "response": "This method is used to compute the objective function of the object. It uses the optimizer function to compute the objective function and then raises the original exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the gradient of the model.", "response": "def _checkgrad(self, target_param=None, verbose=False, step=1e-6, tolerance=1e-3, df_tolerance=1e-12):\n        \"\"\"\n        Check the gradient of the ,odel by comparing to a numerical\n        estimate.  If the verbose flag is passed, individual\n        components are tested (and printed)\n\n        :param verbose: If True, print a \"full\" checking of each parameter\n        :type verbose: bool\n        :param step: The size of the step around which to linearise the objective\n        :type step: float (default 1e-6)\n        :param tolerance: the tolerance allowed (see note)\n        :type tolerance: float (default 1e-3)\n\n        Note:-\n           The gradient is considered correct if the ratio of the analytical\n           and numerical gradients is within <tolerance> of unity.\n\n           The *dF_ratio* indicates the limit of numerical accuracy of numerical gradients.\n           If it is too small, e.g., smaller than 1e-12, the numerical gradients are usually\n           not accurate enough for the tests (shown with blue).\n        \"\"\"\n        if not self._model_initialized_:\n            import warnings\n            warnings.warn(\"This model has not been initialized, try model.inititialize_model()\", RuntimeWarning)\n            return False\n\n        x = self.optimizer_array.copy()\n\n        if not verbose:\n            # make sure only to test the selected parameters\n            if target_param is None:\n                transformed_index = np.arange(len(x))\n            else:\n                transformed_index = self._raveled_index_for_transformed(target_param)\n\n                if transformed_index.size == 0:\n                    print(\"No free parameters to check\")\n                    return True\n\n            # just check the global ratio\n            dx = np.zeros(x.shape)\n            dx[transformed_index] = step * (np.sign(np.random.uniform(-1, 1, transformed_index.size)) if transformed_index.size != 2 else 1.)\n\n            # evaulate around the point x\n            f1 = self._objective(x + dx)\n            f2 = self._objective(x - dx)\n            gradient = self._grads(x)\n\n            dx = dx[transformed_index]\n            gradient = gradient[transformed_index]\n\n            denominator = (2 * np.dot(dx, gradient))\n            global_ratio = (f1 - f2) / np.where(denominator == 0., 1e-32, denominator)\n            global_diff = np.abs(f1 - f2) < tolerance and np.allclose(gradient, 0, atol=tolerance)\n            if global_ratio is np.nan: # pragma: no cover\n                global_ratio = 0\n            return np.abs(1. - global_ratio) < tolerance or global_diff\n        else:\n            # check the gradient of each parameter individually, and do some pretty printing\n            try:\n                names = self.parameter_names_flat()\n            except NotImplementedError:\n                names = ['Variable %i' % i for i in range(len(x))]\n            # Prepare for pretty-printing\n            header = ['Name', 'Ratio', 'Difference', 'Analytical', 'Numerical', 'dF_ratio']\n            max_names = max([len(names[i]) for i in range(len(names))] + [len(header[0])])\n            float_len = 10\n            cols = [max_names]\n            cols.extend([max(float_len, len(header[i])) for i in range(1, len(header))])\n            cols = np.array(cols) + 5\n            header_string = [\"{h:^{col}}\".format(h=header[i], col=cols[i]) for i in range(len(cols))]\n            header_string = list(map(lambda x: '|'.join(x), [header_string]))\n            separator = '-' * len(header_string[0])\n            print('\\n'.join([header_string[0], separator]))\n\n            if target_param is None:\n                target_param = self\n            transformed_index = self._raveled_index_for_transformed(target_param)\n\n            if transformed_index.size == 0:\n                print(\"No free parameters to check\")\n                return True\n\n            gradient = self._grads(x).copy()\n            np.where(gradient == 0, 1e-312, gradient)\n            ret = True\n            for xind in zip(transformed_index):\n                xx = x.copy()\n                xx[xind] += step\n                f1 = float(self._objective(xx))\n                xx[xind] -= 2.*step\n                f2 = float(self._objective(xx))\n                #Avoid divide by zero, if any of the values are above 1e-15, otherwise both values are essentiall\n                #the same\n                if f1 > 1e-15 or f1 < -1e-15 or f2 > 1e-15 or f2 < -1e-15:\n                    df_ratio = np.abs((f1 - f2) / min(f1, f2))\n                else: # pragma: no cover\n                    df_ratio = 1.0\n                df_unstable = df_ratio < df_tolerance\n                numerical_gradient = (f1 - f2) / (2. * step)\n                if np.all(gradient[xind] == 0): # pragma: no cover\n                    ratio = (f1 - f2) == gradient[xind]\n                else:\n                    ratio = (f1 - f2) / (2. * step * gradient[xind])\n                difference = np.abs(numerical_gradient - gradient[xind])\n\n                if (np.abs(1. - ratio) < tolerance) or np.abs(difference) < tolerance:\n                    formatted_name = \"\\033[92m {0} \\033[0m\".format(names[xind])\n                    ret &= True\n                else:  # pragma: no cover\n                    formatted_name = \"\\033[91m {0} \\033[0m\".format(names[xind])\n                    ret &= False\n                if df_unstable:  # pragma: no cover\n                    formatted_name = \"\\033[94m {0} \\033[0m\".format(names[xind])\n\n                r = '%.6f' % float(ratio)\n                d = '%.6f' % float(difference)\n                g = '%.6f' % gradient[xind]\n                ng = '%.6f' % float(numerical_gradient)\n                df = '%1.e' % float(df_ratio)\n                grad_string = \"{0:<{c0}}|{1:^{c1}}|{2:^{c2}}|{3:^{c3}}|{4:^{c4}}|{5:^{c5}}\".format(formatted_name, r, d, g, ng, df, c0=cols[0] + 9, c1=cols[1], c2=cols[2], c3=cols[3], c4=cols[4], c5=cols[5])\n                print(grad_string)\n\n            self.optimizer_array = x\n            return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_index_operation(self, name, operations):\n        if name not in self._index_operations:\n            self._add_io(name, operations)\n        else:\n            raise AttributeError(\"An index operation with the name {} was already taken\".format(name))", "response": "Add an index operation with name to the operations given."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _disconnect_parent(self, *args, **kw):\n        for name, iop in list(self._index_operations.items()):\n            iopc = iop.copy()\n            iop.clear()\n            self.remove_index_operation(name)\n            self.add_index_operation(name, iopc)\n        #self.constraints.clear()\n        #self.constraints = constr\n        self._parent_ = None\n        self._parent_index_ = None\n        self._connect_fixes()\n        self._notify_parent_change()", "response": "Disconnect the parent and set the constraints to constr\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the offset of the parameter in this object.", "response": "def _offset_for(self, param):\n        \"\"\"\n        Return the offset of the param inside this parameterized object.\n        This does not need to account for shaped parameters, as it\n        basically just sums up the parameter sizes which come before param.\n        \"\"\"\n        if param.has_parent():\n            p = param._parent_._get_original(param)\n            if p in self.parameters:\n                return reduce(lambda a,b: a + b.size, self.parameters[:p._parent_index_], 0)\n            return self._offset_for(param._parent_) + param._parent_._offset_for(param)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _raveled_index_for(self, param):\n        from ..param import ParamConcatenation\n        if isinstance(param, ParamConcatenation):\n            return np.hstack((self._raveled_index_for(p) for p in param.params))\n        return param._raveled_index() + self._offset_for(param)", "response": "get the raveled index for a param"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the raveled index for a parameter array", "response": "def _raveled_index_for_transformed(self, param):\n        \"\"\"\n        get the raveled index for a param for the transformed parameter array\n        (optimizer array).\n\n        that is an int array, containing the indexes for the flattened\n        param inside this parameterized logic.\n\n        !Warning! be sure to call this method on the highest parent of a hierarchy,\n        as it uses the fixes to do its work. If you do not know\n        what you are doing, do not use this method, it will have\n        unexpected returns!\n        \"\"\"\n        ravi = self._raveled_index_for(param)\n        if self._has_fixes():\n            fixes = self._fixes_\n            ### Transformed indices, handling the offsets of previous fixes\n            transformed = (np.r_[:self.size] - (~fixes).cumsum())\n            return transformed[ravi[fixes[ravi]]]\n        else:\n            return ravi"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parent_changed(self, parent):\n        from .index_operations import ParameterIndexOperationsView\n        #if getattr(self, \"_in_init_\"):\n            #import ipdb;ipdb.set_trace()\n            #self.constraints.update(param.constraints, start)\n            #self.priors.update(param.priors, start)\n        offset = parent._offset_for(self)\n        for name, iop in list(self._index_operations.items()):\n            self.remove_index_operation(name)\n            self.add_index_operation(name, ParameterIndexOperationsView(parent._index_operations[name], offset, self.size))\n        self._fixes_ = None\n        for p in self.parameters:\n            p._parent_changed(parent)", "response": "Called when the parent has changed the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        from .lists_and_dicts import ObserverList\n        memo = {}\n        memo[id(self)] = self\n        memo[id(self.observers)] = ObserverList()\n        return self.__deepcopy__(memo)", "response": "Make a copy of this object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the model with the current state of the entry.", "response": "def update_model(self, updates=None):\n        \"\"\"\n        Get or set, whether automatic updates are performed. When updates are\n        off, the model might be in a non-working state. To make the model work\n        turn updates on again.\n\n        :param bool|None updates:\n\n            bool: whether to do updates\n            None: get the current update state\n        \"\"\"\n        if updates is None:\n            return self._update_on\n        assert isinstance(updates, bool), \"updates are either on (True) or off (False)\"\n        p = getattr(self, '_highest_parent_', None)\n        def turn_updates(s):\n            s._update_on = updates\n        p.traverse(turn_updates)\n        self.trigger_update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trigger_update(self, trigger_parent=True):\n        if not self.update_model() or (hasattr(self, \"_in_init_\") and self._in_init_):\n            #print \"Warning: updates are off, updating the model will do nothing\"\n            return\n        self._trigger_params_changed(trigger_parent)", "response": "Update the model from the current state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the array of parameters for the optimizer.", "response": "def optimizer_array(self):\n        \"\"\"\n        Array for the optimizer to work on.\n        This array always lives in the space for the optimizer.\n        Thus, it is untransformed, going from Transformations.\n\n        Setting this array, will make sure the transformed parameters for this model\n        will be set accordingly. It has to be set with an array, retrieved from\n        this method, as e.g. fixing will resize the array.\n\n        The optimizer should only interfere with this array, such that transformations\n        are secured.\n        \"\"\"\n        if self.__dict__.get('_optimizer_copy_', None) is None or self.size != self._optimizer_copy_.size:\n            self._optimizer_copy_ = np.empty(self.size)\n\n        if not self._optimizer_copy_transformed:\n            self._optimizer_copy_.flat = self.param_array.flat\n            #py3 fix\n            #[np.put(self._optimizer_copy_, ind, c.finv(self.param_array[ind])) for c, ind in self.constraints.iteritems() if c != __fixed__]\n            [np.put(self._optimizer_copy_, ind, c.finv(self.param_array[ind])) for c, ind in self.constraints.items() if c != __fixed__]\n            self._optimizer_copy_transformed = True\n\n        if self._has_fixes():# or self._has_ties()):\n            self._ensure_fixes()\n            return self._optimizer_copy_[self._fixes_]\n        return self._optimizer_copy_"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef optimizer_array(self, p):\n        f = None\n        if self.has_parent() and self.constraints[__fixed__].size != 0:\n            f = np.ones(self.size).astype(bool)\n            f[self.constraints[__fixed__]] = FIXED\n        elif self._has_fixes():\n            f = self._fixes_\n        if f is None:\n            self.param_array.flat = p\n            [np.put(self.param_array, ind, c.f(self.param_array.flat[ind]))\n             #py3 fix\n             #for c, ind in self.constraints.iteritems() if c != __fixed__]\n             for c, ind in self.constraints.items() if c != __fixed__]\n        else:\n            self.param_array.flat[f] = p\n            [np.put(self.param_array, ind[f[ind]], c.f(self.param_array.flat[ind[f[ind]]]))\n             #py3 fix\n             #for c, ind in self.constraints.iteritems() if c != __fixed__]\n             for c, ind in self.constraints.items() if c != __fixed__]\n        #self._highest_parent_.tie.propagate_val()\n\n        self._optimizer_copy_transformed = False\n        self.trigger_update()", "response": "This method is called by the optimizer to update the parameter_array with the values from the parameters in the optimizer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntrigger all children to update and notify observers of parameters changed", "response": "def _trigger_params_changed(self, trigger_parent=True):\n        \"\"\"\n        First tell all children to update,\n        then update yourself.\n\n        If trigger_parent is True, we will tell the parent, otherwise not.\n        \"\"\"\n        [p._trigger_params_changed(trigger_parent=False) for p in self.parameters if not p.is_fixed]\n        self.notify_observers(None, None if trigger_parent else -np.inf)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _transform_gradients(self, g):\n        #py3 fix\n        #[np.put(g, i, c.gradfactor(self.param_array[i], g[i])) for c, i in self.constraints.iteritems() if c != __fixed__]\n        [np.put(g, i, c.gradfactor(self.param_array[i], g[i])) for c, i in self.constraints.items() if c != __fixed__]\n        if self._has_fixes(): return g[self._fixes_]\n        return g", "response": "Transform the gradients by multiplying the gradient factor for each\n        constraint to it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parameter_names(self, add_self=False, adjust_for_printing=False, recursive=True, intermediate=False):\n        if adjust_for_printing: adjust = adjust_name_for_printing\n        else: adjust = lambda x: x\n        names = []\n        if intermediate or (not recursive):\n            names.extend([adjust(x.name) for x in self.parameters])\n        if intermediate or recursive: names.extend([\n                xi for x in self.parameters for xi in\n                 x.parameter_names(add_self=True,\n                                   adjust_for_printing=adjust_for_printing,\n                                   recursive=True,\n                                   intermediate=False)])\n        if add_self: names = map(lambda x: adjust(self.name) + \".\" + x, names)\n        return names", "response": "Get the names of all parameters of this model or parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the flattened parameter names for all subsequent parameters .", "response": "def parameter_names_flat(self, include_fixed=False):\n        \"\"\"\n        Return the flattened parameter names for all subsequent parameters\n        of this parameter. We do not include the name for self here!\n\n        If you want the names for fixed parameters as well in this list,\n        set include_fixed to True.\n            if not hasattr(obj, 'cache'):\n                obj.cache = FunctionCacher()\n        :param bool include_fixed: whether to include fixed names here.\n        \"\"\"\n        name_list = []\n        for p in self.flattened_parameters:\n            name = p.hierarchy_name()\n            if p.size > 1:\n                name_list.extend([\"{}[{!s}]\".format(name, i) for i in p._indices()])\n            else:\n                name_list.append(name)\n        name_list = np.array(name_list)\n\n        if not include_fixed and self._has_fixes():\n            return name_list[self._fixes_]\n        return name_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrandomize the model. Make this draw from the rand_gen if one exists, else draw random normal(0,1) :param rand_gen: np random number generator which takes args and kwargs :param flaot loc: loc parameter for random number generator :param float scale: scale parameter for random number generator :param args, kwargs: will be passed through to random number generator", "response": "def randomize(self, rand_gen=None, *args, **kwargs):\n        \"\"\"\n        Randomize the model.\n        Make this draw from the rand_gen if one exists, else draw random normal(0,1)\n\n        :param rand_gen: np random number generator which takes args and kwargs\n        :param flaot loc: loc parameter for random number generator\n        :param float scale: scale parameter for random number generator\n        :param args, kwargs: will be passed through to random number generator\n        \"\"\"\n        if rand_gen is None:\n            rand_gen = np.random.normal\n        # first take care of all parameters (from N(0,1))\n        x = rand_gen(size=self._size_transformed(), *args, **kwargs)\n        updates = self.update_model()\n        self.update_model(False) # Switch off the updates\n        self.optimizer_array = x  # makes sure all of the tied parameters get the same init (since there's only one prior object...)\n        # now draw from prior where possible\n        x = self.param_array.copy()\n        unfixlist = np.ones((self.size,),dtype=np.bool)\n        unfixlist[self.constraints[__fixed__]] = False\n        self.param_array.flat[unfixlist] = x.view(np.ndarray).ravel()[unfixlist]\n        self.update_model(updates)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _propagate_param_grad(self, parray, garray):\n        #if self.param_array.size != self.size:\n        #    self._param_array_ = np.empty(self.size, dtype=np.float64)\n        #if self.gradient.size != self.size:\n        #    self._gradient_array_ = np.empty(self.size, dtype=np.float64)\n\n        pi_old_size = 0\n        for pi in self.parameters:\n            pislice = slice(pi_old_size, pi_old_size + pi.size)\n\n            self.param_array[pislice] = pi.param_array.flat  # , requirements=['C', 'W']).flat\n            self.gradient_full[pislice] = pi.gradient_full.flat  # , requirements=['C', 'W']).flat\n\n            pi.param_array.data = parray[pislice].data\n            pi.gradient_full.data = garray[pislice].data\n\n            pi._propagate_param_grad(parray[pislice], garray[pislice])\n            pi_old_size += pi.size\n\n        self._model_initialized_ = True", "response": "For propagating the param_array and gradient_array for each parameter and gradient_array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_parameter(self):\n        #logger.debug(\"connecting parameters\")\n        self._highest_parent_._notify_parent_change()\n        self._highest_parent_._connect_parameters() #logger.debug(\"calling parameters changed\")\n        self._highest_parent_._connect_fixes()\n        self.trigger_update()", "response": "Initialize the parameter of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\narray representing the parameters of this class.", "response": "def param_array(self):\n        \"\"\"\n        Array representing the parameters of this class.\n        There is only one copy of all parameters in memory, two during optimization.\n\n        !WARNING!: setting the parameter array MUST always be done in memory:\n        m.param_array[:] = m_copy.param_array\n        \"\"\"\n        if (self.__dict__.get('_param_array_', None) is None) or (self._param_array_.size != self.size):\n            self._param_array_ = np.empty(self.size, dtype=np.float64)\n        return self._param_array_"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unfixed_param_array(self):\n        if self.constraints[__fixed__].size !=0:\n            fixes = np.ones(self.size).astype(bool)\n            fixes[self.constraints[__fixed__]] = FIXED\n            return self._param_array_[fixes]\n        else:\n            return self._param_array_", "response": "Returns the array of unfixed parameters for this class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef traverse(self, visit, *args, **kwargs):\n        if not self.__visited:\n            visit(self, *args, **kwargs)\n            self.__visited = True\n            self._traverse(visit, *args, **kwargs)\n            self.__visited = False", "response": "Traverse the hierarchy performing visit on the node passed by downwards."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef traverse_parents(self, visit, *args, **kwargs):\n        if self.has_parent():\n            self.__visited = True\n            self._parent_.traverse_parents(visit, *args, **kwargs)\n            self._parent_.traverse(visit, *args, **kwargs)\n            self.__visited = False", "response": "Traverse the hierarchy upwards visiting all parents and their children except self."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, filename, ftype='HDF5'): # pragma: no coverage\n        from ..param import Param\n\n        def gather_params(self, plist):\n            if isinstance(self,Param):\n                plist.append(self)\n        plist = []\n        self.traverse(gather_params, plist)\n        names = self.parameter_names(adjust_for_printing=True)\n        if ftype=='HDF5':\n            try:\n                import h5py\n                f = h5py.File(filename,'w')\n                for p,n in zip(plist,names):\n                    n = n.replace('.','_')\n                    p = p.values\n                    d = f.create_dataset(n,p.shape,dtype=p.dtype)\n                    d[:] = p\n                if hasattr(self, 'param_array'):\n                    d = f.create_dataset('param_array',self.param_array.shape, dtype=self.param_array.dtype)\n                    d[:] = self.param_array\n                f.close()\n            except:\n                raise 'Fails to write the parameters into a HDF5 file!'", "response": "Save the model to a hdf5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the design matrix for this model using the given array - like Xpred and the given degrees.", "response": "def phi(self, Xpred, degrees=None):\n        \"\"\"\n        Compute the design matrix for this model\n        using the degrees given by the index array\n        in degrees\n\n        :param array-like Xpred: inputs to compute the design matrix for\n        :param array-like degrees: array of degrees to use [default=range(self.degree+1)]\n        :returns array-like phi: The design matrix [degree x #samples x #dimensions]\n        \"\"\"\n        assert Xpred.shape[1] == self.X.shape[1], \"Need to predict with same shape as training data.\"\n        if degrees is None:\n            degrees = range(self.basis.degree+1)\n        tmp_phi = np.empty((len(degrees), Xpred.shape[0], Xpred.shape[1]))\n        for i, w in enumerate(degrees):\n            # Objective function\n            tmpX = self._phi(Xpred, w)\n            tmp_phi[i] = tmpX * self.weights[[w], :]\n        return tmp_phi"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npickles the object to a file object.", "response": "def pickle(self, f, protocol=-1):\n        \"\"\"\n        :param f: either filename or open file object to write to.\n                  if it is an open buffer, you have to make sure to close\n                  it properly.\n        :param protocol: pickling protocol to use, python-pickle for details.\n        \"\"\"\n        try: #Py2\n            import cPickle as pickle\n            if isinstance(f, basestring):\n                with open(f, 'wb') as f:\n                    pickle.dump(self, f, protocol)\n            else:\n                pickle.dump(self, f, protocol)\n        except ImportError: #python3\n            import pickle\n            if isinstance(f, str):\n                with open(f, 'wb') as f:\n                    pickle.dump(self, f, protocol)\n            else:\n                pickle.dump(self, f, protocol)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self, memo=None, which=None):\n        #raise NotImplementedError, \"Copy is not yet implemented, TODO: Observable hierarchy\"\n        if memo is None:\n            memo = {}\n        import copy\n        # the next part makes sure that we do not include parents in any form:\n        parents = []\n        if which is None:\n            which = self\n        which.traverse_parents(parents.append) # collect parents\n        for p in parents:\n            if not id(p) in memo :memo[id(p)] = None # set all parents to be None, so they will not be copied\n        if not id(self.gradient) in memo:memo[id(self.gradient)] = None # reset the gradient\n        if not id(self._fixes_) in memo :memo[id(self._fixes_)] = None # fixes have to be reset, as this is now highest parent\n        copy = copy.deepcopy(self, memo) # and start the copy\n        copy._parent_index_ = None\n        copy._trigger_params_changed()\n        return copy", "response": "Returns a deep copy of the current parameter handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef consolidate_dependencies(needs_ipython, child_program,\n                             requirement_files, manual_dependencies):\n    \"\"\"Parse files, get deps and merge them. Deps read later overwrite those read earlier.\"\"\"\n    # We get the logger here because it's not defined at module level\n    logger = logging.getLogger('fades')\n\n    if needs_ipython:\n        logger.debug(\"Adding ipython dependency because --ipython was detected\")\n        ipython_dep = parsing.parse_manual(['ipython'])\n    else:\n        ipython_dep = {}\n\n    if child_program:\n        srcfile_deps = parsing.parse_srcfile(child_program)\n        logger.debug(\"Dependencies from source file: %s\", srcfile_deps)\n        docstring_deps = parsing.parse_docstring(child_program)\n        logger.debug(\"Dependencies from docstrings: %s\", docstring_deps)\n    else:\n        srcfile_deps = {}\n        docstring_deps = {}\n\n    all_dependencies = [ipython_dep, srcfile_deps, docstring_deps]\n\n    if requirement_files is not None:\n        for rf_path in requirement_files:\n            rf_deps = parsing.parse_reqfile(rf_path)\n            logger.debug('Dependencies from requirements file %r: %s', rf_path, rf_deps)\n            all_dependencies.append(rf_deps)\n\n    manual_deps = parsing.parse_manual(manual_dependencies)\n    logger.debug(\"Dependencies from parameters: %s\", manual_deps)\n    all_dependencies.append(manual_deps)\n\n    # Merge dependencies\n    indicated_deps = {}\n    for dep in all_dependencies:\n        for repo, info in dep.items():\n            indicated_deps.setdefault(repo, set()).update(info)\n\n    return indicated_deps", "response": "Parse files get deps and merge them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeciding which child program really is.", "response": "def decide_child_program(args_executable, args_child_program):\n    \"\"\"Decide which the child program really is (if any).\"\"\"\n    # We get the logger here because it's not defined at module level\n    logger = logging.getLogger('fades')\n\n    if args_executable:\n        # if --exec given, check that it's just the executable name,\n        # not absolute or relative paths\n        if os.path.sep in args_child_program:\n            logger.error(\n                \"The parameter to --exec must be a file name (to be found \"\n                \"inside venv's bin directory), not a file path: %r\",\n                args_child_program)\n            raise FadesError(\"File path given to --exec parameter\")\n\n        # indicated --execute, local and not analyzable for dependencies\n        analyzable_child_program = None\n        child_program = args_child_program\n    elif args_child_program is not None:\n        # normal case, the child program is to be analyzed (being it local or remote)\n        if args_child_program.startswith((\"http://\", \"https://\")):\n            args_child_program = helpers.download_remote_script(args_child_program)\n        else:\n            if not os.access(args_child_program, os.R_OK):\n                logger.error(\"'%s' not found. If you want to run an executable \"\n                             \"file from a library installed in the virtualenv \"\n                             \"check the `--exec` option in the help.\",\n                             args_child_program)\n                raise FadesError(\"child program  not found.\")\n        analyzable_child_program = args_child_program\n        child_program = args_child_program\n    else:\n        # not indicated executable, not child program, \"interpreter\" mode\n        analyzable_child_program = None\n        child_program = None\n\n    return analyzable_child_program, child_program"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetect if a given prefix is running inside a virtualenv.", "response": "def detect_inside_virtualenv(prefix, real_prefix, base_prefix):\n    \"\"\"Tell if fades is running inside a virtualenv.\n\n    The params 'real_prefix' and 'base_prefix' may be None.\n\n    This is copied from pip code (slightly modified), see\n\n        https://github.com/pypa/pip/blob/281eb61b09d87765d7c2b92f6982b3fe76ccb0af/\n            pip/locations.py#L39\n    \"\"\"\n    if real_prefix is not None:\n        return True\n\n    if base_prefix is None:\n        return False\n\n    # if prefix is different than base_prefix, it's a venv\n    return prefix != base_prefix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the parsed command line arguments.", "response": "def _get_normalized_args(parser):\n    \"\"\"Return the parsed command line arguments.\n\n    Support the case when executed from a shebang, where all the\n    parameters come in sys.argv[1] in a single string separated\n    by spaces (in this case, the third parameter is what is being\n    executed)\n    \"\"\"\n    env = os.environ\n    if '_' in env and env['_'] != sys.argv[0] and len(sys.argv) >= 1 and \" \" in sys.argv[1]:\n        return parser.parse_args(shlex.split(sys.argv[1]) + sys.argv[2:])\n    else:\n        return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake the magic happen.", "response": "def go():\n    \"\"\"Make the magic happen.\"\"\"\n    parser = argparse.ArgumentParser(prog='PROG', epilog=help_epilog,\n                                     formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument('-V', '--version', action='store_true',\n                        help=\"show version and info about the system, and exit\")\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help=\"send all internal debugging lines to stderr, which may be very \"\n                             \"useful to debug any problem that may arise.\")\n    parser.add_argument('-q', '--quiet', action='store_true',\n                        help=\"don't show anything (unless it has a real problem), so the \"\n                             \"original script stderr is not polluted at all.\")\n    parser.add_argument('-d', '--dependency', action='append',\n                        help=\"specify dependencies through command line (this option can be \"\n                             \"used multiple times)\")\n    parser.add_argument('-r', '--requirement', action='append',\n                        help=\"indicate files to read dependencies from (this option can be \"\n                             \"used multiple times)\")\n    parser.add_argument('-p', '--python', action='store',\n                        help=(\"Specify the Python interpreter to use.\\n\"\n                              \" Default is: %s\") % (sys.executable,))\n    parser.add_argument('-x', '--exec', dest='executable', action='store_true',\n                        help=(\"Indicate that the child_program should be looked up in the \"\n                              \"virtualenv.\"))\n    parser.add_argument('-i', '--ipython', action='store_true', help=\"use IPython shell.\")\n    parser.add_argument('--system-site-packages', action='store_true', default=False,\n                        help=(\"Give the virtual environment access to the \"\n                              \"system site-packages dir.\"))\n    parser.add_argument('--virtualenv-options', action='append', default=[],\n                        help=(\"Extra options to be supplied to virtualenv. (this option can be \"\n                              \"used multiple times)\"))\n    parser.add_argument('--check-updates', action='store_true',\n                        help=(\"check for packages updates\"))\n    parser.add_argument('--no-precheck-availability', action='store_true',\n                        help=(\"Don't check if the packages exists in PyPI before actually try \"\n                              \"to install them.\"))\n    parser.add_argument('--pip-options', action='append', default=[],\n                        help=(\"Extra options to be supplied to pip. (this option can be \"\n                              \"used multiple times)\"))\n    parser.add_argument('--python-options', action='append', default=[],\n                        help=(\"Extra options to be supplied to python. (this option can be \"\n                              \"used multiple times)\"))\n    parser.add_argument('--rm', dest='remove', metavar='UUID',\n                        help=(\"Remove a virtualenv by UUID. See --get-venv-dir option to \"\n                              \"easily find out the UUID.\"))\n    parser.add_argument('--clean-unused-venvs', action='store',\n                        help=(\"This option remove venvs that haven't been used for more than \"\n                              \"CLEAN_UNUSED_VENVS days. Appart from that, will compact usage \"\n                              \"stats file.\\n\"\n                              \"When this option is present, the cleaning takes place at the \"\n                              \"beginning of the execution.\"))\n    parser.add_argument('--get-venv-dir', action='store_true',\n                        help=(\"Show the virtualenv base directory (which includes the \"\n                              \"virtualenv UUID) and quit.\"))\n    parser.add_argument('child_program', nargs='?', default=None)\n    parser.add_argument('child_options', nargs=argparse.REMAINDER)\n\n    cli_args = _get_normalized_args(parser)\n\n    # update args from config file (if needed).\n    args = file_options.options_from_file(cli_args)\n\n    # validate input, parameters, and support some special options\n    if args.version:\n        print(\"Running 'fades' version\", fades.__version__)\n        print(\"    Python:\", sys.version_info)\n        print(\"    System:\", platform.platform())\n        return 0\n\n    # set up logger and dump basic version info\n    logger = fades_logger.set_up(args.verbose, args.quiet)\n    logger.debug(\"Running Python %s on %r\", sys.version_info, platform.platform())\n    logger.debug(\"Starting fades v. %s\", fades.__version__)\n    logger.debug(\"Arguments: %s\", args)\n\n    # verify that the module is NOT being used from a virtualenv\n    if detect_inside_virtualenv(sys.prefix, getattr(sys, 'real_prefix', None),\n                                getattr(sys, 'base_prefix', None)):\n        logger.error(\n            \"fades is running from inside a virtualenv (%r), which is not supported\", sys.prefix)\n        raise FadesError(\"Cannot run from a virtualenv\")\n\n    if args.verbose and args.quiet:\n        logger.warning(\"Overriding 'quiet' option ('verbose' also requested)\")\n\n    # start the virtualenvs manager\n    venvscache = cache.VEnvsCache(os.path.join(helpers.get_basedir(), 'venvs.idx'))\n    # start usage manager\n    usage_manager = envbuilder.UsageManager(os.path.join(helpers.get_basedir(), 'usage_stats'),\n                                            venvscache)\n\n    if args.clean_unused_venvs:\n        try:\n            max_days_to_keep = int(args.clean_unused_venvs)\n        except ValueError:\n            logger.error(\"clean_unused_venvs must be an integer.\")\n            raise FadesError('clean_unused_venvs not an integer')\n\n        usage_manager.clean_unused_venvs(max_days_to_keep)\n        return 0\n\n    uuid = args.remove\n    if uuid:\n        venv_data = venvscache.get_venv(uuid=uuid)\n        if venv_data:\n            # remove this venv from the cache\n            env_path = venv_data.get('env_path')\n            if env_path:\n                envbuilder.destroy_venv(env_path, venvscache)\n            else:\n                logger.warning(\"Invalid 'env_path' found in virtualenv metadata: %r. \"\n                               \"Not removing virtualenv.\", env_path)\n        else:\n            logger.warning('No virtualenv found with uuid: %s.', uuid)\n        return 0\n\n    # decided which the child program really is\n    analyzable_child_program, child_program = decide_child_program(\n        args.executable, args.child_program)\n\n    # Group and merge dependencies\n    indicated_deps = consolidate_dependencies(args.ipython,\n                                              analyzable_child_program,\n                                              args.requirement,\n                                              args.dependency)\n\n    # Check for packages updates\n    if args.check_updates:\n        helpers.check_pypi_updates(indicated_deps)\n\n    # get the interpreter version requested for the child_program\n    interpreter, is_current = helpers.get_interpreter_version(args.python)\n\n    # options\n    pip_options = args.pip_options  # pip_options mustn't store.\n    python_options = args.python_options\n    options = {}\n    options['pyvenv_options'] = []\n    options['virtualenv_options'] = args.virtualenv_options\n    if args.system_site_packages:\n        options['virtualenv_options'].append(\"--system-site-packages\")\n        options['pyvenv_options'] = [\"--system-site-packages\"]\n\n    create_venv = False\n    venv_data = venvscache.get_venv(indicated_deps, interpreter, uuid, options)\n    if venv_data:\n        env_path = venv_data['env_path']\n        # A venv was found in the cache check if its valid or re-generate it.\n        if not os.path.exists(env_path):\n            logger.warning(\"Missing directory (the virtualenv will be re-created): %r\", env_path)\n            venvscache.remove(env_path)\n            create_venv = True\n    else:\n        create_venv = True\n\n    if create_venv:\n        # Check if the requested packages exists in pypi.\n        if not args.no_precheck_availability and indicated_deps.get('pypi'):\n            logger.info(\"Checking the availabilty of dependencies in PyPI. \"\n                        \"You can use '--no-precheck-availability' to avoid it.\")\n            if not helpers.check_pypi_exists(indicated_deps):\n                logger.error(\"An indicated dependency doesn't exist. Exiting\")\n                raise FadesError(\"Required dependency does not exist\")\n\n        # Create a new venv\n        venv_data, installed = envbuilder.create_venv(indicated_deps, args.python, is_current,\n                                                      options, pip_options)\n        # store this new venv in the cache\n        venvscache.store(installed, venv_data, interpreter, options)\n\n    if args.get_venv_dir:\n        # all it was requested is the virtualenv's path, show it and quit (don't run anything)\n        print(venv_data['env_path'])\n        return 0\n\n    # run forest run!!\n    python_exe = 'ipython' if args.ipython else 'python'\n    python_exe = os.path.join(venv_data['env_bin_path'], python_exe)\n\n    # add the virtualenv /bin path to the child PATH.\n    environ_path = venv_data['env_bin_path']\n    if 'PATH' in os.environ:\n        environ_path += os.pathsep + os.environ['PATH']\n    os.environ['PATH'] = environ_path\n\n    # store usage information\n    usage_manager.store_usage_stat(venv_data, venvscache)\n    if child_program is None:\n        interactive = True\n        logger.debug(\n            \"Calling the interactive Python interpreter with arguments %r\", python_options)\n        cmd = [python_exe] + python_options\n        p = subprocess.Popen(cmd)\n    else:\n        interactive = False\n        if args.executable:\n            cmd = [os.path.join(venv_data['env_bin_path'], child_program)]\n            logger.debug(\"Calling child program %r with options %s\",\n                         child_program, args.child_options)\n        else:\n            cmd = [python_exe] + python_options + [child_program]\n            logger.debug(\n                \"Calling Python interpreter with arguments %s to execute the child program\"\n                \" %r with options %s\", python_options, child_program, args.child_options)\n\n        try:\n            p = subprocess.Popen(cmd + args.child_options)\n        except FileNotFoundError:\n            logger.error(\"Command not found: %s\", child_program)\n            raise FadesError(\"Command not found\")\n\n    def _signal_handler(signum, _):\n        \"\"\"Handle signals received by parent process, send them to child.\n\n        The only exception is CTRL-C, that is generated *from* the interactive\n        interpreter (it's a keyboard combination!), so we swallow it for the\n        interpreter to not see it twice.\n        \"\"\"\n        if interactive and signum == signal.SIGINT:\n            logger.debug(\"Swallowing signal %s\", signum)\n        else:\n            logger.debug(\"Redirecting signal %s to child\", signum)\n            os.kill(p.pid, signum)\n\n    # redirect the useful signals\n    for s in REDIRECTED_SIGNALS:\n        signal.signal(s, _signal_handler)\n\n    # wait child to finish, end\n    rc = p.wait()\n    if rc:\n        logger.debug(\"Child process not finished correctly: returncode=%d\", rc)\n    return rc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_up(verbose, quiet):\n    logger = logging.getLogger('fades')\n    logger.setLevel(logging.DEBUG)\n\n    # select logging level according to user desire; also use a simpler\n    # formatting for non-verbose logging\n    if verbose:\n        log_level = logging.DEBUG\n        log_format = FMT_DETAILED\n    elif quiet:\n        log_level = logging.WARNING\n        log_format = FMT_SIMPLE\n    else:\n        log_level = logging.INFO\n        log_format = FMT_SIMPLE\n\n    # all to the stdout\n    handler = SalutingStreamHandler(logger)\n    handler.setLevel(log_level)\n    logger.addHandler(handler)\n    formatter = logging.Formatter(log_format)\n    handler.setFormatter(formatter)\n\n    # and to the syslog\n    for syslog_path in ('/dev/log', '/var/run/syslog'):\n        if not os.path.exists(syslog_path):\n            continue\n        try:\n            handler = logging.handlers.SysLogHandler(address=syslog_path)\n        except Exception:\n            # silently ignore that the user doesn't have a syslog active; can\n            # see all the info with \"-v\" anyway\n            pass\n        else:\n            logger.addHandler(handler)\n            formatter = logging.Formatter(FMT_SYSLOG)\n            handler.setFormatter(formatter)\n            break\n\n    return logger", "response": "Set up the logging."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef emit(self, record):\n        if not self._already_saluted:\n            self._already_saluted = True\n            self._logger.info(SALUTATION)\n        super().emit(record)", "response": "Call father s emit but salute first."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a requirement and repo from the given text already parsed and converted.", "response": "def parse_fade_requirement(text):\n    \"\"\"Return a requirement and repo from the given text, already parsed and converted.\"\"\"\n    text = text.strip()\n\n    if \"::\" in text:\n        repo_raw, requirement = text.split(\"::\", 1)\n        try:\n            repo = {'pypi': REPO_PYPI, 'vcs': REPO_VCS}[repo_raw]\n        except KeyError:\n            logger.warning(\"Not understood fades repository: %r\", repo_raw)\n            return\n    else:\n        if \":\" in text and \"/\" in text:\n            repo = REPO_VCS\n        else:\n            repo = REPO_PYPI\n        requirement = text\n\n    if repo == REPO_VCS:\n        dependency = VCSDependency(requirement)\n    else:\n        dependency = list(parse_requirements(requirement))[0]\n    return repo, dependency"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the content of a script to find marked dependencies.", "response": "def _parse_content(fh):\n    \"\"\"Parse the content of a script to find marked dependencies.\"\"\"\n    content = iter(fh)\n    deps = {}\n\n    for line in content:\n        # quickly discard most of the lines\n        if 'fades' not in line:\n            continue\n\n        # discard other string with 'fades' that isn't a comment\n        if '#' not in line:\n            continue\n\n        # assure that it's a well commented line and no other stuff\n        line = line.strip()\n        index_of_last_fades = line.rfind('fades')\n        index_of_first_hash = line.index('#')\n\n        # discard when fades does not appear after #\n        if index_of_first_hash > index_of_last_fades:\n            continue\n\n        import_part, fades_part = line.rsplit(\"#\", 1)\n\n        # discard other comments in the same line that aren't for fades\n        if \"fades\" not in fades_part:\n            import_part, fades_part = import_part.rsplit(\"#\", 1)\n\n        fades_part = fades_part.strip()\n        if not fades_part.startswith(\"fades\"):\n            continue\n\n        if not import_part:\n            # the fades comment was done at the beginning of the line,\n            # which means that the import info is in the next one\n            import_part = next(content).strip()\n\n        if import_part.startswith('#'):\n            continue\n\n        # get module\n        import_tokens = import_part.split()\n        if import_tokens[0] == 'import':\n            module_path = import_tokens[1]\n        elif import_tokens[0] == 'from' and import_tokens[2] == 'import':\n            module_path = import_tokens[1]\n        else:\n            logger.debug(\"Not understood import info: %s\", import_tokens)\n            continue\n        module = module_path.split(\".\")[0]\n        # If fades know the real name of the pkg. Replace it!\n        if module in PKG_NAMES_DB:\n            module = PKG_NAMES_DB[module]\n        # To match the \"safe\" name that pkg_resources creates:\n        module = module.replace('_', '-')\n\n        # get the fades info after 'fades' mark, if any\n        if len(fades_part) == 5 or fades_part[5:].strip()[0] in \"<>=!\":\n            # just the 'fades' mark, and maybe a version specification, the requirement is what\n            # was imported (maybe with that version comparison)\n            requirement = module + fades_part[5:]\n        elif fades_part[5] != \" \":\n            # starts with fades but it's part of a longer weird word\n            logger.warning(\"Not understood fades info: %r\", fades_part)\n            continue\n        else:\n            # more complex stuff, to be parsed as a normal requirement\n            requirement = fades_part[5:]\n\n        # parse and convert the requirement\n        parsed_req = parse_fade_requirement(requirement)\n        if parsed_req is None:\n            continue\n        repo, dependency = parsed_req\n        deps.setdefault(repo, []).append(dependency)\n\n    return deps"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_docstring(fh):\n    find_fades = re.compile(r'\\b(fades)\\b:').search\n\n    for line in fh:\n        if line.startswith(\"'\"):\n            quote = \"'\"\n            break\n        if line.startswith('\"'):\n            quote = '\"'\n            break\n    else:\n        return {}\n\n    if line[1] == quote:\n        # comment start with triple quotes\n        endquote = quote * 3\n    else:\n        endquote = quote\n\n    if endquote in line[len(endquote):]:\n        docstring_lines = [line[:line.index(endquote)]]\n    else:\n        docstring_lines = [line]\n        for line in fh:\n            if endquote in line:\n                docstring_lines.append(line[:line.index(endquote)])\n                break\n            docstring_lines.append(line)\n\n    docstring_lines = iter(docstring_lines)\n    for doc_line in docstring_lines:\n        if find_fades(doc_line):\n            break\n    else:\n        return {}\n\n    return _parse_requirement(list(docstring_lines))", "response": "Parse the docstrings of a script to find marked dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a req file to a list to support nested requirement files.", "response": "def _read_lines(filepath):\n    \"\"\"Read a req file to a list to support nested requirement files.\"\"\"\n    with open(filepath, 'rt', encoding='utf8') as fh:\n        for line in fh:\n            line = line.strip()\n            if line.startswith(\"-r\"):\n                logger.debug(\"Reading deps from nested requirement file: %s\", line)\n                try:\n                    nested_filename = line.split()[1]\n                except IndexError:\n                    logger.warning(\n                        \"Invalid format to indicate a nested requirements file: '%r'\", line)\n                else:\n                    nested_filepath = os.path.join(\n                        os.path.dirname(filepath), nested_filename)\n                    yield from _read_lines(nested_filepath)\n            else:\n                yield line"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_venv(requested_deps, interpreter, is_current, options, pip_options):\n    # create virtualenv\n    env = _FadesEnvBuilder()\n    env_path, env_bin_path, pip_installed = env.create_env(interpreter, is_current, options)\n    venv_data = {}\n    venv_data['env_path'] = env_path\n    venv_data['env_bin_path'] = env_bin_path\n    venv_data['pip_installed'] = pip_installed\n\n    # install deps\n    installed = {}\n    for repo in requested_deps.keys():\n        if repo in (REPO_PYPI, REPO_VCS):\n            mgr = PipManager(env_bin_path, pip_installed=pip_installed, options=pip_options)\n        else:\n            logger.warning(\"Install from %r not implemented\", repo)\n            continue\n        installed[repo] = {}\n\n        repo_requested = requested_deps[repo]\n        logger.debug(\"Installing dependencies for repo %r: requested=%s\", repo, repo_requested)\n        for dependency in repo_requested:\n            try:\n                mgr.install(dependency)\n            except Exception:\n                logger.debug(\"Installation Step failed, removing virtualenv\")\n                destroy_venv(env_path)\n                raise FadesError('Dependency installation failed')\n\n            if repo == REPO_VCS:\n                # no need to request the installed version, as we'll always compare\n                # to the url itself\n                project = dependency.url\n                version = None\n            else:\n                # always store the installed dependency, as in the future we'll select the venv\n                # based on what is installed, not what used requested (remember that user may\n                # request >, >=, etc!)\n                project = dependency.project_name\n                version = mgr.get_version(project)\n            installed[repo][project] = version\n\n        logger.debug(\"Installed dependencies: %s\", installed)\n    return venv_data, installed", "response": "Create a new virtualenv with the requirements of this script."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_with_virtualenv(self, interpreter, virtualenv_options):\n        args = ['virtualenv', '--python', interpreter, self.env_path]\n        args.extend(virtualenv_options)\n        if not self.pip_installed:\n            args.insert(3, '--no-pip')\n        try:\n            helpers.logged_exec(args)\n            self.env_bin_path = os.path.join(self.env_path, 'bin')\n        except FileNotFoundError as error:\n            logger.error('Virtualenv is not installed. It is needed to create a virtualenv with '\n                         'a different python version than fades (got {})'.format(error))\n            raise FadesError('virtualenv not found')\n        except helpers.ExecutionError as error:\n            error.dump_to_log(logger)\n            raise FadesError('virtualenv could not be run')\n        except Exception as error:\n            logger.exception(\"Error creating virtualenv:  %s\", error)\n            raise FadesError('General error while running virtualenv')", "response": "Create a virtualenv using the virtualenv lib."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_env(self, interpreter, is_current, options):\n        if is_current:\n            # apply pyvenv options\n            pyvenv_options = options['pyvenv_options']\n            if \"--system-site-packages\" in pyvenv_options:\n                self.system_site_packages = True\n            logger.debug(\"Creating virtualenv with pyvenv. options=%s\", pyvenv_options)\n            self.create(self.env_path)\n        else:\n            virtualenv_options = options['virtualenv_options']\n            logger.debug(\"Creating virtualenv with virtualenv\")\n            self.create_with_virtualenv(interpreter, virtualenv_options)\n        logger.debug(\"env_bin_path: %s\", self.env_bin_path)\n\n        # Re check if pip was installed (supporting both binary and .exe for Windows)\n        pip_bin = os.path.join(self.env_bin_path, \"pip\")\n        pip_exe = os.path.join(self.env_bin_path, \"pip.exe\")\n        if not (os.path.exists(pip_bin) or os.path.exists(pip_exe)):\n            logger.debug(\"pip isn't installed in the venv, setting pip_installed=False\")\n            self.pip_installed = False\n\n        return self.env_path, self.env_bin_path, self.pip_installed", "response": "Create the virtualenv and return its info."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores a usage record for a given venv_data.", "response": "def store_usage_stat(self, venv_data, cache):\n        \"\"\"Log an usage record for venv_data.\"\"\"\n        with open(self.stat_file_path, 'at') as f:\n            self._write_venv_usage(f, venv_data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompacts usage stats and remove venvs.", "response": "def clean_unused_venvs(self, max_days_to_keep):\n        \"\"\"Compact usage stats and remove venvs.\n\n        This method loads the complete file usage in memory, for every venv compact all records in\n        one (the lastest), updates this info for every env deleted and, finally, write the entire\n        file to disk.\n\n        If something failed during this steps, usage file remains unchanged and can contain some\n        data about some deleted env. This is not a problem, the next time this function it's\n        called, this records will be deleted.\n        \"\"\"\n        with filelock(self.stat_file_lock):\n            now = datetime.utcnow()\n            venvs_dict = self._get_compacted_dict_usage_from_file()\n            for venv_uuid, usage_date in venvs_dict.copy().items():\n                usage_date = self._str_to_datetime(usage_date)\n                if (now - usage_date).days > max_days_to_keep:\n                    # remove venv from usage dict\n                    del venvs_dict[venv_uuid]\n                    venv_meta = self.venvscache.get_venv(uuid=venv_uuid)\n                    if venv_meta is None:\n                        # if meta isn't found means that something had failed previously and\n                        # usage_file wasn't updated.\n                        continue\n                    env_path = venv_meta['env_path']\n                    logger.info(\"Destroying virtualenv at: %s\", env_path)  # #256\n                    destroy_venv(env_path, self.venvscache)\n\n            self._write_compacted_dict_usage_to_file(venvs_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logged_exec(cmd):\n    logger = logging.getLogger('fades.exec')\n    logger.debug(\"Executing external command: %r\", cmd)\n    p = subprocess.Popen(\n        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n    stdout = []\n    for line in p.stdout:\n        line = line[:-1]\n        stdout.append(line)\n        logger.debug(STDOUT_LOG_PREFIX + line)\n    retcode = p.wait()\n    if retcode:\n        raise ExecutionError(retcode, cmd, stdout)\n    return stdout", "response": "Execute a command redirecting the output to the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_specific_dir(dir_type):\n    if SNAP_BASEDIR_NAME in os.environ:\n        logger.debug(\"Getting base dir information from SNAP_BASEDIR_NAME env var.\")\n        direct = os.path.join(os.environ[SNAP_BASEDIR_NAME], dir_type)\n    else:\n        try:\n            basedirectory = _get_basedirectory()\n        except ImportError:\n            logger.debug(\"Using last resort base dir: ~/.fades\")\n            from os.path import expanduser\n            direct = os.path.join(expanduser(\"~\"), \".fades\")\n        else:\n            xdg_attrib = 'xdg_{}_home'.format(dir_type)\n            base = getattr(basedirectory, xdg_attrib)\n            direct = os.path.join(base, 'fades')\n\n    if not os.path.exists(direct):\n        os.makedirs(direct)\n    return direct", "response": "Get a specific directory using some XDG base."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_interpreter_info(interpreter=None):\n    if interpreter is None:\n        # If interpreter is None by default returns the current interpreter data.\n        major, minor = sys.version_info[:2]\n        executable = sys.executable\n    else:\n        args = [interpreter, '-c', SHOW_VERSION_CMD]\n        try:\n            requested_interpreter_info = logged_exec(args)\n        except Exception as error:\n            logger.error(\"Error getting requested interpreter version: %s\", error)\n            raise FadesError(\"Could not get interpreter version\")\n        requested_interpreter_info = json.loads(requested_interpreter_info[0])\n        executable = requested_interpreter_info['path']\n        major = requested_interpreter_info['major']\n        minor = requested_interpreter_info['minor']\n    if executable[-1].isdigit():\n        executable = executable.split(\".\")[0][:-1]\n    interpreter = \"{}{}.{}\".format(executable, major, minor)\n    return interpreter", "response": "Return the full path using pythonX. Y format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a sanitized interpreter and indicates if it is the current one.", "response": "def get_interpreter_version(requested_interpreter):\n    \"\"\"Return a 'sanitized' interpreter and indicates if it is the current one.\"\"\"\n    logger.debug('Getting interpreter version for: %s', requested_interpreter)\n    current_interpreter = _get_interpreter_info()\n    logger.debug('Current interpreter is %s', current_interpreter)\n    if requested_interpreter is None:\n        return(current_interpreter, True)\n    else:\n        requested_interpreter = _get_interpreter_info(requested_interpreter)\n        is_current = requested_interpreter == current_interpreter\n        logger.debug('Interpreter=%s. It is the same as fades?=%s',\n                     requested_interpreter, is_current)\n        return (requested_interpreter, is_current)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of dependencies to upgrade.", "response": "def check_pypi_updates(dependencies):\n    \"\"\"Return a list of dependencies to upgrade.\"\"\"\n    dependencies_up_to_date = []\n    for dependency in dependencies.get('pypi', []):\n        # get latest version from PyPI api\n        try:\n            latest_version = get_latest_version_number(dependency.project_name)\n        except Exception as error:\n            logger.warning(\"--check-updates command will be aborted. Error: %s\", error)\n            return dependencies\n        # get required version\n        required_version = None\n        if dependency.specs:\n            _, required_version = dependency.specs[0]\n\n        if required_version:\n            dependencies_up_to_date.append(dependency)\n            if latest_version > required_version:\n                logger.info(\"There is a new version of %s: %s\",\n                            dependency.project_name, latest_version)\n            elif latest_version < required_version:\n                logger.warning(\"The requested version for %s is greater \"\n                               \"than latest found in PyPI: %s\",\n                               dependency.project_name, latest_version)\n            else:\n                logger.info(\"The requested version for %s is the latest one in PyPI: %s\",\n                            dependency.project_name, latest_version)\n        else:\n            project_name_plus = \"{}=={}\".format(dependency.project_name, latest_version)\n            dependencies_up_to_date.append(pkg_resources.Requirement.parse(project_name_plus))\n            logger.info(\"The latest version of %r is %s and will use it.\",\n                        dependency.project_name, latest_version)\n\n    dependencies[\"pypi\"] = dependencies_up_to_date\n    return dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pypi_head_package(dependency):\n    if dependency.specs:\n        _, version = dependency.specs[0]\n        url = BASE_PYPI_URL_WITH_VERSION.format(name=dependency.project_name, version=version)\n    else:\n        url = BASE_PYPI_URL.format(name=dependency.project_name)\n    logger.debug(\"Doing HEAD requests against %s\", url)\n    req = request.Request(url, method='HEAD')\n    try:\n        response = request.urlopen(req)\n    except HTTPError as http_error:\n        if http_error.code == HTTP_STATUS_NOT_FOUND:\n            return False\n        else:\n            raise\n    if response.status == HTTP_STATUS_OK:\n        logger.debug(\"%r exists in PyPI.\", dependency)\n        return True\n    else:\n        # Maybe we are getting somethink like a redirect. In this case we are only\n        # warning to the user and trying to install the dependency.\n        # In the worst scenery fades will fail to install it.\n        logger.warning(\"Got a (unexpected) HTTP_STATUS=%r and reason=%r checking if %r exists\",\n                       response.status, response.reason, dependency)\n        return True", "response": "Hit pypi with a http HEAD to check if pkg_name exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the indicated dependencies actually exists in pypi.", "response": "def check_pypi_exists(dependencies):\n    \"\"\"Check if the indicated dependencies actually exists in pypi.\"\"\"\n    for dependency in dependencies.get('pypi', []):\n        logger.debug(\"Checking if %r exists in PyPI\", dependency)\n        try:\n            exists = _pypi_head_package(dependency)\n        except Exception as error:\n            logger.error(\"Error checking %s in PyPI: %r\", dependency, error)\n            raise FadesError(\"Could not check if dependency exists in PyPI\")\n        else:\n            if not exists:\n                logger.error(\"%s doesn't exists in PyPI.\", dependency)\n                return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download_remote_script(url):\n    temp_fh = tempfile.NamedTemporaryFile('wt', encoding='utf8', suffix=\".py\", delete=False)\n    downloader = _ScriptDownloader(url)\n    logger.info(\n        \"Downloading remote script from %r using (%r downloader) to %r\",\n        url, downloader.name, temp_fh.name)\n\n    content = downloader.get()\n    temp_fh.write(content)\n    temp_fh.close()\n    return temp_fh.name", "response": "Download the content of a remote script to a local temp file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_to_log(self, logger):\n        logger.error(\"Execution ended in %s for cmd %s\", self._retcode, self._cmd)\n        for line in self._collected_stdout:\n            logger.error(STDOUT_LOG_PREFIX + line)", "response": "Send the cmd info and collected stdout to logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decide(self):\n        netloc = parse.urlparse(self.url).netloc\n        name = self.NETLOCS.get(netloc, 'raw')\n        return name", "response": "Find out which method should be applied to download that URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the script content from the URL using the decided downloader.", "response": "def get(self):\n        \"\"\"Get the script content from the URL using the decided downloader.\"\"\"\n        method_name = \"_download_\" + self.name\n        method = getattr(self, method_name)\n        return method()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading content from URL directly.", "response": "def _download_raw(self, url=None):\n        \"\"\"Download content from URL directly.\"\"\"\n        if url is None:\n            url = self.url\n        req = request.Request(url, headers=self.HEADERS_PLAIN)\n        return request.urlopen(req).read().decode(\"utf8\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading content from Linkode pastebin.", "response": "def _download_linkode(self):\n        \"\"\"Download content from Linkode pastebin.\"\"\"\n        # build the API url\n        linkode_id = self.url.split(\"/\")[-1]\n        if linkode_id.startswith(\"#\"):\n            linkode_id = linkode_id[1:]\n        url = \"https://linkode.org/api/1/linkodes/\" + linkode_id\n\n        req = request.Request(url, headers=self.HEADERS_JSON)\n        resp = request.urlopen(req)\n        raw = resp.read()\n        data = json.loads(raw.decode(\"utf8\"))\n        content = data['content']\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _download_pastebin(self):\n        paste_id = self.url.split(\"/\")[-1]\n        url = \"https://pastebin.com/raw/\" + paste_id\n        return self._download_raw(url)", "response": "Download content from Pastebin itself."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _download_gist(self):\n        parts = parse.urlparse(self.url)\n        url = \"https://gist.github.com\" + parts.path + \"/raw\"\n        return self._download_raw(url)", "response": "Download content from github s pastebin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving package version from the file.", "response": "def get_version():\n    \"\"\"Retrieves package version from the file.\"\"\"\n    with open('fades/_version.py') as fh:\n        m = re.search(\"\\(([^']*)\\)\", fh.read())\n    if m is None:\n        raise ValueError(\"Unrecognized version in 'fades/_version.py'\")\n    return m.groups()[0].replace(', ', '.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun parent initialization and then fix the scripts var.", "response": "def initialize_options(self):\n        \"\"\"Run parent initialization and then fix the scripts var.\"\"\"\n        install.initialize_options(self)\n\n        # leave the proper script according to the platform\n        script = SCRIPT_WIN if sys.platform == \"win32\" else SCRIPT_REST\n        self.distribution.scripts = [script]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        install.run(self)\n\n        # man directory\n        if self._custom_man_dir is not None:\n            if not os.path.exists(self._custom_man_dir):\n                os.makedirs(self._custom_man_dir)\n            shutil.copy(\"man/fades.1\", self._custom_man_dir)", "response": "Run the parent install and then save the man file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\naltering the installation path.", "response": "def finalize_options(self):\n        \"\"\"Alter the installation path.\"\"\"\n        install.finalize_options(self)\n        if self.prefix is None:\n            # no place for man page (like in a 'snap')\n            man_dir = None\n        else:\n            man_dir = os.path.join(self.prefix, \"share\", \"man\", \"man1\")\n\n            # if we have 'root', put the building path also under it (used normally\n            # by pbuilder)\n            if self.root is not None:\n                man_dir = os.path.join(self.root, man_dir[1:])\n        self._custom_man_dir = man_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a argparse. Namespace and return it updated with options from config files.", "response": "def options_from_file(args):\n    \"\"\"Get a argparse.Namespace and return it updated with options from config files.\n\n    Config files will be parsed with priority equal to his order in CONFIG_FILES.\n    \"\"\"\n    logger.debug(\"updating options from config files\")\n    updated_from_file = []\n    for config_file in CONFIG_FILES:\n        logger.debug(\"updating from: %s\", config_file)\n        parser = ConfigParser()\n        parser.read(config_file)\n        try:\n            items = parser.items('fades')\n        except NoSectionError:\n            continue\n\n        for config_key, config_value in items:\n            if config_value in ['true', 'false']:\n                config_value = config_value == 'true'\n            if config_key in MERGEABLE_CONFIGS:\n                current_value = getattr(args, config_key, [])\n                if current_value is None:\n                    current_value = []\n                current_value.append(config_value)\n                setattr(args, config_key, current_value)\n            if not getattr(args, config_key, False) or config_key in updated_from_file:\n                # By default all 'store-true' arguments are False. So we only\n                # override them if they are False. If they are True means that the\n                # user is setting those on the CLI.\n                setattr(args, config_key, config_value)\n                updated_from_file.append(config_key)\n                logger.debug(\"updating %s to %s from file settings\", config_key, config_value)\n\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if what is installed satisfies the requirements.", "response": "def _venv_match(self, installed, requirements):\n        \"\"\"Return True if what is installed satisfies the requirements.\n\n        This method has multiple exit-points, but only for False (because\n        if *anything* is not satisified, the venv is no good). Only after\n        all was checked, and it didn't exit, the venv is ok so return True.\n        \"\"\"\n        if not requirements:\n            # special case for no requirements, where we can't actually\n            # check anything: the venv is useful if nothing installed too\n            return None if installed else []\n\n        satisfying_deps = []\n        for repo, req_deps in requirements.items():\n            useful_inst = set()\n            if repo not in installed:\n                # the venv doesn't even have the repo\n                return None\n\n            if repo == REPO_VCS:\n                inst_deps = {VCSDependency(url) for url in installed[repo].keys()}\n            else:\n                inst_deps = {Distribution(project_name=dep, version=ver)\n                             for (dep, ver) in installed[repo].items()}\n            for req in req_deps:\n                for inst in inst_deps:\n                    if inst in req:\n                        useful_inst.add(inst)\n                        break\n                else:\n                    # nothing installed satisfied that requirement\n                    return None\n\n            # assure *all* that is installed is useful for the requirements\n            if useful_inst == inst_deps:\n                satisfying_deps.extend(inst_deps)\n            else:\n                return None\n\n        # it did it through!\n        return satisfying_deps"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting a venv matching exactly by uuid.", "response": "def _match_by_uuid(self, current_venvs, uuid):\n        \"\"\"Select a venv matching exactly by uuid.\"\"\"\n        for venv_str in current_venvs:\n            venv = json.loads(venv_str)\n            env_path = venv.get('metadata', {}).get('env_path')\n            _, env_uuid = os.path.split(env_path)\n            if env_uuid == uuid:\n                return venv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreceiving a list of matching venvs and decide which one is the best fit.", "response": "def _select_better_fit(self, matching_venvs):\n        \"\"\"Receive a list of matching venvs, and decide which one is the best fit.\"\"\"\n        # keep the venvs in a separate array, to pick up the winner, and the (sorted, to compare\n        # each dependency with its equivalent) in other structure to later compare\n        venvs = []\n        to_compare = []\n        for matching, venv in matching_venvs:\n            to_compare.append(sorted(matching, key=lambda req: getattr(req, 'key', '')))\n            venvs.append(venv)\n\n        # compare each n-tuple of dependencies to see which one is bigger, and add score to the\n        # position of the winner\n        scores = [0] * len(venvs)\n        for dependencies in zip(*to_compare):\n            if not isinstance(dependencies[0], Distribution):\n                # only distribution URLs can be compared\n                continue\n\n            winner = dependencies.index(max(dependencies))\n            scores[winner] = scores[winner] + 1\n\n        # get the rightmost winner (in case of ties, to select the latest venv)\n        winner_pos = None\n        winner_score = -1\n        for i, score in enumerate(scores):\n            if score >= winner_score:\n                winner_score = score\n                winner_pos = i\n        return venvs[winner_pos]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _match_by_requirements(self, current_venvs, requirements, interpreter, options):\n        matching_venvs = []\n        for venv_str in current_venvs:\n            venv = json.loads(venv_str)\n\n            # simple filter, need to have exactly same options and interpreter\n            if venv.get('options') != options or venv.get('interpreter') != interpreter:\n                continue\n\n            # requirements complying: result can be None (no comply) or a score to later sort\n            matching = self._venv_match(venv['installed'], requirements)\n            if matching is not None:\n                matching_venvs.append((matching, venv))\n\n        if not matching_venvs:\n            return\n\n        return self._select_better_fit(matching_venvs)", "response": "Select a venv matching interpreter and options complying with requirements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting which venv satisfy the received requirements.", "response": "def _select(self, current_venvs, requirements=None, interpreter='', uuid='', options=None):\n        \"\"\"Select which venv satisfy the received requirements.\"\"\"\n        if uuid:\n            logger.debug(\"Searching a venv by uuid: %s\", uuid)\n            venv = self._match_by_uuid(current_venvs, uuid)\n        else:\n            logger.debug(\"Searching a venv for: reqs=%s interpreter=%s options=%s\",\n                         requirements, interpreter, options)\n            venv = self._match_by_requirements(current_venvs, requirements, interpreter, options)\n\n        if venv is None:\n            logger.debug(\"No matching venv found :(\")\n            return\n\n        logger.debug(\"Found a matching venv! %s\", venv)\n        return venv['metadata']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_venv(self, requirements=None, interpreter='', uuid='', options=None):\n        lines = self._read_cache()\n        return self._select(lines, requirements, interpreter, uuid=uuid, options=options)", "response": "Find a venv that serves these requirements if any."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the virtualenv metadata for the indicated installed_stuff.", "response": "def store(self, installed_stuff, metadata, interpreter, options):\n        \"\"\"Store the virtualenv metadata for the indicated installed_stuff.\"\"\"\n        new_content = {\n            'timestamp': int(time.mktime(time.localtime())),\n            'installed': installed_stuff,\n            'metadata': metadata,\n            'interpreter': interpreter,\n            'options': options\n        }\n        logger.debug(\"Storing installed=%s metadata=%s interpreter=%s options=%s\",\n                     installed_stuff, metadata, interpreter, options)\n        with filelock(self.lockpath):\n            self._write_cache([json.dumps(new_content)], append=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving metadata for a given virtualenv from cache.", "response": "def remove(self, env_path):\n        \"\"\"Remove metadata for a given virtualenv from cache.\"\"\"\n        with filelock(self.lockpath):\n            cache = self._read_cache()\n            logger.debug(\"Removing virtualenv from cache: %s\" % env_path)\n            lines = [\n                line for line in cache\n                if json.loads(line).get('metadata', {}).get('env_path') != env_path\n            ]\n            self._write_cache(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_cache(self):\n        if os.path.exists(self.filepath):\n            with open(self.filepath, 'rt', encoding='utf8') as fh:\n                lines = [x.strip() for x in fh]\n        else:\n            logger.debug(\"Index not found, starting empty\")\n            lines = []\n        return lines", "response": "Read virtualenv metadata from cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite virtualenv metadata to cache.", "response": "def _write_cache(self, lines, append=False):\n        \"\"\"Write virtualenv metadata to cache.\"\"\"\n        mode = 'at' if append else 'wt'\n        with open(self.filepath, mode, encoding='utf8') as fh:\n            fh.writelines(line + '\\n' for line in lines)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install(self, dependency):\n        if not self.pip_installed:\n            logger.info(\"Need to install a dependency with pip, but no builtin, \"\n                        \"doing it manually (just wait a little, all should go well)\")\n            self._brute_force_install_pip()\n\n        # split to pass several tokens on multiword dependency (this is very specific for '-e' on\n        # external requirements, but implemented generically; note that this does not apply for\n        # normal reqs, because even if it originally is 'foo > 1.2', after parsing it loses the\n        # internal spaces)\n        str_dep = str(dependency)\n        args = [self.pip_exe, \"install\"] + str_dep.split()\n\n        if self.options:\n            for option in self.options:\n                args.extend(option.split())\n        logger.info(\"Installing dependency: %r\", str_dep)\n        try:\n            helpers.logged_exec(args)\n        except helpers.ExecutionError as error:\n            error.dump_to_log(logger)\n            raise error\n        except Exception as error:\n            logger.exception(\"Error installing %s: %s\", str_dep, error)\n            raise error", "response": "Install a new dependency."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the installed version parsing the output of pip show.", "response": "def get_version(self, dependency):\n        \"\"\"Return the installed version parsing the output of 'pip show'.\"\"\"\n        logger.debug(\"getting installed version for %s\", dependency)\n        stdout = helpers.logged_exec([self.pip_exe, \"show\", str(dependency)])\n        version = [line for line in stdout if line.startswith('Version:')]\n        if len(version) == 1:\n            version = version[0].strip().split()[1]\n            logger.debug(\"Installed version of %s is: %s\", dependency, version)\n            return version\n        else:\n            logger.error('Fades is having problems getting the installed version. '\n                         'Run with -v or check the logs for details')\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_configs_from_default(self, overrides=None):\n        # type: (Dict[str, int]) -> Dict[str, int]\n        \"\"\" Generate configs by inheriting from defaults \"\"\"\n        config = DEFAULT_CONFIG.copy()\n        if not overrides:\n            overrides = {}\n        for k, v in overrides.items():\n            config[k] = v\n        return config", "response": "Generate configs by inheriting from defaults"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the ical file and returns the calendar object", "response": "def read_ical(self, ical_file_location):  # type: (str) -> Calendar\n        \"\"\" Read the ical file \"\"\"\n        with open(ical_file_location, 'r') as ical_file:\n            data = ical_file.read()\n        self.cal = Calendar.from_ical(data)\n        return self.cal"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the CSV file and returns the data as a list of strings.", "response": "def read_csv(self, csv_location, csv_configs=None):\n        # type: (str, Dict[str, int]) -> List[List[str]]\n        \"\"\" Read the csv file \"\"\"\n        csv_configs = self._generate_configs_from_default(csv_configs)\n        with open(csv_location, 'r') as csv_file:\n            csv_reader = csv.reader(csv_file)\n            self.csv_data = list(csv_reader)\n        self.csv_data = self.csv_data[csv_configs['HEADER_COLUMNS_TO_SKIP']:]\n        return self.csv_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_ical(self, ical_location):  # type: (str) -> None\n        data = self.cal.to_ical()\n        with open(ical_location, 'w') as ical_file:\n            ical_file.write(data.decode('utf-8'))", "response": "Save the calendar instance to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the CSV to a file.", "response": "def save_csv(self, csv_location):  # type: (str) -> None\n        \"\"\" Save the csv to a file \"\"\"\n        with open(csv_location, 'w') as csv_handle:\n            writer = csv.writer(csv_handle)\n            for row in self.csv_data:\n                writer.writerow(row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads an image file from disk and returns a new object.", "response": "def open(cls, filename):\n        \"\"\" Read an image file from disk\n\n        Parameters\n        ----------\n        filename : string\n            Name of file to read as an image file.  This file may be gzip\n            (``.gz``) or bzip2 (``.bz2``) compressed.\n        \"\"\"\n        if filename.endswith('.gz'):\n            fp = gzip.open(filename, 'rb')\n            try:\n                return cls(fp, filename, compression='gz')\n            finally:\n                fp.close()\n        elif filename.endswith('.bz2'):\n            fp = bz2.BZ2File(filename, 'rb')\n            try:\n                return cls(fp, filename, compression='bz2')\n            finally:\n                fp.close()\n        else:\n            with open(filename, 'rb') as fp:\n                return cls(fp, filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts isis special pixel values to numpy special pixel values.", "response": "def apply_numpy_specials(self, copy=True):\n        \"\"\"Convert isis special pixel values to numpy special pixel values.\n\n            =======  =======\n             Isis     Numpy\n            =======  =======\n            Null     nan\n            Lrs      -inf\n            Lis      -inf\n            His      inf\n            Hrs      inf\n            =======  =======\n\n        Parameters\n        ----------\n        copy : bool [True]\n            Whether to apply the new special values to a copy of the\n            pixel data and leave the original unaffected\n\n        Returns\n        -------\n        Numpy Array\n            A numpy array with special values converted to numpy's nan, inf,\n            and -inf\n        \"\"\"\n        if copy:\n            data = self.data.astype(numpy.float64)\n\n        elif self.data.dtype != numpy.float64:\n            data = self.data = self.data.astype(numpy.float64)\n\n        else:\n            data = self.data\n\n        data[data == self.specials['Null']] = numpy.nan\n        data[data < self.specials['Min']] = numpy.NINF\n        data[data > self.specials['Max']] = numpy.inf\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(cls, value, record_bytes):\n        if isinstance(value, six.string_types):\n            return cls(value, 0)\n\n        if isinstance(value, list):\n            if len(value) == 1:\n                return cls(value[0], 0)\n\n            if len(value) == 2:\n                return cls(value[0], cls._parse_bytes(value[1], record_bytes))\n\n            raise ValueError('Unsupported pointer type')\n\n        return cls(None, cls._parse_bytes(value, record_bytes))", "response": "Parses the pointer label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave PDS3Image object as PDS3 file.", "response": "def _save(self, file_to_write, overwrite):\n        \"\"\"Save PDS3Image object as PDS3 file.\n\n        Parameters\n        ----------\n        filename: Set filename for the pds image to be saved.\n        Overwrite: Use this keyword to save image with same filename.\n\n        Usage: image.save('temp.IMG', overwrite=True)\n\n        \"\"\"\n        if overwrite:\n            file_to_write = self.filename\n        elif os.path.isfile(file_to_write):\n            msg = 'File ' + file_to_write + ' already exists !\\n' + \\\n                  'Call save() with \"overwrite = True\" to overwrite the file.'\n            raise IOError(msg)\n\n        encoder = pvl.encoder.PDSLabelEncoder\n        serial_label = pvl.dumps(self.label, cls=encoder)\n        label_sz = len(serial_label)\n        image_pointer = int(label_sz / self.label['RECORD_BYTES']) + 1\n        self.label['^IMAGE'] = image_pointer + 1\n\n        if self._sample_bytes != self.label['IMAGE']['SAMPLE_BITS'] * 8:\n            self.label['IMAGE']['SAMPLE_BITS'] = self.data.itemsize * 8\n\n        sample_type_to_save = self.DTYPES[self._sample_type[0] + self.dtype.kind]\n        self.label['IMAGE']['SAMPLE_TYPE'] = sample_type_to_save\n\n        if len(self.data.shape) == 3:\n            self.label['IMAGE']['BANDS'] = self.data.shape[0]\n            self.label['IMAGE']['LINES'] = self.data.shape[1]\n            self.label['IMAGE']['LINE_SAMPLES'] = self.data.shape[2]\n        else:\n            self.label['IMAGE']['BANDS'] = 1\n            self.label['IMAGE']['LINES'] = self.data.shape[0]\n            self.label['IMAGE']['LINE_SAMPLES'] = self.data.shape[1]\n\n        diff = 0\n        if len(pvl.dumps(self.label, cls=encoder)) != label_sz:\n            diff = abs(label_sz - len(pvl.dumps(self.label, cls=encoder)))\n        pvl.dump(self.label, file_to_write, cls=encoder)\n        offset = image_pointer * self.label['RECORD_BYTES'] - label_sz\n        stream = open(file_to_write, 'a')\n        for i in range(0, offset+diff):\n            stream.write(\" \")\n\n        if (self._bands > 1 and self._format != 'BAND_SEQUENTIAL'):\n            raise NotImplementedError\n        else:\n            self.data.tofile(stream, format='%' + self.dtype.kind)\n        stream.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_label(self, array):\n        if len(array.shape) == 3:\n            bands = array.shape[0]\n            lines = array.shape[1]\n            line_samples = array.shape[2]\n        else:\n            bands = 1\n            lines = array.shape[0]\n            line_samples = array.shape[1]\n        record_bytes = line_samples * array.itemsize\n        label_module = pvl.PVLModule([\n            ('PDS_VERSION_ID', 'PDS3'),\n            ('RECORD_TYPE', 'FIXED_LENGTH'),\n            ('RECORD_BYTES', record_bytes),\n            ('LABEL_RECORDS', 1),\n            ('^IMAGE', 1),\n            ('IMAGE',\n                {'BANDS': bands,\n                 'LINES': lines,\n                 'LINE_SAMPLES': line_samples,\n                 'MAXIMUM': 0,\n                 'MEAN': 0,\n                 'MEDIAN': 0,\n                 'MINIMUM': 0,\n                 'SAMPLE_BITS': array.itemsize * 8,\n                 'SAMPLE_TYPE': 'MSB_INTEGER',\n                 'STANDARD_DEVIATION': 0})\n            ])\n        return self._update_label(label_module, array)", "response": "Create sample PDS3 label for NumPy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates PDS3 label for NumPy array.", "response": "def _update_label(self, label, array):\n        \"\"\"Update PDS3 label for NumPy Array.\n        It is called by '_create_label' to update label values\n        such as,\n        - ^IMAGE, RECORD_BYTES\n        - STANDARD_DEVIATION\n        - MAXIMUM, MINIMUM\n        - MEDIAN, MEAN\n\n        Returns\n        -------\n        Update label module for the NumPy array.\n\n        Usage: self.label = self._update_label(label, array)\n\n        \"\"\"\n        maximum = float(numpy.max(array))\n        mean = float(numpy.mean(array))\n        median = float(numpy.median(array))\n        minimum = float(numpy.min(array))\n        stdev = float(numpy.std(array, ddof=1))\n\n        encoder = pvl.encoder.PDSLabelEncoder\n        serial_label = pvl.dumps(label, cls=encoder)\n        label_sz = len(serial_label)\n        image_pointer = int(label_sz / label['RECORD_BYTES']) + 1\n\n        label['^IMAGE'] = image_pointer + 1\n        label['LABEL_RECORDS'] = image_pointer\n        label['IMAGE']['MEAN'] = mean\n        label['IMAGE']['MAXIMUM'] = maximum\n        label['IMAGE']['MEDIAN'] = median\n        label['IMAGE']['MINIMUM'] = minimum\n        label['IMAGE']['STANDARD_DEVIATION'] = stdev\n\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef derive_key(mode, version, salt, key,\n               private_key, dh, auth_secret,\n               keyid, keylabel=\"P-256\"):\n    \"\"\"Derive the encryption key\n\n    :param mode: operational mode (encrypt or decrypt)\n    :type mode: enumerate('encrypt', 'decrypt)\n    :param salt: encryption salt value\n    :type salt: str\n    :param key: raw key\n    :type key: str\n    :param private_key: DH private key\n    :type key: object\n    :param dh: Diffie Helman public key value\n    :type dh: str\n    :param keyid: key identifier label\n    :type keyid: str\n    :param keylabel: label for aesgcm/aesgcm128\n    :type keylabel: str\n    :param auth_secret: authorization secret\n    :type auth_secret: str\n    :param version: Content Type identifier\n    :type version: enumerate('aes128gcm', 'aesgcm', 'aesgcm128')\n\n    \"\"\"\n    context = b\"\"\n    keyinfo = \"\"\n    nonceinfo = \"\"\n\n    def build_info(base, info_context):\n        return b\"Content-Encoding: \" + base + b\"\\0\" + info_context\n\n    def derive_dh(mode, version, private_key, dh, keylabel):\n        def length_prefix(key):\n            return struct.pack(\"!H\", len(key)) + key\n        if isinstance(dh, ec.EllipticCurvePublicKey):\n            pubkey = dh\n            dh = dh.public_bytes(\n                Encoding.X962,\n                PublicFormat.UncompressedPoint)\n        else:\n            pubkey = ec.EllipticCurvePublicKey.from_encoded_point(\n                ec.SECP256R1(),\n                dh\n            )\n\n        encoded = private_key.public_key().public_bytes(\n            Encoding.X962,\n            PublicFormat.UncompressedPoint)\n        if mode == \"encrypt\":\n            sender_pub_key = encoded\n            receiver_pub_key = dh\n        else:\n            sender_pub_key = dh\n            receiver_pub_key = encoded\n\n        if version == \"aes128gcm\":\n            context = b\"WebPush: info\\x00\" + receiver_pub_key + sender_pub_key\n        else:\n            context = (keylabel.encode('utf-8') + b\"\\0\" +\n                       length_prefix(receiver_pub_key) +\n                       length_prefix(sender_pub_key))\n\n        return private_key.exchange(ec.ECDH(), pubkey), context\n\n    if version not in versions:\n        raise ECEException(u\"Invalid version\")\n    if mode not in ['encrypt', 'decrypt']:\n        raise ECEException(u\"unknown 'mode' specified: \" + mode)\n    if salt is None or len(salt) != KEY_LENGTH:\n        raise ECEException(u\"'salt' must be a 16 octet value\")\n    if dh is not None:\n        if private_key is None:\n            raise ECEException(u\"DH requires a private_key\")\n        (secret, context) = derive_dh(mode=mode, version=version,\n                                      private_key=private_key, dh=dh,\n                                      keylabel=keylabel)\n    else:\n        secret = key\n\n    if secret is None:\n        raise ECEException(u\"unable to determine the secret\")\n\n    if version == \"aesgcm\":\n        keyinfo = build_info(b\"aesgcm\", context)\n        nonceinfo = build_info(b\"nonce\", context)\n    elif version == \"aesgcm128\":\n        keyinfo = b\"Content-Encoding: aesgcm128\"\n        nonceinfo = b\"Content-Encoding: nonce\"\n    elif version == \"aes128gcm\":\n        keyinfo = b\"Content-Encoding: aes128gcm\\x00\"\n        nonceinfo = b\"Content-Encoding: nonce\\x00\"\n        if dh is None:\n            # Only mix the authentication secret when using DH for aes128gcm\n            auth_secret = None\n\n    if auth_secret is not None:\n        if version == \"aes128gcm\":\n            info = context\n        else:\n            info = build_info(b'auth', b'')\n        hkdf_auth = HKDF(\n            algorithm=hashes.SHA256(),\n            length=32,\n            salt=auth_secret,\n            info=info,\n            backend=default_backend()\n        )\n        secret = hkdf_auth.derive(secret)\n\n    hkdf_key = HKDF(\n        algorithm=hashes.SHA256(),\n        length=KEY_LENGTH,\n        salt=salt,\n        info=keyinfo,\n        backend=default_backend()\n    )\n    hkdf_nonce = HKDF(\n        algorithm=hashes.SHA256(),\n        length=NONCE_LENGTH,\n        salt=salt,\n        info=nonceinfo,\n        backend=default_backend()\n    )\n    return hkdf_key.derive(secret), hkdf_nonce.derive(secret)", "response": "Derive the encryption key from the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an initialization vector.", "response": "def iv(base, counter):\n    \"\"\"Generate an initialization vector.\n\n    \"\"\"\n    if (counter >> 64) != 0:\n        raise ECEException(u\"Counter too big\")\n    (mask,) = struct.unpack(\"!Q\", base[4:])\n    return base[:4] + struct.pack(\"!Q\", counter ^ mask)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decrypt(content, salt=None, key=None,\n            private_key=None, dh=None, auth_secret=None,\n            keyid=None, keylabel=\"P-256\",\n            rs=4096, version=\"aes128gcm\"):\n    \"\"\"\n    Decrypt a data block\n\n    :param content: Data to be decrypted\n    :type content: str\n    :param salt: Encryption salt\n    :type salt: str\n    :param key: local public key\n    :type key: str\n    :param private_key: DH private key\n    :type key: object\n    :param keyid: Internal key identifier for private key info\n    :type keyid: str\n    :param dh: Remote Diffie Hellman sequence (omit for aes128gcm)\n    :type dh: str\n    :param rs: Record size\n    :type rs: int\n    :param auth_secret: Authorization secret\n    :type auth_secret: str\n    :param version: ECE Method version\n    :type version: enumerate('aes128gcm', 'aesgcm', 'aesgcm128')\n    :return: Decrypted message content\n    :rtype str\n\n    \"\"\"\n    def parse_content_header(content):\n        \"\"\"Parse an aes128gcm content body and extract the header values.\n\n        :param content: The encrypted body of the message\n        :type content: str\n\n        \"\"\"\n        id_len = struct.unpack(\"!B\", content[20:21])[0]\n        return {\n            \"salt\": content[:16],\n            \"rs\": struct.unpack(\"!L\", content[16:20])[0],\n            \"keyid\": content[21:21 + id_len],\n            \"content\": content[21 + id_len:],\n        }\n\n    def decrypt_record(key, nonce, counter, content):\n        decryptor = Cipher(\n            algorithms.AES(key),\n            modes.GCM(iv(nonce, counter), tag=content[-TAG_LENGTH:]),\n            backend=default_backend()\n        ).decryptor()\n        return decryptor.update(content[:-TAG_LENGTH]) + decryptor.finalize()\n\n    def unpad_legacy(data):\n        pad_size = versions[version]['pad']\n        pad = functools.reduce(\n            lambda x, y: x << 8 | y, struct.unpack(\n                \"!\" + (\"B\" * pad_size), data[0:pad_size])\n        )\n        if pad_size + pad > len(data) or \\\n           data[pad_size:pad_size+pad] != (b\"\\x00\" * pad):\n            raise ECEException(u\"Bad padding\")\n        return data[pad_size + pad:]\n\n    def unpad(data, last):\n        i = len(data) - 1\n        for i in range(len(data) - 1, -1, -1):\n            v = struct.unpack('B', data[i:i+1])[0]\n            if v != 0:\n                if not last and v != 1:\n                    raise ECEException(u'record delimiter != 1')\n                if last and v != 2:\n                    raise ECEException(u'last record delimiter != 2')\n                return data[0:i]\n        raise ECEException(u'all zero record plaintext')\n\n    if version not in versions:\n        raise ECEException(u\"Invalid version\")\n\n    overhead = versions[version]['pad']\n    if version == \"aes128gcm\":\n        try:\n            content_header = parse_content_header(content)\n        except Exception:\n            raise ECEException(\"Could not parse the content header\")\n        salt = content_header['salt']\n        rs = content_header['rs']\n        keyid = content_header['keyid']\n        if private_key is not None and not dh:\n            dh = keyid\n        else:\n            keyid = keyid.decode('utf-8')\n        content = content_header['content']\n        overhead += 16\n\n    (key_, nonce_) = derive_key(\"decrypt\", version=version,\n                                salt=salt, key=key,\n                                private_key=private_key, dh=dh,\n                                auth_secret=auth_secret,\n                                keyid=keyid, keylabel=keylabel)\n    if rs <= overhead:\n        raise ECEException(u\"Record size too small\")\n    chunk = rs\n    if version != \"aes128gcm\":\n        chunk += 16  # account for tags in old versions\n        if len(content) % chunk == 0:\n            raise ECEException(u\"Message truncated\")\n\n    result = b''\n    counter = 0\n    try:\n        for i in list(range(0, len(content), chunk)):\n            data = decrypt_record(key_, nonce_, counter, content[i:i + chunk])\n            if version == 'aes128gcm':\n                last = (i + chunk) >= len(content)\n                result += unpad(data, last)\n            else:\n                result += unpad_legacy(data)\n            counter += 1\n    except InvalidTag as ex:\n        raise ECEException(\"Decryption error: {}\".format(repr(ex)))\n    return result", "response": "Decrypt a message content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencrypting a block of data with a salt key and a private key.", "response": "def encrypt(content, salt=None, key=None,\n            private_key=None, dh=None, auth_secret=None,\n            keyid=None, keylabel=\"P-256\",\n            rs=4096, version=\"aes128gcm\"):\n    \"\"\"\n    Encrypt a data block\n\n    :param content: block of data to encrypt\n    :type content: str\n    :param salt: Encryption salt\n    :type salt: str\n    :param key: Encryption key data\n    :type key: str\n    :param private_key: DH private key\n    :type key: object\n    :param keyid: Internal key identifier for private key info\n    :type keyid: str\n    :param dh: Remote Diffie Hellman sequence\n    :type dh: str\n    :param rs: Record size\n    :type rs: int\n    :param auth_secret: Authorization secret\n    :type auth_secret: str\n    :param version: ECE Method version\n    :type version: enumerate('aes128gcm', 'aesgcm', 'aesgcm128')\n    :return: Encrypted message content\n    :rtype str\n\n    \"\"\"\n    def encrypt_record(key, nonce, counter, buf, last):\n        encryptor = Cipher(\n            algorithms.AES(key),\n            modes.GCM(iv(nonce, counter)),\n            backend=default_backend()\n        ).encryptor()\n\n        if version == 'aes128gcm':\n            data = encryptor.update(buf + (b'\\x02' if last else b'\\x01'))\n        else:\n            data = encryptor.update((b\"\\x00\" * versions[version]['pad']) + buf)\n        data += encryptor.finalize()\n        data += encryptor.tag\n        return data\n\n    def compose_aes128gcm(salt, content, rs, keyid):\n        \"\"\"Compose the header and content of an aes128gcm encrypted\n        message body\n\n        :param salt: The sender's salt value\n        :type salt: str\n        :param content: The encrypted body of the message\n        :type content: str\n        :param rs: Override for the content length\n        :type rs: int\n        :param keyid: The keyid to use for this message\n        :type keyid: str\n\n        \"\"\"\n        if len(keyid) > 255:\n            raise ECEException(\"keyid is too long\")\n        header = salt\n        if rs > MAX_RECORD_SIZE:\n            raise ECEException(\"Too much content\")\n        header += struct.pack(\"!L\", rs)\n        header += struct.pack(\"!B\", len(keyid))\n        header += keyid\n        return header + content\n\n    if version not in versions:\n        raise ECEException(u\"Invalid version\")\n\n    if salt is None:\n        salt = os.urandom(16)\n\n    (key_, nonce_) = derive_key(\"encrypt\", version=version,\n                                salt=salt, key=key,\n                                private_key=private_key, dh=dh,\n                                auth_secret=auth_secret,\n                                keyid=keyid, keylabel=keylabel)\n\n    overhead = versions[version]['pad']\n    if version == 'aes128gcm':\n        overhead += 16\n        end = len(content)\n    else:\n        end = len(content) + 1\n    if rs <= overhead:\n        raise ECEException(u\"Record size too small\")\n    chunk_size = rs - overhead\n\n    result = b\"\"\n    counter = 0\n\n    # the extra one on the loop ensures that we produce a padding only\n    # record if the data length is an exact multiple of the chunk size\n    for i in list(range(0, end, chunk_size)):\n        result += encrypt_record(key_, nonce_, counter,\n                                 content[i:i + chunk_size],\n                                 (i + chunk_size) >= end)\n        counter += 1\n    if version == \"aes128gcm\":\n        if keyid is None and private_key is not None:\n            kid = private_key.public_key().public_bytes(\n                Encoding.X962,\n                PublicFormat.UncompressedPoint)\n        else:\n            kid = (keyid or '').encode('utf-8')\n        return compose_aes128gcm(salt, result, rs, keyid=kid)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parameters(self, namespaced=False):\n        if namespaced:\n            return json.loads(json.dumps(self.args[0]['parameters']), object_hook=lambda d: SimpleNamespace(**d))\n        else:\n            return self.args[0].get('parameters')", "response": "returns the exception varlink error parameters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetInterfaceDescription(self, interface):\n        try:\n            i = self.interfaces[interface]\n        except KeyError:\n            raise InterfaceNotFound(interface)\n\n        return {'description': i.description}", "response": "The standardized org. varlink. service. GetInterfaceDescription() varlink method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef server_bind(self):\n        if self.allow_reuse_address:\n            self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.socket.setblocking(True)\n\n        if not self.listen_fd:\n            self.socket.bind(self.server_address)\n\n        self.server_address = self.socket.getsockname()\n\n        if self.server_address[0] == 0:\n            self.server_address = '@' + self.server_address[1:].decode('utf-8')\n            if self.mode:\n                os.fchmod(self.socket.fileno(), mode=int(self.mode, 8))\n        elif self.mode:\n            os.chmod(self.server_address, mode=int(self.mode, 8))", "response": "Bind the socket to the server address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling to clean - up the server.", "response": "def server_close(self):\n        \"\"\"Called to clean-up the server.\n\n        May be overridden.\n\n        \"\"\"\n        if self.remove_file:\n            try:\n                os.remove(self.remove_file)\n            except:\n                pass\n        self.socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls to shutdown and close an individual request.", "response": "def shutdown_request(self, request):\n        \"\"\"Called to shutdown and close an individual request.\"\"\"\n        try:\n            # explicitly shutdown.  socket.close() merely releases\n            # the socket and waits for GC to perform the actual close.\n            request.shutdown(socket.SHUT_RDWR)\n\n        except:\n            pass  # some platforms may raise ENOTCONN here\n        self.close_request(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a new connection and get a client interface handle.", "response": "def open(self, interface_name, namespaced=False, connection=None):\n        \"\"\"Open a new connection and get a client interface handle with the varlink methods installed.\n\n        :param interface_name: an interface name, which the service this client object is\n                               connected to, provides.\n        :param namespaced: If arguments and return values are instances of SimpleNamespace\n                            rather than dictionaries.\n        :param connection: If set, get the interface handle for an already opened connection.\n        :exception InterfaceNotFound: if the interface is not found\n\n        \"\"\"\n\n        if not connection:\n            connection = self.open_connection()\n\n        if interface_name not in self._interfaces:\n            self.get_interface(interface_name, socket_connection=connection)\n\n        if interface_name not in self._interfaces:\n            raise InterfaceNotFound(interface_name)\n\n        return self.handler(self._interfaces[interface_name], connection, namespaced=namespaced)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_interfaces(self, socket_connection=None):\n        if not socket_connection:\n            socket_connection = self.open_connection()\n            close_socket = True\n        else:\n            close_socket = False\n\n        # noinspection PyUnresolvedReferences\n        _service = self.handler(self._interfaces[\"org.varlink.service\"], socket_connection)\n        self.info = _service.GetInfo()\n\n        if close_socket:\n            socket_connection.close()\n\n        return self.info['interfaces']", "response": "Returns the a list of Interface objects the service implements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_interface(self, interface):\n        if not isinstance(interface, Interface):\n            raise TypeError\n\n        self._interfaces[interface.name] = interface", "response": "Manually add an interface definition from an Interface object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rematch_entry(envkernel, gamma = 0.1, threshold = 1e-6):\n    n, m = envkernel.shape\n    K = np.exp(-(1 - envkernel) / gamma)\n\n    # initialisation\n    u = np.ones((n,)) / n\n    v = np.ones((m,)) / m\n\n    en = np.ones((n,)) / float(n)\n    em = np.ones((m,)) / float(m)\n\n    Kp = (1 / en).reshape(-1, 1) * K\n\n    # converge balancing vectors u and v\n    itercount = 0\n    error = 1\n    while (error > threshold):\n        uprev = u\n        vprev = v\n        v = np.divide(em, np.dot(K.T, u))\n        u = np.divide(en, np.dot(K, v))\n\n        # determine error every now and then\n        if itercount % 5:\n            error = np.sum((u - uprev) ** 2) / np.sum((u) ** 2) + np.sum((v - vprev) ** 2) / np.sum((v) ** 2)\n        itercount += 1\n\n    # using Tr(X.T Y) = Sum[ij](Xij * Yij)\n    # P.T * C\n    # P_ij = u_i * v_j * K_ij\n    pity = np.multiply( np.multiply(K, u.reshape((-1,1))) , v)\n\n    glosim = np.sum( np.multiply( pity, envkernel))\n\n    return glosim", "response": "Compute the global similarity between two structures A and B."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(atoms_list,N, L, cutoff = 0, all_atomtypes=[]):\n    myAlphas, myBetas = genBasis.getBasisFunc(cutoff, N)\n    # get information about feature length\n    n_datapoints = len(atoms_list)\n    atoms = atoms_list[0]\n    x = get_lastatom_soap(atoms, cutoff, myAlphas, myBetas,N,L, all_atomtypes=all_atomtypes)\n    n_features = x.shape[1]\n    print(\"soap first\", x.shape)\n    print(n_datapoints, n_features)\n    soapmatrix = np.zeros((n_datapoints, n_features))\n\n    i = -1\n    for atoms in atoms_list:\n        i +=1\n        #atoms\n        print(\"Processing \" + str(atoms.info),\" Run time: \" + str(time.time()-t0_total), end=\"\\r\")\n        soapmatrix[i,:] = get_lastatom_soap(atoms, cutoff, myAlphas, myBetas, N, L, all_atomtypes=all_atomtypes)\n    print(\"\")\n\n    # infos\n    print(\"shape\", soapmatrix.shape)\n    return soapmatrix", "response": "Takes a trajectory xyz file and writes soap features\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates discrete vectors for the polynomial radial functions.", "response": "def getPoly(rCut, nMax):\n    \"\"\"Used to calculate discrete vectors for the polynomial basis functions.\n\n    Args:\n        rCut(float): Radial cutoff\n        nMax(int): Number of polynomial radial functions\n    \"\"\"\n    rCutVeryHard = rCut+5.0\n    rx = 0.5*rCutVeryHard*(x + 1)\n\n    basisFunctions = []\n    for i in range(1, nMax + 1):\n        basisFunctions.append(lambda rr, i=i, rCut=rCut: (rCut - np.clip(rr, 0, rCut))**(i+2))\n\n    # Calculate the overlap of the different polynomial functions in a\n    # matrix S. These overlaps defined through the dot product over the\n    # radial coordinate are analytically calculable: Integrate[(rc - r)^(a\n    # + 2) (rc - r)^(b + 2) r^2, {r, 0, rc}]. Then the weights B that make\n    # the basis orthonormal are given by B=S^{-1/2}\n    S = np.zeros((nMax, nMax))\n    for i in range(1, nMax+1):\n        for j in range(1, nMax+1):\n            S[i-1, j-1] = (2*(rCut)**(7+i+j))/((5+i+j)*(6+i+j)*(7+i+j))\n    betas = sqrtm(np.linalg.inv(S))\n\n    # If the result is complex, the calculation is currently halted.\n    if (betas.dtype == np.complex128):\n        raise ValueError(\n            \"Could not calculate normalization factors for the polynomial basis\"\n            \" in the domain of real numbers. Lowering the number of radial \"\n            \"basis functions is advised.\"\n        )\n\n    fs = np.zeros([nMax, len(x)])\n    for n in range(1, nMax+1):\n        fs[n-1, :] = (rCut-np.clip(rx, 0, rCut))**(n+2)\n\n    gss = np.dot(betas, fs)\n\n    return nMax, rx, gss"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _format_ase2clusgeo(obj, all_atomtypes=None):\n    #atoms metadata\n    totalAN = len(obj)\n    if all_atomtypes is not None:\n        atomtype_set = set(all_atomtypes)\n    else:\n        atomtype_set = set(obj.get_atomic_numbers())\n\n    atomtype_lst = np.sort(list(atomtype_set))\n    n_atoms_per_type_lst = []\n    pos_lst = []\n    for atomtype in atomtype_lst:\n        condition = obj.get_atomic_numbers() == atomtype\n        pos_onetype = obj.get_positions()[condition]\n        n_onetype = pos_onetype.shape[0]\n\n        # store data in lists\n        pos_lst.append(pos_onetype)\n        n_atoms_per_type_lst.append(n_onetype)\n\n    typeNs = n_atoms_per_type_lst\n    Ntypes = len(n_atoms_per_type_lst)\n    atomtype_lst\n    Apos = np.concatenate(pos_lst).ravel()\n    return Apos, typeNs, Ntypes, atomtype_lst, totalAN", "response": "Takes an ase Atoms object and returns numpy arrays and integers\n    which are currently a flattened array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_supercell(obj, rCut=5.0):\n    rCutHard = rCut + 5  # Giving extra space for hard cutOff\n    \"\"\" Takes atoms object (with a defined cell) and a radial cutoff.\n    Returns a supercell centered around the original cell\n    generously extended to contain all spheres with the given radial\n    cutoff centered around the original atoms.\n    \"\"\"\n\n    cell_vectors = obj.get_cell()\n    a1, a2, a3 = cell_vectors[0], cell_vectors[1], cell_vectors[2]\n\n    # vectors perpendicular to two cell vectors\n    b1 = np.cross(a2, a3, axis=0)\n    b2 = np.cross(a3, a1, axis=0)\n    b3 = np.cross(a1, a2, axis=0)\n    # projections onto perpendicular vectors\n    p1 = np.dot(a1, b1) / np.dot(b1, b1) * b1\n    p2 = np.dot(a2, b2) / np.dot(b2, b2) * b2\n    p3 = np.dot(a3, b3) / np.dot(b3, b3) * b3\n    xyz_arr = np.linalg.norm(np.array([p1, p2, p3]), axis=1)\n    cell_images = np.ceil(rCutHard/xyz_arr)\n    nx = int(cell_images[0])\n    ny = int(cell_images[1])\n    nz = int(cell_images[2])\n    suce = obj * (1+2*nx, 1+2*ny, 1+2*nz)\n    shift = obj.get_cell()\n\n    shifted_suce = suce.copy()\n    shifted_suce.translate(-shift[0]*nx - shift[1]*ny - shift[2]*nz)\n\n    return shifted_suce", "response": "Returns a supercell centered around the original atoms and a radial cutoff."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_soap_locals(obj, Hpos, alp, bet, rCut=5.0, nMax=5, Lmax=5, crossOver=True, all_atomtypes=None, eta=1.0):\n    rCutHard = rCut + 5\n    assert Lmax <= 9, \"l cannot exceed 9. Lmax={}\".format(Lmax)\n    assert Lmax >= 0, \"l cannot be negative.Lmax={}\".format(Lmax)\n    assert rCutHard < 17.0001, \"hard radius cuttof cannot be larger than 17 Angs. rCut={}\".format(rCutHard)\n    assert rCutHard > 1.999, \"hard redius cuttof cannot be lower than 1 Ang. rCut={}\".format(rCutHard)\n    assert nMax >= 2, \"number of basis functions cannot be lower than 2. nMax={}\".format(nMax)\n    assert nMax <= 13, \"number of basis functions cannot exceed 12. nMax={}\".format(nMax)\n    assert eta >= 0.0001, \"Eta cannot be zero or negative. nMax={}\".format(eta)\n\n    # get clusgeo internal format for c-code\n    Apos, typeNs, py_Ntypes, atomtype_lst, totalAN = _format_ase2clusgeo(obj, all_atomtypes)\n    Hpos = np.array(Hpos)\n    py_Hsize = Hpos.shape[0]\n\n    # flatten arrays\n    Hpos = Hpos.flatten()\n    alp = alp.flatten()\n    bet = bet.flatten()\n\n    # convert int to c_int\n    lMax = c_int(Lmax)\n    Hsize = c_int(py_Hsize)\n    Ntypes = c_int(py_Ntypes)\n    totalAN = c_int(totalAN)\n    rCutHard = c_double(rCutHard)\n    Nsize = c_int(nMax)\n    c_eta = c_double(eta)\n    #convert int array to c_int array\n    typeNs = (c_int * len(typeNs))(*typeNs)\n    # convert to c_double arrays\n    # alphas\n    alphas = (c_double * len(alp))(*alp.tolist())\n    # betas\n    betas = (c_double * len(bet))(*bet.tolist())\n    #Apos\n    axyz = (c_double * len(Apos))(*Apos.tolist())\n    #Hpos\n    hxyz = (c_double * len(Hpos))(*Hpos.tolist())\n    ### START SOAP###\n    #path_to_so = os.path.dirname(os.path.abspath(__file__))\n    _PATH_TO_SOAPLITE_SO = os.path.dirname(os.path.abspath(__file__))\n    _SOAPLITE_SOFILES = glob.glob( \"\".join([ _PATH_TO_SOAPLITE_SO, \"/../lib/libsoap*.*so\"]) ) ## NOT SURE ABOUT THIS\n\n    if py_Ntypes == 1 or (not crossOver):\n        substring = \"lib/libsoapPySig.\"\n        libsoap = CDLL(next((s for s in _SOAPLITE_SOFILES if substring in s), None))\n        libsoap.soap.argtypes = [POINTER (c_double),POINTER (c_double), POINTER (c_double),POINTER (c_double), POINTER (c_double), POINTER (c_int),c_double,c_int,c_int,c_int,c_int,c_int,c_double]\n        libsoap.soap.restype = POINTER (c_double)\n        c = (c_double*(int((nMax*(nMax+1))/2)*(Lmax+1)*py_Ntypes*py_Hsize))()\n        libsoap.soap( c, axyz, hxyz, alphas, betas, typeNs, rCutHard, totalAN, Ntypes, Nsize, lMax, Hsize,c_eta)\n    else:\n        substring = \"lib/libsoapGTO.\"\n        libsoapGTO = CDLL(next((s for s in _SOAPLITE_SOFILES if substring in s), None))\n        libsoapGTO.soap.argtypes = [POINTER (c_double),POINTER (c_double), POINTER (c_double),POINTER (c_double), POINTER (c_double), POINTER (c_int),c_double,c_int,c_int,c_int,c_int,c_int,c_double]\n        libsoapGTO.soap.restype = POINTER (c_double)\n        c = (c_double*(int((nMax*(nMax+1))/2)*(Lmax+1)*int((py_Ntypes*(py_Ntypes +1))/2)*py_Hsize))()\n        libsoapGTO.soap( c, axyz, hxyz, alphas, betas, typeNs, rCutHard, totalAN, Ntypes, Nsize, lMax, Hsize,c_eta)\n\n    #   return c;\n    if crossOver:\n        crosTypes = int((py_Ntypes*(py_Ntypes+1))/2)\n        shape = (py_Hsize, int((nMax*(nMax+1))/2)*(Lmax+1)*crosTypes)\n    else:\n        shape = (py_Hsize, int((nMax*(nMax+1))/2)*(Lmax+1)*py_Ntypes)\n\n    a = np.ctypeslib.as_array(c)\n    a = a.reshape(shape)\n\n    return a", "response": "Get the SOAP output for the given positions in a finite system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the SOAP output for a finite structure.", "response": "def get_soap_structure(obj, alp, bet, rCut=5.0, nMax=5, Lmax=5, crossOver=True, all_atomtypes=None, eta=1.0):\n    \"\"\"Get the RBF basis SOAP output for atoms in a finite structure.\n\n    Args:\n        obj(ase.Atoms): Atomic structure for which the SOAP output is\n            calculated.\n        alp: Alphas\n        bet: Betas\n        rCut: Radial cutoff.\n        nMax: Maximum nmber of radial basis functions\n        Lmax: Maximum spherical harmonics degree\n        crossOver:\n        all_atomtypes: Can be used to specify the atomic elements for which to\n            calculate the output. If given the output is calculated only for the\n            given species.\n        eta: The gaussian smearing width.\n\n    Returns:\n        np.ndarray: SOAP output for the given structure.\n    \"\"\"\n    Hpos = obj.get_positions()\n    arrsoap = get_soap_locals(obj, Hpos, alp, bet,  rCut, nMax, Lmax, crossOver, all_atomtypes=all_atomtypes, eta=eta)\n\n    return arrsoap"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_periodic_soap_locals(obj, Hpos, alp, bet, rCut=5.0, nMax=5, Lmax=5, crossOver=True, all_atomtypes=None, eta=1.0):\n    suce = _get_supercell(obj, rCut)\n    arrsoap = get_soap_locals(suce, Hpos, alp, bet, rCut, nMax=nMax, Lmax=Lmax, crossOver=crossOver, all_atomtypes=all_atomtypes, eta=eta)\n\n    return arrsoap", "response": "Get the SOAP output for the given position in a periodic system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake cluster structure and nearest neighbour information of a datapoint returns a single array of soap vectors.", "response": "def get_nnsoap(obj, first_shell, alphas, betas, rcut=6, nmax=10, lmax=9, all_atomtypes=[]):\n    \"\"\"Takes cluster structure and nearest neighbour information of a datapoint,\n    Returns concatenated soap vectors for each nearest\n    neighbour (up to 3). Top, bridge, hollow fill the initial\n    zero soap vector from left to right.\n    \"\"\"\n\n    soap_vector = []\n    nnn = len(first_shell)\n    for tbh in range(0,3):\n        try:\n            atom_idx = first_shell[tbh]\n        except:\n            soap_vector.append(soap_zero)\n        else:\n            Hpos = []\n            print(atom_idx)\n            pos = obj.get_positions()[atom_idx]\n            Hpos.append(pos)\n            x = soapPy.get_soap_locals(obj, Hpos, myAlphas, myBetas, rCut=rcut, NradBas=nmax, Lmax=lmax,crossOver=False, all_atomtypes=all_atomtypes)\n            soap_zero = np.zeros(x.shape)\n            soap_vector.append(x)\n    print(len(soap_vector), soap_vector[0].shape, soap_vector[1].shape, soap_vector[2].shape)\n    print(\"exemplary soapvalues\",soap_vector[0][0,1], soap_vector[1][0,1], soap_vector[2][0,1])\n    soap_array = np.hstack(soap_vector)\n    return soap_array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake cluster structure and nearest neighbour information of a datapoint returns a single cluster structure with the same soap values.", "response": "def get_sitecenteredsoap(obj, first_shell, alphas, betas, rcut=6, nmax=10, lmax=9, all_atomtypes=[]):\n    \"\"\"Takes cluster structure and nearest neighbour information of a datapoint,\n    Returns concatenated soap vectors for each nearest\n    neighbour (up to 3). Top, bridge, hollow fill the initial\n    zero soap vector from left to right.\n    \"\"\"\n\n    soap_vector = []\n    nnn = len(first_shell)\n    center_of_atoms = 1.0 / nnn * np.mean(obj.get_positions()[first_shell], axis = 0)\n    #print(\"center of atoms\", center_of_atoms)\n    Hpos = [center_of_atoms]\n    soap_vector = soapPy.get_soap_locals(obj, Hpos, myAlphas, myBetas, rCut=rcut, NradBas=nmax, Lmax=lmax,crossOver=False, all_atomtypes=all_atomtypes)\n    #print(len(soap_vector), soap_vector.shape)\n    #print(\"exemplary soapvalues\",soap_vector[0,0], soap_vector[0,1], soap_vector[0,2])\n    return soap_vector"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef w(self, units=None):\n\n        if units is None:\n            if self.hamiltonian is None:\n                units = dimensionless\n            else:\n                units = self.hamiltonian.units\n\n        return super(Orbit, self).w(units=units)", "response": "This returns a single array containing the phase - space positions and velocities."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef represent_as(self, new_pos, new_vel=None):\n\n        o = super(Orbit, self).represent_as(new_pos=new_pos, new_vel=new_vel)\n        return self.__class__(pos=o.pos,\n                              vel=o.vel,\n                              hamiltonian=self.hamiltonian)", "response": "Represent the position and velocity of the orbit in an alternate skeleton."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_hdf5(self, f):\n\n        f = super(Orbit, self).to_hdf5(f)\n\n        if self.potential is not None:\n            import yaml\n            from ..potential.potential.io import to_dict\n            f['potential'] = yaml.dump(to_dict(self.potential)).encode('utf-8')\n\n        if self.t:\n            quantity_to_hdf5(f, 'time', self.t)\n\n        return f", "response": "Serialize this object to an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_hdf5(cls, f):\n        # TODO: this is duplicated code from PhaseSpacePosition\n        if isinstance(f, str):\n            import h5py\n            f = h5py.File(f)\n\n        pos = quantity_from_hdf5(f['pos'])\n        vel = quantity_from_hdf5(f['vel'])\n\n        time = None\n        if 'time' in f:\n            time = quantity_from_hdf5(f['time'])\n\n        frame = None\n        if 'frame' in f:\n            g = f['frame']\n\n            frame_mod = g.attrs['module']\n            frame_cls = g.attrs['class']\n            frame_units = [u.Unit(x.decode('utf-8')) for x in g['units']]\n\n            if u.dimensionless_unscaled in frame_units:\n                units = DimensionlessUnitSystem()\n            else:\n                units = UnitSystem(*frame_units)\n\n            pars = dict()\n            for k in g['parameters']:\n                pars[k] = quantity_from_hdf5(g['parameters/'+k])\n\n            exec(\"from {0} import {1}\".format(frame_mod, frame_cls))\n            frame_cls = eval(frame_cls)\n\n            frame = frame_cls(units=units, **pars)\n\n        potential = None\n        if 'potential' in f:\n            import yaml\n            from ..potential.potential.io import from_dict\n            _dict = yaml.load(f['potential'][()].decode('utf-8'))\n            potential = from_dict(_dict)\n\n        return cls(pos=pos, vel=vel, t=time,\n                   frame=frame, potential=potential)", "response": "Load an object from an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef potential_energy(self, potential=None):\n        if self.hamiltonian is None and potential is None:\n            raise ValueError(\"To compute the potential energy, a potential\"\n                             \" object must be provided!\")\n        if potential is None:\n            potential = self.hamiltonian.potential\n\n        return super(Orbit,self).potential_energy(potential)", "response": "Compute the potential energy of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef energy(self, hamiltonian=None):\n\n        if self.hamiltonian is None and hamiltonian is None:\n            raise ValueError(\"To compute the total energy, a hamiltonian\"\n                             \" object must be provided!\")\n\n        from ..potential import PotentialBase\n        if isinstance(hamiltonian, PotentialBase):\n            from ..potential import Hamiltonian\n\n            warnings.warn(\"This function now expects a `Hamiltonian` instance \"\n                          \"instead of a `PotentialBase` subclass instance. If \"\n                          \"you are using a static reference frame, you just \"\n                          \"need to pass your potential object in to the \"\n                          \"Hamiltonian constructor to use, e.g., Hamiltonian\"\n                          \"(potential).\", DeprecationWarning)\n\n            hamiltonian = Hamiltonian(hamiltonian)\n\n        if hamiltonian is None:\n            hamiltonian = self.hamiltonian\n\n        return hamiltonian(self)", "response": "r Returns the total energy of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the pericenter of the local minima in the current time - series.", "response": "def pericenter(self, return_times=False, func=np.mean,\n                   interp_kwargs=None, minimize_kwargs=None,\n                   approximate=False):\n        \"\"\"\n        Estimate the pericenter(s) of the orbit by identifying local minima in\n        the spherical radius and interpolating between timesteps near the\n        minima.\n\n        By default, this returns the mean of all local minima (pericenters). To\n        get, e.g., the minimum pericenter, pass in ``func=np.min``. To get\n        all pericenters, pass in ``func=None``.\n\n        Parameters\n        ----------\n        func : func (optional)\n            A function to evaluate on all of the identified pericenter times.\n        return_times : bool (optional)\n            Also return the pericenter times.\n        interp_kwargs : dict (optional)\n            Keyword arguments to be passed to\n            :class:`scipy.interpolate.InterpolatedUnivariateSpline`.\n        minimize_kwargs : dict (optional)\n            Keyword arguments to be passed to :class:`scipy.optimize.minimize`.\n        approximate : bool (optional)\n            Compute an approximate pericenter by skipping interpolation.\n\n        Returns\n        -------\n        peri : float, :class:`~numpy.ndarray`\n            Either a single number or an array of pericenters.\n        times : :class:`~numpy.ndarray` (optional, see ``return_times``)\n            If ``return_times=True``, also returns an array of the pericenter\n            times.\n\n        \"\"\"\n\n        if return_times and func is not None:\n            raise ValueError(\"Cannot return times if reducing pericenters \"\n                             \"using an input function. Pass `func=None` if \"\n                             \"you want to return all individual pericenters \"\n                             \"and times.\")\n\n        if func is None:\n            reduce = False\n            func = lambda x: x\n        else:\n            reduce = True\n\n        # time must increase\n        if self.t[-1] < self.t[0]:\n            self = self[::-1]\n\n        vals = []\n        times = []\n        for orbit in self.orbit_gen():\n            v, t = orbit._max_helper(-orbit.physicsspherical.r, # pericenter\n                                     interp_kwargs=interp_kwargs,\n                                     minimize_kwargs=minimize_kwargs,\n                                     approximate=approximate)\n            vals.append(func(-v)) # negative for pericenter\n            times.append(t)\n\n        return self._max_return_helper(vals, times, return_times, reduce)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zmax(self, return_times=False, func=np.mean,\n             interp_kwargs=None, minimize_kwargs=None,\n             approximate=False):\n        \"\"\"\n        Estimate the maximum ``z`` height of the orbit by identifying local\n        maxima in the absolute value of the ``z`` position and interpolating\n        between timesteps near the maxima.\n\n        By default, this returns the mean of all local maxima. To get, e.g., the\n        largest ``z`` excursion, pass in ``func=np.max``. To get all ``z``\n        maxima, pass in ``func=None``.\n\n        Parameters\n        ----------\n        func : func (optional)\n            A function to evaluate on all of the identified z maximum times.\n        return_times : bool (optional)\n            Also return the times of maximum.\n        interp_kwargs : dict (optional)\n            Keyword arguments to be passed to\n            :class:`scipy.interpolate.InterpolatedUnivariateSpline`.\n        minimize_kwargs : dict (optional)\n            Keyword arguments to be passed to :class:`scipy.optimize.minimize`.\n        approximate : bool (optional)\n            Compute approximate values by skipping interpolation.\n\n        Returns\n        -------\n        zs : float, :class:`~numpy.ndarray`\n            Either a single number or an array of maximum z heights.\n        times : :class:`~numpy.ndarray` (optional, see ``return_times``)\n            If ``return_times=True``, also returns an array of the apocenter\n            times.\n\n        \"\"\"\n\n        if return_times and func is not None:\n            raise ValueError(\"Cannot return times if reducing \"\n                             \"using an input function. Pass `func=None` if \"\n                             \"you want to return all individual values \"\n                             \"and times.\")\n\n        if func is None:\n            reduce = False\n            func = lambda x: x\n        else:\n            reduce = True\n\n        # time must increase\n        if self.t[-1] < self.t[0]:\n            self = self[::-1]\n\n        vals = []\n        times = []\n        for orbit in self.orbit_gen():\n            v, t = orbit._max_helper(np.abs(orbit.cylindrical.z),\n                                     interp_kwargs=interp_kwargs,\n                                     minimize_kwargs=minimize_kwargs,\n                                     approximate=approximate)\n            vals.append(func(v))\n            times.append(t)\n\n        return self._max_return_helper(vals, times, return_times, reduce)", "response": "Return the maximum z height of the local maxima in the time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef circulation(self):\n        L = self.angular_momentum()\n\n        # if only 2D, add another empty axis\n        if L.ndim == 2:\n            single_orbit = True\n            L = L[...,None]\n        else:\n            single_orbit = False\n\n        ndim,ntimes,norbits = L.shape\n\n        # initial angular momentum\n        L0 = L[:,0]\n\n        # see if at any timestep the sign has changed\n        circ = np.ones((ndim,norbits))\n        for ii in range(ndim):\n            cnd = (np.sign(L0[ii]) != np.sign(L[ii,1:])) | \\\n                  (np.abs(L[ii,1:]).value < 1E-13)\n            ix = np.atleast_1d(np.any(cnd, axis=0))\n            circ[ii,ix] = 0\n\n        circ = circ.astype(int)\n        if single_orbit:\n            return circ.reshape((ndim,))\n        else:\n            return circ", "response": "Returns a 2D array that contains the circulation of the angular momentum."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef align_circulation_with_z(self, circulation=None):\n\n        if circulation is None:\n            circulation = self.circulation()\n        circulation = atleast_2d(circulation, insert_axis=1)\n\n        cart = self.cartesian\n        pos = cart.xyz\n        vel = np.vstack((cart.v_x.value[None],\n                         cart.v_y.value[None],\n                         cart.v_z.value[None])) * cart.v_x.unit\n\n        if pos.ndim < 3:\n            pos = pos[...,np.newaxis]\n            vel = vel[...,np.newaxis]\n\n        if (circulation.shape[0] != self.ndim or\n                circulation.shape[1] != pos.shape[2]):\n            raise ValueError(\"Shape of 'circulation' array should match the \"\n                             \"shape of the position/velocity (minus the time \"\n                             \"axis).\")\n\n        new_pos = pos.copy()\n        new_vel = vel.copy()\n        for n in range(pos.shape[2]):\n            if circulation[2,n] == 1 or np.all(circulation[:,n] == 0):\n                # already circulating about z or box orbit\n                continue\n\n            if sum(circulation[:,n]) > 1:\n                logger.warning(\"Circulation about multiple axes - are you sure \"\n                               \"the orbit has been integrated for long enough?\")\n\n            if circulation[0,n] == 1:\n                circ = 0\n            elif circulation[1,n] == 1:\n                circ = 1\n            else:\n                raise RuntimeError(\"Should never get here...\")\n\n            new_pos[circ,:,n] = pos[2,:,n]\n            new_pos[2,:,n] = pos[circ,:,n]\n\n            new_vel[circ,:,n] = vel[2,:,n]\n            new_vel[2,:,n] = vel[circ,:,n]\n\n        return self.__class__(pos=new_pos.reshape(cart.xyz.shape),\n                              vel=new_vel.reshape(cart.xyz.shape),\n                              t=self.t,\n                              hamiltonian=self.hamiltonian)", "response": "This function aligns the circulation with the z axis and returns a copy of the original orbit with the circulation aligned with the z axis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert this Orbit to a new reference frame.", "response": "def to_frame(self, frame, current_frame=None, **kwargs):\n        \"\"\"\n        TODO:\n\n        Parameters\n        ----------\n        frame : `gala.potential.CFrameBase`\n            The frame to transform to.\n        current_frame : `gala.potential.CFrameBase` (optional)\n            If the Orbit has no associated Hamiltonian, this specifies the\n            current frame of the orbit.\n\n        Returns\n        -------\n        orbit : `gala.dynamics.Orbit`\n            The orbit in the new reference frame.\n\n        \"\"\"\n\n        kw = kwargs.copy()\n\n        # TODO: need a better way to do this!\n        from ..potential.frame.builtin import ConstantRotatingFrame\n        for fr in [frame, current_frame, self.frame]:\n            if isinstance(fr, ConstantRotatingFrame):\n                if 't' not in kw:\n                    kw['t'] = self.t\n\n        psp = super(Orbit, self).to_frame(frame, current_frame, **kw)\n\n        return Orbit(pos=psp.pos, vel=psp.vel, t=self.t,\n                     frame=frame, potential=self.potential)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms between two greatcircle frames.", "response": "def greatcircle_to_greatcircle(from_greatcircle_coord,\n                               to_greatcircle_frame):\n    \"\"\"Transform between two greatcircle frames.\"\"\"\n\n    # This transform goes through the parent frames on each side.\n    # from_frame -> from_frame.origin -> to_frame.origin -> to_frame\n    intermediate_from = from_greatcircle_coord.transform_to(\n        from_greatcircle_coord.pole)\n    intermediate_to = intermediate_from.transform_to(\n        to_greatcircle_frame.pole)\n    return intermediate_to.transform_to(to_greatcircle_frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a reference coordinate to a great circle frame.", "response": "def reference_to_greatcircle(reference_frame, greatcircle_frame):\n    \"\"\"Convert a reference coordinate to a great circle frame.\"\"\"\n\n    # Define rotation matrices along the position angle vector, and\n    # relative to the origin.\n    pole = greatcircle_frame.pole.transform_to(coord.ICRS)\n    ra0 = greatcircle_frame.ra0\n    center = greatcircle_frame.center\n    R_rot = rotation_matrix(greatcircle_frame.rotation, 'z')\n\n    if not np.isnan(ra0):\n        xaxis = np.array([np.cos(ra0), np.sin(ra0), 0.])\n        zaxis = pole.cartesian.xyz.value\n        if np.abs(zaxis[2]) >= 1e-15:\n            xaxis[2] = -(zaxis[0]*xaxis[0] + zaxis[1]*xaxis[1]) / zaxis[2] # what?\n        else:\n            xaxis[2] = 0.\n        xaxis = xaxis / np.sqrt(np.sum(xaxis**2))\n        yaxis = np.cross(zaxis, xaxis)\n        R = np.stack((xaxis, yaxis, zaxis))\n\n    elif center is not None:\n        R1 = rotation_matrix(pole.ra, 'z')\n        R2 = rotation_matrix(90*u.deg - pole.dec, 'y')\n        Rtmp = matrix_product(R2, R1)\n\n        rot = center.cartesian.transform(Rtmp)\n        rot_lon = rot.represent_as(coord.UnitSphericalRepresentation).lon\n        R3 = rotation_matrix(rot_lon, 'z')\n        R = matrix_product(R3, R2, R1)\n\n    else:\n        R1 = rotation_matrix(pole.ra, 'z')\n        R2 = rotation_matrix(pole.dec, 'y')\n        R = matrix_product(R2, R1)\n\n    return matrix_product(R_rot, R)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the pole from a great circle that connects the two specified coordinates.", "response": "def pole_from_endpoints(coord1, coord2):\n    \"\"\"Compute the pole from a great circle that connects the two specified\n    coordinates.\n\n    This assumes a right-handed rule from coord1 to coord2: the pole is the\n    north pole under that assumption.\n\n    Parameters\n    ----------\n    coord1 : `~astropy.coordinates.SkyCoord`\n        Coordinate of one point on a great circle.\n    coord2 : `~astropy.coordinates.SkyCoord`\n        Coordinate of the other point on a great circle.\n\n    Returns\n    -------\n    pole : `~astropy.coordinates.SkyCoord`\n        The coordinates of the pole.\n    \"\"\"\n    c1 = coord1.cartesian / coord1.cartesian.norm()\n\n    coord2 = coord2.transform_to(coord1.frame)\n    c2 = coord2.cartesian / coord2.cartesian.norm()\n\n    pole = c1.cross(c2)\n    pole = pole / pole.norm()\n    return coord1.frame.realize_frame(pole)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sph_midpoint(coord1, coord2):\n    c1 = coord1.cartesian / coord1.cartesian.norm()\n\n    coord2 = coord2.transform_to(coord1.frame)\n    c2 = coord2.cartesian / coord2.cartesian.norm()\n\n    midpt = 0.5 * (c1 + c2)\n    usph = midpt.represent_as(coord.UnitSphericalRepresentation)\n\n    return coord1.frame.realize_frame(usph)", "response": "Compute the midpoint between two points on the sphere."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_uv_tan(c):\n    l = c.spherical.lon\n    b = c.spherical.lat\n\n    p = np.array([-np.sin(l), np.cos(l), np.zeros_like(l.value)]).T\n    q = np.array([-np.cos(l)*np.sin(b), -np.sin(l)*np.sin(b), np.cos(b)]).T\n\n    return np.stack((p, q), axis=-1)", "response": "Get tangent plane vectors on the unit sphere at the given\n    spherical coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_transform_matrix(from_frame, to_frame):\n    path, distance = coord.frame_transform_graph.find_shortest_path(\n        from_frame, to_frame)\n\n    matrices = []\n    currsys = from_frame\n    for p in path[1:]:  # first element is fromsys so we skip it\n        trans = coord.frame_transform_graph._graph[currsys][p]\n        if isinstance(trans, coord.DynamicMatrixTransform):\n            M = trans.matrix_func(currsys(), p)\n        elif isinstance(trans, coord.StaticMatrixTransform):\n            M = trans.matrix\n        else:\n            raise ValueError(\"Transform path contains a '{0}': cannot \"\n                             \"be composed into a single transformation \"\n                             \"matrix.\".format(trans.__class__.__name__))\n\n        matrices.append(M)\n        currsys = p\n\n    M = None\n    for Mi in reversed(matrices):\n        if M is None:\n            M = Mi\n        else:\n            M = matrix_product(M, Mi)\n\n    return M", "response": "Compose a sequential matrix transformation from a given frame through the Astropy\n    transformation machinery."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming a proper motion covariance matrix to a new frame.", "response": "def transform_pm_cov(c, cov, to_frame):\n    \"\"\"Transform a proper motion covariance matrix to a new frame.\n\n    Parameters\n    ----------\n    c : `~astropy.coordinates.SkyCoord`\n        The sky coordinates of the sources in the initial coordinate frame.\n    cov : array_like\n        The covariance matrix of the proper motions. Must have same length as\n        the input coordinates.\n    to_frame : `~astropy.coordinates.BaseCoordinateFrame` subclass\n        The frame to transform to as an Astropy coordinate frame class or\n        instance.\n\n    Returns\n    -------\n    new_cov : array_like\n        The transformed covariance matrix.\n\n    \"\"\"\n    if c.isscalar and cov.shape != (2, 2):\n        raise ValueError('If input coordinate object is a scalar coordinate, '\n                         'the proper motion covariance matrix must have shape '\n                         '(2, 2), not {}'.format(cov.shape))\n\n    elif not c.isscalar and len(c) != cov.shape[0]:\n        raise ValueError('Input coordinates and covariance matrix must have '\n                         'the same number of entries ({} vs {}).'\n                         .format(len(c), cov.shape[0]))\n\n    # 3D rotation matrix, to be projected onto the tangent plane\n    if hasattr(c, 'frame'):\n        frame = c.frame\n    else:\n        frame = c\n    R = get_transform_matrix(frame.__class__, to_frame)\n\n    # Get input coordinates in the desired frame:\n    c_to = c.transform_to(to_frame)\n\n    # Get tangent plane coordinates:\n    uv_in = get_uv_tan(c)\n    uv_to = get_uv_tan(c_to)\n\n    if not c.isscalar:\n        G = np.einsum('nab,nac->nbc', uv_to,\n                      np.einsum('ji,nik->njk', R, uv_in))\n\n        # transform\n        cov_to = np.einsum('nba,nac->nbc', G,\n                           np.einsum('nij,nki->njk', cov, G))\n    else:\n        G = np.einsum('ab,ac->bc', uv_to,\n                      np.einsum('ji,ik->jk', R, uv_in))\n\n        # transform\n        cov_to = np.einsum('ba,ac->bc', G,\n                           np.einsum('ij,ki->jk', cov, G))\n\n    return cov_to"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rodrigues_axis_angle_rotate(x, vec, theta):\n    x = np.array(x).T\n    vec = np.array(vec).T\n    theta = np.array(theta).T[...,None]\n\n    out = np.cos(theta)*x + np.sin(theta)*np.cross(vec, x) + \\\n        (1 - np.cos(theta)) * (vec * x).sum(axis=-1)[...,None] * vec\n\n    return out.T", "response": "Rotated the input vector or set of vectors x around the axis\n    vec by the angle theta."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef z_angle_rotate(xy, theta):\n    xy = np.array(xy).T\n    theta = np.array(theta).T\n\n    out = np.zeros_like(xy)\n    out[...,0] = np.cos(theta)*xy[...,0] - np.sin(theta)*xy[...,1]\n    out[...,1] = np.sin(theta)*xy[...,0] + np.cos(theta)*xy[...,1]\n\n    return out.T", "response": "Rotated the input vector or set of vectors xy by the angle theta."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform from an inertial static frame to a rotating frame.", "response": "def static_to_constantrotating(frame_i, frame_r, w, t=None):\n    \"\"\"\n    Transform from an inertial static frame to a rotating frame.\n\n    Parameters\n    ----------\n    frame_i : `~gala.potential.StaticFrame`\n    frame_r : `~gala.potential.ConstantRotatingFrame`\n    w : `~gala.dynamics.PhaseSpacePosition`, `~gala.dynamics.Orbit`\n    t : quantity_like (optional)\n        Required if input coordinates are just a phase-space position.\n\n    Returns\n    -------\n    pos : `~astropy.units.Quantity`\n        Position in rotating frame.\n    vel : `~astropy.units.Quantity`\n        Velocity in rotating frame.\n    \"\"\"\n    return _constantrotating_static_helper(frame_r=frame_r, frame_i=frame_i,\n                                           w=w, t=t, sign=1.)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef constantrotating_to_static(frame_r, frame_i, w, t=None):\n    return _constantrotating_static_helper(frame_r=frame_r, frame_i=frame_i,\n                                           w=w, t=t, sign=-1.)", "response": "Transform from a constantly rotating frame to a static inertial frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_dict(d, module=None):\n    # need this here for circular import\n    from .. import potential as gala_potential\n\n    if module is None:\n        potential = gala_potential\n    else:\n        potential = module\n\n    if 'type' in d and d['type'] == 'composite':\n        p = getattr(potential, d['class'])()\n        for i, component in enumerate(d['components']):\n            c = _parse_component(component, module)\n            name = component.get('name', str(i))\n            p[name] = c\n\n    elif 'type' in d and d['type'] == 'custom':\n        param_groups = dict()\n        for i, component in enumerate(d['components']):\n            c = _parse_component(component, module)\n\n            try:\n                name = component['name']\n            except KeyError:\n                raise KeyError(\"For custom potentials, component specification \"\n                               \"must include the component name (e.g., name: \"\n                               \"'blah')\")\n\n            params = component.get('parameters', {})\n            params = _unpack_params(params) # unpack quantities\n            param_groups[name] = params\n        p = getattr(potential, d['class'])(**param_groups)\n\n    else:\n        p = _parse_component(d, module)\n\n    return p", "response": "Convert a dictionary potential specification into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(potential):\n    from .. import potential as gp\n\n    if isinstance(potential, gp.CompositePotential):\n        d = dict()\n        d['class'] = potential.__class__.__name__\n        d['components'] = []\n        for k, p in potential.items():\n            comp_dict = _to_dict_help(p)\n            comp_dict['name'] = k\n            d['components'].append(comp_dict)\n\n        if potential.__class__.__name__ == 'CompositePotential' or \\\n           potential.__class__.__name__ == 'CCompositePotential':\n            d['type'] = 'composite'\n        else:\n            d['type'] = 'custom'\n\n    else:\n        d = _to_dict_help(potential)\n\n    return d", "response": "Turn a potential object into a dictionary that fully specifies the\n    state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(f, module=None):\n    if hasattr(f, 'read'):\n        p_dict = yaml.load(f.read())\n    else:\n        with open(os.path.abspath(f), 'r') as fil:\n            p_dict = yaml.load(fil.read())\n\n    return from_dict(p_dict, module=module)", "response": "Read a potential specification file and return a new a\n    object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a new object to a YAML file.", "response": "def save(potential, f):\n    \"\"\"\n    Write a :class:`~gala.potential.PotentialBase` object out to a text (YAML)\n    file.\n\n    Parameters\n    ----------\n    potential : :class:`~gala.potential.PotentialBase`\n        The instantiated :class:`~gala.potential.PotentialBase` object.\n    f : str, file_like\n        A filename or file-like object to write the input potential object to.\n\n    \"\"\"\n    d = to_dict(potential)\n\n    if hasattr(f, 'write'):\n        yaml.dump(d, f, default_flow_style=False)\n    else:\n        with open(f, 'w') as f2:\n            yaml.dump(d, f2, default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _prepare_ws(self, w0, mmap, n_steps):\n        from ..dynamics import PhaseSpacePosition\n        if not isinstance(w0, PhaseSpacePosition):\n            w0 = PhaseSpacePosition.from_w(w0)\n\n        arr_w0 = w0.w(self._func_units)\n\n        self.ndim, self.norbits = arr_w0.shape\n        self.ndim = self.ndim//2\n\n        return_shape = (2*self.ndim, n_steps+1, self.norbits)\n        if mmap is None:\n            # create the return arrays\n            ws = np.zeros(return_shape, dtype=float)\n\n        else:\n            if mmap.shape != return_shape:\n                raise ValueError(\"Shape of memory-mapped array doesn't match \"\n                                 \"expected shape of return array ({} vs {})\"\n                                 .format(mmap.shape, return_shape))\n\n            if not mmap.flags.writeable:\n                raise TypeError(\"Memory-mapped array must be a writable mode, \"\n                                \" not '{}'\".format(mmap.mode))\n\n            ws = mmap\n\n        return w0, arr_w0, ws", "response": "Prepare the array for the memory - mapped array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fast_lyapunov_max(w0, hamiltonian, dt, n_steps, d0=1e-5,\n                      n_steps_per_pullback=10, noffset_orbits=2, t1=0.,\n                      atol=1E-10, rtol=1E-10, nmax=0, return_orbit=True):\n    \"\"\"\n    Compute the maximum Lyapunov exponent using a C-implemented estimator\n    that uses the DOPRI853 integrator.\n\n    Parameters\n    ----------\n    w0 : `~gala.dynamics.PhaseSpacePosition`, array_like\n        Initial conditions.\n    hamiltonian : `~gala.potential.Hamiltonian`\n    dt : numeric\n        Timestep.\n    n_steps : int\n        Number of steps to run for.\n    d0 : numeric (optional)\n        The initial separation.\n    n_steps_per_pullback : int (optional)\n        Number of steps to run before re-normalizing the offset vectors.\n    noffset_orbits : int (optional)\n        Number of offset orbits to run.\n    t1 : numeric (optional)\n        Time of initial conditions. Assumed to be t=0.\n    return_orbit : bool (optional)\n        Store the full orbit for the parent and all offset orbits.\n\n    Returns\n    -------\n    LEs : :class:`~astropy.units.Quantity`\n        Lyapunov exponents calculated from each offset / deviation orbit.\n    orbit : `~gala.dynamics.Orbit` (optional)\n\n    \"\"\"\n\n    from .lyapunov import dop853_lyapunov_max, dop853_lyapunov_max_dont_save\n\n    # TODO: remove in v1.0\n    if isinstance(hamiltonian, PotentialBase):\n        from ..potential import Hamiltonian\n        hamiltonian = Hamiltonian(hamiltonian)\n\n    if not hamiltonian.c_enabled:\n        raise TypeError(\"Input Hamiltonian must contain a C-implemented \"\n                        \"potential and frame.\")\n\n    if not isinstance(w0, PhaseSpacePosition):\n        w0 = np.asarray(w0)\n        ndim = w0.shape[0]//2\n        w0 = PhaseSpacePosition(pos=w0[:ndim],\n                                vel=w0[ndim:])\n\n    _w0 = np.squeeze(w0.w(hamiltonian.units))\n    if _w0.ndim > 1:\n        raise ValueError(\"Can only compute fast Lyapunov exponent for a single orbit.\")\n\n    if return_orbit:\n        t,w,l = dop853_lyapunov_max(hamiltonian, _w0,\n                                    dt, n_steps+1, t1,\n                                    d0, n_steps_per_pullback, noffset_orbits,\n                                    atol, rtol, nmax)\n        w = np.rollaxis(w, -1)\n\n        try:\n            tunit = hamiltonian.units['time']\n        except (TypeError, AttributeError):\n            tunit = u.dimensionless_unscaled\n\n        orbit = Orbit.from_w(w=w, units=hamiltonian.units,\n                             t=t*tunit, hamiltonian=hamiltonian)\n        return l/tunit, orbit\n\n    else:\n        l = dop853_lyapunov_max_dont_save(hamiltonian, _w0,\n                                          dt, n_steps+1, t1,\n                                          d0, n_steps_per_pullback, noffset_orbits,\n                                          atol, rtol, nmax)\n\n        try:\n            tunit = hamiltonian.units['time']\n        except (TypeError, AttributeError):\n            tunit = u.dimensionless_unscaled\n\n        return l/tunit", "response": "Compute the maximum Lyapunov exponent using a C - implemented estimator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate and returns a new base - surface of section from an orbit.", "response": "def surface_of_section(orbit, plane_ix, interpolate=False):\n    \"\"\"\n    Generate and return a surface of section from the given orbit.\n\n    .. warning::\n\n        This is an experimental function and the API may change.\n\n    Parameters\n    ----------\n    orbit : `~gala.dynamics.Orbit`\n    plane_ix : int\n        Integer that represents the coordinate to record crossings in. For\n        example, for a 2D Hamiltonian where you want to make a SoS in\n        :math:`y-p_y`, you would specify ``plane_ix=0`` (crossing the\n        :math:`x` axis), and this will only record crossings for which\n        :math:`p_x>0`.\n    interpolate : bool (optional)\n        Whether or not to interpolate on to the plane of interest. This\n        makes it much slower, but will work for orbits with a coarser\n        sampling.\n\n    Returns\n    -------\n\n    Examples\n    --------\n    If your orbit of interest is a tube orbit, it probably conserves (at\n    least approximately) some equivalent to angular momentum in the direction\n    of the circulation axis. Therefore, a surface of section in R-z should\n    be instructive for classifying these orbits. TODO...show how to convert\n    an orbit to Cylindrical..etc...\n\n    \"\"\"\n\n    w = orbit.w()\n    if w.ndim == 2:\n        w = w[...,None]\n\n    ndim,ntimes,norbits = w.shape\n    H_dim = ndim // 2\n    p_ix = plane_ix + H_dim\n\n    if interpolate:\n        raise NotImplementedError(\"Not yet implemented, sorry!\")\n\n    # record position on specified plane when orbit crosses\n    all_sos = np.zeros((ndim,norbits), dtype=object)\n    for n in range(norbits):\n        cross_ix = argrelmin(w[plane_ix,:,n]**2)[0]\n        cross_ix = cross_ix[w[p_ix,cross_ix,n] > 0.]\n        sos = w[:,cross_ix,n]\n\n        for j in range(ndim):\n            all_sos[j,n] = sos[j,:]\n\n    return all_sos"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _remove_units(self, x):\n        if hasattr(x, 'unit'):\n            x = x.decompose(self.units).value\n\n        else:\n            x = np.array(x)\n\n        return x", "response": "Returns an array of the units associated with this object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the potential energy at the given position.", "response": "def energy(self, q, t=0.):\n        \"\"\"\n        Compute the potential energy at the given position(s).\n\n        Parameters\n        ----------\n        q : `~gala.dynamics.PhaseSpacePosition`, `~astropy.units.Quantity`, array_like\n            The position to compute the value of the potential. If the\n            input position object has no units (i.e. is an `~numpy.ndarray`),\n            it is assumed to be in the same unit system as the potential.\n\n        Returns\n        -------\n        E : `~astropy.units.Quantity`\n            The potential energy per unit mass or value of the potential.\n        \"\"\"\n        q = self._remove_units_prepare_shape(q)\n        orig_shape, q = self._get_c_valid_arr(q)\n        t = self._validate_prepare_time(t, q)\n        ret_unit = self.units['energy'] / self.units['mass']\n\n        return self._energy(q, t=t).T.reshape(orig_shape[1:]) * ret_unit"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gradient(self, q, t=0.):\n        q = self._remove_units_prepare_shape(q)\n        orig_shape, q = self._get_c_valid_arr(q)\n        t = self._validate_prepare_time(t, q)\n        ret_unit = self.units['length'] / self.units['time']**2\n        return (self._gradient(q, t=t).T.reshape(orig_shape) * ret_unit).to(self.units['acceleration'])", "response": "Compute the gradient of the potential at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef density(self, q, t=0.):\n        q = self._remove_units_prepare_shape(q)\n        orig_shape, q = self._get_c_valid_arr(q)\n        t = self._validate_prepare_time(t, q)\n        ret_unit = self.units['mass'] / self.units['length']**3\n        return (self._density(q, t=t).T * ret_unit).to(self.units['mass density'])", "response": "Compute the density value at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the Hessian of the potential at the given position.", "response": "def hessian(self, q, t=0.):\n        \"\"\"\n        Compute the Hessian of the potential at the given position(s).\n\n        Parameters\n        ----------\n        q : `~gala.dynamics.PhaseSpacePosition`, `~astropy.units.Quantity`, array_like\n            The position to compute the value of the potential. If the\n            input position object has no units (i.e. is an `~numpy.ndarray`),\n            it is assumed to be in the same unit system as the potential.\n\n        Returns\n        -------\n        hess : `~astropy.units.Quantity`\n            The Hessian matrix of second derivatives of the potential. If the input\n            position has shape ``q.shape``, the output energy will have shape\n            ``(q.shape[0],q.shape[0]) + q.shape[1:]``. That is, an ``n_dim`` by\n            ``n_dim`` array (matrix) for each position.\n        \"\"\"\n        if (self.R is not None and\n                not np.allclose(np.diag(self.R), 1., atol=1e-15, rtol=0)):\n            raise NotImplementedError(\"Computing Hessian matrices for rotated \"\n                                      \"potentials is currently not supported.\")\n        q = self._remove_units_prepare_shape(q)\n        orig_shape,q = self._get_c_valid_arr(q)\n        t = self._validate_prepare_time(t, q)\n        ret_unit = 1 / self.units['time']**2\n        hess = np.moveaxis(self._hessian(q, t=t), 0, -1)\n        return hess.reshape((orig_shape[0], orig_shape[0]) + orig_shape[1:]) * ret_unit"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nestimates the mass enclosed within the given position by assuming the potential is spherical.", "response": "def mass_enclosed(self, q, t=0.):\n        \"\"\"\n        Estimate the mass enclosed within the given position by assuming the potential\n        is spherical.\n\n        Parameters\n        ----------\n        q : `~gala.dynamics.PhaseSpacePosition`, `~astropy.units.Quantity`, array_like\n            Position(s) to estimate the enclossed mass.\n\n        Returns\n        -------\n        menc : `~astropy.units.Quantity`\n            Mass enclosed at the given position(s). If the input position\n            has shape ``q.shape``, the output energy will have shape\n            ``q.shape[1:]``.\n        \"\"\"\n        q = self._remove_units_prepare_shape(q)\n        orig_shape, q = self._get_c_valid_arr(q)\n        t = self._validate_prepare_time(t, q)\n\n        # small step-size in direction of q\n        h = 1E-3 # MAGIC NUMBER\n\n        # Radius\n        r = np.sqrt(np.sum(q**2, axis=1))\n\n        epsilon = h*q/r[:, np.newaxis]\n\n        dPhi_dr_plus = self._energy(q + epsilon, t=t)\n        dPhi_dr_minus = self._energy(q - epsilon, t=t)\n        diff = (dPhi_dr_plus - dPhi_dr_minus)\n\n        if isinstance(self.units, DimensionlessUnitSystem):\n            Gee = 1.\n        else:\n            Gee = G.decompose(self.units).value\n\n        Menc = np.abs(r*r * diff / Gee / (2.*h))\n        Menc = Menc.reshape(orig_shape[1:])\n\n        sgn = 1.\n        if 'm' in self.parameters and self.parameters['m'] < 0:\n            sgn = -1.\n\n        return sgn * Menc * self.units['mass']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef circular_velocity(self, q, t=0.):\n        q = self._remove_units_prepare_shape(q)\n\n        # Radius\n        r = np.sqrt(np.sum(q**2, axis=0)) * self.units['length']\n        dPhi_dxyz = self.gradient(q, t=t)\n        dPhi_dr = np.sum(dPhi_dxyz * q/r.value, axis=0)\n\n        return self.units.decompose(np.sqrt(r * np.abs(dPhi_dr)))", "response": "Estimate the circular velocity at the given position assuming the potential is spherical."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_contours(self, grid, filled=True, ax=None, labels=None,\n                      subplots_kw=dict(), **kwargs):\n        \"\"\"\n        Plot equipotentials contours. Computes the potential energy on a grid\n        (specified by the array `grid`).\n\n        .. warning:: Right now the grid input must be arrays and must already\n            be in the unit system of the potential. Quantity support is coming...\n\n        Parameters\n        ----------\n        grid : tuple\n            Coordinate grids or slice value for each dimension. Should be a\n            tuple of 1D arrays or numbers.\n        filled : bool (optional)\n            Use :func:`~matplotlib.pyplot.contourf` instead of\n            :func:`~matplotlib.pyplot.contour`. Default is ``True``.\n        ax : matplotlib.Axes (optional)\n        labels : iterable (optional)\n            List of axis labels.\n        subplots_kw : dict\n            kwargs passed to matplotlib's subplots() function if an axes object\n            is not specified.\n        kwargs : dict\n            kwargs passed to either contourf() or plot().\n\n        Returns\n        -------\n        fig : `~matplotlib.Figure`\n\n        \"\"\"\n\n        import matplotlib.pyplot as plt\n        from matplotlib import cm\n\n        # figure out which elements are iterable, which are numeric\n        _grids = []\n        _slices = []\n        for ii, g in enumerate(grid):\n            if isiterable(g):\n                _grids.append((ii, g))\n            else:\n                _slices.append((ii, g))\n\n        # figure out the dimensionality\n        ndim = len(_grids)\n\n        # if ndim > 2, don't know how to handle this!\n        if ndim > 2:\n            raise ValueError(\"ndim > 2: you can only make contours on a 2D grid. For other \"\n                             \"dimensions, you have to specify values to slice.\")\n\n        if ax is None:\n            # default figsize\n            fig, ax = plt.subplots(1, 1, **subplots_kw)\n        else:\n            fig = ax.figure\n\n        if ndim == 1:\n            # 1D curve\n            x1 = _grids[0][1]\n            r = np.zeros((len(_grids) + len(_slices), len(x1)))\n            r[_grids[0][0]] = x1\n\n            for ii, slc in _slices:\n                r[ii] = slc\n\n            Z = self.energy(r*self.units['length']).value\n            ax.plot(x1, Z, **kwargs)\n\n            if labels is not None:\n                ax.set_xlabel(labels[0])\n                ax.set_ylabel(\"potential\")\n        else:\n            # 2D contours\n            x1, x2 = np.meshgrid(_grids[0][1], _grids[1][1])\n            shp = x1.shape\n            x1, x2 = x1.ravel(), x2.ravel()\n\n            r = np.zeros((len(_grids) + len(_slices), len(x1)))\n            r[_grids[0][0]] = x1\n            r[_grids[1][0]] = x2\n\n            for ii, slc in _slices:\n                r[ii] = slc\n\n            Z = self.energy(r*self.units['length']).value\n\n            # make default colormap not suck\n            cmap = kwargs.pop('cmap', cm.Blues)\n            if filled:\n                cs = ax.contourf(x1.reshape(shp), x2.reshape(shp), Z.reshape(shp),\n                                 cmap=cmap, **kwargs)\n            else:\n                cs = ax.contour(x1.reshape(shp), x2.reshape(shp), Z.reshape(shp),\n                                cmap=cmap, **kwargs)\n\n            if labels is not None:\n                ax.set_xlabel(labels[0])\n                ax.set_ylabel(labels[1])\n\n        return fig", "response": "Plots the potential energy on a grid of equipotentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_energy(self, x, v):\n        warnings.warn(\"Use the energy methods on Orbit objects instead. In a future \"\n                      \"release this will be removed.\", DeprecationWarning)\n\n        v = atleast_2d(v, insert_axis=1)\n        return self.energy(x) + 0.5*np.sum(v**2, axis=0)", "response": "Compute the total energy of a point in phase - space at a given position and velocity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new object with the same set of units replaced.", "response": "def replace_units(self, units, copy=True):\n        \"\"\"Change the unit system of this potential.\n\n        Parameters\n        ----------\n        units : `~gala.units.UnitSystem`\n            Set of non-reducable units that specify (at minimum) the\n            length, mass, time, and angle units.\n        copy : bool (optional)\n            If True, returns a copy, if False, changes this object.\n        \"\"\"\n        if copy:\n            pot = pycopy.deepcopy(self)\n        else:\n            pot = self\n\n        PotentialBase.__init__(pot,\n                               parameters=self.parameters,\n                               origin=self.origin,\n                               R=self.R,\n                               ndim=self.ndim,\n                               units=units)\n\n        return pot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_units(self, units, copy=True):\n        _lock = self.lock\n        if copy:\n            pots = self.__class__()\n        else:\n            pots = self\n\n        pots._units = None\n        pots.lock = False\n\n        for k, v in self.items():\n            pots[k] = v.replace_units(units, copy=copy)\n\n        pots.lock = _lock\n        return pots", "response": "Returns a new object with the given set of non - reducable units replaced."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that replaces the docstring of the object and formats it.", "response": "def format_doc(*args, **kwargs):\n    \"\"\"\n    Replaces the docstring of the decorated object and then formats it.\n\n    Modeled after astropy.utils.decorators.format_doc\n    \"\"\"\n    def set_docstring(obj):\n\n        # None means: use the objects __doc__\n        doc = obj.__doc__\n        # Delete documentation in this case so we don't end up with\n        # awkwardly self-inserted docs.\n        obj.__doc__ = None\n\n        # If the original has a not-empty docstring append it to the format\n        # kwargs.\n        kwargs['__doc__'] = obj.__doc__ or ''\n        obj.__doc__ = doc.format(*args, **kwargs)\n        return obj\n    return set_docstring"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quantity_from_hdf5(dset):\n    if 'unit' in dset.attrs and dset.attrs['unit'] is not None:\n        unit = u.Unit(dset.attrs['unit'])\n    else:\n        unit = 1.\n\n    return dset[:] * unit", "response": "Returns an Astropy Quantity object from a key in an HDF5 file group or dataset."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quantity_to_hdf5(f, key, q):\n\n    if hasattr(q, 'unit'):\n        f[key] = q.value\n        f[key].attrs['unit'] = str(q.unit)\n\n    else:\n        f[key] = q\n        f[key].attrs['unit'] = \"\"", "response": "Turn an Astropy Quantity object into something we can write out to\n    an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decompose(self, q):\n        try:\n            ptype = q.unit.physical_type\n        except AttributeError:\n            raise TypeError(\"Object must be an astropy.units.Quantity, not \"\n                            \"a '{}'.\".format(q.__class__.__name__))\n\n        if ptype in self._registry:\n            return q.to(self._registry[ptype])\n        else:\n            return q.decompose(self)", "response": "Decomposes a Quantity object into a new object of type u."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a constant with specified name in this unit system.", "response": "def get_constant(self, name):\n        \"\"\"\n        Retrieve a constant with specified name in this unit system.\n\n        Parameters\n        ----------\n        name : str\n            The name of the constant, e.g., G.\n\n        Returns\n        -------\n        const : float\n            The value of the constant represented in this unit system.\n\n        Examples\n        --------\n\n            >>> usys = UnitSystem(u.kpc, u.Myr, u.radian, u.Msun)\n            >>> usys.get_constant('c')\n            306.6013937879527\n\n        \"\"\"\n        try:\n            c = getattr(const, name)\n        except AttributeError:\n            raise ValueError(\"Constant name '{}' doesn't exist in astropy.constants\".format(name))\n\n        return c.decompose(self._core_units).value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef atleast_2d(*arys, **kwargs):\n    insert_axis = kwargs.pop('insert_axis', 0)\n    slc = [slice(None)]*2\n    slc[insert_axis] = None\n    slc = tuple(slc)\n\n    res = []\n    for ary in arys:\n        ary = np.asanyarray(ary)\n        if len(ary.shape) == 0:\n            result = ary.reshape(1, 1)\n        elif len(ary.shape) == 1:\n            result = ary[slc]\n        else:\n            result = ary\n        res.append(result)\n    if len(res) == 1:\n        return res[0]\n    else:\n        return res", "response": "View inputs as arrays with at least two dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlike numpy s assert_allclose but for angles.", "response": "def assert_angles_allclose(x, y, **kwargs):\n    \"\"\"\n    Like numpy's assert_allclose, but for angles (in radians).\n    \"\"\"\n    c2 = (np.sin(x)-np.sin(y))**2 + (np.cos(x)-np.cos(y))**2\n    diff = np.arccos((2.0 - c2)/2.0) # a = b = 1\n    assert np.allclose(diff, 0.0, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_v_theta(cls, v, theta):\n        theta = np.asarray(theta)\n        v = np.asarray(v)\n\n        s = np.sin(0.5 * theta)\n        c = np.cos(0.5 * theta)\n        vnrm = np.sqrt(np.sum(v * v))\n\n        q = np.concatenate([[c], s * v / vnrm])\n        return cls(q)", "response": "Create a quaternion from unit vector v and rotation angle theta."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the equivalent of the normalized quaternion.", "response": "def v_theta(self):\n        \"\"\"\n        Return the ``(v, theta)`` equivalent of the (normalized) quaternion.\n\n        Returns\n        -------\n        v : float\n        theta : float\n\n        \"\"\"\n        # compute theta\n        norm = np.sqrt(np.sum(self.wxyz**2))\n        theta = 2 * np.arccos(self.wxyz[0] / norm)\n\n        # compute the unit vector\n        v = np.array(self.wxyz[1:])\n        v = v / np.sqrt(np.sum(v**2))\n\n        return v, theta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the rotation matrix of the normalized quaternion.", "response": "def rotation_matrix(self):\n        \"\"\"\n        Compute the rotation matrix of the (normalized) quaternion.\n\n        Returns\n        -------\n        R : :class:`~numpy.ndarray`\n            A 3 by 3 rotation matrix (has shape ``(3,3)``).\n\n        \"\"\"\n        v, theta = self.v_theta\n        c = np.cos(theta)\n        s = np.sin(theta)\n\n        return np.array([[v[0] * v[0] * (1. - c) + c,\n                          v[0] * v[1] * (1. - c) - v[2] * s,\n                          v[0] * v[2] * (1. - c) + v[1] * s],\n                         [v[1] * v[0] * (1. - c) + v[2] * s,\n                          v[1] * v[1] * (1. - c) + c,\n                          v[1] * v[2] * (1. - c) - v[0] * s],\n                         [v[2] * v[0] * (1. - c) - v[1] * s,\n                          v[2] * v[1] * (1. - c) + v[0] * s,\n                          v[2] * v[2] * (1. - c) + c]])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random(cls):\n\n        s = np.random.uniform()\n        s1 = np.sqrt(1 - s)\n        s2 = np.sqrt(s)\n        t1 = np.random.uniform(0, 2*np.pi)\n        t2 = np.random.uniform(0, 2*np.pi)\n\n        w = np.cos(t2)*s2\n        x = np.sin(t1)*s1\n        y = np.cos(t1)*s1\n        z = np.sin(t2)*s2\n\n        return cls([w,x,y,z])", "response": "Randomly sample a Quaternion from a distribution uniform in\n        3D rotation angles."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step(self, t, x_im1, v_im1_2, dt):\n\n        x_i = x_im1 + v_im1_2 * dt\n        F_i = self.F(t, np.vstack((x_i, v_im1_2)), *self._func_args)\n        a_i = F_i[self.ndim:]\n\n        v_i = v_im1_2 + a_i * dt / 2\n        v_ip1_2 = v_i + a_i * dt / 2\n\n        return x_i, v_i, v_ip1_2", "response": "Step forward the positions and velocities by the given timestep."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the velocities of the current object.", "response": "def _init_v(self, t, w0, dt):\n        \"\"\"\n        Leapfrog updates the velocities offset a half-step from the\n        position updates. If we're given initial conditions aligned in\n        time, e.g. the positions and velocities at the same 0th step,\n        then we have to initially scoot the velocities forward by a half\n        step to prime the integrator.\n\n        Parameters\n        ----------\n        dt : numeric\n            The first timestep.\n        \"\"\"\n\n        # here is where we scoot the velocity at t=t1 to v(t+1/2)\n        F0 = self.F(t.copy(), w0.copy(), *self._func_args)\n        a0 = F0[self.ndim:]\n        v_1_2 = w0[self.ndim:] + a0*dt/2.\n\n        return v_1_2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_n_vectors(N_max, dx=1, dy=1, dz=1, half_lattice=True):\n    vecs = np.meshgrid(np.arange(-N_max, N_max+1, dx),\n                       np.arange(-N_max, N_max+1, dy),\n                       np.arange(-N_max, N_max+1, dz))\n    vecs = np.vstack(map(np.ravel, vecs)).T\n    vecs = vecs[np.linalg.norm(vecs, axis=1) <= N_max]\n\n    if half_lattice:\n        ix = ((vecs[:, 2] > 0) |\n              ((vecs[:, 2] == 0) &\n               (vecs[:, 1] > 0)) |\n              ((vecs[:, 2] == 0) &\n               (vecs[:, 1] == 0) &\n               (vecs[:, 0] > 0)))\n        vecs = vecs[ix]\n\n    vecs = np.array(sorted(vecs, key=lambda x: (x[0], x[1], x[2])))\n    return vecs", "response": "r Generate integer vectors with shape N_max where N_max is the maximum number of elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_isochrone(orbit, m0=2E11, b0=1., minimize_kwargs=None):\n    pot = orbit.hamiltonian.potential\n    if pot is None:\n        raise ValueError(\"The orbit object must have an associated potential\")\n\n    w = np.squeeze(orbit.w(pot.units))\n    if w.ndim > 2:\n        raise ValueError(\"Input orbit object must be a single orbit.\")\n\n    def f(p, w):\n        logm, logb = p\n        potential = IsochronePotential(m=np.exp(logm), b=np.exp(logb),\n                                       units=pot.units)\n        H = (potential.value(w[:3]).decompose(pot.units).value +\n             0.5*np.sum(w[3:]**2, axis=0))\n        return np.sum(np.squeeze(H - np.mean(H))**2)\n\n    logm0 = np.log(m0)\n    logb0 = np.log(b0)\n\n    if minimize_kwargs is None:\n        minimize_kwargs = dict()\n    minimize_kwargs['x0'] = np.array([logm0, logb0])\n    minimize_kwargs['method'] = minimize_kwargs.get('method', 'Nelder-Mead')\n    res = minimize(f, args=(w,), **minimize_kwargs)\n\n    if not res.success:\n        raise ValueError(\"Failed to fit toy potential to orbit.\")\n\n    logm, logb = np.abs(res.x)\n    m = np.exp(logm)\n    b = np.exp(logb)\n\n    return IsochronePotential(m=m, b=b, units=pot.units)", "response": "r Fit the toy Isochrone potential to the sum of the energy residuals relative to the mean energy of the core radius of the Isochrone potential."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_harmonic_oscillator(orbit, omega0=[1., 1, 1], minimize_kwargs=None):\n    omega0 = np.atleast_1d(omega0)\n\n    pot = orbit.hamiltonian.potential\n    if pot is None:\n        raise ValueError(\"The orbit object must have an associated potential\")\n\n    w = np.squeeze(orbit.w(pot.units))\n    if w.ndim > 2:\n        raise ValueError(\"Input orbit object must be a single orbit.\")\n\n    def f(omega, w):\n        potential = HarmonicOscillatorPotential(omega=omega, units=pot.units)\n        H = (potential.value(w[:3]).decompose(pot.units).value +\n             0.5*np.sum(w[3:]**2, axis=0))\n        return np.sum(np.squeeze(H - np.mean(H))**2)\n\n    if minimize_kwargs is None:\n        minimize_kwargs = dict()\n    minimize_kwargs['x0'] = omega0\n    minimize_kwargs['method'] = minimize_kwargs.get('method', 'Nelder-Mead')\n    res = minimize(f, args=(w,), **minimize_kwargs)\n\n    if not res.success:\n        raise ValueError(\"Failed to fit toy potential to orbit.\")\n\n    best_omega = np.abs(res.x)\n    return HarmonicOscillatorPotential(omega=best_omega, units=pot.units)", "response": "r Fit the toy harmonic oscillator potential to the sum of the energy of the mean energy of the harmonic oscillator."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits a best fitting toy potential to the orbit provided.", "response": "def fit_toy_potential(orbit, force_harmonic_oscillator=False):\n    \"\"\"\n    Fit a best fitting toy potential to the orbit provided. If the orbit is a\n    tube (loop) orbit, use the Isochrone potential. If the orbit is a box\n    potential, use the harmonic oscillator potential. An option is available to\n    force using the harmonic oscillator (`force_harmonic_oscillator`).\n\n    See the docstrings for ~`gala.dynamics.fit_isochrone()` and\n    ~`gala.dynamics.fit_harmonic_oscillator()` for more information.\n\n    Parameters\n    ----------\n    orbit : `~gala.dynamics.Orbit`\n    force_harmonic_oscillator : bool (optional)\n        Force using the harmonic oscillator potential as the toy potential.\n\n    Returns\n    -------\n    potential : :class:`~gala.potential.IsochronePotential` or :class:`~gala.potential.HarmonicOscillatorPotential`\n        The best-fit potential object.\n\n    \"\"\"\n    circulation = orbit.circulation()\n    if np.any(circulation == 1) and not force_harmonic_oscillator:  # tube orbit\n        logger.debug(\"===== Tube orbit =====\")\n        logger.debug(\"Using Isochrone toy potential\")\n\n        toy_potential = fit_isochrone(orbit)\n        logger.debug(\"Best m={}, b={}\".format(toy_potential.parameters['m'],\n                                              toy_potential.parameters['b']))\n\n    else:  # box orbit\n        logger.debug(\"===== Box orbit =====\")\n        logger.debug(\"Using triaxial harmonic oscillator toy potential\")\n\n        toy_potential = fit_harmonic_oscillator(orbit)\n        logger.debug(\"Best omegas ({})\"\n                     .format(toy_potential.parameters['omega']))\n\n    return toy_potential"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_angle_sampling(nvecs, angles):\n\n    failed_nvecs = []\n    failures = []\n\n    for i, vec in enumerate(nvecs):\n        # N = np.linalg.norm(vec)\n        # X = np.dot(angles,vec)\n        X = (angles*vec[:, None]).sum(axis=0)\n        diff = float(np.abs(X.max() - X.min()))\n\n        if diff < (2.*np.pi):\n            warnings.warn(\"Need a longer integration window for mode {0}\"\n                          .format(vec))\n            failed_nvecs.append(vec.tolist())\n            # P.append(2.*np.pi - diff)\n            failures.append(0)\n\n        elif (diff/len(X)) > np.pi:\n            warnings.warn(\"Need a finer sampling for mode {0}\"\n                          .format(str(vec)))\n            failed_nvecs.append(vec.tolist())\n            # P.append(np.pi - diff/len(X))\n            failures.append(1)\n\n    return np.array(failed_nvecs), np.array(failures)", "response": "Check if the toy angles of the n - dimensional array of n is adequate."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _action_prepare(aa, N_max, dx, dy, dz, sign=1., throw_out_modes=False):\n\n    # unroll the angles so they increase continuously instead of wrap\n    angles = np.unwrap(aa[3:])\n\n    # generate integer vectors for fourier modes\n    nvecs = generate_n_vectors(N_max, dx, dy, dz)\n\n    # make sure we have enough angle coverage\n    modes, P = check_angle_sampling(nvecs, angles)\n\n    # throw out modes?\n    # if throw_out_modes:\n    #     nvecs = np.delete(nvecs, (modes,P), axis=0)\n\n    n = len(nvecs) + 3\n    b = np.zeros(shape=(n, ))\n    A = np.zeros(shape=(n, n))\n\n    # top left block matrix: identity matrix summed over timesteps\n    A[:3, :3] = aa.shape[1]*np.identity(3)\n\n    actions = aa[:3]\n    angles = aa[3:]\n\n    # top right block matrix: transpose of C_nk matrix (Eq. 12)\n    C_T = 2.*nvecs.T * np.sum(np.cos(np.dot(nvecs, angles)), axis=-1)\n    A[:3,3:] = C_T\n    A[3:, :3] = C_T.T\n\n    # lower right block matrix: C_nk dotted with C_nk^T\n    cosv = np.cos(np.dot(nvecs, angles))\n    A[3:,3:] = 4.*np.dot(nvecs, nvecs.T)*np.einsum('it,jt->ij', cosv, cosv)\n\n    # b vector first three is just sum of toy actions\n    b[:3] = np.sum(actions, axis=1)\n\n    # rest of the vector is C dotted with actions\n    b[3:] = 2*np.sum(np.dot(nvecs, actions)*np.cos(np.dot(nvecs, angles)),\n                     axis=1)\n\n    return A, b, nvecs", "response": "Prepare a new toy action list for use in the next stage of the next stage of the next stage of the next stage of the next stage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _angle_prepare(aa, t, N_max, dx, dy, dz, sign=1.):\n\n    # unroll the angles so they increase continuously instead of wrap\n    angles = np.unwrap(aa[3:])\n\n    # generate integer vectors for fourier modes\n    nvecs = generate_n_vectors(N_max, dx, dy, dz)\n\n    # make sure we have enough angle coverage\n    modes, P = check_angle_sampling(nvecs, angles)\n\n    # TODO: throw out modes?\n    # if(throw_out_modes):\n    #     n_vectors = np.delete(n_vectors,check_each_direction(n_vectors,angs),axis=0)\n\n    nv = len(nvecs)\n    n = 3 + 3 + 3*nv # angle(0)'s, freqs, 3 derivatives of Sn\n\n    b = np.zeros(shape=(n,))\n    A = np.zeros(shape=(n, n))\n\n    # top left block matrix: identity matrix summed over timesteps\n    A[:3, :3] = aa.shape[1]*np.identity(3)\n\n    # identity matrices summed over times\n    A[:3, 3:6] = A[3:6, :3] = np.sum(t)*np.identity(3)\n    A[3:6, 3:6] = np.sum(t*t)*np.identity(3)\n\n    # S1,2,3\n    A[6:6+nv, 0] = -2.*np.sum(np.sin(np.dot(nvecs, angles)), axis=1)\n    A[6+nv:6+2*nv, 1] = A[6:6+nv, 0]\n    A[6+2*nv:6+3*nv, 2] = A[6:6+nv, 0]\n\n    # t*S1,2,3\n    A[6:6+nv, 3] = -2.*np.sum(t[None, :]*np.sin(np.dot(nvecs, angles)),\n                              axis=1)\n    A[6+nv:6+2*nv, 4] = A[6:6+nv, 3]\n    A[6+2*nv:6+3*nv, 5] = A[6:6+nv, 3]\n\n    # lower right block structure: S dot S^T\n    sinv = np.sin(np.dot(nvecs, angles))\n    SdotST = np.einsum('it,jt->ij', sinv, sinv)\n    A[6:6+nv, 6:6+nv] = A[6+nv:6+2*nv, 6+nv:6+2*nv] = \\\n        A[6+2*nv:6+3*nv, 6+2*nv:6+3*nv] = 4*SdotST\n\n    # top rectangle\n    A[:6, :] = A[:, :6].T\n\n    b[:3] = np.sum(angles.T, axis=0)\n    b[3:6] = np.sum(t[:, None]*angles.T, axis=0)\n    b[6:6+nv] = -2.*np.sum(angles[0]*np.sin(np.dot(nvecs, angles)), axis=1)\n    b[6+nv:6+2*nv] = -2.*np.sum(angles[1]*np.sin(np.dot(nvecs, angles)),\n                                axis=1)\n    b[6+2*nv:6+3*nv] = -2.*np.sum(angles[2]*np.sin(np.dot(nvecs, angles)),\n                                  axis=1)\n\n    return A, b, nvecs", "response": "This function takes a list of toy actions and angles and returns the matrix A and vector b to solve for the vector of true angles frequencies and derivatives x."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _single_orbit_find_actions(orbit, N_max, toy_potential=None,\n                               force_harmonic_oscillator=False):\n    \"\"\"\n    Find approximate actions and angles for samples of a phase-space orbit,\n    `w`, at times `t`. Uses toy potentials with known, analytic action-angle\n    transformations to approximate the true coordinates as a Fourier sum.\n\n    This code is adapted from Jason Sanders'\n    `genfunc <https://github.com/jlsanders/genfunc>`_\n\n    .. todo::\n\n        Wrong shape for w -- should be (6,n) as usual...\n\n    Parameters\n    ----------\n    orbit : `~gala.dynamics.Orbit`\n    N_max : int\n        Maximum integer Fourier mode vector length, |n|.\n    toy_potential : Potential (optional)\n        Fix the toy potential class.\n    force_harmonic_oscillator : bool (optional)\n        Force using the harmonic oscillator potential as the toy potential.\n    \"\"\"\n\n    if orbit.norbits > 1:\n        raise ValueError(\"must be a single orbit\")\n\n    if toy_potential is None:\n        toy_potential = fit_toy_potential(\n            orbit, force_harmonic_oscillator=force_harmonic_oscillator)\n\n    else:\n        logger.debug(\"Using *fixed* toy potential: {}\"\n                     .format(toy_potential.parameters))\n\n    if isinstance(toy_potential, IsochronePotential):\n        orbit_align = orbit.align_circulation_with_z()\n        w = orbit_align.w()\n\n        dxyz = (1, 2, 2)\n        circ = np.sign(w[0, 0]*w[4, 0]-w[1, 0]*w[3, 0])\n        sign = np.array([1., circ, 1.])\n        orbit = orbit_align\n    elif isinstance(toy_potential, HarmonicOscillatorPotential):\n        dxyz = (2, 2, 2)\n        sign = 1.\n        w = orbit.w()\n    else:\n        raise ValueError(\"Invalid toy potential.\")\n\n    t = orbit.t.value\n\n    # Now find toy actions and angles\n    aaf = toy_potential.action_angle(orbit)\n\n    if aaf[0].ndim > 2:\n        aa = np.vstack((aaf[0].value[..., 0], aaf[1].value[..., 0]))\n    else:\n        aa = np.vstack((aaf[0].value, aaf[1].value))\n\n    if np.any(np.isnan(aa)):\n        ix = ~np.any(np.isnan(aa), axis=0)\n        aa = aa[:, ix]\n        t = t[ix]\n        warnings.warn(\"NaN value in toy actions or angles!\")\n        if sum(ix) > 1:\n            raise ValueError(\"Too many NaN value in toy actions or angles!\")\n\n    t1 = time.time()\n    A, b, nvecs = _action_prepare(aa, N_max, dx=dxyz[0], dy=dxyz[1], dz=dxyz[2])\n    actions = np.array(solve(A,b))\n    logger.debug(\"Action solution found for N_max={}, size {} symmetric\"\n                 \" matrix in {} seconds\"\n                 .format(N_max, len(actions), time.time()-t1))\n\n    t1 = time.time()\n    A, b, nvecs = _angle_prepare(aa, t, N_max, dx=dxyz[0],\n                                 dy=dxyz[1], dz=dxyz[2], sign=sign)\n    angles = np.array(solve(A, b))\n    logger.debug(\"Angle solution found for N_max={}, size {} symmetric\"\n                 \" matrix in {} seconds\"\n                 .format(N_max, len(angles), time.time()-t1))\n\n    # Just some checks\n    if len(angles) > len(aa):\n        warnings.warn(\"More unknowns than equations!\")\n\n    J = actions[:3]  # * sign\n    theta = angles[:3]\n    freqs = angles[3:6]  # * sign\n\n    return dict(actions=J*aaf[0].unit, angles=theta*aaf[1].unit,\n                freqs=freqs*aaf[2].unit,\n                Sn=actions[3:], dSn_dJ=angles[6:], nvecs=nvecs)", "response": "Find approximate actions and angles for samples of a single phase - space orbit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_time_specification(units, dt=None, n_steps=None, nsteps=None, t1=None, t2=None, t=None):\n    if nsteps is not None:\n        warn(\"The argument 'nsteps' is deprecated and will be removed in a future version.\"\n             \"Use 'n_steps' instead.\")\n        n_steps = nsteps\n\n    if n_steps is not None: # parse and validate n_steps\n        n_steps = int(n_steps)\n\n    if hasattr(dt, 'unit'):\n        dt = dt.decompose(units).value\n\n    if hasattr(t1, 'unit'):\n        t1 = t1.decompose(units).value\n\n    if hasattr(t2, 'unit'):\n        t2 = t2.decompose(units).value\n\n    if hasattr(t, 'unit'):\n        t = t.decompose(units).value\n\n    # t : array_like\n    if t is not None:\n        times = t\n        return times\n\n    else:\n        if dt is None and (t1 is None or t2 is None or n_steps is None):\n            raise ValueError(\"Invalid spec. See docstring.\")\n\n        # dt, n_steps[, t1] : (numeric, int[, numeric])\n        elif dt is not None and n_steps is not None:\n            if t1 is None:\n                t1 = 0.\n\n            times = parse_time_specification(units, dt=np.ones(n_steps+1)*dt, t1=t1)\n        # dt, t1, t2 : (numeric, numeric, numeric)\n        elif dt is not None and t1 is not None and t2 is not None:\n            if t2 < t1 and dt < 0:\n\n                t_i = t1\n                times = []\n                ii = 0\n                while (t_i > t2) and (ii < 1E6):\n                    times.append(t_i)\n                    t_i += dt\n\n                if times[-1] != t2:\n                    times.append(t2)\n\n                return np.array(times)\n\n            elif t2 > t1 and dt > 0:\n\n                t_i = t1\n                times = []\n                ii = 0\n                while (t_i < t2) and (ii < 1E6):\n                    times.append(t_i)\n                    t_i += dt\n\n                return np.array(times)\n\n            else:\n                raise ValueError(\"If t2 < t1, dt must be negative. If t1 < t2, \"\n                                 \"dt should be positive.\")\n\n        # dt, t1 : (array_like, numeric)\n        elif isinstance(dt, np.ndarray) and t1 is not None:\n            times = np.cumsum(np.append([0.], dt)) + t1\n            times = times[:-1]\n\n        # n_steps, t1, t2 : (int, numeric, numeric)\n        elif dt is None and not (t1 is None or t2 is None or n_steps is None):\n            times = np.linspace(t1, t2, n_steps, endpoint=True)\n\n        else:\n            raise ValueError(\"Invalid options. See docstring.\")\n\n        return times", "response": "Parse a time specification into a sequence of times."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates angle and action variable in sho potential with parameter omega", "response": "def angact_ho(x,omega):\n    \"\"\" Calculate angle and action variable in sho potential with\n    parameter omega \"\"\"\n    action = (x[3:]**2+(omega*x[:3])**2)/(2.*omega)\n    angle = np.array([np.arctan(-x[3+i]/omega[i]/x[i]) if x[i]!=0. else -np.sign(x[3+i])*np.pi/2. for i in range(3)])\n    for i in range(3):\n        if(x[i]<0):\n            angle[i]+=np.pi\n    return np.concatenate((action,angle % (2.*np.pi)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findbestparams_ho(xsamples):\n    return np.abs(leastsq(deltaH_ho,np.array([10.,10.,10.]), Dfun = Jac_deltaH_ho, args=(xsamples,))[0])[:3]", "response": "Minimize sum of square differences of H_sho - <H_sho for timesamples"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform coordinate transformation from cartesian to spherical polar coordinates with ( r phi theta ) having usual meanings.", "response": "def cart2spol(X):\n    \"\"\" Performs coordinate transformation from cartesian\n    to spherical polar coordinates with (r,phi,theta) having\n    usual meanings. \"\"\"\n    x,y,z,vx,vy,vz=X\n    r=np.sqrt(x*x+y*y+z*z)\n    p=np.arctan2(y,x)\n    t=np.arccos(z/r)\n    vr=(vx*np.cos(p)+vy*np.sin(p))*np.sin(t)+np.cos(t)*vz\n    vp=-vx*np.sin(p)+vy*np.cos(p)\n    vt=(vx*np.cos(p)+vy*np.sin(p))*np.cos(t)-np.sin(t)*vz\n    return np.array([r,p,t,vr,vp,vt])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef H_iso(x,params):\n    #r = (np.sqrt(np.sum(x[:3]**2))-params[2])**2\n    r = np.sum(x[:3]**2)\n    return 0.5*np.sum(x[3:]**2)-Grav*params[0]/(params[1]+np.sqrt(params[1]**2+r))", "response": "Isochrone Hamiltonian = -GM/(b+sqrt(b**2+(r-r0)**2))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the angle and action variable in isochrone potential with the given parameters.", "response": "def angact_iso(x,params):\n    \"\"\" Calculate angle and action variable in isochrone potential with\n    parameters params = (M,b) \"\"\"\n    GM = Grav*params[0]\n    E = H_iso(x,params)\n    r,p,t,vr,vphi,vt=cart2spol(x)\n    st=np.sin(t)\n    Lz=r*vphi*st\n    L=np.sqrt(r*r*vt*vt+Lz*Lz/st/st)\n    if(E>0.):  # Unbound\n        return (np.nan,np.nan,np.nan,np.nan,np.nan,np.nan)\n    Jr=GM/np.sqrt(-2*E)-0.5*(L+np.sqrt(L*L+4*GM*params[1]))\n    action = np.array([Jr,Lz,L-abs(Lz)])\n\n    c=GM/(-2*E)-params[1]\n    e=np.sqrt(1-L*L*(1+params[1]/c)/GM/c)\n    eta=np.arctan2(r*vr/np.sqrt(-2.*E),params[1]+c-np.sqrt(params[1]**2+r*r))\n    OmR=np.power(-2*E,1.5)/GM\n    Omp=0.5*OmR*(1+L/np.sqrt(L*L+4*GM*params[1]))\n    thetar=eta-e*c*np.sin(eta)/(c+params[1])\n\n    if(abs(vt)>1e-10):\n        psi=np.arctan2(np.cos(t),-np.sin(t)*r*vt/L)\n    else:\n        psi=np.pi/2.\n    a=np.sqrt((1+e)/(1-e))\n    ap=np.sqrt((1+e+2*params[1]/c)/(1-e+2*params[1]/c))\n    F = lambda x,y: np.pi/2.-np.arctan(np.tan(np.pi/2.-0.5*y)/x) if y>np.pi/2. \\\n        else -np.pi/2.+np.arctan(np.tan(np.pi/2.+0.5*y)/x) if y<-np.pi/2. \\\n        else np.arctan(x*np.tan(0.5*y))\n\n    thetaz=psi+Omp*thetar/OmR-F(a,eta)-F(ap,eta)/np.sqrt(1+4*GM*params[1]/L/L)\n\n    LR=Lz/L\n    sinu = LR/np.sqrt(1.-LR**2)/np.tan(t)\n    u = 0\n    if(sinu>1.):\n        u=np.pi/2.\n    elif(sinu<-1.):\n        u = -np.pi/2.\n    else:\n        u = np.arcsin(sinu)\n    if(vt>0.):\n        u=np.pi-u\n    thetap=p-u+np.sign(Lz)*thetaz\n    angle = np.array([thetar,thetap,thetaz])\n    return np.concatenate((action,angle % (2.*np.pi)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nminimize sum of square differences of H_iso - <H_iso > for timesamples", "response": "def findbestparams_iso(xsamples):\n    \"\"\" Minimize sum of square differences of H_iso-<H_iso> for timesamples\"\"\"\n    p = 0.5*np.sum(xsamples.T[3:]**2,axis=0)\n    r = np.sum(xsamples.T[:3]**2,axis=0)\n    return np.abs(leastsq(deltaH_iso,np.array([10.,10.]), Dfun = None , col_deriv=1,args=(p,r,))[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef peak_to_peak_period(t, f, amplitude_threshold=1E-2):\n    if hasattr(t, 'unit'):\n        t_unit = t.unit\n        t = t.value\n    else:\n        t_unit = u.dimensionless_unscaled\n\n    # find peaks\n    max_ix = argrelmax(f, mode='wrap')[0]\n    max_ix = max_ix[(max_ix != 0) & (max_ix != (len(f)-1))]\n\n    # find troughs\n    min_ix = argrelmin(f, mode='wrap')[0]\n    min_ix = min_ix[(min_ix != 0) & (min_ix != (len(f)-1))]\n\n    # neglect minor oscillations\n    if abs(np.mean(f[max_ix]) - np.mean(f[min_ix])) < amplitude_threshold:\n        return np.nan\n\n    # compute mean peak-to-peak\n    if len(max_ix) > 0:\n        T_max = np.mean(t[max_ix[1:]] - t[max_ix[:-1]])\n    else:\n        T_max = np.nan\n\n    # now compute mean trough-to-trough\n    if len(min_ix) > 0:\n        T_min = np.mean(t[min_ix[1:]] - t[min_ix[:-1]])\n    else:\n        T_min = np.nan\n\n    # then take the mean of these two\n    return np.mean([T_max, T_min]) * t_unit", "response": "Estimate the peak - to - peak period of the input time series by measuring the average peak - to - peak time."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef estimate_dt_n_steps(w0, hamiltonian, n_periods, n_steps_per_period,\n                        dE_threshold=1E-9, func=np.nanmax,\n                        **integrate_kwargs):\n    \"\"\"\n    Estimate the timestep and number of steps to integrate an orbit for\n    given its initial conditions and a potential object.\n\n    Parameters\n    ----------\n    w0 : `~gala.dynamics.PhaseSpacePosition`, array_like\n        Initial conditions.\n    potential : :class:`~gala.potential.PotentialBase`\n        The potential to integrate the orbit in.\n    n_periods : int\n        Number of (max) orbital periods to integrate for.\n    n_steps_per_period : int\n        Number of steps to take per (max) orbital period.\n    dE_threshold : numeric (optional)\n        Maximum fractional energy difference -- used to determine initial\n        timestep. Set to ``None`` to ignore this.\n    func : callable (optional)\n        Determines which period to use. By default, this takes the maximum\n        period using :func:`~numpy.nanmax`. Other options could be\n        :func:`~numpy.nanmin`, :func:`~numpy.nanmean`, :func:`~numpy.nanmedian`.\n\n    Returns\n    -------\n    dt : float\n        The timestep.\n    n_steps : int\n        The number of timesteps to integrate for.\n\n    \"\"\"\n    if not isinstance(w0, PhaseSpacePosition):\n        w0 = np.asarray(w0)\n        w0 = PhaseSpacePosition.from_w(w0, units=hamiltonian.units)\n\n    # integrate orbit\n    dt = _autodetermine_initial_dt(w0, hamiltonian, dE_threshold=dE_threshold,\n                                   **integrate_kwargs)\n    n_steps = int(round(10000 / dt))\n    orbit = hamiltonian.integrate_orbit(w0, dt=dt, n_steps=n_steps,\n                                        **integrate_kwargs)\n\n    # if loop, align circulation with Z and take R period\n    circ = orbit.circulation()\n    if np.any(circ):\n        orbit = orbit.align_circulation_with_z(circulation=circ)\n        cyl = orbit.represent_as(coord.CylindricalRepresentation)\n\n        # convert to cylindrical coordinates\n        R = cyl.rho.value\n        phi = cyl.phi.value\n        z = cyl.z.value\n\n        T = np.array([peak_to_peak_period(orbit.t, f).value\n                      for f in [R, phi, z]])*orbit.t.unit\n\n    else:\n        T = np.array([peak_to_peak_period(orbit.t, f).value\n                      for f in orbit.pos])*orbit.t.unit\n\n    # timestep from number of steps per period\n    T = func(T)\n\n    if np.isnan(T):\n        raise RuntimeError(\"Failed to find period.\")\n\n    T = T.decompose(hamiltonian.units).value\n    dt = T / float(n_steps_per_period)\n    n_steps = int(round(n_periods * T / dt))\n\n    if dt == 0. or dt < 1E-13:\n        raise ValueError(\"Timestep is zero or very small!\")\n\n    return dt, n_steps", "response": "Estimate the timestep and number of steps to integrate an orbit for a given set of initial conditions and a potential object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncombining the specified objects into a single orbit or phase space position or orbit.", "response": "def combine(objs):\n    \"\"\"Combine the specified `~gala.dynamics.PhaseSpacePosition` or\n    `~gala.dynamics.Orbit` objects.\n\n    Parameters\n    ----------\n    objs : iterable\n        An iterable of either `~gala.dynamics.PhaseSpacePosition` or\n        `~gala.dynamics.Orbit` objects.\n    \"\"\"\n    from .orbit import Orbit\n\n    # have to special-case this because they are iterable\n    if isinstance(objs, PhaseSpacePosition) or isinstance(objs, Orbit):\n        raise ValueError(\"You must pass a non-empty iterable to combine.\")\n\n    elif not isiterable(objs) or len(objs) < 1:\n        raise ValueError(\"You must pass a non-empty iterable to combine.\")\n\n    elif len(objs) == 1: # short circuit\n        return objs[0]\n\n    # We only support these two types to combine:\n    if objs[0].__class__ not in [PhaseSpacePosition, Orbit]:\n        raise TypeError(\"Objects must be either PhaseSpacePosition or Orbit \"\n                        \"instances.\")\n\n    # Validate objects:\n    # - check type\n    # - check dimensionality\n    # - check frame, potential\n    # - Right now, we only support Cartesian\n    for obj in objs:\n        # Check to see if they are all the same type of object:\n        if obj.__class__ != objs[0].__class__:\n            raise TypeError(\"All objects must have the same type.\")\n\n        # Make sure they have same dimensionality\n        if obj.ndim != objs[0].ndim:\n            raise ValueError(\"All objects must have the same ndim.\")\n\n        # Check that all objects have the same reference frame\n        if obj.frame != objs[0].frame:\n            raise ValueError(\"All objects must have the same frame.\")\n\n        # Check that (for orbits) they all have the same potential\n        if hasattr(obj, 'potential') and obj.potential != objs[0].potential:\n            raise ValueError(\"All objects must have the same potential.\")\n\n        # For orbits, time arrays must be the same\n        if (hasattr(obj, 't') and obj.t is not None and objs[0].t is not None\n                and not quantity_allclose(obj.t, objs[0].t,\n                                          atol=1E-13*objs[0].t.unit)):\n            raise ValueError(\"All orbits must have the same time array.\")\n\n        if 'cartesian' not in obj.pos.get_name():\n            raise NotImplementedError(\"Currently, combine only works for \"\n                                      \"Cartesian-represented objects.\")\n\n    # Now we prepare the positions, velocities:\n    if objs[0].__class__ == PhaseSpacePosition:\n        pos = []\n        vel = []\n\n        for i, obj in enumerate(objs):\n            if i == 0:\n                pos_unit = obj.pos.xyz.unit\n                vel_unit = obj.vel.d_xyz.unit\n\n            pos.append(atleast_2d(obj.pos.xyz.to(pos_unit).value,\n                                  insert_axis=1))\n            vel.append(atleast_2d(obj.vel.d_xyz.to(vel_unit).value,\n                                  insert_axis=1))\n\n        pos = np.concatenate(pos, axis=1) * pos_unit\n        vel = np.concatenate(vel, axis=1) * vel_unit\n\n        return PhaseSpacePosition(pos=pos, vel=vel, frame=objs[0].frame)\n\n    elif objs[0].__class__ == Orbit:\n        pos = []\n        vel = []\n\n        for i, obj in enumerate(objs):\n            if i == 0:\n                pos_unit = obj.pos.xyz.unit\n                vel_unit = obj.vel.d_xyz.unit\n\n            p = obj.pos.xyz.to(pos_unit).value\n            v = obj.vel.d_xyz.to(vel_unit).value\n\n            if p.ndim < 3:\n                p = p.reshape(p.shape + (1,))\n                v = v.reshape(v.shape + (1,))\n\n            pos.append(p)\n            vel.append(v)\n\n        pos = np.concatenate(pos, axis=2) * pos_unit\n        vel = np.concatenate(vel, axis=2) * vel_unit\n\n        return Orbit(pos=pos, vel=vel,\n                     t=objs[0].t, frame=objs[0].frame,\n                     potential=objs[0].potential)\n\n    else:\n        raise RuntimeError(\"should never get here...\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reflex_correct(coords, galactocentric_frame=None):\n    c = coord.SkyCoord(coords)\n\n    # If not specified, use the Astropy default Galactocentric frame\n    if galactocentric_frame is None:\n        galactocentric_frame = coord.Galactocentric()\n\n    v_sun = galactocentric_frame.galcen_v_sun\n\n    observed = c.transform_to(galactocentric_frame)\n    rep = observed.cartesian.without_differentials()\n    rep = rep.with_differentials(observed.cartesian.differentials['s'] + v_sun)\n    fr = galactocentric_frame.realize_frame(rep).transform_to(c.frame)\n    return coord.SkyCoord(fr)", "response": "Correct the input Astropy coordinate object for solar reflex motion."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn matplotlib axes for the base orbit.", "response": "def _get_axes(dim, subplots_kwargs=dict()):\n    \"\"\"\n    Parameters\n    ----------\n    dim : int\n        Dimensionality of the orbit.\n    subplots_kwargs : dict (optional)\n        Dictionary of kwargs passed to :func:`~matplotlib.pyplot.subplots`.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n\n    if dim > 1:\n        n_panels = int(dim * (dim - 1) / 2)\n    else:\n        n_panels = 1\n    figsize = subplots_kwargs.pop('figsize', (4*n_panels, 4))\n    fig, axes = plt.subplots(1, n_panels, figsize=figsize,\n                             **subplots_kwargs)\n\n    if n_panels == 1:\n        axes = [axes]\n\n    else:\n        axes = axes.flat\n\n    return axes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the projections of the given N - dimensional quantity x on the axes and axes.", "response": "def plot_projections(x, relative_to=None, autolim=True, axes=None,\n                     subplots_kwargs=dict(), labels=None, plot_function=None,\n                     **kwargs):\n    \"\"\"\n    Given N-dimensional quantity, ``x``, make a figure containing 2D projections\n    of all combinations of the axes.\n\n    Parameters\n    ----------\n    x : array_like\n        Array of values. ``axis=0`` is assumed to be the dimensionality,\n        ``axis=1`` is the time axis. See :ref:`shape-conventions` for more\n        information.\n    relative_to : bool (optional)\n        Plot the values relative to this value or values.\n    autolim : bool (optional)\n        Automatically set the plot limits to be something sensible.\n    axes : array_like (optional)\n        Array of matplotlib Axes objects.\n    subplots_kwargs : dict (optional)\n        Dictionary of kwargs passed to :func:`~matplotlib.pyplot.subplots`.\n    labels : iterable (optional)\n        List or iterable of axis labels as strings. They should correspond to\n        the dimensions of the input orbit.\n    plot_function : callable (optional)\n        The ``matplotlib`` plot function to use. By default, this is\n        :func:`~matplotlib.pyplot.scatter`, but can also be, e.g.,\n        :func:`~matplotlib.pyplot.plot`.\n    **kwargs\n        All other keyword arguments are passed to the ``plot_function``.\n        You can pass in any of the usual style kwargs like ``color=...``,\n        ``marker=...``, etc.\n\n    Returns\n    -------\n    fig : `~matplotlib.Figure`\n\n    \"\"\"\n\n    # don't propagate changes back...\n    x = np.array(x, copy=True)\n    ndim = x.shape[0]\n\n    # get axes object from arguments\n    if axes is None:\n        axes = _get_axes(dim=ndim, subplots_kwargs=subplots_kwargs)\n\n    # if the quantities are relative\n    if relative_to is not None:\n        x -= relative_to\n\n    # name of the plotting function\n    plot_fn_name = plot_function.__name__\n\n    # automatically determine limits\n    if autolim:\n        lims = []\n        for i in range(ndim):\n            max_,min_ = np.max(x[i]), np.min(x[i])\n            delta = max_ - min_\n\n            if delta == 0.:\n                delta = 1.\n\n            lims.append([min_ - delta*0.02, max_ + delta*0.02])\n\n    k = 0\n    for i in range(ndim):\n        for j in range(ndim):\n            if i >= j:\n                continue # skip diagonal, upper triangle\n\n            plot_func = getattr(axes[k], plot_fn_name)\n            plot_func(x[i], x[j], **kwargs)\n\n            if labels is not None:\n                axes[k].set_xlabel(labels[i])\n                axes[k].set_ylabel(labels[j])\n\n            if autolim:\n                axes[k].set_xlim(lims[i])\n                axes[k].set_ylim(lims[j])\n\n            k += 1\n\n    axes[0].figure.tight_layout()\n    return axes[0].figure"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the toy angle solution against the toy angles", "response": "def check_angle_solution(ang,n_vec,toy_aa,timeseries):\n    \"\"\" Plots the toy angle solution against the toy angles ---\n        Takes true angles and frequencies ang,\n        the Fourier vectors n_vec,\n        the toy action-angles toy_aa\n        and the timeseries \"\"\"\n    f,a=plt.subplots(3,1)\n    for i in range(3):\n        a[i].plot(toy_aa.T[i+3],'.')\n        size = len(ang[6:])/3\n        AA = np.array([np.sum(ang[6+i*size:6+(i+1)*size]*np.sin(np.sum(n_vec*K,axis=1))) for K in toy_aa.T[3:].T])\n        a[i].plot((ang[i]+ang[i+3]*timeseries-2.*AA) % (2.*np.pi),'.')\n        a[i].set_ylabel(r'$\\theta$'+str(i+1))\n    a[2].set_xlabel(r'$t$')\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates the mean error functions for the current toy class.", "response": "def eval_mean_error_functions(act,ang,n_vec,toy_aa,timeseries,withplot=False):\n    \"\"\" Calculates sqrt(mean(E)) and sqrt(mean(F)) \"\"\"\n\n    Err = np.zeros(6)\n    NT = len(timeseries)\n    size = len(ang[6:])/3\n    UA = ua(toy_aa.T[3:].T,np.ones(3))\n    fig,axis=None,None\n    if(withplot):\n        fig,axis=plt.subplots(3,2)\n        plt.subplots_adjust(wspace=0.3)\n    for K in range(3):\n        ErrJ = np.array([(i[K]-act[K]-2.*np.sum(n_vec.T[K]*act[3:]*np.cos(np.dot(n_vec,i[3:]))))**2 for i in toy_aa])\n        Err[K] = np.sum(ErrJ)\n        ErrT = np.array(((ang[K]+timeseries*ang[K+3]-UA.T[K]-2.*np.array([np.sum(ang[6+K*size:6+(K+1)*size]*np.sin(np.sum(n_vec*i,axis=1))) for i in toy_aa.T[3:].T])))**2)\n        Err[K+3] = np.sum(ErrT)\n        if(withplot):\n            axis[K][0].plot(ErrJ,'.')\n            axis[K][0].set_ylabel(r'$E$'+str(K+1))\n            axis[K][1].plot(ErrT,'.')\n            axis[K][1].set_ylabel(r'$F$'+str(K+1))\n\n    if(withplot):\n        for i in range(3):\n            axis[i][0].set_xlabel(r'$t$')\n            axis[i][1].set_xlabel(r'$t$')\n        plt.show()\n\n    EJ = np.sqrt(Err[:3]/NT)\n    ET = np.sqrt(Err[3:]/NT)\n\n    return np.array([EJ,ET])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the actions angles and frequencies for a box orbit.", "response": "def box_actions(results, times, N_matrix, ifprint):\n    \"\"\"\n        Finds actions, angles and frequencies for box orbit.\n        Takes a series of phase-space points from an orbit integration at times t and returns\n        L = (act,ang,n_vec,toy_aa, pars) -- explained in find_actions() below.\n    \"\"\"\n    if(ifprint):\n        print(\"\\n=====\\nUsing triaxial harmonic toy potential\")\n\n    t = time.time()\n    # Find best toy parameters\n    omega = toy.findbestparams_ho(results)\n    if(ifprint):\n        print(\"Best omega \"+str(omega)+\" found in \"+str(time.time()-t)+\" seconds\")\n\n    # Now find toy actions and angles\n    AA = np.array([toy.angact_ho(i,omega) for i in results])\n    AA = AA[~np.isnan(AA).any(1)]\n    if(len(AA)==0):\n        return\n\n    t = time.time()\n    act = solver.solver(AA, N_matrix)\n    if act==None:\n        return\n\n    if(ifprint):\n        print(\"Action solution found for N_max = \"+str(N_matrix)+\", size \"+str(len(act[0]))+\" symmetric matrix in \"+str(time.time()-t)+\" seconds\")\n\n    np.savetxt(\"GF.Sn_box\",np.vstack((act[1].T,act[0][3:])).T)\n\n    ang = solver.angle_solver(AA,times,N_matrix,np.ones(3))\n    if(ifprint):\n        print(\"Angle solution found for N_max = \"+str(N_matrix)+\", size \"+str(len(ang))+\" symmetric matrix in \"+str(time.time()-t)+\" seconds\")\n\n    # Just some checks\n    if(len(ang)>len(AA)):\n        print(\"More unknowns than equations\")\n\n    return act[0], ang, act[1], AA, omega"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the actions angles and frequencies for a loop orbit.", "response": "def loop_actions(results, times, N_matrix, ifprint):\n    \"\"\"\n        Finds actions, angles and frequencies for loop orbit.\n        Takes a series of phase-space points from an orbit integration at times t and returns\n        L = (act,ang,n_vec,toy_aa, pars) -- explained in find_actions() below.\n        results must be oriented such that circulation is about the z-axis\n    \"\"\"\n    if(ifprint):\n        print(\"\\n=====\\nUsing isochrone toy potential\")\n\n    t = time.time()\n    # First find the best set of toy parameters\n    params = toy.findbestparams_iso(results)\n    if(params[0]!=params[0]):\n        params = np.array([10.,10.])\n    if(ifprint):\n        print(\"Best params \"+str(params)+\" found in \"+str(time.time()-t)+\" seconds\")\n\n    # Now find the toy angles and actions in this potential\n    AA = np.array([toy.angact_iso(i,params) for i in results])\n    AA = AA[~np.isnan(AA).any(1)]\n    if(len(AA)==0):\n        return\n\n    t = time.time()\n    act = solver.solver(AA, N_matrix,symNx = 1)\n    if act==None:\n        return\n\n    if(ifprint):\n        print(\"Action solution found for N_max = \"+str(N_matrix)+\", size \"+str(len(act[0]))+\" symmetric matrix in \"+str(time.time()-t)+\" seconds\")\n\n    # Store Sn\n    np.savetxt(\"GF.Sn_loop\",np.vstack((act[1].T,act[0][3:])).T)\n\n    # Find angles\n    sign = np.array([1.,np.sign(results[0][0]*results[0][4]-results[0][1]*results[0][3]),1.])\n    ang = solver.angle_solver(AA,times,N_matrix,sign,symNx = 1)\n    if(ifprint):\n        print(\"Angle solution found for N_max = \"+str(N_matrix)+\", size \"+str(len(ang))+\" symmetric matrix in \"+str(time.time()-t)+\" seconds\")\n\n    # Just some checks\n    if(len(ang)>len(AA)):\n        print(\"More unknowns than equations\")\n\n    return act[0], ang, act[1], AA, params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef angmom(x):\n    return np.array([x[1]*x[5]-x[2]*x[4],x[2]*x[3]-x[0]*x[5],x[0]*x[4]-x[1]*x[3]])", "response": "returns angular momentum vector of phase - space point x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assess_angmom(X):\n    L=angmom(X[0])\n    loop = np.array([1,1,1])\n    for i in X[1:]:\n        L0 = angmom(i)\n        if(L0[0]*L[0]<0.):\n            loop[0] = 0\n        if(L0[1]*L[1]<0.):\n            loop[1] = 0\n        if(L0[2]*L[2]<0.):\n            loop[2] = 0\n    return loop", "response": "Assesses that the angular momentum is in the correct format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naligns circulation with z - axis", "response": "def flip_coords(X,loop):\n    \"\"\" Align circulation with z-axis \"\"\"\n    if(loop[0]==1):\n        return np.array(map(lambda i: np.array([i[2],i[1],i[0],i[5],i[4],i[3]]),X))\n    else:\n        return X"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_actions(results, t, N_matrix=8, use_box=False, ifloop=False, ifprint = True):\n\n    # Determine orbit class\n    loop = assess_angmom(results)\n    arethereloops = np.any(loop>0)\n    if(arethereloops and not use_box):\n        L = loop_actions(flip_coords(results,loop),t,N_matrix, ifprint)\n        if(L==None):\n            if(ifprint):\n                print(\"Failed to find actions for this orbit\")\n            return\n        # Used for switching J_2 and J_3 for long-axis loop orbits\n        # This is so the orbit classes form a continuous plane in action space\n        # if(loop[0]):\n        #     L[0][1],L[0][2]=L[0][2],L[0][1]\n        #     L[1][1],L[1][2]=L[1][2],L[1][1]\n        #     L[1][4],L[1][5]=L[1][5],L[1][4]\n        #     L[3].T[1],L[3].T[2]=L[3].T[2],L[3].T[1]\n    else:\n        L = box_actions(results,t,N_matrix, ifprint)\n        if(L==None):\n            if(ifprint):\n                print(\"Failed to find actions for this orbit\")\n            return\n    if(ifloop):\n        return L,loop\n    else:\n        return L", "response": "Find the actions of the orbit at time t."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot SN timesamples for the given PSP.", "response": "def plot_Sn_timesamples(PSP):\n    \"\"\" Plots Fig. 5 from Sanders & Binney (2014) \"\"\"\n    TT = pot.stackel_triax()\n    f,a = plt.subplots(2,1,figsize=[3.32,3.6])\n    plt.subplots_adjust(hspace=0.,top=0.8)\n\n    LowestPeriod = 2.*np.pi/38.86564386\n    Times = np.array([2.,4.,8.,12.])\n    Sr = np.arange(2,14,2)\n\n    # Loop over length of integration window\n    for i,P,C in zip(Times,['.','s','D','^'],['k','r','b','g']):\n        diffact = np.zeros((len(Sr),3))\n        difffreq = np.zeros((len(Sr),3))\n        MAXGAPS = np.array([])\n        # Loop over N_max\n        for k,j in enumerate(Sr):\n            NT = choose_NT(j)\n            timeseries=np.linspace(0.,i*LowestPeriod,NT)\n            results = odeint(pot.orbit_derivs2,PSP,timeseries,args=(TT,),rtol=1e-13,atol=1e-13)\n            act,ang,n_vec,toy_aa, pars = find_actions(results, timeseries,N_matrix=j,ifprint=False,use_box=True)\n            # Check all modes\n            checks,maxgap = ced(n_vec,ua(toy_aa.T[3:].T,np.ones(3)))\n            if len(maxgap)>0:\n                maxgap = np.max(maxgap)\n            else:\n                maxgap = 0\n            diffact[k] = act[:3]/TT.action(results[0])\n            MAXGAPS = np.append(MAXGAPS,maxgap)\n            difffreq[k] = ang[3:6]/TT.freq(results[0])\n        size = 15\n        if(P=='.'):\n            size = 30\n        LW = np.array(map(lambda i: 0.5+i*0.5, MAXGAPS))\n        a[0].scatter(Sr,np.log10(np.abs(diffact.T[2]-1)),marker=P,s=size, color=C,facecolors=\"none\",lw=LW,label=r'$T =\\,$'+str(i)+r'$\\,T_F$')\n        a[1].scatter(Sr,np.log10(np.abs(difffreq.T[2]-1)),marker=P,s=size, color=C,facecolors=\"none\", lw=LW)\n    a[1].get_yticklabels()[-1].set_visible(False)\n    a[0].set_xticklabels([])\n    a[0].set_xlim(1,13)\n    a[0].set_ylabel(r\"$\\log_{10}|J_3^\\prime/J_{3, \\rm true}-1|$\")\n    leg = a[0].legend(loc='upper center',bbox_to_anchor=(0.5,1.4),ncol=2, scatterpoints = 1)\n    leg.draw_frame(False)\n    a[1].set_xlim(1,13)\n    a[1].set_xlabel(r'$N_{\\rm max}$')\n    a[1].set_ylabel(r\"$\\log_{10}|\\Omega_3^\\prime/\\Omega_{3,\\rm true}-1|$\")\n    plt.savefig('Sn_T_box.pdf',bbox_inches='tight')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the 3D stack - triax problem.", "response": "def plot3D_stacktriax(initial,final_t,N_MAT,file_output):\n    \"\"\" For producing plots from paper \"\"\"\n\n    # Setup Stackel potential\n    TT = pot.stackel_triax()\n    times = choose_NT(N_MAT)\n    timeseries=np.linspace(0.,final_t,times)\n    # Integrate orbit\n    results = odeint(pot.orbit_derivs2,initial,timeseries,args=(TT,),rtol=1e-13,atol=1e-13)\n    # Find actions, angles and frequencies\n    (act,ang,n_vec,toy_aa, pars),loop = find_actions(results, timeseries,N_matrix=N_MAT,ifloop=True)\n\n    toy_pot = 0\n    if(loop[2]>0.5 or loop[0]>0.5):\n        toy_pot = pot.isochrone(par=np.append(pars,0.))\n    else:\n        toy_pot = pot.harmonic_oscillator(omega=pars[:3])\n    # Integrate initial condition in toy potential\n    timeseries_2=np.linspace(0.,2.*final_t,3500)\n    results_toy = odeint(pot.orbit_derivs2,initial,timeseries_2,args=(toy_pot,))\n\n    # and plot\n    f,a = plt.subplots(2,3,figsize=[3.32,5.5])\n    a[0,0] = plt.subplot2grid((3,2), (0, 0))\n    a[1,0] = plt.subplot2grid((3,2), (0, 1))\n    a[0,1] = plt.subplot2grid((3,2), (1, 0))\n    a[1,1] = plt.subplot2grid((3,2), (1, 1))\n    a[0,2] = plt.subplot2grid((3,2), (2, 0),colspan=2)\n    plt.subplots_adjust(wspace=0.5,hspace=0.45)\n\n    # xy orbit\n    a[0,0].plot(results.T[0],results.T[1],'k')\n    a[0,0].set_xlabel(r'$x/{\\rm kpc}$')\n    a[0,0].set_ylabel(r'$y/{\\rm kpc}$')\n    a[0,0].xaxis.set_major_locator(MaxNLocator(5))\n    # xz orbit\n    a[1,0].plot(results.T[0],results.T[2],'k')\n    a[1,0].set_xlabel(r'$x/{\\rm kpc}$')\n    a[1,0].set_ylabel(r'$z/{\\rm kpc}$')\n    a[1,0].xaxis.set_major_locator(MaxNLocator(5))\n    # toy orbits\n    a[0,0].plot(results_toy.T[0],results_toy.T[1],'r',alpha=0.2,linewidth=0.3)\n    a[1,0].plot(results_toy.T[0],results_toy.T[2],'r',alpha=0.2,linewidth=0.3)\n\n    # Toy actions\n    a[0,2].plot(Conv*timeseries,toy_aa.T[0],'k:',label='Toy action')\n    a[0,2].plot(Conv*timeseries,toy_aa.T[1],'r:')\n    a[0,2].plot(Conv*timeseries,toy_aa.T[2],'b:')\n    # Arrows to show approx. actions\n    arrow_end = a[0,2].get_xlim()[1]\n    arrowd = 0.08*(arrow_end-a[0,2].get_xlim()[0])\n    a[0,2].annotate('',(arrow_end+arrowd,act[0]),(arrow_end,act[0]),arrowprops=dict(arrowstyle='<-',color='k'),annotation_clip=False)\n    a[0,2].annotate('',(arrow_end+arrowd,act[1]),(arrow_end,act[1]),arrowprops=dict(arrowstyle='<-',color='r'),annotation_clip=False)\n    a[0,2].annotate('',(arrow_end+arrowd,act[2]),(arrow_end,act[2]),arrowprops=dict(arrowstyle='<-',color='b'),annotation_clip=False)\n    # True actions\n    a[0,2].plot(Conv*timeseries,TT.action(results[0])[0]*np.ones(len(timeseries)),'k',label='True action')\n    a[0,2].plot(Conv*timeseries,TT.action(results[0])[1]*np.ones(len(timeseries)),'k')\n    a[0,2].plot(Conv*timeseries,TT.action(results[0])[2]*np.ones(len(timeseries)),'k')\n    a[0,2].set_xlabel(r'$t/{\\rm Gyr}$')\n    a[0,2].set_ylabel(r'$J/{\\rm kpc\\,km\\,s}^{-1}$')\n    leg = a[0,2].legend(loc='upper center',bbox_to_anchor=(0.5,1.2),ncol=3, numpoints = 1)\n    leg.draw_frame(False)\n\n    # Toy angle coverage\n    a[0,1].plot(toy_aa.T[3]/(np.pi),toy_aa.T[4]/(np.pi),'k.',markersize=0.4)\n    a[0,1].set_xlabel(r'$\\theta_1/\\pi$')\n    a[0,1].set_ylabel(r'$\\theta_2/\\pi$')\n    a[1,1].plot(toy_aa.T[3]/(np.pi),toy_aa.T[5]/(np.pi),'k.',markersize=0.4)\n    a[1,1].set_xlabel(r'$\\theta_1/\\pi$')\n    a[1,1].set_ylabel(r'$\\theta_3/\\pi$')\n\n    plt.savefig(file_output,bbox_inches='tight')\n    return act"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform the input cartesian position and velocity to action-angle coordinates in the Isochrone potential. See Section 3.5.2 in Binney & Tremaine (2008), and be aware of the errata entry for Eq. 3.225. This transformation is analytic and can be used as a \"toy potential\" in the Sanders & Binney (2014) formalism for computing action-angle coordinates in any potential. .. note:: This function is included as a method of the :class:`~gala.potential.IsochronePotential` and it is recommended to call :meth:`~gala.potential.IsochronePotential.phase_space()` instead. Parameters ---------- w : :class:`gala.dynamics.PhaseSpacePosition`, :class:`gala.dynamics.Orbit` potential : :class:`gala.potential.IsochronePotential`, dict An instance of the potential to use for computing the transformation to angle-action coordinates. Or, a dictionary of parameters used to define an :class:`gala.potential.IsochronePotential` instance. Returns ------- actions : :class:`numpy.ndarray` An array of actions computed from the input positions and velocities. angles : :class:`numpy.ndarray` An array of angles computed from the input positions and velocities. freqs : :class:`numpy.ndarray` An array of frequencies computed from the input positions and velocities.", "response": "def isochrone_to_aa(w, potential):\n    \"\"\"\n    Transform the input cartesian position and velocity to action-angle\n    coordinates in the Isochrone potential. See Section 3.5.2 in\n    Binney & Tremaine (2008), and be aware of the errata entry for\n    Eq. 3.225.\n\n    This transformation is analytic and can be used as a \"toy potential\"\n    in the Sanders & Binney (2014) formalism for computing action-angle\n    coordinates in any potential.\n\n    .. note::\n\n        This function is included as a method of the\n        :class:`~gala.potential.IsochronePotential` and it is recommended\n        to call :meth:`~gala.potential.IsochronePotential.phase_space()`\n        instead.\n\n    Parameters\n    ----------\n    w : :class:`gala.dynamics.PhaseSpacePosition`, :class:`gala.dynamics.Orbit`\n    potential : :class:`gala.potential.IsochronePotential`, dict\n        An instance of the potential to use for computing the transformation\n        to angle-action coordinates. Or, a dictionary of parameters used to\n        define an :class:`gala.potential.IsochronePotential` instance.\n\n    Returns\n    -------\n    actions : :class:`numpy.ndarray`\n        An array of actions computed from the input positions and velocities.\n    angles : :class:`numpy.ndarray`\n        An array of angles computed from the input positions and velocities.\n    freqs : :class:`numpy.ndarray`\n        An array of frequencies computed from the input positions and velocities.\n    \"\"\"\n\n    if not isinstance(potential, PotentialBase):\n        potential = IsochronePotential(**potential)\n\n    usys = potential.units\n    GM = (G*potential.parameters['m']).decompose(usys).value\n    b = potential.parameters['b'].decompose(usys).value\n    E = w.energy(Hamiltonian(potential)).decompose(usys).value\n    E = np.squeeze(E)\n\n    if np.any(E > 0.):\n        raise ValueError(\"Unbound particle. (E = {})\".format(E))\n\n    # convert position, velocity to spherical polar coordinates\n    w_sph = w.represent_as(coord.PhysicsSphericalRepresentation)\n    r,phi,theta = map(np.squeeze, [w_sph.r.decompose(usys).value,\n                                   w_sph.phi.radian,\n                                   w_sph.theta.radian])\n\n    ang_unit = u.radian/usys['time']\n    vr,phi_dot,theta_dot = map(np.squeeze, [w_sph.radial_velocity.decompose(usys).value,\n                                            w_sph.pm_phi.to(ang_unit).value,\n                                            w_sph.pm_theta.to(ang_unit).value])\n    vphi = r*np.sin(theta) * phi_dot\n    vtheta = r*theta_dot\n\n    # ----------------------------\n    # Compute the actions\n    # ----------------------------\n\n    L_vec = np.squeeze(w.angular_momentum().decompose(usys).value)\n    Lz = L_vec[2]\n    L = np.linalg.norm(L_vec, axis=0)\n\n    # Radial action\n    Jr = GM / np.sqrt(-2*E) - 0.5*(L + np.sqrt(L*L + 4*GM*b))\n\n    # compute the three action variables\n    actions = np.array([Jr, Lz, L - np.abs(Lz)]) # Jr, Jphi, Jtheta\n\n    # ----------------------------\n    # Angles\n    # ----------------------------\n    c = GM / (-2*E) - b\n    e = np.sqrt(1 - L*L*(1 + b/c) / GM / c)\n\n    # Compute theta_r using eta\n    tmp1 = r*vr / np.sqrt(-2.*E)\n    tmp2 = b + c - np.sqrt(b*b + r*r)\n    eta = np.arctan2(tmp1,tmp2)\n    thetar = eta - e*c*np.sin(eta) / (c + b)  # same as theta3\n\n    # Compute theta_z\n    psi = np.arctan2(np.cos(theta), -np.sin(theta)*r*vtheta/L)\n    psi[np.abs(vtheta) <= 1e-10] = np.pi/2.  # blows up for small vtheta\n\n    omega_th = 0.5 * (1 + L/np.sqrt(L*L + 4*GM*b))\n\n    a = np.sqrt((1+e) / (1-e))\n    ap = np.sqrt((1 + e + 2*b/c) / (1 - e + 2*b/c))\n\n    def F(x, y):\n        z = np.zeros_like(x)\n\n        ix = y>np.pi/2.\n        z[ix] = np.pi/2. - np.arctan(np.tan(np.pi/2.-0.5*y[ix])/x[ix])\n\n        ix = y<-np.pi/2.\n        z[ix] = -np.pi/2. + np.arctan(np.tan(np.pi/2.+0.5*y[ix])/x[ix])\n\n        ix = (y<=np.pi/2) & (y>=-np.pi/2)\n        z[ix] = np.arctan(x[ix]*np.tan(0.5*y[ix]))\n        return z\n\n    A = omega_th*thetar - F(a,eta) - F(ap,eta)/np.sqrt(1 + 4*GM*b/L/L)\n    thetaz = psi + A\n\n    LR = Lz/L\n    sinu = (LR/np.sqrt(1.-LR*LR)/np.tan(theta))\n    uu = np.arcsin(sinu)\n\n    uu[sinu > 1.] = np.pi/2.\n    uu[sinu < -1.] = -np.pi/2.\n    uu[vtheta > 0.] = np.pi - uu[vtheta > 0.]\n\n    thetap = phi - uu + np.sign(Lz)*thetaz\n    angles = np.array([thetar, thetap, thetaz])\n    angles = angles % (2*np.pi)\n\n    # ----------------------------\n    # Frequencies\n    # ----------------------------\n    freqs = np.zeros_like(actions)\n    omega_r = GM**2 / (Jr + 0.5*(L + np.sqrt(L*L + 4*GM*b)))**3\n    freqs[0] = omega_r\n    freqs[1] = np.sign(actions[1]) * omega_th * omega_r\n    freqs[2] = omega_th * omega_r\n\n    a_unit = (1*usys['angular momentum']/usys['mass']).decompose(usys).unit\n    f_unit = (1*usys['frequency']).decompose(usys).unit\n    return actions*a_unit, angles*u.radian, freqs*f_unit"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef step(self, t, w, dt):\n\n        # Runge-Kutta Fehlberg formulas (see: Numerical Recipes)\n        F = lambda t, w: self.F(t, w, *self._func_args)\n\n        K = np.zeros((6,)+w.shape)\n        K[0] = dt * F(t, w)\n        K[1] = dt * F(t + A[1]*dt, w + B[1][0]*K[0])\n        K[2] = dt * F(t + A[2]*dt, w + B[2][0]*K[0] + B[2][1]*K[1])\n        K[3] = dt * F(t + A[3]*dt, w + B[3][0]*K[0] + B[3][1]*K[1] + B[3][2]*K[2])\n        K[4] = dt * F(t + A[4]*dt, w + B[4][0]*K[0] + B[4][1]*K[1] + B[4][2]*K[2] + B[4][3]*K[3])\n        K[5] = dt * F(t + A[5]*dt, w + B[5][0]*K[0] + B[5][1]*K[1] + B[5][2]*K[2] + B[5][3]*K[3] + B[5][4]*K[4])\n\n        # shift\n        dw = np.zeros_like(w)\n        for i in range(6):\n            dw = dw + C[i]*K[i]\n\n        return w + dw", "response": "Step forward the vector w by the given timestep."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_each_direction(n,angs,ifprint=True):\n    checks = np.array([])\n    P = np.array([])\n    if(ifprint):\n        print(\"\\nChecking modes:\\n====\")\n    for k,i in enumerate(n):\n        N_matrix = np.linalg.norm(i)\n        X = np.dot(angs,i)\n        if(np.abs(np.max(X)-np.min(X))<2.*np.pi):\n            if(ifprint):\n                print(\"Need a longer integration window for mode \", i)\n            checks=np.append(checks,i)\n            P = np.append(P,(2.*np.pi-np.abs(np.max(X)-np.min(X))))\n        elif(np.abs(np.max(X)-np.min(X))/len(X)>np.pi):\n            if(ifprint):\n                print(\"Need a finer sampling for mode \", i)\n            checks=np.append(checks,i)\n            P = np.append(P,(2.*np.pi-np.abs(np.max(X)-np.min(X))))\n    if(ifprint):\n        print(\"====\\n\")\n    return checks,P", "response": "checks the toy angles of a sequence of elements in n for adequate sequence of toy angles"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsolves the system of the toy2D algorithm for the given action - angles AA and returns the matrix A and the vector b.", "response": "def solver(AA, N_max, symNx = 2, throw_out_modes=False):\n    \"\"\" Constructs the matrix A and the vector b from a timeseries of toy\n    action-angles AA to solve for the vector x = (J_0,J_1,J_2,S...) where\n    x contains all Fourier components of the generating function with |n|<N_max \"\"\"\n\n    # Find all integer component n_vectors which lie within sphere of radius N_max\n    # Here we have assumed that the potential is symmetric x->-x, y->-y, z->-z\n    # This can be relaxed by changing symN to 1\n    # Additionally due to time reversal symmetry S_n = -S_-n so we only consider\n    # \"half\" of the n-vector-space\n\n    angs = unroll_angles(AA.T[3:].T,np.ones(3))\n\n    symNz = 2\n    NNx = range(-N_max, N_max+1, symNx)\n    NNy = range(-N_max, N_max+1, symNz)\n    NNz = range(-N_max, N_max+1, symNz)\n    n_vectors = np.array([[i,j,k] for (i,j,k) in product(NNx,NNy,NNz)\n                          if(not(i==0 and j==0 and k==0)            # exclude zero vector\n                             and (k>0                               # northern hemisphere\n                                  or (k==0 and j>0)                 # half of x-y plane\n                                  or (k==0 and j==0 and i>0))       # half of x axis\n                             and np.sqrt(i*i+j*j+k*k)<=N_max)])     # inside sphere\n\n    xxx = check_each_direction(n_vectors,angs)\n\n    if(throw_out_modes):\n        n_vectors = np.delete(n_vectors,check_each_direction(n_vectors,angs),axis=0)\n\n    n = len(n_vectors)+3\n    b = np.zeros(shape=(n, ))\n    a = np.zeros(shape=(n,n))\n\n    a[:3,:3]=len(AA)*np.identity(3)\n\n    for i in AA:\n        a[:3,3:]+=2.*n_vectors.T[:3]*np.cos(np.dot(n_vectors,i[3:]))\n        a[3:,3:]+=4.*np.dot(n_vectors,n_vectors.T)*np.outer(np.cos(np.dot(n_vectors,i[3:])),np.cos(np.dot(n_vectors,i[3:])))\n        b[:3]+=i[:3]\n        b[3:]+=2.*np.dot(n_vectors,i[:3])*np.cos(np.dot(n_vectors,i[3:]))\n\n    a[3:,:3]=a[:3,3:].T\n\n    return np.array(solve(a,b)), n_vectors"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unroll_angles(A,sign):\n    n = np.array([0,0,0])\n    P = np.zeros(np.shape(A))\n    P[0]=A[0]\n    for i in range(1,len(A)):\n        n = n+((A[i]-A[i-1]+0.5*sign*np.pi)*sign<0)*np.ones(3)*2.*np.pi\n        P[i] = A[i]+sign*n\n    return P", "response": "Unrolls the angles A so they increase continuously"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef angle_solver(AA, timeseries, N_max, sign, symNx = 2, throw_out_modes=False):\n\n    # First unroll angles\n    angs = unroll_angles(AA.T[3:].T,sign)\n\n    # Same considerations as above\n    symNz = 2\n    NNx = range(-N_max, N_max+1, symNx)\n    NNy = range(-N_max, N_max+1, symNz)\n    NNz = range(-N_max, N_max+1, symNz)\n    n_vectors = np.array([[i,j,k] for (i,j,k) in product(NNx,NNy,NNz)\n                          if(not(i==0 and j==0 and k==0)    # exclude zero vector\n                             and (k>0                          # northern hemisphere\n                                  or (k==0 and j>0)                 # half of x-y plane\n                                  or (k==0 and j==0 and i>0))       # half of x axis\n                             and np.sqrt(i*i+j*j+k*k)<=N_max     # inside sphere\n                             )])\n\n    if(throw_out_modes):\n        n_vectors = np.delete(n_vectors,check_each_direction(n_vectors,angs),axis=0)\n\n    nv = len(n_vectors)\n    n = 3*nv+6\n\n    b = np.zeros(shape=(n, ))\n    a = np.zeros(shape=(n,n))\n\n    a[:3,:3]=len(AA)*np.identity(3)\n    a[:3,3:6]=np.sum(timeseries)*np.identity(3)\n    a[3:6,:3]=a[:3,3:6]\n    a[3:6,3:6]=np.sum(timeseries*timeseries)*np.identity(3)\n\n    for i,j in zip(angs,timeseries):\n        a[6:6+nv,0]+=-2.*np.sin(np.dot(n_vectors,i))\n        a[6:6+nv,3]+=-2.*j*np.sin(np.dot(n_vectors,i))\n        a[6:6+nv,6:6+nv]+=4.*np.outer(np.sin(np.dot(n_vectors,i)),np.sin(np.dot(n_vectors,i)))\n\n        b[:3]+=i\n        b[3:6]+=j*i\n\n        b[6:6+nv]+=-2.*i[0]*np.sin(np.dot(n_vectors,i))\n        b[6+nv:6+2*nv]+=-2.*i[1]*np.sin(np.dot(n_vectors,i))\n        b[6+2*nv:6+3*nv]+=-2.*i[2]*np.sin(np.dot(n_vectors,i))\n\n    a[6+nv:6+2*nv,1]=a[6:6+nv,0]\n    a[6+2*nv:6+3*nv,2]=a[6:6+nv,0]\n    a[6+nv:6+2*nv,4]=a[6:6+nv,3]\n    a[6+2*nv:6+3*nv,5]=a[6:6+nv,3]\n    a[6+nv:6+2*nv,6+nv:6+2*nv]=a[6:6+nv,6:6+nv]\n    a[6+2*nv:6+3*nv,6+2*nv:6+3*nv]=a[6:6+nv,6:6+nv]\n\n    a[:6,:]=a[:,:6].T\n\n    return np.array(solve(a,b))", "response": "This function solves the angle problem for the action - angles AA."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the expansion coefficients for representing the input density function.", "response": "def compute_coeffs(density_func, nmax, lmax, M, r_s, args=(),\n                   skip_odd=False, skip_even=False, skip_m=False,\n                   S_only=False, progress=False, **nquad_opts):\n    \"\"\"\n    Compute the expansion coefficients for representing the input density function using a basis\n    function expansion.\n\n    Computing the coefficients involves computing triple integrals which are computationally\n    expensive. For an example of how to parallelize the computation of the coefficients, see\n    ``examples/parallel_compute_Anlm.py``.\n\n    Parameters\n    ----------\n    density_func : function, callable\n        A function or callable object that evaluates the density at a given position. The call\n        format must be of the form: ``density_func(x, y, z, M, r_s, args)`` where ``x,y,z`` are\n        cartesian coordinates, ``M`` is a scale mass, ``r_s`` a scale radius, and ``args`` is an\n        iterable containing any other arguments needed by the density function.\n    nmax : int\n        Maximum value of ``n`` for the radial expansion.\n    lmax : int\n        Maximum value of ``l`` for the spherical harmonics.\n    M : numeric\n        Scale mass.\n    r_s : numeric\n        Scale radius.\n    args : iterable (optional)\n        A list or iterable of any other arguments needed by the density\n        function.\n    skip_odd : bool (optional)\n        Skip the odd terms in the angular portion of the expansion. For example, only\n        take :math:`l=0,2,4,...`\n    skip_even : bool (optional)\n        Skip the even terms in the angular portion of the expansion. For example, only\n        take :math:`l=1,3,5,...`\n    skip_m : bool (optional)\n        Ignore terms with :math:`m > 0`.\n    S_only : bool (optional)\n        Only compute the S coefficients.\n    progress : bool (optional)\n        If ``tqdm`` is installed, display a progress bar.\n    **nquad_opts\n        Any additional keyword arguments are passed through to\n        `~scipy.integrate.nquad` as options, `opts`.\n\n    Returns\n    -------\n    Snlm : float, `~numpy.ndarray`\n        The value of the cosine expansion coefficient.\n    Snlm_err : , `~numpy.ndarray`\n        An estimate of the uncertainty in the coefficient value (from `~scipy.integrate.nquad`).\n    Tnlm : , `~numpy.ndarray`\n        The value of the sine expansion coefficient.\n    Tnlm_err : , `~numpy.ndarray`\n        An estimate of the uncertainty in the coefficient value. (from `~scipy.integrate.nquad`).\n\n    \"\"\"\n    from gala._cconfig import GSL_ENABLED\n    if not GSL_ENABLED:\n        raise ValueError(\"Gala was compiled without GSL and so this function \"\n                         \"will not work.  See the gala documentation for more \"\n                         \"information about installing and using GSL with \"\n                         \"gala: http://gala.adrian.pw/en/latest/install.html\")\n\n    lmin = 0\n    lstride = 1\n\n    if skip_odd or skip_even:\n        lstride = 2\n\n    if skip_even:\n        lmin = 1\n\n    Snlm = np.zeros((nmax+1, lmax+1, lmax+1))\n    Snlm_e = np.zeros((nmax+1, lmax+1, lmax+1))\n    Tnlm = np.zeros((nmax+1, lmax+1, lmax+1))\n    Tnlm_e = np.zeros((nmax+1, lmax+1, lmax+1))\n\n    nquad_opts.setdefault('limit', 256)\n    nquad_opts.setdefault('epsrel', 1E-10)\n\n    limits = [[0, 2*np.pi], # phi\n              [-1, 1.], # X (cos(theta))\n              [-1, 1.]] # xsi\n\n    nlms = []\n    for n in range(nmax+1):\n        for l in range(lmin, lmax+1, lstride):\n            for m in range(l+1):\n                if skip_m and m > 0:\n                    continue\n\n                nlms.append((n, l, m))\n\n    if progress:\n        try:\n            from tqdm import tqdm\n        except ImportError as e:\n            raise ImportError('tqdm is not installed - you can install it '\n                              'with `pip install tqdm`.\\n' + str(e))\n        iterfunc = tqdm\n    else:\n        iterfunc = lambda x: x\n\n    for n, l, m in iterfunc(nlms):\n        Snlm[n, l, m], Snlm_e[n, l, m] = si.nquad(\n            Snlm_integrand, ranges=limits,\n            args=(density_func, n, l, m, M, r_s, args),\n            opts=nquad_opts)\n\n        if not S_only:\n            Tnlm[n, l, m], Tnlm_e[n, l, m] = si.nquad(\n                Tnlm_integrand, ranges=limits,\n                args=(density_func, n, l, m, M, r_s, args),\n                opts=nquad_opts)\n\n    return (Snlm, Snlm_e), (Tnlm, Tnlm_e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_coeffs_discrete(xyz, mass, nmax, lmax, r_s,\n                            skip_odd=False, skip_even=False, skip_m=False,\n                            compute_var=False):\n    \"\"\"\n    Compute the expansion coefficients for representing the density distribution of input points\n    as a basis function expansion. The points, ``xyz``, are assumed to be samples from the\n    density distribution.\n\n    Computing the coefficients involves computing triple integrals which are computationally\n    expensive. For an example of how to parallelize the computation of the coefficients, see\n    ``examples/parallel_compute_Anlm.py``.\n\n    Parameters\n    ----------\n    xyz : array_like\n        Samples from the density distribution. Should have shape ``(n_samples,3)``.\n    mass : array_like\n        Mass of each sample. Should have shape ``(n_samples,)``.\n    nmax : int\n        Maximum value of ``n`` for the radial expansion.\n    lmax : int\n        Maximum value of ``l`` for the spherical harmonics.\n    r_s : numeric\n        Scale radius.\n    skip_odd : bool (optional)\n        Skip the odd terms in the angular portion of the expansion. For example, only\n        take :math:`l=0,2,4,...`\n    skip_even : bool (optional)\n        Skip the even terms in the angular portion of the expansion. For example, only\n        take :math:`l=1,3,5,...`\n    skip_m : bool (optional)\n        Ignore terms with :math:`m > 0`.\n    compute_var : bool (optional)\n        Also compute the variances of the coefficients. This does not compute the full covariance\n        matrix of the coefficients, just the individual variances.\n        TODO: separate function to compute full covariance matrix?\n\n    Returns\n    -------\n    Snlm : float\n        The value of the cosine expansion coefficient.\n    Tnlm : float\n        The value of the sine expansion coefficient.\n\n    \"\"\"\n    lmin = 0\n    lstride = 1\n\n    if skip_odd or skip_even:\n        lstride = 2\n\n    if skip_even:\n        lmin = 1\n\n    Snlm = np.zeros((nmax+1, lmax+1, lmax+1))\n    Tnlm = np.zeros((nmax+1, lmax+1, lmax+1))\n\n    if compute_var:\n        Snlm_var = np.zeros((nmax+1, lmax+1, lmax+1))\n        Tnlm_var = np.zeros((nmax+1, lmax+1, lmax+1))\n\n    # positions and masses of point masses\n    xyz = np.ascontiguousarray(np.atleast_2d(xyz))\n    mass = np.ascontiguousarray(np.atleast_1d(mass))\n\n    r = np.sqrt(np.sum(xyz**2, axis=-1))\n    s = r / r_s\n    phi = np.arctan2(xyz[:,1], xyz[:,0])\n    X = xyz[:,2] / r\n\n    for n in range(nmax+1):\n        for l in range(lmin, lmax+1, lstride):\n            for m in range(l+1):\n                if skip_m and m > 0: continue\n\n                # logger.debug(\"Computing coefficients (n,l,m)=({},{},{})\".format(n,l,m))\n\n                Snlm[n,l,m], Tnlm[n,l,m] = STnlm_discrete(s, phi, X, mass, n, l, m)\n                if compute_var:\n                    Snlm_var[n,l,m], Tnlm_var[n,l,m] = STnlm_var_discrete(s, phi, X, mass, n, l, m)\n\n    if compute_var:\n        return (Snlm,Snlm_var), (Tnlm,Tnlm_var)\n    else:\n        return Snlm, Tnlm", "response": "Compute the expansion coefficients for representing the density distribution of input points xyz and mass."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef integrate_orbit(self, **time_spec):\n\n        # Prepare the initial conditions\n        pos = self.w0.xyz.decompose(self.units).value\n        vel = self.w0.v_xyz.decompose(self.units).value\n        w0 = np.ascontiguousarray(np.vstack((pos, vel)).T)\n\n        # Prepare the time-stepping array\n        t = parse_time_specification(self.units, **time_spec)\n\n        ws = _direct_nbody_dop853(w0, t, self._ext_ham,\n                                  self.particle_potentials)\n        pos = np.rollaxis(np.array(ws[..., :3]), axis=2)\n        vel = np.rollaxis(np.array(ws[..., 3:]), axis=2)\n\n        orbits = Orbit(\n            pos=pos * self.units['length'],\n            vel=vel * self.units['length'] / self.units['time'],\n            t=t * self.units['time'])\n\n        return orbits", "response": "Integrate the initial conditions in the combined external potential with N - body forces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mock_stream(hamiltonian, prog_orbit, prog_mass, k_mean, k_disp,\n                release_every=1, Integrator=DOPRI853Integrator,\n                Integrator_kwargs=dict(),\n                snapshot_filename=None, output_every=1, seed=None):\n    \"\"\"\n    Generate a mock stellar stream in the specified potential with a\n    progenitor system that ends up at the specified position.\n\n    Parameters\n    ----------\n    hamiltonian : `~gala.potential.Hamiltonian`\n        The system Hamiltonian.\n    prog_orbit : `~gala.dynamics.Orbit`\n        The orbit of the progenitor system.\n    prog_mass : numeric, array_like\n        A single mass or an array of masses if the progenitor mass evolves\n        with time.\n    k_mean : `numpy.ndarray`\n        Array of mean :math:`k` values (see Fardal et al. 2015). These are used\n        to determine the exact prescription for generating the mock stream. The\n        components are for: :math:`(R,\\phi,z,v_R,v_\\phi,v_z)`. If 1D, assumed\n        constant in time. If 2D, time axis is axis 0.\n    k_disp : `numpy.ndarray`\n        Array of :math:`k` value dispersions (see Fardal et al. 2015). These are\n        used to determine the exact prescription for generating the mock stream.\n        The components are for: :math:`(R,\\phi,z,v_R,v_\\phi,v_z)`. If 1D,\n        assumed constant in time. If 2D, time axis is axis 0.\n    release_every : int (optional)\n        Release particles at the Lagrange points every X timesteps.\n    Integrator : `~gala.integrate.Integrator` (optional)\n        Integrator to use.\n    Integrator_kwargs : dict (optional)\n        Any extra keyword argumets to pass to the integrator function.\n    snapshot_filename : str (optional)\n        Filename to save all incremental snapshots of particle positions and\n        velocities. Warning: this can make very large files if you are not\n        careful!\n    output_every : int (optional)\n        If outputing snapshots (i.e., if snapshot_filename is specified), this\n        controls how often to output a snapshot.\n    seed : int (optional)\n        A random number seed for initializing the particle positions.\n\n    Returns\n    -------\n    stream : `~gala.dynamics.PhaseSpacePosition`\n\n    \"\"\"\n\n    if isinstance(hamiltonian, CPotentialBase):\n        warnings.warn(\"This function now expects a `Hamiltonian` instance \"\n                      \"instead of a `PotentialBase` subclass instance. If you \"\n                      \"are using a static reference frame, you just need to \"\n                      \"pass your potential object in to the Hamiltonian \"\n                      \"constructor to use, e.g., Hamiltonian(potential).\",\n                      DeprecationWarning)\n\n        hamiltonian = Hamiltonian(hamiltonian)\n\n    # ------------------------------------------------------------------------\n    # Some initial checks to short-circuit if input is bad\n    if Integrator not in [LeapfrogIntegrator, DOPRI853Integrator]:\n        raise ValueError(\"Only Leapfrog and dop853 integration is supported for\"\n                         \" generating mock streams.\")\n\n    if not isinstance(hamiltonian, Hamiltonian) or not hamiltonian.c_enabled:\n        raise TypeError(\"Input potential must be a CPotentialBase subclass.\")\n\n    if not isinstance(prog_orbit, Orbit):\n        raise TypeError(\"Progenitor orbit must be an Orbit subclass.\")\n\n    if snapshot_filename is not None and Integrator != DOPRI853Integrator:\n        raise ValueError(\"If saving snapshots, must use the DOP853Integrator.\")\n\n    k_mean = np.atleast_1d(k_mean)\n    k_disp = np.atleast_1d(k_disp)\n\n    if k_mean.ndim > 1:\n        assert k_mean.shape[0] == prog_orbit.t.size\n        assert k_disp.shape[0] == prog_orbit.t.size\n\n    # ------------------------------------------------------------------------\n\n    if prog_orbit.t[1] < prog_orbit.t[0]:\n        raise ValueError(\"Progenitor orbit goes backwards in time. Streams can \"\n                         \"only be generated on orbits that run forwards. Hint: \"\n                         \"you can reverse the orbit with prog_orbit[::-1], but \"\n                         \"make sure the array of k_mean values is ordered \"\n                         \"correctly.\")\n\n    c_w = np.squeeze(prog_orbit.w(hamiltonian.units)).T # transpose for Cython funcs\n    prog_w = np.ascontiguousarray(c_w)\n    prog_t = np.ascontiguousarray(prog_orbit.t.decompose(hamiltonian.units).value)\n    if not hasattr(prog_mass, 'unit'):\n        prog_mass = prog_mass * hamiltonian.units['mass']\n\n    if not prog_mass.isscalar:\n        if len(prog_mass) != prog_orbit.ntimes:\n            raise ValueError(\"If passing in an array of progenitor masses, it \"\n                             \"must have the same length as the number of \"\n                             \"timesteps in the input orbit.\")\n\n    prog_mass = prog_mass.decompose(hamiltonian.units).value\n\n    if Integrator == LeapfrogIntegrator:\n        stream_w = _mock_stream_leapfrog(hamiltonian, t=prog_t, prog_w=prog_w,\n                                         release_every=release_every,\n                                         _k_mean=k_mean, _k_disp=k_disp,\n                                         G=hamiltonian.potential.G,\n                                         _prog_mass=prog_mass, seed=seed,\n                                         **Integrator_kwargs)\n\n    elif Integrator == DOPRI853Integrator:\n        if snapshot_filename is not None:\n            if os.path.exists(snapshot_filename):\n                raise IOError(\"Mockstream save file '{}' already exists.\")\n\n            import h5py\n\n            _mock_stream_animate(snapshot_filename, hamiltonian, t=prog_t, prog_w=prog_w,\n                                 release_every=release_every,\n                                 output_every=output_every,\n                                 _k_mean=k_mean, _k_disp=k_disp,\n                                 G=hamiltonian.potential.G,\n                                 _prog_mass=prog_mass, seed=seed,\n                                 **Integrator_kwargs)\n\n            with h5py.File(str(snapshot_filename), 'a') as h5f:\n                h5f['pos'].attrs['unit'] = str(hamiltonian.units['length'])\n                h5f['vel'].attrs['unit'] = str(hamiltonian.units['length']/hamiltonian.units['time'])\n                h5f['t'].attrs['unit'] = str(hamiltonian.units['time'])\n\n            return None\n\n        else:\n            stream_w = _mock_stream_dop853(hamiltonian, t=prog_t, prog_w=prog_w,\n                                           release_every=release_every,\n                                           _k_mean=k_mean, _k_disp=k_disp,\n                                           G=hamiltonian.potential.G,\n                                           _prog_mass=prog_mass, seed=seed,\n                                           **Integrator_kwargs)\n\n    else:\n        raise RuntimeError(\"Should never get here...\")\n\n    return PhaseSpacePosition.from_w(w=stream_w.T, units=hamiltonian.units)", "response": "Generates a mock stream in the specified potential with the specified orbit and mass."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a mock stellar stream in the specified potential with a specific orbital system.", "response": "def streakline_stream(hamiltonian, prog_orbit, prog_mass, release_every=1,\n                      Integrator=DOPRI853Integrator, Integrator_kwargs=dict(),\n                      snapshot_filename=None, output_every=1, seed=None):\n    \"\"\"\n    Generate a mock stellar stream in the specified potential with a\n    progenitor system that ends up at the specified position.\n\n    This uses the Streakline method from Kuepper et al. (2012).\n\n    Parameters\n    ----------\n    hamiltonian : `~gala.potential.Hamiltonian`\n        The system Hamiltonian.\n    prog_orbit : `~gala.dynamics.Orbit`\n            The orbit of the progenitor system.\n    prog_mass : numeric, array_like\n        A single mass or an array of masses if the progenitor mass evolves\n        with time.\n    release_every : int (optional)\n        Release particles at the Lagrange points every X timesteps.\n    Integrator : `~gala.integrate.Integrator` (optional)\n        Integrator to use.\n    Integrator_kwargs : dict (optional)\n        Any extra keyword argumets to pass to the integrator function.\n    snapshot_filename : str (optional)\n        Filename to save all incremental snapshots of particle positions and\n        velocities. Warning: this can make very large files if you are not\n        careful!\n    output_every : int (optional)\n        If outputing snapshots (i.e., if snapshot_filename is specified), this\n        controls how often to output a snapshot.\n    seed : int (optional)\n        A random number seed for initializing the particle positions.\n\n    Returns\n    -------\n    stream : `~gala.dynamics.PhaseSpacePosition`\n\n    \"\"\"\n    k_mean = np.zeros(6)\n    k_disp = np.zeros(6)\n\n    k_mean[0] = 1. # R\n    k_disp[0] = 0.\n\n    k_mean[1] = 0. # phi\n    k_disp[1] = 0.\n\n    k_mean[2] = 0. # z\n    k_disp[2] = 0.\n\n    k_mean[3] = 0. # vR\n    k_disp[3] = 0.\n\n    k_mean[4] = 1. # vt\n    k_disp[4] = 0.\n\n    k_mean[5] = 0. # vz\n    k_disp[5] = 0.\n\n    return mock_stream(hamiltonian=hamiltonian, prog_orbit=prog_orbit,\n                       prog_mass=prog_mass,\n                       k_mean=k_mean, k_disp=k_disp,\n                       release_every=release_every,\n                       Integrator=Integrator,\n                       Integrator_kwargs=Integrator_kwargs,\n                       snapshot_filename=snapshot_filename,\n                       output_every=output_every, seed=seed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dissolved_fardal_stream(hamiltonian, prog_orbit, prog_mass, t_disrupt, release_every=1,\n                            Integrator=DOPRI853Integrator, Integrator_kwargs=dict(),\n                            snapshot_filename=None, output_every=1, seed=None):\n    \"\"\"\n    Generate a mock stellar stream in the specified potential with a\n    progenitor system that ends up at the specified position.\n\n    This uses the prescription from Fardal et al. (2015), but at a specified\n    time the progenitor completely dissolves and the radial offset of the\n    tidal radius is reduced to 0 at fixed dispersion.\n\n    Parameters\n    ----------\n    hamiltonian : `~gala.potential.Hamiltonian`\n            The system Hamiltonian.\n    prog_orbit : `~gala.dynamics.Orbit`\n            The orbit of the progenitor system.\n    prog_mass : numeric, array_like\n        A single mass or an array of masses if the progenitor mass evolves\n        with time.\n    t_disrupt : numeric\n        The time that the progenitor completely disrupts.\n    release_every : int (optional)\n        Release particles at the Lagrange points every X timesteps.\n    Integrator : `~gala.integrate.Integrator` (optional)\n        Integrator to use.\n    Integrator_kwargs : dict (optional)\n        Any extra keyword argumets to pass to the integrator function.\n    snapshot_filename : str (optional)\n        Filename to save all incremental snapshots of particle positions and\n        velocities. Warning: this can make very large files if you are not\n        careful!\n    output_every : int (optional)\n        If outputing snapshots (i.e., if snapshot_filename is specified), this\n        controls how often to output a snapshot.\n    seed : int (optional)\n        A random number seed for initializing the particle positions.\n\n    Returns\n    -------\n    stream : `~gala.dynamics.PhaseSpacePosition`\n\n    \"\"\"\n\n    try:\n        # the time index closest to when the disruption happens\n        t = prog_orbit.t\n    except AttributeError:\n        raise TypeError(\"Input progenitor orbit must be an Orbit subclass instance.\")\n\n    disrupt_ix = np.abs(t - t_disrupt).argmin()\n\n    k_mean = np.zeros((t.size, 6))\n    k_disp = np.zeros((t.size, 6))\n\n    k_mean[:, 0] = 2. # R\n    k_mean[disrupt_ix:, 0] = 0.\n    k_disp[:, 0] = 0.5\n\n    k_mean[:, 1] = 0. # phi\n    k_disp[:, 1] = 0.\n\n    k_mean[:, 2] = 0. # z\n    k_disp[:, 2] = 0.5\n\n    k_mean[:, 3] = 0. # vR\n    k_disp[:, 3] = 0.\n\n    k_mean[:, 4] = 0.3 # vt\n    k_disp[:, 4] = 0.5\n\n    k_mean[:, 5] = 0. # vz\n    k_disp[:, 5] = 0.5\n\n    return mock_stream(hamiltonian=hamiltonian, prog_orbit=prog_orbit,\n                       prog_mass=prog_mass,\n                       k_mean=k_mean, k_disp=k_disp,\n                       release_every=release_every,\n                       Integrator=Integrator,\n                       Integrator_kwargs=Integrator_kwargs,\n                       snapshot_filename=snapshot_filename,\n                       output_every=output_every, seed=seed)", "response": "Generates a mock stellar stream for a dissolved Fardal system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef vgsr_to_vhel(coordinate, vgsr, vsun=None):\n\n    if vsun is None:\n        vsun = coord.Galactocentric.galcen_v_sun.to_cartesian().xyz\n\n    return vgsr - _get_vproj(coordinate, vsun)", "response": "Convert a radial velocity in the Galactic standard of rest of GSR to a barycentric radial velocity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef vhel_to_vgsr(coordinate, vhel, vsun):\n\n    if vsun is None:\n        vsun = coord.Galactocentric.galcen_v_sun.to_cartesian().xyz\n\n    return vhel + _get_vproj(coordinate, vsun)", "response": "Convert a velocity from a heliocentric radial velocity to a GSR."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new representation with method applied to the internal array.", "response": "def _apply(self, method, *args, **kwargs):\n        \"\"\"Create a new representation with ``method`` applied to the arrays.\n\n        In typical usage, the method is any of the shape-changing methods for\n        `~numpy.ndarray` (``reshape``, ``swapaxes``, etc.), as well as those\n        picking particular elements (``__getitem__``, ``take``, etc.), which\n        are all defined in `~astropy.utils.misc.ShapedLikeNDArray`. It will be\n        applied to the underlying arrays (e.g., ``x``, ``y``, and ``z`` for\n        `~astropy.coordinates.CartesianRepresentation`), with the results used\n        to create a new instance.\n\n        Internally, it is also used to apply functions to the components\n        (in particular, `~numpy.broadcast_to`).\n\n        Parameters\n        ----------\n        method : str or callable\n            If str, it is the name of a method that is applied to the internal\n            ``components``. If callable, the function is applied.\n        args : tuple\n            Any positional arguments for ``method``.\n        kwargs : dict\n            Any keyword arguments for ``method``.\n        \"\"\"\n        if callable(method):\n            apply_method = lambda array: method(array, *args, **kwargs)\n        else:\n            apply_method = operator.methodcaller(method, *args, **kwargs)\n        return self.__class__([apply_method(getattr(self, component))\n                               for component in self.components], copy=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_xyz(self, xyz_axis=0):\n        # Add new axis in x, y, z so one can concatenate them around it.\n        # NOTE: just use np.stack once our minimum numpy version is 1.10.\n        result_ndim = self.ndim + 1\n        if not -result_ndim <= xyz_axis < result_ndim:\n            raise IndexError('xyz_axis {0} out of bounds [-{1}, {1})'\n                             .format(xyz_axis, result_ndim))\n        if xyz_axis < 0:\n            xyz_axis += result_ndim\n\n        # Get components to the same units (very fast for identical units)\n        # since np.concatenate cannot deal with quantity.\n        unit = self._x1.unit\n\n        sh = self.shape\n        sh = sh[:xyz_axis] + (1,) + sh[xyz_axis:]\n        components = [getattr(self, '_'+name).reshape(sh).to(unit).value\n                      for name in self.attr_classes]\n        xs_value = np.concatenate(components, axis=xyz_axis)\n        return u.Quantity(xs_value, unit=unit, copy=False)", "response": "Return a vector array of the x y and z coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning array shape and x for C code.", "response": "def _get_c_valid_arr(self, x):\n        \"\"\"\n        Warning! Interpretation of axes is different for C code.\n        \"\"\"\n        orig_shape = x.shape\n        x = np.ascontiguousarray(x.reshape(orig_shape[0], -1).T)\n        return orig_shape, x"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_prepare_time(self, t, pos_c):\n        if hasattr(t, 'unit'):\n            t = t.decompose(self.units).value\n\n        if not isiterable(t):\n            t = np.atleast_1d(t)\n\n        t = np.ascontiguousarray(t.ravel())\n\n        if len(t) > 1:\n            if len(t) != pos_c.shape[0]:\n                raise ValueError(\"If passing in an array of times, it must have a shape \"\n                                 \"compatible with the input position(s).\")\n\n        return t", "response": "Validate that the input time is a 1D array and compatible with the C position array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_components(self, which):\n        mappings = self.representation_mappings.get(\n            getattr(self, which).__class__, [])\n\n        old_to_new = dict()\n        for name in getattr(self, which).components:\n            for m in mappings:\n                if isinstance(m, RegexRepresentationMapping):\n                    pattr = re.match(m.repr_name, name)\n                    old_to_new[name] = m.new_name.format(*pattr.groups())\n\n                elif m.repr_name == name:\n                    old_to_new[name] = m.new_name\n\n        mapping = OrderedDict()\n        for name in getattr(self, which).components:\n            mapping[old_to_new.get(name, name)] = name\n\n        return mapping", "response": "Get the component name dictionary for the desired object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new instance of the same type as this one.", "response": "def represent_as(self, new_pos, new_vel=None):\n        \"\"\"\n        Represent the position and velocity of the orbit in an alternate\n        coordinate system. Supports any of the Astropy coordinates\n        representation classes.\n\n        Parameters\n        ----------\n        new_pos : :class:`~astropy.coordinates.BaseRepresentation`\n            The type of representation to generate. Must be a class (not an\n            instance), or the string name of the representation class.\n        new_vel : :class:`~astropy.coordinates.BaseDifferential` (optional)\n            Class in which any velocities should be represented. Must be a class\n            (not an instance), or the string name of the differential class. If\n            None, uses the default differential for the new position class.\n\n        Returns\n        -------\n        new_psp : `gala.dynamics.PhaseSpacePosition`\n        \"\"\"\n\n        if self.ndim != 3:\n            raise ValueError(\"Can only change representation for \"\n                             \"ndim=3 instances.\")\n\n        # get the name of the desired representation\n        if isinstance(new_pos, str):\n            pos_name = new_pos\n        else:\n            pos_name = new_pos.get_name()\n\n        if isinstance(new_vel, str):\n            vel_name = new_vel\n        elif new_vel is None:\n            vel_name = pos_name\n        else:\n            vel_name = new_vel.get_name()\n\n        Representation = coord.representation.REPRESENTATION_CLASSES[pos_name]\n        Differential = coord.representation.DIFFERENTIAL_CLASSES[vel_name]\n\n        new_pos = self.pos.represent_as(Representation)\n        new_vel = self.vel.represent_as(Differential, self.pos)\n\n        return self.__class__(pos=new_pos,\n                              vel=new_vel,\n                              frame=self.frame)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms to a new frame.", "response": "def to_frame(self, frame, current_frame=None, **kwargs):\n        \"\"\"\n        Transform to a new reference frame.\n\n        Parameters\n        ----------\n        frame : `~gala.potential.FrameBase`\n            The frame to transform to.\n        current_frame : `gala.potential.CFrameBase`\n            The current frame the phase-space position is in.\n        **kwargs\n            Any additional arguments are passed through to the individual frame\n            transformation functions (see:\n            `~gala.potential.frame.builtin.transformations`).\n\n        Returns\n        -------\n        psp : `gala.dynamics.CartesianPhaseSpacePosition`\n            The phase-space position in the new reference frame.\n\n        \"\"\"\n\n        from ..potential.frame.builtin import transformations as frame_trans\n\n        if ((inspect.isclass(frame) and issubclass(frame, coord.BaseCoordinateFrame)) or\n                isinstance(frame, coord.BaseCoordinateFrame)):\n            import warnings\n            warnings.warn(\"This function now expects a \"\n                          \"`gala.potential.FrameBase` instance. To transform to\"\n                          \" an Astropy coordinate frame, use the \"\n                          \"`.to_coord_frame()` method instead.\",\n                          DeprecationWarning)\n            return self.to_coord_frame(frame=frame, **kwargs)\n\n        if self.frame is None and current_frame is None:\n            raise ValueError(\"If no frame was specified when this {} was \"\n                             \"initialized, you must pass the current frame in \"\n                             \"via the current_frame argument to transform to a \"\n                             \"new frame.\")\n\n        elif self.frame is not None and current_frame is None:\n            current_frame = self.frame\n\n        name1 = current_frame.__class__.__name__.rstrip('Frame').lower()\n        name2 = frame.__class__.__name__.rstrip('Frame').lower()\n        func_name = \"{}_to_{}\".format(name1, name2)\n\n        if not hasattr(frame_trans, func_name):\n            raise ValueError(\"Unsupported frame transformation: {} to {}\"\n                             .format(current_frame, frame))\n        else:\n            trans_func = getattr(frame_trans, func_name)\n\n        pos, vel = trans_func(current_frame, frame, self, **kwargs)\n        return PhaseSpacePosition(pos=pos, vel=vel, frame=frame)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform the orbit from Galactocentric cartesian coordinates to Astropy coordinate frame.", "response": "def to_coord_frame(self, frame, galactocentric_frame=None, **kwargs):\n        \"\"\"\n        Transform the orbit from Galactocentric, cartesian coordinates to\n        Heliocentric coordinates in the specified Astropy coordinate frame.\n\n        Parameters\n        ----------\n        frame : :class:`~astropy.coordinates.BaseCoordinateFrame`\n            The class or frame instance specifying the desired output frame.\n            For example, :class:`~astropy.coordinates.ICRS`.\n        galactocentric_frame : :class:`~astropy.coordinates.Galactocentric`\n            This is the assumed frame that the position and velocity of this\n            object are in. The ``Galactocentric`` instand should have parameters\n            specifying the position and motion of the sun in the Galactocentric\n            frame, but no data.\n\n        Returns\n        -------\n        c : :class:`~astropy.coordinates.BaseCoordinateFrame`\n            An instantiated coordinate frame containing the positions and\n            velocities from this object transformed to the specified coordinate\n            frame.\n\n        \"\"\"\n\n        if self.ndim != 3:\n            raise ValueError(\"Can only change representation for \"\n                             \"ndim=3 instances.\")\n\n        if galactocentric_frame is None:\n            galactocentric_frame = coord.Galactocentric()\n\n        if 'vcirc' in kwargs or 'vlsr' in kwargs:\n            import warnings\n            warnings.warn(\"Instead of passing in 'vcirc' and 'vlsr', specify \"\n                          \"these parameters to the input Galactocentric frame \"\n                          \"using the `galcen_v_sun` argument.\",\n                          DeprecationWarning)\n\n        pos_keys = list(self.pos_components.keys())\n        vel_keys = list(self.vel_components.keys())\n        if (getattr(self, pos_keys[0]).unit == u.one or\n                getattr(self, vel_keys[0]).unit == u.one):\n            raise u.UnitConversionError(\"Position and velocity must have \"\n                                        \"dimensioned units to convert to a \"\n                                        \"coordinate frame.\")\n\n        # first we need to turn the position into a Galactocentric instance\n        gc_c = galactocentric_frame.realize_frame(\n            self.pos.with_differentials(self.vel))\n        c = gc_c.transform_to(frame)\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef w(self, units=None):\n        if self.ndim == 3:\n            cart = self.cartesian\n        else:\n            cart = self\n\n        xyz = cart.xyz\n        d_xyz = cart.v_xyz\n\n        x_unit = xyz.unit\n        v_unit = d_xyz.unit\n        if ((units is None or isinstance(units, DimensionlessUnitSystem)) and\n                (x_unit == u.one and v_unit == u.one)):\n            units = DimensionlessUnitSystem()\n\n        elif units is None:\n            raise ValueError(\"A UnitSystem must be provided.\")\n\n        x = xyz.decompose(units).value\n        if x.ndim < 2:\n            x = atleast_2d(x, insert_axis=1)\n\n        v = d_xyz.decompose(units).value\n        if v.ndim < 2:\n            v = atleast_2d(v, insert_axis=1)\n\n        return np.vstack((x,v))", "response": "This returns a single array containing the phase - space positions and velocities in the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_hdf5(self, f):\n\n        if isinstance(f, str):\n            import h5py\n            f = h5py.File(f)\n\n        if self.frame is not None:\n            frame_group = f.create_group('frame')\n            frame_group.attrs['module'] = self.frame.__module__\n            frame_group.attrs['class'] = self.frame.__class__.__name__\n\n            units = [str(x).encode('utf8')\n                     for x in self.frame.units.to_dict().values()]\n            frame_group.create_dataset('units', data=units)\n\n            d = frame_group.create_group('parameters')\n            for k, par in self.frame.parameters.items():\n                quantity_to_hdf5(d, k, par)\n\n        cart = self.represent_as('cartesian')\n        quantity_to_hdf5(f, 'pos', cart.xyz)\n        quantity_to_hdf5(f, 'vel', cart.v_xyz)\n\n        return f", "response": "Serialize this object to an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_hdf5(cls, f):\n        if isinstance(f, str):\n            import h5py\n            f = h5py.File(f)\n\n        pos = quantity_from_hdf5(f['pos'])\n        vel = quantity_from_hdf5(f['vel'])\n\n        frame = None\n        if 'frame' in f:\n            g = f['frame']\n\n            frame_mod = g.attrs['module']\n            frame_cls = g.attrs['class']\n            frame_units = [u.Unit(x.decode('utf-8')) for x in g['units']]\n\n            if u.dimensionless_unscaled in frame_units:\n                units = DimensionlessUnitSystem()\n            else:\n                units = UnitSystem(*frame_units)\n\n            pars = dict()\n            for k in g['parameters']:\n                pars[k] = quantity_from_hdf5(g['parameters/'+k])\n\n            exec(\"from {0} import {1}\".format(frame_mod, frame_cls))\n            frame_cls = eval(frame_cls)\n\n            frame = frame_cls(units=units, **pars)\n\n        return cls(pos=pos, vel=vel, frame=frame)", "response": "Load an object from an HDF5 file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef angular_momentum(self):\n        cart = self.represent_as(coord.CartesianRepresentation)\n        return cart.pos.cross(cart.vel).xyz", "response": "r Compute the angular momentum for the phase - space positions contained in this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _plot_prepare(self, components, units):\n\n        # components to plot\n        if components is None:\n            components = self.pos.components\n        n_comps = len(components)\n\n        # if units not specified, get units from the components\n        if units is not None:\n            if isinstance(units, u.UnitBase):\n                units = [units]*n_comps # global unit\n\n            elif len(units) != n_comps:\n                raise ValueError('You must specify a unit for each axis, or a '\n                                 'single unit for all axes.')\n\n        labels = []\n        x = []\n        for i,name in enumerate(components):\n            val = getattr(self, name)\n\n            if units is not None:\n                val = val.to(units[i])\n                unit = units[i]\n            else:\n                unit = val.unit\n\n            if val.unit != u.one:\n                uu = unit.to_string(format='latex_inline')\n                unit_str = ' [{}]'.format(uu)\n            else:\n                unit_str = ''\n\n            # Figure out how to fancy display the component name\n            if name.startswith('d_'):\n                dot = True\n                name = name[2:]\n            else:\n                dot = False\n\n            if name in _greek_letters:\n                name = r\"\\{}\".format(name)\n\n            if dot:\n                name = \"\\dot{{{}}}\".format(name)\n\n            labels.append('${}$'.format(name) + unit_str)\n            x.append(val.value)\n\n        return x, labels", "response": "Prepare the PhaseSpacePosition or subclass for passing to a plotting\n            routine to plot all projections of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the components and velocities of the current state of the entry in the system.", "response": "def plot(self, components=None, units=None, auto_aspect=True, **kwargs):\n        \"\"\"\n        Plot the positions in all projections. This is a wrapper around\n        `~gala.dynamics.plot_projections` for fast access and quick\n        visualization. All extra keyword arguments are passed to that function\n        (the docstring for this function is included here for convenience).\n\n        Parameters\n        ----------\n        components : iterable (optional)\n            A list of component names (strings) to plot. By default, this is the\n            Cartesian positions ``['x', 'y', 'z']``. To plot Cartesian\n            velocities, pass in the velocity component names\n            ``['d_x', 'd_y', 'd_z']``.\n        units : `~astropy.units.UnitBase`, iterable (optional)\n            A single unit or list of units to display the components in.\n        auto_aspect : bool (optional)\n            Automatically enforce an equal aspect ratio.\n        relative_to : bool (optional)\n            Plot the values relative to this value or values.\n        autolim : bool (optional)\n            Automatically set the plot limits to be something sensible.\n        axes : array_like (optional)\n            Array of matplotlib Axes objects.\n        subplots_kwargs : dict (optional)\n            Dictionary of kwargs passed to :func:`~matplotlib.pyplot.subplots`.\n        labels : iterable (optional)\n            List or iterable of axis labels as strings. They should correspond to\n            the dimensions of the input orbit.\n        plot_function : callable (optional)\n            The ``matplotlib`` plot function to use. By default, this is\n            :func:`~matplotlib.pyplot.scatter`, but can also be, e.g.,\n            :func:`~matplotlib.pyplot.plot`.\n        **kwargs\n            All other keyword arguments are passed to the ``plot_function``.\n            You can pass in any of the usual style kwargs like ``color=...``,\n            ``marker=...``, etc.\n\n        Returns\n        -------\n        fig : `~matplotlib.Figure`\n\n        \"\"\"\n\n        try:\n            import matplotlib.pyplot as plt\n        except ImportError:\n            msg = 'matplotlib is required for visualization.'\n            raise ImportError(msg)\n\n        if components is None:\n            components = self.pos.components\n\n        x,labels = self._plot_prepare(components=components,\n                                      units=units)\n\n        default_kwargs = {\n            'marker': '.',\n            'labels': labels,\n            'plot_function': plt.scatter,\n            'autolim': False\n        }\n\n        for k,v in default_kwargs.items():\n            kwargs[k] = kwargs.get(k, v)\n\n        fig = plot_projections(x, **kwargs)\n\n        if self.pos.get_name() == 'cartesian' and \\\n                all([not c.startswith('d_') for c in components]) and \\\n                auto_aspect:\n            for ax in fig.axes:\n                ax.set(aspect='equal', adjustable='datalim')\n\n        return fig"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new account.", "response": "def create_account(self, email_address, password=None, client_id=None, client_secret=None):\n        ''' Create a new account.\n\n        If the account is created via an app, then Account.oauth will contain the\n        OAuth data that can be used to execute actions on behalf of the newly created account.\n\n        Args:\n            email_address (str):            Email address of the new account to create\n\n            password (str):                 [DEPRECATED] This parameter will be ignored\n\n            client_id (str, optional):      Client id of the app to use to create this account\n\n            client_secret (str, optional):  Secret of the app to use to create this account\n\n        Returns:\n            The new Account object\n\n        '''\n        request = self._get_request()\n\n        params = {\n            'email_address': email_address\n        }\n        if client_id:\n            params['client_id'] = client_id\n            params['client_secret'] = client_secret\n\n        response = request.post(self.ACCOUNT_CREATE_URL, params)\n\n        if 'oauth_data' in response:\n            response[\"account\"][\"oauth\"] = response['oauth_data']\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget information about the current account", "response": "def get_account_info(self):\n        ''' Get current account information\n\n        The information then will be saved in `self.account` so that you can\n        access the information like this:\n\n        >>> hsclient = HSClient()\n        >>> acct = hsclient.get_account_info()\n        >>> print acct.email_address\n\n        Returns:\n            An Account object\n\n        '''\n        request = self._get_request()\n        response = request.get(self.ACCOUNT_INFO_URL)\n        self.account.json_data = response[\"account\"]\n        return self.account"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the current account information.", "response": "def update_account_info(self):\n        ''' Update current account information\n\n        At the moment you can only update your callback_url.\n\n        Returns:\n            An Account object\n\n        '''\n        request = self._get_request()\n        return request.post(self.ACCOUNT_UPDATE_URL, {\n            'callback_url': self.account.callback_url\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_account(self, email_address):\n        ''' Verify whether a HelloSign Account exists\n\n            Args:\n\n                email_address (str): Email address for the account to verify\n\n            Returns:\n                True or False\n        '''\n        request = self._get_request()\n        resp = request.post(self.ACCOUNT_VERIFY_URL, {\n            'email_address': email_address\n        })\n        return ('account' in resp)", "response": "Verify whether a HelloSign Account exists in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_signature_request(self, signature_request_id, ux_version=None):\n        ''' Get a signature request by its ID\n\n        Args:\n\n            signature_request_id (str):     The id of the SignatureRequest to retrieve\n\n            ux_version (int):               UX version, either 1 (default) or 2.\n\n        Returns:\n            A SignatureRequest object\n\n        '''\n\n        request = self._get_request()\n        parameters = None\n\n        if ux_version is not None:\n            parameters = {\n                'ux_version': ux_version\n            }\n\n        return request.get(self.SIGNATURE_REQUEST_INFO_URL + signature_request_id, parameters=parameters)", "response": "Retrieves a SignatureRequest object by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_signature_request_list(self, page=1, ux_version=None):\n        ''' Get a list of SignatureRequest that you can access\n\n        This includes SignatureRequests you have sent as well as received, but\n        not ones that you have been CCed on.\n\n        Args:\n\n            page (int, optional):   Which page number of the SignatureRequest list to return. Defaults to 1.\n\n            ux_version (int):       UX version, either 1 (default) or 2.\n\n        Returns:\n            A ResourceList object\n\n        '''\n\n        request = self._get_request()\n        parameters = {\n            \"page\": page\n        }\n\n        if ux_version is not None:\n            parameters['ux_version'] = ux_version\n\n        return request.get(self.SIGNATURE_REQUEST_LIST_URL, parameters=parameters)", "response": "Get a list of SignatureRequest that you can access."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the PDF copy of the current documents and return the path or file object.", "response": "def get_signature_request_file(self, signature_request_id, path_or_file=None, file_type=None, filename=None):\n        ''' Download the PDF copy of the current documents\n\n        Args:\n\n            signature_request_id (str): Id of the signature request\n\n            path_or_file (str or file): A writable File-like object or a full path to save the PDF file to.\n\n            filename (str):             [DEPRECATED] Filename to save the PDF file to. This should be a full path.\n\n            file_type (str):            Type of file to return. Either \"pdf\" for a single merged document or \"zip\" for a collection of individual documents. Defaults to \"pdf\" if not specified.\n\n        Returns:\n            True if file is downloaded and successfully written, False otherwise.\n\n        '''\n        request = self._get_request()\n        url = self.SIGNATURE_REQUEST_DOWNLOAD_PDF_URL + signature_request_id\n        if file_type:\n            url += '?file_type=%s' % file_type\n        return request.get_file(url, path_or_file or filename)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_signature_request(self, test_mode=False, files=None, file_urls=None, title=None, subject=None, message=None, signing_redirect_url=None, signers=None, cc_email_addresses=None, form_fields_per_document=None, use_text_tags=False, hide_text_tags=False, metadata=None, ux_version=None, allow_decline=False):\n        ''' Creates and sends a new SignatureRequest with the submitted documents\n\n        Creates and sends a new SignatureRequest with the submitted documents.\n        If form_fields_per_document is not specified, a signature page will be\n        affixed where all signers will be required to add their signature,\n        signifying their agreement to all contained documents.\n\n        Args:\n\n            test_mode (bool, optional):             Whether this is a test, the signature request will not be legally binding if set to True. Defaults to False.\n\n            files (list of str):                    The uploaded file(s) to send for signature\n\n            file_urls (list of str):                URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            title (str, optional):                  The title you want to assign to the SignatureRequest\n\n            subject (str, optional):                The subject in the email that will be sent to the signers\n\n            message (str, optional):                The custom message in the email that will be sent to the signers\n\n            signing_redirect_url (str, optional):   The URL you want the signer redirected to after they successfully sign.\n\n            signers (list of dict):                 A list of signers, which each has the following attributes:\n\n                name (str):                         The name of the signer\n                email_address (str):                Email address of the signer\n                order (str, optional):              The order the signer is required to sign in\n                pin (str, optional):                The 4- to 12-character access code that will secure this signer's signature page\n\n            cc_email_addresses (list, optional):    A list of email addresses that should be CC'd\n\n            form_fields_per_document (str):         The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest)\n\n            use_text_tags (bool, optional):         Use text tags in the provided file(s) to create form fields\n\n            hide_text_tags (bool, optional):        Hide text tag areas\n\n            metadata (dict, optional):              Metadata to associate with the signature request\n\n            ux_version (int):                       UX version, either 1 (default) or 2.\n\n            allow_decline(bool, optional):         Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            A SignatureRequest object\n\n        '''\n\n        self._check_required_fields({\n            \"signers\": signers\n        }, [{\n            \"files\": files,\n            \"file_urls\": file_urls\n            }]\n        )\n\n        params = {\n            'test_mode': test_mode,\n            'files': files,\n            'file_urls': file_urls,\n            'title': title,\n            'subject': subject,\n            'message': message,\n            'signing_redirect_url': signing_redirect_url,\n            'signers': signers,\n            'cc_email_addresses': cc_email_addresses,\n            'form_fields_per_document': form_fields_per_document,\n            'use_text_tags': use_text_tags,\n            'hide_text_tags': hide_text_tags,\n            'metadata': metadata,\n            'allow_decline': allow_decline\n        }\n\n        if ux_version is not None:\n            params['ux_version'] = ux_version\n\n        return self._send_signature_request(**params)", "response": "Creates and sends a new SignatureRequest with the submitted documents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate and sends a new SignatureRequest based off of a Template and returns the ID of the template that was created with the template_id parameter.", "response": "def send_signature_request_with_template(self, test_mode=False, template_id=None, template_ids=None, title=None, subject=None, message=None, signing_redirect_url=None, signers=None, ccs=None, custom_fields=None, metadata=None, ux_version=None, allow_decline=False):\n        ''' Creates and sends a new SignatureRequest based off of a Template\n\n        Creates and sends a new SignatureRequest based off of the Template\n        specified with the template_id parameter.\n\n        Args:\n\n            test_mode (bool, optional):             Whether this is a test, the signature request will not be legally binding if set to True. Defaults to False.\n\n            template_id (str):                      The id of the Template to use when creating the SignatureRequest. Mutually exclusive with template_ids.\n\n            template_ids (list):                    The ids of the Templates to use when creating the SignatureRequest. Mutually exclusive with template_id.\n\n            title (str, optional):                  The title you want to assign to the SignatureRequest\n\n            subject (str, optional):                The subject in the email that will be sent to the signers\n\n            message (str, optional):                The custom message in the email that will be sent to the signers\n\n            signing_redirect_url (str, optional):   The URL you want the signer redirected to after they successfully sign.\n\n            signers (list of dict):                 A list of signers, which each has the following attributes:\n\n                role_name (str):                    Signer role\n                name (str):                         The name of the signer\n                email_address (str):                Email address of the signer\n                pin (str, optional):                The 4- to 12-character access code that will secure this signer's signature page\n\n            ccs (list of str, optional):            The email address of the CC filling the role of RoleName. Required when a CC role exists for the Template. Each dict has the following attributes:\n\n                role_name (str):                    CC role name\n                email_address (str):                CC email address\n\n            custom_fields (list of dict, optional): A list of custom fields. Required when a CustomField exists in the Template. An item of the list should look like this: `{'name: value'}`\n\n            metadata (dict, optional):              Metadata to associate with the signature request\n\n            ux_version (int):                       UX version, either 1 (default) or 2.\n\n            allow_decline (bool, optional):         Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            A SignatureRequest object\n\n        '''\n\n        self._check_required_fields({\n            \"signers\": signers\n        }, [{\n            \"template_id\": template_id,\n            \"template_ids\": template_ids\n            }]\n        )\n\n        params = {\n            'test_mode': test_mode,\n            'template_id': template_id,\n            'template_ids': template_ids,\n            'title': title,\n            'subject': subject,\n            'message': message,\n            'signing_redirect_url': signing_redirect_url,\n            'signers': signers,\n            'ccs': ccs,\n            'custom_fields': custom_fields,\n            'metadata': metadata,\n            'allow_decline': allow_decline\n        }\n\n        if ux_version is not None:\n            params['ux_version'] = ux_version\n\n        return self._send_signature_request_with_template(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an email to the signer to remind the signature request for the specified email address.", "response": "def remind_signature_request(self, signature_request_id, email_address):\n        ''' Sends an email to the signer reminding them to sign the signature request\n\n        Sends an email to the signer reminding them to sign the signature\n        request. You cannot send a reminder within 1 hours of the last reminder\n        that was sent. This includes manual AND automatic reminders.\n\n        Args:\n\n            signature_request_id (str): The id of the SignatureRequest to send a reminder for\n\n            email_address (str):        The email address of the signer to send a reminder to\n\n        Returns:\n            A SignatureRequest object\n\n        '''\n        request = self._get_request()\n        return request.post(self.SIGNATURE_REQUEST_REMIND_URL + signature_request_id, data={\n            \"email_address\": email_address\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cancel_signature_request(self, signature_request_id):\n        ''' Cancels a SignatureRequest\n\n        Cancels a SignatureRequest. After canceling, no one will be able to sign\n        or access the SignatureRequest or its documents. Only the requester can\n        cancel and only before everyone has signed.\n\n        Args:\n\n            signing_request_id (str): The id of the signature request to cancel\n\n        Returns:\n            None\n\n        '''\n        request = self._get_request()\n        request.post(url=self.SIGNATURE_REQUEST_CANCEL_URL + signature_request_id, get_json=False)", "response": "Cancels a SignatureRequest\n\n        Cancels a SignatureRequest. After canceling, no one will be able to sign\n        or access the SignatureRequest or its documents. Only the requester can\n        cancel and only before everyone has signed.\n\n        Args:\n\n            signing_request_id (str): The id of the signature request to cancel\n\n        Returns:\n            None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a Template which includes a list of Accounts that can access it", "response": "def get_template(self, template_id):\n        ''' Gets a Template which includes a list of Accounts that can access it\n\n        Args:\n\n            template_id (str): The id of the template to retrieve\n\n        Returns:\n            A Template object\n\n        '''\n        request = self._get_request()\n        return request.get(self.TEMPLATE_GET_URL + template_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting your Templates and returns a ResourceList object.", "response": "def get_template_list(self, page=1, page_size=None, account_id=None, query=None):\n        ''' Lists your Templates\n\n        Args:\n\n            page (int, optional):           Page number of the template List to return. Defaults to 1.\n            page_size (int, optional):      Number of objects to be returned per page, must be between 1 and 100, default is 20.\n            account_id (str, optional):     Which account to return Templates for. Must be a team member. Use \"all\" to indicate all team members. Defaults to your account.\n            query (str, optional):          String that includes search terms and/or fields to be used to filter the Template objects.\n\n        Returns:\n            A ResourceList object\n\n        '''\n        request = self._get_request()\n        parameters = {\n            'page': page,\n            'page_size': page_size,\n            'account_id': account_id,\n            'query': query\n        }\n        return request.get(self.TEMPLATE_GET_LIST_URL, parameters=parameters)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_user_to_template(self, template_id, account_id=None, email_address=None):\n        ''' Gives the specified Account access to the specified Template\n\n        Args:\n\n            template_id (str):      The id of the template to give the account access to\n\n            account_id (str):       The id of the account to give access to the template. The account id prevails if both account_id and email_address are provided.\n\n            email_address (str):    The email address of the account to give access to.\n\n        Returns:\n            A Template object\n\n        '''\n        return self._add_remove_user_template(self.TEMPLATE_ADD_USER_URL, template_id, account_id, email_address)", "response": "Gives the specified Account access to the specified Template\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the specified Account s access to the specified Template.", "response": "def remove_user_from_template(self, template_id, account_id=None, email_address=None):\n        ''' Removes the specified Account's access to the specified Template\n\n        Args:\n\n            template_id (str):      The id of the template to remove the account's access from.\n\n            account_id (str):       The id of the account to remove access from the template. The account id prevails if both account_id and email_address are provided.\n\n            email_address (str):    The email address of the account to remove access from.\n\n        Returns:\n            An Template object\n\n        '''\n        return self._add_remove_user_template(self.TEMPLATE_REMOVE_USER_URL, template_id, account_id, email_address)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the specified template", "response": "def delete_template(self, template_id):\n        ''' Deletes the specified template\n\n        Args:\n\n            template_id (str): The id of the template to delete\n\n        Returns:\n            A status code\n\n        '''\n\n        url = self.TEMPLATE_DELETE_URL\n\n        request = self._get_request()\n        response = request.post(url + template_id, get_json=False)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading a PDF copy of a template s original files", "response": "def get_template_files(self, template_id, filename):\n        ''' Download a PDF copy of a template's original files\n\n        Args:\n\n            template_id (str):  The id of the template to retrieve.\n\n            filename (str):     Filename to save the PDF file to. This should be a full path.\n\n        Returns:\n            Returns a PDF file\n\n        '''\n\n        url = self.TEMPLATE_GET_FILES_URL + template_id\n        request = self._get_request()\n\n        return request.get_file(url, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an embedded Template draft for further editing.", "response": "def create_embedded_template_draft(self, client_id, signer_roles, test_mode=False, files=None, file_urls=None, title=None, subject=None, message=None, cc_roles=None, merge_fields=None, use_preexisting_fields=False):\n        ''' Creates an embedded Template draft for further editing.\n\n        Args:\n\n            test_mode (bool, optional):         Whether this is a test, the signature request created from this draft will not be legally binding if set to 1. Defaults to 0.\n\n            client_id (str):                    Client id of the app you're using to create this draft.\n\n            files (list of str):                The file(s) to use for the template.\n\n            file_urls (list of str):            URLs of the file for HelloSign to use for the template. Use either `files` or `file_urls`, but not both.\n\n            title (str, optional):              The template title\n\n            subject (str, optional):            The default template email subject\n\n            message (str, optional):            The default template email message\n\n            signer_roles (list of dict):        A list of signer roles, each of which has the following attributes:\n\n                name (str):                     The role name of the signer that will be displayed when the template is used to create a signature request.\n                order (str, optional):          The order in which this signer role is required to sign.\n\n            cc_roles (list of str, optional):   The CC roles that must be assigned when using the template to send a signature request\n\n            merge_fields (list of dict, optional): The merge fields that can be placed on the template's document(s) by the user claiming the template draft. Each must have the following two parameters:\n\n                name (str):                     The name of the merge field. Must be unique.\n                type (str):                     Can only be \"text\" or \"checkbox\".\n\n            use_preexisting_fields (bool):      Whether to use preexisting PDF fields\n\n        Returns:\n            A Template object specifying the Id of the draft\n\n        '''\n        params = {\n            'test_mode': test_mode,\n            'client_id': client_id,\n            'files': files,\n            'file_urls': file_urls,\n            'title': title,\n            'subject': subject,\n            'message': message,\n            'signer_roles': signer_roles,\n            'cc_roles': cc_roles,\n            'merge_fields': merge_fields,\n            'use_preexisting_fields': use_preexisting_fields\n        }\n\n        return self._create_embedded_template_draft(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_team(self, name):\n        ''' Creates a new Team\n\n        Creates a new Team and makes you a member. You must not currently belong to a team to invoke.\n\n        Args:\n\n            name (str): The name of your team\n\n        Returns:\n            A Team object\n\n        '''\n        request = self._get_request()\n        return request.post(self.TEAM_CREATE_URL, {\"name\": name})", "response": "Creates a new Team and makes you a member."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a Team s name with the new name.", "response": "def update_team_name(self, name):\n        ''' Updates a Team's name\n\n        Args:\n\n            name (str): The new name of your team\n\n        Returns:\n            A Team object\n\n        '''\n        request = self._get_request()\n        return request.post(self.TEAM_UPDATE_URL, {\"name\": name})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes your Team Deletes your Team. Can only be invoked when you have a team with only one member left (yourself). Returns: None", "response": "def destroy_team(self):\n        ''' Delete your Team\n\n        Deletes your Team. Can only be invoked when you have a team with only one member left (yourself).\n\n        Returns:\n            None\n\n        '''\n        request = self._get_request()\n        request.post(url=self.TEAM_DESTROY_URL, get_json=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_team_member(self, account_id=None, email_address=None):\n        ''' Add or invite a user to your Team\n\n        Args:\n\n            account_id (str):       The id of the account of the user to invite to your team.\n\n            email_address (str):    The email address of the account to invite to your team. The account id prevails if both account_id and email_address are provided.\n\n        Returns:\n            A Team object\n\n        '''\n        return self._add_remove_team_member(self.TEAM_ADD_MEMBER_URL, email_address, account_id)", "response": "Add or invite a user to your Team"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_team_member(self, account_id=None, email_address=None):\n        ''' Remove a user from your Team\n\n        Args:\n\n            account_id (str):       The id of the account of the user to remove from your team.\n\n            email_address (str):    The email address of the account to remove from your team. The account id prevails if both account_id and email_address are provided.\n\n        Returns:\n            A Team object\n\n        '''\n        return self._add_remove_team_member(self.TEAM_REMOVE_MEMBER_URL, email_address, account_id)", "response": "Removes a user from your Team"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving an embedded object containing a signature url that can be opened in an iFrame.", "response": "def get_embedded_object(self, signature_id):\n        ''' Retrieves a embedded signing object\n\n        Retrieves an embedded object containing a signature url that can be opened in an iFrame.\n\n        Args:\n\n            signature_id (str): The id of the signature to get a signature url for\n\n        Returns:\n            An Embedded object\n\n        '''\n        request = self._get_request()\n        return request.get(self.EMBEDDED_OBJECT_GET_URL + signature_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve an embedded template for editing a template.", "response": "def get_template_edit_url(self, template_id):\n        ''' Retrieves a embedded template for editing\n\n        Retrieves an embedded object containing a template url that can be opened in an iFrame.\n\n        Args:\n\n            template_id (str): The id of the template to get a signature url for\n\n        Returns:\n            An Embedded object\n\n        '''\n        request = self._get_request()\n        return request.get(self.EMBEDDED_TEMPLATE_EDIT_URL + template_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_unclaimed_draft(self, test_mode=False, files=None, file_urls=None, draft_type=None, subject=None, message=None, signers=None, cc_email_addresses=None, signing_redirect_url=None, form_fields_per_document=None, metadata=None, use_preexisting_fields=False, allow_decline=False):\n        ''' Creates a new Draft that can be claimed using the claim URL\n\n        Creates a new Draft that can be claimed using the claim URL. The first\n        authenticated user to access the URL will claim the Draft and will be\n        shown either the \"Sign and send\" or the \"Request signature\" page with\n        the Draft loaded. Subsequent access to the claim URL will result in a\n        404. If the type is \"send_document\" then only the file parameter is\n        required. If the type is \"request_signature\", then the identities of the\n        signers and optionally the location of signing elements on the page are\n        also required.\n\n        Args:\n\n            test_mode (bool, optional):                 Whether this is a test, the signature request created from this draft will not be legally binding if set to True. Defaults to False.\n\n            files (list of str):                        The uploaded file(s) to send for signature\n\n            file_urls (list of str):                    URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            draft_type (str):                           The type of unclaimed draft to create. Use \"send_document\" to create a claimable file, and \"request_signature\" for a claimable signature request. If the type is \"request_signature\" then signers name and email_address are not optional.\n\n            subject (str, optional):                    The subject in the email that will be sent to the signers\n\n            message (str, optional):                    The custom message in the email that will be sent to the signers\n\n            signers (list of dict):                     A list of signers, which each has the following attributes:\n\n                name (str):                             The name of the signer\n                email_address (str):                    Email address of the signer\n                order (str, optional):                  The order the signer is required to sign in\n\n            cc_email_addresses (list of str, optional): A list of email addresses that should be CC'd\n\n            signing_redirect_url (str, optional):       The URL you want the signer redirected to after they successfully sign.\n\n            form_fields_per_document (str, optional):   The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest)\n\n            metadata (dict, optional):                  Metadata to associate with the draft\n\n            use_preexisting_fields (bool):              Whether to use preexisting PDF fields\n\n            allow_decline (bool, optional):             Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            An UnclaimedDraft object\n\n        '''\n\n        self._check_required_fields({\n            'draft_type': draft_type\n        }, [{\n            \"files\": files,\n            \"file_urls\": file_urls\n            }]\n        )\n\n        params = {\n            'test_mode': test_mode,\n            'files': files,\n            'file_urls': file_urls,\n            'draft_type': draft_type,\n            'subject': subject,\n            'message': message,\n            'signing_redirect_url': signing_redirect_url,\n            'signers': signers,\n            'cc_email_addresses': cc_email_addresses,\n            'form_fields_per_document': form_fields_per_document,\n            'metadata': metadata,\n            'use_preexisting_fields': use_preexisting_fields,\n            'allow_decline': allow_decline\n        }\n\n        return self._create_unclaimed_draft(**params)", "response": "Creates a new unclaimed draft."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_embedded_unclaimed_draft(self, test_mode=False, client_id=None, is_for_embedded_signing=False, requester_email_address=None, files=None, file_urls=None, draft_type=None, subject=None, message=None, signers=None, cc_email_addresses=None, signing_redirect_url=None, requesting_redirect_url=None, form_fields_per_document=None, metadata=None, use_preexisting_fields=False, allow_decline=False):\n        ''' Creates a new Draft to be used for embedded requesting\n\n        Args:\n\n            test_mode (bool, optional):                 Whether this is a test, the signature request created from this draft will not be legally binding if set to True. Defaults to False.\n\n            client_id (str):                            Client id of the app used to create the embedded draft.\n\n            is_for_embedded_signing (bool, optional):   Whether this is also for embedded signing. Defaults to False.\n\n            requester_email_address (str):              Email address of the requester.\n\n            files (list of str):                        The uploaded file(s) to send for signature.\n\n            file_urls (list of str):                    URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            draft_type (str):                           The type of unclaimed draft to create. Use \"send_document\" to create a claimable file, and \"request_signature\" for a claimable signature request. If the type is \"request_signature\" then signers name and email_address are not optional.\n\n            subject (str, optional):                    The subject in the email that will be sent to the signers\n\n            message (str, optional):                    The custom message in the email that will be sent to the signers\n\n            signers (list of dict):                     A list of signers, which each has the following attributes:\n\n                name (str):                             The name of the signer\n                email_address (str):                    Email address of the signer\n                order (str, optional):                  The order the signer is required to sign in\n\n            cc_email_addresses (list of str, optional): A list of email addresses that should be CC'd\n\n            signing_redirect_url (str, optional):       The URL you want the signer redirected to after they successfully sign.\n\n            requesting_redirect_url (str, optional):    The URL you want the signer to be redirected to after the request has been sent.\n\n            form_fields_per_document (str, optional):   The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest)\n\n            metadata (dict, optional):                  Metadata to associate with the draft\n\n            use_preexisting_fields (bool):              Whether to use preexisting PDF fields\n\n            allow_decline (bool, optional):             Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            An UnclaimedDraft object\n\n        '''\n\n        self._check_required_fields({\n            'client_id': client_id,\n            'requester_email_address': requester_email_address,\n            'draft_type': draft_type\n        }, [{\n            \"files\": files,\n            \"file_urls\": file_urls\n            }]\n        )\n\n        params = {\n            'test_mode': test_mode,\n            'client_id': client_id,\n            'requester_email_address': requester_email_address,\n            'is_for_embedded_signing': is_for_embedded_signing,\n            'files': files,\n            'file_urls': file_urls,\n            'draft_type': draft_type,\n            'subject': subject,\n            'message': message,\n            'signing_redirect_url': signing_redirect_url,\n            'requesting_redirect_url': requesting_redirect_url,\n            'signers': signers,\n            'cc_email_addresses': cc_email_addresses,\n            'form_fields_per_document': form_fields_per_document,\n            'metadata': metadata,\n            'use_preexisting_fields': use_preexisting_fields,\n            'allow_decline': allow_decline\n        }\n\n        return self._create_unclaimed_draft(**params)", "response": "Creates a new Draft that is used for embedded request signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Unclaimed Draft with a template.", "response": "def create_embedded_unclaimed_draft_with_template(self, test_mode=False, client_id=None, is_for_embedded_signing=False, template_id=None, template_ids=None, requester_email_address=None, title=None, subject=None, message=None, signers=None, ccs=None, signing_redirect_url=None, requesting_redirect_url=None, metadata=None, custom_fields=None, allow_decline=False):\n        ''' Creates a new Draft to be used for embedded requesting\n\n            Args:\n\n                test_mode (bool, optional):                 Whether this is a test, the signature request created from this draft will not be legally binding if set to True. Defaults to False.\n\n                client_id (str):                            Client id of the app you're using to create this draft. Visit our embedded page to learn more about this parameter.\n\n                template_id (str):                          The id of the Template to use when creating the Unclaimed Draft. Mutually exclusive with template_ids.\n\n                template_ids (list of str):                 The ids of the Templates to use when creating the Unclaimed Draft. Mutually exclusive with template_id.\n\n                requester_email_address (str):              The email address of the user that should be designated as the requester of this draft, if the draft type is \"request_signature.\"\n\n                title (str, optional):                      The title you want to assign to the Unclaimed Draft\n\n                subject (str, optional):                    The subject in the email that will be sent to the signers\n\n                message (str, optional):                    The custom message in the email that will be sent to the signers\n\n                signers (list of dict):                     A list of signers, which each has the following attributes:\n\n                    name (str):                             The name of the signer\n                    email_address (str):                    Email address of the signer\n\n                ccs (list of str, optional):                A list of email addresses that should be CC'd\n\n                signing_redirect_url (str, optional):       The URL you want the signer redirected to after they successfully sign.\n\n                requesting_redirect_url (str, optional):    The URL you want the signer to be redirected to after the request has been sent.\n\n                is_for_embedded_signing (bool, optional):   The request created from this draft will also be signable in embedded mode if set to True. The default is False.\n\n                metadata (dict, optional):                  Metadata to associate with the draft. Each request can include up to 10 metadata keys, with key names up to 40 characters long and values up to 500 characters long.\n\n                custom_fields (list of dict, optional):     A list of custom fields. Required when a CustomField exists in the Template. An item of the list should look like this: `{'name: value'}`\n\n                allow_decline (bool, optional):             Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        '''\n\n        self._check_required_fields({\n            \"client_id\": client_id,\n            \"requester_email_address\": requester_email_address\n        }, [{\n            \"template_id\": template_id,\n            \"template_ids\": template_ids\n            }]\n        )\n\n        params = {\n            'test_mode': test_mode,\n            'client_id': client_id,\n            'is_for_embedded_signing': is_for_embedded_signing,\n            'template_id': template_id,\n            'template_ids': template_ids,\n            'title': title,\n            'subject': subject,\n            'message': message,\n            'requester_email_address': requester_email_address,\n            'signing_redirect_url': signing_redirect_url,\n            'requesting_redirect_url': requesting_redirect_url,\n            'signers': signers,\n            'ccs': ccs,\n            'custom_fields': custom_fields,\n            'metadata': metadata,\n            'allow_decline': allow_decline\n        }\n\n        return self._create_embedded_unclaimed_draft_with_template(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_oauth_data(self, code, client_id, client_secret, state):\n        ''' Get Oauth data from HelloSign\n\n        Args:\n\n            code (str):             Code returned by HelloSign for our callback url\n\n            client_id (str):        Client id of the associated app\n\n            client_secret (str):    Secret token of the associated app\n\n        Returns:\n            A HSAccessTokenAuth object\n\n        '''\n        request = self._get_request()\n        response = request.post(self.OAUTH_TOKEN_URL, {\n            \"state\": state,\n            \"code\": code,\n            \"grant_type\": \"authorization_code\",\n            \"client_id\": client_id,\n            \"client_secret\": client_secret\n        })\n        return HSAccessTokenAuth.from_response(response)", "response": "Get Oauth data from HelloSign"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh_access_token(self, refresh_token):\n        ''' Refreshes the current access token.\n\n            Gets a new access token, updates client auth and returns it.\n\n        Args:\n\n            refresh_token (str): Refresh token to use\n\n        Returns:\n            The new access token\n        '''\n        request = self._get_request()\n        response = request.post(self.OAUTH_TOKEN_URL, {\n            \"grant_type\": \"refresh_token\",\n            \"refresh_token\": refresh_token\n        })\n        self.auth = HSAccessTokenAuth.from_response(response)\n        return self.auth.access_token", "response": "Refreshes the current access token. Returns the new access token."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an http request object for the current object holding the necessary attributes.", "response": "def _get_request(self, auth=None):\n        ''' Return an http request object\n\n            auth: Auth data to use\n\n            Returns:\n                A HSRequest object\n        '''\n        self.request = HSRequest(auth or self.auth, self.env)\n        self.request.response_callback = self.response_callback\n        return self.request"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates authentication object to send requests to the application.", "response": "def _authenticate(self, email_address=None, password=None, api_key=None, access_token=None, access_token_type=None):\n        ''' Create authentication object to send requests\n\n        Args:\n\n            email_address (str):        Email address of the account to make the requests\n\n            password (str):             Password of the account used with email address\n\n            api_key (str):              API Key. You can find your API key in https://www.hellosign.com/home/myAccount/current_tab/integrations\n\n            access_token (str):         OAuth access token\n\n            access_token_type (str):    Type of OAuth access token\n\n        Raises:\n            NoAuthMethod: If no authentication information found\n\n        Returns:\n            A HTTPBasicAuth or HSAccessTokenAuth object\n\n        '''\n\n        if access_token_type and access_token:\n            return HSAccessTokenAuth(access_token, access_token_type)\n        elif api_key:\n            return HTTPBasicAuth(api_key, '')\n        elif email_address and password:\n            return HTTPBasicAuth(email_address, password)\n        else:\n            raise NoAuthMethod(\"No authentication information found!\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_required_fields(self, fields=None, either_fields=None):\n        ''' Check the values of the fields\n\n        If no value found in `fields`, an exception will be raised.\n        `either_fields` are the fields that one of them must have a value\n\n        Raises:\n            HSException: If no value found in at least one item of`fields`, or\n                no value found in one of the items of `either_fields`\n\n        Returns:\n            None\n\n        '''\n\n        for (key, value) in fields.items():\n            # If value is a dict, one of the fields in the dict is required ->\n            # exception if all are None\n            if not value:\n                raise HSException(\"Field '%s' is required.\" % key)\n        if either_fields is not None:\n            for field in either_fields:\n                if not any(field.values()):\n                    raise HSException(\"One of the following fields is required: %s\" % \", \".join(field.keys()))", "response": "Check the values of the fields that one of them must have a value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_signature_request(self, test_mode=False, client_id=None, files=None, file_urls=None, title=None, subject=None, message=None, signing_redirect_url=None, signers=None, cc_email_addresses=None, form_fields_per_document=None, use_text_tags=False, hide_text_tags=False, metadata=None, ux_version=None, allow_decline=False):\n        ''' To share the same logic between send_signature_request &\n            send_signature_request_embedded functions\n\n        Args:\n\n            test_mode (bool, optional):             Whether this is a test, the signature request will not be legally binding if set to True. Defaults to False.\n\n            client_id (str):                        Client id of the app you're using to create this embedded signature request. Visit the embedded page to learn more about this parameter (https://www.hellosign.com/api/embeddedSigningWalkthrough)\n\n            files (list of str):                    The uploaded file(s) to send for signature\n\n            file_urls (list of str):                URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            title (str, optional):                  The title you want to assign to the SignatureRequest\n\n            subject (str, optional):                The subject in the email that will be sent to the signers\n\n            message (str, optional):                The custom message in the email that will be sent to the signers\n\n            signing_redirect_url (str, optional):   The URL you want the signer redirected to after they successfully sign\n\n            signers (list of dict):                 A list of signers, which each has the following attributes:\n\n                name (str):                         The name of the signer\n                email_address (str):                Email address of the signer\n                order (str, optional):              The order the signer is required to sign in\n                pin (str, optional):                The 4- to 12-character access code that will secure this signer's signature page\n\n            cc_email_addresses (list, optional):    A list of email addresses that should be CCed\n\n            form_fields_per_document (str):         The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest)\n\n            use_text_tags (bool, optional):         Use text tags in the provided file(s) to create form fields\n\n            hide_text_tags (bool, optional):        Hide text tag areas\n\n            metadata (dict, optional):              Metadata to associate with the signature request\n\n            ux_version (int):                       UX version, either 1 (default) or 2.\n\n            allow_decline (bool, optional);         Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            A SignatureRequest object\n\n        '''\n\n        # Files\n        files_payload = HSFormat.format_file_params(files)\n\n        # File URLs\n        file_urls_payload = HSFormat.format_file_url_params(file_urls)\n\n        # Signers\n        signers_payload = HSFormat.format_dict_list(signers, 'signers')\n\n        # CCs\n        cc_email_addresses_payload = HSFormat.format_param_list(cc_email_addresses, 'cc_email_addresses')\n\n        # Metadata\n        metadata_payload = HSFormat.format_single_dict(metadata, 'metadata')\n\n        payload = {\n            \"test_mode\": self._boolean(test_mode),\n            \"client_id\": client_id,\n            \"title\": title,\n            \"subject\": subject,\n            \"message\": message,\n            \"signing_redirect_url\": signing_redirect_url,\n            \"form_fields_per_document\": form_fields_per_document,\n            \"use_text_tags\": self._boolean(use_text_tags),\n            \"hide_text_tags\": self._boolean(hide_text_tags),\n            \"allow_decline\": self._boolean(allow_decline)\n        }\n\n        if ux_version is not None:\n            payload['ux_version'] = ux_version\n\n        # remove attributes with none value\n        payload = HSFormat.strip_none_values(payload)\n\n        url = self.SIGNATURE_REQUEST_CREATE_URL\n        if client_id:\n            url = self.SIGNATURE_REQUEST_CREATE_EMBEDDED_URL\n\n        data = {}\n        data.update(payload)\n        data.update(signers_payload)\n        data.update(cc_email_addresses_payload)\n        data.update(file_urls_payload)\n        data.update(metadata_payload)\n\n        request = self._get_request()\n        response = request.post(url, data=data, files=files_payload)\n        return response", "response": "This function is used to send a signature request to the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new Draft that can be claimed using the claim URL Args: test_mode (bool, optional): Whether this is a test, the signature request created from this draft will not be legally binding if set to True. Defaults to False. client_id (str): Client id of the app used to create the embedded draft. is_for_embedded_signing (bool): Whether this is for embedded signing on top of being for embedded requesting. requester_email_address (str): Email address of the requester when creating a draft for embedded requesting. files (list of str): The uploaded file(s) to send for signature. file_urls (list of str): URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls` draft_type (str): The type of unclaimed draft to create. Use \"send_document\" to create a claimable file, and \"request_signature\" for a claimable signature request. If the type is \"request_signature\" then signers name and email_address are not optional. subject (str, optional): The subject in the email that will be sent to the signers message (str, optional): The custom message in the email that will be sent to the signers signers (list of dict): A list of signers, which each has the following attributes: name (str): The name of the signer email_address (str): Email address of the signer order (str, optional): The order the signer is required to sign in cc_email_addresses (list of str, optional): A list of email addresses that should be CC'd signing_redirect_url (str, optional): The URL you want the signer redirected to after they successfully sign. requesting_redirect_url (str, optional): The URL you want the signer to be redirected to after the request has been sent. form_fields_per_document (str): The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest). metadata (dict, optional): Metadata to associate with the draft use_preexisting_fields (bool): Whether to use preexisting PDF fields allow_decline (bool, optional): Allows signers to decline to sign a document if set to 1. Defaults to 0. Returns: An UnclaimedDraft object", "response": "def _create_unclaimed_draft(self, test_mode=False, client_id=None, is_for_embedded_signing=False, requester_email_address=None, files=None, file_urls=None, draft_type=None, subject=None, message=None, signers=None, cc_email_addresses=None, signing_redirect_url=None, requesting_redirect_url=None, form_fields_per_document=None, metadata=None, use_preexisting_fields=False, allow_decline=False):\n        ''' Creates a new Draft that can be claimed using the claim URL\n\n        Args:\n\n            test_mode (bool, optional):                     Whether this is a test, the signature request created from this draft will not be legally binding if set to True. Defaults to False.\n\n            client_id (str):                                Client id of the app used to create the embedded draft.\n\n            is_for_embedded_signing (bool):                 Whether this is for embedded signing on top of being for embedded requesting.\n\n            requester_email_address (str):                  Email address of the requester when creating a draft for embedded requesting.\n\n            files (list of str):                            The uploaded file(s) to send for signature.\n\n            file_urls (list of str):                        URLs of the file for HelloSign to download to send for signature. Use either `files` or `file_urls`\n\n            draft_type (str):                               The type of unclaimed draft to create. Use \"send_document\" to create a claimable file, and \"request_signature\" for a claimable signature request. If the type is \"request_signature\" then signers name and email_address are not optional.\n\n            subject (str, optional):                        The subject in the email that will be sent to the signers\n\n            message (str, optional):                        The custom message in the email that will be sent to the signers\n\n            signers (list of dict):                         A list of signers, which each has the following attributes:\n\n                name (str):                                 The name of the signer\n                email_address (str):                        Email address of the signer\n                order (str, optional):                      The order the signer is required to sign in\n\n            cc_email_addresses (list of str, optional):     A list of email addresses that should be CC'd\n\n            signing_redirect_url (str, optional):           The URL you want the signer redirected to after they successfully sign.\n\n            requesting_redirect_url (str, optional):        The URL you want the signer to be redirected to after the request has been sent.\n\n            form_fields_per_document (str):                 The fields that should appear on the document, expressed as a serialized JSON data structure which is a list of lists of the form fields. Please refer to the API reference of HelloSign for more details (https://www.hellosign.com/api/reference#SignatureRequest).\n\n            metadata (dict, optional):                      Metadata to associate with the draft\n\n            use_preexisting_fields (bool):                  Whether to use preexisting PDF fields\n\n            allow_decline (bool, optional):                 Allows signers to decline to sign a document if set to 1. Defaults to 0.\n\n        Returns:\n            An UnclaimedDraft object\n\n        '''\n\n        # Files\n        files_payload = HSFormat.format_file_params(files)\n\n        # Files URLs\n        file_urls_payload = HSFormat.format_file_url_params(file_urls)\n\n        # Signers\n        signers_payload = {}\n        if signers:\n            for (idx, signer) in enumerate(signers):\n                if draft_type == UnclaimedDraft.UNCLAIMED_DRAFT_REQUEST_SIGNATURE_TYPE:\n                    if \"name\" not in signer and \"email_address\" not in signer:\n                        raise HSException(\"Signer's name and email are required\")\n            signers_payload = HSFormat.format_dict_list(signers, 'signers')\n\n        # CCs\n        cc_email_addresses_payload = HSFormat.format_param_list(cc_email_addresses, 'cc_email_addresses')\n\n        # Metadata\n        metadata_payload = HSFormat.format_single_dict(metadata, 'metadata')\n\n        payload = {\n            \"test_mode\": self._boolean(test_mode),\n            \"type\": draft_type,\n            \"subject\": subject,\n            \"message\": message,\n            \"signing_redirect_url\": signing_redirect_url,\n            \"form_fields_per_document\": form_fields_per_document,\n            \"use_preexisting_fields\": self._boolean(use_preexisting_fields),\n            \"allow_decline\": self._boolean(allow_decline)\n        }\n\n        url = self.UNCLAIMED_DRAFT_CREATE_URL\n\n        if client_id is not None:\n            payload.update({\n                'client_id': client_id,\n                'is_for_embedded_signing': '1' if is_for_embedded_signing else '0',\n                'requester_email_address': requester_email_address,\n                'requesting_redirect_url': requesting_redirect_url\n            })\n            url = self.UNCLAIMED_DRAFT_CREATE_EMBEDDED_URL\n\n        # remove attributes with none value\n        payload = HSFormat.strip_none_values(payload)\n\n        data = payload.copy()\n        data.update(signers_payload)\n        data.update(cc_email_addresses_payload)\n        data.update(file_urls_payload)\n        data.update(metadata_payload)\n\n        request = self._get_request()\n        response = request.post(url, data=data, files=files_payload)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_remove_user_template(self, url, template_id, account_id=None, email_address=None):\n        ''' Add or Remove user from a Template\n\n        We use this function for two tasks because they have the same API call\n\n        Args:\n\n            template_id (str):      The id of the template\n\n            account_id (str):       ID of the account to add/remove access to/from\n\n            email_address (str):    The email_address of the account to add/remove access to/from\n\n        Raises:\n            HSException: If no email address or account_id specified\n\n        Returns:\n            A Template object\n\n        '''\n\n        if not email_address and not account_id:\n            raise HSException(\"No email address or account_id specified\")\n\n        data = {}\n        if account_id is not None:\n            data = {\n                \"account_id\": account_id\n            }\n        else:\n            data = {\n                \"email_address\": email_address\n            }\n\n        request = self._get_request()\n        response = request.post(url + template_id, data)\n\n        return response", "response": "Add or Remove user from a Template object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_remove_team_member(self, url, email_address=None, account_id=None):\n        ''' Add or Remove a team member\n\n        We use this function for two different tasks because they have the same\n        API call\n\n        Args:\n\n            email_address (str):    Email address of the Account to add/remove\n\n            account_id (str):       ID of the Account to add/remove\n\n        Returns:\n            A Team object\n\n        '''\n\n        if not email_address and not account_id:\n            raise HSException(\"No email address or account_id specified\")\n\n        data = {}\n        if account_id is not None:\n            data = {\n                \"account_id\": account_id\n            }\n        else:\n            data = {\n                \"email_address\": email_address\n            }\n\n        request = self._get_request()\n        response = request.post(url, data)\n\n        return response", "response": "Add or Remove a team member from the specified account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_file(self, url, path_or_file=None, headers=None, filename=None):\n        ''' Get a file from a url and save it as `filename`\n\n        Args:\n            url (str): URL to send the request to\n\n            path_or_file (str or file): A writable File-like object or a path to save the file to.\n\n            filename (str): [DEPRECATED] File name to save the file as, this can be either\n                a full path or a relative path\n\n            headers (str, optional): custom headers\n\n        Returns:\n            True if file is downloaded and written successfully, False\n            otherwise.\n\n        '''\n        path_or_file = path_or_file or filename\n\n        if self.debug:\n            print(\"GET FILE: %s, headers=%s\" % (url, headers))\n\n        self.headers = self._get_default_headers()\n        if headers is not None:\n            self.headers.update(headers)\n\n        response = requests.get(url, headers=self.headers, auth=self.auth, verify=self.verify_ssl)\n\n        self.http_status_code = response.status_code\n        try:\n            # No need to check for warnings here\n            self._check_error(response)\n            try:\n                path_or_file.write(response.content)\n            except AttributeError:\n                fd = os.open(path_or_file, os.O_CREAT | os.O_RDWR)\n                with os.fdopen(fd, \"w+b\") as f:\n                    f.write(response.content)\n        except:\n            return False\n\n        return True", "response": "Get a file from a url and save it as filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a GET request to the specified URL and return the JSON response if get_json is True and the response object otherwise.", "response": "def get(self, url, headers=None, parameters=None, get_json=True):\n        ''' Send a GET request with custome headers and parameters\n\n        Args:\n            url (str): URL to send the request to\n            headers (str, optional): custom headers\n            parameters (str, optional): optional parameters\n\n        Returns:\n            A JSON object of the returned response if `get_json` is True,\n            Requests' response object otherwise\n\n        '''\n\n        if self.debug:\n            print(\"GET: %s, headers=%s\" % (url, headers))\n\n        self.headers = self._get_default_headers()\n        get_parameters = self.parameters\n        if get_parameters is None:\n            # In case self.parameters is still empty\n            get_parameters = {}\n        if headers is not None:\n            self.headers.update(headers)\n        if parameters is not None:\n            get_parameters.update(parameters)\n\n        response = requests.get(url, headers=self.headers, params=get_parameters, auth=self.auth, verify=self.verify_ssl)\n        json_response = self._process_json_response(response)\n\n        return json_response if get_json is True else response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post(self, url, data=None, files=None, headers=None, get_json=True):\n        ''' Make POST request to a url\n\n        Args:\n            url (str): URL to send the request to\n            data (dict, optional): Data to send\n            files (dict, optional): Files to send with the request\n            headers (str, optional): custom headers\n\n        Returns:\n            A JSON object of the returned response if `get_json` is True,\n            Requests' response object otherwise\n\n        '''\n\n        if self.debug:\n            print(\"POST: %s, headers=%s\" % (url, headers))\n\n        self.headers = self._get_default_headers()\n        if headers is not None:\n            self.headers.update(headers)\n\n        response = requests.post(url, headers=self.headers, data=data, auth=self.auth, files=files, verify=self.verify_ssl)\n        json_response = self._process_json_response(response)\n        \n        return json_response if get_json is True else response", "response": "Make a POST request to a url and return the JSON response if get_json is True and the response object otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a JSON response from the server and return a dictionary of the data.", "response": "def _get_json_response(self, resp):\n        ''' Parse a JSON response '''\n        if resp is not None and resp.text is not None:\n            try:\n                text = resp.text.strip('\\n')\n                if len(text) > 0:\n                    return json.loads(text)\n            except ValueError as e:\n                if self.debug:\n                    print(\"Could not decode JSON response: \\\"%s\\\"\" % resp.text)\n                raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a given response and return a json object", "response": "def _process_json_response(self, response):\n        ''' Process a given response '''\n\n        json_response = self._get_json_response(response)\n        \n        if self.response_callback is not None:\n            json_response = self.response_callback(json_response)\n            response._content = json.dumps(json_response)\n\n        self.http_status_code = response.status_code\n        self._check_error(response, json_response)\n        self._check_warnings(json_response)\n\n        return json_response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck for HTTP error code from the response raise exception if there s any issue", "response": "def _check_error(self, response, json_response=None):\n        ''' Check for HTTP error code from the response, raise exception if there's any\n\n        Args:\n            response (object): Object returned by requests' `get` and `post`\n                methods\n\n            json_response (dict): JSON response, if applicable\n\n        Raises:\n            HTTPError: If the status code of response is either 4xx or 5xx\n\n        Returns:\n            True if status code is not error code\n        \n        '''\n\n        # If status code is 4xx or 5xx, that should be an error\n        if response.status_code >= 400:\n            json_response = json_response or self._get_json_response(response)\n            err_cls = self._check_http_error_code(response.status_code)\n            try:\n                raise err_cls(\"%s error: %s\" % (response.status_code, json_response[\"error\"][\"error_msg\"]), response.status_code)\n            # This is to catch error when we post get oauth data\n            except TypeError:\n                raise err_cls(\"%s error: %s\" % (response.status_code, json_response[\"error_description\"]), response.status_code)\n\n        # Return True if everything is OK\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_warnings(self, json_response):\n        ''' Extract warnings from the response to make them accessible\n\n        Args:\n            json_response (dict): JSON response\n        \n        '''\n\n        self.warnings = None\n        if json_response:\n            self.warnings = json_response.get('warnings')\n\n        if self.debug and self.warnings:\n            for w in self.warnings:\n                print(\"WARNING: %s - %s\" % (w['warning_name'], w['warning_msg']))", "response": "Extract warnings from the response to make them accessible\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a new HSAccessTokenAuth object from response data", "response": "def from_response(self, response_data):\n        ''' Builds a new HSAccessTokenAuth straight from response data \n\n        Args:\n            response_data (dict): Response data to use\n\n        Returns:\n            A HSAccessTokenAuth objet\n\n        '''\n        return HSAccessTokenAuth(\n            response_data['access_token'],\n            response_data['token_type'], \n            response_data['refresh_token'],\n            response_data['expires_in'], \n            response_data.get('state') # Not always here\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_response_component(self, api_id=None, signature_id=None):\n        ''' Find one or many repsonse components.\n\n            Args:\n\n                api_id (str):           Api id associated with the component(s) to be retrieved.\n\n                signature_id (str):     Signature id associated with the component(s) to be retrieved.\n\n            Returns:\n                A list of dictionaries containing component data\n\n        '''\n        if not api_id and not signature_id:\n            raise ValueError('At least one of api_id and signature_id is required')\n\n        components = list()\n        \n        if self.response_data:\n            for component in self.response_data:\n                if (api_id and component['api_id']) == api_id or (signature_id and component['signature_id'] == signature_id):\n                    components.append(component)\n\n        return components", "response": "Find one or many repsonse components."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_signature(self, signature_id=None, signer_email_address=None):\n        ''' Return a signature for the given parameters\n\n            Args:\n\n                signature_id (str):             Id of the signature to retrieve.\n                signer_email_address (str):     Email address of the associated signer for the signature to retrieve.\n\n            Returns:\n                A Signature object or None\n\n        '''\n        if self.signatures:\n            for signature in self.signatures:\n                if signature.signature_id == signature_id or signature.signer_email_address == signer_email_address: \n                    return signature", "response": "Return a signature for the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _uncamelize(self, s):\n        ''' Convert a camel-cased string to using underscores '''\n        res = ''\n        if s:\n            for i in range(len(s)): \n                if i > 0 and s[i].lower() != s[i]:\n                    res += '_'\n                res += s[i].lower()\n        return res", "response": "Convert a camel - cased string to using underscores"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_file_params(files):\n        '''\n            Utility method for formatting file parameters for transmission\n        '''\n        files_payload = {}\n        if files:\n            for idx, filename in enumerate(files):\n                files_payload[\"file[\" + str(idx) + \"]\"] = open(filename, 'rb')\n        return files_payload", "response": "Utility method for formatting file parameters for transmission\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_param_list(listed_params, output_name):\n        '''\n            Utility method for formatting lists of parameters for api consumption\n            Useful for email address lists, etc\n            Args:\n                listed_params (list of values) - the list to format\n                output_name (str) - the parameter name to prepend to each key\n        '''\n        output_payload = {}\n        if listed_params:\n            for index, item in enumerate(listed_params):\n                output_payload[str(output_name) + \"[\" + str(index) + \"]\" ] = item\n        return output_payload", "response": "Utility method for formatting lists of parameters for api consumption\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat a dictionary of items into a dictionary of key = value pairs.", "response": "def format_single_dict(dictionary, output_name):\n        '''\n            Currently used for metadata fields\n        '''\n        output_payload = {}\n        if dictionary:\n            for (k, v) in dictionary.items():\n                output_payload[output_name + '[' + k + ']'] = v\n        return output_payload"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef format_custom_fields(list_of_custom_fields):\n        '''\n            Custom fields formatting for submission\n        '''\n        output_payload = {}\n        if list_of_custom_fields:\n            # custom_field: {\"name\": value}\n            for custom_field in list_of_custom_fields:\n                for key, value in custom_field.items():\n                    output_payload[\"custom_fields[\" + key + \"]\"] = value\n        return output_payload", "response": "Formats the list of custom fields for submission"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_logscale(self,t=True):\n        if(t == self.get_logscale()):\n            return\n        else:\n            if(t):\n                self.__image = np.log10(self.__image+1)\n                self.__logscale_flag = True;\n            else:\n                self.__image = 10**self.__image-1.\n                self.__logscale_flag = False;", "response": "Sets the logscale of the log10 matrix of the log10 image."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the current image in some common image formats.", "response": "def save(self,outputfile,**kargs):\n        \"\"\"\n        - Save the image in some common image formats. It uses the pyplot.save \n        method.  \n        outputfile is a string containing a path to a filename, \n        of a Python file-like object. If *format* is *None* and\n        *fname* is a string, the output format is deduced from\n        the extension of the filename.\n\n        Keyword arguments:\n        *vmin*/*vmax*: [ None | scalar ]\n        *vmin* and *vmax* set the color scaling for the image by fixing the\n        values that map to the colormap color limits. If either *vmin* or *vmax*\n        is None, that limit is determined from the *arr* min/max value.\n        *cmap*:\n        cmap is a colors.Colormap instance, eg cm.jet.\n        If None, default to the rc image.cmap value.\n        *format*:\n        One of the file extensions supported by the active\n        backend.  Most backends support png, pdf, ps, eps and svg.\n        *origin*\n        [ 'upper' | 'lower' ] Indicates where the [0,0] index of\n        the array is in the upper left or lower left corner of\n        the axes. Defaults to the rc image.origin value.\n        *dpi*\n        The DPI to store in the metadata of the file.  This does not affect the\n        resolution of the output image.\n        \"\"\"\n        plt.imsave(outputfile, self.__image, **kargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_autocamera(self,mode='density'):\n        self.Camera.set_autocamera(self._Particles,mode=mode)\n        self._camera_params = self.Camera.get_params()\n        self._x, self._y, self._hsml, self._kview = self.__compute_scene()\n        self._m = self._Particles._mass[self._kview]", "response": "Set the autocamera for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_scene(self):\n        return self._x, self._y, self._hsml, self._m, self._kview", "response": "Returns the x y smoothing length m kview"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the camera parameters of the current object.", "response": "def update_camera(self,**kargs):\n        \"\"\"\n        - update_camera(**kwarg): By using this method you can define all \n        the new paramenters of the camera. Read the available **kwarg in \n        the sphviewer.Camera documentation. \n        \"\"\"\n        self.Camera.set_params(**kargs)\n        self._x, self._y, self._hsml, self._kview = self.__compute_scene()\n        self._m = self._Particles._mass[self._kview]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(self,axis=None,**kargs):\n        if(axis == None):\n            axis = plt.gca()\n        axis.plot(self.__x, self.__y, 'k.', **kargs)", "response": "This method is used to plot the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot(self,plane,axis=None,**kargs):\n        if(axis == None):\n            axis = plt.gca()\n        if(plane == 'xy'):\n            axis.plot(self._pos[:,0], self._pos[:,0], 'k.', **kargs)\n        elif(plane == 'xz'):\n            axis.plot(self._pos[:,1], self._pos[:,2], 'k.', **kargs)\n        elif(plane == 'yz'):\n            axis.plot(self._pos[:,2], self._pos[:,2], 'k.', **kargs)", "response": "Plot the distribution of the set of particles in a given plane."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __det_hsml_old(self, pos, nb):\n        manager = Manager()\n        out_hsml  = manager.Queue()\n        size  = multiprocessing.cpu_count()\t\n\n        if self.__verbose:\n            print('Building a KDTree...')\n        tree = self.__make_kdtree(pos)\n\n        index  = np.arange(np.shape(pos)[1])\n\t\t#I split the job among the number of available processors\n        pos   = np.array_split(pos, size, axis=1)\t\n        \n        procs = []\n\n        #We distribute the tasks among different processes\n        if self.__verbose:\n                print('Searching the ', nb,\n                      'closer neighbors to each particle...')\n        for rank in range(size):\n            task = multiprocessing.Process(target=self.__nbsearch, \n                                           args=(pos[rank], nb, tree, \n                                                 out_hsml,rank))\n            procs.append(task) \n            task.start()\n            \n            #Wait until all processes finish\n        for p in procs:\n            p.join()\n\n            index = []\n            hsml  = []\n        for i in range(size):\n            a, b = out_hsml.get()\n            index.append(a)\n            hsml.append(b)\n    #\t    if a == 0: print(b[0])\n\n            #I have to order the data before return it\n        k = np.argsort(index)\n        hsml1 = np.array([])\n        for i in k:\n            hsml1 = np.append(hsml1,hsml[i])\n        if self.__verbose:\n            print('Done...')\n        return hsml1", "response": "This function is used to find the smoothing lengths of the particles in the KD tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(fname, fail_silently=False):\n        try:\n            filepath = os.path.join(os.path.dirname(__file__), fname)\n            with io.open(filepath, 'rt', encoding='utf8') as f:\n                return f.read()\n        except:\n            if not fail_silently:\n                raise\n            return ''", "response": "Reads the content of the given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pass_verbosity(f):\n    def new_func(*args, **kwargs):\n        kwargs['verbosity'] = click.get_current_context().verbosity\n        return f(*args, **kwargs)\n    return update_wrapper(new_func, f)", "response": "Decorator to mark a callback as wanting to receive the verbosity as a keyword argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when run from the command line.", "response": "def run_from_argv(self, argv):\n        \"\"\"\n        Called when run from the command line.\n        \"\"\"\n        try:\n            return self.main(args=argv[2:], standalone_mode=False)\n        except click.ClickException as e:\n            if getattr(e.ctx, 'traceback', False):\n                raise\n            e.show()\n            sys.exit(e.exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, *args, **kwargs):\n        # Remove internal Django command handling machinery\n        kwargs.pop('skip_checks', None)\n        parent_ctx = click.get_current_context(silent=True)\n        with self.make_context('', list(args), parent=parent_ctx) as ctx:\n            # Rename kwargs to to the appropriate destination argument name\n            opt_mapping = dict(self.map_names())\n            arg_options = {opt_mapping.get(key, key): value\n                           for key, value in six.iteritems(kwargs)}\n\n            # Update the context with the passed (renamed) kwargs\n            ctx.params.update(arg_options)\n\n            # Invoke the command\n            self.invoke(ctx)", "response": "Called when run through call_command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt(data, key):\n    '''encrypt the data with the key'''\n    data = __tobytes(data)\n    data_len = len(data)\n    data = ffi.from_buffer(data)\n    key = ffi.from_buffer(__tobytes(key))\n    out_len = ffi.new('size_t *')\n    result = lib.xxtea_encrypt(data, data_len, key, out_len)\n    ret = ffi.buffer(result, out_len[0])[:]\n    lib.free(result)\n    return ret", "response": "encrypt the data with the key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flaskrun(app, default_host=\"127.0.0.1\", default_port=\"8000\"):\n\n    # Set up the command-line options\n    parser = optparse.OptionParser()\n    parser.add_option(\n        \"-H\",\n        \"--host\",\n        help=\"Hostname of the Flask app \" + \"[default %s]\" % default_host,\n        default=default_host,\n    )\n    parser.add_option(\n        \"-P\",\n        \"--port\",\n        help=\"Port for the Flask app \" + \"[default %s]\" % default_port,\n        default=default_port,\n    )\n\n    # Two options useful for debugging purposes, but\n    # a bit dangerous so not exposed in the help message.\n    parser.add_option(\n        \"-d\", \"--debug\", action=\"store_true\", dest=\"debug\", help=optparse.SUPPRESS_HELP\n    )\n    parser.add_option(\n        \"-p\",\n        \"--profile\",\n        action=\"store_true\",\n        dest=\"profile\",\n        help=optparse.SUPPRESS_HELP,\n    )\n\n    options, _ = parser.parse_args()\n\n    # If the user selects the profiling option, then we need\n    # to do a little extra setup\n    if options.profile:\n        from werkzeug.contrib.profiler import ProfilerMiddleware\n\n        app.config[\"PROFILE\"] = True\n        app.wsgi_app = ProfilerMiddleware(app.wsgi_app, restrictions=[30])\n        options.debug = True\n\n    app.run(debug=options.debug, host=options.host, port=int(options.port))", "response": "Runs a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_randomized_guid_sample(self, item_count):\n        dataset = self.get_whitelist()\n        random.shuffle(dataset)\n        return dataset[:item_count]", "response": "Get a randomized version of the GUIDs from the whitelist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can_recommend(self, client_data, extra_data={}):\n        self.logger.info(\"Curated can_recommend: {}\".format(True))\n        return True", "response": "This function checks if the curated recommender can recommend the item with the given data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncurate recommendations are just random selections", "response": "def recommend(self, client_data, limit, extra_data={}):\n        \"\"\"\n        Curated recommendations are just random selections\n        \"\"\"\n        guids = self._curated_wl.get_randomized_guid_sample(limit)\n\n        results = [(guid, 1.0) for guid in guids]\n\n        log_data = (client_data[\"client_id\"], str(guids))\n        self.logger.info(\n            \"Curated recommendations client_id: [%s], guids: [%s]\" % log_data\n        )\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef can_recommend(self, client_data, extra_data={}):\n        ensemble_recommend = self._ensemble_recommender.can_recommend(\n            client_data, extra_data\n        )\n        curated_recommend = self._curated_recommender.can_recommend(\n            client_data, extra_data\n        )\n        result = ensemble_recommend and curated_recommend\n        self.logger.info(\"Hybrid can_recommend: {}\".format(result))\n        return result", "response": "Returns True if the ensemble recommender can recommend the given user data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the ensemble recommender can recommend the client data.", "response": "def can_recommend(self, client_data, extra_data={}):\n        \"\"\"The ensemble recommender is always going to be\n        available if at least one recommender is available\"\"\"\n        result = sum(\n            [\n                self._recommender_map[rkey].can_recommend(client_data)\n                for rkey in self.RECOMMENDER_KEYS\n            ]\n        )\n        self.logger.info(\"Ensemble can_recommend: {}\".format(result))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _recommend(self, client_data, limit, extra_data={}):\n        self.logger.info(\"Ensemble recommend invoked\")\n        preinstalled_addon_ids = client_data.get(\"installed_addons\", [])\n\n        # Compute an extended limit by adding the length of\n        # the list of any preinstalled addons.\n        extended_limit = limit + len(preinstalled_addon_ids)\n\n        flattened_results = []\n        ensemble_weights = self._weight_cache.getWeights()\n\n        for rkey in self.RECOMMENDER_KEYS:\n            recommender = self._recommender_map[rkey]\n\n            if recommender.can_recommend(client_data):\n                raw_results = recommender.recommend(\n                    client_data, extended_limit, extra_data\n                )\n                reweighted_results = []\n                for guid, weight in raw_results:\n                    item = (guid, weight * ensemble_weights[rkey])\n                    reweighted_results.append(item)\n                flattened_results.extend(reweighted_results)\n\n        # Sort the results by the GUID\n        flattened_results.sort(key=lambda item: item[0])\n\n        # group by the guid, sum up the weights for recurring GUID\n        # suggestions across all recommenders\n        guid_grouper = itertools.groupby(flattened_results, lambda item: item[0])\n\n        ensemble_suggestions = []\n        for (guid, guid_group) in guid_grouper:\n            weight_sum = sum([v for (g, v) in guid_group])\n            item = (guid, weight_sum)\n            ensemble_suggestions.append(item)\n\n        # Sort in reverse order (greatest weight to least)\n        ensemble_suggestions.sort(key=lambda x: -x[1])\n\n        filtered_ensemble_suggestions = [\n            (guid, weight)\n            for (guid, weight) in ensemble_suggestions\n            if guid not in preinstalled_addon_ids\n        ]\n\n        results = filtered_ensemble_suggestions[:limit]\n\n        log_data = (\n            client_data[\"client_id\"],\n            str(ensemble_weights),\n            str([r[0] for r in results]),\n        )\n        self.logger.info(\n            \"client_id: [%s], ensemble_weight: [%s], guids: [%s]\" % log_data\n        )\n        return results", "response": "Recommends the relevant records for the given client_data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the JSON object from the cache or S3.", "response": "def get(self, transform=None):\n        \"\"\"\n        Return the JSON defined at the S3 location in the constructor.\n\n        The get method will reload the S3 object after the TTL has\n        expired.\n        Fetch the JSON object from cache or S3 if necessary\n        \"\"\"\n        if not self.has_expired() and self._cached_copy is not None:\n            return self._cached_copy, False\n\n        return self._refresh_cache(transform), True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hashed_download(url, temp, digest):\n    # Based on pip 1.4.1's URLOpener but with cert verification removed\n    def opener():\n        opener = build_opener(HTTPSHandler())\n        # Strip out HTTPHandler to prevent MITM spoof:\n        for handler in opener.handlers:\n            if isinstance(handler, HTTPHandler):\n                opener.handlers.remove(handler)\n        return opener\n\n    def read_chunks(response, chunk_size):\n        while True:\n            chunk = response.read(chunk_size)\n            if not chunk:\n                break\n            yield chunk\n\n    response = opener().open(url)\n    path = join(temp, urlparse(url).path.split('/')[-1])\n    actual_hash = sha256()\n    with open(path, 'wb') as file:\n        for chunk in read_chunks(response, 4096):\n            file.write(chunk)\n            actual_hash.update(chunk)\n\n    actual_digest = actual_hash.hexdigest()\n    if actual_digest != digest:\n        raise HashError(url, path, actual_digest, digest)\n    return path", "response": "Download url to temp make sure it has the SHA - 256 digest and return its path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_lr(self, score):\n        # Find the index of the closest value that was precomputed in lr_curves\n        # This will significantly speed up |get_lr|.\n\n        # The lr_curves_cache is a list of scalar distance\n        # measurements\n        lr_curves_cache = np.array([s[0] for s in self.lr_curves])\n\n        # np.argmin produces the index to the part of the curve\n        # where distance is the smallest to the score which we are\n        # inspecting currently.\n        idx = np.argmin(abs(score - lr_curves_cache))\n\n        numer_val = self.lr_curves[idx][1][0]\n        denum_val = self.lr_curves[idx][1][1]\n\n        # Compute LR based on numerator and denominator values\n        return float(numer_val) / float(denum_val)", "response": "Compute a : float : likelihood ratio from a provided similarity score when compared\n        to two probability density functions which are pre - loaded during init."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes a set of similar donors for each comparable variable.", "response": "def get_similar_donors(self, client_data):\n        \"\"\"Computes a set of :float: similarity scores between a client and a set of candidate\n        donors for which comparable variables have been measured.\n\n        A custom similarity metric is defined in this function that combines the Hamming distance\n        for categorical variables with the Canberra distance for continuous variables into a\n        univariate similarity metric between the client and a set of candidate donors loaded during\n        init.\n\n        :param client_data: a client data payload including a subset fo telemetry fields.\n        :return: the sorted approximate likelihood ratio (np.array) corresponding to the\n                 internally computed similarity score and a list of indices that link\n                 each LR score with the related donor in the |self.donors_pool|.\n        \"\"\"\n        # Compute the distance between self and any comparable client.\n        distances = self.compute_clients_dist(client_data)\n\n        # Compute the LR based on precomputed distributions that relate the score\n        # to a probability of providing good addon recommendations.\n\n        lrs_from_scores = np.array(\n            [self.get_lr(distances[i]) for i in range(self.num_donors)]\n        )\n\n        # Sort the LR values (descending) and return the sorted values together with\n        # the original indices.\n        indices = (-lrs_from_scores).argsort()\n        return lrs_from_scores[indices], indices"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn recommendations for the given client.", "response": "def recommend(self, client_id, limit, extra_data={}):\n        \"\"\"Return recommendations for the given client.\n\n        The recommendation logic will go through each recommender and\n        pick the first one that \"can_recommend\".\n\n        :param client_id: the client unique id.\n        :param limit: the maximum number of recommendations to return.\n        :param extra_data: a dictionary with extra client data.\n        \"\"\"\n\n        if client_id in TEST_CLIENT_IDS:\n            data = self._whitelist_data.get()[0]\n            random.shuffle(data)\n            samples = data[:limit]\n            self.logger.info(\"Test ID detected [{}]\".format(client_id))\n            return [(s, 1.1) for s in samples]\n\n        if client_id in EMPTY_TEST_CLIENT_IDS:\n            self.logger.info(\"Empty Test ID detected [{}]\".format(client_id))\n            return []\n\n        client_info = self.profile_fetcher.get(client_id)\n        if client_info is None:\n            self.logger.info(\n                \"Defaulting to empty results.  No client info fetched from dynamo.\"\n            )\n            return []\n\n        results = self._ensemble_recommender.recommend(client_info, limit, extra_data)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_client_profile(self, client_id):\n        try:\n            response = self._table.get_item(Key={'client_id': client_id})\n            compressed_bytes = response['Item']['json_payload'].value\n            json_byte_data = zlib.decompress(compressed_bytes)\n            json_str_data = json_byte_data.decode('utf8')\n            return json.loads(json_str_data)\n        except KeyError:\n            # No client ID found - not really an error\n            return None\n        except Exception as e:\n            # Return None on error.  The caller in ProfileFetcher will\n            # handle error logging\n            msg = \"Error loading client data for {}.  Error: {}\"\n            self.logger.debug(msg.format(client_id, str(e)))\n            return None", "response": "This fetches a single client record out of DynamoDB\n            and returns the corresponding dict."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the promoted GUIDs are formatted correctly and strip it down into an empty list.", "response": "def clean_promoted_guids(raw_promoted_guids):\n    \"\"\" Verify that the promoted GUIDs are formatted correctly,\n    otherwise strip it down into an empty list.\n    \"\"\"\n    valid = True\n\n    for row in raw_promoted_guids:\n        if len(row) != 2:\n            valid = False\n            break\n\n        if not (\n            (isinstance(row[0], str) or isinstance(row[0], unicode))\n            and (isinstance(row[1], int) or isinstance(row[1], float))  # noqa\n        ):\n            valid = False\n            break\n\n    if valid:\n        return raw_promoted_guids\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring the plugin for the given flask application.", "response": "def configure_plugin(app):  # noqa: C901\n    \"\"\"\n    This is a factory function that configures all the routes for\n    flask given a particular library.\n    \"\"\"\n\n    @app.route(\n        \"/v1/api/client_has_addon/<hashed_client_id>/<addon_id>/\", methods=[\"GET\"]\n    )\n    def client_has_addon(hashed_client_id, addon_id):\n        # Use the module global PROXY_MANAGER\n        global PROXY_MANAGER\n        recommendation_manager = check_proxy_manager(PROXY_MANAGER)\n        pf = recommendation_manager._ctx[\"profile_fetcher\"]\n\n        client_meta = pf.get(hashed_client_id)\n        if client_meta is None:\n            # no valid client metadata was found for the given\n            # clientId\n            result = {\"results\": False, 'error': 'No client found'}\n            response = app.response_class(\n                response=json.dumps(result), status=200, mimetype=\"application/json\"\n            )\n            return response\n\n        result = {\"results\": addon_id in client_meta.get(\"installed_addons\", [])}\n        response = app.response_class(\n            response=json.dumps(result), status=200, mimetype=\"application/json\"\n        )\n        return response\n\n    @app.route(\"/v1/api/recommendations/<hashed_client_id>/\", methods=[\"GET\", \"POST\"])\n    def recommendations(hashed_client_id):\n        \"\"\"Return a list of recommendations provided a telemetry client_id.\"\"\"\n        # Use the module global PROXY_MANAGER\n        global PROXY_MANAGER\n\n        extra_data = {}\n        extra_data[\"options\"] = {}\n        extra_data[\"options\"][\"promoted\"] = []\n\n        try:\n            if request.method == \"POST\":\n                json_data = request.data\n                # At least Python3.5 returns request.data as bytes\n                # type instead of a string type.\n                # Both Python2.7 and Python3.7 return a string type\n                if type(json_data) == bytes:\n                    json_data = json_data.decode(\"utf8\")\n\n                if json_data != \"\":\n                    post_data = json.loads(json_data)\n                    raw_promoted_guids = post_data.get(\"options\", {}).get(\n                        \"promoted\", []\n                    )\n                    promoted_guids = clean_promoted_guids(raw_promoted_guids)\n                    extra_data[\"options\"][\"promoted\"] = promoted_guids\n\n        except Exception as e:\n            jdata = {}\n            jdata[\"results\"] = []\n            jdata[\"error\"] = \"Invalid JSON in POST: {}\".format(e)\n            return app.response_class(\n                response=json.dumps(jdata, status=400, mimetype=\"application/json\")\n            )\n\n        # Coerce the uuid.UUID type into a string\n        client_id = str(hashed_client_id)\n\n        locale = request.args.get(\"locale\", None)\n        if locale is not None:\n            extra_data[\"locale\"] = locale\n\n        platform = request.args.get(\"platform\", None)\n        if platform is not None:\n            extra_data[\"platform\"] = platform\n\n        recommendation_manager = check_proxy_manager(PROXY_MANAGER)\n        recommendations = recommendation_manager.recommend(\n            client_id=client_id, limit=TAAR_MAX_RESULTS, extra_data=extra_data\n        )\n\n        promoted_guids = extra_data.get(\"options\", {}).get(\"promoted\", [])\n        recommendations = merge_promoted_guids(promoted_guids, recommendations)\n\n        # Strip out weights from TAAR results to maintain compatibility\n        # with TAAR 1.0\n        jdata = {\"results\": [x[0] for x in recommendations]}\n\n        response = app.response_class(\n            response=json.dumps(jdata), status=200, mimetype=\"application/json\"\n        )\n        return response\n\n    def check_proxy_manager(PROXY_MANAGER):\n        if PROXY_MANAGER.getResource() is None:\n            ctx = default_context()\n            profile_fetcher = ProfileFetcher(ctx)\n\n            ctx[\"profile_fetcher\"] = profile_fetcher\n\n            # Lock the context down after we've got basic bits installed\n            root_ctx = ctx.child()\n            r_factory = recommenders.RecommenderFactory(root_ctx)\n            root_ctx[\"recommender_factory\"] = r_factory\n            instance = recommenders.RecommendationManager(root_ctx.child())\n            PROXY_MANAGER.setResource(instance)\n        return PROXY_MANAGER.getResource()\n\n    class MyPlugin:\n        def set(self, config_options):\n            \"\"\"\n            This setter is primarily so that we can instrument the\n            cached RecommendationManager implementation under test.\n\n            All plugins should implement this set method to enable\n            overwriting configuration options with a TAAR library.\n            \"\"\"\n            global PROXY_MANAGER\n            if \"PROXY_RESOURCE\" in config_options:\n                PROXY_MANAGER._resource = config_options[\"PROXY_RESOURCE\"]\n\n    return MyPlugin()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlogin to Tahoma API.", "response": "def login(self):\n        \"\"\"Login to Tahoma API.\"\"\"\n        if self.__logged_in:\n            return\n        login = {'userId': self.__username, 'userPassword': self.__password}\n        header = BASE_HEADERS.copy()\n        request = requests.post(BASE_URL + 'login',\n                                data=login,\n                                headers=header,\n                                timeout=10)\n\n        try:\n            result = request.json()\n        except ValueError as error:\n            raise Exception(\n                \"Not a valid result for login, \" +\n                \"protocol error: \" + request.status_code + ' - ' +\n                request.reason + \"(\" + str(error) + \")\")\n\n        if 'error' in result.keys():\n            raise Exception(\"Could not login: \" + result['error'])\n\n        if request.status_code != 200:\n            raise Exception(\n                \"Could not login, HTTP code: \" +\n                str(request.status_code) + ' - ' + request.reason)\n\n        if 'success' not in result.keys() or not result['success']:\n            raise Exception(\"Could not login, no success\")\n\n        cookie = request.headers.get(\"set-cookie\")\n        if cookie is None:\n            raise Exception(\"Could not login, no cookie set\")\n\n        self.__cookie = cookie\n        self.__logged_in = True\n        return self.__logged_in"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the user informations from the server.", "response": "def get_user(self):\n        \"\"\"Get the user informations from the server.\n\n        :return: a dict with all the informations\n        :rtype: dict\n\n        raises ValueError in case of protocol issues\n\n        :Example:\n\n        >>> \"creationTime\": <time>,\n        >>> \"lastUpdateTime\": <time>,\n        >>> \"userId\": \"<email for login>\",\n        >>> \"title\": 0,\n        >>> \"firstName\": \"<First>\",\n        >>> \"lastName\": \"<Last>\",\n        >>> \"email\": \"<contact email>\",\n        >>> \"phoneNumber\": \"<phone>\",\n        >>> \"mobilePhone\": \"<mobile>\",\n        >>> \"locale\": \"<two char country code>\"\n\n        :Warning:\n\n        The type and amount of values in the dictionary can change any time.\n        \"\"\"\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        request = requests.get(BASE_URL + 'getEndUser',\n                               headers=header,\n                               timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.get_user()\n            return\n\n        try:\n            result = request.json()\n        except ValueError:\n            raise Exception(\n                \"Not a valid result for getEndUser, protocol error!\")\n\n        return result['endUser']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_actions(self, name_of_action, actions):\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        actions_serialized = []\n\n        for action in actions:\n            actions_serialized.append(action.serialize())\n\n        data = {\"label\": name_of_action, \"actions\": actions_serialized}\n        json_data = json.dumps(data, indent=None, sort_keys=True)\n\n        request = requests.post(\n            BASE_URL + \"apply\",\n            headers=header, data=json_data,\n            timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.apply_actions(name_of_action, actions)\n            return\n\n        try:\n            result = request.json()\n        except ValueError as error:\n            raise Exception(\n                \"Not a valid result for applying an \" +\n                \"action, protocol error: \" + request.status_code +\n                ' - ' + request.reason + \" (\" + error + \")\")\n\n        if 'execId' not in result.keys():\n            raise Exception(\"Could not run actions, missing execId.\")\n\n        return result['execId']", "response": "This method executes an action or a group of actions on the Tahoma box."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_events(self):\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        request = requests.post(BASE_URL + 'getEvents',\n                                headers=header,\n                                timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.get_events()\n            return\n\n        try:\n            result = request.json()\n        except ValueError as error:\n            raise Exception(\n                \"Not a valid result for getEvent,\" +\n                \" protocol error: \" + error)\n\n        return self._get_events(result)", "response": "This method returns a set of events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_events(self, result):\n        events = []\n\n        for event_data in result:\n            event = Event.factory(event_data)\n\n            if event is not None:\n                events.append(event)\n\n                if isinstance(event, DeviceStateChangedEvent):\n                    # change device state\n                    if self.__devices[event.device_url] is None:\n                        raise Exception(\n                            \"Received device change \" +\n                            \"state for unknown device '\" +\n                            event.device_url + \"'\")\n\n                    self.__devices[event.device_url].set_active_states(\n                        event.states)\n\n        return events", "response": "Internal method for being able to run unit tests."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all current running executions.", "response": "def get_current_executions(self):\n        \"\"\"Get all current running executions.\n\n        :return: Returns a set of running Executions or empty list.\n        :rtype: list\n\n        raises ValueError in case of protocol issues\n\n        :Seealso:\n\n        - apply_actions\n        - launch_action_group\n        - get_history\n        \"\"\"\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        request = requests.get(\n            BASE_URL +\n            'getCurrentExecutions',\n            headers=header,\n            timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.get_current_executions()\n            return\n\n        try:\n            result = request.json()\n        except ValueError as error:\n            raise Exception(\n                \"Not a valid result for\" +\n                \"get_current_executions, protocol error: \" + error)\n\n        if 'executions' not in result.keys():\n            return None\n\n        executions = []\n\n        for execution_data in result['executions']:\n            exe = Execution(execution_data)\n            executions.append(exe)\n\n        return executions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all Action Groups.", "response": "def get_action_groups(self):\n        \"\"\"Get all Action Groups.\n\n        :return: List of Action Groups\n        \"\"\"\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        request = requests.get(BASE_URL + \"getActionGroups\",\n                               headers=header,\n                               timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.get_action_groups()\n            return\n\n        try:\n            result = request.json()\n        except ValueError:\n            raise Exception(\n                \"get_action_groups: Not a valid result for \")\n\n        if 'actionGroups' not in result.keys():\n            return None\n\n        groups = []\n\n        for group_data in result['actionGroups']:\n            group = ActionGroup(group_data)\n            groups.append(group)\n\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_states(self, devices):\n        header = BASE_HEADERS.copy()\n        header['Cookie'] = self.__cookie\n\n        json_data = self._create_get_state_request(devices)\n\n        request = requests.post(\n            BASE_URL + 'getStates',\n            headers=header,\n            data=json_data,\n            timeout=10)\n\n        if request.status_code != 200:\n            self.__logged_in = False\n            self.login()\n            self.get_states(devices)\n            return\n\n        try:\n            result = request.json()\n        except ValueError as error:\n            raise Exception(\n                \"Not a valid result for\" +\n                \"getStates, protocol error:\" + error)\n\n        self._get_states(result)", "response": "Get States of Devices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget states of devices.", "response": "def _get_states(self, result):\n        \"\"\"Get states of devices.\"\"\"\n        if 'devices' not in result.keys():\n            return\n\n        for device_states in result['devices']:\n            device = self.__devices[device_states['deviceURL']]\n            try:\n                device.set_active_states(device_states['states'])\n            except KeyError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds command to action.", "response": "def add_command(self, cmd_name, *args):\n        \"\"\"Add command to action.\"\"\"\n        self.__commands.append(Command(cmd_name, args))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a date into a FlexiDate.", "response": "def parse(date, dayfirst=True):\n    '''Parse a `date` into a `FlexiDate`.\n\n    @param date: the date to parse - may be a string, datetime.date,\n    datetime.datetime or FlexiDate.\n\n    TODO: support for quarters e.g. Q4 1980 or 1954 Q3\n    TODO: support latin stuff like M.DCC.LIII\n    TODO: convert '-' to '?' when used that way\n        e.g. had this date [181-]\n    '''\n    if not date:\n        return None\n    if isinstance(date, FlexiDate):\n        return date\n    if isinstance(date, int):\n        return FlexiDate(year=date)\n    elif isinstance(date, datetime.datetime):\n        parser = PythonDateTimeParser()\n        return parser.parse(date)\n    elif isinstance(date, datetime.date):\n        parser = PythonDateParser()\n        return parser.parse(date)\n    else:  # assuming its a string\n        parser = DateutilDateParser()\n        out = parser.parse(date, **{'dayfirst': dayfirst})\n        if out is not None:\n            return out\n        # msg = 'Unable to parse %s' % date\n        # raise ValueError(date)\n        val = 'UNPARSED: %s' % date\n        val = val.encode('ascii', 'ignore')\n        return FlexiDate(qualifier=val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef isoformat(self, strict=False):\n        '''Return date in isoformat (same as __str__ but without qualifier).\n\n        WARNING: does not replace '?' in dates unless strict=True.\n        '''\n        out = self.year\n        # what do we do when no year ...\n        for val in [self.month, self.day]:\n            if not val:\n                break\n            out += u'-' + val\n        if strict:\n            out = out.replace('?', '0')\n\n        if self.hour:\n            out += u' '\n            out += self.hour\n            for val in [self.minute, self.second]:\n                if not val:\n                    break\n                out += u':' + val\n            if self.microsecond:\n                out += u'.' + self.microsecond\n        return out", "response": "Return date in isoformat."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_str(self, instr):\n        '''Undo affect of __str__'''\n        if not instr:\n            return FlexiDate()\n\n        out = self.our_re.match(instr)\n        if out is None:  # no match TODO: raise Exception?\n            return None\n        else:\n            return FlexiDate(\n                out.group('year'),\n                out.group('month'),\n                out.group('day'),\n                out.group('hour'),\n                out.group('minute'),\n                out.group('second'),\n                out.group('microsecond'),\n                qualifier=out.group('qualifier')\n            )", "response": "Undo affect of __str__"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting as a float.", "response": "def as_float(self):\n        '''Get as a float (year being the integer part).\n\n        Replace '?' in year with 9 so as to be conservative (e.g. 19?? becomes\n        1999) and elsewhere (month, day) with 0\n\n        @return: float.\n        '''\n        if not self.year:\n            return None\n        out = float(self.year.replace('?', '9'))\n        if self.month:\n            # TODO: we are assuming months are of equal length\n            out += float(self.month.replace('?', '0')) / 12.0\n            if self.day:\n                out += float(self.day.replace('?', '0')) / 365.0\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef as_datetime(self):\n        '''Get as python datetime.datetime.\n\n        Require year to be a valid datetime year. Default month and day to 1 if\n        do not exist.\n\n        @return: datetime.datetime object.\n        '''\n        year = int(self.year)\n        month = int(self.month) if self.month else 1\n        day = int(self.day) if self.day else 1\n        hour = int(self.hour) if self.hour else 0\n        minute = int(self.minute) if self.minute else 0\n        second = int(self.second) if self.second else 0\n        microsecond = int(self.microsecond) if self.microsecond else 0\n        return datetime.datetime(year, month, day, hour, minute, second, microsecond)", "response": "Get as python datetime. datetime."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, date, **kwargs):\n        '''\n        :param **kwargs: any kwargs accepted by dateutil.parse function.\n        '''\n        qualifiers = []\n        if dateutil_parser is None:\n            return None\n        date = orig_date = date.strip()\n\n        # various normalizations\n        # TODO: call .lower() first\n        date = date.replace('B.C.E.', 'BC')\n        date = date.replace('BCE', 'BC')\n        date = date.replace('B.C.', 'BC')\n        date = date.replace('A.D.', 'AD')\n        date = date.replace('C.E.', 'AD')\n        date = date.replace('CE', 'AD')\n\n        # deal with pre 0AD dates\n        if date.startswith('-') or 'BC' in date or 'B.C.' in date:\n            pre0AD = True\n        else:\n            pre0AD = False\n        # BC seems to mess up parser\n        date = date.replace('BC', '')\n\n        # deal with circa: 'c.1950' or 'c1950'\n        circa_match = re.match('([^a-zA-Z]*)c\\.?\\s*(\\d+.*)', date)\n        if circa_match:\n            # remove circa bit\n            qualifiers.append(\"Note 'circa'\")\n            date = ''.join(circa_match.groups())\n\n        # deal with p1980 (what does this mean? it can appear in\n        # field 008 of MARC records\n        p_match = re.match(\"^p(\\d+)\", date)\n        if p_match:\n            date = date[1:]\n\n        # Deal with uncertainty: '1985?'\n        uncertainty_match = re.match('([0-9xX]{4})\\?', date)\n        if uncertainty_match:\n            # remove the ?\n            date = date[:-1]\n            qualifiers.append('Uncertainty')\n\n        # Parse the numbers intelligently\n        # do not use std parser function as creates lots of default data\n        res = dateutil_parser._parse(date, **kwargs)\n        try:\n            res = res[0]\n        except:\n            res = res\n        if res is None:\n            # Couldn't parse it\n            return None\n        # Note: Years of less than 3 digits not interpreted by\n        #      dateutil correctly\n        #      e.g. 87 -> 1987\n        #           4  -> day 4 (no year)\n        # Both cases are handled in this routine\n        if res.year is None and res.day:\n            year = res.day\n        # If the whole date is simply two digits then dateutil_parser makes\n        # it '86' -> '1986'. So strip off the '19'. (If the date specified\n        # day/month then a two digit year is more likely to be this century\n        # and so allow the '19' prefix to it.)\n        elif self._numeric.match(date) and (len(date) == 2 or date.startswith('00')):\n            year = res.year % 100\n        else:\n            year = res.year\n\n        # finally add back in BC stuff\n        if pre0AD:\n            year = -year\n\n        if not qualifiers:\n            qualifier = ''\n        else:\n            qualifier = ', '.join(qualifiers) + (' : %s' % orig_date)\n        return FlexiDate(year, res.month, res.day, res.hour, res.minute, res.second, res.microsecond, qualifier=qualifier)", "response": "Parse the ISO 8601 date and return a dict of the ISO 8601 date and the number of entries in the record."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef md5sum( string ):\n    h = hashlib.new( 'md5' )\n    h.update( string.encode( 'utf-8' ) )\n    return h.hexdigest()", "response": "Generate the md5 checksum for a string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_md5( filename ):\n    with zopen( filename, 'r' ) as f:\n        file_string = f.read()\n    try: # attempt to decode byte object\n        file_string = file_string.decode()\n    except AttributeError:\n        pass\n    return( md5sum( file_string ) )", "response": "Generate the md5 checksum for a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_filename( filename ):\n    f = next( ( '{}{}'.format( filename, extension ) for extension in [ '', '.gz' ]\n        if Path( '{}{}'.format( filename, extension ) ).is_file() ), None ) \n    return f", "response": "Returns the name of the file that matches the filename."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_checksum( filename, md5sum ):\n    filename = match_filename( filename )\n    md5_hash = file_md5( filename=filename )\n    if md5_hash != md5sum:\n        raise ValueError('md5 checksums are inconsistent: {}'.format( filename ))", "response": "Validate the md5 checksum of a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a list of matrix components to a 3x3 matrix.", "response": "def to_matrix( xx, yy, zz, xy, yz, xz ):\n    \"\"\"\n    Convert a list of matrix components to a symmetric 3x3 matrix.\n    Inputs should be in the order xx, yy, zz, xy, yz, xz.\n\n    Args:\n        xx (float): xx component of the matrix.\n        yy (float): yy component of the matrix.\n        zz (float): zz component of the matrix.\n        xy (float): xy component of the matrix.\n        yz (float): yz component of the matrix.\n        xz (float): xz component of the matrix.\n\n    Returns:\n        (np.array): The matrix, as a 3x3 numpy array.\n    \"\"\"\n    matrix = np.array( [[xx, xy, xz], [xy, yy, yz], [xz, yz, zz]] )\n    return matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef absorption_coefficient( dielectric ):\n    energies_in_eV = np.array( dielectric[0] )\n    real_dielectric = parse_dielectric_data( dielectric[1] )\n    imag_dielectric = parse_dielectric_data( dielectric[2] )\n    epsilon_1 = np.mean( real_dielectric, axis=1 )\n    epsilon_2 = np.mean( imag_dielectric, axis=1 )\n    return ( 2.0 * np.sqrt(2.0)*pi*eV_to_recip_cm*energies_in_eV\n                 * np.sqrt( -epsilon_1 + np.sqrt( epsilon_1**2 + epsilon_2**2 ) ) )", "response": "Calculates optical absorption coefficient from a list of dielectric constant data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the energy at this volume using the Murnaghan equation of state", "response": "def murnaghan( vol, e0, b0, bp, v0 ):\n    \"\"\"\n    Calculate the energy as a function of volume, using the Murnaghan equation of state\n    [Murnaghan, Proc. Nat. Acad. Sci. 30, 244 (1944)]\n    https://en.wikipedia.org/wiki/Murnaghan_equation_of_state\n    cf. Fu and Ho, Phys. Rev. B 28, 5480 (1983).\n\n    Args:\n        vol (float): this volume.\n        e0 (float):  energy at the minimum-energy volume, E0.\n        b0 (float):  bulk modulus at the minimum-energy volume, B0.\n        bp (float):  pressure-derivative of the bulk modulus at the minimum-energy volume, B0'.\n        v0 (float):  volume at the minimum-energy volume, V0.\n        \n    Returns:\n        (float): The energy at this volume. \n    \"\"\"\n    energy = e0 + b0 * vol / bp * (((v0 / vol)**bp) / (bp - 1) + 1) - v0 * b0 / (bp - 1.0)\n    return energy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an observed interatomic distance to the g ( r ) data at dr.", "response": "def add_dr( self, dr ):\n        \"\"\"\n        Add an observed interatomic distance to the g(r) data at dr.\n\n        Args:\n            dr (Float): the interatomic distance, dr.\n\n        Returns:\n            None\n        \"\"\" \n        this_bin = int( dr / self.dr ) \n        if this_bin > self.number_of_bins:\n            raise IndexError( 'dr is larger than rdf max_r' )\n        self.data[ this_bin ] += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dr( self, atom1, atom2 ):\n        return self.cell.dr( atom1.r, atom2.r )", "response": "Calculates the distance between two atoms."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the area of a triangle defined by three points in Cartesian space.", "response": "def area_of_a_triangle_in_cartesian_space( a, b, c ):\n    \"\"\"\n    Returns the area of a triangle defined by three points in Cartesian space.\n\n    Args:\n        a (np.array): Cartesian coordinates of point A.\n        b (np.array): Cartesian coordinates of point B.\n        c (np.array): Cartesian coordinates of point C.\n\n    Returns:\n        (float): the area of the triangle.\n    \"\"\"\n    return 0.5 * np.linalg.norm( np.cross( b-a, c-a ) )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef points_are_in_a_straight_line( points, tolerance=1e-7 ):\n    a = points[0]\n    b = points[1]\n    for c in points[2:]:\n        if area_of_a_triangle_in_cartesian_space( a, b, c ) > tolerance:\n            return False\n    return True", "response": "Checks whether a set of points fall on a straight line."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the effective mass given the eigenvalues at two k - points.", "response": "def two_point_effective_mass( cartesian_k_points, eigenvalues ):\n    \"\"\"\n    Calculate the effective mass given eigenvalues at two k-points.\n    Reimplemented from Aron Walsh's original effective mass Fortran code.\n\n    Args:\n        cartesian_k_points (np.array): 2D numpy array containing the k-points in (reciprocal) Cartesian coordinates.\n        eigenvalues (np.array):        numpy array containing the eigenvalues at each k-point.\n\n    Returns:\n        (float): The effective mass\n    \"\"\"\n    assert( cartesian_k_points.shape[0] == 2 )\n    assert( eigenvalues.size == 2 )\n    dk = cartesian_k_points[ 1 ] - cartesian_k_points[ 0 ]\n    mod_dk = np.sqrt( np.dot( dk, dk ) )\n    delta_e = ( eigenvalues[ 1 ] - eigenvalues[ 0 ] ) * ev_to_hartree * 2.0\n    effective_mass = mod_dk * mod_dk / delta_e\n    return effective_mass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the effective mass using a least squares quadratic fit.", "response": "def least_squares_effective_mass( cartesian_k_points, eigenvalues ):\n    \"\"\"\n    Calculate the effective mass using a least squares quadratic fit.\n\n    Args:\n        cartesian_k_points (np.array): Cartesian reciprocal coordinates for the k-points\n        eigenvalues (np.array):        Energy eigenvalues at each k-point to be used in the fit.\n\n    Returns:\n        (float): The fitted effective mass\n\n    Notes:\n        If the k-points do not sit on a straight line a ValueError will be raised.\n    \"\"\"\n    if not points_are_in_a_straight_line( cartesian_k_points ):\n        raise ValueError( 'k-points are not collinear' )\n    dk = cartesian_k_points - cartesian_k_points[0]\n    mod_dk = np.linalg.norm( dk, axis = 1 )\n    delta_e = eigenvalues - eigenvalues[0]\n    effective_mass = 1.0 / ( np.polyfit( mod_dk, eigenvalues, 2 )[0] * ev_to_hartree * 2.0 )\n    return effective_mass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_from_file( self, filename, negative_occupancies='warn' ):\n        valid_negative_occupancies = [ 'warn', 'raise', 'ignore', 'zero' ]\n        if negative_occupancies not in valid_negative_occupancies:\n            raise ValueError( '\"{}\" is not a valid value for the keyword `negative_occupancies`.'.format( negative_occupancies ) )\n        with open( filename, 'r' ) as file_in:\n            file_in.readline()\n            self.number_of_k_points, self.number_of_bands, self.number_of_ions = [ int( f ) for f in get_numbers_from_string( file_in.readline() ) ]\n            self.read_in = file_in.read()\n        self.parse_k_points()\n        self.parse_bands()\n        self.parse_occupancy()\n        if np.any( self.occupancy[:,1] < 0 ): # Handle negative occupancies\n            if negative_occupancies == 'warn':\n                warnings.warn( \"One or more occupancies in your PROCAR file are negative.\" )\n            elif negative_occupancies == 'raise':\n                raise ValueError( \"One or more occupancies in your PROCAR file are negative.\" )\n            elif negative_occupancies == 'zero':\n                self.occupancy[ self.occupancy < 0 ] = 0.0\n        self.parse_projections()\n        self.sanity_check()\n        self.read_in = None\n        if self.calculation[ 'spin_polarised' ]:\n            self.data = self.projection_data.reshape( self.spin_channels, self.number_of_k_points, self.number_of_bands, self.number_of_ions + 1, self.number_of_projections )[:,:,:,:,1:].swapaxes( 0, 1).swapaxes( 1, 2 )\n        else:\n            self.data = self.projection_data.reshape( self.number_of_k_points, self.number_of_bands, self.spin_channels, self.number_of_ions + 1, self.number_of_projections )[:,:,:,:,1:]", "response": "Reads the projected wavefunction character of each band from a VASP PROCAR file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Counter object for this POSCAR.", "response": "def stoichiometry( self ):\n        \"\"\"\n        Stoichiometry for this POSCAR, as a Counter.\n        e.g. AB_2O_4 -> Counter( { 'A': 1, 'B': 2, O: 4 } )\n        \n        Args:\n            None\n\n        Returns:\n            None\n        \"\"\"\n        return Counter( { label: number for label, number in zip( self.atoms, self.atom_numbers ) } )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_vasp_summary( filename ):\n    with open( filename, 'r' ) as stream:\n        docs = yaml.load_all( stream, Loader=yaml.SafeLoader )\n        data = { d['title']: d for d in docs }\n    return data", "response": "Reads a vasp_summary. yaml file and returns a dictionary of dictionaries. Each dictionary corresponds to one sub - dictionary with the corresponding\nAttributeNames key as the title value. Each dictionary corresponds to one sub - dictionary with the corresponding\nAttributeNames key as the title value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef potcar_spec( filename ):\n    p_spec = {}\n    with open( filename, 'r' ) as f:\n        potcars = re.split('(End of Dataset\\n)', f.read() )\n    potcar_md5sums = [ md5sum( ''.join( pair ) ) for pair in zip( potcars[::2], potcars[1:-1:2] ) ]\n    for this_md5sum in potcar_md5sums:\n        for ps in potcar_sets:\n            for p, p_md5sum in potcar_md5sum_data[ ps ].items():\n                if this_md5sum == p_md5sum:\n                    p_spec[ p ] = ps\n    if len( p_spec ) != len( potcar_md5sums ):\n        raise ValueError( 'One or more POTCARs did not have matching md5 hashes' )\n    return p_spec", "response": "Returns a dictionary specifying the pseudopotentials contained in a POTCAR file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_vasp_calculations():\n    dir_list = [ './' + re.sub( r'vasprun\\.xml', '', path ) for path in glob.iglob( '**/vasprun.xml', recursive=True ) ]\n    gz_dir_list = [ './' + re.sub( r'vasprun\\.xml\\.gz', '', path ) for path in glob.iglob( '**/vasprun.xml.gz', recursive=True ) ]\n    return dir_list + gz_dir_list", "response": "Returns a list of all subdirectories that contain either a vasprun. xml file or a compressed vasprun. xml. gz file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_vasprun( self ):\n        self.vasprun_filename = match_filename( 'vasprun.xml' )\n        if not self.vasprun_filename:\n            raise FileNotFoundError( 'Could not find vasprun.xml or vasprun.xml.gz file' )\n        try:\n            self.vasprun = Vasprun( self.vasprun_filename, parse_potcar_file=False )\n        except ET.ParseError:\n            self.vasprun = None\n        except:\n            raise", "response": "Parse the vasprun. xml file and set self. vasprun."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the functional of the current object.", "response": "def functional( self ):\n        \"\"\"\n        String description of the calculation functional.\n       \n        Recognises:\n            - PBE\n            - PBEsol\n            - PBE-based hybrids:\n                - PBE0 (alpha=0.25, no screening)\n                - HSE06 (alpha=0.25, mu=0.2)\n                - generic hybrids (alpha=?, no screening)\n                - generic screened hybrids (alpha=?, mu=?)\n        \n        Returns:\n            (Str): String describing the calculation functional.\n\n        \"\"\"\n        if self.potcars_are_pbe(): # PBE base funtional\n            if 'LHFCALC' in self.vasprun.parameters:\n                alpha = float( self.vasprun.parameters['AEXX'] )\n            else:\n                alpha = 0.0\n            if 'HFSCREEN' in self.vasprun.parameters:\n                mu = float( self.vasprun.parameters['HFSCREEN'] )\n            else:\n                mu = 0\n            if alpha > 0:\n                if mu > 0: # screened hybrid\n                    if ( mu == 0.2 ) and ( alpha == 0.25 ):\n                        f = 'HSE06'\n                    else:\n                        f = \"screened hybrid. alpha={}, mu={}\".format( alpha, mu )\n                else: # unscreened hybrid\n                    if alpha == 0.25:\n                        f = 'PBE0'\n                    else: \n                        f = \"hybrid. alpha={}\".format( alpha )\n            else: # not hybrid. Plain PBE or some variant.\n                pbe_list = { 'PS': 'PBEsol',\n                             'PE': 'PBE',\n                             '91': 'PW91',\n                             'RP': 'rPBE',\n                             'AM': 'AM05' }\n                f = pbe_list[ self.vasprun.parameters['GGA'] ]\n        else:\n            f = 'not recognised'    \n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the projected density of states data into self. pdos.", "response": "def read_projected_dos( self ):\n        \"\"\"\n        Read the projected density of states data into \"\"\"\n        pdos_list = []\n        for i in range( self.number_of_atoms ):\n            df = self.read_atomic_dos_as_df( i+1 )\n            pdos_list.append( df )\n        self.pdos = np.vstack( [ np.array( df ) for df in pdos_list ] ).reshape( \n            self.number_of_atoms, self.number_of_data_points, self.number_of_channels, self.ispin )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a subset of the projected density of states array.", "response": "def pdos_select( self, atoms=None, spin=None, l=None, m=None ):\n        \"\"\"\n        Returns a subset of the projected density of states array.\n\n        Args:\n            atoms (int or list(int)): Atom numbers to include in the selection. Atom numbers count from 1. \n                                   Default is to select all atoms.\n            spin (str): Select up or down, or both spin channels to include in the selection.\n                        Accepted options are 'up', 'down', and 'both'. Default is to select both spins.\n            l (str): Select one angular momentum to include in the selectrion.\n                     Accepted options are 's', 'p', 'd', and 'f'. Default is to include all l-values.\n                     Setting `l` and not setting `m` will return all projections for that angular momentum value.\n            m (list(str)): Select one or more m-values. Requires `l` to be set. \n                           The accepted values depend on the value of `l`:\n                           `l='s'`: Only one projection. Not set.\n                           `l='p'`: One or more of [ 'x', 'y', 'z' ]\n                           `l='d'`: One or more of [ 'xy', 'yz', 'z2-r2', 'xz', 'x2-y2' ]\n                           `l='f'`: One or more of [ 'y(3x2-y2)', 'xyz', 'yz2', 'z3', 'xz2', 'z(x2-y2)', 'x(x2-3y2)' ]\n\n        Returns:\n            np.array: A 4-dimensional numpy array containing the selected pdos values. \n            The array dimensions are [ atom_no, energy_value, lm-projection, spin ]\n\n        \"\"\"\n        valid_m_values = { 's': [],\n                           'p': [ 'x', 'y', 'z' ],\n                           'd': [ 'xy', 'yz', 'z2-r2', 'xz', 'x2-y2' ],\n                           'f': [ 'y(3x2-y2)', 'xyz', 'yz2', 'z3', 'xz2', 'z(x2-y2)', 'x(x2-3y2)' ] }\n        if not atoms:\n            atom_idx = list(range( self.number_of_atoms ))\n        else:\n            atom_idx = atoms\n        to_return = self.pdos[ atom_idx, :, :, : ]\n        if not spin:\n            spin_idx = list(range( self.ispin ))\n        elif spin is 'up':\n            spin_idx = [0]\n        elif spin is 'down':\n            spin_idx = [1]\n        elif spin is 'both':\n            spin_idx = [0,1]\n        else:\n            raise ValueError( \"valid spin values are 'up', 'down', and 'both'. The default is 'both'\" )\n        to_return = to_return[ :, :, :, spin_idx ]\n        if not l:\n            channel_idx = list(range( self.number_of_channels ))\n        elif l == 's':\n            channel_idx = [ 0 ]\n        elif l == 'p':\n            if not m:\n                channel_idx = [ 1, 2, 3 ]\n            else: # TODO this looks like it should be i+1\n                channel_idx = [ i+1 for i, v in enumerate( valid_m_values['p'] ) if v in m ]\n        elif l == 'd':\n            if not m:\n                channel_idx = [ 4, 5, 6, 7, 8 ]\n            else: # TODO this looks like it should be i+4\n                channel_idx = [ i+4 for i, v in enumerate( valid_m_values['d'] ) if v in m ]\n        elif l == 'f':\n            if not m:\n                channel_idx = [ 9, 10, 11, 12, 13, 14, 15 ]\n            else: # TODO this looks like it should be i+9\n                channel_idx = [ i+9 for i, v in enumerate( valid_m_values['f'] ) if v in m ]\n        else:\n            raise ValueError\n        return to_return[ :, :, channel_idx, : ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delta_E( reactants, products, check_balance=True ):\n    if check_balance:\n        if delta_stoichiometry( reactants, products ) != {}:\n            raise ValueError( \"reaction is not balanced: {}\".format( delta_stoichiometry( reactants, products) ) )\n    return sum( [ r.energy for r in products ] ) - sum( [ r.energy for r in reactants ] )", "response": "Calculate the change in energy for a list of reactants and products."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delta_stoichiometry( reactants, products ):\n    totals = Counter()\n    for r in reactants:\n        totals.update( ( r * -1.0 ).stoichiometry )\n    for p in products:\n        totals.update( p.stoichiometry )\n    to_return = {}\n    for c in totals:\n        if totals[c] != 0:\n            to_return[c] = totals[c]\n    return to_return", "response": "Calculate the change in stoichiometry for reactants and products."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef energy_string_to_float( string ):\n    energy_re = re.compile( \"(-?\\d+\\.\\d+)\" )\n    return float( energy_re.match( string ).group(0) )", "response": "Converts a string of a calculation energy e. g. - 1. 2345 eV to a float."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_calculations_from_file( filename ):\n    calcs = {}\n    with open( filename, 'r' ) as stream:\n        docs = yaml.load_all( stream, Loader=yaml.SafeLoader )\n        for d in docs:\n            stoichiometry = Counter()\n            for s in d['stoichiometry']:\n                stoichiometry.update( s )\n            calcs[ d['title'] ] = Calculation( title=d['title'], \n                                               stoichiometry=stoichiometry, \n                                               energy=energy_string_to_float( d['energy'] ) )\n    return calcs", "response": "Imports a list of Calculation objects from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scale_stoichiometry( self, scaling ):\n        return { k:v*scaling for k,v in self.stoichiometry.items() }", "response": "Returns the stoichiometry scaled by the argument scaling."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the angle between two vectors in degrees.", "response": "def angle( x, y ):\n    \"\"\"\n    Calculate the angle between two vectors, in degrees.\n\n    Args:\n        x (np.array): one vector.\n        y (np.array): the other vector.\n\n    Returns:\n        (float):      the angle between x and y in degrees.\n    \"\"\"\n    dot = np.dot( x, y )\n    x_mod = np.linalg.norm( x )\n    y_mod = np.linalg.norm( y )\n    cos_angle = dot / ( x_mod * y_mod )\n    return np.degrees( np.arccos( cos_angle ) )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the distance between two fractional coordinates in the cell.", "response": "def dr( self, r1, r2, cutoff=None ):\n        \"\"\"\n        Calculate the distance between two fractional coordinates in the cell.\n        \n        Args:\n            r1 (np.array): fractional coordinates for position 1.\n            r2 (np.array): fractional coordinates for position 2.\n            cutoff (optional:Bool): If set, returns None for distances greater than the cutoff. Default None (unset).\n\n        Returns:\n            (float): the distance between r1 and r2.\n        \"\"\"\n        delta_r_cartesian = ( r1 - r2 ).dot( self.matrix )\n        delta_r_squared = sum( delta_r_cartesian**2 )\n        if cutoff != None:\n            cutoff_squared = cutoff ** 2\n            if delta_r_squared > cutoff_squared:\n                return None\n        return( math.sqrt( delta_r_squared ) )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef minimum_image( self, r1, r2 ):\n        delta_r = r2 - r1\n        delta_r = np.array( [ x - math.copysign( 1.0, x ) if abs(x) > 0.5 else x for x in delta_r ] )\n        return( delta_r )", "response": "Find the minimum image vector from point r1 to point r2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef minimum_image_dr( self, r1, r2, cutoff=None ):\n        delta_r_vector = self.minimum_image( r1, r2 )\n        return( self.dr( np.zeros( 3 ), delta_r_vector, cutoff ) )", "response": "Calculates the shortest distance between two points in the cell and returns the distance between r1 and r2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lengths( self ):\n        return( np.array( [ math.sqrt( sum( row**2 ) ) for row in self.matrix ] ) )", "response": "Returns the length of the set of elements in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef angles( self ):\n        ( a, b, c ) = [ row for row in self.matrix ]\n        return [ angle( b, c ), angle( a, c ), angle( a, b ) ]", "response": "Returns the cell angles in degrees."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inside_cell( self, r ):\n        centre = np.array( [ 0.5, 0.5, 0.5 ] )\n        new_r = self.nearest_image( centre, r )\n        return new_r", "response": "Given a fractional - coordinate return the equivalent point inside the cell."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the cell volume.", "response": "def volume( self ):\n        \"\"\"\n        The cell volume.\n\n        Args:\n            None\n\n        Returns:\n            (float): The cell volume.\n        \"\"\"\n        return np.dot( self.matrix[0], np.cross( self.matrix[1], self.matrix[2] ) )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file( cls, filename ):\n        with open( filename, 'r' ) as stream:\n            data = yaml.load( stream, Loader=yaml.SafeLoader )\n            notes = data.get( 'notes' )\n            v_type = data.get( 'type' )\n            track = data.get( 'track' )\n            xargs = {}\n            if track:\n                if type( track ) is str:\n                    track = [ track ]\n                xargs['track'] = track \n            vaspmeta = VASPMeta( data['title'], \n                                 data['description'], \n                                 data['status'], \n                                 notes=notes, \n                                 type=v_type,\n                                 **xargs )\n        return vaspmeta", "response": "Create a VASPMeta object by reading a vaspmeta. yaml file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the reciprocal lattice vectors from an outcar file.", "response": "def reciprocal_lattice_from_outcar( filename ): # from https://github.com/MaterialsDiscovery/PyChemia\n    \"\"\"\n    Finds and returns the reciprocal lattice vectors, if more than\n    one set present, it just returns the last one.\n    Args:\n        filename (Str): The name of the outcar file to be read\n\n    Returns:\n        List(Float): The reciprocal lattice vectors.\n    \"\"\"\n    outcar = open(filename, \"r\").read()\n    # just keeping the last component\n    recLat = re.findall(r\"reciprocal\\s*lattice\\s*vectors\\s*([-.\\s\\d]*)\",\n                        outcar)[-1]\n    recLat = recLat.split()\n    recLat = np.array(recLat, dtype=float)\n    # up to now I have, both direct and rec. lattices (3+3=6 columns)\n    recLat.shape = (3, 6)\n    recLat = recLat[:, 3:]\n    return recLat"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef final_energy_from_outcar( filename='OUTCAR' ):\n    with open( filename ) as f:\n        outcar = f.read()\n    energy_re = re.compile( \"energy\\(sigma->0\\) =\\s+([-\\d\\.]+)\" )\n    energy = float( energy_re.findall( outcar )[-1] )\n    return energy", "response": "Finds and returns the energy from a VASP OUTCAR file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vasp_version_from_outcar( filename='OUTCAR' ):\n    with open( filename ) as f:\n        line = f.readline().strip()\n    return line", "response": "Returns the first line from a VASP OUTCAR file to get the VASP source version string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of EATOM values for the pseudopotentials used in the OUTCAR file.", "response": "def potcar_eatom_list_from_outcar( filename='OUTCAR' ):\n    \"\"\"\n    Returns a list of EATOM values for the pseudopotentials used.\n\n    Args:\n        filename (Str, optional): OUTCAR filename. Defaults to 'OUTCAR'.\n\n    Returns:\n        (List(Float)): A list of EATOM values, in the order they appear in the OUTCAR.\n    \"\"\"\n    with open( filename ) as f:\n        outcar = f.read()\n    eatom_re = re.compile( \"energy of atom\\s+\\d+\\s+EATOM=\\s*([-\\d\\.]+)\" )\n    eatom = [ float( e ) for e in eatom_re.findall( outcar ) ]\n    return eatom"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds and returns the fermi energy from the OUTCAR file", "response": "def fermi_energy_from_outcar( filename='OUTCAR' ):\n    \"\"\"Finds and returns the fermi energy.\n    Args:\n    -filename: the name of the outcar file to be read\n\n    Returns:\n        (Float): The fermi energy as found in the OUTCAR \n    \"\"\"\n    outcar = open(filename, \"r\").read()\n    # returns a match object\n    fermi_energy = re.search(r\"E-fermi\\s*:\\s*([-.\\d]*)\", outcar)\n    # take the first group - group(0) contains entire match\n    fermi_energy = float(fermi_energy.group(1))\n    return fermi_energy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_description(node=None):\n    if node is None:\n        from logging_tree.nodes import tree\n        node = tree()\n    return '\\n'.join([ line.rstrip() for line in describe(node) ]) + '\\n'", "response": "Return a multi - line string describing a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a generator for the given node and parent.", "response": "def _describe(node, parent):\n    \"\"\"Generate lines describing the given `node` tuple.\n\n    This is the recursive back-end that powers ``describe()``.  With its\n    extra ``parent`` parameter, this routine remembers the nearest\n    non-placeholder ancestor so that it can compare it against the\n    actual value of the ``.parent`` attribute of each node.\n\n    \"\"\"\n    name, logger, children = node\n    is_placeholder = isinstance(logger, logging.PlaceHolder)\n    if is_placeholder:\n        yield '<--[%s]' % name\n    else:\n        parent_is_correct = (parent is None) or (logger.parent is parent)\n        if not logger.propagate:\n            arrow = '   '\n        elif parent_is_correct:\n            arrow = '<--'\n        else:\n            arrow = ' !-'\n        yield '%s\"%s\"' % (arrow, name)\n        if not parent_is_correct:\n            if logger.parent is None:\n                yield ('   Broken .parent is None, so messages stop here')\n            else:\n                yield ('   Broken .parent redirects messages to %r instead'\n                       % (logger.parent.name,))\n        if logger.level == logging.NOTSET:\n            yield '   Level NOTSET so inherits level ' + logging.getLevelName(\n                logger.getEffectiveLevel())\n        else:\n            yield '   Level ' + logging.getLevelName(logger.level)\n        if not logger.propagate:\n            yield '   Propagate OFF'\n        if logger.disabled:\n            yield '   Disabled'\n\n        # In case someone has defined a custom logger that lacks a\n        # `filters` or `handlers` attribute, we call getattr() and\n        # provide an empty sequence as a fallback.\n\n        for f in getattr(logger, 'filters', ()):\n            yield '   Filter %s' % describe_filter(f)\n        for h in getattr(logger, 'handlers', ()):\n            g = describe_handler(h)\n            yield '   Handler %s' % next(g)\n            for line in g:\n                yield '   ' + line\n\n    if children:\n        if not is_placeholder:\n            parent = logger\n        last_child = children[-1]\n        for child in children:\n            g = _describe(child, parent)\n            yield '   |'\n            yield '   o' + next(g)\n            if child is last_child:\n                prefix = '    '\n            else:\n                prefix = '   |'\n            for line in g:\n                yield prefix + line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef describe_filter(f):\n    if f.__class__ is logging.Filter:  # using type() breaks in Python <= 2.6\n        return 'name=%r' % f.name\n    return repr(f)", "response": "Return text describing the logging filter f."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef describe_handler(h):\n    t = h.__class__  # using type() breaks in Python <= 2.6\n    format = handler_formats.get(t)\n    if format is not None:\n        yield format % h.__dict__\n    else:\n        yield repr(h)\n    level = getattr(h, 'level', logging.NOTSET)\n    if level != logging.NOTSET:\n        yield '  Level ' + logging.getLevelName(level)\n    for f in getattr(h, 'filters', ()):\n        yield '  Filter %s' % describe_filter(f)\n    formatter = getattr(h, 'formatter', None)\n    if formatter is not None:\n        if type(formatter) is logging.Formatter:\n            yield '  Formatter fmt=%r datefmt=%r' % (\n                getattr(formatter, '_fmt', None),\n                getattr(formatter, 'datefmt', None))\n        else:\n            yield '  Formatter %r' % (formatter,)\n    if t is logging.handlers.MemoryHandler and h.target is not None:\n        yield '  Flushes output to:'\n        g = describe_handler(h.target)\n        yield '    Handler ' + next(g)\n        for line in g:\n            yield '    ' + line", "response": "Yields one or more lines describing the logging handler h."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tree():\n    root = ('', logging.root, [])\n    nodes = {}\n    items = list(logging.root.manager.loggerDict.items())  # for Python 2 and 3\n    items.sort()\n    for name, logger in items:\n        nodes[name] = node = (name, logger, [])\n        i = name.rfind('.', 0, len(name) - 1)  # same formula used in `logging`\n        if i == -1:\n            parent = root\n        else:\n            parent = nodes[name[:i]]\n        parent[2].append(node)\n    return root", "response": "Return a tree of tuples representing the logger layout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patched_str(self):\n\n    def red(words):\n      return u(\"\\033[31m\\033[49m%s\\033[0m\") % words\n\n    def white(words):\n      return u(\"\\033[37m\\033[49m%s\\033[0m\") % words\n\n    def blue(words):\n      return u(\"\\033[34m\\033[49m%s\\033[0m\") % words\n\n    def teal(words):\n      return u(\"\\033[36m\\033[49m%s\\033[0m\") % words\n\n    def get_uri(code):\n       return \"https://www.signalwire.com/docs/errors/{0}\".format(code)\n\n    # If it makes sense to print a human readable error message, try to\n    # do it. The one problem is that someone might catch this error and\n    # try to display the message from it to an end user.\n    if hasattr(sys.stderr, 'isatty') and sys.stderr.isatty():\n      msg = (\n        \"\\n{red_error} {request_was}\\n\\n{http_line}\"\n        \"\\n\\n{sw_returned}\\n\\n{message}\\n\".format(\n          red_error=red(\"HTTP Error\"),\n          request_was=white(\"Your request was:\"),\n          http_line=teal(\"%s %s\" % (self.method, self.uri)),\n          sw_returned=white(\n            \"Signalwire returned the following information:\"),\n            message=blue(str(self.msg))\n          ))\n      if self.code:\n        msg = \"\".join([msg, \"\\n{more_info}\\n\\n{uri}\\n\\n\".format(\n          more_info=white(\"More information may be available here:\"),\n          uri=blue(get_uri(self.code))),\n        ])\n      return msg\n    else:\n      return \"HTTP {0} error: {1}\".format(self.status, self.msg)", "response": "Return a string that can be used to display the exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef patched_fax_init(self, twilio):\n  super(TwilioFax, self).__init__(twilio)\n\n  self.base_url = ''\n  self.account_sid = twilio.account_sid\n\n  # Versions\n  self._v1 = None", "response": "Patched to allow for custom initialization of Fax Domain\n ers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patched_fax_v1_init(self, domain):\n  print(domain.__class__.__name__)\n  super(TwilioV1, self).__init__(domain)\n  self.version = \"2010-04-01/Accounts/\" + domain.account_sid\n  self._faxes = None", "response": "Patched version of FaxVersion1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_this(search, filename=MODULE_PATH):\n    if not search:\n        return\n    for line in open(str(filename)).readlines():\n        if search.lower() in line.lower():\n            line = line.split(\"=\")[1].strip()\n            if \"'\" in line or '\"' in line or '\"\"\"' in line:\n                line = line.replace(\"'\", \"\").replace('\"', '').replace('\"\"\"', '')\n            return line", "response": "Take a string and a filename path string and return the found value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef score(self, outcomes, modelparams, expparams, return_L=False):\n        \n        if len(modelparams.shape) == 1:\n            modelparams = modelparams[:, np.newaxis]\n        \n        # compute likelihood at central point\n        L0 = self.likelihood(outcomes, modelparams, expparams)\n        \n        # allocate space for the score\n        q = np.empty([self.n_modelparams, \n                      outcomes.shape[0], \n                      modelparams.shape[0], \n                      expparams.shape[0]])\n        h_perturb = np.empty(modelparams.shape)\n        \n        # just loop over the model parameter as there usually won't be so many\n        # of them that vectorizing would be worth the effort.\n        for mp_idx in range(self.n_modelparams):\n            h_perturb[:] = np.zeros(modelparams.shape)\n            h_perturb[:, mp_idx] = self.h[mp_idx]\n            # use the chain rule since taking the numerical derivative of a \n            # logarithm is unstable\n            q[mp_idx, :] = (\n                self.likelihood(outcomes, modelparams + h_perturb, expparams) - \n                self.likelihood(outcomes, modelparams - h_perturb, expparams)\n            ) / (2 * self.h[mp_idx] * L0)\n            \n        \n        if return_L:\n            return q, L0\n        else: \n            return q", "response": "r Returns the numerically computed score of the likelihood function defined as the central difference method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear any cache associated with the underlying model and the direct view.", "response": "def clear_cache(self):\n        \"\"\"\n        Clears any cache associated with the serial model and the engines\n        seen by the direct view.\n        \"\"\"\n        self.underlying_model.clear_cache()\n        try:\n            logger.info('DirectView results has {} items. Clearing.'.format(\n                len(self._dv.results)\n            ))\n            self._dv.purge_results('all')\n            if self._purge_client:\n                self._dv.client.purge_everything()\n        except:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef likelihood(self, outcomes, modelparams, expparams):\n        # By calling the superclass implementation, we can consolidate\n        # call counting there.\n        super(DirectViewParallelizedModel, self).likelihood(outcomes, modelparams, expparams)\n\n        # If there's less models than some threshold, just use the serial model.\n        # By default, we'll set that threshold to be the number of engines * 10.\n        if modelparams.shape[0] <= self._serial_threshold:\n            return self.underlying_model.likelihood(outcomes, modelparams, expparams)\n        \n        if self._dv is None:\n            raise RuntimeError(\n                \"No direct view provided; this may be because the instance was \"\n                \"loaded from a pickle or NumPy saved array without providing a \"\n                \"new direct view.\"\n            )\n\n        # Need to decorate with interactive to overcome namespace issues with\n        # remote engines.\n        @interactive\n        def serial_likelihood(mps, sm, os, eps):\n            return sm.likelihood(os, mps, eps)\n\n        # TODO: check whether there's a better way to pass the extra parameters\n        # that doesn't use so much memory.\n        # The trick is that serial_likelihood will be pickled, so we need to be\n        # careful about closures.\n        L = self._dv.map_sync(\n            serial_likelihood,\n            np.array_split(modelparams, self.n_engines, axis=0),\n            [self.underlying_model] * self.n_engines,\n            [outcomes] * self.n_engines,\n            [expparams] * self.n_engines\n        )\n\n        return np.concatenate(L, axis=1)", "response": "Returns the likelihood for the underlying model distributing\n        the model parameter array across the engines controlled by thisDirectViewParallelizedModel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simulate_experiment(self, modelparams, expparams, repeat=1, split_by_modelparams=True):\n        # By calling the superclass implementation, we can consolidate\n        # simulation counting there.\n        super(DirectViewParallelizedModel, self).simulate_experiment(modelparams, expparams, repeat=repeat)\n\n        if self._dv is None:\n                raise RuntimeError(\n                    \"No direct view provided; this may be because the instance was \"\n                    \"loaded from a pickle or NumPy saved array without providing a \"\n                    \"new direct view.\"\n                )\n\n        # Need to decorate with interactive to overcome namespace issues with\n        # remote engines.\n        @interactive\n        def serial_simulator(sm, mps, eps, r):\n            return sm.simulate_experiment(mps, eps, repeat=r)\n\n        if split_by_modelparams:\n            # If there's less models than some threshold, just use the serial model.\n            # By default, we'll set that threshold to be the number of engines * 10.\n            if modelparams.shape[0] <= self._serial_threshold:\n                return self.underlying_model.simulate_experiment(modelparams, expparams, repeat=repeat)\n\n            # The trick is that serial_likelihood will be pickled, so we need to be\n            # careful about closures.\n            os = self._dv.map_sync(\n                serial_simulator,\n                [self.underlying_model] * self.n_engines,\n                np.array_split(modelparams, self.n_engines, axis=0),\n                [expparams] * self.n_engines,\n                [repeat] * self.n_engines\n            )\n\n            return np.concatenate(os, axis=0)\n\n        else:\n            # If there's less models than some threshold, just use the serial model.\n            # By default, we'll set that threshold to be the number of engines * 10.\n            if expparams.shape[0] <= self._serial_threshold:\n                return self.underlying_model.simulate_experiment(modelparams, expparams, repeat=repeat)\n\n            # The trick is that serial_likelihood will be pickled, so we need to be\n            # careful about closures.\n            os = self._dv.map_sync(\n                serial_simulator,\n                [self.underlying_model] * self.n_engines,\n                [modelparams] * self.n_engines,\n                np.array_split(expparams, self.n_engines, axis=0),\n                [repeat] * self.n_engines\n            )\n\n            return np.concatenate(os, axis=1)", "response": "Simulates the underlying model using the parallelised model engines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the resample threshold and conditionally resamples.", "response": "def _maybe_resample(self):\n        \"\"\"\n        Checks the resample threshold and conditionally resamples.\n        \"\"\"\n        ess = self.n_ess\n        if ess <= 10:\n            warnings.warn(\n                \"Extremely small n_ess encountered ({}). \"\n                \"Resampling is likely to fail. Consider adding particles, or \"\n                \"resampling more often.\".format(ess),\n                ApproximationWarning\n            )\n        if ess < self.n_particles * self.resample_thresh:\n            self.resample()\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, outcome, expparams, check_for_resample=True):\n\n        # First, record the outcome.\n        # TODO: record the experiment as well.\n        self._data_record.append(outcome)\n        self._just_resampled = False\n\n        # Perform the update.\n        weights, norm = self.hypothetical_update(outcome, expparams, return_normalization=True)\n\n        # Check for negative weights before applying the update.\n        if not np.all(weights >= 0):\n            warnings.warn(\"Negative weights occured in particle approximation. Smallest weight observed == {}. Clipping weights.\".format(np.min(weights)), ApproximationWarning)\n            np.clip(weights, 0, 1, out=weights)\n\n        # Next, check if we have caused the weights to go to zero, as can\n        # happen if the likelihood is identically zero for all particles,\n        # or if the previous clip step choked on a NaN.\n        if np.sum(weights) <= self._zero_weight_thresh:\n            if self._zero_weight_policy == 'ignore':\n                pass\n            elif self._zero_weight_policy == 'skip':\n                return\n            elif self._zero_weight_policy == 'warn':\n                warnings.warn(\"All particle weights are zero. This will very likely fail quite badly.\", ApproximationWarning)\n            elif self._zero_weight_policy == 'error':\n                raise RuntimeError(\"All particle weights are zero.\")\n            elif self._zero_weight_policy == 'reset':\n                warnings.warn(\"All particle weights are zero. Resetting from initial prior.\", ApproximationWarning)\n                self.reset()\n            else:\n                raise ValueError(\"Invalid zero-weight policy {} encountered.\".format(self._zero_weight_policy))\n\n        # Since hypothetical_update returns an array indexed by\n        # [outcome, experiment, particle], we need to strip off those two\n        # indices first.\n        self.particle_weights[:] = weights[0,0,:]\n\n        # Record the normalization\n        self._normalization_record.append(norm[0][0])\n\n        # Update the particle locations according to the model's timestep.\n        self.particle_locations = self.model.update_timestep(\n            self.particle_locations, expparams\n        )[:, :, 0]\n\n        # Check if we need to update our min_n_ess attribute.\n        if self.n_ess <= self._min_n_ess:\n            self._min_n_ess = self.n_ess\n\n        # Resample if needed.\n        if check_for_resample:\n            self._maybe_resample()", "response": "Updates the posterior distribution of the current state of the canon."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef batch_update(self, outcomes, expparams, resample_interval=5):\n\n        # TODO: write a faster implementation here using vectorized calls to\n        #       likelihood.\n\n        # Check that the number of outcomes and experiments is the same.\n        n_exps = outcomes.shape[0]\n        if expparams.shape[0] != n_exps:\n            raise ValueError(\"The number of outcomes and experiments must match.\")\n\n        if len(expparams.shape) == 1:\n            expparams = expparams[:, None]\n\n        # Loop over experiments and update one at a time.\n        for idx_exp, (outcome, experiment) in enumerate(zip(iter(outcomes), iter(expparams))):\n            self.update(outcome, experiment, check_for_resample=False)\n            if (idx_exp + 1) % resample_interval == 0:\n                self._maybe_resample()", "response": "r This method is used to update a batch of outcomes and experiments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nforces the updater to perform a resampling step immediately.", "response": "def resample(self):\n        \"\"\"\n        Forces the updater to perform a resampling step immediately.\n        \"\"\"\n\n        if self.just_resampled:\n            warnings.warn(\n                \"Resampling without additional data; this may not perform as \"\n                \"desired.\",\n                ResamplerWarning\n            )\n\n        # Record that we have performed a resampling step.\n        self._just_resampled = True\n        self._resample_count += 1\n\n        # If we're tracking divergences, make a copy of the weights and\n        # locations.\n        if self._resampling_divergences is not None:\n            old_locs = self.particle_locations.copy()\n            old_weights = self.particle_weights.copy()\n\n        # Record the previous mean, cov if needed.\n        if self._debug_resampling:\n            old_mean = self.est_mean()\n            old_cov = self.est_covariance_mtx()\n\n        # Find the new particle locations according to the chosen resampling\n        # algorithm.\n        # We pass the model so that the resampler can check for validity of\n        # newly placed particles.\n        # FIXME This feels fishy. If we update particles elsewwhere\n        new_distribution = self.resampler(self.model, self)\n        self.particle_weights = new_distribution.particle_weights\n        self.particle_locations = new_distribution.particle_locations\n\n        # Possibly canonicalize, if we've been asked to do so.\n        if self._canonicalize:\n            self.particle_locations[:, :] = self.model.canonicalize(self.particle_locations)\n\n        # Instruct the model to clear its cache, demoting any errors to\n        # warnings.\n        try:\n            self.model.clear_cache()\n        except Exception as e:\n            warnings.warn(\"Exception raised when clearing model cache: {}. Ignoring.\".format(e))\n\n        # Possibly track the new divergence.\n        if self._resampling_divergences is not None:\n            self._resampling_divergences.append(\n                self._kl_divergence(old_locs, old_weights)\n            )\n\n        # Report current and previous mean, cov.\n        if self._debug_resampling:\n            new_mean = self.est_mean()\n            new_cov = self.est_covariance_mtx()\n            logger.debug(\"Resampling changed mean by {}. Norm change in cov: {}.\".format(\n                old_mean - new_mean,\n                np.linalg.norm(new_cov - old_cov)\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bayes_risk(self, expparams):\n\n        # for models whose outcome number changes with experiment, we \n        # take the easy way out and for-loop over experiments\n        n_eps = expparams.size\n        if n_eps > 1 and not self.model.is_n_outcomes_constant:\n            risk = np.empty(n_eps)\n            for idx in range(n_eps):\n                risk[idx] = self.bayes_risk(expparams[idx, np.newaxis])\n            return risk\n        \n        # outcomes for the first experiment\n        os = self.model.domain(expparams[0,np.newaxis])[0].values\n\n        # compute the hypothetical weights, likelihoods and normalizations for\n        # every possible outcome and expparam\n        # the likelihood over outcomes should sum to 1, so don't compute for last outcome\n        w_hyp, L, N = self.hypothetical_update(\n                os[:-1], \n                expparams, \n                return_normalization=True, \n                return_likelihood=True\n            )\n        w_hyp_last_outcome = (1 - L.sum(axis=0)) * self.particle_weights[np.newaxis, :]\n        N = np.concatenate([N[:,:,0], np.sum(w_hyp_last_outcome[np.newaxis,:,:], axis=2)], axis=0)\n        w_hyp_last_outcome = w_hyp_last_outcome / N[-1,:,np.newaxis]\n        w_hyp = np.concatenate([w_hyp, w_hyp_last_outcome[np.newaxis,:,:]], axis=0)\n        # w_hyp.shape == (n_out, n_eps, n_particles)\n        # N.shape == (n_out, n_eps)\n\n        # compute the hypothetical means and variances given outcomes and exparams\n        # mu_hyp.shape == (n_out, n_eps, n_models)\n        # var_hyp.shape == (n_out, n_eps)\n        mu_hyp = np.dot(w_hyp, self.particle_locations)\n        var_hyp = np.sum(\n            w_hyp * \n            np.sum(self.model.Q * (\n                self.particle_locations[np.newaxis,np.newaxis,:,:] - \n                mu_hyp[:,:,np.newaxis,:]\n            ) ** 2,  axis=3),\n            axis=2\n        )\n\n        # the risk of a given expparam can be calculated as the mean posterior\n        # variance weighted over all possible outcomes\n        return np.sum(N * var_hyp, axis=0)", "response": "r Calculates the Bayes risk for the current posterior distribution of the current posterior distribution at each hypothetical experiment in expparams."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the marginal distribution of a given model parameter.", "response": "def posterior_marginal(self, idx_param=0, res=100, smoothing=0, range_min=None, range_max=None):\n        \"\"\"\n        Returns an estimate of the marginal distribution of a given model parameter, based on\n        taking the derivative of the interpolated cdf.\n\n        :param int idx_param: Index of parameter to be marginalized.\n        :param int res1: Resolution of of the axis.\n        :param float smoothing: Standard deviation of the Gaussian kernel\n            used to smooth; same units as parameter.\n        :param float range_min: Minimum range of the output axis.\n        :param float range_max: Maximum range of the output axis.\n\n        .. seealso::\n\n            :meth:`SMCUpdater.plot_posterior_marginal`\n        \"\"\"\n\n        # We need to sort the particles to get cumsum to make sense.\n        # interp1d would  do it anyways (using argsort, too), so it's not a waste\n        s = np.argsort(self.particle_locations[:,idx_param])\n        locs = self.particle_locations[s,idx_param]\n\n        # relevant axis discretization\n        r_min = np.min(locs) if range_min is None else range_min\n        r_max = np.max(locs) if range_max is None else range_max\n        ps = np.linspace(r_min, r_max, res)\n\n        # interpolate the cdf of the marginal distribution using cumsum\n        interp = scipy.interpolate.interp1d(\n            np.append(locs, r_max + np.abs(r_max-r_min)),\n            np.append(np.cumsum(self.particle_weights[s]), 1),\n            #kind='cubic',\n            bounds_error=False,\n            fill_value=0,\n            assume_sorted=True\n        )\n\n        # get distribution from derivative of cdf, and smooth it\n        pr = np.gradient(interp(ps), ps[1]-ps[0])\n        if smoothing > 0:\n            gaussian_filter1d(pr, res*smoothing/(np.abs(r_max-r_min)), output=pr)\n\n        del interp\n\n        return ps, pr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_posterior_marginal(self, idx_param=0, res=100, smoothing=0,\n            range_min=None, range_max=None, label_xaxis=True,\n            other_plot_args={}, true_model=None\n        ):\n        \"\"\"\n        Plots a marginal of the requested parameter.\n\n        :param int idx_param: Index of parameter to be marginalized.\n        :param int res1: Resolution of of the axis.\n        :param float smoothing: Standard deviation of the Gaussian kernel\n            used to smooth; same units as parameter.\n        :param float range_min: Minimum range of the output axis.\n        :param float range_max: Maximum range of the output axis.\n        :param bool label_xaxis: Labels the :math:`x`-axis with the model parameter name\n            given by this updater's model.\n        :param dict other_plot_args: Keyword arguments to be passed to\n            matplotlib's ``plot`` function.\n        :param np.ndarray true_model: Plots a given model parameter vector\n            as the \"true\" model for comparison.\n\n        .. seealso::\n\n            :meth:`SMCUpdater.posterior_marginal`\n        \"\"\"\n        res = plt.plot(*self.posterior_marginal(\n            idx_param, res, smoothing,\n            range_min, range_max\n        ), **other_plot_args)\n        if label_xaxis:\n            plt.xlabel('${}$'.format(self.model.modelparam_names[idx_param]))\n        if true_model is not None:\n            true_model = true_model[0, idx_param] if true_model.ndim == 2 else true_model[idx_param]\n            old_ylim = plt.ylim()\n            plt.vlines(true_model, old_ylim[0] - 0.1, old_ylim[1] + 0.1, color='k', linestyles='--')\n            plt.ylim(old_ylim)\n\n        return res", "response": "Plots a marginal of the requested parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_covariance(self, corr=False, param_slice=None, tick_labels=None, tick_params=None):\n        if mpls is None:\n            raise ImportError(\"Hinton diagrams require mpltools.\")\n\n        if param_slice is None:\n            param_slice = np.s_[:]\n\n        tick_labels = (\n            list(range(len(self.model.modelparam_names[param_slice]))),\n            tick_labels\n            if tick_labels is not None else\n            list(map(u\"${}$\".format, self.model.modelparam_names[param_slice]))\n        )\n\n        cov = self.est_covariance_mtx(corr=corr)[param_slice, param_slice]\n\n        retval = mpls.hinton(cov)\n        plt.xticks(*tick_labels, **(tick_params if tick_params is not None else {}))\n        plt.yticks(*tick_labels, **(tick_params if tick_params is not None else {}))\n        plt.gca().xaxis.tick_top()\n\n        return retval", "response": "Plots the covariance matrix of the posterior."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef posterior_mesh(self, idx_param1=0, idx_param2=1, res1=100, res2=100, smoothing=0.01):\n\n        # WARNING: fancy indexing is used here, which means that a copy is\n        #          made.\n        locs = self.particle_locations[:, [idx_param1, idx_param2]]\n\n        p1s, p2s = np.meshgrid(\n            np.linspace(np.min(locs[:, 0]), np.max(locs[:, 0]), res1),\n            np.linspace(np.min(locs[:, 1]), np.max(locs[:, 1]), res2)\n        )\n        plot_locs = np.array([p1s, p2s]).T.reshape((np.prod(p1s.shape), 2))\n\n        pr = np.sum( # <- sum over the particles in the SMC approximation.\n            np.prod( # <- product over model parameters to get a multinormal\n                # Evaluate the PDF at the plotting locations, with a normal\n                # located at the particle locations.\n                scipy.stats.norm.pdf(\n                    plot_locs[:, np.newaxis, :],\n                    scale=smoothing,\n                    loc=locs\n                ),\n                axis=-1\n            ) * self.particle_weights,\n            axis=1\n        ).reshape(p1s.shape) # Finally, reshape back into the same shape as the mesh.\n\n        return p1s, p2s, pr", "response": "Returns a mesh of the current posterior distribution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_posterior_contour(self, idx_param1=0, idx_param2=1, res1=100, res2=100, smoothing=0.01):\n        return plt.contour(*self.posterior_mesh(idx_param1, idx_param2, res1, res2, smoothing))", "response": "Plots a contour of the kernel density estimation of the current posterior distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the local Bayesian Information Matrix for a set of SMC particle set entries.", "response": "def prior_bayes_information(self, expparams, n_samples=None):\n        \"\"\"\n        Evaluates the local Bayesian Information Matrix (BIM) for a set of\n        samples from the SMC particle set, with uniform weights.\n\n        :param expparams: Parameters describing the experiment that was\n            performed.\n        :type expparams: :class:`~numpy.ndarray` of dtype given by the\n            :attr:`~qinfer.abstract_model.Model.expparams_dtype` property\n            of the underlying model\n\n        :param n_samples int: Number of samples to draw from particle distribution,\n                        to evaluate BIM over.\n        \"\"\"\n\n        if n_samples is None:\n            n_samples = self.particle_locations.shape[0]\n        return self._bim(self.prior.sample(n_samples), expparams)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates the local Bayesian Information Matrix over all particles in the current posterior distribution with corresponding weights.", "response": "def posterior_bayes_information(self, expparams):\n        \"\"\"\n        Evaluates the local Bayesian Information Matrix (BIM) over all particles\n        of the current posterior distribution with corresponding weights.\n\n        :param expparams: Parameters describing the experiment that was\n            performed.\n        :type expparams: :class:`~numpy.ndarray` of dtype given by the\n            :attr:`~qinfer.abstract_model.Model.expparams_dtype` property\n            of the underlying model\n\n        \"\"\"\n        return self._bim(\n            self.particle_locations, expparams,\n            modelweights=self.particle_weights\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the posterior distribution of the current posterior distribution of the current posterior distribution of the current experiment and the given outcome.", "response": "def update(self, outcome, expparams,check_for_resample=True):\n        \"\"\"\n        Given an experiment and an outcome of that experiment, updates the\n        posterior distribution to reflect knowledge of that experiment.\n\n        After updating, resamples the posterior distribution if necessary.\n\n        :param int outcome: Label for the outcome that was observed, as defined\n            by the :class:`~qinfer.abstract_model.Model` instance under study.\n        :param expparams: Parameters describing the experiment that was\n            performed.\n        :type expparams: :class:`~numpy.ndarray` of dtype given by the\n            :attr:`~qinfer.abstract_model.Model.expparams_dtype` property\n            of the underlying model\n        :param bool check_for_resample: If :obj:`True`, after performing the\n            update, the effective sample size condition will be checked and\n            a resampling step may be performed.\n        \"\"\"\n        # Before we update, we need to commit the new Bayesian information\n        # matrix corresponding to the measurement we just made.\n        self._current_bim += self.prior_bayes_information(expparams)[:, :, 0]\n\n        # If we're tracking the information content accessible to adaptive\n        # algorithms, then we must use the current posterior as the prior\n        # for the next step, then add that accordingly.\n        if self._track_adaptive:\n            self._adaptive_bim += self.posterior_bayes_information(expparams)[:, :, 0]\n\n        # We now can update as normal.\n        SMCUpdater.update(self, outcome, expparams,check_for_resample=check_for_resample)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef particle_clusters(\n        particle_locations, particle_weights=None,\n        eps=0.5, min_particles=5, metric='euclidean',\n        weighted=False, w_pow=0.5,\n        quiet=True\n    ):\n    \"\"\"\n    Yields an iterator onto tuples ``(cluster_label, cluster_particles)``,\n    where ``cluster_label`` is an `int` identifying the cluster (or ``NOISE``\n    for the particles lying outside of all clusters), and where\n    ``cluster_particles`` is an array of ``dtype`` `bool` specifying the indices\n    of all particles in that cluster. That is, particle ``i`` is in the cluster\n    if ``cluster_particles[i] == True``.\n    \"\"\"\n\n\n    if weighted == True and particle_weights is None:\n        raise ValueError(\"Weights must be specified for weighted clustering.\")\n\n    # Allocate new arrays to hold the weights and locations.\n    new_weights = np.empty(particle_weights.shape)\n    new_locs    = np.empty(particle_locations.shape)\n\n    # Calculate and possibly reweight the metric.\n    if weighted:\n        M = sklearn.metrics.pairwise.pairwise_distances(particle_locations, metric=metric)\n        M = metrics.weighted_pairwise_distances(M, particle_weights, w_pow=w_pow)\n\n        # Create and run a SciKit-Learn DBSCAN clusterer.\n        clusterer = sklearn.cluster.DBSCAN(\n            min_samples=min_particles,\n            eps=eps,\n            metric='precomputed'\n        )\n        cluster_labels = clusterer.fit_predict(M)\n    else:\n        clusterer = sklearn.cluster.DBSCAN(\n            min_samples=min_particles,\n            eps=eps,\n            metric=metric\n        )\n        cluster_labels = clusterer.fit_predict(particle_locations)\n\n    # Find out how many clusters were identified.\n    # Cluster counting logic from:\n    # [http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html].\n    is_noise = -1 in cluster_labels\n    n_clusters = len(set(cluster_labels)) - (1 if is_noise else 0)\n\n    # If more than 10% of the particles were labeled as NOISE,\n    # warn.\n    n_noise = np.sum(cluster_labels == -1)\n    if n_noise / particle_weights.shape[0] >= 0.1:\n        warnings.warn(\"More than 10% of the particles were classified as NOISE. Consider increasing the neighborhood size ``eps``.\", ResamplerWarning)\n\n    # Print debugging info.\n    if not quiet:\n        print(\"[Clustering] DBSCAN identified {} cluster{}. \"\\\n              \"{} particles identified as NOISE.\".format(\n                  n_clusters, \"s\" if n_clusters > 1 else \"\", n_noise\n              ))\n\n    # Loop over clusters, calling the secondary resampler for each.\n    # The loop should include -1 if noise was found.\n    for idx_cluster in range(-1 if is_noise else 0, n_clusters):\n        # Grab a boolean array identifying the particles in a  particular\n        # cluster.\n        this_cluster = cluster_labels == idx_cluster\n\n        yield idx_cluster, this_cluster", "response": "Return an iterator onto tuples containing cluster labels and cluster_particles."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_rebit_modelparams(modelparams, rebit_axes=REBIT_AXES, **kwargs):\n    mps = modelparams[:, rebit_axes] * np.sqrt(2)\n    plt.scatter(mps[:, 0], mps[:, 1], **kwargs)", "response": "Plots the model parameters representing rebits and their states as a scatter plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the boundary of rebits of the current state space.", "response": "def plot_decorate_rebits(basis=None, rebit_axes=REBIT_AXES):\n    \"\"\"\n    Decorates a figure with the boundary of rebit state space\n    and basis labels drawn from a :ref:`~qinfer.tomography.TomographyBasis`.\n\n    :param qinfer.tomography.TomographyBasis basis: Basis to use in\n        labeling axes.\n    :param list rebit_axes: List containing indices for the :math:`x`\n        and :math:`z` axes.\n    \"\"\"\n    ax = plt.gca()\n\n    if basis is not None:\n        labels = list(map(r'$\\langle\\!\\langle {} | \\rho \\rangle\\!\\rangle$'.format,\n            # Pick out the x and z by default.\n            [basis.labels[rebit_axes[0]], basis.labels[rebit_axes[1]]]\n        ))\n        plt.xlabel(labels[0])\n        plt.ylabel(labels[1])\n\n    ax.add_artist(plt.Circle([0, 0], 1, color='k', fill=False))\n    ax.set_xlim(-1.1, 1.1)\n    ax.set_ylim(-1.1, 1.1)\n    ax.set_aspect('equal')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the rebits of a given prior.", "response": "def plot_rebit_prior(prior, rebit_axes=REBIT_AXES,\n        n_samples=2000, true_state=None, true_size=250,\n        force_mean=None,\n        legend=True,\n        mean_color_index=2\n    ):\n    \"\"\"\n    Plots rebit states drawn from a given prior.\n\n    :param qinfer.tomography.DensityOperatorDistribution prior: Distribution over\n        rebit states to plot.\n    :param list rebit_axes: List containing indices for the :math:`x`\n        and :math:`z` axes.\n    :param int n_samples: Number of samples to draw from the\n        prior.\n    :param np.ndarray true_state: State to be plotted as a \"true\" state for\n        comparison.\n    \"\"\"\n    pallette = plt.rcParams['axes.color_cycle']\n\n    plot_rebit_modelparams(prior.sample(n_samples),\n        c=pallette[0],\n        label='Prior',\n        rebit_axes=rebit_axes\n    )\n\n    if true_state is not None:\n        plot_rebit_modelparams(true_state,\n            c=pallette[1],\n            label='True', marker='*', s=true_size,\n            rebit_axes=rebit_axes\n        )\n\n    if hasattr(prior, '_mean') or force_mean is not None:\n        mean = force_mean if force_mean is not None else prior._mean\n        plot_rebit_modelparams(\n            prior._basis.state_to_modelparams(mean)[None, :],\n            edgecolors=pallette[mean_color_index], s=250, facecolors='none', linewidth=3,\n            label='Mean',\n            rebit_axes=rebit_axes\n        )\n\n    plot_decorate_rebits(prior.basis,\n        rebit_axes=rebit_axes\n    )\n    if legend:\n        plt.legend(loc='lower left', ncol=3, scatterpoints=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_rebit_posterior(updater, prior=None, true_state=None, n_std=3, rebit_axes=REBIT_AXES, true_size=250,\n            legend=True,\n            level=0.95,\n            region_est_method='cov'\n    ):\n    \"\"\"\n    Plots posterior distributions over rebits, including covariance ellipsoids\n\n    :param qinfer.smc.SMCUpdater updater: Posterior distribution over rebits.\n    :param qinfer.tomography.DensityOperatorDistribution: Prior distribution\n        over rebit states.\n    :param np.ndarray true_state: Model parameters for \"true\" state to plot\n        as comparison.\n    :param float n_std: Number of standard deviations out from the mean\n        at which to draw the covariance ellipse. Only used if\n        region_est_method is ``'cov'``.\n    :param float level: Credibility level to use for computing\n        region estimators from convex hulls.\n    :param list rebit_axes: List containing indices for the :math:`x`\n        and :math:`z` axes.\n    :param str region_est_method: Method to use to draw region estimation.\n        Must be one of None, ``'cov'`` or ``'hull'``.\n    \"\"\"\n    pallette = plt.rcParams['axes.color_cycle']\n\n    plot_rebit_modelparams(updater.particle_locations,\n        c=pallette[0],\n        label='Posterior',\n        s=12 * np.sqrt(updater.particle_weights * len(updater.particle_weights)),\n        rebit_axes=rebit_axes,\n        zorder=-10\n    )\n\n    plot_rebit_modelparams(true_state,\n        c=pallette[1],\n        label='True', marker='*', s=true_size,\n        rebit_axes=rebit_axes\n    )\n\n    if prior is not None:\n        plot_rebit_modelparams(\n            prior._basis.state_to_modelparams(prior._mean)[None, :],\n            edgecolors=pallette[3], s=250, facecolors='none', linewidth=3,\n            label='Prior Mean',\n            rebit_axes=rebit_axes\n        )\n    plot_rebit_modelparams(\n        updater.est_mean()[None, :],\n        edgecolors=pallette[2], s=250, facecolors='none', linewidth=3,\n        label='Posterior Mean',\n        rebit_axes=rebit_axes\n    )\n\n    if region_est_method == 'cov':\n        # Multiplying by sqrt{2} to rescale to Bloch ball.\n        cov = 2 * updater.est_covariance_mtx()\n        # Use fancy indexing to cut out all but the desired submatrix.\n        cov = cov[rebit_axes, :][:, rebit_axes]\n        plot_cov_ellipse(\n            cov, updater.est_mean()[rebit_axes] * np.sqrt(2),\n            nstd=n_std,\n            edgecolor='k', fill=True, lw=2,\n            facecolor=pallette[0],\n            alpha=0.4,\n            zorder=-9,\n            label='Posterior Cov Ellipse ($Z = {}$)'.format(n_std)\n        )\n\n    elif region_est_method == 'hull':\n        # Find the convex hull from the updater, projected\n        # on the rebit axes.\n        faces, vertices = updater.region_est_hull(level, modelparam_slice=rebit_axes)\n        polygon = Polygon(vertices * np.sqrt(2),\n            facecolor=pallette[0], alpha=0.4, zorder=-9,\n            label=r'Credible Region ($\\alpha = {}$)'.format(level),\n            edgecolor='k', lw=2, fill=True\n        )\n        # TODO: consolidate add_patch code with that above.\n        plt.gca().add_patch(polygon)\n\n        \n    plot_decorate_rebits(updater.model.base_model._basis,\n        rebit_axes=rebit_axes\n    )\n\n    if legend:\n        plt.legend(loc='lower left', ncol=4, scatterpoints=1)", "response": "Plots posterior distributions over rebits."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives data as a NumPy array separates out each column either as a scalar array or as a field of an expparams array.", "response": "def data_to_params(data,\n        expparams_dtype,\n        col_outcomes=(0, 'counts'),\n        cols_expparams=None\n    ):\n    \"\"\"\n    Given data as a NumPy array, separates out each column either as\n    the outcomes, or as a field of an expparams array. Columns may be specified\n    either as indices into a two-axis scalar array, or as field names for a one-axis\n    record array.\n\n    Since scalar arrays are homogenous in type, this may result in loss of precision\n    due to casting between data types.\n    \"\"\"\n    BY_IDX, BY_NAME = range(2)\n\n    is_exp_scalar = np.issctype(expparams_dtype)\n    is_data_scalar = np.issctype(data.dtype) and not data.dtype.fields\n\n    s_ = (\n        (lambda idx: np.s_[..., idx[BY_IDX]])\n        if is_data_scalar else\n        (lambda idx: np.s_[idx[BY_NAME]])\n    )\n\n    outcomes = data[s_(col_outcomes)].astype(int)\n\n    # mk new slicer t\n\n    expparams = np.empty(outcomes.shape, dtype=expparams_dtype)\n    if is_exp_scalar:\n        expparams[:] = data[s_(cols_expparams)]\n    else:\n        for expparams_key, column in cols_expparams.items():\n            expparams[expparams_key] = data[s_(column)]\n\n    return outcomes, expparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nestimate a simple precession (cos\u00b2) from experimental data. Note that this model is mainly for testing purposes, as it does not consider the phase or amplitude of precession, leaving only the frequency. :param data: Data to be used in estimating the precession frequency. :type data: see :ref:`simple_est_data_arg` :param float freq_min: The minimum feasible frequency to consider. :param float freq_max: The maximum feasible frequency to consider. :param int n_particles: The number of particles to be used in estimating the precession frequency. :param bool return_all: Controls whether additional return values are provided, such as the updater. :column counts (int): How many counts were observed at the sampled time. :column t (float): The evolutions time at which the samples were collected. :column n_shots (int): How many samples were collected at the given evolution time. :return mean: Bayesian mean estimator for the precession frequency. :return var: Variance of the final posterior over frequency. :return extra: See :ref:`simple_est_extra_return`. Only returned if ``return_all`` is `True`.", "response": "def simple_est_prec(data, freq_min=0.0, freq_max=1.0, n_particles=6000, return_all=False):\n    \"\"\"\n    Estimates a simple precession (cos\u00b2) from experimental data.\n    Note that this model is mainly for testing purposes, as it does not\n    consider the phase or amplitude of precession, leaving only the frequency.\n\n    :param data: Data to be used in estimating the precession frequency.\n    :type data: see :ref:`simple_est_data_arg`\n    :param float freq_min: The minimum feasible frequency to consider.\n    :param float freq_max: The maximum feasible frequency to consider.\n    :param int n_particles: The number of particles to be used in estimating\n        the precession frequency.\n    :param bool return_all: Controls whether additional return\n        values are provided, such as the updater.\n\n    :column counts (int): How many counts were observed at the sampled\n        time.\n    :column t (float): The evolutions time at which the samples\n        were collected.\n    :column n_shots (int): How many samples were collected at the\n        given evolution time.\n\n    :return mean: Bayesian mean estimator for the precession frequency.\n    :return var: Variance of the final posterior over frequency.\n    :return extra: See :ref:`simple_est_extra_return`. Only returned\n        if ``return_all`` is `True`.\n    \"\"\"\n    model = BinomialModel(SimplePrecessionModel(freq_min))\n    prior = UniformDistribution([0, freq_max])\n\n    data = load_data_or_txt(data, [\n        ('counts', 'uint'),\n        ('t', float),\n        ('n_shots', 'uint')\n    ])\n\n    outcomes, expparams = data_to_params(data,\n        model.expparams_dtype,\n        cols_expparams={\n            'x': (1, 't'),\n            'n_meas': (2, 'n_shots')\n        }\n    )\n\n    return do_update(\n        model, n_particles, prior, outcomes, expparams,\n        return_all\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef simple_est_rb(data, interleaved=False, p_min=0.0, p_max=1.0, n_particles=8000, return_all=False):\n    model = BinomialModel(RandomizedBenchmarkingModel(interleaved=interleaved))\n    prior = PostselectedDistribution(UniformDistribution([\n            [p_min, p_max],\n            [0, 1],\n            [0, 1]\n        ] if not interleaved else [\n            [p_min, p_max],\n            [p_min, p_max],\n            [0, 1],\n            [0, 1]\n        ]),\n        model\n    )\n\n    data = load_data_or_txt(data, [\n        ('counts', 'uint'),\n        ('m', 'uint'),\n        ('n_shots', 'uint')\n    ] + ([\n        ('reference', 'uint')\n    ] if interleaved else []))\n\n    cols_expparams = {\n        'm': (1, 'm'),\n        'n_meas': (2, 'n_shots')\n    }\n    if interleaved:\n        cols_expparams['reference'] = (3, 'reference')\n\n    outcomes, expparams = data_to_params(data,\n        model.expparams_dtype,\n        cols_expparams=cols_expparams\n    )\n\n    return do_update(\n        model, n_particles, prior, outcomes, expparams,\n        return_all\n    )", "response": "r Estimates the fidelity of a gateset from a standard or interleaved randomized benchmarking model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing the model parameter tensor with truncated negative eigenvalues and renormalizes as appropriate.", "response": "def canonicalize(self, modelparams):\n        \"\"\"\n        Truncates negative eigenvalues and from each\n        state represented by a tensor of model parameter\n        vectors, and renormalizes as appropriate.\n\n        :param np.ndarray modelparams: Array of shape\n            ``(n_states, dim**2)`` containing model parameter\n            representations of each of ``n_states`` different\n            states.\n        :return: The same model parameter tensor with all\n            states truncated to be positive operators. If\n            :attr:`~TomographyModel.allow_subnormalized` is\n            `False`, all states are also renormalized to trace\n            one. \n        \"\"\"\n        modelparams = np.apply_along_axis(self.trunc_neg_eigs, 1, modelparams)\n        # Renormalizes particles if allow_subnormalized=False.\n        if not self._allow_subnormalied:\n            modelparams = self.renormalize(modelparams)\n\n        return modelparams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a state represented as a model parameter vector returns a model parameter vector representing the same state with any negative eigenvalues set to zero.", "response": "def trunc_neg_eigs(self, particle):\n        \"\"\"\n        Given a state represented as a model parameter vector,\n        returns a model parameter vector representing the same\n        state with any negative eigenvalues set to zero.\n\n        :param np.ndarray particle: Vector of length ``(dim ** 2, )``\n            representing a state.\n        :return: The same state with any negative eigenvalues\n            set to zero.\n        \"\"\"\n        arr = np.tensordot(particle, self._basis.data.conj(), 1)\n        w, v = np.linalg.eig(arr)\n        if np.all(w >= 0):\n            return particle\n        else:\n            w[w < 0] = 0\n            new_arr = np.dot(v * w, v.conj().T)\n            new_particle = np.real(np.dot(self._basis.flat(), new_arr.flatten()))\n            assert new_particle[0] > 0\n            return new_particle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef n_members(self):\n        if self.is_finite:\n            return reduce(mul, [domain.n_members for domain in self._domains], 1)\n        else:\n            return np.inf", "response": "Returns the number of members in the domain if is_finite otherwise returns np. inf."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an array containing all the values from the domain.", "response": "def values(self):\n        \"\"\"\n        Returns an `np.array` of type `dtype` containing\n        some values from the domain.\n        For domains where `is_finite` is ``True``, all elements\n        of the domain will be yielded exactly once.\n\n        :rtype: `np.ndarray`\n        \"\"\"\n        separate_values = [domain.values for domain in self._domains]\n        return np.concatenate([\n            join_struct_arrays(list(map(np.array, value))) \n            for value in product(*separate_values)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_regular_arrays(self, arrays):\n        return self._mytype(join_struct_arrays([\n            array.astype(dtype)\n            for dtype, array in zip(self._dtypes, arrays)\n        ]))", "response": "Merges a list of arrays of dtypes \n        corresponding to the factor domains into a single array \n        with the dtype of the ProductDomain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef in_domain(self, points):\n        return all([\n            domain.in_domain(array)\n            for domain, array in\n                zip(self._domains, separate_struct_array(points, self._dtypes))\n        ])", "response": "Returns True if all of the given points are in the domain False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef example_point(self):\n        if not np.isinf(self.min):\n            return np.array([self.min], dtype=self.dtype)\n        if not np.isinf(self.max):\n            return np.array([self.max], dtype=self.dtype)\n        else:\n            return np.array([0], dtype=self.dtype)", "response": "Returns any point guaranteed to be in the domain but not in the domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_domain(self, points):\n        if np.all(np.isreal(points)):\n            are_greater = np.all(np.greater_equal(points, self._min))\n            are_smaller = np.all(np.less_equal(points, self._max))\n            return  are_greater and are_smaller\n        else:\n            return False", "response": "Returns True if all of the given points are in the domain False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the minimum value of the domain.", "response": "def min(self):\n        \"\"\"\n        Returns the minimum value of the domain.\n\n        :rtype: `float` or `np.inf`\n        \"\"\"\n        return int(self._min) if not np.isinf(self._min) else self._min"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max(self):\n        return int(self._max) if not np.isinf(self._max) else self._max", "response": "Returns the maximum value of the domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_finite(self):\n        return not np.isinf(self.min) and not np.isinf(self.max)", "response": "Determines if the domain contains a finite number of points."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of members in the domain if is_finite otherwise returns np. inf.", "response": "def n_members(self):\n        \"\"\"\n        Returns the number of members in the domain if it\n        `is_finite`, otherwise, returns `np.inf`.\n\n        :type: ``int`` or ``np.inf``\n        \"\"\"\n        if self.is_finite:\n            return int(self.max - self.min + 1)\n        else:\n            return np.inf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef values(self):\n        if self.is_finite:\n            return np.arange(self.min, self.max + 1, dtype = self.dtype)\n        else:\n            return self.example_point", "response": "Returns an array containing all values from the domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef n_members(self):\n        return int(binom(self.n_meas + self.n_elements -1, self.n_elements - 1))", "response": "Returns the number of members in the domain if it is_finite otherwise returns None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef example_point(self):\n        return np.array([([self.n_meas] + [0] * (self.n_elements-1),)], dtype=self.dtype)", "response": "Returns any point guaranteed to be in the domain but\n        no other guarantees ; useful for testing purposes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an array containing all values from the domain.", "response": "def values(self):\n        \"\"\"\n        Returns an `np.array` of type `self.dtype` containing\n        some values from the domain.\n        For domains where ``is_finite`` is ``True``, all elements\n        of the domain will be yielded exactly once.\n\n        :rtype: `np.ndarray`\n        \"\"\"\n\n        # This code comes from Jared Goguen at http://stackoverflow.com/a/37712597/1082565\n        partition_array = np.empty((self.n_members, self.n_elements), dtype=int)\n        masks = np.identity(self.n_elements, dtype=int)\n        for i, c in enumerate(combinations_with_replacement(masks, self.n_meas)):\n            partition_array[i,:] = sum(c)\n\n        # Convert to dtype before returning\n        return self.from_regular_array(partition_array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert from an array of type int to an array of type int with an additional index labeling the tuple indeces.", "response": "def to_regular_array(self, A):\n        \"\"\"\n        Converts from an array of type `self.dtype` to an array\n        of type `int` with an additional index labeling the\n        tuple indeces.\n\n        :param np.ndarray A: An `np.array` of type `self.dtype`.\n\n        :rtype: `np.ndarray`\n        \"\"\"\n        # this could be a static method, but we choose to be consistent with\n        # from_regular_array\n        return A.view((int, len(A.dtype.names))).reshape(A.shape + (-1,))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert from an array of type int where the last index is assumed to have length self. n_elements.", "response": "def from_regular_array(self, A):\n        \"\"\"\n        Converts from an array of type `int` where the last index\n        is assumed to have length `self.n_elements` to an array\n        of type `self.d_type` with one fewer index.\n\n        :param np.ndarray A: An `np.array` of type `int`.\n\n        :rtype: `np.ndarray`\n        \"\"\"\n        dims = A.shape[:-1]\n        return A.reshape((np.prod(dims),-1)).view(dtype=self.dtype).squeeze(-1).reshape(dims)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if all of the given points are in the domain False otherwise.", "response": "def in_domain(self, points):\n        \"\"\"\n        Returns ``True`` if all of the given points are in the domain,\n        ``False`` otherwise.\n\n        :param np.ndarray points: An `np.ndarray` of type `self.dtype`.\n\n        :rtype: `bool`\n        \"\"\"\n        array_view = self.to_regular_array(points)\n        non_negative = np.all(np.greater_equal(array_view, 0))\n        correct_sum = np.all(np.sum(array_view, axis=-1) == self.n_meas)\n        return non_negative and correct_sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, max):\n        try:\n            self.widget.max = max\n            display(self.widget)\n        except:\n            pass", "response": "Starts the progress bar for a given maximum value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the likelihood function at the states specified by modelparams and measurement specified by expparams.", "response": "def likelihood(self, outcomes, modelparams, expparams):\n        \"\"\"\n        Calculates the likelihood function at the states specified \n        by modelparams and measurement specified by expparams.\n        This is given by the Born rule and is the probability of\n        outcomes given the state and measurement operator.\n        \n        Parameters\n        ----------\n        outcomes = \n            measurement outcome\n        expparams = \n            Bloch vector of measurement axis and visibility\n        modelparams = \n            quantum state Bloch vector\n        \"\"\"\n        \n        # By calling the superclass implementation, we can consolidate\n        # call counting there.\n        super(QubitStatePauliModel, self).likelihood(outcomes, modelparams, expparams)\n        \n        # Note that expparams['axis'] has shape (n_exp, 3).\n        pr0 = 0.5*(1 + np.sum(modelparams*expparams['axis'],1))\n        \n        # Note that expparams['vis'] has shape (n_exp, ).\n        pr0 = expparams['vis'] * pr0 + (1 - expparams['vis']) * 0.5\n\n        pr0 = pr0[:,np.newaxis]\n\n        # Now we concatenate over outcomes.\n        return Model.pr0_to_likelihood_array(outcomes, pr0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the likelihood function at the states specified by modelparams and measurement specified by expparams.", "response": "def likelihood(self, outcomes, modelparams, expparams):\n        \"\"\"\n        Calculates the likelihood function at the states specified \n        by modelparams and measurement specified by expparams.\n        This is given by the Born rule and is the probability of\n        outcomes given the state and measurement operator.\n        \n        Parameters\n        ----------\n        outcomes = \n            measurement outcome\n        expparams = \n            Bloch vector of measurement axis\n        modelparams = \n            quantum state Bloch vector\n        \"\"\"\n        \n        # By calling the superclass implementation, we can consolidate\n        # call counting there.\n        super(RebitStatePauliModel, self).likelihood(outcomes, modelparams, expparams)\n        \n        pr0 = np.zeros((modelparams.shape[0], expparams.shape[0]))\n        \n        # Note that expparams['axis'] has shape (n_exp, 3).\n        pr0 = 0.5*(1 + np.sum(modelparams*expparams['axis'],1))\n        \n        # Use the following hack if you don't want to ensure positive weights\n        pr0[pr0 < 0] = 0\n        pr0[pr0 > 1] = 1\n        \n        pr0 = pr0[:,np.newaxis]\n        \n        # Now we concatenate over outcomes.\n        return Model.pr0_to_likelihood_array(outcomes, pr0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the likelihood function at the states specified by modelparams and measurement specified by expparams.", "response": "def likelihood(self, outcomes, modelparams, expparams):\n        \"\"\"\n        Calculates the likelihood function at the states specified \n        by modelparams and measurement specified by expparams.\n        This is given by the Born rule and is the probability of\n        outcomes given the state and measurement operator.\n        \"\"\"\n        \n        # By calling the superclass implementation, we can consolidate\n        # call counting there.\n        super(MultiQubitStatePauliModel, self).likelihood(outcomes, modelparams, expparams)\n        \n        \n        # Note that expparams['axis'] has shape (n_exp, 3).\n        pr0 = 0.5*(1 + modelparams[:,expparams['pauli']])\n\n        # Use the following hack if you don't want to ensure positive weights\n        pr0[pr0 < 0] = 0\n        pr0[pr0 > 1] = 1\n        \n        # Note that expparams['vis'] has shape (n_exp, ).\n        pr0 = expparams['vis'] * pr0 + (1 - expparams['vis']) * 0.5\n\n        # Now we concatenate over outcomes.\n        return Model.pr0_to_likelihood_array(outcomes, pr0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simulate_experiment(self, modelparams, expparams, repeat=1):\n        super(PoisonedModel, self).simulate_experiment(modelparams, expparams, repeat)\n        return self.underlying_model.simulate_experiment(modelparams, expparams, repeat)", "response": "Simulates the experimental data according to the original model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of domains one for each input expparam.", "response": "def domain(self, expparams):\n        \"\"\"\n        Returns a list of ``Domain``s, one for each input expparam.\n\n        :param numpy.ndarray expparams:  Array of experimental parameters. This\n            array must be of dtype agreeing with the ``expparams_dtype``\n            property, or, in the case where ``n_outcomes_constant`` is ``True``,\n            ``None`` should be a valid input.\n\n        :rtype: list of ``Domain``\n        \"\"\"\n        return [IntegerDomain(min=0,max=n_o-1) for n_o in self.n_outcomes(expparams)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef underlying_likelihood(self, binary_outcomes, modelparams, expparams):\n        original_mps = modelparams[..., self._orig_mps_slice]\n        return self.underlying_model.likelihood(binary_outcomes, original_mps, expparams)", "response": "Returns the likelihood of the underlying model given outcomes hypothesized for the underlying model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an array of dtype uint describing the number of outcomes for each experiment specified by expparams.", "response": "def n_outcomes(self, expparams):\n        \"\"\"\n        Returns an array of dtype ``uint`` describing the number of outcomes\n        for each experiment specified by ``expparams``.\n        \n        :param numpy.ndarray expparams: Array of experimental parameters. This\n            array must be of dtype agreeing with the ``expparams_dtype``\n            property.\n        \"\"\"\n        # Standard combinatorial formula equal to the number of \n        # possible tuples whose non-negative integer entries sum to n_meas.\n        n = expparams['n_meas']\n        k = self.n_sides\n        return scipy.special.binom(n + k - 1, k - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of domains for each input experiment parameter.", "response": "def domain(self, expparams):\n        \"\"\"\n        Returns a list of :class:`Domain` objects, one for each input expparam.\n        :param numpy.ndarray expparams:  Array of experimental parameters. This\n            array must be of dtype agreeing with the ``expparams_dtype``\n            property.\n        :rtype: list of ``Domain``\n        \"\"\"\n        return [\n            MultinomialDomain(n_elements=self.n_sides, n_meas=ep['n_meas']) \n                for ep in expparams\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef est_update_covariance(self, modelparams):\n        if self._diagonal:\n            cov = (self._fixed_scale ** 2 if self._has_fixed_covariance \\\n                else np.mean(modelparams[:, self._srw_idxs] ** 2, axis=0))\n            cov = np.diag(cov)\n        else:\n            if self._has_fixed_covariance:\n                cov = np.dot(self._fixed_chol, self._fixed_chol.T)\n            else:\n                chol = np.zeros((modelparams.shape[0], self._n_rw, self._n_rw))\n                chol[(np.s_[:],) + self._srw_tri_idxs] = modelparams[:, self._srw_idxs]\n                cov = np.mean(np.einsum('ijk,ilk->ijl', chol, chol), axis=0)\n        return cov", "response": "Returns the covariance matrix for one \n        unit step."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True iff all of the given expparams correspond to outcome domains with the same dtype.", "response": "def are_expparam_dtypes_consistent(self, expparams):\n        \"\"\"\n        Returns ``True`` iff all of the given expparams \n        correspond to outcome domains with the same dtype.\n        For efficiency, concrete subclasses should override this method \n        if the result is always ``True``.\n\n        :param np.ndarray expparams: Array of expparamms \n             of type ``expparams_dtype``\n        :rtype: ``bool``\n        \"\"\"\n        if self.is_n_outcomes_constant:\n            # This implies that all domains are equal, so this must be true\n            return True\n\n        # otherwise we have to actually check all the dtypes\n        if expparams.size > 0:\n            domains = self.domain(expparams)\n            first_dtype = domains[0].dtype\n            return all(domain.dtype == first_dtype for domain in domains[1:])\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates the given model parameters and experimental parameters.", "response": "def simulate_experiment(self, modelparams, expparams, repeat=1):\n        \"\"\"\n        Produces data according to the given model parameters and experimental\n        parameters, structured as a NumPy array.\n\n        :param np.ndarray modelparams: A shape ``(n_models, n_modelparams)``\n            array of model parameter vectors describing the hypotheses under\n            which data should be simulated.\n        :param np.ndarray expparams: A shape ``(n_experiments, )`` array of\n            experimental control settings, with ``dtype`` given by \n            :attr:`~qinfer.Model.expparams_dtype`, describing the\n            experiments whose outcomes should be simulated.\n        :param int repeat: How many times the specified experiment should\n            be repeated.\n        :rtype: np.ndarray\n        :return: A three-index tensor ``data[i, j, k]``, where ``i`` is the repetition,\n            ``j`` indexes which vector of model parameters was used, and where\n            ``k`` indexes which experimental parameters where used. If ``repeat == 1``,\n            ``len(modelparams) == 1`` and ``len(expparams) == 1``, then a scalar\n            datum is returned instead.\n        \n        \"\"\"\n        self._sim_count += modelparams.shape[0] * expparams.shape[0] * repeat\n        assert(self.are_expparam_dtypes_consistent(expparams))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of Domain objects one for each input expparam.", "response": "def domain(self, expparams):\n        \"\"\"\n        Returns a list of :class:`Domain` objects, one for each input expparam.\n\n        :param numpy.ndarray expparams:  Array of experimental parameters. This\n            array must be of dtype agreeing with the ``expparams_dtype``\n            property, or, in the case where ``n_outcomes_constant`` is ``True``,\n            ``None`` should be a valid input.\n\n        :rtype: list of ``Domain``\n        \"\"\"\n        # As a convenience to most users, we define domain for them. If a \n        # fancier domain is desired, this method can easily be overridden.\n        if self.is_n_outcomes_constant:\n            return self._domain if expparams is None else [self._domain for ep in expparams]\n        else:\n            return [IntegerDomain(min=0,max=n_o-1) for n_o in self.n_outcomes(expparams)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pr0_to_likelihood_array(outcomes, pr0):\n        pr0 = pr0[np.newaxis, ...]\n        pr1 = 1 - pr0\n\n        if len(np.shape(outcomes)) == 0:\n            outcomes = np.array(outcomes)[None]\n                    \n        return np.concatenate([\n            pr0 if outcomes[idx] == 0 else pr1\n            for idx in range(safe_shape(outcomes))\n        ])", "response": "Assuming a two - outcome measurement with probabilities given by the\n            array pr0 returns an array of the form expected to be returned by thelikelihood method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Fisher information matrix for each possible outcome and the model parameters.", "response": "def fisher_information(self, modelparams, expparams):\n        \"\"\"\n        Returns the covariance of the score taken over possible outcomes,\n        known as the Fisher information.\n        \n        The result is represented as the four-index tensor\n        ``fisher[idx_modelparam_i, idx_modelparam_j, idx_model, idx_experiment]``,\n        which gives the Fisher information matrix for each model vector\n        and each experiment vector.\n        \n        .. note::\n            \n            The default implementation of this method calls\n            :meth:`~DifferentiableModel.score()` for each possible outcome,\n            which can be quite slow. If possible, overriding this method can\n            give significant speed advantages.\n        \"\"\"\n        \n        if self.is_n_outcomes_constant:\n            outcomes = np.arange(self.n_outcomes(expparams))\n            scores, L = self.score(outcomes, modelparams, expparams, return_L=True)\n            \n            assert len(scores.shape) in (3, 4)\n            \n            if len(scores.shape) == 3:\n                scores = scores[np.newaxis, :, :, :]\n            \n            # Note that E[score] = 0 by regularity assumptions, so we only\n            # need the expectation over the outer product.\n            return np.einsum(\"ome,iome,jome->ijme\",\n                L, scores, scores\n            )\n        else:\n            # Indexing will be a major pain here, so we need to start\n            # by making an empty array, so that index errors will be raised\n            # when (not if!) we make mistakes.\n            fisher = np.empty((\n                self.n_modelparams, self.n_modelparams,\n                modelparams.shape[0], expparams.shape[0]\n            ))\n            \n            # Now we loop over experiments, since we cannot vectorize the\n            # expectation value over data.\n            for idx_experiment, experiment in enumerate(expparams):\n                experiment = experiment.reshape((1,))\n                n_o = self.n_outcomes(experiment)\n            \n                outcomes = np.arange(n_o)\n                scores, L = self.score(outcomes, modelparams, experiment, return_L=True)\n                \n                fisher[:, :, :, idx_experiment] = np.einsum(\"ome,iome,jome->ijme\",\n                    L, scores, scores\n                )\n            \n            return fisher"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_qutip_module(required_version='3.2'):\n    try:\n        import qutip as qt\n        from distutils.version import LooseVersion\n        _qt_version = LooseVersion(qt.version.version)\n        if _qt_version < LooseVersion(required_version):\n            return None\n    except ImportError:\n        return None\n\n    return qt", "response": "Returns the qutip module or None if it can t be imported."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multinomial_pdf(n,p):\n\n    # work in log space to avoid overflow\n    log_N_fac = gammaln(np.sum(n, axis=0) + 1)[np.newaxis,...]\n    log_n_fac_sum = np.sum(gammaln(n + 1), axis=0)\n\n    # since working in log space, we need special\n    # consideration at p=0. deal with p=0, n>0 later.\n    def nlogp(n,p):\n        result = np.zeros(p.shape)\n        mask = p!=0\n        result[mask] = n[mask] * np.log(p[mask])\n        return result\n\n    if p.shape[0] == n.shape[0] - 1:\n        ep = np.empty(n.shape)\n        ep[:p.shape[0],...] = p\n        ep[-1,...] = 1-np.sum(p,axis=0)\n    else:\n        ep = p\n    log_p_sum = np.sum(nlogp(n, ep), axis=0)\n\n    probs = np.exp(log_N_fac - log_n_fac_sum + log_p_sum)\n\n    # if n_k>0 but p_k=0, the whole probability must be 0\n    mask = np.sum(np.logical_and(n!=0, ep==0), axis=0) == 0\n    probs = mask * probs\n\n    return probs[0,...]", "response": "r Returns the multinomial PDF of the multinomial distribution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample_multinomial(N, p, size=None):\n    # ensure s is array\n    s = np.array([1]) if size is None else np.array([size]).flatten()\n\n    def take_samples(ps):\n        # we have to flatten to make apply_along_axis work.\n        return np.random.multinomial(N, ps, np.prod(s)).flatten()\n\n    # should have shape (prod(size)*ps.shape[0], ps.shape[1:])\n    samples = np.apply_along_axis(take_samples, 0, p)\n    # should have shape (size, p.shape)\n    samples = samples.reshape(np.concatenate([s, p.shape]))\n    # should have shape (p.shape, size)\n    samples = samples.transpose(np.concatenate(\n        [np.arange(s.ndim, p.ndim+s.ndim), np.arange(s.ndim)]\n    ))\n\n    if size is None:\n        # get rid of trailing singleton dimension.\n        samples = samples[...,0]\n\n    return samples", "response": "r Draws fixed number of samples N from different\n    multinomial distributions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef particle_meanfn(weights, locations, fn=None):\n    warnings.warn('particle_meanfn is deprecated, please use distributions.ParticleDistribution',\n                  DeprecationWarning)\n    fn_vals = fn(locations) if fn is not None else locations\n    return np.sum(weights * fn_vals.transpose([1, 0]),\n        axis=1)", "response": "r Returns the mean of a function over model parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef particle_covariance_mtx(weights,locations):\n    # TODO: add shapes to docstring.\n    warnings.warn('particle_covariance_mtx is deprecated, please use distributions.ParticleDistribution',\n                  DeprecationWarning)\n\n    # Find the mean model vector, shape (n_modelparams, ).\n    mu = particle_meanfn(weights, locations)\n\n    # Transpose the particle locations to have shape\n    # (n_modelparams, n_particles).\n    xs = locations.transpose([1, 0])\n    # Give a shorter name to the particle weights, shape (n_particles, ).\n    ws = weights\n\n    cov = (\n        # This sum is a reduction over the particle index, chosen to be\n        # axis=2. Thus, the sum represents an expectation value over the\n        # outer product $x . x^T$.\n        #\n        # All three factors have the particle index as the rightmost\n        # index, axis=2. Using the Einstein summation convention (ESC),\n        # we can reduce over the particle index easily while leaving\n        # the model parameter index to vary between the two factors\n        # of xs.\n        #\n        # This corresponds to evaluating A_{m,n} = w_{i} x_{m,i} x_{n,i}\n        # using the ESC, where A_{m,n} is the temporary array created.\n        np.einsum('i,mi,ni', ws, xs, xs)\n        # We finish by subracting from the above expectation value\n        # the outer product $mu . mu^T$.\n        - np.dot(mu[..., np.newaxis], mu[np.newaxis, ...])\n    )\n\n    # The SMC approximation is not guaranteed to produce a\n    # positive-semidefinite covariance matrix. If a negative eigenvalue\n    # is produced, we should warn the caller of this.\n    assert np.all(np.isfinite(cov))\n    if not np.all(la.eig(cov)[0] >= 0):\n        warnings.warn('Numerical error in covariance estimation causing positive semidefinite violation.', ApproximationWarning)\n\n    return cov", "response": "Returns an estimate of the covariance matrix of a given set of SMC particle distributions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ellipsoid_volume(A=None, invA=None):\n\n    if invA is None and A is None:\n        raise ValueError(\"Must pass either inverse(A) or A.\")\n\n    if invA is None and A is not None:\n        invA = la.inv(A)\n\n    # Find the unit sphere volume.\n    # http://en.wikipedia.org/wiki/Unit_sphere#General_area_and_volume_formulas\n    n  = invA.shape[0]\n    Vn = (np.pi ** (n/2)) / gamma(1 + (n/2))\n\n    return Vn * la.det(sqrtm(invA))", "response": "Returns the volume of an ellipsoid given either its\n    matrix or the inverse of its matrix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the minimum - volume enclosing ellipse of a set of points using the Khachiyan algorithm.", "response": "def mvee(points, tol=0.001):\n    \"\"\"\n    Returns the minimum-volume enclosing ellipse (MVEE)\n    of a set of points, using the Khachiyan algorithm.\n    \"\"\"\n\n    # This function is a port of the matlab function by\n    # Nima Moshtagh found here:\n    # https://www.mathworks.com/matlabcentral/fileexchange/9542-minimum-volume-enclosing-ellipsoid\n    # with accompanying writup here:\n    # https://www.researchgate.net/profile/Nima_Moshtagh/publication/254980367_MINIMUM_VOLUME_ENCLOSING_ELLIPSOIDS/links/54aab5260cf25c4c472f487a.pdf\n\n    N, d = points.shape\n\n    Q = np.zeros([N,d+1])\n    Q[:,0:d] = points[0:N,0:d]\n    Q[:,d] = np.ones([1,N])\n\n    Q = np.transpose(Q)\n    points = np.transpose(points)\n    count = 1\n    err = 1\n    u = (1/N) * np.ones(shape = (N,))\n\n    while err > tol:\n\n        X = np.dot(np.dot(Q, np.diag(u)), np.transpose(Q))\n        M = np.diag( np.dot(np.dot(np.transpose(Q), la.inv(X)),Q))\n        jdx = np.argmax(M)\n        step_size = (M[jdx] - d - 1)/((d+1)*(M[jdx] - 1))\n        new_u = (1 - step_size)*u\n        new_u[jdx] = new_u[jdx] + step_size\n        count = count + 1\n        err = la.norm(new_u - u)\n        u = new_u\n\n    U = np.diag(u)\n    c = np.dot(points,u)\n    A = (1/d) * la.inv(np.dot(np.dot(points,U), np.transpose(points)) - np.outer(c,c) )\n    return A, np.transpose(c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef in_ellipsoid(x, A, c):\n    if x.ndim == 1:\n        y = c - x\n        return np.einsum('j,jl,l', y, np.linalg.inv(A), y) <= 1\n    else:\n        y = c[np.newaxis,:] - x\n        return np.einsum('ij,jl,il->i', y, np.linalg.inv(A), y) <= 1", "response": "Determines which of the points x are in the current closed ellipsoid with shape matrix A centered at c."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assert_sigfigs_equal(x, y, sigfigs=3):\n    # determine which power of 10 best describes x\n    xpow =  np.floor(np.log10(x))\n    # now rescale 1 \\leq x < 9\n    x = x * 10**(- xpow)\n    # scale y by the same amount\n    y = y * 10**(- xpow)\n\n    # now test if abs(x-y) < 0.5 * 10**(-sigfigs)\n    assert_almost_equal(x, y, sigfigs)", "response": "Tests if all elements in x and y agree up to a certain number of significant figures."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_uncertainty(value, uncertianty, scinotn_break=4):\n    if uncertianty == 0:\n        # Return the exact number, without the \u00b1 annotation as a fixed point\n        # number, since all digits matter.\n        # FIXME: this assumes a precision of 6; need to select that dynamically.\n        return \"{0:f}\".format(value)\n    else:\n        # Return a string of the form \"0.00 \\pm 0.01\".\n        mag_unc = int(np.log10(np.abs(uncertianty)))\n        # Zero should be printed as a single digit; that is, as wide as str \"1\".\n        mag_val = int(np.log10(np.abs(value))) if value != 0 else 0\n        n_digits = max(mag_val - mag_unc, 0)\n\n\n        if abs(mag_val) < abs(mag_unc) and abs(mag_unc) > scinotn_break:\n            # We're formatting something close to zero, so recale uncertianty\n            # accordingly.\n            scale = 10**mag_unc\n            return r\"({{0:0.{0}f}} \\pm {{1:0.{0}f}}) \\times 10^{{2}}\".format(\n                n_digits\n            ).format(\n                value / scale,\n                uncertianty / scale,\n                mag_unc\n           )\n        if abs(mag_val) <= scinotn_break:\n            return r\"{{0:0.{n_digits}f}} \\pm {{1:0.{n_digits}f}}\".format(n_digits=n_digits).format(value, uncertianty)\n        else:\n            scale = 10**mag_val\n            return r\"({{0:0.{0}f}} \\pm {{1:0.{0}f}}) \\times 10^{{2}}\".format(\n                n_digits\n            ).format(\n                value / scale,\n                uncertianty / scale,\n                mag_val\n           )", "response": "Given a value and its uncertianty format as LaTeX string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compactspace(scale, n):\n    logit = logistic(scale=scale).ppf\n    compact_xs = np.linspace(0, 1, n + 2)[1:-1]\n    return logit(compact_xs)", "response": "r Returns a list of points that are spaced in the open interval of the given scale factor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_simplex(y):\n    n = y.shape[-1]\n    # z are the stick breaking fractions in [0,1]\n    z = expit(y - np.log(n - np.arange(1, n+1)))\n    x = np.empty(y.shape)\n    x[..., 0] = z[..., 0]\n    x[..., 1:] = z[..., 1:] * (1 - z[..., :-1]).cumprod(axis=-1)\n    return x", "response": "r Converts a single index y into a unit simplex."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_simplex(x):\n    n = x.shape[-1]\n    # z are the stick breaking fractions in [0,1]\n    # the last one is always 1, so don't worry about it\n    z = np.empty(shape=x.shape)\n    z[..., 0] = x[..., 0]\n    z[..., 1:-1] = x[..., 1:-1] / (1 - x[..., :-2].cumsum(axis=-1))\n\n    # now z are the logit-transformed breaking fractions\n    z[..., :-1] = logit(z[..., :-1]) - logit(1 / (n - np.arange(n-1, dtype=np.float)))\n    # set this to 0 manually to avoid subtracting inf-inf\n    z[..., -1] = 0\n    return z", "response": "r Converts a simplex array into a logit - transformed version of the last index of x."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a list of possibly structured arrays concatenates their dtypes and returns one big array with that dtype. Does the inverse of separate_struct_array.", "response": "def join_struct_arrays(arrays):\n    \"\"\"\n    Takes a list of possibly structured arrays, concatenates their\n    dtypes, and returns one big array with that dtype. Does the\n    inverse of ``separate_struct_array``.\n\n    :param list arrays: List of ``np.ndarray``s\n    \"\"\"\n    # taken from http://stackoverflow.com/questions/5355744/numpy-joining-structured-arrays\n    sizes = np.array([a.itemsize for a in arrays])\n    offsets = np.r_[0, sizes.cumsum()]\n    shape = arrays[0].shape\n    joint = np.empty(shape + (offsets[-1],), dtype=np.uint8)\n    for a, size, offset in zip(arrays, sizes, offsets):\n        joint[...,offset:offset+size] = np.atleast_1d(a).view(np.uint8).reshape(shape + (size,))\n    dtype = sum((a.dtype.descr for a in arrays), [])\n    return joint.ravel().view(dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef separate_struct_array(array, dtypes):\n    try:\n        offsets = np.cumsum([np.dtype(dtype).itemsize for dtype in dtypes])\n    except TypeError:\n        dtype_size = np.dtype(dtypes).itemsize\n        num_fields = int(array.nbytes / (array.size * dtype_size))\n        offsets = np.cumsum([dtype_size] * num_fields)\n        dtypes = [dtypes] * num_fields\n    offsets = np.concatenate([[0], offsets]).astype(int)\n    uint_array = array.view(np.uint8).reshape(array.shape + (-1,))\n    return [\n        uint_array[..., offsets[idx]:offsets[idx+1]].flatten().view(dtype)\n        for idx, dtype in enumerate(dtypes)\n    ]", "response": "Takes an array with a structured dtype and separates it out into a list of arrays with dtypes coming from the input dtypes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the square root of a positive semidefinite matrix and truncating negative eigenvalues.", "response": "def sqrtm_psd(A, est_error=True, check_finite=True):\n    \"\"\"\n    Returns the matrix square root of a positive semidefinite matrix,\n    truncating negative eigenvalues.\n    \"\"\"\n    w, v = eigh(A, check_finite=check_finite)\n    mask = w <= 0\n    w[mask] = 0\n    np.sqrt(w, out=w)\n    A_sqrt = (v * w).dot(v.conj().T)\n\n    if est_error:\n        return A_sqrt, np.linalg.norm(np.dot(A_sqrt, A_sqrt) - A, 'fro')\n    else:\n        return A_sqrt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a class definition and a decorator that acts on methods, applies that decorator to the class' __init__ method. Useful for decorating __init__ while still allowing __init__ to be inherited.", "response": "def decorate_init(init_decorator):\n    \"\"\"\n    Given a class definition and a decorator that acts on methods,\n    applies that decorator to the class' __init__ method.\n    Useful for decorating __init__ while still allowing __init__ to be\n    inherited.\n    \"\"\"\n\n    def class_decorator(cls):\n        cls.__init__ = init_decorator(cls.__init__)\n        return cls\n\n    return class_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gell_mann_basis(dim):\n    # Start by making an empty array of the right shape to\n    # hold the matrices that we construct.\n    basis = np.zeros((dim**2, dim, dim), dtype=complex)\n\n    # The first matrix should be the identity.\n    basis[0, :, :] = np.eye(dim) / np.sqrt(dim)\n\n    # The next dim basis elements should be diagonal,\n    # with all by one element nonnegative.\n    for idx_basis in range(1, dim):\n        basis[idx_basis, :, :] = np.diag(np.concatenate([\n            np.ones((idx_basis, )),\n            [-idx_basis],\n            np.zeros((dim - idx_basis - 1, ))\n        ])) / np.sqrt(idx_basis + idx_basis**2)\n\n    # Finally, we get the off-diagonal matrices.\n    # These rely on some index gymnastics I don't yet fully\n    # understand.\n    y_offset = dim * (dim - 1) // 2\n    for idx_i in range(1, dim):\n        for idx_j in range(idx_i):\n            idx_basis = (idx_i - 1) * (idx_i) // 2 + idx_j + dim\n            basis[idx_basis, [idx_i, idx_j], [idx_j, idx_i]] = 1 / np.sqrt(2)\n            basis[idx_basis + y_offset, [idx_i, idx_j], [idx_j, idx_i]] = [1j / np.sqrt(2), -1j / np.sqrt(2)]\n\n    return TomographyBasis(basis, [dim], r'\\gamma', name='gell_mann_basis')", "response": "This function returns a MATLAB - language implementation of the Gell - Mann matrices on dim dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a TomographyBasis formed by the tensor product of two or more factor bases.", "response": "def tensor_product_basis(*bases):\n    \"\"\"\n    Returns a TomographyBasis formed by the tensor\n    product of two or more factor bases. Each basis element\n    is the tensor product of basis elements from the underlying\n    factors.\n    \"\"\"\n    dim = np.prod([basis.data.shape[1] for basis in bases])\n    tp_basis = np.zeros((dim**2, dim, dim), dtype=complex)\n\n    for idx_factors, factors in enumerate(it.product(*[basis.data for basis in bases])):\n        tp_basis[idx_factors, :, :] = reduce(np.kron, factors)\n\n    return TomographyBasis(tp_basis,\n        sum((\n            factor.dims for factor in bases\n        ), []),\n        list(map(\n        r\"\\otimes\".join,\n        it.product(*[\n            basis.labels for basis in bases\n        ])\n    )))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pauli_basis(nq=1):\n    basis = tensor_product_basis(*[\n        TomographyBasis(\n            gell_mann_basis(2).data[[0, 2, 3, 1]],\n            [2],\n            [u'\ud835\udfd9', r'\\sigma_x', r'\\sigma_y', r'\\sigma_z']\n        )\n    ] * nq)\n\n    basis._name = 'pauli_basis'\n    return basis", "response": "Returns a TomographyBasis for the Pauli basis on nq qubits."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a QuTiP - represented state into a vector of real parameters.", "response": "def state_to_modelparams(self, state):\n        \"\"\"\n        Converts a QuTiP-represented state into a model parameter vector.\n\n        :param qutip.Qobj state: State to be converted.\n        :rtype: :class:`np.ndarray`\n        :return: The representation of the given state in this basis,\n            as a vector of real parameters.\n        \"\"\"\n        basis = self.flat()\n        data = state.data.todense().view(np.ndarray).flatten()\n\n        # NB: assumes Hermitian state and basis!\n        return np.real(np.dot(basis.conj(), data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert one or more vectors of model parameters into QuTiP - represented states.", "response": "def modelparams_to_state(self, modelparams):\n        \"\"\"\n        Converts one or more vectors of model parameters into\n        QuTiP-represented states.\n\n        :param np.ndarray modelparams: Array of shape\n            ``(basis.dim ** 2, )`` or\n            ``(n_states, basis.dim ** 2)`` containing\n            states represented as model parameter vectors in this\n            basis.\n        :rtype: :class:`~qutip.Qobj` or `list` of :class:`~qutip.Qobj`\n            instances.\n        :return: The given states represented as :class:`~qutip.Qobj`\n            instances.\n        \"\"\"\n        if modelparams.ndim == 1:\n            qobj = qt.Qobj(\n                np.tensordot(modelparams, self.data, 1),\n                dims=[self.dims, self.dims]\n            )\n            if self.superrep is not None:\n                qobj.superrep = self.superrep\n            return qobj\n        else:\n            return list(map(self.modelparams_to_state, modelparams))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef covariance_mtx_to_superop(self, mtx):\n        M = self.flat()\n        return qt.Qobj(\n            np.dot(np.dot(M.conj().T, mtx), M),\n            dims=[[self.dims] * 2] * 2\n        )", "response": "Converts a covariance matrix to the corresponding\n            superoperator represented as a QuTiP Qobj with type = super."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef weighted_pairwise_distances(X, w, metric='euclidean', w_pow=0.5):\n\n    if sklearn is None:\n        raise ImportError(\"This function requires scikit-learn.\")\n\n    base_metric = sklearn.metrics.pairwise.pairwise_distances(X, metric=metric)\n    N = w.shape[0]\n    w_matrix = outer_product(w) * N**2\n\n    return base_metric / (w_matrix ** w_pow)", "response": "r Calculates the weighted pairwise distances between features X and w."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _dist_kw_arg(self, k):\n        if self._dist_kw_args is not None:\n            return {\n                key:self._dist_kw_args[key][k,:]\n                for key in self._dist_kw_args.keys()\n            }\n        else:\n            return {}", "response": "Returns a dictionary of keyword arguments for the k th distribution."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sample(self, n=1):\n        cumsum_weights = np.cumsum(self.particle_weights)\n        return self.particle_locations[np.minimum(cumsum_weights.searchsorted(\n            np.random.random((n,)),\n            side='right'\n        ), len(cumsum_weights) - 1)]", "response": "Returns random samples from the current particle distribution according\n            to particle weights."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an estimate of the mean of a given function over the current particle distribution.", "response": "def est_meanfn(self, fn):\n        \"\"\"\n        Returns an the expectation value of a given function\n        :math:`f` over the current particle distribution.\n\n        Here, :math:`f` is represented by a function ``fn`` that is vectorized\n        over particles, such that ``f(modelparams)`` has shape\n        ``(n_particles, k)``, where ``n_particles = modelparams.shape[0]``, and\n        where ``k`` is a positive integer.\n\n        :param callable fn: Function implementing :math:`f` in a vectorized\n            manner. (See above.)\n\n        :rtype: :class:`numpy.ndarray`, shape ``(k, )``.\n        :returns: An array containing the an estimate of the mean of :math:`f`.\n        \"\"\"\n\n        return np.einsum('i...,i...',\n            self.particle_weights, fn(self.particle_locations)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the full - rank covariance matrix of the current particle load information.", "response": "def est_covariance_mtx(self, corr=False):\n        \"\"\"\n        Returns the full-rank covariance matrix of the current particle\n        distribution.\n\n        :param bool corr: If `True`, the covariance matrix is normalized\n            by the outer product of the square root diagonal of the covariance matrix,\n            i.e. the correlation matrix is returned instead.\n\n        :rtype: :class:`numpy.ndarray`, shape\n            ``(n_modelparams, n_modelparams)``.\n        :returns: An array containing the estimated covariance matrix.\n        \"\"\"\n\n        cov = self.particle_covariance_mtx(self.particle_weights,\n                                           self.particle_locations)\n\n        if corr:\n            dstd = np.sqrt(np.diag(cov))\n            cov /= (np.outer(dstd, dstd))\n\n        return cov"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _kl_divergence(self, other_locs, other_weights, kernel=None, delta=1e-2):\n        if kernel is None:\n            kernel = st.norm(loc=0, scale=1).pdf\n\n        dist = rescaled_distance_mtx(self, other_locs) / delta\n        K = kernel(dist)\n\n        return -self.est_entropy() - (1 / delta) * np.sum(\n            self.particle_weights *\n            np.log(\n                np.sum(\n                    other_weights * K,\n                    axis=1 # Sum over the particles of ``other``.\n                )\n            ),\n            axis=0  # Sum over the particles of ``self``.\n        )", "response": "Calculates the KL divergence between this particle and another particle."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates the KL divergence between this particle and another particle distribution.", "response": "def est_kl_divergence(self, other, kernel=None, delta=1e-2):\n        \"\"\"\n        Finds the KL divergence between this and another particle\n        distribution by using a kernel density estimator to smooth over the\n        other distribution's particles.\n\n        :param SMCUpdater other:\n        \"\"\"\n        return self._kl_divergence(\n            other.particle_locations,\n            other.particle_weights,\n            kernel, delta\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef est_cluster_metric(self, cluster_opts=None):\n        wcv, bcv, tv = self.est_cluster_covs(cluster_opts)\n        return np.diag(bcv) / np.diag(tv)", "response": "Estimate the variance of the current posterior cluster"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestimating the credible region of a specific level.", "response": "def est_credible_region(self, level=0.95, return_outside=False, modelparam_slice=None):\n        \"\"\"\n        Returns an array containing particles inside a credible region of a\n        given level, such that the described region has probability mass\n        no less than the desired level.\n\n        Particles in the returned region are selected by including the highest-\n        weight particles first until the desired credibility level is reached.\n\n        :param float level: Crediblity level to report.\n        :param bool return_outside: If `True`, the return value is a tuple\n            of the those particles within the credible region, and the rest\n            of the posterior particle cloud.\n        :param slice modelparam_slice: Slice over which model parameters\n            to consider.\n\n        :rtype: :class:`numpy.ndarray`, shape ``(n_credible, n_mps)``,\n            where ``n_credible`` is the number of particles in the credible\n            region and ``n_mps`` corresponds to the size of ``modelparam_slice``.\n             If ``return_outside`` is ``True``, this method instead\n             returns tuple ``(inside, outside)`` where ``inside`` is as\n             described above, and ``outside`` has shape ``(n_particles-n_credible, n_mps)``.\n        :return: An array of particles inside the estimated credible region. Or,\n            if ``return_outside`` is ``True``, both the particles inside and the\n            particles outside, as a tuple.\n        \"\"\"\n\n        # which slice of modelparams to take\n        s_ = np.s_[modelparam_slice] if modelparam_slice is not None else np.s_[:]\n        mps = self.particle_locations[:, s_]\n\n        # Start by sorting the particles by weight.\n        # We do so by obtaining an array of indices `id_sort` such that\n        # `particle_weights[id_sort]` is in descending order.\n        id_sort = np.argsort(self.particle_weights)[::-1]\n\n        # Find the cummulative sum of the sorted weights.\n        cumsum_weights = np.cumsum(self.particle_weights[id_sort])\n\n        # Find all the indices where the sum is less than level.\n        # We first find id_cred such that\n        # `all(cumsum_weights[id_cred] <= level)`.\n        id_cred = cumsum_weights <= level\n        # By construction, by adding the next particle to id_cred, it must be\n        # true that `cumsum_weights[id_cred] >= level`, as required.\n        id_cred[np.sum(id_cred)] = True\n\n        # We now return a slice onto the particle_locations by first permuting\n        # the particles according to the sort order, then by selecting the\n        # credible particles.\n        if return_outside:\n            return (\n                mps[id_sort][id_cred],\n                mps[id_sort][np.logical_not(id_cred)]\n            )\n        else:\n            return mps[id_sort][id_cred]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef region_est_hull(self, level=0.95, modelparam_slice=None):\n        points = self.est_credible_region(\n            level=level,\n            modelparam_slice=modelparam_slice\n        )\n        hull = ConvexHull(points)\n\n        return points[hull.simplices], points[u.uniquify(hull.vertices.flatten())]", "response": "Estimates a credible region over models by taking the convex hull of the particles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining whether each of the points lie within a credible region.", "response": "def in_credible_region(self, points, level=0.95, modelparam_slice=None, method='hpd-hull', tol=0.0001):\n        \"\"\"\n        Decides whether each of the points lie within a credible region\n        of the current distribution.\n\n        If ``tol`` is ``None``, the particles are tested directly against\n        the convex hull object. If ``tol`` is a positive ``float``,\n        particles are tested to be in the interior of the smallest\n        enclosing ellipsoid of this convex hull, see\n        :meth:`SMCUpdater.region_est_ellipsoid`.\n\n        :param np.ndarray points: An ``np.ndarray`` of shape ``(n_mps)`` for\n            a single point, or of shape ``(n_points, n_mps)`` for multiple points,\n            where ``n_mps`` corresponds to the same dimensionality as ``param_slice``.\n        :param float level: The desired crediblity level (see\n            :meth:`SMCUpdater.est_credible_region`).\n        :param str method: A string specifying which credible region estimator to\n            use. One of ``'pce'``, ``'hpd-hull'`` or ``'hpd-mvee'`` (see below).\n        :param float tol: The allowed error tolerance for those methods\n            which require a tolerance (see :meth:`~qinfer.utils.mvee`).\n        :param slice modelparam_slice: A slice describing which model parameters\n            to consider in the credible region, effectively marginizing out the\n            remaining parameters. By default, all model parameters are included.\n\n        :return: A boolean array of shape ``(n_points, )`` specifying whether\n            each of the points lies inside the confidence region.\n\n        Methods\n        ~~~~~~~\n\n        The following values are valid for the ``method`` argument.\n\n        - ``'pce'``: Posterior Covariance Ellipsoid.\n            Computes the covariance\n            matrix of the particle distribution marginalized over the excluded\n            slices and uses the :math:`\\chi^2` distribution to determine\n            how to rescale it such the the corresponding ellipsoid has\n            the correct size. The ellipsoid is translated by the\n            mean of the particle distribution. It is determined which\n            of the ``points`` are on the interior.\n        - ``'hpd-hull'``: High Posterior Density Convex Hull.\n            See :meth:`SMCUpdater.region_est_hull`. Computes the\n            HPD region resulting from the particle approximation, computes\n            the convex hull of this, and it is determined which\n            of the ``points`` are on the interior.\n        - ``'hpd-mvee'``: High Posterior Density Minimum Volume Enclosing Ellipsoid.\n            See :meth:`SMCUpdater.region_est_ellipsoid`\n            and :meth:`~qinfer.utils.mvee`. Computes the\n            HPD region resulting from the particle approximation, computes\n            the convex hull of this, and determines the minimum enclosing\n            ellipsoid. Deterimines which\n            of the ``points`` are on the interior.\n        \"\"\"\n\n        if method == 'pce':\n            s_ = np.s_[modelparam_slice] if modelparam_slice is not None else np.s_[:]\n            A = self.est_covariance_mtx()[s_, s_]\n            c = self.est_mean()[s_]\n            # chi-squared distribution gives correct level curve conversion\n            mult = st.chi2.ppf(level, c.size)\n            results = u.in_ellipsoid(points, mult * A, c)\n\n        elif method == 'hpd-mvee':\n            tol = 0.0001 if tol is None else tol\n            A, c = self.region_est_ellipsoid(level=level, tol=tol, modelparam_slice=modelparam_slice)\n            results = u.in_ellipsoid(points, np.linalg.inv(A), c)\n\n        elif method == 'hpd-hull':\n            # it would be more natural to call region_est_hull,\n            # but that function uses ConvexHull which has no\n            # easy way of determining if a point is interior.\n            # Here, Delaunay gives us access to all of the\n            # necessary simplices.\n\n            # this fills the convex hull with (n_mps+1)-dimensional\n            # simplices; the convex hull is an almost-everywhere\n            # disjoint union of these simplices\n            hull = Delaunay(self.est_credible_region(level=level, modelparam_slice=modelparam_slice))\n\n            # now we just check whether each of the given points are in\n            # any of the simplices. (http://stackoverflow.com/a/16898636/1082565)\n            results = hull.find_simplex(points) >= 0\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample(self, n=1):\n        samples = np.empty((n, self.n_rvs))\n        idxs_to_sample = np.arange(n)\n\n        iters = 0\n\n        while idxs_to_sample.size and iters < self._maxiters:\n            samples[idxs_to_sample] = self._dist.sample(len(idxs_to_sample))\n\n            idxs_to_sample = idxs_to_sample[np.nonzero(np.logical_not(\n                self._model.are_models_valid(samples[idxs_to_sample, :])\n            ))[0]]\n\n            iters += 1\n\n        if idxs_to_sample.size:\n            raise RuntimeError(\"Did not successfully postselect within {} iterations.\".format(self._maxiters))\n\n        return samples", "response": "Returns one or more samples from this probability distribution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_actions(self):\n\n        # pylint: disable=too-many-locals\n        # pylint: disable=invalid-name\n        ns = '{urn:schemas-upnp-org:service-1-0}'\n        # get the scpd body as bytes, and feed directly to elementtree\n        # which likes to receive bytes\n        scpd_body = requests.get(self.base_url + self.scpd_url).content\n        tree = XML.fromstring(scpd_body)\n        # parse the state variables to get the relevant variable types\n        vartypes = {}\n        srvStateTables = tree.findall('{}serviceStateTable'.format(ns))\n        for srvStateTable in srvStateTables:\n            statevars = srvStateTable.findall('{}stateVariable'.format(ns))\n            for state in statevars:\n                name = state.findtext('{}name'.format(ns))\n                datatype = state.findtext('{}dataType'.format(ns))\n                default = state.findtext('{}defaultValue'.format(ns))\n                value_list_elt = state.find('{}allowedValueList'.format(ns))\n                if value_list_elt is None:\n                    value_list_elt = ()\n                value_list = [item.text for item in value_list_elt] or None\n                value_range_elt = state.find('{}allowedValueRange'.format(ns))\n                if value_range_elt is None:\n                    value_range_elt = ()\n                value_range = [item.text for item in value_range_elt] or None\n                vartypes[name] = Vartype(datatype, default, value_list,\n                                         value_range)\n        # find all the actions\n        actionLists = tree.findall('{}actionList'.format(ns))\n        for actionList in actionLists:\n            actions = actionList.findall('{}action'.format(ns))\n            for i in actions:\n                action_name = i.findtext('{}name'.format(ns))\n                argLists = i.findall('{}argumentList'.format(ns))\n                for argList in argLists:\n                    args_iter = argList.findall('{}argument'.format(ns))\n                    in_args = []\n                    out_args = []\n                    for arg in args_iter:\n                        arg_name = arg.findtext('{}name'.format(ns))\n                        direction = arg.findtext('{}direction'.format(ns))\n                        related_variable = arg.findtext(\n                            '{}relatedStateVariable'.format(ns))\n                        vartype = vartypes[related_variable]\n                        if direction == \"in\":\n                            in_args.append(Argument(arg_name, vartype))\n                        else:\n                            out_args.append(Argument(arg_name, vartype))\n                    yield Action(action_name, in_args, out_args)", "response": "Yields the service s actions with their arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the body of an UPnP event encoded by the UPnP API and return a dictionary containing the relevant properties.", "response": "def parse_event_xml(xml_event):\n    \"\"\"Parse the body of a UPnP event.\n\n    Args:\n        xml_event (bytes): bytes containing the body of the event encoded\n            with utf-8.\n\n    Returns:\n        dict: A dict with keys representing the evented variables. The\n            relevant value will usually be a string representation of the\n            variable's value, but may on occasion be:\n\n            * a dict (eg when the volume changes, the value will itself be a\n              dict containing the volume for each channel:\n              :code:`{'Volume': {'LF': '100', 'RF': '100', 'Master': '36'}}`)\n            * an instance of a `DidlObject` subclass (eg if it represents\n              track metadata).\n            * a `SoCoFault` (if a variable contains illegal metadata)\n\n    Example:\n\n        Run this code, and change your volume, tracks etc::\n\n            from __future__ import print_function\n            try:\n                from queue import Empty\n            except:  # Py2.7\n                from Queue import Empty\n\n            import soco\n            from pprint import pprint\n            from soco.events import event_listener\n            # pick a device at random\n            device = soco.discover().pop()\n            print (device.player_name)\n            sub = device.renderingControl.subscribe()\n            sub2 = device.avTransport.subscribe()\n\n            while True:\n                try:\n                    event = sub.events.get(timeout=0.5)\n                    pprint (event.variables)\n                except Empty:\n                    pass\n                try:\n                    event = sub2.events.get(timeout=0.5)\n                    pprint (event.variables)\n                except Empty:\n                    pass\n\n                except KeyboardInterrupt:\n                    sub.unsubscribe()\n                    sub2.unsubscribe()\n                    event_listener.stop()\n                    break\n    \"\"\"\n\n    result = {}\n    tree = XML.fromstring(xml_event)\n    # property values are just under the propertyset, which\n    # uses this namespace\n    properties = tree.findall(\n        '{urn:schemas-upnp-org:event-1-0}property')\n    for prop in properties:  # pylint: disable=too-many-nested-blocks\n        for variable in prop:\n            # Special handling for a LastChange event specially. For details on\n            # LastChange events, see\n            # http://upnp.org/specs/av/UPnP-av-RenderingControl-v1-Service.pdf\n            # and http://upnp.org/specs/av/UPnP-av-AVTransport-v1-Service.pdf\n            if variable.tag == \"LastChange\":\n                last_change_tree = XML.fromstring(\n                    variable.text.encode('utf-8'))\n                # We assume there is only one InstanceID tag. This is true for\n                # Sonos, as far as we know.\n                # InstanceID can be in one of two namespaces, depending on\n                # whether we are looking at an avTransport event, a\n                # renderingControl event, or a Queue event\n                # (there, it is named QueueID)\n                instance = last_change_tree.find(\n                    \"{urn:schemas-upnp-org:metadata-1-0/AVT/}InstanceID\")\n                if instance is None:\n                    instance = last_change_tree.find(\n                        \"{urn:schemas-upnp-org:metadata-1-0/RCS/}InstanceID\")\n                if instance is None:\n                    instance = last_change_tree.find(\n                        \"{urn:schemas-sonos-com:metadata-1-0/Queue/}QueueID\")\n                # Look at each variable within the LastChange event\n                for last_change_var in instance:\n                    tag = last_change_var.tag\n                    # Remove any namespaces from the tags\n                    if tag.startswith('{'):\n                        tag = tag.split('}', 1)[1]\n                    # Un-camel case it\n                    tag = camel_to_underscore(tag)\n                    # Now extract the relevant value for the variable.\n                    # The UPnP specs suggest that the value of any variable\n                    # evented via a LastChange Event will be in the 'val'\n                    # attribute, but audio related variables may also have a\n                    # 'channel' attribute. In addition, it seems that Sonos\n                    # sometimes uses a text value instead: see\n                    # http://forums.sonos.com/showthread.php?t=34663\n                    value = last_change_var.get('val')\n                    if value is None:\n                        value = last_change_var.text\n                    # If DIDL metadata is returned, convert it to a music\n                    # library data structure\n                    if value.startswith('<DIDL-Lite'):\n                        # Wrap any parsing exception in a SoCoFault, so the\n                        # user can handle it\n                        try:\n                            didl = from_didl_string(value)\n                            if not didl:\n                                continue\n                            value = didl[0]\n                        except SoCoException as original_exception:\n                            log.debug(\"Event contains illegal metadata\"\n                                      \"for '%s'.\\n\"\n                                      \"Error message: '%s'\\n\"\n                                      \"The result will be a SoCoFault.\",\n                                      tag, str(original_exception))\n                            event_parse_exception = EventParseException(\n                                tag, value, original_exception\n                            )\n                            value = SoCoFault(event_parse_exception)\n                    channel = last_change_var.get('channel')\n                    if channel is not None:\n                        if result.get(tag) is None:\n                            result[tag] = {}\n                        result[tag][channel] = value\n                    else:\n                        result[tag] = value\n            else:\n                result[camel_to_underscore(variable.tag)] = variable.text\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unsubscribe(self):\n        # Trying to unsubscribe if already unsubscribed, or not yet\n        # subscribed, fails silently\n        if self._has_been_unsubscribed or not self.is_subscribed:\n            return\n\n        # Cancel any auto renew\n        self._auto_renew_thread_flag.set()\n        # Send an unsubscribe request like this:\n        # UNSUBSCRIBE publisher path HTTP/1.1\n        # HOST: publisher host:publisher port\n        # SID: uuid:subscription UUID\n        headers = {\n            'SID': self.sid\n        }\n        response = None\n        try:\n            response = requests.request(\n                'UNSUBSCRIBE',\n                self.service.base_url + self.service.event_subscription_url,\n                headers=headers,\n                timeout=3)\n        except requests.exceptions.RequestException:\n            pass\n\n        self.is_subscribed = False\n        self._timestamp = None\n        log.info(\n            \"Unsubscribed from %s, sid: %s\",\n            self.service.base_url + self.service.event_subscription_url,\n            self.sid)\n        # remove queue from event queues and sid to service mappings\n\n        with _subscriptions_lock:\n            try:\n                del _subscriptions[self.sid]\n            except KeyError:\n                pass\n        self._has_been_unsubscribed = True\n\n        # Ignore \"412 Client Error: Precondition Failed for url:\"\n        # from rebooted speakers.\n        if response and response.status_code != 412:\n            response.raise_for_status()", "response": "Unsubscribe from the service s events."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the speaker s mode.", "response": "def play_mode(self, playmode):\n        \"\"\"Set the speaker's mode.\"\"\"\n        playmode = playmode.upper()\n        if playmode not in PLAY_MODES.keys():\n            raise KeyError(\"'%s' is not a valid play mode\" % playmode)\n\n        self.avTransport.SetPlayMode([\n            ('InstanceID', 0),\n            ('NewPlayMode', playmode)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef repeat(self, repeat):\n        shuffle = self.shuffle\n        self.play_mode = PLAY_MODE_BY_MEANING[(shuffle, repeat)]", "response": "Set the queue s repeat option"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cross_fade(self):\n\n        response = self.avTransport.GetCrossfadeMode([\n            ('InstanceID', 0),\n        ])\n        cross_fade_state = response['CrossfadeMode']\n        return bool(int(cross_fade_state))", "response": "Returns True if the speaker s cross fade state. False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mute(self):\n\n        response = self.renderingControl.GetMute([\n            ('InstanceID', 0),\n            ('Channel', 'Master')\n        ])\n        mute_state = response['CurrentMute']\n        return bool(int(mute_state))", "response": "Returns True if the speaker s mute state False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if on False otherwise.", "response": "def loudness(self):\n        \"\"\"bool: The Sonos speaker's loudness compensation.\n\n        True if on, False otherwise.\n\n        Loudness is a complicated topic. You can find a nice summary about this\n        feature here: http://forums.sonos.com/showthread.php?p=4698#post4698\n        \"\"\"\n        response = self.renderingControl.GetLoudness([\n            ('InstanceID', 0),\n            ('Channel', 'Master'),\n        ])\n        loudness = response[\"CurrentLoudness\"]\n        return bool(int(loudness))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\njoin this speaker to another master speaker.", "response": "def join(self, master):\n        \"\"\"Join this speaker to another \"master\" speaker.\"\"\"\n        self.avTransport.SetAVTransportURI([\n            ('InstanceID', 0),\n            ('CurrentURI', 'x-rincon:{0}'.format(master.uid)),\n            ('CurrentURIMetaData', '')\n        ])\n        self._zgs_cache.clear()\n        self._parse_zone_group_state()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unjoin(self):\n\n        self.avTransport.BecomeCoordinatorOfStandaloneGroup([\n            ('InstanceID', 0)\n        ])\n        self._zgs_cache.clear()\n        self._parse_zone_group_state()", "response": "Remove this speaker from a group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the sleep timer for the current node.", "response": "def set_sleep_timer(self, sleep_time_seconds):\n        \"\"\"Sets the sleep timer.\n\n        Args:\n            sleep_time_seconds (int or NoneType): How long to wait before\n                turning off speaker in seconds, None to cancel a sleep timer.\n                Maximum value of 86399\n\n        Raises:\n            SoCoException: Upon errors interacting with Sonos controller\n            ValueError: Argument/Syntax errors\n\n        \"\"\"\n        # Note: A value of None for sleep_time_seconds is valid, and needs to\n        # be preserved distinctly separate from 0. 0 means go to sleep now,\n        # which will immediately start the sound tappering, and could be a\n        # useful feature, while None means cancel the current timer\n        try:\n            if sleep_time_seconds is None:\n                sleep_time = ''\n            else:\n                sleep_time = format(\n                    datetime.timedelta(seconds=int(sleep_time_seconds))\n                )\n            self.avTransport.ConfigureSleepTimer([\n                ('InstanceID', 0),\n                ('NewSleepTimerDuration', sleep_time),\n            ])\n        except SoCoUPnPException as err:\n            if 'Error 402 received' in str(err):\n                raise ValueError('invalid sleep_time_seconds, must be integer \\\n                    value between 0 and 86399 inclusive or None')\n            raise\n        except ValueError:\n            raise ValueError('invalid sleep_time_seconds, must be integer \\\n                value between 0 and 86399 inclusive or None')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore(self, fade=False):\n\n        try:\n            if self.is_coordinator:\n                self._restore_coordinator()\n        finally:\n            self._restore_volume(fade)\n\n        # Now everything is set, see if we need to be playing, stopped\n        # or paused ( only for coordinators)\n        if self.is_coordinator:\n            if self.transport_state == 'PLAYING':\n                self.device.play()\n            elif self.transport_state == 'STOPPED':\n                self.device.stop()", "response": "Restores the state of a device to that which was previously saved."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _restore_coordinator(self):\n        # Start by ensuring that the speaker is paused as we don't want\n        # things all rolling back when we are changing them, as this could\n        # include things like audio\n        transport_info = self.device.get_current_transport_info()\n        if transport_info is not None:\n            if transport_info['current_transport_state'] == 'PLAYING':\n                self.device.pause()\n\n        # Check if the queue should be restored\n        self._restore_queue()\n\n        # Reinstate what was playing\n\n        if self.is_playing_queue and self.playlist_position > 0:\n            # was playing from playlist\n\n            if self.playlist_position is not None:\n                # The position in the playlist returned by\n                # get_current_track_info starts at 1, but when\n                # playing from playlist, the index starts at 0\n                # if position > 0:\n                self.playlist_position -= 1\n                self.device.play_from_queue(self.playlist_position, False)\n\n            if self.track_position is not None:\n                if self.track_position != \"\":\n                    self.device.seek(self.track_position)\n\n            # reinstate track, position, play mode, cross fade\n            # Need to make sure there is a proper track selected first\n            self.device.play_mode = self.play_mode\n            self.device.cross_fade = self.cross_fade\n\n        elif self.is_playing_cloud_queue:\n            # was playing a cloud queue started by Alexa\n            # No way yet to re-start this so prevent it throwing an error!\n            pass\n\n        else:\n            # was playing a stream (radio station, file, or nothing)\n            # reinstate uri and meta data\n            if self.media_uri != \"\":\n                self.device.play_uri(\n                    self.media_uri, self.media_metadata, start=False)", "response": "Restores the current state of the current item in the system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _restore_volume(self, fade):\n        self.device.mute = self.mute\n\n        # Can only change volume on device with fixed volume set to False\n        # otherwise get uPnP error, so check first. Before issuing a network\n        # command to check, fixed volume always has volume set to 100.\n        # So only checked fixed volume if volume is 100.\n        if self.volume == 100:\n            fixed_vol = self.device.renderingControl.GetOutputFixed(\n                [('InstanceID', 0)])['CurrentFixed']\n        else:\n            fixed_vol = False\n\n        # now set volume if not fixed\n        if not fixed_vol:\n            self.device.bass = self.bass\n            self.device.treble = self.treble\n            self.device.loudness = self.loudness\n\n            if fade:\n                # if fade requested in restore\n                # set volume to 0 then fade up to saved volume (non blocking)\n                self.device.volume = 0\n                self.device.ramp_to_volume(self.volume)\n            else:\n                # set volume\n                self.device.volume = self.volume", "response": "Reinstate the volume of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndiscovering Sonos zones on the local network.", "response": "def _discover_thread(callback,\n                     timeout,\n                     include_invisible,\n                     interface_addr):\n    \"\"\" Discover Sonos zones on the local network. \"\"\"\n\n    def create_socket(interface_addr=None):\n        \"\"\" A helper function for creating a socket for discover purposes.\n\n        Create and return a socket with appropriate options set for multicast.\n        \"\"\"\n\n        _sock = socket.socket(\n            socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        # UPnP v1.0 requires a TTL of 4\n        _sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL,\n                         struct.pack(\"B\", 4))\n        _sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n        if interface_addr is not None:\n            _sock.setsockopt(\n                socket.IPPROTO_IP, socket.IP_MULTICAST_IF,\n                socket.inet_aton(interface_addr))\n        return _sock\n\n    # pylint: disable=invalid-name\n    PLAYER_SEARCH = dedent(\"\"\"\\\n        M-SEARCH * HTTP/1.1\n        HOST: 239.255.255.250:1900\n        MAN: \"ssdp:discover\"\n        MX: 1\n        ST: urn:schemas-upnp-org:device:ZonePlayer:1\n        \"\"\").encode('utf-8')\n    BCAST_ADDR = \"255.255.255.255\"\n    MCAST_GRP = \"239.255.255.250\"\n    MCAST_PORT = 1900\n\n    _sockets = {}\n    # Use the specified interface, if any\n    if interface_addr is not None:\n        try:\n            address = socket.inet_aton(interface_addr)\n        except socket.error:\n            raise ValueError(\"{0} is not a valid IP address string\".format(\n                interface_addr))\n        _sockets[interface_addr] = create_socket(interface_addr)\n        _LOG.info(\"Sending discovery packets on default interface\")\n    else:\n        # Find the local network addresses using ifaddr.\n        addresses = [\n            ip.ip\n            for adapter in ifaddr.get_adapters()\n            for ip in adapter.ips\n            if ip.is_IPv4\n            if ip.ip != \"127.0.0.1\"\n        ]\n\n        # Create a socket for each unique address found, and one for the\n        # default multicast address\n        for address in addresses:\n            try:\n                _sockets[address] = create_socket(address)\n            except socket.error as e:\n                _LOG.warning(\"Can't make a discovery socket for %s: %s: %s\",\n                             address, e.__class__.__name__, e)\n\n    found_zones = set()\n    deadline = time.monotonic() + timeout\n    last_response = None\n    while not threading.current_thread().stopped():\n        time_left = deadline - time.monotonic()\n        if time_left < 0:\n            break\n\n        # Repeated sending, UDP is unreliable\n        if last_response is None or last_response < time.monotonic() - 1:\n            for _addr, _sock in _sockets.items():\n                try:\n                    _LOG.info(\"Sending discovery packets on %s\", _addr)\n                    _sock.sendto(\n                        really_utf8(PLAYER_SEARCH), (MCAST_GRP, MCAST_PORT))\n                    _sock.sendto(\n                        really_utf8(PLAYER_SEARCH), (BCAST_ADDR, MCAST_PORT))\n                except OSError:\n                    _LOG.info(\"Discovery failed on %s\", _addr)\n\n        response, _, _ = select.select(\n            list(_sockets.values()), [], [], min(1, time_left))\n\n        # Only Zone Players should respond, given the value of ST in the\n        # PLAYER_SEARCH message. However, to prevent misbehaved devices\n        # on the network disrupting the discovery process, we check that\n        # the response contains the \"Sonos\" string; otherwise we keep\n        # waiting for a correct response.\n        #\n        # Here is a sample response from a real Sonos device (actual numbers\n        # have been redacted):\n        # HTTP/1.1 200 OK\n        # CACHE-CONTROL: max-age = 1800\n        # EXT:\n        # LOCATION: http://***.***.***.***:1400/xml/device_description.xml\n        # SERVER: Linux UPnP/1.0 Sonos/26.1-76230 (ZPS3)\n        # ST: urn:schemas-upnp-org:device:ZonePlayer:1\n        # USN: uuid:RINCON_B8*************00::urn:schemas-upnp-org:device:\n        #                                                     ZonePlayer:1\n        # X-RINCON-BOOTSEQ: 3\n        # X-RINCON-HOUSEHOLD: Sonos_7O********************R7eU\n\n        for _sock in response:\n            last_response = time.monotonic()\n            data, addr = _sock.recvfrom(1024)\n            _LOG.debug(\n                'Received discovery response from %s: \"%s\"', addr, data\n            )\n            if b\"Sonos\" in data:\n                # pylint: disable=not-callable\n                zone = config.SOCO_CLASS(addr[0])\n                if zone not in found_zones:\n                    if zone.is_visible or include_invisible:\n                        found_zones.add(zone)\n                        callback(zone)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a started thread with a discovery callback.", "response": "def discover_thread(callback,\n                    timeout=5,\n                    include_invisible=False,\n                    interface_addr=None):\n    \"\"\" Return a started thread with a discovery callback. \"\"\"\n    thread = StoppableThread(\n        target=_discover_thread,\n        args=(callback, timeout, include_invisible, interface_addr))\n    thread.start()\n    return thread"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discover(timeout=5,\n             include_invisible=False,\n             interface_addr=None,\n             all_households=False):\n    \"\"\" Discover Sonos zones on the local network.\n\n    Return a set of `SoCo` instances for each zone found.\n    Include invisible zones (bridges and slave zones in stereo pairs if\n    ``include_invisible`` is `True`. Will block for up to ``timeout`` seconds,\n     after which return `None` if no zones found.\n\n    Args:\n        timeout (int, optional): block for this many seconds, at most.\n            Defaults to 5.\n        include_invisible (bool, optional): include invisible zones in the\n            return set. Defaults to `False`.\n        interface_addr (str or None): Discovery operates by sending UDP\n            multicast datagrams. ``interface_addr`` is a string (dotted\n            quad) representation of the network interface address to use as\n            the source of the datagrams (i.e. it is a value for\n            `socket.IP_MULTICAST_IF <socket>`). If `None` or not specified,\n            all system interfaces will be tried. Defaults to `None`.\n        all_households (bool, optional): wait for all replies to discover\n            multiple households. If `False` or not specified, return only\n            the first household found.\n    Returns:\n        set: a set of `SoCo` instances, one for each zone found, or else\n            `None`.\n\n    \"\"\"\n\n    found_zones = set()\n    first_response = None\n\n    def callback(zone):\n        nonlocal first_response\n\n        if first_response is None:\n            first_response = time.monotonic()\n\n        if include_invisible:\n            found_zones.update(zone.all_zones)\n        else:\n            found_zones.update(zone.visible_zones)\n\n        if not all_households:\n            thread.stop()\n\n    thread = discover_thread(\n        callback, timeout, include_invisible, interface_addr)\n    while thread.is_alive() and not thread.stopped():\n        if first_response is None:\n            thread.join(timeout=1)\n        else:\n            thread.join(timeout=first_response + 1 - time.monotonic())\n            thread.stop()\n\n    return found_zones or None", "response": "Discover Sonos zones on the local network."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a device by name.", "response": "def by_name(name):\n    \"\"\"Return a device by name.\n\n    Args:\n        name (str): The name of the device to return.\n\n    Returns:\n        :class:`~.SoCo`: The first device encountered among all zone with the\n            given player name. If none are found `None` is returned.\n    \"\"\"\n    devices = discover(all_households=True)\n    for device in (devices or []):\n        if device.player_name == name:\n            return device\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ascii(pid=None, name=None, pokemons=None, return_pokemons=False, message=None):\n    '''get_ascii will return ascii art for a pokemon based on a name or pid.\n    :param pid: the pokemon ID to return\n    :param name: the pokemon name to return\n    :param return_pokemons: return catches (default False)\n    :param message: add a message to the ascii\n    '''\n    pokemon = get_pokemon(name=name,pid=pid,pokemons=pokemons)\n    printme = message\n    if len(pokemon) > 0:\n        for pid,data in pokemon.items():\n            if message == None:\n                printme = data[\"name\"].capitalize()\n            print(\"%s\\n\\n%s\" % (data['ascii'],printme))\n          \n    if return_pokemons == True:\n        return pokemon", "response": "get_ascii will return ascii art for a pokemon based on a name or pid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_avatar(name, pokemons=None, print_screen=True, include_name=True):\n    '''get_avatar will return a unique pokemon for a specific avatar based on the hash\n    :param name: the name to look up\n    :param print_screen: if True, will print ascii to the screen (default True) and not return\n    :param include_name: if True, will add name (minus end of address after @) to avatar\n    '''\n    if pokemons is None:\n        pokemons = catch_em_all()\n\n    # The IDs are numbers between 1 and the max\n    number_pokemons = len(pokemons)\n\n    trainer = get_trainer(name)\n\n    pid = str(trainer % number_pokemons)\n    pokemon = get_pokemon(pid=pid,pokemons=pokemons)\n\n    avatar = pokemon[pid][\"ascii\"]\n    if include_name is True:\n        avatar = \"%s\\n\\n%s\" %(avatar,name.split(\"@\")[0])\n    if print_screen is True:\n        print(avatar)\n    return avatar", "response": "get_avatar will return a unique pokemon for a specific name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_trainer(name):\n    '''return the unique id for a trainer, determined by the md5 sum\n    '''\n    name = name.lower()\n    return int(hashlib.md5(name.encode('utf-8')).hexdigest(), 16) % 10**8", "response": "return the unique id for a trainer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup_pokemon(field,value,pokemons=None):\n    '''lookup_pokemon will search a particular field (name) for a value. If no pokemons\n    data structure is provided, all will be used.\n    :param field: the field to look up.\n    :param pokemons: the pokemons data structure\n    '''\n    if pokemons == None:\n        pokemons = catch_em_all()\n\n    catches = {}\n    for pid,data in pokemons.items():\n        if isinstance(data[field],list):\n            for entry in data[field]:\n                found = search_entry(entry,value)        \n                if found == True:\n                    catches[pid] = data\n        else:\n            found = search_entry(data[field],value)\n            if found == True:\n                catches[pid] = data\n                            \n    if len(catches) > 0:\n        return catches\n    return None", "response": "search_pokemon will search a particular field for a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scale_image(image, new_width):\n    (original_width, original_height) = image.size\n    aspect_ratio = original_height/float(original_width)\n    new_height = int(aspect_ratio * new_width)\n\n    # This scales it wider than tall, since characters are biased\n    new_image = image.resize((new_width*2, new_height))\n    return new_image", "response": "Resizes an image preserving the aspect ratio."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps each pixel to an ascii char based on the range .", "response": "def map_pixels_to_ascii_chars(image, range_width=25):\n    \"\"\"Maps each pixel to an ascii char based on the range\n    in which it lies.\n\n    0-255 is divided into 11 ranges of 25 pixels each.\n    \"\"\"\n\n    pixels_in_image = list(image.getdata())\n    pixels_to_chars = [ASCII_CHARS[pixel_value/range_width] for pixel_value in\n            pixels_in_image]\n\n    return \"\".join(pixels_to_chars)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a list of steps from a CWL file.", "response": "def load_steps(working_dir=None, steps_dir=None, step_file=None,\n               step_list=None):\n    \"\"\"Return a dictionary containing Steps read from file.\n\n    Args:\n        steps_dir (str, optional): path to directory containing CWL files.\n        step_file (str, optional): path or http(s) url to a single CWL file.\n        step_list (list, optional): a list of directories, urls or local file\n            paths to CWL files or directories containing CWL files.\n\n    Return:\n        dict containing (name, Step) entries.\n\n    \"\"\"\n    if steps_dir is not None:\n        step_files = glob.glob(os.path.join(steps_dir, '*.cwl'))\n    elif step_file is not None:\n        step_files = [step_file]\n    elif step_list is not None:\n        step_files = []\n        for path in step_list:\n            if os.path.isdir(path):\n                step_files += glob.glob(os.path.join(path, '*.cwl'))\n            else:\n                step_files.append(path)\n    else:\n        step_files = []\n\n    if working_dir is not None:\n        step_files = sort_loading_order(step_files)\n\n    steps = {}\n    for f in step_files:\n        if working_dir is not None:\n            # Copy file to working_dir\n            if not working_dir == os.path.dirname(f) and not is_url(f):\n                copied_file = os.path.join(working_dir, os.path.basename(f))\n                shutil.copy2(f, copied_file)\n                f = copied_file\n\n        # Create steps\n        try:\n            s = Step(f)\n            steps[s.name] = s\n        except (NotImplementedError, ValidationException,\n                PackedWorkflowException) as e:\n            logger.warning(e)\n\n    return steps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a yaml file.", "response": "def load_yaml(filename):\n    \"\"\"Return object in yaml file.\"\"\"\n    with open(filename) as myfile:\n        content = myfile.read()\n        if \"win\" in sys.platform:\n            content = content.replace(\"\\\\\", \"/\")\n        return yaml.safe_load(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sort_loading_order(step_files):\n    tools = []\n    workflows = []\n    workflows_with_subworkflows = []\n\n    for f in step_files:\n        # assume that urls are tools\n        if f.startswith('http://') or f.startswith('https://'):\n            tools.append(f)\n        else:\n            obj = load_yaml(f)\n            if obj.get('class', '') == 'Workflow':\n                if 'requirements' in obj.keys():\n                    subw = {'class': 'SubworkflowFeatureRequirement'}\n                    if subw in obj['requirements']:\n                        workflows_with_subworkflows.append(f)\n                    else:\n                        workflows.append(f)\n                else:\n                    workflows.append(f)\n            else:\n                tools.append(f)\n    return tools + workflows + workflows_with_subworkflows", "response": "Sort step files into correct loading order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading and validate CWL file using cwltool", "response": "def load_cwl(fname):\n    \"\"\"Load and validate CWL file using cwltool\n    \"\"\"\n    logger.debug('Loading CWL file \"{}\"'.format(fname))\n    # Fetching, preprocessing and validating cwl\n\n    # Older versions of cwltool\n    if legacy_cwltool:\n        try:\n            (document_loader, workflowobj, uri) = fetch_document(fname)\n            (document_loader, _, processobj, metadata, uri) = \\\n                validate_document(document_loader, workflowobj, uri)\n        except TypeError:\n            from cwltool.context import LoadingContext, getdefault\n            from cwltool import workflow\n            from cwltool.resolver import tool_resolver\n            from cwltool.load_tool import resolve_tool_uri\n\n            loadingContext = LoadingContext()\n            loadingContext.construct_tool_object = getdefault(\n                loadingContext.construct_tool_object,\n                workflow.default_make_tool)\n            loadingContext.resolver = getdefault(loadingContext.resolver,\n                                                 tool_resolver)\n\n            uri, tool_file_uri = resolve_tool_uri(\n                fname, resolver=loadingContext.resolver,\n                fetcher_constructor=loadingContext.fetcher_constructor)\n\n            document_loader, workflowobj, uri = fetch_document(\n                    uri, resolver=loadingContext.resolver,\n                    fetcher_constructor=loadingContext.fetcher_constructor)\n            document_loader, avsc_names, processobj, metadata, uri = \\\n                validate_document(\n                    document_loader, workflowobj, uri,\n                    loadingContext.overrides_list, {},\n                    enable_dev=loadingContext.enable_dev,\n                    strict=loadingContext.strict,\n                    preprocess_only=False,\n                    fetcher_constructor=loadingContext.fetcher_constructor,\n                    skip_schemas=False,\n                    do_validate=loadingContext.do_validate)\n    # Recent versions of cwltool\n    else:\n        (loading_context, workflowobj, uri) = fetch_document(fname)\n        loading_context, uri = resolve_and_validate_document(loading_context,\n                                                             workflowobj, uri)\n        document_loader = loading_context.loader\n        processobj = workflowobj\n        metadata = loading_context.metadata\n\n    return document_loader, processobj, metadata, uri"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_input(self, p_name, value):\n        name = self.python_names.get(p_name)\n        if p_name is None or name not in self.get_input_names():\n            raise ValueError('Invalid input \"{}\"'.format(p_name))\n        self.step_inputs[name] = value", "response": "Set a Step s input variable to a certain value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output_reference(self, name):\n        if name not in self.output_names:\n            raise ValueError('Invalid output \"{}\"'.format(name))\n        return Reference(step_name=self.name_in_workflow, output_name=name)", "response": "Return a reference to the given output for use in an input\n            of a next Step."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if a step input parameter is optional.", "response": "def _input_optional(inp):\n        \"\"\"Returns True if a step input parameter is optional.\n\n        Args:\n            inp (dict): a dictionary representation of an input.\n\n        Raises:\n            ValueError: The inp provided is not valid.\n        \"\"\"\n        if 'default' in inp.keys():\n            return True\n\n        typ = inp.get('type')\n        if isinstance(typ, six.string_types):\n            return typ.endswith('?')\n        elif isinstance(typ, dict):\n            # TODO: handle case where iput type is dict\n            return False\n        elif isinstance(typ, list):\n            # The cwltool validation expands optional arguments to\n            # [u'null', <type>]\n            return bool(u'null' in typ)\n        else:\n            raise ValueError('Invalid input \"{}\"'.format(inp.get['id']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the step as an object that can be written to a yaml file.", "response": "def to_obj(self, wd=False, pack=False, relpath=None):\n        \"\"\"Return the step as an dict that can be written to a yaml file.\n\n        Returns:\n            dict: yaml representation of the step.\n        \"\"\"\n        obj = CommentedMap()\n        if pack:\n            obj['run'] = self.orig\n        elif relpath is not None:\n            if self.from_url:\n                obj['run'] = self.run\n            else:\n                obj['run'] = os.path.relpath(self.run, relpath)\n        elif wd:\n            if self.from_url:\n                obj['run'] = self.run\n            else:\n                obj['run'] = os.path.basename(self.run)\n        else:\n            obj['run'] = self.run\n        obj['in'] = self.step_inputs\n        obj['out'] = self.output_names\n        if self.is_scattered:\n            obj['scatter'] = self.scattered_inputs\n            # scatter_method is optional when scattering over a single variable\n            if self.scatter_method is not None:\n                obj['scatterMethod'] = self.scatter_method\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string listing all the Step s input names and their types.", "response": "def list_inputs(self):\n        \"\"\"Return a string listing all the Step's input names and their types.\n\n        The types are returned in a copy/pastable format, so if the type is\n        `string`, `'string'` (with single quotes) is returned.\n\n        Returns:\n            str containing all input names and types.\n        \"\"\"\n        doc = []\n        for inp, typ in self.input_types.items():\n            if isinstance(typ, six.string_types):\n                typ = \"'{}'\".format(typ)\n            doc.append('{}: {}'.format(inp, typ))\n        return '\\n'.join(doc)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, steps_dir=None, step_file=None, step_list=None):\n        self._closed()\n\n        self.steps_library.load(steps_dir=steps_dir, step_file=step_file,\n                                step_list=step_list)", "response": "Loads CWL steps into the WorkflowGenerator s steps library."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the workflow needs a requirements section False otherwise.", "response": "def _has_requirements(self):\n        \"\"\"Returns True if the workflow needs a requirements section.\n\n        Returns:\n            bool: True if the workflow needs a requirements section, False\n                otherwise.\n        \"\"\"\n        self._closed()\n\n        return any([self.has_workflow_step, self.has_scatter_requirement,\n                   self.has_multiple_inputs])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inputs(self, name):\n        self._closed()\n\n        step = self._get_step(name, make_copy=False)\n        return step.list_inputs()", "response": "List the names and types of a step in the steps library."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a step to the workflow.", "response": "def _add_step(self, step):\n        \"\"\"Add a step to the workflow.\n\n        Args:\n            step (Step): a step from the steps library.\n        \"\"\"\n        self._closed()\n\n        self.has_workflow_step = self.has_workflow_step or step.is_workflow\n        self.wf_steps[step.name_in_workflow] = step"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_input(self, **kwargs):\n        self._closed()\n\n        def _get_item(args):\n            \"\"\"Get a single item from args.\"\"\"\n            if not args:\n                raise ValueError(\"No parameter specified.\")\n            item = args.popitem()\n            if args:\n                raise ValueError(\"Too many parameters, not clear what to do \"\n                                 \"with {}\".format(kwargs))\n            return item\n\n        symbols = None\n        input_dict = CommentedMap()\n\n        if 'default' in kwargs:\n            input_dict['default'] = kwargs.pop('default')\n        if 'label' in kwargs:\n            input_dict['label'] = kwargs.pop('label')\n        if 'symbols' in kwargs:\n            symbols = kwargs.pop('symbols')\n\n        name, input_type = _get_item(kwargs)\n\n        if input_type == 'enum':\n            typ = CommentedMap()\n            typ['type'] = 'enum'\n            # make sure symbols is set\n            if symbols is None:\n                raise ValueError(\"Please specify the enum's symbols.\")\n            # make sure symbols is not empty\n            if symbols == []:\n                raise ValueError(\"The enum's symbols cannot be empty.\")\n            # make sure the symbols are a list\n            if type(symbols) != list:\n                raise ValueError('Symbols should be a list.')\n            # make sure symbols is a list of strings\n            symbols = [str(s) for s in symbols]\n\n            typ['symbols'] = symbols\n            input_dict['type'] = typ\n        else:\n            # Set the 'type' if we can't use simple notation (because there is\n            # a default value or a label)\n            if bool(input_dict):\n                input_dict['type'] = input_type\n\n        msg = '\"{}\" is already used as a workflow input. Please use a ' +\\\n              'different name.'\n        if name in self.wf_inputs:\n            raise ValueError(msg.format(name))\n\n        # Add 'type' for complex input types, so the user doesn't have to do it\n        if isinstance(input_type, dict):\n            input_dict['type'] = input_type\n\n        # Make sure we can use the notation without 'type' if the input allows\n        # it.\n        if bool(input_dict):\n            self.wf_inputs[name] = input_dict\n        else:\n            self.wf_inputs[name] = input_type\n\n        return Reference(input_name=name)", "response": "Add a new workflow input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_outputs(self, **kwargs):\n        self._closed()\n\n        for name, source_name in kwargs.items():\n            obj = {}\n            obj['outputSource'] = source_name\n            obj['type'] = self.step_output_types[source_name]\n            self.wf_outputs[name] = obj", "response": "Add workflow outputs.\n\n        The output type is added automatically, based on the steps in the steps\n        library.\n\n        Args:\n            kwargs (dict): A dict containing ``name=source name`` pairs.\n                ``name`` is the name of the workflow output (e.g.,\n                ``txt_files``) and source name is the name of the step that\n                produced this output plus the output name (e.g.,\n                ``saf-to-txt/out_files``)."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a step from the steps library.", "response": "def _get_step(self, name, make_copy=True):\n        \"\"\"Return step from steps library.\n\n        Optionally, the step returned is a deep copy from the step in the steps\n        library, so additional information (e.g., about whether the step was\n        scattered) can be stored in the copy.\n\n        Args:\n            name (str): name of the step in the steps library.\n            make_copy (bool): whether a deep copy of the step should be\n                returned or not (default: True).\n\n        Returns:\n            Step from steps library.\n\n        Raises:\n            ValueError: The requested step cannot be found in the steps\n                library.\n        \"\"\"\n        self._closed()\n\n        s = self.steps_library.get_step(name)\n        if s is None:\n            msg = '\"{}\" not found in steps library. Please check your ' \\\n                  'spelling or load additional steps'\n            raise ValueError(msg.format(name))\n        if make_copy:\n            s = copy.deepcopy(s)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_obj(self, wd=False, pack=False, relpath=None):\n        self._closed()\n\n        obj = CommentedMap()\n        obj['cwlVersion'] = 'v1.0'\n        obj['class'] = 'Workflow'\n        try:\n            obj['doc'] = self.documentation\n        except (AttributeError, ValueError):\n            pass\n        try:\n            obj['label'] = self.label\n        except (AttributeError, ValueError):\n            pass\n        if self._has_requirements():\n            obj['requirements'] = []\n        if self.has_workflow_step:\n            obj['requirements'].append(\n                {'class': 'SubworkflowFeatureRequirement'})\n        if self.has_scatter_requirement:\n            obj['requirements'].append({'class': 'ScatterFeatureRequirement'})\n        if self.has_multiple_inputs:\n            obj['requirements'].append(\n                {'class': 'MultipleInputFeatureRequirement'})\n        obj['inputs'] = self.wf_inputs\n        obj['outputs'] = self.wf_outputs\n\n        steps_obj = CommentedMap()\n        for key in self.wf_steps:\n            steps_obj[key] = self.wf_steps[key].to_obj(relpath=relpath,\n                                                       pack=pack,\n                                                       wd=wd)\n        obj['steps'] = steps_obj\n\n        return obj", "response": "Return the created workflow as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the scriptcwl script for the currunt workflow.", "response": "def to_script(self, wf_name='wf'):\n        \"\"\"Generated and print the scriptcwl script for the currunt workflow.\n\n        Args:\n            wf_name (str): string used for the WorkflowGenerator object in the\n                generated script (default: ``wf``).\n        \"\"\"\n        self._closed()\n\n        script = []\n\n        # Workflow documentation\n        # if self.documentation:\n        #    if is_multiline(self.documentation):\n        #        print('doc = \"\"\"')\n        #        print(self.documentation)\n        #        print('\"\"\"')\n        #        print('{}.set_documentation(doc)'.format(wf_name))\n        #    else:\n        #        print('{}.set_documentation(\\'{}\\')'.format(wf_name,\n        #        self.documentation))\n\n        # Workflow inputs\n        params = []\n        returns = []\n        for name, typ in self.wf_inputs.items():\n            params.append('{}=\\'{}\\''.format(name, typ))\n            returns.append(name)\n        script.append('{} = {}.add_inputs({})'.format(\n            ', '.join(returns), wf_name, ', '.join(params)))\n\n        # Workflow steps\n        returns = []\n        for name, step in self.wf_steps.items():\n            pyname = step.python_name\n            returns = ['{}_{}'.format(pyname, o) for o in step['out']]\n            params = ['{}={}'.format(name, python_name(param))\n                      for name, param in step['in'].items()]\n            script.append('{} = {}.{}({})'.format(\n                ', '.join(returns), wf_name, pyname, ', '.join(params)))\n\n        # Workflow outputs\n        params = []\n        for name, details in self.wf_outputs.items():\n            params.append('{}={}'.format(\n                name, python_name(details['outputSource'])))\n        script.append('{}.add_outputs({})'.format(wf_name, ', '.join(params)))\n\n        return '\\n'.join(script)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if type1 and type2 can possibly match.", "response": "def _types_match(type1, type2):\n        \"\"\"Returns False only if it can show that no value of type1\n        can possibly match type2.\n\n        Supports only a limited selection of types.\n        \"\"\"\n        if isinstance(type1, six.string_types) and \\\n                isinstance(type2, six.string_types):\n            type1 = type1.rstrip('?')\n            type2 = type2.rstrip('?')\n            if type1 != type2:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the workflow object.", "response": "def validate(self):\n        \"\"\"Validate workflow object.\n\n        This method currently validates the workflow object with the use of\n        cwltool. It writes the workflow to a tmp CWL file, reads it, validates\n        it and removes the tmp file again. By default, the workflow is written\n        to file using absolute paths to the steps.\n        \"\"\"\n        # define tmpfile\n        (fd, tmpfile) = tempfile.mkstemp()\n        os.close(fd)\n        try:\n            # save workflow object to tmpfile,\n            # do not recursively call validate function\n            self.save(tmpfile, mode='abs', validate=False)\n            # load workflow from tmpfile\n            document_loader, processobj, metadata, uri = load_cwl(tmpfile)\n        finally:\n            # cleanup tmpfile\n            os.remove(tmpfile)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the workflow with pack option.", "response": "def _pack(self, fname, encoding):\n        \"\"\"Save workflow with ``--pack`` option\n\n        This means that al tools and subworkflows are included in the workflow\n        file that is created. A packed workflow cannot be loaded and used in\n        scriptcwl.\n        \"\"\"\n        (fd, tmpfile) = tempfile.mkstemp()\n        os.close(fd)\n        try:\n            self.save(tmpfile, mode='abs', validate=False)\n            document_loader, processobj, metadata, uri = load_cwl(tmpfile)\n        finally:\n            # cleanup tmpfile\n            os.remove(tmpfile)\n\n        with codecs.open(fname, 'wb', encoding=encoding) as f:\n            f.write(print_pack(document_loader, processobj, uri, metadata))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, fname, mode=None, validate=True, encoding='utf-8',\n             wd=False, inline=False, relative=False, pack=False):\n        \"\"\"Save the workflow to file.\n\n        Save the workflow to a CWL file that can be run with a CWL runner.\n\n        Args:\n            fname (str): file to save the workflow to.\n            mode (str): one of  (rel, abs, wd, inline, pack)\n            encoding (str): file encoding to use (default: ``utf-8``).\n        \"\"\"\n        self._closed()\n\n        if mode is None:\n            mode = 'abs'\n            if pack:\n                mode = 'pack'\n            elif wd:\n                mode = 'wd'\n            elif relative:\n                mode = 'rel'\n\n            msg = 'Using deprecated save method. Please save the workflow ' \\\n                  'with: wf.save(\\'{}\\', mode=\\'{}\\'). Redirecting to new ' \\\n                  'save method.'.format(fname, mode)\n            warnings.warn(msg, DeprecationWarning)\n\n        modes = ('rel', 'abs', 'wd', 'inline', 'pack')\n        if mode not in modes:\n            msg = 'Illegal mode \"{}\". Choose one of ({}).'\\\n                  .format(mode, ','.join(modes))\n            raise ValueError(msg)\n\n        if validate:\n            self.validate()\n\n        dirname = os.path.dirname(os.path.abspath(fname))\n        if not os.path.exists(dirname):\n            os.makedirs(dirname)\n\n        if mode == 'inline':\n            msg = ('Inline saving is deprecated. Please save the workflow '\n                   'using mode=\\'pack\\'. Setting mode to pack.')\n            warnings.warn(msg, DeprecationWarning)\n            mode = 'pack'\n\n        if mode == 'rel':\n            relpath = dirname\n            save_yaml(fname=fname, wf=self, pack=False, relpath=relpath,\n                      wd=False)\n\n        if mode == 'abs':\n            save_yaml(fname=fname, wf=self, pack=False, relpath=None,\n                      wd=False)\n\n        if mode == 'pack':\n            self._pack(fname, encoding)\n\n        if mode == 'wd':\n            if self.get_working_dir() is None:\n                raise ValueError('Working directory not set.')\n            else:\n                # save in working_dir\n                bn = os.path.basename(fname)\n                wd_file = os.path.join(self.working_dir, bn)\n                save_yaml(fname=wd_file, wf=self, pack=False, relpath=None,\n                          wd=True)\n                # and copy workflow file to other location (as though all steps\n                # are in the same directory as the workflow)\n                try:\n                    shutil.copy2(wd_file, fname)\n                except shutil.Error:\n                    pass", "response": "Save the workflow to a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeprecate function use add_input ( self kwargs ) instead.", "response": "def add_inputs(self, **kwargs):\n        \"\"\"Deprecated function, use add_input(self, **kwargs) instead.\n        Add workflow input.\n\n        Args:\n            kwargs (dict): A dict with a `name: type` item\n                and optionally a `default: value` item, where name is the\n                name (id) of the workflow input (e.g., `dir_in`) and type is\n                the type of the input (e.g., `'Directory'`).\n                The type of input parameter can be learned from\n                `step.inputs(step_name=input_name)`.\n\n        Returns:\n            inputname\n\n        Raises:\n            ValueError: No or multiple parameter(s) have been specified.\n        \"\"\"\n        msg = ('The add_inputs() function is deprecation in favour of the '\n               'add_input() function, redirecting...')\n        warnings.warn(msg, DeprecationWarning)\n        return self.add_input(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef str_presenter(dmpr, data):\n    if is_multiline(data):\n        return dmpr.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n    return dmpr.represent_scalar('tag:yaml.org,2002:str', data)", "response": "Return correct str_presenter to write multiple lines to a yaml field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the sparse m - by - n matrices that map a function in V to the values of dx and dy at a number m of points.", "response": "def build_grad_matrices(V, points):\n    \"\"\"Build the sparse m-by-n matrices that map a coefficient set for a function in V\n    to the values of dx and dy at a number m of points.\n    \"\"\"\n    # See <https://www.allanswered.com/post/lkbkm/#zxqgk>\n    mesh = V.mesh()\n\n    bbt = BoundingBoxTree()\n    bbt.build(mesh)\n    dofmap = V.dofmap()\n    el = V.element()\n    rows = []\n    cols = []\n    datax = []\n    datay = []\n    for i, xy in enumerate(points):\n        cell_id = bbt.compute_first_entity_collision(Point(*xy))\n        cell = Cell(mesh, cell_id)\n        coordinate_dofs = cell.get_vertex_coordinates()\n\n        rows.append([i, i, i])\n        cols.append(dofmap.cell_dofs(cell_id))\n\n        v = el.evaluate_basis_derivatives_all(1, xy, coordinate_dofs, cell_id)\n        v = v.reshape(3, 2)\n        datax.append(v[:, 0])\n        datay.append(v[:, 1])\n\n    rows = numpy.concatenate(rows)\n    cols = numpy.concatenate(cols)\n    datax = numpy.concatenate(datax)\n    datay = numpy.concatenate(datay)\n\n    m = len(points)\n    n = V.dim()\n    dx_matrix = sparse.csr_matrix((datax, (rows, cols)), shape=(m, n))\n    dy_matrix = sparse.csr_matrix((datay, (rows, cols)), shape=(m, n))\n    return dx_matrix, dy_matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_M(self, ax, ay):\n        jac = numpy.array(\n            [[self.dx.dot(ax), self.dy.dot(ax)], [self.dx.dot(ay), self.dy.dot(ay)]]\n        )\n\n        # jacs and J are of shape (2, 2, k). M must be of the same shape and\n        # contain the result of the k 2x2 dot products. Perhaps there's a\n        # dot() for this.\n        M = numpy.einsum(\"ijl,jkl->ikl\", jac, self.J)\n        # M = numpy.array([\n        #     [\n        #         jac[0][0]*self.J[0][0] + jac[0][1]*self.J[1][0],\n        #         jac[0][0]*self.J[0][1] + jac[0][1]*self.J[1][1],\n        #     ],\n        #     [\n        #         jac[1][0]*self.J[0][0] + jac[1][1]*self.J[1][0],\n        #         jac[1][0]*self.J[0][1] + jac[1][1]*self.J[1][1],\n        #     ],\n        #     ])\n\n        # One could use\n        #\n        #     M = numpy.moveaxis(M, -1, 0)\n        #     _, sigma, _ = numpy.linalg.svd(M)\n        #\n        # but computing the singular values explicitly via\n        # <https://scicomp.stackexchange.com/a/14103/3980> is faster and more\n        # explicit.\n        a = (M[0, 0] + M[1, 1]) / 2\n        b = (M[0, 0] - M[1, 1]) / 2\n        c = (M[1, 0] + M[0, 1]) / 2\n        d = (M[1, 0] - M[0, 1]) / 2\n\n        return a, b, c, d", "response": "Linear operator that converts ax ay to abcd."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cost_min2(self, alpha):\n        n = self.V.dim()\n        ax = alpha[:n]\n        ay = alpha[n:]\n\n        # ml = pyamg.ruge_stuben_solver(self.L)\n        # # ml = pyamg.smoothed_aggregation_solver(self.L)\n        # print(ml)\n        # print()\n        # print(self.L)\n        # print()\n        # x = ml.solve(ax, tol=1e-10)\n        # print('residual: {}'.format(numpy.linalg.norm(ax - self.L*x)))\n        # print()\n        # print(ax)\n        # print()\n        # print(x)\n        # exit(1)\n\n        # x = sparse.linalg.spsolve(self.L, ax)\n        # print('residual: {}'.format(numpy.linalg.norm(ax - self.L*x)))\n        # exit(1)\n\n        q2, r2 = self.get_q2_r2(ax, ay)\n\n        Lax = self.L * ax\n        Lay = self.L * ay\n\n        out = [\n            0.5 * numpy.dot(Lax, Lax),\n            0.5 * numpy.dot(Lay, Lay),\n            0.5 * numpy.dot(q2 - 1, q2 - 1),\n            0.5 * numpy.dot(r2, r2),\n        ]\n\n        if self.num_f_eval % 10000 == 0:\n            print(\"{:7d}     {:e} {:e} {:e} {:e}\".format(self.num_f_eval, *out))\n\n        self.num_f_eval += 1\n        return numpy.sum(out)", "response": "Residual formulation of the identity. Hessian is a low - rank update of the identity."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delta(a, b):\n    diff = a - b\n    return numpy.einsum(\"i...,i...->...\", diff, diff)", "response": "Computes the distances between two colors or color sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_flat_gamut(\n    xy_to_2d=lambda xy: xy,\n    axes_labels=(\"x\", \"y\"),\n    plot_rgb_triangle=True,\n    fill_horseshoe=True,\n    plot_planckian_locus=True,\n):\n    \"\"\"Show a flat color gamut, by default xy.  There exists a chroma gamut for\n    all color models which transform lines in XYZ to lines, and hence have a\n    natural decomposition into lightness and chroma components.  Also, the flat\n    gamut is the same for every lightness value. Examples for color models with\n    this property are CIELUV and IPT, examples for color models without are\n    CIELAB and CIECAM02.\n    \"\"\"\n    observer = observers.cie_1931_2()\n    # observer = observers.cie_1964_10()\n\n    _plot_monochromatic(observer, xy_to_2d, fill_horseshoe=fill_horseshoe)\n    # plt.grid()\n\n    if plot_rgb_triangle:\n        _plot_rgb_triangle(xy_to_2d)\n    if plot_planckian_locus:\n        _plot_planckian_locus(observer, xy_to_2d)\n\n    plt.gca().set_aspect(\"equal\")\n    # plt.legend()\n    plt.xlabel(axes_labels[0])\n    plt.ylabel(axes_labels[1])\n    return", "response": "Show a flat color gamut by default xy."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_macadam(\n    ellipse_scaling=10,\n    plot_filter_positions=False,\n    plot_standard_deviations=False,\n    plot_rgb_triangle=True,\n    plot_mesh=True,\n    n=1,\n    xy_to_2d=lambda xy: xy,\n    axes_labels=(\"x\", \"y\"),\n):\n    \"\"\"See <https://en.wikipedia.org/wiki/MacAdam_ellipse>,\n    <https://doi.org/10.1364%2FJOSA.32.000247>.\n    \"\"\"\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    with open(os.path.join(dir_path, \"data/macadam1942/table3.yaml\")) as f:\n        data = yaml.safe_load(f)\n\n    # if plot_filter_positions:\n    #     with open(os.path.join(dir_path, 'data/macadam1942/table1.yaml')) as f:\n    #         filters_xyz = yaml.safe_load(f)\n    #     filters_xyz = {\n    #         key: 100 * numpy.array(value) for key, value in filters_xyz.items()\n    #         }\n    #     for key, xyz in filters_xyz.items():\n    #         x, y = xyz100_to_2d(xyz)\n    #         plt.plot(x, y, 'xk')\n    #         ax.annotate(key, (x, y))\n\n    # collect the ellipse centers and offsets\n    centers = []\n    offsets = []\n    for datak in data:\n        # collect ellipse points\n        _, _, _, _, delta_y_delta_x, delta_s = numpy.array(datak[\"data\"]).T\n\n        offset = (\n            numpy.array([numpy.ones(delta_y_delta_x.shape[0]), delta_y_delta_x])\n            / numpy.sqrt(1 + delta_y_delta_x ** 2)\n            * delta_s\n        )\n\n        if offset.shape[1] < 2:\n            continue\n\n        centers.append([datak[\"x\"], datak[\"y\"]])\n        offsets.append(numpy.column_stack([+offset, -offset]))\n\n    centers = numpy.array(centers)\n\n    _plot_ellipse_data(\n        centers,\n        offsets,\n        ellipse_scaling=ellipse_scaling,\n        xy_to_2d=xy_to_2d,\n        plot_mesh=plot_mesh,\n        n=n,\n        plot_rgb_triangle=plot_rgb_triangle,\n    )\n    return", "response": "Plot the MacAdam ellipse."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_xy_tree(xy, degree):\n    x, y = xy\n    tree = [numpy.array([numpy.ones(x.shape, dtype=int)])]\n    for d in range(degree):\n        tree.append(numpy.concatenate([tree[-1] * x, [tree[-1][-1] * y]]))\n    return tree", "response": "Evaluates the entire tree of 2d mononomials."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_dx_tree(xy, degree):\n    x, y = xy\n\n    # build smaller tree\n    one = numpy.array([numpy.ones(x.shape, dtype=int)])\n    tree = [one]\n    for d in range(1, degree):\n        tree.append(\n            numpy.concatenate(\n                [\n                    # Integer division `//` would be nice here, but\n                    # <https://github.com/sympy/sympy/issues/14542>.\n                    [tree[-1][0] / d * (d + 1) * x],\n                    tree[-1] * y,\n                ]\n            )\n        )\n\n    # append zeros\n    zero = numpy.array([numpy.zeros(x.shape, dtype=int)])\n    tree = [zero] + [numpy.concatenate([t, zero]) for t in tree]\n    return tree", "response": "Get the tree of the given x y and degree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the Jacobian at ( x y ).", "response": "def jac(self, xy=None):\n        \"\"\"Get the Jacobian at (x, y).\n        \"\"\"\n        if xy is not None:\n            self.set_xy(xy)\n\n        ux = numpy.dot(self.ax, self.xy_list[: len(self.ax)])\n        vx = numpy.dot(self.bx, self.xy_list[: len(self.bx)])\n        uy = numpy.dot(self.ay, self.xy_list[: len(self.ay)])\n        vy = numpy.dot(self.by, self.xy_list[: len(self.by)])\n\n        ux_dx = numpy.dot(self.ax, self.dx_list[: len(self.ax)])\n        vx_dx = numpy.dot(self.bx, self.dx_list[: len(self.bx)])\n        uy_dx = numpy.dot(self.ay, self.dx_list[: len(self.ay)])\n        vy_dx = numpy.dot(self.by, self.dx_list[: len(self.by)])\n\n        ux_dy = numpy.dot(self.ax, self.dy_list[: len(self.ax)])\n        vx_dy = numpy.dot(self.bx, self.dy_list[: len(self.bx)])\n        uy_dy = numpy.dot(self.ay, self.dy_list[: len(self.ay)])\n        vy_dy = numpy.dot(self.by, self.dy_list[: len(self.by)])\n\n        jac = numpy.array(\n            [\n                [\n                    (ux_dx * vx - vx_dx * ux) / vx ** 2,\n                    (ux_dy * vx - vx_dy * ux) / vx ** 2,\n                ],\n                [\n                    (uy_dx * vy - vy_dx * uy) / vy ** 2,\n                    (uy_dy * vy - vy_dy * uy) / vy ** 2,\n                ],\n            ]\n        )\n        return jac"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spectrum_to_xyz100(spectrum, observer):\n    lambda_o, data_o = observer\n    lambda_s, data_s = spectrum\n\n    # form the union of lambdas\n    lmbda = numpy.sort(numpy.unique(numpy.concatenate([lambda_o, lambda_s])))\n\n    # The technical document prescribes that the integration be performed over\n    # the wavelength range corresponding to the entire visible spectrum, 360 nm\n    # to 830 nm.\n    assert lmbda[0] < 361e-9\n    assert lmbda[-1] > 829e-9\n\n    # interpolate data\n    idata_o = numpy.array([numpy.interp(lmbda, lambda_o, dt) for dt in data_o])\n    # The technical report specifies the interpolation techniques, too:\n    # ```\n    # Use one of the four following methods to calculate needed but unmeasured\n    # values of phi(l), R(l) or tau(l) within the range of measurements:\n    #   1) the third-order polynomial interpolation (Lagrange) from the four\n    #      neighbouring data points around the point to be interpolated, or\n    #   2) cubic spline interpolation formula, or\n    #   3) a fifth order polynomial interpolation formula from the six\n    #      neighboring data points around the point to be interpolated, or\n    #   4) a Sprague interpolation (see Seve, 2003).\n    # ```\n    # Well, don't do that but simply use linear interpolation now. We only use\n    # the midpoint rule for integration anyways.\n    idata_s = numpy.interp(lmbda, lambda_s, data_s)\n\n    # step sizes\n    delta = numpy.zeros(len(lmbda))\n    diff = lmbda[1:] - lmbda[:-1]\n    delta[1:] += diff\n    delta[:-1] += diff\n    delta /= 2\n\n    values = numpy.dot(idata_o, idata_s * delta)\n\n    return values * 100", "response": "Computes the tristimulus values XYZ from a given spectrum and observer via a given\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the white point of an object under the illuminant.", "response": "def white_point(illuminant, observer=observers.cie_1931_2()):\n    \"\"\"From <https://en.wikipedia.org/wiki/White_point>:\n    The white point of an illuminant is the chromaticity of a white object\n    under the illuminant.\n    \"\"\"\n    values = spectrum_to_xyz100(illuminant, observer)\n    # normalize for relative luminance, Y=100\n    values /= values[1]\n    values *= 100\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef d(nominal_temperature):\n    # From CIE 15:2004. Colorimetry, 3rd edition, 2004 (page 69, note 5):\n    #\n    # The method required to calculate the values for the relative spectral\n    # power distributions of illuminants D50, D55, D65, and D75, in Table T.1\n    # is as follows\n    #   1. Multiply the nominal correlated colour temperature (5000 K, 5500 K,\n    #      6500 K or 7500 K) by 1,4388/1,4380.\n    #   2. Calculate XD and YD using the equations given in the text.\n    #   3. Calculate M1 and M2 using the equations given in the text.\n    #   4. Round M1 and M2 to three decimal places.\n    #   5. Calculate S(lambda) every 10 nm by\n    #        S(lambda) = S0(lambda) + M1 S1(lambda) + M2 S2(lambda)\n    #      using values of S0(lambda), S1(lambda) and S2(lambda) from\n    #      Table T.2.\n    #   6. Interpolate the 10 nm values of S(lambda) linearly to obtain values\n    #      at intermediate wavelengths.\n    tcp = 1.4388e-2 / 1.4380e-2 * nominal_temperature\n\n    if 4000 <= tcp <= 7000:\n        xd = ((-4.6070e9 / tcp + 2.9678e6) / tcp + 0.09911e3) / tcp + 0.244063\n    else:\n        assert 7000 < tcp <= 25000\n        xd = ((-2.0064e9 / tcp + 1.9018e6) / tcp + 0.24748e3) / tcp + 0.237040\n\n    yd = (-3.000 * xd + 2.870) * xd - 0.275\n\n    m1 = (-1.3515 - 1.7703 * xd + 5.9114 * yd) / (0.0241 + 0.2562 * xd - 0.7341 * yd)\n    m2 = (+0.0300 - 31.4424 * xd + 30.0717 * yd) / (0.0241 + 0.2562 * xd - 0.7341 * yd)\n\n    m1 = numpy.around(m1, decimals=3)\n    m2 = numpy.around(m2, decimals=3)\n\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    with open(os.path.join(dir_path, \"data/illuminants/d.yaml\")) as f:\n        data = yaml.safe_load(f)\n    data = numpy.array(data).T\n\n    lmbda = data[0]\n    s = data[1:]\n\n    return lmbda, s[0] + m1 * s[1] + m2 * s[2]", "response": "A function that calculates the d - series illuminants for a given nominal temperature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the xyz - 100 of the current log - level from JQQC M or s ; H or h", "response": "def to_xyz100(self, data, description):\n        \"\"\"Input: J or Q; C, M or s; H or h\n        \"\"\"\n        rgb_c = compute_to(data, description, self)\n        # Step 6: Calculate R, G and B\n        # rgb = (rgb_c.T / self.D_RGB).T\n        # Step 7: Calculate X, Y and Z\n        # xyz = self.solve_M16(rgb)\n        return dot(self.invM_, rgb_c)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the dot product between two arrays a and b.", "response": "def dot(a, b):\n    \"\"\"Take arrays `a` and `b` and form the dot product between the last axis\n    of `a` and the first of `b`.\n    \"\"\"\n    b = numpy.asarray(b)\n    return numpy.dot(a, b.reshape(b.shape[0], -1)).reshape(a.shape[:-1] + b.shape[1:])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves a linear equation system with a matrix of shape n and an anon array of shape n.", "response": "def solve(A, x):\n    \"\"\"Solves a linear equation system with a matrix of shape (n, n) and an\n    array of shape (n, ...). The output has the same shape as the second\n    argument.\n    \"\"\"\n    # https://stackoverflow.com/a/48387507/353337\n    x = numpy.asarray(x)\n    return numpy.linalg.solve(A, x.reshape(x.shape[0], -1)).reshape(x.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_xyz100(self, data, description):\n        # Steps 1-5\n        rgb_ = compute_to(data, description, self)\n\n        # Step 6: Calculate RC, GC and BC\n        # rgb_c = dot(self.M_cat02, solve(self.M_hpe, rgb_))\n        #\n        # Step 7: Calculate R, G and B\n        # rgb = (rgb_c.T / self.D_RGB).T\n        #\n        # Step 8: Calculate X, Y and Z\n        # xyz = solve(self.M_cat02, rgb)\n        return dot(self.invM_, rgb_)", "response": "Compute the xyz - 100 of the current log - level from the given data and description."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the filename of the NLM file for the current language.", "response": "def get_nlcd_fn():\n    \"\"\"Calls external shell script `get_nlcd.sh` to fetch:\n\n    2011 Land Use Land Cover (nlcd) grids, 30 m\n    \n    http://www.mrlc.gov/nlcd11_leg.php\n    \"\"\"\n    #This is original filename, which requires ~17 GB\n    #nlcd_fn = os.path.join(datadir, 'nlcd_2011_landcover_2011_edition_2014_10_10/nlcd_2011_landcover_2011_edition_2014_10_10.img')\n    #get_nlcd.sh now creates a compressed GTiff, which is 1.1 GB\n    nlcd_fn = os.path.join(datadir, 'nlcd_2011_landcover_2011_edition_2014_10_10/nlcd_2011_landcover_2011_edition_2014_10_10.tif')\n    if not os.path.exists(nlcd_fn):\n        cmd = ['get_nlcd.sh',]\n        #subprocess.call(cmd)\n        sys.exit(\"Missing nlcd data source. If already downloaded, specify correct datadir. If not, run `%s` to download\" % cmd[0])\n    return nlcd_fn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_bareground_fn():\n    bg_fn = os.path.join(datadir, 'bare2010/bare2010.vrt')\n    if not os.path.exists(bg_fn):\n        cmd = ['get_bareground.sh',]\n        sys.exit(\"Missing bareground data source. If already downloaded, specify correct datadir. If not, run `%s` to download\" % cmd[0])\n        #subprocess.call(cmd)\n    return bg_fn", "response": "Returns bare ground file name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning path to the base glacier poly file", "response": "def get_glacier_poly():\n    \"\"\"Calls external shell script `get_rgi.sh` to fetch:\n\n    Randolph Glacier Inventory (RGI) glacier outline shapefiles \n\n    Full RGI database: rgi50.zip is 410 MB\n\n    The shell script will unzip and merge regional shp into single global shp\n    \n    http://www.glims.org/RGI/\n    \"\"\"\n    #rgi_fn = os.path.join(datadir, 'rgi50/regions/rgi50_merge.shp')\n    #Update to rgi60, should have this returned from get_rgi.sh\n    rgi_fn = os.path.join(datadir, 'rgi60/regions/rgi60_merge.shp')\n    if not os.path.exists(rgi_fn):\n        cmd = ['get_rgi.sh',]\n        sys.exit(\"Missing rgi glacier data source. If already downloaded, specify correct datadir. If not, run `%s` to download\" % cmd[0])\n        #subprocess.call(cmd)\n    return rgi_fn"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_icemask(ds, glac_shp_fn=None):\n    print(\"Masking glaciers\")\n    if glac_shp_fn is None:\n        glac_shp_fn = get_glacier_poly()\n\n    if not os.path.exists(glac_shp_fn):\n        print(\"Unable to locate glacier shp: %s\" % glac_shp_fn)\n    else:\n        print(\"Found glacier shp: %s\" % glac_shp_fn)\n\n    #All of the proj, extent, handling should now occur in shp2array\n    icemask = geolib.shp2array(glac_shp_fn, ds)\n    return icemask", "response": "Generate a mask for the input Dataset res and extent"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_nlcd_mask(nlcd_ds, filter='not_forest', out_fn=None):\n    print(\"Loading NLCD LULC\")\n    b = nlcd_ds.GetRasterBand(1)\n    l = b.ReadAsArray()\n    print(\"Filtering NLCD LULC with: %s\" % filter)\n    #Original nlcd products have nan as ndv\n        #12 - ice\n        #31 - rock\n        #11 - open water, includes rivers\n        #52 - shrub, <5 m tall, >20%\n        #42 - evergreeen forest\n    #Should use data dictionary here for general masking\n    #Using 'rock+ice+water' preserves the most pixels, although could be problematic over areas with lakes\n    if filter == 'rock':\n        mask = (l==31)\n    elif filter == 'rock+ice':\n        mask = np.logical_or((l==31),(l==12))\n    elif filter == 'rock+ice+water':\n        mask = np.logical_or(np.logical_or((l==31),(l==12)),(l==11))\n    elif filter == 'not_forest':\n        mask = ~(np.logical_or(np.logical_or((l==41),(l==42)),(l==43)))\n    elif filter == 'not_forest+not_water':\n        mask = ~(np.logical_or(np.logical_or(np.logical_or((l==41),(l==42)),(l==43)),(l==11)))\n    else:\n        print(\"Invalid mask type\")\n        mask = None\n    #Write out original data\n    if out_fn is not None:\n        print(\"Writing out %s\" % out_fn)\n        iolib.writeGTiff(l, out_fn, nlcd_ds)\n    l = None\n    return mask", "response": "Generate a mask for a given NLCD LULC filter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_bareground_mask(bareground_ds, bareground_thresh=60, out_fn=None):\n    print(\"Loading bareground\")\n    b = bareground_ds.GetRasterBand(1)\n    l = b.ReadAsArray()\n    print(\"Masking pixels with <%0.1f%% bare ground\" % bareground_thresh)\n    if bareground_thresh < 0.0 or bareground_thresh > 100.0:\n        sys.exit(\"Invalid bare ground percentage\")\n    mask = (l>bareground_thresh)\n    #Write out original data\n    if out_fn is not None:\n        print(\"Writing out %s\" % out_fn)\n        iolib.writeGTiff(l, out_fn, bareground_ds)\n    l = None\n    return mask", "response": "Generate raster mask for exposed bare ground"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_snodas_ds(dem_dt, code=1036):\n    import tarfile\n    import gzip\n    snodas_ds = None\n    snodas_url_str = None\n\n    outdir = os.path.join(datadir, 'snodas')\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    #Note: unmasked products (beyond CONUS) are only available from 2010-present\n    if dem_dt >= datetime(2003,9,30) and dem_dt < datetime(2010,1,1):\n        snodas_url_str = 'ftp://sidads.colorado.edu/DATASETS/NOAA/G02158/masked/%Y/%m_%b/SNODAS_%Y%m%d.tar'\n        tar_subfn_str_fmt = 'us_ssmv1%itS__T0001TTNATS%%Y%%m%%d05HP001.%s.gz'\n    elif dem_dt >= datetime(2010,1,1):\n        snodas_url_str = 'ftp://sidads.colorado.edu/DATASETS/NOAA/G02158/unmasked/%Y/%m_%b/SNODAS_unmasked_%Y%m%d.tar'\n        tar_subfn_str_fmt = './zz_ssmv1%itS__T0001TTNATS%%Y%%m%%d05HP001.%s.gz'\n    else:\n        print(\"No SNODAS data available for input date\")\n\n    if snodas_url_str is not None:\n        snodas_url = dem_dt.strftime(snodas_url_str)\n        snodas_tar_fn = iolib.getfile(snodas_url, outdir=outdir)\n        print(\"Unpacking\")\n        tar = tarfile.open(snodas_tar_fn)\n        #gunzip to extract both dat and Hdr files, tar.gz\n        for ext in ('dat', 'Hdr'):\n            tar_subfn_str = tar_subfn_str_fmt % (code, ext)\n            tar_subfn_gz = dem_dt.strftime(tar_subfn_str)\n            tar_subfn = os.path.splitext(tar_subfn_gz)[0]\n            print(tar_subfn)\n            if outdir is not None:\n                tar_subfn = os.path.join(outdir, tar_subfn)\n            if not os.path.exists(tar_subfn):\n                #Should be able to do this without writing intermediate gz to disk\n                tar.extract(tar_subfn_gz)\n                with gzip.open(tar_subfn_gz, 'rb') as f:\n                    outf = open(tar_subfn, 'wb')\n                    outf.write(f.read())\n                    outf.close()\n                os.remove(tar_subfn_gz)\n\n        #Need to delete 'Created by module comment' line from Hdr, can contain too many characters\n        bad_str = 'Created by module comment'\n        snodas_fn = tar_subfn\n        f = open(snodas_fn)\n        output = []\n        for line in f:\n            if not bad_str in line:\n                output.append(line)\n        f.close()\n        f = open(snodas_fn, 'w')\n        f.writelines(output)\n        f.close()\n\n        #Return GDAL dataset for extracted product\n        snodas_ds = gdal.Open(snodas_fn)\n    return snodas_ds", "response": "Function to fetch and process SNODAS snow depth products for input datetime dem_dt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to fetch and process MODSCAG fractional snow cover products for input datetime", "response": "def get_modscag_fn_list(dem_dt, tile_list=('h08v04', 'h09v04', 'h10v04', 'h08v05', 'h09v05'), pad_days=7):\n    \"\"\"Function to fetch and process MODSCAG fractional snow cover products for input datetime\n\n    Products are tiled in MODIS sinusoidal projection\n\n    example url: https://snow-data.jpl.nasa.gov/modscag-historic/2015/001/MOD09GA.A2015001.h07v03.005.2015006001833.snow_fraction.tif\n\n    \"\"\"\n\n    #Could also use global MODIS 500 m snowcover grids, 8 day\n    #http://nsidc.org/data/docs/daac/modis_v5/mod10a2_modis_terra_snow_8-day_global_500m_grid.gd.html\n    #These are HDF4, sinusoidal\n    #Should be able to load up with warplib without issue\n\n    import re\n    import requests\n    from bs4 import BeautifulSoup\n    auth = iolib.get_auth()\n    pad_days = timedelta(days=pad_days)\n    dt_list = timelib.dt_range(dem_dt-pad_days, dem_dt+pad_days+timedelta(1), timedelta(1))\n\n    outdir = os.path.join(datadir, 'modscag')\n    if not os.path.exists(outdir):\n        os.makedirs(outdir)\n\n    out_vrt_fn_list = []\n    for dt in dt_list:\n        out_vrt_fn = os.path.join(outdir, dt.strftime('%Y%m%d_snow_fraction.vrt'))\n        #If we already have a vrt and it contains all of the necessary tiles\n        if os.path.exists(out_vrt_fn):\n            vrt_ds = gdal.Open(out_vrt_fn)\n            if np.all([np.any([tile in sub_fn for sub_fn in vrt_ds.GetFileList()]) for tile in tile_list]):\n                out_vrt_fn_list.append(out_vrt_fn)\n                continue\n        #Otherwise, download missing tiles and rebuild\n        #Try to use historic products\n        modscag_fn_list = []\n        #Note: not all tiles are available for same date ranges in historic vs. real-time\n        #Need to repeat search tile-by-tile\n        for tile in tile_list:\n            modscag_url_str = 'https://snow-data.jpl.nasa.gov/modscag-historic/%Y/%j/' \n            modscag_url_base = dt.strftime(modscag_url_str)\n            print(\"Trying: %s\" % modscag_url_base)\n            r = requests.get(modscag_url_base, auth=auth)\n            modscag_url_fn = []\n            if r.ok:\n                parsed_html = BeautifulSoup(r.content, \"html.parser\")\n                modscag_url_fn = parsed_html.findAll(text=re.compile('%s.*snow_fraction.tif' % tile))\n            if not modscag_url_fn:\n                #Couldn't find historic, try to use real-time products\n                modscag_url_str = 'https://snow-data.jpl.nasa.gov/modscag/%Y/%j/' \n                modscag_url_base = dt.strftime(modscag_url_str)\n                print(\"Trying: %s\" % modscag_url_base)\n                r = requests.get(modscag_url_base, auth=auth)\n            if r.ok: \n                parsed_html = BeautifulSoup(r.content, \"html.parser\")\n                modscag_url_fn = parsed_html.findAll(text=re.compile('%s.*snow_fraction.tif' % tile))\n            if not modscag_url_fn:\n                print(\"Unable to fetch MODSCAG for %s\" % dt)\n            else:\n                #OK, we got\n                #Now extract actual tif filenames to fetch from html\n                parsed_html = BeautifulSoup(r.content, \"html.parser\")\n                #Fetch all tiles\n                modscag_url_fn = parsed_html.findAll(text=re.compile('%s.*snow_fraction.tif' % tile))\n                if modscag_url_fn:\n                    modscag_url_fn = modscag_url_fn[0]\n                    modscag_url = os.path.join(modscag_url_base, modscag_url_fn)\n                    print(modscag_url)\n                    modscag_fn = os.path.join(outdir, os.path.split(modscag_url_fn)[-1])\n                    if not os.path.exists(modscag_fn):\n                        iolib.getfile2(modscag_url, auth=auth, outdir=outdir)\n                    modscag_fn_list.append(modscag_fn)\n        #Mosaic tiles - currently a hack\n        if modscag_fn_list:\n            cmd = ['gdalbuildvrt', '-vrtnodata', '255', out_vrt_fn]\n            cmd.extend(modscag_fn_list)\n            print(cmd)\n            subprocess.call(cmd, shell=False)\n            out_vrt_fn_list.append(out_vrt_fn)\n    return out_vrt_fn_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the MODSCAG products for full date range create composites and reproject them", "response": "def proc_modscag(fn_list, extent=None, t_srs=None):\n    \"\"\"Process the MODSCAG products for full date range, create composites and reproject\n    \"\"\"\n    #Use cubic spline here for improve upsampling \n    ds_list = warplib.memwarp_multi_fn(fn_list, res='min', extent=extent, t_srs=t_srs, r='cubicspline')\n    stack_fn = os.path.splitext(fn_list[0])[0] + '_' + os.path.splitext(os.path.split(fn_list[-1])[1])[0] + '_stack_%i' % len(fn_list) \n    #Create stack here - no need for most of mastack machinery, just make 3D array\n    #Mask values greater than 100% (clouds, bad pixels, etc)\n    ma_stack = np.ma.array([np.ma.masked_greater(iolib.ds_getma(ds), 100) for ds in np.array(ds_list)], dtype=np.uint8)\n\n    stack_count = np.ma.masked_equal(ma_stack.count(axis=0), 0).astype(np.uint8)\n    stack_count.set_fill_value(0)\n    stack_min = ma_stack.min(axis=0).astype(np.uint8)\n    stack_min.set_fill_value(0)\n    stack_max = ma_stack.max(axis=0).astype(np.uint8)\n    stack_max.set_fill_value(0)\n    stack_med = np.ma.median(ma_stack, axis=0).astype(np.uint8)\n    stack_med.set_fill_value(0)\n\n    out_fn = stack_fn + '_count.tif'\n    iolib.writeGTiff(stack_count, out_fn, ds_list[0])\n    out_fn = stack_fn + '_max.tif'\n    iolib.writeGTiff(stack_max, out_fn, ds_list[0])\n    out_fn = stack_fn + '_min.tif'\n    iolib.writeGTiff(stack_min, out_fn, ds_list[0])\n    out_fn = stack_fn + '_med.tif'\n    iolib.writeGTiff(stack_med, out_fn, ds_list[0])\n\n    ds = gdal.Open(out_fn)\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies horizontal shift to GDAL dataset GeoTransform", "response": "def apply_xy_shift(ds, dx, dy, createcopy=True):\n    \"\"\"\n    Apply horizontal shift to GDAL dataset GeoTransform\n    \n    Returns:\n    GDAL Dataset copy with updated GeoTransform\n    \"\"\"\n    print(\"X shift: \", dx)\n    print(\"Y shift: \", dy)\n   \n    #Update geotransform\n    gt_orig = ds.GetGeoTransform()\n    gt_shift = np.copy(gt_orig)\n    gt_shift[0] += dx \n    gt_shift[3] += dy\n\n    print(\"Original geotransform:\", gt_orig)\n    print(\"Updated geotransform:\", gt_shift)\n\n    #Update ds Geotransform\n    if createcopy:\n        ds_align = iolib.mem_drv.CreateCopy('', ds, 0)\n    else:\n        #Update in place, assume ds is opened as GA_Update\n        ds_align = ds\n    ds_align.SetGeoTransform(gt_shift)\n    return ds_align"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_offset_sad(dem1, dem2, pad=(9,9), plot=False):\n    #This defines the search window size\n    #Use half-pixel stride?\n    #Note: stride is not properly implemented \n    #stride = 1\n    #ref = dem1[::stride,::stride]\n    #kernel = dem2[pad[0]:-pad[0]:stride, pad[1]:-pad[1]:stride]\n    kernel = dem2[pad[0]:-pad[0], pad[1]:-pad[1]]\n    #Want to pad evenly on both sides, so add +1 here\n    m = np.zeros((pad[0]*2+1, pad[1]*2+1))\n   \n    #Find integer pixel offset\n    i = j = 0\n    for i in range(m.shape[0]):\n        print(i)\n        for j in range(m.shape[1]):\n            print(j)\n            ref = dem1[i:i+kernel.shape[0], j:j+kernel.shape[1]]\n            diff = ref - kernel\n            \n            #Remove outliers beyond IQR\n            diff_iqr = malib.calcperc(diff, (25,75))\n            diff = np.ma.masked_outside(diff, *diff_iqr)\n            \"\"\" \n            diff_med = np.ma.median(diff)\n            diff_mad = malib.mad(diff)\n            diff_madr = (diff_med - mad, diff_med + mad)\n            diff = np.ma.masked_outside(diff, diff_madr)     \n            \"\"\"\n            #Masked areas will decrease sum! Normalize by count of valid pixels\n            m[i,j] = np.ma.abs(diff).sum()/diff.count()\n    \n    #Note, we're dealing with min SAD here, so want to provide -m for sub-pixel refinement \n    m = -m  \n\n    int_argmax = np.array(np.unravel_index(m.argmax(), m.shape))\n    int_offset = int_argmax - pad\n    \n    sp_argmax = np.array(find_subpixel_peak_position(m, 'parabolic'))\n    sp_offset = sp_argmax - pad\n\n    if plot:\n        plt.figure()\n        plt.title('Sum of Absolute Differences')\n        plt.imshow(m)\n        plt.scatter(*sp_argmax[::-1])\n        #plt.show()\n\n    return m, int_offset, sp_offset", "response": "Compute the horizontal offset between two input rasters using sum of absolute differences"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing horizontal offset between input rasters using normalized cross - correlation NCC", "response": "def compute_offset_ncc(dem1, dem2, pad=(9,9), prefilter=False, plot=False): \n    \"\"\"Compute horizontal offset between input rasters using normalized cross-correlation (NCC) method\n    \"\"\"\n\n    #Apply edge detection filter up front - improves results when input DEMs are same resolution\n    if prefilter:\n        print(\"Applying LoG edge-detection filter to DEMs\")\n        sigma = 1\n        import scipy.ndimage\n        #Note, ndimage alone propagates Nans and greatly reduces valid data area\n        #Use the malib.nanfill wrapper to avoid this\n        dem1 = malib.nanfill(dem1, scipy.ndimage.filters.gaussian_laplace, sigma) \n        dem2 = malib.nanfill(dem2, scipy.ndimage.filters.gaussian_laplace, sigma) \n\n    import scipy.signal\n    #Compute max offset given dem spatial resolution\n    #Should implement arbirary x and y search space\n    #xsearch = (20, 41)\n    #ysearch = (-10, 1)\n    stride = 1\n    ref = dem1[::stride,::stride]\n    kernel = dem2[pad[0]:-pad[1]:stride, pad[0]:-pad[1]:stride]\n    #kernel = dem2[-ysearch[0]:-ysearch[1]:stride, xsearch[0]:-xsearch[1]:stride]\n\n    #Normalize\n    ref = (ref - ref.mean()) / ref.std()\n    kernel = (kernel - kernel.mean()) / kernel.std()\n\n    #Consider using astropy.convolve here instead of scipy.correlate?\n\n    print(\"Adding random noise to masked regions\")\n    #Generate random noise to fill gaps before correlation in frequency domain\n    #Normal distribution N(mean, std^2)\n    #ref_noise = ref.mask * ref.std() * np.random.rand(*ref.shape) + ref.mean()\n    #kernel_noise = kernel.mask * kernel.std() * np.random.rand(*kernel.shape) + kernel.mean()\n    #This provides noise in proper range, but noise propagates to m, peak is in different locations!\n    #ref_noise = ref.mask * (ref.min() + ref.ptp() * np.random.rand(*ref.shape))\n    #kernel_noise = kernel.mask * (kernel.min() + kernel.ptp() * np.random.rand(*kernel.shape))\n\n    #This provides a proper normal distribution with mean=0 and std=1\n    ref_noise = ref.mask * (np.random.randn(*ref.shape))\n    kernel_noise = kernel.mask * (np.random.randn(*kernel.shape))\n    #Add the noise\n    ref = ref.filled(0) + ref_noise\n    kernel = kernel.filled(0) + kernel_noise\n\n    print(\"Running 2D correlation with search window (x,y): %i, %i\" % (pad[1], pad[0]))\n    m = scipy.signal.correlate2d(ref, kernel, 'valid')\n    #This has memory issues, but ndimage filters can handle nan\n    #m = scipy.ndimage.filters.correlate(ref, kernel)\n   \n    print(\"Computing sub-pixel peak\")\n    int_argmax = np.array(np.unravel_index(m.argmax(), m.shape))\n    int_offset = int_argmax*stride - pad\n    #int_offset = int_argmax*stride + np.array([ysearch[0], xsearch[0]]) \n\n    print(m.argmax())\n    print(m.shape)\n    print(int_argmax)\n    print(int_offset)\n\n    #Find sub-pixel peak\n    sp_argmax = np.array(find_subpixel_peak_position(m, 'parabolic'))\n    #May need to split this into integer and decimal components, multipy stride*int and add decimal\n    #sp_offset = int_offset + (sp_argmax - int_argmax)\n    sp_offset = sp_argmax - pad\n    #sp_offset = sp_argmax + np.array([ysearch[0], xsearch[0]]) \n\n    print(sp_argmax)\n    print(sp_offset)\n\n    if plot: \n        fig, ax = plt.subplots()\n        ax.set_title('NCC offset, parabolic SPR')\n        ax.imshow(m)\n        #plt.scatter(*int_argmax[::-1])\n        ax.scatter(*sp_argmax[::-1])\n    else:\n        fig = None\n\n    return m, int_offset, sp_offset, fig"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing horizontal offset between input rasters using Nuth and Kaab [ 20151 ]", "response": "def compute_offset_nuth(dh, slope, aspect, min_count=100, remove_outliers=True, plot=True):\n    \"\"\"Compute horizontal offset between input rasters using Nuth and Kaab [2011] (nuth) method\n    \"\"\"\n    import scipy.optimize as optimization\n\n    if dh.count() < min_count:\n        sys.exit(\"Not enough dh samples\")\n    if slope.count() < min_count:\n        sys.exit(\"Not enough slope/aspect samples\")\n\n    #mean_dh = dh.mean()\n    #mean_slope = slope.mean()\n    #c_seed = (mean_dh/np.tan(np.deg2rad(mean_slope))) \n    med_dh = malib.fast_median(dh)\n    med_slope = malib.fast_median(slope)\n    c_seed = (med_dh/np.tan(np.deg2rad(med_slope))) \n\n    x0 = np.array([0.0, 0.0, c_seed])\n  \n    print(\"Computing common mask\")\n    common_mask = ~(malib.common_mask([dh, aspect, slope]))\n\n    #Prepare x and y data\n    xdata = aspect[common_mask].data\n    ydata = (dh[common_mask]/np.tan(np.deg2rad(slope[common_mask]))).data\n\n    print(\"Initial sample count:\")\n    print(ydata.size)\n\n    if remove_outliers:\n        print(\"Removing outliers\")\n        #print(\"Absolute dz filter: %0.2f\" % max_dz)\n        #diff = np.ma.masked_greater(diff, max_dz)\n        #print(diff.count())\n\n        #Outlier dz filter\n        f = 3\n        sigma, u = (ydata.std(), ydata.mean())\n        #sigma, u = malib.mad(ydata, return_med=True)\n        rmin = u - f*sigma\n        rmax = u + f*sigma\n        print(\"3-sigma filter: %0.2f - %0.2f\" % (rmin, rmax))\n        idx = (ydata >= rmin) & (ydata <= rmax)\n        xdata = xdata[idx]\n        ydata = ydata[idx]\n        print(ydata.size)\n\n    #Generate synthetic data to test curve_fit\n    #xdata = np.arange(0,360,0.01)\n    #ydata = f(xdata, 20.0, 130.0, -3.0) + 20*np.random.normal(size=len(xdata))\n    \n    #Limit sample size\n    #n = 10000\n    #idx = random.sample(range(xdata.size), n)\n    #xdata = xdata[idx]\n    #ydata = ydata[idx]\n\n    #Compute robust statistics for 1-degree bins\n    nbins = 360\n    bin_range = (0., 360.)\n    bin_width = 1.0\n    bin_count, bin_edges, bin_centers = malib.bin_stats(xdata, ydata, stat='count', nbins=nbins, bin_range=bin_range)\n    bin_med, bin_edges, bin_centers = malib.bin_stats(xdata, ydata, stat='median', nbins=nbins, bin_range=bin_range)\n    #Needed to estimate sigma for weighted lsq\n    #bin_mad, bin_edges, bin_centers = malib.bin_stats(xdata, ydata, stat=malib.mad, nbins=nbins, bin_range=bin_range)\n    #Started implementing this for more generic binning, needs testing\n    #bin_count, x_bin_edges, y_bin_edges = malib.get_2dhist(xdata, ydata, \\\n    #        xlim=bin_range, nbins=(nbins, nbins), stat='count')\n\n    \"\"\"\n    #Mask bins in grid directions, can potentially contain biased stats\n    #Especially true for SGM algorithm\n    #badbins = [0, 90, 180, 270, 360]\n    badbins = [0, 45, 90, 135, 180, 225, 270, 315, 360]\n    bin_stat = np.ma.masked_where(np.around(bin_edges[:-1]) % 45 == 0, bin_stat)\n    bin_edges = np.ma.masked_where(np.around(bin_edges[:-1]) % 45 == 0, bin_edges)\n    \"\"\"\n\n    #Remove any bins with only a few points\n    min_bin_sample_count = 9\n    idx = (bin_count.filled(0) >= min_bin_sample_count) \n    bin_count = bin_count[idx].data\n    bin_med = bin_med[idx].data\n    #bin_mad = bin_mad[idx].data\n    bin_centers = bin_centers[idx]\n\n    fit = None\n    fit_fig = None\n\n    #Want a good distribution of bins, at least 1/4 to 1/2 of sinusoid, to ensure good fit\n    #Need at least 3 valid bins to fit 3 parameters in nuth_func\n    #min_bin_count = 3\n    min_bin_count = 90 \n    \n    #Not going to help if we have a step function between two plateaus, but better than nothing\n    #Calculate bin aspect spread\n    bin_ptp = np.cos(np.radians(bin_centers)).ptp()\n    min_bin_ptp = 1.0 \n\n    #Should iterate here, if not enough bins, increase bin width\n    if len(bin_med) >= min_bin_count and bin_ptp >= min_bin_ptp:\n\n        print(\"Computing fit\")\n        #Unweighted fit\n        fit = optimization.curve_fit(nuth_func, bin_centers, bin_med, x0)[0]\n\n        #Weight by observed spread in each bin \n        #sigma = bin_mad\n        #fit = optimization.curve_fit(nuth_func, bin_centers, bin_med, x0, sigma, absolute_sigma=True)[0]\n\n        #Weight by bin count\n        #sigma = bin_count.max()/bin_count\n        #fit = optimization.curve_fit(nuth_func, bin_centers, bin_med, x0, sigma, absolute_sigma=False)[0]\n\n        print(fit)\n\n        if plot:\n            print(\"Generating Nuth and Kaab plot\")\n            bin_idx = np.digitize(xdata, bin_edges)\n            output = []\n            for i in np.arange(1, len(bin_edges)):\n                output.append(ydata[bin_idx==i])\n            #flierprops={'marker':'.'}\n            lw = 0.25\n            whiskerprops={'linewidth':lw}\n            capprops={'linewidth':lw}\n            boxprops={'facecolor':'k', 'linewidth':0}\n            medianprops={'marker':'o', 'ms':1, 'color':'r'}\n            fit_fig, ax = plt.subplots(figsize=(6,6))\n            #widths = (bin_width/2.0)\n            widths = 2.5*(bin_count/bin_count.max())\n            #widths = bin_count/np.percentile(bin_count, 50)\n            #Stride\n            s=3\n            #This is inefficient, but we have list of arrays with different length, need to filter\n            #Reduntant with earlier filter, should refactor\n            bp = ax.boxplot(np.array(output)[idx][::s], positions=bin_centers[::s], widths=widths[::s], showfliers=False, \\\n                    patch_artist=True, boxprops=boxprops, whiskerprops=whiskerprops, capprops=capprops, \\\n                    medianprops=medianprops)\n            bin_ticks = [0, 45, 90, 135, 180, 225, 270, 315, 360]\n            ax.set_xticks(bin_ticks)\n            ax.set_xticklabels(bin_ticks)\n            \"\"\"\n            #Can pull out medians from boxplot\n            #We are computing multiple times, inefficient\n            bp_bin_med = []\n            for medline in bp['medians']:\n                bp_bin_med.append(medline.get_ydata()[0])\n            \"\"\"\n\n            #Plot the fit\n            f_a = nuth_func(bin_centers, fit[0], fit[1], fit[2])\n            nuth_func_str = r'$y=%0.2f*cos(%0.2f-x)+%0.2f$' % tuple(fit)\n            ax.plot(bin_centers, f_a, 'b', label=nuth_func_str)\n\n            ax.set_xlabel('Aspect (deg)')\n            ax.set_ylabel('dh/tan(slope) (m)')\n            ax.axhline(color='gray', linewidth=0.5)\n\n            ax.set_xlim(*bin_range)\n            ylim = ax.get_ylim()\n            abs_ylim = np.max(np.abs(ylim))\n            #abs_ylim = np.max(np.abs([ydata.min(), ydata.max()]))\n            #pad = 0.2 * abs_ylim \n            pad = 0\n            ylim = (-abs_ylim - pad, abs_ylim + pad)\n            minylim = (-10,10)\n            if ylim[0] > minylim[0]:\n                ylim = minylim\n            ax.set_ylim(*ylim)\n            ax.legend(prop={'size':8})\n\n    return fit, fit_fig"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_first_peak(corr):\n    ind = corr.argmax()\n    s = corr.shape[1] \n    \n    i = ind // s \n    j = ind %  s\n    \n    return i, j, corr.max()", "response": "Find row and column indices of the first correlation peak."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_subpixel_peak_position(corr, subpixel_method='gaussian'):\n    # initialization\n    default_peak_position = (corr.shape[0]/2,corr.shape[1]/2)\n\n    # the peak locations\n    peak1_i, peak1_j, dummy = find_first_peak(corr)\n    \n    try:\n        # the peak and its neighbours: left, right, down, up\n        c = corr[peak1_i, peak1_j]\n        cl = corr[peak1_i-1, peak1_j]\n        cr = corr[peak1_i+1, peak1_j]\n        cd = corr[peak1_i, peak1_j-1] \n        cu = corr[peak1_i, peak1_j+1]\n        \n        # gaussian fit\n        if np.any(np.array([c,cl,cr,cd,cu]) < 0) and subpixel_method == 'gaussian':\n            subpixel_method = 'centroid'\n        \n        try: \n            if subpixel_method == 'centroid':\n                subp_peak_position = (((peak1_i-1)*cl+peak1_i*c+(peak1_i+1)*cr)/(cl+c+cr),\n                                    ((peak1_j-1)*cd+peak1_j*c+(peak1_j+1)*cu)/(cd+c+cu))\n        \n            elif subpixel_method == 'gaussian':\n                subp_peak_position = (peak1_i + ((np.log(cl)-np.log(cr))/(2*np.log(cl) - 4*np.log(c) + 2*np.log(cr))),\n                                    peak1_j + ((np.log(cd)-np.log(cu))/( 2*np.log(cd) - 4*np.log(c) + 2*np.log(cu)))) \n        \n            elif subpixel_method == 'parabolic':\n                subp_peak_position = (peak1_i +  (cl-cr)/(2*cl-4*c+2*cr),\n                                        peak1_j +  (cd-cu)/(2*cd-4*c+2*cu)) \n    \n        except: \n            subp_peak_position = default_peak_position\n            \n    except IndexError:\n            subp_peak_position = default_peak_position\n            \n    return subp_peak_position[0], subp_peak_position[1]", "response": "This function returns the position of the subpixel approximation of the correlation peak."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    #filenames = !ls *align/*reference-DEM.tif\n    #run ~/src/demtools/error_analysis.py $filenames.s\n\n    if len(sys.argv) < 1:\n        sys.exit('No input files provided')\n\n    fn_list = sys.argv[1:]\n    n_samp = len(fn_list)\n\n    error_dict_list = []\n    for fn in fn_list:\n        ed = parse_pc_align_log(fn)\n        if 'Translation vector (North-East-Down, meters)' in ed.keys(): \n            error_dict_list.append(ed)  \n\n    import matplotlib.dates as mdates\n    #This is used for interactive display of x-value in plot window \n    date_str = '%Y-%m-%d %H:%M'\n    date_fmt = mdates.DateFormatter(date_str)\n    #ax.fmt_xdata = mdates.DateFormatter(date_fmt)\n    months = mdates.MonthLocator() \n    months_int = mdates.MonthLocator(interval=6)  # every n months \n    years = mdates.YearLocator()   # every year\n    yearsFmt = mdates.DateFormatter('%Y')\n    #ax.xaxis.set_major_formatter(yearsFmt)\n    #ax.xaxis.set_major_locator(months_int3)\n\n    print\n    print \"n:\", len(error_dict_list) \n\n    \"\"\"\n    #ECEF translations\n    #key = 'Translation vector (ECEF meters)'\n    key = 'Translation vector (Cartesian, meters)'\n    #key = 'Translation vector (meters)'\n    val = np.array([e[key] for e in error_dict_list])\n    #make_plot3d(val[:,0], val[:,1], val[:,2], title=key)\n    ce90 = geolib.CE90(val[:,0], val[:,1])\n    le90 = geolib.LE90(val[:,2])\n    print\n    print key\n    print \"CE90:\", ce90 \n    print \"LE90:\", le90 \n    print\n\n    #Proj translation\n    key = 'Translation vector (Proj meters)' \n    val = np.array([e[key] for e in error_dict_list])\n    ce90 = geolib.CE90(val[:,0], val[:,1])\n    le90 = geolib.LE90(val[:,2])\n    print\n    print key\n    print \"CE90:\", ce90 \n    print \"LE90:\", le90 \n    print\n    print 'Centroid (mean) of offsets (Proj meters): ', np.mean(val, axis=0) \n    print 'Centroid (median) of offsets (Proj meters): ', np.median(val, axis=0) \n    \"\"\"\n\n    #NOTE: changed default to N-E-D on 9/18/15\n    #Can have significant differences for local proj vs. polar stereographic proj\n    #Should regenerate all previous figures\n\n    #Local translation on ellipsoid\n    #This appears to be local stereographic projection on ellipsoid\n    key = 'Translation vector (North-East-Down, meters)'\n    val = np.array([e[key] for e in error_dict_list])\n\n    #Reformat (n, e, +d) for (x, y, +z) coord sys\n    val[:,[0,1]] = val[:,[1,0]]\n    val[:,2] *= -1\n    ce90 = geolib.CE90(val[:,0], val[:,1])\n    le90 = geolib.LE90(val[:,2])\n    print\n    print key\n    print \"CE90:\", ce90 \n    print \"LE90:\", le90 \n    print\n    print 'Centroid (mean) of offsets (local ned meters): ', np.mean(val, axis=0) \n    print 'Centroid (median) of offsets (local ned meters): ', np.median(val, axis=0) \n\n    #Remove vertical bias\n    remove_vertbias = False \n    if remove_vertbias:\n        print \"Removing vertical bias: %0.2f\" % np.mean(val, axis=0)[2]\n        val[:,2] -= np.mean(val, axis=0)[2]\n\n    remove_outliers = False \n    #Flag outliers\n    x_mag = val[:,0]\n    y_mag = val[:,1]\n    h_mag = np.sqrt(val[:,0]**2 + val[:,1]**2)\n    v_mag = val[:,2]\n    mag = np.sqrt(val[:,0]**2 + val[:,1]**2 + val[:,2]**2)\n    abs_thresh = 10.0\n    p = 98.0\n    p_thresh = np.percentile(h_mag, p)\n    #print \"Outliers with horiz error >= %0.2f (%0.1f%%)\" % (p_thresh, p)\n    print \"Outliers:\" \n    #idx = (h_mag >= p_thresh).nonzero()[0]\n    idx = (h_mag >= ce90).nonzero()[0]\n    idx = np.unique(np.hstack([idx, ((np.abs(v_mag) >= le90).nonzero()[0])]))\n\n    #Print all\n    #idx = np.arange(h_mag.size)\n    #idx_sort = np.argsort(mag[idx])\n    #idx = idx[idx_sort]\n\n    print 'name, m, h, v, x, y, z'\n    for i in idx:\n        print error_dict_list[i]['File'], mag[i], h_mag[i], v_mag[i], val[i,0:3]\n        #Delete from list\n        if remove_outliers:\n            print \"Removing from calculation\"\n            del error_dict_list[i]\n\n    if remove_vertbias or remove_outliers:\n        print\n        print \"Updated values\"\n        print key\n        print \"CE90:\", geolib.CE90(val[:,0], val[:,1])\n        print \"LE90:\", geolib.LE90(val[:,2])\n        print\n        print 'Centroid (mean) of offsets (local ned meters): ', np.mean(val, axis=0) \n        print 'Centroid (median) of offsets (local ned meters): ', np.median(val, axis=0) \n\n    #Extract dates\n    date_vec = np.array([e['Date'] for e in error_dict_list])\n    x = date_vec\n\n    make_plot3d(val[:,0], val[:,1], val[:,2], title=key)\n    #Note: there is a bug in pdf that displayes surface lines\n    #fig_fn = 'icp_translation_vec_proj_meters.png'\n    fig_fn = 'icp_translation_vec_local_meters.png'\n    #plt.savefig(fig_fn, dpi=600, bbox_inches='tight')\n\n    fig, ax = plt.subplots(1)\n    key = 'Translation vector (lat,lon,z)'\n    plt.title('ICP translation vector (lat,lon,z): Z component')\n    val = np.array([e[key] for e in error_dict_list])\n    y = val[:,2]\n    make_plot(x,y,c='b',label=key, abs=False)\n    fig.autofmt_xdate()\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    ax.set_ylabel('Z offset (m)')\n\n    fig, ax = plt.subplots(1)\n    key = 'Translation vector magnitude (meters)'\n    plt.title('ICP Translation vector magnitude (meters)')\n    y = np.array([e[key] for e in error_dict_list])\n    make_plot(x,y,c='b',label=key, abs=True)\n    fig.autofmt_xdate()\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    ax.set_ylabel('Offset (m)')\n\n    fig, ax = plt.subplots(1)\n    key = 'Number of errors'\n    plt.title('Number of error samples')\n    nerr = np.array([e[key] for e in error_dict_list])\n    make_plot(x,nerr,c='b',label=key)\n    fig.autofmt_xdate()\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    ax.set_ylabel('N samples')\n\n    \"\"\"\n    fig, ax = plt.subplots(1)\n    plt.title('ICP Standard Deviation')\n    key = 'Input Std Error'\n    in_std = np.array([e[key] for e in error_dict_list])\n    make_plot(x,in_std,c='r',label=key)\n    key = 'Output Std Error'\n    out_std = np.array([e[key] for e in error_dict_list])\n    make_plot(x,out_std,c='b',label=key)\n    fig.autofmt_xdate()\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    plt.legend(scatterpoints=1)\n    \"\"\"\n\n    fig, ax = plt.subplots(1)\n    plt.title('ICP Mean Error')\n    key = 'Input Mean Error'\n    in_mean = np.array([e[key] for e in error_dict_list])\n    #make_plot(x,in_mean,c='r',label=key,yerr=in_std)\n    make_plot(x,in_mean,c='r',label=key, abs=True)\n    key = 'Output Mean Error'\n    out_mean = np.array([e[key] for e in error_dict_list])\n    #make_plot(x,out_mean,c='b',label=key,yerr=out_std)\n    make_plot(x,out_mean,c='b',label=key, abs=True)\n    fig.autofmt_xdate()\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    ax.set_ylabel('Mean error (m)')\n    plt.legend(scatterpoints=1, loc='upper left', prop={'size':8})\n\n    fig, ax = plt.subplots(1)\n    plt.title('ICP Median Error')\n    key = 'Input 16th Percentile Error'\n    in_16p = np.array([e[key] for e in error_dict_list])\n    key = 'Input 84th Percentile Error'\n    in_84p = np.array([e[key] for e in error_dict_list])\n    key = 'Input Median Error'\n    in_med = np.array([e[key] for e in error_dict_list])\n    make_plot(x,in_med,c='r',label=key,yerr=[in_med - in_16p, in_84p - in_med], abs=True)\n    key = 'Output 16th Percentile Error'\n    out_16p = np.array([e[key] for e in error_dict_list])\n    key = 'Output 84th Percentile Error'\n    out_84p = np.array([e[key] for e in error_dict_list])\n    key = 'Output Median Error'\n    out_med = np.array([e[key] for e in error_dict_list])\n    make_plot(x,out_med,c='b',label=key,yerr=[out_med - out_16p, out_84p - out_med], abs=True)\n    fig.autofmt_xdate()\n    ax.fmt_xdata = mdates.DateFormatter(date_fmt)\n    ax.xaxis.set_minor_locator(months)\n    #ax.xaxis.set_major_locator(months_int)\n    #ax.xaxis.set_major_formatter(date_fmt)\n    ax.fmt_xdata = date_fmt\n    ax.set_ylabel('Median error (m)')\n    plt.legend(scatterpoints=1, loc='upper left', prop={'size':8})\n    fig_fn = 'icp_median_error.pdf'\n    plt.savefig(fig_fn, dpi=600, bbox_inches='tight')\n\n    fig, ax = plt.subplots(1)\n    plt.title('Sampled Median Error')\n    key = 'Input Sampled 16th Percentile Error'\n    in_16p = np.ma.fix_invalid([e[key] for e in error_dict_list])\n    if in_16p.count() > 0:\n        key = 'Input Sampled 84th Percentile Error'\n        in_84p = np.ma.fix_invalid([e[key] for e in error_dict_list])\n        key = 'Input Sampled Median Error'\n        in_med = np.ma.fix_invalid([e[key] for e in error_dict_list])\n        in_spread = in_84p - in_16p\n        make_plot(x,in_med,c='r',label=key,yerr=[in_med - in_16p, in_84p - in_med], abs=True)\n\n        key = 'Output Sampled 16th Percentile Error'\n        out_16p = np.ma.fix_invalid([e[key] for e in error_dict_list])\n        key = 'Output Sampled 84th Percentile Error'\n        out_84p = np.ma.fix_invalid([e[key] for e in error_dict_list])\n        key = 'Output Sampled Median Error'\n        out_med = np.ma.fix_invalid([e[key] for e in error_dict_list])\n        out_spread = out_84p - out_16p\n\n        p = 90.0\n        out_med_thresh = np.percentile(out_med, p)\n        out_spread_thresh = np.percentile(out_spread, p)\n        #print \"Outliers with horiz error >= %0.2f (%0.1f%%)\" % (p_thresh, p)\n        print\n        print \"Sampled Error Outliers:\" \n        #idx = (h_mag >= p_thresh).nonzero()[0]\n        idx = (out_med >= out_med_thresh).nonzero()[0]\n        idx = np.unique(np.hstack([idx, ((out_spread >= out_spread_thresh).nonzero()[0])]))\n        #Print all\n        idx = np.arange(out_med.size)\n        idx_sort = np.argsort(out_med[idx])\n        idx = idx[idx_sort]\n        print 'name, samp_mederrr, samp_errspread, nerr'\n        for i in idx:\n            print error_dict_list[i]['File'], out_med[i], out_spread[i], nerr[i]\n            #Delete from list\n            if remove_outliers:\n                print \"Removing from calculation\"\n                del error_dict_list[i]\n        print\n        print 'Input sampled median error (spread/2): %0.2f (%0.2f)' % (np.median(in_med), np.median(in_spread)/2.)\n        print 'Output sampled median error (spread/2): %0.2f (%0.2f)' % (np.median(out_med), np.median(out_spread)/2.)\n        print\n\n        make_plot(x,out_med,c='b',label=key,yerr=[out_med - out_16p, out_84p - out_med], abs=True)\n        fig.autofmt_xdate()\n        ax.set_ylabel('Median error (m)')\n        ax.fmt_xdata = mdates.DateFormatter(date_fmt)\n        ax.xaxis.set_minor_locator(months)\n        #ax.xaxis.set_major_locator(months_int)\n        #ax.xaxis.set_major_formatter(date_fmt)\n        ax.fmt_xdata = date_fmt\n        ax.set_ylabel('Median error (m)')\n        plt.legend(scatterpoints=1, loc='upper left', prop={'size':8})\n        ax.set_ylim(-15,15)\n        fig_fn = 'sampled_median_error.pdf'\n        #fig_fn = 'sampled_median_error_2014-2016.pdf'\n        #from datetime import datetime\n        #ax.set_xlim(datetime(2014,1,1),datetime(2016,7,1))\n        plt.savefig(fig_fn, dpi=600, bbox_inches='tight')", "response": "main function for the sample alignment"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _value_length(self, value, t):\n\n        if isinstance(value, int):\n            fmt = '<%s' % (type_codes[t])\n            output = struct.pack(fmt, value)\n            return len(output)\n        elif isinstance(value, str):\n            return len(value) + 1  # Account for final 0\n\n        len_accum = 0\n        for x in value:\n            len_accum += self._value_length(x, t)\n\n        return len_accum", "response": "Given an integer or list of bytes convert it to an array of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a line in a TileBus file and return a dict of the parsed information.", "response": "def _parse_line(self, line_no, line):\n        \"\"\"Parse a line in a TileBus file\n\n        Args:\n            line_no (int): The line number for printing useful error messages\n            line (string): The line that we are trying to parse\n        \"\"\"\n\n        try:\n            matched = statement.parseString(line)\n        except ParseException as exc:\n            raise DataError(\"Error parsing line in TileBus file\", line_number=line_no, column=exc.col, contents=line)\n\n        if 'symbol' in matched:\n            self._parse_cmd(matched)\n        elif 'filename' in matched:\n            self._parse_include(matched)\n        elif 'variable' in matched:\n            self._parse_assignment(matched)\n        elif 'configvar' in matched:\n            self._parse_configvar(matched)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that all information has been filled in.", "response": "def _validate_information(self):\n        \"\"\"Validate that all information has been filled in\"\"\"\n\n        needed_variables = [\"ModuleName\", \"ModuleVersion\", \"APIVersion\"]\n\n        for var in needed_variables:\n            if var not in self.variables:\n                raise DataError(\"Needed variable was not defined in mib file.\", variable=var)\n\n        # Make sure ModuleName is <= 6 characters\n        if len(self.variables[\"ModuleName\"]) > 6:\n            raise DataError(\"ModuleName too long, must be 6 or fewer characters.\",\n                            module_name=self.variables[\"ModuleName\"])\n\n        if not isinstance(self.variables[\"ModuleVersion\"], str):\n            raise ValueError(\"ModuleVersion ('%s') must be a string of the form X.Y.Z\" %\n                             str(self.variables['ModuleVersion']))\n\n        if not isinstance(self.variables[\"APIVersion\"], str):\n            raise ValueError(\"APIVersion ('%s') must be a string of the form X.Y\" % str(self.variables['APIVersion']))\n\n        self.variables['ModuleVersion'] = self._convert_module_version(self.variables[\"ModuleVersion\"])\n        self.variables['APIVersion'] = self._convert_api_version(self.variables[\"APIVersion\"])\n        self.variables[\"ModuleName\"] = self.variables[\"ModuleName\"].ljust(6)\n\n        self.valid = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_block(self, config_only=False):\n\n        mib = TBBlock()\n\n        for cid, config in self.configs.items():\n            mib.add_config(cid, config)\n\n        if not config_only:\n            for key, val in self.commands.items():\n                mib.add_command(key, val)\n\n            if not self.valid:\n                self._validate_information()\n\n            mib.set_api_version(*self.variables[\"APIVersion\"])\n            mib.set_module_version(*self.variables[\"ModuleVersion\"])\n            mib.set_name(self.variables[\"ModuleName\"])\n\n        return mib", "response": "Create a TileBus Block based on the information in this descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a device adapter to this aggregating adapter.", "response": "def add_adapter(self, adapter):\n        \"\"\"Add a device adapter to this aggregating adapter.\"\"\"\n\n        if self._started:\n            raise InternalError(\"New adapters cannot be added after start() is called\")\n\n        if isinstance(adapter, DeviceAdapter):\n            self._logger.warning(\"Wrapping legacy device adapter %s in async wrapper\", adapter)\n            adapter = AsynchronousModernWrapper(adapter, loop=self._loop)\n\n        self.adapters.append(adapter)\n\n        adapter_callback = functools.partial(self.handle_adapter_event,\n                                             len(self.adapters) - 1)\n        events = ['device_seen', 'broadcast', 'report', 'connection',\n                  'disconnection', 'trace', 'progress']\n\n        adapter.register_monitor([None], events, adapter_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a configuration setting from this DeviceAdapter.", "response": "def get_config(self, name, default=_MISSING):\n        \"\"\"Get a configuration setting from this DeviceAdapter.\n\n        See :meth:`AbstractDeviceAdapter.get_config`.\n        \"\"\"\n\n        val = self._config.get(name, default)\n        if val is _MISSING:\n            raise ArgumentError(\"DeviceAdapter config {} did not exist and no default\".format(name))\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts all adapters managed by this device adapter.", "response": "async def start(self):\n        \"\"\"Start all adapters managed by this device adapter.\n\n        If there is an error starting one or more adapters, this method will\n        stop any adapters that we successfully started and raise an exception.\n        \"\"\"\n\n        successful = 0\n\n        try:\n            for adapter in self.adapters:\n                await adapter.start()\n                successful += 1\n\n            self._started = True\n        except:\n            for adapter in self.adapters[:successful]:\n                await adapter.stop()\n\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nunify all visible devices across all connected adapters and return a dictionary mapping UUIDs to device information dictionaries", "response": "def visible_devices(self):\n        \"\"\"Unify all visible devices across all connected adapters\n\n        Returns:\n            dict: A dictionary mapping UUIDs to device information dictionaries\n        \"\"\"\n\n        devs = {}\n\n        for device_id, adapters in self._devices.items():\n            dev = None\n            max_signal = None\n            best_adapter = None\n\n            for adapter_id, devinfo in adapters.items():\n                connstring = \"adapter/{0}/{1}\".format(adapter_id, devinfo['connection_string'])\n                if dev is None:\n                    dev = copy.deepcopy(devinfo)\n                    del dev['connection_string']\n\n                if 'adapters' not in dev:\n                    dev['adapters'] = []\n                    best_adapter = adapter_id\n\n                dev['adapters'].append((adapter_id, devinfo['signal_strength'], connstring))\n\n                if max_signal is None:\n                    max_signal = devinfo['signal_strength']\n                elif devinfo['signal_strength'] > max_signal:\n                    max_signal = devinfo['signal_strength']\n                    best_adapter = adapter_id\n\n            # If device has been seen in no adapters, it will get expired\n            # don't return it\n            if dev is None:\n                continue\n\n            dev['connection_string'] = \"device/%x\" % dev['uuid']\n            dev['adapters'] = sorted(dev['adapters'], key=lambda x: x[1], reverse=True)\n            dev['best_adapter'] = best_adapter\n            dev['signal_strength'] = max_signal\n\n            devs[device_id] = dev\n\n        return devs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to a device.", "response": "async def connect(self, conn_id, connection_string):\n        \"\"\"Connect to a device.\n\n        See :meth:`AbstractDeviceAdapter.connect`.\n        \"\"\"\n\n        if connection_string.startswith('device/'):\n            adapter_id, local_conn = self._find_best_adapter(connection_string, conn_id)\n            translate_conn = True\n        elif connection_string.startswith('adapter/'):\n            adapter_str, _, local_conn = connection_string[8:].partition('/')\n            adapter_id = int(adapter_str)\n            translate_conn = False\n        else:\n            raise DeviceAdapterError(conn_id, 'connect', 'invalid connection string format')\n\n        if self.adapters[adapter_id].can_connect() is False:\n            raise DeviceAdapterError(conn_id, 'connect', 'chosen adapter cannot handle another connection')\n\n        # Make sure to set up the connection information before\n        # so there are no races with events coming soon after connect.\n        self._setup_connection(conn_id, local_conn)\n        self._track_property(conn_id, 'adapter', adapter_id)\n        self._track_property(conn_id, 'translate', translate_conn)\n\n        try:\n            await self.adapters[adapter_id].connect(conn_id, local_conn)\n        except:\n            self._teardown_connection(conn_id)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def disconnect(self, conn_id):\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        await self.adapters[adapter_id].disconnect(conn_id)\n\n        self._teardown_connection(conn_id)", "response": "Disconnect from a connected device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens an interface on an IOTile device.", "response": "async def open_interface(self, conn_id, interface):\n        \"\"\"Open an interface on an IOTile device.\n\n        See :meth:`AbstractDeviceAdapter.open_interface`.\n        \"\"\"\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        await self.adapters[adapter_id].open_interface(conn_id, interface)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def close_interface(self, conn_id, interface):\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        await self.adapters[adapter_id].close_interface(conn_id, interface)", "response": "Close an interface on this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def probe(self):\n\n        for adapter in self.adapters:\n            if adapter.get_config('probe_supported', False):\n                await adapter.probe()", "response": "Probe for devices.\n\n        This method will probe all adapters that can probe and will send a\n        notification for all devices that we have seen from all adapters.\n\n        See :meth:`AbstractDeviceAdapter.probe`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_rpc(self, conn_id, address, rpc_id, payload, timeout):\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        return await self.adapters[adapter_id].send_rpc(conn_id, address, rpc_id, payload, timeout)", "response": "Send an RPC to a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def debug(self, conn_id, name, cmd_args):\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        return await self.adapters[adapter_id].debug(conn_id, name, cmd_args)", "response": "Send a debug command to a device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_script(self, conn_id, data):\n\n        adapter_id = self._get_property(conn_id, 'adapter')\n        return await self.adapters[adapter_id].send_script(conn_id, data)", "response": "Send a script to a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle an event received from an adapter.", "response": "async def handle_adapter_event(self, adapter_id, conn_string, conn_id, name, event):\n        \"\"\"Handle an event received from an adapter.\"\"\"\n\n        if name == 'device_seen':\n            self._track_device_seen(adapter_id, conn_string, event)\n            event = self._translate_device_seen(adapter_id, conn_string, event)\n\n            conn_string = self._translate_conn_string(adapter_id, conn_string)\n        elif conn_id is not None and self._get_property(conn_id, 'translate'):\n            conn_string = self._translate_conn_string(adapter_id, conn_string)\n        else:\n            conn_string = \"adapter/%d/%s\" % (adapter_id, conn_string)\n\n        await self.notify_event(conn_string, name, event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _device_expiry_callback(self):\n\n        expired = 0\n        for adapters in self._devices.values():\n            to_remove = []\n            now = monotonic()\n\n            for adapter_id, dev in adapters.items():\n                if 'expires' not in dev:\n                    continue\n\n                if now > dev['expires']:\n                    to_remove.append(adapter_id)\n                    local_conn = \"adapter/%d/%s\" % (adapter_id, dev['connection_string'])\n\n                    if local_conn in self._conn_strings:\n                        del self._conn_strings[local_conn]\n\n            for entry in to_remove:\n                del adapters[entry]\n                expired += 1\n\n        if expired > 0:\n            self._logger.info('Expired %d devices', expired)", "response": "Periodic callback to remove expired devices from visible_devices."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef PathIsDir(self, key, val, env):\n        if not os.path.isdir(val):\n            if os.path.isfile(val):\n                m = 'Directory path for option %s is a file: %s'\n            else:\n                m = 'Directory path for option %s does not exist: %s'\n            raise SCons.Errors.UserError(m % (key, val))", "response": "Validator to check if Path is a directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PathExists(self, key, val, env):\n        if not os.path.exists(val):\n            m = 'Path for option %s does not exist: %s'\n            raise SCons.Errors.UserError(m % (key, val))", "response": "Validator to check if Path exists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing an input through this sensor graph.", "response": "async def process_graph_input(graph, stream, value, rpc_executor):\n    \"\"\"Process an input through this sensor graph.\n\n    The tick information in value should be correct and is transfered\n    to all results produced by nodes acting on this tick.  This coroutine\n    is an asyncio compatible version of SensorGraph.process_input()\n\n    Args:\n        stream (DataStream): The stream the input is part of\n        value (IOTileReading): The value to process\n        rpc_executor (RPCExecutor): An object capable of executing RPCs\n            in case we need to do that.\n    \"\"\"\n\n    graph.sensor_log.push(stream, value)\n\n    # FIXME: This should be specified in our device model\n    if stream.important:\n        associated_output = stream.associated_stream()\n        graph.sensor_log.push(associated_output, value)\n\n    to_check = deque([x for x in graph.roots])\n\n    while len(to_check) > 0:\n        node = to_check.popleft()\n        if node.triggered():\n            try:\n                results = node.process(rpc_executor, graph.mark_streamer)\n                for result in results:\n                    if inspect.iscoroutine(result.value):\n                        result.value = await asyncio.ensure_future(result.value)\n\n                    result.raw_time = value.raw_time\n                    graph.sensor_log.push(node.stream, result)\n            except:\n                logging.getLogger(__name__).exception(\"Unhandled exception in graph node processing function for node %s\", str(node))\n\n            # If we generated any outputs, notify our downstream nodes\n            # so that they are also checked to see if they should run.\n            if len(results) > 0:\n                to_check.extend(node.outputs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclear all volatile information across a reset.", "response": "def clear_to_reset(self, config_vars):\n        \"\"\"Clear all volatile information across a reset.\n\n        The reset behavior is that:\n        - any persisted sensor_graph is loaded\n        - if there is a persisted graph found, enabled is set to True\n        - if there is a persisted graph found, reset readings are pushed\n          into it.\n        \"\"\"\n\n        super(SensorGraphSubsystem, self).clear_to_reset(config_vars)\n\n        self.graph.clear()\n\n        if not self.persisted_exists:\n            return\n\n        for node in self.persisted_nodes:\n            self.graph.add_node(node)\n\n        for streamer_desc in self.persisted_streamers:\n            streamer = streamer_descriptor.parse_string_descriptor(streamer_desc)\n            self.graph.add_streamer(streamer)\n\n        # Load in the constants\n        for stream, reading in self.persisted_constants:\n            self._sensor_log.push(stream, reading)\n\n        self.enabled = True\n\n        # Set up all streamers\n        for index, value in self.streamer_acks.items():\n            self._seek_streamer(index, value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_input(self, encoded_stream, value):\n\n        if not self.enabled:\n            return\n\n        if isinstance(encoded_stream, str):\n            stream = DataStream.FromString(encoded_stream)\n            encoded_stream = stream.encode()\n        elif isinstance(encoded_stream, DataStream):\n            stream = encoded_stream\n            encoded_stream = stream.encode()\n        else:\n            stream = DataStream.FromEncoded(encoded_stream)\n\n        reading = IOTileReading(self.get_timestamp(), encoded_stream, value)\n\n        self._inputs.put_nowait((stream, reading))", "response": "Process or drop a graph input."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _seek_streamer(self, index, value):\n\n        highest_id = self._rsl.highest_stored_id()\n\n        streamer = self.graph.streamers[index]\n        if not streamer.walker.buffered:\n            return _pack_sgerror(SensorLogError.CANNOT_USE_UNBUFFERED_STREAM)\n\n        find_type = None\n        try:\n            exact = streamer.walker.seek(value, target='id')\n            if exact:\n                find_type = 'exact'\n            else:\n                find_type = 'other_stream'\n\n        except UnresolvedIdentifierError:\n            if value > highest_id:\n                find_type = 'too_high'\n            else:\n                find_type = 'too_low'\n\n        # If we found an exact match, move one beyond it\n\n        if find_type == 'exact':\n            try:\n                streamer.walker.pop()\n            except StreamEmptyError:\n                pass\n\n            error = Error.NO_ERROR\n        elif find_type == 'too_high':\n            streamer.walker.skip_all()\n            error = _pack_sgerror(SensorLogError.NO_MORE_READINGS)\n        elif find_type == 'too_low':\n            streamer.walker.seek(0, target='offset')\n            error = _pack_sgerror(SensorLogError.NO_MORE_READINGS)\n        else:\n            error = _pack_sgerror(SensorLogError.ID_FOUND_FOR_ANOTHER_STREAM)\n\n        return error", "response": "Internal method to seek a streamer to a specific reading_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nacknowledge a streamer value as received from the remote side.", "response": "def acknowledge_streamer(self, index, ack, force):\n        \"\"\"Acknowledge a streamer value as received from the remote side.\"\"\"\n\n        if index >= len(self.graph.streamers):\n            return _pack_sgerror(SensorGraphError.STREAMER_NOT_ALLOCATED)\n\n        old_ack = self.streamer_acks.get(index, 0)\n\n        if ack != 0:\n            if ack <= old_ack and not force:\n                return _pack_sgerror(SensorGraphError.OLD_ACKNOWLEDGE_UPDATE)\n\n            self.streamer_acks[index] = ack\n\n        current_ack = self.streamer_acks.get(index, 0)\n        return self._seek_streamer(index, current_ack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_streamers(self):\n\n        # Check for any triggered streamers and pass them to stream manager\n        in_progress = self._stream_manager.in_progress()\n        triggered = self.graph.check_streamers(blacklist=in_progress)\n\n        for streamer in triggered:\n            self._stream_manager.process_streamer(streamer, callback=self._handle_streamer_finished)", "response": "Check if any streamers should be handed to the stream manager and pass them to the stream manager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trigger_streamer(self, index):\n\n        self._logger.debug(\"trigger_streamer RPC called on streamer %d\", index)\n\n        if index >= len(self.graph.streamers):\n            return _pack_sgerror(SensorGraphError.STREAMER_NOT_ALLOCATED)\n\n        if index in self._stream_manager.in_progress():\n            return _pack_sgerror(SensorGraphError.STREAM_ALREADY_IN_PROGRESS)\n\n        streamer = self.graph.streamers[index]\n        if not streamer.triggered(manual=True):\n            return _pack_sgerror(SensorGraphError.STREAMER_HAS_NO_NEW_DATA)\n\n        self._logger.debug(\"calling mark_streamer on streamer %d from trigger_streamer RPC\", index)\n        self.graph.mark_streamer(index)\n\n        self.process_streamers()\n\n        return Error.NO_ERROR", "response": "Pass a streamer to the stream manager if it has data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef persist(self):\n\n        self.persisted_nodes = self.graph.dump_nodes()\n        self.persisted_streamers = self.graph.dump_streamers()\n        self.persisted_exists = True\n        self.persisted_constants = self._sensor_log.dump_constants()", "response": "Trigger saving the current sensorgraph to persistent storage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing the sensorgraph from RAM and flash.", "response": "def reset(self):\n        \"\"\"Clear the sensorgraph from RAM and flash.\"\"\"\n\n        self.persisted_exists = False\n        self.persisted_nodes = []\n        self.persisted_streamers = []\n        self.persisted_constants = []\n        self.graph.clear()\n\n        self.streamer_status = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_node(self, binary_descriptor):\n\n        try:\n            node_string = parse_binary_descriptor(binary_descriptor)\n        except:\n            self._logger.exception(\"Error parsing binary node descriptor: %s\", binary_descriptor)\n            return _pack_sgerror(SensorGraphError.INVALID_NODE_STREAM)  # FIXME: Actually provide the correct error codes here\n\n        try:\n            self.graph.add_node(node_string)\n        except NodeConnectionError:\n            return _pack_sgerror(SensorGraphError.STREAM_NOT_IN_USE)\n        except ProcessingFunctionError:\n            return _pack_sgerror(SensorGraphError.INVALID_PROCESSING_FUNCTION)\n        except ResourceUsageError:\n            return _pack_sgerror(SensorGraphError.NO_NODE_SPACE_AVAILABLE)\n\n        return Error.NO_ERROR", "response": "Add a node to the sensor_graph using a binary node descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_streamer(self, binary_descriptor):\n\n        streamer = streamer_descriptor.parse_binary_descriptor(binary_descriptor)\n\n        try:\n            self.graph.add_streamer(streamer)\n            self.streamer_status[len(self.graph.streamers) - 1] = StreamerStatus()\n\n            return Error.NO_ERROR\n        except ResourceUsageError:\n            return _pack_sgerror(SensorGraphError.NO_MORE_STREAMER_RESOURCES)", "response": "Add a streamer to the sensor_graph using a binary streamer descriptor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inspect_streamer(self, index):\n\n        if index >= len(self.graph.streamers):\n            return [_pack_sgerror(SensorGraphError.STREAMER_NOT_ALLOCATED), b'\\0'*14]\n\n        return [Error.NO_ERROR, streamer_descriptor.create_binary_descriptor(self.graph.streamers[index])]", "response": "Inspect the streamer at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inspect_node(self, index):\n\n        if index >= len(self.graph.nodes):\n            raise RPCErrorCode(6)  #FIXME: use actual error code here for UNKNOWN_ERROR status\n\n        return create_binary_descriptor(str(self.graph.nodes[index]))", "response": "Inspect the graph node at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_streamer(self, index):\n\n        if index >= len(self.graph.streamers):\n            return None\n\n        info = self.streamer_status[index]\n        highest_ack = self.streamer_acks.get(index, 0)\n\n        return [info.last_attempt_time, info.last_success_time, info.last_error, highest_ack, info.last_status, info.attempt_number, info.comm_status]", "response": "Query the status of the streamer at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the sensor - graph online or offline.", "response": "def sg_set_online(self, online):\n        \"\"\"Set the sensor-graph online/offline.\"\"\"\n\n        self.sensor_graph.enabled = bool(online)\n        return [Error.NO_ERROR]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npresent a graph input to the sensor_graph subsystem.", "response": "def sg_graph_input(self, value, stream_id):\n        \"\"\"\"Present a graph input to the sensor_graph subsystem.\"\"\"\n\n        self.sensor_graph.process_input(stream_id, value)\n        return [Error.NO_ERROR]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sg_add_streamer(self, desc):\n\n        if len(desc) == 13:\n            desc += b'\\0'\n\n        err = self.sensor_graph.add_streamer(desc)\n        return [err]", "response": "Add a streamer using a binary descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying the current status of a streamer.", "response": "def sg_query_streamer(self, index):\n        \"\"\"Query the current status of a streamer.\"\"\"\n\n        resp = self.sensor_graph.query_streamer(index)\n        if resp is None:\n            return [struct.pack(\"<L\", _pack_sgerror(SensorGraphError.STREAMER_NOT_ALLOCATED))]\n\n        return [struct.pack(\"<LLLLBBBx\", *resp)]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dispatch(self, value, callback=None):\n\n        done = None\n\n        if callback is None:\n            done = threading.Event()\n            shared_data = [None, None]\n\n            def _callback(exc_info, return_value):\n                shared_data[0] = exc_info\n                shared_data[1] = return_value\n\n                done.set()\n\n            callback = _callback\n\n        workitem = WorkItem(value, callback)\n        self._work_queue.put(workitem)\n        if done is None:\n            return None\n\n        done.wait()\n        exc_info, return_value = shared_data\n        if exc_info is not None:\n            self.future_raise(*exc_info)\n\n        return return_value", "response": "Dispatch an item to the work queue and optionally wait."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nraise implementation from future. utils", "response": "def future_raise(self, tp, value=None, tb=None):\n        \"\"\"raise_ implementation from future.utils\"\"\"\n        if value is not None and isinstance(tp, Exception):\n            raise TypeError(\"instance exception may not have a separate value\")\n        if value is not None:\n            exc = tp(value)\n        else:\n            exc = tp\n        if exc.__traceback__ is not tb:\n            raise exc.with_traceback(tb)\n        raise exc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nblocking the calling thread until the work queue is empty.", "response": "def wait_until_idle(self):\n        \"\"\"Block the calling thread until the work queue is (temporarily) empty.\n\n        See the detailed discussion under defer_until_idle() for restrictions\n        and expected use cases for this method.\n\n        This routine will block the calling thread.\n        \"\"\"\n\n        done = threading.Event()\n\n        def _callback():\n            done.set()\n\n        self.defer_until_idle(_callback)\n        done.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef direct_dispatch(self, arg, callback):\n\n        try:\n            self._current_callbacks.appendleft(callback)\n\n            exc_info = None\n            retval = None\n\n            retval = self._routine(arg)\n        except:  # pylint:disable=bare-except;We need to capture the exception and feed it back to the caller\n            exc_info = sys.exc_info()\n        finally:\n            self._current_callbacks.popleft()\n\n        if callback is not None and retval is not self.STILL_PENDING:\n            callback(exc_info, retval)\n\n        return retval, exc_info", "response": "Directly dispatch a work item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self):\n\n        idle_watchers = []\n\n        while True:\n            try:\n                if self._work_queue.empty() and len(idle_watchers) > 0:\n                    for watcher in idle_watchers:\n                        try:\n                            watcher()\n                        except: # pylint:disable=bare-except;We can't let one idle watcher failure impact any other watcher\n                            self._logger.exception(\"Error inside queue idle watcher\")\n\n                    idle_watchers = []\n\n                item = self._work_queue.get()\n\n                # Handle special actions that are not RPCs\n                if item is STOP_WORKER_ITEM:\n                    return\n                elif isinstance(item, MarkLocationItem):\n                    item.callback()\n                    continue\n                elif isinstance(item, WaitIdleItem):\n                    idle_watchers.append(item.callback)\n                    continue\n                elif not isinstance(item, WorkItem):\n                    self._logger.error(\"Invalid item passed to WorkQueueThread: %s, ignoring\", item)\n                    continue\n\n                self.direct_dispatch(item.arg, item.callback)\n\n            except:  # pylint:disable=bare-except;We cannot let this background thread die until we are told to stop()\n                self._logger.exception(\"Error inside background workqueue thread\")", "response": "The main thread of the main thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the worker thread and synchronously wait for it to finish.", "response": "def stop(self, timeout=None, force=False):\n        \"\"\"Stop the worker thread and synchronously wait for it to finish.\n\n        Args:\n            timeout (float): The maximum time to wait for the thread to stop\n                before raising a TimeoutExpiredError.  If force is True, TimeoutExpiredError\n                is not raised and the thread is just marked as a daemon thread\n                so that it does not block cleanly exiting the process.\n            force (bool): If true and the thread does not exit in timeout seconds\n                no error is raised since the thread is marked as daemon and will\n                be killed when the process exits.\n        \"\"\"\n\n        self.signal_stop()\n        self.wait_stopped(timeout, force)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for the background thread to exit.", "response": "def wait_stopped(self, timeout=None, force=False):\n        \"\"\"Wait for the thread to stop.\n\n        You must have previously called signal_stop or this function will\n        hang.\n\n        Args:\n\n            timeout (float): The maximum time to wait for the thread to stop\n                before raising a TimeoutExpiredError.  If force is True,\n                TimeoutExpiredError is not raised and the thread is just\n                marked as a daemon thread so that it does not block cleanly\n                exiting the process.\n            force (bool): If true and the thread does not exit in timeout seconds\n                no error is raised since the thread is marked as daemon and will\n                be killed when the process exits.\n        \"\"\"\n\n        self.join(timeout)\n\n        if self.is_alive() and force is False:\n            raise TimeoutExpiredError(\"Error waiting for background thread to exit\", timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    if not exists(env):\n      return\n\n    env['WIXCANDLEFLAGS'] = ['-nologo']\n    env['WIXCANDLEINCLUDE'] = []\n    env['WIXCANDLECOM'] = '$WIXCANDLE $WIXCANDLEFLAGS -I $WIXCANDLEINCLUDE -o ${TARGET} ${SOURCE}'\n\n    env['WIXLIGHTFLAGS'].append( '-nologo' )\n    env['WIXLIGHTCOM'] = \"$WIXLIGHT $WIXLIGHTFLAGS -out ${TARGET} ${SOURCES}\"\n    env['WIXSRCSUF'] = '.wxs'\n    env['WIXOBJSUF'] = '.wixobj'\n\n    object_builder = SCons.Builder.Builder(\n        action      = '$WIXCANDLECOM',\n        suffix      = '$WIXOBJSUF',\n        src_suffix  = '$WIXSRCSUF')\n\n    linker_builder = SCons.Builder.Builder(\n        action      = '$WIXLIGHTCOM',\n        src_suffix  = '$WIXOBJSUF',\n        src_builder = object_builder)\n\n    env['BUILDERS']['WiX'] = linker_builder", "response": "Add Builders and construction variables for WiX to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new stimulus from a string description.", "response": "def FromString(cls, desc):\n        \"\"\"Create a new stimulus from a description string.\n\n        The string must have the format:\n\n        [time: ][system ]input X = Y\n        where X and Y are integers.  The time, if given must\n        be a time_interval, which is an integer followed by a\n        time unit such as second(s), minute(s), etc.\n\n        Args:\n            desc (str): A string description of the stimulus.\n\n        Returns:\n            SimulationStimulus: The parsed stimulus object.\n        \"\"\"\n        if language.stream is None:\n            language.get_language()\n\n        parse_exp = Optional(time_interval('time') - Literal(':').suppress()) - language.stream('stream') - Literal('=').suppress() - number('value')\n\n        try:\n            data = parse_exp.parseString(desc)\n            time = 0\n            if 'time' in data:\n                time = data['time'][0]\n\n            return SimulationStimulus(time, data['stream'][0], data['value'])\n        except (ParseException, ParseSyntaxException):\n            raise ArgumentError(\"Could not parse stimulus descriptor\", descriptor=desc)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_connection_id(self, conn_or_int_id):\n\n        key = conn_or_int_id\n        if isinstance(key, str):\n            table = self._int_connections\n        elif isinstance(key, int):\n            table = self._connections\n        else:\n            raise ArgumentError(\"You must supply either an int connection id or a string internal id to _get_connection_state\", id=key)\n\n        try:\n            data = table[key]\n        except KeyError:\n            raise ArgumentError(\"Could not find connection by id\", id=key)\n\n        return data['conn_id']", "response": "Get the connection id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_connection(self, conn_or_int_id):\n\n        key = conn_or_int_id\n        if isinstance(key, str):\n            table = self._int_connections\n        elif isinstance(key, int):\n            table = self._connections\n        else:\n            return None\n\n        try:\n            data = table[key]\n        except KeyError:\n            return None\n\n        return data", "response": "Get the data associated with a connection by either conn_id or internal_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_connection_state(self, conn_or_int_id):\n\n        key = conn_or_int_id\n        if isinstance(key, str):\n            table = self._int_connections\n        elif isinstance(key, int):\n            table = self._connections\n        else:\n            raise ArgumentError(\"You must supply either an int connection id or a string internal id to _get_connection_state\", id=key)\n\n        if key not in table:\n            return self.Disconnected\n\n        data = table[key]\n        return data['state']", "response": "Get a connection s state by either conn_id or internal_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_timeouts(self):\n\n        for conn_id, data in self._connections.items():\n            if 'timeout' in data and data['timeout'].expired:\n                if data['state'] == self.Connecting:\n                    self.finish_connection(conn_id, False, 'Connection attempt timed out')\n                elif data['state'] == self.Disconnecting:\n                    self.finish_disconnection(conn_id, False, 'Disconnection attempt timed out')\n                elif data['state'] == self.InProgress:\n                    if data['microstate'] == 'rpc':\n                        self.finish_operation(conn_id, False, 'RPC timed out without response', None, None)\n                    elif data['microstate'] == 'open_interface':\n                        self.finish_operation(conn_id, False, 'Open interface request timed out')", "response": "Checks if any operations in progress need to be timed out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _begin_connection_action(self, action):\n\n        conn_id = action.data['connection_id']\n        int_id = action.data['internal_id']\n        callback = action.data['callback']\n\n        # Make sure we are not reusing an id that is currently connected to something\n        if self._get_connection_state(conn_id) != self.Disconnected:\n            print(self._connections[conn_id])\n            callback(conn_id, self.id, False, 'Connection ID is already in use for another connection')\n            return\n\n        if self._get_connection_state(int_id) != self.Disconnected:\n            callback(conn_id, self.id, False, 'Internal ID is already in use for another connection')\n            return\n\n        conn_data = {\n            'state': self.Connecting,\n            'microstate': None,\n            'conn_id': conn_id,\n            'int_id': int_id,\n            'callback': callback,\n            'timeout': action.timeout,\n            'context': action.data['context']\n        }\n\n        self._connections[conn_id] = conn_data\n        self._int_connections[int_id] = conn_data", "response": "This function is called when we are about to start a new connection attempt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _finish_connection_action(self, action):\n\n        success = action.data['success']\n        conn_key = action.data['id']\n\n        if self._get_connection_state(conn_key) != self.Connecting:\n            print(\"Invalid finish_connection action on a connection whose state is not Connecting, conn_key=%s\" % str(conn_key))\n            return\n\n        # Cannot be None since we checked above to make sure it exists\n        data = self._get_connection(conn_key)\n        callback = data['callback']\n\n        conn_id = data['conn_id']\n        int_id = data['int_id']\n\n        if success is False:\n            reason = action.data['reason']\n            if reason is None:\n                reason = \"No reason was given\"\n\n            del self._connections[conn_id]\n            del self._int_connections[int_id]\n            callback(conn_id, self.id, False, reason)\n        else:\n            data['state'] = self.Idle\n            data['microstate'] = None\n            data['callback'] = None\n            callback(conn_id, self.id, True, None)", "response": "Finish a connection attempt."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnotifying that there was an unexpected disconnection of the device.", "response": "def unexpected_disconnect(self, conn_or_internal_id):\n        \"\"\"Notify that there was an unexpected disconnection of the device.\n\n        Any in progress operations are canceled cleanly and the device is transitioned\n        to a disconnected state.\n\n        Args:\n            conn_or_internal_id (string, int): Either an integer connection id or a string\n                internal_id\n        \"\"\"\n\n        data = {\n            'id': conn_or_internal_id\n        }\n\n        action = ConnectionAction('force_disconnect', data, sync=False)\n        self._actions.put(action)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef begin_disconnection(self, conn_or_internal_id, callback, timeout):\n\n        data = {\n            'id': conn_or_internal_id,\n            'callback': callback\n        }\n\n        action = ConnectionAction('begin_disconnection', data, timeout=timeout, sync=False)\n        self._actions.put(action)", "response": "Begin a disconnection attempt for the specified connection or internal id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbeginning a disconnection attempt for a specific resource.", "response": "def _begin_disconnection_action(self, action):\n        \"\"\"Begin a disconnection attempt\n\n        Args:\n            action (ConnectionAction): the action object describing what we are\n                connecting to and what the result of the operation was\n        \"\"\"\n\n        conn_key = action.data['id']\n        callback = action.data['callback']\n\n        if self._get_connection_state(conn_key) != self.Idle:\n            callback(conn_key, self.id, False, 'Cannot start disconnection, connection is not idle')\n            return\n\n        # Cannot be None since we checked above to make sure it exists\n        data = self._get_connection(conn_key)\n        data['state'] = self.Disconnecting\n        data['microstate'] = None\n        data['callback'] = callback\n        data['timeout'] = action.timeout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfinish a disconnection attempt.", "response": "def _finish_disconnection_action(self, action):\n        \"\"\"Finish a disconnection attempt\n\n        There are two possible outcomes:\n        - if we were successful at disconnecting, we transition to disconnected\n        - if we failed at disconnecting, we transition back to idle\n\n        Args:\n            action (ConnectionAction): the action object describing what we are\n                disconnecting from and what the result of the operation was\n        \"\"\"\n\n        success = action.data['success']\n        conn_key = action.data['id']\n\n        if self._get_connection_state(conn_key) != self.Disconnecting:\n            self._logger.error(\"Invalid finish_disconnection action on a connection whose state is not Disconnecting, conn_key=%s\", str(conn_key))\n            return\n\n        # Cannot be None since we checked above to make sure it exists\n        data = self._get_connection(conn_key)\n        callback = data['callback']\n\n        conn_id = data['conn_id']\n        int_id = data['int_id']\n\n        if success is False:\n            reason = action.data['reason']\n            if reason is None:\n                reason = \"No reason was given\"\n\n            data['state'] = self.Idle\n            data['microstate'] = None\n            data['callback'] = None\n            callback(conn_id, self.id, False, reason)\n        else:\n            del self._connections[conn_id]\n            del self._int_connections[int_id]\n            callback(conn_id, self.id, True, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfinish an operation on a connection.", "response": "def finish_operation(self, conn_or_internal_id, success, *args):\n        \"\"\"Finish an operation on a connection.\n\n        Args:\n            conn_or_internal_id (string, int): Either an integer connection id or a string\n                internal_id\n            success (bool): Whether the operation was successful\n            failure_reason (string): Optional reason why the operation failed\n            result (dict): Optional dictionary containing the results of the operation\n        \"\"\"\n\n        data = {\n            'id': conn_or_internal_id,\n            'success': success,\n            'callback_args': args\n        }\n\n        action = ConnectionAction('finish_operation', data, sync=False)\n        self._actions.put(action)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _finish_operation_action(self, action):\n\n        success = action.data['success']\n        conn_key = action.data['id']\n\n        if self._get_connection_state(conn_key) != self.InProgress:\n            self._logger.error(\"Invalid finish_operation action on a connection whose state is not InProgress, conn_key=%s\", str(conn_key))\n            return\n\n        # Cannot be None since we checked above to make sure it exists\n        data = self._get_connection(conn_key)\n        callback = data['callback']\n        conn_id = data['conn_id']\n        args = action.data['callback_args']\n\n        data['state'] = self.Idle\n        data['microstate'] = None\n\n        callback(conn_id, self.id, success, *args)", "response": "Finish an attempted operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef canonical_text(self, text):\n        out = []\n        line_continues_a_comment = False\n        for line in text.splitlines():\n            line,comment = self.comment_re.findall(line)[0]\n            if line_continues_a_comment == True:\n                out[-1] = out[-1] + line.lstrip()\n            else:\n                out.append(line)\n            line_continues_a_comment = len(comment) > 0\n        return '\\n'.join(out).rstrip()+'\\n'", "response": "Standardize TeX - file contents. Currently : * removes comments and unwrapping comment - wrapped lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing a recursive scan of the top level target file This lets us search for included files based on the directory of the main file just as latex does", "response": "def scan_recurse(self, node, path=()):\n        \"\"\" do a recursive scan of the top level target file\n        This lets us search for included files based on the\n        directory of the main file just as latex does\"\"\"\n\n        path_dict = dict(list(path))\n        \n        queue = [] \n        queue.extend( self.scan(node) )\n        seen = {}\n\n        # This is a hand-coded DSU (decorate-sort-undecorate, or\n        # Schwartzian transform) pattern.  The sort key is the raw name\n        # of the file as specifed on the \\include, \\input, etc. line.\n        # TODO: what about the comment in the original Classic scanner:\n        # \"\"\"which lets\n        # us keep the sort order constant regardless of whether the file\n        # is actually found in a Repository or locally.\"\"\"\n        nodes = []\n        source_dir = node.get_dir()\n        #for include in includes:\n        while queue:\n            \n            include = queue.pop()\n            inc_type, inc_subdir, inc_filename = include\n\n            try:\n                if seen[inc_filename] == 1:\n                    continue\n            except KeyError:\n                seen[inc_filename] = 1\n\n            #\n            # Handle multiple filenames in include[1]\n            #\n            n, i = self.find_include(include, source_dir, path_dict)\n            if n is None:\n                # Do not bother with 'usepackage' warnings, as they most\n                # likely refer to system-level files\n                if inc_type != 'usepackage':\n                    SCons.Warnings.warn(SCons.Warnings.DependencyWarning,\n                                        \"No dependency generated for file: %s (included from: %s) -- file not found\" % (i, node))\n            else:\n                sortkey = self.sort_key(n)\n                nodes.append((sortkey, n))\n                # recurse down\n                queue.extend( self.scan(n, inc_subdir) )\n\n        return [pair[1] for pair in sorted(nodes)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef caller_trace(back=0):\n    global caller_bases, caller_dicts\n    import traceback\n    tb = traceback.extract_stack(limit=3+back)\n    tb.reverse()\n    callee = tb[1][:3]\n    caller_bases[callee] = caller_bases.get(callee, 0) + 1\n    for caller in tb[2:]:\n        caller = callee + caller[:3]\n        try:\n            entry = caller_dicts[callee]\n        except KeyError:\n            caller_dicts[callee] = entry = {}\n        entry[caller] = entry.get(caller, 0) + 1\n        callee = caller", "response": "Trace the caller stack and save info into global dicts which can be used to create SCons execution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a trace message to a file.", "response": "def Trace(msg, file=None, mode='w', tstamp=None):\n    \"\"\"Write a trace message to a file.  Whenever a file is specified,\n    it becomes the default for the next call to Trace().\"\"\"\n    global TraceDefault\n    global TimeStampDefault\n    global PreviousTime\n    if file is None:\n        file = TraceDefault\n    else:\n        TraceDefault = file\n    if tstamp is None:\n        tstamp = TimeStampDefault\n    else:\n        TimeStampDefault = tstamp\n    try:\n        fp = TraceFP[file]\n    except KeyError:\n        try:\n            fp = TraceFP[file] = open(file, mode)\n        except TypeError:\n            # Assume we were passed an open file pointer.\n            fp = file\n    if tstamp:\n        now = time.time()\n        fp.write('%8.4f %8.4f:  ' % (now - StartTime, now - PreviousTime))\n        PreviousTime = now\n    fp.write(msg)\n    fp.flush()\n    fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(self, obj):\n\n        if isinstance(obj, str):\n            raise ValidationError(\"Object was not a list\", reason=\"a string was passed instead of a list\", object=obj)\n\n        out_obj = []\n        if self._min_length is not None and len(obj) < self._min_length:\n            raise ValidationError(\"List was too short\",\n                                  reason=\"list length %d was less than the minimum %d\" % (len(obj), self._min_length),\n                                  min_length=self._min_length, actual_length=len(obj))\n\n        if self._max_length is not None and len(obj) > self._max_length:\n            raise ValidationError(\"List was too long\",\n                                  reason=\"list length %d was greater than the max %d\" % (len(obj), self._max_length),\n                                  min_length=self._max_length, actual_length=len(obj))\n\n        for val in obj:\n            out_obj.append(self._verifier.verify(val))\n\n        return out_obj", "response": "Verifies that the object conforms to this verifier s schema\nTaxonomy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a hex file to binary file.", "response": "def hex2bin(fin, fout, start=None, end=None, size=None, pad=None):\n    \"\"\"Hex-to-Bin convertor engine.\n    @return     0   if all OK\n\n    @param  fin     input hex file (filename or file-like object)\n    @param  fout    output bin file (filename or file-like object)\n    @param  start   start of address range (optional)\n    @param  end     end of address range (inclusive; optional)\n    @param  size    size of resulting file (in bytes) (optional)\n    @param  pad     padding byte (optional)\n    \"\"\"\n    try:\n        h = IntelHex(fin)\n    except HexReaderError:\n        e = sys.exc_info()[1]     # current exception\n        txt = \"ERROR: bad HEX file: %s\" % str(e)\n        print(txt)\n        return 1\n\n    # start, end, size\n    if size != None and size != 0:\n        if end == None:\n            if start == None:\n                start = h.minaddr()\n            end = start + size - 1\n        else:\n            if (end+1) >= size:\n                start = end + 1 - size\n            else:\n                start = 0\n\n    try:\n        if pad is not None:\n            # using .padding attribute rather than pad argument to function call\n            h.padding = pad\n        h.tobinfile(fout, start, end)\n    except IOError:\n        e = sys.exc_info()[1]     # current exception\n        txt = \"ERROR: Could not write to file: %s: %s\" % (fout, str(e))\n        print(txt)\n        return 1\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bin2hex(fin, fout, offset=0):\n    h = IntelHex()\n    try:\n        h.loadbin(fin, offset)\n    except IOError:\n        e = sys.exc_info()[1]     # current exception\n        txt = 'ERROR: unable to load bin file:', str(e)\n        print(txt)\n        return 1\n\n    try:\n        h.tofile(fout, format='hex')\n    except IOError:\n        e = sys.exc_info()[1]     # current exception\n        txt = \"ERROR: Could not write to file: %s: %s\" % (fout, str(e))\n        print(txt)\n        return 1\n\n    return 0", "response": "Simple bin - to - hex conversion."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff_dumps(ih1, ih2, tofile=None, name1=\"a\", name2=\"b\", n_context=3):\n    def prepare_lines(ih):\n        sio = StringIO()\n        ih.dump(sio)\n        dump = sio.getvalue()\n        lines = dump.splitlines()\n        return lines\n    a = prepare_lines(ih1)\n    b = prepare_lines(ih2)\n    import difflib\n    result = list(difflib.unified_diff(a, b, fromfile=name1, tofile=name2, n=n_context, lineterm=''))\n    if tofile is None:\n        tofile = sys.stdout\n    output = '\\n'.join(result)+'\\n'\n    tofile.write(output)", "response": "Diff 2 IntelHex objects and produce unified diff output for their\n    hex dumps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _decode_record(self, s, line=0):\n        '''Decode one record of HEX file.\n\n        @param  s       line with HEX record.\n        @param  line    line number (for error messages).\n\n        @raise  EndOfFile   if EOF record encountered.\n        '''\n        s = s.rstrip('\\r\\n')\n        if not s:\n            return          # empty line\n\n        if s[0] == ':':\n            try:\n                bin = array('B', unhexlify(asbytes(s[1:])))\n            except (TypeError, ValueError):\n                # this might be raised by unhexlify when odd hexascii digits\n                raise HexRecordError(line=line)\n            length = len(bin)\n            if length < 5:\n                raise HexRecordError(line=line)\n        else:\n            raise HexRecordError(line=line)\n\n        record_length = bin[0]\n        if length != (5 + record_length):\n            raise RecordLengthError(line=line)\n\n        addr = bin[1]*256 + bin[2]\n\n        record_type = bin[3]\n        if not (0 <= record_type <= 5):\n            raise RecordTypeError(line=line)\n\n        crc = sum(bin)\n        crc &= 0x0FF\n        if crc != 0:\n            raise RecordChecksumError(line=line)\n\n        if record_type == 0:\n            # data record\n            addr += self._offset\n            for i in range_g(4, 4+record_length):\n                if not self._buf.get(addr, None) is None:\n                    raise AddressOverlapError(address=addr, line=line)\n                self._buf[addr] = bin[i]\n                addr += 1   # FIXME: addr should be wrapped\n                            # BUT after 02 record (at 64K boundary)\n                            # and after 04 record (at 4G boundary)\n\n        elif record_type == 1:\n            # end of file record\n            if record_length != 0:\n                raise EOFRecordError(line=line)\n            raise _EndOfFile\n\n        elif record_type == 2:\n            # Extended 8086 Segment Record\n            if record_length != 2 or addr != 0:\n                raise ExtendedSegmentAddressRecordError(line=line)\n            self._offset = (bin[4]*256 + bin[5]) * 16\n\n        elif record_type == 4:\n            # Extended Linear Address Record\n            if record_length != 2 or addr != 0:\n                raise ExtendedLinearAddressRecordError(line=line)\n            self._offset = (bin[4]*256 + bin[5]) * 65536\n\n        elif record_type == 3:\n            # Start Segment Address Record\n            if record_length != 4 or addr != 0:\n                raise StartSegmentAddressRecordError(line=line)\n            if self.start_addr:\n                raise DuplicateStartAddressRecordError(line=line)\n            self.start_addr = {'CS': bin[4]*256 + bin[5],\n                               'IP': bin[6]*256 + bin[7],\n                              }\n\n        elif record_type == 5:\n            # Start Linear Address Record\n            if record_length != 4 or addr != 0:\n                raise StartLinearAddressRecordError(line=line)\n            if self.start_addr:\n                raise DuplicateStartAddressRecordError(line=line)\n            self.start_addr = {'EIP': (bin[4]*16777216 +\n                                       bin[5]*65536 +\n                                       bin[6]*256 +\n                                       bin[7]),\n                              }", "response": "Decode one record of HEX file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the object from a hex file into internal buffer.", "response": "def loadhex(self, fobj):\n        \"\"\"Load hex file into internal buffer. This is not necessary\n        if object was initialized with source set. This will overwrite\n        addresses if object was already initialized.\n\n        @param  fobj        file name or file-like object\n        \"\"\"\n        if getattr(fobj, \"read\", None) is None:\n            fobj = open(fobj, \"r\")\n            fclose = fobj.close\n        else:\n            fclose = None\n\n        self._offset = 0\n        line = 0\n\n        try:\n            decode = self._decode_record\n            try:\n                for s in fobj:\n                    line += 1\n                    decode(s, line)\n            except _EndOfFile:\n                pass\n        finally:\n            if fclose:\n                fclose()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the contents of a bin file into internal buffer.", "response": "def loadbin(self, fobj, offset=0):\n        \"\"\"Load bin file into internal buffer. Not needed if source set in\n        constructor. This will overwrite addresses without warning\n        if object was already initialized.\n\n        @param  fobj        file name or file-like object\n        @param  offset      starting address offset\n        \"\"\"\n        fread = getattr(fobj, \"read\", None)\n        if fread is None:\n            f = open(fobj, \"rb\")\n            fread = f.read\n            fclose = f.close\n        else:\n            fclose = None\n\n        try:\n            self.frombytes(array('B', asbytes(fread())), offset=offset)\n        finally:\n            if fclose:\n                fclose()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef loadfile(self, fobj, format):\n        if format == \"hex\":\n            self.loadhex(fobj)\n        elif format == \"bin\":\n            self.loadbin(fobj)\n        else:\n            raise ValueError('format should be either \"hex\" or \"bin\";'\n                ' got %r instead' % format)", "response": "Wrapper over loadbin or loadhex."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromdict(self, dikt):\n        s = dikt.copy()\n        start_addr = s.get('start_addr')\n        if start_addr is not None:\n            del s['start_addr']\n        for k in dict_keys_g(s):\n            if type(k) not in IntTypes or k < 0:\n                raise ValueError('Source dictionary should have only int keys')\n        self._buf.update(s)\n        if start_addr is not None:\n            self.start_addr = start_addr", "response": "Load data from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef frombytes(self, bytes, offset=0):\n        for b in bytes:\n            self._buf[offset] = b\n            offset += 1", "response": "Load data from array or list of bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_start_end(self, start=None, end=None, size=None):\n        if (start,end) == (None,None) and self._buf == {}:\n            raise EmptyIntelHexError\n        if size is not None:\n            if None not in (start, end):\n                raise ValueError(\"tobinarray: you can't use start,end and size\"\n                                 \" arguments in the same time\")\n            if (start, end) == (None, None):\n                start = self.minaddr()\n            if start is not None:\n                end = start + size - 1\n            else:\n                start = end - size + 1\n                if start < 0:\n                    raise ValueError(\"tobinarray: invalid size (%d) \"\n                                     \"for given end address (%d)\" % (size,end))\n        else:\n            if start is None:\n                start = self.minaddr()\n            if end is None:\n                end = self.maxaddr()\n            if start > end:\n                start, end = end, start\n        return start, end", "response": "Return default values for start and end if they are None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting this object to binary form as array.", "response": "def tobinarray(self, start=None, end=None, pad=_DEPRECATED, size=None):\n        ''' Convert this object to binary form as array. If start and end\n        unspecified, they will be inferred from the data.\n        @param  start   start address of output bytes.\n        @param  end     end address of output bytes (inclusive).\n        @param  pad     [DEPRECATED PARAMETER, please use self.padding instead]\n                        fill empty spaces with this value\n                        (if pad is None then this method uses self.padding).\n        @param  size    size of the block, used with start or end parameter.\n        @return         array of unsigned char data.\n        '''\n        if not isinstance(pad, _DeprecatedParam):\n            print (\"IntelHex.tobinarray: 'pad' parameter is deprecated.\")\n            if pad is not None:\n                print (\"Please, use IntelHex.padding attribute instead.\")\n            else:\n                print (\"Please, don't pass it explicitly.\")\n                print (\"Use syntax like this: ih.tobinarray(start=xxx, end=yyy, size=zzz)\")\n        else:\n            pad = None\n        return self._tobinarray_really(start, end, pad, size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tobinstr(self, start=None, end=None, pad=_DEPRECATED, size=None):\n        ''' Convert to binary form and return as binary string.\n        @param  start   start address of output bytes.\n        @param  end     end address of output bytes (inclusive).\n        @param  pad     [DEPRECATED PARAMETER, please use self.padding instead]\n                        fill empty spaces with this value\n                        (if pad is None then this method uses self.padding).\n        @param  size    size of the block, used with start or end parameter.\n        @return         bytes string of binary data.\n        '''\n        if not isinstance(pad, _DeprecatedParam):\n            print (\"IntelHex.tobinstr: 'pad' parameter is deprecated.\")\n            if pad is not None:\n                print (\"Please, use IntelHex.padding attribute instead.\")\n            else:\n                print (\"Please, don't pass it explicitly.\")\n                print (\"Use syntax like this: ih.tobinstr(start=xxx, end=yyy, size=zzz)\")\n        else:\n            pad = None\n        return self._tobinstr_really(start, end, pad, size)", "response": "Convert to binary form and return as binary string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tobinfile(self, fobj, start=None, end=None, pad=_DEPRECATED, size=None):\n        '''Convert to binary and write to file.\n\n        @param  fobj    file name or file object for writing output bytes.\n        @param  start   start address of output bytes.\n        @param  end     end address of output bytes (inclusive).\n        @param  pad     [DEPRECATED PARAMETER, please use self.padding instead]\n                        fill empty spaces with this value\n                        (if pad is None then this method uses self.padding).\n        @param  size    size of the block, used with start or end parameter.\n        '''\n        if not isinstance(pad, _DeprecatedParam):\n            print (\"IntelHex.tobinfile: 'pad' parameter is deprecated.\")\n            if pad is not None:\n                print (\"Please, use IntelHex.padding attribute instead.\")\n            else:\n                print (\"Please, don't pass it explicitly.\")\n                print (\"Use syntax like this: ih.tobinfile(start=xxx, end=yyy, size=zzz)\")\n        else:\n            pad = None\n        if getattr(fobj, \"write\", None) is None:\n            fobj = open(fobj, \"wb\")\n            close_fd = True\n        else:\n            close_fd = False\n\n        fobj.write(self._tobinstr_really(start, end, pad, size))\n\n        if close_fd:\n            fobj.close()", "response": "Convert to binary and write to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef todict(self):\n        '''Convert to python dictionary.\n\n        @return         dict suitable for initializing another IntelHex object.\n        '''\n        r = {}\n        r.update(self._buf)\n        if self.start_addr:\n            r['start_addr'] = self.start_addr\n        return r", "response": "Convert to python dictionary.\n        @return         dict suitable for initializing another IntelHex object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting data to a HEX file.", "response": "def write_hex_file(self, f, write_start_addr=True, eolstyle='native', byte_count=16):\n        \"\"\"Write data to file f in HEX format.\n\n        @param  f                   filename or file-like object for writing\n        @param  write_start_addr    enable or disable writing start address\n                                    record to file (enabled by default).\n                                    If there is no start address in obj, nothing\n                                    will be written regardless of this setting.\n        @param  eolstyle            can be used to force CRLF line-endings\n                                    for output file on different platforms.\n                                    Supported eol styles: 'native', 'CRLF'.\n        @param byte_count           number of bytes in the data field\n        \"\"\"\n        if byte_count > 255 or byte_count < 1:\n            raise ValueError(\"wrong byte_count value: %s\" % byte_count)\n        fwrite = getattr(f, \"write\", None)\n        if fwrite:\n            fobj = f\n            fclose = None\n        else:\n            fobj = open(f, 'w')\n            fwrite = fobj.write\n            fclose = fobj.close\n\n        eol = IntelHex._get_eol_textfile(eolstyle, sys.platform)\n\n        # Translation table for uppercasing hex ascii string.\n        # timeit shows that using hexstr.translate(table)\n        # is faster than hexstr.upper():\n        # 0.452ms vs. 0.652ms (translate vs. upper)\n        if sys.version_info[0] >= 3:\n            # Python 3\n            table = bytes(range_l(256)).upper()\n        else:\n            # Python 2\n            table = ''.join(chr(i).upper() for i in range_g(256))\n\n        # start address record if any\n        if self.start_addr and write_start_addr:\n            keys = dict_keys(self.start_addr)\n            keys.sort()\n            bin = array('B', asbytes('\\0'*9))\n            if keys == ['CS','IP']:\n                # Start Segment Address Record\n                bin[0] = 4      # reclen\n                bin[1] = 0      # offset msb\n                bin[2] = 0      # offset lsb\n                bin[3] = 3      # rectyp\n                cs = self.start_addr['CS']\n                bin[4] = (cs >> 8) & 0x0FF\n                bin[5] = cs & 0x0FF\n                ip = self.start_addr['IP']\n                bin[6] = (ip >> 8) & 0x0FF\n                bin[7] = ip & 0x0FF\n                bin[8] = (-sum(bin)) & 0x0FF    # chksum\n                fwrite(':' +\n                       asstr(hexlify(array_tobytes(bin)).translate(table)) +\n                       eol)\n            elif keys == ['EIP']:\n                # Start Linear Address Record\n                bin[0] = 4      # reclen\n                bin[1] = 0      # offset msb\n                bin[2] = 0      # offset lsb\n                bin[3] = 5      # rectyp\n                eip = self.start_addr['EIP']\n                bin[4] = (eip >> 24) & 0x0FF\n                bin[5] = (eip >> 16) & 0x0FF\n                bin[6] = (eip >> 8) & 0x0FF\n                bin[7] = eip & 0x0FF\n                bin[8] = (-sum(bin)) & 0x0FF    # chksum\n                fwrite(':' +\n                       asstr(hexlify(array_tobytes(bin)).translate(table)) +\n                       eol)\n            else:\n                if fclose:\n                    fclose()\n                raise InvalidStartAddressValueError(start_addr=self.start_addr)\n\n        # data\n        addresses = dict_keys(self._buf)\n        addresses.sort()\n        addr_len = len(addresses)\n        if addr_len:\n            minaddr = addresses[0]\n            maxaddr = addresses[-1]\n\n            if maxaddr > 65535:\n                need_offset_record = True\n            else:\n                need_offset_record = False\n            high_ofs = 0\n\n            cur_addr = minaddr\n            cur_ix = 0\n\n            while cur_addr <= maxaddr:\n                if need_offset_record:\n                    bin = array('B', asbytes('\\0'*7))\n                    bin[0] = 2      # reclen\n                    bin[1] = 0      # offset msb\n                    bin[2] = 0      # offset lsb\n                    bin[3] = 4      # rectyp\n                    high_ofs = int(cur_addr>>16)\n                    b = divmod(high_ofs, 256)\n                    bin[4] = b[0]   # msb of high_ofs\n                    bin[5] = b[1]   # lsb of high_ofs\n                    bin[6] = (-sum(bin)) & 0x0FF    # chksum\n                    fwrite(':' +\n                           asstr(hexlify(array_tobytes(bin)).translate(table)) +\n                           eol)\n\n                while True:\n                    # produce one record\n                    low_addr = cur_addr & 0x0FFFF\n                    # chain_len off by 1\n                    chain_len = min(byte_count-1, 65535-low_addr, maxaddr-cur_addr)\n\n                    # search continuous chain\n                    stop_addr = cur_addr + chain_len\n                    if chain_len:\n                        ix = bisect_right(addresses, stop_addr,\n                                          cur_ix,\n                                          min(cur_ix+chain_len+1, addr_len))\n                        chain_len = ix - cur_ix     # real chain_len\n                        # there could be small holes in the chain\n                        # but we will catch them by try-except later\n                        # so for big continuous files we will work\n                        # at maximum possible speed\n                    else:\n                        chain_len = 1               # real chain_len\n\n                    bin = array('B', asbytes('\\0'*(5+chain_len)))\n                    b = divmod(low_addr, 256)\n                    bin[1] = b[0]   # msb of low_addr\n                    bin[2] = b[1]   # lsb of low_addr\n                    bin[3] = 0          # rectype\n                    try:    # if there is small holes we'll catch them\n                        for i in range_g(chain_len):\n                            bin[4+i] = self._buf[cur_addr+i]\n                    except KeyError:\n                        # we catch a hole so we should shrink the chain\n                        chain_len = i\n                        bin = bin[:5+i]\n                    bin[0] = chain_len\n                    bin[4+chain_len] = (-sum(bin)) & 0x0FF    # chksum\n                    fwrite(':' +\n                           asstr(hexlify(array_tobytes(bin)).translate(table)) +\n                           eol)\n\n                    # adjust cur_addr/cur_ix\n                    cur_ix += chain_len\n                    if cur_ix < addr_len:\n                        cur_addr = addresses[cur_ix]\n                    else:\n                        cur_addr = maxaddr + 1\n                        break\n                    high_addr = int(cur_addr>>16)\n                    if high_addr > high_ofs:\n                        break\n\n        # end-of-file record\n        fwrite(\":00000001FF\"+eol)\n        if fclose:\n            fclose()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tofile(self, fobj, format):\n        if format == 'hex':\n            self.write_hex_file(fobj)\n        elif format == 'bin':\n            self.tobinfile(fobj)\n        else:\n            raise ValueError('format should be either \"hex\" or \"bin\";'\n                ' got %r instead' % format)", "response": "Write data to hex or bin file. Preferred method over tohex or tobin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gets(self, addr, length):\n        a = array('B', asbytes('\\0'*length))\n        try:\n            for i in range_g(length):\n                a[i] = self._buf[addr+i]\n        except KeyError:\n            raise NotEnoughDataError(address=addr, length=length)\n        return array_tobytes(a)", "response": "Get string of bytes from given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef puts(self, addr, s):\n        a = array('B', asbytes(s))\n        for i in range_g(len(a)):\n            self._buf[addr+i] = a[i]", "response": "Put string of bytes at given address. Will overwrite any previous previous\n        entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting zero - terminated bytes string from given address. Will raise NotEnoughDataError exception if a hole is encountered before a 0.", "response": "def getsz(self, addr):\n        \"\"\"Get zero-terminated bytes string from given address. Will raise\n        NotEnoughDataError exception if a hole is encountered before a 0.\n        \"\"\"\n        i = 0\n        try:\n            while True:\n                if self._buf[addr+i] == 0:\n                    break\n                i += 1\n        except KeyError:\n            raise NotEnoughDataError(msg=('Bad access at 0x%X: '\n                'not enough data to read zero-terminated string') % addr)\n        return self.gets(addr, i)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput bytes string in object at addr and append terminating zero at end.", "response": "def putsz(self, addr, s):\n        \"\"\"Put bytes string in object at addr and append terminating zero at end.\"\"\"\n        self.puts(addr, s)\n        self._buf[addr+len(s)] = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps the contents of the object to a file object or to stdout if None.", "response": "def dump(self, tofile=None, width=16, withpadding=False):\n        \"\"\"Dump object content to specified file object or to stdout if None.\n        Format is a hexdump with some header information at the beginning,\n        addresses on the left, and data on right.\n\n        @param  tofile          file-like object to dump to\n        @param  width           number of bytes per line (i.e. columns)\n        @param  withpadding     print padding character instead of '--'\n        @raise  ValueError      if width is not a positive integer\n        \"\"\"\n\n        if not isinstance(width,int) or width < 1:\n            raise ValueError('width must be a positive integer.')\n        # The integer can be of float type - does not work with bit operations\n        width = int(width)\n        if tofile is None:\n            tofile = sys.stdout\n\n        # start addr possibly\n        if self.start_addr is not None:\n            cs = self.start_addr.get('CS')\n            ip = self.start_addr.get('IP')\n            eip = self.start_addr.get('EIP')\n            if eip is not None and cs is None and ip is None:\n                tofile.write('EIP = 0x%08X\\n' % eip)\n            elif eip is None and cs is not None and ip is not None:\n                tofile.write('CS = 0x%04X, IP = 0x%04X\\n' % (cs, ip))\n            else:\n                tofile.write('start_addr = %r\\n' % start_addr)\n        # actual data\n        addresses = dict_keys(self._buf)\n        if addresses:\n            addresses.sort()\n            minaddr = addresses[0]\n            maxaddr = addresses[-1]\n            startaddr = (minaddr // width) * width\n            endaddr = ((maxaddr // width) + 1) * width\n            maxdigits = max(len(hex(endaddr)) - 2, 4)   # Less 2 to exclude '0x'\n            templa = '%%0%dX' % maxdigits\n            rangewidth = range_l(width)\n            if withpadding:\n                pad = self.padding\n            else:\n                pad = None\n            for i in range_g(startaddr, endaddr, width):\n                tofile.write(templa % i)\n                tofile.write(' ')\n                s = []\n                for j in rangewidth:\n                    x = self._buf.get(i+j, pad)\n                    if x is not None:\n                        tofile.write(' %02X' % x)\n                        if 32 <= x < 127:   # GNU less does not like 0x7F (128 decimal) so we'd better show it as dot\n                            s.append(chr(x))\n                        else:\n                            s.append('.')\n                    else:\n                        tofile.write(' --')\n                        s.append(' ')\n                tofile.write('  |' + ''.join(s) + '|\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge content of other IntelHex object into current IntelHex object.", "response": "def merge(self, other, overlap='error'):\n        \"\"\"Merge content of other IntelHex object into current object (self).\n        @param  other   other IntelHex object.\n        @param  overlap action on overlap of data or starting addr:\n                        - error: raising OverlapError;\n                        - ignore: ignore other data and keep current data\n                                  in overlapping region;\n                        - replace: replace data with other data\n                                  in overlapping region.\n\n        @raise  TypeError       if other is not instance of IntelHex\n        @raise  ValueError      if other is the same object as self\n                                (it can't merge itself)\n        @raise  ValueError      if overlap argument has incorrect value\n        @raise  AddressOverlapError    on overlapped data\n        \"\"\"\n        # check args\n        if not isinstance(other, IntelHex):\n            raise TypeError('other should be IntelHex object')\n        if other is self:\n            raise ValueError(\"Can't merge itself\")\n        if overlap not in ('error', 'ignore', 'replace'):\n            raise ValueError(\"overlap argument should be either \"\n                \"'error', 'ignore' or 'replace'\")\n        # merge data\n        this_buf = self._buf\n        other_buf = other._buf\n        for i in other_buf:\n            if i in this_buf:\n                if overlap == 'error':\n                    raise AddressOverlapError(\n                        'Data overlapped at address 0x%X' % i)\n                elif overlap == 'ignore':\n                    continue\n            this_buf[i] = other_buf[i]\n        # merge start_addr\n        if self.start_addr != other.start_addr:\n            if self.start_addr is None:     # set start addr from other\n                self.start_addr = other.start_addr\n            elif other.start_addr is None:  # keep existing start addr\n                pass\n            else:                           # conflict\n                if overlap == 'error':\n                    raise AddressOverlapError(\n                        'Starting addresses are different')\n                elif overlap == 'replace':\n                    self.start_addr = other.start_addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of ordered tuple objects representing contiguous occupied data addresses.", "response": "def segments(self):\n        \"\"\"Return a list of ordered tuple objects, representing contiguous occupied data addresses.\n        Each tuple has a length of two and follows the semantics of the range and xrange objects.\n        The second entry of the tuple is always an integer greater than the first entry.\n        \"\"\"\n        addresses = self.addresses()\n        if not addresses:\n            return []\n        elif len(addresses) == 1:\n            return([(addresses[0], addresses[0]+1)])\n        adjacent_differences = [(b - a) for (a, b) in zip(addresses[:-1], addresses[1:])]\n        breaks = [i for (i, x) in enumerate(adjacent_differences) if x > 1]\n        endings = [addresses[b] for b in breaks]\n        endings.append(addresses[-1])\n        beginings = [addresses[b+1] for b in breaks]\n        beginings.insert(0, addresses[0])\n        return [(a, b+1) for (a, b) in zip(beginings, endings)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_memory_size(self):\n        n = sys.getsizeof(self)\n        n += sys.getsizeof(self.padding)\n        n += total_size(self.start_addr)\n        n += total_size(self._buf)\n        n += sys.getsizeof(self._offset)\n        return n", "response": "Returns the approximate memory footprint for data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tobinarray(self, start=None, end=None, size=None):\n        '''Convert this object to binary form as array (of 2-bytes word data).\n        If start and end unspecified, they will be inferred from the data.\n        @param  start   start address of output data.\n        @param  end     end address of output data (inclusive).\n        @param  size    size of the block (number of words),\n                        used with start or end parameter.\n        @return         array of unsigned short (uint16_t) data.\n        '''\n        bin = array('H')\n\n        if self._buf == {} and None in (start, end):\n            return bin\n\n        if size is not None and size <= 0:\n            raise ValueError(\"tobinarray: wrong value for size\")\n\n        start, end = self._get_start_end(start, end, size)\n\n        for addr in range_g(start, end+1):\n            bin.append(self[addr])\n\n        return bin", "response": "Convert this object to binary form as array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _from_bytes(bytes):\n        assert len(bytes) >= 4\n        # calculate checksum\n        s = (-sum(bytes)) & 0x0FF\n        bin = array('B', bytes + [s])\n        return ':' + asstr(hexlify(array_tobytes(bin))).upper()", "response": "Takes a list of bytes computes the checksum and outputs the entire\n        record as a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data(offset, bytes):\n        assert 0 <= offset < 65536\n        assert 0 < len(bytes) < 256\n        b = [len(bytes), (offset>>8)&0x0FF, offset&0x0FF, 0x00] + bytes\n        return Record._from_bytes(b)", "response": "Return a data record. This constructs the full record including the length information the checksum and the offset of the first byte."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_segment_address(cs, ip):\n        b = [4, 0, 0, 0x03, (cs>>8)&0x0FF, cs&0x0FF,\n             (ip>>8)&0x0FF, ip&0x0FF]\n        return Record._from_bytes(b)", "response": "Return Start Segment Address Record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn Start Linear Address Record.", "response": "def start_linear_address(eip):\n        \"\"\"Return Start Linear Address Record.\n        @param  eip     32-bit linear address for the EIP register.\n\n        @return         String representation of Intel Hex SLA record.\n        \"\"\"\n        b = [4, 0, 0, 0x05, (eip>>24)&0x0FF, (eip>>16)&0x0FF,\n             (eip>>8)&0x0FF, eip&0x0FF]\n        return Record._from_bytes(b)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying module_settings. json and add release and build information", "response": "def create_release_settings_action(target, source, env):\n    \"\"\"Copy module_settings.json and add release and build information\n    \"\"\"\n\n    with open(str(source[0]), \"r\") as fileobj:\n        settings = json.load(fileobj)\n\n    settings['release'] = True\n    settings['release_date'] = datetime.datetime.utcnow().isoformat()\n    settings['dependency_versions'] = {}\n\n    #Also insert the versions of every dependency that we used to build this component\n    for dep in env['TILE'].dependencies:\n        tile = IOTile(os.path.join('build', 'deps', dep['unique_id']))\n\n        settings['dependency_versions'][dep['unique_id']] = str(tile.parsed_version)\n\n    with open(str(target[0]), \"w\") as fileobj:\n        json.dump(settings, fileobj, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_include_dirs(tile):\n\n    if 'products' not in tile.settings:\n        return\n\n    incdirs = tile.settings['products'].get('include_directories', [])\n    incdirs = map(lambda x: os.path.normpath(utilities.join_path(x)), incdirs)\n    incdirs = sorted(incdirs, key=lambda x: len(x))\n\n    seen_dirs = pygtrie.PrefixSet(factory=lambda: pygtrie.StringTrie(separator=os.path.sep))\n\n    env = Environment(tools=[])\n\n    # all include directories are relative to the firmware/src directory\n    outputbase = os.path.join('build', 'output', 'include')\n    inputbase = os.path.join('firmware', 'src')\n    for inc in incdirs:\n        if inc in seen_dirs:\n            continue\n\n        relinput = os.path.join(inputbase, inc)\n        finaldir = os.path.join(outputbase, inc)\n\n        for folder, subdirs, filenames in os.walk(relinput):\n            relfolder = os.path.relpath(folder, relinput)\n            for filename in filenames:\n                if filename.endswith(\".h\"):\n                    infile = os.path.join(folder, filename)\n                    outfile = os.path.join(finaldir, relfolder, filename)\n                    env.Command([outfile], [infile], Copy(\"$TARGET\", \"$SOURCE\"))\n\n        seen_dirs.add(inc)", "response": "Copy all include directories that this tile defines as products in build/output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying all extra files listed in copy_files and copy_products section.", "response": "def copy_extra_files(tile):\n    \"\"\"Copy all files listed in a copy_files and copy_products section.\n\n    Files listed in copy_files will be copied from the specified location\n    in the current component to the specified path under the output\n    folder.\n\n    Files listed in copy_products will be looked up with a ProductResolver\n    and copied copied to the specified path in the output folder.  There\n    is not currently a way to specify what type of product is being resolved.\n    The `short_name` given must be unique across all products from this\n    component and its direct dependencies.\n    \"\"\"\n\n    env = Environment(tools=[])\n    outputbase = os.path.join('build', 'output')\n\n    for src, dest in tile.settings.get('copy_files', {}).items():\n        outputfile = os.path.join(outputbase, dest)\n        env.Command([outputfile], [src], Copy(\"$TARGET\", \"$SOURCE\"))\n\n    resolver = ProductResolver.Create()\n    for src, dest in tile.settings.get('copy_products', {}).items():\n        prod = resolver.find_unique(None, src)\n        outputfile = os.path.join(outputbase, dest)\n\n        env.Command([outputfile], [prod.full_path], Copy(\"$TARGET\", \"$SOURCE\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy all documentation from dependencies into build output folder", "response": "def copy_dependency_docs(tile):\n    \"\"\"Copy all documentation from dependencies into build/output/doc folder\"\"\"\n\n    env = Environment(tools=[])\n\n    outputbase = os.path.join('build', 'output', 'doc')\n    depbase = os.path.join('build', 'deps')\n    for dep in tile.dependencies:\n        depdir = os.path.join(depbase, dep['unique_id'], 'doc', dep['unique_id'])\n        outputdir = os.path.join(outputbase, dep['unique_id'])\n\n        if os.path.exists(depdir):\n            env.Command([outputdir], [depdir], Copy(\"$TARGET\", \"$SOURCE\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_dependency_images(tile):\n\n    env = Environment(tools=[])\n\n    outputbase = os.path.join('build', 'output')\n    depbase = os.path.join('build', 'deps')\n    for dep in tile.dependencies:\n        depdir = os.path.join(depbase, dep['unique_id'])\n        outputdir = os.path.join(outputbase)\n\n        deptile = IOTile(depdir)\n\n        for image in deptile.find_products('firmware_image'):\n            name = os.path.basename(image)\n            input_path = os.path.join(depdir, name)\n            output_path = os.path.join(outputdir, name)\n            env.Command([output_path], [input_path], Copy(\"$TARGET\", \"$SOURCE\"))", "response": "Copy all documentation from dependencies into build/output folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Builders and construction variables for masm to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for masm to an Environment.\"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in ASSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.ASAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ASAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n        shared_obj.add_emitter(suffix, SCons.Defaults.SharedObjectEmitter)\n\n    for suffix in ASPPSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.ASPPAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ASPPAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n        shared_obj.add_emitter(suffix, SCons.Defaults.SharedObjectEmitter)\n\n    env['AS']        = 'ml'\n    env['ASFLAGS']   = SCons.Util.CLVar('/nologo')\n    env['ASPPFLAGS'] = '$ASFLAGS'\n    env['ASCOM']     = '$AS $ASFLAGS /c /Fo$TARGET $SOURCES'\n    env['ASPPCOM']   = '$CC $ASPPFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS /c /Fo$TARGET $SOURCES'\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning median value for the list of values for processing.", "response": "def median(values):\n    \"\"\"Return median value for the list of values.\n    @param  values:     list of values for processing.\n    @return:            median value.\n    \"\"\"\n    values.sort()\n    n = int(len(values) / 2)\n    return values[n]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns time coefficient relative to base numbers.", "response": "def time_coef(tc, nc, tb, nb):\n    \"\"\"Return time coefficient relative to base numbers.\n    @param  tc:     current test time\n    @param  nc:     current test data size\n    @param  tb:     base test time\n    @param  nb:     base test data size\n    @return:        time coef.\n    \"\"\"\n    tc = float(tc)\n    nc = float(nc)\n    tb = float(tb)\n    nb = float(nb)\n    q = (tc * nb) / (tb * nc)\n    return q"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(argv=None):\n    import getopt\n\n    # default values\n    test_read = None\n    test_write = None\n    n = 3       # number of repeat\n\n    if argv is None:\n        argv = sys.argv[1:]\n\n    try:\n        opts, args = getopt.getopt(argv, 'hn:rw', [])\n\n        for o,a in opts:\n            if o == '-h':\n                print(HELP)\n                return 0\n            elif o == '-n':\n                n = int(a)\n            elif o == '-r':\n                test_read = True\n            elif o == '-w':\n                test_write = True\n\n        if args:\n            raise getopt.GetoptError('Arguments are not used.')\n    except getopt.GetoptError:\n        msg = sys.exc_info()[1]     # current exception\n        txt = str(msg)\n        print(txt)\n        return 1\n\n    if (test_read, test_write) == (None, None):\n        test_read = test_write = True\n\n    m = Measure(n, test_read, test_write)\n    m.measure_all()\n    m.print_report()\n\n    return 0", "response": "Main function to run benchmarks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measure_one(self, data):\n        _unused, hexstr, ih = data\n        tread, twrite = 0.0, 0.0\n        if self.read:\n            tread = run_readtest_N_times(intelhex.IntelHex, hexstr, self.n)[0]\n        if self.write:\n            twrite = run_writetest_N_times(ih.write_hex_file, self.n)[0]\n        return tread, twrite", "response": "Do measuring of read and write operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_key(cls, device_id):\n\n        var_name = \"USER_KEY_{0:08X}\".format(device_id)\n\n        if var_name not in os.environ:\n            raise NotFoundError(\"No user key could be found for devices\", device_id=device_id,\n                                expected_variable_name=var_name)\n\n        key_var = os.environ[var_name]\n        if len(key_var) != 64:\n            raise NotFoundError(\"User key in variable is not the correct length, should be 64 hex characters\",\n                                device_id=device_id, key_value=key_var)\n\n        try:\n            key = binascii.unhexlify(key_var)\n        except ValueError:\n            raise NotFoundError(\"User key in variable could not be decoded from hex\", device_id=device_id,\n                                key_value=key_var)\n\n        if len(key) != 32:\n            raise NotFoundError(\"User key in variable is not the correct length, should be 64 hex characters\",\n                                device_id=device_id, key_value=key_var)\n\n        return key", "response": "Attempt to get a user key from an environment variable"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsign a buffer of report data on behalf of a device.", "response": "def sign_report(self, device_id, root, data, **kwargs):\n        \"\"\"Sign a buffer of report data on behalf of a device.\n\n        Args:\n            device_id (int): The id of the device that we should encrypt for\n            root (int): The root key type that should be used to generate the report\n            data (bytearray): The data that we should sign\n            **kwargs: There are additional specific keyword args that are required\n                depending on the root key used.  Typically, you must specify\n                - report_id (int): The report id\n                - sent_timestamp (int): The sent timestamp of the report\n\n                These two bits of information are used to construct the per report\n                signing and encryption key from the specific root key type.\n\n        Returns:\n            dict: The signature and any associated metadata about the signature.\n                The signature itself must always be a bytearray stored under the\n                'signature' key, however additional keys may be present depending\n                on the signature method used.\n\n        Raises:\n            NotFoundError: If the auth provider is not able to sign the data.\n        \"\"\"\n\n        report_key = self._verify_derive_key(device_id, root, **kwargs)\n\n        # We sign the SHA256 hash of the message\n        message_hash = hashlib.sha256(data).digest()\n        hmac_calc = hmac.new(report_key, message_hash, hashlib.sha256)\n        result = bytearray(hmac_calc.digest())\n\n        return {'signature': result, 'root_key': root}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify a buffer of report data on behalf of a device.", "response": "def verify_report(self, device_id, root, data, signature, **kwargs):\n        \"\"\"Verify a buffer of report data on behalf of a device.\n\n        Args:\n            device_id (int): The id of the device that we should encrypt for\n            root (int): The root key type that should be used to generate the report\n            data (bytearray): The data that we should verify\n            signature (bytearray): The signature attached to data that we should verify\n            **kwargs: There are additional specific keyword args that are required\n                depending on the root key used.  Typically, you must specify\n                - report_id (int): The report id\n                - sent_timestamp (int): The sent timestamp of the report\n\n                These two bits of information are used to construct the per report\n                signing and encryption key from the specific root key type.\n\n        Returns:\n            dict: The result of the verification process must always be a bool under the\n                'verified' key, however additional keys may be present depending on the\n                signature method used.\n\n        Raises:\n            NotFoundError: If the auth provider is not able to verify the data due to\n                an error.  If the data is simply not valid, then the function returns\n                normally.\n        \"\"\"\n\n        report_key = self._verify_derive_key(device_id, root, **kwargs)\n\n        message_hash = hashlib.sha256(data).digest()\n        hmac_calc = hmac.new(report_key, message_hash, hashlib.sha256)\n        result = bytearray(hmac_calc.digest())\n\n        if len(signature) == 0:\n            verified = False\n        elif len(signature) > len(result):\n            verified = False\n        elif len(signature) < len(result):\n            trunc_result = result[:len(signature)]\n            verified = hmac.compare_digest(signature, trunc_result)\n        else:\n            verified = hmac.compare_digest(signature, result)\n\n        return {'verified': verified, 'bit_length': 8*len(signature)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt_report(self, device_id, root, data, **kwargs):\n\n        report_key = self._verify_derive_key(device_id, root, **kwargs)\n\n        try:\n            from Crypto.Cipher import AES\n            import Crypto.Util.Counter\n        except ImportError:\n            raise NotFoundError\n\n        ctr = Crypto.Util.Counter.new(128)\n\n        # We use AES-128 for encryption\n        encryptor = AES.new(bytes(report_key[:16]), AES.MODE_CTR, counter=ctr)\n\n        decrypted = encryptor.decrypt(bytes(data))\n        return {'data': decrypted}", "response": "Decrypt a buffer of report data on behalf of a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencrypts a buffer of report data on behalf of a device.", "response": "def encrypt_report(self, device_id, root, data, **kwargs):\n        \"\"\"Encrypt a buffer of report data on behalf of a device.\n\n        Args:\n            device_id (int): The id of the device that we should encrypt for\n            root (int): The root key type that should be used to generate the report\n            data (bytearray): The data that we should decrypt\n            **kwargs: There are additional specific keyword args that are required\n                depending on the root key used.  Typically, you must specify\n                - report_id (int): The report id\n                - sent_timestamp (int): The sent timestamp of the report\n\n                These two bits of information are used to construct the per report\n                signing and encryption key from the specific root key type.\n\n        Returns:\n            dict: The encrypted data and any associated metadata about the data.\n                The data itself must always be a bytearray stored under the 'data'\n                key, however additional keys may be present depending on the encryption method\n                used.\n\n        Raises:\n            NotFoundError: If the auth provider is not able to decrypt the data.\n        \"\"\"\n\n        report_key = self._verify_derive_key(device_id, root, **kwargs)\n\n        try:\n            from Crypto.Cipher import AES\n            import Crypto.Util.Counter\n        except ImportError:\n            raise NotFoundError\n\n        # We use AES-128 for encryption\n        ctr = Crypto.Util.Counter.new(128)\n        encryptor = AES.new(bytes(report_key[:16]), AES.MODE_CTR, counter=ctr)\n\n        encrypted = encryptor.encrypt(bytes(data))\n        return {'data': encrypted}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join_path(path):\n\n    if isinstance(path, str):\n        return path\n\n    return os.path.join(*path)", "response": "Join a list of paths into a single string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a list of directives to pass to the compiler.", "response": "def build_defines(defines):\n    \"\"\"Build a list of `-D` directives to pass to the compiler.\n\n    This will drop any definitions whose value is None so that\n    you can get rid of a define from another architecture by\n    setting its value to null in the `module_settings.json`.\n    \"\"\"\n\n    return ['-D\"%s=%s\"' % (x, str(y)) for x, y in defines.items() if y is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect_async(self, connection_id, connection_string, callback):\n\n        topics = MQTTTopicValidator(self.prefix + 'devices/{}'.format(connection_string))\n        key = self._generate_key()\n        name = self.name\n\n        conn_message = {'type': 'command', 'operation': 'connect', 'key': key, 'client': name}\n        context = {'key': key, 'slug': connection_string, 'topics': topics}\n\n        self.conns.begin_connection(connection_id, connection_string, callback, context, self.get_config('default_timeout'))\n\n        self._bind_topics(topics)\n\n        try:\n            self.client.publish(topics.connect, conn_message)\n        except IOTileException:\n            self._unbind_topics(topics)\n            self.conns.finish_connection(connection_id, False, 'Failed to send connection message')", "response": "Connect to a device by its connection_string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _open_interface(self, conn_id, iface, callback):\n\n        try:\n            context = self.conns.get_context(conn_id)\n        except ArgumentError:\n            callback(conn_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self.conns.begin_operation(conn_id, 'open_interface', callback, self.get_config('default_timeout'))\n\n        topics = context['topics']\n\n        open_iface_message = {'key': context['key'], 'type': 'command', 'operation': 'open_interface', 'client': self.name, 'interface': iface}\n        self.client.publish(topics.action, open_iface_message)", "response": "Open an interface on this device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_sync(self):\n\n        conn_ids = self.conns.get_connections()\n\n        # If we have any open connections, try to close them here before shutting down\n        for conn in list(conn_ids):\n            try:\n                self.disconnect_sync(conn)\n            except HardwareError:\n                pass\n\n        self.client.disconnect()\n        self.conns.stop()", "response": "Synchronously stop this adapter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprobe for visible devices connected to this DeviceAdapter.", "response": "def probe_async(self, callback):\n        \"\"\"Probe for visible devices connected to this DeviceAdapter.\n\n        Args:\n            callback (callable): A callback for when the probe operation has completed.\n                callback should have signature callback(adapter_id, success, failure_reason) where:\n                    success: bool\n                    failure_reason: None if success is True, otherwise a reason for why we could not probe\n        \"\"\"\n\n        topics = MQTTTopicValidator(self.prefix)\n        self.client.publish(topics.probe, {'type': 'command', 'operation': 'probe', 'client': self.name})\n        callback(self.id, True, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef periodic_callback(self):\n\n        while True:\n            try:\n                action = self._deferred.get(False)\n                action()\n            except queue.Empty:\n                break\n            except Exception:\n                self._logger.exception('Exception in periodic callback')", "response": "Periodically help maintain adapter internal state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubscribes to all the topics we need to communication with this device.", "response": "def _bind_topics(self, topics):\n        \"\"\"Subscribe to all the topics we need to communication with this device\n\n        Args:\n            topics (MQTTTopicValidator): The topic validator for this device that\n                we are connecting to.\n        \"\"\"\n\n        # FIXME: Allow for these subscriptions to fail and clean up the previous ones\n        # so that this function is atomic\n\n        self.client.subscribe(topics.status, self._on_status_message)\n        self.client.subscribe(topics.tracing, self._on_trace)\n        self.client.subscribe(topics.streaming, self._on_report)\n        self.client.subscribe(topics.response, self._on_response_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _unbind_topics(self, topics):\n\n        self.client.unsubscribe(topics.status)\n        self.client.unsubscribe(topics.tracing)\n        self.client.unsubscribe(topics.streaming)\n        self.client.unsubscribe(topics.response)", "response": "Unsubscribe to all of the topics we need for communication with the device that we have connected to."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_connection(self, topic):\n\n        parts = topic.split('/')\n        if len(parts) < 3:\n            return None\n\n        slug = parts[-3]\n        return slug", "response": "Attempt to find a connection id corresponding with a topic"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _on_report(self, sequence, topic, message):\n\n        try:\n            conn_key = self._find_connection(topic)\n            conn_id = self.conns.get_connection_id(conn_key)\n        except ArgumentError:\n            self._logger.warn(\"Dropping report message that does not correspond with a known connection, topic=%s\", topic)\n            return\n\n        try:\n            rep_msg = messages.ReportNotification.verify(message)\n\n            serialized_report = {}\n            serialized_report['report_format'] = rep_msg['report_format']\n            serialized_report['encoded_report'] = rep_msg['report']\n            serialized_report['received_time'] = datetime.datetime.strptime(rep_msg['received_time'].encode().decode(), \"%Y%m%dT%H:%M:%S.%fZ\")\n\n            report = self.report_parser.deserialize_report(serialized_report)\n            self._trigger_callback('on_report', conn_id, report)\n        except Exception:\n            self._logger.exception(\"Error processing report conn_id=%d\", conn_id)", "response": "Process a report received from a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_trace(self, sequence, topic, message):\n\n        try:\n            conn_key = self._find_connection(topic)\n            conn_id = self.conns.get_connection_id(conn_key)\n        except ArgumentError:\n            self._logger.warn(\"Dropping trace message that does not correspond with a known connection, topic=%s\", topic)\n            return\n\n        try:\n            tracing = messages.TracingNotification.verify(message)\n            self._trigger_callback('on_trace', conn_id, tracing['trace'])\n        except Exception:\n            self._logger.exception(\"Error processing trace conn_id=%d\", conn_id)", "response": "Process a trace received from a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a status message received from the broker", "response": "def _on_status_message(self, sequence, topic, message):\n        \"\"\"Process a status message received\n\n        Args:\n            sequence (int): The sequence number of the packet received\n            topic (string): The topic this message was received on\n            message (dict): The message itself\n        \"\"\"\n\n        self._logger.debug(\"Received message on (topic=%s): %s\" % (topic, message))\n\n        try:\n            conn_key = self._find_connection(topic)\n        except ArgumentError:\n            self._logger.warn(\"Dropping message that does not correspond with a known connection, message=%s\", message)\n            return\n\n        if messages.ConnectionResponse.matches(message):\n            if self.name != message['client']:\n                self._logger.debug(\"Connection response received for a different client, client=%s, name=%s\", message['client'], self.name)\n                return\n\n            self.conns.finish_connection(conn_key, message['success'], message.get('failure_reason', None))\n        else:\n            self._logger.warn(\"Dropping message that did not correspond with a known schema, message=%s\", message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a response message received from the broker.", "response": "def _on_response_message(self, sequence, topic, message):\n        \"\"\"Process a response message received\n\n        Args:\n            sequence (int): The sequence number of the packet received\n            topic (string): The topic this message was received on\n            message (dict): The message itself\n        \"\"\"\n\n        try:\n            conn_key = self._find_connection(topic)\n            context = self.conns.get_context(conn_key)\n        except ArgumentError:\n            self._logger.warn(\"Dropping message that does not correspond with a known connection, message=%s\", message)\n            return\n\n        if 'client' in message and message['client'] != self.name:\n            self._logger.debug(\"Dropping message that is for another client %s, we are %s\", message['client'], self.name)\n\n        if messages.DisconnectionResponse.matches(message):\n            self.conns.finish_disconnection(conn_key, message['success'], message.get('failure_reason', None))\n        elif messages.OpenInterfaceResponse.matches(message):\n            self.conns.finish_operation(conn_key, message['success'], message.get('failure_reason', None))\n        elif messages.RPCResponse.matches(message):\n            rpc_message = messages.RPCResponse.verify(message)\n            self.conns.finish_operation(conn_key, rpc_message['success'], rpc_message.get('failure_reason', None), rpc_message.get('status', None), rpc_message.get('payload', None))\n        elif messages.ProgressNotification.matches(message):\n            progress_callback = context.get('progress_callback', None)\n            if progress_callback is not None:\n                progress_callback(message['done_count'], message['total_count'])\n        elif messages.ScriptResponse.matches(message):\n            if 'progress_callback' in context:\n                del context['progress_callback']\n\n            self.conns.finish_operation(conn_key, message['success'], message.get('failure_reason', None))\n        elif messages.DisconnectionNotification.matches(message):\n            try:\n                conn_key = self._find_connection(topic)\n                conn_id = self.conns.get_connection_id(conn_key)\n            except ArgumentError:\n                self._logger.warn(\"Dropping disconnect notification that does not correspond with a known connection, topic=%s\", topic)\n                return\n\n            self.conns.unexpected_disconnect(conn_key)\n            self._trigger_callback('on_disconnect', self.id, conn_id)\n        else:\n            self._logger.warn(\"Invalid response message received, message=%s\", message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates command line argument parser.", "response": "def build_args():\n    \"\"\"Create command line argument parser.\"\"\"\n\n    parser = argparse.ArgumentParser(description=u'Compile a sensor graph.')\n    parser.add_argument(u'sensor_graph', type=str, help=u\"the sensor graph file to load and run.\")\n    parser.add_argument(u'-f', u'--format', default=u\"nodes\", choices=[u'nodes', u'ast', u'snippet', u'ascii', u'config', u'script'], type=str, help=u\"the output format for the compiled result.\")\n    parser.add_argument(u'-o', u'--output', type=str, help=u\"the output file to save the results (defaults to stdout)\")\n    parser.add_argument(u'--disable-optimizer', action=\"store_true\", help=u\"disable the sensor graph optimizer completely\")\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_output(output, text=True, output_path=None):\n\n    if output_path is None and text is False:\n        print(\"ERROR: You must specify an output file using -o/--output for binary output formats\")\n        sys.exit(1)\n\n    if output_path is not None:\n        if text:\n            outfile = open(output_path, \"w\", encoding=\"utf-8\")\n        else:\n            outfile = open(output_path, \"wb\")\n    else:\n        outfile = sys.stdout\n\n    try:\n        if text and isinstance(output, bytes):\n            output = output.decode('utf-8')\n\n        outfile.write(output)\n    finally:\n        if outfile is not sys.stdout:\n            outfile.close()", "response": "Write binary or text output to a file or stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n\n    arg_parser = build_args()\n    args = arg_parser.parse_args()\n\n    model = DeviceModel()\n\n    parser = SensorGraphFileParser()\n    parser.parse_file(args.sensor_graph)\n\n    if args.format == u'ast':\n        write_output(parser.dump_tree(), True, args.output)\n        sys.exit(0)\n\n    parser.compile(model)\n\n    if not args.disable_optimizer:\n        opt = SensorGraphOptimizer()\n        opt.optimize(parser.sensor_graph, model=model)\n\n    if args.format == u'nodes':\n        output = u'\\n'.join(parser.sensor_graph.dump_nodes()) + u'\\n'\n        write_output(output, True, args.output)\n    else:\n        if args.format not in KNOWN_FORMATS:\n            print(\"Unknown output format: {}\".format(args.format))\n            sys.exit(1)\n\n        output_format = KNOWN_FORMATS[args.format]\n        output = output_format.format(parser.sensor_graph)\n\n        write_output(output, output_format.text, args.output)", "response": "Entry point for iotile - sgcompile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_external_components(typesys):\n\n    # Find all of the registered IOTile components and see if we need to add any type libraries for them\n    from iotile.core.dev.registry import ComponentRegistry\n\n    reg = ComponentRegistry()\n    modules = reg.list_components()\n\n    typelibs = reduce(lambda x, y: x+y, [reg.find_component(x).find_products('type_package') for x in modules], [])\n    for lib in typelibs:\n        if lib.endswith('.py'):\n            lib = lib[:-3]\n\n        typesys.load_external_types(lib)", "response": "Load all external types defined by iotile plugins."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreleases an IOTile component using release providers.", "response": "def release(component=\".\", cloud=False):\n    \"\"\"Release an IOTile component using release providers.\n\n    Releasing an IOTile component means packaging up the products of its build process and storing\n    them somewhere.  The module_settings.json file of the IOTile component should have a\n    \"release_steps\" key that lists the release providers that will be used to release the various\n    build products.  There are usually multiple release providers to, for example, send firmware\n    images somewhere for future download, post the documentation and upload python support wheels\n    to a PyPI index.\n    \"\"\"\n\n    comp = IOTile(component)\n    providers = _find_release_providers()\n\n    # If we were given a dev mode component that has been built, get its release mode version\n    if not comp.release and comp.release_date is not None:\n        comp = IOTile(comp.output_folder)\n\n    if not comp.release:\n        raise ArgumentError(\"Attempting to release a dev mode IOTile component that has not been built.\",\n                            suggestion='Use iotile build to build the component before releasing', component=comp)\n\n    if not comp.can_release:\n        raise ArgumentError(\"Attemping to release an IOTile component that does not \"\n                            \"specify release_steps and hence is not releasable\",\n                            suggestion=\"Update module_settings.json to include release_steps\", component=comp)\n\n    # A component can specify that it should only be releasable in a clean continuous integration/continuous deployment\n    # server.  If that's the case then do not allow `iotile release` to work unless the cloud parameter is set to\n    # indicate that we're in such a setting.\n    if comp.settings.get('cloud_release', False) and not cloud:\n        raise ArgumentError(\"Attempting to release an IOTile component locally when it specifies that it \"\n                            \"can only be released using a clean CI/CD server\",\n                            suggestion=\"Use iotile release --cloud if you are running in a CI/CD server\")\n\n    configured_provs = []\n\n    for step in comp.release_steps:\n        if step.provider not in providers:\n            raise DataError(\"Release step for component required unknown ReleaseProvider\",\n                            provider=step.provider, known_providers=providers.keys())\n\n        prov = providers[step.provider](comp, step.args)\n        configured_provs.append(prov)\n\n    # Attempt to stage releases for each provider and then release them all, rolling back if there is an error\n    for i, prov in enumerate(configured_provs):\n        try:\n            prov.stage()\n        except IOTileException as exc:\n            try:\n                # There was an error, roll back\n                for j in range(0, i):\n                    configured_provs[j].unstage()\n            except Exception as unstage_exc:\n                raise DirtyReleaseFailureError(\"Error staging release (COULD NOT ROLL BACK)\",\n                                               failed_step=i, original_exception=exc, operation='staging',\n                                               failed_unstage=j, unstage_exception=unstage_exc)\n\n            raise CleanReleaseFailureError(\"Error staging release (cleanly rolled back)\",\n                                           failed_step=i, original_exception=exc, operation='staging')\n        except Exception as exc:\n            raise DirtyReleaseFailureError(\"Error staging release due to unknown exception type \"\n                                           \"(DID NOT ATTEMPT ROLL BACK)\",\n                                           failed_step=i, original_exception=exc, operation='staging')\n\n    # Stage was successful, attempt to release\n    for i, prov in enumerate(configured_provs):\n        try:\n            prov.release()\n        except IOTileException as exc:\n            j = None\n            try:\n                # There was an error, roll back\n                for j in range(0, i):\n                    configured_provs[j].unrelease()\n            except Exception as unstage_exc:\n                raise DirtyReleaseFailureError(\"Error performing release (COULD NOT ROLL BACK)\",\n                                               failed_step=i, original_exception=exc, operation='release',\n                                               failed_unrelease=j, unrelease_exception=unstage_exc)\n\n            raise CleanReleaseFailureError(\"Error performing release (cleanly rolled back)\", failed_step=i,\n                                           original_exception=exc, operation='release')\n        except Exception as exc:\n            raise DirtyReleaseFailureError(\"Error performing release due to unknown exception type \"\n                                           \"(DID NOT ATTEMPT ROLL BACK)\", failed_step=i,\n                                           original_exception=exc, operation='release')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify(self, obj):\n\n        if len(self._options) == 0:\n            raise ValidationError(\"No options\", reason='no options given in options verifier, matching not possible',\n                                  object=obj)\n\n        exceptions = {}\n\n        for i, option in enumerate(self._options):\n            try:\n                obj = option.verify(obj)\n                return obj\n            except ValidationError as exc:\n                exceptions['option_%d' % (i+1)] = exc.params['reason']\n\n        raise ValidationError(\"Object did not match any of a set of options\",\n                              reason=\"object did not match any given option (first failure = '%s')\"\n                                     % exceptions['option_1'], **exceptions)", "response": "Verify that the object conforms to this verifier s schema."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_recipe_folder(self, recipe_folder, whitelist=None):\n\n        if whitelist is not None:\n            whitelist = set(whitelist)\n\n        if recipe_folder == '':\n            recipe_folder = '.'\n\n        for yaml_file in [x for x in os.listdir(recipe_folder) if x.endswith('.yaml')]:\n            if whitelist is not None and yaml_file not in whitelist:\n                continue\n\n            recipe = RecipeObject.FromFile(os.path.join(recipe_folder, yaml_file), self._recipe_actions, self._recipe_resources)\n            self._recipes[recipe.name] = recipe\n\n        for ship_file in [x for x in os.listdir(recipe_folder) if x.endswith('.ship')]:\n            if whitelist is not None and ship_file not in whitelist:\n                continue\n\n            recipe = RecipeObject.FromArchive(os.path.join(recipe_folder, ship_file), self._recipe_actions, self._recipe_resources)\n            self._recipes[recipe.name] = recipe", "response": "Add all recipes inside a folder to this RecipeManager with an optional whitelist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_recipe_actions(self, recipe_actions):\n        for action_name, action in recipe_actions:\n            self._recipe_actions[action_name] = action", "response": "Add additional valid recipe actions to RecipeManager\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a recipe by name.", "response": "def get_recipe(self, recipe_name):\n        \"\"\"Get a recipe by name.\n\n        Args:\n            recipe_name (str): The name of the recipe to fetch. Can be either the\n                yaml file name or the name of the recipe.\n        \"\"\"\n        if recipe_name.endswith('.yaml'):\n            recipe = self._recipes.get(RecipeObject.FromFile(recipe_name, self._recipe_actions, self._recipe_resources).name)\n        else:\n            recipe = self._recipes.get(recipe_name)\n        if recipe is None:\n            raise RecipeNotFoundError(\"Could not find recipe\", recipe_name=recipe_name, known_recipes=[x for x in self._recipes.keys()])\n\n        return recipe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_time_backwards(self):\n\n        now = time.time()\n\n        if now < self.start:\n            self.start = now\n            self.end = self.start + self.length", "response": "Make sure a clock reset didn t cause time to go backwards"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns an asynchronous command.", "response": "def command(self, cmd_name, callback, *args):\n        \"\"\"Run an asynchronous command.\n\n        Args:\n            cmd_name (int): The unique code for the command to execute.\n            callback (callable): The optional callback to run when the command finishes.\n                The signature should be callback(cmd_name, result, exception)\n            *args: Any arguments that are passed to the underlying command handler\n        \"\"\"\n        cmd = JLinkCommand(cmd_name, args, callback)\n        self._commands.put(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending an RPC to the device.", "response": "def _send_rpc(self, device_info, control_info, address, rpc_id, payload, poll_interval, timeout):\n        \"\"\"Write and trigger an RPC.\"\"\"\n\n        write_address, write_data = control_info.format_rpc(address, rpc_id, payload)\n        self._jlink.memory_write32(write_address, write_data)\n\n        self._trigger_rpc(device_info)\n\n        start = monotonic()\n        now = start\n\n        poll_address, poll_mask = control_info.poll_info()\n\n        while (now - start) < timeout:\n            time.sleep(poll_interval)\n            value, = self._jlink.memory_read8(poll_address, 1)\n\n            if value & poll_mask:\n                break\n\n            now = monotonic()\n\n        if (now - start) >= timeout:\n            raise HardwareError(\"Timeout waiting for RPC response\", timeout=timeout, poll_interval=poll_interval)\n\n        read_address, read_length = control_info.response_info()\n        read_data = self._read_memory(read_address, read_length, join=True)\n\n        return control_info.format_response(read_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_script(self, device_info, control_info, script, progress_callback):\n\n        for i in range(0, len(script), 20):\n            chunk = script[i:i+20]\n            self._send_rpc(device_info, control_info, 8, 0x2101, chunk, 0.001, 1.0)\n            if progress_callback is not None:\n                progress_callback(i + len(chunk), len(script))", "response": "Send a script to the device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntriggering an RPC in a device specific way.", "response": "def _trigger_rpc(self, device_info):\n        \"\"\"Trigger an RPC in a device specific way.\"\"\"\n\n        method = device_info.rpc_trigger\n        if isinstance(method, devices.RPCTriggerViaSWI):\n            self._jlink.memory_write32(method.register, [1 << method.bit])\n        else:\n            raise HardwareError(\"Unknown RPC trigger method\", method=method)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the control structure in RAM for this IOTile device.", "response": "def _find_control_structure(self, start_address, search_length):\n        \"\"\"Find the control structure in RAM for this device.\n\n        Returns:\n            ControlStructure: The decoded contents of the shared memory control structure\n                used for communication with this IOTile device.\n        \"\"\"\n\n        words = self._read_memory(start_address, search_length, chunk_size=4, join=False)\n        found_offset = None\n\n        for i, word in enumerate(words):\n            if word == ControlStructure.CONTROL_MAGIC_1:\n                if (len(words) - i) < 4:\n                    continue\n\n                if words[i + 1] == ControlStructure.CONTROL_MAGIC_2 and words[i + 2] == ControlStructure.CONTROL_MAGIC_3 and words[i + 3] == ControlStructure.CONTROL_MAGIC_4:\n                    found_offset = i\n                    break\n\n        if found_offset is None:\n            raise HardwareError(\"Could not find control structure magic value in search area\")\n\n        struct_info = words[found_offset + 4]\n        _version, _flags, length = struct.unpack(\"<BBH\", struct.pack(\"<L\", struct_info))\n\n        if length % 4 != 0:\n            raise HardwareError(\"Invalid control structure length that was not a multiple of 4\", length=length)\n\n        word_length = length // 4\n        control_data = struct.pack(\"<%dL\" % word_length, *words[found_offset:found_offset + word_length])\n\n        logger.info(\"Found control stucture at address 0x%08X, word_length=%d\", start_address + 4*found_offset, word_length)\n\n        return ControlStructure(start_address + 4*found_offset, control_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _verify_control_structure(self, device_info, control_info=None):\n\n        if control_info is None:\n            control_info = self._find_control_structure(device_info.ram_start, device_info.ram_size)\n\n        #FIXME: Actually reread the memory here to verify that the control structure is still valid\n        return control_info", "response": "Verify that a control structure is still valid or find one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, out_path):\n\n        out = {\n            'selectors': [str(x) for x in self.selectors],\n            'trace': [{'stream': str(DataStream.FromEncoded(x.stream)), 'time': x.raw_time, 'value': x.value, 'reading_id': x.reading_id} for x in self]\n        }\n\n        with open(out_path, \"wb\") as outfile:\n            json.dump(out, outfile, indent=4)", "response": "Save an ascii representation of this simulation trace."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a previously saved ascii representation of this simulation trace.", "response": "def FromFile(cls, in_path):\n        \"\"\"Load a previously saved ascii representation of this simulation trace.\n\n        Args:\n            in_path (str): The path of the input file that we should load.\n\n        Returns:\n            SimulationTrace: The loaded trace object.\n        \"\"\"\n\n        with open(in_path, \"rb\") as infile:\n            in_data = json.load(infile)\n\n        if not ('trace', 'selectors') in in_data:\n            raise ArgumentError(\"Invalid trace file format\", keys=in_data.keys(), expected=('trace', 'selectors'))\n\n        selectors = [DataStreamSelector.FromString(x) for x in in_data['selectors']]\n        readings = [IOTileReading(x['time'], DataStream.FromString(x['stream']).encode(), x['value'], reading_id=x['reading_id']) for x in in_data['trace']]\n\n        return SimulationTrace(readings, selectors=selectors)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _on_scan(_loop, adapter, _adapter_id, info, expiration_time):\n\n    info['validity_period'] = expiration_time\n    adapter.notify_event_nowait(info.get('connection_string'), 'device_seen', info)", "response": "Callback when a new device is seen."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_config(self, name, default=_MISSING):\n\n        value = self._adapter.get_config(name, default)\n        if value is _MISSING:\n            raise ArgumentError(\"Config value did not exist\", name=name)\n\n        return value", "response": "Get a config value from this adapter by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def start(self):\n\n        self._loop.add_task(self._periodic_loop, name=\"periodic task for %s\" % self._adapter.__class__.__name__,\n                            parent=self._task)\n\n        self._adapter.add_callback('on_scan', functools.partial(_on_scan, self._loop, self))\n        self._adapter.add_callback('on_report', functools.partial(_on_report, self._loop, self))\n        self._adapter.add_callback('on_trace', functools.partial(_on_trace, self._loop, self))\n        self._adapter.add_callback('on_disconnect', functools.partial(_on_disconnect, self._loop, self))", "response": "Start the device adapter."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops the underlying adapter.", "response": "async def stop(self, _task=None):\n        \"\"\"Stop the device adapter.\n\n        See :meth:`AbstractDeviceAdapter.stop`.\n        \"\"\"\n\n        self._logger.info(\"Stopping adapter wrapper\")\n\n        if self._task.stopped:\n            return\n\n        for task in self._task.subtasks:\n            await task.stop()\n\n        self._logger.debug(\"Stopping underlying adapter %s\", self._adapter.__class__.__name__)\n        await self._execute(self._adapter.stop_sync)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def connect(self, conn_id, connection_string):\n\n        self._logger.info(\"Inside connect, conn_id=%d, conn_string=%s\", conn_id, connection_string)\n\n        try:\n            self._setup_connection(conn_id, connection_string)\n\n            resp = await self._execute(self._adapter.connect_sync, conn_id, connection_string)\n            _raise_error(conn_id, 'connect', resp)\n        except:\n            self._teardown_connection(conn_id, force=True)\n            raise", "response": "Connect to a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisconnecting from a connected device.", "response": "async def disconnect(self, conn_id):\n        \"\"\"Disconnect from a connected device.\n\n        See :meth:`AbstractDeviceAdapter.disconnect`.\n        \"\"\"\n\n        resp = await self._execute(self._adapter.disconnect_sync, conn_id)\n        _raise_error(conn_id, 'disconnect', resp)\n        self._teardown_connection(conn_id, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen an interface on an IOTile device.", "response": "async def open_interface(self, conn_id, interface):\n        \"\"\"Open an interface on an IOTile device.\n\n        See :meth:`AbstractDeviceAdapter.open_interface`.\n        \"\"\"\n\n        resp = await self._execute(self._adapter.open_interface_sync, conn_id, interface)\n        _raise_error(conn_id, 'open_interface', resp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def close_interface(self, conn_id, interface):\n\n        resp = await self._execute(self._adapter.close_interface_sync, conn_id, interface)\n        _raise_error(conn_id, 'close_interface', resp)", "response": "Close an interface on this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprobes for devices connected to this adapter.", "response": "async def probe(self):\n        \"\"\"Probe for devices connected to this adapter.\n\n        See :meth:`AbstractDeviceAdapter.probe`.\n        \"\"\"\n\n        resp = await self._execute(self._adapter.probe_sync)\n        _raise_error(None, 'probe', resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def send_rpc(self, conn_id, address, rpc_id, payload, timeout):\n\n        resp = await self._execute(self._adapter.send_rpc_sync, conn_id, address, rpc_id, payload, timeout)\n        _raise_error(conn_id, 'send_rpc', resp)\n\n        status = resp.get('status')\n        payload = resp.get('payload')\n\n        # This will raise an exception if needed based on status\n        return unpack_rpc_response(status, payload, rpc_id, address)", "response": "Send an RPC to a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a debug command to a device.", "response": "async def debug(self, conn_id, name, cmd_args):\n        \"\"\"Send a debug command to a device.\n\n        See :meth:`AbstractDeviceAdapter.debug`.\n        \"\"\"\n\n        progress_callback = functools.partial(_on_progress, self, 'debug', conn_id)\n\n        resp = await self._execute(self._adapter.debug_sync, conn_id, name, cmd_args, progress_callback)\n        _raise_error(conn_id, 'send_rpc', resp)\n\n        return resp.get('return_value')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def send_script(self, conn_id, data):\n\n        progress_callback = functools.partial(_on_progress, self, 'script', conn_id)\n\n        resp = await self._execute(self._adapter.send_script_sync, conn_id, data, progress_callback)\n        _raise_error(conn_id, 'send_rpc', resp)", "response": "Send a script to a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autobuild_shiparchive(src_file):\n\n    if not src_file.endswith('.tpl'):\n        raise BuildError(\"You must pass a .tpl file to autobuild_shiparchive\", src_file=src_file)\n\n    env = Environment(tools=[])\n\n    family = ArchitectureGroup('module_settings.json')\n    target = family.platform_independent_target()\n    resolver = ProductResolver.Create()\n\n    #Parse through build_step products to see what needs to imported\n    custom_steps = []\n    for build_step in family.tile.find_products('build_step'):\n        full_file_name = build_step.split(\":\")[0]\n        basename = os.path.splitext(os.path.basename(full_file_name))[0]\n        folder = os.path.dirname(full_file_name)\n\n        fileobj, pathname, description = imp.find_module(basename, [folder])\n        mod = imp.load_module(basename, fileobj, pathname, description)\n        full_file_name, class_name = build_step.split(\":\")\n        custom_steps.append((class_name, getattr(mod, class_name)))\n    env['CUSTOM_STEPS'] = custom_steps\n\n    env[\"RESOLVER\"] = resolver\n\n    base_name, tpl_name = _find_basename(src_file)\n    yaml_name = tpl_name[:-4]\n    ship_name = yaml_name[:-5] + \".ship\"\n\n    output_dir = target.build_dirs()['output']\n    build_dir = os.path.join(target.build_dirs()['build'], base_name)\n    tpl_path = os.path.join(build_dir, tpl_name)\n    yaml_path = os.path.join(build_dir, yaml_name)\n    ship_path = os.path.join(build_dir, ship_name)\n    output_path = os.path.join(output_dir, ship_name)\n\n    # We want to build up all related files in\n    # <build_dir>/<ship archive_folder>/\n    # - First copy the template yaml over\n    # - Then render the template yaml\n    # - Then find all products referenced in the template yaml and copy them\n    # - over\n    # - Then build a .ship archive\n    # - Then copy that archive into output_dir\n\n    ship_deps = [yaml_path]\n\n    env.Command([tpl_path], [src_file], Copy(\"$TARGET\", \"$SOURCE\"))\n\n    prod_deps = _find_product_dependencies(src_file, resolver)\n\n    env.Command([yaml_path], [tpl_path], action=Action(template_shipfile_action, \"Rendering $TARGET\"))\n\n    for prod in prod_deps:\n        dest_file = os.path.join(build_dir, prod.short_name)\n        ship_deps.append(dest_file)\n        env.Command([dest_file], [prod.full_path], Copy(\"$TARGET\", \"$SOURCE\"))\n\n    env.Command([ship_path], [ship_deps], action=Action(create_shipfile, \"Archiving Ship Recipe $TARGET\"))\n    env.Command([output_path], [ship_path], Copy(\"$TARGET\", \"$SOURCE\"))", "response": "Create a ship file archive containing a yaml_file and its dependencies."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a. ship file with all dependencies.", "response": "def create_shipfile(target, source, env):\n    \"\"\"Create a .ship file with all dependencies.\"\"\"\n\n    source_dir = os.path.dirname(str(source[0]))\n    recipe_name = os.path.basename(str(source[0]))[:-5]\n\n    resman = RecipeManager()\n\n    resman.add_recipe_actions(env['CUSTOM_STEPS'])\n    resman.add_recipe_folder(source_dir, whitelist=[os.path.basename(str(source[0]))])\n    recipe = resman.get_recipe(recipe_name)\n\n    recipe.archive(str(target[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef record_trace(self, selectors=None):\n\n        if selectors is None:\n            selectors = [x.selector for x in self.sensor_graph.streamers]\n\n        self.trace = SimulationTrace(selectors=selectors)\n\n        for sel in selectors:\n            self.sensor_graph.sensor_log.watch(sel, self._on_trace_callback)", "response": "Record a trace of readings produced by this simulation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstep the sensor graph through one since input.", "response": "def step(self, input_stream, value):\n        \"\"\"Step the sensor graph through one since input.\n\n        The internal tick count is not advanced so this function may\n        be called as many times as desired to input specific conditions\n        without simulation time passing.\n\n        Args:\n            input_stream (DataStream): The input stream to push the\n                value into\n            value (int): The reading value to push as an integer\n        \"\"\"\n\n        reading = IOTileReading(input_stream.encode(), self.tick_count, value)\n        self.sensor_graph.process_input(input_stream, reading, self.rpc_executor)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, include_reset=True, accelerated=True):\n\n        self._start_tick = self.tick_count\n\n        if self._check_stop_conditions(self.sensor_graph):\n            return\n\n        if include_reset:\n            pass  # TODO: include a reset event here\n\n        # Process all stimuli that occur at the start of the simulation\n        i = None\n        for i, stim in enumerate(self.stimuli):\n            if stim.time != 0:\n                break\n\n            reading = IOTileReading(self.tick_count, stim.stream.encode(), stim.value)\n            self.sensor_graph.process_input(stim.stream, reading, self.rpc_executor)\n\n        if i is not None and i > 0:\n            self.stimuli = self.stimuli[i:]\n\n        while not self._check_stop_conditions(self.sensor_graph):\n            # Process one more one second tick\n            now = monotonic()\n            next_tick = now + 1.0\n\n            # To match what is done in actual hardware, we increment tick count so the first tick\n            # is 1.\n            self.tick_count += 1\n\n            # Process all stimuli that occur at this tick of the simulation\n            i = None\n            for i, stim in enumerate(self.stimuli):\n                if stim.time != self.tick_count:\n                    break\n\n                reading = IOTileReading(self.tick_count, stim.stream.encode(), stim.value)\n                self.sensor_graph.process_input(stim.stream, reading, self.rpc_executor)\n\n            if i is not None and i > 0:\n                self.stimuli = self.stimuli[i:]\n\n            self._check_additional_ticks(self.tick_count)\n\n            if (self.tick_count % 10) == 0:\n                reading = IOTileReading(self.tick_count, system_tick.encode(), self.tick_count)\n                self.sensor_graph.process_input(system_tick, reading, self.rpc_executor)\n\n                # Every 10 seconds the battery voltage is reported in 16.16 fixed point format in volts\n                reading = IOTileReading(self.tick_count, battery_voltage.encode(), int(self.voltage * 65536))\n                self.sensor_graph.process_input(battery_voltage, reading, self.rpc_executor)\n\n            now = monotonic()\n\n            # If we are trying to execute this sensor graph in realtime, wait for\n            # the remaining slice of this tick.\n            if (not accelerated) and (now < next_tick):\n                time.sleep(next_tick - now)", "response": "Run this sensor graph until a stop condition is hit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if any of our stop conditions are met.", "response": "def _check_stop_conditions(self, sensor_graph):\n        \"\"\"Check if any of our stop conditions are met.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph we are currently simulating\n\n        Returns:\n            bool: True if we should stop the simulation\n        \"\"\"\n\n        for stop in self.stop_conditions:\n            if stop.should_stop(self.tick_count, self.tick_count - self._start_tick, sensor_graph):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stimulus(self, stimulus):\n\n        if not isinstance(stimulus, SimulationStimulus):\n            stimulus = SimulationStimulus.FromString(stimulus)\n\n        self.stimuli.append(stimulus)\n        self.stimuli.sort(key=lambda x:x.time)", "response": "Add a simulation stimulus at a given time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_condition(self, condition):\n\n        # Try to parse this into a stop condition with each of our registered\n        # condition types\n        for cond_format in self._known_conditions:\n            try:\n                cond = cond_format.FromString(condition)\n                self.stop_conditions.append(cond)\n                return\n            except ArgumentError:\n                continue\n\n        raise ArgumentError(\"Stop condition could not be processed by any known StopCondition type\", condition=condition, suggestion=\"It may be mistyped or otherwise invalid.\")", "response": "Add a stop condition to this simulation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self):\n\n        walker = self.dump_walker\n        if walker is not None:\n            walker = walker.dump()\n\n        state = {\n            'storage': self.storage.dump(),\n            'dump_walker': walker,\n            'next_id': self.next_id\n        }\n\n        return state", "response": "Serialize the state of this subsystem into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore(self, state):\n\n        self.storage.restore(state.get('storage'))\n\n        dump_walker = state.get('dump_walker')\n        if dump_walker is not None:\n            dump_walker = self.storage.restore_walker(dump_walker)\n\n        self.dump_walker = dump_walker\n        self.next_id = state.get('next_id', 1)", "response": "Restore the state of this subsystem from a prior call to dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self, timestamp):\n\n        self.storage.clear()\n\n        self.push(streams.DATA_CLEARED, timestamp, 1)", "response": "Clear all data from the RSL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing all volatile information across a reset.", "response": "def clear_to_reset(self, config_vars):\n        \"\"\"Clear all volatile information across a reset.\"\"\"\n\n        self._logger.info(\"Config vars in sensor log reset: %s\", config_vars)\n        super(SensorLogSubsystem, self).clear_to_reset(config_vars)\n\n        self.storage.destroy_all_walkers()\n        self.dump_walker = None\n\n        if config_vars.get('storage_fillstop', False):\n            self._logger.debug(\"Marking storage log fill/stop\")\n            self.storage.set_rollover('storage', False)\n\n        if config_vars.get('streaming_fillstop', False):\n            self._logger.debug(\"Marking streaming log fill/stop\")\n            self.storage.set_rollover('streaming', False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npush a value to a stream.", "response": "def push(self, stream_id, timestamp, value):\n        \"\"\"Push a value to a stream.\n\n        Args:\n            stream_id (int): The stream we want to push to.\n            timestamp (int): The raw timestamp of the value we want to\n                store.\n            value (int): The 32-bit integer value we want to push.\n        Returns:\n            int: Packed 32-bit error code.\n        \"\"\"\n\n        stream = DataStream.FromEncoded(stream_id)\n        reading = IOTileReading(stream_id, timestamp, value)\n\n        try:\n            self.storage.push(stream, reading)\n\n            return Error.NO_ERROR\n        except StorageFullError:\n            return pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.RING_BUFFER_FULL)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninspects the last value written into a virtual stream.", "response": "def inspect_virtual(self, stream_id):\n        \"\"\"Inspect the last value written into a virtual stream.\n\n        Args:\n            stream_id (int): The virtual stream was want to inspect.\n\n        Returns:\n            (int, int): An error code and the stream value.\n        \"\"\"\n\n        stream = DataStream.FromEncoded(stream_id)\n\n        if stream.buffered:\n            return [pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.VIRTUAL_STREAM_NOT_FOUND), 0]\n\n        try:\n            reading = self.storage.inspect_last(stream, only_allocated=True)\n            return [Error.NO_ERROR, reading.value]\n        except StreamEmptyError:\n            return [Error.NO_ERROR, 0]\n        except UnresolvedIdentifierError:\n            return [pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.VIRTUAL_STREAM_NOT_FOUND), 0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_begin(self, selector_id):\n\n        if self.dump_walker is not None:\n            self.storage.destroy_walker(self.dump_walker)\n\n        selector = DataStreamSelector.FromEncoded(selector_id)\n        self.dump_walker = self.storage.create_walker(selector, skip_all=False)\n\n        return Error.NO_ERROR, Error.NO_ERROR, self.dump_walker.count()", "response": "Starts dumping a buffered stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_seek(self, reading_id):\n\n        if self.dump_walker is None:\n            return (pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.STREAM_WALKER_NOT_INITIALIZED),\n                    Error.NO_ERROR, 0)\n\n        try:\n            exact = self.dump_walker.seek(reading_id, target='id')\n        except UnresolvedIdentifierError:\n            return (pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.NO_MORE_READINGS),\n                    Error.NO_ERROR, 0)\n\n        error = Error.NO_ERROR\n        if not exact:\n            error = pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.ID_FOUND_FOR_ANOTHER_STREAM)\n\n        return (error, error.NO_ERROR, self.dump_walker.count())", "response": "Seek the dump streamer to a given ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the next reading from the stream.", "response": "def dump_next(self):\n        \"\"\"Dump the next reading from the stream.\n\n        Returns:\n            IOTileReading: The next reading or None if there isn't one\n        \"\"\"\n\n        if self.dump_walker is None:\n            return pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.STREAM_WALKER_NOT_INITIALIZED)\n\n        try:\n            return self.dump_walker.pop()\n        except StreamEmptyError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscan through the stored readings and report the highest stored id.", "response": "def highest_stored_id(self):\n        \"\"\"Scan through the stored readings and report the highest stored id.\n\n        Returns:\n            int: The highest stored id.\n        \"\"\"\n\n        shared = [0]\n        def _keep_max(_i, reading):\n            if reading.reading_id > shared[0]:\n                shared[0] = reading.reading_id\n\n        self.engine.scan_storage('storage', _keep_max)\n        self.engine.scan_storage('streaming', _keep_max)\n\n        return shared[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rsl_push_reading(self, value, stream_id):\n\n        #FIXME: Fix this with timestamp from clock manager task\n        err = self.sensor_log.push(stream_id, 0, value)\n        return [err]", "response": "Push a reading to the RSL directly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rsl_push_many_readings(self, value, count, stream_id):\n\n        #FIXME: Fix this with timestamp from clock manager task\n\n        for i in range(1, count+1):\n            err = self.sensor_log.push(stream_id, 0, value)\n            if err != Error.NO_ERROR:\n                return [err, i]\n\n        return [Error.NO_ERROR, count]", "response": "Push many copies of a reading to the RSL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rsl_count_readings(self):\n\n        storage, output = self.sensor_log.count()\n        return [Error.NO_ERROR, storage, output]", "response": "Count how many readings are stored in the RSL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rsl_dump_stream_begin(self, stream_id):\n\n        err, err2, count = self.sensor_log.dump_begin(stream_id)\n\n        #FIXME: Fix this with the uptime of the clock manager task\n        return [err, err2, count, 0]", "response": "Begin dumping the contents of a stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump the next reading from the output stream.", "response": "def rsl_dump_stream_next(self, output_format):\n        \"\"\"Dump the next reading from the output stream.\"\"\"\n\n        timestamp = 0\n        stream_id = 0\n        value = 0\n        reading_id = 0\n        error = Error.NO_ERROR\n\n        reading = self.sensor_log.dump_next()\n        if reading is not None:\n            timestamp = reading.raw_time\n            stream_id = reading.stream\n            value = reading.value\n            reading_id = reading.reading_id\n        else:\n            error = pack_error(ControllerSubsystem.SENSOR_LOG, SensorLogError.NO_MORE_READINGS)\n\n        if output_format == 0:\n            return [struct.pack(\"<LLL\", error, timestamp, value)]\n        elif output_format != 1:\n            raise ValueError(\"Output format other than 1 not yet supported\")\n\n        return [struct.pack(\"<LLLLH2x\", error, timestamp, value, reading_id, stream_id)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate size and encoding from a type name. This method takes a C-style type string like uint8_t[10] and returns - the total size in bytes - the unit size of each member (if it's an array) - the scruct.{pack,unpack} format code for decoding the base type - whether it is an array.", "response": "def parse_size_name(type_name):\n    \"\"\"Calculate size and encoding from a type name.\n\n    This method takes a C-style type string like uint8_t[10] and returns\n    - the total size in bytes\n    - the unit size of each member (if it's an array)\n    - the scruct.{pack,unpack} format code for decoding the base type\n    - whether it is an array.\n    \"\"\"\n\n    if ' ' in type_name:\n        raise ArgumentError(\"There should not be a space in config variable type specifier\", specifier=type_name)\n\n    variable = False\n    count = 1\n    base_type = type_name\n\n    if type_name[-1] == ']':\n        variable = True\n        start_index = type_name.find('[')\n        if start_index == -1:\n            raise ArgumentError(\"Could not find matching [ for ] character\", specifier=type_name)\n\n        count = int(type_name[start_index+1:-1], 0)\n        base_type = type_name[:start_index]\n\n    matched_type = TYPE_CODES.get(base_type)\n    if matched_type is None:\n        raise ArgumentError(\"Could not find base type name\", base_type=base_type, type_string=type_name)\n\n    base_size = struct.calcsize(\"<%s\" % matched_type)\n    total_size = base_size*count\n\n    return total_size, base_size, matched_type, variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_python_type(self, python_type):\n\n        if python_type == 'bool':\n            if self.variable:\n                raise ArgumentError(\"You can only specify a bool python type on a scalar (non-array) type_name\", type_name=self.type_name)\n\n            return\n\n        if python_type == 'string':\n            if not (self.variable and self.unit_size == 1):\n                raise ArgumentError(\"You can only pass a string python type on an array of 1-byte objects\", type_name=self.type_name)\n\n            return\n\n        if python_type is not None:\n            raise ArgumentError(\"You can only declare a bool or string python type.  Otherwise it must be passed as None\", python_type=python_type)", "response": "Validate the possible combinations of python_type and type_name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the passed default value to binary.", "response": "def _convert_default_value(self, default):\n        \"\"\"Convert the passed default value to binary.\n\n        The default value (if passed) may be specified as either a `bytes`\n        object or a python int or list of ints.  If an int or list of ints is\n        passed, it is converted to binary.  Otherwise, the raw binary data is\n        used.\n\n        If you pass a bytes object with python_type as True, do not null terminate\n        it, an additional null termination will be added.\n\n        Passing a unicode string is only allowed if as_string is True and it\n        will be encoded as utf-8 and null terminated for use as a default value.\n        \"\"\"\n\n        if default is None:\n            return None\n\n        if isinstance(default, str):\n            if self.special_type == 'string':\n                return default.encode('utf-8') + b'\\0'\n\n            raise DataError(\"You can only pass a unicode string if you are declaring a string type config variable\", default=default)\n\n        if isinstance(default, (bytes, bytearray)):\n            if self.special_type == 'string' and isinstance(default, bytes):\n                default += b'\\0'\n\n            return default\n\n        if isinstance(default, int):\n            default = [default]\n\n        format_string = \"<\" + (self.base_type*len(default))\n        return struct.pack(format_string, *default)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing this config variable to its reset value.", "response": "def clear(self):\n        \"\"\"Clear this config variable to its reset value.\"\"\"\n\n        if self.default_value is None:\n            self.current_value = bytearray()\n        else:\n            self.current_value = bytearray(self.default_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the binary value currently stored for this config value.", "response": "def update_value(self, offset, value):\n        \"\"\"Update the binary value currently stored for this config value.\n\n        Returns:\n            int: An opaque error code that can be returned from a set_config rpc\n        \"\"\"\n\n        if offset + len(value) > self.total_size:\n            return Error.INPUT_BUFFER_TOO_LONG\n\n        if len(self.current_value) < offset:\n            self.current_value += bytearray(offset - len(self.current_value))\n        if len(self.current_value) > offset:\n            self.current_value = self.current_value[:offset]\n\n        self.current_value += bytearray(value)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the current value inside this config descriptor to a python object.", "response": "def latch(self):\n        \"\"\"Convert the current value inside this config descriptor to a python object.\n\n        The conversion proceeds by mapping the given type name to a native\n        python class and performing the conversion.  You can override what\n        python object is used as the destination class by passing a\n        python_type parameter to __init__.\n\n        The default mapping is:\n        - char (u)int8_t, (u)int16_t, (u)int32_t: int\n        - char[] (u)int8_t[], (u)int16_t[]0, u(int32_t): list of int\n\n        If you want to parse a char[] or uint8_t[] as a python string, it\n        needs to be null terminated and you should pass python_type='string'.\n\n        If you are declaring a scalar integer type and wish it to be decoded\n        as a bool, you can pass python_type='bool' to the constructor.\n\n        All integers are decoded as little-endian.\n\n        Returns:\n            object: The corresponding python object.\n\n            This will either be an int, list of int or string based on the\n            type_name specified and the optional python_type keyword argument\n            to the constructor.\n\n        Raises:\n            DataError: if the object cannot be converted to the desired type.\n            ArgumentError: if an invalid python_type was specified during construction.\n        \"\"\"\n\n        if len(self.current_value) == 0:\n            raise DataError(\"There was no data in a config variable during latching\", name=self.name)\n\n        # Make sure the data ends on a unit boundary.  This would have happened automatically\n        # in an actual device by the C runtime 0 padding out the storage area.\n        remaining = len(self.current_value) % self.unit_size\n        if remaining > 0:\n            self.current_value += bytearray(remaining)\n\n        if self.special_type == 'string':\n            if self.current_value[-1] != 0:\n                raise DataError(\"String type was specified by data did not end with a null byte\", data=self.current_value, name=self.name)\n\n            return bytes(self.current_value[:-1]).decode('utf-8')\n\n        fmt_code = \"<\" + (self.base_type * (len(self.current_value) // self.unit_size))\n        data = struct.unpack(fmt_code, self.current_value)\n\n        if self.variable:\n            data = list(data)\n        else:\n            data = data[0]\n\n            if self.special_type == 'bool':\n                data = bool(data)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef declare_config_variable(self, name, config_id, type_name, default=None, convert=None):  #pylint:disable=too-many-arguments;These are all necessary with sane defaults.\n\n        config = ConfigDescriptor(config_id, type_name, default, name=name, python_type=convert)\n        self._config_variables[config_id] = config", "response": "Declare a config variable that this emulated tile accepts."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlatch the current value of all config variables as python objects. This function will capture the current value of all config variables at the time that this method is called. It must be called after start() has been called so that any default values in the config variables have been properly set otherwise DataError will be thrown. Conceptually this method performs the operation that happens just before a tile executive hands control to the tile application firmware. It latches in the value of all config variables at that point in time. For convenience, this method does all necessary binary -> python native object conversion so that you just get python objects back. Returns: dict: A dict of str -> object with the config variable values. The keys in the dict will be the name passed to `declare_config_variable`. The values will be the python objects that result from calling latch() on each config variable. Consult ConfigDescriptor.latch() for documentation on how that method works.", "response": "def latch_config_variables(self):\n        \"\"\"Latch the current value of all config variables as python objects.\n\n        This function will capture the current value of all config variables\n        at the time that this method is called.  It must be called after\n        start() has been called so that any default values in the config\n        variables have been properly set otherwise DataError will be thrown.\n\n        Conceptually this method performs the operation that happens just\n        before a tile executive hands control to the tile application\n        firmware. It latches in the value of all config variables at that\n        point in time.\n\n        For convenience, this method does all necessary binary -> python\n        native object conversion so that you just get python objects back.\n\n        Returns:\n            dict: A dict of str -> object with the config variable values.\n\n            The keys in the dict will be the name passed to\n            `declare_config_variable`.\n\n            The values will be the python objects that result from calling\n            latch() on each config variable.  Consult ConfigDescriptor.latch()\n            for documentation on how that method works.\n        \"\"\"\n\n        return {desc.name: desc.latch() for desc in self._config_variables.values()}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_state(self):\n\n        return {\n            \"config_variables\": {x: base64.b64encode(y.current_value).decode('utf-8') for x, y in self._config_variables.items()},\n        }", "response": "Dump the current state of this emulated tile as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore_state(self, state):\n\n        config_vars = state.get('config_variables', {})\n\n        for str_name, str_value in config_vars.items():\n            name = int(str_name)\n            value = base64.b64decode(str_value)\n\n            if name in self._config_variables:\n                self._config_variables[name].current_value = value", "response": "Restore the current state of this emulated object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def reset(self):\n\n        await self._device.emulator.stop_tasks(self.address)\n\n        self._handle_reset()\n\n        self._logger.info(\"Tile at address %d has reset itself.\", self.address)\n\n        self._logger.info(\"Starting main task for tile at address %d\", self.address)\n        self._device.emulator.add_task(self.address, self._reset_vector())", "response": "Synchronously reset a tile."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_config_variables(self, offset):\n\n        names = sorted(self._config_variables)\n        names = names[offset:offset + 9]\n        count = len(names)\n\n        if len(names) < 9:\n            names += [0]*(9 - count)\n\n        return [count] + names", "response": "List defined config variables up to 9 at a time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef describe_config_variable(self, config_id):\n\n        config = self._config_variables.get(config_id)\n        if config is None:\n            return [Error.INVALID_ARRAY_KEY, 0, 0, 0, 0]\n\n        packed_size = config.total_size\n        packed_size |= int(config.variable) << 15\n\n        return [0, 0, 0, config_id, packed_size]", "response": "Describe the config variable by its id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a chunk of the current config value s value.", "response": "def set_config_variable(self, config_id, offset, value):\n        \"\"\"Set a chunk of the current config value's value.\"\"\"\n\n        if self.initialized.is_set():\n            return [Error.STATE_CHANGE_AT_INVALID_TIME]\n\n        config = self._config_variables.get(config_id)\n        if config is None:\n            return [Error.INVALID_ARRAY_KEY]\n\n        error = config.update_value(offset, value)\n        return [error]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_config_variable(self, config_id, offset):\n\n        config = self._config_variables.get(config_id)\n        if config is None:\n            return [b\"\"]\n\n        return [bytes(config.current_value[offset:offset + 20])]", "response": "Get a chunk of a config variable s value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_config(self, name, default=MISSING):\n\n        res = self.config.get(name, default)\n        if res is MISSING:\n            raise ArgumentError(\"Could not find config value by name and no default supplied\", name=name)\n\n        return res", "response": "Get a config value from this adapter by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_callback(self, name, func):\n\n        if name not in self.callbacks:\n            raise ValueError(\"Unknown callback name: %s\" % name)\n\n        self.callbacks[name].add(func)", "response": "Add a callback when Device events happen\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_sync(self, connection_id, connection_string):\n\n        calldone = threading.Event()\n        results = {}\n\n        def connect_done(callback_connid, callback_adapterid, callback_success, failure_reason):\n            results['success'] = callback_success\n            results['failure_reason'] = failure_reason\n            calldone.set()  # Be sure to set after all operations are done to prevent race condition\n\n        self.connect_async(connection_id, connection_string, connect_done)\n        calldone.wait()\n\n        return results", "response": "Synchronously connect to a device"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disconnect_sync(self, conn_id):\n\n        done = threading.Event()\n        result = {}\n\n        def disconnect_done(conn_id, adapter_id, status, reason):\n            result['success'] = status\n            result['failure_reason'] = reason\n            done.set()\n\n        self.disconnect_async(conn_id, disconnect_done)\n        done.wait()\n\n        return result", "response": "Synchronously disconnect from a connected device"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_interface_async(self, conn_id, interface, callback, connection_string=None):\n\n        if interface not in {\"rpc\", \"script\", \"streaming\", \"tracing\", \"debug\"}:\n            callback(conn_id, self.id, False, \"invalid interface name in call to open_interface_async\")\n            return\n\n        if interface == \"rpc\":\n            self._open_rpc_interface(conn_id, callback)\n        elif interface == 'script':\n            self._open_script_interface(conn_id, callback)\n        elif interface == 'streaming':\n            self._open_streaming_interface(conn_id, callback)\n        elif interface == 'tracing':\n            self._open_tracing_interface(conn_id, callback)\n        elif interface == 'debug':\n            self._open_debug_interface(conn_id, callback, connection_string)\n        else:\n            callback(conn_id, self.id, False, \"interface not supported yet\")", "response": "Asynchronously open an interface to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_rpc_async(self, conn_id, address, rpc_id, payload, timeout, callback):\n\n        callback(conn_id, self.id, False, 'RPCs are not supported on this adapter', None, None)", "response": "Asynchronously send an RPC to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_rpc_sync(self, conn_id, address, rpc_id, payload, timeout):\n\n        done = threading.Event()\n        result = {}\n\n        def send_rpc_done(conn_id, adapter_id, status, reason, rpc_status, resp_payload):\n            result['success'] = status\n            result['failure_reason'] = reason\n            result['status'] = rpc_status\n            result['payload'] = resp_payload\n\n            done.set()\n\n        self.send_rpc_async(conn_id, address, rpc_id, payload, timeout, send_rpc_done)\n        done.wait()\n\n        return result", "response": "Synchronously send an RPC to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a specific installed auth provider by name.", "response": "def FindByName(cls, name):\n        \"\"\"Find a specific installed auth provider by name.\"\"\"\n\n        reg = ComponentRegistry()\n        for _, entry in reg.load_extensions('iotile.auth_provider', name_filter=name):\n            return entry"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nderiving a standard one time use report signing key.", "response": "def DeriveReportKey(cls, root_key, report_id, sent_timestamp):\n        \"\"\"Derive a standard one time use report signing key.\n\n        The standard method is HMAC-SHA256(root_key, MAGIC_NUMBER || report_id || sent_timestamp)\n        where MAGIC_NUMBER is 0x00000002 and all integers are in little endian.\n        \"\"\"\n\n        signed_data = struct.pack(\"<LLL\", AuthProvider.ReportKeyMagic, report_id, sent_timestamp)\n\n        hmac_calc = hmac.new(root_key, signed_data, hashlib.sha256)\n        return bytearray(hmac_calc.digest())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef declare(self, name):\n\n        if name in self._data:\n            raise KeyError(\"Declared name {} that already existed\".format(name))\n\n        self._data[name] = self._loop.create_future()", "response": "Declare that a key will be set in the future."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting for a value to be set for a key.", "response": "async def get(self, name, timeout=None, autoremove=True):\n        \"\"\"Wait for a value to be set for a key.\n\n        This is the primary way to receive values from AwaitableDict.\n        You pass in the name of the key you want to wait for, the maximum\n        amount of time you want to wait and then you can await the result\n        and it will resolve to value from the call to set or an\n        asyncio.TimeoutError.\n\n        You should generally leave autoremove as the default True value. This\n        causes the key to be removed from the dictionary after get returns.\n        Normally you have a single user calling ``get`` and another calling\n        ``set`` so you want to automatically clean up after the getter\n        returns, no matter what.\n\n        If the key has not already been declared, it will be declared\n        automatically inside this function so it is not necessary to call\n        :meth:`declare` manually in most use cases.\n\n        Args:\n            name (str): The name of the key to wait on.\n            timeout (float): The maximum timeout to wait.\n            autoremove (bool): Whether to automatically remove the\n                key when get() returns.\n\n        Returns:\n            object: Whatever was set in the key by :meth:`set`.\n\n        Raises:\n            asyncio.TimeoutError: The key was not set within the timeout.\n        \"\"\"\n\n        self._ensure_declared(name)\n\n        try:\n            await asyncio.wait_for(self._data[name], timeout, loop=self._loop.get_loop())\n            return self._data[name].result()\n        finally:\n            if autoremove:\n                self._data[name].cancel()\n                del self._data[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_nowait(self, name, default=_MISSING, autoremove=False):\n\n        self._ensure_declared(name)\n\n        try:\n            future = self._data[name]\n            if future.done():\n                return future.result()\n\n            if default is _MISSING:\n                raise KeyError(\"Key {} has not been assigned a value and no default given\".format(name))\n\n            return default\n        finally:\n            if autoremove:\n                self._data[name].cancel()\n                del self._data[name]", "response": "Get the value of a key in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(self, name, value, autodeclare=False):\n\n        if not autodeclare and name not in self._data:\n            raise KeyError(\"Key {} has not been declared and autodeclare=False\".format(name))\n\n        self._ensure_declared(name)\n        self._data[name].set_result(value)", "response": "Sets the value of a key in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify(self, obj):\n\n        if obj != self._literal:\n            raise ValidationError(\"Object is not equal to literal\",\n                                  reason='%s is not equal to %s' % (str(obj), str(self._literal)), object=obj)\n\n        return obj", "response": "Verify that the object conforms to this verifier s schema\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat this verifier string", "response": "def format(self, indent_level, indent_size=4):\n        \"\"\"Format this verifier\n\n        Returns:\n            string: A formatted string\n        \"\"\"\n\n        name = self.format_name('Literal', indent_size)\n\n        if self.long_desc is not None:\n            name += '\\n'\n\n        name += self.wrap_lines('value: %s\\n' % str(self._literal), 1, indent_size)\n\n        return self.wrap_lines(name, indent_level, indent_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_tree(self, statement=None, indent_level=0):\n\n        out = u\"\"\n\n        indent = u\" \"*indent_level\n\n        if statement is None:\n            for root_statement in self.statements:\n                out += self.dump_tree(root_statement, indent_level)\n        else:\n            out += indent + str(statement) + u'\\n'\n\n            if len(statement.children) > 0:\n                for child in statement.children:\n                    out += self.dump_tree(child, indent_level=indent_level+4)\n\n        return out", "response": "Dump the AST for this SensorGraphStatement as a nested\n            tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a sensor graph file into an AST describing the file.", "response": "def parse_file(self, sg_file=None, data=None):\n        \"\"\"Parse a sensor graph file into an AST describing the file.\n\n        This function builds the statements list for this parser.\n        If you pass ``sg_file``, it will be interpreted as the path to a file\n        to parse.  If you pass ``data`` it will be directly interpreted as the\n        string to parse.\n        \"\"\"\n\n        if sg_file is not None and data is not None:\n            raise ArgumentError(\"You must pass either a path to an sgf file or the sgf contents but not both\")\n\n        if sg_file is None and data is None:\n            raise ArgumentError(\"You must pass either a path to an sgf file or the sgf contents, neither passed\")\n\n        if sg_file is not None:\n            try:\n                with open(sg_file, \"r\") as inf:\n                    data = inf.read()\n            except IOError:\n                raise ArgumentError(\"Could not read sensor graph file\", path=sg_file)\n\n        # convert tabs to spaces so our line numbers match correctly\n        data = data.replace(u'\\t', u'    ')\n\n        lang = get_language()\n        result = lang.parseString(data)\n\n        for statement in result:\n            parsed = self.parse_statement(statement, orig_contents=data)\n            self.statements.append(parsed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile(self, model):\n\n        log = SensorLog(InMemoryStorageEngine(model), model)\n        self.sensor_graph = SensorGraph(log, model)\n\n        allocator = StreamAllocator(self.sensor_graph, model)\n\n        self._scope_stack = []\n\n        # Create a root scope\n        root = RootScope(self.sensor_graph, allocator)\n        self._scope_stack.append(root)\n\n        for statement in self.statements:\n            statement.execute(self.sensor_graph, self._scope_stack)\n\n        self.sensor_graph.initialize_remaining_constants()\n        self.sensor_graph.sort_nodes()", "response": "Compile this file into a SensorGraph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_statement(self, statement, orig_contents):\n\n        children = []\n        is_block = False\n        name = statement.getName()\n\n        # Recursively parse all children statements in a block\n        # before parsing the block itself.\n        # If this is a non-block statement, parse it using the statement\n        # parser to figure out what specific statement it is before\n        # processing it further.\n        # This two step process produces better syntax error messsages\n        if name == 'block':\n            children_statements = statement[1]\n            for child in children_statements:\n                parsed = self.parse_statement(child, orig_contents=orig_contents)\n                children.append(parsed)\n\n            locn = statement[0]['location']\n            statement = statement[0][1]\n            name = statement.getName()\n            is_block = True\n        else:\n            stmt_language = get_statement()\n            locn = statement['location']\n            statement = statement['match']\n            statement_string = str(u\"\".join(statement.asList()))\n\n            # Try to parse this generic statement into an actual statement.\n            # Do this here in a separate step so we have good error messages when there\n            # is a problem parsing a step.\n            try:\n                statement = stmt_language.parseString(statement_string)[0]\n            except (pyparsing.ParseException, pyparsing.ParseSyntaxException) as exc:\n                raise SensorGraphSyntaxError(\"Error parsing statement in sensor graph file\", message=exc.msg, line=pyparsing.line(locn, orig_contents).strip(), line_number=pyparsing.lineno(locn, orig_contents), column=pyparsing.col(locn, orig_contents))\n            except SensorGraphSemanticError as exc:\n                # Reraise semantic errors with line information\n                raise SensorGraphSemanticError(exc.msg, line=pyparsing.line(locn, orig_contents).strip(), line_number=pyparsing.lineno(locn, orig_contents), **exc.params)\n\n            name = statement.getName()\n\n        if name not in statement_map:\n            raise ArgumentError(\"Unknown statement in sensor graph file\", parsed_statement=statement, name=name)\n\n        # Save off our location information so we can give good error and warning information\n        line = pyparsing.line(locn, orig_contents).strip()\n        line_number = pyparsing.lineno(locn, orig_contents)\n        column = pyparsing.col(locn, orig_contents)\n        location_info = LocationInfo(line, line_number, column)\n\n        if is_block:\n            return statement_map[name](statement, children=children, location=location_info)\n\n        return statement_map[name](statement, location_info)", "response": "Parse a statement in a SensorGraph file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart running this virtual device including any necessary worker threads.", "response": "def start(self, channel):\n        \"\"\"Start running this virtual device including any necessary worker threads.\n\n        Args:\n            channel (IOTilePushChannel): the channel with a stream and trace\n                routine for streaming and tracing data through a VirtualInterface\n        \"\"\"\n\n        if self._started:\n            raise InternalError(\"The method start() was called twice on VirtualIOTileDevice.\")\n\n        self._push_channel = channel\n        self.start_workers()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream(self, report, callback=None):\n\n        if self._push_channel is None:\n            return\n\n        self._push_channel.stream(report, callback=callback)", "response": "Stream a report asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstreaming a realtime value as an IndividualReadingReport.", "response": "def stream_realtime(self, stream, value):\n        \"\"\"Stream a realtime value as an IndividualReadingReport.\n\n        If the streaming interface of the VirtualInterface this\n        VirtualDevice is attached to is not opened, the realtime\n        reading may be dropped.\n\n        Args:\n            stream (int): The stream id to send\n            value (int): The stream value to send\n        \"\"\"\n\n        if not self.stream_iface_open:\n            return\n\n        reading = IOTileReading(0, stream, value)\n\n        report = IndividualReadingReport.FromReadings(self.iotile_id, [reading])\n        self.stream(report)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trace(self, data, callback=None):\n\n        if self._push_channel is None:\n            return\n\n        self._push_channel.trace(data, callback=callback)", "response": "Trace data asynchronously.\n\n        If no one is listening for traced data, it will be dropped\n        otherwise it will be queued for sending.\n\n        Args:\n            data (bytearray, string): Unstructured data to trace to any\n                connected client.\n            callback (callable): Optional callback to get notified when\n                this data is actually sent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a single RPC handler with the given info.", "response": "def register_rpc(self, address, rpc_id, func):\n        \"\"\"Register a single RPC handler with the given info.\n\n        This function can be used to directly register individual RPCs,\n        rather than delegating all RPCs at a given address to a virtual\n        Tile.\n\n        If calls to this function are mixed with calls to add_tile for\n        the same address, these RPCs will take precedence over what is\n        defined in the tiles.\n\n        Args:\n            address (int): The address of the mock tile this RPC is for\n            rpc_id (int): The number of the RPC\n            func (callable): The function that should be called to handle the\n                RPC.  func is called as func(payload) and must return a single\n                string object of up to 20 bytes with its response\n        \"\"\"\n\n        if rpc_id < 0 or rpc_id > 0xFFFF:\n            raise RPCInvalidIDError(\"Invalid RPC ID: {}\".format(rpc_id))\n\n        if address not in self._rpc_overlays:\n            self._rpc_overlays[address] = RPCDispatcher()\n\n        self._rpc_overlays[address].add_rpc(rpc_id, func)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call_rpc(self, address, rpc_id, payload=b\"\"):\n\n        if rpc_id < 0 or rpc_id > 0xFFFF:\n            raise RPCInvalidIDError(\"Invalid RPC ID: {}\".format(rpc_id))\n\n        if address not in self._rpc_overlays and address not in self._tiles:\n            raise TileNotFoundError(\"Unknown tile address, no registered handler\", address=address)\n\n        overlay = self._rpc_overlays.get(address, None)\n        tile = self._tiles.get(address, None)\n        if overlay is not None and overlay.has_rpc(rpc_id):\n            return overlay.call_rpc(rpc_id, payload)\n        elif tile is not None and tile.has_rpc(rpc_id):\n            return tile.call_rpc(rpc_id, payload)\n\n        raise RPCNotFoundError(\"Could not find RPC 0x%X at address %d\" % (rpc_id, address))", "response": "Call an RPC by its address and ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_tile(self, address, tile):\n\n        if address in self._tiles:\n            raise ArgumentError(\"Tried to add two tiles at the same address\", address=address)\n\n        self._tiles[address] = tile", "response": "Add a tile to handle all RPCs at a given address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding the contents of this update record without including a record header.", "response": "def encode_contents(self):\n        \"\"\"Encode the contents of this update record without including a record header.\n\n        Returns:\n            bytearary: The encoded contents.\n        \"\"\"\n\n        header = struct.pack(\"<LL\", self.offset, len(self.raw_data))\n        return bytearray(header) + self.raw_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an update record from a binary record.", "response": "def FromBinary(cls, record_data, record_count=1):\n        \"\"\"Create an UpdateRecord subclass from binary record data.\n\n        This should be called with a binary record blob (NOT including the\n        record type header) and it will decode it into a ReflashControllerRecord.\n\n        Args:\n            record_data (bytearray): The raw record data that we wish to parse\n                into an UpdateRecord subclass NOT including its 8 byte record header.\n            record_count (int): The number of records included in record_data.\n\n        Raises:\n            ArgumentError: If the record_data is malformed and cannot be parsed.\n\n        Returns:\n            ReflashControllerRecord: The decoded reflash tile record.\n        \"\"\"\n\n        if len(record_data) < ReflashControllerRecord.RecordHeaderLength:\n            raise ArgumentError(\"Record was too short to contain a full reflash record header\",\n                                length=len(record_data), header_length=ReflashControllerRecord.RecordHeaderLength)\n\n        offset, data_length = struct.unpack_from(\"<LL\", record_data)\n\n        bindata = record_data[ReflashControllerRecord.RecordHeaderLength:]\n        if len(bindata) != data_length:\n            raise ArgumentError(\"Embedded firmware length did not agree with actual length of embeded data\",\n                                length=len(bindata), embedded_length=data_length)\n\n        return ReflashControllerRecord(bindata, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_tiles(self, include_controller=True):\n\n        for address, tile in sorted(self._tiles.items()):\n            if address == 8 and not include_controller:\n                continue\n\n            yield address, tile", "response": "Iterate over all tiles in this device in order."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts this emulated device.", "response": "def start(self, channel=None):\n        \"\"\"Start this emulated device.\n\n        This triggers the controller to call start on all peripheral tiles in\n        the device to make sure they start after the controller does and then\n        it waits on each one to make sure they have finished initializing\n        before returning.\n\n        Args:\n            channel (IOTilePushChannel): the channel with a stream and trace\n                routine for streaming and tracing data through a VirtualInterface\n        \"\"\"\n\n        super(ReferenceDevice, self).start(channel)\n\n        try:\n            self.controller.start(channel)\n\n            # Guarantee an initialization order so that our trace files are deterministic\n            for address, tile in sorted(self._tiles.items()):\n                if address == 8:\n                    continue\n\n                if not isinstance(tile, EmulatedPeripheralTile):\n                    raise DataError(\"An emulated ReferenceDevice can only have a single controller and all other tiles must inherit from EmulatedPeripheralTile\",\n                                    address=address)\n\n                tile.start(channel)\n\n            async def _launch_tiles():\n                await self.controller.reset()\n                await asyncio.wait_for(self.controller.initialized.wait(), 2.0)\n\n                # Note that we do not explicitly reset the tiles.\n                # The controller resets all tiles in its reset method.\n                for address, tile in sorted(self._tiles.items()):\n                    if address == 8:\n                        continue\n\n                    await asyncio.wait_for(tile.initialized.wait(), 2.0)\n\n            self.emulator.run_task_external(_launch_tiles())\n\n            if self._simulating_time:\n                self.emulator.add_task(None, self._time_ticker())\n        except:\n            self.stop()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when someone opens a streaming interface to the device.", "response": "def open_streaming_interface(self):\n        \"\"\"Called when someone opens a streaming interface to the device.\n\n        This method will automatically notify sensor_graph that there is a\n        streaming interface opened.\n\n        Returns:\n            list: A list of IOTileReport objects that should be sent out\n                the streaming interface.\n        \"\"\"\n\n        super(ReferenceDevice, self).open_streaming_interface()\n\n        self.rpc(8, rpcs.SG_GRAPH_INPUT, 8, streams.COMM_TILE_OPEN)\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close_streaming_interface(self):\n\n        super(ReferenceDevice, self).close_streaming_interface()\n\n        self.rpc(8, rpcs.SG_GRAPH_INPUT, 8, streams.COMM_TILE_CLOSED)", "response": "Called when someone closes the streaming interface to the device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_state(self):\n\n        # Dump the state of all of the tiles\n        def _background_dump():\n            state = super(ReferenceDevice, self).dump_state()\n\n            state['state_name'] = self.STATE_NAME\n            state['state_version'] = self.STATE_VERSION\n            state['reset_count'] = self.reset_count\n            state['received_script'] = base64.b64encode(self.script).decode('utf-8')\n\n            return state\n\n        return self.synchronize_task(_background_dump)", "response": "Dump the current state of this emulated object as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef restore_state(self, state):\n\n        state_name = state.get('state_name')\n        state_version = state.get('state_version')\n\n        if state_name != self.STATE_NAME or state_version != self.STATE_VERSION:\n            raise ArgumentError(\"Invalid emulated device state name or version\", found=(state_name, state_version),\n                                expected=(self.STATE_NAME, self.STATE_VERSION))\n\n        def _background_restore():\n            # Restore the state of all of the tiles\n            super(ReferenceDevice, self).restore_state(state)\n\n            self.reset_count = state.get('reset_count', 0)\n            self.script = base64.b64decode(state.get('received_script'))\n\n        self.synchronize_task(_background_restore)", "response": "Restore the current state of this emulated device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the script s argument parser.", "response": "def build_parser():\n    \"\"\"Build the script's argument parser.\"\"\"\n\n    parser = argparse.ArgumentParser(description=\"The IOTile task supervisor\")\n    parser.add_argument('-c', '--config', help=\"config json with options\")\n    parser.add_argument('-v', '--verbose', action=\"count\", default=0, help=\"Increase logging verbosity\")\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_logging(verbosity):\n\n    root = logging.getLogger()\n\n    formatter = logging.Formatter('%(asctime)s.%(msecs)03d %(levelname).3s %(name)s %(message)s',\n                                  '%y-%m-%d %H:%M:%S')\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n\n    loglevels = [logging.CRITICAL, logging.ERROR, logging.WARNING, logging.INFO, logging.DEBUG]\n    if verbosity >= len(loglevels):\n        verbosity = len(loglevels) - 1\n\n    level = loglevels[verbosity]\n\n    root.setLevel(level)\n    root.addHandler(handler)", "response": "Configure the global logging level."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call_linker_cb(env, callback, args, result = None):\n\n    Verbose = False\n\n    if Verbose:\n        print('_call_linker_cb: args=%r' % args)\n        print('_call_linker_cb: callback=%r' % callback)\n\n    try:\n        cbfun = env['LINKCALLBACKS'][callback]\n    except (KeyError, TypeError):\n        if Verbose:\n            print('_call_linker_cb: env[\"LINKCALLBACKS\"][%r] not found or can not be used' % callback)\n        pass\n    else:\n        if Verbose:\n            print('_call_linker_cb: env[\"LINKCALLBACKS\"][%r] found' % callback)\n            print('_call_linker_cb: env[\"LINKCALLBACKS\"][%r]=%r' % (callback, cbfun))\n        if(isinstance(cbfun, collections.Callable)):\n            if Verbose:\n                print('_call_linker_cb: env[\"LINKCALLBACKS\"][%r] is callable' % callback)\n            result = cbfun(env, *args)\n    return result", "response": "Calls the callback in the environment and returns the result of the callback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting list with pairs of nodes to list with pairs of node paths ( Used mainly for debugging.", "response": "def StringizeLibSymlinks(symlinks):\n    \"\"\"Converts list with pairs of nodes to list with pairs of node paths\n    (strings). Used mainly for debugging.\"\"\"\n    if SCons.Util.is_List(symlinks):\n        try:\n            return [ (k.get_path(), v.get_path()) for k,v in symlinks ]\n        except (TypeError, ValueError):\n            return symlinks\n    else:\n        return symlinks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemitting symlinks to the target directory of the library.", "response": "def EmitLibSymlinks(env, symlinks, libnode, **kw):\n    \"\"\"Used by emitters to handle (shared/versioned) library symlinks\"\"\"\n    Verbose = False\n\n    # nodes involved in process... all symlinks + library\n    nodes = list(set([ x for x,y in symlinks ] + [libnode]))\n\n    clean_targets = kw.get('clean_targets', [])\n    if not SCons.Util.is_List(clean_targets):\n        clean_targets = [ clean_targets ]\n\n    for link, linktgt in symlinks:\n        env.SideEffect(link, linktgt)\n        if(Verbose):\n            print(\"EmitLibSymlinks: SideEffect(%r,%r)\" % (link.get_path(), linktgt.get_path()))\n        clean_list = [x for x in nodes if x != linktgt]\n        env.Clean(list(set([linktgt] + clean_targets)), clean_list)\n        if(Verbose):\n            print(\"EmitLibSymlinks: Clean(%r,%r)\" % (linktgt.get_path(), [x.get_path() for x in clean_list]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef CreateLibSymlinks(env, symlinks):\n\n    Verbose = False\n    for link, linktgt in symlinks:\n        linktgt = link.get_dir().rel_path(linktgt)\n        link = link.get_path()\n        if(Verbose):\n            print(\"CreateLibSymlinks: preparing to add symlink %r -> %r\" % (link, linktgt))\n        # Delete the (previously created) symlink if exists. Let only symlinks\n        # to be deleted to prevent accidental deletion of source files...\n        if env.fs.islink(link):\n            env.fs.unlink(link)\n            if(Verbose):\n                print(\"CreateLibSymlinks: removed old symlink %r\" % link)\n        # If a file or directory exists with the same name as link, an OSError\n        # will be thrown, which should be enough, I think.\n        env.fs.symlink(linktgt, link)\n        if(Verbose):\n            print(\"CreateLibSymlinks: add symlink %r -> %r\" % (link, linktgt))\n    return 0", "response": "Physically creates symlinks. The symlinks argument must be a list in\n    form [ (link, linktarget), ... ], where link and linktarget are SCons\n    nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Jar builder for the given environment.", "response": "def CreateJarBuilder(env):\n    \"\"\"The Jar builder expects a list of class files\n    which it can package into a jar file.\n\n    The jar tool provides an interface for passing other types\n    of java files such as .java, directories or swig interfaces\n    and will build them to class files in which it can package\n    into the jar.\n    \"\"\"\n    try:\n        java_jar = env['BUILDERS']['JarFile']\n    except KeyError:\n        fs = SCons.Node.FS.get_default_fs()\n        jar_com = SCons.Action.Action('$JARCOM', '$JARCOMSTR')\n        java_jar = SCons.Builder.Builder(action = jar_com,\n                                         suffix = '$JARSUFFIX',\n                                         src_suffix = '$JAVACLASSSUFFIX',\n                                         src_builder = 'JavaClassFile',\n                                         source_factory = fs.Entry)\n        env['BUILDERS']['JarFile'] = java_jar\n    return java_jar"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_builder(self, env):\n        builder = getattr(env, self.__name__)\n\n        self.initializer.apply_tools(env)\n\n        builder = getattr(env, self.__name__)\n        if builder is self:\n            # There was no Builder added, which means no valid Tool\n            # for this name was found (or possibly there's a mismatch\n            # between the name we were called by and the Builder name\n            # added by the Tool module).\n            return None\n\n        self.initializer.remove_methods(env)\n\n        return builder", "response": "Returns the appropriate real Builder for this method name\n        after having the associated ToolInitializer object apply\n            the appropriate Tool module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the methods that were added by the tool initialization environment so we no longer copy and re - bind them when the environment gets cloned.", "response": "def remove_methods(self, env):\n        \"\"\"\n        Removes the methods that were added by the tool initialization\n        so we no longer copy and re-bind them when the construction\n        environment gets cloned.\n        \"\"\"\n        for method in list(self.methods.values()):\n            env.RemoveMethod(method)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies the tools to the construction environment.", "response": "def apply_tools(self, env):\n        \"\"\"\n        Searches the list of associated Tool modules for one that\n        exists, and applies that to the construction environment.\n        \"\"\"\n        for t in self.tools:\n            tool = SCons.Tool.Tool(t)\n            if tool.exists(env):\n                env.Tool(tool)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_contents_entry(node):\n    try:\n        node = node.disambiguate(must_exist=1)\n    except SCons.Errors.UserError:\n        # There was nothing on disk with which to disambiguate\n        # this entry.  Leave it as an Entry, but return a null\n        # string so calls to get_contents() in emitters and the\n        # like (e.g. in qt.py) don't have to disambiguate by hand\n        # or catch the exception.\n        return ''\n    else:\n        return _get_contents_map[node._func_get_contents](node)", "response": "Fetch the contents of the entry. Returns the exact binary\n    contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns content signatures and names of all our children separated by new - lines. Ensure that the nodes are sorted.", "response": "def get_contents_dir(node):\n    \"\"\"Return content signatures and names of all our children\n    separated by new-lines. Ensure that the nodes are sorted.\"\"\"\n    contents = []\n    for n in sorted(node.children(), key=lambda t: t.name):\n        contents.append('%s %s\\n' % (n.get_csig(), n.name))\n    return ''.join(contents)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_build_env(self):\n        try:\n            return self._memo['get_build_env']\n        except KeyError:\n            pass\n        result = self.get_executor().get_build_env()\n        self._memo['get_build_env'] = result\n        return result", "response": "Fetch the appropriate Environment to build this node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_executor(self, create=1):\n        try:\n            executor = self.executor\n        except AttributeError:\n            if not create:\n                raise\n            try:\n                act = self.builder.action\n            except AttributeError:\n                executor = SCons.Executor.Null(targets=[self])\n            else:\n                executor = SCons.Executor.Executor(act,\n                                                   self.env or self.builder.env,\n                                                   [self.builder.overrides],\n                                                   [self],\n                                                   self.sources)\n            self.executor = executor\n        return executor", "response": "Fetch the action executor for this node. Create one if there isn t already one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlet the executor clean up any cached information.", "response": "def executor_cleanup(self):\n        \"\"\"Let the executor clean up any cached information.\"\"\"\n        try:\n            executor = self.get_executor(create=None)\n        except AttributeError:\n            pass\n        else:\n            if executor is not None:\n                executor.cleanup()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare(self):\n        if self.depends is not None:\n            for d in self.depends:\n                if d.missing():\n                    msg = \"Explicit dependency `%s' not found, needed by target `%s'.\"\n                    raise SCons.Errors.StopError(msg % (d, self))\n        if self.implicit is not None:\n            for i in self.implicit:\n                if i.missing():\n                    msg = \"Implicit dependency `%s' not found, needed by target `%s'.\"\n                    raise SCons.Errors.StopError(msg % (i, self))\n        self.binfo = self.get_binfo()", "response": "This method is called by the Taskmaster to prepare the child node for the build. This method is called by the Taskmaster to prepare the child Node to be built."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build(self, **kw):\n        try:\n            self.get_executor()(self, **kw)\n        except SCons.Errors.BuildError as e:\n            e.node = self\n            raise", "response": "Actually build the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef built(self):\n\n        # Clear the implicit dependency caches of any Nodes\n        # waiting for this Node to be built.\n        for parent in self.waiting_parents:\n            parent.implicit = None\n\n        self.clear()\n\n        if self.pseudo:\n            if self.exists():\n                raise SCons.Errors.UserError(\"Pseudo target \" + str(self) + \" must not exist\")\n        else:\n            if not self.exists() and do_store_info:\n                SCons.Warnings.warn(SCons.Warnings.TargetNotBuiltWarning,\n                                    \"Cannot find target \" + str(self) + \" after building\")\n        self.ninfo.update(self)", "response": "Called just after this node is successfully built."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls just after this node has been visited.", "response": "def visited(self):\n        \"\"\"Called just after this node has been visited (with or\n        without a build).\"\"\"\n        try:\n            binfo = self.binfo\n        except AttributeError:\n            # Apparently this node doesn't need build info, so\n            # don't bother calculating or storing it.\n            pass\n        else:\n            self.ninfo.update(self)\n            SCons.Node.store_info_map[self.store_info](self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_to_waiting_parents(self, node):\n        wp = self.waiting_parents\n        if node in wp:\n            return 0\n        wp.add(node)\n        return 1", "response": "Adds a node to our waiting parents list. Returns 0 if we don t add a unique waiting parent 0 if we don t add a unique waiting parent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_builder(self):\n        try:\n            b = self.builder\n        except AttributeError:\n            # There was no explicit builder for this Node, so initialize\n            # the self.builder attribute to None now.\n            b = self.builder = None\n        return b is not None", "response": "Return whether this Node has a builder attribute or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_implicit_deps(self, env, initial_scanner, path_func, kw = {}):\n        nodes = [self]\n        seen = set(nodes)\n        dependencies = []\n        path_memo = {}\n\n        root_node_scanner = self._get_scanner(env, initial_scanner, None, kw)\n\n        while nodes:\n            node = nodes.pop(0)\n\n            scanner = node._get_scanner(env, initial_scanner, root_node_scanner, kw)\n            if not scanner:\n                continue\n\n            try:\n                path = path_memo[scanner]\n            except KeyError:\n                path = path_func(scanner)\n                path_memo[scanner] = path\n\n            included_deps = [x for x in node.get_found_includes(env, scanner, path) if x not in seen]\n            if included_deps:\n                dependencies.extend(included_deps)\n                seen.update(included_deps)\n                nodes.extend(scanner.recurse_nodes(included_deps))\n\n        return dependencies", "response": "Return a list of implicit dependencies for this node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch the source scanner for the specified node.", "response": "def get_source_scanner(self, node):\n        \"\"\"Fetch the source scanner for the specified node\n\n        NOTE:  \"self\" is the target being built, \"node\" is\n        the source file for which we want to fetch the scanner.\n\n        Implies self.has_builder() is true; again, expect to only be\n        called from locations where this is already verified.\n\n        This function may be called very often; it attempts to cache\n        the scanner found to improve performance.\n        \"\"\"\n        scanner = None\n        try:\n            scanner = self.builder.source_scanner\n        except AttributeError:\n            pass\n        if not scanner:\n            # The builder didn't have an explicit scanner, so go look up\n            # a scanner from env['SCANNERS'] based on the node's scanner\n            # key (usually the file extension).\n            scanner = self.get_env_scanner(self.get_build_env())\n        if scanner:\n            scanner = scanner.select(node)\n        return scanner"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scan(self):\n        # Don't bother scanning non-derived files, because we don't\n        # care what their dependencies are.\n        # Don't scan again, if we already have scanned.\n        if self.implicit is not None:\n            return\n        self.implicit = []\n        self.implicit_set = set()\n        self._children_reset()\n        if not self.has_builder():\n            return\n\n        build_env = self.get_build_env()\n        executor = self.get_executor()\n\n        # Here's where we implement --implicit-cache.\n        if implicit_cache and not implicit_deps_changed:\n            implicit = self.get_stored_implicit()\n            if implicit is not None:\n                # We now add the implicit dependencies returned from the\n                # stored .sconsign entry to have already been converted\n                # to Nodes for us.  (We used to run them through a\n                # source_factory function here.)\n\n                # Update all of the targets with them.  This\n                # essentially short-circuits an N*M scan of the\n                # sources for each individual target, which is a hell\n                # of a lot more efficient.\n                for tgt in executor.get_all_targets():\n                    tgt.add_to_implicit(implicit)\n\n                if implicit_deps_unchanged or self.is_up_to_date():\n                    return\n                # one of this node's sources has changed,\n                # so we must recalculate the implicit deps for all targets\n                for tgt in executor.get_all_targets():\n                    tgt.implicit = []\n                    tgt.implicit_set = set()\n\n        # Have the executor scan the sources.\n        executor.scan_sources(self.builder.source_scanner)\n\n        # If there's a target scanner, have the executor scan the target\n        # node itself and associated targets that might be built.\n        scanner = self.get_target_scanner()\n        if scanner:\n            executor.scan_targets(scanner)", "response": "Scan this node s dependents for implicit dependencies."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch a build information for a node.", "response": "def get_binfo(self):\n        \"\"\"\n        Fetch a node's build information.\n\n        node - the node whose sources will be collected\n        cache - alternate node to use for the signature cache\n        returns - the build signature\n\n        This no longer handles the recursive descent of the\n        node's children's signatures.  We expect that they're\n        already built and updated by someone else, if that's\n        what's wanted.\n        \"\"\"\n        try:\n            return self.binfo\n        except AttributeError:\n            pass\n\n        binfo = self.new_binfo()\n        self.binfo = binfo\n\n        executor = self.get_executor()\n        ignore_set = self.ignore_set\n\n        if self.has_builder():\n            binfo.bact = str(executor)\n            binfo.bactsig = SCons.Util.MD5signature(executor.get_contents())\n\n        if self._specific_sources:\n            sources = [ s for s in self.sources if not s in ignore_set]\n\n        else:\n            sources = executor.get_unignored_sources(self, self.ignore)\n\n        seen = set()\n        binfo.bsources = [s for s in sources if s not in seen and not seen.add(s)]\n        binfo.bsourcesigs = [s.get_ninfo() for s in binfo.bsources]\n\n\n        binfo.bdepends = self.depends\n        binfo.bdependsigs = [d.get_ninfo() for d in self.depends if d not in ignore_set]\n\n        binfo.bimplicit = self.implicit or []\n        binfo.bimplicitsigs = [i.get_ninfo() for i in binfo.bimplicit if i not in ignore_set]\n\n\n        return binfo"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a dependency to the current node.", "response": "def add_dependency(self, depend):\n        \"\"\"Adds dependencies.\"\"\"\n        try:\n            self._add_child(self.depends, self.depends_set, depend)\n        except TypeError as e:\n            e = e.args[0]\n            if SCons.Util.is_List(e):\n                s = list(map(str, e))\n            else:\n                s = str(e)\n            raise SCons.Errors.UserError(\"attempted to add a non-Node dependency to %s:\\n\\t%s is a %s, not a Node\" % (str(self), s, type(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_prerequisite(self, prerequisite):\n        if self.prerequisites is None:\n            self.prerequisites = SCons.Util.UniqueList()\n        self.prerequisites.extend(prerequisite)\n        self._children_reset()", "response": "Adds a prerequisite to the set of prerequisites."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd dependencies to ignore.", "response": "def add_ignore(self, depend):\n        \"\"\"Adds dependencies to ignore.\"\"\"\n        try:\n            self._add_child(self.ignore, self.ignore_set, depend)\n        except TypeError as e:\n            e = e.args[0]\n            if SCons.Util.is_List(e):\n                s = list(map(str, e))\n            else:\n                s = str(e)\n            raise SCons.Errors.UserError(\"attempted to ignore a non-Node dependency of %s:\\n\\t%s is a %s, not a Node\" % (str(self), s, type(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a source to the set of sources.", "response": "def add_source(self, source):\n        \"\"\"Adds sources.\"\"\"\n        if self._specific_sources:\n            return\n        try:\n            self._add_child(self.sources, self.sources_set, source)\n        except TypeError as e:\n            e = e.args[0]\n            if SCons.Util.is_List(e):\n                s = list(map(str, e))\n            else:\n                s = str(e)\n            raise SCons.Errors.UserError(\"attempted to add a non-Node as source of %s:\\n\\t%s is a %s, not a Node\" % (str(self), s, type(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_child(self, collection, set, child):\n        added = None\n        for c in child:\n            if c not in set:\n                set.add(c)\n                collection.append(c)\n                added = 1\n        if added:\n            self._children_reset()", "response": "Adds a child to the collection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_children(self, scan=1):\n        if scan:\n            self.scan()\n\n        # The return list may contain duplicate Nodes, especially in\n        # source trees where there are a lot of repeated #includes\n        # of a tangle of .h files.  Profiling shows, however, that\n        # eliminating the duplicates with a brute-force approach that\n        # preserves the order (that is, something like:\n        #\n        #       u = []\n        #       for n in list:\n        #           if n not in u:\n        #               u.append(n)\"\n        #\n        # takes more cycles than just letting the underlying methods\n        # hand back cached values if a Node's information is requested\n        # multiple times.  (Other methods of removing duplicates, like\n        # using dictionary keys, lose the order, and the only ordered\n        # dictionary patterns I found all ended up using \"not in\"\n        # internally anyway...)\n        return list(chain.from_iterable([_f for _f in [self.sources, self.depends, self.implicit] if _f]))", "response": "Return a list of all the direct children of this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Tag(self, key, value):\n        if not self._tags:\n            self._tags = {}\n        self._tags[key] = value", "response": "Add a user - defined tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the node has been changed.", "response": "def changed(self, node=None, allowcache=False):\n        \"\"\"\n        Returns if the node is up-to-date with respect to the BuildInfo\n        stored last time it was built.  The default behavior is to compare\n        it against our own previously stored BuildInfo, but the stored\n        BuildInfo from another Node (typically one in a Repository)\n        can be used instead.\n\n        Note that we now *always* check every dependency.  We used to\n        short-circuit the check by returning as soon as we detected\n        any difference, but we now rely on checking every dependency\n        to make sure that any necessary Node information (for example,\n        the content signature of an #included .h file) is updated.\n\n        The allowcache option was added for supporting the early\n        release of the executor/builder structures, right after\n        a File target was built. When set to true, the return\n        value of this changed method gets cached for File nodes.\n        Like this, the executor isn't needed any longer for subsequent\n        calls to changed().\n\n        @see: FS.File.changed(), FS.File.release_target_info()\n        \"\"\"\n        t = 0\n        if t: Trace('changed(%s [%s], %s)' % (self, classname(self), node))\n        if node is None:\n            node = self\n\n        result = False\n\n        bi = node.get_stored_info().binfo\n        then = bi.bsourcesigs + bi.bdependsigs + bi.bimplicitsigs\n        children = self.children()\n\n        diff = len(children) - len(then)\n        if diff:\n            # The old and new dependency lists are different lengths.\n            # This always indicates that the Node must be rebuilt.\n            # We also extend the old dependency list with enough None\n            # entries to equal the new dependency list, for the benefit\n            # of the loop below that updates node information.\n            then.extend([None] * diff)\n            if t: Trace(': old %s new %s' % (len(then), len(children)))\n            result = True\n\n        for child, prev_ni in zip(children, then):\n            if _decider_map[child.changed_since_last_build](child, self, prev_ni):\n                if t: Trace(': %s changed' % child)\n                result = True\n\n        contents = self.get_executor().get_contents()\n        if self.has_builder():\n            import SCons.Util\n            newsig = SCons.Util.MD5signature(contents)\n            if bi.bactsig != newsig:\n                if t: Trace(': bactsig %s != newsig %s' % (bi.bactsig, newsig))\n                result = True\n\n        if not result:\n            if t: Trace(': up to date')\n\n        if t: Trace('\\n')\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef children_are_up_to_date(self):\n        # Allow the children to calculate their signatures.\n        self.binfo = self.get_binfo()\n        if self.always_build:\n            return None\n        state = 0\n        for kid in self.children(None):\n            s = kid.get_state()\n            if s and (not state or s > state):\n                state = s\n        return (state == 0 or state == SCons.Node.up_to_date)", "response": "Alternate check for whether the children of this node are up - to - date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a text representation suitable for displaying to the user of the include tree for the sources of this node.", "response": "def render_include_tree(self):\n        \"\"\"\n        Return a text representation, suitable for displaying to the\n        user, of the include tree for the sources of this node.\n        \"\"\"\n        if self.is_derived():\n            env = self.get_build_env()\n            if env:\n                for s in self.sources:\n                    scanner = self.get_source_scanner(s)\n                    if scanner:\n                        path = self.get_build_scanner_path(scanner)\n                    else:\n                        path = None\n                    def f(node, env=env, scanner=scanner, path=path):\n                        return node.get_found_includes(env, scanner, path)\n                    return SCons.Util.render_tree(s, f, 1)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the next node in the tree.", "response": "def get_next(self):\n        \"\"\"Return the next node for this walk of the tree.\n\n        This function is intentionally iterative, not recursive,\n        to sidestep any issues of stack size limitations.\n        \"\"\"\n\n        while self.stack:\n            if self.stack[-1].wkids:\n                node = self.stack[-1].wkids.pop(0)\n                if not self.stack[-1].wkids:\n                    self.stack[-1].wkids = None\n                if node in self.history:\n                    self.cycle_func(node, self.stack)\n                else:\n                    node.wkids = copy.copy(self.kids_func(node, self.stack[-1]))\n                    self.stack.append(node)\n                    self.history[node] = None\n            else:\n                node = self.stack.pop()\n                del self.history[node]\n                if node:\n                    if self.stack:\n                        parent = self.stack[-1]\n                    else:\n                        parent = None\n                    self.eval_func(node, parent)\n                return node\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign_report(self, device_id, root, data, **kwargs):\n\n        AuthProvider.VerifyRoot(root)\n\n        if root != AuthProvider.NoKey:\n            raise NotFoundError('unsupported root key in BasicAuthProvider', root_key=root)\n\n        result = bytearray(hashlib.sha256(data).digest())\n        return {'signature': result, 'root_key': root}", "response": "Sign a buffer of report data on behalf of a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies a buffer of report data on behalf of a device.", "response": "def verify_report(self, device_id, root, data, signature, **kwargs):\n        \"\"\"Verify a buffer of report data on behalf of a device.\n\n        Args:\n            device_id (int): The id of the device that we should encrypt for\n            root (int): The root key type that should be used to generate the report\n            data (bytearray): The data that we should verify\n            signature (bytearray): The signature attached to data that we should verify\n            **kwargs: There are additional specific keyword args that are required\n                depending on the root key used.  Typically, you must specify\n                - report_id (int): The report id\n                - sent_timestamp (int): The sent timestamp of the report\n\n                These two bits of information are used to construct the per report\n                signing and encryption key from the specific root key type.\n\n        Returns:\n            dict: The result of the verification process must always be a bool under the\n                'verified' key, however additional keys may be present depending on the\n                signature method used.\n\n        Raises:\n            NotFoundError: If the auth provider is not able to verify the data due to\n                an error.  If the data is simply not valid, then the function returns\n                normally.\n        \"\"\"\n\n        AuthProvider.VerifyRoot(root)\n\n        if root != AuthProvider.NoKey:\n            raise NotFoundError('unsupported root key in BasicAuthProvider', root_key=root)\n\n        result = bytearray(hashlib.sha256(data).digest())\n\n        if len(signature) == 0:\n            verified = False\n        elif len(signature) > len(result):\n            verified = False\n        elif len(signature) < len(result):\n            trunc_result = result[:len(signature)]\n            verified = hmac.compare_digest(signature, trunc_result)\n        else:\n            verified = hmac.compare_digest(signature, result)\n\n        return {'verified': verified, 'bit_length': 8*len(signature)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, sensor_graph, scope_stack):\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        trigger_stream, trigger_cond = parent.trigger_chain()\n        rpc_const = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n        rpc_val = (self.slot_id.address << 16) | self.rpc_id\n\n        stream = self.stream\n        if stream is None:\n            stream = alloc.allocate_stream(DataStream.UnbufferedType)\n\n        sensor_graph.add_node(u\"({} {} && {} always) => {} using call_rpc\".format(trigger_stream, trigger_cond, rpc_const, stream))\n        sensor_graph.add_constant(rpc_const, rpc_val)", "response": "Execute this statement on the sensor_graph given the current scope tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timeout_thread_handler(timeout, stop_event):\n\n    stop_happened = stop_event.wait(timeout)\n    if stop_happened is False:\n        print(\"Killing program due to %f second timeout\" % timeout)\n\n    os._exit(2)", "response": "A background thread to kill the process if it takes too long."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the argument parser for iotile.", "response": "def create_parser():\n    \"\"\"Create the argument parser for iotile.\"\"\"\n    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)\n\n    parser.add_argument('-v', '--verbose', action=\"count\", default=0, help=\"Increase logging level (goes error, warn, info, debug)\")\n    parser.add_argument('-l', '--logfile', help=\"The file where we should log all logging messages\")\n    parser.add_argument('-i', '--include', action=\"append\", default=[], help=\"Only include the specified loggers\")\n    parser.add_argument('-e', '--exclude', action=\"append\", default=[], help=\"Exclude the specified loggers, including all others\")\n    parser.add_argument('-q', '--quit', action=\"store_true\", help=\"Do not spawn a shell after executing any commands\")\n    parser.add_argument('-t', '--timeout', type=float, help=\"Do not allow this process to run for more than a specified number of seconds.\")\n    parser.add_argument('commands', nargs=argparse.REMAINDER, help=\"The command(s) to execute\")\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_global_args(argv):\n\n    parser = create_parser()\n    args = parser.parse_args(argv)\n\n    should_log = args.include or args.exclude or (args.verbose > 0)\n    verbosity = args.verbose\n\n    root = logging.getLogger()\n\n    if should_log:\n        formatter = logging.Formatter('%(asctime)s.%(msecs)03d %(levelname).3s %(name)s %(message)s',\n                                      '%y-%m-%d %H:%M:%S')\n        if args.logfile:\n            handler = logging.FileHandler(args.logfile)\n        else:\n            handler = logging.StreamHandler()\n\n        handler.setFormatter(formatter)\n\n        if args.include and args.exclude:\n            print(\"You cannot combine whitelisted (-i) and blacklisted (-e) loggers, you must use one or the other.\")\n            sys.exit(1)\n\n        loglevels = [logging.ERROR, logging.WARNING, logging.INFO, logging.DEBUG]\n        if verbosity >= len(loglevels):\n            verbosity = len(loglevels) - 1\n\n        level = loglevels[verbosity]\n\n        if args.include:\n            for name in args.include:\n                logger = logging.getLogger(name)\n                logger.setLevel(level)\n                logger.addHandler(handler)\n\n            root.addHandler(logging.NullHandler())\n        else:\n            # Disable propagation of log events from disabled loggers\n            for name in args.exclude:\n                logger = logging.getLogger(name)\n                logger.disabled = True\n\n            root.setLevel(level)\n            root.addHandler(handler)\n    else:\n        root.addHandler(logging.NullHandler())\n\n    return args", "response": "Parse all global iotile tool arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the iotile shell tool. You can optionally pass the arguments that should be run in the argv parameter. If nothing is passed, the args are pulled from sys.argv. The return value of this function is the return value of the shell command.", "response": "def main(argv=None):\n    \"\"\"Run the iotile shell tool.\n\n    You can optionally pass the arguments that should be run\n    in the argv parameter.  If nothing is passed, the args\n    are pulled from sys.argv.\n\n    The return value of this function is the return value\n    of the shell command.\n    \"\"\"\n\n    if argv is None:\n        argv = sys.argv[1:]\n\n    args = parse_global_args(argv)\n\n    type_system.interactive = True\n    line = args.commands\n\n    timeout_thread = None\n    timeout_stop_event = threading.Event()\n\n    if args.timeout:\n        timeout_thread = threading.Thread(target=timeout_thread_handler, args=(args.timeout, timeout_stop_event))\n        timeout_thread.daemon = True\n        timeout_thread.start()\n\n    shell = HierarchicalShell('iotile')\n\n    shell.root_add(\"registry\", \"iotile.core.dev.annotated_registry,registry\")\n    shell.root_add(\"config\", \"iotile.core.dev.config,ConfigManager\")\n    shell.root_add('hw', \"iotile.core.hw.hwmanager,HardwareManager\")\n\n    reg = ComponentRegistry()\n    plugins = reg.list_plugins()\n    for key, val in plugins.items():\n        shell.root_add(key, val)\n\n    finished = False\n\n    try:\n        if len(line) > 0:\n            finished = shell.invoke(line)\n    except IOTileException as exc:\n        print(exc.format())\n        # if the command passed on the command line fails, then we should\n        # just exit rather than drop the user into a shell.\n        SharedLoop.stop()\n        return 1\n    except Exception:  # pylint:disable=broad-except; We need to make sure we always call cmdstream.do_final_close()\n        # Catch all exceptions because otherwise we won't properly close cmdstreams\n        # since the program will be said to except 'abnormally'\n        traceback.print_exc()\n        SharedLoop.stop()\n        return 1\n\n    # If the user tells us to never spawn a shell, make sure we don't\n    # Also, if we finished our command and there is no context, quit now\n    if args.quit or finished:\n        SharedLoop.stop()\n        return 0\n\n    setup_completion(shell)\n\n    # We ended the initial command with a context, start a shell\n    try:\n        while True:\n            try:\n                linebuf = input(\"(%s) \" % shell.context_name())\n\n                # Skip comments automatically\n                if len(linebuf) > 0 and linebuf[0] == '#':\n                    continue\n            except KeyboardInterrupt:\n                print(\"\")\n                continue\n\n            # Catch exception outside the loop so we stop invoking submethods if a parent\n            # fails because then the context and results would be unpredictable\n            try:\n                finished = shell.invoke_string(linebuf)\n            except KeyboardInterrupt:\n                print(\"\")\n                if timeout_stop_event.is_set():\n                    break\n            except IOTileException as exc:\n                print(exc.format())\n            except Exception:  #pylint:disable=broad-except;\n                # We want to make sure the iotile tool never crashes when in interactive shell mode\n                traceback.print_exc()\n\n            if shell.finished():\n                break\n\n    # Make sure to catch ^C and ^D so that we can cleanly dispose of subprocess resources if\n    # there are any.\n    except EOFError:\n        print(\"\")\n    except KeyboardInterrupt:\n        print(\"\")\n    finally:\n        # Make sure we close any open CMDStream communication channels so that we don't lockup at exit\n        SharedLoop.stop()\n\n    # Make sure we cleanly join our timeout thread before exiting\n    if timeout_thread is not None:\n        timeout_stop_event.set()\n        timeout_thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_help(self, argv):\n        if argv[1:]:\n            for arg in argv[1:]:\n                if self._do_one_help(arg):\n                    break\n        else:\n            # If bare 'help' is called, print this class's doc\n            # string (if it has one).\n            doc = self._doc_to_help(self.__class__)\n            if doc:\n                sys.stdout.write(doc + '\\n')\n                sys.stdout.flush()", "response": "Prints help for the specified COMMAND."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_shell(self, argv):\n        import subprocess\n        argv = argv[1:]\n        if not argv:\n            argv = os.environ[self.shell_variable]\n        try:\n            # Per \"[Python-Dev] subprocess insufficiently platform-independent?\"\n            # http://mail.python.org/pipermail/python-dev/2008-August/081979.html \"+\n            # Doing the right thing with an argument list currently\n            # requires different shell= values on Windows and Linux.\n            p = subprocess.Popen(argv, shell=(sys.platform=='win32'))\n        except EnvironmentError as e:\n            sys.stderr.write('scons: %s: %s\\n' % (argv[0], e.strerror))\n        else:\n            p.wait()", "response": "Execute COMMANDLINE in a subshell."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(args):\n\n    # Do some sleuthing work to find scons if it's not installed into an importable\n    # place, as it is usually not.\n    scons_path = \"Error\"\n    try:\n        scons_path = resource_path('scons-local-{}'.format(SCONS_VERSION), expect='folder')\n        sys.path.insert(0, scons_path)\n        import SCons.Script\n    except ImportError:\n        raise BuildError(\"Couldn't find internal scons packaged w/ iotile-build. This is a bug that should be reported\",\n                         scons_path=scons_path)\n\n    site_path = resource_path('site_scons', expect='folder')\n\n    all_args = ['iotile', '--site-dir=%s' % site_path, '-Q']\n    sys.argv = all_args + list(args)\n    SCons.Script.main()", "response": "Invoke the scons build system from the current directory exactly as if\n    the scons tool had been invoked."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge_dicts(a, b):\n\n    for key in b:\n        if key in a:\n            if isinstance(a[key], dict) and isinstance(b[key], dict):\n                merge_dicts(a[key], b[key])\n            else:\n                a[key] = b[key]\n        else:\n            a[key] = b[key]\n\n    return a", "response": "merges a into b"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef archs(self, as_list=False):\n\n        archs = self.arch_list().split('/')\n\n        if as_list:\n            return archs\n\n        return set(archs)", "response": "Returns a list of all of the architectures used in this target."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retarget(self, remove=[], add=[]):\n\n        archs = self.arch_list().split('/')\n\n        for r in remove:\n            if r in archs:\n                archs.remove(r)\n\n        archs.extend(add)\n\n        archstr = \"/\".join(archs)\n        return self.family.find(archstr, self.module_name())", "response": "Return a TargetSettings object for the same module but with some of the architectures\n        removed and others added."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_dirs(self):\n\n        arch = self.arch_name()\n\n        build_path = os.path.join('build', arch)\n        output = os.path.join('build', 'output')\n        test = os.path.join('build', 'test', arch)\n\n        return {'build': build_path, 'output': output, 'test': test}", "response": "Return the build directory hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the value of the given property for this chip using the default value if not found.", "response": "def property(self, name, default=MISSING):\n        \"\"\"Get the value of the given property for this chip, using the default\n        value if not found and one is provided.  If not found and default is None,\n        raise an Exception.\n        \"\"\"\n\n        if name in self.settings:\n            return self.settings[name]\n\n        if default is not MISSING:\n            return default\n\n        raise ArgumentError(\"property %s not found for target '%s' and no default given\" % (name, self.name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the value of all properties whose name ends with suffix and join them together into a list.", "response": "def combined_properties(self, suffix):\n        \"\"\"Get the value of all properties whose name ends with suffix and join them\n        together into a list.\n        \"\"\"\n\n        props = [y for x, y in self.settings.items() if x.endswith(suffix)]\n        properties = itertools.chain(*props)\n\n        processed_props = [x for x in properties]\n        return processed_props"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef includes(self):\n\n        incs = self.combined_properties('includes')\n\n        processed_incs = []\n        for prop in incs:\n            if isinstance(prop, str):\n                processed_incs.append(prop)\n            else:\n                processed_incs.append(os.path.join(*prop))\n\n        # All include paths are relative to base directory of the\n        fullpaths = [os.path.normpath(os.path.join('.', x)) for x in processed_incs]\n        fullpaths.append(os.path.normpath(os.path.abspath(self.build_dirs()['build'])))\n\n        return fullpaths", "response": "Return all of the include directories for this chip as a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the initial 1 2... N architectures as a list of strings", "response": "def arch_prefixes(self):\n        \"\"\"Return the initial 1, 2, ..., N architectures as a prefix list\n\n        For arch1/arch2/arch3, this returns\n        [arch1],[arch1/arch2],[arch1/arch2/arch3]\n        \"\"\"\n\n        archs = self.archs(as_list=True)\n        prefixes = []\n\n        for i in range(1, len(archs)+1):\n            prefixes.append(archs[:i])\n\n        return prefixes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a dependency from build / deps/<unique_id >.", "response": "def _load_dependency(cls, tile, dep, family):\n        \"\"\"Load a dependency from build/deps/<unique_id>.\"\"\"\n\n        depname = dep['unique_id']\n        depdir = os.path.join(tile.folder, 'build', 'deps', depname)\n        deppath = os.path.join(depdir, 'module_settings.json')\n\n        if not os.path.exists(deppath):\n            raise BuildError(\"Could not find dependency\", dependency=dep)\n\n        try:\n            deptile = IOTile(depdir)\n        except DataError as exc:\n            raise BuildError(\"Could not find dependency\", dependency=dep, error=exc)\n\n        merge_dicts(family['architectures'], deptile.architectures.copy())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef targets(self, module):\n\n        if module not in self.module_targets:\n            raise BuildError(\"Could not find module in targets()\", module=module)\n\n        return [self.find(x, module) for x in self.module_targets[module]]", "response": "Find the targets for a given module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling func once for all of the targets of this module.", "response": "def for_all_targets(self, module, func, filter_func=None):\n        \"\"\"Call func once for all of the targets of this module.\"\"\"\n\n        for target in self.targets(module):\n            if filter_func is None or filter_func(target):\n                func(target)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_target(self, target):\n\n        archs = target.split('/')\n\n        for arch in archs:\n            if not arch in self.archs:\n                return False\n\n        return True", "response": "Make sure that the specified target only contains architectures that we know about."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_target(self, target, module=None):\n\n        mod = ModuleSettings({}, {})\n        if not self.validate_target(target):\n            raise ArgumentError(\"Target %s is invalid, check to make sure every architecture in it is defined\" % target)\n\n        if module is not None:\n            if module not in self.modules:\n                raise ArgumentError(\"Unknown module name passed: %s\" % module)\n\n            mod = self.modules[module]\n\n        settings = {}\n        archs = target.split('/')\n\n        for arch in archs:\n            arch_settings = deepcopy(self.archs[arch])\n\n            if arch in mod.overlays:\n                arch_settings = merge_dicts(arch_settings, mod.overlays[arch])\n\n            # Allow this architecture to overlay previous architectures as well\n            if \"overlays\" in arch_settings:\n                for arch2 in archs:\n                    if arch2 == arch:\n                        break\n\n                    if arch2 in arch_settings[\"overlays\"]:\n                        arch_settings = merge_dicts(arch_settings, arch_settings[\"overlays\"][arch2])\n\n                del arch_settings[\"overlays\"]\n\n            # Allow the module to overlay included architectures as well\n            if \"overlays\" in mod.settings and arch in mod.settings['overlays']:\n                arch_settings = merge_dicts(arch_settings, mod.settings['overlays'][arch])\n\n            settings = merge_dicts(settings, arch_settings)\n\n        settings = merge_dicts(settings, mod.settings)\n\n        targetname = \"%s:%s\" % (str(module), target)\n\n        return TargetSettings(targetname, settings, self)", "response": "Load a target from the given target string and return a TargetSettings object that encapsulates all of the settings for this target."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads in all of the architectural overlays for this family.", "response": "def _load_architectures(self, family):\n        \"\"\"Load in all of the architectural overlays for this family.  An architecture adds configuration\n        information that is used to build a common set of source code for a particular hardware and situation.\n        They are stackable so that you can specify a chip and a configuration for that chip, for example.\n        \"\"\"\n\n        if \"architectures\" not in family:\n            raise InternalError(\"required architectures key not in build_settings.json for desired family\")\n\n        for key, val in family['architectures'].items():\n            if not isinstance(val, dict):\n                raise InternalError(\"All entries under chip_settings must be dictionaries\")\n\n            self.archs[key] = deepcopy(val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds Builders and construction variables for lex to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for lex to an Environment.\"\"\"\n    c_file, cxx_file = SCons.Tool.createCFileBuilders(env)\n\n    # C\n    c_file.add_action(\".l\", LexAction)\n    c_file.add_emitter(\".l\", lexEmitter)\n\n    c_file.add_action(\".lex\", LexAction)\n    c_file.add_emitter(\".lex\", lexEmitter)\n\n    # Objective-C\n    cxx_file.add_action(\".lm\", LexAction)\n    cxx_file.add_emitter(\".lm\", lexEmitter)\n\n    # C++\n    cxx_file.add_action(\".ll\", LexAction)\n    cxx_file.add_emitter(\".ll\", lexEmitter)\n\n    env[\"LEX\"]      = env.Detect(\"flex\") or \"lex\"\n    env[\"LEXFLAGS\"] = SCons.Util.CLVar(\"\")\n    env[\"LEXCOM\"] = \"$LEX $LEXFLAGS -t $SOURCES > $TARGET\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_to_reset(self, config_vars):\n\n        super(ClockManagerSubsystem, self).clear_to_reset(config_vars)\n\n        self.tick_counters = dict(fast=0, user1=0, user2=0, normal=0)\n\n        self.is_utc = False\n        self.time_offset = 0\n\n        if self.has_rtc and self.stored_offset is not None:\n            self.time_offset = self.stored_offset + self.uptime\n\n        self.uptime = 0\n\n        self.ticks['fast'] = config_vars.get('fast_tick', 0)\n        self.ticks['user1'] = config_vars.get('user_tick_1', 0)\n        self.ticks['user2'] = config_vars.get('user_tick_2', 0)", "response": "Clear all volatile information across a reset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the a tick s interval.", "response": "def set_tick(self, index, interval):\n        \"\"\"Update the a tick's interval.\n\n        Args:\n            index (int): The index of the tick that you want to fetch.\n            interval (int): The number of seconds between ticks.\n                Setting this to 0 will disable the tick.\n\n        Returns:\n            int: An error code.\n        \"\"\"\n\n        name = self.tick_name(index)\n        if name is None:\n            return pack_error(ControllerSubsystem.SENSOR_GRAPH, Error.INVALID_ARRAY_KEY)\n\n        self.ticks[name] = interval\n        return Error.NO_ERROR"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_tick(self, index):\n\n        name = self.tick_name(index)\n        if name is None:\n            return [pack_error(ControllerSubsystem.SENSOR_GRAPH, Error.INVALID_ARRAY_KEY), 0]\n\n        return [Error.NO_ERROR, self.ticks[name]]", "response": "Get a tick s interval in seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the current UTC time or uptime.", "response": "def get_time(self, force_uptime=False):\n        \"\"\"Get the current UTC time or uptime.\n\n        By default, this method will return UTC time if possible and fall back\n        to uptime if not.  If you specify, force_uptime=True, it will always\n        return uptime even if utc time is available.\n\n        Args:\n            force_uptime (bool): Always return uptime, defaults to False.\n\n        Returns:\n            int: The current uptime or encoded utc time.\n        \"\"\"\n\n        if force_uptime:\n            return self.uptime\n\n        time = self.uptime + self.time_offset\n\n        if self.is_utc:\n            time |= (1 << 31)\n\n        return time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsynchronize the clock to UTC time.", "response": "def synchronize_clock(self, offset):\n        \"\"\"Persistently synchronize the clock to UTC time.\n\n        Args:\n            offset (int): The number of seconds since 1/1/2000 00:00Z\n        \"\"\"\n\n        self.time_offset = offset - self.uptime\n        self.is_utc = True\n\n        if self.has_rtc:\n            self.stored_offset = self.time_offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_user_timer(self, index):\n\n        err, tick = self.clock_manager.get_tick(index)\n        return [err, tick]", "response": "Get the current value of a user timer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_user_timer(self, value, index):\n\n        err = self.clock_manager.set_tick(index, value)\n        return [err]", "response": "Set the current value of a user timer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_time_offset(self, offset, is_utc):\n\n        is_utc = bool(is_utc)\n        self.clock_manager.time_offset = offset\n        self.clock_manager.is_utc = is_utc\n\n        return [Error.NO_ERROR]", "response": "Temporarily set the current time offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a d - letter device slug to an integer.", "response": "def device_slug_to_id(slug):\n    \"\"\"Convert a d-- device slug to an integer.\n\n    Args:\n        slug (str): A slug in the format d--XXXX-XXXX-XXXX-XXXX\n\n    Returns:\n        int: The device id as an integer\n\n    Raises:\n        ArgumentError: if there is a malformed slug\n    \"\"\"\n\n    if not isinstance(slug, str):\n        raise ArgumentError(\"Invalid device slug that is not a string\", slug=slug)\n\n    try:\n        device_slug = IOTileDeviceSlug(slug, allow_64bits=False)\n    except ValueError:\n        raise ArgumentError(\"Unable to recognize {} as a device id\".format(slug))\n\n    return device_slug.get_id()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef device_id_to_slug(did):\n\n    try:\n        device_slug = IOTileDeviceSlug(did, allow_64bits=False)\n    except ValueError:\n        raise ArgumentError(\"Unable to recognize {} as a device id\".format(did))\n\n    return str(device_slug)", "response": "Converts a device id into a correct device slug."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fleet_id_to_slug(did):\n\n    try:\n        fleet_slug = IOTileFleetSlug(did)\n    except ValueError:\n        raise ArgumentError(\"Unable to recognize {} as a fleet id\".format(did))\n\n    return str(fleet_slug)", "response": "Converts a fleet id into a correct fleet slug."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_program_files_dir():\n    # Now see if we can look in the registry...\n    val = ''\n    if SCons.Util.can_read_reg:\n        try:\n            # Look for Windows Program Files directory\n            k=SCons.Util.RegOpenKeyEx(SCons.Util.hkey_mod.HKEY_LOCAL_MACHINE,\n                                      'Software\\\\Microsoft\\\\Windows\\\\CurrentVersion')\n            val, tok = SCons.Util.RegQueryValueEx(k, 'ProgramFilesDir')\n        except SCons.Util.RegError:\n            val = ''\n            pass\n\n    if val == '':\n        # A reasonable default if we can't read the registry\n        # (Actually, it's pretty reasonable even if we can :-)\n        val = os.path.join(os.path.dirname(get_system_root()),\"Program Files\")\n\n    return val", "response": "Get the location of the program files directory"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_architecture(arch=None):\n    if arch is None:\n        arch = os.environ.get('PROCESSOR_ARCHITEW6432')\n        if not arch:\n            arch = os.environ.get('PROCESSOR_ARCHITECTURE')\n    return SupportedArchitectureMap.get(arch, ArchDefinition('', ['']))", "response": "Returns the definition for the specified architecture string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate(env):\n    try:\n        bld = env['BUILDERS']['Rpm']\n    except KeyError:\n        bld = RpmBuilder\n        env['BUILDERS']['Rpm'] = bld\n\n    env.SetDefault(RPM          = 'LC_ALL=C rpmbuild')\n    env.SetDefault(RPMFLAGS     = SCons.Util.CLVar('-ta'))\n    env.SetDefault(RPMCOM       = rpmAction)\n    env.SetDefault(RPMSUFFIX    = '.rpm')", "response": "Add Builders and construction variables for rpm to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the next sequence number for a named channel or topic.", "response": "def next_id(self, channel):\n        \"\"\"Get the next sequence number for a named channel or topic\n\n        If channel has not been sent to next_id before, 0 is returned\n        otherwise next_id returns the last id returned + 1.\n\n        Args:\n            channel (string): The name of the channel to get a sequential\n                id for.\n\n        Returns:\n            int: The next id for this channel\n        \"\"\"\n\n        if channel not in self.topics:\n            self.topics[channel] = 0\n            return 0\n\n        self.topics[channel] += 1\n        return self.topics[channel]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef escape(arg):\n    \"escape shell special characters\" \n    slash = '\\\\'\n    special = '\"$'\n\n    arg = arg.replace(slash, slash+slash)\n    for c in special:\n        arg = arg.replace(c, slash+c)\n\n    # print(\"ESCAPE RESULT: %s\" % arg)\n    return '\"' + arg + '\"'", "response": "escape shell special characters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef MatchQuality(cls, record_data, record_count=1):\n\n        if record_count > 1:\n            return MatchQuality.NoMatch\n\n        cmd, _address, _resp_length, payload = cls._parse_rpc_info(record_data)\n\n        if cmd == cls.RPC_ID:\n            try:\n                _os_info, _app_info, update_os, update_app = struct.unpack(\"<LLBB\", payload)\n                update_os = bool(update_os)\n                update_app = bool(update_app)\n\n            except ValueError:\n                return MatchQuality.NoMatch\n\n            return MatchQuality.PerfectMatch\n\n        return MatchQuality.NoMatch", "response": "This function checks whether the given binary record data matches the given binary record_data and returns a MatchQuality."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FromBinary(cls, record_data, record_count=1):\n\n        _cmd, _address, _resp_length, payload = cls._parse_rpc_info(record_data)\n\n        try:\n            os_info, app_info, update_os, update_app = struct.unpack(\"<LLBB\", payload)\n            update_os = bool(update_os)\n            update_app = bool(update_app)\n\n            if update_app and not update_os:\n                tag, version = _parse_info(app_info)\n                return SetDeviceTagRecord(app_tag=tag, app_version=version)\n            elif update_os and not update_app:\n                tag, version = _parse_info(os_info)\n                return SetDeviceTagRecord(os_tag=tag, os_version=version)\n            elif update_os and update_app:\n                os_tag, os_version = _parse_info(os_info)\n                app_tag, app_version = _parse_info(app_info)\n                return SetDeviceTagRecord(app_tag=app_tag, app_version=app_version,\n                                          os_tag=os_tag, os_version=os_version)\n            else:\n                raise ArgumentError(\"Neither update_os nor update_app is set True\")\n\n        except ValueError:\n            raise ArgumentError(\"Could not parse set device version payload\", payload=payload)", "response": "Create an UpdateRecord subclass from binary record data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify(self, obj):\n\n        if not isinstance(obj, str):\n            raise ValidationError(\"Object is not a string\", reason='object is not a string',\n                                  object=obj, type=type(obj), str_type=str)\n\n        return obj", "response": "Verify that the object conforms to this verifier s schema\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting this verifier string", "response": "def format(self, indent_level, indent_size=4):\n        \"\"\"Format this verifier\n\n        Returns:\n            string: A formatted string\n        \"\"\"\n\n        desc = self.format_name('String')\n        return self.wrap_lines(desc, indent_level, indent_size=indent_size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear all volatile information across a reset.", "response": "def clear_to_reset(self, config_vars):\n        \"\"\"Clear all volatile information across a reset.\"\"\"\n\n        super(BasicStreamingSubsystem, self).clear_to_reset(config_vars)\n        self._in_progress_streamers = set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_streamer(self, streamer, callback=None):\n\n        index = streamer.index\n\n        if index in self._in_progress_streamers:\n            raise InternalError(\"You cannot add a streamer again until it has finished streaming.\")\n\n        queue_item = QueuedStreamer(streamer, callback)\n        self._in_progress_streamers.add(index)\n\n        self._logger.debug(\"Streamer %d: queued to send %d readings\", index, queue_item.initial_count)\n        self._queue.put_nowait(queue_item)", "response": "Start streaming a streamer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a response or exception to a status code and payload.", "response": "def pack_rpc_response(response=None, exception=None):\n    \"\"\"Convert a response payload or exception to a status code and payload.\n\n    This function will convert an Exception raised by an RPC implementation\n    to the corresponding status code.\n    \"\"\"\n\n    if response is None:\n        response = bytes()\n\n    if exception is None:\n        status = (1 << 6)\n        if len(response) > 0:\n            status |= (1 << 7)\n    elif isinstance(exception, (RPCInvalidIDError, RPCNotFoundError)):\n        status = 2\n    elif isinstance(exception, BusyRPCResponse):\n        status = 0\n    elif isinstance(exception, TileNotFoundError):\n        status = 0xFF\n    elif isinstance(exception, RPCErrorCode):\n        status = (1 << 6) | (exception.params['code'] & ((1 << 6) - 1))\n    else:\n        status = 3\n\n    return status, response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack_rpc_response(status, response=None, rpc_id=0, address=0):\n\n    status_code = status & ((1 << 6) - 1)\n\n    if address == 8:\n        status_code &= ~(1 << 7)\n\n    if status == 0:\n        raise BusyRPCResponse()\n    elif status == 2:\n        raise RPCNotFoundError(\"rpc %d:%04X not found\" % (address, rpc_id))\n    elif status == 3:\n        raise RPCErrorCode(status_code)\n    elif status == 0xFF:\n        raise TileNotFoundError(\"tile %d not found\" % address)\n    elif status_code != 0:\n        raise RPCErrorCode(status_code)\n\n    if response is None:\n        response = b''\n\n    return response", "response": "Unpack an RPC status back in to payload or exception."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pack_rpc_payload(arg_format, args):\n\n    code = _create_respcode(arg_format, args)\n\n    packed_result = struct.pack(code, *args)\n    unpacked_validation = struct.unpack(code, packed_result)\n    if tuple(args) != unpacked_validation:\n        raise RPCInvalidArgumentsError(\"Passed values would be truncated, please validate the size of your string\",\n                                       code=code, args=args)\n    return packed_result", "response": "Pack an RPC payload according to arg_format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nunpacks an RPC payload according to resp_format. The returned list is a list of the unpacked items.", "response": "def unpack_rpc_payload(resp_format, payload):\n    \"\"\"Unpack an RPC payload according to resp_format.\n\n    Args:\n        resp_format (str): a struct format code (without the <) for the\n            parameter format for this RPC.  This format code may include the final\n            character V, which means that it expects a variable length bytearray.\n        payload (bytes): The binary payload that should be unpacked.\n\n    Returns:\n        list: A list of the unpacked payload items.\n    \"\"\"\n\n    code = _create_argcode(resp_format, payload)\n    return struct.unpack(code, payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call_rpc(self, rpc_id, payload=bytes()):\n        if rpc_id < 0 or rpc_id > 0xFFFF:\n            raise RPCInvalidIDError(\"Invalid RPC ID: {}\".format(rpc_id))\n\n        if rpc_id not in self._rpcs:\n            raise RPCNotFoundError(\"rpc_id: {}\".format(rpc_id))\n\n        return self._rpcs[rpc_id](payload)", "response": "Call an RPC by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isfortran(env, source):\n    try:\n        fsuffixes = env['FORTRANSUFFIXES']\n    except KeyError:\n        # If no FORTRANSUFFIXES, no fortran tool, so there is no need to look\n        # for fortran sources.\n        return 0\n\n    if not source:\n        # Source might be None for unusual cases like SConf.\n        return 0\n    for s in source:\n        if s.sources:\n            ext = os.path.splitext(str(s.sources[0]))[1]\n            if ext in fsuffixes:\n                return 1\n    return 0", "response": "Return 1 if any of code in source has fortran files in it 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the fortran suffixes for the given list of suffixes and ppsuffixes.", "response": "def ComputeFortranSuffixes(suffixes, ppsuffixes):\n    \"\"\"suffixes are fortran source files, and ppsuffixes the ones to be\n    pre-processed. Both should be sequences, not strings.\"\"\"\n    assert len(suffixes) > 0\n    s = suffixes[0]\n    sup = s.upper()\n    upper_suffixes = [_.upper() for _ in suffixes]\n    if SCons.Util.case_sensitive_suffixes(s, sup):\n        ppsuffixes.extend(upper_suffixes)\n    else:\n        suffixes.extend(upper_suffixes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CreateDialectActions(dialect):\n    CompAction = SCons.Action.Action('$%sCOM ' % dialect, '$%sCOMSTR' % dialect)\n    CompPPAction = SCons.Action.Action('$%sPPCOM ' % dialect, '$%sPPCOMSTR' % dialect)\n    ShCompAction = SCons.Action.Action('$SH%sCOM ' % dialect, '$SH%sCOMSTR' % dialect)\n    ShCompPPAction = SCons.Action.Action('$SH%sPPCOM ' % dialect, '$SH%sPPCOMSTR' % dialect)\n\n    return CompAction, CompPPAction, ShCompAction, ShCompPPAction", "response": "Create dialect specific actions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DialectAddToEnv(env, dialect, suffixes, ppsuffixes, support_module = 0):\n    ComputeFortranSuffixes(suffixes, ppsuffixes)\n\n    fscan = SCons.Scanner.Fortran.FortranScan(\"%sPATH\" % dialect)\n\n    for suffix in suffixes + ppsuffixes:\n        SCons.Tool.SourceFileScanner.add_scanner(suffix, fscan)\n\n    env.AppendUnique(FORTRANSUFFIXES = suffixes + ppsuffixes)\n\n    compaction, compppaction, shcompaction, shcompppaction = \\\n            CreateDialectActions(dialect)\n\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in suffixes:\n        static_obj.add_action(suffix, compaction)\n        shared_obj.add_action(suffix, shcompaction)\n        static_obj.add_emitter(suffix, FortranEmitter)\n        shared_obj.add_emitter(suffix, ShFortranEmitter)\n\n    for suffix in ppsuffixes:\n        static_obj.add_action(suffix, compppaction)\n        shared_obj.add_action(suffix, shcompppaction)\n        static_obj.add_emitter(suffix, FortranEmitter)\n        shared_obj.add_emitter(suffix, ShFortranEmitter)\n\n    if '%sFLAGS' % dialect not in env:\n        env['%sFLAGS' % dialect] = SCons.Util.CLVar('')\n\n    if 'SH%sFLAGS' % dialect not in env:\n        env['SH%sFLAGS' % dialect] = SCons.Util.CLVar('$%sFLAGS' % dialect)\n\n    # If a tool does not define fortran prefix/suffix for include path, use C ones\n    if 'INC%sPREFIX' % dialect not in env:\n        env['INC%sPREFIX' % dialect] = '$INCPREFIX'\n\n    if 'INC%sSUFFIX' % dialect not in env:\n        env['INC%sSUFFIX' % dialect] = '$INCSUFFIX'\n\n    env['_%sINCFLAGS' % dialect] = '$( ${_concat(INC%sPREFIX, %sPATH, INC%sSUFFIX, __env__, RDirs, TARGET, SOURCE)} $)' % (dialect, dialect, dialect)\n\n    if support_module == 1:\n        env['%sCOM' % dialect]     = '$%s -o $TARGET -c $%sFLAGS $_%sINCFLAGS $_FORTRANMODFLAG $SOURCES' % (dialect, dialect, dialect)\n        env['%sPPCOM' % dialect]   = '$%s -o $TARGET -c $%sFLAGS $CPPFLAGS $_CPPDEFFLAGS $_%sINCFLAGS $_FORTRANMODFLAG $SOURCES' % (dialect, dialect, dialect)\n        env['SH%sCOM' % dialect]    = '$SH%s -o $TARGET -c $SH%sFLAGS $_%sINCFLAGS $_FORTRANMODFLAG $SOURCES' % (dialect, dialect, dialect)\n        env['SH%sPPCOM' % dialect]  = '$SH%s -o $TARGET -c $SH%sFLAGS $CPPFLAGS $_CPPDEFFLAGS $_%sINCFLAGS $_FORTRANMODFLAG $SOURCES' % (dialect, dialect, dialect)\n    else:\n        env['%sCOM' % dialect]     = '$%s -o $TARGET -c $%sFLAGS $_%sINCFLAGS $SOURCES' % (dialect, dialect, dialect)\n        env['%sPPCOM' % dialect]   = '$%s -o $TARGET -c $%sFLAGS $CPPFLAGS $_CPPDEFFLAGS $_%sINCFLAGS $SOURCES' % (dialect, dialect, dialect)\n        env['SH%sCOM' % dialect]    = '$SH%s -o $TARGET -c $SH%sFLAGS $_%sINCFLAGS $SOURCES' % (dialect, dialect, dialect)\n        env['SH%sPPCOM' % dialect]  = '$SH%s -o $TARGET -c $SH%sFLAGS $CPPFLAGS $_CPPDEFFLAGS $_%sINCFLAGS $SOURCES' % (dialect, dialect, dialect)", "response": "Add dialect specific construction variables to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding Builders and construction variables for Fortran to an Environment.", "response": "def add_fortran_to_env(env):\n    \"\"\"Add Builders and construction variables for Fortran to an Environment.\"\"\"\n    try:\n        FortranSuffixes = env['FORTRANFILESUFFIXES']\n    except KeyError:\n        FortranSuffixes = ['.f', '.for', '.ftn']\n\n    #print(\"Adding %s to fortran suffixes\" % FortranSuffixes)\n    try:\n        FortranPPSuffixes = env['FORTRANPPFILESUFFIXES']\n    except KeyError:\n        FortranPPSuffixes = ['.fpp', '.FPP']\n\n    DialectAddToEnv(env, \"FORTRAN\", FortranSuffixes,\n                    FortranPPSuffixes, support_module = 1)\n\n    env['FORTRANMODPREFIX'] = ''     # like $LIBPREFIX\n    env['FORTRANMODSUFFIX'] = '.mod' # like $LIBSUFFIX\n\n    env['FORTRANMODDIR'] = ''          # where the compiler should place .mod files\n    env['FORTRANMODDIRPREFIX'] = ''    # some prefix to $FORTRANMODDIR - similar to $INCPREFIX\n    env['FORTRANMODDIRSUFFIX'] = ''    # some suffix to $FORTRANMODDIR - similar to $INCSUFFIX\n    env['_FORTRANMODFLAG'] = '$( ${_concat(FORTRANMODDIRPREFIX, FORTRANMODDIR, FORTRANMODDIRSUFFIX, __env__, RDirs, TARGET, SOURCE)} $)'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_f77_to_env(env):\n    try:\n        F77Suffixes = env['F77FILESUFFIXES']\n    except KeyError:\n        F77Suffixes = ['.f77']\n\n    #print(\"Adding %s to f77 suffixes\" % F77Suffixes)\n    try:\n        F77PPSuffixes = env['F77PPFILESUFFIXES']\n    except KeyError:\n        F77PPSuffixes = []\n\n    DialectAddToEnv(env, \"F77\", F77Suffixes, F77PPSuffixes)", "response": "Add Builders and construction variables for f77 to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_f90_to_env(env):\n    try:\n        F90Suffixes = env['F90FILESUFFIXES']\n    except KeyError:\n        F90Suffixes = ['.f90']\n\n    #print(\"Adding %s to f90 suffixes\" % F90Suffixes)\n    try:\n        F90PPSuffixes = env['F90PPFILESUFFIXES']\n    except KeyError:\n        F90PPSuffixes = []\n\n    DialectAddToEnv(env, \"F90\", F90Suffixes, F90PPSuffixes,\n                    support_module = 1)", "response": "Add Builders and construction variables for f90 to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for f95 to an Environment.", "response": "def add_f95_to_env(env):\n    \"\"\"Add Builders and construction variables for f95 to an Environment.\"\"\"\n    try:\n        F95Suffixes = env['F95FILESUFFIXES']\n    except KeyError:\n        F95Suffixes = ['.f95']\n\n    #print(\"Adding %s to f95 suffixes\" % F95Suffixes)\n    try:\n        F95PPSuffixes = env['F95PPFILESUFFIXES']\n    except KeyError:\n        F95PPSuffixes = []\n\n    DialectAddToEnv(env, \"F95\", F95Suffixes, F95PPSuffixes,\n                    support_module = 1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_f03_to_env(env):\n    try:\n        F03Suffixes = env['F03FILESUFFIXES']\n    except KeyError:\n        F03Suffixes = ['.f03']\n\n    #print(\"Adding %s to f95 suffixes\" % F95Suffixes)\n    try:\n        F03PPSuffixes = env['F03PPFILESUFFIXES']\n    except KeyError:\n        F03PPSuffixes = []\n\n    DialectAddToEnv(env, \"F03\", F03Suffixes, F03PPSuffixes,\n                    support_module = 1)", "response": "Add Builders and construction variables for f03 to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_f08_to_env(env):\n    try:\n        F08Suffixes = env['F08FILESUFFIXES']\n    except KeyError:\n        F08Suffixes = ['.f08']\n\n    try:\n        F08PPSuffixes = env['F08PPFILESUFFIXES']\n    except KeyError:\n        F08PPSuffixes = []\n\n    DialectAddToEnv(env, \"F08\", F08Suffixes, F08PPSuffixes,\n                    support_module = 1)", "response": "Add Builders and construction variables for f08 to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding builders and construction variables for all supported fortran dialects.", "response": "def add_all_to_env(env):\n    \"\"\"Add builders and construction variables for all supported fortran\n    dialects.\"\"\"\n    add_fortran_to_env(env)\n    add_f77_to_env(env)\n    add_f90_to_env(env)\n    add_f95_to_env(env)\n    add_f03_to_env(env)\n    add_f08_to_env(env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes duplicates from a sequence keeping the first or last.", "response": "def _delete_duplicates(l, keep_last):\n    \"\"\"Delete duplicates from a sequence, keeping the first or last.\"\"\"\n    seen=set()\n    result=[]\n    if keep_last:           # reverse in & out, then keep first\n        l.reverse()\n    for i in l:\n        try:\n            if i not in seen:\n                result.append(i)\n                seen.add(i)\n        except TypeError:\n            # probably unhashable.  Just keep it.\n            result.append(i)\n    if keep_last:\n        result.reverse()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef NoSubstitutionProxy(subject):\n    class _NoSubstitutionProxy(Environment):\n        def __init__(self, subject):\n            self.__dict__['__subject'] = subject\n        def __getattr__(self, name):\n            return getattr(self.__dict__['__subject'], name)\n        def __setattr__(self, name, value):\n            return setattr(self.__dict__['__subject'], name, value)\n        def executor_to_lvars(self, kwdict):\n            if 'executor' in kwdict:\n                kwdict['lvars'] = kwdict['executor'].get_lvars()\n                del kwdict['executor']\n            else:\n                kwdict['lvars'] = {}\n        def raw_to_mode(self, dict):\n            try:\n                raw = dict['raw']\n            except KeyError:\n                pass\n            else:\n                del dict['raw']\n                dict['mode'] = raw\n        def subst(self, string, *args, **kwargs):\n            return string\n        def subst_kw(self, kw, *args, **kwargs):\n            return kw\n        def subst_list(self, string, *args, **kwargs):\n            nargs = (string, self,) + args\n            nkw = kwargs.copy()\n            nkw['gvars'] = {}\n            self.executor_to_lvars(nkw)\n            self.raw_to_mode(nkw)\n            return SCons.Subst.scons_subst_list(*nargs, **nkw)\n        def subst_target_source(self, string, *args, **kwargs):\n            nargs = (string, self,) + args\n            nkw = kwargs.copy()\n            nkw['gvars'] = {}\n            self.executor_to_lvars(nkw)\n            self.raw_to_mode(nkw)\n            return SCons.Subst.scons_subst(*nargs, **nkw)\n    return _NoSubstitutionProxy(subject)", "response": "This is a wrapper for the base class _NoSubstitutionProxy that returns a proxy subclass that overrides the subst* method that does not actually perform substitution."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clone(self, new_object):\n        return self.__class__(new_object, self.method, self.name)", "response": "Returns a new object that re - binds the underlying method to\n        the specified new object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_special(self):\n        self._special_del = {}\n        self._special_del['SCANNERS'] = _del_SCANNERS\n\n        self._special_set = {}\n        for key in reserved_construction_var_names:\n            self._special_set[key] = _set_reserved\n        for key in future_reserved_construction_var_names:\n            self._special_set[key] = _set_future_reserved\n        self._special_set['BUILDERS'] = _set_BUILDERS\n        self._special_set['SCANNERS'] = _set_SCANNERS\n\n        # Freeze the keys of self._special_set in a list for use by\n        # methods that need to check.  (Empirically, list scanning has\n        # gotten better than dict.has_key() in Python 2.5.)\n        self._special_set_keys = list(self._special_set.keys())", "response": "Initial the dispatch tables for special handling of\n        special construction variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subst_list(self, string, raw=0, target=None, source=None, conv=None, executor=None):\n        gvars = self.gvars()\n        lvars = self.lvars()\n        lvars['__env__'] = self\n        if executor:\n            lvars.update(executor.get_lvars())\n        return SCons.Subst.scons_subst_list(string, self, raw, target, source, gvars, lvars, conv)", "response": "Calls through to SCons. Subst. subst_list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subst_path(self, path, target=None, source=None):\n\n        if not SCons.Util.is_List(path):\n            path = [path]\n\n        def s(obj):\n            \"\"\"This is the \"string conversion\" routine that we have our\n            substitutions use to return Nodes, not strings.  This relies\n            on the fact that an EntryProxy object has a get() method that\n            returns the underlying Node that it wraps, which is a bit of\n            architectural dependence that we might need to break or modify\n            in the future in response to additional requirements.\"\"\"\n            try:\n                get = obj.get\n            except AttributeError:\n                obj = SCons.Util.to_String_for_subst(obj)\n            else:\n                obj = get()\n            return obj\n\n        r = []\n        for p in path:\n            if SCons.Util.is_String(p):\n                p = self.subst(p, target=target, source=source, conv=s)\n                if SCons.Util.is_List(p):\n                    if len(p) == 1:\n                        p = p[0]\n                    else:\n                        # We have an object plus a string, or multiple\n                        # objects that we need to smush together.  No choice\n                        # but to make them into a string.\n                        p = ''.join(map(SCons.Util.to_String_for_subst, p))\n            else:\n                p = s(p)\n            r.append(p)\n        return r", "response": "Substitute a path list into EntryProxies into Nodes\n            and leaving Nodes as - is."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddMethod(self, function, name=None):\n        method = MethodWrapper(self, function, name)\n        self.added_methods.append(method)", "response": "Adds a function as a method of this construction\n        environment with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RemoveMethod(self, function):\n        self.added_methods = [dm for dm in self.added_methods if not dm.method is function]", "response": "Removes the specified function s MethodWrapper from the internal list of added methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a modified Environment with the variables overridden by the given overrides dictionary.", "response": "def Override(self, overrides):\n        \"\"\"\n        Produce a modified environment whose variables are overridden by\n        the overrides dictionaries.  \"overrides\" is a dictionary that\n        will override the variables of this environment.\n\n        This function is much more efficient than Clone() or creating\n        a new Environment because it doesn't copy the construction\n        environment dictionary, it just wraps the underlying construction\n        environment, and doesn't even create a wrapper object if there\n        are no overrides.\n        \"\"\"\n        if not overrides: return self\n        o = copy_non_reserved_keywords(overrides)\n        if not o: return self\n        overrides = {}\n        merges = None\n        for key, value in o.items():\n            if key == 'parse_flags':\n                merges = value\n            else:\n                overrides[key] = SCons.Subst.scons_subst_once(value, self, key)\n        env = OverrideEnvironment(self, overrides)\n        if merges: env.MergeFlags(merges)\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the set of flags and returns a dictionary with the flags placed in the appropriate entry in the appropriate entry.", "response": "def ParseFlags(self, *flags):\n        \"\"\"\n        Parse the set of flags and return a dict with the flags placed\n        in the appropriate entry.  The flags are treated as a typical\n        set of command-line flags for a GNU-like toolchain and used to\n        populate the entries in the dict immediately below.  If one of\n        the flag strings begins with a bang (exclamation mark), it is\n        assumed to be a command and the rest of the string is executed;\n        the result of that evaluation is then added to the dict.\n        \"\"\"\n        dict = {\n            'ASFLAGS'       : SCons.Util.CLVar(''),\n            'CFLAGS'        : SCons.Util.CLVar(''),\n            'CCFLAGS'       : SCons.Util.CLVar(''),\n            'CXXFLAGS'      : SCons.Util.CLVar(''),\n            'CPPDEFINES'    : [],\n            'CPPFLAGS'      : SCons.Util.CLVar(''),\n            'CPPPATH'       : [],\n            'FRAMEWORKPATH' : SCons.Util.CLVar(''),\n            'FRAMEWORKS'    : SCons.Util.CLVar(''),\n            'LIBPATH'       : [],\n            'LIBS'          : [],\n            'LINKFLAGS'     : SCons.Util.CLVar(''),\n            'RPATH'         : [],\n        }\n\n        def do_parse(arg):\n            # if arg is a sequence, recurse with each element\n            if not arg:\n                return\n\n            if not SCons.Util.is_String(arg):\n                for t in arg: do_parse(t)\n                return\n\n            # if arg is a command, execute it\n            if arg[0] == '!':\n                arg = self.backtick(arg[1:])\n\n            # utility function to deal with -D option\n            def append_define(name, dict = dict):\n                t = name.split('=')\n                if len(t) == 1:\n                    dict['CPPDEFINES'].append(name)\n                else:\n                    dict['CPPDEFINES'].append([t[0], '='.join(t[1:])])\n\n            # Loop through the flags and add them to the appropriate option.\n            # This tries to strike a balance between checking for all possible\n            # flags and keeping the logic to a finite size, so it doesn't\n            # check for some that don't occur often.  It particular, if the\n            # flag is not known to occur in a config script and there's a way\n            # of passing the flag to the right place (by wrapping it in a -W\n            # flag, for example) we don't check for it.  Note that most\n            # preprocessor options are not handled, since unhandled options\n            # are placed in CCFLAGS, so unless the preprocessor is invoked\n            # separately, these flags will still get to the preprocessor.\n            # Other options not currently handled:\n            #  -iqoutedir      (preprocessor search path)\n            #  -u symbol       (linker undefined symbol)\n            #  -s              (linker strip files)\n            #  -static*        (linker static binding)\n            #  -shared*        (linker dynamic binding)\n            #  -symbolic       (linker global binding)\n            #  -R dir          (deprecated linker rpath)\n            # IBM compilers may also accept -qframeworkdir=foo\n\n            params = shlex.split(arg)\n            append_next_arg_to = None   # for multi-word args\n            for arg in params:\n                if append_next_arg_to:\n                   if append_next_arg_to == 'CPPDEFINES':\n                       append_define(arg)\n                   elif append_next_arg_to == '-include':\n                       t = ('-include', self.fs.File(arg))\n                       dict['CCFLAGS'].append(t)\n                   elif append_next_arg_to == '-isysroot':\n                       t = ('-isysroot', arg)\n                       dict['CCFLAGS'].append(t)\n                       dict['LINKFLAGS'].append(t)\n                   elif append_next_arg_to == '-isystem':\n                       t = ('-isystem', arg)\n                       dict['CCFLAGS'].append(t)\n                   elif append_next_arg_to == '-arch':\n                       t = ('-arch', arg)\n                       dict['CCFLAGS'].append(t)\n                       dict['LINKFLAGS'].append(t)\n                   else:\n                       dict[append_next_arg_to].append(arg)\n                   append_next_arg_to = None\n                elif not arg[0] in ['-', '+']:\n                    dict['LIBS'].append(self.fs.File(arg))\n                elif arg == '-dylib_file':\n                    dict['LINKFLAGS'].append(arg)\n                    append_next_arg_to = 'LINKFLAGS'\n                elif arg[:2] == '-L':\n                    if arg[2:]:\n                        dict['LIBPATH'].append(arg[2:])\n                    else:\n                        append_next_arg_to = 'LIBPATH'\n                elif arg[:2] == '-l':\n                    if arg[2:]:\n                        dict['LIBS'].append(arg[2:])\n                    else:\n                        append_next_arg_to = 'LIBS'\n                elif arg[:2] == '-I':\n                    if arg[2:]:\n                        dict['CPPPATH'].append(arg[2:])\n                    else:\n                        append_next_arg_to = 'CPPPATH'\n                elif arg[:4] == '-Wa,':\n                    dict['ASFLAGS'].append(arg[4:])\n                    dict['CCFLAGS'].append(arg)\n                elif arg[:4] == '-Wl,':\n                    if arg[:11] == '-Wl,-rpath=':\n                        dict['RPATH'].append(arg[11:])\n                    elif arg[:7] == '-Wl,-R,':\n                        dict['RPATH'].append(arg[7:])\n                    elif arg[:6] == '-Wl,-R':\n                        dict['RPATH'].append(arg[6:])\n                    else:\n                        dict['LINKFLAGS'].append(arg)\n                elif arg[:4] == '-Wp,':\n                    dict['CPPFLAGS'].append(arg)\n                elif arg[:2] == '-D':\n                    if arg[2:]:\n                        append_define(arg[2:])\n                    else:\n                        append_next_arg_to = 'CPPDEFINES'\n                elif arg == '-framework':\n                    append_next_arg_to = 'FRAMEWORKS'\n                elif arg[:14] == '-frameworkdir=':\n                    dict['FRAMEWORKPATH'].append(arg[14:])\n                elif arg[:2] == '-F':\n                    if arg[2:]:\n                        dict['FRAMEWORKPATH'].append(arg[2:])\n                    else:\n                        append_next_arg_to = 'FRAMEWORKPATH'\n                elif arg in ['-mno-cygwin',\n                             '-pthread',\n                             '-openmp',\n                             '-fopenmp']:\n                    dict['CCFLAGS'].append(arg)\n                    dict['LINKFLAGS'].append(arg)\n                elif arg == '-mwindows':\n                    dict['LINKFLAGS'].append(arg)\n                elif arg[:5] == '-std=':\n                    if arg[5:].find('++')!=-1:\n                        key='CXXFLAGS'\n                    else:\n                        key='CFLAGS'\n                    dict[key].append(arg)\n                elif arg[0] == '+':\n                    dict['CCFLAGS'].append(arg)\n                    dict['LINKFLAGS'].append(arg)\n                elif arg in ['-include', '-isysroot', '-isystem', '-arch']:\n                    append_next_arg_to = arg\n                else:\n                    dict['CCFLAGS'].append(arg)\n\n        for arg in flags:\n            do_parse(arg)\n        return dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef MergeFlags(self, args, unique=1, dict=None):\n\n        if dict is None:\n            dict = self\n        if not SCons.Util.is_Dict(args):\n            args = self.ParseFlags(args)\n        if not unique:\n            self.Append(**args)\n            return self\n        for key, value in args.items():\n            if not value:\n                continue\n            try:\n                orig = self[key]\n            except KeyError:\n                orig = value\n            else:\n                if not orig:\n                    orig = value\n                elif value:\n                    # Add orig and value.  The logic here was lifted from\n                    # part of env.Append() (see there for a lot of comments\n                    # about the order in which things are tried) and is\n                    # used mainly to handle coercion of strings to CLVar to\n                    # \"do the right thing\" given (e.g.) an original CCFLAGS\n                    # string variable like '-pipe -Wall'.\n                    try:\n                        orig = orig + value\n                    except (KeyError, TypeError):\n                        try:\n                            add_to_orig = orig.append\n                        except AttributeError:\n                            value.insert(0, orig)\n                            orig = value\n                        else:\n                            add_to_orig(value)\n            t = []\n            if key[-4:] == 'PATH':\n                ### keep left-most occurence\n                for v in orig:\n                    if v not in t:\n                        t.append(v)\n            else:\n                ### keep right-most occurence\n                orig.reverse()\n                for v in orig:\n                    if v not in t:\n                        t.insert(0, v)\n            self[key] = t\n        return self", "response": "Merge the flags of this instance into the construction variables of the passed - in dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_factory(self, factory, default='File'):\n        name = default\n        try:\n            is_node = issubclass(factory, SCons.Node.FS.Base)\n        except TypeError:\n            # The specified factory isn't a Node itself--it's\n            # most likely None, or possibly a callable.\n            pass\n        else:\n            if is_node:\n                # The specified factory is a Node (sub)class.  Try to\n                # return the FS method that corresponds to the Node's\n                # name--that is, we return self.fs.Dir if they want a Dir,\n                # self.fs.File for a File, etc.\n                try: name = factory.__name__\n                except AttributeError: pass\n                else: factory = None\n        if not factory:\n            # They passed us None, or we picked up a name from a specified\n            # class, so return the FS method.  (Note that we *don't*\n            # use our own self.{Dir,File} methods because that would\n            # cause env.subst() to be called twice on the file name,\n            # interfering with files that have $$ in them.)\n            factory = getattr(self.fs, name)\n        return factory", "response": "Return a factory function for creating Nodes for this environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_scanner(self, skey):\n        if skey and self['PLATFORM'] == 'win32':\n            skey = skey.lower()\n        return self._gsm().get(skey)", "response": "Find the appropriate scanner given a key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nappending values to existing construction variables in an Environment.", "response": "def Append(self, **kw):\n        \"\"\"Append values to existing construction variables\n        in an Environment.\n        \"\"\"\n        kw = copy_non_reserved_keywords(kw)\n        for key, val in kw.items():\n            # It would be easier on the eyes to write this using\n            # \"continue\" statements whenever we finish processing an item,\n            # but Python 1.5.2 apparently doesn't let you use \"continue\"\n            # within try:-except: blocks, so we have to nest our code.\n            try:\n                if key == 'CPPDEFINES' and SCons.Util.is_String(self._dict[key]):\n                    self._dict[key] = [self._dict[key]]\n                orig = self._dict[key]\n            except KeyError:\n                # No existing variable in the environment, so just set\n                # it to the new value.\n                if key == 'CPPDEFINES' and SCons.Util.is_String(val):\n                    self._dict[key] = [val]\n                else:\n                    self._dict[key] = val\n            else:\n                try:\n                    # Check if the original looks like a dictionary.\n                    # If it is, we can't just try adding the value because\n                    # dictionaries don't have __add__() methods, and\n                    # things like UserList will incorrectly coerce the\n                    # original dict to a list (which we don't want).\n                    update_dict = orig.update\n                except AttributeError:\n                    try:\n                        # Most straightforward:  just try to add them\n                        # together.  This will work in most cases, when the\n                        # original and new values are of compatible types.\n                        self._dict[key] = orig + val\n                    except (KeyError, TypeError):\n                        try:\n                            # Check if the original is a list.\n                            add_to_orig = orig.append\n                        except AttributeError:\n                            # The original isn't a list, but the new\n                            # value is (by process of elimination),\n                            # so insert the original in the new value\n                            # (if there's one to insert) and replace\n                            # the variable with it.\n                            if orig:\n                                val.insert(0, orig)\n                            self._dict[key] = val\n                        else:\n                            # The original is a list, so append the new\n                            # value to it (if there's a value to append).\n                            if val:\n                                add_to_orig(val)\n                else:\n                    # The original looks like a dictionary, so update it\n                    # based on what we think the value looks like.\n                    if SCons.Util.is_List(val):\n                        if key == 'CPPDEFINES':\n                            tmp = []\n                            for (k, v) in orig.items():\n                                if v is not None:\n                                    tmp.append((k, v))\n                                else:\n                                    tmp.append((k,))\n                            orig = tmp\n                            orig += val\n                            self._dict[key] = orig\n                        else:\n                            for v in val:\n                                orig[v] = None\n                    else:\n                        try:\n                            update_dict(val)\n                        except (AttributeError, TypeError, ValueError):\n                            if SCons.Util.is_Dict(val):\n                                for k, v in val.items():\n                                    orig[k] = v\n                            else:\n                                orig[val] = None\n        self.scanner_map_delete(kw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AppendENVPath(self, name, newpath, envname = 'ENV',\n                      sep = os.pathsep, delete_existing=1):\n        \"\"\"Append path elements to the path 'name' in the 'ENV'\n        dictionary for this environment.  Will only add any particular\n        path once, and will normpath and normcase all paths to help\n        assure this.  This can also handle the case where the env\n        variable is a list instead of a string.\n\n        If delete_existing is 0, a newpath which is already in the path\n        will not be moved to the end (it will be left where it is).\n        \"\"\"\n\n        orig = ''\n        if envname in self._dict and name in self._dict[envname]:\n            orig = self._dict[envname][name]\n\n        nv = SCons.Util.AppendPath(orig, newpath, sep, delete_existing,\n                                   canonicalize=self._canonicalize)\n\n        if envname not in self._dict:\n            self._dict[envname] = {}\n\n        self._dict[envname][name] = nv", "response": "Append path elements to the path elements in the ENV dictionary for this environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nappending values to existing construction variables in an Environment if they are not already there.", "response": "def AppendUnique(self, delete_existing=0, **kw):\n        \"\"\"Append values to existing construction variables\n        in an Environment, if they're not already there.\n        If delete_existing is 1, removes existing values first, so\n        values move to end.\n        \"\"\"\n        kw = copy_non_reserved_keywords(kw)\n        for key, val in kw.items():\n            if SCons.Util.is_List(val):\n                val = _delete_duplicates(val, delete_existing)\n            if key not in self._dict or self._dict[key] in ('', None):\n                self._dict[key] = val\n            elif SCons.Util.is_Dict(self._dict[key]) and \\\n                 SCons.Util.is_Dict(val):\n                self._dict[key].update(val)\n            elif SCons.Util.is_List(val):\n                dk = self._dict[key]\n                if key == 'CPPDEFINES':\n                    tmp = []\n                    for i in val:\n                        if SCons.Util.is_List(i):\n                            if len(i) >= 2:\n                                tmp.append((i[0], i[1]))\n                            else:\n                                tmp.append((i[0],))\n                        elif SCons.Util.is_Tuple(i):\n                            tmp.append(i)\n                        else:\n                            tmp.append((i,))\n                    val = tmp\n                    # Construct a list of (key, value) tuples.\n                    if SCons.Util.is_Dict(dk):\n                        tmp = []\n                        for (k, v) in dk.items():\n                            if v is not None:\n                                tmp.append((k, v))\n                            else:\n                                tmp.append((k,))\n                        dk = tmp\n                    elif SCons.Util.is_String(dk):\n                        dk = [(dk,)]\n                    else:\n                        tmp = []\n                        for i in dk:\n                            if SCons.Util.is_List(i):\n                                if len(i) >= 2:\n                                    tmp.append((i[0], i[1]))\n                                else:\n                                    tmp.append((i[0],))\n                            elif SCons.Util.is_Tuple(i):\n                                tmp.append(i)\n                            else:\n                                tmp.append((i,))\n                        dk = tmp\n                else:\n                    if not SCons.Util.is_List(dk):\n                        dk = [dk]\n                if delete_existing:\n                    dk = [x for x in dk if x not in val]\n                else:\n                    val = [x for x in val if x not in dk]\n                self._dict[key] = dk + val\n            else:\n                dk = self._dict[key]\n                if SCons.Util.is_List(dk):\n                    if key == 'CPPDEFINES':\n                        tmp = []\n                        for i in dk:\n                            if SCons.Util.is_List(i):\n                                if len(i) >= 2:\n                                    tmp.append((i[0], i[1]))\n                                else:\n                                    tmp.append((i[0],))\n                            elif SCons.Util.is_Tuple(i):\n                                tmp.append(i)\n                            else:\n                                tmp.append((i,))\n                        dk = tmp\n                        # Construct a list of (key, value) tuples.\n                        if SCons.Util.is_Dict(val):\n                            tmp = []\n                            for (k, v) in val.items():\n                                if v is not None:\n                                    tmp.append((k, v))\n                                else:\n                                    tmp.append((k,))\n                            val = tmp\n                        elif SCons.Util.is_String(val):\n                            val = [(val,)]\n                        if delete_existing:\n                            dk = list(filter(lambda x, val=val: x not in val, dk))\n                            self._dict[key] = dk + val\n                        else:\n                            dk = [x for x in dk if x not in val]\n                            self._dict[key] = dk + val\n                    else:\n                        # By elimination, val is not a list.  Since dk is a\n                        # list, wrap val in a list first.\n                        if delete_existing:\n                            dk = list(filter(lambda x, val=val: x not in val, dk))\n                            self._dict[key] = dk + [val]\n                        else:\n                            if not val in dk:\n                                self._dict[key] = dk + [val]\n                else:\n                    if key == 'CPPDEFINES':\n                        if SCons.Util.is_String(dk):\n                            dk = [dk]\n                        elif SCons.Util.is_Dict(dk):\n                            tmp = []\n                            for (k, v) in dk.items():\n                                if v is not None:\n                                    tmp.append((k, v))\n                                else:\n                                    tmp.append((k,))\n                            dk = tmp\n                        if SCons.Util.is_String(val):\n                            if val in dk:\n                                val = []\n                            else:\n                                val = [val]\n                        elif SCons.Util.is_Dict(val):\n                            tmp = []\n                            for i,j in val.items():\n                                if j is not None:\n                                    tmp.append((i,j))\n                                else:\n                                    tmp.append(i)\n                            val = tmp\n                    if delete_existing:\n                        dk = [x for x in dk if x not in val]\n                    self._dict[key] = dk + val\n        self.scanner_map_delete(kw)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a deep copy of this Environment.", "response": "def Clone(self, tools=[], toolpath=None, parse_flags = None, **kw):\n        \"\"\"Return a copy of a construction Environment.  The\n        copy is like a Python \"deep copy\"--that is, independent\n        copies are made recursively of each objects--except that\n        a reference is copied when an object is not deep-copyable\n        (like a function).  There are no references to any mutable\n        objects in the original Environment.\n        \"\"\"\n\n        builders = self._dict.get('BUILDERS', {})\n\n        clone = copy.copy(self)\n        # BUILDERS is not safe to do a simple copy\n        clone._dict = semi_deepcopy_dict(self._dict, ['BUILDERS'])\n        clone._dict['BUILDERS'] = BuilderDict(builders, clone)\n\n        # Check the methods added via AddMethod() and re-bind them to\n        # the cloned environment.  Only do this if the attribute hasn't\n        # been overwritten by the user explicitly and still points to\n        # the added method.\n        clone.added_methods = []\n        for mw in self.added_methods:\n            if mw == getattr(self, mw.name):\n                clone.added_methods.append(mw.clone(clone))\n\n        clone._memo = {}\n\n        # Apply passed-in variables before the tools\n        # so the tools can use the new variables\n        kw = copy_non_reserved_keywords(kw)\n        new = {}\n        for key, value in kw.items():\n            new[key] = SCons.Subst.scons_subst_once(value, self, key)\n        clone.Replace(**new)\n\n        apply_tools(clone, tools, toolpath)\n\n        # apply them again in case the tools overwrote them\n        clone.Replace(**new)\n\n        # Finally, apply any flags to be merged in\n        if parse_flags: clone.MergeFlags(parse_flags)\n\n        if SCons.Debug.track_instances: logInstanceCreation(self, 'Environment.EnvironmentClone')\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Detect(self, progs):\n        if not SCons.Util.is_List(progs):\n            progs = [ progs ]\n        for prog in progs:\n            path = self.WhereIs(prog)\n            if path: return prog\n        return None", "response": "Detect the first available program in a list of programs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the contents of the scons build environment as a string.", "response": "def Dump(self, key = None):\n        \"\"\"\n        Using the standard Python pretty printer, return the contents of the\n        scons build environment as a string.\n\n        If the key passed in is anything other than None, then that will\n        be used as an index into the build environment dictionary and\n        whatever is found there will be fed into the pretty printer. Note\n        that this key is case sensitive.\n        \"\"\"\n        import pprint\n        pp = pprint.PrettyPrinter(indent=2)\n        if key:\n            dict = self.Dictionary(key)\n        else:\n            dict = self.Dictionary()\n        return pp.pformat(dict)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding an iXes file in a list of paths that match the prefix and suffix.", "response": "def FindIxes(self, paths, prefix, suffix):\n        \"\"\"\n        Search a list of paths for something that matches the prefix and suffix.\n\n        paths - the list of paths or nodes.\n        prefix - construction variable for the prefix.\n        suffix - construction variable for the suffix.\n        \"\"\"\n\n        suffix = self.subst('$'+suffix)\n        prefix = self.subst('$'+prefix)\n\n        for path in paths:\n            dir,name = os.path.split(str(path))\n            if name[:len(prefix)] == prefix and name[-len(suffix):] == suffix:\n                return path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ParseConfig(self, command, function=None, unique=1):\n        if function is None:\n            def parse_conf(env, cmd, unique=unique):\n                return env.MergeFlags(cmd, unique)\n            function = parse_conf\n        if SCons.Util.is_List(command):\n            command = ' '.join(command)\n        command = self.subst(command)\n        return function(self, self.backtick(command))", "response": "Parse the output of a command and return a dictionary of the appropriate variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ParseDepends(self, filename, must_exist=None, only_one=0):\n        filename = self.subst(filename)\n        try:\n            fp = open(filename, 'r')\n        except IOError:\n            if must_exist:\n                raise\n            return\n        lines = SCons.Util.LogicalLines(fp).readlines()\n        lines = [l for l in lines if l[0] != '#']\n        tdlist = []\n        for line in lines:\n            try:\n                target, depends = line.split(':', 1)\n            except (AttributeError, ValueError):\n                # Throws AttributeError if line isn't a string.  Can throw\n                # ValueError if line doesn't split into two or more elements.\n                pass\n            else:\n                tdlist.append((target.split(), depends.split()))\n        if only_one:\n            targets = []\n            for td in tdlist:\n                targets.extend(td[0])\n            if len(targets) > 1:\n                raise SCons.Errors.UserError(\n                            \"More than one dependency target found in `%s':  %s\"\n                                            % (filename, targets))\n        for target, depends in tdlist:\n            self.Depends(target, depends)", "response": "Parses a mkdep - style file for explicit dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Prepend(self, **kw):\n        kw = copy_non_reserved_keywords(kw)\n        for key, val in kw.items():\n            # It would be easier on the eyes to write this using\n            # \"continue\" statements whenever we finish processing an item,\n            # but Python 1.5.2 apparently doesn't let you use \"continue\"\n            # within try:-except: blocks, so we have to nest our code.\n            try:\n                orig = self._dict[key]\n            except KeyError:\n                # No existing variable in the environment, so just set\n                # it to the new value.\n                self._dict[key] = val\n            else:\n                try:\n                    # Check if the original looks like a dictionary.\n                    # If it is, we can't just try adding the value because\n                    # dictionaries don't have __add__() methods, and\n                    # things like UserList will incorrectly coerce the\n                    # original dict to a list (which we don't want).\n                    update_dict = orig.update\n                except AttributeError:\n                    try:\n                        # Most straightforward:  just try to add them\n                        # together.  This will work in most cases, when the\n                        # original and new values are of compatible types.\n                        self._dict[key] = val + orig\n                    except (KeyError, TypeError):\n                        try:\n                            # Check if the added value is a list.\n                            add_to_val = val.append\n                        except AttributeError:\n                            # The added value isn't a list, but the\n                            # original is (by process of elimination),\n                            # so insert the the new value in the original\n                            # (if there's one to insert).\n                            if val:\n                                orig.insert(0, val)\n                        else:\n                            # The added value is a list, so append\n                            # the original to it (if there's a value\n                            # to append).\n                            if orig:\n                                add_to_val(orig)\n                            self._dict[key] = val\n                else:\n                    # The original looks like a dictionary, so update it\n                    # based on what we think the value looks like.\n                    if SCons.Util.is_List(val):\n                        for v in val:\n                            orig[v] = None\n                    else:\n                        try:\n                            update_dict(val)\n                        except (AttributeError, TypeError, ValueError):\n                            if SCons.Util.is_Dict(val):\n                                for k, v in val.items():\n                                    orig[k] = v\n                            else:\n                                orig[val] = None\n        self.scanner_map_delete(kw)", "response": "Prepend values to existing construction variables in an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PrependUnique(self, delete_existing=0, **kw):\n        kw = copy_non_reserved_keywords(kw)\n        for key, val in kw.items():\n            if SCons.Util.is_List(val):\n                val = _delete_duplicates(val, not delete_existing)\n            if key not in self._dict or self._dict[key] in ('', None):\n                self._dict[key] = val\n            elif SCons.Util.is_Dict(self._dict[key]) and \\\n                 SCons.Util.is_Dict(val):\n                self._dict[key].update(val)\n            elif SCons.Util.is_List(val):\n                dk = self._dict[key]\n                if not SCons.Util.is_List(dk):\n                    dk = [dk]\n                if delete_existing:\n                    dk = [x for x in dk if x not in val]\n                else:\n                    val = [x for x in val if x not in dk]\n                self._dict[key] = val + dk\n            else:\n                dk = self._dict[key]\n                if SCons.Util.is_List(dk):\n                    # By elimination, val is not a list.  Since dk is a\n                    # list, wrap val in a list first.\n                    if delete_existing:\n                        dk = [x for x in dk if x not in val]\n                        self._dict[key] = [val] + dk\n                    else:\n                        if not val in dk:\n                            self._dict[key] = [val] + dk\n                else:\n                    if delete_existing:\n                        dk = [x for x in dk if x not in val]\n                    self._dict[key] = val + dk\n        self.scanner_map_delete(kw)", "response": "Prepend values to existing construction variables\n        in an Environment if they are not already there."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces existing construction variables in an Environment with new construction variables and or values.", "response": "def Replace(self, **kw):\n        \"\"\"Replace existing construction variables in an Environment\n        with new construction variables and/or values.\n        \"\"\"\n        try:\n            kwbd = kw['BUILDERS']\n        except KeyError:\n            pass\n        else:\n            kwbd = BuilderDict(kwbd,self)\n            del kw['BUILDERS']\n            self.__setitem__('BUILDERS', kwbd)\n        kw = copy_non_reserved_keywords(kw)\n        self._update(semi_deepcopy(kw))\n        self.scanner_map_delete(kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces old_prefix with new_prefix and old_suffix with new_suffix.", "response": "def ReplaceIxes(self, path, old_prefix, old_suffix, new_prefix, new_suffix):\n        \"\"\"\n        Replace old_prefix with new_prefix and old_suffix with new_suffix.\n\n        env - Environment used to interpolate variables.\n        path - the path that will be modified.\n        old_prefix - construction variable for the old prefix.\n        old_suffix - construction variable for the old suffix.\n        new_prefix - construction variable for the new prefix.\n        new_suffix - construction variable for the new suffix.\n        \"\"\"\n        old_prefix = self.subst('$'+old_prefix)\n        old_suffix = self.subst('$'+old_suffix)\n\n        new_prefix = self.subst('$'+new_prefix)\n        new_suffix = self.subst('$'+new_suffix)\n\n        dir,name = os.path.split(str(path))\n        if name[:len(old_prefix)] == old_prefix:\n            name = name[len(old_prefix):]\n        if name[-len(old_suffix):] == old_suffix:\n            name = name[:-len(old_suffix)]\n        return os.path.join(dir, new_prefix+name+new_suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the first entry in the path.", "response": "def WhereIs(self, prog, path=None, pathext=None, reject=[]):\n        \"\"\"Find prog in the path.\n        \"\"\"\n        if path is None:\n            try:\n                path = self['ENV']['PATH']\n            except KeyError:\n                pass\n        elif SCons.Util.is_String(path):\n            path = self.subst(path)\n        if pathext is None:\n            try:\n                pathext = self['ENV']['PATHEXT']\n            except KeyError:\n                pass\n        elif SCons.Util.is_String(pathext):\n            pathext = self.subst(pathext)\n        prog = SCons.Util.CLVar(self.subst(prog)) # support \"program --with-args\"\n        path = SCons.Util.WhereIs(prog[0], path, pathext, reject)\n        if path: return path\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the supplied target files from the supplied source files using the supplied action.", "response": "def Command(self, target, source, action, **kw):\n        \"\"\"Builds the supplied target files from the supplied\n        source files using the supplied action.  Action may\n        be any type that the Builder constructor will accept\n        for an action.\"\"\"\n        bkw = {\n            'action' : action,\n            'target_factory' : self.fs.Entry,\n            'source_factory' : self.fs.Entry,\n        }\n        try: bkw['source_scanner'] = kw['source_scanner']\n        except KeyError: pass\n        else: del kw['source_scanner']\n        bld = SCons.Builder.Builder(**bkw)\n        return bld(self, target, source, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntagging a target so that it will not be cleaned by - c", "response": "def NoClean(self, *targets):\n        \"\"\"Tags a target so that it will not be cleaned by -c\"\"\"\n        tlist = []\n        for t in targets:\n            tlist.extend(self.arg2nodes(t, self.fs.Entry))\n        for t in tlist:\n            t.set_noclean()\n        return tlist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntag a target so that it will not be cached.", "response": "def NoCache(self, *targets):\n        \"\"\"Tags a target so that it will not be cached\"\"\"\n        tlist = []\n        for t in targets:\n            tlist.extend(self.arg2nodes(t, self.fs.Entry))\n        for t in tlist:\n            t.set_nocache()\n        return tlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Execute(self, action, *args, **kw):\n        action = self.Action(action, *args, **kw)\n        result = action([], [], self)\n        if isinstance(result, SCons.Errors.BuildError):\n            errstr = result.errstr\n            if result.filename:\n                errstr = result.filename + ': ' + errstr\n            sys.stderr.write(\"scons: *** %s\\n\" % errstr)\n            return result.status\n        else:\n            return result", "response": "Directly execute an action through an Environment\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Requires(self, target, prerequisite):\n        tlist = self.arg2nodes(target, self.fs.Entry)\n        plist = self.arg2nodes(prerequisite, self.fs.Entry)\n        for t in tlist:\n            t.add_prerequisite(plist)\n        return tlist", "response": "Specify that target depends on prerequisite."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SideEffect(self, side_effect, target):\n        side_effects = self.arg2nodes(side_effect, self.fs.Entry)\n        targets = self.arg2nodes(target, self.fs.Entry)\n\n        for side_effect in side_effects:\n            if side_effect.multiple_side_effect_has_builder():\n                raise SCons.Errors.UserError(\"Multiple ways to build the same target were specified for: %s\" % str(side_effect))\n            side_effect.add_source(targets)\n            side_effect.side_effect = 1\n            self.Precious(side_effect)\n            for target in targets:\n                target.side_effects.append(side_effect)\n        return side_effects", "response": "Tellsscons that side_effects are built as side_effects of building targets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SourceCode(self, entry, builder):\n        msg = \"\"\"SourceCode() has been deprecated and there is no replacement.\n\\tIf you need this function, please contact scons-dev@scons.org\"\"\"\n        SCons.Warnings.warn(SCons.Warnings.DeprecatedSourceCodeWarning, msg)\n        entries = self.arg2nodes(entry, self.fs.Entry)\n        for entry in entries:\n            entry.set_src_builder(builder)\n        return entries", "response": "Arrange for a source code builder for a tree entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Split(self, arg):\n\n        if SCons.Util.is_List(arg):\n            return list(map(self.subst, arg))\n        elif SCons.Util.is_String(arg):\n            return self.subst(arg).split()\n        else:\n            return [self.subst(arg)]", "response": "This function converts a string or list into a list of Nodes and strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all source files.", "response": "def FindSourceFiles(self, node='.'):\n        \"\"\" returns a list of all source files.\n        \"\"\"\n        node = self.arg2nodes(node, self.fs.Entry)[0]\n\n        sources = []\n        def build_source(ss):\n            for s in ss:\n                if isinstance(s, SCons.Node.FS.Dir):\n                    build_source(s.all_children())\n                elif s.has_builder():\n                    build_source(s.sources)\n                elif isinstance(s.disambiguate(), SCons.Node.FS.File):\n                    sources.append(s)\n        build_source(node.all_children())\n\n        def final_source(node):\n            while (node != node.srcnode()):\n              node = node.srcnode()\n            return node\n        sources = list(map( final_source, sources ));\n        # remove duplicates\n        return list(set(sources))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef FindInstalledFiles(self):\n        from SCons.Tool import install\n        if install._UNIQUE_INSTALLED_FILES is None:\n            install._UNIQUE_INSTALLED_FILES = SCons.Util.uniquer_hashables(install._INSTALLED_FILES)\n        return install._UNIQUE_INSTALLED_FILES", "response": "returns the list of all targets of the Install and InstallAs Builder."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, key, default=None):\n        try:\n            return self.__dict__['overrides'][key]\n        except KeyError:\n            return self.__dict__['__subject'].get(key, default)", "response": "Emulates the get method of dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nemulating the items method of dictionaries.", "response": "def Dictionary(self):\n        \"\"\"Emulates the items() method of dictionaries.\"\"\"\n        d = self.__dict__['__subject'].Dictionary().copy()\n        d.update(self.__dict__['overrides'])\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FromBinary(cls, record_data, record_count=1):\n\n        _cmd, address, _resp_length, payload = cls._parse_rpc_info(record_data)\n\n        try:\n            value, encoded_stream = struct.unpack(\"<LH\", payload)\n            stream = DataStream.FromEncoded(encoded_stream)\n        except ValueError:\n            raise ArgumentError(\"Could not parse set_constant payload\", payload=payload)\n\n        return SetConstantRecord(stream, value, address=address)", "response": "Create an UpdateRecord subclass from binary record data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(env):\n    global PDFLaTeXAction\n    if PDFLaTeXAction is None:\n        PDFLaTeXAction = SCons.Action.Action('$PDFLATEXCOM', '$PDFLATEXCOMSTR')\n\n    global PDFLaTeXAuxAction\n    if PDFLaTeXAuxAction is None:\n        PDFLaTeXAuxAction = SCons.Action.Action(PDFLaTeXAuxFunction,\n                              strfunction=SCons.Tool.tex.TeXLaTeXStrFunction)\n\n    env.AppendUnique(LATEXSUFFIXES=SCons.Tool.LaTeXSuffixes)\n\n    from . import pdf\n    pdf.generate(env)\n\n    bld = env['BUILDERS']['PDF']\n    bld.add_action('.ltx', PDFLaTeXAuxAction)\n    bld.add_action('.latex', PDFLaTeXAuxAction)\n    bld.add_emitter('.ltx', SCons.Tool.tex.tex_pdf_emitter)\n    bld.add_emitter('.latex', SCons.Tool.tex.tex_pdf_emitter)\n\n    SCons.Tool.tex.generate_common(env)", "response": "Add Builders and construction variables for pdflatex to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scons_copytree(src, dst, symlinks=False):\n    names = os.listdir(src)\n    # garyo@genarts.com fix: check for dir before making dirs.\n    if not os.path.exists(dst):\n        os.makedirs(dst)\n    errors = []\n    for name in names:\n        srcname = os.path.join(src, name)\n        dstname = os.path.join(dst, name)\n        try:\n            if symlinks and os.path.islink(srcname):\n                linkto = os.readlink(srcname)\n                os.symlink(linkto, dstname)\n            elif os.path.isdir(srcname):\n                scons_copytree(srcname, dstname, symlinks)\n            else:\n                shutil.copy2(srcname, dstname)\n            # XXX What about devices, sockets etc.?\n        except (IOError, os.error) as why:\n            errors.append((srcname, dstname, str(why)))\n        # catch the CopytreeError from the recursive copytree so that we can\n        # continue with other files\n        except CopytreeError as err:\n            errors.extend(err.args[0])\n    try:\n        shutil.copystat(src, dst)\n    except SCons.Util.WinError:\n        # can't copy file access times on Windows\n        pass\n    except OSError as why:\n        errors.extend((src, dst, str(why)))\n    if errors:\n        raise CopytreeError(errors)", "response": "Recursively copy a directory tree using copy2."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copyFunc(dest, source, env):\n\n    if os.path.isdir(source):\n        if os.path.exists(dest):\n            if not os.path.isdir(dest):\n                raise SCons.Errors.UserError(\"cannot overwrite non-directory `%s' with a directory `%s'\" % (str(dest), str(source)))\n        else:\n            parent = os.path.split(dest)[0]\n            if not os.path.exists(parent):\n                os.makedirs(parent)\n        scons_copytree(source, dest)\n    else:\n        shutil.copy2(source, dest)\n        st = os.stat(source)\n        os.chmod(dest, stat.S_IMODE(st[stat.ST_MODE]) | stat.S_IWRITE)\n\n    return 0", "response": "Copy a source file or directory into a destination by copying."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies a versioned library into a destination by copying and creating a versioned library required symlinks.", "response": "def copyFuncVersionedLib(dest, source, env):\n    \"\"\"Install a versioned library into a destination by copying,\n    (including copying permission/mode bits) and then creating\n    required symlinks.\"\"\"\n\n    if os.path.isdir(source):\n        raise SCons.Errors.UserError(\"cannot install directory `%s' as a version library\" % str(source) )\n    else:\n        # remove the link if it is already there\n        try:\n            os.remove(dest)\n        except:\n            pass\n        shutil.copy2(source, dest)\n        st = os.stat(source)\n        os.chmod(dest, stat.S_IMODE(st[stat.ST_MODE]) | stat.S_IWRITE)\n        installShlibLinks(dest, source, env)\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef installShlibLinks(dest, source, env):\n    Verbose = False\n    symlinks = listShlibLinksToInstall(dest, source, env)\n    if Verbose:\n        print('installShlibLinks: symlinks={:r}'.format(SCons.Tool.StringizeLibSymlinks(symlinks)))\n    if symlinks:\n        SCons.Tool.CreateLibSymlinks(env, symlinks)\n    return", "response": "Installs the required links for the shared library."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef installFunc(target, source, env):\n    try:\n        install = env['INSTALL']\n    except KeyError:\n        raise SCons.Errors.UserError('Missing INSTALL construction variable.')\n\n    assert len(target)==len(source), \\\n           \"Installing source %s into target %s: target and source lists must have same length.\"%(list(map(str, source)), list(map(str, target)))\n    for t,s in zip(target,source):\n        if install(t.get_path(),s.get_path(),env):\n            return 1\n\n    return 0", "response": "Install a source file into a target using the function specified\n    as the INSTALL construction variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef installFuncVersionedLib(target, source, env):\n    try:\n        install = env['INSTALLVERSIONEDLIB']\n    except KeyError:\n        raise SCons.Errors.UserError('Missing INSTALLVERSIONEDLIB construction variable.')\n\n    assert len(target)==len(source), \\\n           \"Installing source %s into target %s: target and source lists must have same length.\"%(list(map(str, source)), list(map(str, target)))\n    for t,s in zip(target,source):\n        if hasattr(t.attributes, 'shlibname'):\n            tpath = os.path.join(t.get_dir(), t.attributes.shlibname)\n        else:\n            tpath = t.get_path()\n        if install(tpath,s.get_path(),env):\n            return 1\n\n    return 0", "response": "Install a versioned library into a target using the function specified\n    as the INSTALLVERSIONEDLIB construction variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_targets_to_INSTALLED_FILES(target, source, env):\n    global _INSTALLED_FILES, _UNIQUE_INSTALLED_FILES\n    _INSTALLED_FILES.extend(target)\n\n    _UNIQUE_INSTALLED_FILES = None\n    return (target, source)", "response": "An emitter that adds all target files to the list stored in the _INSTALLED_FILES global variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes the contents of this update record without including a record header.", "response": "def encode_contents(self):\n        \"\"\"Encode the contents of this update record without including a record header.\n\n        Returns:\n            bytearray: The encoded contents.\n        \"\"\"\n\n        if self.variable_size:\n            resp_length = 1\n        else:\n            resp_length = self.fixed_response_size << 1\n\n        header = struct.pack(\"<HBB\", self.rpc_id, self.address, resp_length)\n        return bytearray(header) + self.payload"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an UpdateRecord subclass from a binary record.", "response": "def FromBinary(cls, record_data, record_count=1):\n        \"\"\"Create an UpdateRecord subclass from binary record data.\n\n        This should be called with a binary record blob (NOT including the\n        record type header) and it will decode it into a SendRPCRecord.\n\n        Args:\n            record_data (bytearray): The raw record data that we wish to parse\n                into an UpdateRecord subclass NOT including its 8 byte record header.\n            record_count (int): The number of records included in record_data.\n\n        Raises:\n            ArgumentError: If the record_data is malformed and cannot be parsed.\n\n        Returns:\n            SendRPCRecord: The decoded reflash tile record.\n        \"\"\"\n\n        cmd, address, resp_length, payload = cls._parse_rpc_info(record_data)\n\n        # The first bit is 1 if we do not have a fixed length\n        # The next 7 bits encode the fixed length if we do have a fixed length\n        fixed_length = resp_length >> 1\n        if resp_length & 0b1:\n            fixed_length = None\n\n        return cls(address, cmd, payload, fixed_length)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing record_data into multiple error checking rpcs.", "response": "def parse_multiple_rpcs(cls, record_data):\n        \"\"\"Parse record_data into multiple error checking rpcs.\"\"\"\n\n        rpcs = []\n\n        while len(record_data) > 0:\n            total_length, record_type = struct.unpack_from(\"<LB3x\", record_data)\n            if record_type != SendErrorCheckingRPCRecord.RecordType:\n                raise ArgumentError(\"Record set contains a record that is not an error checking RPC\",\n                                    record_type=record_type)\n\n            record_contents = record_data[8: total_length]\n            parsed_rpc = cls._parse_rpc_info(record_contents)\n            rpcs.append(parsed_rpc)\n\n            record_data = record_data[total_length:]\n\n        return rpcs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, sensor_graph, scope_stack):\n\n        if not isinstance(scope_stack[-1], RootScope):\n            raise SensorGraphSemanticError(\"You may only declare metadata at global scope in a sensorgraph.\", identifier=self.identifier, value=self.value)\n\n        sensor_graph.add_metadata(self.identifier, self.value)", "response": "Execute this statement on the sensor_graph given the current scope tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding Builders and construction variables for clang to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for clang to an Environment.\"\"\"\n    SCons.Tool.cc.generate(env)\n\n    env['CC'] = env.Detect(compilers) or 'clang'\n    if env['PLATFORM'] in ['cygwin', 'win32']:\n        env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS')\n    else:\n        env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS -fPIC')\n    # determine compiler version\n    if env['CC']:\n        #pipe = SCons.Action._subproc(env, [env['CC'], '-dumpversion'],\n        pipe = SCons.Action._subproc(env, [env['CC'], '--version'],\n                                     stdin='devnull',\n                                     stderr='devnull',\n                                     stdout=subprocess.PIPE)\n        if pipe.wait() != 0: return\n        # clang -dumpversion is of no use\n        line = pipe.stdout.readline()\n        if sys.version_info[0] > 2:\n            line = line.decode()\n        match = re.search(r'clang +version +([0-9]+(?:\\.[0-9]+)+)', line)\n        if match:\n            env['CCVERSION'] = match.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n\n        if self._generator:\n            try:\n                gen = self._routine(*self._worker_args, **self._worker_kwargs)\n\n                while True:\n                    if self._stop_condition.is_set():\n                        return\n\n                    self._running.set()\n\n                    next(gen)\n\n                    for _i in range(0, self._wait_count):\n                        if self._stop_condition.is_set():\n                            return\n                        time.sleep(self._wait)\n\n            except StopIteration:\n                pass\n            except Exception:\n                print(\"Exception occurred in background worker thread\")\n                traceback.print_exc()\n        else:\n            try:\n                while True:\n                    if self._stop_condition.is_set():\n                        break\n\n                    self._running.set()\n\n                    self._routine(*self._worker_args, **self._worker_kwargs)\n\n                    # Wait for the desired interval, checking if we should exit\n                    for _i in range(0, self._wait_count):\n                        if self._stop_condition.is_set():\n                            return\n\n                        time.sleep(self._wait)\n            except Exception:\n                print(\"Exception occurred in background worker thread\")\n                traceback.print_exc()", "response": "The main thread loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wait_running(self, timeout=None):\n\n        flag = self._running.wait(timeout)\n\n        if flag is False:\n            raise TimeoutExpiredError(\"Timeout waiting for thread to start running\")", "response": "Wait for the thread to pass control to its routine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_event(self, register=False):\n\n        event = asyncio.Event(loop=self._loop)\n        if register:\n            self._events.add(event)\n\n        return event", "response": "Create an asyncio. Event object inside the emulation loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new work queue and optionally register it.", "response": "def create_queue(self, register=False):\n        \"\"\"Create a new work queue and optionally register it.\n\n        This will make sure the queue is attached to the correct event loop.\n        You can optionally choose to automatically register it so that\n        wait_idle() will block until the queue is empty.\n\n        Args:\n            register (bool): Whether to call register_workqueue() automatically.\n\n        Returns:\n            asyncio.Queue: The newly created queue.\n        \"\"\"\n\n        queue = asyncio.Queue(loop=self._loop)\n        if register:\n            self._work_queues.add(queue)\n\n        return queue"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinishes a previous asynchronous RPC.", "response": "def finish_async_rpc(self, address, rpc_id, *response):\n        \"\"\"Finish a previous asynchronous RPC.\n\n        This method should be called by a peripheral tile that previously\n        had an RPC called on it and chose to response asynchronously by\n        raising ``AsynchronousRPCResponse`` in the RPC handler itself.\n\n        The response passed to this function will be returned to the caller\n        as if the RPC had returned it immediately.\n\n        This method must only ever be called from a coroutine inside the\n        emulation loop that is handling background work on behalf of a tile.\n\n        Args:\n            address (int): The tile address the RPC was called on.\n            rpc_id (int): The ID of the RPC that was called.\n            *response: The response that should be returned to the caller.\n\n                This can either be a single bytes or bytearray object or a\n                str object containing the format code followed by the required\n                number of python objects that will then be packed using\n                pack_rpc_payload(format, args).\n\n                If you pass no additional response arguments then an\n                empty response will be given.\n        \"\"\"\n\n        self.verify_calling_thread(True, \"All asynchronous rpcs must be finished from within the emulation loop\")\n\n        if len(response) == 0:\n            response_bytes = b''\n        elif len(response) == 1:\n            response_bytes = response[0]\n\n            if not isinstance(response_bytes, (bytes, bytearray)):\n                raise ArgumentError(\"When passing a binary response to finish_async_rpc, you must \"\n                                    \"pass a bytes or bytearray object\", response=response_bytes)\n        else:\n            resp_format = response[0]\n            resp_args = response[1:]\n\n            if not isinstance(resp_format, str):\n                raise ArgumentError(\"When passing a formatted response to finish_async_rpc, you must \"\n                                    \"pass a str object with the format code as the first parameter after \"\n                                    \"the rpc id.\", resp_format=resp_format, additional_args=resp_args)\n\n            response_bytes = pack_rpc_payload(resp_format, resp_args)\n\n        self._rpc_queue.finish_async_rpc(address, rpc_id, response_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n\n        if self._started is True:\n            raise ArgumentError(\"EmulationLoop.start() called multiple times\")\n\n        self._thread = threading.Thread(target=self._loop_thread_main)\n        self._thread.start()\n        self._started = True", "response": "Start the background emulation loop."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n\n        if self._started is False:\n            raise ArgumentError(\"EmulationLoop.stop() called without calling start()\")\n\n        self.verify_calling_thread(False, \"Cannot call EmulationLoop.stop() from inside the event loop\")\n\n        if self._thread.is_alive():\n            self._loop.call_soon_threadsafe(self._loop.create_task, self._clean_shutdown())\n            self._thread.join()", "response": "Stop the background emulation loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_idle(self, timeout=1.0):\n\n        async def _awaiter():\n            background_work = {x.join() for x in self._work_queues}\n            for event in self._events:\n                if not event.is_set():\n                    background_work.add(event.wait())\n\n            _done, pending = await asyncio.wait(background_work, timeout=timeout)\n            if len(pending) > 0:\n                raise TimeoutExpiredError(\"Timeout waiting for event loop to become idle\", pending=pending)\n\n        if self._on_emulation_thread():\n            return asyncio.wait_for(_awaiter(), timeout=timeout)\n\n        self.run_task_external(_awaiter())\n        return None", "response": "Wait until the event loop is empty."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_task_external(self, coroutine):\n\n        self.verify_calling_thread(False, 'run_task_external must not be called from the emulation thread')\n\n        future = asyncio.run_coroutine_threadsafe(coroutine, self._loop)\n        return future.result()", "response": "Inject a task into the emulation loop and wait for it to finish."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling an external RPC from outside of the event loop and block until it completes.", "response": "def call_rpc_external(self, address, rpc_id, arg_payload, timeout=10.0):\n        \"\"\"Call an RPC from outside of the event loop and block until it finishes.\n\n        This is the main method by which a caller outside of the EmulationLoop\n        can inject an RPC into the EmulationLoop and wait for it to complete.\n        This method is synchronous so it blocks until the RPC completes or the\n        timeout expires.\n\n        Args:\n            address (int): The address of the mock tile this RPC is for\n            rpc_id (int): The number of the RPC\n            payload (bytes): A byte string of payload parameters up to 20 bytes\n            timeout (float): The maximum time to wait for the RPC to finish.\n\n        Returns:\n            bytes: The response payload from the RPC\n        \"\"\"\n\n        self.verify_calling_thread(False, \"call_rpc_external is for use **outside** of the event loop\")\n\n        response = CrossThreadResponse()\n\n        self._loop.call_soon_threadsafe(self._rpc_queue.put_rpc, address, rpc_id, arg_payload, response)\n\n        try:\n            return response.wait(timeout)\n        except RPCRuntimeError as err:\n            return err.binary_error"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an RPC from inside the EmulationLoop. This is the primary method by which tasks running inside the EmulationLoop dispatch RPCs. The RPC is added to the queue of waiting RPCs to be drained by the RPC dispatch task and this coroutine will block until it finishes. **This method must only be called from inside the EmulationLoop** Args: address (int): The address of the tile that has the RPC. rpc_id (int): The 16-bit id of the rpc we want to call *args: Any required arguments for the RPC as python objects. **kwargs: Only two keyword arguments are supported: - arg_format: A format specifier for the argument list - result_format: A format specifier for the result Returns: list: A list of the decoded response members from the RPC.", "response": "async def await_rpc(self, address, rpc_id, *args, **kwargs):\n        \"\"\"Send an RPC from inside the EmulationLoop.\n\n        This is the primary method by which tasks running inside the\n        EmulationLoop dispatch RPCs.  The RPC is added to the queue of waiting\n        RPCs to be drained by the RPC dispatch task and this coroutine will\n        block until it finishes.\n\n        **This method must only be called from inside the EmulationLoop**\n\n        Args:\n            address (int): The address of the tile that has the RPC.\n            rpc_id (int): The 16-bit id of the rpc we want to call\n            *args: Any required arguments for the RPC as python objects.\n            **kwargs: Only two keyword arguments are supported:\n                - arg_format: A format specifier for the argument list\n                - result_format: A format specifier for the result\n\n        Returns:\n            list: A list of the decoded response members from the RPC.\n        \"\"\"\n\n        self.verify_calling_thread(True, \"await_rpc must be called from **inside** the event loop\")\n\n        if isinstance(rpc_id, RPCDeclaration):\n            arg_format = rpc_id.arg_format\n            resp_format = rpc_id.resp_format\n            rpc_id = rpc_id.rpc_id\n        else:\n            arg_format = kwargs.get('arg_format', None)\n            resp_format = kwargs.get('resp_format', None)\n\n        arg_payload = b''\n\n        if arg_format is not None:\n            arg_payload = pack_rpc_payload(arg_format, args)\n\n        self._logger.debug(\"Sending rpc to %d:%04X, payload=%s\", address, rpc_id, args)\n\n        response = AwaitableResponse()\n        self._rpc_queue.put_rpc(address, rpc_id, arg_payload, response)\n\n        try:\n            resp_payload = await response.wait(1.0)\n        except RPCRuntimeError as err:\n            resp_payload = err.binary_error\n\n        if resp_format is None:\n            return []\n\n        resp = unpack_rpc_payload(resp_format, resp_payload)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies if the calling thread is the emulation thread.", "response": "def verify_calling_thread(self, should_be_emulation, message=None):\n        \"\"\"Verify if the calling thread is or is not the emulation thread.\n\n        This method can be called to make sure that an action is being taken\n        in the appropriate context such as not blocking the event loop thread\n        or modifying an emulate state outside of the event loop thread.\n\n        If the verification fails an InternalError exception is raised,\n        allowing this method to be used to protect other methods from being\n        called in a context that could deadlock or cause race conditions.\n\n        Args:\n            should_be_emulation (bool): True if this call should be taking place\n                on the emulation, thread, False if it must not take place on\n                the emulation thread.\n            message (str): Optional message to include when raising the exception.\n                Otherwise a generic message is used.\n\n        Raises:\n            InternalError: When called from the wrong thread.\n        \"\"\"\n\n        if should_be_emulation == self._on_emulation_thread():\n            return\n\n        if message is None:\n            message = \"Operation performed on invalid thread\"\n\n        raise InternalError(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a task into the event loop.", "response": "def add_task(self, tile_address, coroutine):\n        \"\"\"Add a task into the event loop.\n\n        This is the main entry point for registering background tasks that are\n        associated with a tile. The tasks are added to the EmulationLoop and\n        the tile they are a part of is recorded.  When the tile is reset, all\n        of its background tasks are canceled as part of the reset process.\n\n        If you have a task that should not be associated with any tile, you\n        may pass `None` for tile_address and the task will not be cancelled\n        when any tile is reset.\n\n        Args:\n            tile_address (int): The address of the tile running\n                the task.\n            coroutine (coroutine): A coroutine that will be added\n                to the event loop.\n        \"\"\"\n\n        self._loop.call_soon_threadsafe(self._add_task, tile_address, coroutine)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop all tasks pertaining to a given tile.", "response": "async def stop_tasks(self, address):\n        \"\"\"Clear all tasks pertaining to a tile.\n\n        This coroutine will synchronously cancel all running tasks that were\n        attached to the given tile and wait for them to stop before returning.\n\n        Args:\n            address (int): The address of the tile we should stop.\n        \"\"\"\n\n        tasks = self._tasks.get(address, [])\n        for task in tasks:\n            task.cancel()\n\n        asyncio.gather(*tasks, return_exceptions=True)\n        self._tasks[address] = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_task(self, tile_address, coroutine):\n\n        self.verify_calling_thread(True, \"_add_task is not thread safe\")\n\n        if tile_address not in self._tasks:\n            self._tasks[tile_address] = []\n\n        task = self._loop.create_task(coroutine)\n        self._tasks[tile_address].append(task)", "response": "Add a task from within the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef key_rule(self, regex, verifier):\n\n        if regex is not None:\n            regex = re.compile(regex)\n\n        self._additional_key_rules.append((regex, verifier))", "response": "Add a rule that should be applied to all keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying that the object conforms to this verifier s schema.", "response": "def verify(self, obj):\n        \"\"\"Verify that the object conforms to this verifier's schema\n\n        Args:\n            obj (object): A python object to verify\n\n        Raises:\n            ValidationError: If there is a problem verifying the dictionary, a\n                ValidationError is thrown with at least the reason key set indicating\n                the reason for the lack of validation.\n        \"\"\"\n\n        out_obj = {}\n\n        if not isinstance(obj, dict):\n            raise ValidationError(\"Invalid dictionary\", reason=\"object is not a dictionary\")\n\n        if self._fixed_length is not None and len(obj) != self._fixed_length:\n            raise ValidationError(\"Dictionary did not have the correct length\", expected_length=self._fixed_length,\n                                  actual_length=self._fixed_length)\n\n        unmatched_keys = set(obj.keys())\n        required_keys = set(self._required_keys.keys())\n\n        # First check and make sure that all required keys are included and verify them\n        for key in required_keys:\n            if key not in unmatched_keys:\n                raise ValidationError(\"Required key not found in dictionary\",\n                                      reason=\"required key %s not found\" % key, key=key)\n\n            out_obj[key] = self._required_keys[key].verify(obj[key])\n            unmatched_keys.remove(key)\n\n        # Now check and see if any of the keys in the dictionary are optional and check them\n        to_remove = set()\n        for key in unmatched_keys:\n            if key not in self._optional_keys:\n                continue\n\n            out_obj[key] = self._optional_keys[key].verify(obj[key])\n            to_remove.add(key)\n\n        unmatched_keys -= to_remove\n\n        # If there are additional keys, they need to match at least one of the additional key rules\n        if len(unmatched_keys) > 0:\n            if len(self._additional_key_rules) == 0:\n                raise ValidationError(\"Extra key found in dictionary that does not allow extra keys\",\n                                      reason=\"extra keys found that were not expected\", keys=unmatched_keys)\n\n            to_remove = set()\n            for key in unmatched_keys:\n                for key_match, rule in self._additional_key_rules:\n                    if key_match is None or key_match.matches(key):\n                        out_obj[key] = rule.verify(obj[key])\n                        to_remove.add(key)\n                        break\n\n            unmatched_keys -= to_remove\n\n            if len(unmatched_keys) > 0:\n                raise ValidationError(\"Extra key found in dictionary that did not match any extra key rule\",\n                                      reason=\"extra keys found that did not match any rule\", keys=unmatched_keys)\n\n        return out_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueues data for streaming to a client", "response": "def stream(self, report, callback=None):\n        \"\"\"Queue data for streaming\n\n        Args:\n            report (IOTileReport): A report object to stream to a client\n            callback (callable): An optional callback that will be called with\n                a bool value of True when this report actually gets streamed.\n                If the client disconnects and the report is dropped instead,\n                callback will be called with False\n        \"\"\"\n\n        conn_id = self._find_connection(self.conn_string)\n\n        if isinstance(report, BroadcastReport):\n            self.adapter.notify_event_nowait(self.conn_string, 'broadcast', report)\n        elif conn_id is not None:\n            self.adapter.notify_event_nowait(self.conn_string, 'report', report)\n\n        if callback is not None:\n            callback(isinstance(report, BroadcastReport) or (conn_id is not None))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nqueuing data for tracing", "response": "def trace(self, data, callback=None):\n        \"\"\"Queue data for tracing\n\n        Args:\n            data (bytearray, string): Unstructured data to trace to any\n                connected client.\n            callback (callable): An optional callback that will be called with\n                a bool value of True when this data actually gets traced.\n                If the client disconnects and the data is dropped instead,\n                callback will be called with False.\n        \"\"\"\n\n        conn_id = self._find_connection(self.conn_string)\n\n        if conn_id is not None:\n            self.adapter.notify_event_nowait(self.conn_string, 'trace', data)\n\n        if callback is not None:\n            callback(conn_id is not None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a virtual iotile device from a script or an installed module.", "response": "def _load_device(self, name, config):\n        \"\"\"Load a device either from a script or from an installed module\"\"\"\n\n        if config is None:\n            config_dict = {}\n        elif isinstance(config, dict):\n            config_dict = config\n        elif config[0] == '#':\n            # Allow passing base64 encoded json directly in the port string to ease testing.\n            import base64\n            config_str = str(base64.b64decode(config[1:]), 'utf-8')\n            config_dict = json.loads(config_str)\n        else:\n            try:\n                with open(config, \"r\") as conf:\n                    data = json.load(conf)\n            except IOError as exc:\n                raise ArgumentError(\"Could not open config file\", error=str(exc), path=config)\n\n            if 'device' not in data:\n                raise ArgumentError(\"Invalid configuration file passed to VirtualDeviceAdapter\",\n                                    device_name=name, config_path=config, missing_key='device')\n\n            config_dict = data['device']\n\n        reg = ComponentRegistry()\n\n        if name.endswith('.py'):\n            _name, device_factory = reg.load_extension(name, class_filter=VirtualIOTileDevice, unique=True)\n            return device_factory(config_dict)\n\n        seen_names = []\n        for device_name, device_factory in reg.load_extensions('iotile.virtual_device',\n                                                               class_filter=VirtualIOTileDevice,\n                                                               product_name=\"virtual_device\"):\n            if device_name == name:\n                return device_factory(config_dict)\n\n            seen_names.append(device_name)\n\n        raise ArgumentError(\"Could not find virtual_device by name\", name=name, known_names=seen_names)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def connect(self, conn_id, connection_string):\n\n        id_number = int(connection_string)\n        if id_number not in self.devices:\n            raise DeviceAdapterError(conn_id, 'connect', 'device not found')\n\n        if self._get_conn_id(connection_string) is not None:\n            raise DeviceAdapterError(conn_id, 'connect', 'device already connected')\n\n        dev = self.devices[id_number]\n\n        if dev.connected:\n            raise DeviceAdapterError(conn_id, 'connect', 'device already connected')\n\n        dev.connected = True\n\n        self._setup_connection(conn_id, connection_string)\n        self._track_property(conn_id, 'device', dev)", "response": "Asynchronously connect to a device in a device adapter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def disconnect(self, conn_id):\n\n        self._ensure_connection(conn_id, True)\n\n        dev = self._get_property(conn_id, 'device')\n        dev.connected = False\n\n        self._teardown_connection(conn_id)", "response": "Asynchronously disconnect from a connected device"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def send_script(self, conn_id, data):\n\n        self._ensure_connection(conn_id, True)\n        dev = self._get_property(conn_id, 'device')\n        conn_string = self._get_property(conn_id, 'connection_string')\n\n        # Simulate some progress callbacks (0, 50%, 100%)\n        await self.notify_progress(conn_string, 'script', 0, len(data))\n        await self.notify_progress(conn_string, 'script', len(data) // 2, len(data))\n        await self.notify_progress(conn_string, 'script', len(data), len(data))\n\n        dev.script = data", "response": "Asynchronously send a script to the IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a debug command to a device.", "response": "async def debug(self, conn_id, name, cmd_args):\n        \"\"\"Send a debug command to a device.\n\n        This method responds to a single command 'inspect_property' that takes\n        the name of a propery on the device and returns its value.  The\n        ``cmd_args`` dict should have a single key: 'properties' that is a\n        list of strings with the property names that should be returned.\n\n        Those properties are all queried and their result returned.\n\n        The result is a dict that maps property name to value.  There is a\n        progress event generated for every property whose purpose is primarily\n        to allow for testing the progress system of a device server.\n\n        See :meth:`AbstractDeviceAdapter.debug`.\n        \"\"\"\n\n        self._ensure_connection(conn_id, True)\n        dev = self._get_property(conn_id, 'device')\n        conn_string = self._get_property(conn_id, 'connection_string')\n\n        if name != 'inspect_property':\n            raise DeviceAdapterError(conn_id, 'debug', 'operation {} not supported'.format(name))\n\n        properties = cmd_args.get('properties', [])\n\n        result = {}\n\n        for i, prop in enumerate(properties):\n            if not hasattr(dev, prop):\n                raise DeviceAdapterError(conn_id, 'debug', 'property {} did not exist'.format(prop))\n\n            value = getattr(dev, prop)\n            result[prop] = value\n\n            await self.notify_progress(conn_string, 'debug', i + 1, len(properties))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a scan event from a device.", "response": "async def _send_scan_event(self, device):\n        \"\"\"Send a scan event from a device.\"\"\"\n\n        conn_string = str(device.iotile_id)\n        info = {\n            'connection_string': conn_string,\n            'uuid': device.iotile_id,\n            'signal_strength': 100,\n            'validity_period': self.ExpirationTime\n        }\n\n        await self.notify_event(conn_string, 'device_seen', info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmaps an RPC id to a string name.", "response": "def rpc_name(rpc_id):\n    \"\"\"Map an RPC id to a string name.\n\n    This function looks the RPC up in a map of all globally declared RPCs,\n    and returns a nice name string.  if the RPC is not found in the global\n    name map, returns a generic name string such as 'rpc 0x%04X'.\n\n    Args:\n        rpc_id (int): The id of the RPC that we wish to look up.\n\n    Returns:\n        str: The nice name of the RPC.\n    \"\"\"\n\n    name = _RPC_NAME_MAP.get(rpc_id)\n    if name is None:\n        name = 'RPC 0x%04X' % rpc_id\n\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps a stream id to a human readable name.", "response": "def stream_name(stream_id):\n    \"\"\"Map a stream id to a human readable name.\n\n    The mapping process is as follows:\n\n    If the stream id is globally known, its global name is used as <name>\n    otherwise a string representation of the stream is used as <name>.\n\n    In both cases the hex representation of the stream id is appended as a\n    number:\n\n    <name> (0x<stream id in hex>)\n\n    Args:\n        stream_id (int): An integer stream id.\n\n    Returns:\n        str: The nice name of the stream.\n    \"\"\"\n\n    name = _STREAM_NAME_MAP.get(stream_id)\n    if name is None:\n        name = str(DataStream.FromEncoded(stream_id))\n\n    return \"{} (0x{:04X})\".format(name, stream_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an options parser object initialized with the standard SCons options.", "response": "def Parser(version):\n    \"\"\"\n    Returns an options parser object initialized with the standard\n    SCons options.\n    \"\"\"\n\n    formatter = SConsIndentedHelpFormatter(max_help_position=30)\n\n    op = SConsOptionParser(option_class=SConsOption,\n                           add_help_option=False,\n                           formatter=formatter,\n                           usage=\"usage: scons [OPTION] [TARGET] ...\",)\n\n    op.preserve_unknown_options = True\n    op.version = version\n\n    # Add the options to the parser we just created.\n    #\n    # These are in the order we want them to show up in the -H help\n    # text, basically alphabetical.  Each op.add_option() call below\n    # should have a consistent format:\n    #\n    #   op.add_option(\"-L\", \"--long-option-name\",\n    #                 nargs=1, type=\"string\",\n    #                 dest=\"long_option_name\", default='foo',\n    #                 action=\"callback\", callback=opt_long_option,\n    #                 help=\"help text goes here\",\n    #                 metavar=\"VAR\")\n    #\n    # Even though the optparse module constructs reasonable default\n    # destination names from the long option names, we're going to be\n    # explicit about each one for easier readability and so this code\n    # will at least show up when grepping the source for option attribute\n    # names, or otherwise browsing the source code.\n\n    # options ignored for compatibility\n    def opt_ignore(option, opt, value, parser):\n        sys.stderr.write(\"Warning:  ignoring %s option\\n\" % opt)\n    op.add_option(\"-b\", \"-d\", \"-e\", \"-m\", \"-S\", \"-t\", \"-w\",\n                  \"--environment-overrides\",\n                  \"--no-keep-going\",\n                  \"--no-print-directory\",\n                  \"--print-directory\",\n                  \"--stop\",\n                  \"--touch\",\n                  action=\"callback\", callback=opt_ignore,\n                  help=\"Ignored for compatibility.\")\n\n    op.add_option('-c', '--clean', '--remove',\n                  dest=\"clean\", default=False,\n                  action=\"store_true\",\n                  help=\"Remove specified targets and dependencies.\")\n\n    op.add_option('-C', '--directory',\n                  nargs=1, type=\"string\",\n                  dest=\"directory\", default=[],\n                  action=\"append\",\n                  help=\"Change to DIR before doing anything.\",\n                  metavar=\"DIR\")\n\n    op.add_option('--cache-debug',\n                  nargs=1,\n                  dest=\"cache_debug\", default=None,\n                  action=\"store\",\n                  help=\"Print CacheDir debug info to FILE.\",\n                  metavar=\"FILE\")\n\n    op.add_option('--cache-disable', '--no-cache',\n                  dest='cache_disable', default=False,\n                  action=\"store_true\",\n                  help=\"Do not retrieve built targets from CacheDir.\")\n\n    op.add_option('--cache-force', '--cache-populate',\n                  dest='cache_force', default=False,\n                  action=\"store_true\",\n                  help=\"Copy already-built targets into the CacheDir.\")\n\n    op.add_option('--cache-readonly',\n                  dest='cache_readonly', default=False,\n                  action=\"store_true\",\n                  help=\"Do not update CacheDir with built targets.\")\n\n    op.add_option('--cache-show',\n                  dest='cache_show', default=False,\n                  action=\"store_true\",\n                  help=\"Print build actions for files from CacheDir.\")\n\n    def opt_invalid(group, value, options):\n        errmsg  = \"`%s' is not a valid %s option type, try:\\n\" % (value, group)\n        return errmsg + \"    %s\" % \", \".join(options)\n\n    config_options = [\"auto\", \"force\" ,\"cache\"]\n\n    opt_config_help = \"Controls Configure subsystem: %s.\" \\\n                      % \", \".join(config_options)\n\n    op.add_option('--config',\n                  nargs=1, choices=config_options,\n                  dest=\"config\", default=\"auto\",\n                  help = opt_config_help,\n                  metavar=\"MODE\")\n\n    op.add_option('-D',\n                  dest=\"climb_up\", default=None,\n                  action=\"store_const\", const=2,\n                  help=\"Search up directory tree for SConstruct,       \"\n                       \"build all Default() targets.\")\n\n    deprecated_debug_options = {\n        \"dtree\"         : '; please use --tree=derived instead',\n        \"nomemoizer\"    : ' and has no effect',\n        \"stree\"         : '; please use --tree=all,status instead',\n        \"tree\"          : '; please use --tree=all instead',\n    }\n\n    debug_options = [\"count\", \"duplicate\", \"explain\", \"findlibs\",\n                     \"includes\", \"memoizer\", \"memory\", \"objects\",\n                     \"pdb\", \"prepare\", \"presub\", \"stacktrace\",\n                     \"time\"]\n\n    def opt_debug(option, opt, value__, parser,\n                  debug_options=debug_options,\n                  deprecated_debug_options=deprecated_debug_options):\n        for value in value__.split(','):\n            if value in debug_options:\n                parser.values.debug.append(value)\n            elif value in list(deprecated_debug_options.keys()):\n                parser.values.debug.append(value)\n                try:\n                    parser.values.delayed_warnings\n                except AttributeError:\n                    parser.values.delayed_warnings = []\n                msg = deprecated_debug_options[value]\n                w = \"The --debug=%s option is deprecated%s.\" % (value, msg)\n                t = (SCons.Warnings.DeprecatedDebugOptionsWarning, w)\n                parser.values.delayed_warnings.append(t)\n            else:\n                raise OptionValueError(opt_invalid('debug', value, debug_options))\n\n    opt_debug_help = \"Print various types of debugging information: %s.\" \\\n                     % \", \".join(debug_options)\n    op.add_option('--debug',\n                  nargs=1, type=\"string\",\n                  dest=\"debug\", default=[],\n                  action=\"callback\", callback=opt_debug,\n                  help=opt_debug_help,\n                  metavar=\"TYPE\")\n\n    def opt_diskcheck(option, opt, value, parser):\n        try:\n            diskcheck_value = diskcheck_convert(value)\n        except ValueError as e:\n            raise OptionValueError(\"`%s' is not a valid diskcheck type\" % e)\n        setattr(parser.values, option.dest, diskcheck_value)\n\n    op.add_option('--diskcheck',\n                  nargs=1, type=\"string\",\n                  dest='diskcheck', default=None,\n                  action=\"callback\", callback=opt_diskcheck,\n                  help=\"Enable specific on-disk checks.\",\n                  metavar=\"TYPE\")\n\n    def opt_duplicate(option, opt, value, parser):\n        if not value in SCons.Node.FS.Valid_Duplicates:\n            raise OptionValueError(opt_invalid('duplication', value,\n                                              SCons.Node.FS.Valid_Duplicates))\n        setattr(parser.values, option.dest, value)\n        # Set the duplicate style right away so it can affect linking\n        # of SConscript files.\n        SCons.Node.FS.set_duplicate(value)\n\n    opt_duplicate_help = \"Set the preferred duplication methods. Must be one of \" \\\n                         + \", \".join(SCons.Node.FS.Valid_Duplicates)\n\n    op.add_option('--duplicate',\n                  nargs=1, type=\"string\",\n                  dest=\"duplicate\", default='hard-soft-copy',\n                  action=\"callback\", callback=opt_duplicate,\n                  help=opt_duplicate_help)\n\n    op.add_option('-f', '--file', '--makefile', '--sconstruct',\n                  nargs=1, type=\"string\",\n                  dest=\"file\", default=[],\n                  action=\"append\",\n                  help=\"Read FILE as the top-level SConstruct file.\")\n\n    op.add_option('-h', '--help',\n                  dest=\"help\", default=False,\n                  action=\"store_true\",\n                  help=\"Print defined help message, or this one.\")\n\n    op.add_option(\"-H\", \"--help-options\",\n                  action=\"help\",\n                  help=\"Print this message and exit.\")\n\n    op.add_option('-i', '--ignore-errors',\n                  dest='ignore_errors', default=False,\n                  action=\"store_true\",\n                  help=\"Ignore errors from build actions.\")\n\n    op.add_option('-I', '--include-dir',\n                  nargs=1,\n                  dest='include_dir', default=[],\n                  action=\"append\",\n                  help=\"Search DIR for imported Python modules.\",\n                  metavar=\"DIR\")\n\n    op.add_option('--implicit-cache',\n                  dest='implicit_cache', default=False,\n                  action=\"store_true\",\n                  help=\"Cache implicit dependencies\")\n\n    def opt_implicit_deps(option, opt, value, parser):\n        setattr(parser.values, 'implicit_cache', True)\n        setattr(parser.values, option.dest, True)\n\n    op.add_option('--implicit-deps-changed',\n                  dest=\"implicit_deps_changed\", default=False,\n                  action=\"callback\", callback=opt_implicit_deps,\n                  help=\"Ignore cached implicit dependencies.\")\n\n    op.add_option('--implicit-deps-unchanged',\n                  dest=\"implicit_deps_unchanged\", default=False,\n                  action=\"callback\", callback=opt_implicit_deps,\n                  help=\"Ignore changes in implicit dependencies.\")\n\n    op.add_option('--interact', '--interactive',\n                  dest='interactive', default=False,\n                  action=\"store_true\",\n                  help=\"Run in interactive mode.\")\n\n    op.add_option('-j', '--jobs',\n                  nargs=1, type=\"int\",\n                  dest=\"num_jobs\", default=1,\n                  action=\"store\",\n                  help=\"Allow N jobs at once.\",\n                  metavar=\"N\")\n\n    op.add_option('-k', '--keep-going',\n                  dest='keep_going', default=False,\n                  action=\"store_true\",\n                  help=\"Keep going when a target can't be made.\")\n\n    op.add_option('--max-drift',\n                  nargs=1, type=\"int\",\n                  dest='max_drift', default=SCons.Node.FS.default_max_drift,\n                  action=\"store\",\n                  help=\"Set maximum system clock drift to N seconds.\",\n                  metavar=\"N\")\n\n    op.add_option('--md5-chunksize',\n                  nargs=1, type=\"int\",\n                  dest='md5_chunksize', default=SCons.Node.FS.File.md5_chunksize,\n                  action=\"store\",\n                  help=\"Set chunk-size for MD5 signature computation to N kilobytes.\",\n                  metavar=\"N\")\n\n    op.add_option('-n', '--no-exec', '--just-print', '--dry-run', '--recon',\n                  dest='no_exec', default=False,\n                  action=\"store_true\",\n                  help=\"Don't build; just print commands.\")\n\n    op.add_option('--no-site-dir',\n                  dest='no_site_dir', default=False,\n                  action=\"store_true\",\n                  help=\"Don't search or use the usual site_scons dir.\")\n\n    op.add_option('--profile',\n                  nargs=1,\n                  dest=\"profile_file\", default=None,\n                  action=\"store\",\n                  help=\"Profile SCons and put results in FILE.\",\n                  metavar=\"FILE\")\n\n    op.add_option('-q', '--question',\n                  dest=\"question\", default=False,\n                  action=\"store_true\",\n                  help=\"Don't build; exit status says if up to date.\")\n\n    op.add_option('-Q',\n                  dest='no_progress', default=False,\n                  action=\"store_true\",\n                  help=\"Suppress \\\"Reading/Building\\\" progress messages.\")\n\n    op.add_option('--random',\n                  dest=\"random\", default=False,\n                  action=\"store_true\",\n                  help=\"Build dependencies in random order.\")\n\n    op.add_option('-s', '--silent', '--quiet',\n                  dest=\"silent\", default=False,\n                  action=\"store_true\",\n                  help=\"Don't print commands.\")\n\n    op.add_option('--site-dir',\n                  nargs=1,\n                  dest='site_dir', default=None,\n                  action=\"store\",\n                  help=\"Use DIR instead of the usual site_scons dir.\",\n                  metavar=\"DIR\")\n\n    op.add_option('--stack-size',\n                  nargs=1, type=\"int\",\n                  dest='stack_size',\n                  action=\"store\",\n                  help=\"Set the stack size of the threads used to run jobs to N kilobytes.\",\n                  metavar=\"N\")\n\n    op.add_option('--taskmastertrace',\n                  nargs=1,\n                  dest=\"taskmastertrace_file\", default=None,\n                  action=\"store\",\n                  help=\"Trace Node evaluation to FILE.\",\n                  metavar=\"FILE\")\n\n    tree_options = [\"all\", \"derived\", \"prune\", \"status\"]\n\n    def opt_tree(option, opt, value, parser, tree_options=tree_options):\n        from . import Main\n        tp = Main.TreePrinter()\n        for o in value.split(','):\n            if o == 'all':\n                tp.derived = False\n            elif o == 'derived':\n                tp.derived = True\n            elif o == 'prune':\n                tp.prune = True\n            elif o == 'status':\n                tp.status = True\n            else:\n                raise OptionValueError(opt_invalid('--tree', o, tree_options))\n        parser.values.tree_printers.append(tp)\n\n    opt_tree_help = \"Print a dependency tree in various formats: %s.\" \\\n                    % \", \".join(tree_options)\n\n    op.add_option('--tree',\n                  nargs=1, type=\"string\",\n                  dest=\"tree_printers\", default=[],\n                  action=\"callback\", callback=opt_tree,\n                  help=opt_tree_help,\n                  metavar=\"OPTIONS\")\n\n    op.add_option('-u', '--up', '--search-up',\n                  dest=\"climb_up\", default=0,\n                  action=\"store_const\", const=1,\n                  help=\"Search up directory tree for SConstruct,       \"\n                       \"build targets at or below current directory.\")\n\n    op.add_option('-U',\n                  dest=\"climb_up\", default=0,\n                  action=\"store_const\", const=3,\n                  help=\"Search up directory tree for SConstruct,       \"\n                       \"build Default() targets from local SConscript.\")\n\n    def opt_version(option, opt, value, parser):\n        sys.stdout.write(parser.version + '\\n')\n        sys.exit(0)\n    op.add_option(\"-v\", \"--version\",\n                  action=\"callback\", callback=opt_version,\n                  help=\"Print the SCons version number and exit.\")\n\n    def opt_warn(option, opt, value, parser, tree_options=tree_options):\n        if SCons.Util.is_String(value):\n            value = value.split(',')\n        parser.values.warn.extend(value)\n\n    op.add_option('--warn', '--warning',\n                  nargs=1, type=\"string\",\n                  dest=\"warn\", default=[],\n                  action=\"callback\", callback=opt_warn,\n                  help=\"Enable or disable warnings.\",\n                  metavar=\"WARNING-SPEC\")\n\n    op.add_option('-Y', '--repository', '--srcdir',\n                  nargs=1,\n                  dest=\"repository\", default=[],\n                  action=\"append\",\n                  help=\"Search REPOSITORY for source and target files.\")\n\n    # Options from Make and Cons classic that we do not yet support,\n    # but which we may support someday and whose (potential) meanings\n    # we don't want to change.  These all get a \"the -X option is not\n    # yet implemented\" message and don't show up in the help output.\n\n    def opt_not_yet(option, opt, value, parser):\n        msg = \"Warning:  the %s option is not yet implemented\\n\" % opt\n        sys.stderr.write(msg)\n\n    op.add_option('-l', '--load-average', '--max-load',\n                  nargs=1, type=\"float\",\n                  dest=\"load_average\", default=0,\n                  action=\"callback\", callback=opt_not_yet,\n                  # action=\"store\",\n                  # help=\"Don't start multiple jobs unless load is below \"\n                  #      \"LOAD-AVERAGE.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--list-actions',\n                  dest=\"list_actions\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Don't build; list files and build actions.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--list-derived',\n                  dest=\"list_derived\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Don't build; list files that would be built.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--list-where',\n                  dest=\"list_where\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Don't build; list files and where defined.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('-o', '--old-file', '--assume-old',\n                  nargs=1, type=\"string\",\n                  dest=\"old_file\", default=[],\n                  action=\"callback\", callback=opt_not_yet,\n                  # action=\"append\",\n                  # help = \"Consider FILE to be old; don't rebuild it.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--override',\n                  nargs=1, type=\"string\",\n                  action=\"callback\", callback=opt_not_yet,\n                  dest=\"override\",\n                  # help=\"Override variables as specified in FILE.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('-p',\n                  action=\"callback\", callback=opt_not_yet,\n                  dest=\"p\",\n                  # help=\"Print internal environments/objects.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('-r', '-R', '--no-builtin-rules', '--no-builtin-variables',\n                  action=\"callback\", callback=opt_not_yet,\n                  dest=\"no_builtin_rules\",\n                  # help=\"Clear default environments and variables.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--write-filenames',\n                  nargs=1, type=\"string\",\n                  dest=\"write_filenames\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Write all filenames examined into FILE.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('-W', '--new-file', '--assume-new', '--what-if',\n                  nargs=1, type=\"string\",\n                  dest=\"new_file\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Consider FILE to be changed.\"\n                  help=SUPPRESS_HELP)\n    op.add_option('--warn-undefined-variables',\n                  dest=\"warn_undefined_variables\",\n                  action=\"callback\", callback=opt_not_yet,\n                  # help=\"Warn when an undefined variable is referenced.\"\n                  help=SUPPRESS_HELP)\n\n    return op"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_option(self, name, value):\n        if not name in self.settable:\n            raise SCons.Errors.UserError(\"This option is not settable from a SConscript file: %s\"%name)\n\n        if name == 'num_jobs':\n            try:\n                value = int(value)\n                if value < 1:\n                    raise ValueError\n            except ValueError:\n                raise SCons.Errors.UserError(\"A positive integer is required: %s\"%repr(value))\n        elif name == 'max_drift':\n            try:\n                value = int(value)\n            except ValueError:\n                raise SCons.Errors.UserError(\"An integer is required: %s\"%repr(value))\n        elif name == 'duplicate':\n            try:\n                value = str(value)\n            except ValueError:\n                raise SCons.Errors.UserError(\"A string is required: %s\"%repr(value))\n            if not value in SCons.Node.FS.Valid_Duplicates:\n                raise SCons.Errors.UserError(\"Not a valid duplication style: %s\" % value)\n            # Set the duplicate style right away so it can affect linking\n            # of SConscript files.\n            SCons.Node.FS.set_duplicate(value)\n        elif name == 'diskcheck':\n            try:\n                value = diskcheck_convert(value)\n            except ValueError as v:\n                raise SCons.Errors.UserError(\"Not a valid diskcheck value: %s\"%v)\n            if 'diskcheck' not in self.__dict__:\n                # No --diskcheck= option was specified on the command line.\n                # Set this right away so it can affect the rest of the\n                # file/Node lookups while processing the SConscript files.\n                SCons.Node.FS.set_diskcheck(value)\n        elif name == 'stack_size':\n            try:\n                value = int(value)\n            except ValueError:\n                raise SCons.Errors.UserError(\"An integer is required: %s\"%repr(value))\n        elif name == 'md5_chunksize':\n            try:\n                value = int(value)\n            except ValueError:\n                raise SCons.Errors.UserError(\"An integer is required: %s\"%repr(value))\n        elif name == 'warn':\n            if SCons.Util.is_String(value):\n                value = [value]\n            value = self.__SConscript_settings__.get(name, []) + value\n            SCons.Warnings.process_warn_strings(value)\n\n        self.__SConscript_settings__[name] = value", "response": "Sets an option in the current instance of the node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting an option group s help text", "response": "def format_help(self, formatter):\n        \"\"\"\n        Format an option group's help text, outdenting the title so it's\n        flush with the \"SCons Options\" title we print at the top.\n        \"\"\"\n        formatter.dedent()\n        result = formatter.format_heading(self.title)\n        formatter.indent()\n        result = result + optparse.OptionContainer.format_help(self, formatter)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_long_opt(self, rargs, values):\n        arg = rargs.pop(0)\n\n        # Value explicitly attached to arg?  Pretend it's the next\n        # argument.\n        if \"=\" in arg:\n            (opt, next_arg) = arg.split(\"=\", 1)\n            rargs.insert(0, next_arg)\n            had_explicit_value = True\n        else:\n            opt = arg\n            had_explicit_value = False\n\n        try:\n            opt = self._match_long_opt(opt)\n        except optparse.BadOptionError:\n            if self.preserve_unknown_options:\n                # SCons-specific:  if requested, add unknown options to\n                # the \"leftover arguments\" list for later processing.\n                self.largs.append(arg)\n                if had_explicit_value:\n                    # The unknown option will be re-processed later,\n                    # so undo the insertion of the explicit value.\n                    rargs.pop(0)\n                return\n            raise\n\n        option = self._long_opt[opt]\n        if option.takes_value():\n            nargs = option.nargs\n            if nargs == '?':\n                if had_explicit_value:\n                    value = rargs.pop(0)\n                else:\n                    value = option.const\n            elif len(rargs) < nargs:\n                if nargs == 1:\n                    if not option.choices:\n                        self.error(_(\"%s option requires an argument\") % opt)\n                    else:\n                        msg  = _(\"%s option requires an argument \" % opt)\n                        msg += _(\"(choose from %s)\"\n                                 % ', '.join(option.choices))\n                        self.error(msg)\n                else:\n                    self.error(_(\"%s option requires %d arguments\")\n                               % (opt, nargs))\n            elif nargs == 1:\n                value = rargs.pop(0)\n            else:\n                value = tuple(rargs[0:nargs])\n                del rargs[0:nargs]\n\n        elif had_explicit_value:\n            self.error(_(\"%s option does not take a value\") % opt)\n\n        else:\n            value = None\n\n        option.process(opt, value, values, self)", "response": "This method is called by the optionparse. _parse_long_opt method to process the option and extract the value from the argument list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reparse_local_options(self):\n        rargs = []\n        largs_restore = []\n        # Loop over all remaining arguments\n        skip = False\n        for l in self.largs:\n            if skip:\n                # Accept all remaining arguments as they are\n                largs_restore.append(l)\n            else:\n                if len(l) > 2 and l[0:2] == \"--\":\n                    # Check long option\n                    lopt = (l,)\n                    if \"=\" in l:\n                        # Split into option and value\n                        lopt = l.split(\"=\", 1)\n                        \n                    if lopt[0] in self._long_opt:\n                        # Argument is already known\n                        rargs.append('='.join(lopt))\n                    else:\n                        # Not known yet, so reject for now\n                        largs_restore.append('='.join(lopt))\n                else:\n                    if l == \"--\" or l == \"-\":\n                        # Stop normal processing and don't\n                        # process the rest of the command-line opts\n                        largs_restore.append(l)\n                        skip = True\n                    else:\n                        rargs.append(l)\n        \n        # Parse the filtered list\n        self.parse_args(rargs, self.values)\n        # Restore the list of remaining arguments for the\n        # next call of AddOption/add_local_option...\n        self.largs = self.largs + largs_restore", "response": "Reparse the leftover command - line options stored in self. largs and return a list of the command - line options that were added to the list of local options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a local option to the parser.", "response": "def add_local_option(self, *args, **kw):\n        \"\"\"\n        Adds a local option to the parser.\n\n        This is initiated by a SetOption() call to add a user-defined\n        command-line option.  We add the option to a separate option\n        group for the local options, creating the group if necessary.\n        \"\"\"\n        try:\n            group = self.local_option_group\n        except AttributeError:\n            group = SConsOptionGroup(self, 'Local Options')\n            group = self.add_option_group(group)\n            self.local_option_group = group\n\n        result = group.add_option(*args, **kw)\n\n        if result:\n            # The option was added successfully.  We now have to add the\n            # default value to our object that holds the default values\n            # (so that an attempt to fetch the option's attribute will\n            # yield the default value when not overridden) and then\n            # we re-parse the leftover command-line options, so that\n            # any value overridden on the command line is immediately\n            # available if the user turns around and does a GetOption()\n            # right away.\n            setattr(self.values.__defaults__, result.dest, result.default)\n            self.reparse_local_options()\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_option(self, option):\n        # The help for each option consists of two parts:\n        #   * the opt strings and metavars\n        #     eg. (\"-x\", or \"-fFILENAME, --file=FILENAME\")\n        #   * the user-supplied help string\n        #     eg. (\"turn on expert mode\", \"read data from FILENAME\")\n        #\n        # If possible, we write both of these on the same line:\n        #   -x      turn on expert mode\n        #\n        # But if the opt string list is too long, we put the help\n        # string on a second line, indented to the same column it would\n        # start in if it fit on the first line.\n        #   -fFILENAME, --file=FILENAME\n        #           read data from FILENAME\n        result = []\n\n        opts = self.option_strings[option]\n        opt_width = self.help_position - self.current_indent - 2\n        if len(opts) > opt_width:\n            wrapper = textwrap.TextWrapper(width=self.width,\n                                           initial_indent = '  ',\n                                           subsequent_indent = '  ')\n            wrapper.wordsep_re = no_hyphen_re\n            opts = wrapper.fill(opts) + '\\n'\n            indent_first = self.help_position\n        else:                       # start help on same line as opts\n            opts = \"%*s%-*s  \" % (self.current_indent, \"\", opt_width, opts)\n            indent_first = 0\n        result.append(opts)\n        if option.help:\n\n            help_text = self.expand_default(option)\n\n            # SCons:  indent every line of the help text but the first.\n            wrapper = textwrap.TextWrapper(width=self.help_width,\n                                           subsequent_indent = '  ')\n            wrapper.wordsep_re = no_hyphen_re\n            help_lines = wrapper.wrap(help_text)\n            result.append(\"%*s%s\\n\" % (indent_first, \"\", help_lines[0]))\n            for line in help_lines[1:]:\n                result.append(\"%*s%s\\n\" % (self.help_position, \"\", line))\n        elif opts[-1] != \"\\n\":\n            result.append(\"\\n\")\n        return \"\".join(result)", "response": "This method formats the option and returns a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_dict(self):\n\n        out_dict = {}\n\n        out_dict['commands'] = self.commands\n        out_dict['configs'] = self.configs\n        out_dict['short_name'] = self.name\n        out_dict['versions'] = {\n            'module': self.module_version,\n            'api': self.api_version\n        }\n\n        return out_dict", "response": "Convert this object into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_api_version(self, major, minor):\n\n        if not self._is_byte(major) or not self._is_byte(minor):\n            raise ArgumentError(\"Invalid API version number with component that does not fit in 1 byte\",\n                                major=major, minor=minor)\n\n        self.api_version = (major, minor)", "response": "Set the API version of the mib12 module."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the module version for this module.", "response": "def set_module_version(self, major, minor, patch):\n        \"\"\"Set the module version for this module.\n\n        Each module must declare a semantic version number in the form:\n        major.minor.patch\n\n        where each component is a 1 byte number between 0 and 255.\n        \"\"\"\n\n        if not (self._is_byte(major) and self._is_byte(minor) and self._is_byte(patch)):\n            raise ArgumentError(\"Invalid module version number with component that does not fit in 1 byte\",\n                                major=major, minor=minor, patch=patch)\n\n        self.module_version = (major, minor, patch)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the module name to a 6 byte string.", "response": "def set_name(self, name):\n        \"\"\"Set the module name to a 6 byte string\n\n        If the string is too short it is appended with space characters.\n        \"\"\"\n\n        if len(name) > 6:\n            raise ArgumentError(\"Name must be at most 6 characters long\", name=name)\n\n        if len(name) < 6:\n            name += ' '*(6 - len(name))\n\n        self.name = name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a command to the MIB block.", "response": "def add_command(self, cmd_id, handler):\n        \"\"\"Add a command to the TBBlock.\n\n        The cmd_id must be a non-negative 2 byte number.\n        handler should be the command handler\n        \"\"\"\n\n        if cmd_id < 0 or cmd_id >= 2**16:\n            raise ArgumentError(\"Command ID in mib block is not a non-negative 2-byte number\",\n                                cmd_id=cmd_id, handler=handler)\n\n        if cmd_id in self.commands:\n            raise ArgumentError(\"Attempted to add the same command ID twice.\", cmd_id=cmd_id,\n                                existing_handler=self.commands[cmd_id],\n                                new_handler=handler)\n\n        self.commands[cmd_id] = handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_config(self, config_id, config_data):\n\n        if config_id < 0 or config_id >= 2**16:\n            raise ArgumentError(\"Config ID in mib block is not a non-negative 2-byte number\",\n                                config_data=config_id, data=config_data)\n\n        if config_id in self.configs:\n            raise ArgumentError(\"Attempted to add the same command ID twice.\", config_data=config_id,\n                                old_data=self.configs[config_id], new_data=config_data)\n\n        self.configs[config_id] = config_data", "response": "Add a configuration variable to the MIB block"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_hwtype(self):\n\n        self.chip_name = KNOWN_HARDWARE_TYPES.get(self.hw_type, \"Unknown Chip (type=%d)\" % self.hw_type)", "response": "Convert the numerical hardware id to a chip name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_template(self, template_name, out_path=None):\n\n        return render_template(template_name, self.to_dict(), out_path=out_path)", "response": "Render a template based on this tile bus block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Tag(env, target, source, *more_tags, **kw_tags):\n    if not target:\n        target=source\n        first_tag=None\n    else:\n        first_tag=source\n\n    if first_tag:\n        kw_tags[first_tag[0]] = ''\n\n    if len(kw_tags) == 0 and len(more_tags) == 0:\n        raise UserError(\"No tags given.\")\n\n    # XXX: sanity checks\n    for x in more_tags:\n        kw_tags[x] = ''\n\n    if not SCons.Util.is_List(target):\n        target=[target]\n    else:\n        # hmm, sometimes the target list, is a list of a list\n        # make sure it is flattened prior to processing.\n        # TODO: perhaps some bug ?!?\n        target=env.Flatten(target)\n\n    for t in target:\n        for (k,v) in kw_tags.items():\n            # all file tags have to start with PACKAGING_, so we can later\n            # differentiate between \"normal\" object attributes and the\n            # packaging attributes. As the user should not be bothered with\n            # that, the prefix will be added here if missing.\n            if k[:10] != 'PACKAGING_':\n                k='PACKAGING_'+k\n            t.Tag(k, v)", "response": "Tag a file with the given arguments just sets the accordingly named\nFormula attribute on the file object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies the special packaging file attributes from f1 to f2.", "response": "def copy_attr(f1, f2):\n    \"\"\" copies the special packaging file attributes from f1 to f2.\n    \"\"\"\n    copyit = lambda x: not hasattr(f2, x) and x[:10] == 'PACKAGING_'\n    if f1._tags:\n        pattrs = [tag for tag in f1._tags if copyit(tag)]\n        for attr in pattrs:\n            f2.Tag(attr, f1.GetTag(attr))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef putintopackageroot(target, source, env, pkgroot, honor_install_location=1):\n    # make sure the packageroot is a Dir object.\n    if SCons.Util.is_String(pkgroot):  pkgroot=env.Dir(pkgroot)\n    if not SCons.Util.is_List(source): source=[source]\n\n    new_source = []\n    for file in source:\n        if SCons.Util.is_String(file): file = env.File(file)\n\n        if file.is_under(pkgroot):\n            new_source.append(file)\n        else:\n            if file.GetTag('PACKAGING_INSTALL_LOCATION') and\\\n                       honor_install_location:\n                new_name=make_path_relative(file.GetTag('PACKAGING_INSTALL_LOCATION'))\n            else:\n                new_name=make_path_relative(file.get_path())\n\n            new_file=pkgroot.File(new_name)\n            new_file=env.CopyAs(new_file, file)[0]\n            copy_attr(file, new_file)\n            new_source.append(new_file)\n\n    return (target, new_source)", "response": "Copies all source files to the given target directory and returns the new source directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstripping the install builder action from the source list and stores the final installation location as thePACKAGING_INSTALL_LOCATION attribute.", "response": "def stripinstallbuilder(target, source, env):\n    \"\"\" Strips the install builder action from the source list and stores\n    the final installation location as the \"PACKAGING_INSTALL_LOCATION\" of\n    the source of the source file. This effectively removes the final installed\n    files from the source list while remembering the installation location.\n\n    It also warns about files which have no install builder attached.\n    \"\"\"\n    def has_no_install_location(file):\n        return not (file.has_builder() and\\\n            hasattr(file.builder, 'name') and\\\n            (file.builder.name==\"InstallBuilder\" or\\\n             file.builder.name==\"InstallAsBuilder\"))\n\n    if len([src for src in source if has_no_install_location(src)]):\n        warn(Warning, \"there are files to package which have no\\\n        InstallBuilder attached, this might lead to irreproducible packages\")\n\n    n_source=[]\n    for s in source:\n        if has_no_install_location(s):\n            n_source.append(s)\n        else:\n            for ss in s.sources:\n                n_source.append(ss)\n                copy_attr(s, ss)\n                ss.Tag('PACKAGING_INSTALL_LOCATION', s.get_path())\n\n    return (target, n_source)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrestoring a previous state of this stream walker.", "response": "def restore(self, state):\n        \"\"\"Restore a previous state of this stream walker.\n\n        Raises:\n            ArgumentError: If the state refers to a different selector or the\n                offset is invalid.\n        \"\"\"\n\n        selector = DataStreamSelector.FromString(state.get(u'selector'))\n        if selector != self.selector:\n            raise ArgumentError(\"Attempted to restore a BufferedStreamWalker with a different selector\",\n                                selector=self.selector, serialized_data=state)\n\n        self.seek(state.get(u'offset'), target=\"offset\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self):\n\n        if self._count == 0:\n            raise StreamEmptyError(\"Pop called on buffered stream walker without any data\", selector=self.selector)\n\n        while True:\n            curr = self.engine.get(self.storage_type, self.offset)\n            self.offset += 1\n\n            stream = DataStream.FromEncoded(curr.stream)\n            if self.matches(stream):\n                self._count -= 1\n                return curr", "response": "Pop a reading off of this stream and return it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nseek this stream to a specific offset or reading id.", "response": "def seek(self, value, target=\"offset\"):\n        \"\"\"Seek this stream to a specific offset or reading id.\n\n        There are two modes of use.  You can seek to a specific reading id,\n        which means the walker will be positioned exactly at the reading\n        pointed to by the reading ID.  If the reading id cannot be found\n        an exception will be raised.  The reading id can be found but corresponds\n        to a reading that is not selected by this walker, the walker will\n        be moved to point at the first reading after that reading and False\n        will be returned.\n\n        If target==\"offset\", the walker will be positioned at the specified\n        offset in the sensor log. It will also update the count of available\n        readings based on that new location so that the count remains correct.\n\n        The offset does not need to correspond to a reading selected by this\n        walker.  If offset does not point to a selected reading, the effective\n        behavior will be as if the walker pointed to the next selected reading\n        after `offset`.\n\n        Args:\n            value (int): The identifier to seek, either an offset or a\n                reading id.\n            target (str): The type of thing to seek.  Can be offset or id.\n                If id is given, then a reading with the given ID will be\n                searched for.  If offset is given then the walker will\n                be positioned at the given offset.\n\n        Returns:\n            bool: True if an exact match was found, False otherwise.\n\n            An exact match means that the offset or reading ID existed and\n            corresponded to a reading selected by this walker.\n\n            An inexact match means that the offset or reading ID existed but\n            corresponded to reading that was not selected by this walker.\n\n            If the offset or reading ID could not be found an Exception is\n            thrown instead.\n\n        Raises:\n            ArgumentError: target is an invalid string, must be offset or\n                id.\n            UnresolvedIdentifierError: the desired offset or reading id\n                could not be found.\n        \"\"\"\n\n        if target not in (u'offset', u'id'):\n            raise ArgumentError(\"You must specify target as either offset or id\", target=target)\n\n        if target == u'offset':\n            self._verify_offset(value)\n            self.offset = value\n        else:\n            self.offset = self._find_id(value)\n\n        self._count = self.engine.count_matching(self.selector, offset=self.offset)\n\n        curr = self.engine.get(self.storage_type, self.offset)\n        return self.matches(DataStream.FromEncoded(curr.stream))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef skip_all(self):\n\n        storage, streaming = self.engine.count()\n\n        if self.selector.output:\n            self.offset = streaming\n        else:\n            self.offset = storage\n\n        self._count = 0", "response": "Skip all readings in this walker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notify_rollover(self, stream):\n\n        self.offset -= 1\n\n        if not self.matches(stream):\n            return\n\n        if self._count == 0:\n            raise InternalError(\"BufferedStreamWalker out of sync with storage engine, count was wrong.\")\n\n        self._count -= 1", "response": "Notify that a reading in the given stream had overwritten data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump(self):\n\n        reading = self.reading\n        if reading is not None:\n            reading = reading.asdict()\n\n        return {\n            u'selector': str(self.selector),\n            u'reading': reading\n        }", "response": "Serialize the state of this stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore(self, state):\n\n        reading = state.get(u'reading')\n        if reading is not None:\n            reading = IOTileReading.FromDict(reading)\n\n        selector = DataStreamSelector.FromString(state.get(u'selector'))\n        if self.selector != selector:\n            raise ArgumentError(\"Attempted to restore a VirtualStreamWalker with a different selector\",\n                                selector=self.selector, serialized_data=state)\n\n        self.reading = reading", "response": "Restore the contents of this virtual stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef push(self, stream, value):\n\n        if not self.matches(stream):\n            raise ArgumentError(\"Attempting to push reading to stream walker that does not match\", selector=self.selector, stream=stream)\n\n        self.reading = value", "response": "Push a new reading to a Virtual stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopping a reading off of this virtual stream and return it.", "response": "def pop(self):\n        \"\"\"Pop a reading off of this virtual stream and return it.\"\"\"\n\n        if self.reading is None:\n            raise StreamEmptyError(\"Pop called on virtual stream walker without any data\", selector=self.selector)\n\n        reading = self.reading\n\n        # If we're not a constant stream, we just exhausted ourselves\n        if self.selector.match_type != DataStream.ConstantType:\n            self.reading = None\n\n        return reading"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop(self):\n\n        if self._count == 0:\n            raise StreamEmptyError(\"Pop called on virtual stream walker without any data\", selector=self.selector)\n\n        self._count = self._count - 1\n        return self.reading", "response": "Pop a reading off of this virtual stream and return it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npeeking at the oldest reading in this virtual stream.", "response": "def peek(self):\n        \"\"\"Peek at the oldest reading in this virtual stream.\"\"\"\n\n        if self.reading is None:\n            raise StreamEmptyError(\"peek called on virtual stream walker without any data\", selector=self.selector)\n\n        return self.reading"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore(self, state):\n\n\n        selector = DataStreamSelector.FromString(state.get(u'selector'))\n        if self.selector != selector:\n            raise ArgumentError(\"Attempted to restore an InvalidStreamWalker with a different selector\",\n                                selector=self.selector, serialized_data=state)\n\n        if state.get(u'type') != u'invalid':\n            raise ArgumentError(\"Invalid serialized state for InvalidStreamWalker\", serialized_data=state)", "response": "Restores the contents of this virtual stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush a new responsive reading to a stream walker.", "response": "def push(self, stream, value):\n        \"\"\"Update this stream walker with a new responsive reading.\n\n        Args:\n            stream (DataStream): The stream that we're pushing\n            value (IOTileReading): The reading tha we're pushing\n        \"\"\"\n\n        raise ArgumentError(\"Attempting to push reading to an invalid stream walker that cannot hold data\", selector=self.selector, stream=stream)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, refresh_interval=0.05):\n        try:\n            from asciimatics.screen import Screen\n        except ImportError:\n            raise ExternalError(\"You must have asciimatics installed to use LinebufferUI\",\n                                suggestion=\"pip install iotilecore[ui]\")\n\n        Screen.wrapper(self._run_loop, arguments=[refresh_interval])", "response": "Set up the loop check that the tool is installed and run the loop"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the given host - target tuple is supported given the msvc version.", "response": "def is_host_target_supported(host_target, msvc_version):\n    \"\"\"Return True if the given (host, target) tuple is supported given the\n    msvc version.\n\n    Parameters\n    ----------\n    host_target: tuple\n        tuple of (canonalized) host-target, e.g. (\"x86\", \"amd64\") for cross\n        compilation from 32 bits windows to 64 bits.\n    msvc_version: str\n        msvc version (major.minor, e.g. 10.0)\n\n    Note\n    ----\n    This only check whether a given version *may* support the given (host,\n    target), not that the toolchain is actually present on the machine.\n    \"\"\"\n    # We assume that any Visual Studio version supports x86 as a target\n    if host_target[1] != \"x86\":\n        maj, min = msvc_version_to_maj_min(msvc_version)\n        if maj < 8:\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_vc_pdir_vswhere(msvc_version):\n    vswhere_path = os.path.join(\n        'C:\\\\',\n        'Program Files (x86)',\n        'Microsoft Visual Studio',\n        'Installer',\n        'vswhere.exe'\n    )\n    vswhere_cmd = [vswhere_path, '-version', msvc_version, '-property', 'installationPath']\n\n    if os.path.exists(vswhere_path):\n        sp = subprocess.Popen(vswhere_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        vsdir, err = sp.communicate()\n        vsdir = vsdir.decode(\"mbcs\")\n        vsdir = vsdir.rstrip()\n        vc_pdir = os.path.join(vsdir, 'VC')\n        return vc_pdir\n    else:\n        # No vswhere on system, no install info available\n        return None", "response": "Find MSVC product directory using vswhere. exe and get MSVS install location"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to find the product directory for the given version.", "response": "def find_vc_pdir(msvc_version):\n    \"\"\"Try to find the product directory for the given\n    version.\n\n    Note\n    ----\n    If for some reason the requested version could not be found, an\n    exception which inherits from VisualCException will be raised.\"\"\"\n    root = 'Software\\\\'\n    try:\n        hkeys = _VCVER_TO_PRODUCT_DIR[msvc_version]\n    except KeyError:\n        debug(\"Unknown version of MSVC: %s\" % msvc_version)\n        raise UnsupportedVersion(\"Unknown version %s\" % msvc_version)\n\n    for hkroot, key in hkeys:\n        try:\n            comps = None\n            if not key:\n                comps = find_vc_pdir_vswhere(msvc_version)\n                if not comps:\n                    debug('find_vc_dir(): no VC found via vswhere for version {}'.format(repr(key)))\n                    raise SCons.Util.WinError\n            else:\n                if common.is_win64():\n                    try:\n                        # ordinally at win64, try Wow6432Node first.\n                        comps = common.read_reg(root + 'Wow6432Node\\\\' + key, hkroot)\n                    except SCons.Util.WinError as e:\n                        # at Microsoft Visual Studio for Python 2.7, value is not in Wow6432Node\n                        pass\n                if not comps:\n                    # not Win64, or Microsoft Visual Studio for Python 2.7\n                    comps = common.read_reg(root + key, hkroot)\n        except SCons.Util.WinError as e:\n            debug('find_vc_dir(): no VC registry key {}'.format(repr(key)))\n        else:\n            debug('find_vc_dir(): found VC in registry: {}'.format(comps))\n            if os.path.exists(comps):\n                return comps\n            else:\n                debug('find_vc_dir(): reg says dir is {}, but it does not exist. (ignoring)'.format(comps))\n                raise MissingConfiguration(\"registry dir {} not found on the filesystem\".format(comps))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the location of the batch script which should set up the compiler for any TARGET_ARCH whose compilers were installed by Visual Studio.", "response": "def find_batch_file(env,msvc_version,host_arch,target_arch):\n    \"\"\"\n    Find the location of the batch script which should set up the compiler\n    for any TARGET_ARCH whose compilers were installed by Visual Studio/VCExpress\n    \"\"\"\n    pdir = find_vc_pdir(msvc_version)\n    if pdir is None:\n        raise NoVersionFound(\"No version of Visual Studio found\")\n\n    debug('vc.py: find_batch_file() pdir:{}'.format(pdir))\n\n    # filter out e.g. \"Exp\" from the version name\n    msvc_ver_numeric = ''.join([x for x in msvc_version if x in string_digits + \".\"])\n    vernum = float(msvc_ver_numeric)\n    if 7 <= vernum < 8:\n        pdir = os.path.join(pdir, os.pardir, \"Common7\", \"Tools\")\n        batfilename = os.path.join(pdir, \"vsvars32.bat\")\n    elif vernum < 7:\n        pdir = os.path.join(pdir, \"Bin\")\n        batfilename = os.path.join(pdir, \"vcvars32.bat\")\n    elif 8 <= vernum <= 14:\n        batfilename = os.path.join(pdir, \"vcvarsall.bat\")\n    else:  # vernum >= 14.1  VS2017 and above\n        batfilename = os.path.join(pdir, \"Auxiliary\", \"Build\", \"vcvarsall.bat\")\n\n    if not os.path.exists(batfilename):\n        debug(\"Not found: %s\" % batfilename)\n        batfilename = None\n\n    installed_sdks=get_installed_sdks()\n    for _sdk in installed_sdks:\n        sdk_bat_file = _sdk.get_sdk_vc_script(host_arch,target_arch)\n        if not sdk_bat_file:\n            debug(\"vc.py:find_batch_file() not found:%s\"%_sdk)\n        else:\n            sdk_bat_file_path = os.path.join(pdir,sdk_bat_file)\n            if os.path.exists(sdk_bat_file_path):\n                debug('vc.py:find_batch_file() sdk_bat_file_path:%s'%sdk_bat_file_path)\n                return (batfilename,sdk_bat_file_path)\n    return (batfilename,None)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_sgf(in_path, optimize=True, model=None):\n\n    if model is None:\n        model = DeviceModel()\n\n    parser = SensorGraphFileParser()\n    parser.parse_file(in_path)\n    parser.compile(model)\n\n    if optimize:\n        opt = SensorGraphOptimizer()\n        opt.optimize(parser.sensor_graph, model=model)\n\n    return parser.sensor_graph", "response": "Compile and optionally optimize an SGF file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding Builders and construction variables for g77 to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for g77 to an Environment.\"\"\"\n    add_all_to_env(env)\n    add_f77_to_env(env)\n\n    fcomp = env.Detect(compilers) or 'g77'\n    if env['PLATFORM'] in ['cygwin', 'win32']:\n        env['SHFORTRANFLAGS'] = SCons.Util.CLVar('$FORTRANFLAGS')\n        env['SHF77FLAGS'] = SCons.Util.CLVar('$F77FLAGS')\n    else:\n        env['SHFORTRANFLAGS'] = SCons.Util.CLVar('$FORTRANFLAGS -fPIC')\n        env['SHF77FLAGS'] = SCons.Util.CLVar('$F77FLAGS -fPIC')\n\n    env['FORTRAN'] = fcomp\n    env['SHFORTRAN'] = '$FORTRAN'\n\n    env['F77'] = fcomp\n    env['SHF77'] = '$F77'\n\n    env['INCFORTRANPREFIX'] = \"-I\"\n    env['INCFORTRANSUFFIX'] = \"\"\n\n    env['INCF77PREFIX'] = \"-I\"\n    env['INCF77SUFFIX'] = \"\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting this statement on the sensor_graph given the current scope tree.", "response": "def execute(self, sensor_graph, scope_stack):\n        \"\"\"Execute this statement on the sensor_graph given the current scope tree.\n\n        This adds a single node to the sensor graph with the trigger_streamer function\n        as is processing function.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        # The output is unused\n        output = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n\n        trigger_stream, trigger_cond = parent.trigger_chain()\n        streamer_const = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n\n        sensor_graph.add_node(u\"({} {} && {} always) => {} using trigger_streamer\".format(trigger_stream, trigger_cond, streamer_const, output))\n        sensor_graph.add_constant(streamer_const, self.index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates or retrieve the parse tree for defining a sensor graph.", "response": "def get_language():\n    \"\"\"Create or retrieve the parse tree for defining a sensor graph.\"\"\"\n\n    global sensor_graph, statement\n\n    if sensor_graph is not None:\n        return sensor_graph\n\n    _create_primitives()\n    _create_simple_statements()\n    _create_block_bnf()\n\n    sensor_graph = ZeroOrMore(statement) + StringEnd()\n    sensor_graph.ignore(comment)\n\n    return sensor_graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_mo_file_builder(env, **kw):\n  import SCons.Action\n  # FIXME: What factory use for source? Ours or their?\n  kw['action'] = SCons.Action.Action('$MSGFMTCOM','$MSGFMTCOMSTR')\n  kw['suffix'] = '$MOSUFFIX'\n  kw['src_suffix'] = '$POSUFFIX'\n  kw['src_builder'] = '_POUpdateBuilder'\n  kw['single_source'] = True \n  return _MOFileBuilder(**kw)", "response": "Create a builder object for MOFiles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef RCScan():\n\n    res_re= r'^(?:\\s*#\\s*(?:include)|' \\\n            '.*?\\s+(?:ICON|BITMAP|CURSOR|HTML|FONT|MESSAGETABLE|TYPELIB|REGISTRY|D3DFX)' \\\n            '\\s*.*?)' \\\n            '\\s*(<|\"| )([^>\"\\s]+)(?:[>\"\\s])*$'\n    resScanner = SCons.Scanner.ClassicCPP(\"ResourceScanner\",\n                                          \"$RCSUFFIXES\",\n                                          \"CPPPATH\",\n                                          res_re,\n                                          recursive=no_tlb)\n    \n    return resScanner", "response": "Returns a prototype Scanner instance for scanning RC source files"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_linguas_from_files(env, linguas_files=None):\n    import SCons.Util\n    import SCons.Environment\n    global _re_comment\n    global _re_lang\n    if not SCons.Util.is_List(linguas_files) \\\n            and not SCons.Util.is_String(linguas_files) \\\n            and not isinstance(linguas_files, SCons.Node.FS.Base) \\\n            and linguas_files:\n        # If, linguas_files==True or such, then read 'LINGUAS' file.\n        linguas_files = ['LINGUAS']\n    if linguas_files is None:\n        return []\n    fnodes = env.arg2nodes(linguas_files)\n    linguas = []\n    for fnode in fnodes:\n        contents = _re_comment.sub(\"\", fnode.get_text_contents())\n        ls = [l for l in _re_lang.findall(contents) if l]\n        linguas.extend(ls)\n    return linguas", "response": "Parse LINGUAS files and return list of extracted languages"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _translate(env, target=None, source=SCons.Environment._null, *args, **kw):\n    if target is None: target = []\n    pot = env.POTUpdate(None, source, *args, **kw)\n    po = env.POUpdate(target, pot, *args, **kw)\n    return po", "response": "Function for the Translate pseudo - builder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_po_files(target, source, env):\n    nop = lambda target, source, env: 0\n    if 'POAUTOINIT' in env:\n        autoinit = env['POAUTOINIT']\n    else:\n        autoinit = False\n    # Well, if everything outside works well, this loop should do single\n    # iteration. Otherwise we are rebuilding all the targets even, if just\n    # one has changed (but is this our fault?).\n    for tgt in target:\n        if not tgt.exists():\n            if autoinit:\n                action = SCons.Action.Action('$MSGINITCOM', '$MSGINITCOMSTR')\n            else:\n                msg = 'File ' + repr(str(tgt)) + ' does not exist. ' \\\n                      + 'If you are a translator, you can create it through: \\n' \\\n                      + '$MSGINITCOM'\n                action = SCons.Action.Action(nop, msg)\n            status = action([tgt], source, env)\n            if status: return status\n    return 0", "response": "Action function for POInit builder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _detect_xgettext(env):\n    if 'XGETTEXT' in env:\n        return env['XGETTEXT']\n    xgettext = env.Detect('xgettext');\n    if xgettext:\n        return xgettext\n    raise SCons.Errors.StopError(XgettextNotFound, \"Could not detect xgettext\")\n    return None", "response": "Detects xgettext and returns the first element in the tree"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetect msgfmt in an Environment and returns the msgfmt object if found.", "response": "def _detect_msgfmt(env):\n    \"\"\" Detects *msgmfmt(1)* program. \"\"\"\n    if 'MSGFMT' in env:\n        return env['MSGFMT']\n    msgfmt = env.Detect('msgfmt');\n    if msgfmt:\n        return msgfmt\n    raise SCons.Errors.StopError(MsgfmtNotFound, \"Could not detect msgfmt\")\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a node and set it up to factory settings.", "response": "def _create_node(self, name, factory, directory=None, create=1):\n        \"\"\" Create node, and set it up to factory settings. \"\"\"\n        import SCons.Util\n        node = factory(name, directory, create)\n        node.set_noclean(self.noclean)\n        node.set_precious(self.precious)\n        if self.nodefault:\n            self.env.Ignore('.', node)\n        if self.alias:\n            self.env.AlwaysBuild(self.env.Alias(self.alias, node))\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an entry node.", "response": "def Entry(self, name, directory=None, create=1):\n        \"\"\" Create `SCons.Node.FS.Entry` \"\"\"\n        return self._create_node(name, self.env.fs.Entry, directory, create)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new file node.", "response": "def File(self, name, directory=None, create=1):\n        \"\"\" Create `SCons.Node.FS.File` \"\"\"\n        return self._create_node(name, self.env.fs.File, directory, create)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the Builder s actions.", "response": "def _execute(self, env, target, source, *args, **kw):\n        \"\"\" Execute builder's actions.\n        \n        Here we append to `target` the languages read from `$LINGUAS_FILE` and \n        apply `SCons.Builder.BuilderBase._execute()` separatelly to each target.\n        The arguments and return value are same as for\n        `SCons.Builder.BuilderBase._execute()`. \n        \"\"\"\n        import SCons.Util\n        import SCons.Node\n        linguas_files = None\n        if 'LINGUAS_FILE' in env and env['LINGUAS_FILE']:\n            linguas_files = env['LINGUAS_FILE']\n            # This prevents endless recursion loop (we'll be invoked once for\n            # each target appended here, we must not extend the list again).\n            env['LINGUAS_FILE'] = None\n            linguas = _read_linguas_from_files(env, linguas_files)\n            if SCons.Util.is_List(target):\n                target.extend(linguas)\n            elif target is not None:\n                target = [target] + linguas\n            else:\n                target = linguas\n        if not target:\n            # Let the SCons.BuilderBase to handle this patologic situation\n            return BuilderBase._execute(self, env, target, source, *args, **kw)\n        # The rest is ours\n        if not SCons.Util.is_List(target):\n            target = [target]\n        result = []\n        for tgt in target:\n            r = BuilderBase._execute(self, env, [tgt], source, *args, **kw)\n            result.extend(r)\n        if linguas_files is not None:\n            env['LINGUAS_FILE'] = linguas_files\n        return SCons.Node.NodeList(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nallocate a new data stream of the given type.", "response": "def allocate_stream(self, stream_type, stream_id=None, previous=None, attach=False):\n        \"\"\"Allocate a new stream of the given type.\n\n        The stream is allocated with an incremental ID starting at\n        StreamAllocator.StartingID.  The returned data stream can always\n        be used to to attach a NodeInput to this stream, however the\n        attach_stream() function should always be called first since this\n        stream's output may need to be split and a logically equivalent\n        stream used instead to satisfy a device specific constraint on the\n        maximum number of outputs attached to a given stream.\n\n        You can call allocate_stream on the same stream multiple times without\n        issue.  Subsequent calls to allocate_stream are noops.\n\n        Args:\n            stream_type (int): A stream type specified in the DataStream class\n                like DataStream.ConstantType\n            stream_id (int): The ID we would like to use for this stream, if\n                this is not specified, an ID is automatically allocated.\n            previous (DataStream): If this stream was automatically derived from\n                another stream, this parameter should be a link to the old\n                stream.\n            attach (bool): Call attach_stream immediately before returning.  Convenience\n                routine for streams that should immediately be attached to something.\n\n        Returns:\n            DataStream: The allocated data stream.\n        \"\"\"\n\n        if stream_type not in DataStream.TypeToString:\n            raise ArgumentError(\"Unknown stream type in allocate_stream\", stream_type=stream_type)\n\n        if stream_id is not None and stream_id >= StreamAllocator.StartingID:\n            raise ArgumentError(\"Attempted to explicitly allocate a stream id in the internally managed id range\", stream_id=stream_id, started_id=StreamAllocator.StartingID)\n\n        # If the stream id is not explicitly given, we need to manage and track it\n        # from our autoallocate range\n        if stream_id is None:\n            if stream_type not in self._next_id:\n                self._next_id[stream_type] = StreamAllocator.StartingID\n\n            stream_id = self._next_id[stream_type]\n            self._next_id[stream_type] += 1\n\n        # Keep track of how many downstream nodes are attached to this stream so\n        # that we know when we need to split it into two.\n        stream = DataStream(stream_type, stream_id)\n\n        if stream not in self._allocated_streams:\n            self._allocated_streams[stream] = (stream, 0, previous)\n\n        if attach:\n            stream = self.attach_stream(stream)\n\n        return stream"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attach_stream(self, stream):\n\n        curr_stream, count, prev = self._allocated_streams[stream]\n\n        # Check if we need to split this stream and allocate a new one\n        if count == (self.model.get(u'max_node_outputs') - 1):\n            new_stream = self.allocate_stream(curr_stream.stream_type, previous=curr_stream)\n            copy_desc = u\"({} always) => {} using copy_all_a\".format(curr_stream, new_stream)\n\n            self.sensor_graph.add_node(copy_desc)\n            self._allocated_streams[stream] = (new_stream, 1, curr_stream)\n\n            # If we are splitting a constant stream, make sure we also duplicate the initialization value\n            # FIXME: If there is no default value for the stream, that is probably a warning since all constant\n            #        streams should be initialized with a value.\n            if curr_stream.stream_type == DataStream.ConstantType and curr_stream in self.sensor_graph.constant_database:\n                self.sensor_graph.add_constant(new_stream, self.sensor_graph.constant_database[curr_stream])\n\n            return new_stream\n\n        self._allocated_streams[stream] = (curr_stream, count + 1, prev)\n        return curr_stream", "response": "Notify that we would like to attach a data stream to a new node input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_v1_settings(self, settings):\n\n        if 'module_name' in settings:\n            modname = settings['module_name']\n        if 'modules' not in settings or len(settings['modules']) == 0:\n            raise DataError(\"No modules defined in module_settings.json file\")\n        elif len(settings['modules']) > 1:\n            raise DataError(\"Multiple modules defined in module_settings.json file\",\n                            modules=[x for x in settings['modules']])\n        else:\n            modname = list(settings['modules'])[0]\n\n        if modname not in settings['modules']:\n            raise DataError(\"Module name does not correspond with an entry in the modules directory\",\n                            name=modname, modules=[x for x in settings['modules']])\n\n        release_info = self._load_release_info(settings)\n        modsettings = settings['modules'][modname]\n        architectures = settings.get('architectures', {})\n\n        target_defs = settings.get('module_targets', {})\n        targets = target_defs.get(modname, [])\n\n        return TileInfo(modname, modsettings, architectures, targets, release_info)", "response": "Parse a v1 module_settings. json file and return a TileInfo object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_settings(self, info):\n\n        modname, modsettings, architectures, targets, release_info = info\n        self.settings = modsettings\n\n        # Name is converted to all lowercase to canonicalize it\n        prepend = ''\n        if 'domain' in modsettings:\n            prepend = modsettings['domain'].lower() + '/'\n\n        key = prepend + modname.lower()\n\n        # Copy over some key properties that we want easy access to\n        self.name = key\n        self.unique_id = key.replace('/', '_')\n        self.short_name = modname\n        self.targets = targets\n\n        self.full_name = \"Undefined\"\n        if \"full_name\" in self.settings:\n            self.full_name = self.settings['full_name']\n\n        # FIXME: make sure this is a list\n        self.authors = []\n        if \"authors\" in self.settings:\n            self.authors = self.settings['authors']\n\n        self.version = \"0.0.0\"\n        if \"version\" in self.settings:\n            self.version = self.settings['version']\n\n        self.parsed_version = SemanticVersion.FromString(self.version)\n\n        # Load all of the build products that can be created by this IOTile\n        self.products = modsettings.get('products', {})\n\n        # Load in the release information telling us how to release this component\n        release_steps = modsettings.get('release_steps', [])\n        self.release_steps = []\n        self.can_release = False\n\n        for step in release_steps:\n            if 'provider' not in step:\n                raise DataError(\"Invalid release step that did not have a provider key\", step=step)\n\n            parsed_step = ReleaseStep(provider=step['provider'], args=step.get('args', {}))\n            self.release_steps.append(parsed_step)\n\n        if len(self.release_steps) > 0:\n            self.can_release = True\n\n        self.dependency_versions = {}\n\n        # If this is a release IOTile component, check for release information\n        if release_info is not None:\n            self.release = True\n            self.release_date = release_info.release_date\n            self.output_folder = self.folder\n            self.dependency_versions = release_info.dependency_versions\n        else:\n            self.release = False\n            self.output_folder = os.path.join(self.folder, 'build', 'output')\n\n            # If this tile is a development tile and it has been built at least one, add in a release date\n            # from the last time it was built\n            if os.path.exists(os.path.join(self.output_folder, 'module_settings.json')):\n                release_settings = os.path.join(self.output_folder, 'module_settings.json')\n\n                with open(release_settings, 'r') as infile:\n                    release_dict = json.load(infile)\n\n                import dateutil.parser\n                self.release_date = dateutil.parser.parse(release_dict['release_date'])\n            else:\n                self.release_date = None\n\n        # Find all of the things that this module could possibly depend on\n        # Dependencies include those defined in the module itself as well as\n        # those defined in architectures that are present in the module_settings.json\n        # file.\n        self.dependencies = []\n\n        archs_with_deps = [y['depends'].items() for _x, y in architectures.items() if 'depends' in y]\n        if 'depends' in self.settings:\n            if not isinstance(self.settings['depends'], dict):\n                raise DataError(\"module must have a depends key that is a dictionary\",\n                                found=str(self.settings['depends']))\n\n            archs_with_deps.append(self.settings['depends'].items())\n\n        # Find all python package needed\n        self.support_wheel_depends = []\n\n        if 'python_depends' in self.settings:\n            if not isinstance(self.settings['python_depends'], list):\n                raise DataError(\"module must have a python_depends key that is a list of strings\",\n                                found=str(self.settings['python_depends']))\n\n            for python_depend in self.settings['python_depends']:\n                if not isinstance(python_depend, str):\n                    raise DataError(\"module must have a python_depends key that is a list of strings\",\n                                    found=str(self.settings['python_depends']))\n\n                self.support_wheel_depends.append(python_depend)\n\n        # Also search through overlays to architectures that are defined in this module_settings.json file\n        # and see if those overlays contain dependencies.\n        for overlay_arch in self.settings.get('overlays', {}).values():\n            if 'depends' in overlay_arch:\n                archs_with_deps.append(overlay_arch['depends'].items())\n\n        found_deps = set()\n        for dep, _ in itertools.chain(*archs_with_deps):\n            name, _, version = dep.partition(',')\n            unique_id = name.lower().replace('/', '_')\n\n            version = version.strip()\n            if version == '':\n                version = \"*\"\n\n            ver_range = SemanticVersionRange.FromString(version)\n\n            depdict = {\n                'name': name,\n                'unique_id': unique_id,\n                'required_version': ver_range,\n                'required_version_string': version\n            }\n\n            if name not in found_deps:\n                self.dependencies.append(depdict)\n\n            found_deps.add(name)\n\n        # Store any architectures that we find in this json file for future reference\n        self.architectures = architectures\n\n        # Setup our support package information\n        self.support_distribution = \"iotile_support_{0}_{1}\".format(self.short_name, self.parsed_version.major)\n\n        if 'python_universal' in self.settings:\n            py_version = \"py2.py3\"\n        elif sys.version_info[0] >= 3:\n            py_version = \"py3\"\n        else:\n            py_version = \"py2\"\n\n        self.support_wheel = \"{0}-{1}-{2}-none-any.whl\".format(self.support_distribution,\n                                                               self.parsed_version.pep440_string(),\n                                                               py_version)\n        self.has_wheel = self._check_has_wheel()", "response": "Load the settings for a module."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure that all product locations are strings.", "response": "def _ensure_product_string(cls, product):\n        \"\"\"Ensure that all product locations are strings.\n\n        Older components specify paths as lists of path components.  Join\n        those paths into a normal path string.\n        \"\"\"\n\n        if isinstance(product, str):\n            return product\n\n        if isinstance(product, list):\n            return os.path.join(*product)\n\n        raise DataError(\"Unknown object (not str or list) specified as a component product\", product=product)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_products(self, product_type):\n\n        if self.filter_prods and product_type in self.LIST_PRODUCTS and product_type not in self.desired_prods:\n            return []\n\n        if product_type in self.LIST_PRODUCTS:\n            found_products = self.products.get(product_type, [])\n        else:\n            found_products = [x[0] for x in self.products.items()\n                              if x[1] == product_type and (not self.filter_prods or x[0] in self.desired_prods)]\n\n        found_products = [self._ensure_product_string(x) for x in found_products]\n\n        declaration = self.PATH_PRODUCTS.get(product_type)\n        if declaration is not None:\n            found_products = [self._process_product_path(x, declaration) for x in found_products]\n\n        return found_products", "response": "Search through the list of products declared by this IOTile component and return only those that match the given product type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of directories containing any static libraries built by this IOTile.", "response": "def library_directories(self):\n        \"\"\"Return a list of directories containing any static libraries built by this IOTile.\"\"\"\n\n        libs = self.find_products('library')\n\n        if len(libs) > 0:\n            return [os.path.join(self.output_folder)]\n\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_ascii(sensor_graph):\n\n    cmdfile = CommandFile(\"Sensor Graph\", \"1.0\")\n\n    # Clear any old sensor graph\n    cmdfile.add(\"set_online\", False)\n    cmdfile.add(\"clear\")\n    cmdfile.add(\"reset\")\n\n    # Load in the nodes\n    for node in sensor_graph.dump_nodes():\n        cmdfile.add('add_node', node)\n\n    # Load in the streamers\n    for streamer in sensor_graph.streamers:\n        other = 0xFF\n        if streamer.with_other is not None:\n            other = streamer.with_other\n\n        args = [streamer.selector, streamer.dest, streamer.automatic, streamer.format, streamer.report_type, other]\n        cmdfile.add('add_streamer', *args)\n\n    # Load all the constants\n    for stream, value in sorted(sensor_graph.constant_database.items(), key=lambda x: x[0].encode()):\n        cmdfile.add(\"push_reading\", stream, value)\n\n    # Persist the sensor graph\n    cmdfile.add(\"persist\")\n    cmdfile.add(\"set_online\", True)\n\n    return cmdfile.dump()", "response": "Format this sensor graph as an ascii file format."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear(self):\n\n        self.roots = []\n        self.nodes = []\n        self.streamers = []\n\n        self.constant_database = {}\n        self.metadata_database = {}\n        self.config_database = {}", "response": "Clear all nodes from this sensor_graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_node(self, node_descriptor):\n\n        if self._max_nodes is not None and len(self.nodes) >= self._max_nodes:\n            raise ResourceUsageError(\"Maximum number of nodes exceeded\", max_nodes=self._max_nodes)\n\n        node, inputs, processor = parse_node_descriptor(node_descriptor, self.model)\n\n        in_root = False\n\n        for i, input_data in enumerate(inputs):\n            selector, trigger = input_data\n\n            walker = self.sensor_log.create_walker(selector)\n\n            # Constant walkers begin life initialized to 0 so they always read correctly\n            if walker.selector.inexhaustible:\n                walker.reading = IOTileReading(0xFFFFFFFF, walker.selector.as_stream(), 0)\n\n            node.connect_input(i, walker, trigger)\n\n            if selector.input and not in_root:\n                self.roots.append(node)\n                in_root = True  # Make sure we only add to root list once\n            else:\n                found = False\n                for other in self.nodes:\n                    if selector.matches(other.stream):\n                        other.connect_output(node)\n                        found = True\n\n                if not found and selector.buffered:\n                    raise NodeConnectionError(\"Node has input that refers to another node that has not been created yet\", node_descriptor=node_descriptor, input_selector=str(selector), input_index=i)\n\n        # Also make sure we add this node's output to any other existing node's inputs\n        # this is important for constant nodes that may be written from multiple places\n        # FIXME: Make sure when we emit nodes, they are topologically sorted\n        for other_node in self.nodes:\n            for selector, trigger in other_node.inputs:\n                if selector.matches(node.stream):\n                    node.connect_output(other_node)\n\n        # Find and load the processing function for this node\n        func = self.find_processing_function(processor)\n        if func is None:\n            raise ProcessingFunctionError(\"Could not find processing function in installed packages\", func_name=processor)\n\n        node.set_func(processor, func)\n        self.nodes.append(node)", "response": "Add a node to the sensor graph based on the description given."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_config(self, slot, config_id, config_type, value):\n\n        if slot not in self.config_database:\n            self.config_database[slot] = {}\n\n        self.config_database[slot][config_id] = (config_type, value)", "response": "Adds a config variable assignment to this sensor graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a streamer to this sensor graph.", "response": "def add_streamer(self, streamer):\n        \"\"\"Add a streamer to this sensor graph.\n\n        Args:\n            streamer (DataStreamer): The streamer we want to add\n        \"\"\"\n\n        if self._max_streamers is not None and len(self.streamers) >= self._max_streamers:\n            raise ResourceUsageError(\"Maximum number of streamers exceeded\", max_streamers=self._max_streamers)\n\n        streamer.link_to_storage(self.sensor_log)\n        streamer.index = len(self.streamers)\n\n        self.streamers.append(streamer)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_constant(self, stream, value):\n\n        if stream in self.constant_database:\n            raise ArgumentError(\"Attempted to set the same constant twice\", stream=stream, old_value=self.constant_database[stream], new_value=value)\n\n        self.constant_database[stream] = value", "response": "Store a constant value for use in this sensor graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattaching a piece of metadata to this sensorgraph.", "response": "def add_metadata(self, name, value):\n        \"\"\"Attach a piece of metadata to this sensorgraph.\n\n        Metadata is not used during the simulation of a sensorgraph but allows\n        it to convey additional context that may be used during code\n        generation.  For example, associating an `app_tag` with a sensorgraph\n        allows the snippet code generator to set that app_tag on a device when\n        programming the sensorgraph.\n\n        Arg:\n            name (str): The name of the metadata that we wish to associate with this\n                sensorgraph.\n            value (object): The value we wish to store.\n        \"\"\"\n\n        if name in self.metadata_database:\n            raise ArgumentError(\"Attempted to set the same metadata value twice\", name=name, old_value=self.metadata_database[name], new_value=value)\n\n        self.metadata_database[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_remaining_constants(self, value=0):\n\n        remaining = []\n\n        for node, _inputs, _outputs in self.iterate_bfs():\n            streams = node.input_streams() + [node.stream]\n\n            for stream in streams:\n                if stream.stream_type is not DataStream.ConstantType:\n                    continue\n\n                if stream not in self.constant_database:\n                    self.add_constant(stream, value)\n                    remaining.append(stream)\n\n        return remaining", "response": "This function initializes all uninitialized constant streams that are not yet initialized."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all constants into their respective streams.", "response": "def load_constants(self):\n        \"\"\"Load all constants into their respective streams.\n\n        All previous calls to add_constant stored a constant value that\n        should be associated with virtual stream walkers.  This function\n        actually calls push_stream in order to push all of the constant\n        values to their walkers.\n        \"\"\"\n\n        for stream, value in self.constant_database.items():\n            self.sensor_log.push(stream, IOTileReading(0, stream.encode(), value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a config variable assignment previously set on this sensor graph.", "response": "def get_config(self, slot, config_id):\n        \"\"\"Get a config variable assignment previously set on this sensor graph.\n\n        Args:\n            slot (SlotIdentifier): The slot that we are setting this config variable\n                on.\n            config_id (int): The 16-bit config variable identifier.\n\n        Returns:\n            (str, str|int): Returns a tuple with the type of the config variable and\n                the value that is being set.\n\n        Raises:\n            ArgumentError: If the config variable is not currently set on the specified\n                slot.\n        \"\"\"\n\n        if slot not in self.config_database:\n            raise ArgumentError(\"No config variables have been set on specified slot\", slot=slot)\n\n        if config_id not in self.config_database[slot]:\n            raise ArgumentError(\"Config variable has not been set on specified slot\", slot=slot, config_id=config_id)\n\n        return self.config_database[slot][config_id]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a stream is a sensor graph output.", "response": "def is_output(self, stream):\n        \"\"\"Check if a stream is a sensor graph output.\n\n        Return:\n            bool\n        \"\"\"\n\n        for streamer in self.streamers:\n            if streamer.selector.matches(stream):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tick(self, name):\n\n        name_map = {\n            'fast': config_fast_tick_secs,\n            'user1': config_tick1_secs,\n            'user2': config_tick2_secs\n        }\n\n        config = name_map.get(name)\n        if config is None:\n            raise ArgumentError(\"Unknown tick requested\", name=name)\n\n        slot = SlotIdentifier.FromString('controller')\n\n        try:\n            var = self.get_config(slot, config)\n            return var[1]\n        except ArgumentError:\n            return 0", "response": "Get the number of seconds between each configurable tick."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_input(self, stream, value, rpc_executor):\n\n        self.sensor_log.push(stream, value)\n\n        # FIXME: This should be specified in our device model\n        if stream.important:\n            associated_output = stream.associated_stream()\n            self.sensor_log.push(associated_output, value)\n\n        to_check = deque([x for x in self.roots])\n\n        while len(to_check) > 0:\n            node = to_check.popleft()\n            if node.triggered():\n                try:\n                    results = node.process(rpc_executor, self.mark_streamer)\n                    for result in results:\n                        result.raw_time = value.raw_time\n                        self.sensor_log.push(node.stream, result)\n                except:\n                    self._logger.exception(\"Unhandled exception in graph node processing function for node %s\", str(node))\n\n                # If we generated any outputs, notify our downstream nodes\n                # so that they are also checked to see if they should run.\n                if len(results) > 0:\n                    to_check.extend(node.outputs)", "response": "Process an input through this sensor graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mark_streamer(self, index):\n\n        self._logger.debug(\"Marking streamer %d manually\", index)\n        if index >= len(self.streamers):\n            raise ArgumentError(\"Invalid streamer index\", index=index, num_streamers=len(self.streamers))\n\n        self._manually_triggered_streamers.add(index)", "response": "Manually mark a streamer that should trigger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_streamers(self, blacklist=None):\n\n        ready = []\n        selected = set()\n\n        for i, streamer in enumerate(self.streamers):\n            if blacklist is not None and i in blacklist:\n                continue\n\n            if i in selected:\n                continue\n\n            marked = False\n            if i in self._manually_triggered_streamers:\n                marked = True\n                self._manually_triggered_streamers.remove(i)\n\n            if streamer.triggered(marked):\n                self._logger.debug(\"Streamer %d triggered, manual=%s\", i, marked)\n                ready.append(streamer)\n                selected.add(i)\n\n                # Handle streamers triggered with another\n                for j, streamer2 in enumerate(self.streamers[i:]):\n                    if streamer2.with_other == i and j not in selected and streamer2.triggered(True):\n                        self._logger.debug(\"Streamer %d triggered due to with-other on %d\", j, i)\n                        ready.append(streamer2)\n                        selected.add(j)\n\n        return ready", "response": "Check if any streamers are ready to produce a report."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterate_bfs(self):\n\n        working_set = deque(self.roots)\n        seen = []\n\n        while len(working_set) > 0:\n            curr = working_set.popleft()\n\n            # Now build input and output node lists for this node\n            inputs = []\n            for walker, _ in curr.inputs:\n                for other in seen:\n                    if walker.matches(other.stream) and other not in inputs:\n                        inputs.append(other)\n\n            outputs = [x for x in curr.outputs]\n            yield curr, inputs, outputs\n\n            working_set.extend(curr.outputs)\n            seen.append(curr)", "response": "Iterate over all nodes in the sensor graph in breadth first order."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(env):\n    try:\n        bld = env['BUILDERS']['Ipkg']\n    except KeyError:\n        bld = SCons.Builder.Builder(action='$IPKGCOM',\n                                    suffix='$IPKGSUFFIX',\n                                    source_scanner=None,\n                                    target_scanner=None)\n        env['BUILDERS']['Ipkg'] = bld\n\n\n    env['IPKG'] = 'ipkg-build'\n    env['IPKGCOM'] = '$IPKG $IPKGFLAGS ${SOURCE}'\n\n    if env.WhereIs('id'):\n        env['IPKGUSER'] = os.popen('id -un').read().strip()\n        env['IPKGGROUP'] = os.popen('id -gn').read().strip()\n    env['IPKGFLAGS'] = SCons.Util.CLVar('-o $IPKGUSER -g $IPKGGROUP')\n    env['IPKGSUFFIX'] = '.ipk'", "response": "Add Builders and construction variables for ipkg to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a user understandable string like count > = X.", "response": "def format_trigger(self, stream):\n        \"\"\"Create a user understandable string like count(stream) >= X.\n\n        Args:\n            stream (DataStream): The stream to use to format ourselves.\n\n        Returns:\n            str: The formatted string\n        \"\"\"\n\n        src = u'value'\n        if self.use_count:\n            src = u'count'\n\n        return u\"{}({}) {} {}\".format(src, stream, self.comp_string, self.reference)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef triggered(self, walker):\n\n        if self.use_count:\n            comp_value = walker.count()\n        else:\n            if walker.count() == 0:\n                return False\n\n            comp_value = walker.peek().value\n\n        return self.comp_function(comp_value, self.reference)", "response": "Check if this input is triggered on the given stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect_input(self, index, walker, trigger=None):\n\n        if trigger is None:\n            trigger = TrueTrigger()\n\n        if index >= len(self.inputs):\n            raise TooManyInputsError(\"Input index exceeded max number of inputs\", index=index, max_inputs=len(self.inputs), stream=self.stream)\n\n        self.inputs[index] = (walker, trigger)", "response": "Connect an input to a stream walker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef input_streams(self):\n\n        streams = []\n\n        for walker, _trigger in self.inputs:\n            if walker.selector is None or not walker.selector.singular:\n                continue\n\n            streams.append(walker.selector.as_stream())\n\n        return streams", "response": "Return a list of DataStreams for all singular input streams."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the input that responds to this stream.", "response": "def find_input(self, stream):\n        \"\"\"Find the input that responds to this stream.\n\n        Args:\n            stream (DataStream): The stream to find\n\n        Returns:\n            (index, None): The index if found or None\n        \"\"\"\n\n        for i, input_x in enumerate(self.inputs):\n            if input_x[0].matches(stream):\n                return i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of connected inputs.", "response": "def num_inputs(self):\n        \"\"\"Return the number of connected inputs.\n\n        Returns:\n            int: The number of connected inputs\n        \"\"\"\n\n        num = 0\n\n        for walker, _ in self.inputs:\n            if not isinstance(walker, InvalidStreamWalker):\n                num += 1\n\n        return num"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects another node to our output.", "response": "def connect_output(self, node):\n        \"\"\"Connect another node to our output.\n\n        This downstream node will automatically be triggered when we update\n        our output.\n\n        Args:\n            node (SGNode): The node that should receive our output\n        \"\"\"\n\n        if len(self.outputs) == self.max_outputs:\n            raise TooManyOutputsError(\"Attempted to connect too many nodes to the output of a node\", max_outputs=self.max_outputs, stream=self.stream)\n\n        self.outputs.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef triggered(self):\n\n        trigs = [x[1].triggered(x[0]) for x in self.inputs]\n\n        if self.trigger_combiner == self.OrTriggerCombiner:\n            return True in trigs\n\n        return False not in trigs", "response": "Test if we should trigger our operation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the processing function to use for this node.", "response": "def set_func(self, name, func):\n        \"\"\"Set the processing function to use for this node.\n\n        Args:\n            name (str): The name of the function to use.  This is\n                just stored for reference in case we need to serialize\n                the node later.\n            func (callable): A function that is called to process inputs\n                for this node.  It should have the following signature:\n                callable(input1_walker, input2_walker, ...)\n                It should return a list of IOTileReadings that are then pushed into\n                the node's output stream\n        \"\"\"\n\n        self.func_name = name\n        self.func = func"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun this node s processing function.", "response": "def process(self, rpc_executor, mark_streamer=None):\n        \"\"\"Run this node's processing function.\n\n        Args:\n            rpc_executor (RPCExecutor): An object capable of executing RPCs\n                in case we need to do that.\n            mark_streamer (callable): Function that can be called to manually\n                mark a streamer as triggered by index.\n\n        Returns:\n            list(IOTileReading): A list of IOTileReadings with the results of\n                the processing function or an empty list if no results were\n                produced\n        \"\"\"\n\n        if self.func is None:\n            raise ProcessingFunctionError('No processing function set for node', stream=self.stream)\n\n        results = self.func(*[x[0] for x in self.inputs], rpc_executor=rpc_executor, mark_streamer=mark_streamer)\n        if results is None:\n            results = []\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FortranScan(path_variable=\"FORTRANPATH\"):\n\n#   The USE statement regex matches the following:\n#\n#   USE module_name\n#   USE :: module_name\n#   USE, INTRINSIC :: module_name\n#   USE, NON_INTRINSIC :: module_name\n#\n#   Limitations\n#\n#   --  While the regex can handle multiple USE statements on one line,\n#       it cannot properly handle them if they are commented out.\n#       In either of the following cases:\n#\n#            !  USE mod_a ; USE mod_b         [entire line is commented out]\n#               USE mod_a ! ; USE mod_b       [in-line comment of second USE statement]\n#\n#       the second module name (mod_b) will be picked up as a dependency\n#       even though it should be ignored.  The only way I can see\n#       to rectify this would be to modify the scanner to eliminate\n#       the call to re.findall, read in the contents of the file,\n#       treating the comment character as an end-of-line character\n#       in addition to the normal linefeed, loop over each line,\n#       weeding out the comments, and looking for the USE statements.\n#       One advantage to this is that the regex passed to the scanner\n#       would no longer need to match a semicolon.\n#\n#   --  I question whether or not we need to detect dependencies to\n#       INTRINSIC modules because these are built-in to the compiler.\n#       If we consider them a dependency, will SCons look for them, not\n#       find them, and kill the build?  Or will we there be standard\n#       compiler-specific directories we will need to point to so the\n#       compiler and SCons can locate the proper object and mod files?\n\n#   Here is a breakdown of the regex:\n#\n#   (?i)               : regex is case insensitive\n#   ^                  : start of line\n#   (?:                : group a collection of regex symbols without saving the match as a \"group\"\n#      ^|;             : matches either the start of the line or a semicolon - semicolon\n#   )                  : end the unsaved grouping\n#   \\s*                : any amount of white space\n#   USE                : match the string USE, case insensitive\n#   (?:                : group a collection of regex symbols without saving the match as a \"group\"\n#      \\s+|            : match one or more whitespace OR ....  (the next entire grouped set of regex symbols)\n#      (?:             : group a collection of regex symbols without saving the match as a \"group\"\n#         (?:          : establish another unsaved grouping of regex symbols\n#            \\s*          : any amount of white space\n#            ,         : match a comma\n#            \\s*       : any amount of white space\n#            (?:NON_)? : optionally match the prefix NON_, case insensitive\n#            INTRINSIC : match the string INTRINSIC, case insensitive\n#         )?           : optionally match the \", INTRINSIC/NON_INTRINSIC\" grouped expression\n#         \\s*          : any amount of white space\n#         ::           : match a double colon that must appear after the INTRINSIC/NON_INTRINSIC attribute\n#      )               : end the unsaved grouping\n#   )                  : end the unsaved grouping\n#   \\s*                : match any amount of white space\n#   (\\w+)              : match the module name that is being USE'd\n#\n#\n    use_regex = \"(?i)(?:^|;)\\s*USE(?:\\s+|(?:(?:\\s*,\\s*(?:NON_)?INTRINSIC)?\\s*::))\\s*(\\w+)\"\n\n\n#   The INCLUDE statement regex matches the following:\n#\n#   INCLUDE 'some_Text'\n#   INCLUDE \"some_Text\"\n#   INCLUDE \"some_Text\" ; INCLUDE \"some_Text\"\n#   INCLUDE kind_\"some_Text\"\n#   INCLUDE kind_'some_Text\"\n#\n#   where some_Text can include any alphanumeric and/or special character\n#   as defined by the Fortran 2003 standard.\n#\n#   Limitations:\n#\n#   --  The Fortran standard dictates that a \" or ' in the INCLUDE'd\n#       string must be represented as a \"\" or '', if the quotes that wrap\n#       the entire string are either a ' or \", respectively.   While the\n#       regular expression below can detect the ' or \" characters just fine,\n#       the scanning logic, presently is unable to detect them and reduce\n#       them to a single instance.  This probably isn't an issue since,\n#       in practice, ' or \" are not generally used in filenames.\n#\n#   --  This regex will not properly deal with multiple INCLUDE statements\n#       when the entire line has been commented out, ala\n#\n#           ! INCLUDE 'some_file' ; INCLUDE 'some_file'\n#\n#       In such cases, it will properly ignore the first INCLUDE file,\n#       but will actually still pick up the second.  Interestingly enough,\n#       the regex will properly deal with these cases:\n#\n#             INCLUDE 'some_file'\n#             INCLUDE 'some_file' !; INCLUDE 'some_file'\n#\n#       To get around the above limitation, the FORTRAN programmer could\n#       simply comment each INCLUDE statement separately, like this\n#\n#           ! INCLUDE 'some_file' !; INCLUDE 'some_file'\n#\n#       The way I see it, the only way to get around this limitation would\n#       be to modify the scanning logic to replace the calls to re.findall\n#       with a custom loop that processes each line separately, throwing\n#       away fully commented out lines before attempting to match against\n#       the INCLUDE syntax.\n#\n#   Here is a breakdown of the regex:\n#\n#   (?i)               : regex is case insensitive\n#   (?:                : begin a non-saving group that matches the following:\n#      ^               :    either the start of the line\n#      |               :                or\n#      ['\">]\\s*;       :    a semicolon that follows a single quote,\n#                           double quote or greater than symbol (with any\n#                           amount of whitespace in between).  This will\n#                           allow the regex to match multiple INCLUDE\n#                           statements per line (although it also requires\n#                           the positive lookahead assertion that is\n#                           used below).  It will even properly deal with\n#                           (i.e. ignore) cases in which the additional\n#                           INCLUDES are part of an in-line comment, ala\n#                                           \"  INCLUDE 'someFile' ! ; INCLUDE 'someFile2' \"\n#   )                  : end of non-saving group\n#   \\s*                : any amount of white space\n#   INCLUDE            : match the string INCLUDE, case insensitive\n#   \\s+                : match one or more white space characters\n#   (?\\w+_)?           : match the optional \"kind-param _\" prefix allowed by the standard\n#   [<\"']              : match the include delimiter - an apostrophe, double quote, or less than symbol\n#   (.+?)              : match one or more characters that make up\n#                        the included path and file name and save it\n#                        in a group.  The Fortran standard allows for\n#                        any non-control character to be used.  The dot\n#                        operator will pick up any character, including\n#                        control codes, but I can't conceive of anyone\n#                        putting control codes in their file names.\n#                        The question mark indicates it is non-greedy so\n#                        that regex will match only up to the next quote,\n#                        double quote, or greater than symbol\n#   (?=[\"'>])          : positive lookahead assertion to match the include\n#                        delimiter - an apostrophe, double quote, or\n#                        greater than symbol.  This level of complexity\n#                        is required so that the include delimiter is\n#                        not consumed by the match, thus allowing the\n#                        sub-regex discussed above to uniquely match a\n#                        set of semicolon-separated INCLUDE statements\n#                        (as allowed by the F2003 standard)\n\n    include_regex = \"\"\"(?i)(?:^|['\">]\\s*;)\\s*INCLUDE\\s+(?:\\w+_)?[<\"'](.+?)(?=[\"'>])\"\"\"\n\n#   The MODULE statement regex finds module definitions by matching\n#   the following:\n#\n#   MODULE module_name\n#\n#   but *not* the following:\n#\n#   MODULE PROCEDURE procedure_name\n#\n#   Here is a breakdown of the regex:\n#\n#   (?i)               : regex is case insensitive\n#   ^\\s*               : any amount of white space\n#   MODULE             : match the string MODULE, case insensitive\n#   \\s+                : match one or more white space characters\n#   (?!PROCEDURE)      : but *don't* match if the next word matches\n#                        PROCEDURE (negative lookahead assertion),\n#                        case insensitive\n#   (\\w+)              : match one or more alphanumeric characters\n#                        that make up the defined module name and\n#                        save it in a group\n\n    def_regex = \"\"\"(?i)^\\s*MODULE\\s+(?!PROCEDURE)(\\w+)\"\"\"\n\n    scanner = F90Scanner(\"FortranScan\",\n                         \"$FORTRANSUFFIXES\",\n                         path_variable,\n                         use_regex,\n                         include_regex,\n                         def_regex)\n    return scanner", "response": "Returns a prototype Scanner instance for scanning source files for Fortran USE statements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding Builders and construction variables for compaq visual fortran to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for compaq visual fortran to an Environment.\"\"\"\n\n    fortran.generate(env)\n\n    env['FORTRAN']        = 'f90'\n    env['FORTRANCOM']     = '$FORTRAN $FORTRANFLAGS $_FORTRANMODFLAG $_FORTRANINCFLAGS /compile_only ${SOURCES.windows} /object:${TARGET.windows}'\n    env['FORTRANPPCOM']   = '$FORTRAN $FORTRANFLAGS $CPPFLAGS $_CPPDEFFLAGS $_FORTRANMODFLAG $_FORTRANINCFLAGS /compile_only ${SOURCES.windows} /object:${TARGET.windows}'\n    env['SHFORTRANCOM']   = '$SHFORTRAN $SHFORTRANFLAGS $_FORTRANMODFLAG $_FORTRANINCFLAGS /compile_only ${SOURCES.windows} /object:${TARGET.windows}'\n    env['SHFORTRANPPCOM'] = '$SHFORTRAN $SHFORTRANFLAGS $CPPFLAGS $_CPPDEFFLAGS $_FORTRANMODFLAG $_FORTRANINCFLAGS /compile_only ${SOURCES.windows} /object:${TARGET.windows}'\n    env['OBJSUFFIX']      = '.obj'\n    env['FORTRANMODDIR'] = '${TARGET.dir}'\n    env['FORTRANMODDIRPREFIX'] = '/module:'\n    env['FORTRANMODDIRSUFFIX'] = ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self):\n        self.build()\n        if not hasattr(self, 'built_value'):\n            self.built_value = self.value\n        return self.built_value", "response": "Return the value. If necessary the value is built."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_text_contents(self):\n        ###TODO: something reasonable about universal newlines\n        contents = str(self.value)\n        for kid in self.children(None):\n            contents = contents + kid.get_contents().decode()\n        return contents", "response": "Returns the text contents of the value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_csig(self, calc=None):\n        try:\n            return self.ninfo.csig\n        except AttributeError:\n            pass\n        contents = self.get_contents()\n        self.get_ninfo().csig = contents\n        return contents", "response": "Get the contents of the value node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef restore(self, state):\n\n        own_properties = set(self.get_properties())\n        state_properties = set(state)\n\n        to_restore = own_properties.intersection(state_properties)\n\n        for name in to_restore:\n            value = state.get(name)\n\n            if name in self._complex_properties:\n                value = self._complex_properties[name][1](value)\n\n            setattr(self, name, value)", "response": "Restore this state from the output of dump."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mark_complex(self, name, serializer, deserializer):\n\n        self._complex_properties[name] = (serializer, deserializer)", "response": "Mark a property as complex with serializer and deserializer functions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmarking a property as containing serializable objects of a given type.", "response": "def mark_typed_list(self, name, type_object):\n        \"\"\"Mark a property as containing serializable objects of a given type.\n\n        This convenience method allows you to avoid having to call\n        ``mark_complex()`` whenever you need to serialize a list of objects.\n        This method requires that all members of the given list be of a single\n        class that contains a dump() method and a Restore() class method where\n        type_object.Restore(x.dump()) == x.\n\n        Args:\n            name (str): The name of the complex property.\n            type_object: The class object that will be contained inside\n                this list.\n        \"\"\"\n\n        if not hasattr(type_object, 'dump'):\n            raise ArgumentError(\"The passed type object %s is missing required method: dump()\" % type_object)\n        if not hasattr(type_object, 'Restore'):\n            raise ArgumentError(\"The passed type object %s is missing required method: Restore()\" % type_object)\n\n        def _dump_list(obj):\n            if obj is None:\n                return None\n\n            if not isinstance(obj, list):\n                raise DataError(\"Property %s marked as list was not a list: %s\" % (name, repr(obj)))\n\n            return [x.dump() for x in obj]\n\n        def _restore_list(obj):\n            if obj is None:\n                return obj\n\n            return [type_object.Restore(x) for x in obj]\n\n        self.mark_complex(name, _dump_list, _restore_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmarks a property as containing a map str to serializable object.", "response": "def mark_typed_map(self, name, type_object):\n        \"\"\"Mark a property as containing a map str to serializable object.\n\n        This convenience method allows you to avoid having to call\n        ``mark_complex()`` whenever you need to serialize a dict of objects.\n        This method requires that all members of the given dict be of a single\n        class that contains a dump() method and a Restore() class method where\n        type_object.Restore(x.dump()) == x.\n\n        Args:\n            name (str): The name of the complex property.\n            type_object: The class object that will be contained inside\n                this dict.\n        \"\"\"\n\n        if not hasattr(type_object, 'dump'):\n            raise ArgumentError(\"The passed type object %s is missing required method: dump()\" % type_object)\n        if not hasattr(type_object, 'Restore'):\n            raise ArgumentError(\"The passed type object %s is missing required method: Restore()\" % type_object)\n\n        def _dump_map(obj):\n            if obj is None:\n                return None\n\n            if not isinstance(obj, dict):\n                raise DataError(\"Property %s marked as list was not a dict: %s\" % (name, repr(obj)))\n\n            return {key: val.dump() for key, val in obj.items()}\n\n        def _restore_map(obj):\n            if obj is None:\n                return obj\n\n            return {key: type_object.Restore(val) for key, val in obj.items()}\n\n        self.mark_complex(name, _dump_map, _restore_map)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmarking a property as containing a serializable object.", "response": "def mark_typed_object(self, name, type_object):\n        \"\"\"Mark a property as containing a serializable object.\n\n        This convenience method allows you to avoid having to call\n        ``mark_complex()`` whenever you need to serialize a complex object.\n        This method requires that property ``name`` be a single class that\n        contains a dump() method and a Restore() class method where\n        type_object.Restore(x.dump()) == x.\n\n        Args:\n            name (str): The name of the complex property.\n            type_object: The class object that will be contained inside\n                this property.\n        \"\"\"\n\n        if not hasattr(type_object, 'dump'):\n            raise ArgumentError(\"The passed type object %s is missing required method: dump()\" % type_object)\n        if not hasattr(type_object, 'Restore'):\n            raise ArgumentError(\"The passed type object %s is missing required method: Restore()\" % type_object)\n\n        def _dump_obj(obj):\n            if obj is None:\n                return None\n\n            return obj.dump()\n\n        def _restore_obj(obj):\n            if obj is None:\n                return obj\n\n            return type_object.Restore(obj)\n\n        self.mark_complex(name, _dump_obj, _restore_obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_property(self, name):\n\n        if not hasattr(self, name):\n            raise ArgumentError(\"Unknown property %s\" % name)\n\n        value = getattr(self, name)\n        if name in self._complex_properties:\n            value = self._complex_properties[name][0](value)\n\n        return value", "response": "Serialize a property of this class by name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_properties(self):\n\n        names = inspect.getmembers(self, predicate=lambda x: not inspect.ismethod(x))\n        return [x[0] for x in names if not x[0].startswith(\"_\") and x[0] not in self._ignored_properties]", "response": "Get a list of all of the public data properties of this class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default_version(env):\n    if 'MSVS' not in env or not SCons.Util.is_Dict(env['MSVS']):\n        # get all versions, and remember them for speed later\n        versions = [vs.version for vs in get_installed_visual_studios()]\n        env['MSVS'] = {'VERSIONS' : versions}\n    else:\n        versions = env['MSVS'].get('VERSIONS', [])\n\n    if 'MSVS_VERSION' not in env:\n        if versions:\n            env['MSVS_VERSION'] = versions[0] #use highest version by default\n        else:\n            debug('get_default_version: WARNING: no installed versions found, '\n                  'using first in SupportedVSList (%s)'%SupportedVSList[0].version)\n            env['MSVS_VERSION'] = SupportedVSList[0].version\n\n    env['MSVS']['VERSION'] = env['MSVS_VERSION']\n\n    return env['MSVS_VERSION']", "response": "Returns the default version string to use for MSVS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the default architecture to use for MSVS", "response": "def get_default_arch(env):\n    \"\"\"Return the default arch to use for MSVS\n\n    if no version was requested by the user through the MSVS_ARCH environment\n    variable, select x86\n\n    Return\n    ------\n    arch: str\n    \"\"\"\n    arch = env.get('MSVS_ARCH', 'x86')\n\n    msvs = InstalledVSMap.get(env['MSVS_VERSION'])\n\n    if not msvs:\n        arch = 'x86'\n    elif not arch in msvs.get_supported_arch():\n        fmt = \"Visual Studio version %s does not support architecture %s\"\n        raise SCons.Errors.UserError(fmt % (env['MSVS_VERSION'], arch))\n\n    return arch"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encrypt_report(self, device_id, root, data, **kwargs):\n\n        for _priority, provider in self.providers:\n            try:\n                return provider.encrypt_report(device_id, root, data, **kwargs)\n            except NotFoundError:\n                pass\n\n        raise NotFoundError(\"encrypt_report method is not implemented in any sub_providers\")", "response": "Encrypt a buffer of report data on behalf of a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying a buffer of report data on behalf of a device.", "response": "def verify_report(self, device_id, root, data, signature, **kwargs):\n        \"\"\"Verify a buffer of report data on behalf of a device.\n\n        Args:\n            device_id (int): The id of the device that we should encrypt for\n            root (int): The root key type that should be used to generate the report\n            data (bytearray): The data that we should verify\n            signature (bytearray): The signature attached to data that we should verify\n            **kwargs: There are additional specific keyword args that are required\n                depending on the root key used.  Typically, you must specify\n                - report_id (int): The report id\n                - sent_timestamp (int): The sent timestamp of the report\n\n                These two bits of information are used to construct the per report\n                signing and encryption key from the specific root key type.\n\n        Returns:\n            dict: The result of the verification process must always be a bool under the\n                'verified' key, however additional keys may be present depending on the\n                signature method used.\n\n        Raises:\n            NotFoundError: If the auth provider is not able to verify the data due to\n                an error.  If the data is simply not valid, then the function returns\n                normally.\n        \"\"\"\n\n        for _priority, provider in self.providers:\n            try:\n                return provider.verify_report(device_id, root, data, signature, **kwargs)\n            except NotFoundError:\n                pass\n\n        raise NotFoundError(\"verify_report method is not implemented in any sub_providers\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_rpc(self, address, rpc_id, payload):\n\n        addr_word = (rpc_id | (address << 16) | ((1 << 1) << 24))\n\n        send_length = len(payload)\n        if len(payload) < 20:\n            payload = payload + b'\\0'*(20 - len(payload))\n\n        payload_words = struct.unpack(\"<5L\", payload)\n\n        return self.base_address + self.RPC_TLS_OFFSET + 8, ([addr_word, send_length, 0] + [x for x in payload_words])", "response": "Create a formated word list that encodes this rpc."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_response(self, response_data):\n\n        _addr, length = self.response_info()\n        if len(response_data) != length:\n            raise HardwareError(\"Invalid response read length, should be the same as what response_info() returns\", expected=length, actual=len(response_data))\n\n        resp, flags, received_length, payload = struct.unpack(\"<HxBL4x20s\", response_data)\n        resp = resp & 0xFF\n        if flags & (1 << 3):\n            raise HardwareError(\"Could not grab external gate\")\n\n        if received_length > 20:\n            raise HardwareError(\"Invalid received payload length > 20 bytes\", received_length=received_length)\n\n        payload = payload[:received_length]\n\n        return {\n            'status': resp,\n            'payload': payload\n        }", "response": "Format an RPC response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ProgramScanner(**kw):\n    kw['path_function'] = SCons.Scanner.FindPathDirs('LIBPATH')\n    ps = SCons.Scanner.Base(scan, \"ProgramScanner\", **kw)\n    return ps", "response": "Return a prototype Scanner instance for scanning executable\n    files for static - lib dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsubstitutes environment variables and split into list.", "response": "def _subst_libs(env, libs):\n    \"\"\"\n    Substitute environment variables and split into list.\n    \"\"\"\n    if SCons.Util.is_String(libs):\n        libs = env.subst(libs)\n        if SCons.Util.is_String(libs):\n            libs = libs.split()\n    elif SCons.Util.is_Sequence(libs):\n        _libs = []\n        for l in libs:\n            _libs += _subst_libs(env, l)\n        libs = _libs\n    else:\n        # libs is an object (Node, for example)\n        libs = [libs]\n    return libs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ListVariable(key, help, default, names, map={}):\n    names_str = 'allowed names: %s' % ' '.join(names)\n    if SCons.Util.is_List(default):\n        default = ','.join(default)\n    help = '\\n    '.join(\n        (help, '(all|none|comma-separated list of names)', names_str))\n    return (key, help, default,\n            None, #_validator,\n            lambda val: _converter(val, names, map))", "response": "A function to create a list variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the RemoteBridge subsystem to its reset state.", "response": "def clear_to_reset(self, config_vars):\n        \"\"\"Clear the RemoteBridge subsystem to its reset state.\"\"\"\n\n        super(RemoteBridgeState, self).clear_to_reset(config_vars)\n        self.status = BRIDGE_STATUS.IDLE\n        self.error = 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef begin_script(self):\n\n        if self.remote_bridge.status in (BRIDGE_STATUS.RECEIVED, BRIDGE_STATUS.VALIDATED, BRIDGE_STATUS.EXECUTING):\n            return [1]  #FIXME: Return correct error here\n\n        self.remote_bridge.status = BRIDGE_STATUS.WAITING\n        self.remote_bridge.error = 0\n        self.remote_bridge.script_error = None\n        self.remote_bridge.parsed_script = None\n\n        self._device.script = bytearray()\n\n        return [0]", "response": "Indicate we are going to start loading a script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef end_script(self):\n\n        if self.remote_bridge.status not in (BRIDGE_STATUS.RECEIVED, BRIDGE_STATUS.WAITING):\n            return [1] #FIXME: State change\n\n        self.remote_bridge.status = BRIDGE_STATUS.RECEIVED\n        return [0]", "response": "Indicate that we have finished receiving a script."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trigger_script(self):\n\n        if self.remote_bridge.status not in (BRIDGE_STATUS.RECEIVED,):\n            return [1] #FIXME: State change\n\n        # This is asynchronous in real life so just cache the error\n        try:\n            self.remote_bridge.parsed_script = UpdateScript.FromBinary(self._device.script)\n            #FIXME: Actually run the script\n\n            self.remote_bridge.status = BRIDGE_STATUS.IDLE\n        except Exception as exc:\n            self._logger.exception(\"Error parsing script streamed to device\")\n            self.remote_bridge.script_error = exc\n            self.remote_bridge.error = 1 # FIXME: Error code\n\n        return [0]", "response": "Actually process a script."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears any partially received script.", "response": "def reset_script(self):\n        \"\"\"Clear any partially received script.\"\"\"\n\n        self.remote_bridge.status = BRIDGE_STATUS.IDLE\n        self.remote_bridge.error = 0\n        self.remote_bridge.parsed_script = None\n        self._device.script = bytearray()\n\n        return [0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a template file in place.", "response": "def render_template_inplace(template_path, info, dry_run=False, extra_filters=None, resolver=None):\n    \"\"\"Render a template file in place.\n\n    This function expects template path to be a path to a file\n    that ends in .tpl.  It will be rendered to a file in the\n    same directory with the .tpl suffix removed.\n\n    Args:\n        template_path (str): The path to the template file\n            that we want to render in place.\n        info (dict): A dictionary of variables passed into the template to\n            perform substitutions.\n        dry_run (bool): Whether to actually render the output file or just return\n            the file path that would be generated.\n        extra_filters (dict of str -> callable): An optional group of filters that\n            will be made available to the template.  The dict key will be the\n            name at which callable is made available.\n        resolver (ProductResolver): The specific ProductResolver class to use in the\n            find_product filter.\n\n    Returns:\n        str: The path to the output file generated.\n    \"\"\"\n\n    filters = {}\n    if resolver is not None:\n        filters['find_product'] = _create_resolver_filter(resolver)\n\n    if extra_filters is not None:\n        filters.update(extra_filters)\n\n    basedir = os.path.dirname(template_path)\n    template_name = os.path.basename(template_path)\n\n    if not template_name.endswith('.tpl'):\n        raise ArgumentError(\"You must specify a filename that ends in .tpl\", filepath=template_path)\n\n    out_path = os.path.join(basedir, template_name[:-4])\n\n    if basedir == '':\n        basedir = '.'\n\n    env = Environment(loader=FileSystemLoader(basedir),\n                      trim_blocks=True, lstrip_blocks=True)\n\n    # Load any filters the user wants us to use\n    for name, func in filters.items():\n        env.filters[name] = func\n\n    template = env.get_template(template_name)\n    result = template.render(info)\n\n    if not dry_run:\n        with open(out_path, 'wb') as outfile:\n            outfile.write(result.encode('utf-8'))\n\n    return out_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a must template using the variables in info.", "response": "def render_template(template_name, info, out_path=None):\n    \"\"\"Render a template using the variables in info.\n\n    You can optionally render to a file by passing out_path.\n\n    Args:\n        template_name (str): The name of the template to load.  This must\n            be a file in config/templates inside this package\n        out_path (str): An optional path of where to save the output\n            file, otherwise it is just returned as a string.\n        info (dict): A dictionary of variables passed into the template to\n            perform substitutions.\n\n    Returns:\n        string: The rendered template data.\n    \"\"\"\n\n    env = Environment(loader=PackageLoader('iotile.build', 'config/templates'),\n                      trim_blocks=True, lstrip_blocks=True)\n\n    template = env.get_template(template_name)\n    result = template.render(info)\n\n    if out_path is not None:\n        with open(out_path, 'wb') as outfile:\n            outfile.write(result.encode('utf-8'))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies a directory tree rendering all templates found within. This function inspects all of the files in template_folder recursively. If any file ends .tpl, it is rendered using render_template and the .tpl suffix is removed. All other files are copied without modification. out_folder is not cleaned before rendering so you must delete its contents yourself if you want that behavior. If you just want to see all of the file paths that would be generated, call with dry_run=True. This will not render anything but just inspect what would be generated. Args: template_folder (str): A relative path from config/templates with the folder that should be rendered recursively. info (dict): A dictionary of variables to be substituted into any templates found in template_folder. out_folder (str): The path to the output folder where the template will be generated. dry_run (bool): Whether to actually render output files or just return the files that would be generated. preserve (list of str): A list of file names relative to the start of the template folder that we are rendering that end in .tpl but should not be rendered and should not have their .tpl suffix removed. This allows you to partially render a template so that you can render a specific file later. Returns: dict, list: The dict is map of output file path (relative to out_folder) to the absolute path of the input file that it depends on. This result is suitable for using in a dependency graph like SCons. The list is a list of all of the directories that would need to be created to hold these files (not including out_folder).", "response": "def render_recursive_template(template_folder, info, out_folder, preserve=None, dry_run=False):\n    \"\"\"Copy a directory tree rendering all templates found within.\n\n    This function inspects all of the files in template_folder recursively. If\n    any file ends .tpl, it is rendered using render_template and the .tpl\n    suffix is removed.  All other files are copied without modification.\n\n    out_folder is not cleaned before rendering so you must delete its contents\n    yourself if you want that behavior.\n\n    If you just want to see all of the file paths that would be generated,\n    call with dry_run=True.  This will not render anything but just inspect\n    what would be generated.\n\n    Args:\n        template_folder (str): A relative path from config/templates with the\n            folder that should be rendered recursively.\n        info (dict): A dictionary of variables to be substituted into any\n            templates found in template_folder.\n        out_folder (str): The path to the output folder where the template will\n            be generated.\n        dry_run (bool): Whether to actually render output files or just return\n            the files that would be generated.\n        preserve (list of str): A list of file names relative to the start of the\n            template folder that we are rendering that end in .tpl but should not\n            be rendered and should not have their .tpl suffix removed.  This allows\n            you to partially render a template so that you can render a specific\n            file later.\n\n    Returns:\n        dict, list: The dict is map of output file path (relative to\n            out_folder) to the absolute path of the input file that it depends\n            on. This result is suitable for using in a dependency graph like\n            SCons. The list is a list of all of the directories that would need\n            to be created to hold these files (not including out_folder).\n    \"\"\"\n\n    if isinstance(preserve, str):\n        raise ArgumentError(\"You must pass a list of strings to preserve, not a string\", preserve=preserve)\n\n    if preserve is None:\n        preserve = []\n\n    preserve = set(preserve)\n\n    template_dir = resource_path('templates', expect='folder')\n    indir = os.path.join(template_dir, template_folder)\n\n    if not os.path.exists(indir):\n        raise ArgumentError(\"Input template folder for recursive template not found\",\n                            template_folder=template_folder, absolute_path=indir)\n    elif not os.path.isdir(indir):\n        raise ArgumentError(\"Input template folder is not a directory\",\n                            template_folder=template_folder, absolute_path=indir)\n\n    create_dirs = []\n    file_map = {}\n\n    # Walk over all input files\n    for dirpath, dirs, files in os.walk(indir):\n        for file in files:\n            in_abspath = os.path.abspath(os.path.join(dirpath, file))\n            in_path = os.path.relpath(os.path.join(dirpath, file), start=indir)\n\n            if file.endswith(\".tpl\") and not in_path in preserve:\n                out_path = in_path[:-4]\n            else:\n                out_path = in_path\n\n            file_map[out_path] = (in_path, in_abspath)\n\n            for folder in dirs:\n                dir_path = os.path.relpath(os.path.join(dirpath, folder), start=indir)\n                create_dirs.append(dir_path)\n\n    # Actually render / copy all files if we are not doing a dry run\n    if not dry_run:\n        for folder in create_dirs:\n            out_path = os.path.join(out_folder, folder)\n            if not os.path.isdir(out_path):\n                os.makedirs(out_path)\n\n        for out_rel, (in_path, in_abspath) in file_map.items():\n            out_path = os.path.join(out_folder, out_rel)\n            if in_path in preserve or not in_path.endswith(\".tpl\"):\n                shutil.copyfile(in_abspath, out_path)\n            else:\n                # jinja needs to have unix path separators regardless of the platform and a relative path\n                # from the templates base directory\n                in_template_path = os.path.join(template_folder, in_path).replace(os.path.sep, '/')\n                render_template(in_template_path, info, out_path=out_path)\n\n    return file_map, create_dirs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for g ++ to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for g++ to an Environment.\"\"\"\n    cplusplus.generate(env)\n\n    if acc:\n        env['CXX']        = acc or 'aCC'\n        env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS +Z')\n        # determine version of aCC\n        line = os.popen(acc + ' -V 2>&1').readline().rstrip()\n        if line.find('aCC: HP ANSI C++') == 0:\n            env['CXXVERSION'] = line.split()[-1]\n\n        if env['PLATFORM'] == 'cygwin':\n            env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS')\n        else:\n            env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS +Z')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all devices and events with a given monitor installed.", "response": "def _find_monitor(monitors, handle):\n    \"\"\"Find all devices and events with a given monitor installed.\"\"\"\n\n    found_devs = set()\n    found_events = set()\n\n    for conn_string, device in monitors.items():\n        for event, handles in device.items():\n            if handle in handles:\n                found_events.add(event)\n                found_devs.add(conn_string)\n\n    return found_devs, found_events"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_monitor(monitors, handle, callback, devices, events):\n\n    for conn_string in devices:\n        data = monitors.get(conn_string)\n        if data is None:\n            data = dict()\n            monitors[conn_string] = data\n\n        for event in events:\n            event_dict = data.get(event)\n            if event_dict is None:\n                event_dict = dict()\n                data[event] = event_dict\n\n            event_dict[handle] = callback", "response": "Add the given monitor to the listed devices and events."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _remove_monitor(monitors, handle, devices, events):\n\n    empty_devices = []\n\n    for conn_string in devices:\n        data = monitors.get(conn_string)\n        if data is None:\n            continue\n\n        for event in events:\n            event_dict = data.get(event)\n            if event_dict is None:\n                continue\n\n            if handle in event_dict:\n                del event_dict[handle]\n\n            if len(event_dict) == 0:\n                del data[event]\n\n        if len(data) == 0:\n            empty_devices.append(conn_string)\n\n    return empty_devices", "response": "Remove the given monitor from the listed devices and events."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a callback when events happen.", "response": "def register_monitor(self, devices, events, callback):\n        \"\"\"Register a callback when events happen.\n\n        If this method is called, it is guaranteed to take effect before the\n        next call to ``_notify_event`` after this method returns.  This method\n        is safe to call from within a callback that is itself called by\n        ``notify_event``.\n\n        See :meth:`AbstractDeviceAdapter.register_monitor`.\n        \"\"\"\n\n        # Ensure we don't exhaust any iterables\n        events = list(events)\n        devices = list(devices)\n\n        for event in events:\n            if event not in self.SUPPORTED_EVENTS:\n                raise ArgumentError(\"Unknown event type {} specified\".format(event), events=events)\n\n        monitor_id = str(uuid.uuid4())\n\n        action = (monitor_id, \"add\", devices, events)\n        self._callbacks[monitor_id] = callback\n\n        if self._currently_notifying:\n            self._deferred_adjustments.append(action)\n        else:\n            self._adjust_monitor_internal(*action)\n\n        return monitor_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_monitors(self):\n\n        for conn_string, events in self._monitors.items():\n            for event, handlers in events.items():\n                for handler in handlers:\n                    yield (conn_string, event, handler)", "response": "Iterate over all defined ( conn_string event monitor ) tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadjust a previously registered callback.", "response": "def adjust_monitor(self, handle, action, devices, events):\n        \"\"\"Adjust a previously registered callback.\n\n        See :meth:`AbstractDeviceAdapter.adjust_monitor`.\n        \"\"\"\n\n        events = list(events)\n        devices = list(devices)\n\n        for event in events:\n            if event not in self.SUPPORTED_EVENTS:\n                raise ArgumentError(\"Unknown event type {} specified\".format(event), events=events)\n\n        if action not in self.SUPPORTED_ADJUSTMENTS:\n            raise ArgumentError(\"Unknown adjustment {} specified\".format(action))\n\n        action = (handle, action, devices, events)\n        if self._currently_notifying:\n            self._deferred_adjustments.append(action)\n        else:\n            self._adjust_monitor_internal(*action)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a previously registered monitor.", "response": "def remove_monitor(self, handle):\n        \"\"\"Remove a previously registered monitor.\n\n        See :meth:`AbstractDeviceAdapter.adjust_monitor`.\n        \"\"\"\n\n        action = (handle, \"delete\", None, None)\n        if self._currently_notifying:\n            self._deferred_adjustments.append(action)\n        else:\n            self._adjust_monitor_internal(*action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _notify_event_internal(self, conn_string, name, event):\n\n        try:\n            self._currently_notifying = True\n            conn_id = self._get_conn_id(conn_string)\n\n            event_maps = self._monitors.get(conn_string, {})\n            wildcard_maps = self._monitors.get(None, {})\n\n            wildcard_handlers = wildcard_maps.get(name, {})\n            event_handlers = event_maps.get(name, {})\n\n            for handler, func in itertools.chain(event_handlers.items(), wildcard_handlers.items()):\n                try:\n                    result = func(conn_string, conn_id, name, event)\n                    if inspect.isawaitable(result):\n                        await result\n                except:  #pylint:disable=bare-except;This is a background function and we are logging exceptions\n                    self._logger.warning(\"Error calling notification callback id=%s, func=%s\", handler, func, exc_info=True)\n        finally:\n            for action in self._deferred_adjustments:\n                self._adjust_monitor_internal(*action)\n\n            self._deferred_adjustments = []\n            self._currently_notifying = False", "response": "Notify that an event has occured."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notify_event(self, conn_string, name, event):\n\n        return self._loop.launch_coroutine(self._notify_event_internal, conn_string, name, event)", "response": "Notify an event.\n\n        This method will launch a coroutine that runs all callbacks (and\n        awaits all coroutines) attached to the given event that was just\n        raised.  Internally it uses\n        :meth:`BackgroundEventLoop.launch_coroutine` which retains an\n        awaitable object when called from within an event loop and a\n        concurrent Future object when called outside of the event loop.\n\n        Calling this method from outside of the BackgroundEventLoop is\n        considered experimental and not stable behavior that can be depended\n        on.\n\n        Args:\n            conn_string (str): The connection string for the device that the\n                event is associated with.\n            name (str): The name of the event. Must be in SUPPORTED_EVENTS.\n            event (object): The event object.  The type of this object will\n                depend on what is being notified.\n\n        Returns:\n            awaitable: An awaitable object that can be used to wait for all callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnotifies an event. This will move the notification to the background event loop and return immediately. It is useful for situations where you cannot await notify_event but keep in mind that it prevents back-pressure when you are notifying too fast so should be used sparingly. Note that calling this method will push the notification to a background task so it can be difficult to reason about when it will precisely occur. For that reason, :meth:`notify_event` should be preferred when possible since that method guarantees that all callbacks will be called synchronously before it finishes. Args: conn_string (str): The connection string for the device that the event is associated with. name (str): The name of the event. Must be in SUPPORTED_EVENTS. event (object): The event object. The type of this object will depend on what is being notified.", "response": "def notify_event_nowait(self, conn_string, name, event):\n        \"\"\"Notify an event.\n\n        This will move the notification to the background event loop and\n        return immediately.  It is useful for situations where you cannot\n        await notify_event but keep in mind that it prevents back-pressure\n        when you are notifying too fast so should be used sparingly.\n\n        Note that calling this method will push the notification to a\n        background task so it can be difficult to reason about when it will\n        precisely occur.  For that reason, :meth:`notify_event` should be\n        preferred when possible since that method guarantees that all\n        callbacks will be called synchronously before it finishes.\n\n        Args:\n            conn_string (str): The connection string for the device that the\n                event is associated with.\n            name (str): The name of the event. Must be in SUPPORTED_EVENTS.\n            event (object): The event object.  The type of this object will\n                depend on what is being notified.\n        \"\"\"\n\n        if self._loop.stopping:\n            self._logger.debug(\"Ignoring notification %s from %s because loop is shutting down\", name, conn_string)\n            return\n\n        self._loop.log_coroutine(self._notify_event_internal, conn_string, name, event)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a progress event.", "response": "def notify_progress(self, conn_string, operation, finished, total, wait=True):\n        \"\"\"Send a progress event.\n\n        Progress events can be sent for ``debug`` and ``script`` operations and\n        notify the caller about the progress of these potentially long-running\n        operations.  They have two integer properties that specify what fraction\n        of the operation has been completed.\n\n        Args:\n            conn_string (str): The device that is sending the event.\n            operations (str): The operation that is in progress: debug or script\n            finished (int): The number of \"steps\" that have finished.\n            total (int): The total number of steps to perform.\n            wait (bool): Whether to return an awaitable that we can use to\n                block until the notification has made it to all callbacks.\n\n        Returns:\n            awaitable or None: An awaitable if wait=True.\n\n            If wait is False, the notification is run in the background with\n            no way to check its progress and None is returned.\n        \"\"\"\n\n        if operation not in self.PROGRESS_OPERATIONS:\n            raise ArgumentError(\"Invalid operation for progress event: {}\".format(operation))\n\n        event = dict(operation=operation, finished=finished, total=total)\n\n        if wait:\n            return self.notify_event(conn_string, 'progress', event)\n\n        self.notify_event_nowait(conn_string, 'progress', event)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd Builders and construction variables for SGI MIPS C ++ to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for SGI MIPS C++ to an Environment.\"\"\"\n\n    cplusplus.generate(env)\n\n    env['CXX']         = 'CC'\n    env['CXXFLAGS']    = SCons.Util.CLVar('-LANG:std')\n    env['SHCXX']       = '$CXX'\n    env['SHOBJSUFFIX'] = '.o'\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread one packet from the queue", "response": "def read_packet(self, timeout=3.0):\n        \"\"\"read one packet, timeout if one packet is not available in the timeout period\"\"\"\n\n        try:\n            return self.queue.get(timeout=timeout)\n        except Empty:\n            raise InternalTimeoutError(\"Timeout waiting for packet in AsyncPacketBuffer\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies a dict by adding or adding a key value pair.", "response": "def modify_dict(data, key, value, create_if_missing=False):\n    \"\"\" Change (or add) a json key/value pair.\n\n    Args:\n        data (dict): The original data. This will not be modified.\n        key (list): A list of keys and subkeys specifing the key to change (list can be one)\n        value (str): The value to change for the above key\n        create_if_missing (bool): Set to true to create key if the last key in the list is not found\n                Otherwise the function will throw a KeyError\n    Returns:\n        (dict): the final modified dict\n    \"\"\"\n    data_copy = copy.deepcopy(data)\n    key_copy = copy.deepcopy(key)\n\n    delver = data_copy\n    current_key = key_copy\n    last_key = \"Root\"\n\n    # Dig through the json, setting delver to the dict that contains the last key in \"key\"\n    while len(current_key) > 1:\n        if current_key[0] not in delver:\n            raise KeyError(\"ModifyJsonStep Key Couldn't find Subkey {} in {}.\".format(current_key[0], last_key))\n\n        if len(current_key) > 2 and not isinstance(delver[current_key[0]], dict):\n            raise ValueError(\"ModifyJsonStep The Value of {} is a {}, not a dict\".format(current_key[0], type(delver[current_key[0]])))\n\n        last_key = current_key[0]\n        delver = delver[current_key[0]]\n        current_key.pop(0)\n\n    if current_key[0] not in delver and not create_if_missing:\n        raise KeyError(\"ModifyJsonStep Key Couldn't find Subkey {} in {}.\".format(current_key[0], last_key))\n\n    delver[current_key[0]] = value\n\n    return data_copy"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef emit_java_classes(target, source, env):\n    java_suffix = env.get('JAVASUFFIX', '.java')\n    class_suffix = env.get('JAVACLASSSUFFIX', '.class')\n\n    target[0].must_be_same(SCons.Node.FS.Dir)\n    classdir = target[0]\n\n    s = source[0].rentry().disambiguate()\n    if isinstance(s, SCons.Node.FS.File):\n        sourcedir = s.dir.rdir()\n    elif isinstance(s, SCons.Node.FS.Dir):\n        sourcedir = s.rdir()\n    else:\n        raise SCons.Errors.UserError(\"Java source must be File or Dir, not '%s'\" % s.__class__)\n\n    slist = []\n    js = _my_normcase(java_suffix)\n    for entry in source:\n        entry = entry.rentry().disambiguate()\n        if isinstance(entry, SCons.Node.FS.File):\n            slist.append(entry)\n        elif isinstance(entry, SCons.Node.FS.Dir):\n            result = SCons.Util.OrderedDict()\n            dirnode = entry.rdir()\n            def find_java_files(arg, dirpath, filenames):\n                java_files = sorted([n for n in filenames\n                                       if _my_normcase(n).endswith(js)])\n                mydir = dirnode.Dir(dirpath)\n                java_paths = [mydir.File(f) for f in java_files]\n                for jp in java_paths:\n                     arg[jp] = True\n            for dirpath, dirnames, filenames in os.walk(dirnode.get_abspath()):\n               find_java_files(result, dirpath, filenames)\n            entry.walk(find_java_files, result)\n\n            slist.extend(list(result.keys()))\n        else:\n            raise SCons.Errors.UserError(\"Java source must be File or Dir, not '%s'\" % entry.__class__)\n\n    version = env.get('JAVAVERSION', '1.4')\n    full_tlist = []\n    for f in slist:\n        tlist = []\n        source_file_based = True\n        pkg_dir = None\n        if not f.is_derived():\n            pkg_dir, classes = parse_java_file(f.rfile().get_abspath(), version)\n            if classes:\n                source_file_based = False\n                if pkg_dir:\n                    d = target[0].Dir(pkg_dir)\n                    p = pkg_dir + os.sep\n                else:\n                    d = target[0]\n                    p = ''\n                for c in classes:\n                    t = d.File(c + class_suffix)\n                    t.attributes.java_classdir = classdir\n                    t.attributes.java_sourcedir = sourcedir\n                    t.attributes.java_classname = classname(p + c)\n                    tlist.append(t)\n\n        if source_file_based:\n            base = f.name[:-len(java_suffix)]\n            if pkg_dir:\n                t = target[0].Dir(pkg_dir).File(base + class_suffix)\n            else:\n                t = target[0].File(base + class_suffix)\n            t.attributes.java_classdir = classdir\n            t.attributes.java_sourcedir = f.dir\n            t.attributes.java_classname = classname(base)\n            tlist.append(t)\n\n        for t in tlist:\n            t.set_specific_source([f])\n\n        full_tlist.extend(tlist)\n\n    return full_tlist, slist", "response": "Create and return lists of source java files\n    and their corresponding target class files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Java(env, target, source, *args, **kw):\n    if not SCons.Util.is_List(target):\n        target = [target]\n    if not SCons.Util.is_List(source):\n        source = [source]\n\n    # Pad the target list with repetitions of the last element in the\n    # list so we have a target for every source element.\n    target = target + ([target[-1]] * (len(source) - len(target)))\n\n    java_suffix = env.subst('$JAVASUFFIX')\n    result = []\n\n    for t, s in zip(target, source):\n        if isinstance(s, SCons.Node.FS.Base):\n            if isinstance(s, SCons.Node.FS.File):\n                b = env.JavaClassFile\n            else:\n                b = env.JavaClassDir\n        else:\n            if os.path.isfile(s):\n                b = env.JavaClassFile\n            elif os.path.isdir(s):\n                b = env.JavaClassDir\n            elif s[-len(java_suffix):] == java_suffix:\n                b = env.JavaClassFile\n            else:\n                b = env.JavaClassDir\n        result.extend(b(t, s, *args, **kw))\n\n    return result", "response": "A pseudo - Builder wrapper around the separate Java { File Dir } Builders."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds Builders and construction variables for javac to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for javac to an Environment.\"\"\"\n    java_file = SCons.Tool.CreateJavaFileBuilder(env)\n    java_class = SCons.Tool.CreateJavaClassFileBuilder(env)\n    java_class_dir = SCons.Tool.CreateJavaClassDirBuilder(env)\n    java_class.add_emitter(None, emit_java_classes)\n    java_class.add_emitter(env.subst('$JAVASUFFIX'), emit_java_classes)\n    java_class_dir.emitter = emit_java_classes\n\n    env.AddMethod(Java)\n\n    env['JAVAC']                    = 'javac'\n    env['JAVACFLAGS']               = SCons.Util.CLVar('')\n    env['JAVABOOTCLASSPATH']        = []\n    env['JAVACLASSPATH']            = []\n    env['JAVASOURCEPATH']           = []\n    env['_javapathopt']             = pathopt\n    env['_JAVABOOTCLASSPATH']       = '${_javapathopt(\"-bootclasspath\", \"JAVABOOTCLASSPATH\")} '\n    env['_JAVACLASSPATH']           = '${_javapathopt(\"-classpath\", \"JAVACLASSPATH\")} '\n    env['_JAVASOURCEPATH']          = '${_javapathopt(\"-sourcepath\", \"JAVASOURCEPATH\", \"_JAVASOURCEPATHDEFAULT\")} '\n    env['_JAVASOURCEPATHDEFAULT']   = '${TARGET.attributes.java_sourcedir}'\n    env['_JAVACCOM']                = '$JAVAC $JAVACFLAGS $_JAVABOOTCLASSPATH $_JAVACLASSPATH -d ${TARGET.attributes.java_classdir} $_JAVASOURCEPATH $SOURCES'\n    env['JAVACCOM']                 = \"${TEMPFILE('$_JAVACCOM','$JAVACCOMSTR')}\"\n    env['JAVACLASSSUFFIX']          = '.class'\n    env['JAVASUFFIX']               = '.java'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Add(self, key, help=\"\", default=None, validator=None, converter=None, **kw):\n\n        if SCons.Util.is_List(key) or isinstance(key, tuple):\n            self._do_add(*key)\n            return\n\n        if not SCons.Util.is_String(key) or \\\n            not SCons.Environment.is_valid_construction_var(key):\n                raise SCons.Errors.UserError(\"Illegal Variables.Add() key `%s'\" % str(key))\n\n        self._do_add(key, help, default, validator, converter)", "response": "Add an option to the set of available modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates an environment with the option variables and the command line options.", "response": "def Update(self, env, args=None):\n        \"\"\"\n        Update an environment with the option variables.\n\n        env - the environment to update.\n        \"\"\"\n\n        values = {}\n\n        # first set the defaults:\n        for option in self.options:\n            if not option.default is None:\n                values[option.key] = option.default\n\n        # next set the value specified in the options file\n        for filename in self.files:\n            if os.path.exists(filename):\n                dir = os.path.split(os.path.abspath(filename))[0]\n                if dir:\n                    sys.path.insert(0, dir)\n                try:\n                    values['__name__'] = filename\n                    with open(filename, 'r') as f:\n                        contents = f.read()\n                    exec(contents, {}, values)\n                finally:\n                    if dir:\n                        del sys.path[0]\n                    del values['__name__']\n\n        # set the values specified on the command line\n        if args is None:\n            args = self.args\n\n        for arg, value in args.items():\n            added = False\n            for option in self.options:\n                if arg in list(option.aliases) + [ option.key ]:\n                    values[option.key] = value\n                    added = True\n            if not added:\n                self.unknown[arg] = value\n\n        # put the variables in the environment:\n        # (don't copy over variables that are not declared as options)\n        for option in self.options:\n            try:\n                env[option.key] = values[option.key]\n            except KeyError:\n                pass\n\n        # Call the convert functions:\n        for option in self.options:\n            if option.converter and option.key in values:\n                value = env.subst('${%s}'%option.key)\n                try:\n                    try:\n                        env[option.key] = option.converter(value)\n                    except TypeError:\n                        env[option.key] = option.converter(value, env)\n                except ValueError as x:\n                    raise SCons.Errors.UserError('Error converting option: %s\\n%s'%(option.key, x))\n\n\n        # Finally validate the values:\n        for option in self.options:\n            if option.validator and option.key in values:\n                option.validator(option.key, env.subst('${%s}'%option.key), env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Save(self, filename, env):\n\n        # Create the file and write out the header\n        try:\n            fh = open(filename, 'w')\n\n            try:\n                # Make an assignment in the file for each option\n                # within the environment that was assigned a value\n                # other than the default.\n                for option in self.options:\n                    try:\n                        value = env[option.key]\n                        try:\n                            prepare = value.prepare_to_store\n                        except AttributeError:\n                            try:\n                                eval(repr(value))\n                            except KeyboardInterrupt:\n                                raise\n                            except:\n                                # Convert stuff that has a repr() that\n                                # cannot be evaluated into a string\n                                value = SCons.Util.to_String(value)\n                        else:\n                            value = prepare()\n\n                        defaultVal = env.subst(SCons.Util.to_String(option.default))\n                        if option.converter:\n                            defaultVal = option.converter(defaultVal)\n\n                        if str(env.subst('${%s}' % option.key)) != str(defaultVal):\n                            fh.write('%s = %s\\n' % (option.key, repr(value)))\n                    except KeyError:\n                        pass\n            finally:\n                fh.close()\n\n        except IOError as x:\n            raise SCons.Errors.UserError('Error writing options to file: %s\\n%s' % (filename, x))", "response": "Saves all the options in the given file into the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GenerateHelpText(self, env, sort=None):\n\n        if callable(sort):\n            options = sorted(self.options, key=cmp_to_key(lambda x,y: sort(x.key,y.key)))\n        elif sort is True:\n            options = sorted(self.options, key=lambda x: x.key)\n        else:\n            options = self.options\n\n        def format(opt, self=self, env=env):\n            if opt.key in env:\n                actual = env.subst('${%s}' % opt.key)\n            else:\n                actual = None\n            return self.FormatVariableHelpText(env, opt.key, opt.help, opt.default, actual, opt.aliases)\n        lines = [_f for _f in map(format, options) if _f]\n\n        return ''.join(lines)", "response": "Generates the help text for the current values of the options."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes the drive letter uppercase.", "response": "def updrive(path):\n    \"\"\"\n    Make the drive letter (if any) upper case.\n    This is useful because Windows is inconsistent on the case\n    of the drive letter, which can cause inconsistencies when\n    calculating command signatures.\n    \"\"\"\n    drive, rest = os.path.splitdrive(path)\n    if drive:\n        path = drive.upper() + rest\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a string returns the value of the environment variable that corresponds to the given string.", "response": "def get_environment_var(varstr):\n    \"\"\"Given a string, first determine if it looks like a reference\n    to a single environment variable, like \"$FOO\" or \"${FOO}\".\n    If so, return that variable with no decorations (\"FOO\").\n    If not, return None.\"\"\"\n    mo=_get_env_var.match(to_String(varstr))\n    if mo:\n        var = mo.group(1)\n        if var[0] == '{':\n            return var[1:-1]\n        else:\n            return var\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_tree(root, child_func, prune=0, margin=[0], visited=None):\n\n    rname = str(root)\n\n    # Initialize 'visited' dict, if required\n    if visited is None:\n        visited = {}\n\n    children = child_func(root)\n    retval = \"\"\n    for pipe in margin[:-1]:\n        if pipe:\n            retval = retval + \"| \"\n        else:\n            retval = retval + \"  \"\n\n    if rname in visited:\n        return retval + \"+-[\" + rname + \"]\\n\"\n\n    retval = retval + \"+-\" + rname + \"\\n\"\n    if not prune:\n        visited = copy.copy(visited)\n    visited[rname] = 1\n\n    for i in range(len(children)):\n        margin.append(i < len(children)-1)\n        retval = retval + render_tree(children[i], child_func, prune, margin, visited)\n        margin.pop()\n\n    return retval", "response": "Render a tree of nodes into an ASCII tree view."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint a tree of nodes.", "response": "def print_tree(root, child_func, prune=0, showtags=0, margin=[0], visited=None):\n    \"\"\"\n    Print a tree of nodes.  This is like render_tree, except it prints\n    lines directly instead of creating a string representation in memory,\n    so that huge trees can be printed.\n\n    :Parameters:\n        - `root`       - the root node of the tree\n        - `child_func` - the function called to get the children of a node\n        - `prune`      - don't visit the same node twice\n        - `showtags`   - print status information to the left of each node line\n        - `margin`     - the format of the left margin to use for children of root. 1 results in a pipe, and 0 results in no pipe.\n        - `visited`    - a dictionary of visited nodes in the current branch if not prune, or in the whole tree if prune.\n    \"\"\"\n\n    rname = str(root)\n\n\n    # Initialize 'visited' dict, if required\n    if visited is None:\n        visited = {}\n\n    if showtags:\n\n        if showtags == 2:\n            legend = (' E         = exists\\n' +\n                      '  R        = exists in repository only\\n' +\n                      '   b       = implicit builder\\n' +\n                      '   B       = explicit builder\\n' +\n                      '    S      = side effect\\n' +\n                      '     P     = precious\\n' +\n                      '      A    = always build\\n' +\n                      '       C   = current\\n' +\n                      '        N  = no clean\\n' +\n                      '         H = no cache\\n' +\n                      '\\n')\n            sys.stdout.write(legend)\n\n        tags = ['[']\n        tags.append(' E'[IDX(root.exists())])\n        tags.append(' R'[IDX(root.rexists() and not root.exists())])\n        tags.append(' BbB'[[0,1][IDX(root.has_explicit_builder())] +\n                           [0,2][IDX(root.has_builder())]])\n        tags.append(' S'[IDX(root.side_effect)])\n        tags.append(' P'[IDX(root.precious)])\n        tags.append(' A'[IDX(root.always_build)])\n        tags.append(' C'[IDX(root.is_up_to_date())])\n        tags.append(' N'[IDX(root.noclean)])\n        tags.append(' H'[IDX(root.nocache)])\n        tags.append(']')\n\n    else:\n        tags = []\n\n    def MMM(m):\n        return [\"  \",\"| \"][m]\n    margins = list(map(MMM, margin[:-1]))\n\n    children = child_func(root)\n\n    if prune and rname in visited and children:\n        sys.stdout.write(''.join(tags + margins + ['+-[', rname, ']']) + '\\n')\n        return\n\n    sys.stdout.write(''.join(tags + margins + ['+-', rname]) + '\\n')\n\n    visited[rname] = 1\n\n    if children:\n        margin.append(1)\n        idx = IDX(showtags)\n        for C in children[:-1]:\n            print_tree(C, child_func, prune, idx, margin, visited)\n        margin[-1] = 0\n        print_tree(children[-1], child_func, prune, idx, margin, visited)\n        margin.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening a sequence to a non - nested list.", "response": "def flatten(obj, isinstance=isinstance, StringTypes=StringTypes,\n            SequenceTypes=SequenceTypes, do_flatten=do_flatten):\n    \"\"\"Flatten a sequence to a non-nested list.\n\n    Flatten() converts either a single scalar or a nested sequence\n    to a non-nested list. Note that flatten() considers strings\n    to be scalars instead of sequences like Python would.\n    \"\"\"\n    if isinstance(obj, StringTypes) or not isinstance(obj, SequenceTypes):\n        return [obj]\n    result = []\n    for item in obj:\n        if isinstance(item, StringTypes) or not isinstance(item, SequenceTypes):\n            result.append(item)\n        else:\n            do_flatten(item, result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PrependPath(oldpath, newpath, sep = os.pathsep,\n                delete_existing=1, canonicalize=None):\n    \"\"\"This prepends newpath elements to the given oldpath.  Will only\n    add any particular path once (leaving the first one it encounters\n    and ignoring the rest, to preserve path order), and will\n    os.path.normpath and os.path.normcase all paths to help assure\n    this.  This can also handle the case where the given old path\n    variable is a list instead of a string, in which case a list will\n    be returned instead of a string.\n\n    Example:\n      Old Path: \"/foo/bar:/foo\"\n      New Path: \"/biz/boom:/foo\"\n      Result:   \"/biz/boom:/foo:/foo/bar\"\n\n    If delete_existing is 0, then adding a path that exists will\n    not move it to the beginning; it will stay where it is in the\n    list.\n\n    If canonicalize is not None, it is applied to each element of\n    newpath before use.\n    \"\"\"\n\n    orig = oldpath\n    is_list = 1\n    paths = orig\n    if not is_List(orig) and not is_Tuple(orig):\n        paths = paths.split(sep)\n        is_list = 0\n\n    if is_String(newpath):\n        newpaths = newpath.split(sep)\n    elif not is_List(newpath) and not is_Tuple(newpath):\n        newpaths = [ newpath ]  # might be a Dir\n    else:\n        newpaths = newpath\n\n    if canonicalize:\n        newpaths=list(map(canonicalize, newpaths))\n\n    if not delete_existing:\n        # First uniquify the old paths, making sure to\n        # preserve the first instance (in Unix/Linux,\n        # the first one wins), and remembering them in normpaths.\n        # Then insert the new paths at the head of the list\n        # if they're not already in the normpaths list.\n        result = []\n        normpaths = []\n        for path in paths:\n            if not path:\n                continue\n            normpath = os.path.normpath(os.path.normcase(path))\n            if normpath not in normpaths:\n                result.append(path)\n                normpaths.append(normpath)\n        newpaths.reverse()      # since we're inserting at the head\n        for path in newpaths:\n            if not path:\n                continue\n            normpath = os.path.normpath(os.path.normcase(path))\n            if normpath not in normpaths:\n                result.insert(0, path)\n                normpaths.append(normpath)\n        paths = result\n\n    else:\n        newpaths = newpaths + paths # prepend new paths\n\n        normpaths = []\n        paths = []\n        # now we add them only if they are unique\n        for path in newpaths:\n            normpath = os.path.normpath(os.path.normcase(path))\n            if path and not normpath in normpaths:\n                paths.append(path)\n                normpaths.append(normpath)\n\n    if is_list:\n        return paths\n    else:\n        return sep.join(paths)", "response": "This function prepends newpath elements to the given oldpath."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the elements in s but without duplicates.", "response": "def unique(s):\n    \"\"\"Return a list of the elements in s, but without duplicates.\n\n    For example, unique([1,2,3,1,2,3]) is some permutation of [1,2,3],\n    unique(\"abcabc\") some permutation of [\"a\", \"b\", \"c\"], and\n    unique(([1, 2], [2, 3], [1, 2])) some permutation of\n    [[2, 3], [1, 2]].\n\n    For best speed, all sequence elements should be hashable.  Then\n    unique() will usually work in linear time.\n\n    If not possible, the sequence elements should enjoy a total\n    ordering, and if list(s).sort() doesn't raise TypeError it's\n    assumed that they do enjoy a total ordering.  Then unique() will\n    usually work in O(N*log2(N)) time.\n\n    If that's not possible either, the sequence elements must support\n    equality-testing.  Then unique() will usually work in quadratic\n    time.\n    \"\"\"\n\n    n = len(s)\n    if n == 0:\n        return []\n\n    # Try using a dict first, as that's the fastest and will usually\n    # work.  If it doesn't work, it will usually fail quickly, so it\n    # usually doesn't cost much to *try* it.  It requires that all the\n    # sequence elements be hashable, and support equality comparison.\n    u = {}\n    try:\n        for x in s:\n            u[x] = 1\n    except TypeError:\n        pass    # move on to the next method\n    else:\n        return list(u.keys())\n    del u\n\n    # We can't hash all the elements.  Second fastest is to sort,\n    # which brings the equal elements together; then duplicates are\n    # easy to weed out in a single pass.\n    # NOTE:  Python's list.sort() was designed to be efficient in the\n    # presence of many duplicate elements.  This isn't true of all\n    # sort functions in all languages or libraries, so this approach\n    # is more effective in Python than it may be elsewhere.\n    try:\n        t = sorted(s)\n    except TypeError:\n        pass    # move on to the next method\n    else:\n        assert n > 0\n        last = t[0]\n        lasti = i = 1\n        while i < n:\n            if t[i] != last:\n                t[lasti] = last = t[i]\n                lasti = lasti + 1\n            i = i + 1\n        return t[:lasti]\n    del t\n\n    # Brute force is all that's left.\n    u = []\n    for x in s:\n        if x not in u:\n            u.append(x)\n    return u"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_path_relative(path):\n    if os.path.isabs(path):\n        drive_s,path = os.path.splitdrive(path)\n\n        import re\n        if not drive_s:\n            path=re.compile(\"/*(.*)\").findall(path)[0]\n        else:\n            path=path[1:]\n\n    assert( not os.path.isabs( path ) ), path\n    return path", "response": "Makes an absolute path name to a relative pathname."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddMethod(obj, function, name=None):\n    if name is None:\n        name = function.__name__\n    else:\n        function = RenameFunction(function, name)\n\n    # Note the Python version checks - WLB\n    # Python 3.3 dropped the 3rd parameter from types.MethodType\n    if hasattr(obj, '__class__') and obj.__class__ is not type:\n        # \"obj\" is an instance, so it gets a bound method.\n        if sys.version_info[:2] > (3, 2):\n            method = MethodType(function, obj)\n        else:\n            method = MethodType(function, obj, obj.__class__)\n    else:\n        # Handle classes\n        method = function\n\n    setattr(obj, name, method)", "response": "Adds a bound method to an object or class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RenameFunction(function, name):\n    return FunctionType(function.__code__,\n                        function.__globals__,\n                        name,\n                        function.__defaults__)", "response": "Returns a new function with the specified name renamed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the response of an RPC call into a dictionary with integer and buffer results", "response": "def _create_old_return_value(payload, num_ints, buff):\n    \"\"\"Parse the response of an RPC call into a dictionary with integer and buffer results\"\"\"\n\n    parsed = {'ints': payload[:num_ints], 'buffer': None, 'error': 'No Error',\n              'is_error': False, 'return_value': 0}\n\n    if buff:\n        parsed['buffer'] = bytearray(payload[-1])\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rpc(self, feature, cmd, *args, **kw):\n\n        rpc_id = (feature << 8 | cmd)\n\n        result_format = _create_resp_format(kw.get('result_type'), kw.get('result_format'))\n        arg_format = kw.get('arg_format')\n        if arg_format is None:\n            arg_format = _create_arg_format(args)\n\n        passed_kw = {}\n        if 'timeout' in kw:\n            passed_kw['timeout'] = kw['timeout']\n\n        response = self.rpc_v2(rpc_id, arg_format, result_format, *args, **passed_kw)\n\n        old_return = kw.get('result_type')\n        if old_return is not None:\n            return _create_old_return_value(response, *old_return)\n\n        return response", "response": "Send an RPC to this module."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend an RPC to this module and interpret the return value according to the result_type kw argument.", "response": "def rpc_v2(self, cmd, arg_format, result_format, *args, **kw):\n        \"\"\"Send an RPC call to this module, interpret the return value\n        according to the result_type kw argument.  Unless raise keyword\n        is passed with value False, raise an RPCException if the command\n        is not successful.\n\n        v2 enforces the use of arg_format and result_format\n        v2 combines the feature+cmd chunks in to a single 2-byte chunk\n        \"\"\"\n        if args:\n            packed_args = pack_rpc_payload(arg_format, list(args))\n        elif arg_format == \"\":\n            packed_args = b''\n        else:\n            raise RPCInvalidArgumentsError(\"Arg format expects arguments to be present\", arg_format=arg_format, args=args)\n\n        passed_kw = dict()\n        if 'timeout' in kw:\n            passed_kw['timeout'] = kw['timeout']\n\n        try:\n            should_retry = False\n            payload = self.stream.send_rpc(self.addr, cmd, packed_args, **passed_kw)\n        except BusyRPCResponse:\n            if \"retries\" not in kw:\n                kw['retries'] = 10\n\n            # Sleep 100 ms and try again unless we've exhausted our retry attempts\n            if kw[\"retries\"] == 0:\n                raise BusyRPCResponse(\"Could not complete RPC %d:%04X after 10 attempts due to busy tile\" %\n                                      (self.addr, cmd))\n\n            should_retry = True\n\n        # If the tile was busy, automatically retry up to 10 times\n        if should_retry:\n            kw['retries'] -= 1\n            sleep(0.1)\n            return self.rpc_v2(cmd, arg_format, result_format, *args, **kw)\n\n        return unpack_rpc_payload(result_format, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hardware_version(self):\n        res = self.rpc(0x00, 0x02, result_type=(0, True))\n\n        # Result is a string but with zero appended to the end to make it a fixed 10 byte size\n        binary_version = res['buffer']\n\n        ver = \"\"\n\n        for x in binary_version:\n            if x != 0:\n                ver += chr(x)\n\n        return ver", "response": "Return the embedded hardware version string for this tile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking sure the hardware version of the current version is the expected version.", "response": "def check_hardware(self, expected):\n        \"\"\"Make sure the hardware version is what we expect.\n\n        This convenience function is meant for ensuring that we are talking to\n        a tile that has the correct hardware version.\n\n        Args:\n            expected (str): The expected hardware string that is compared\n                against what is reported by the hardware_version RPC.\n\n        Returns:\n            bool: true if the hardware is the expected version, false otherwise\n        \"\"\"\n\n        if len(expected) < 10:\n            expected += '\\0'*(10 - len(expected))\n\n        err, = self.rpc(0x00, 0x03, expected, result_format=\"L\")\n        if err == 0:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(self):\n\n        hw_type, name, major, minor, patch, status = self.rpc(0x00, 0x04, result_format=\"H6sBBBB\")\n\n        status = {\n            'hw_type': hw_type,\n            'name': name.decode('utf-8'),\n            'version': (major, minor, patch),\n            'status': status\n        }\n\n        return status", "response": "Query the status of an IOTile including its name and version"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tile_status(self):\n        stat = self.status()\n\n        flags = stat['status']\n\n        # FIXME: This needs to stay in sync with lib_common: cdb_status.h\n        status = {}\n        status['debug_mode'] = bool(flags & (1 << 3))\n        status['configured'] = bool(flags & (1 << 1))\n        status['app_running'] = bool(flags & (1 << 0))\n        status['trapped'] = bool(flags & (1 << 2))\n\n        return status", "response": "Get the current status of this tile"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def client_event_handler(self, client_id, event_tuple, user_data):\n\n        conn_string, event_name, _event = event_tuple\n        self._logger.debug(\"Ignoring event %s from device %s forwarded for client %s\",\n                           event_name, conn_string, client_id)\n\n        return None", "response": "This method is called by the client when an event is received from a device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def stop(self):\n\n        clients = list(self._clients)\n\n        for client in clients:\n            self._logger.info(\"Tearing down client %s at server stop()\", client)\n            await self.teardown_client(client)", "response": "Stop the server and teardown any remaining clients."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisconnects all resources held by a client.", "response": "async def teardown_client(self, client_id):\n        \"\"\"Release all resources held by a client.\n\n        This method must be called and awaited whenever a client is\n        disconnected.  It ensures that all of the client's resources are\n        properly released and any devices they have connected to are\n        disconnected cleanly.\n\n        Args:\n            client_id (str): The client that we should tear down.\n\n        Raises:\n            ArgumentError: The client_id is unknown.\n        \"\"\"\n\n        client_info = self._client_info(client_id)\n\n        self.adapter.remove_monitor(client_info['monitor'])\n        conns = client_info['connections']\n\n        for conn_string, conn_id in conns.items():\n            try:\n                self._logger.debug(\"Disconnecting client %s from conn %s at teardown\", client_id, conn_string)\n                await self.adapter.disconnect(conn_id)\n            except:  #pylint:disable=bare-except; This is a finalization method that should not raise unexpectedly\n                self._logger.exception(\"Error disconnecting device during teardown_client: conn_string=%s\", conn_string)\n\n        del self._clients[client_id]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to a device on behalf of a client.", "response": "async def connect(self, client_id, conn_string):\n        \"\"\"Connect to a device on behalf of a client.\n\n        See :meth:`AbstractDeviceAdapter.connect`.\n\n        Args:\n            client_id (str): The client we are working for.\n            conn_string (str): A connection string that will be\n                passed to the underlying device adapter to connect.\n\n        Raises:\n            DeviceServerError: There is an issue with your client_id.\n            DeviceAdapterError: The adapter had an issue connecting.\n        \"\"\"\n        conn_id = self.adapter.unique_conn_id()\n\n        self._client_info(client_id)\n\n        await self.adapter.connect(conn_id, conn_string)\n        self._hook_connect(conn_string, conn_id, client_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisconnects from a device on behalf of a client.", "response": "async def disconnect(self, client_id, conn_string):\n        \"\"\"Disconnect from a device on behalf of a client.\n\n        See :meth:`AbstractDeviceAdapter.disconnect`.\n\n        Args:\n            client_id (str): The client we are working for.\n            conn_string (str): A connection string that will be\n                passed to the underlying device adapter to connect.\n\n        Raises:\n            DeviceServerError: There is an issue with your client_id such\n                as not being connected to the device.\n            DeviceAdapterError: The adapter had an issue disconnecting.\n        \"\"\"\n\n        conn_id = self._client_connection(client_id, conn_string)\n\n        try:\n            await self.adapter.disconnect(conn_id)\n        finally:\n            self._hook_disconnect(conn_string, client_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def open_interface(self, client_id, conn_string, interface):\n\n        conn_id = self._client_connection(client_id, conn_string)\n\n        # Hook first so there is no race on getting the first event\n        self._hook_open_interface(conn_string, interface, client_id)\n        await self.adapter.open_interface(conn_id, interface)", "response": "Open a device interface on behalf of a client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def close_interface(self, client_id, conn_string, interface):\n\n        conn_id = self._client_connection(client_id, conn_string)\n\n        await self.adapter.close_interface(conn_id, interface)\n        self._hook_close_interface(conn_string, interface, client_id)", "response": "Closes a device interface on behalf of a client."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def send_rpc(self, client_id, conn_string, address, rpc_id, payload, timeout):\n\n        conn_id = self._client_connection(client_id, conn_string)\n        return await self.adapter.send_rpc(conn_id, address, rpc_id, payload, timeout)", "response": "Send an RPC to a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_script(self, client_id, conn_string, script):\n\n        conn_id = self._client_connection(client_id, conn_string)\n        await self.adapter.send_script(conn_id, script)", "response": "Send a script to a device on behalf of a client."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def debug(self, client_id, conn_string, command, args):\n\n        conn_id = self._client_info(client_id, 'connections')[conn_string]\n        return await self.adapter.debug(conn_id, command, args)", "response": "Send a debug command to a device on behalf of a client."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes this into a tuple suitable for returning from an RPC.", "response": "def registration_packet(self):\n        \"\"\"Serialize this into a tuple suitable for returning from an RPC.\n\n        Returns:\n            tuple: The serialized values.\n        \"\"\"\n\n        return (self.hw_type, self.api_info[0], self.api_info[1], self.name, self.fw_info[0], self.fw_info[1], self.fw_info[2],\n                self.exec_info[0], self.exec_info[0], self.exec_info[0], self.slot, self.unique_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_to_reset(self, config_vars):\n\n        super(TileManagerState, self).clear_to_reset(config_vars)\n        self.registered_tiles = self.registered_tiles[:1]\n        self.safe_mode = False\n        self.debug_mode = False", "response": "Clear to the state immediately after a reset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_tile(self, tile_info):\n\n        for i, tile in enumerate(self.registered_tiles):\n            if tile.slot == tile_info.slot:\n                self.registered_tiles[i] = tile_info\n                return\n\n        self.registered_tiles.append(tile_info)", "response": "Add or replace an entry in the tile cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_tile(self, hw_type, api_major, api_minor, name, fw_major, fw_minor, fw_patch, exec_major, exec_minor, exec_patch, slot, unique_id):\n\n        api_info = (api_major, api_minor)\n        fw_info = (fw_major, fw_minor, fw_patch)\n        exec_info = (exec_major, exec_minor, exec_patch)\n\n        address = 10 + slot\n        info = TileInfo(hw_type, name, api_info, fw_info, exec_info, slot, unique_id, state=TileState.JUST_REGISTERED, address=address)\n\n        self.tile_manager.insert_tile(info)\n\n        debug = int(self.tile_manager.debug_mode)\n\n        if self.tile_manager.safe_mode:\n            run_level = RunLevel.SAFE_MODE\n            info.state = TileState.SAFE_MODE\n            config_rpcs = []\n        else:\n            run_level = RunLevel.START_ON_COMMAND\n            info.state = TileState.BEING_CONFIGURED\n            config_rpcs = self.config_database.stream_matching(address, name)\n\n        self.tile_manager.queue.put_nowait((info, config_rpcs))\n\n        return [address, run_level, debug]", "response": "This function registers a tile with this controller."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef describe_tile(self, index):\n\n        if index >= len(self.tile_manager.registered_tiles):\n            tile = TileInfo.CreateInvalid()\n        else:\n            tile = self.tile_manager.registered_tiles[index]\n\n        return tile.registration_packet()", "response": "Get the registration information for the tile at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_before(self, sensor_graph, scope_stack):\n\n        sensor_graph.add_constant(self.stream, 0)\n\n        new_scope = GatedClockScope(sensor_graph, scope_stack, (self.stream, self.trigger))\n        scope_stack.append(new_scope)", "response": "Execute statement before children are executed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ParseHeader(cls, script_data):\n\n        if len(script_data) < UpdateScript.SCRIPT_HEADER_LENGTH:\n            raise ArgumentError(\"Script is too short to contain a script header\",\n                                length=len(script_data), header_length=UpdateScript.SCRIPT_HEADER_LENGTH)\n\n        embedded_hash, magic, total_length = struct.unpack_from(\"<16sLL\", script_data)\n        if magic != UpdateScript.SCRIPT_MAGIC:\n            raise ArgumentError(\"Script has invalid magic value\", expected=UpdateScript.SCRIPT_MAGIC, found=magic)\n\n        if total_length != len(script_data):\n            raise ArgumentError(\"Script length does not match embedded length\",\n                                embedded_length=total_length, length=len(script_data))\n\n        hashed_data = script_data[16:]\n\n        sha = hashlib.sha256()\n        sha.update(hashed_data)\n        hash_value = sha.digest()[:16]\n\n        if not compare_digest(embedded_hash, hash_value):\n            raise ArgumentError(\"Script has invalid embedded hash\", embedded_hash=hexlify(embedded_hash),\n                                calculated_hash=hexlify(hash_value))\n\n        return ScriptHeader(UpdateScript.SCRIPT_HEADER_LENGTH, False, True, False)", "response": "Parses a script integrity header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a binary update script.", "response": "def FromBinary(cls, script_data, allow_unknown=True, show_rpcs=False):\n        \"\"\"Parse a binary update script.\n\n        Args:\n            script_data (bytearray): The binary data containing the script.\n            allow_unknown (bool): Allow the script to contain unknown records\n                so long as they have correct headers to allow us to skip them.\n            show_rpcs (bool): Show SendRPCRecord matches for each record rather than\n                the more specific operation\n        Raises:\n            ArgumentError: If the script contains malformed data that cannot\n                be parsed.\n            DataError: If the script contains unknown records and allow_unknown=False\n\n        Returns:\n            UpdateScript: The parsed update script.\n        \"\"\"\n\n        curr = 0\n        records = []\n\n        header = cls.ParseHeader(script_data)\n        curr = header.header_length\n\n        cls.logger.debug(\"Parsed script header: %s, skipping %d bytes\", header, curr)\n\n        record_count = 0\n        record_data = bytearray()\n        partial_match = None\n        match_offset = 0\n\n        while curr < len(script_data):\n            if len(script_data) - curr < UpdateRecord.HEADER_LENGTH:\n                raise ArgumentError(\"Script ended with a partial record\", remaining_length=len(script_data) - curr)\n\n            # Add another record to our current list of records that we're parsing\n\n            total_length, record_type = struct.unpack_from(\"<LB\", script_data[curr:])\n            cls.logger.debug(\"Found record of type %d, length %d\", record_type, total_length)\n\n            record_data += script_data[curr:curr+total_length]\n            record_count += 1\n\n            curr += total_length\n\n            try:\n                if show_rpcs and record_type == SendRPCRecord.MatchType():\n                    cls.logger.debug(\"   {0}\".format(hexlify(record_data)))\n                    record = SendRPCRecord.FromBinary(record_data[UpdateRecord.HEADER_LENGTH:], record_count)\n                elif show_rpcs and record_type == SendErrorCheckingRPCRecord.MatchType():\n                    cls.logger.debug(\"   {0}\".format(hexlify(record_data)))\n                    record = SendErrorCheckingRPCRecord.FromBinary(record_data[UpdateRecord.HEADER_LENGTH:],\n                                                                   record_count)\n                else:\n                    record = UpdateRecord.FromBinary(record_data, record_count)\n\n            except DeferMatching as defer:\n                # If we're told to defer matching, continue accumulating record_data\n                # until we get a complete match.  If a partial match is available, keep track of\n                # that partial match so that we can use it once the record no longer matches.\n                if defer.partial_match is not None:\n                    partial_match = defer.partial_match\n                    match_offset = curr\n\n                continue\n\n            except DataError:\n                if record_count > 1 and partial_match:\n                    record = partial_match\n                    curr = match_offset\n                elif not allow_unknown:\n                    raise\n                elif allow_unknown and record_count > 1:\n                    raise ArgumentError(\"A record matched an initial record subset but failed\"\n                                        \" matching a subsequent addition without leaving a partial_match\")\n                else:\n                    record = UnknownRecord(record_type, record_data[UpdateRecord.HEADER_LENGTH:])\n\n            # Reset our record accumulator since we successfully matched one or more records\n            record_count = 0\n            record_data = bytearray()\n            partial_match = None\n            match_offset = 0\n\n            records.append(record)\n\n        return UpdateScript(records)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self):\n\n        blob = bytearray()\n\n        for record in self.records:\n            blob += record.encode()\n\n        header = struct.pack(\"<LL\", self.SCRIPT_MAGIC, len(blob) + self.SCRIPT_HEADER_LENGTH)\n        blob = header + blob\n\n        sha = hashlib.sha256()\n        sha.update(blob)\n        hash_value = sha.digest()[:16]\n\n        return bytearray(hash_value) + blob", "response": "Encode this record into a binary blob."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_worker(self, func, interval, *args, **kwargs):\n\n        thread = StoppableWorkerThread(func, interval, args, kwargs)\n        self._workers.append(thread)\n\n        if self._started:\n            thread.start()", "response": "Spawns a worker thread running func."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_workers(self):\n\n        if self._started:\n            raise InternalError(\"The method start() was called twice on a BaseRunnable object.\")\n\n        self._started = True\n\n        for worker in self._workers:\n            worker.start()", "response": "Start all worker threads."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_workers(self):\n\n        self._started = False\n\n        for worker in self._workers:\n            worker.stop()", "response": "Synchronously stop any potential workers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_workers_async(self):\n\n        self._started = False\n        for worker in self._workers:\n            worker.signal_stop()", "response": "Signal that all workers should stop without waiting."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple for triggering an event every interval.", "response": "def clock(self, interval, basis):\n        \"\"\"Return a NodeInput tuple for triggering an event every interval.\n\n        We request each distinct type of clock at most once and combine it with our\n        latch stream each time it is requested.\n\n        Args:\n            interval (int): The interval (in seconds) at which this input should\n                trigger.\n        \"\"\"\n\n        cache_name = self._classify_clock(interval, basis)\n        cache_data = self.clock_cache.get(cache_name)\n\n        if cache_data is None:\n            parent_stream, trigger = self.parent.clock(interval, basis)\n\n            if trigger.use_count is False:\n                raise SensorGraphSemanticError(\"Unsupported clock trigger in GatedClockScope\", trigger=trigger)\n            elif interval % trigger.reference != 0:\n                raise SensorGraphSemanticError(\"Unsupported trigger ratio in GatedClockScope\", trigger=trigger, interval=interval)\n\n            ratio = interval // trigger.reference\n\n            stream = self.allocator.allocate_stream(DataStream.CounterType)\n            latch_stream = self.allocator.attach_stream(self.latch_stream)\n\n            self.sensor_graph.add_node(u'({} always && {} {}) => {} using copy_latest_a'.format(parent_stream, latch_stream, self.latch_trigger, stream))\n            self.clock_cache[cache_name] = (stream, ratio)\n        else:\n            stream, ratio = cache_data\n\n        if interval % ratio != 0:\n            raise SensorGraphSemanticError(\"Unsupported trigger ratio in GatedClockScope\", ratio=ratio, interval=interval)\n\n        count = interval // ratio\n\n        clock_stream = self.allocator.attach_stream(stream)\n        return clock_stream, InputTrigger(u'count', '>=', count)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _download_ota_script(script_url):\n\n    try:\n        blob = requests.get(script_url, stream=True)\n        return blob.content\n    except Exception as e:\n        iprint(\"Failed to download OTA script\")\n        iprint(e)\n        return False", "response": "Download the script from the cloud service and store it to temporary file location"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_as(module, name):\n    dir = os.path.split(__file__)[0]\n    return imp.load_module(name, *imp.find_module(module, [dir]))", "response": "Imports the specified module as the\n    specified name returning the loaded module object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrenaming the module with the given name.", "response": "def rename_module(new, old):\n    \"\"\"\n    Attempts to import the old module and load it under the new name.\n    Used for purely cosmetic name changes in Python 3.x.\n    \"\"\"\n    try:\n        sys.modules[new] = imp.load_module(old, *imp.find_module(old))\n        return True\n    except ImportError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes statement before children are executed.", "response": "def execute_before(self, sensor_graph, scope_stack):\n        \"\"\"Execute statement before children are executed.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        parent = scope_stack[-1]\n        new_scope = Scope(\"Configuration Scope\", sensor_graph, parent.allocator, parent)\n        new_scope.add_identifier('current_slot', self.slot)\n        scope_stack.append(new_scope)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a connection string from the debug - c or connect_direct command.", "response": "def _parse_conn_string(self, conn_string):\n        \"\"\"Parse a connection string passed from 'debug -c' or 'connect_direct'\n            Returns True if any settings changed in the debug port, which\n            would require a jlink disconnection \"\"\"\n        disconnection_required = False\n\n        \"\"\"If device not in conn_string, set to default info\"\"\"\n        if conn_string is None or 'device' not in conn_string:\n            if self._default_device_info is not None and self._device_info != self._default_device_info:\n                disconnection_required = True\n                self._device_info = self._default_device_info\n\n        if conn_string is None or len(conn_string) == 0:\n            return disconnection_required\n\n        if '@' in conn_string:\n            raise ArgumentError(\"Configuration files are not yet supported as part of a connection string argument\",\n                                conn_string=conn_string)\n\n        pairs = conn_string.split(';')\n        for pair in pairs:\n            name, _, value = pair.partition('=')\n            if len(name) == 0 or len(value) == 0:\n                continue\n\n            name = name.strip()\n            value = value.strip()\n\n            if name == 'device':\n                if value in DEVICE_ALIASES:\n                    device_name = DEVICE_ALIASES[value]\n                if device_name in KNOWN_DEVICES:\n                    device_info = KNOWN_DEVICES.get(device_name)\n                    if self._device_info != device_info:\n                        self._device_info = device_info\n                        disconnection_required = True\n                else:\n                    raise ArgumentError(\"Unknown device name or alias, please select from known_devices\",\n                                        device_name=value, known_devices=[x for x in DEVICE_ALIASES.keys()])\n            elif name == 'channel':\n                if self._mux_func is not None:\n                    if self._channel != int(value):\n                        self._channel = int(value)\n                        disconnection_required = True\n                else:\n                    print(\"Warning: multiplexing architecture not selected, channel will not be set\")\n        return disconnection_required"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _try_connect(self, connection_string):\n        if self._parse_conn_string(connection_string):\n            self._trigger_callback('on_disconnect', self.id, self._connection_id)\n\n            self.stop_sync()\n\n            if self._mux_func is not None:\n                self._mux_func(self._channel)\n\n            if self._device_info is None:\n                raise ArgumentError(\"Missing device name or alias, specify using device=name in port string \"\n                                    \"or -c device=name in connect_direct or debug command\",\n                                    known_devices=[x for x in DEVICE_ALIASES.keys()])\n\n            try:\n                self.jlink = pylink.JLink()\n                self.jlink.open(serial_no=self._jlink_serial)\n                self.jlink.set_tif(pylink.enums.JLinkInterfaces.SWD)\n                self.jlink.connect(self._device_info.jlink_name)\n                self.jlink.set_little_endian()\n            except pylink.errors.JLinkException as exc:\n                if exc.code == exc.VCC_FAILURE:\n                    raise HardwareError(\"No target power detected\", code=exc.code,\n                                        suggestion=\"Check jlink connection and power wiring\")\n\n                raise\n            except:\n                raise\n\n            self._control_thread = JLinkControlThread(self.jlink)\n            self._control_thread.start()\n\n            self.set_config('probe_required', True)\n            self.set_config('probe_supported', True)", "response": "Try and connect to an attached device"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends advertisements for all connected devices.", "response": "def probe_async(self, callback):\n        \"\"\"Send advertisements for all connected devices.\n\n        Args:\n            callback (callable): A callback for when the probe operation has completed.\n                callback should have signature callback(adapter_id, success, failure_reason) where:\n                    success: bool\n                    failure_reason: None if success is True, otherwise a reason for why we could not probe\n        \"\"\"\n\n        def _on_finished(_name, control_info, exception):\n            if exception is not None:\n                callback(self.id, False, str(exception))\n                return\n\n            self._control_info = control_info\n\n            try:\n                info = {\n                    'connection_string': \"direct\",\n                    'uuid': control_info.uuid,\n                    'signal_strength': 100\n                }\n\n                self._trigger_callback('on_scan', self.id, info, self.ExpirationTime)\n            finally:\n                callback(self.id, True, None)\n\n        self._control_thread.command(JLinkControlThread.FIND_CONTROL, _on_finished, self._device_info.ram_start, self._device_info.ram_size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef debug_async(self, conn_id, cmd_name, cmd_args, progress_callback, callback):\n\n        known_commands = {\n            'dump_ram': JLinkControlThread.DUMP_ALL_RAM,\n            'program_flash': JLinkControlThread.PROGRAM_FLASH,\n        }\n\n        cmd_code = known_commands.get(cmd_name)\n        if cmd_code is None:\n            callback(conn_id, self.id, False, None, \"Unsupported command: %s\" % cmd_name)\n\n        def _on_finished(_name, retval, exception):\n            if exception is not None:\n                callback(conn_id, self.id, False, None, str(exception))\n                return\n\n            callback(conn_id, self.id, True, retval, None)\n\n        self._control_thread.command(cmd_code, _on_finished, self._device_info, self._control_info, cmd_args, progress_callback)", "response": "Asynchronously complete a debug command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to a device by its connection_string asynchronously.", "response": "def connect_async(self, connection_id, connection_string, callback):\n        \"\"\"Connect to a device by its connection_string\n\n        This function asynchronously connects to a device by its BLE address\n        passed in the connection_string parameter and calls callback when\n        finished.  Callback is called on either success or failure with the\n        signature:\n\n        callback(conection_id, adapter_id, success: bool, failure_reason: string or None)\n\n        Args:\n            connection_string (string): A unique connection string that identifies\n                which device to connect to, if many are possible.\n            connection_id (int): A unique integer set by the caller for\n                referring to this connection once created\n            callback (callable): A callback function called when the\n                connection has succeeded or failed\n        \"\"\"\n        self._try_connect(connection_string)\n\n        def _on_finished(_name, control_info, exception):\n            if exception is not None:\n                callback(connection_id, self.id, False, str(exception))\n                return\n\n            if control_info is not None:\n                self._control_info = control_info\n\n            callback(connection_id, self.id, True, None)\n            self._connection_id = connection_id\n\n        self._control_thread.command(JLinkControlThread.VERIFY_CONTROL, _on_finished, self._device_info, self._control_info)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _open_debug_interface(self, conn_id, callback, connection_string=None):\n        self._try_connect(connection_string)\n        callback(conn_id, self.id, True, None)", "response": "Enable debug interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_reset(self):\n\n        self._registered.clear()\n        self._start_received.clear()\n        self._hosted_app_running.clear()\n\n        super(EmulatedPeripheralTile, self)._handle_reset()", "response": "Reset this tile.\n\n        This process needs to trigger the peripheral tile to reregister itself\n        with the controller and get new configuration variables.  It also\n        needs to clear app_running."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump the current state of this emulated tile as a dictionary.", "response": "def dump_state(self):\n        \"\"\"Dump the current state of this emulated tile as a dictionary.\n\n        This function just dumps the status of the config variables.  It is\n        designed to be called in a chained fashion to serialize the complete\n        state of a tile subclass.\n\n        Returns:\n            dict: The current state of the object that could be passed to load_state.\n        \"\"\"\n\n        state = super(EmulatedPeripheralTile, self).dump_state()\n        state['app_started'] = self._hosted_app_running.is_set()\n        state['debug_mode'] = self.debug_mode\n        state['run_level'] = self.run_level\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestore the current state of this emulated object.", "response": "def restore_state(self, state):\n        \"\"\"Restore the current state of this emulated object.\n\n        Args:\n            state (dict): A previously dumped state produced by dump_state.\n        \"\"\"\n\n        super(EmulatedPeripheralTile, self).restore_state(state)\n\n        self.debug_mode = state.get('debug_mode', False)\n        self.run_level = state.get('run_level', None)\n\n        if state.get('app_started', False):\n            self._hosted_app_running.set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the gateway manager and synchronously wait for it to stop.", "response": "async def stop(self):\n        \"\"\"Stop the gateway manager and synchronously wait for it to stop.\"\"\"\n\n        self._logger.info(\"Stopping all servers\")\n        for server in self.servers:\n            await server.stop()\n\n        self._logger.info(\"Stopping all device adapters\")\n        await self.device_manager.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_args():\n    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument('recipe', type=str, help=\"The recipe file to load and run.\")\n    parser.add_argument('-d', '--define', action=\"append\", default=[], help=\"Set a free variable in the recipe\")\n    parser.add_argument('-l', '--loop', default=None, help=\"Loop over a free variable\")\n    parser.add_argument('-i', '--info', action='store_true', help=\"Lists out all the steps of that recipe, doesn't run the recipe steps\")\n    parser.add_argument('-a', '--archive', help=\"Archive the passed yaml recipe and do not run it\")\n    parser.add_argument('-c', '--config', default=None, help=\"A YAML config file with variable definitions\")\n\n    return parser", "response": "Create command line argument parser."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_variables(defines, config_file):\n\n    if config_file is not None:\n        with open(config_file, \"r\") as conf_file:\n            variables = yaml.load(conf_file)\n    else:\n        variables = {}\n\n    for define in defines:\n        name, equ, value = define.partition('=')\n        if equ != '=':\n            print(\"Invalid variable definition\")\n            print(\"- expected name=value\")\n            print(\"- found: '%s'\" % define)\n            sys.exit(1)\n\n        variables[name] = value\n\n    return variables", "response": "Load all variables from cmdline args or a config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck how well this record matches the given binary data. This function will only be called if the record matches the type code given by calling MatchType() and this functon should check how well this record matches and return a quality score between 0 and 100, with higher quality matches having higher scores. The default value should be MatchQuality.GenericMatch which is 50. If this record does not match at all, it should return MatchQuality.NoMatch. Many times, only a single record type will match a given binary record but there are times when multiple different logical records produce the same type of record in a script, such as set_version and set_userkey both producing a call_rpc record with different RPC values. The MatchQuality method is used to allow for rich decoding of such scripts back to the best possible record that created them. Args: record_data (bytearay): The raw record that we should check for a match. record_count (int): The number of binary records that are included in record_data. Returns: int: The match quality between 0 and 100. You should use the constants defined in MatchQuality as much as possible.", "response": "def MatchQuality(cls, record_data, record_count=1):\n        \"\"\"Check how well this record matches the given binary data.\n\n        This function will only be called if the record matches the type code\n        given by calling MatchType() and this functon should check how well\n        this record matches and return a quality score between 0 and 100, with\n        higher quality matches having higher scores.  The default value should\n        be MatchQuality.GenericMatch which is 50.  If this record does not\n        match at all, it should return MatchQuality.NoMatch.\n\n        Many times, only a single record type will match a given binary record\n        but there are times when multiple different logical records produce\n        the same type of record in a script, such as set_version and\n        set_userkey both producing a call_rpc record with different RPC\n        values.  The MatchQuality method is used to allow for rich decoding\n        of such scripts back to the best possible record that created them.\n\n        Args:\n            record_data (bytearay): The raw record that we should check for\n                a match.\n            record_count (int): The number of binary records that are included\n                in record_data.\n\n        Returns:\n            int: The match quality between 0 and 100.  You should use the\n                constants defined in MatchQuality as much as possible.\n        \"\"\"\n\n        if record_count > 1:\n            return MatchQuality.NoMatch\n\n        cmd, _address, _resp_length, _payload = cls._parse_rpc_info(record_data)\n\n        if cmd == PersistGraphRecord.RPC_ID:\n            return MatchQuality.PerfectMatch\n\n        return MatchQuality.NoMatch"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef FromBinary(cls, record_data, record_count=1):\n\n        _cmd, address, _resp_length, _payload = cls._parse_rpc_info(record_data)\n        return PersistGraphRecord(address=address)", "response": "Create an UpdateRecord subclass from a binary record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nescape a list of arguments by running the specified escape_funcon every object in the list that has an escape method.", "response": "def escape_list(mylist, escape_func):\n    \"\"\"Escape a list of arguments by running the specified escape_func\n    on every object in the list that has an escape() method.\"\"\"\n    def escape(obj, escape_func=escape_func):\n        try:\n            e = obj.escape\n        except AttributeError:\n            return obj\n        else:\n            return e(escape_func)\n    return list(map(escape, mylist))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a dictionary for substitution of target and source.", "response": "def subst_dict(target, source):\n    \"\"\"Create a dictionary for substitution of special\n    construction variables.\n\n    This translates the following special arguments:\n\n    target - the target (object or array of objects),\n             used to generate the TARGET and TARGETS\n             construction variables\n\n    source - the source (object or array of objects),\n             used to generate the SOURCES and SOURCE\n             construction variables\n    \"\"\"\n    dict = {}\n\n    if target:\n        def get_tgt_subst_proxy(thing):\n            try:\n                subst_proxy = thing.get_subst_proxy()\n            except AttributeError:\n                subst_proxy = thing # probably a string, just return it\n            return subst_proxy\n        tnl = NLWrapper(target, get_tgt_subst_proxy)\n        dict['TARGETS'] = Targets_or_Sources(tnl)\n        dict['TARGET'] = Target_or_Source(tnl)\n\n        # This is a total cheat, but hopefully this dictionary goes\n        # away soon anyway.  We just let these expand to $TARGETS\n        # because that's \"good enough\" for the use of ToolSurrogates\n        # (see test/ToolSurrogate.py) to generate documentation.\n        dict['CHANGED_TARGETS'] = '$TARGETS'\n        dict['UNCHANGED_TARGETS'] = '$TARGETS'\n    else:\n        dict['TARGETS'] = NullNodesList\n        dict['TARGET'] = NullNodesList\n\n    if source:\n        def get_src_subst_proxy(node):\n            try:\n                rfile = node.rfile\n            except AttributeError:\n                pass\n            else:\n                node = rfile()\n            try:\n                return node.get_subst_proxy()\n            except AttributeError:\n                return node     # probably a String, just return it\n        snl = NLWrapper(source, get_src_subst_proxy)\n        dict['SOURCES'] = Targets_or_Sources(snl)\n        dict['SOURCE'] = Target_or_Source(snl)\n\n        # This is a total cheat, but hopefully this dictionary goes\n        # away soon anyway.  We just let these expand to $TARGETS\n        # because that's \"good enough\" for the use of ToolSurrogates\n        # (see test/ToolSurrogate.py) to generate documentation.\n        dict['CHANGED_SOURCES'] = '$SOURCES'\n        dict['UNCHANGED_SOURCES'] = '$SOURCES'\n    else:\n        dict['SOURCES'] = NullNodesList\n        dict['SOURCE'] = NullNodesList\n\n    return dict"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scons_subst(strSubst, env, mode=SUBST_RAW, target=None, source=None, gvars={}, lvars={}, conv=None):\n    if isinstance(strSubst, str) and strSubst.find('$') < 0:\n        return strSubst\n\n    class StringSubber(object):\n        \"\"\"A class to construct the results of a scons_subst() call.\n\n        This binds a specific construction environment, mode, target and\n        source with two methods (substitute() and expand()) that handle\n        the expansion.\n        \"\"\"\n        def __init__(self, env, mode, conv, gvars):\n            self.env = env\n            self.mode = mode\n            self.conv = conv\n            self.gvars = gvars\n\n        def expand(self, s, lvars):\n            \"\"\"Expand a single \"token\" as necessary, returning an\n            appropriate string containing the expansion.\n\n            This handles expanding different types of things (strings,\n            lists, callables) appropriately.  It calls the wrapper\n            substitute() method to re-expand things as necessary, so that\n            the results of expansions of side-by-side strings still get\n            re-evaluated separately, not smushed together.\n            \"\"\"\n            if is_String(s):\n                try:\n                    s0, s1 = s[:2]\n                except (IndexError, ValueError):\n                    return s\n                if s0 != '$':\n                    return s\n                if s1 == '$':\n                    # In this case keep the double $'s which we'll later\n                    # swap for a single dollar sign as we need to retain\n                    # this information to properly avoid matching \"$(\"\" when\n                    # the actual text was \"$$(\"\"  (or \"$)\"\" when \"$$)\"\" )\n                    return '$$'\n                elif s1 in '()':\n                    return s\n                else:\n                    key = s[1:]\n                    if key[0] == '{' or '.' in key:\n                        if key[0] == '{':\n                            key = key[1:-1]\n                        try:\n                            s = eval(key, self.gvars, lvars)\n                        except KeyboardInterrupt:\n                            raise\n                        except Exception as e:\n                            if e.__class__ in AllowableExceptions:\n                                return ''\n                            raise_exception(e, lvars['TARGETS'], s)\n                    else:\n                        if key in lvars:\n                            s = lvars[key]\n                        elif key in self.gvars:\n                            s = self.gvars[key]\n                        elif not NameError in AllowableExceptions:\n                            raise_exception(NameError(key), lvars['TARGETS'], s)\n                        else:\n                            return ''\n\n                    # Before re-expanding the result, handle\n                    # recursive expansion by copying the local\n                    # variable dictionary and overwriting a null\n                    # string for the value of the variable name\n                    # we just expanded.\n                    #\n                    # This could potentially be optimized by only\n                    # copying lvars when s contains more expansions,\n                    # but lvars is usually supposed to be pretty\n                    # small, and deeply nested variable expansions\n                    # are probably more the exception than the norm,\n                    # so it should be tolerable for now.\n                    lv = lvars.copy()\n                    var = key.split('.')[0]\n                    lv[var] = ''\n                    return self.substitute(s, lv)\n            elif is_Sequence(s):\n                def func(l, conv=self.conv, substitute=self.substitute, lvars=lvars):\n                    return conv(substitute(l, lvars))\n                return list(map(func, s))\n            elif callable(s):\n                try:\n                    s = s(target=lvars['TARGETS'],\n                         source=lvars['SOURCES'],\n                         env=self.env,\n                         for_signature=(self.mode != SUBST_CMD))\n                except TypeError:\n                    # This probably indicates that it's a callable\n                    # object that doesn't match our calling arguments\n                    # (like an Action).\n                    if self.mode == SUBST_RAW:\n                        return s\n                    s = self.conv(s)\n                return self.substitute(s, lvars)\n            elif s is None:\n                return ''\n            else:\n                return s\n\n        def substitute(self, args, lvars):\n            \"\"\"Substitute expansions in an argument or list of arguments.\n\n            This serves as a wrapper for splitting up a string into\n            separate tokens.\n            \"\"\"\n            if is_String(args) and not isinstance(args, CmdStringHolder):\n                args = str(args)        # In case it's a UserString.\n                try:\n                    def sub_match(match):\n                        return self.conv(self.expand(match.group(1), lvars))\n                    result = _dollar_exps.sub(sub_match, args)\n                except TypeError:\n                    # If the internal conversion routine doesn't return\n                    # strings (it could be overridden to return Nodes, for\n                    # example), then the 1.5.2 re module will throw this\n                    # exception.  Back off to a slower, general-purpose\n                    # algorithm that works for all data types.\n                    args = _separate_args.findall(args)\n                    result = []\n                    for a in args:\n                        result.append(self.conv(self.expand(a, lvars)))\n                    if len(result) == 1:\n                        result = result[0]\n                    else:\n                        result = ''.join(map(str, result))\n                return result\n            else:\n                return self.expand(args, lvars)\n\n    if conv is None:\n        conv = _strconv[mode]\n\n    # Doing this every time is a bit of a waste, since the Executor\n    # has typically already populated the OverrideEnvironment with\n    # $TARGET/$SOURCE variables.  We're keeping this (for now), though,\n    # because it supports existing behavior that allows us to call\n    # an Action directly with an arbitrary target+source pair, which\n    # we use in Tool/tex.py to handle calling $BIBTEX when necessary.\n    # If we dropped that behavior (or found another way to cover it),\n    # we could get rid of this call completely and just rely on the\n    # Executor setting the variables.\n    if 'TARGET' not in lvars:\n        d = subst_dict(target, source)\n        if d:\n            lvars = lvars.copy()\n            lvars.update(d)\n\n    # We're (most likely) going to eval() things.  If Python doesn't\n    # find a __builtins__ value in the global dictionary used for eval(),\n    # it copies the current global values for you.  Avoid this by\n    # setting it explicitly and then deleting, so we don't pollute the\n    # construction environment Dictionary(ies) that are typically used\n    # for expansion.\n    gvars['__builtins__'] = __builtins__\n\n    ss = StringSubber(env, mode, conv, gvars)\n    result = ss.substitute(strSubst, lvars)\n\n    try:\n        del gvars['__builtins__']\n    except KeyError:\n        pass\n\n    res = result\n    if is_String(result):\n        # Remove $(-$) pairs and any stuff in between,\n        # if that's appropriate.\n        remove = _regex_remove[mode]\n        if remove:\n            if mode == SUBST_SIG:\n                result = _list_remove[mode](remove.split(result))\n                if result is None:\n                    raise SCons.Errors.UserError(\"Unbalanced $(/$) in: \" + res)\n                result = ' '.join(result)\n            else:\n                result = remove.sub('', result)\n        if mode != SUBST_RAW:\n            # Compress strings of white space characters into\n            # a single space.\n            result = _space_sep.sub(' ', result).strip()\n\n        # Now replace escaped $'s currently \"$$\"\n        # This is needed because we now retain $$ instead of\n        # replacing them during substition to avoid\n        # improperly trying to escape \"$$(\" as being \"$(\"\n        result = result.replace('$$','$')\n    elif is_Sequence(result):\n        remove = _list_remove[mode]\n        if remove:\n            result = remove(result)\n            if result is None:\n                raise SCons.Errors.UserError(\"Unbalanced $(/$) in: \" + str(res))\n\n    return result", "response": "This function is used to expand a string or list of strings into a single string or list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubstitute construction variables in a string (or list or other object) and separate the arguments into a command list. The companion scons_subst() function (above) handles basic substitutions within strings, so see that function instead if that's what you're looking for.", "response": "def scons_subst_list(strSubst, env, mode=SUBST_RAW, target=None, source=None, gvars={}, lvars={}, conv=None):\n    \"\"\"Substitute construction variables in a string (or list or other\n    object) and separate the arguments into a command list.\n\n    The companion scons_subst() function (above) handles basic\n    substitutions within strings, so see that function instead\n    if that's what you're looking for.\n    \"\"\"\n    class ListSubber(collections.UserList):\n        \"\"\"A class to construct the results of a scons_subst_list() call.\n\n        Like StringSubber, this class binds a specific construction\n        environment, mode, target and source with two methods\n        (substitute() and expand()) that handle the expansion.\n\n        In addition, however, this class is used to track the state of\n        the result(s) we're gathering so we can do the appropriate thing\n        whenever we have to append another word to the result--start a new\n        line, start a new word, append to the current word, etc.  We do\n        this by setting the \"append\" attribute to the right method so\n        that our wrapper methods only need ever call ListSubber.append(),\n        and the rest of the object takes care of doing the right thing\n        internally.\n        \"\"\"\n        def __init__(self, env, mode, conv, gvars):\n            collections.UserList.__init__(self, [])\n            self.env = env\n            self.mode = mode\n            self.conv = conv\n            self.gvars = gvars\n\n            if self.mode == SUBST_RAW:\n                self.add_strip = lambda x: self.append(x)\n            else:\n                self.add_strip = lambda x: None\n            self.in_strip = None\n            self.next_line()\n\n        def expand(self, s, lvars, within_list):\n            \"\"\"Expand a single \"token\" as necessary, appending the\n            expansion to the current result.\n\n            This handles expanding different types of things (strings,\n            lists, callables) appropriately.  It calls the wrapper\n            substitute() method to re-expand things as necessary, so that\n            the results of expansions of side-by-side strings still get\n            re-evaluated separately, not smushed together.\n            \"\"\"\n\n            if is_String(s):\n                try:\n                    s0, s1 = s[:2]\n                except (IndexError, ValueError):\n                    self.append(s)\n                    return\n                if s0 != '$':\n                    self.append(s)\n                    return\n                if s1 == '$':\n                    self.append('$')\n                elif s1 == '(':\n                    self.open_strip('$(')\n                elif s1 == ')':\n                    self.close_strip('$)')\n                else:\n                    key = s[1:]\n                    if key[0] == '{' or key.find('.') >= 0:\n                        if key[0] == '{':\n                            key = key[1:-1]\n                        try:\n                            s = eval(key, self.gvars, lvars)\n                        except KeyboardInterrupt:\n                            raise\n                        except Exception as e:\n                            if e.__class__ in AllowableExceptions:\n                                return\n                            raise_exception(e, lvars['TARGETS'], s)\n                    else:\n                        if key in lvars:\n                            s = lvars[key]\n                        elif key in self.gvars:\n                            s = self.gvars[key]\n                        elif not NameError in AllowableExceptions:\n                            raise_exception(NameError(), lvars['TARGETS'], s)\n                        else:\n                            return\n\n                    # Before re-expanding the result, handle\n                    # recursive expansion by copying the local\n                    # variable dictionary and overwriting a null\n                    # string for the value of the variable name\n                    # we just expanded.\n                    lv = lvars.copy()\n                    var = key.split('.')[0]\n                    lv[var] = ''\n                    self.substitute(s, lv, 0)\n                    self.this_word()\n            elif is_Sequence(s):\n                for a in s:\n                    self.substitute(a, lvars, 1)\n                    self.next_word()\n            elif callable(s):\n                try:\n                    s = s(target=lvars['TARGETS'],\n                         source=lvars['SOURCES'],\n                         env=self.env,\n                         for_signature=(self.mode != SUBST_CMD))\n                except TypeError:\n                    # This probably indicates that it's a callable\n                    # object that doesn't match our calling arguments\n                    # (like an Action).\n                    if self.mode == SUBST_RAW:\n                        self.append(s)\n                        return\n                    s = self.conv(s)\n                self.substitute(s, lvars, within_list)\n            elif s is None:\n                self.this_word()\n            else:\n                self.append(s)\n\n        def substitute(self, args, lvars, within_list):\n            \"\"\"Substitute expansions in an argument or list of arguments.\n\n            This serves as a wrapper for splitting up a string into\n            separate tokens.\n            \"\"\"\n\n            if is_String(args) and not isinstance(args, CmdStringHolder):\n                args = str(args)        # In case it's a UserString.\n                args = _separate_args.findall(args)\n                for a in args:\n                    if a[0] in ' \\t\\n\\r\\f\\v':\n                        if '\\n' in a:\n                            self.next_line()\n                        elif within_list:\n                            self.append(a)\n                        else:\n                            self.next_word()\n                    else:\n                        self.expand(a, lvars, within_list)\n            else:\n                self.expand(args, lvars, within_list)\n\n        def next_line(self):\n            \"\"\"Arrange for the next word to start a new line.  This\n            is like starting a new word, except that we have to append\n            another line to the result.\"\"\"\n            collections.UserList.append(self, [])\n            self.next_word()\n\n        def this_word(self):\n            \"\"\"Arrange for the next word to append to the end of the\n            current last word in the result.\"\"\"\n            self.append = self.add_to_current_word\n\n        def next_word(self):\n            \"\"\"Arrange for the next word to start a new word.\"\"\"\n            self.append = self.add_new_word\n\n        def add_to_current_word(self, x):\n            \"\"\"Append the string x to the end of the current last word\n            in the result.  If that is not possible, then just add\n            it as a new word.  Make sure the entire concatenated string\n            inherits the object attributes of x (in particular, the\n            escape function) by wrapping it as CmdStringHolder.\"\"\"\n\n            if not self.in_strip or self.mode != SUBST_SIG:\n                try:\n                    current_word = self[-1][-1]\n                except IndexError:\n                    self.add_new_word(x)\n                else:\n                    # All right, this is a hack and it should probably\n                    # be refactored out of existence in the future.\n                    # The issue is that we want to smoosh words together\n                    # and make one file name that gets escaped if\n                    # we're expanding something like foo$EXTENSION,\n                    # but we don't want to smoosh them together if\n                    # it's something like >$TARGET, because then we'll\n                    # treat the '>' like it's part of the file name.\n                    # So for now, just hard-code looking for the special\n                    # command-line redirection characters...\n                    try:\n                        last_char = str(current_word)[-1]\n                    except IndexError:\n                        last_char = '\\0'\n                    if last_char in '<>|':\n                        self.add_new_word(x)\n                    else:\n                        y = current_word + x\n\n                        # We used to treat a word appended to a literal\n                        # as a literal itself, but this caused problems\n                        # with interpreting quotes around space-separated\n                        # targets on command lines.  Removing this makes\n                        # none of the \"substantive\" end-to-end tests fail,\n                        # so we'll take this out but leave it commented\n                        # for now in case there's a problem not covered\n                        # by the test cases and we need to resurrect this.\n                        #literal1 = self.literal(self[-1][-1])\n                        #literal2 = self.literal(x)\n                        y = self.conv(y)\n                        if is_String(y):\n                            #y = CmdStringHolder(y, literal1 or literal2)\n                            y = CmdStringHolder(y, None)\n                        self[-1][-1] = y\n\n        def add_new_word(self, x):\n            if not self.in_strip or self.mode != SUBST_SIG:\n                literal = self.literal(x)\n                x = self.conv(x)\n                if is_String(x):\n                    x = CmdStringHolder(x, literal)\n                self[-1].append(x)\n            self.append = self.add_to_current_word\n\n        def literal(self, x):\n            try:\n                l = x.is_literal\n            except AttributeError:\n                return None\n            else:\n                return l()\n\n        def open_strip(self, x):\n            \"\"\"Handle the \"open strip\" $( token.\"\"\"\n            self.add_strip(x)\n            self.in_strip = 1\n\n        def close_strip(self, x):\n            \"\"\"Handle the \"close strip\" $) token.\"\"\"\n            self.add_strip(x)\n            self.in_strip = None\n\n    if conv is None:\n        conv = _strconv[mode]\n\n    # Doing this every time is a bit of a waste, since the Executor\n    # has typically already populated the OverrideEnvironment with\n    # $TARGET/$SOURCE variables.  We're keeping this (for now), though,\n    # because it supports existing behavior that allows us to call\n    # an Action directly with an arbitrary target+source pair, which\n    # we use in Tool/tex.py to handle calling $BIBTEX when necessary.\n    # If we dropped that behavior (or found another way to cover it),\n    # we could get rid of this call completely and just rely on the\n    # Executor setting the variables.\n    if 'TARGET' not in lvars:\n        d = subst_dict(target, source)\n        if d:\n            lvars = lvars.copy()\n            lvars.update(d)\n\n    # We're (most likely) going to eval() things.  If Python doesn't\n    # find a __builtins__ value in the global dictionary used for eval(),\n    # it copies the current global values for you.  Avoid this by\n    # setting it explicitly and then deleting, so we don't pollute the\n    # construction environment Dictionary(ies) that are typically used\n    # for expansion.\n    gvars['__builtins__'] = __builtins__\n\n    ls = ListSubber(env, mode, conv, gvars)\n    ls.substitute(strSubst, lvars, 0)\n\n    try:\n        del gvars['__builtins__']\n    except KeyError:\n        pass\n\n    return ls.data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scons_subst_once(strSubst, env, key):\n    if isinstance(strSubst, str) and strSubst.find('$') < 0:\n        return strSubst\n\n    matchlist = ['$' + key, '${' + key + '}']\n    val = env.get(key, '')\n    def sub_match(match, val=val, matchlist=matchlist):\n        a = match.group(1)\n        if a in matchlist:\n            a = val\n        if is_Sequence(a):\n            return ' '.join(map(str, a))\n        else:\n            return str(a)\n\n    if is_Sequence(strSubst):\n        result = []\n        for arg in strSubst:\n            if is_String(arg):\n                if arg in matchlist:\n                    arg = val\n                    if is_Sequence(arg):\n                        result.extend(arg)\n                    else:\n                        result.append(arg)\n                else:\n                    result.append(_dollar_exps.sub(sub_match, arg))\n            else:\n                result.append(arg)\n        return result\n    elif is_String(strSubst):\n        return _dollar_exps.sub(sub_match, strSubst)\n    else:\n        return strSubst", "response": "Perform a single ( non - recursive substitution of a single\n    construction variable keyword."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nescapes the string with the supplied function.", "response": "def escape(self, escape_func, quote_func=quote_spaces):\n        \"\"\"Escape the string with the supplied function.  The\n        function is expected to take an arbitrary string, then\n        return it with all special characters escaped and ready\n        for passing to the command interpreter.\n\n        After calling this function, the next call to str() will\n        return the escaped string.\n        \"\"\"\n\n        if self.is_literal():\n            return escape_func(self.data)\n        elif ' ' in self.data or '\\t' in self.data:\n            return quote_func(self.data)\n        else:\n            return self.data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\njoins a list of strings one per line with level spaces before each one", "response": "def indent_list(inlist, level):\n    \"\"\"Join a list of strings, one per line with 'level' spaces before each one\"\"\"\n\n    indent = ' '*level\n    joinstr = '\\n' + indent\n\n    retval = joinstr.join(inlist)\n    return indent + retval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing string specifications of enabling and disabling warnings.", "response": "def process_warn_strings(arguments):\n    \"\"\"Process string specifications of enabling/disabling warnings,\n    as passed to the --warn option or the SetOption('warn') function.\n    \n\n    An argument to this option should be of the form <warning-class>\n    or no-<warning-class>.  The warning class is munged in order\n    to get an actual class name from the classes above, which we\n    need to pass to the {enable,disable}WarningClass() functions.\n    The supplied <warning-class> is split on hyphens, each element\n    is capitalized, then smushed back together.  Then the string\n    \"Warning\" is appended to get the class name.\n\n    For example, 'deprecated' will enable the DeprecatedWarning\n    class.  'no-dependency' will disable the DependencyWarning class.\n\n    As a special case, --warn=all and --warn=no-all will enable or\n    disable (respectively) the base Warning class of all warnings.\n\n    \"\"\"\n\n    def _capitalize(s):\n        if s[:5] == \"scons\":\n            return \"SCons\" + s[5:]\n        else:\n            return s.capitalize()\n\n    for arg in arguments:\n\n        elems = arg.lower().split('-')\n        enable = 1\n        if elems[0] == 'no':\n            enable = 0\n            del elems[0]\n\n        if len(elems) == 1 and elems[0] == 'all':\n            class_name = \"Warning\"\n        else:\n            class_name = ''.join(map(_capitalize, elems)) + \"Warning\"\n        try:\n            clazz = globals()[class_name]\n        except KeyError:\n            sys.stderr.write(\"No warning type: '%s'\\n\" % arg)\n        else:\n            if enable:\n                enableWarningClass(clazz)\n            elif issubclass(clazz, MandatoryDeprecatedWarning):\n                fmt = \"Can not disable mandataory warning: '%s'\\n\"\n                sys.stderr.write(fmt % arg)\n            else:\n                suppressWarningClass(clazz)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(env):\n    fortran.generate(env)\n\n    for dialect in ['F77', 'F90', 'FORTRAN', 'F95', 'F03', 'F08']:\n        env['%s' % dialect] = 'gfortran'\n        env['SH%s' % dialect] = '$%s' % dialect\n        if env['PLATFORM'] in ['cygwin', 'win32']:\n            env['SH%sFLAGS' % dialect] = SCons.Util.CLVar('$%sFLAGS' % dialect)\n        else:\n            env['SH%sFLAGS' % dialect] = SCons.Util.CLVar('$%sFLAGS -fPIC' % dialect)\n\n        env['INC%sPREFIX' % dialect] = \"-I\"\n        env['INC%sSUFFIX' % dialect] = \"\"", "response": "Add Builders and construction variables for gfortran to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_device_uuid(cls, slug):\n\n        if len(slug) != 22:\n            raise ArgumentError(\"Invalid device slug\", slug=slug)\n\n        hexdigits = slug[3:]\n        hexdigits = hexdigits.replace('-', '')\n\n        try:\n            rawbytes = binascii.unhexlify(hexdigits)\n            words = struct.unpack(\">LL\", rawbytes)\n            return (words[0] << 32) | (words[1])\n        except ValueError as exc:\n            raise ArgumentError(\"Could not convert device slug to hex integer\", slug=slug, error=str(exc))", "response": "Turn a string slug into a UUID"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n\n        self._prepare()\n\n        self._disconnector = tornado.ioloop.PeriodicCallback(self._disconnect_hanging_devices, 1000, self._loop)\n        self._disconnector.start()", "response": "Start this gateway agent."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop this gateway agent.", "response": "def stop(self):\n        \"\"\"Stop this gateway agent.\"\"\"\n\n        if self._disconnector:\n            self._disconnector.stop()\n\n        self.client.disconnect()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that a message received for a device has the right key.", "response": "def _validate_connection(self, action, uuid, key):\n        \"\"\"Validate that a message received for a device has the right key\n\n        If this action is valid the corresponding internal connection id to\n        be used with the DeviceManager is returned, otherwise None is returned\n        and an invalid message status is published.\n\n        Args:\n            slug (string): The slug for the device we're trying to connect to\n            uuid (int): The uuid corresponding to the slug\n            key (string): The key passed in when this device was first connected\n                to\n\n        Returns:\n            int: if the action is allowed, otherwise None\n        \"\"\"\n\n        if uuid not in self._connections:\n            self._logger.warn(\"Received message for device with no connection 0x%X\", uuid)\n            return None\n\n        data = self._connections[uuid]\n        if key != data['key']:\n            self._logger.warn(\"Received message for device with incorrect key, uuid=0x%X\", uuid)\n            return None\n\n        return data['connection_id']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npublish a status message for a device in the cluster", "response": "def _publish_status(self, slug, data):\n        \"\"\"Publish a status message for a device\n\n        Args:\n            slug (string): The device slug that we are publishing on behalf of\n            data (dict): The status message data to be sent back to the caller\n        \"\"\"\n\n        status_topic = self.topics.prefix + 'devices/{}/data/status'.format(slug)\n\n        self._logger.debug(\"Publishing status message: (topic=%s) (message=%s)\", status_topic, str(data))\n        self.client.publish(status_topic, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a response message for a device in the cluster.", "response": "def _publish_response(self, slug, message):\n        \"\"\"Publish a response message for a device\n\n        Args:\n            slug (string): The device slug that we are publishing on behalf of\n            message (dict): A set of key value pairs that are used to create the message\n                that is sent.\n        \"\"\"\n\n        resp_topic = self.topics.gateway_topic(slug, 'data/response')\n        self._logger.debug(\"Publishing response message: (topic=%s) (message=%s)\", resp_topic, message)\n        self.client.publish(resp_topic, message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_action(self, sequence, topic, message):\n\n        try:\n            slug = None\n            parts = topic.split('/')\n            slug = parts[-3]\n            uuid = self._extract_device_uuid(slug)\n        except Exception as exc:\n            self._logger.warn(\"Error parsing slug in action handler (slug=%s, topic=%s)\", slug, topic)\n            return\n\n        if messages.DisconnectCommand.matches(message):\n            self._logger.debug(\"Received disconnect command for device 0x%X\", uuid)\n            key = message['key']\n            client = message['client']\n            self._loop.add_callback(self._disconnect_from_device, uuid, key, client)\n        elif messages.OpenInterfaceCommand.matches(message) or messages.CloseInterfaceCommand.matches(message):\n            self._logger.debug(\"Received %s command for device 0x%X\", message['operation'], uuid)\n            key = message['key']\n            client = message['client']\n            oper = message['operation']\n\n            if oper == 'open_interface':\n                self._loop.add_callback(self._open_interface, client, uuid, message['interface'], key)\n            else:\n                self._loop.add_callback(self._close_interface, client, uuid, message['interface'], key)\n        elif messages.RPCCommand.matches(message):\n            rpc_msg = messages.RPCCommand.verify(message)\n\n            client = rpc_msg['client']\n            address = rpc_msg['address']\n            rpc = rpc_msg['rpc_id']\n            payload = rpc_msg['payload']\n            key = rpc_msg['key']\n            timeout = rpc_msg['timeout']\n\n            self._loop.add_callback(self._send_rpc, client, uuid, address, rpc, payload, timeout, key)\n        elif messages.ScriptCommand.matches(message):\n            script_msg = messages.ScriptCommand.verify(message)\n\n            key = script_msg['key']\n            client = script_msg['client']\n            script = script_msg['script']\n\n            self._loop.add_callback(self._send_script, client, uuid, script, key, (script_msg['fragment_index'], script_msg['fragment_count']))\n        else:\n            self._logger.error(\"Unsupported message received (topic=%s) (message=%s)\", topic, str(message))", "response": "Process a command action that we received from a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing a connection request from an IOTile device", "response": "def _on_connect(self, sequence, topic, message):\n        \"\"\"Process a request to connect to an IOTile device\n\n        A connection message triggers an attempt to connect to a device,\n        any error checking is done by the DeviceManager that is actually\n        managing the devices.\n\n        A disconnection message is checked to make sure its key matches\n        what we except for this device and is either discarded or\n        forwarded on to the DeviceManager.\n        Args:\n            sequence (int): The sequence number of the packet received\n            topic (string): The topic this message was received on\n            message_type (string): The type of the packet received\n            message (dict): The message itself\n        \"\"\"\n\n        try:\n            slug = None\n            parts = topic.split('/')\n            slug = parts[-3]\n            uuid = self._extract_device_uuid(slug)\n        except Exception:\n            self._logger.exception(\"Error parsing slug from connection request (slug=%s, topic=%s)\", slug, topic)\n            return\n\n        if messages.ConnectCommand.matches(message):\n            key = message['key']\n            client = message['client']\n\n            self._loop.add_callback(self._connect_to_device, uuid, key, client)\n        else:\n            self._logger.warn(\"Unknown message received on connect topic=%s, message=%s\", topic, message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_rpc(self, client, uuid, address, rpc, payload, timeout, key):\n\n        conn_id = self._validate_connection('send_rpc', uuid, key)\n        if conn_id is None:\n            return\n\n        conn_data = self._connections[uuid]\n        conn_data['last_touch'] = monotonic()\n\n        slug = self._build_device_slug(uuid)\n\n        try:\n            resp = yield self._manager.send_rpc(conn_id, address, rpc >> 8, rpc & 0xFF, bytes(payload), timeout)\n        except Exception as exc:\n            self._logger.error(\"Error in manager send rpc: %s\" % str(exc))\n            resp = {'success': False, 'reason': \"Internal error: %s\" % str(exc)}\n\n        payload = {'client': client, 'type': 'response', 'operation': 'rpc'}\n        payload['success'] = resp['success']\n\n        if resp['success'] is False:\n            payload['failure_reason'] = resp['reason']\n        else:\n            payload['status'] = resp['status']\n            payload['payload'] = binascii.hexlify(resp['payload'])\n\n        self._publish_response(slug, payload)", "response": "Send an RPC to a connected device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _send_script(self, client, uuid, chunk, key, chunk_status):\n\n        conn_id = self._validate_connection('send_script', uuid, key)\n        if conn_id is None:\n            return\n\n        conn_data = self._connections[uuid]\n        conn_data['last_touch'] = monotonic()\n\n        slug = self._build_device_slug(uuid)\n\n        # Check and see if we have the entire script or if we need to accumulate it\n        index, count = chunk_status\n        if index == 0:\n            conn_data['script'] = bytes()\n\n        conn_data['script'] += chunk\n\n        # If there is more than one chunk and we aren't on the last one, wait until we receive them\n        # all before sending them on to the device as a unit\n        if index != count - 1:\n            return\n\n        # Initialize our progress throttling system in case we need to throttle progress reports\n        conn_data['last_progress'] = None\n\n        try:\n            resp = yield self._manager.send_script(conn_id, conn_data['script'], lambda x, y: self._notify_progress_async(uuid, client, x, y))\n            yield None # Make sure we give time for any progress notifications that may have been queued to flush out\n            conn_data['script'] = bytes()\n        except Exception as exc:\n            self._logger.exception(\"Error in manager send_script\")\n            resp = {'success': False, 'reason': \"Internal error: %s\" % str(exc)}\n\n        payload = {'client': client, 'type': 'response', 'operation': 'send_script', 'success': resp['success']}\n        if resp['success'] is False:\n            payload['failure_reason'] = resp['reason']\n\n        self._publish_response(slug, payload)", "response": "Send a script to the connected device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnotify the progress of a script download.", "response": "def _notify_progress_sync(self, uuid, client, done_count, total_count):\n        \"\"\"Notify progress reporting on the status of a script download.\n\n        This function must be called synchronously inside of the event loop.\n\n        Args:\n            uuid (int): The id of the device that we are talking to\n            client (string): The client identifier\n            done_count (int): The number of items that have been finished\n            total_count (int): The total number of items\n        \"\"\"\n\n        # If the connection was closed, don't notify anything\n        conn_data = self._connections.get(uuid, None)\n        if conn_data is None:\n            return\n\n        last_progress = conn_data['last_progress']\n\n        should_drop = False\n\n        # We drop status updates that come faster than our configured update interval\n        # unless those updates are the final update, which we send on.  The first\n        # update is always also sent since there would not have been an update before\n        # that.\n\n        now = monotonic()\n        if last_progress is not None and (now - last_progress) < self.throttle_progress:\n            should_drop = True\n\n        if should_drop and (done_count != total_count):\n            return\n\n        conn_data['last_progress'] = now\n\n        slug = self._build_device_slug(uuid)\n        status_msg = {'type': 'notification', 'operation': 'send_script', 'client': client, 'done_count': done_count, 'total_count': total_count}\n        self._publish_response(slug, status_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnotifying the progress reporting on the status of a script download.", "response": "def _notify_progress_async(self, uuid, client, done_count, total_count):\n        \"\"\"Notify progress reporting on the status of a script download.\n\n        This function is called asynchronously to the event loop so it cannot\n        do any processing on its own.  It's job is to schedule the sync version\n        of itself in the event loop.\n\n        Args:\n            uuid (int): The id of the device that we are talking to\n            client (string): The client identifier\n            done_count (int): The number of items that have been finished\n            total_count (int): The total number of items\n        \"\"\"\n\n        self._loop.add_callback(self._notify_progress_sync, uuid, client, done_count, total_count)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens an interface on a connected device.", "response": "def _open_interface(self, client, uuid, iface, key):\n        \"\"\"Open an interface on a connected device.\n\n        Args:\n            client (string): The client id who is requesting this operation\n            uuid (int): The id of the device we're opening the interface on\n            iface (string): The name of the interface that we're opening\n            key (string): The key to authenticate the caller\n        \"\"\"\n\n        conn_id = self._validate_connection('open_interface', uuid, key)\n        if conn_id is None:\n            return\n\n        conn_data = self._connections[uuid]\n        conn_data['last_touch'] = monotonic()\n\n        slug = self._build_device_slug(uuid)\n\n        try:\n            resp = yield self._manager.open_interface(conn_id, iface)\n        except Exception as exc:\n            self._logger.exception(\"Error in manager open interface\")\n            resp = {'success': False, 'reason': \"Internal error: %s\" % str(exc)}\n\n        message = {'type': 'response', 'operation': 'open_interface', 'client': client}\n        message['success'] = resp['success']\n\n        if not message['success']:\n            message['failure_reason'] = resp['reason']\n\n        self._publish_response(slug, message)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _disconnect_hanging_devices(self):\n\n        now = monotonic()\n        for uuid, data in self._connections.items():\n            if (now - data['last_touch']) > self.client_timeout:\n                self._logger.info(\"Disconnect inactive client %s from device 0x%X\", data['client'], uuid)\n                self._loop.add_callback(self._disconnect_from_device, uuid, data['key'], data['client'], unsolicited=True)", "response": "Periodic callback that checks for devices that haven t been used and disconnects them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _disconnect_from_device(self, uuid, key, client, unsolicited=False):\n\n        conn_id = self._validate_connection('disconnect', uuid, key)\n        if conn_id is None:\n            return\n\n        conn_data = self._connections[uuid]\n\n        slug = self._build_device_slug(uuid)\n\n        message = {'client': client, 'type': 'response', 'operation': 'disconnect'}\n\n        self.client.reset_sequence(self.topics.gateway_topic(slug, 'control/connect'))\n        self.client.reset_sequence(self.topics.gateway_topic(slug, 'control/action'))\n\n        try:\n            resp = yield self._manager.disconnect(conn_id)\n        except Exception as exc:\n            self._logger.exception(\"Error in manager disconnect\")\n            resp = {'success': False, 'reason': \"Internal error: %s\" % str(exc)}\n\n        # Remove any monitors that we registered for this device\n        self._manager.remove_monitor(conn_data['report_monitor'])\n        self._manager.remove_monitor(conn_data['trace_monitor'])\n\n        if resp['success']:\n            del self._connections[uuid]\n            message['success'] = True\n        else:\n            message['success'] = False\n            message['failure_reason'] = resp['reason']\n\n        self._logger.info(\"Client %s disconnected from device 0x%X\", client, uuid)\n\n        # Send a response for all requested disconnects and if we tried to disconnect the client\n        # on our own and succeeded, send an unsolicited notification to that effect\n        if unsolicited and resp['success']:\n            self._publish_response(slug, {'client': client, 'type': 'notification', 'operation': 'disconnect'})\n        elif not unsolicited:\n            self._publish_response(slug, message)", "response": "Disconnect from a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to a device given its uuid and client id Returns a context manager that can be used to create a new connection.", "response": "def _connect_to_device(self, uuid, key, client):\n        \"\"\"Connect to a device given its uuid\n\n        Args:\n            uuid (int): The unique id of the device\n            key (string): A 64 byte string used to secure this connection\n            client (string): The client id for who is trying to connect\n                to the device.\n        \"\"\"\n\n        slug = self._build_device_slug(uuid)\n        message = {'client': client, 'type': 'response', 'operation': 'connect'}\n\n        self._logger.info(\"Connection attempt for device %d\", uuid)\n\n        # If someone is already connected, fail the request\n        if uuid in self._connections:\n            message['success'] = False\n            message['failure_reason'] = 'Someone else is connected to the device'\n\n            self._publish_status(slug, message)\n            return\n\n        # Otherwise try to connect\n        resp = yield self._manager.connect(uuid)\n        message['success'] = resp['success']\n        if resp['success']:\n            conn_id = resp['connection_id']\n            self._connections[uuid] = {'key': key, 'client': client, 'connection_id': conn_id, 'last_touch': monotonic(),\n                                       'script': [], 'trace_accum': bytes(), 'last_trace': None, 'trace_scheduled': False,\n                                       'last_progress': None}\n        else:\n            message['failure_reason'] = resp['reason']\n            self._connections[uuid] = {}\n\n        connection = self._connections[uuid]\n        connection['report_monitor'] = self._manager.register_monitor(uuid, ['report'], self._notify_report)\n        connection['trace_monitor'] = self._manager.register_monitor(uuid, ['trace'], self._notify_trace)\n\n        self._publish_status(slug, message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _notify_report(self, device_uuid, event_name, report):\n\n        if device_uuid not in self._connections:\n            self._logger.debug(\"Dropping report for device without an active connection, uuid=0x%X\", device_uuid)\n            return\n\n        slug = self._build_device_slug(device_uuid)\n        streaming_topic = self.topics.prefix + 'devices/{}/data/streaming'.format(slug)\n\n        data = {'type': 'notification', 'operation': 'report'}\n\n        ser = report.serialize()\n        data['received_time'] = ser['received_time'].strftime(\"%Y%m%dT%H:%M:%S.%fZ\").encode()\n        data['report_origin'] = ser['origin']\n        data['report_format'] = ser['report_format']\n        data['report'] = binascii.hexlify(ser['encoded_report'])\n        data['fragment_count'] = 1\n        data['fragment_index'] = 0\n        self._logger.debug(\"Publishing report: (topic=%s)\", streaming_topic)\n        self.client.publish(streaming_topic, data)", "response": "Notify that a report has been received from a device."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify that we have received tracing data from a device.", "response": "def _notify_trace(self, device_uuid, event_name, trace):\n        \"\"\"Notify that we have received tracing data from a device.\n\n        This routine is called synchronously in the event loop by the DeviceManager\n        \"\"\"\n\n        if device_uuid not in self._connections:\n            self._logger.debug(\"Dropping trace data for device without an active connection, uuid=0x%X\", device_uuid)\n            return\n\n        conn_data = self._connections[device_uuid]\n        last_trace = conn_data['last_trace']\n        now = monotonic()\n\n        conn_data['trace_accum'] += bytes(trace)\n\n        # If we're throttling tracing data, we need to see if we should accumulate this trace or\n        # send it now.  We acculumate if we've last sent tracing data less than self.throttle_trace seconds ago\n        if last_trace is not None and (now - last_trace) < self.throttle_trace:\n            if not conn_data['trace_scheduled']:\n                self._loop.call_later(self.throttle_trace - (now - last_trace), self._send_accum_trace, device_uuid)\n                conn_data['trace_scheduled'] = True\n                self._logger.debug(\"Deferring trace data due to throttling uuid=0x%X\", device_uuid)\n        else:\n            self._send_accum_trace(device_uuid)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend whatever accumulated tracing data we have for the device.", "response": "def _send_accum_trace(self, device_uuid):\n        \"\"\"Send whatever accumulated tracing data we have for the device.\"\"\"\n\n        if device_uuid not in self._connections:\n            self._logger.debug(\"Dropping trace data for device without an active connection, uuid=0x%X\", device_uuid)\n            return\n\n        conn_data = self._connections[device_uuid]\n\n        trace = conn_data['trace_accum']\n\n        if len(trace) > 0:\n            slug = self._build_device_slug(device_uuid)\n            tracing_topic = self.topics.prefix + 'devices/{}/data/tracing'.format(slug)\n\n            data = {'type': 'notification', 'operation': 'trace'}\n            data['trace'] = binascii.hexlify(trace)\n            data['trace_origin'] = device_uuid\n\n            self._logger.debug('Publishing trace: (topic=%s)', tracing_topic)\n            self.client.publish(tracing_topic, data)\n\n        conn_data['trace_scheduled'] = False\n        conn_data['last_trace'] = monotonic()\n        conn_data['trace_accum'] = bytes()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a request for scanning information about the current node.", "response": "def _on_scan_request(self, sequence, topic, message):\n        \"\"\"Process a request for scanning information\n\n        Args:\n            sequence (int:) The sequence number of the packet received\n            topic (string): The topic this message was received on\n            message_type (string): The type of the packet received\n            message (dict): The message itself\n        \"\"\"\n\n        if messages.ProbeCommand.matches(message):\n            self._logger.debug(\"Received probe message on topic %s, message=%s\", topic, message)\n            self._loop.add_callback(self._publish_scan_response, message['client'])\n        else:\n            self._logger.warn(\"Invalid message received on topic %s, message=%s\", topic, message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish a scan response message to the client.", "response": "def _publish_scan_response(self, client):\n        \"\"\"Publish a scan response message\n\n        The message contains all of the devices that are currently known\n        to this agent.  Connection strings for direct connections are\n        translated to what is appropriate for this agent.\n\n        Args:\n            client (string): A unique id for the client that made this request\n        \"\"\"\n\n        devices = self._manager.scanned_devices\n\n        converted_devs = []\n        for uuid, info in devices.items():\n            slug = self._build_device_slug(uuid)\n\n            message = {}\n            message['uuid'] = uuid\n            if uuid in self._connections:\n                message['user_connected'] = True\n            elif 'user_connected' in info:\n                message['user_connected'] = info['user_connected']\n            else:\n                message['user_connected'] = False\n\n            message['connection_string'] = slug\n            message['signal_strength'] = info['signal_strength']\n\n            converted_devs.append({x: y for x, y in message.items()})\n            message['type'] = 'notification'\n            message['operation'] = 'advertisement'\n\n            self.client.publish(self.topics.gateway_topic(slug, 'data/advertisement'), message)\n\n        probe_message = {}\n        probe_message['type'] = 'response'\n        probe_message['client'] = client\n        probe_message['success'] = True\n        probe_message['devices'] = converted_devs\n\n        self.client.publish(self.topics.status, probe_message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _versioned_lib_name(env, libnode, version, prefix, suffix, prefix_generator, suffix_generator, **kw):\n    Verbose = False\n\n    if Verbose:\n        print(\"_versioned_lib_name: libnode={:r}\".format(libnode.get_path()))\n        print(\"_versioned_lib_name: version={:r}\".format(version))\n        print(\"_versioned_lib_name: prefix={:r}\".format(prefix))\n        print(\"_versioned_lib_name: suffix={:r}\".format(suffix))\n        print(\"_versioned_lib_name: suffix_generator={:r}\".format(suffix_generator))\n\n    versioned_name = os.path.basename(libnode.get_path())\n    if Verbose:\n        print(\"_versioned_lib_name: versioned_name={:r}\".format(versioned_name))\n\n    versioned_prefix = prefix_generator(env, **kw)\n    versioned_suffix = suffix_generator(env, **kw)\n    if Verbose:\n        print(\"_versioned_lib_name: versioned_prefix={:r}\".format(versioned_prefix))\n        print(\"_versioned_lib_name: versioned_suffix={:r}\".format(versioned_suffix))\n\n    versioned_prefix_re = '^' + re.escape(versioned_prefix)\n    versioned_suffix_re = re.escape(versioned_suffix) + '$'\n    name = re.sub(versioned_prefix_re, prefix, versioned_name)\n    name = re.sub(versioned_suffix_re, suffix, name)\n    if Verbose:\n        print(\"_versioned_lib_name: name={:r}\".format(name))\n    return name", "response": "For libnode = / optional / dir / libfoo. so. X. Y. Z it returns libfoo. so. X. Y. Z"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _versioned_lib_suffix(env, suffix, version):\n    Verbose = False\n    if Verbose:\n        print(\"_versioned_lib_suffix: suffix={:r}\".format(suffix))\n        print(\"_versioned_lib_suffix: version={:r}\".format(version))\n    if not suffix.endswith(version):\n        suffix = suffix + '.' + version\n    if Verbose:\n        print(\"_versioned_lib_suffix: return suffix={:r}\".format(suffix))\n    return suffix", "response": "Return the versioned library suffix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _versioned_lib_symlinks(env, libnode, version, prefix, suffix, name_func, soname_func):\n    Verbose = False\n\n    if Verbose:\n        print(\"_versioned_lib_symlinks: libnode={:r}\".format(libnode.get_path()))\n        print(\"_versioned_lib_symlinks: version={:r}\".format(version))\n\n    if sys.platform.startswith('openbsd'):\n        # OpenBSD uses x.y shared library versioning numbering convention\n        # and doesn't use symlinks to backwards-compatible libraries\n        if Verbose:\n            print(\"_versioned_lib_symlinks: return symlinks={:r}\".format(None))\n        return None\n\n    linkdir = libnode.get_dir()\n    if Verbose:\n        print(\"_versioned_lib_symlinks: linkdir={:r}\".format(linkdir.get_path()))\n\n    name = name_func(env, libnode, version, prefix, suffix)\n    if Verbose:\n        print(\"_versioned_lib_symlinks: name={:r}\".format(name))\n\n    soname = soname_func(env, libnode, version, prefix, suffix)\n\n    link0 = env.fs.File(soname, linkdir)\n    link1 = env.fs.File(name, linkdir)\n\n    # We create direct symlinks, not daisy-chained.\n    if link0 == libnode:\n        # This enables SHLIBVERSION without periods (e.g. SHLIBVERSION=1)\n        symlinks = [ (link1, libnode) ]\n    else:\n        # This handles usual SHLIBVERSION, i.e. '1.2', '1.2.3', etc.\n        symlinks = [ (link0, libnode), (link1, libnode) ]\n\n    if Verbose:\n        print(\"_versioned_lib_symlinks: return symlinks={:r}\".format(SCons.Tool.StringizeLibSymlinks(symlinks)))\n\n    return symlinks", "response": "Generate a list of symlink names that should be created for a versioned shared library."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(env):\n    SCons.Tool.createSharedLibBuilder(env)\n    SCons.Tool.createProgBuilder(env)\n\n    env['SHLINK']      = '$LINK'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -shared')\n    env['SHLINKCOM']   = '$SHLINK -o $TARGET $SHLINKFLAGS $__SHLIBVERSIONFLAGS $__RPATH $SOURCES $_LIBDIRFLAGS $_LIBFLAGS'\n    # don't set up the emitter, cause AppendUnique will generate a list\n    # starting with None :-(\n    env.Append(SHLIBEMITTER = [shlib_emitter])\n    env['SMARTLINK']   = smart_link\n    env['LINK']        = \"$SMARTLINK\"\n    env['LINKFLAGS']   = SCons.Util.CLVar('')\n    # __RPATH is only set to something ($_RPATH typically) on platforms that support it.\n    env['LINKCOM']     = '$LINK -o $TARGET $LINKFLAGS $__RPATH $SOURCES $_LIBDIRFLAGS $_LIBFLAGS'\n    env['LIBDIRPREFIX']='-L'\n    env['LIBDIRSUFFIX']=''\n    env['_LIBFLAGS']='${_stripixes(LIBLINKPREFIX, LIBS, LIBLINKSUFFIX, LIBPREFIXES, LIBSUFFIXES, __env__)}'\n    env['LIBLINKPREFIX']='-l'\n    env['LIBLINKSUFFIX']=''\n\n    if env['PLATFORM'] == 'hpux':\n        env['SHLIBSUFFIX'] = '.sl'\n    elif env['PLATFORM'] == 'aix':\n        env['SHLIBSUFFIX'] = '.a'\n\n    # For most platforms, a loadable module is the same as a shared\n    # library.  Platforms which are different can override these, but\n    # setting them the same means that LoadableModule works everywhere.\n    SCons.Tool.createLoadableModuleBuilder(env)\n    env['LDMODULE'] = '$SHLINK'\n    env.Append(LDMODULEEMITTER = [ldmod_emitter])\n    env['LDMODULEPREFIX'] = '$SHLIBPREFIX'\n    env['LDMODULESUFFIX'] = '$SHLIBSUFFIX'\n    env['LDMODULEFLAGS'] = '$SHLINKFLAGS'\n    env['LDMODULECOM'] = '$LDMODULE -o $TARGET $LDMODULEFLAGS $__LDMODULEVERSIONFLAGS $__RPATH $SOURCES $_LIBDIRFLAGS $_LIBFLAGS'\n    env['LDMODULEVERSION'] = '$SHLIBVERSION'\n    env['LDMODULENOVERSIONSYMLINKS'] = '$SHLIBNOVERSIONSYMLINKS'", "response": "Add Builders and construction variables for gnulink to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None, loop=SharedLoop, max_time=None):\n    should_raise = argv is not None\n\n    if argv is None:\n        argv = sys.argv[1:]\n\n    parser = build_parser()\n    cmd_args = parser.parse_args(argv)\n\n    configure_logging(cmd_args.verbose)\n    logger = logging.getLogger(__name__)\n\n    try:\n        args = {}\n        if cmd_args.config is not None:\n            try:\n                with open(cmd_args.config, \"r\") as conf:\n                    args = json.load(conf)\n            except IOError as exc:\n                raise ScriptError(\"Could not open config file %s due to %s\"\n                                  % (cmd_args.config, str(exc)), 2)\n            except ValueError as exc:\n                raise ScriptError(\"Could not parse JSON from config file %s due to %s\"\n                                  % (cmd_args.config, str(exc)), 3)\n            except TypeError as exc:\n                raise ScriptError(\"You must pass the path to a json config file\", 4)\n\n        logger.critical(\"Starting gateway\")\n\n        gateway = IOTileGateway(args, loop=loop)\n        loop.run_coroutine(gateway.start())\n\n        logger.critical(\"Gateway running\")\n\n        # Run forever until we receive a ctrl-c\n        # (allow quitting early after max_time seconds for testing)\n        loop.wait_for_interrupt(max_time=max_time)\n\n        loop.run_coroutine(gateway.stop())\n    except ScriptError as exc:\n        if should_raise:\n            raise exc\n\n        logger.fatal(\"Quitting due to error: %s\", exc.msg)\n        return exc.code\n    except Exception as exc:  # pylint: disable=W0703\n        if should_raise:\n            raise exc\n\n        logger.exception(\"Fatal error running gateway\")\n        return 1\n\n    return 0", "response": "Entry point for iotile - gateway."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify(self, obj):\n\n        if obj is not None:\n            raise ValidationError(\"Object is not None\",\n                                  reason='%s is not None' % str(obj), object=obj)\n\n        return obj", "response": "Verify that the object conforms to this verifier s schema\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of this _TimeAnchor.", "response": "def copy(self):\n        \"\"\"Return a copy of this _TimeAnchor.\"\"\"\n        return _TimeAnchor(self.reading_id, self.uptime, self.utc, self.is_break, self.exact)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef anchor_stream(self, stream_id, converter=\"rtc\"):\n\n        if isinstance(converter, str):\n            converter = self._known_converters.get(converter)\n\n            if converter is None:\n                raise ArgumentError(\"Unknown anchor converter string: %s\" % converter,\n                                    known_converters=list(self._known_converters))\n\n        self._anchor_streams[stream_id] = converter", "response": "Mark a stream as containing anchor points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef id_range(self):\n\n        if len(self._anchor_points) == 0:\n            return (0, 0)\n\n        return (self._anchor_points[0].reading_id, self._anchor_points[-1].reading_id)", "response": "Get the range of archor reading ids."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_rtc(cls, timestamp):\n\n        if timestamp & (1  << 31):\n            timestamp &= ~(1 << 31)\n\n        delta = datetime.timedelta(seconds=timestamp)\n        return cls._Y2KReference + delta", "response": "Convert a number of seconds since 1 / 1 2000 to UTC time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a reading containing an epoch timestamp to datetime.", "response": "def _convert_epoch_anchor(cls, reading):\n        \"\"\"Convert a reading containing an epoch timestamp to datetime.\"\"\"\n\n        delta = datetime.timedelta(seconds=reading.value)\n        return cls._EpochReference + delta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_point(self, reading_id, uptime=None, utc=None, is_break=False):\n\n        if reading_id == 0:\n            return\n\n        if uptime is None and utc is None:\n            return\n\n        if uptime is not None and uptime & (1 << 31):\n            if utc is not None:\n                return\n\n            uptime &= ~(1 << 31)\n\n            utc = self.convert_rtc(uptime)\n            uptime = None\n\n        anchor = _TimeAnchor(reading_id, uptime, utc, is_break, exact=utc is not None)\n\n        if anchor in self._anchor_points:\n            return\n\n        self._anchor_points.add(anchor)\n        self._prepared = False", "response": "Add a time point that could be used as a UTC reference."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a report to the calendar.", "response": "def add_report(self, report, ignore_errors=False):\n        \"\"\"Add all anchors from a report.\"\"\"\n\n        if not isinstance(report, SignedListReport):\n            if ignore_errors:\n                return\n\n            raise ArgumentError(\"You can only add SignedListReports to a UTCAssigner\", report=report)\n\n        for reading in report.visible_readings:\n            self.add_reading(reading)\n\n        self.add_point(report.report_id, report.sent_timestamp, report.received_time)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nassigning a utc datetime to a reading id.", "response": "def assign_utc(self, reading_id, uptime=None, prefer=\"before\"):\n        \"\"\"Assign a utc datetime to a reading id.\n\n        This method will return an object with assignment information or None\n        if a utc value cannot be assigned.  The assignment object returned\n        contains a utc property that has the asssigned UTC as well as other\n        properties describing how reliable the assignment is.\n\n        Args:\n            reading_id (int): The monotonic reading id that we wish to assign\n                a utc timestamp to.\n            uptime (int): Optional uptime that should be associated with the\n                reading id.  If this is not specified and the reading_id is\n                found in the anchor points passed to this class then the\n                uptime from the corresponding anchor point will be used.\n            prefer (str): There are two possible directions that can be used\n                to assign a UTC timestamp (the nearest anchor before or after the\n                reading).  If both directions are of similar quality, the choice\n                is arbitrary.  Passing prefer=\"before\" will use the anchor point\n                before the reading.  Passing prefer=\"after\" will use the anchor\n                point after the reading.  Default: before.\n\n        Returns:\n            UTCAssignment: The assigned UTC time or None if assignment is impossible.\n        \"\"\"\n\n        if prefer not in (\"before\", \"after\"):\n            raise ArgumentError(\"Invalid prefer parameter: {}, must be 'before' or 'after'\".format(prefer))\n\n        if len(self._anchor_points) == 0:\n            return None\n\n        if reading_id > self._anchor_points[-1].reading_id:\n            return None\n\n        i = self._anchor_points.bisect_key_left(reading_id)\n        found_id = False\n        crossed_break = False\n        exact = True\n\n        last = self._anchor_points[i].copy()\n        if uptime is not None:\n            last.uptime = uptime\n\n        if last.reading_id == reading_id:\n            found_id = True\n\n            if last.utc is not None:\n                return UTCAssignment(reading_id, last.utc, found_id, exact, crossed_break)\n\n        left_assign = self._fix_left(reading_id, last, i, found_id)\n        if left_assign is not None and left_assign.exact:\n            return left_assign\n\n        right_assign = self._fix_right(reading_id, last, i, found_id)\n        if right_assign is not None and right_assign.exact:\n            return right_assign\n\n        return self._pick_best_fix(left_assign, right_assign, prefer)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ensure_prepared(self):\n\n        if self._prepared:\n            return\n\n        exact_count = 0\n        fixed_count = 0\n        inexact_count = 0\n\n        self._logger.debug(\"Preparing UTCAssigner (%d total anchors)\", len(self._anchor_points))\n\n        for curr in self._anchor_points:\n            if not curr.exact:\n                assignment = self.assign_utc(curr.reading_id, curr.uptime)\n                if assignment is not None and assignment.exact:\n                    curr.utc = assignment.utc\n                    curr.exact = True\n                    fixed_count += 1\n                else:\n                    inexact_count += 1\n            else:\n                exact_count += 1\n\n        self._logger.debug(\"Prepared UTCAssigner with %d reference points, \"\n                           \"%d exact anchors and %d inexact anchors\",\n                           exact_count, fixed_count, inexact_count)\n\n        self._prepared = True", "response": "Calculate and cache UTC values for all exactly known anchor points."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fix_report(self, report, errors=\"drop\", prefer=\"before\"):\n\n        if not isinstance(report, SignedListReport):\n            raise ArgumentError(\"Report must be a SignedListReport\", report=report)\n\n        if errors not in ('drop',):\n            raise ArgumentError(\"Unknown errors handler: {}, supported=['drop']\".format(errors))\n\n        self.ensure_prepared()\n\n        fixed_readings = []\n        dropped_readings = 0\n\n        for reading in report.visible_readings:\n            assignment = self.assign_utc(reading.reading_id, reading.raw_time, prefer=prefer)\n\n            if assignment is None:\n                dropped_readings += 1\n                continue\n\n            fixed_reading = IOTileReading(assignment.rtc_value, reading.stream, reading.value,\n                                          reading_time=assignment.utc, reading_id=reading.reading_id)\n            fixed_readings.append(fixed_reading)\n\n        fixed_report = SignedListReport.FromReadings(report.origin, fixed_readings, report_id=report.report_id,\n                                                     selector=report.streamer_selector, streamer=report.origin_streamer,\n                                                     sent_timestamp=report.sent_timestamp)\n        fixed_report.received_time = report.received_time\n\n        if dropped_readings > 0:\n            self._logger.warning(\"Dropped %d readings of %d when fixing UTC timestamps in report 0x%08X for device 0x%08X\",\n                                 dropped_readings, len(report.visible_readings), report.report_id, report.origin)\n\n        return fixed_report", "response": "This function will fix all readings in a report by performing utc assignment on all readings in a report."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfix a reading by looking for the nearest anchor point before it.", "response": "def _fix_left(self, reading_id, last, start, found_id):\n        \"\"\"Fix a reading by looking for the nearest anchor point before it.\"\"\"\n\n        accum_delta = 0\n        exact = True\n        crossed_break = False\n\n        if start == 0:\n            return None\n\n        for curr in self._anchor_points.islice(None, start - 1, reverse=True):\n            if curr.uptime is None or last.uptime is None:\n                exact = False\n            elif curr.is_break or last.uptime < curr.uptime:\n                exact = False\n                crossed_break = True\n            else:\n                accum_delta += last.uptime - curr.uptime\n\n            if curr.utc is not None:\n                time_delta = datetime.timedelta(seconds=accum_delta)\n                return UTCAssignment(reading_id, curr.utc + time_delta, found_id, exact, crossed_break)\n\n            last = curr\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the. sconsign file info for this directory.", "response": "def sconsign_dir(node):\n    \"\"\"Return the .sconsign file info for this directory,\n    creating it first if necessary.\"\"\"\n    if not node._sconsign:\n        import SCons.SConsign\n        node._sconsign = SCons.SConsign.ForDirectory(node)\n    return node._sconsign"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninvalidate the memoized values of all Nodes files or directories associated with the given entries.", "response": "def invalidate_node_memos(targets):\n    \"\"\"\n    Invalidate the memoized values of all Nodes (files or directories)\n    that are associated with the given entries. Has been added to\n    clear the cache of nodes affected by a direct execution of an\n    action (e.g.  Delete/Copy/Chmod). Existing Node caches become\n    inconsistent if the action is run through Execute().  The argument\n    `targets` can be a single Node object or filename, or a sequence\n    of Nodes/filenames.\n    \"\"\"\n    from traceback import extract_stack\n\n    # First check if the cache really needs to be flushed. Only\n    # actions run in the SConscript with Execute() seem to be\n    # affected. XXX The way to check if Execute() is in the stacktrace\n    # is a very dirty hack and should be replaced by a more sensible\n    # solution.\n    for f in extract_stack():\n        if f[2] == 'Execute' and f[0][-14:] == 'Environment.py':\n            break\n    else:\n        # Dont have to invalidate, so return\n        return\n\n    if not SCons.Util.is_List(targets):\n        targets = [targets]\n\n    for entry in targets:\n        # If the target is a Node object, clear the cache. If it is a\n        # filename, look up potentially existing Node object first.\n        try:\n            entry.clear_memoized_values()\n        except AttributeError:\n            # Not a Node object, try to look up Node by filename.  XXX\n            # This creates Node objects even for those filenames which\n            # do not correspond to an existing Node object.\n            node = get_default_fs().Entry(entry)\n            if node:\n                node.clear_memoized_values()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the file s directory and file name with the suffix stripped.", "response": "def __get_base_path(self):\n        \"\"\"Return the file's directory and file name, with the\n        suffix stripped.\"\"\"\n        entry = self.get()\n        return SCons.Subst.SpecialAttrWrapper(SCons.Util.splitext(entry.get_path())[0],\n                                             entry.name + \"_base\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_posix_path(self):\n        if os_sep_is_slash:\n            return self\n        else:\n            entry = self.get()\n            r = entry.get_path().replace(OS_SEP, '/')\n            return SCons.Subst.SpecialAttrWrapper(r, entry.name + \"_posix\")", "response": "Return the path with _posix as the path separator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_windows_path(self):\n        if OS_SEP == '\\\\':\n            return self\n        else:\n            entry = self.get()\n            r = entry.get_path().replace(OS_SEP, '\\\\')\n            return SCons.Subst.SpecialAttrWrapper(r, entry.name + \"_windows\")", "response": "Return the path with \\ as the path separator and the platform as the platform separator."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an exception if the node is not the same as the specified class.", "response": "def must_be_same(self, klass):\n        \"\"\"\n        This node, which already existed, is being looked up as the\n        specified klass.  Raise an exception if it isn't.\n        \"\"\"\n        if isinstance(self, klass) or klass is Entry:\n            return\n        raise TypeError(\"Tried to lookup %s '%s' as a %s.\" %\\\n              (self.__class__.__name__, self.get_internal_path(), klass.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the node that is in a build path or None if this node is in a build path.", "response": "def srcnode(self):\n        \"\"\"If this node is in a build path, return the node\n        corresponding to its source file.  Otherwise, return\n        ourself.\n        \"\"\"\n        srcdir_list = self.dir.srcdir_list()\n        if srcdir_list:\n            srcnode = srcdir_list[0].Entry(self.name)\n            srcnode.must_be_same(self.__class__)\n            return srcnode\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the path relative to the current working directory of the the object that owns us.", "response": "def get_path(self, dir=None):\n        \"\"\"Return path relative to the current working directory of the\n        Node.FS.Base object that owns us.\"\"\"\n        if not dir:\n            dir = self.fs.getcwd()\n        if self == dir:\n            return '.'\n        path_elems = self.get_path_elements()\n        pathname = ''\n        try: i = path_elems.index(dir)\n        except ValueError:\n            for p in path_elems[:-1]:\n                pathname += p.dirname\n        else:\n            for p in path_elems[i+1:-1]:\n                pathname += p.dirname\n        return pathname + path_elems[-1].name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the source code builder for this node.", "response": "def set_src_builder(self, builder):\n        \"\"\"Set the source code builder for this node.\"\"\"\n        self.sbuilder = builder\n        if not self.has_builder():\n            self.builder_set(builder)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef src_builder(self):\n        try:\n            scb = self.sbuilder\n        except AttributeError:\n            scb = self.dir.src_builder()\n            self.sbuilder = scb\n        return scb", "response": "Fetch the source code builder for this node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all of the directories in a given pathlist including any backing directories in any repositories.", "response": "def Rfindalldirs(self, pathlist):\n        \"\"\"\n        Return all of the directories for a given path list, including\n        corresponding \"backing\" directories in any repositories.\n\n        The Node lookups are relative to this Node (typically a\n        directory), so memoizing result saves cycles from looking\n        up the same path for each target in a given directory.\n        \"\"\"\n        try:\n            memo_dict = self._memo['Rfindalldirs']\n        except KeyError:\n            memo_dict = {}\n            self._memo['Rfindalldirs'] = memo_dict\n        else:\n            try:\n                return memo_dict[pathlist]\n            except KeyError:\n                pass\n\n        create_dir_relative_to_self = self.Dir\n        result = []\n        for path in pathlist:\n            if isinstance(path, SCons.Node.Node):\n                result.append(path)\n            else:\n                dir = create_dir_relative_to_self(path)\n                result.extend(dir.get_all_rdirs())\n\n        memo_dict[pathlist] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RDirs(self, pathlist):\n        cwd = self.cwd or self.fs._cwd\n        return cwd.Rfindalldirs(pathlist)", "response": "Search for a list of directories in the Repository list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rfile(self):\n        self.__class__ = File\n        self._morph()\n        self.clear()\n        return File.rfile(self)", "response": "This is a generic Entry but the caller is actually looking for\n        a File at this point so morph into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the decoded text contents of a Unicode encoded Entry.", "response": "def get_text_contents(self):\n        \"\"\"Fetch the decoded text contents of a Unicode encoded Entry.\n\n        Since this should return the text contents from the file\n        system, we check to see into what sort of subclass we should\n        morph this Entry.\"\"\"\n        try:\n            self = self.disambiguate(must_exist=1)\n        except SCons.Errors.UserError:\n            # There was nothing on disk with which to disambiguate\n            # this entry.  Leave it as an Entry, but return a null\n            # string so calls to get_text_contents() in emitters and\n            # the like (e.g. in qt.py) don't have to disambiguate by\n            # hand or catch the exception.\n            return ''\n        else:\n            return self.get_text_contents()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall to make sure that a Node is a Dir. Since we re an Entry we can morph into one.", "response": "def must_be_same(self, klass):\n        \"\"\"Called to make sure a Node is a Dir.  Since we're an\n        Entry, we can morph into one.\"\"\"\n        if self.__class__ is not klass:\n            self.__class__ = klass\n            self._morph()\n            self.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chdir(self, dir, change_os_dir=0):\n        curr=self._cwd\n        try:\n            if dir is not None:\n                self._cwd = dir\n                if change_os_dir:\n                    os.chdir(dir.get_abspath())\n        except OSError:\n            self._cwd = curr\n            raise", "response": "Change the current working directory for lookups."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the root directory for the specified drive creating it if necessary.", "response": "def get_root(self, drive):\n        \"\"\"\n        Returns the root directory for the specified drive, creating\n        it if necessary.\n        \"\"\"\n        drive = _my_normcase(drive)\n        try:\n            return self.Root[drive]\n        except KeyError:\n            root = RootDir(drive, self)\n            self.Root[drive] = root\n            if not drive:\n                self.Root[self.defaultDrive] = root\n            elif drive == self.defaultDrive:\n                self.Root[''] = root\n            return root"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _lookup(self, p, directory, fsclass, create=1):\n        if isinstance(p, Base):\n            # It's already a Node.FS object.  Make sure it's the right\n            # class and return.\n            p.must_be_same(fsclass)\n            return p\n        # str(p) in case it's something like a proxy object\n        p = str(p)\n\n        if not os_sep_is_slash:\n            p = p.replace(OS_SEP, '/')\n\n        if p[0:1] == '#':\n            # There was an initial '#', so we strip it and override\n            # whatever directory they may have specified with the\n            # top-level SConstruct directory.\n            p = p[1:]\n            directory = self.Top\n\n            # There might be a drive letter following the\n            # '#'. Although it is not described in the SCons man page,\n            # the regression test suite explicitly tests for that\n            # syntax. It seems to mean the following thing:\n            #\n            #   Assuming the the SCons top dir is in C:/xxx/yyy,\n            #   '#X:/toto' means X:/xxx/yyy/toto.\n            #\n            # i.e. it assumes that the X: drive has a directory\n            # structure similar to the one found on drive C:.\n            if do_splitdrive:\n                drive, p = _my_splitdrive(p)\n                if drive:\n                    root = self.get_root(drive)\n                else:\n                    root = directory.root\n            else:\n                root = directory.root\n\n            # We can only strip trailing after splitting the drive\n            # since the drive might the UNC '//' prefix.\n            p = p.strip('/')\n\n            needs_normpath = needs_normpath_match(p)\n\n            # The path is relative to the top-level SCons directory.\n            if p in ('', '.'):\n                p = directory.get_labspath()\n            else:\n                p = directory.get_labspath() + '/' + p\n        else:\n            if do_splitdrive:\n                drive, p = _my_splitdrive(p)\n                if drive and not p:\n                    # This causes a naked drive letter to be treated\n                    # as a synonym for the root directory on that\n                    # drive.\n                    p = '/'\n            else:\n                drive = ''\n\n            # We can only strip trailing '/' since the drive might the\n            # UNC '//' prefix.\n            if p != '/':\n                p = p.rstrip('/')\n\n            needs_normpath = needs_normpath_match(p)\n\n            if p[0:1] == '/':\n                # Absolute path\n                root = self.get_root(drive)\n            else:\n                # This is a relative lookup or to the current directory\n                # (the path name is not absolute).  Add the string to the\n                # appropriate directory lookup path, after which the whole\n                # thing gets normalized.\n                if directory:\n                    if not isinstance(directory, Dir):\n                        directory = self.Dir(directory)\n                else:\n                    directory = self._cwd\n\n                if p in ('', '.'):\n                    p = directory.get_labspath()\n                else:\n                    p = directory.get_labspath() + '/' + p\n\n                if drive:\n                    root = self.get_root(drive)\n                else:\n                    root = directory.root\n\n        if needs_normpath is not None:\n            # Normalize a pathname. Will return the same result for\n            # equivalent paths.\n            #\n            # We take advantage of the fact that we have an absolute\n            # path here for sure. In addition, we know that the\n            # components of lookup path are separated by slashes at\n            # this point. Because of this, this code is about 2X\n            # faster than calling os.path.normpath() followed by\n            # replacing os.sep with '/' again.\n            ins = p.split('/')[1:]\n            outs = []\n            for d in ins:\n                if d == '..':\n                    try:\n                        outs.pop()\n                    except IndexError:\n                        pass\n                elif d not in ('', '.'):\n                    outs.append(d)\n            p = '/' + '/'.join(outs)\n\n        return root._lookup_abs(p, fsclass, create)", "response": "This function is a generic entry point for Node. FS objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Entry(self, name, directory = None, create = 1):\n        return self._lookup(name, directory, Entry, create)", "response": "Look up or create a generic Entry node with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef File(self, name, directory = None, create = 1):\n        return self._lookup(name, directory, File, create)", "response": "Look up or create a File node with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Dir(self, name, directory = None, create = True):\n        return self._lookup(name, directory, Dir, create)", "response": "Look up or create a Dir node with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef VariantDir(self, variant_dir, src_dir, duplicate=1):\n\n        if not isinstance(src_dir, SCons.Node.Node):\n            src_dir = self.Dir(src_dir)\n        if not isinstance(variant_dir, SCons.Node.Node):\n            variant_dir = self.Dir(variant_dir)\n        if src_dir.is_under(variant_dir):\n            raise SCons.Errors.UserError(\"Source directory cannot be under variant directory.\")\n        if variant_dir.srcdir:\n            if variant_dir.srcdir == src_dir:\n                return # We already did this.\n            raise SCons.Errors.UserError(\"'%s' already has a source directory: '%s'.\"%(variant_dir, variant_dir.srcdir))\n        variant_dir.link(src_dir, duplicate)", "response": "Link the supplied variant directory to the source directory\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Repository(self, *dirs):\n        for d in dirs:\n            if not isinstance(d, SCons.Node.Node):\n                d = self.Dir(d)\n            self.Top.addRepository(d)", "response": "Specify the directories to search for."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlocating the directory of a given python module name", "response": "def PyPackageDir(self, modulename):\n        \"\"\"Locate the directory of a given python module name\n\t\t\n        For example scons might resolve to\n        Windows: C:\\Python27\\Lib\\site-packages\\scons-2.5.1\n        Linux: /usr/lib/scons\n\n        This can be useful when we want to determine a toolpath based on a python module name\"\"\"\n\n        dirpath = ''\n        if sys.version_info[0] < 3 or (sys.version_info[0] == 3 and sys.version_info[1] in (0,1,2,3,4)):\n            # Python2 Code\n            import imp\n            splitname = modulename.split('.')\n            srchpths = sys.path\n            for item in splitname:\n                file, path, desc = imp.find_module(item, srchpths)\n                if file is not None:\n                    path = os.path.dirname(path)\n                srchpths = [path]\n            dirpath = path\n        else:\n            # Python3 Code\n            import importlib.util\n            modspec = importlib.util.find_spec(modulename)\n            dirpath = os.path.dirname(modspec.origin)\n        return self._lookup(dirpath, None, Dir, True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate targets in corresponding variant directories and look up path names relative to any linked variant directories we find.", "response": "def variant_dir_target_climb(self, orig, dir, tail):\n        \"\"\"Create targets in corresponding variant directories\n\n        Climb the directory tree, and look up path names\n        relative to any linked variant directories we find.\n\n        Even though this loops and walks up the tree, we don't memoize\n        the return value because this is really only used to process\n        the command-line targets.\n        \"\"\"\n        targets = []\n        message = None\n        fmt = \"building associated VariantDir targets: %s\"\n        start_dir = dir\n        while dir:\n            for bd in dir.variant_dirs:\n                if start_dir.is_under(bd):\n                    # If already in the build-dir location, don't reflect\n                    return [orig], fmt % str(orig)\n                p = os.path.join(bd._path, *tail)\n                targets.append(self.Entry(p))\n            tail = [dir.name] + tail\n            dir = dir.up()\n        if targets:\n            message = fmt % ' '.join(map(str, targets))\n        return targets, message"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Glob(self, pathname, ondisk=True, source=True, strings=False, exclude=None, cwd=None):\n        if cwd is None:\n            cwd = self.getcwd()\n        return cwd.glob(pathname, ondisk, source, strings, exclude)", "response": "Globs the given pathname."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _morph(self):\n\n        self.repositories = []\n        self.srcdir = None\n\n        self.entries = {}\n        self.entries['.'] = self\n        self.entries['..'] = self.dir\n        self.cwd = self\n        self.searched = 0\n        self._sconsign = None\n        self.variant_dirs = []\n        self.root = self.dir.root\n        self.changed_since_last_build = 3\n        self._func_sconsign = 1\n        self._func_exists = 2\n        self._func_get_contents = 2\n\n        self._abspath = SCons.Util.silent_intern(self.dir.entry_abspath(self.name))\n        self._labspath = SCons.Util.silent_intern(self.dir.entry_labspath(self.name))\n        if self.dir._path == '.':\n            self._path = SCons.Util.silent_intern(self.name)\n        else:\n            self._path = SCons.Util.silent_intern(self.dir.entry_path(self.name))\n        if self.dir._tpath == '.':\n            self._tpath = SCons.Util.silent_intern(self.name)\n        else:\n            self._tpath = SCons.Util.silent_intern(self.dir.entry_tpath(self.name))\n        self._path_elements = self.dir._path_elements + [self]\n\n        # For directories, we make a difference between the directory\n        # 'name' and the directory 'dirname'. The 'name' attribute is\n        # used when we need to print the 'name' of the directory or\n        # when we it is used as the last part of a path. The 'dirname'\n        # is used when the directory is not the last element of the\n        # path. The main reason for making that distinction is that\n        # for RoorDir's the dirname can not be easily inferred from\n        # the name. For example, we have to add a '/' after a drive\n        # letter but not after a UNC path prefix ('//').\n        self.dirname = self.name + OS_SEP\n\n        # Don't just reset the executor, replace its action list,\n        # because it might have some pre-or post-actions that need to\n        # be preserved.\n        #\n        # But don't reset the executor if there is a non-null executor\n        # attached already. The existing executor might have other\n        # targets, in which case replacing the action list with a\n        # Mkdir action is a big mistake.\n        if not hasattr(self, 'executor'):\n            self.builder = get_MkdirBuilder()\n            self.get_executor().set_action_list(self.builder.action)\n        else:\n            # Prepend MkdirBuilder action to existing action list\n            l = self.get_executor().action_list\n            a = get_MkdirBuilder().action\n            l.insert(0, a)\n            self.get_executor().set_action_list(l)", "response": "This method is used to morph a file system Node into a proper directory object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __clearRepositoryCache(self, duplicate=None):\n\n        for node in list(self.entries.values()):\n            if node != self.dir:\n                if node != self and isinstance(node, Dir):\n                    node.__clearRepositoryCache(duplicate)\n                else:\n                    node.clear()\n                    try:\n                        del node._srcreps\n                    except AttributeError:\n                        pass\n                    if duplicate is not None:\n                        node.duplicate=duplicate", "response": "Called when we change the repository ( ies ) for a directory. This clears any cached information that is invalidated by changing\n        the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a directory node named name relative to this directory.", "response": "def Dir(self, name, create=True):\n        \"\"\"\n        Looks up or creates a directory node named 'name' relative to\n        this directory.\n        \"\"\"\n        return self.fs.Dir(name, self, create)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset this directory as the variant directory for the the supplied source directory.", "response": "def link(self, srcdir, duplicate):\n        \"\"\"Set this directory as the variant directory for the\n        supplied source directory.\"\"\"\n        self.srcdir = srcdir\n        self.duplicate = duplicate\n        self.__clearRepositoryCache(duplicate)\n        srcdir.variant_dirs.append(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of repositories for this directory.", "response": "def getRepositories(self):\n        \"\"\"Returns a list of repositories for this directory.\n        \"\"\"\n        if self.srcdir and not self.duplicate:\n            return self.srcdir.get_all_rdirs() + self.repositories\n        return self.repositories"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rel_path(self, other):\n\n        # This complicated and expensive method, which constructs relative\n        # paths between arbitrary Node.FS objects, is no longer used\n        # by SCons itself.  It was introduced to store dependency paths\n        # in .sconsign files relative to the target, but that ended up\n        # being significantly inefficient.\n        #\n        # We're continuing to support the method because some SConstruct\n        # files out there started using it when it was available, and\n        # we're all about backwards compatibility..\n\n        try:\n            memo_dict = self._memo['rel_path']\n        except KeyError:\n            memo_dict = {}\n            self._memo['rel_path'] = memo_dict\n        else:\n            try:\n                return memo_dict[other]\n            except KeyError:\n                pass\n\n        if self is other:\n            result = '.'\n\n        elif not other in self._path_elements:\n            try:\n                other_dir = other.get_dir()\n            except AttributeError:\n                result = str(other)\n            else:\n                if other_dir is None:\n                    result = other.name\n                else:\n                    dir_rel_path = self.rel_path(other_dir)\n                    if dir_rel_path == '.':\n                        result = other.name\n                    else:\n                        result = dir_rel_path + OS_SEP + other.name\n        else:\n            i = self._path_elements.index(other) + 1\n\n            path_elems = ['..'] * (len(self._path_elements) - i) \\\n                         + [n.name for n in other._path_elements[i:]]\n\n            result = OS_SEP.join(path_elems)\n\n        memo_dict[other] = result\n\n        return result", "response": "Return a path to other relative to this directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning this directory s implicit dependencies.", "response": "def get_found_includes(self, env, scanner, path):\n        \"\"\"Return this directory's implicit dependencies.\n\n        We don't bother caching the results because the scan typically\n        shouldn't be requested more than once (as opposed to scanning\n        .h file contents, which can be requested as many times as the\n        files is #included by other files).\n        \"\"\"\n        if not scanner:\n            return []\n        # Clear cached info for this Dir.  If we already visited this\n        # directory on our walk down the tree (because we didn't know at\n        # that point it was being used as the source for another Node)\n        # then we may have calculated build signature before realizing\n        # we had to scan the disk.  Now that we have to, though, we need\n        # to invalidate the old calculated signature so that any node\n        # dependent on our directory structure gets one that includes\n        # info about everything on disk.\n        self.clear()\n        return scanner(self, env, path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating this directory silently and without worrying about the base Node.", "response": "def _create(self):\n        \"\"\"Create this directory, silently and without worrying about\n        whether the builder is the default or not.\"\"\"\n        listDirs = []\n        parent = self\n        while parent:\n            if parent.exists():\n                break\n            listDirs.append(parent)\n            p = parent.up()\n            if p is None:\n                # Don't use while: - else: for this condition because\n                # if so, then parent is None and has no .path attribute.\n                raise SCons.Errors.StopError(parent._path)\n            parent = p\n        listDirs.reverse()\n        for dirnode in listDirs:\n            try:\n                # Don't call dirnode.build(), call the base Node method\n                # directly because we definitely *must* create this\n                # directory.  The dirnode.build() method will suppress\n                # the build if it's the default builder.\n                SCons.Node.Node.build(dirnode)\n                dirnode.get_executor().nullify()\n                # The build() action may or may not have actually\n                # created the directory, depending on whether the -n\n                # option was used or not.  Delete the _exists and\n                # _rexists attributes so they can be reevaluated.\n                dirnode.clear()\n            except OSError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns 1 if any child is up - to - date.", "response": "def is_up_to_date(self):\n        \"\"\"If any child is not up-to-date, then this directory isn't,\n        either.\"\"\"\n        if self.builder is not MkdirBuilder and not self.exists():\n            return 0\n        up_to_date = SCons.Node.up_to_date\n        for kid in self.children():\n            if kid.get_state() > up_to_date:\n                return 0\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the latest timestamp from among our children", "response": "def get_timestamp(self):\n        \"\"\"Return the latest timestamp from among our children\"\"\"\n        stamp = 0\n        for kid in self.children():\n            if kid.get_timestamp() > stamp:\n                stamp = kid.get_timestamp()\n        return stamp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if a physical entry with the given name could be found on disk.", "response": "def entry_exists_on_disk(self, name):\n        \"\"\" Searches through the file/dir entries of the current\n            directory, and returns True if a physical entry with the given\n            name could be found.\n\n            @see rentry_exists_on_disk\n        \"\"\"\n        try:\n            d = self.on_disk_entries\n        except AttributeError:\n            d = {}\n            try:\n                entries = os.listdir(self._abspath)\n            except OSError:\n                pass\n            else:\n                for entry in map(_my_normcase, entries):\n                    d[entry] = True\n            self.on_disk_entries = d\n        if sys.platform == 'win32' or sys.platform == 'cygwin':\n            name = _my_normcase(name)\n            result = d.get(name)\n            if result is None:\n                # Belt-and-suspenders for Windows:  check directly for\n                # 8.3 file names that don't show up in os.listdir().\n                result = os.path.exists(self._abspath + OS_SEP + name)\n                d[name] = result\n            return result\n        else:\n            return name in d"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if a physical entry with the given name could be found on disk.", "response": "def rentry_exists_on_disk(self, name):\n        \"\"\" Searches through the file/dir entries of the current\n            *and* all its remote directories (repos), and returns\n            True if a physical entry with the given name could be found.\n            The local directory (self) gets searched first, so\n            repositories take a lower precedence regarding the\n            searching order.\n\n            @see entry_exists_on_disk\n        \"\"\"\n\n        rentry_exists = self.entry_exists_on_disk(name)\n        if not rentry_exists:\n            # Search through the repository folders\n            norm_name = _my_normcase(name)\n            for rdir in self.get_all_rdirs():\n                try:\n                    node = rdir.entries[norm_name]\n                    if node:\n                        rentry_exists = True\n                        break\n                except KeyError:\n                    if rdir.entry_exists_on_disk(name):\n                        rentry_exists = True\n                        break\n        return rentry_exists"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk(self, func, arg):\n        entries = self.entries\n        names = list(entries.keys())\n        names.remove('.')\n        names.remove('..')\n        func(arg, self, names)\n        for dirname in [n for n in names if isinstance(entries[n], Dir)]:\n            entries[dirname].walk(func, arg)", "response": "Walk this directory tree by calling the specified function for each directory in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef glob(self, pathname, ondisk=True, source=False, strings=False, exclude=None):\n        dirname, basename = os.path.split(pathname)\n        if not dirname:\n            result = self._glob1(basename, ondisk, source, strings)\n        else:\n            if has_glob_magic(dirname):\n                list = self.glob(dirname, ondisk, source, False, exclude)\n            else:\n                list = [self.Dir(dirname, create=True)]\n            result = []\n            for dir in list:\n                r = dir._glob1(basename, ondisk, source, strings)\n                if strings:\n                    r = [os.path.join(str(dir), x) for x in r]\n                result.extend(r)\n        if exclude:\n            excludes = []\n            excludeList = SCons.Util.flatten(exclude)\n            for x in excludeList:\n                r = self.glob(x, ondisk, source, strings)\n                excludes.extend(r)\n            result = [x for x in result if not any(fnmatch.fnmatch(str(x), str(e)) for e in SCons.Util.flatten(excludes))]\n        return sorted(result, key=lambda a: str(a))", "response": "Returns a list of Nodes that match a specified pathname pattern."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _glob1(self, pattern, ondisk=True, source=False, strings=False):\n        search_dir_list = self.get_all_rdirs()\n        for srcdir in self.srcdir_list():\n            search_dir_list.extend(srcdir.get_all_rdirs())\n\n        selfEntry = self.Entry\n        names = []\n        for dir in search_dir_list:\n            # We use the .name attribute from the Node because the keys of\n            # the dir.entries dictionary are normalized (that is, all upper\n            # case) on case-insensitive systems like Windows.\n            node_names = [ v.name for k, v in dir.entries.items()\n                           if k not in ('.', '..') ]\n            names.extend(node_names)\n            if not strings:\n                # Make sure the working directory (self) actually has\n                # entries for all Nodes in repositories or variant dirs.\n                for name in node_names: selfEntry(name)\n            if ondisk:\n                try:\n                    disk_names = os.listdir(dir._abspath)\n                except os.error:\n                    continue\n                names.extend(disk_names)\n                if not strings:\n                    # We're going to return corresponding Nodes in\n                    # the local directory, so we need to make sure\n                    # those Nodes exist.  We only want to create\n                    # Nodes for the entries that will match the\n                    # specified pattern, though, which means we\n                    # need to filter the list here, even though\n                    # the overall list will also be filtered later,\n                    # after we exit this loop.\n                    if pattern[0] != '.':\n                        disk_names = [x for x in disk_names if x[0] != '.']\n                    disk_names = fnmatch.filter(disk_names, pattern)\n                    dirEntry = dir.Entry\n                    for name in disk_names:\n                        # Add './' before disk filename so that '#' at\n                        # beginning of filename isn't interpreted.\n                        name = './' + name\n                        node = dirEntry(name).disambiguate()\n                        n = selfEntry(name)\n                        if n.__class__ != node.__class__:\n                            n.__class__ = node.__class__\n                            n._morph()\n\n        names = set(names)\n        if pattern[0] != '.':\n            names = [x for x in names if x[0] != '.']\n        names = fnmatch.filter(names, pattern)\n\n        if strings:\n            return names\n\n        return [self.entries[_my_normcase(n)] for n in names]", "response": "Globs for and returns a list of entry names matching a single pattern in this directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _morph(self):\n\n        self.repositories = []\n        self.srcdir = None\n\n        self.entries = {}\n        self.entries['.'] = self\n        self.entries['..'] = self.dir\n        self.cwd = self\n        self.searched = 0\n        self._sconsign = None\n        self.variant_dirs = []\n        self.changed_since_last_build = 3\n        self._func_sconsign = 1\n        self._func_exists = 2\n        self._func_get_contents = 2\n\n        # Don't just reset the executor, replace its action list,\n        # because it might have some pre-or post-actions that need to\n        # be preserved.\n        #\n        # But don't reset the executor if there is a non-null executor\n        # attached already. The existing executor might have other\n        # targets, in which case replacing the action list with a\n        # Mkdir action is a big mistake.\n        if not hasattr(self, 'executor'):\n            self.builder = get_MkdirBuilder()\n            self.get_executor().set_action_list(self.builder.action)\n        else:\n            # Prepend MkdirBuilder action to existing action list\n            l = self.get_executor().action_list\n            a = get_MkdirBuilder().action\n            l.insert(0, a)\n            self.get_executor().set_action_list(l)", "response": "This method is used to morph a file system Node into a proper directory object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfast (?) lookup of a *normalized* absolute path. This method is intended for use by internal lookups with already-normalized path data. For general-purpose lookups, use the FS.Entry(), FS.Dir() or FS.File() methods. The caller is responsible for making sure we're passed a normalized absolute path; we merely let Python's dictionary look up and return the One True Node.FS object for the path. If a Node for the specified \"p\" doesn't already exist, and \"create\" is specified, the Node may be created after recursive invocation to find or create the parent directory or directories.", "response": "def _lookup_abs(self, p, klass, create=1):\n        \"\"\"\n        Fast (?) lookup of a *normalized* absolute path.\n\n        This method is intended for use by internal lookups with\n        already-normalized path data.  For general-purpose lookups,\n        use the FS.Entry(), FS.Dir() or FS.File() methods.\n\n        The caller is responsible for making sure we're passed a\n        normalized absolute path; we merely let Python's dictionary look\n        up and return the One True Node.FS object for the path.\n\n        If a Node for the specified \"p\" doesn't already exist, and\n        \"create\" is specified, the Node may be created after recursive\n        invocation to find or create the parent directory or directories.\n        \"\"\"\n        k = _my_normcase(p)\n        try:\n            result = self._lookupDict[k]\n        except KeyError:\n            if not create:\n                msg = \"No such file or directory: '%s' in '%s' (and create is False)\" % (p, str(self))\n                raise SCons.Errors.UserError(msg)\n            # There is no Node for this path name, and we're allowed\n            # to create it.\n            dir_name, file_name = p.rsplit('/',1)\n            dir_node = self._lookup_abs(dir_name, Dir)\n            result = klass(file_name, dir_node, self.fs)\n\n            # Double-check on disk (as configured) that the Node we\n            # created matches whatever is out there in the real world.\n            result.diskcheck_match()\n\n            self._lookupDict[k] = result\n            dir_node.entries[_my_normcase(file_name)] = result\n            dir_node.implicit = None\n        else:\n            # There is already a Node for this path name.  Allow it to\n            # complain if we were looking for an inappropriate type.\n            result.must_be_same(klass)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_to_sconsign(self):\n        if os_sep_is_slash:\n            node_to_str = str\n        else:\n            def node_to_str(n):\n                try:\n                    s = n.get_internal_path()\n                except AttributeError:\n                    s = str(n)\n                else:\n                    s = s.replace(OS_SEP, '/')\n                return s\n        for attr in ['bsources', 'bdepends', 'bimplicit']:\n            try:\n                val = getattr(self, attr)\n            except AttributeError:\n                pass\n            else:\n                setattr(self, attr, list(map(node_to_str, val)))", "response": "Converts this FileBuildInfo object to a. sconsign file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare a FileBuildInfo object for explaining what changed .", "response": "def prepare_dependencies(self):\n        \"\"\"\n        Prepares a FileBuildInfo object for explaining what changed\n\n        The bsources, bdepends and bimplicit lists have all been\n        stored on disk as paths relative to the top-level SConstruct\n        directory.  Convert the strings to actual Nodes (for use by the\n        --debug=explain code and --implicit-cache).\n        \"\"\"\n        attrs = [\n            ('bsources', 'bsourcesigs'),\n            ('bdepends', 'bdependsigs'),\n            ('bimplicit', 'bimplicitsigs'),\n        ]\n        for (nattr, sattr) in attrs:\n            try:\n                strings = getattr(self, nattr)\n                nodeinfos = getattr(self, sattr)\n            except AttributeError:\n                continue\n            if strings is None or nodeinfos is None:\n                continue\n            nodes = []\n            for s, ni in zip(strings, nodeinfos):\n                if not isinstance(s, SCons.Node.Node):\n                    s = ni.str_to_node(s)\n                nodes.append(s)\n            setattr(self, nattr, nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a directory node named name relative to the directory of this file.", "response": "def Dir(self, name, create=True):\n        \"\"\"Create a directory node named 'name' relative to\n        the directory of this file.\"\"\"\n        return self.dir.Dir(name, create=create)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning a file system node into a File object.", "response": "def _morph(self):\n        \"\"\"Turn a file system node into a File object.\"\"\"\n        self.scanner_paths = {}\n        if not hasattr(self, '_local'):\n            self._local = 0\n        if not hasattr(self, 'released_target_info'):\n            self.released_target_info = False\n\n        self.store_info = 1\n        self._func_exists = 4\n        self._func_get_contents = 3\n\n        # Initialize this Node's decider function to decide_source() because\n        # every file is a source file until it has a Builder attached...\n        self.changed_since_last_build = 4\n\n        # If there was already a Builder set on this entry, then\n        # we need to make sure we call the target-decider function,\n        # not the source-decider.  Reaching in and doing this by hand\n        # is a little bogus.  We'd prefer to handle this by adding\n        # an Entry.builder_set() method that disambiguates like the\n        # other methods, but that starts running into problems with the\n        # fragile way we initialize Dir Nodes with their Mkdir builders,\n        # yet still allow them to be overridden by the user.  Since it's\n        # not clear right now how to fix that, stick with what works\n        # until it becomes clear...\n        if self.has_builder():\n            self.changed_since_last_build = 5"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes and return the MD5 hash for this file.", "response": "def get_content_hash(self):\n        \"\"\"\n        Compute and return the MD5 hash for this file.\n        \"\"\"\n        if not self.rexists():\n            return SCons.Util.MD5signature('')\n        fname = self.rfile().get_abspath()\n        try:\n            cs = SCons.Util.MD5filesignature(fname,\n                chunksize=SCons.Node.FS.File.md5_chunksize*1024)\n        except EnvironmentError as e:\n            if not e.filename:\n                e.filename = fname\n            raise\n        return cs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the included implicit dependencies in this file. Cache results so we only scan the file once per path", "response": "def get_found_includes(self, env, scanner, path):\n        \"\"\"Return the included implicit dependencies in this file.\n        Cache results so we only scan the file once per path\n        regardless of how many times this information is requested.\n        \"\"\"\n        memo_key = (id(env), id(scanner), path)\n        try:\n            memo_dict = self._memo['get_found_includes']\n        except KeyError:\n            memo_dict = {}\n            self._memo['get_found_includes'] = memo_dict\n        else:\n            try:\n                return memo_dict[memo_key]\n            except KeyError:\n                pass\n\n        if scanner:\n            result = [n.disambiguate() for n in scanner(self, env, path)]\n        else:\n            result = []\n\n        memo_dict[memo_key] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to push the node into a cache.", "response": "def push_to_cache(self):\n        \"\"\"Try to push the node into a cache\n        \"\"\"\n        # This should get called before the Nodes' .built() method is\n        # called, which would clear the build signature if the file has\n        # a source scanner.\n        #\n        # We have to clear the local memoized values *before* we push\n        # the node to cache so that the memoization of the self.exists()\n        # return value doesn't interfere.\n        if self.nocache:\n            return\n        self.clear_memoized_values()\n        if self.exists():\n            self.get_build_env().get_CacheDir().push(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve_from_cache(self):\n        if self.nocache:\n            return None\n        if not self.is_derived():\n            return None\n        return self.get_build_env().get_CacheDir().retrieve(self)", "response": "Try to retrieve the node s content from a cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling just after a build step has been done and is ready to be used to build the target info of this node.", "response": "def release_target_info(self):\n        \"\"\"Called just after this node has been marked\n         up-to-date or was built completely.\n\n         This is where we try to release as many target node infos\n         as possible for clean builds and update runs, in order\n         to minimize the overall memory consumption.\n\n         We'd like to remove a lot more attributes like self.sources\n         and self.sources_set, but they might get used\n         in a next build step. For example, during configuration\n         the source files for a built E{*}.o file are used to figure out\n         which linker to use for the resulting Program (gcc vs. g++)!\n         That's why we check for the 'keep_targetinfo' attribute,\n         config Nodes and the Interactive mode just don't allow\n         an early release of most variables.\n\n         In the same manner, we can't simply remove the self.attributes\n         here. The smart linking relies on the shared flag, and some\n         parts of the java Tool use it to transport information\n         about nodes...\n\n         @see: built() and Node.release_target_info()\n         \"\"\"\n        if (self.released_target_info or SCons.Node.interactive):\n            return\n\n        if not hasattr(self.attributes, 'keep_targetinfo'):\n            # Cache some required values, before releasing\n            # stuff like env, executor and builder...\n            self.changed(allowcache=True)\n            self.get_contents_sig()\n            self.get_build_env()\n            # Now purge unneeded stuff to free memory...\n            self.executor = None\n            self._memo.pop('rfile', None)\n            self.prerequisites = None\n            # Cleanup lists, but only if they're empty\n            if not len(self.ignore_set):\n                self.ignore_set = None\n            if not len(self.implicit_set):\n                self.implicit_set = None\n            if not len(self.depends_set):\n                self.depends_set = None\n            if not len(self.ignore):\n                self.ignore = None\n            if not len(self.depends):\n                self.depends = None\n            # Mark this node as done, we only have to release\n            # the memory once...\n            self.released_target_info = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn whether this Node has a source code builder or not.", "response": "def has_src_builder(self):\n        \"\"\"Return whether this Node has a source builder or not.\n\n        If this Node doesn't have an explicit source code builder, this\n        is where we figure out, on the fly, if there's a transparent\n        source code builder for it.\n\n        Note that if we found a source builder, we also set the\n        self.builder attribute, so that all of the methods that actually\n        *build* this file don't have to do anything different.\n        \"\"\"\n        try:\n            scb = self.sbuilder\n        except AttributeError:\n            scb = self.sbuilder = self.find_src_builder()\n        return scb is not None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning any corresponding targets in a variant directory.", "response": "def alter_targets(self):\n        \"\"\"Return any corresponding targets in a variant directory.\n        \"\"\"\n        if self.is_derived():\n            return [], None\n        return self.fs.variant_dir_target_climb(self, self.dir, [self.name])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare(self):\n        SCons.Node.Node.prepare(self)\n\n        if self.get_state() != SCons.Node.up_to_date:\n            if self.exists():\n                if self.is_derived() and not self.precious:\n                    self._rmv_existing()\n            else:\n                try:\n                    self._createDir()\n                except SCons.Errors.StopError as drive:\n                    raise SCons.Errors.StopError(\"No drive `{}' for target `{}'.\".format(drive, self))", "response": "Prepare for this file to be created."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_max_drift_csig(self):\n        old = self.get_stored_info()\n        mtime = self.get_timestamp()\n\n        max_drift = self.fs.max_drift\n        if max_drift > 0:\n            if (time.time() - mtime) > max_drift:\n                try:\n                    n = old.ninfo\n                    if n.timestamp and n.csig and n.timestamp == mtime:\n                        return n.csig\n                except AttributeError:\n                    pass\n        elif max_drift == 0:\n            try:\n                return old.ninfo.csig\n            except AttributeError:\n                pass\n\n        return None", "response": "Returns the content signature currently stored for this node. Returns None if the node has been unmodified longer than the max_drift value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_csig(self):\n        ninfo = self.get_ninfo()\n        try:\n            return ninfo.csig\n        except AttributeError:\n            pass\n\n        csig = self.get_max_drift_csig()\n        if csig is None:\n\n            try:\n                if self.get_size() < SCons.Node.FS.File.md5_chunksize:\n                    contents = self.get_contents()\n                else:\n                    csig = self.get_content_hash()\n            except IOError:\n                # This can happen if there's actually a directory on-disk,\n                # which can be the case if they've disabled disk checks,\n                # or if an action with a File target actually happens to\n                # create a same-named directory by mistake.\n                csig = ''\n            else:\n                if not csig:\n                    csig = SCons.Util.MD5signature(contents)\n\n        ninfo.csig = csig\n\n        return csig", "response": "Generate a node s content signature the digested signature\n        of its content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall just after this File node is successfully built.", "response": "def built(self):\n        \"\"\"Called just after this File node is successfully built.\n\n         Just like for 'release_target_info' we try to release\n         some more target node attributes in order to minimize the\n         overall memory consumption.\n\n         @see: release_target_info\n        \"\"\"\n\n        SCons.Node.Node.built(self)\n\n        if (not SCons.Node.interactive and\n            not hasattr(self.attributes, 'keep_targetinfo')):\n            # Ensure that the build infos get computed and cached...\n            SCons.Node.store_info_map[self.store_info](self)\n            # ... then release some more variables.\n            self._specific_sources = False\n            self._labspath = None\n            self._save_str()\n            self.cwd = None\n\n            self.scanner_paths = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef changed(self, node=None, allowcache=False):\n        if node is None:\n            try:\n                return self._memo['changed']\n            except KeyError:\n                pass\n\n        has_changed = SCons.Node.Node.changed(self, node)\n        if allowcache:\n            self._memo['changed'] = has_changed\n        return has_changed", "response": "Returns True if the node has been changed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a Node s content signature for purposes of computing another Node s cachesig.", "response": "def get_cachedir_csig(self):\n        \"\"\"\n        Fetch a Node's content signature for purposes of computing\n        another Node's cachesig.\n\n        This is a wrapper around the normal get_csig() method that handles\n        the somewhat obscure case of using CacheDir with the -n option.\n        Any files that don't exist would normally be \"built\" by fetching\n        them from the cache, but the normal get_csig() method will try\n        to open up the local file, which doesn't exist because the -n\n        option meant we didn't actually pull the file from cachedir.\n        But since the file *does* actually exist in the cachedir, we\n        can use its contents for the csig.\n        \"\"\"\n        try:\n            return self.cachedir_csig\n        except AttributeError:\n            pass\n\n        cachedir, cachefile = self.get_build_env().get_CacheDir().cachepath(self)\n        if not self.exists() and cachefile and os.path.exists(cachefile):\n            self.cachedir_csig = SCons.Util.MD5filesignature(cachefile, \\\n                SCons.Node.FS.File.md5_chunksize * 1024)\n        else:\n            self.cachedir_csig = self.get_csig()\n        return self.cachedir_csig"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cachedir_bsig(self):\n        try:\n            return self.cachesig\n        except AttributeError:\n            pass\n\n        # Collect signatures for all children\n        children = self.children()\n        sigs = [n.get_cachedir_csig() for n in children]\n        # Append this node's signature...\n        sigs.append(self.get_contents_sig())\n        # ...and it's path\n        sigs.append(self.get_internal_path())\n        # Merge this all into a single signature\n        result = self.cachesig = SCons.Util.MD5collect(sigs)\n        return result", "response": "Returns the signature for a cached file including its children and appends the path of the file to the signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filedir_lookup(self, p, fd=None):\n        if fd is None:\n            fd = self.default_filedir\n        dir, name = os.path.split(fd)\n        drive, d = _my_splitdrive(dir)\n        if not name and d[:1] in ('/', OS_SEP):\n            #return p.fs.get_root(drive).dir_on_disk(name)\n            return p.fs.get_root(drive)\n        if dir:\n            p = self.filedir_lookup(p, dir)\n            if not p:\n                return None\n        norm_name = _my_normcase(name)\n        try:\n            node = p.entries[norm_name]\n        except KeyError:\n            return p.dir_on_disk(name)\n        if isinstance(node, Dir):\n            return node\n        if isinstance(node, Entry):\n            node.must_be_same(Dir)\n            return node\n        return None", "response": "A helper method for filedir_lookup that looks up a directory for a file we re trying to find."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding a node corresponding to a derived file or a file that exists already.", "response": "def find_file(self, filename, paths, verbose=None):\n        \"\"\"\n        Find a node corresponding to either a derived file or a file that exists already.\n\n        Only the first file found is returned, and none is returned if no file is found.\n\n        filename: A filename to find\n        paths: A list of directory path *nodes* to search in.  Can be represented as a list, a tuple, or a callable that is called with no arguments and returns the list or tuple.\n\n        returns The node created from the found file.\n\n        \"\"\"\n        memo_key = self._find_file_key(filename, paths)\n        try:\n            memo_dict = self._memo['find_file']\n        except KeyError:\n            memo_dict = {}\n            self._memo['find_file'] = memo_dict\n        else:\n            try:\n                return memo_dict[memo_key]\n            except KeyError:\n                pass\n\n        if verbose and not callable(verbose):\n            if not SCons.Util.is_String(verbose):\n                verbose = \"find_file\"\n            _verbose = u'  %s: ' % verbose\n            verbose = lambda s: sys.stdout.write(_verbose + s)\n\n        filedir, filename = os.path.split(filename)\n        if filedir:\n            self.default_filedir = filedir\n            paths = [_f for _f in map(self.filedir_lookup, paths) if _f]\n\n        result = None\n        for dir in paths:\n            if verbose:\n                verbose(\"looking for '%s' in '%s' ...\\n\" % (filename, dir))\n            node, d = dir.srcdir_find_file(filename)\n            if node:\n                if verbose:\n                    verbose(\"... FOUND '%s' in '%s'\\n\" % (filename, d))\n                result = node\n                break\n\n        memo_dict[memo_key] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a BGAPI packet containing a GATT service description and add it to the dictionary of services that is updated with this event", "response": "def process_gatt_service(services, event):\n    \"\"\"Process a BGAPI event containing a GATT service description and add it to a dictionary\n\n    Args:\n        services (dict): A dictionary of discovered services that is updated with this event\n        event (BGAPIPacket): An event containing a GATT service\n\n    \"\"\"\n\n    length = len(event.payload) - 5\n\n    handle, start, end, uuid = unpack('<BHH%ds' % length, event.payload)\n\n    uuid = process_uuid(uuid)\n    services[uuid] = {'uuid_raw': uuid, 'start_handle': start, 'end_handle': end}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the corresponding UUID for an attribute handle", "response": "def handle_to_uuid(handle, services):\n    \"\"\"Find the corresponding UUID for an attribute handle\"\"\"\n\n    for service in services.values():\n        for char_uuid, char_def in service['characteristics'].items():\n            if char_def['handle'] == handle:\n                return char_uuid\n\n    raise ValueError(\"Handle not found in GATT table\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a string to True or False depending on the truth expressed by .", "response": "def _text2bool(val):\n    \"\"\"\n    Converts strings to True/False depending on the 'truth' expressed by\n    the string. If the string can't be converted, the original value\n    will be returned.\n\n    See '__true_strings' and '__false_strings' for values considered\n    'true' or 'false respectively.\n\n    This is usable as 'converter' for SCons' Variables.\n    \"\"\"\n    lval = val.lower()\n    if lval in __true_strings: return True\n    if lval in __false_strings: return False\n    raise ValueError(\"Invalid value for boolean option: %s\" % val)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validator(key, val, env):\n    if not env[key] in (True, False):\n        raise SCons.Errors.UserError(\n            'Invalid value for boolean option %s: %s' % (key, env[key]))", "response": "Validate the value of an option in a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new object from a dictionary with kv pairs.", "response": "def FromDictionary(cls, msg_dict):\n        \"\"\"Create from a dictionary with kv pairs.\n\n        Args:\n            msg_dict (dict): A dictionary with information as created by to_dict()\n\n        Returns:\n            ServiceMessage: the converted message\n        \"\"\"\n\n        level = msg_dict.get('level')\n        msg = msg_dict.get('message')\n        now = msg_dict.get('now_time')\n        created = msg_dict.get('created_time')\n        count = msg_dict.get('count', 1)\n        msg_id = msg_dict.get('id', 0)\n\n        new_msg = ServiceMessage(level, msg, msg_id, created, now)\n        if count > 1:\n            new_msg.count = count\n\n        return new_msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_dict(self):\n\n        msg_dict = {}\n        msg_dict['level'] = self.level\n        msg_dict['message'] = self.message\n        msg_dict['now_time'] = monotonic()\n        msg_dict['created_time'] = self.created\n        msg_dict['id'] = self.id\n        msg_dict['count'] = self.count\n\n        return msg_dict", "response": "Create a dictionary with the information in this message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_message(self, message_id):\n\n        for message in self.messages:\n            if message.id == message_id:\n                return message\n\n        raise ArgumentError(\"Message ID not found\", message_id=message_id)", "response": "Get a message by its persistent id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npost a new message to the service.", "response": "def post_message(self, level, message, count=1, timestamp=None, now_reference=None):\n        \"\"\"Post a new message for service.\n\n        Args:\n            level (int): The level of the message (info, warning, error)\n            message (string): The message contents\n            count (int): The number of times the message has been repeated\n            timestamp (float): An optional monotonic value in seconds for when the message was created\n            now_reference (float): If timestamp is not relative to monotonic() as called from this\n                module then this should be now() as seen by whoever created the timestamp.\n\n        Returns:\n            ServiceMessage: The posted message\n        \"\"\"\n\n        if len(self.messages) > 0 and self.messages[-1].message == message:\n            self.messages[-1].count += 1\n        else:\n            msg_object = ServiceMessage(level, message, self._last_message_id, timestamp, now_reference)\n            msg_object.count = count\n            self.messages.append(msg_object)\n            self._last_message_id += 1\n\n        return self.messages[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the persistent headline message for this service.", "response": "def set_headline(self, level, message, timestamp=None, now_reference=None):\n        \"\"\"Set the persistent headline message for this service.\n\n        Args:\n            level (int): The level of the message (info, warning, error)\n            message (string): The message contents\n            timestamp (float): An optional monotonic value in seconds for when the message was created\n            now_reference (float): If timestamp is not relative to monotonic() as called from this\n                module then this should be now() as seen by whoever created the timestamp.\n        \"\"\"\n\n        if self.headline is not None and self.headline.message == message:\n            self.headline.created = monotonic()\n            self.headline.count += 1\n            return\n\n        msg_object = ServiceMessage(level, message, self._last_message_id, timestamp, now_reference)\n        self.headline = msg_object\n        self._last_message_id += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a default doxygen template file", "response": "def generate_doxygen_file(output_path, iotile):\n    \"\"\"Fill in our default doxygen template file with info from an IOTile\n\n    This populates things like name, version, etc.\n\n    Arguments:\n        output_path (str):  a string path for where the filled template should go\n        iotile (IOTile): An IOTile object that can be queried for information\n    \"\"\"\n\n    mapping = {}\n\n    mapping['short_name'] = iotile.short_name\n    mapping['full_name'] = iotile.full_name\n    mapping['authors'] = iotile.authors\n    mapping['version'] = iotile.version\n\n    render_template('doxygen.txt.tpl', mapping, out_path=output_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npulling a release IOTile component into the current working directory.", "response": "def pull(name, version, force=False):\n    \"\"\"Pull a released IOTile component into the current working directory\n\n    The component is found using whatever DependencyResolvers are installed and registered\n    as part of the default DependencyResolverChain.  This is the same mechanism used in\n    iotile depends update, so any component that can be updated using iotile depends update\n    can be found and pulled using this method.\n    \"\"\"\n\n    chain = DependencyResolverChain()\n\n    ver = SemanticVersionRange.FromString(version)\n    chain.pull_release(name, ver, force=force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a callback to be called when device events happen.", "response": "def add_callback(self, name, func):\n        \"\"\"Add a callback when device events happen.\n\n        Args:\n            name (str): currently support 'on_scan' and 'on_disconnect'\n            func (callable): the function that should be called\n        \"\"\"\n\n        if name == 'on_scan':\n            events = ['device_seen']\n            def callback(_conn_string, _conn_id, _name, event):\n                func(self.id, event, event.get('validity_period', 60))\n        elif name == 'on_report':\n            events = ['report', 'broadcast']\n            def callback(_conn_string, conn_id, _name, event):\n                func(conn_id, event)\n        elif name == 'on_trace':\n            events = ['trace']\n            def callback(_conn_string, conn_id, _name, event):\n                func(conn_id, event)\n        elif name == 'on_disconnect':\n            events = ['disconnection']\n            def callback(_conn_string, conn_id, _name, _event):\n                func(self.id, conn_id)\n        else:\n            raise ArgumentError(\"Unknown callback type {}\".format(name))\n\n        self._adapter.register_monitor([None], events, callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disconnect_async(self, conn_id, callback):\n\n        future = self._loop.launch_coroutine(self._adapter.disconnect(conn_id))\n        future.add_done_callback(lambda x: self._callback_future(conn_id, x, callback))", "response": "Asynchronously disconnect from a device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef probe_async(self, callback):\n\n        future = self._loop.launch_coroutine(self._adapter.probe())\n        future.add_done_callback(lambda x: self._callback_future(None, x, callback))", "response": "Asynchronously connect to a device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef debug_async(self, conn_id, cmd_name, cmd_args, progress_callback, callback):\n\n        def monitor_callback(_conn_string, _conn_id, _event_name, event):\n            if event.get('operation') != 'debug':\n                return\n\n            progress_callback(event.get('finished'), event.get('total'))\n\n        async def _install_monitor():\n            try:\n                conn_string = self._adapter._get_property(conn_id, 'connection_string')\n                return self._adapter.register_monitor([conn_string], ['progress'], monitor_callback)\n            except:  #pylint:disable=bare-except;This is a legacy shim that must always ensure it doesn't raise.\n                self._logger.exception(\"Error installing debug progress monitor\")\n                return None\n\n        monitor_id = self._loop.run_coroutine(_install_monitor())\n        if monitor_id is None:\n            callback(conn_id, self.id, False, 'could not install progress monitor', None)\n            return\n\n        future = self._loop.launch_coroutine(self._adapter.debug(conn_id, cmd_name, cmd_args))\n\n        def format_response(future):\n            ret_val = None\n            success = True\n            failure = None\n            if future.exception() is None:\n                ret_val = future.result()\n            else:\n                success = False\n                failure = str(future.exception())\n\n            self._adapter.remove_monitor(monitor_id)\n            callback(conn_id, self.id, success, ret_val, failure)\n\n        future.add_done_callback(format_response)", "response": "Asynchronously invoke a debug command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lock(self, key, client):\n\n        self.key = key\n        self.client = client", "response": "Set the key that will be used to validate future messages from one party\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef track_change(self, tile, property_name, value, formatter=None):\n\n        if not self.tracking:\n            return\n\n        if len(self._whitelist) > 0 and (tile, property_name) not in self._whitelist:\n            return\n\n        if formatter is None:\n            formatter = str\n\n        change = StateChange(monotonic(), tile, property_name, value, formatter(value))\n\n        with self._lock:\n            self.changes.append(change)", "response": "Record that a change happened on a given tile s property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves this list of changes as a csv file at out_path.", "response": "def dump(self, out_path, header=True):\n        \"\"\"Save this list of changes as a csv file at out_path.\n\n        The format of the output file will be a CSV with 4 columns:\n        timestamp, tile address, property, string_value\n\n        There will be a single header row starting the CSV output unless\n        header=False is passed.\n\n        Args:\n            out_path (str): The path where we should save our current list of\n                changes.\n            header (bool): Whether we should include a header row in the csv\n                file.  Defaults to True.\n        \"\"\"\n\n        # See https://stackoverflow.com/a/3348664/9739119 for why this is necessary\n        if sys.version_info[0] < 3:\n            mode = \"wb\"\n        else:\n            mode = \"w\"\n\n        with open(out_path, mode) as outfile:\n            writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n            if header:\n                writer.writerow([\"Timestamp\", \"Tile Address\", \"Property Name\", \"Value\"])\n\n            for entry in self.changes:\n                writer.writerow([entry.time, entry.tile, entry.property, entry.string_value])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PDFTeXLaTeXFunction(target = None, source= None, env=None):\n    basedir = os.path.split(str(source[0]))[0]\n    abspath = os.path.abspath(basedir)\n\n    if SCons.Tool.tex.is_LaTeX(source,env,abspath):\n        result = PDFLaTeXAuxAction(target,source,env)\n        if result != 0:\n            SCons.Tool.tex.check_file_error_message(env['PDFLATEX'])\n    else:\n        result = PDFTeXAction(target,source,env)\n        if result != 0:\n            SCons.Tool.tex.check_file_error_message(env['PDFTEX'])\n    return result", "response": "A builder for TeX and LaTeX that scans the source file to\n    decide the flavor of the source and then executes the appropriate PDFTeXAction program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(env):\n    global PDFTeXAction\n    if PDFTeXAction is None:\n        PDFTeXAction = SCons.Action.Action('$PDFTEXCOM', '$PDFTEXCOMSTR')\n\n    global PDFLaTeXAction\n    if PDFLaTeXAction is None:\n        PDFLaTeXAction = SCons.Action.Action(\"$PDFLATEXCOM\", \"$PDFLATEXCOMSTR\")\n\n    global PDFTeXLaTeXAction\n    if PDFTeXLaTeXAction is None:\n        PDFTeXLaTeXAction = SCons.Action.Action(PDFTeXLaTeXFunction,\n                              strfunction=SCons.Tool.tex.TeXLaTeXStrFunction)\n\n    env.AppendUnique(LATEXSUFFIXES=SCons.Tool.LaTeXSuffixes)\n\n    from . import pdf\n    pdf.generate(env)\n\n    bld = env['BUILDERS']['PDF']\n    bld.add_action('.tex', PDFTeXLaTeXAction)\n    bld.add_emitter('.tex', SCons.Tool.tex.tex_pdf_emitter)\n\n    # Add the epstopdf builder after the pdftex builder \n    # so pdftex is the default for no source suffix\n    pdf.generate2(env)\n\n    SCons.Tool.tex.generate_common(env)", "response": "Add Builders and construction variables for pdftex to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting running this virtual device including any necessary worker threads.", "response": "def start(self, channel):\n        \"\"\"Start running this virtual device including any necessary worker threads.\n\n        Args:\n            channel (IOTilePushChannel): the channel with a stream and trace\n                routine for streaming and tracing data through a VirtualInterface\n        \"\"\"\n\n        super(TileBasedVirtualDevice, self).start(channel)\n\n        for tile in self._tiles.values():\n            tile.start(channel=channel)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop running this virtual device including any worker threads.", "response": "def stop(self):\n        \"\"\"Stop running this virtual device including any worker threads.\"\"\"\n\n        for tile in self._tiles.values():\n            tile.signal_stop()\n\n        for tile in self._tiles.values():\n            tile.wait_stopped()\n\n        super(TileBasedVirtualDevice, self).stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SetCacheMode(mode):\n    global cache_mode\n    if mode == \"auto\":\n        cache_mode = AUTO\n    elif mode == \"force\":\n        cache_mode = FORCE\n    elif mode == \"cache\":\n        cache_mode = CACHE\n    else:\n        raise ValueError(\"SCons.SConf.SetCacheMode: Unknown mode \" + mode)", "response": "Sets the Configure cache mode. mode must be one of auto force or cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef CreateConfigHBuilder(env):\n    action = SCons.Action.Action(_createConfigH,\n                                 _stringConfigH)\n    sconfigHBld = SCons.Builder.Builder(action=action)\n    env.Append( BUILDERS={'SConfigHBuilder':sconfigHBld} )\n    for k in list(_ac_config_hs.keys()):\n        env.SConfigHBuilder(k, env.Value(_ac_config_hs[k]))", "response": "Called if necessary just before the building targets phase begins."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CheckLib(context, library = None, symbol = \"main\",\n             header = None, language = None, autoadd = 1):\n    \"\"\"\n    A test for a library. See also CheckLibWithHeader.\n    Note that library may also be None to test whether the given symbol\n    compiles without flags.\n    \"\"\"\n\n    if library == []:\n        library = [None]\n\n    if not SCons.Util.is_List(library):\n        library = [library]\n\n    # ToDo: accept path for the library\n    res = SCons.Conftest.CheckLib(context, library, symbol, header = header,\n                                        language = language, autoadd = autoadd)\n    context.did_show_result = 1\n    return not res", "response": "A test for a library."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a library and header is available for a given language.", "response": "def CheckLibWithHeader(context, libs, header, language,\n                       call = None, autoadd = 1):\n    # ToDo: accept path for library. Support system header files.\n    \"\"\"\n    Another (more sophisticated) test for a library.\n    Checks, if library and header is available for language (may be 'C'\n    or 'CXX'). Call maybe be a valid expression _with_ a trailing ';'.\n    As in CheckLib, we support library=None, to test if the call compiles\n    without extra link flags.\n    \"\"\"\n    prog_prefix, dummy = \\\n                 createIncludesFromHeaders(header, 0)\n    if libs == []:\n        libs = [None]\n\n    if not SCons.Util.is_List(libs):\n        libs = [libs]\n\n    res = SCons.Conftest.CheckLib(context, libs, None, prog_prefix,\n            call = call, language = language, autoadd = autoadd)\n    context.did_show_result = 1\n    return not res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CheckProg(context, prog_name):\n    res = SCons.Conftest.CheckProg(context, prog_name)\n    context.did_show_result = 1\n    return res", "response": "Simple check if a program exists in the path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog the original builder messages given the SConfBuildInfo instance bi.", "response": "def display_cached_string(self, bi):\n        \"\"\"\n        Logs the original builder messages, given the SConfBuildInfo instance\n        bi.\n        \"\"\"\n        if not isinstance(bi, SConfBuildInfo):\n            SCons.Warnings.warn(SConfWarning,\n              \"The stored build information has an unexpected class: %s\" % bi.__class__)\n        else:\n            self.display(\"The original builder output was:\\n\" +\n                         (\"  |\" + str(bi.string)).replace(\"\\n\", \"\\n  |\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines a pre processor symbol name with the optional given value in the current config header.", "response": "def Define(self, name, value = None, comment = None):\n        \"\"\"\n        Define a pre processor symbol name, with the optional given value in the\n        current config header.\n\n        If value is None (default), then #define name is written. If value is not\n        none, then #define name value is written.\n\n        comment is a string which will be put as a C comment in the header, to explain the meaning of the value\n        (appropriate C comments will be added automatically).\n        \"\"\"\n        lines = []\n        if comment:\n            comment_str = \"/* %s */\" % comment\n            lines.append(comment_str)\n\n        if value is not None:\n            define_str = \"#define %s %s\" % (name, value)\n        else:\n            define_str = \"#define %s\" % name\n        lines.append(define_str)\n        lines.append('')\n\n        self.config_h_text = self.config_h_text + '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the given nodes. Returns 1 on success 0 on error.", "response": "def BuildNodes(self, nodes):\n        \"\"\"\n        Tries to build the given nodes immediately. Returns 1 on success,\n        0 on error.\n        \"\"\"\n        if self.logstream is not None:\n            # override stdout / stderr to write in log file\n            oldStdout = sys.stdout\n            sys.stdout = self.logstream\n            oldStderr = sys.stderr\n            sys.stderr = self.logstream\n\n        # the engine assumes the current path is the SConstruct directory ...\n        old_fs_dir = SConfFS.getcwd()\n        old_os_dir = os.getcwd()\n        SConfFS.chdir(SConfFS.Top, change_os_dir=1)\n\n        # Because we take responsibility here for writing out our\n        # own .sconsign info (see SConfBuildTask.execute(), above),\n        # we override the store_info() method with a null place-holder\n        # so we really control how it gets written.\n        for n in nodes:\n            n.store_info = 0\n            if not hasattr(n, 'attributes'):\n                n.attributes = SCons.Node.Node.Attrs()\n            n.attributes.keep_targetinfo = 1\n\n        ret = 1\n\n        try:\n            # ToDo: use user options for calc\n            save_max_drift = SConfFS.get_max_drift()\n            SConfFS.set_max_drift(0)\n            tm = SCons.Taskmaster.Taskmaster(nodes, SConfBuildTask)\n            # we don't want to build tests in parallel\n            jobs = SCons.Job.Jobs(1, tm )\n            jobs.run()\n            for n in nodes:\n                state = n.get_state()\n                if (state != SCons.Node.executed and\n                    state != SCons.Node.up_to_date):\n                    # the node could not be built. we return 0 in this case\n                    ret = 0\n        finally:\n            SConfFS.set_max_drift(save_max_drift)\n            os.chdir(old_os_dir)\n            SConfFS.chdir(old_fs_dir, change_os_dir=0)\n            if self.logstream is not None:\n                # restore stdout / stderr\n                sys.stdout = oldStdout\n                sys.stderr = oldStderr\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pspawn_wrapper(self, sh, escape, cmd, args, env):\n        return self.pspawn(sh, escape, cmd, args, env, self.logstream, self.logstream)", "response": "Wrapper function for handling piped spawns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlowing level TryBuild implementation.", "response": "def TryBuild(self, builder, text = None, extension = \"\"):\n        \"\"\"Low level TryBuild implementation. Normally you don't need to\n        call that - you can use TryCompile / TryLink / TryRun instead\n        \"\"\"\n        global _ac_build_counter\n\n        # Make sure we have a PSPAWN value, and save the current\n        # SPAWN value.\n        try:\n            self.pspawn = self.env['PSPAWN']\n        except KeyError:\n            raise SCons.Errors.UserError('Missing PSPAWN construction variable.')\n        try:\n            save_spawn = self.env['SPAWN']\n        except KeyError:\n            raise SCons.Errors.UserError('Missing SPAWN construction variable.')\n\n        nodesToBeBuilt = []\n\n        f = \"conftest_\" + str(_ac_build_counter)\n        pref = self.env.subst( builder.builder.prefix )\n        suff = self.env.subst( builder.builder.suffix )\n        target = self.confdir.File(pref + f + suff)\n\n        try:\n            # Slide our wrapper into the construction environment as\n            # the SPAWN function.\n            self.env['SPAWN'] = self.pspawn_wrapper\n            sourcetext = self.env.Value(text)\n\n            if text is not None:\n                textFile = self.confdir.File(f + extension)\n                textFileNode = self.env.SConfSourceBuilder(target=textFile,\n                                                           source=sourcetext)\n                nodesToBeBuilt.extend(textFileNode)\n                source = textFileNode\n            else:\n                source = None\n\n            nodes = builder(target = target, source = source)\n            if not SCons.Util.is_List(nodes):\n                nodes = [nodes]\n            nodesToBeBuilt.extend(nodes)\n            result = self.BuildNodes(nodesToBeBuilt)\n\n        finally:\n            self.env['SPAWN'] = save_spawn\n\n        _ac_build_counter = _ac_build_counter + 1\n        if result:\n            self.lastTarget = nodes[0]\n        else:\n            self.lastTarget = None\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to execute the given action with optional source file contents and optional source file extension", "response": "def TryAction(self, action, text = None, extension = \"\"):\n        \"\"\"Tries to execute the given action with optional source file\n        contents <text> and optional source file extension <extension>,\n        Returns the status (0 : failed, 1 : ok) and the contents of the\n        output file.\n        \"\"\"\n        builder = SCons.Builder.Builder(action=action)\n        self.env.Append( BUILDERS = {'SConfActionBuilder' : builder} )\n        ok = self.TryBuild(self.env.SConfActionBuilder, text, extension)\n        del self.env['BUILDERS']['SConfActionBuilder']\n        if ok:\n            outputStr = self.lastTarget.get_contents().decode()\n            return (1, outputStr)\n        return (0, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompiles the program given in text using the given extension as file extension. Returns 1 if compilation was successful 0 otherwise.", "response": "def TryCompile( self, text, extension):\n        \"\"\"Compiles the program given in text to an env.Object, using extension\n        as file extension (e.g. '.c'). Returns 1, if compilation was\n        successful, 0 otherwise. The target is saved in self.lastTarget (for\n        further processing).\n        \"\"\"\n        return self.TryBuild(self.env.Object, text, extension)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompile the program given in text to an executable env. Program and returns 1 if the compilation was successful 0 otherwise.", "response": "def TryLink( self, text, extension ):\n        \"\"\"Compiles the program given in text to an executable env.Program,\n        using extension as file extension (e.g. '.c'). Returns 1, if\n        compilation was successful, 0 otherwise. The target is saved in\n        self.lastTarget (for further processing).\n        \"\"\"\n        return self.TryBuild(self.env.Program, text, extension )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef TryRun(self, text, extension ):\n        ok = self.TryLink(text, extension)\n        if( ok ):\n            prog = self.lastTarget\n            pname = prog.get_internal_path()\n            output = self.confdir.File(os.path.basename(pname)+'.out')\n            node = self.env.Command(output, prog, [ [ pname, \">\", \"${TARGET}\"] ])\n            ok = self.BuildNodes(node)\n            if ok:\n                outputStr = SCons.Util.to_str(output.get_contents())\n                return( 1, outputStr)\n        return (0, \"\")", "response": "Compiles and runs the program given in text using the given extension. Returns 0 on success and outputStr on failure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _shutdown(self):\n        global sconf_global, _ac_config_hs\n\n        if not self.active:\n            raise SCons.Errors.UserError(\"Finish may be called only once!\")\n        if self.logstream is not None and not dryrun:\n            self.logstream.write(\"\\n\")\n            self.logstream.close()\n            self.logstream = None\n        # remove the SConfSourceBuilder from the environment\n        blds = self.env['BUILDERS']\n        del blds['SConfSourceBuilder']\n        self.env.Replace( BUILDERS=blds )\n        self.active = 0\n        sconf_global = None\n        if not self.config_h is None:\n            _ac_config_hs[self.config_h] = self.config_h_text\n        self.env.fs = self.lastEnvFs", "response": "Private method to reset the state of the current process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Message(self, text):\n        self.Display(text)\n        self.sconf.cached = 1\n        self.did_show_result = 0", "response": "Inform about what we are doing SOMETHING..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Result(self, res):\n        if isinstance(res, str):\n            text = res\n        elif res:\n            text = \"yes\"\n        else:\n            text = \"no\"\n\n        if self.did_show_result == 0:\n            # Didn't show result yet, do it now.\n            self.Display(text + \"\\n\")\n            self.did_show_result = 1", "response": "Display the result of the test."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing a Linux compiler version number.", "response": "def linux_ver_normalize(vstr):\n    \"\"\"Normalize a Linux compiler version number.\n    Intel changed from \"80\" to \"9.0\" in 2005, so we assume if the number\n    is greater than 60 it's an old-style number and otherwise new-style.\n    Always returns an old-style float like 80 or 90 for compatibility with Windows.\n    Shades of Y2K!\"\"\"\n    # Check for version number like 9.1.026: return 91.026\n    # XXX needs to be updated for 2011+ versions (like 2011.11.344 which is compiler v12.1.5)\n    m = re.match(r'([0-9]+)\\.([0-9]+)\\.([0-9]+)', vstr)\n    if m:\n        vmaj,vmin,build = m.groups()\n        return float(vmaj) * 10. + float(vmin) + float(build) / 1000.;\n    else:\n        f = float(vstr)\n        if is_windows:\n            return f\n        else:\n            if f < 60: return f * 10.0\n            else: return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_abi(abi):\n    if not abi:\n        return None\n    abi = abi.lower()\n    # valid_abis maps input name to canonical name\n    if is_windows:\n        valid_abis = {'ia32'  : 'ia32',\n                      'x86'   : 'ia32',\n                      'ia64'  : 'ia64',\n                      'em64t' : 'em64t',\n                      'amd64' : 'em64t'}\n    if is_linux:\n        valid_abis = {'ia32'   : 'ia32',\n                      'x86'    : 'ia32',\n                      'x86_64' : 'x86_64',\n                      'em64t'  : 'x86_64',\n                      'amd64'  : 'x86_64'}\n    if is_mac:\n        valid_abis = {'ia32'   : 'ia32',\n                      'x86'    : 'ia32',\n                      'x86_64' : 'x86_64',\n                      'em64t'  : 'x86_64'}\n    try:\n        abi = valid_abis[abi]\n    except KeyError:\n        raise SCons.Errors.UserError(\"Intel compiler: Invalid ABI %s, valid values are %s\"% \\\n              (abi, list(valid_abis.keys())))\n    return abi", "response": "Check for valid ABI name and map into canonical one"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the version number of the given version number in the given list of strings.", "response": "def get_version_from_list(v, vlist):\n    \"\"\"See if we can match v (string) in vlist (list of strings)\n    Linux has to match in a fuzzy way.\"\"\"\n    if is_windows:\n        # Simple case, just find it in the list\n        if v in vlist: return v\n        else: return None\n    else:\n        # Fuzzy match: normalize version number first, but still return\n        # original non-normalized form.\n        fuzz = 0.001\n        for vi in vlist:\n            if math.fabs(linux_ver_normalize(vi) - linux_ver_normalize(v)) < fuzz:\n                return vi\n        # Not found\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a value from the Intel compiler registry tree.", "response": "def get_intel_registry_value(valuename, version=None, abi=None):\n    \"\"\"\n    Return a value from the Intel compiler registry tree. (Windows only)\n    \"\"\"\n    # Open the key:\n    if is_win64:\n        K = 'Software\\\\Wow6432Node\\\\Intel\\\\Compilers\\\\C++\\\\' + version + '\\\\'+abi.upper()\n    else:\n        K = 'Software\\\\Intel\\\\Compilers\\\\C++\\\\' + version + '\\\\'+abi.upper()\n    try:\n        k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, K)\n    except SCons.Util.RegError:\n        # For version 13 and later, check UUID subkeys for valuename\n        if is_win64:\n            K = 'Software\\\\Wow6432Node\\\\Intel\\\\Suites\\\\' + version + \"\\\\Defaults\\\\C++\\\\\" + abi.upper()\n        else:\n            K = 'Software\\\\Intel\\\\Suites\\\\' + version + \"\\\\Defaults\\\\C++\\\\\" + abi.upper()\n        try:\n            k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, K)\n            uuid = SCons.Util.RegQueryValueEx(k, 'SubKey')[0]\n\n            if is_win64:\n                K = 'Software\\\\Wow6432Node\\\\Intel\\\\Suites\\\\' + version + \"\\\\\" + uuid + \"\\\\C++\"\n            else:\n                K = 'Software\\\\Intel\\\\Suites\\\\' + version + \"\\\\\" + uuid + \"\\\\C++\"\n            k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, K)\n\n            try:\n                v = SCons.Util.RegQueryValueEx(k, valuename)[0]\n                return v  # or v.encode('iso-8859-1', 'replace') to remove unicode?\n            except SCons.Util.RegError:\n                if abi.upper() == 'EM64T':\n                    abi = 'em64t_native'\n                if is_win64:\n                    K = 'Software\\\\Wow6432Node\\\\Intel\\\\Suites\\\\' + version + \"\\\\\" + uuid + \"\\\\C++\\\\\" + abi.upper()\n                else:\n                    K = 'Software\\\\Intel\\\\Suites\\\\' + version + \"\\\\\" + uuid + \"\\\\C++\\\\\" + abi.upper()\n                k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, K)\n\n            try:\n                v = SCons.Util.RegQueryValueEx(k, valuename)[0]\n                return v  # or v.encode('iso-8859-1', 'replace') to remove unicode?\n            except SCons.Util.RegError:\n                raise MissingRegistryError(\"%s was not found in the registry, for Intel compiler version %s, abi='%s'\"%(K, version,abi))\n\n        except SCons.Util.RegError:\n            raise MissingRegistryError(\"%s was not found in the registry, for Intel compiler version %s, abi='%s'\"%(K, version,abi))\n        except SCons.Util.WinError:\n            raise MissingRegistryError(\"%s was not found in the registry, for Intel compiler version %s, abi='%s'\"%(K, version,abi))\n\n    # Get the value:\n    try:\n        v = SCons.Util.RegQueryValueEx(k, valuename)[0]\n        return v  # or v.encode('iso-8859-1', 'replace') to remove unicode?\n    except SCons.Util.RegError:\n        raise MissingRegistryError(\"%s\\\\%s was not found in the registry.\"%(K, valuename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_compiler_versions():\n    versions=[]\n    if is_windows:\n        if is_win64:\n            keyname = 'Software\\\\WoW6432Node\\\\Intel\\\\Compilers\\\\C++'\n        else:\n            keyname = 'Software\\\\Intel\\\\Compilers\\\\C++'\n        try:\n            k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE,\n                                        keyname)\n        except SCons.Util.WinError:\n            # For version 13 or later, check for default instance UUID\n            if is_win64:\n                keyname = 'Software\\\\WoW6432Node\\\\Intel\\\\Suites'\n            else:\n                keyname = 'Software\\\\Intel\\\\Suites'\n            try:\n                k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE,\n                                            keyname)\n            except SCons.Util.WinError:\n                return []\n        i = 0\n        versions = []\n        try:\n            while i < 100:\n                subkey = SCons.Util.RegEnumKey(k, i) # raises EnvironmentError\n                # Check that this refers to an existing dir.\n                # This is not 100% perfect but should catch common\n                # installation issues like when the compiler was installed\n                # and then the install directory deleted or moved (rather\n                # than uninstalling properly), so the registry values\n                # are still there.\n                if subkey == 'Defaults': # Ignore default instances\n                    i = i + 1\n                    continue\n                ok = False\n                for try_abi in ('IA32', 'IA32e',  'IA64', 'EM64T'):\n                    try:\n                        d = get_intel_registry_value('ProductDir', subkey, try_abi)\n                    except MissingRegistryError:\n                        continue  # not found in reg, keep going\n                    if os.path.exists(d): ok = True\n                if ok:\n                    versions.append(subkey)\n                else:\n                    try:\n                        # Registry points to nonexistent dir.  Ignore this\n                        # version.\n                        value = get_intel_registry_value('ProductDir', subkey, 'IA32')\n                    except MissingRegistryError as e:\n\n                        # Registry key is left dangling (potentially\n                        # after uninstalling).\n\n                        print(\"scons: *** Ignoring the registry key for the Intel compiler version %s.\\n\" \\\n                            \"scons: *** It seems that the compiler was uninstalled and that the registry\\n\" \\\n                            \"scons: *** was not cleaned up properly.\\n\" % subkey)\n                    else:\n                        print(\"scons: *** Ignoring \"+str(value))\n\n                i = i + 1\n        except EnvironmentError:\n            # no more subkeys\n            pass\n    elif is_linux or is_mac:\n        for d in glob.glob('/opt/intel_cc_*'):\n            # Typical dir here is /opt/intel_cc_80.\n            m = re.search(r'cc_(.*)$', d)\n            if m:\n                versions.append(m.group(1))\n        for d in glob.glob('/opt/intel/cc*/*'):\n            # Typical dir here is /opt/intel/cc/9.0 for IA32,\n            # /opt/intel/cce/9.0 for EMT64 (AMD64)\n            m = re.search(r'([0-9][0-9.]*)$', d)\n            if m:\n                versions.append(m.group(1))\n        for d in glob.glob('/opt/intel/Compiler/*'):\n            # Typical dir here is /opt/intel/Compiler/11.1\n            m = re.search(r'([0-9][0-9.]*)$', d)\n            if m:\n                versions.append(m.group(1))\n        for d in glob.glob('/opt/intel/composerxe-*'):\n            # Typical dir here is /opt/intel/composerxe-2011.4.184\n            m = re.search(r'([0-9][0-9.]*)$', d)\n            if m:\n                versions.append(m.group(1))\n        for d in glob.glob('/opt/intel/composer_xe_*'):\n            # Typical dir here is /opt/intel/composer_xe_2011_sp1.11.344\n            # The _sp1 is useless, the installers are named 2011.9.x, 2011.10.x, 2011.11.x\n            m = re.search(r'([0-9]{0,4})(?:_sp\\d*)?\\.([0-9][0-9.]*)$', d)\n            if m:\n                versions.append(\"%s.%s\"%(m.group(1), m.group(2)))\n        for d in glob.glob('/opt/intel/compilers_and_libraries_*'):\n            # JPA: For the new version of Intel compiler 2016.1.\n            m = re.search(r'([0-9]{0,4})(?:_sp\\d*)?\\.([0-9][0-9.]*)$', d)\n            if m:\n                versions.append(\"%s.%s\"%(m.group(1), m.group(2)))\n            \n    def keyfunc(str):\n        \"\"\"Given a dot-separated version string, return a tuple of ints representing it.\"\"\"\n        return [int(x) for x in str.split('.')]\n    # split into ints, sort, then remove dups\n    return sorted(SCons.Util.unique(versions), key=keyfunc, reverse=True)", "response": "Returns a list of strings like 70 80 or 9. 0 or a list of strings like 80 or 9. 0 or a list of strings like 70 80 or 9. 0 or a list of strings like 70 80 or 9. 0 or a list of strings like 80 or 9. 0 or a list of strings like 70 80 or 9. 0 or a list of strings like 70 80 or 9. 0 or a list of strings like 80 or 9. 0 or a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_intel_compiler_top(version, abi):\n\n    if is_windows:\n        if not SCons.Util.can_read_reg:\n            raise NoRegistryModuleError(\"No Windows registry module was found\")\n        top = get_intel_registry_value('ProductDir', version, abi)\n        archdir={'x86_64': 'intel64',\n                 'amd64' : 'intel64',\n                 'em64t' : 'intel64',\n                 'x86'   : 'ia32',\n                 'i386'  : 'ia32',\n                 'ia32'  : 'ia32'\n        }[abi] # for v11 and greater\n        # pre-11, icl was in Bin.  11 and later, it's in Bin/<abi> apparently.\n        if not os.path.exists(os.path.join(top, \"Bin\", \"icl.exe\")) \\\n              and not os.path.exists(os.path.join(top, \"Bin\", abi, \"icl.exe\")) \\\n              and not os.path.exists(os.path.join(top, \"Bin\", archdir, \"icl.exe\")):\n            raise MissingDirError(\"Can't find Intel compiler in %s\"%(top))\n    elif is_mac or is_linux:\n        def find_in_2008style_dir(version):\n            # first dir is new (>=9.0) style, second is old (8.0) style.\n            dirs=('/opt/intel/cc/%s', '/opt/intel_cc_%s')\n            if abi == 'x86_64':\n                dirs=('/opt/intel/cce/%s',)  # 'e' stands for 'em64t', aka x86_64 aka amd64\n            top=None\n            for d in dirs:\n                if os.path.exists(os.path.join(d%version, \"bin\", \"icc\")):\n                    top = d%version\n                    break\n            return top\n        def find_in_2010style_dir(version):\n            dirs=('/opt/intel/Compiler/%s/*'%version)\n            # typically /opt/intel/Compiler/11.1/064 (then bin/intel64/icc)\n            dirs=glob.glob(dirs)\n            # find highest sub-version number by reverse sorting and picking first existing one.\n            dirs.sort()\n            dirs.reverse()\n            top=None\n            for d in dirs:\n                if (os.path.exists(os.path.join(d, \"bin\", \"ia32\", \"icc\")) or\n                    os.path.exists(os.path.join(d, \"bin\", \"intel64\", \"icc\"))):\n                    top = d\n                    break\n            return top\n        def find_in_2011style_dir(version):\n            # The 2011 (compiler v12) dirs are inconsistent, so just redo the search from\n            # get_all_compiler_versions and look for a match (search the newest form first)\n            top=None\n            for d in glob.glob('/opt/intel/composer_xe_*'):\n                # Typical dir here is /opt/intel/composer_xe_2011_sp1.11.344\n                # The _sp1 is useless, the installers are named 2011.9.x, 2011.10.x, 2011.11.x\n                m = re.search(r'([0-9]{0,4})(?:_sp\\d*)?\\.([0-9][0-9.]*)$', d)\n                if m:\n                    cur_ver = \"%s.%s\"%(m.group(1), m.group(2))\n                    if cur_ver == version and \\\n                        (os.path.exists(os.path.join(d, \"bin\", \"ia32\", \"icc\")) or\n                        os.path.exists(os.path.join(d, \"bin\", \"intel64\", \"icc\"))):\n                        top = d\n                        break\n            if not top:\n                for d in glob.glob('/opt/intel/composerxe-*'):\n                    # Typical dir here is /opt/intel/composerxe-2011.4.184\n                    m = re.search(r'([0-9][0-9.]*)$', d)\n                    if m and m.group(1) == version and \\\n                        (os.path.exists(os.path.join(d, \"bin\", \"ia32\", \"icc\")) or\n                        os.path.exists(os.path.join(d, \"bin\", \"intel64\", \"icc\"))):\n                            top = d\n                            break\n            return top\n        def find_in_2016style_dir(version):\n            # The 2016 (compiler v16) dirs are inconsistent from previous.\n            top = None\n            for d in glob.glob('/opt/intel/compilers_and_libraries_%s/linux'%version):\n                if os.path.exists(os.path.join(d, \"bin\", \"ia32\", \"icc\")) or os.path.exists(os.path.join(d, \"bin\", \"intel64\", \"icc\")):\n                    top = d\n                    break\n            return top\n                    \n        top = find_in_2016style_dir(version) or find_in_2011style_dir(version) or find_in_2010style_dir(version) or find_in_2008style_dir(version)\n        # print \"INTELC: top=\",top\n        if not top:\n            raise MissingDirError(\"Can't find version %s Intel compiler in %s (abi='%s')\"%(version,top, abi))\n    return top", "response": "Return the top - level dir of the Intel compiler using the given version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env, version=None, abi=None, topdir=None, verbose=0):\n    if not (is_mac or is_linux or is_windows):\n        # can't handle this platform\n        return\n\n    if is_windows:\n        SCons.Tool.msvc.generate(env)\n    elif is_linux:\n        SCons.Tool.gcc.generate(env)\n    elif is_mac:\n        SCons.Tool.gcc.generate(env)\n\n    # if version is unspecified, use latest\n    vlist = get_all_compiler_versions()\n    if not version:\n        if vlist:\n            version = vlist[0]\n    else:\n        # User may have specified '90' but we need to get actual dirname '9.0'.\n        # get_version_from_list does that mapping.\n        v = get_version_from_list(version, vlist)\n        if not v:\n            raise SCons.Errors.UserError(\"Invalid Intel compiler version %s: \"%version + \\\n                  \"installed versions are %s\"%(', '.join(vlist)))\n        version = v\n\n    # if abi is unspecified, use ia32\n    # alternatives are ia64 for Itanium, or amd64 or em64t or x86_64 (all synonyms here)\n    abi = check_abi(abi)\n    if abi is None:\n        if is_mac or is_linux:\n            # Check if we are on 64-bit linux, default to 64 then.\n            uname_m = os.uname()[4]\n            if uname_m == 'x86_64':\n                abi = 'x86_64'\n            else:\n                abi = 'ia32'\n        else:\n            if is_win64:\n                abi = 'em64t'\n            else:\n                abi = 'ia32'\n\n    if version and not topdir:\n        try:\n            topdir = get_intel_compiler_top(version, abi)\n        except (SCons.Util.RegError, IntelCError):\n            topdir = None\n\n    if not topdir:\n        # Normally this is an error, but it might not be if the compiler is\n        # on $PATH and the user is importing their env.\n        class ICLTopDirWarning(SCons.Warnings.Warning):\n            pass\n        if (is_mac or is_linux) and not env.Detect('icc') or \\\n           is_windows and not env.Detect('icl'):\n\n            SCons.Warnings.enableWarningClass(ICLTopDirWarning)\n            SCons.Warnings.warn(ICLTopDirWarning,\n                                \"Failed to find Intel compiler for version='%s', abi='%s'\"%\n                                (str(version), str(abi)))\n        else:\n            # should be cleaned up to say what this other version is\n            # since in this case we have some other Intel compiler installed\n            SCons.Warnings.enableWarningClass(ICLTopDirWarning)\n            SCons.Warnings.warn(ICLTopDirWarning,\n                                \"Can't find Intel compiler top dir for version='%s', abi='%s'\"%\n                                    (str(version), str(abi)))\n\n    if topdir:\n        archdir={'x86_64': 'intel64',\n                 'amd64' : 'intel64',\n                 'em64t' : 'intel64',\n                 'x86'   : 'ia32',\n                 'i386'  : 'ia32',\n                 'ia32'  : 'ia32'\n        }[abi] # for v11 and greater\n        if os.path.exists(os.path.join(topdir, 'bin', archdir)):\n            bindir=\"bin/%s\"%archdir\n            libdir=\"lib/%s\"%archdir\n        else:\n            bindir=\"bin\"\n            libdir=\"lib\"\n        if verbose:\n            print(\"Intel C compiler: using version %s (%g), abi %s, in '%s/%s'\"%\\\n                  (repr(version), linux_ver_normalize(version),abi,topdir,bindir))\n            if is_linux:\n                # Show the actual compiler version by running the compiler.\n                os.system('%s/%s/icc --version'%(topdir,bindir))\n            if is_mac:\n                # Show the actual compiler version by running the compiler.\n                os.system('%s/%s/icc --version'%(topdir,bindir))\n\n        env['INTEL_C_COMPILER_TOP'] = topdir\n        if is_linux:\n            paths={'INCLUDE'         : 'include',\n                   'LIB'             : libdir,\n                   'PATH'            : bindir,\n                   'LD_LIBRARY_PATH' : libdir}\n            for p in list(paths.keys()):\n                env.PrependENVPath(p, os.path.join(topdir, paths[p]))\n        if is_mac:\n            paths={'INCLUDE'         : 'include',\n                   'LIB'             : libdir,\n                   'PATH'            : bindir,\n                   'LD_LIBRARY_PATH' : libdir}\n            for p in list(paths.keys()):\n                env.PrependENVPath(p, os.path.join(topdir, paths[p]))\n        if is_windows:\n            #       env key    reg valname   default subdir of top\n            paths=(('INCLUDE', 'IncludeDir', 'Include'),\n                   ('LIB'    , 'LibDir',     'Lib'),\n                   ('PATH'   , 'BinDir',     'Bin'))\n            # We are supposed to ignore version if topdir is set, so set\n            # it to the emptry string if it's not already set.\n            if version is None:\n                version = ''\n            # Each path has a registry entry, use that or default to subdir\n            for p in paths:\n                try:\n                    path=get_intel_registry_value(p[1], version, abi)\n                    # These paths may have $(ICInstallDir)\n                    # which needs to be substituted with the topdir.\n                    path=path.replace('$(ICInstallDir)', topdir + os.sep)\n                except IntelCError:\n                    # Couldn't get it from registry: use default subdir of topdir\n                    env.PrependENVPath(p[0], os.path.join(topdir, p[2]))\n                else:\n                    env.PrependENVPath(p[0], path.split(os.pathsep))\n                    # print \"ICL %s: %s, final=%s\"%(p[0], path, str(env['ENV'][p[0]]))\n\n    if is_windows:\n        env['CC']        = 'icl'\n        env['CXX']       = 'icl'\n        env['LINK']      = 'xilink'\n    else:\n        env['CC']        = 'icc'\n        env['CXX']       = 'icpc'\n        # Don't reset LINK here;\n        # use smart_link which should already be here from link.py.\n        #env['LINK']      = '$CC'\n        env['AR']        = 'xiar'\n        env['LD']        = 'xild' # not used by default\n\n    # This is not the exact (detailed) compiler version,\n    # just the major version as determined above or specified\n    # by the user.  It is a float like 80 or 90, in normalized form for Linux\n    # (i.e. even for Linux 9.0 compiler, still returns 90 rather than 9.0)\n    if version:\n        env['INTEL_C_COMPILER_VERSION']=linux_ver_normalize(version)\n\n    if is_windows:\n        # Look for license file dir\n        # in system environment, registry, and default location.\n        envlicdir = os.environ.get(\"INTEL_LICENSE_FILE\", '')\n        K = ('SOFTWARE\\Intel\\Licenses')\n        try:\n            k = SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, K)\n            reglicdir = SCons.Util.RegQueryValueEx(k, \"w_cpp\")[0]\n        except (AttributeError, SCons.Util.RegError):\n            reglicdir = \"\"\n        defaultlicdir = r'C:\\Program Files\\Common Files\\Intel\\Licenses'\n\n        licdir = None\n        for ld in [envlicdir, reglicdir]:\n            # If the string contains an '@', then assume it's a network\n            # license (port@system) and good by definition.\n            if ld and (ld.find('@') != -1 or os.path.exists(ld)):\n                licdir = ld\n                break\n        if not licdir:\n            licdir = defaultlicdir\n            if not os.path.exists(licdir):\n                class ICLLicenseDirWarning(SCons.Warnings.Warning):\n                    pass\n                SCons.Warnings.enableWarningClass(ICLLicenseDirWarning)\n                SCons.Warnings.warn(ICLLicenseDirWarning,\n                                    \"Intel license dir was not found.\"\n                                    \"  Tried using the INTEL_LICENSE_FILE environment variable (%s), the registry (%s) and the default path (%s).\"\n                                    \"  Using the default path as a last resort.\"\n                                        % (envlicdir, reglicdir, defaultlicdir))\n        env['ENV']['INTEL_LICENSE_FILE'] = licdir", "response": "Generate Intel C ++ compiler tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string node descriptor and return a 3 - tuple of SGNode and a list of input trigger functions and processing functions.", "response": "def parse_node_descriptor(desc, model):\n    \"\"\"Parse a string node descriptor.\n\n    The function creates an SGNode object without connecting its inputs and outputs\n    and returns a 3-tuple:\n\n    SGNode, [(input X, trigger X)], <processing function name>\n\n    Args:\n        desc (str): A description of the node to be created.\n        model (str): A device model for the node to be created that sets any\n            device specific limits on how the node is set up.\n    \"\"\"\n\n    try:\n        data = graph_node.parseString(desc)\n    except ParseException:\n        raise  # TODO: Fix this to properly encapsulate the parse error\n\n    stream_desc = u' '.join(data['node'])\n\n    stream = DataStream.FromString(stream_desc)\n    node = SGNode(stream, model)\n\n    inputs = []\n\n    if 'input_a' in data:\n        input_a = data['input_a']\n        stream_a = DataStreamSelector.FromString(u' '.join(input_a['input_stream']))\n\n        trigger_a = None\n        if 'type' in input_a:\n            trigger_a = InputTrigger(input_a['type'], input_a['op'], int(input_a['reference'], 0))\n\n        inputs.append((stream_a, trigger_a))\n\n    if 'input_b' in data:\n        input_a = data['input_b']\n        stream_a = DataStreamSelector.FromString(u' '.join(input_a['input_stream']))\n\n        trigger_a = None\n        if 'type' in input_a:\n            trigger_a = InputTrigger(input_a['type'], input_a['op'], int(input_a['reference'], 0))\n\n        inputs.append((stream_a, trigger_a))\n\n    if 'combiner' in data and str(data['combiner']) == u'||':\n        node.trigger_combiner = SGNode.OrTriggerCombiner\n    else:\n        node.trigger_combiner = SGNode.AndTriggerCombiner\n\n    processing = data['processor']\n    return node, inputs, processing"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a string node descriptor into a 20 - byte binary node descriptor.", "response": "def create_binary_descriptor(descriptor):\n    \"\"\"Convert a string node descriptor into a 20-byte binary descriptor.\n\n    This is the inverse operation of parse_binary_descriptor and composing\n    the two operations is a noop.\n\n    Args:\n        descriptor (str): A string node descriptor\n\n    Returns:\n        bytes: A 20-byte binary node descriptor.\n    \"\"\"\n\n    func_names = {0: 'copy_latest_a', 1: 'average_a',\n                  2: 'copy_all_a', 3: 'sum_a',\n                  4: 'copy_count_a', 5: 'trigger_streamer',\n                  6: 'call_rpc', 7: 'subtract_afromb'}\n\n    func_codes = {y: x for x, y in func_names.items()}\n\n    node, inputs, processing = parse_node_descriptor(descriptor, DeviceModel())\n\n    func_code = func_codes.get(processing)\n    if func_code is None:\n        raise ArgumentError(\"Unknown processing function\", function=processing)\n\n    stream_a, trigger_a = inputs[0]\n    stream_a = stream_a.encode()\n\n    if len(inputs) == 2:\n        stream_b, trigger_b = inputs[1]\n        stream_b = stream_b.encode()\n    else:\n        stream_b, trigger_b = 0xFFFF, None\n\n    if trigger_a is None:\n        trigger_a = TrueTrigger()\n\n    if trigger_b is None:\n        trigger_b = TrueTrigger()\n\n    ref_a = 0\n    if isinstance(trigger_a, InputTrigger):\n        ref_a = trigger_a.reference\n\n    ref_b = 0\n    if isinstance(trigger_b, InputTrigger):\n        ref_b = trigger_b.reference\n\n    trigger_a = _create_binary_trigger(trigger_a)\n    trigger_b = _create_binary_trigger(trigger_b)\n\n    combiner = node.trigger_combiner\n\n    bin_desc = struct.pack(\"<LLHHHBBBB2x\", ref_a, ref_b, node.stream.encode(), stream_a, stream_b, func_code, trigger_a, trigger_b, combiner)\n    return bin_desc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a binary node descriptor into a string description.", "response": "def parse_binary_descriptor(bindata):\n    \"\"\"Convert a binary node descriptor into a string descriptor.\n\n    Binary node descriptor are 20-byte binary structures that encode all\n    information needed to create a graph node.  They are used to communicate\n    that information to an embedded device in an efficent format.  This\n    function exists to turn such a compressed node description back into\n    an understandable string.\n\n    Args:\n        bindata (bytes): The raw binary structure that contains the node\n            description.\n\n    Returns:\n        str: The corresponding string description of the same sensor_graph node\n    \"\"\"\n\n    func_names = {0: 'copy_latest_a', 1: 'average_a',\n                  2: 'copy_all_a', 3: 'sum_a',\n                  4: 'copy_count_a', 5: 'trigger_streamer',\n                  6: 'call_rpc', 7: 'subtract_afromb'}\n\n    if len(bindata) != 20:\n        raise ArgumentError(\"Invalid binary node descriptor with incorrect size\", size=len(bindata), expected=20, bindata=bindata)\n\n    a_trig, b_trig, stream_id, a_id, b_id, proc, a_cond, b_cond, trig_combiner = struct.unpack(\"<LLHHHBBBB2x\", bindata)\n\n    node_stream = DataStream.FromEncoded(stream_id)\n\n    if a_id == 0xFFFF:\n        raise ArgumentError(\"Invalid binary node descriptor with invalid first input\", input_selector=a_id)\n\n    a_selector = DataStreamSelector.FromEncoded(a_id)\n    a_trigger = _process_binary_trigger(a_trig, a_cond)\n\n    b_selector = None\n    b_trigger = None\n    if b_id != 0xFFFF:\n        b_selector = DataStreamSelector.FromEncoded(b_id)\n        b_trigger = _process_binary_trigger(b_trig, b_cond)\n\n    if trig_combiner == SGNode.AndTriggerCombiner:\n        comb = '&&'\n    elif trig_combiner == SGNode.OrTriggerCombiner:\n        comb = '||'\n    else:\n        raise ArgumentError(\"Invalid trigger combiner in binary node descriptor\", combiner=trig_combiner)\n\n    if proc not in func_names:\n        raise ArgumentError(\"Unknown processing function\", function_id=proc, known_functions=func_names)\n\n    func_name = func_names[proc]\n\n    # Handle one input nodes\n    if b_selector is None:\n        return '({} {}) => {} using {}'.format(a_selector, a_trigger, node_stream, func_name)\n\n    return '({} {} {} {} {}) => {} using {}'.format(a_selector, a_trigger, comb,\n                                                    b_selector, b_trigger,\n                                                    node_stream, func_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_binary_trigger(trigger_value, condition):\n\n    ops = {\n        0: \">\",\n        1: \"<\",\n        2: \">=\",\n        3: \"<=\",\n        4: \"==\",\n        5: 'always'\n    }\n\n    sources = {\n        0: 'value',\n        1: 'count'\n    }\n\n    encoded_source = condition & 0b1\n    encoded_op = condition >> 1\n\n    oper = ops.get(encoded_op, None)\n    source = sources.get(encoded_source, None)\n\n    if oper is None:\n        raise ArgumentError(\"Unknown operation in binary trigger\", condition=condition, operation=encoded_op, known_ops=ops)\n    if source is None:\n        raise ArgumentError(\"Unknown value source in binary trigger\", source=source, known_sources=sources)\n\n    if oper == 'always':\n        return TrueTrigger()\n\n    return InputTrigger(source, oper, trigger_value)", "response": "Process a binary trigger."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_binary_trigger(trigger):\n\n    ops = {\n        0: \">\",\n        1: \"<\",\n        2: \">=\",\n        3: \"<=\",\n        4: \"==\",\n        5: 'always'\n    }\n\n    op_codes = {y: x for x, y in ops.items()}\n    source = 0\n\n    if isinstance(trigger, TrueTrigger):\n        op_code = op_codes['always']\n    elif isinstance(trigger, FalseTrigger):\n        raise ArgumentError(\"Cannot express a never trigger in binary descriptor\", trigger=trigger)\n    else:\n        op_code = op_codes[trigger.comp_string]\n\n        if trigger.use_count:\n            source = 1\n\n    return (op_code << 1) | source", "response": "Create an 8 - bit binary trigger from an InputTrigger TrueTrigger FalseTrigger."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to assign a UTC time to this reading.", "response": "def _try_assign_utc_time(self, raw_time, time_base):\n        \"\"\"Try to assign a UTC time to this reading.\"\"\"\n\n        # Check if the raw time is encoded UTC since y2k or just uptime\n        if raw_time != IOTileEvent.InvalidRawTime and (raw_time & (1 << 31)):\n            y2k_offset = self.raw_time ^ (1 << 31)\n            return self._Y2KReference + datetime.timedelta(seconds=y2k_offset)\n\n        if time_base is not None:\n            return time_base + datetime.timedelta(seconds=raw_time)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asdict(self):\n\n        timestamp_str = None\n        if self.reading_time is not None:\n            timestamp_str = self.reading_time.isoformat()\n\n        return {\n            'stream': self.stream,\n            'device_timestamp': self.raw_time,\n            'streamer_local_id': self.reading_id,\n            'timestamp': timestamp_str,\n            'value': self.value\n        }", "response": "Encode the data in this reading into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding the data in this event into a dictionary.", "response": "def asdict(self):\n        \"\"\"Encode the data in this event into a dictionary.\n\n        The dictionary returned from this method is a reference to the data\n        stored in the IOTileEvent, not a copy.  It should be treated as read\n        only.\n\n        Returns:\n            dict: A dictionary containing the information from this event.\n        \"\"\"\n\n        return {\n            'stream': self.stream,\n            'device_timestamp': self.raw_time,\n            'streamer_local_id': self.reading_id,\n            'timestamp': self.reading_time,\n            'extra_data': self.summary_data,\n            'data': self.raw_data\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an IOTileEvent object from a dictionary produced by a previous call to asdict().", "response": "def FromDict(cls, obj):\n        \"\"\"Create an IOTileEvent from the result of a previous call to asdict().\n\n        Args:\n            obj (dict): A dictionary produced by a call to IOTileEvent.asdict()\n\n        Returns:\n            IOTileEvent: The converted IOTileEvent object.\n        \"\"\"\n\n        timestamp = obj.get('timestamp')\n        if timestamp is not None:\n            import dateutil.parser\n            timestamp = dateutil.parser.parse(timestamp)\n\n        return IOTileEvent(obj.get('device_timestamp'), obj.get('stream'), obj.get('extra_data'),\n                           obj.get('data'), reading_id=obj.get('streamer_local_id'), reading_time=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, path):\n\n        data = self.encode()\n\n        with open(path, \"wb\") as out:\n            out.write(data)", "response": "Save a binary copy of this report\n            to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nturn this report into a dictionary that encodes all information including received timestamp", "response": "def serialize(self):\n        \"\"\"Turn this report into a dictionary that encodes all information including received timestamp\"\"\"\n\n        info = {}\n        info['received_time'] = self.received_time\n        info['encoded_report'] = bytes(self.encode())\n\n        # Handle python 2 / python 3 differences\n        report_format = info['encoded_report'][0]\n        if not isinstance(report_format, int):\n            report_format = ord(report_format)\n        info['report_format'] = report_format  # Report format is the first byte of the encoded report\n        info['origin'] = self.origin\n\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_csig(self):\n        try:\n            return self.ninfo.csig\n        except AttributeError:\n            pass\n\n        contents = self.get_contents()\n        csig = SCons.Util.MD5signature(contents)\n        self.get_ninfo().csig = csig\n        return csig", "response": "Generate a node s content signature the digested signature\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(env):\n    import SCons.Tool\n    import SCons.Tool.cc\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in CXXSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.CXXAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ShCXXAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n        shared_obj.add_emitter(suffix, SCons.Defaults.SharedObjectEmitter)\n\n    SCons.Tool.cc.add_common_cc_variables(env)\n\n    if 'CXX' not in env:\n        env['CXX']    = env.Detect(compilers) or compilers[0]\n    env['CXXFLAGS']   = SCons.Util.CLVar('')\n    env['CXXCOM']     = '$CXX -o $TARGET -c $CXXFLAGS $CCFLAGS $_CCCOMCOM $SOURCES'\n    env['SHCXX']      = '$CXX'\n    env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS')\n    env['SHCXXCOM']   = '$SHCXX -o $TARGET -c $SHCXXFLAGS $SHCCFLAGS $_CCCOMCOM $SOURCES'\n\n    env['CPPDEFPREFIX']  = '-D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '-I'\n    env['INCSUFFIX']  = ''\n    env['SHOBJSUFFIX'] = '.os'\n    env['OBJSUFFIX'] = '.o'\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 0\n\n    env['CXXFILESUFFIX'] = '.cc'", "response": "Add Builders and construction variables for Visual Age C ++ compilers to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef link_to_storage(self, sensor_log):\n\n        if self.walker is not None:\n            self._sensor_log.destroy_walker(self.walker)\n            self.walker = None\n\n        self.walker = sensor_log.create_walker(self.selector)\n        self._sensor_log = sensor_log", "response": "Attach this DataStreamer to an underlying SensorLog and store the results in the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if this streamer should generate a report.", "response": "def triggered(self, manual=False):\n        \"\"\"Check if this streamer should generate a report.\n\n        Streamers can be triggered automatically whenever they have data\n        or they can be triggered manually. This method returns True if the\n        streamer is currented triggered.\n\n        A streamer is triggered if it:\n          - (has data AND is automatic) OR\n          - (has data AND is manually triggered)\n\n        Args:\n            manual (bool): Indicate that the streamer has been manually triggered.\n\n        Returns:\n            bool: Whether the streamer can generate a report right now.\n        \"\"\"\n\n        if self.walker is None:\n            raise InternalError(\"You can only check if a streamer is triggered if you create it with a SensorLog\")\n\n        if not self.automatic and not manual:\n            return False\n\n        return self.has_data()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a report from the contents of this streamer.", "response": "def build_report(self, device_id, max_size=None, device_uptime=0, report_id=None, auth_chain=None):\n        \"\"\"Build a report with all of the readings in this streamer.\n\n        This method will produce an IOTileReport subclass and, if necessary,\n        sign it using the passed authentication chain.\n\n        Args:\n            device_id (int): The UUID of the device to generate a report for.\n            max_size (int): Optional maximum number of bytes that the report can be\n            device_uptime (int): The device's uptime to use as the sent timestamp of the report\n            report_id (int): The report id to use if the report type require serialization.\n            auth_chain (AuthChain): An auth chain class to use to sign the report if the report\n                type requires signing.\n\n        Returns:\n            StreamerReport: The report, its highest id and the number of readings in it.\n\n            The highest reading id and number of readings are returned\n            separately from the report itself because, depending on the format\n            of the report (such as whether it is encrypted or does not contain\n            reading ids), these details may not be recoverable from the report\n            itself.\n\n        Raises:\n            InternalError: If there was no SensorLog passed when this streamer was created.\n            StreamEmptyError: If there is no data to generate a report from.  This can only happen\n                if a call to triggered() returned False.\n            ArgumentError: If the report requires additional metadata that was not passed like a\n                signing key or report_id.\n        \"\"\"\n\n        if self.walker is None or self.index is None:\n            raise InternalError(\"You can only build a report with a DataStreamer if you create it with a SensorLog and a streamer index\")\n\n        if self.requires_signing() and auth_chain is None:\n            raise ArgumentError(\"You must pass an auth chain to sign this report.\")\n\n        if self.requires_id() and report_id is None:\n            raise ArgumentError(\"You must pass a report_id to serialize this report\")\n\n        if self.format == 'individual':\n            reading = self.walker.pop()\n\n            highest_id = reading.reading_id\n\n            if self.report_type == 'telegram':\n                return StreamerReport(IndividualReadingReport.FromReadings(device_id, [reading]), 1, highest_id)\n            elif self.report_type == 'broadcast':\n                return StreamerReport(BroadcastReport.FromReadings(device_id, [reading], device_uptime), 1, highest_id)\n        elif self.format == 'hashedlist':\n            max_readings = (max_size - 20 - 24) // 16\n            if max_readings <= 0:\n                raise InternalError(\"max_size is too small to hold even a single reading\", max_size=max_size)\n\n            readings = []\n            highest_id = 0\n            try:\n                while len(readings) < max_readings:\n                    reading = self.walker.pop()\n                    readings.append(reading)\n                    if reading.reading_id > highest_id:\n                        highest_id = reading.reading_id\n            except StreamEmptyError:\n                if len(readings) == 0:\n                    raise\n\n            return StreamerReport(SignedListReport.FromReadings(device_id, readings, report_id=report_id, selector=self.selector.encode(),\n                                                                streamer=self.index, sent_timestamp=device_uptime), len(readings), highest_id)\n\n        raise InternalError(\"Streamer report format or type is not supported currently\", report_format=self.format, report_type=self.report_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matches(self, address, name=None):\n\n        if self.controller:\n            return address == 8\n\n        return self.address == address", "response": "Check if this slot identifier matches the given tile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a slot identifier from a string description.", "response": "def FromString(cls, desc):\n        \"\"\"Create a slot identifier from a string description.\n\n        The string needs to be either:\n\n        controller\n        OR\n        slot <X> where X is an integer that can be converted with int(X, 0)\n\n        Args:\n            desc (str): The string description of the slot\n\n        Returns:\n            SlotIdentifier\n        \"\"\"\n\n        desc = str(desc)\n\n        if desc == u'controller':\n            return SlotIdentifier(controller=True)\n\n        words = desc.split()\n        if len(words) != 2 or words[0] != u'slot':\n            raise ArgumentError(u\"Illegal slot identifier\", descriptor=desc)\n\n        try:\n            slot_id = int(words[1], 0)\n        except ValueError:\n            raise ArgumentError(u\"Could not convert slot identifier to number\", descriptor=desc, number=words[1])\n\n        return SlotIdentifier(slot=slot_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef FromEncoded(cls, bindata):\n\n        if len(bindata) != 8:\n            raise ArgumentError(\"Invalid binary slot descriptor with invalid length\", length=len(bindata), expected=8, data=bindata)\n\n        slot, match_op = struct.unpack(\"<B6xB\", bindata)\n\n        match_name = cls.KNOWN_MATCH_CODES.get(match_op)\n        if match_name is None:\n            raise ArgumentError(\"Unknown match operation specified in binary slot descriptor\", operation=match_op, known_match_ops=cls.KNOWN_MATCH_CODES)\n\n        if match_name == 'match_controller':\n            return SlotIdentifier(controller=True)\n\n        if match_name == 'match_slot':\n            return SlotIdentifier(slot=slot)\n\n        raise ArgumentError(\"Unsupported match operation in binary slot descriptor\", match_op=match_name)", "response": "Create a slot identifier from an encoded binary descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes this slot identifier into a binary descriptor.", "response": "def encode(self):\n        \"\"\"Encode this slot identifier into a binary descriptor.\n\n        Returns:\n            bytes: The 8-byte encoded slot identifier\n        \"\"\"\n\n        slot = 0\n        match_op = self.KNOWN_MATCH_NAMES['match_controller']\n\n        if not self.controller:\n            slot = self.slot\n            match_op = self.KNOWN_MATCH_NAMES['match_slot']\n\n        return struct.pack(\"<B6xB\", slot, match_op)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle syntax errors. Print out a message and show where the error occured.", "response": "def _scons_syntax_error(e):\n    \"\"\"Handle syntax errors. Print out a message and show where the error\n    occurred.\n    \"\"\"\n    etype, value, tb = sys.exc_info()\n    lines = traceback.format_exception_only(etype, value)\n    for line in lines:\n        sys.stderr.write(line+'\\n')\n    sys.exit(2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_deepest_user_frame(tb):\n\n    tb.reverse()\n\n    # find the deepest traceback frame that is not part\n    # of SCons:\n    for frame in tb:\n        filename = frame[0]\n        if filename.find(os.sep+'SCons'+os.sep) == -1:\n            return frame\n    return tb[0]", "response": "Find the deepest user frame in a traceback."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles user errors. Print out a message and a description of the error and exit.", "response": "def _scons_user_error(e):\n    \"\"\"Handle user errors. Print out a message and a description of the\n    error, along with the line number and routine where it occured.\n    The file and line number will be the deepest stack frame that is\n    not part of SCons itself.\n    \"\"\"\n    global print_stacktrace\n    etype, value, tb = sys.exc_info()\n    if print_stacktrace:\n        traceback.print_exception(etype, value, tb)\n    filename, lineno, routine, dummy = find_deepest_user_frame(traceback.extract_tb(tb))\n    sys.stderr.write(\"\\nscons: *** %s\\n\" % value)\n    sys.stderr.write('File \"%s\", line %d, in %s\\n' % (filename, lineno, routine))\n    sys.exit(2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle user warnings. Print out a message and a description of the warning.", "response": "def _scons_user_warning(e):\n    \"\"\"Handle user warnings. Print out a message and a description of\n    the warning, along with the line number and routine where it occured.\n    The file and line number will be the deepest stack frame that is\n    not part of SCons itself.\n    \"\"\"\n    etype, value, tb = sys.exc_info()\n    filename, lineno, routine, dummy = find_deepest_user_frame(traceback.extract_tb(tb))\n    sys.stderr.write(\"\\nscons: warning: %s\\n\" % e)\n    sys.stderr.write('File \"%s\", line %d, in %s\\n' % (filename, lineno, routine))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading the site_scons dir under topdir.", "response": "def _load_site_scons_dir(topdir, site_dir_name=None):\n    \"\"\"Load the site_scons dir under topdir.\n    Prepends site_scons to sys.path, imports site_scons/site_init.py,\n    and prepends site_scons/site_tools to default toolpath.\"\"\"\n    if site_dir_name:\n        err_if_not_found = True       # user specified: err if missing\n    else:\n        site_dir_name = \"site_scons\"\n        err_if_not_found = False\n\n    site_dir = os.path.join(topdir, site_dir_name)\n    if not os.path.exists(site_dir):\n        if err_if_not_found:\n            raise SCons.Errors.UserError(\"site dir %s not found.\"%site_dir)\n        return\n\n    site_init_filename = \"site_init.py\"\n    site_init_modname = \"site_init\"\n    site_tools_dirname = \"site_tools\"\n    # prepend to sys.path\n    sys.path = [os.path.abspath(site_dir)] + sys.path\n    site_init_file = os.path.join(site_dir, site_init_filename)\n    site_tools_dir = os.path.join(site_dir, site_tools_dirname)\n    if os.path.exists(site_init_file):\n        import imp, re\n        try:\n            try:\n                fp, pathname, description = imp.find_module(site_init_modname,\n                                                            [site_dir])\n                # Load the file into SCons.Script namespace.  This is\n                # opaque and clever; m is the module object for the\n                # SCons.Script module, and the exec ... in call executes a\n                # file (or string containing code) in the context of the\n                # module's dictionary, so anything that code defines ends\n                # up adding to that module.  This is really short, but all\n                # the error checking makes it longer.\n                try:\n                    m = sys.modules['SCons.Script']\n                except Exception as e:\n                    fmt = 'cannot import site_init.py: missing SCons.Script module %s'\n                    raise SCons.Errors.InternalError(fmt % repr(e))\n                try:\n                    sfx = description[0]\n                    modname = os.path.basename(pathname)[:-len(sfx)]\n                    site_m = {\"__file__\": pathname, \"__name__\": modname, \"__doc__\": None}\n                    re_special = re.compile(\"__[^_]+__\")\n                    for k in list(m.__dict__.keys()):\n                        if not re_special.match(k):\n                            site_m[k] = m.__dict__[k]\n\n                    # This is the magic.\n                    exec(compile(fp.read(), fp.name, 'exec'), site_m)\n                except KeyboardInterrupt:\n                    raise\n                except Exception as e:\n                    fmt = '*** Error loading site_init file %s:\\n'\n                    sys.stderr.write(fmt % repr(site_init_file))\n                    raise\n                else:\n                    for k in site_m:\n                        if not re_special.match(k):\n                            m.__dict__[k] = site_m[k]\n            except KeyboardInterrupt:\n                raise\n            except ImportError as e:\n                fmt = '*** cannot import site init file %s:\\n'\n                sys.stderr.write(fmt % repr(site_init_file))\n                raise\n        finally:\n            if fp:\n                fp.close()\n    if os.path.exists(site_tools_dir):\n        # prepend to DefaultToolpath\n        SCons.Tool.DefaultToolpath.insert(0, os.path.abspath(site_tools_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload all of the predefined site_scons dirs.", "response": "def _load_all_site_scons_dirs(topdir, verbose=None):\n    \"\"\"Load all of the predefined site_scons dir.\n    Order is significant; we load them in order from most generic\n    (machine-wide) to most specific (topdir).\n    The verbose argument is only for testing.\n    \"\"\"\n    platform = SCons.Platform.platform_default()\n\n    def homedir(d):\n        return os.path.expanduser('~/'+d)\n\n    if platform == 'win32' or platform == 'cygwin':\n        # Note we use $ here instead of %...% because older\n        # pythons (prior to 2.6?) didn't expand %...% on Windows.\n        # This set of dirs should work on XP, Vista, 7 and later.\n        sysdirs=[\n            os.path.expandvars('$ALLUSERSPROFILE\\\\Application Data\\\\scons'),\n            os.path.expandvars('$USERPROFILE\\\\Local Settings\\\\Application Data\\\\scons')]\n        appdatadir = os.path.expandvars('$APPDATA\\\\scons')\n        if appdatadir not in sysdirs:\n            sysdirs.append(appdatadir)\n        sysdirs.append(homedir('.scons'))\n\n    elif platform == 'darwin':  # MacOS X\n        sysdirs=['/Library/Application Support/SCons',\n                 '/opt/local/share/scons', # (for MacPorts)\n                 '/sw/share/scons', # (for Fink)\n                  homedir('Library/Application Support/SCons'),\n                  homedir('.scons')]\n    elif platform == 'sunos':   # Solaris\n        sysdirs=['/opt/sfw/scons',\n                 '/usr/share/scons',\n                 homedir('.scons')]\n    else:                       # Linux, HPUX, etc.\n        # assume posix-like, i.e. platform == 'posix'\n        sysdirs=['/usr/share/scons',\n                 homedir('.scons')]\n\n    dirs=sysdirs + [topdir]\n    for d in dirs:\n        if verbose:    # this is used by unit tests.\n            print(\"Loading site dir \", d)\n        _load_site_scons_dir(d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_ready(self):\n        SCons.Taskmaster.OutOfDateTask.make_ready(self)\n        if self.out_of_date and self.options.debug_explain:\n            explanation = self.out_of_date[0].explain()\n            if explanation:\n                sys.stdout.write(\"scons: \" + explanation)", "response": "Make a task ready for execution"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(self):\n\n        begin_payload = struct.pack(\"<H8s\", self.config_id, self.target.encode())\n        start_record = SendErrorCheckingRPCRecord(8, self.BEGIN_CONFIG_RPC, begin_payload, 4)\n        end_record = SendErrorCheckingRPCRecord(8, self.END_CONFIG_RPC, bytearray(), 4)\n        push_records = []\n\n        for i in range(0, len(self.data), 20):\n            chunk = self.data[i:i+20]\n            push_record = SendErrorCheckingRPCRecord(8, self.PUSH_CONFIG_RPC, chunk, 4)\n            push_records.append(push_record)\n\n        out_blob = bytearray()\n        out_blob += start_record.encode()\n\n        for push_record in push_records:\n            out_blob += push_record.encode()\n\n        out_blob += end_record.encode()\n        return out_blob", "response": "Encode this record into binary suitable for embedded into an update script."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck how well this record matches the given binary data. This function will only be called if the record matches the type code given by calling MatchType() and this functon should check how well this record matches and return a quality score between 0 and 100, with higher quality matches having higher scores. The default value should be MatchQuality.GenericMatch which is 50. If this record does not match at all, it should return MatchQuality.NoMatch. Many times, only a single record type will match a given binary record but there are times when multiple different logical records produce the same type of record in a script, such as set_version and set_userkey both producing a call_rpc record with different RPC values. The MatchQuality method is used to allow for rich decoding of such scripts back to the best possible record that created them. Args: record_data (bytearay): The raw record that we should check for a match. record_count (int): The number of binary records that are included in record_data. Returns: int: The match quality between 0 and 100. You should use the constants defined in MatchQuality as much as possible.", "response": "def MatchQuality(cls, record_data, record_count=1):\n        \"\"\"Check how well this record matches the given binary data.\n\n        This function will only be called if the record matches the type code\n        given by calling MatchType() and this functon should check how well\n        this record matches and return a quality score between 0 and 100, with\n        higher quality matches having higher scores.  The default value should\n        be MatchQuality.GenericMatch which is 50.  If this record does not\n        match at all, it should return MatchQuality.NoMatch.\n\n        Many times, only a single record type will match a given binary record\n        but there are times when multiple different logical records produce\n        the same type of record in a script, such as set_version and\n        set_userkey both producing a call_rpc record with different RPC\n        values.  The MatchQuality method is used to allow for rich decoding\n        of such scripts back to the best possible record that created them.\n\n        Args:\n            record_data (bytearay): The raw record that we should check for\n                a match.\n            record_count (int): The number of binary records that are included\n                in record_data.\n\n        Returns:\n            int: The match quality between 0 and 100.  You should use the\n                constants defined in MatchQuality as much as possible.\n        \"\"\"\n\n        if record_count == 1:\n            cmd, address, _resp_length, _payload = SendErrorCheckingRPCRecord._parse_rpc_info(record_data)\n\n            if cmd == cls.BEGIN_CONFIG_RPC and address == 8:\n                return MatchQuality.DeferMatch\n\n            return MatchQuality.NoMatch\n\n        # To see if this is a set_config variable record set, we need to decode all of\n        # the records and make sure each is an error checking rpc with the right rpc id\n        try:\n            rpcs = SendErrorCheckingRPCRecord.parse_multiple_rpcs(record_data)\n\n            push_commands = rpcs[1:-1]\n\n            for cmd in push_commands:\n                cmd_id, addr = cmd[:2]\n                if cmd_id != cls.PUSH_CONFIG_RPC or addr != 8:\n                    return MatchQuality.NoMatch\n\n            last_cmd, last_addr = rpcs[-1][:2]\n            if last_cmd == cls.END_CONFIG_RPC and last_addr == 8:\n                return MatchQuality.PerfectMatch\n        except ArgumentError:\n            return MatchQuality.NoMatch\n\n        return MatchQuality.DeferMatch"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an UpdateRecord subclass from binary record data.", "response": "def FromBinary(cls, record_data, record_count=1):\n        \"\"\"Create an UpdateRecord subclass from binary record data.\n\n        This is a multi-action record that matches a pattern of error checking\n        RPC calls:\n        begin config\n        push config data\n        <possibly multiple>\n        end config\n\n        Args:\n            record_data (bytearray): The raw record data that we wish to parse.\n            record_count (int): The number of records included in record_data.\n\n        Raises:\n            ArgumentError: If the record_data is malformed and cannot be parsed.\n\n        Returns:\n            SetConfigRecord: The decoded tile records.\n        \"\"\"\n\n        rpcs = SendErrorCheckingRPCRecord.parse_multiple_rpcs(record_data)\n\n        start_rpc = rpcs[0]\n        push_rpcs = rpcs[1:-1]\n\n        try:\n            config_id, raw_target = struct.unpack(\"<H8s\", start_rpc.payload)\n            target = SlotIdentifier.FromEncoded(raw_target)\n        except ValueError:\n            raise ArgumentError(\"Could not parse payload on begin config rpc\", payload=start_rpc.payload)\n\n        payload = bytearray()\n        for rpc in push_rpcs:\n            payload += rpc.payload\n\n        return SetConfigRecord(target, config_id, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unpack_version(tag_data):\n\n    tag = tag_data & ((1 << 20) - 1)\n\n    version_data = tag_data >> 20\n    major = (version_data >> 6) & ((1 << 6) - 1)\n    minor = (version_data >> 0) & ((1 << 6) - 1)\n\n    return (tag, \"{}.{}\".format(major, minor))", "response": "Unpack a packed version info struct into a tag major. minor version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting this controller tile.", "response": "def _handle_reset(self):\n        \"\"\"Reset this controller tile.\n\n        This process will call _handle_reset() for all of the controller\n        subsystem mixins in order to make sure they all return to their proper\n        reset state.\n\n        It will then reset all of the peripheral tiles to emulate the behavior\n        of a physical POD where the controller tile cuts power to all\n        peripheral tiles on reset for a clean boot.\n\n        This will clear all subsystems of this controller to their reset\n        states.\n\n        The order of these calls is important to guarantee that everything is\n        in the correct state before resetting the next subsystem.\n\n        The behavior of this function is different depending on whether\n        deferred is True or False.  If it's true, this function will only\n        clear the config database and then queue all of the config streaming\n        rpcs to itself to load in all of our config variables.  Once these\n        have been sent, it will reset the rest of the controller subsystems.\n        \"\"\"\n\n        self._logger.info(\"Resetting controller\")\n        self._device.reset_count += 1\n\n        super(ReferenceController, self)._handle_reset()\n\n        # Load in all default values into our config variables before streaming\n        # updated data into them.\n        self.reset_config_variables()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _reset_vector(self):\n\n        # Send ourselves all of our config variable assignments\n        config_rpcs = self.config_database.stream_matching(8, self.name)\n        for rpc in config_rpcs:\n            await self._device.emulator.await_rpc(*rpc)\n\n        config_assignments = self.latch_config_variables()\n        self._logger.info(\"Latched config variables at reset for controller: %s\", config_assignments)\n\n        for system in self._post_config_subsystems:\n            try:\n                system.clear_to_reset(config_assignments)\n                await asyncio.wait_for(system.initialize(), timeout=2.0)\n            except:\n                self._logger.exception(\"Error initializing %s\", system)\n                raise\n\n        self._logger.info(\"Finished clearing controller to reset condition\")\n\n        # Now reset all of the tiles\n        for address, _ in self._device.iter_tiles(include_controller=False):\n            self._logger.info(\"Sending reset signal to tile at address %d\", address)\n\n            try:\n                await self._device.emulator.await_rpc(address, rpcs.RESET)\n            except TileNotFoundError:\n                pass\n            except:\n                self._logger.exception(\"Error sending reset signal to tile at address %d\", address)\n                raise\n\n        self.initialized.set()", "response": "Initialize the controller s subsystems inside the emulation thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump the current state of this emulated object as a dictionary.", "response": "def dump_state(self):\n        \"\"\"Dump the current state of this emulated object as a dictionary.\n\n        Returns:\n            dict: The current state of the object that could be passed to load_state.\n        \"\"\"\n\n        superstate = super(ReferenceController, self).dump_state()\n\n        superstate.update({\n            'state_name': self.STATE_NAME,\n            'state_version': self.STATE_VERSION,\n            'app_info': self.app_info,\n            'os_info': self.os_info,\n\n            # Dump all of the subsystems\n            'remote_bridge': self.remote_bridge.dump(),\n            'tile_manager': self.tile_manager.dump(),\n            'config_database': self.config_database.dump(),\n            'sensor_log': self.sensor_log.dump()\n        })\n\n        return superstate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore_state(self, state):\n\n        super(ReferenceController, self).restore_state(state)\n\n        state_name = state.get('state_name')\n        state_version = state.get('state_version')\n\n        if state_name != self.STATE_NAME or state_version != self.STATE_VERSION:\n            raise ArgumentError(\"Invalid emulated device state name or version\", found=(state_name, state_version),\n                                expected=(self.STATE_NAME, self.STATE_VERSION))\n\n        self.app_info = state.get('app_info', (0, \"0.0\"))\n        self.os_info = state.get('os_info', (0, \"0.0\"))\n\n        # Notify all subsystems of our intent to restore in case they need to prepare\n        self.sensor_log.prepare_for_restore()\n\n        # Restore all of the subsystems\n        self.remote_bridge.restore(state.get('remote_bridge', {}))\n        self.tile_manager.restore(state.get('tile_manager', {}))\n        self.config_database.restore(state.get('config_database', {}))\n        self.sensor_log.restore(state.get('sensor_log', {}))", "response": "Restore the current state of this emulated object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hardware_version(self):\n\n        hardware_string = self.hardware_string\n\n        if not isinstance(hardware_string, bytes):\n            hardware_string = self.hardware_string.encode('utf-8')\n\n        if len(hardware_string) > 10:\n            self._logger.warn(\"Truncating hardware string that was longer than 10 bytes: %s\", self.hardware_string)\n\n        if len(hardware_string) < 10:\n            hardware_string += b'\\0'*(10 - len(hardware_string))\n\n        return [hardware_string]", "response": "Get a hardware identification string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the UUID app tag and os tag.", "response": "def controller_info(self):\n        \"\"\"Get the controller UUID, app tag and os tag.\"\"\"\n\n        return [self._device.iotile_id, _pack_version(*self.os_info), _pack_version(*self.app_info)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_app_os_tag(self, os_tag, app_tag, update_os, update_app):\n\n        update_os = bool(update_os)\n        update_app = bool(update_app)\n\n        if update_os:\n            self.os_info = _unpack_version(os_tag)\n\n        if update_app:\n            self.app_info = _unpack_version(app_tag)\n\n        return [Error.NO_ERROR]", "response": "Update the app and os tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_sgf(self, sgf_data):\n\n        if '\\n' not in sgf_data:\n            with open(sgf_data, \"r\") as infile:\n                sgf_data = infile.read()\n\n        model = DeviceModel()\n\n        parser = SensorGraphFileParser()\n        parser.parse_file(data=sgf_data)\n\n        parser.compile(model)\n        opt = SensorGraphOptimizer()\n        opt.optimize(parser.sensor_graph, model=model)\n\n        sensor_graph = parser.sensor_graph\n        self._logger.info(\"Loading sensor_graph with %d nodes, %d streamers and %d configs\",\n                          len(sensor_graph.nodes), len(sensor_graph.streamers), len(sensor_graph.config_database))\n\n        # Directly load the sensor_graph into our persisted storage\n        self.sensor_graph.persisted_nodes = sensor_graph.dump_nodes()\n        self.sensor_graph.persisted_streamers = sensor_graph.dump_streamers()\n\n        self.sensor_graph.persisted_constants = []\n        for stream, value in sorted(sensor_graph.constant_database.items(), key=lambda x: x[0].encode()):\n            reading = IOTileReading(stream.encode(), 0, value)\n            self.sensor_graph.persisted_constants.append((stream, reading))\n\n        self.sensor_graph.persisted_exists = True\n\n        # Clear all config variables and load in those from this sgf file\n        self.config_database.clear()\n\n        for slot in sorted(sensor_graph.config_database, key=lambda x: x.encode()):\n            for conf_var, (conf_type, conf_val) in sorted(sensor_graph.config_database[slot].items()):\n                self.config_database.add_direct(slot, conf_var, conf_type, conf_val)\n\n        # If we have an app tag and version set program them in\n        app_tag = sensor_graph.metadata_database.get('app_tag')\n        app_version = sensor_graph.metadata_database.get('app_version')\n\n        if app_tag is not None:\n            if app_version is None:\n                app_version = \"0.0\"\n\n            self.app_info = (app_tag, app_version)", "response": "Load a sensor_graph file into memory and persist it into the device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clear_queue(to_clear):\n\n    while not to_clear.empty():\n        try:\n            to_clear.get(False)\n            to_clear.task_done()\n        except queue.Empty:\n            continue", "response": "Clear all items from a queue safely."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmark the end of a recorded RPC.", "response": "def finish(self, status, response):\n        \"\"\"Mark the end of a recorded RPC.\"\"\"\n\n        self.response = binascii.hexlify(response).decode('utf-8')\n        self.status = status\n        self.runtime = monotonic() - self._start_time"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(self):\n\n        return \"{},{: <26},{:2d},{:#06x},{:#04x},{:5.0f},{: <40},{: <40},{}\".\\\n            format(self.connection, self.start_stamp.isoformat(), self.address, self.rpc_id,\n                   self.status, self.runtime * 1000, self.call, self.response, self.error)", "response": "Convert this recorded RPC into a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscanning the adapter for devices.", "response": "def scan(self, wait=None):\n        \"\"\"Return the devices that have been found for this device adapter.\n\n        If the adapter indicates that we need to explicitly tell it to probe for devices, probe now.\n        By default we return the list of seen devices immediately, however there are two cases where\n        we will sleep here for a fixed period of time to let devices show up in our result list:\n\n        - If we are probing then we wait for 'minimum_scan_time'\n        - If we are told an explicit wait time that overrides everything and we wait that long\n        \"\"\"\n\n        min_scan = self.adapter.get_config('minimum_scan_time', 0.0)\n        probe_required = self.adapter.get_config('probe_required', False)\n\n        # Figure out how long and if we need to wait before returning our scan results\n        wait_time = None\n        elapsed = monotonic() - self._start_time\n        if elapsed < min_scan:\n            wait_time = min_scan - elapsed\n\n        # If we need to probe for devices rather than letting them just bubble up, start the probe\n        # and then use our min_scan_time to wait for them to arrive via the normal _on_scan event\n        if probe_required:\n            self._loop.run_coroutine(self.adapter.probe())\n            wait_time = min_scan\n\n        # If an explicit wait is specified that overrides everything else\n        if wait is not None:\n            wait_time = wait\n\n        if wait_time is not None:\n            sleep(wait_time)\n\n        to_remove = set()\n\n        now = monotonic()\n\n        with self._scan_lock:\n            for name, value in self._scanned_devices.items():\n                if value['expiration_time'] < now:\n                    to_remove.add(name)\n\n            for name in to_remove:\n                del self._scanned_devices[name]\n\n            devices = sorted(self._scanned_devices.values(), key=lambda x: x['uuid'])\n\n        return devices"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to a specific device by its unique id.", "response": "def connect(self, uuid_value, wait=None):\n        \"\"\"Connect to a specific device by its uuid\n\n        Attempt to connect to a device that we have previously scanned using its UUID.\n        If wait is not None, then it is used in the same was a scan(wait) to override\n        default wait times with an explicit value.\n\n        Args:\n            uuid_value (int): The unique id of the device that we would like to connect to.\n            wait (float): Optional amount of time to force the device adapter to wait before\n                attempting to connect.\n        \"\"\"\n\n        if self.connected:\n            raise HardwareError(\"Cannot connect when we are already connected\")\n\n        if uuid_value not in self._scanned_devices:\n            self.scan(wait=wait)\n\n        with self._scan_lock:\n            if uuid_value not in self._scanned_devices:\n                raise HardwareError(\"Could not find device to connect to by UUID\", uuid=uuid_value)\n\n            connstring = self._scanned_devices[uuid_value]['connection_string']\n\n        self.connect_direct(connstring)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_direct(self, connection_string, no_rpc=False, force=False):\n\n        if not force and self.connected:\n            raise HardwareError(\"Cannot connect when we are already connected to '%s'\" % self.connection_string)\n\n        self._loop.run_coroutine(self.adapter.connect(0, connection_string))\n\n        try:\n            if no_rpc:\n                self._logger.info(\"Not opening RPC interface on device %s\", self.connection_string)\n            else:\n                self._loop.run_coroutine(self.adapter.open_interface(0, 'rpc'))\n        except HardwareError as exc:\n            self._logger.exception(\"Error opening RPC interface on device %s\", connection_string)\n            self._loop.run_coroutine(self.adapter.disconnect(0))\n            raise exc\n        except Exception as exc:\n            self._logger.exception(\"Error opening RPC interface on device %s\", connection_string)\n            self._loop.run_coroutine(self.adapter.disconnect(0))\n            raise HardwareError(\"Could not open RPC interface on device due to an exception: %s\" % str(exc)) from exc\n\n        self.connected = True\n        self.connection_string = connection_string\n        self.connection_interrupted = False", "response": "Connect to a device using a stream specific connection string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisconnecting from the device that we are currently connected to.", "response": "def disconnect(self):\n        \"\"\"Disconnect from the device that we are currently connected to.\"\"\"\n\n        if not self.connected:\n            raise HardwareError(\"Cannot disconnect when we are not connected\")\n\n        # Close the streaming and tracing interfaces when we disconnect\n        self._reports = None\n        self._traces = None\n\n        self._loop.run_coroutine(self.adapter.disconnect(0))\n        self.connected = False\n        self.connection_interrupted = False\n        self.connection_string = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _try_reconnect(self):\n\n        try:\n            if self.connection_interrupted:\n                self.connect_direct(self.connection_string, force=True)\n                self.connection_interrupted = False\n                self.connected = True\n\n                # Reenable streaming interface if that was open before as well\n                if self._reports is not None:\n                    self._loop.run_coroutine(self.adapter.open_interface(0, 'streaming'))\n\n                # Reenable tracing interface if that was open before as well\n                if self._traces is not None:\n                    self._loop.run_coroutine(self.adapter.open_interface(0, 'tracing'))\n        except HardwareError as exc:\n            self._logger.exception(\"Error reconnecting to device after an unexpected disconnect\")\n            raise HardwareError(\"Device disconnected unexpectedly and we could not reconnect\", reconnect_error=exc) from exc", "response": "Try to recover an interrupted connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend an RPC to our connected device.", "response": "def send_rpc(self, address, rpc_id, call_payload, timeout=3.0):\n        \"\"\"Send an rpc to our connected device.\n\n        The device must already be connected and the rpc interface open.  This\n        method will synchronously send an RPC and wait for the response.  Any\n        RPC errors will be raised as exceptions and if there were no errors, the\n        RPC's response payload will be returned as a binary bytearray.\n\n        See :meth:`AbstractDeviceAdapter.send_rpc` for documentation of the possible\n        exceptions that can be raised here.\n\n        Args:\n            address (int): The tile address containing the RPC\n            rpc_id (int): The ID of the RPC that we wish to call.\n            call_payload (bytes): The payload containing encoded arguments for the\n                RPC.\n            timeout (float): The maximum number of seconds to wait for the RPC to\n                finish.  Defaults to 3s.\n\n        Returns:\n            bytearray: The RPC's response payload.\n        \"\"\"\n\n        if not self.connected:\n            raise HardwareError(\"Cannot send an RPC if we are not in a connected state\")\n\n        if timeout is None:\n            timeout = 3.0\n\n        status = -1\n        payload = b''\n        recording = None\n\n        if self.connection_interrupted:\n            self._try_reconnect()\n\n        if self._record is not None:\n            recording = _RecordedRPC(self.connection_string, address, rpc_id, call_payload)\n            recording.start()\n\n        try:\n            payload = self._loop.run_coroutine(self.adapter.send_rpc(0, address, rpc_id, call_payload, timeout))\n            status, payload = pack_rpc_response(payload, None)\n        except VALID_RPC_EXCEPTIONS as exc:\n            status, payload = pack_rpc_response(payload, exc)\n\n        if self._record is not None:\n            recording.finish(status, payload)\n            self._recording.append(recording)\n\n        if self.connection_interrupted:\n            self._try_reconnect()\n\n        return unpack_rpc_response(status, payload, rpc_id, address)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_highspeed(self, data, progress_callback):\n\n        if not self.connected:\n            raise HardwareError(\"Cannot send a script if we are not in a connected state\")\n\n        if isinstance(data, str) and not isinstance(data, bytes):\n            raise ArgumentError(\"You must send bytes or bytearray to _send_highspeed\", type=type(data))\n\n        if not isinstance(data, bytes):\n            data = bytes(data)\n\n        try:\n            self._on_progress = progress_callback\n            self._loop.run_coroutine(self.adapter.send_script(0, data))\n        finally:\n            self._on_progress = None", "response": "Send a script to a device at highspeed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enable_streaming(self):\n\n        if not self.connected:\n            raise HardwareError(\"Cannot enable streaming if we are not in a connected state\")\n\n        if self._reports is not None:\n            _clear_queue(self._reports)\n            return self._reports\n\n        self._reports = queue.Queue()\n        self._loop.run_coroutine(self.adapter.open_interface(0, 'streaming'))\n\n        return self._reports", "response": "Enable streaming for the specified set of reports."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enable_tracing(self):\n\n        if not self.connected:\n            raise HardwareError(\"Cannot enable tracing if we are not in a connected state\")\n\n        if self._traces is not None:\n            _clear_queue(self._traces)\n            return self._traces\n\n        self._traces = queue.Queue()\n        self._loop.run_coroutine(self.adapter.open_interface(0, 'tracing'))\n\n        return self._traces", "response": "Enable tracing for the specified set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbeginning accumulating broadcast reports received from all devices.", "response": "def enable_broadcasting(self):\n        \"\"\"Begin accumulating broadcast reports received from all devices.\n\n        This method will allocate a queue to receive broadcast reports that\n        will be filled asynchronously as broadcast reports are received.\n\n        Returns:\n            queue.Queue: A queue that will be filled with braodcast reports.\n        \"\"\"\n\n        if self._broadcast_reports is not None:\n            _clear_queue(self._broadcast_reports)\n            return self._broadcast_reports\n\n        self._broadcast_reports = queue.Queue()\n        return self._broadcast_reports"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen the debug interface on the connected device.", "response": "def enable_debug(self):\n        \"\"\"Open the debug interface on the connected device.\"\"\"\n\n        if not self.connected:\n            raise HardwareError(\"Cannot enable debug if we are not in a connected state\")\n\n        self._loop.run_coroutine(self.adapter.open_interface(0, 'debug'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debug_command(self, cmd, args=None, progress_callback=None):\n\n        if args is None:\n            args = {}\n\n        try:\n            self._on_progress = progress_callback\n            return self._loop.run_coroutine(self.adapter.debug(0, cmd, args))\n        finally:\n            self._on_progress = None", "response": "Send a debug command to the connected device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n\n        try:\n            self._loop.run_coroutine(self.adapter.stop())\n        finally:\n            self._save_recording()", "response": "Close this adapter stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _on_disconnect(self):\n\n        self._logger.info(\"Connection to device %s was interrupted\", self.connection_string)\n        self.connection_interrupted = True", "response": "Callback when a device is disconnected unexpectedly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef midl_emitter(target, source, env):\n    base, _ = SCons.Util.splitext(str(target[0]))\n    tlb = target[0]\n    incl = base + '.h'\n    interface = base + '_i.c'\n    targets = [tlb, incl, interface]\n\n    midlcom = env['MIDLCOM']\n\n    if midlcom.find('/proxy') != -1:\n        proxy = base + '_p.c'\n        targets.append(proxy)\n    if midlcom.find('/dlldata') != -1:\n        dlldata = base + '_data.c'\n        targets.append(dlldata)\n\n    return (targets, source)", "response": "Produces a list of outputs from the MIDL compiler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding Builders and construction variables for midl to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for midl to an Environment.\"\"\"\n\n    env['MIDL']          = 'MIDL.EXE'\n    env['MIDLFLAGS']     = SCons.Util.CLVar('/nologo')\n    env['MIDLCOM']       = '$MIDL $MIDLFLAGS /tlb ${TARGETS[0]} /h ${TARGETS[1]} /iid ${TARGETS[2]} /proxy ${TARGETS[3]} /dlldata ${TARGETS[4]} $SOURCE 2> NUL'\n    env['BUILDERS']['TypeLibrary'] = midl_builder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding Builders and construction variables for ar to an Environment.", "response": "def generate(env):\n    SCons.Tool.bcc32.findIt('tlib', env)\n    \"\"\"Add Builders and construction variables for ar to an Environment.\"\"\"\n    SCons.Tool.createStaticLibBuilder(env)\n    env['AR']          = 'tlib'\n    env['ARFLAGS']     = SCons.Util.CLVar('')\n    env['ARCOM']       = '$AR $TARGET $ARFLAGS /a $SOURCES'\n    env['LIBPREFIX']   = ''\n    env['LIBSUFFIX']   = '.lib'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef File(name, dbm_module=None):\n    global ForDirectory, DB_Name, DB_Module\n    if name is None:\n        ForDirectory = DirFile\n        DB_Module = None\n    else:\n        ForDirectory = DB\n        DB_Name = name\n        if not dbm_module is None:\n            DB_Module = dbm_module", "response": "A function to set the name of the file that is used to store all signatures in a global. sconsign. db* file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_entry(self, filename, obj):\n        self.entries[filename] = obj\n        self.dirty = True", "response": "Set the entry for the given filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, sync=1):\n        if not self.dirty:\n            return\n\n        self.merge()\n\n        temp = os.path.join(self.dir.get_internal_path(), '.scons%d' % os.getpid())\n        try:\n            file = open(temp, 'wb')\n            fname = temp\n        except IOError:\n            try:\n                file = open(self.sconsign, 'wb')\n                fname = self.sconsign\n            except IOError:\n                return\n        for key, entry in self.entries.items():\n            entry.convert_to_sconsign()\n        pickle.dump(self.entries, file, PICKLE_PROTOCOL)\n        file.close()\n        if fname != self.sconsign:\n            try:\n                mode = os.stat(self.sconsign)[0]\n                os.chmod(self.sconsign, 0o666)\n                os.unlink(self.sconsign)\n            except (IOError, OSError):\n                # Try to carry on in the face of either OSError\n                # (things like permission issues) or IOError (disk\n                # or network issues).  If there's a really dangerous\n                # issue, it should get re-raised by the calls below.\n                pass\n            try:\n                os.rename(fname, self.sconsign)\n            except OSError:\n                # An OSError failure to rename may indicate something\n                # like the directory has no write permission, but\n                # the .sconsign file itself might still be writable,\n                # so try writing on top of it directly.  An IOError\n                # here, or in any of the following calls, would get\n                # raised, indicating something like a potentially\n                # serious disk or network issue.\n                open(self.sconsign, 'wb').write(open(fname, 'rb').read())\n                os.chmod(self.sconsign, mode)\n        try:\n            os.unlink(temp)\n        except (IOError, OSError):\n            pass", "response": "Write the. sconsign file to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(env):\n    link.generate(env)\n    \n    env['LINK'] = env.Detect(linkers) or 'cc'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -shared')\n\n    # __RPATH is set to $_RPATH in the platform specification if that\n    # platform supports it.\n    env['RPATHPREFIX'] = '-rpath '\n    env['RPATHSUFFIX'] = ''\n    env['_RPATH'] = '${_concat(RPATHPREFIX, RPATH, RPATHSUFFIX, __env__)}'", "response": "Add Builders and construction variables for MIPSPro to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the hit count for all the counters AttributeNames collected so far.", "response": "def Dump(title=None):\n    \"\"\" Dump the hit/miss count for all the counters\n        collected so far.\n    \"\"\"\n    if title:\n        print(title)\n    for counter in sorted(CounterList):\n        CounterList[counter].display()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef CountMethodCall(fn):\n    if use_memoizer:\n        def wrapper(self, *args, **kwargs):\n            global CounterList\n            key = self.__class__.__name__+'.'+fn.__name__\n            if key not in CounterList:\n                CounterList[key] = CountValue(self.__class__.__name__, fn.__name__)\n            CounterList[key].count(self, *args, **kwargs)\n            return fn(self, *args, **kwargs)\n        wrapper.__name__= fn.__name__\n        return wrapper\n    else:\n        return fn", "response": "Decorator for counting memoization hits and misses while retrieving\n        a simple value in a class method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CountDictCall(keyfunc):\n    def decorator(fn):\n        if use_memoizer:\n            def wrapper(self, *args, **kwargs):\n                global CounterList\n                key = self.__class__.__name__+'.'+fn.__name__\n                if key not in CounterList:\n                    CounterList[key] = CountDict(self.__class__.__name__, fn.__name__, keyfunc)\n                CounterList[key].count(self, *args, **kwargs)\n                return fn(self, *args, **kwargs)\n            wrapper.__name__= fn.__name__\n            return wrapper\n        else:\n            return fn\n    return decorator", "response": "Decorator for counting memoizer hits and misses while accessing\n        dictionary values with a key - generating function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts whether the memoized value has already been set.", "response": "def count(self, *args, **kw):\n        \"\"\" Counts whether the memoized value has already been\n            set (a hit) or not (a miss).\n        \"\"\"\n        obj = args[0]\n        if self.method_name in obj._memo:\n            self.hit = self.hit + 1\n        else:\n            self.miss = self.miss + 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount whether the computed key value is already present in the memoization dictionary.", "response": "def count(self, *args, **kw):\n        \"\"\" Counts whether the computed key value is already present\n           in the memoization dictionary (a hit) or not (a miss).\n        \"\"\"\n        obj = args[0]\n        try:\n            memo_dict = obj._memo[self.method_name]\n        except KeyError:\n            self.miss = self.miss + 1\n        else:\n            key = self.keymaker(*args, **kw)\n            if key in memo_dict:\n                self.hit = self.hit + 1\n            else:\n                self.miss = self.miss + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def start(self):\n\n        await self.server.start()\n        self.port = self.server.port", "response": "Start the supervisor server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def prepare_conn(self, conn):\n\n        client_id = str(uuid.uuid4())\n        monitor = functools.partial(self.send_event, client_id)\n\n        self._logger.info(\"New client connection: %s\", client_id)\n\n        self.service_manager.add_monitor(monitor)\n\n        self.clients[client_id] = dict(connection=conn, monitor=monitor)\n        return client_id", "response": "Setup a new connection from a client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def teardown_conn(self, context):\n\n        client_id = context.user_data\n\n        self._logger.info(\"Tearing down client connection: %s\", client_id)\n        if client_id not in self.clients:\n            self._logger.warning(\"client_id %s did not exist in teardown_conn\", client_id)\n        else:\n            del self.clients[client_id]", "response": "Teardown a connection from a client."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends an event to a client.", "response": "async def send_event(self, client_id, service_name, event_name, event_info, directed_client=None):\n        \"\"\"Send an event to a client.\"\"\"\n\n        if directed_client is not None and directed_client != client_id:\n            return\n\n        client_info = self.clients.get(client_id)\n        if client_info is None:\n            self._logger.warning(\"Attempted to send event to invalid client id: %s\", client_id)\n            return\n\n        conn = client_info['connection']\n\n        event = dict(service=service_name)\n        if event_info is not None:\n            event['payload'] = event_info\n\n        self._logger.debug(\"Sending event: %s\", event)\n\n        await self.server.send_event(conn, event_name, event)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_rpc(self, msg, _context):\n\n        service = msg.get('name')\n        rpc_id = msg.get('rpc_id')\n        payload = msg.get('payload')\n        timeout = msg.get('timeout')\n\n        response_id = await self.service_manager.send_rpc_command(service, rpc_id, payload,\n                                                                  timeout)\n\n        try:\n            result = await self.service_manager.rpc_results.get(response_id, timeout=timeout)\n        except asyncio.TimeoutError:\n            self._logger.warning(\"RPC 0x%04X on service %s timed out after %f seconds\",\n                                 rpc_id, service, timeout)\n            result = dict(result='timeout', response=b'')\n\n        return result", "response": "Send an RPC to a service on behalf of a client."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresponding to an RPC previously sent to a service.", "response": "async def respond_rpc(self, msg, _context):\n        \"\"\"Respond to an RPC previously sent to a service.\"\"\"\n\n        rpc_id = msg.get('response_uuid')\n        result = msg.get('result')\n        payload = msg.get('response')\n\n        self.service_manager.send_rpc_response(rpc_id, result, payload)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def set_agent(self, msg, context):\n\n        service = msg.get('name')\n        client = context.user_data\n\n        self.service_manager.set_agent(service, client)", "response": "Mark a client as the RPC agent for a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def post_heartbeat(self, msg, _context):\n\n        name = msg.get('name')\n\n        await self.service_manager.send_heartbeat(name)", "response": "Update the status of a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the status of a service.", "response": "async def update_state(self, msg, _context):\n        \"\"\"Update the status of a service.\"\"\"\n\n        name = msg.get('name')\n        status = msg.get('new_status')\n\n        await self.service_manager.update_state(name, status)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def service_messages(self, msg, _context):\n\n        msgs = self.service_manager.service_messages(msg.get('name'))\n        return [x.to_dict() for x in msgs]", "response": "Get all messages for a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def service_headline(self, msg, _context):\n\n        headline = self.service_manager.service_headline(msg.get('name'))\n        if headline is not None:\n            headline = headline.to_dict()\n\n        return headline", "response": "Get the headline for a service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd Builders and construction variables for nasm to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for nasm to an Environment.\"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in ASSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.ASAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n\n    for suffix in ASPPSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.ASPPAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n\n    env['AS']        = 'nasm'\n    env['ASFLAGS']   = SCons.Util.CLVar('')\n    env['ASPPFLAGS'] = '$ASFLAGS'\n    env['ASCOM']     = '$AS $ASFLAGS -o $TARGET $SOURCES'\n    env['ASPPCOM']   = '$CC $ASPPFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS -c -o $TARGET $SOURCES'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(env):\n    link.generate(env)\n    \n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -G')\n\n    env['RPATHPREFIX'] = '-R'\n    env['RPATHSUFFIX'] = ''\n    env['_RPATH'] = '${_concat(RPATHPREFIX, RPATH, RPATHSUFFIX, __env__)}'\n\n    # Support for versioned libraries\n    link._setup_versioned_lib_variables(env, tool = 'sunlink', use_soname = True) \n    env['LINKCALLBACKS'] = link._versioned_lib_callbacks()", "response": "Add Builders and construction variables for Forte to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the first line of a multiline description", "response": "def _get_short_description(self):\n        \"\"\"Return the first line of a multiline description\n\n        Returns:\n            string: The short description, otherwise None\n        \"\"\"\n\n        if self.description is None:\n            return None\n\n        lines = [x for x in self.description.split('\\n')]\n        if len(lines) == 1:\n            return lines[0]\n        elif len(lines) >= 3 and lines[1] == '':\n            return lines[0]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the subsequent lines of a multiline description", "response": "def _get_long_description(self):\n        \"\"\"Return the subsequent lines of a multiline description\n\n        Returns:\n            string: The long description, otherwise None\n        \"\"\"\n\n        if self.description is None:\n            return None\n\n        lines = [x for x in self.description.split('\\n')]\n        if len(lines) == 1:\n            return None\n\n        elif len(lines) >= 3 and lines[1] == '':\n            return '\\n'.join(lines[2:])\n\n        return self.description"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap_lines(self, text, indent_level, indent_size=4):\n\n        indent = ' '*indent_size*indent_level\n        lines = text.split('\\n')\n\n        wrapped_lines = []\n\n        for line in lines:\n            if line == '':\n                wrapped_lines.append(line)\n            else:\n                wrapped_lines.append(indent + line)\n\n        return '\\n'.join(wrapped_lines)", "response": "Indent a multiline string containing the lines of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat the name of this verifier", "response": "def format_name(self, name, indent_size=4):\n        \"\"\"Format the name of this verifier\n\n        The name will be formatted as:\n            <name>: <short description>\n                long description if one is given followed by \\n\n                otherwise no long description\n\n        Args:\n            name (string): A name for this validator\n            indent_size (int): The number of spaces to indent the\n                description\n        Returns:\n            string: The formatted name block with a short and or long\n                description appended.\n        \"\"\"\n\n        name_block = ''\n\n        if self.short_desc is None:\n            name_block += name + '\\n'\n        else:\n            name_block += name + ': ' + self.short_desc + '\\n'\n\n        if self.long_desc is not None:\n            name_block += self.wrap_lines(self.long_desc, 1, indent_size=indent_size)\n            name_block += '\\n'\n\n        return name_block"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef trim_whitespace(self, text):\n\n        lines = text.split('\\n')\n        new_lines = [x.lstrip() for x in lines]\n\n        return '\\n'.join(new_lines)", "response": "Removes leading whitespace from each line of a multiline string\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an UpdateRecord subclass from binary record data.", "response": "def FromBinary(cls, record_data, record_count=1):\n        \"\"\"Create an UpdateRecord subclass from binary record data.\n\n        This should be called with a binary record blob (NOT including the\n        record type header) and it will decode it into a SetGraphOnlineRecord.\n\n        Args:\n            record_data (bytearray): The raw record data that we wish to parse\n                into an UpdateRecord subclass NOT including its 8 byte record header.\n            record_count (int): The number of records included in record_data.\n\n        Raises:\n            ArgumentError: If the record_data is malformed and cannot be parsed.\n\n        Returns:\n            SetGraphOnlineRecord: The decoded reflash tile record.\n        \"\"\"\n\n        _cmd, address, _resp_length, payload = cls._parse_rpc_info(record_data)\n\n        try:\n            online, = struct.unpack(\"<H\", payload)\n            online = bool(online)\n        except ValueError:\n            raise ArgumentError(\"Could not decode payload for set_online record\", payload=payload)\n        return SetGraphOnlineRecord(online, address)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __extend_targets_sources(target, source):\n    if not SCons.Util.is_List(target):\n        target = [target]\n    if not source:\n        source = target[:]\n    elif not SCons.Util.is_List(source):\n        source = [source]\n    if len(target) < len(source):\n        target.extend(source[len(target):])\n        \n    return target, source", "response": "Extend target and source files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __select_builder(lxml_builder, libxml2_builder, cmdline_builder):\n    if prefer_xsltproc:\n        return cmdline_builder\n    \n    if not has_libxml2:\n        # At the moment we prefer libxml2 over lxml, the latter can lead\n        # to conflicts when installed together with libxml2.\n        if has_lxml:\n            return lxml_builder\n        else:\n            return cmdline_builder\n\n    return libxml2_builder", "response": "Select a builder based on which Python modules are present."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nensure that the target t has the given suffix.", "response": "def __ensure_suffix(t, suffix):\n    \"\"\" Ensure that the target t has the given suffix. \"\"\"\n    tpath = str(t)\n    if not tpath.endswith(suffix):\n        return tpath+suffix\n    \n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nensuring that the target t has the given suffix and return the file s stem.", "response": "def __ensure_suffix_stem(t, suffix):\n    \"\"\" Ensure that the target t has the given suffix, and return the file's stem. \"\"\"\n    tpath = str(t)\n    if not tpath.endswith(suffix):\n        stem = tpath\n        tpath += suffix\n        \n        return tpath, stem\n    else:\n        stem, ext = os.path.splitext(tpath)\n    \n    return t, stem"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the text for the given root node.", "response": "def __get_xml_text(root):\n    \"\"\" Return the text for the given root node (xml.dom.minidom). \"\"\"\n    txt = \"\"\n    for e in root.childNodes:\n        if (e.nodeType == e.TEXT_NODE):\n            txt += e.data\n    return txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the output directory base_dir if it does not exist.", "response": "def __create_output_dir(base_dir):\n    \"\"\" Ensure that the output directory base_dir exists. \"\"\"\n    root, tail = os.path.split(base_dir)\n    dir = None\n    if tail:\n        if base_dir.endswith('/'):\n            dir = base_dir\n        else:\n            dir = root\n    else:\n        if base_dir.endswith('/'):\n            dir = base_dir\n    \n    if dir and not os.path.isdir(dir):\n        os.makedirs(dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __detect_cl_tool(env, chainkey, cdict, cpriority=None):\n    if env.get(chainkey,'') == '':\n        clpath = ''\n\n        if cpriority is None:\n            cpriority = cdict.keys()\n        for cltool in cpriority:\n            if __debug_tool_location:\n                print(\"DocBook: Looking for %s\"%cltool)\n            clpath = env.WhereIs(cltool)\n            if clpath:\n                if __debug_tool_location:\n                    print(\"DocBook: Found:%s\"%cltool)\n                env[chainkey] = clpath\n                if not env[chainkey + 'COM']:\n                    env[chainkey + 'COM'] = cdict[cltool]\n                break", "response": "Helper function to detect a command line tool from the list of command line tools and initialize environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _detect(env):\n    global prefer_xsltproc\n    \n    if env.get('DOCBOOK_PREFER_XSLTPROC',''):\n        prefer_xsltproc = True\n        \n    if ((not has_libxml2 and not has_lxml) or (prefer_xsltproc)):\n        # Try to find the XSLT processors\n        __detect_cl_tool(env, 'DOCBOOK_XSLTPROC', xsltproc_com, xsltproc_com_priority)\n        __detect_cl_tool(env, 'DOCBOOK_XMLLINT', xmllint_com)\n\n    __detect_cl_tool(env, 'DOCBOOK_FOP', fop_com, ['fop','xep','jw'])", "response": "Detect all the command line tools that we might need for creating\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a new XML document using the libxml2 module.", "response": "def __build_libxml2(target, source, env):\n    \"\"\"\n    General XSLT builder (HTML/FO), using the libxml2 module.\n    \"\"\"\n    xsl_style = env.subst('$DOCBOOK_XSL')\n    styledoc = libxml2.parseFile(xsl_style)\n    style = libxslt.parseStylesheetDoc(styledoc)\n    doc = libxml2.readFile(str(source[0]),None,libxml2.XML_PARSE_NOENT)\n    # Support for additional parameters\n    parampass = {}\n    if parampass:\n        result = style.applyStylesheet(doc, parampass)\n    else:\n        result = style.applyStylesheet(doc, None)\n    style.saveResultToFilename(str(target[0]), result, 0)\n    style.freeStylesheet()\n    doc.freeDoc()\n    result.freeDoc()\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __build_lxml(target, source, env):\n    from lxml import etree\n    \n    xslt_ac = etree.XSLTAccessControl(read_file=True, \n                                      write_file=True, \n                                      create_dir=True, \n                                      read_network=False, \n                                      write_network=False)\n    xsl_style = env.subst('$DOCBOOK_XSL')\n    xsl_tree = etree.parse(xsl_style)\n    transform = etree.XSLT(xsl_tree, access_control=xslt_ac)\n    doc = etree.parse(str(source[0]))\n    # Support for additional parameters\n    parampass = {}\n    if parampass:\n        result = transform(doc, **parampass)\n    else:\n        result = transform(doc)\n        \n    try:\n        of = open(str(target[0]), \"wb\")\n        of.write(of.write(etree.tostring(result, pretty_print=True)))\n        of.close()\n    except:\n        pass\n\n    return None", "response": "Builds the XML file using the lxml module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __xinclude_libxml2(target, source, env):\n    doc = libxml2.readFile(str(source[0]), None, libxml2.XML_PARSE_NOENT)\n    doc.xincludeProcessFlags(libxml2.XML_PARSE_NOENT)\n    doc.saveFile(str(target[0]))\n    doc.freeDoc()\n\n    return None", "response": "Resolve XIncludes using the libxml2 module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving XIncludes using the lxml module.", "response": "def __xinclude_lxml(target, source, env):\n    \"\"\"\n    Resolving XIncludes, using the lxml module.\n    \"\"\"\n    from lxml import etree\n    \n    doc = etree.parse(str(source[0]))\n    doc.xinclude()\n    try:\n        doc.write(str(target[0]), xml_declaration=True, \n                  encoding=\"UTF-8\", pretty_print=True)\n    except:\n        pass\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DocbookMan(env, target, source=None, *args, **kw):\n    # Init list of targets/sources\n    target, source = __extend_targets_sources(target, source)\n\n    # Init XSL stylesheet\n    __init_xsl_stylesheet(kw, env, '$DOCBOOK_DEFAULT_XSL_MAN', ['manpages','docbook.xsl'])\n\n    # Setup builder\n    __builder = __select_builder(__lxml_builder, __libxml2_builder, __xsltproc_builder)\n\n    # Create targets\n    result = []\n    for t,s in zip(target,source):\n        volnum = \"1\"\n        outfiles = []\n        srcfile = __ensure_suffix(str(s),'.xml')\n        if os.path.isfile(srcfile):\n            try:\n                import xml.dom.minidom\n                \n                dom = xml.dom.minidom.parse(__ensure_suffix(str(s),'.xml'))\n                # Extract volume number, default is 1\n                for node in dom.getElementsByTagName('refmeta'):\n                    for vol in node.getElementsByTagName('manvolnum'):\n                        volnum = __get_xml_text(vol)\n                        \n                # Extract output filenames\n                for node in dom.getElementsByTagName('refnamediv'):\n                    for ref in node.getElementsByTagName('refname'):\n                        outfiles.append(__get_xml_text(ref)+'.'+volnum)\n                        \n            except:\n                # Use simple regex parsing \n                f = open(__ensure_suffix(str(s),'.xml'), 'r')\n                content = f.read()\n                f.close()\n                \n                for m in re_manvolnum.finditer(content):\n                    volnum = m.group(1)\n                    \n                for m in re_refname.finditer(content):\n                    outfiles.append(m.group(1)+'.'+volnum)\n            \n            if not outfiles:\n                # Use stem of the source file\n                spath = str(s)\n                if not spath.endswith('.xml'):\n                    outfiles.append(spath+'.'+volnum)\n                else:\n                    stem, ext = os.path.splitext(spath)\n                    outfiles.append(stem+'.'+volnum)\n        else:\n            # We have to completely rely on the given target name\n            outfiles.append(t)\n            \n        __builder.__call__(env, outfiles[0], s, **kw)\n        env.Depends(outfiles[0], kw['DOCBOOK_XSL'])\n        result.append(outfiles[0])\n        if len(outfiles) > 1:\n            env.Clean(outfiles[0], outfiles[1:])\n\n        \n    return result", "response": "A pseudo - Builder providing a Docbook toolchain for Man page output."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DocbookSlidesPdf(env, target, source=None, *args, **kw):\n    # Init list of targets/sources\n    target, source = __extend_targets_sources(target, source)\n\n    # Init XSL stylesheet\n    __init_xsl_stylesheet(kw, env, '$DOCBOOK_DEFAULT_XSL_SLIDESPDF', ['slides','fo','plain.xsl'])\n\n    # Setup builder\n    __builder = __select_builder(__lxml_builder, __libxml2_builder, __xsltproc_builder)\n\n    # Create targets\n    result = []\n    for t,s in zip(target,source):\n        t, stem = __ensure_suffix_stem(t, '.pdf')\n        xsl = __builder.__call__(env, stem+'.fo', s, **kw)\n        env.Depends(xsl, kw['DOCBOOK_XSL'])        \n        result.extend(xsl)\n        result.extend(__fop_builder.__call__(env, t, xsl, **kw))\n\n    return result", "response": "A pseudo - Builder providing a Docbook toolchain for PDF slides output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DocbookSlidesHtml(env, target, source=None, *args, **kw):\n    # Init list of targets/sources\n    if not SCons.Util.is_List(target):\n        target = [target]\n    if not source:\n        source = target\n        target = ['index.html']\n    elif not SCons.Util.is_List(source):\n        source = [source]    \n\n    # Init XSL stylesheet\n    __init_xsl_stylesheet(kw, env, '$DOCBOOK_DEFAULT_XSL_SLIDESHTML', ['slides','html','plain.xsl'])\n\n    # Setup builder\n    __builder = __select_builder(__lxml_builder, __libxml2_builder, __xsltproc_builder)\n\n    # Detect base dir\n    base_dir = kw.get('base_dir', '')\n    if base_dir:\n        __create_output_dir(base_dir)\n\n    # Create targets\n    result = []\n    r = __builder.__call__(env, __ensure_suffix(str(target[0]), '.html'), source[0], **kw)\n    env.Depends(r, kw['DOCBOOK_XSL'])\n    result.extend(r)\n    # Add supporting files for cleanup\n    env.Clean(r, [os.path.join(base_dir, 'toc.html')] +\n                 glob.glob(os.path.join(base_dir, 'foil*.html')))\n\n    return result", "response": "A pseudo - Builder providing a Docbook toolchain for HTML slides output."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DocbookXInclude(env, target, source, *args, **kw):\n    # Init list of targets/sources\n    target, source = __extend_targets_sources(target, source)\n\n    # Setup builder\n    __builder = __select_builder(__xinclude_lxml_builder,__xinclude_libxml2_builder,__xmllint_builder)\n            \n    # Create targets\n    result = []\n    for t,s in zip(target,source):\n        result.extend(__builder.__call__(env, t, s, **kw))\n        \n    return result", "response": "A pseudo - Builder for resolving XIncludes in a separate processing step."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DocbookXslt(env, target, source=None, *args, **kw):\n    # Init list of targets/sources\n    target, source = __extend_targets_sources(target, source)\n    \n    # Init XSL stylesheet\n    kw['DOCBOOK_XSL'] = kw.get('xsl', 'transform.xsl')\n\n    # Setup builder\n    __builder = __select_builder(__lxml_builder, __libxml2_builder, __xsltproc_builder)\n    \n    # Create targets\n    result = []\n    for t,s in zip(target,source):\n        r = __builder.__call__(env, t, s, **kw)\n        env.Depends(r, kw['DOCBOOK_XSL'])\n        result.extend(r)\n\n    return result", "response": "A pseudo - Builder that applies a simple XSL transformation to the input file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding Builders and construction variables for docbook to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for docbook to an Environment.\"\"\"\n\n    env.SetDefault(\n        # Default names for customized XSL stylesheets\n        DOCBOOK_DEFAULT_XSL_EPUB = '',\n        DOCBOOK_DEFAULT_XSL_HTML = '',\n        DOCBOOK_DEFAULT_XSL_HTMLCHUNKED = '',\n        DOCBOOK_DEFAULT_XSL_HTMLHELP = '',\n        DOCBOOK_DEFAULT_XSL_PDF = '',\n        DOCBOOK_DEFAULT_XSL_MAN = '',\n        DOCBOOK_DEFAULT_XSL_SLIDESPDF = '',\n        DOCBOOK_DEFAULT_XSL_SLIDESHTML = '',\n        \n        # Paths to the detected executables\n        DOCBOOK_XSLTPROC = '',\n        DOCBOOK_XMLLINT = '',\n        DOCBOOK_FOP = '',\n        \n        # Additional flags for the text processors\n        DOCBOOK_XSLTPROCFLAGS = SCons.Util.CLVar(''),\n        DOCBOOK_XMLLINTFLAGS = SCons.Util.CLVar(''),\n        DOCBOOK_FOPFLAGS = SCons.Util.CLVar(''),\n        DOCBOOK_XSLTPROCPARAMS = SCons.Util.CLVar(''),\n        \n        # Default command lines for the detected executables\n        DOCBOOK_XSLTPROCCOM = xsltproc_com['xsltproc'],\n        DOCBOOK_XMLLINTCOM = xmllint_com['xmllint'],\n        DOCBOOK_FOPCOM = fop_com['fop'],\n\n        # Screen output for the text processors\n        DOCBOOK_XSLTPROCCOMSTR = None,\n        DOCBOOK_XMLLINTCOMSTR = None,\n        DOCBOOK_FOPCOMSTR = None,\n        \n        )\n    _detect(env)\n\n    env.AddMethod(DocbookEpub, \"DocbookEpub\")\n    env.AddMethod(DocbookHtml, \"DocbookHtml\")\n    env.AddMethod(DocbookHtmlChunked, \"DocbookHtmlChunked\")\n    env.AddMethod(DocbookHtmlhelp, \"DocbookHtmlhelp\")\n    env.AddMethod(DocbookPdf, \"DocbookPdf\")\n    env.AddMethod(DocbookMan, \"DocbookMan\")\n    env.AddMethod(DocbookSlidesPdf, \"DocbookSlidesPdf\")\n    env.AddMethod(DocbookSlidesHtml, \"DocbookSlidesHtml\")\n    env.AddMethod(DocbookXInclude, \"DocbookXInclude\")\n    env.AddMethod(DocbookXslt, \"DocbookXslt\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute this statement on the sensor_graph given the current scope tree.", "response": "def execute(self, sensor_graph, scope_stack):\n        \"\"\"Execute this statement on the sensor_graph given the current scope tree.\n\n        This adds a single node to the sensor graph with either the\n        copy_latest_a, copy_all_a or average_a function as is processing function.\n\n        If there is an explicit stream passed, that is used as input a with the\n        current scope's trigger as input b, otherwise the current scope's trigger\n        is used as input a.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        trigger_stream, trigger_cond = parent.trigger_chain()\n\n        op = 'copy_latest_a'\n        if self.all:\n            op = 'copy_all_a'\n        elif self.average:\n            op = 'average_a'\n        elif self.count:\n            op = 'copy_count_a'\n\n        if self.explicit_input:\n            # If root node is an input, create an intermediate node with an unbuffered node\n            if self.explicit_input.input:\n                unbuffered_stream = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n                sensor_graph.add_node(u\"({} always) => {} using {}\".format(self.explicit_input, unbuffered_stream, 'copy_latest_a'))\n                sensor_graph.add_node(u\"({} always && {} {}) => {} using {}\".format(unbuffered_stream, trigger_stream, trigger_cond, self.output, op))\n            else:\n                sensor_graph.add_node(u\"({} always && {} {}) => {} using {}\".format(self.explicit_input, trigger_stream, trigger_cond, self.output, op))\n        elif self.constant_input is not None:\n            const_stream = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n\n            sensor_graph.add_node(u\"({} always && {} {}) => {} using {}\".format(const_stream, trigger_stream, trigger_cond, self.output, op))\n            sensor_graph.add_constant(const_stream, self.constant_input)\n        else:\n            sensor_graph.add_node(u\"({} {}) => {} using {}\".format(trigger_stream, trigger_cond, self.output, op))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify(self, obj):\n\n        if self.encoding == 'none' and not isinstance(obj, (bytes, bytearray)):\n            raise ValidationError('Byte object was not either bytes or a bytearray', type=obj.__class__.__name__)\n        elif self.encoding == 'base64':\n            try:\n                data = base64.b64decode(obj)\n                return data\n            except TypeError:\n                raise ValidationError(\"Could not decode base64 encoded bytes\", obj=obj)\n        elif self.encoding == 'hex':\n            try:\n                data = binascii.unhexlify(obj)\n                return data\n            except TypeError:\n                raise ValidationError(\"Could not decode hex encoded bytes\", obj=obj)\n\n        return obj", "response": "Verify that the object conforms to this verifier s schema\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format(self, indent_level, indent_size=4):\n\n        name = self.format_name('Bytes', indent_size)\n        return self.wrap_lines(name, indent_level, indent_size)", "response": "Format this verifier\n            string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self):\n\n        try:\n            with open(self.path, \"w\") as f:\n                f.writelines(self.contents)\n        except IOError as e:\n            raise InternalError(\"Could not write RCFile contents\", name=self.name, path=self.path, error_message=str(e))", "response": "Save the contents of the RCFile to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def probe_message(self, _message, context):\n        client_id = context.user_data\n\n        await self.probe(client_id)", "response": "Handle a probe message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a connect message.", "response": "async def connect_message(self, message, context):\n        \"\"\"Handle a connect message.\n\n        See :meth:`AbstractDeviceAdapter.connect`.\n        \"\"\"\n        conn_string = message.get('connection_string')\n        client_id = context.user_data\n\n        await self.connect(client_id, conn_string)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a disconnect message.", "response": "async def disconnect_message(self, message, context):\n        \"\"\"Handle a disconnect message.\n\n        See :meth:`AbstractDeviceAdapter.disconnect`.\n        \"\"\"\n\n        conn_string = message.get('connection_string')\n        client_id = context.user_data\n\n        await self.disconnect(client_id, conn_string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle an open_interface message.", "response": "async def open_interface_message(self, message, context):\n        \"\"\"Handle an open_interface message.\n\n        See :meth:`AbstractDeviceAdapter.open_interface`.\n        \"\"\"\n\n        conn_string = message.get('connection_string')\n        interface = message.get('interface')\n        client_id = context.user_data\n\n        await self.open_interface(client_id, conn_string, interface)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a close_interface message.", "response": "async def close_interface_message(self, message, context):\n        \"\"\"Handle a close_interface message.\n\n        See :meth:`AbstractDeviceAdapter.close_interface`.\n        \"\"\"\n\n        conn_string = message.get('connection_string')\n        interface = message.get('interface')\n        client_id = context.user_data\n\n        await self.close_interface(client_id, conn_string, interface)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a send_rpc message.", "response": "async def send_rpc_message(self, message, context):\n        \"\"\"Handle a send_rpc message.\n\n        See :meth:`AbstractDeviceAdapter.send_rpc`.\n        \"\"\"\n\n        conn_string = message.get('connection_string')\n        rpc_id = message.get('rpc_id')\n        address = message.get('address')\n        timeout = message.get('timeout')\n        payload = message.get('payload')\n        client_id = context.user_data\n\n        self._logger.debug(\"Calling RPC %d:0x%04X with payload %s on %s\",\n                           address, rpc_id, payload, conn_string)\n\n        response = bytes()\n        err = None\n        try:\n            response = await self.send_rpc(client_id, conn_string, address, rpc_id, payload, timeout=timeout)\n        except VALID_RPC_EXCEPTIONS as internal_err:\n            err = internal_err\n        except (DeviceAdapterError, DeviceServerError):\n            raise\n        except Exception as internal_err:\n            self._logger.warning(\"Unexpected exception calling RPC %d:0x%04x\", address, rpc_id, exc_info=True)\n            raise ServerCommandError('send_rpc', str(internal_err)) from internal_err\n\n        status, response = pack_rpc_response(response, err)\n        return {\n            'status': status,\n            'payload': base64.b64encode(response)\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def send_script_message(self, message, context):\n\n        script = message.get('script')\n        conn_string = message.get('connection_string')\n        client_id = context.user_data\n\n        if message.get('fragment_count') != 1:\n            raise DeviceServerError(client_id, conn_string, 'send_script', 'fragmented scripts are not yet supported')\n\n        await self.send_script(client_id, conn_string, script)", "response": "Handle a send_script message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle a debug command message.", "response": "async def debug_command_message(self, message, context):\n        \"\"\"Handle a debug message.\n\n        See :meth:`AbstractDeviceAdapter.debug`.\n        \"\"\"\n\n        conn_string = message.get('connection_string')\n        command = message.get('command')\n        args = message.get('args')\n        client_id = context.user_data\n\n        result = await self.debug(client_id, conn_string, command, args)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def client_event_handler(self, client_id, event_tuple, user_data):\n\n        #TODO: Support sending disconnection events\n\n        conn_string, event_name, event = event_tuple\n\n        if event_name == 'report':\n            report = event.serialize()\n            report['encoded_report'] = base64.b64encode(report['encoded_report'])\n            msg_payload = dict(connection_string=conn_string, serialized_report=report)\n            msg_name = OPERATIONS.NOTIFY_REPORT\n        elif event_name == 'trace':\n            encoded_payload = base64.b64encode(event)\n            msg_payload = dict(connection_string=conn_string, payload=encoded_payload)\n            msg_name = OPERATIONS.NOTIFY_TRACE\n        elif event_name == 'progress':\n            msg_payload = dict(connection_string=conn_string, operation=event.get('operation'),\n                               done_count=event.get('finished'), total_count=event.get('total'))\n            msg_name = OPERATIONS.NOTIFY_PROGRESS\n        elif event_name == 'device_seen':\n            msg_payload = event\n            msg_name = OPERATIONS.NOTIFY_DEVICE_FOUND\n        elif event_name == 'broadcast':\n            report = event.serialize()\n            report['encoded_report'] = base64.b64encode(report['encoded_report'])\n            msg_payload = dict(connection_string=conn_string, serialized_report=report)\n            msg_name = OPERATIONS.NOTIFY_BROADCAST\n        else:\n            self._logger.debug(\"Not forwarding unknown event over websockets: %s\", event_tuple)\n            return\n\n        try:\n            self._logger.debug(\"Sending event %s: %s\", msg_name, msg_payload)\n            await self.server.send_event(user_data, msg_name, msg_payload)\n        except websockets.exceptions.ConnectionClosed:\n            self._logger.debug(\"Could not send notification because connection was closed for client %s\", client_id)", "response": "This method is called by StandardDeviceServer when an event is received from a client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(env):\n    add_all_to_env(env)\n\n    fcomp = env.Detect(compilers) or 'f90'\n    env['FORTRAN']  = fcomp\n    env['F90']      = fcomp\n\n    env['SHFORTRAN']  = '$FORTRAN'\n    env['SHF90']      = '$F90'\n\n    env['SHFORTRANFLAGS'] = SCons.Util.CLVar('$FORTRANFLAGS -KPIC')\n    env['SHF90FLAGS'] = SCons.Util.CLVar('$F90FLAGS -KPIC')", "response": "Add Builders and construction variables for sun f90 compiler to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Builder(**kw):\n    composite = None\n    if 'generator' in kw:\n        if 'action' in kw:\n            raise UserError(\"You must not specify both an action and a generator.\")\n        kw['action'] = SCons.Action.CommandGeneratorAction(kw['generator'], {})\n        del kw['generator']\n    elif 'action' in kw:\n        source_ext_match = kw.get('source_ext_match', 1)\n        if 'source_ext_match' in kw:\n            del kw['source_ext_match']\n        if SCons.Util.is_Dict(kw['action']):\n            composite = DictCmdGenerator(kw['action'], source_ext_match)\n            kw['action'] = SCons.Action.CommandGeneratorAction(composite, {})\n            kw['src_suffix'] = composite.src_suffixes()\n        else:\n            kw['action'] = SCons.Action.Action(kw['action'])\n\n    if 'emitter' in kw:\n        emitter = kw['emitter']\n        if SCons.Util.is_String(emitter):\n            # This allows users to pass in an Environment\n            # variable reference (like \"$FOO\") as an emitter.\n            # We will look in that Environment variable for\n            # a callable to use as the actual emitter.\n            var = SCons.Util.get_environment_var(emitter)\n            if not var:\n                raise UserError(\"Supplied emitter '%s' does not appear to refer to an Environment variable\" % emitter)\n            kw['emitter'] = EmitterProxy(var)\n        elif SCons.Util.is_Dict(emitter):\n            kw['emitter'] = DictEmitter(emitter)\n        elif SCons.Util.is_List(emitter):\n            kw['emitter'] = ListEmitter(emitter)\n\n    result = BuilderBase(**kw)\n\n    if not composite is None:\n        result = CompositeBuilder(result, composite)\n\n    return result", "response": "A factory for creating a new Builder object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that the lists of target and source nodes are legal for this builder and environment. Raise errors or warnings as appropriate.", "response": "def _node_errors(builder, env, tlist, slist):\n    \"\"\"Validate that the lists of target and source nodes are\n    legal for this builder and environment.  Raise errors or\n    issue warnings as appropriate.\n    \"\"\"\n\n    # First, figure out if there are any errors in the way the targets\n    # were specified.\n    for t in tlist:\n        if t.side_effect:\n            raise UserError(\"Multiple ways to build the same target were specified for: %s\" % t)\n        if t.has_explicit_builder():\n            # Check for errors when the environments are different\n            # No error if environments are the same Environment instance\n            if (not t.env is None and not t.env is env and\n                    # Check OverrideEnvironment case - no error if wrapped Environments\n                    # are the same instance, and overrides lists match\n                    not (getattr(t.env, '__subject', 0) is getattr(env, '__subject', 1) and\n                         getattr(t.env, 'overrides', 0) == getattr(env, 'overrides', 1) and\n                         not builder.multi)):\n                action = t.builder.action\n                t_contents = t.builder.action.get_contents(tlist, slist, t.env)\n                contents = builder.action.get_contents(tlist, slist, env)\n\n                if t_contents == contents:\n                    msg = \"Two different environments were specified for target %s,\\n\\tbut they appear to have the same action: %s\" % (t, action.genstring(tlist, slist, t.env))\n                    SCons.Warnings.warn(SCons.Warnings.DuplicateEnvironmentWarning, msg)\n                else:\n                    try:\n                        msg = \"Two environments with different actions were specified for the same target: %s\\n(action 1: %s)\\n(action 2: %s)\" % (t,t_contents.decode('utf-8'),contents.decode('utf-8'))\n                    except UnicodeDecodeError as e:\n                        msg = \"Two environments with different actions were specified for the same target: %s\"%t\n                    raise UserError(msg)\n            if builder.multi:\n                if t.builder != builder:\n                    msg = \"Two different builders (%s and %s) were specified for the same target: %s\" % (t.builder.get_name(env), builder.get_name(env), t)\n                    raise UserError(msg)\n                # TODO(batch):  list constructed each time!\n                if t.get_executor().get_all_targets() != tlist:\n                    msg = \"Two different target lists have a target in common: %s  (from %s and from %s)\" % (t, list(map(str, t.get_executor().get_all_targets())), list(map(str, tlist)))\n                    raise UserError(msg)\n            elif t.sources != slist:\n                msg = \"Multiple ways to build the same target were specified for: %s  (from %s and from %s)\" % (t, list(map(str, t.sources)), list(map(str, slist)))\n                raise UserError(msg)\n\n    if builder.single_source:\n        if len(slist) > 1:\n            raise UserError(\"More than one source given for single-source builder: targets=%s sources=%s\" % (list(map(str,tlist)), list(map(str,slist))))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the specified object is one of our Builder classes.", "response": "def is_a_Builder(obj):\n    \"\"\"\"Returns True if the specified obj is one of our Builder classes.\n\n    The test is complicated a bit by the fact that CompositeBuilder\n    is a proxy, not a subclass of BuilderBase.\n    \"\"\"\n    return (isinstance(obj, BuilderBase)\n            or isinstance(obj, CompositeBuilder)\n            or callable(obj))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to get the name of the Builder. This method will attempt to get the name of the Builder. If there s no key then return a directly - configured name or the class name of the Builder. If there s no key then return a directly - configured name. If there s no key then return a directly - configured name.", "response": "def get_name(self, env):\n        \"\"\"Attempts to get the name of the Builder.\n\n        Look at the BUILDERS variable of env, expecting it to be a\n        dictionary containing this Builder, and return the key of the\n        dictionary.  If there's no key, then return a directly-configured\n        name (if there is one) or the name of the class (by default).\"\"\"\n\n        try:\n            index = list(env['BUILDERS'].values()).index(self)\n            return list(env['BUILDERS'].keys())[index]\n        except (AttributeError, KeyError, TypeError, ValueError):\n            try:\n                return self.name\n            except AttributeError:\n                return str(self.__class__)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate and return lists of target and source nodes.", "response": "def _create_nodes(self, env, target = None, source = None):\n        \"\"\"Create and return lists of target and source nodes.\n        \"\"\"\n        src_suf = self.get_src_suffix(env)\n\n        target_factory = env.get_factory(self.target_factory)\n        source_factory = env.get_factory(self.source_factory)\n\n        source = self._adjustixes(source, None, src_suf)\n        slist = env.arg2nodes(source, source_factory)\n\n        pre = self.get_prefix(env, slist)\n        suf = self.get_suffix(env, slist)\n\n        if target is None:\n            try:\n                t_from_s = slist[0].target_from_source\n            except AttributeError:\n                raise UserError(\"Do not know how to create a target from source `%s'\" % slist[0])\n            except IndexError:\n                tlist = []\n            else:\n                splitext = lambda S: self.splitext(S,env)\n                tlist = [ t_from_s(pre, suf, splitext) ]\n        else:\n            target = self._adjustixes(target, pre, suf, self.ensure_suffix)\n            tlist = env.arg2nodes(target, target_factory, target=target, source=source)\n\n        if self.emitter:\n            # The emitter is going to do str(node), but because we're\n            # being called *from* a builder invocation, the new targets\n            # don't yet have a builder set on them and will look like\n            # source files.  Fool the emitter's str() calls by setting\n            # up a temporary builder on the new targets.\n            new_targets = []\n            for t in tlist:\n                if not t.is_derived():\n                    t.builder_set(self)\n                    new_targets.append(t)\n\n            orig_tlist = tlist[:]\n            orig_slist = slist[:]\n\n            target, source = self.emitter(target=tlist, source=slist, env=env)\n\n            # Now delete the temporary builders that we attached to any\n            # new targets, so that _node_errors() doesn't do weird stuff\n            # to them because it thinks they already have builders.\n            for t in new_targets:\n                if t.builder is self:\n                    # Only delete the temporary builder if the emitter\n                    # didn't change it on us.\n                    t.builder_set(None)\n\n            # Have to call arg2nodes yet again, since it is legal for\n            # emitters to spit out strings as well as Node instances.\n            tlist = env.arg2nodes(target, target_factory,\n                                  target=orig_tlist, source=orig_slist)\n            slist = env.arg2nodes(source, source_factory,\n                                  target=orig_tlist, source=orig_slist)\n\n        return tlist, slist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary mapping all of the source suffixes of this Builder to the underlying Builder that we can use to build the target for that Builder.", "response": "def _get_sdict(self, env):\n        \"\"\"\n        Returns a dictionary mapping all of the source suffixes of all\n        src_builders of this Builder to the underlying Builder that\n        should be called first.\n\n        This dictionary is used for each target specified, so we save a\n        lot of extra computation by memoizing it for each construction\n        environment.\n\n        Note that this is re-computed each time, not cached, because there\n        might be changes to one of our source Builders (or one of their\n        source Builders, and so on, and so on...) that we can't \"see.\"\n\n        The underlying methods we call cache their computed values,\n        though, so we hope repeatedly aggregating them into a dictionary\n        like this won't be too big a hit.  We may need to look for a\n        better way to do this if performance data show this has turned\n        into a significant bottleneck.\n        \"\"\"\n        sdict = {}\n        for bld in self.get_src_builders(env):\n            for suf in bld.src_suffixes(env):\n                sdict[suf] = bld\n        return sdict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of source Builders for this Builder.", "response": "def get_src_builders(self, env):\n        \"\"\"\n        Returns the list of source Builders for this Builder.\n\n        This exists mainly to look up Builders referenced as\n        strings in the 'BUILDER' variable of the construction\n        environment and cache the result.\n        \"\"\"\n        memo_key = id(env)\n        try:\n            memo_dict = self._memo['get_src_builders']\n        except KeyError:\n            memo_dict = {}\n            self._memo['get_src_builders'] = memo_dict\n        else:\n            try:\n                return memo_dict[memo_key]\n            except KeyError:\n                pass\n\n        builders = []\n        for bld in self.src_builder:\n            if SCons.Util.is_String(bld):\n                try:\n                    bld = env['BUILDERS'][bld]\n                except KeyError:\n                    continue\n            builders.append(bld)\n\n        memo_dict[memo_key] = builders\n        return builders"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsubstituting the source suffix list for the source of the given environment.", "response": "def subst_src_suffixes(self, env):\n        \"\"\"\n        The suffix list may contain construction variable expansions,\n        so we have to evaluate the individual strings.  To avoid doing\n        this over and over, we memoize the results for each construction\n        environment.\n        \"\"\"\n        memo_key = id(env)\n        try:\n            memo_dict = self._memo['subst_src_suffixes']\n        except KeyError:\n            memo_dict = {}\n            self._memo['subst_src_suffixes'] = memo_dict\n        else:\n            try:\n                return memo_dict[memo_key]\n            except KeyError:\n                pass\n        suffixes = [env.subst(x) for x in self.src_suffix]\n        memo_dict[memo_key] = suffixes\n        return suffixes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of source suffixes for all src_builders of thisCOOKIE.", "response": "def src_suffixes(self, env):\n        \"\"\"\n        Returns the list of source suffixes for all src_builders of this\n        Builder.\n\n        This is essentially a recursive descent of the src_builder \"tree.\"\n        (This value isn't cached because there may be changes in a\n        src_builder many levels deep that we can't see.)\n        \"\"\"\n        sdict = {}\n        suffixes = self.subst_src_suffixes(env)\n        for s in suffixes:\n            sdict[s] = 1\n        for builder in self.get_src_builders(env):\n            for s in builder.src_suffixes(env):\n                if s not in sdict:\n                    sdict[s] = 1\n                    suffixes.append(s)\n        return suffixes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Builders and construction variables for Visual Age linker to an Environment.", "response": "def generate(env):\n    \"\"\"\n    Add Builders and construction variables for Visual Age linker to\n    an Environment.\n    \"\"\"\n    link.generate(env)\n\n    env['SMARTLINKFLAGS'] = smart_linkflags\n    env['LINKFLAGS']      = SCons.Util.CLVar('$SMARTLINKFLAGS')\n    env['SHLINKFLAGS']    = SCons.Util.CLVar('$LINKFLAGS -qmkshrobj -qsuppress=1501-218')\n    env['SHLIBSUFFIX']    = '.a'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve(self, node):\n        if not self.is_enabled():\n            return False\n\n        env = node.get_build_env()\n        if cache_show:\n            if CacheRetrieveSilent(node, [], env, execute=1) == 0:\n                node.build(presub=0, execute=0)\n                return True\n        else:\n            if CacheRetrieve(node, [], env, execute=1) == 0:\n                return True\n\n        return False", "response": "This method is called by the build thread to retrieve the cache entries for a particular node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    as_module.generate(env)\n\n    env['AS']        = '386asm'\n    env['ASFLAGS']   = SCons.Util.CLVar('')\n    env['ASPPFLAGS'] = '$ASFLAGS'\n    env['ASCOM']     = '$AS $ASFLAGS $SOURCES -o $TARGET'\n    env['ASPPCOM']   = '$CC $ASPPFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS $SOURCES -o $TARGET'\n\n    addPharLapPaths(env)", "response": "Add Builders and construction variables for ar to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a binary targeting information structure.", "response": "def _parse_target(target):\n    \"\"\"Parse a binary targeting information structure.\n\n    This function only supports extracting the slot number or controller from\n    the target and will raise an ArgumentError if more complicated targeting\n    is desired.\n\n    Args:\n        target (bytes): The binary targeting data blob.\n\n    Returns:\n        dict: The parsed targeting data\n    \"\"\"\n\n    if len(target) != 8:\n        raise ArgumentError(\"Invalid targeting data length\", expected=8, length=len(target))\n    slot, match_op = struct.unpack(\"<B6xB\", target)\n\n    if match_op == _MATCH_CONTROLLER:\n        return {'controller': True, 'slot': 0}\n    elif match_op == _MATCH_SLOT:\n        return {'controller': False, 'slot': slot}\n\n    raise ArgumentError(\"Unsupported complex targeting specified\", match_op=match_op)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode_contents(self):\n\n        header = struct.pack(\"<LL8sBxxx\", self.offset, len(self.raw_data),\n                             _create_target(slot=self.slot), self.hardware_type)\n        return bytearray(header) + self.raw_data", "response": "Encode the contents of this update record without including a record header."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FromBinary(cls, record_data, record_count=1):\n\n        if len(record_data) < ReflashTileRecord.RecordHeaderLength:\n            raise ArgumentError(\"Record was too short to contain a full reflash record header\",\n                                length=len(record_data), header_length=ReflashTileRecord.RecordHeaderLength)\n\n        offset, data_length, raw_target, hardware_type = struct.unpack_from(\"<LL8sB3x\", record_data)\n\n        bindata = record_data[ReflashTileRecord.RecordHeaderLength:]\n        if len(bindata) != data_length:\n            raise ArgumentError(\"Embedded firmware length did not agree with actual length of embeded data\",\n                                length=len(bindata), embedded_length=data_length)\n\n        target = _parse_target(raw_target)\n        if target['controller']:\n            raise ArgumentError(\"Invalid targetting information, you \"\n                                \"cannot reflash a controller with a ReflashTileRecord\", target=target)\n\n        return ReflashTileRecord(target['slot'], bindata, offset, hardware_type)", "response": "Create an UpdateRecord subclass from a binary record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put_task(self, func, args, response):\n\n        self._rpc_queue.put_nowait((func, args, response))", "response": "Place a task onto the RPC queue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplacing an RPC onto the RPC queue.", "response": "def put_rpc(self, address, rpc_id, arg_payload, response):\n        \"\"\"Place an RPC onto the RPC queue.\n\n        The rpc will be dispatched asynchronously by the background dispatch\n        task.  This method must be called from the event loop.  This method\n        does not block.\n\n        Args:\n            address (int): The address of the tile with the RPC\n            rpc_id (int): The id of the rpc you want to call\n            arg_payload (bytes): The RPC payload\n            respones (GenericResponse): The object to use to signal the result.\n        \"\"\"\n\n        self._rpc_queue.put_nowait((address, rpc_id, arg_payload, response))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef finish_async_rpc(self, address, rpc_id, response):\n\n        pending = self._pending_rpcs.get(address)\n\n        if pending is None:\n            raise ArgumentError(\"No asynchronously RPC currently in progress on tile %d\" % address)\n\n        responder = pending.get(rpc_id)\n        if responder is None:\n            raise ArgumentError(\"RPC %04X is not running asynchronous on tile %d\" % (rpc_id, address))\n\n        del pending[rpc_id]\n\n        responder.set_result(response)\n        self._rpc_queue.task_done()", "response": "Finish an asynchronous RPC."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def stop(self):\n\n        if self._rpc_task is not None:\n            self._rpc_task.cancel()\n\n        try:\n            await self._rpc_task\n        except asyncio.CancelledError:\n            pass\n\n        self._rpc_task = None", "response": "Stop the rpc queue from inside the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a contiguous segment of data to this memory map.", "response": "def add_segment(self, address, data, overwrite=False):\n        \"\"\"Add a contiguous segment of data to this memory map\n\n        If the segment overlaps with a segment already added , an\n        ArgumentError is raised unless the overwrite flag is True.\n\n        Params:\n            address (int): The starting address for this segment\n            data (bytearray): The data to add\n            overwrite (bool): Overwrite data if this segment overlaps\n                with one previously added.\n        \"\"\"\n\n        seg_type = self._classify_segment(address, len(data))\n        if not isinstance(seg_type, DisjointSegment):\n            raise ArgumentError(\"Unsupported segment type\")\n\n        segment = MemorySegment(address, address+len(data)-1, len(data), bytearray(data))\n        self._segments.append(segment)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_slice(self, key):\n\n        if isinstance(key, slice):\n            step = key.step\n            if step is None:\n                step = 1\n\n            if step != 1:\n                raise ArgumentError(\"You cannot slice with a step that is not equal to 1\", step=key.step)\n\n            start_address = key.start\n            end_address = key.stop - 1\n\n            start_i, start_seg = self._find_address(start_address)\n            end_i, _end_seg = self._find_address(end_address)\n\n            if start_seg is None or start_i != end_i:\n                raise ArgumentError(\"Slice would span invalid data in memory\",\n                                    start_address=start_address, end_address=end_address)\n\n            block_offset = start_address - start_seg.start_address\n            block_length = end_address - start_address + 1\n\n            return start_seg, block_offset, block_offset + block_length\n        elif isinstance(key, int):\n            start_i, start_seg = self._find_address(key)\n            if start_seg is None:\n                raise ArgumentError(\"Requested invalid address\", address=key)\n\n            return start_seg, key - start_seg.start_address, None\n        else:\n            raise ArgumentError(\"Unknown type of address key\", address=key)", "response": "Create a slice in a memory segment corresponding to a key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclassify a new data segment into our existing world.", "response": "def _classify_segment(self, address, length):\n        \"\"\"Determine how a new data segment fits into our existing world\n\n        Params:\n            address (int): The address we wish to classify\n            length (int): The length of the segment\n\n        Returns:\n            int: One of SparseMemoryMap.prepended\n        \"\"\"\n\n        end_address = address + length - 1\n\n        _, start_seg = self._find_address(address)\n        _, end_seg = self._find_address(end_address)\n\n        if start_seg is not None or end_seg is not None:\n            raise ArgumentError(\"Overlapping segments are not yet supported\", address=address, length=length)\n\n        return DisjointSegment()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(env):\n    SCons.Tool.createSharedLibBuilder(env)\n    SCons.Tool.createProgBuilder(env)\n\n    env['SUBST_CMD_FILE'] = LinklocGenerator\n    env['SHLINK']      = '$LINK'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS')\n    env['SHLINKCOM']   = '${SUBST_CMD_FILE(\"$SHLINK $SHLINKFLAGS $_LIBDIRFLAGS $_LIBFLAGS -dll $TARGET $SOURCES\")}'\n    env['SHLIBEMITTER']= None\n    env['LDMODULEEMITTER']= None\n    env['LINK']        = \"linkloc\"\n    env['LINKFLAGS']   = SCons.Util.CLVar('')\n    env['LINKCOM']     = '${SUBST_CMD_FILE(\"$LINK $LINKFLAGS $_LIBDIRFLAGS $_LIBFLAGS -exe $TARGET $SOURCES\")}'\n    env['LIBDIRPREFIX']='-libpath '\n    env['LIBDIRSUFFIX']=''\n    env['LIBLINKPREFIX']='-lib '\n    env['LIBLINKSUFFIX']='$LIBSUFFIX'\n\n    # Set-up ms tools paths for default version\n    merge_default_version(env)\n\n    addPharLapPaths(env)", "response": "Add Builders and construction variables for linkloc to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for ifort to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for ifort to an Environment.\"\"\"\n    # ifort supports Fortran 90 and Fortran 95\n    # Additionally, ifort recognizes more file extensions.\n    fscan = FortranScan(\"FORTRANPATH\")\n    SCons.Tool.SourceFileScanner.add_scanner('.i', fscan)\n    SCons.Tool.SourceFileScanner.add_scanner('.i90', fscan)\n\n    if 'FORTRANFILESUFFIXES' not in env:\n        env['FORTRANFILESUFFIXES'] = ['.i']\n    else:\n        env['FORTRANFILESUFFIXES'].append('.i')\n\n    if 'F90FILESUFFIXES' not in env:\n        env['F90FILESUFFIXES'] = ['.i90']\n    else:\n        env['F90FILESUFFIXES'].append('.i90')\n\n    add_all_to_env(env)\n\n    fc = 'ifort'\n\n    for dialect in ['F77', 'F90', 'FORTRAN', 'F95']:\n        env['%s' % dialect] = fc\n        env['SH%s' % dialect] = '$%s' % dialect\n        if env['PLATFORM'] == 'posix':\n            env['SH%sFLAGS' % dialect] = SCons.Util.CLVar('$%sFLAGS -fPIC' % dialect)\n\n    if env['PLATFORM'] == 'win32':\n        # On Windows, the ifort compiler specifies the object on the\n        # command line with -object:, not -o.  Massage the necessary\n        # command-line construction variables.\n        for dialect in ['F77', 'F90', 'FORTRAN', 'F95']:\n            for var in ['%sCOM' % dialect, '%sPPCOM' % dialect,\n                        'SH%sCOM' % dialect, 'SH%sPPCOM' % dialect]:\n                env[var] = env[var].replace('-o $TARGET', '-object:$TARGET')\n        env['FORTRANMODDIRPREFIX'] = \"/module:\"\n    else:\n        env['FORTRANMODDIRPREFIX'] = \"-module \""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the jobs. method.", "response": "def run(self, postfunc=lambda: None):\n        \"\"\"Run the jobs.\n\n        postfunc() will be invoked after the jobs has run. It will be\n        invoked even if the jobs are interrupted by a keyboard\n        interrupt (well, in fact by a signal such as either SIGINT,\n        SIGTERM or SIGHUP). The execution of postfunc() is protected\n        against keyboard interrupts and is guaranteed to run to\n        completion.\"\"\"\n        self._setup_sig_handler()\n        try:\n            self.job.start()\n        finally:\n            postfunc()\n            self._reset_sig_handler()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _reset_sig_handler(self):\n\n        signal.signal(signal.SIGINT, self.old_sigint)\n        signal.signal(signal.SIGTERM, self.old_sigterm)\n        try:\n            signal.signal(signal.SIGHUP, self.old_sighup)\n        except AttributeError:\n            pass", "response": "Restore the signal handlers to their previous state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the job. This will pull all tasks from the taskmaster and execute them and return when there are no more tasks.", "response": "def start(self):\n        \"\"\"Start the job. This will begin pulling tasks from the taskmaster\n        and executing them, and return when there are no more tasks. If a task\n        fails to execute (i.e. execute() raises an exception), then the job will\n        stop.\"\"\"\n        \n        while True:\n            task = self.taskmaster.next_task()\n\n            if task is None:\n                break\n\n            try:\n                task.prepare()\n                if task.needs_execute():\n                    task.execute()\n            except:\n                if self.interrupted():\n                    try:\n                        raise SCons.Errors.BuildError(\n                            task.targets[0], errstr=interrupt_msg)\n                    except:\n                        task.exception_set()\n                else:\n                    task.exception_set()\n\n                # Let the failed() callback function arrange for the\n                # build to stop if that's appropriate.\n                task.failed()\n            else:\n                task.executed()\n\n            task.postprocess()\n        self.taskmaster.cleanup()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_connection(self, connection_id, internal_id, context):\n        # Make sure we are not reusing an id that is currently connected to something\n        if self._get_connection_state(connection_id) != self.Disconnected:\n            return\n        if self._get_connection_state(internal_id) != self.Disconnected:\n            return\n\n        conn_data = {\n            'state': self.Idle,\n            'microstate': None,\n            'connection_id': connection_id,\n            'internal_id': internal_id,\n            'context': context\n        }\n\n        self._connections[connection_id] = conn_data\n        self._int_connections[internal_id] = conn_data", "response": "Add an already created connection to the internal_id and context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef begin_connection(self, connection_id, internal_id, callback, context, timeout):\n\n        data = {\n            'callback': callback,\n            'connection_id': connection_id,\n            'internal_id': internal_id,\n            'context': context\n        }\n\n        action = ConnectionAction('begin_connection', data, timeout=timeout, sync=False)\n        self._actions.put(action)", "response": "Asynchronously begin a connection attempt with the specified external connection id and internal id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef finish_connection(self, conn_or_internal_id, successful, failure_reason=None):\n\n        data = {\n            'id': conn_or_internal_id,\n            'success': successful,\n            'failure_reason': failure_reason\n        }\n\n        action = ConnectionAction('finish_connection', data, sync=False)\n        self._actions.put(action)", "response": "Finish a connection attempt with the specified internal_id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _begin_connection_action(self, action):\n\n        connection_id = action.data['connection_id']\n        internal_id = action.data['internal_id']\n        callback = action.data['callback']\n\n        # Make sure we are not reusing an id that is currently connected to something\n        if self._get_connection_state(connection_id) != self.Disconnected:\n            callback(connection_id, self.id, False, 'Connection ID is already in use for another connection')\n            return\n\n        if self._get_connection_state(internal_id) != self.Disconnected:\n            callback(connection_id, self.id, False, 'Internal ID is already in use for another connection')\n            return\n\n        conn_data = {\n            'state': self.Connecting,\n            'microstate': None,\n            'connection_id': connection_id,\n            'internal_id': internal_id,\n            'action': action,\n            'context': action.data['context']\n        }\n\n        self._connections[connection_id] = conn_data\n        self._int_connections[internal_id] = conn_data", "response": "Called by _get_action_object to begin a connection attempt for a specific resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _force_disconnect_action(self, action):\n\n        conn_key = action.data['id']\n        if self._get_connection_state(conn_key) == self.Disconnected:\n            return\n\n        data = self._get_connection(conn_key)\n\n        # If there are any operations in progress, cancel them cleanly\n        if data['state'] == self.Connecting:\n            callback = data['action'].data['callback']\n            callback(data['connection_id'], self.id, False, 'Unexpected disconnection')\n        elif data['state'] == self.Disconnecting:\n            callback = data['action'].data['callback']\n            callback(data['connection_id'], self.id, True, None)\n        elif data['state'] == self.InProgress:\n            callback = data['action'].data['callback']\n            if data['microstate'] == 'rpc':\n                callback(False, 'Unexpected disconnection', 0xFF, None)\n            elif data['microstate'] == 'open_interface':\n                callback(False, 'Unexpected disconnection')\n            elif data['microstate'] == 'close_interface':\n                callback(False, 'Unexpected disconnection')\n\n        connection_id = data['connection_id']\n        internal_id = data['internal_id']\n        del self._connections[connection_id]\n        del self._int_connections[internal_id]", "response": "Forcibly disconnect a device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinishing a disconnection attempt.", "response": "def _finish_disconnection_action(self, action):\n        \"\"\"Finish a disconnection attempt\n\n        There are two possible outcomes:\n        - if we were successful at disconnecting, we transition to disconnected\n        - if we failed at disconnecting, we transition back to idle\n\n        Args:\n            action (ConnectionAction): the action object describing what we are\n                disconnecting from and what the result of the operation was\n        \"\"\"\n\n        success = action.data['success']\n        conn_key = action.data['id']\n\n        if self._get_connection_state(conn_key) != self.Disconnecting:\n            self._logger.error(\n                \"Invalid finish_disconnection action on a connection whose state is not Disconnecting, conn_key={}\"\n                .format(str(conn_key))\n            )\n            return\n\n        # Cannot be None since we checked above to make sure it exists\n        data = self._get_connection(conn_key)\n        connection_id = data['connection_id']\n        internal_id = data['internal_id']\n\n        last_action = data['action']\n        callback = last_action.data['callback']\n\n        if success is False:\n            failure_reason = action.data['failure_reason']\n            if failure_reason is None:\n                failure_reason = \"No reason was given\"\n\n            data['state'] = self.Idle\n            data['microstate'] = None\n            del data['action']\n            callback(connection_id, self.id, False, failure_reason)\n        else:\n            del self._connections[connection_id]\n            del self._int_connections[internal_id]\n            callback(connection_id, self.id, True, None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart an operation on a connection in the cluster.", "response": "def begin_operation(self, conn_or_internal_id, op_name, callback, timeout):\n        \"\"\"Begin an operation on a connection\n\n        Args:\n            conn_or_internal_id (string, int): Either an integer connection id or a string\n                internal_id\n            op_name (string): The name of the operation that we are starting (stored in\n                the connection's microstate)\n            callback (callable): Callback to call when this disconnection attempt either\n                succeeds or fails\n            timeout (float): How long to allow this connection attempt to proceed\n                without timing it out (in seconds)\n        \"\"\"\n\n        data = {\n            'id': conn_or_internal_id,\n            'callback': callback,\n            'operation_name': op_name\n        }\n\n        action = ConnectionAction('begin_operation', data, timeout=timeout, sync=False)\n        self._actions.put(action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _begin_operation_action(self, action):\n\n        conn_key = action.data['id']\n        callback = action.data['callback']\n\n        if self._get_connection_state(conn_key) != self.Idle:\n            callback(conn_key, self.id, False, 'Cannot start operation, connection is not idle')\n            return\n\n        data = self._get_connection(conn_key)\n        data['state'] = self.InProgress\n        data['microstate'] = action.data['operation_name']\n        data['action'] = action", "response": "Begin an attempted operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef allow_exception(self, exc_class):\n\n        name = exc_class.__name__\n        self._allowed_exceptions[name] = exc_class", "response": "Allow raising an exception from commands."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to the websocket server and start a background task.", "response": "async def start(self, name=\"websocket_client\"):\n        \"\"\"Connect to the websocket server.\n\n        This method will spawn a background task in the designated event loop\n        that will run until stop() is called.  You can control the name of the\n        background task for debugging purposes using the name parameter.  The\n        name is not used in anyway except for debug logging statements.\n\n        Args:\n            name (str): Optional name for the background task.\n        \"\"\"\n\n        self._con = await websockets.connect(self.url)\n        self._connection_task = self._loop.add_task(self._manage_connection(), name=name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops this websocket client and disconnect from the server.", "response": "async def stop(self):\n        \"\"\"Stop this websocket client and disconnect from the server.\n\n        This method is idempotent and may be called multiple times.  If called\n        when there is no active connection, it will simply return.\n        \"\"\"\n\n        if self._connection_task is None:\n            return\n\n        try:\n            await self._connection_task.stop()\n        finally:\n            self._con = None\n            self._connection_task = None\n            self._manager.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a command and synchronously wait for a response.", "response": "async def send_command(self, command, args, validator, timeout=10.0):\n        \"\"\"Send a command and synchronously wait for a single response.\n\n        Args:\n            command (string): The command name\n            args (dict): Optional arguments.\n            validator (Verifier): A SchemaVerifier to verify the response\n                payload.\n            timeout (float): The maximum time to wait for a response.\n                Defaults to 10 seconds.\n\n        Returns:\n            dict: The response payload\n\n        Raises:\n            ExternalError: If the server is not connected or the command\n                fails.\n            asyncio.TimeoutError: If the command times out.\n            ValidationError: If the response payload does not match the\n                given validator.\n        \"\"\"\n\n        if self._con is None:\n            raise ExternalError(\"No websock connection established\")\n\n        cmd_uuid = str(uuid.uuid4())\n        msg = dict(type='command', operation=command, uuid=cmd_uuid,\n                   payload=args)\n\n        packed = pack(msg)\n\n        # Note: register future before sending to avoid race conditions\n        response_future = self._manager.wait_for(type=\"response\", uuid=cmd_uuid,\n                                                 timeout=timeout)\n\n        await self._con.send(packed)\n\n        response = await response_future\n\n        if response.get('success') is False:\n            self._raise_error(command, response)\n\n        if validator is None:\n            return response.get('payload')\n\n        return validator.verify(response.get('payload'))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _manage_connection(self):\n\n        try:\n            while True:\n                message = await self._con.recv()\n\n                try:\n                    unpacked = unpack(message)\n                except Exception:  # pylint:disable=broad-except;This is a background worker\n                    self._logger.exception(\"Corrupt message received\")\n                    continue\n\n                if not VALID_SERVER_MESSAGE.matches(unpacked):\n                    self._logger.warning(\"Dropping invalid message from server: %s\", unpacked)\n                    continue\n\n                # Don't block until all callbacks have finished since once of\n                # those callbacks may call self.send_command, which would deadlock\n                # since it couldn't get the response until it had already finished.\n                if not await self._manager.process_message(unpacked, wait=False):\n                    self._logger.warning(\"No handler found for received message, message=%s\", unpacked)\n        except asyncio.CancelledError:\n            self._logger.info(\"Closing connection to server due to stop()\")\n        finally:\n            await self._manager.process_message(dict(type='event', name=self.DISCONNECT_EVENT, payload=None))\n            await self._con.close()", "response": "Internal coroutine for managing the client connection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_event(self, name, callback, validator):\n\n        async def _validate_and_call(message):\n            payload = message.get('payload')\n\n            try:\n                payload = validator.verify(payload)\n            except ValidationError:\n                self._logger.warning(\"Dropping invalid payload for event %s, payload=%s\",\n                                     name, payload)\n                return\n\n            try:\n                result = callback(payload)\n                if inspect.isawaitable(result):\n                    await result\n            except:  # pylint:disable=bare-except;This is a background logging routine\n                self._logger.error(\"Error calling callback for event %s, payload=%s\",\n                                   name, payload, exc_info=True)\n\n        self._manager.every_match(_validate_and_call, type=\"event\", name=name)", "response": "Register a callback to receive events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_command(self, command, args):\n\n        self._loop.log_coroutine(self.send_command(command, args, Verifier()))", "response": "Post a command asynchronously and don t wait for a response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying all readings in input a into output.", "response": "def copy_all_a(input_a, *other_inputs, **kwargs):\n    \"\"\"Copy all readings in input a into the output.\n\n    All other inputs are skipped so that after this function runs there are no\n    readings left in any of the input walkers when the function finishes, even\n    if it generated no output readings.\n\n    Returns:\n        list(IOTileReading)\n    \"\"\"\n\n    output = []\n    while input_a.count() > 0:\n        output.append(input_a.pop())\n\n    for input_x in other_inputs:\n        input_x.skip_all()\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the latest reading from input a into output.", "response": "def copy_count_a(input_a, *other_inputs, **kwargs):\n    \"\"\"Copy the latest reading from input a into the output.\n\n    All other inputs are skipped to that after this function\n    runs there are no readings left in any of the input walkers\n    even if no output is generated.\n\n    Returns:\n        list(IOTileReading)\n    \"\"\"\n\n    count = input_a.count()\n\n    input_a.skip_all();\n\n    for input_x in other_inputs:\n        input_x.skip_all()\n\n    return [IOTileReading(0, 0, count)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall an RPC on the input b and return the output of this function.", "response": "def call_rpc(*inputs, **kwargs):\n    \"\"\"Call an RPC based on the encoded value read from input b.\n\n    The response of the RPC must be a 4 byte value that is used as\n    the output of this call.  The encoded RPC must be a 32 bit value\n    encoded as \"BBH\":\n        B: ignored, should be 0\n        B: the address of the tile that we should call\n        H: The id of the RPC to call\n\n    All other readings are then skipped so that there are no\n    readings in any input queue when this function returns\n\n    Returns:\n        list(IOTileReading)\n    \"\"\"\n\n    rpc_executor = kwargs['rpc_executor']\n\n    output = []\n    try:\n        value = inputs[1].pop()\n\n        addr = value.value >> 16\n        rpc_id = value.value & 0xFFFF\n\n        reading_value = rpc_executor.rpc(addr, rpc_id)\n        output.append(IOTileReading(0, 0, reading_value))\n    except (HardwareError, StreamEmptyError):\n        pass\n\n    for input_x in inputs:\n        input_x.skip_all()\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntriggering a streamer based on the index read from input b.", "response": "def trigger_streamer(*inputs, **kwargs):\n    \"\"\"Trigger a streamer based on the index read from input b.\n\n    Returns:\n        list(IOTileReading)\n    \"\"\"\n\n    streamer_marker = kwargs['mark_streamer']\n\n    try:\n        reading = inputs[1].pop()\n    except StreamEmptyError:\n        return []\n    finally:\n        for input_x in inputs:\n            input_x.skip_all()\n\n    try:\n        streamer_marker(reading.value)\n    except ArgumentError:\n        return []\n\n    return [IOTileReading(0, 0, 0)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubtract stream a from stream b Returns list of IOTileReading s", "response": "def subtract_afromb(*inputs, **kwargs):\n    \"\"\"Subtract stream a from stream b.\n\n    Returns:\n        list(IOTileReading)\n    \"\"\"\n\n    try:\n        value_a = inputs[0].pop()\n        value_b = inputs[1].pop()\n\n        return [IOTileReading(0, 0, value_b.value - value_a.value)]\n    except StreamEmptyError:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubstitutes all instances of k = v and b = b in the node s text contents with their values.", "response": "def _do_subst(node, subs):\n    \"\"\"\n    Fetch the node contents and replace all instances of the keys with\n    their values.  For example, if subs is\n        {'%VERSION%': '1.2345', '%BASE%': 'MyProg', '%prefix%': '/bin'},\n    then all instances of %VERSION% in the file will be replaced with\n    1.2345 and so forth.\n    \"\"\"\n    contents = node.get_text_contents()\n    if subs:\n        for (k, val) in subs:\n            contents = re.sub(k, val, contents)\n\n    if 'b' in TEXTFILE_FILE_WRITE_MODE:\n        try:\n            contents = bytearray(contents, 'utf-8')\n        except UnicodeDecodeError:\n            # contents is already utf-8 encoded python 2 str i.e. a byte array\n            contents = bytearray(contents)\n\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _clean_intenum(obj):\n\n    if isinstance(obj, dict):\n        for key, value in obj.items():\n            if isinstance(value, IntEnum):\n                obj[key] = value.value\n            elif isinstance(value, (dict, list)):\n                obj[key] = _clean_intenum(value)\n    elif isinstance(obj, list):\n        for i, value in enumerate(obj):\n            if isinstance(value, IntEnum):\n                obj[i] = value.value\n            elif isinstance(value, (dict, list)):\n                obj[i] = _clean_intenum(value)\n\n    return obj", "response": "Remove all IntEnum classes from a map."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntracks that a change happened.", "response": "def _track_change(self, name, value, formatter=None):\n        \"\"\"Track that a change happened.\n\n        This function is only needed for manually recording changes that are\n        not captured by changes to properties of this object that are tracked\n        automatically.  Classes that inherit from `emulation_mixin` should\n        use this function to record interesting changes in their internal\n        state or events that happen.\n\n        The `value` parameter that you pass here should be a native python\n        object best representing what the value of the property that changed\n        is.  When saved to disk, it will be converted to a string using:\n        `str(value)`.  If you do not like the string that would result from\n        such a call, you can pass a custom formatter that will be called as\n        `formatter(value)` and must return a string.\n\n        Args:\n            name (str): The name of the property that changed.\n            value (object): The new value of the property.\n            formatter (callable): Optional function to convert value to a\n                string.  This function will only be called if track_changes()\n                is enabled and `name` is on the whitelist for properties that\n                should be tracked.  If `formatter` is not passed or is None,\n                it will default to `str`\n        \"\"\"\n\n        self._emulation_log.track_change(self._emulation_address, name, value, formatter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_state(self, out_path):\n\n        state = self.dump_state()\n\n        # Remove all IntEnums from state since they cannot be json-serialized on python 2.7\n        # See https://bitbucket.org/stoneleaf/enum34/issues/17/difference-between-enum34-and-enum-json\n        state = _clean_intenum(state)\n\n        with open(out_path, \"w\") as outfile:\n            json.dump(state, outfile, indent=4)", "response": "Save the current state of this emulated\n            to a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the current state of this emulated object from a file.", "response": "def load_state(self, in_path):\n        \"\"\"Load the current state of this emulated object from a file.\n\n        The file should have been produced by a previous call to save_state.\n\n        Args:\n            in_path (str): The path to the saved state dump that you wish\n                to load.\n        \"\"\"\n\n        with open(in_path, \"r\") as infile:\n            state = json.load(infile)\n\n        self.restore_state(state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_scenario(self, scenario_name, **kwargs):\n\n        scenario = self._known_scenarios.get(scenario_name)\n        if scenario is None:\n            raise ArgumentError(\"Unknown scenario %s\" % scenario_name, known_scenarios=list(self._known_scenarios))\n\n        scenario(**kwargs)", "response": "Loads a scenario into the emulated object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_scenario(self, scenario_name, handler):\n\n        if scenario_name in self._known_scenarios:\n            raise ArgumentError(\"Attempted to add the same scenario name twice\", scenario_name=scenario_name,\n                                previous_handler=self._known_scenarios[scenario_name])\n\n        self._known_scenarios[scenario_name] = handler", "response": "Register a scenario handler for this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for aCC & cc to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for aCC & cc to an Environment.\"\"\"\n    cc.generate(env)\n\n    env['CXX']        = 'aCC'\n    env['SHCCFLAGS']  = SCons.Util.CLVar('$CCFLAGS +Z')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an optimization pass to the optimizer.", "response": "def add_pass(self, name, opt_pass, before=None, after=None):\n        \"\"\"Add an optimization pass to the optimizer.\n\n        Optimization passes have a name that allows them\n        to be enabled or disabled by name.  By default all\n        optimization passed are enabled and unordered.  You can\n        explicitly specify passes by name that this pass must run\n        before or after this passs so that they can be properly\n        ordered.\n\n        Args:\n            name (str): The name of the optimization pass to allow for\n                enabling/disabling it by name\n            opt_pass (OptimizationPass): The optimization pass class itself\n            before (list(str)): A list of the passes that this pass should\n                run before.\n            after (list(str)): A list of the passes that this pass should\n                run after.\n        \"\"\"\n\n        if before is None:\n            before = []\n        if after is None:\n            after = []\n\n        self._known_passes[name] = (opt_pass, before, after)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _order_pases(self, passes):\n\n        passes = set(passes)\n\n        pass_deps = {}\n\n        for opt in passes:\n            _, before, after = self._known_passes[opt]\n\n            if opt not in pass_deps:\n                pass_deps[opt] = set()\n\n            for after_pass in after:\n                pass_deps[opt].add(after_pass)\n\n            # For passes that we are before, we may need to\n            # preemptively add them to the list early\n            for other in before:\n                if other not in passes:\n                    continue\n\n                if other not in pass_deps:\n                    pass_deps[other] = set()\n\n                pass_deps[other].add(opt)\n\n        return toposort_flatten(pass_deps)", "response": "Topologically sort the passed - in - set of items in the order of the items in the order they should be run."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef optimize(self, sensor_graph, model):\n\n        passes = self._order_pases(self._known_passes.keys())\n\n        for opt_name in passes:\n            rerun = True\n            pass_instance = self._known_passes[opt_name][0]()\n\n            while rerun:\n                rerun = pass_instance.run(sensor_graph, model=model)", "response": "Optimize a sensor graph by running all of the optimization passes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the locals and globals dictionaries for the function that called into this module in the current call stack.", "response": "def get_calling_namespaces():\n    \"\"\"Return the locals and globals for the function that called\n    into this module in the current call stack.\"\"\"\n    try: 1//0\n    except ZeroDivisionError:\n        # Don't start iterating with the current stack-frame to\n        # prevent creating reference cycles (f_back is safe).\n        frame = sys.exc_info()[2].tb_frame.f_back\n\n    # Find the first frame that *isn't* from this file.  This means\n    # that we expect all of the SCons frames that implement an Export()\n    # or SConscript() call to be in this file, so that we can identify\n    # the first non-Script.SConscript frame as the user's local calling\n    # environment, and the locals and globals dictionaries from that\n    # frame as the calling namespaces.  See the comment below preceding\n    # the DefaultEnvironmentCall block for even more explanation.\n    while frame.f_globals.get(\"__name__\") == __name__:\n        frame = frame.f_back\n\n    return frame.f_locals, frame.f_globals"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a dictionary of exports given one of the parameters to the Export function or the exports argument to SConscript.", "response": "def compute_exports(exports):\n    \"\"\"Compute a dictionary of exports given one of the parameters\n    to the Export() function or the exports argument to SConscript().\"\"\"\n\n    loc, glob = get_calling_namespaces()\n\n    retval = {}\n    try:\n        for export in exports:\n            if SCons.Util.is_Dict(export):\n                retval.update(export)\n            else:\n                try:\n                    retval[export] = loc[export]\n                except KeyError:\n                    retval[export] = glob[export]\n    except KeyError as x:\n        raise SCons.Errors.UserError(\"Export of non-existent variable '%s'\"%x)\n\n    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints an exception stack trace just for the SConscript file ( s.", "response": "def SConscript_exception(file=sys.stderr):\n    \"\"\"Print an exception stack trace just for the SConscript file(s).\n    This will show users who have Python errors where the problem is,\n    without cluttering the output with all of the internal calls leading\n    up to where we exec the SConscript.\"\"\"\n    exc_type, exc_value, exc_tb = sys.exc_info()\n    tb = exc_tb\n    while tb and stack_bottom not in tb.tb_frame.f_locals:\n        tb = tb.tb_next\n    if not tb:\n        # We did not find our exec statement, so this was actually a bug\n        # in SCons itself.  Show the whole stack.\n        tb = exc_tb\n    stack = traceback.extract_tb(tb)\n    try:\n        type = exc_type.__name__\n    except AttributeError:\n        type = str(exc_type)\n        if type[:11] == \"exceptions.\":\n            type = type[11:]\n    file.write('%s: %s:\\n' % (type, exc_value))\n    for fname, line, func, text in stack:\n        file.write('  File \"%s\", line %d:\\n' % (fname, line))\n        file.write('    %s\\n' % text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef annotate(node):\n    tb = sys.exc_info()[2]\n    while tb and stack_bottom not in tb.tb_frame.f_locals:\n        tb = tb.tb_next\n    if not tb:\n        # We did not find any exec of an SConscript file: what?!\n        raise SCons.Errors.InternalError(\"could not find SConscript stack frame\")\n    node.creator = traceback.extract_stack(tb)[0]", "response": "Annotate a node with the stack frame describing the\n    SConscript file and line number that created it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef BuildDefaultGlobals():\n\n    global GlobalDict\n    if GlobalDict is None:\n        GlobalDict = {}\n\n        import SCons.Script\n        d = SCons.Script.__dict__\n        def not_a_module(m, d=d, mtype=type(SCons.Script)):\n             return not isinstance(d[m], mtype)\n        for m in filter(not_a_module, dir(SCons.Script)):\n             GlobalDict[m] = d[m]\n\n    return GlobalDict.copy()", "response": "Builds a dictionary containing all the default globals for the given SConstruct and SConscript files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _exceeds_version(self, major, minor, v_major, v_minor):\n        return (major > v_major or (major == v_major and minor > v_minor))", "response": "Return 1 if major and minor are greater than the version\n        in v_major and v_minor and 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a version string into major minor and revision parts.", "response": "def _get_major_minor_revision(self, version_string):\n        \"\"\"Split a version string into major, minor and (optionally)\n        revision parts.\n\n        This is complicated by the fact that a version string can be\n        something like 3.2b1.\"\"\"\n        version = version_string.split(' ')[0].split('.')\n        v_major = int(version[0])\n        v_minor = int(re.match('\\d+', version[1]).group())\n        if len(version) >= 3:\n            v_revision = int(re.match('\\d+', version[2]).group())\n        else:\n            v_revision = 0\n        return v_major, v_minor, v_revision"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_SConscript_filenames(self, ls, kw):\n        exports = []\n\n        if len(ls) == 0:\n            try:\n                dirs = kw[\"dirs\"]\n            except KeyError:\n                raise SCons.Errors.UserError(\"Invalid SConscript usage - no parameters\")\n\n            if not SCons.Util.is_List(dirs):\n                dirs = [ dirs ]\n            dirs = list(map(str, dirs))\n\n            name = kw.get('name', 'SConscript')\n\n            files = [os.path.join(n, name) for n in dirs]\n\n        elif len(ls) == 1:\n\n            files = ls[0]\n\n        elif len(ls) == 2:\n\n            files   = ls[0]\n            exports = self.Split(ls[1])\n\n        else:\n\n            raise SCons.Errors.UserError(\"Invalid SConscript() usage - too many arguments\")\n\n        if not SCons.Util.is_List(files):\n            files = [ files ]\n\n        if kw.get('exports'):\n            exports.extend(self.Split(kw['exports']))\n\n        variant_dir = kw.get('variant_dir') or kw.get('build_dir')\n        if variant_dir:\n            if len(files) != 1:\n                raise SCons.Errors.UserError(\"Invalid SConscript() usage - can only specify one SConscript with a variant_dir\")\n            duplicate = kw.get('duplicate', 1)\n            src_dir = kw.get('src_dir')\n            if not src_dir:\n                src_dir, fname = os.path.split(str(files[0]))\n                files = [os.path.join(str(variant_dir), fname)]\n            else:\n                if not isinstance(src_dir, SCons.Node.Node):\n                    src_dir = self.fs.Dir(src_dir)\n                fn = files[0]\n                if not isinstance(fn, SCons.Node.Node):\n                    fn = self.fs.File(fn)\n                if fn.is_under(src_dir):\n                    # Get path relative to the source directory.\n                    fname = fn.get_path(src_dir)\n                    files = [os.path.join(str(variant_dir), fname)]\n                else:\n                    files = [fn.get_abspath()]\n                kw['src_dir'] = variant_dir\n            self.fs.VariantDir(variant_dir, src_dir, duplicate)\n\n        return (files, exports)", "response": "Convert the parameters passed to SConscript calls into a list of filenames and export variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef EnsureSConsVersion(self, major, minor, revision=0):\n        # split string to avoid replacement during build process\n        if SCons.__version__ == '__' + 'VERSION__':\n            SCons.Warnings.warn(SCons.Warnings.DevelopmentVersionWarning,\n                \"EnsureSConsVersion is ignored for development version\")\n            return\n        scons_ver = self._get_major_minor_revision(SCons.__version__)\n        if scons_ver < (major, minor, revision):\n            if revision:\n                scons_ver_string = '%d.%d.%d' % (major, minor, revision)\n            else:\n                scons_ver_string = '%d.%d' % (major, minor)\n            print(\"SCons %s or greater required, but you have SCons %s\" % \\\n                  (scons_ver_string, SCons.__version__))\n            sys.exit(2)", "response": "Exit abnormally if the SCons version is not late enough."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef EnsurePythonVersion(self, major, minor):\n        if sys.version_info < (major, minor):\n            v = sys.version.split()[0]\n            print(\"Python %d.%d or greater required, but you have Python %s\" %(major,minor,v))\n            sys.exit(2)", "response": "Exit abnormally if the Python version is not late enough."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an UpdateRecord subclass from a binary record.", "response": "def FromBinary(cls, record_data, record_count=1):\n        \"\"\"Create an UpdateRecord subclass from binary record data.\n\n        This should be called with a binary record blob (NOT including the\n        record type header) and it will decode it into a ResetDeviceRecord.\n\n        Args:\n            record_data (bytearray): The raw record data that we wish to parse\n                into an UpdateRecord subclass NOT including its 8 byte record header.\n            record_count (int): The number of records included in record_data.\n\n        Raises:\n            ArgumentError: If the record_data is malformed and cannot be parsed.\n\n        Returns:\n            ResetDeviceRecord: The decoded reflash tile record.\n        \"\"\"\n\n        if len(record_data) != 0:\n            raise ArgumentError(\"Reset device record should have no included data\", length=len(record_data))\n\n        return ResetDeviceRecord()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_vars(env):\n    if 'PCH' in env and env['PCH']:\n        if 'PCHSTOP' not in env:\n            raise SCons.Errors.UserError(\"The PCHSTOP construction must be defined if PCH is defined.\")\n        if not SCons.Util.is_String(env['PCHSTOP']):\n            raise SCons.Errors.UserError(\"The PCHSTOP construction variable must be a string: %r\"%env['PCHSTOP'])", "response": "Validate the PCH and PCHSTOP construction variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting appropriate PCHPDBFLAGS for the MSVC version being used.", "response": "def msvc_set_PCHPDBFLAGS(env):\n    \"\"\"\n    Set appropriate PCHPDBFLAGS for the MSVC version being used.\n    \"\"\"\n    if env.get('MSVC_VERSION',False):\n        maj, min = msvc_version_to_maj_min(env['MSVC_VERSION'])\n        if maj < 8:\n            env['PCHPDBFLAGS'] = SCons.Util.CLVar(['${(PDB and \"/Yd\") or \"\"}'])\n        else:\n            env['PCHPDBFLAGS'] = ''\n    else:\n        # Default if we can't determine which version of MSVC we're using\n        env['PCHPDBFLAGS'] = SCons.Util.CLVar(['${(PDB and \"/Yd\") or \"\"}'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the object file target.", "response": "def pch_emitter(target, source, env):\n    \"\"\"Adds the object file target.\"\"\"\n\n    validate_vars(env)\n\n    pch = None\n    obj = None\n\n    for t in target:\n        if SCons.Util.splitext(str(t))[1] == '.pch':\n            pch = t\n        if SCons.Util.splitext(str(t))[1] == '.obj':\n            obj = t\n\n    if not obj:\n        obj = SCons.Util.splitext(str(pch))[0]+'.obj'\n\n    target = [pch, obj] # pch must be first, and obj second for the PCHCOM to work\n\n    return (target, source)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef object_emitter(target, source, env, parent_emitter):\n\n    validate_vars(env)\n\n    parent_emitter(target, source, env)\n\n    # Add a dependency, but only if the target (e.g. 'Source1.obj')\n    # doesn't correspond to the pre-compiled header ('Source1.pch').\n    # If the basenames match, then this was most likely caused by\n    # someone adding the source file to both the env.PCH() and the\n    # env.Program() calls, and adding the explicit dependency would\n    # cause a cycle on the .pch file itself.\n    #\n    # See issue #2505 for a discussion of what to do if it turns\n    # out this assumption causes trouble in the wild:\n    # http://scons.tigris.org/issues/show_bug.cgi?id=2505\n    if 'PCH' in env:\n        pch = env['PCH']\n        if str(target[0]) != SCons.Util.splitext(str(pch))[0] + '.obj':\n            env.Depends(target, pch)\n\n    return (target, source)", "response": "Sets up the PCH dependencies for an object file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef msvc_batch_key(action, env, target, source):\n\n    # Fixing MSVC_BATCH mode. Previous if did not work when MSVC_BATCH\n    # was set to False. This new version should work better.\n    # Note we need to do the env.subst so $MSVC_BATCH can be a reference to\n    # another construction variable, which is why we test for False and 0\n    # as strings.\n    if not 'MSVC_BATCH' in env or env.subst('$MSVC_BATCH') in ('0', 'False', '', None):\n        # We're not using batching; return no key.\n        return None\n    t = target[0]\n    s = source[0]\n    if os.path.splitext(t.name)[0] != os.path.splitext(s.name)[0]:\n        # The base names are different, so this *must* be compiled\n        # separately; return no key.\n        return None\n    return (id(action), id(env), t.dir, s.dir)", "response": "Returns a key to identify unique batches of sources for compilation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the correct flag for batching.", "response": "def msvc_output_flag(target, source, env, for_signature):\n    \"\"\"\n    Returns the correct /Fo flag for batching.\n\n    If batching is disabled or there's only one source file, then we\n    return an /Fo string that specifies the target explicitly.  Otherwise,\n    we return an /Fo string that just specifies the first target's\n    directory (where the Visual C/C++ compiler will put the .obj files).\n    \"\"\"\n\n    # Fixing MSVC_BATCH mode. Previous if did not work when MSVC_BATCH\n    # was set to False. This new version should work better. Removed\n    # len(source)==1 as batch mode can compile only one file\n    # (and it also fixed problem with compiling only one changed file\n    # with batch mode enabled)\n    if not 'MSVC_BATCH' in env or env.subst('$MSVC_BATCH') in ('0', 'False', '', None):\n        return '/Fo$TARGET'\n    else:\n        # The Visual C/C++ compiler requires a \\ at the end of the /Fo\n        # option to indicate an output directory.  We use os.sep here so\n        # that the test(s) for this can be run on non-Windows systems\n        # without having a hard-coded backslash mess up command-line\n        # argument parsing.\n        return '/Fo${TARGET.dir}' + os.sep"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for MSVC ++ to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for MSVC++ to an Environment.\"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    # TODO(batch):  shouldn't reach in to cmdgen this way; necessary\n    # for now to bypass the checks in Builder.DictCmdGenerator.__call__()\n    # and allow .cc and .cpp to be compiled in the same command line.\n    static_obj.cmdgen.source_ext_match = False\n    shared_obj.cmdgen.source_ext_match = False\n\n    for suffix in CSuffixes:\n        static_obj.add_action(suffix, CAction)\n        shared_obj.add_action(suffix, ShCAction)\n        static_obj.add_emitter(suffix, static_object_emitter)\n        shared_obj.add_emitter(suffix, shared_object_emitter)\n\n    for suffix in CXXSuffixes:\n        static_obj.add_action(suffix, CXXAction)\n        shared_obj.add_action(suffix, ShCXXAction)\n        static_obj.add_emitter(suffix, static_object_emitter)\n        shared_obj.add_emitter(suffix, shared_object_emitter)\n\n    env['CCPDBFLAGS'] = SCons.Util.CLVar(['${(PDB and \"/Z7\") or \"\"}'])\n    env['CCPCHFLAGS'] = SCons.Util.CLVar(['${(PCH and \"/Yu%s \\\\\\\"/Fp%s\\\\\\\"\"%(PCHSTOP or \"\",File(PCH))) or \"\"}'])\n    env['_MSVC_OUTPUT_FLAG'] = msvc_output_flag\n    env['_CCCOMCOM']  = '$CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS $CCPCHFLAGS $CCPDBFLAGS'\n    env['CC']         = 'cl'\n    env['CCFLAGS']    = SCons.Util.CLVar('/nologo')\n    env['CFLAGS']     = SCons.Util.CLVar('')\n    env['CCCOM']      = '${TEMPFILE(\"$CC $_MSVC_OUTPUT_FLAG /c $CHANGED_SOURCES $CFLAGS $CCFLAGS $_CCCOMCOM\",\"$CCCOMSTR\")}'\n    env['SHCC']       = '$CC'\n    env['SHCCFLAGS']  = SCons.Util.CLVar('$CCFLAGS')\n    env['SHCFLAGS']   = SCons.Util.CLVar('$CFLAGS')\n    env['SHCCCOM']    = '${TEMPFILE(\"$SHCC $_MSVC_OUTPUT_FLAG /c $CHANGED_SOURCES $SHCFLAGS $SHCCFLAGS $_CCCOMCOM\",\"$SHCCCOMSTR\")}'\n    env['CXX']        = '$CC'\n    env['CXXFLAGS']   = SCons.Util.CLVar('$( /TP $)')\n    env['CXXCOM']     = '${TEMPFILE(\"$CXX $_MSVC_OUTPUT_FLAG /c $CHANGED_SOURCES $CXXFLAGS $CCFLAGS $_CCCOMCOM\",\"$CXXCOMSTR\")}'\n    env['SHCXX']      = '$CXX'\n    env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS')\n    env['SHCXXCOM']   = '${TEMPFILE(\"$SHCXX $_MSVC_OUTPUT_FLAG /c $CHANGED_SOURCES $SHCXXFLAGS $SHCCFLAGS $_CCCOMCOM\",\"$SHCXXCOMSTR\")}'\n    env['CPPDEFPREFIX']  = '/D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '/I'\n    env['INCSUFFIX']  = ''\n#    env.Append(OBJEMITTER = [static_object_emitter])\n#    env.Append(SHOBJEMITTER = [shared_object_emitter])\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 1\n\n    env['RC'] = 'rc'\n    env['RCFLAGS'] = SCons.Util.CLVar('')\n    env['RCSUFFIXES']=['.rc','.rc2']\n    env['RCCOM'] = '$RC $_CPPDEFFLAGS $_CPPINCFLAGS $RCFLAGS /fo$TARGET $SOURCES'\n    env['BUILDERS']['RES'] = res_builder\n    env['OBJPREFIX']      = ''\n    env['OBJSUFFIX']      = '.obj'\n    env['SHOBJPREFIX']    = '$OBJPREFIX'\n    env['SHOBJSUFFIX']    = '$OBJSUFFIX'\n\n    # Set-up ms tools paths\n    msvc_setup_env_once(env)\n\n    env['CFILESUFFIX'] = '.c'\n    env['CXXFILESUFFIX'] = '.cc'\n\n    msvc_set_PCHPDBFLAGS(env)\n\n\n    env['PCHCOM'] = '$CXX /Fo${TARGETS[1]} $CXXFLAGS $CCFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS /c $SOURCES /Yc$PCHSTOP /Fp${TARGETS[0]} $CCPDBFLAGS $PCHPDBFLAGS'\n    env['BUILDERS']['PCH'] = pch_builder\n\n    if 'ENV' not in env:\n        env['ENV'] = {}\n    if 'SystemRoot' not in env['ENV']:    # required for dlls in the winsxs folders\n        env['ENV']['SystemRoot'] = SCons.Platform.win32.get_system_root()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen and potentially connect to a device.", "response": "def open(self):\n        \"\"\"Open and potentially connect to a device.\"\"\"\n\n        self.hwman = HardwareManager(port=self._port)\n        self.opened = True\n\n        if self._connection_string is not None:\n            try:\n                self.hwman.connect_direct(self._connection_string)\n            except HardwareError:\n                self.hwman.close()\n                raise\n\n        elif self._connect_id is not None:\n            try:\n                self.hwman.connect(self._connect_id)\n            except HardwareError:\n                self.hwman.close()\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose and potentially disconnect from a device.", "response": "def close(self):\n        \"\"\"Close and potentially disconnect from a device.\"\"\"\n\n        if self.hwman.stream.connected:\n            self.hwman.disconnect()\n\n        self.hwman.close()\n        self.opened = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the support_package product.", "response": "def get_support_package(tile):\n    \"\"\"Returns the support_package product.\"\"\"\n\n    packages = tile.find_products('support_package')\n    if len(packages) == 0:\n        return None\n    elif len(packages) == 1:\n        return packages[0]\n\n    raise BuildError(\"Tile declared multiple support packages, only one is supported\", packages=packages)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_support_files(tile):\n\n    support_package = get_support_package(tile)\n    if support_package is None:\n        for module, _, _ in iter_python_modules(tile):\n            yield os.path.basename(module), module\n    else:\n        for dirpath, _dirnames, filenames in os.walk(support_package):\n            for filename in filenames:\n                if not filename.endswith('.py'):\n                    continue\n\n                input_path = os.path.join(dirpath, filename)\n                output_path = os.path.relpath(input_path, start=support_package)\n\n                if output_path == \"__init__.py\":\n                    continue\n\n                yield output_path, input_path", "response": "Iterate over all files inside the support wheel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iter_python_modules(tile):\n\n    for product_type in tile.PYTHON_PRODUCTS:\n        for product in tile.find_products(product_type):\n            entry_point = ENTRY_POINT_MAP.get(product_type)\n            if entry_point is None:\n                raise BuildError(\"Found an unknown python product (%s) whose entrypoint could not be determined (%s)\" %\n                                 (product_type, product))\n\n            if ':' in product:\n                module, _, obj_name = product.rpartition(':')\n            else:\n                module = product\n                obj_name = None\n\n            if not os.path.exists(module):\n                raise BuildError(\"Found a python product whose path did not exist: %s\" % module)\n\n            product_name = os.path.basename(module)\n            if product_name.endswith(\".py\"):\n                product_name = product_name[:-3]\n\n            import_string = \"{} = {}.{}\".format(product_name, tile.support_distribution, product_name)\n\n            if obj_name is not None:\n                import_string += \":{}\".format(obj_name)\n\n            yield (module, import_string, entry_point)", "response": "Iterate over all python modules in the given tile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_setup_py(target, source, env):\n\n    tile = env['TILE']\n    data = {}\n\n    entry_points = {}\n\n    for _mod, import_string, entry_point in iter_python_modules(tile):\n        if entry_point not in entry_points:\n            entry_points[entry_point] = []\n\n        entry_points[entry_point].append(import_string)\n\n    data['name'] = tile.support_distribution\n    data['package'] = tile.support_distribution\n    data['version'] = tile.parsed_version.pep440_string()\n    data['deps'] = [\"{0} {1}\".format(x.support_distribution, x.parsed_version.pep440_compatibility_specifier())\n                    for x in _iter_dependencies(tile) if x.has_wheel]\n\n    # If there are some python packages needed, we add them to the list of dependencies required\n    if tile.support_wheel_depends:\n        data['deps'] += tile.support_wheel_depends\n\n    data['entry_points'] = entry_points\n\n    outdir = os.path.dirname(str(target[0]))\n\n    render_template('setup.py.tpl', data, out_path=str(target[0]))\n\n    # Run setuptools to generate a wheel and an sdist\n    curr = os.getcwd()\n    os.chdir(outdir)\n    try:\n        setuptools.sandbox.run_setup('setup.py', ['-q', 'clean', 'sdist'])\n        if \"python_universal\" in tile.settings:\n            setuptools.sandbox.run_setup('setup.py', ['-q', 'clean', 'bdist_wheel', '--universal'])\n        else:\n            setuptools.sandbox.run_setup('setup.py', ['-q', 'clean', 'bdist_wheel'])\n    finally:\n        os.chdir(curr)", "response": "Generate the setup. py file for this distribution."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef defaultMachine(use_rpm_default=True):\n\n    if use_rpm_default:\n        try:\n            # This should be the most reliable way to get the default arch\n            rmachine = subprocess.check_output(['rpm', '--eval=%_target_cpu'], shell=False).rstrip()\n            rmachine = SCons.Util.to_str(rmachine)\n        except Exception as e:\n            # Something went wrong, try again by looking up platform.machine()\n            return defaultMachine(False)\n    else:\n        rmachine = platform.machine()\n\n        # Try to lookup the string in the canon table\n        if rmachine in arch_canon:\n            rmachine = arch_canon[rmachine][0]\n\n    return rmachine", "response": "Return the canonicalized machine name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef defaultSystem():\n    rsystem = platform.system()\n\n    # Try to lookup the string in the canon tables\n    if rsystem in os_canon:\n        rsystem = os_canon[rsystem][0]\n\n    return rsystem", "response": "Return the canonicalized system name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the given rpmrc file with RPM definitions and update the info dictionaries in the file pyfile with the new ones.", "response": "def updateRpmDicts(rpmrc, pyfile):\n    \"\"\" Read the given rpmrc file with RPM definitions and update the\n        info dictionaries in the file pyfile with it.\n        The arguments will usually be 'rpmrc.in' from a recent RPM source\n        tree, and 'rpmutils.py' referring to this script itself.\n        See also usage() below.\n    \"\"\"\n    try:\n        # Read old rpmutils.py file\n        oldpy = open(pyfile,\"r\").readlines()\n        # Read current rpmrc.in file\n        rpm = open(rpmrc,\"r\").readlines()\n        # Parse for data\n        data = {}\n        # Allowed section names that get parsed\n        sections = ['optflags',\n                    'arch_canon',\n                    'os_canon',\n                    'buildarchtranslate',\n                    'arch_compat',\n                    'os_compat',\n                    'buildarch_compat']\n        for l in rpm:\n            l = l.rstrip('\\n').replace(':',' ')\n            # Skip comments\n            if l.lstrip().startswith('#'):\n                continue\n            tokens = l.strip().split()\n            if len(tokens):\n                key = tokens[0]\n                if key in sections:\n                    # Have we met this section before?\n                    if tokens[0] not in data:\n                        # No, so insert it\n                        data[key] = {}\n                    # Insert data\n                    data[key][tokens[1]] = tokens[2:]\n        # Write new rpmutils.py file\n        out = open(pyfile,\"w\")\n        pm = 0\n        for l in oldpy:\n            if pm:\n                if l.startswith('# End of rpmrc dictionaries'):\n                    pm = 0\n                    out.write(l)\n            else:\n                out.write(l)\n                if l.startswith('# Start of rpmrc dictionaries'):\n                    pm = 1\n                    # Write data sections to single dictionaries\n                    for key, entries in data.items():\n                        out.write(\"%s = {\\n\" % key)\n                        for arch in sorted(entries.keys()):\n                            out.write(\"  '%s' : ['%s'],\\n\" % (arch, \"','\".join(entries[arch])))\n                        out.write(\"}\\n\\n\")\n        out.close()\n    except:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall just before the task is executed. This is mainly intended to give the target Nodes a chance to unlink underlying files and make all necessary directories before the Action is actually called to build the targets.", "response": "def prepare(self):\n        \"\"\"\n        Called just before the task is executed.\n\n        This is mainly intended to give the target Nodes a chance to\n        unlink underlying files and make all necessary directories before\n        the Action is actually called to build the targets.\n        \"\"\"\n        global print_prepare\n        T = self.tm.trace\n        if T: T.write(self.trace_message(u'Task.prepare()', self.node))\n\n        # Now that it's the appropriate time, give the TaskMaster a\n        # chance to raise any exceptions it encountered while preparing\n        # this task.\n        self.exception_raise()\n\n        if self.tm.message:\n            self.display(self.tm.message)\n            self.tm.message = None\n\n        # Let the targets take care of any necessary preparations.\n        # This includes verifying that all of the necessary sources\n        # and dependencies exist, removing the target file(s), etc.\n        #\n        # As of April 2008, the get_executor().prepare() method makes\n        # sure that all of the aggregate sources necessary to build this\n        # Task's target(s) exist in one up-front check.  The individual\n        # target t.prepare() methods check that each target's explicit\n        # or implicit dependencies exists, and also initialize the\n        # .sconsign info.\n        executor = self.targets[0].get_executor()\n        if executor is None:\n            return\n        executor.prepare()\n        for t in executor.get_action_targets():\n            if print_prepare:\n                print(\"Preparing target %s...\"%t)\n                for s in t.side_effects:\n                    print(\"...with side-effect %s...\"%s)\n            t.prepare()\n            for s in t.side_effects:\n                if print_prepare:\n                    print(\"...Preparing side-effect %s...\"%s)\n                s.prepare()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(self):\n        T = self.tm.trace\n        if T: T.write(self.trace_message(u'Task.execute()', self.node))\n\n        try:\n            cached_targets = []\n            for t in self.targets:\n                if not t.retrieve_from_cache():\n                    break\n                cached_targets.append(t)\n            if len(cached_targets) < len(self.targets):\n                # Remove targets before building. It's possible that we\n                # partially retrieved targets from the cache, leaving\n                # them in read-only mode. That might cause the command\n                # to fail.\n                #\n                for t in cached_targets:\n                    try:\n                        t.fs.unlink(t.get_internal_path())\n                    except (IOError, OSError):\n                        pass\n                self.targets[0].build()\n            else:\n                for t in cached_targets:\n                    t.cached = 1\n        except SystemExit:\n            exc_value = sys.exc_info()[1]\n            raise SCons.Errors.ExplicitExit(self.targets[0], exc_value.code)\n        except SCons.Errors.UserError:\n            raise\n        except SCons.Errors.BuildError:\n            raise\n        except Exception as e:\n            buildError = SCons.Errors.convert_to_BuildError(e)\n            buildError.node = self.targets[0]\n            buildError.exc_info = sys.exc_info()\n            raise buildError", "response": "Called to execute the task.\n\n        This method is called from multiple threads in a parallel build,\n        so only do thread safe stuff here.  Do thread unsafe stuff in\n        prepare(), executed() or failed()."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef executed_without_callbacks(self):\n        T = self.tm.trace\n        if T: T.write(self.trace_message('Task.executed_without_callbacks()',\n                                         self.node))\n\n        for t in self.targets:\n            if t.get_state() == NODE_EXECUTING:\n                for side_effect in t.side_effects:\n                    side_effect.set_state(NODE_NO_STATE)\n                t.set_state(NODE_EXECUTED)", "response": "Called when the task has been successfully executed and the Taskmaster instance doesn t want to call any callback methods."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when the Task has been successfully executed and the Taskmaster instance wants to call the Node s callback methods.", "response": "def executed_with_callbacks(self):\n        \"\"\"\n        Called when the task has been successfully executed and\n        the Taskmaster instance wants to call the Node's callback\n        methods.\n\n        This may have been a do-nothing operation (to preserve build\n        order), so we must check the node's state before deciding whether\n        it was \"built\", in which case we call the appropriate Node method.\n        In any event, we always call \"visited()\", which will handle any\n        post-visit actions that must take place regardless of whether\n        or not the target was an actual built target or a source Node.\n        \"\"\"\n        global print_prepare\n        T = self.tm.trace\n        if T: T.write(self.trace_message('Task.executed_with_callbacks()',\n                                         self.node))\n\n        for t in self.targets:\n            if t.get_state() == NODE_EXECUTING:\n                for side_effect in t.side_effects:\n                    side_effect.set_state(NODE_NO_STATE)\n                t.set_state(NODE_EXECUTED)\n                if not t.cached:\n                    t.push_to_cache()\n                t.built()\n                t.visited()\n                if (not print_prepare and\n                    (not hasattr(self, 'options') or not self.options.debug_includes)):\n                    t.release_target_info()\n            else:\n                t.visited()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark all targets in a task ready for execution.", "response": "def make_ready_all(self):\n        \"\"\"\n        Marks all targets in a task ready for execution.\n\n        This is used when the interface needs every target Node to be\n        visited--the canonical example being the \"scons -c\" option.\n        \"\"\"\n        T = self.tm.trace\n        if T: T.write(self.trace_message('Task.make_ready_all()', self.node))\n\n        self.out_of_date = self.targets[:]\n        for t in self.targets:\n            t.disambiguate().set_state(NODE_EXECUTING)\n            for s in t.side_effects:\n                # add disambiguate here to mirror the call on targets above\n                s.disambiguate().set_state(NODE_EXECUTING)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_ready_current(self):\n        global print_prepare\n        T = self.tm.trace\n        if T: T.write(self.trace_message(u'Task.make_ready_current()',\n                                         self.node))\n\n        self.out_of_date = []\n        needs_executing = False\n        for t in self.targets:\n            try:\n                t.disambiguate().make_ready()\n                is_up_to_date = not t.has_builder() or \\\n                                (not t.always_build and t.is_up_to_date())\n            except EnvironmentError as e:\n                raise SCons.Errors.BuildError(node=t, errstr=e.strerror, filename=e.filename)\n\n            if not is_up_to_date:\n                self.out_of_date.append(t)\n                needs_executing = True\n\n        if needs_executing:\n            for t in self.targets:\n                t.set_state(NODE_EXECUTING)\n                for s in t.side_effects:\n                    # add disambiguate here to mirror the call on targets in first loop above\n                    s.disambiguate().set_state(NODE_EXECUTING)\n        else:\n            for t in self.targets:\n                # We must invoke visited() to ensure that the node\n                # information has been computed before allowing the\n                # parent nodes to execute. (That could occur in a\n                # parallel build...)\n                t.visited()\n                t.set_state(NODE_UP_TO_DATE)\n                if (not print_prepare and\n                    (not hasattr(self, 'options') or not self.options.debug_includes)):\n                    t.release_target_info()", "response": "Mark all targets in a task ready for execution if any target is not current."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nposting - processes a task after it s been executed.", "response": "def postprocess(self):\n        \"\"\"\n        Post-processes a task after it's been executed.\n\n        This examines all the targets just built (or not, we don't care\n        if the build was successful, or even if there was no build\n        because everything was up-to-date) to see if they have any\n        waiting parent Nodes, or Nodes waiting on a common side effect,\n        that can be put back on the candidates list.\n        \"\"\"\n        T = self.tm.trace\n        if T: T.write(self.trace_message(u'Task.postprocess()', self.node))\n\n        # We may have built multiple targets, some of which may have\n        # common parents waiting for this build.  Count up how many\n        # targets each parent was waiting for so we can subtract the\n        # values later, and so we *don't* put waiting side-effect Nodes\n        # back on the candidates list if the Node is also a waiting\n        # parent.\n\n        targets = set(self.targets)\n\n        pending_children = self.tm.pending_children\n        parents = {}\n        for t in targets:\n            # A node can only be in the pending_children set if it has\n            # some waiting_parents.\n            if t.waiting_parents:\n                if T: T.write(self.trace_message(u'Task.postprocess()',\n                                                 t,\n                                                 'removing'))\n                pending_children.discard(t)\n            for p in t.waiting_parents:\n                parents[p] = parents.get(p, 0) + 1\n\n        for t in targets:\n            if t.side_effects is not None:\n                for s in t.side_effects:\n                    if s.get_state() == NODE_EXECUTING:\n                        s.set_state(NODE_NO_STATE)\n                        for p in s.waiting_parents:\n                            parents[p] = parents.get(p, 0) + 1\n                    for p in s.waiting_s_e:\n                        if p.ref_count == 0:\n                            self.tm.candidates.append(p)\n\n        for p, subtract in parents.items():\n            p.ref_count = p.ref_count - subtract\n            if T: T.write(self.trace_message(u'Task.postprocess()',\n                                             p,\n                                             'adjusted parent ref count'))\n            if p.ref_count == 0:\n                self.tm.candidates.append(p)\n\n        for t in targets:\n            t.postprocess()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exception_set(self, exception=None):\n        if not exception:\n            exception = sys.exc_info()\n        self.exception = exception\n        self.exception_raise = self._exception_raise", "response": "Sets the exception attribute of the object to be raised at the appropriate time."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nraises an exception that was recorded while getting a Task ready for execution.", "response": "def _exception_raise(self):\n        \"\"\"\n        Raises a pending exception that was recorded while getting a\n        Task ready for execution.\n        \"\"\"\n        exc = self.exc_info()[:]\n        try:\n            exc_type, exc_value, exc_traceback = exc\n        except ValueError:\n            exc_type, exc_value = exc\n            exc_traceback = None\n\n        # raise exc_type(exc_value).with_traceback(exc_traceback)\n        if sys.version_info[0] == 2:\n            exec(\"raise exc_type, exc_value, exc_traceback\")\n        else: #  sys.version_info[0] == 3:\n            if isinstance(exc_value, Exception): #hasattr(exc_value, 'with_traceback'):\n                # If exc_value is an exception, then just reraise\n                exec(\"raise exc_value.with_traceback(exc_traceback)\")\n            else:\n                # else we'll create an exception using the value and raise that\n                exec(\"raise exc_type(exc_value).with_traceback(exc_traceback)\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the next candidate Node for this Taskmaster and returns it.", "response": "def find_next_candidate(self):\n        \"\"\"\n        Returns the next candidate Node for (potential) evaluation.\n\n        The candidate list (really a stack) initially consists of all of\n        the top-level (command line) targets provided when the Taskmaster\n        was initialized.  While we walk the DAG, visiting Nodes, all the\n        children that haven't finished processing get pushed on to the\n        candidate list.  Each child can then be popped and examined in\n        turn for whether *their* children are all up-to-date, in which\n        case a Task will be created for their actual evaluation and\n        potential building.\n\n        Here is where we also allow candidate Nodes to alter the list of\n        Nodes that should be examined.  This is used, for example, when\n        invoking SCons in a source directory.  A source directory Node can\n        return its corresponding build directory Node, essentially saying,\n        \"Hey, you really need to build this thing over here instead.\"\n        \"\"\"\n        try:\n            return self.candidates.pop()\n        except IndexError:\n            pass\n        try:\n            node = self.top_targets_left.pop()\n        except IndexError:\n            return None\n        self.current_top = node\n        alt, message = node.alter_targets()\n        if alt:\n            self.message = message\n            self.candidates.append(node)\n            self.candidates.extend(self.order(alt))\n            node = self.candidates.pop()\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef no_next_candidate(self):\n        while self.candidates:\n            candidates = self.candidates\n            self.candidates = []\n            self.will_not_build(candidates)\n        return None", "response": "Stops Taskmaster processing by not returning a next candidate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_pending_children(self):\n\n        for n in self.pending_children:\n            assert n.state in (NODE_PENDING, NODE_EXECUTING), \\\n                (str(n), StateString[n.state])\n            assert len(n.waiting_parents) != 0, (str(n), len(n.waiting_parents))\n            for p in n.waiting_parents:\n                assert p.ref_count > 0, (str(n), str(p), p.ref_count)", "response": "Validate the content of the pending_children set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_next_ready_node(self):\n\n        self.ready_exc = None\n\n        T = self.trace\n        if T: T.write(SCons.Util.UnicodeType('\\n') + self.trace_message('Looking for a node to evaluate'))\n\n        while True:\n            node = self.next_candidate()\n            if node is None:\n                if T: T.write(self.trace_message('No candidate anymore.') + u'\\n')\n                return None\n\n            node = node.disambiguate()\n            state = node.get_state()\n\n            # For debugging only:\n            #\n            # try:\n            #     self._validate_pending_children()\n            # except:\n            #     self.ready_exc = sys.exc_info()\n            #     return node\n\n            if CollectStats:\n                if not hasattr(node.attributes, 'stats'):\n                    node.attributes.stats = Stats()\n                    StatsNodes.append(node)\n                S = node.attributes.stats\n                S.considered = S.considered + 1\n            else:\n                S = None\n\n            if T: T.write(self.trace_message(u'    Considering node %s and its children:' % self.trace_node(node)))\n\n            if state == NODE_NO_STATE:\n                # Mark this node as being on the execution stack:\n                node.set_state(NODE_PENDING)\n            elif state > NODE_PENDING:\n                # Skip this node if it has already been evaluated:\n                if S: S.already_handled = S.already_handled + 1\n                if T: T.write(self.trace_message(u'       already handled (executed)'))\n                continue\n\n            executor = node.get_executor()\n\n            try:\n                children = executor.get_all_children()\n            except SystemExit:\n                exc_value = sys.exc_info()[1]\n                e = SCons.Errors.ExplicitExit(node, exc_value.code)\n                self.ready_exc = (SCons.Errors.ExplicitExit, e)\n                if T: T.write(self.trace_message('       SystemExit'))\n                return node\n            except Exception as e:\n                # We had a problem just trying to figure out the\n                # children (like a child couldn't be linked in to a\n                # VariantDir, or a Scanner threw something).  Arrange to\n                # raise the exception when the Task is \"executed.\"\n                self.ready_exc = sys.exc_info()\n                if S: S.problem = S.problem + 1\n                if T: T.write(self.trace_message('       exception %s while scanning children.\\n' % e))\n                return node\n\n            children_not_visited = []\n            children_pending = set()\n            children_not_ready = []\n            children_failed = False\n\n            for child in chain(executor.get_all_prerequisites(), children):\n                childstate = child.get_state()\n\n                if T: T.write(self.trace_message(u'       ' + self.trace_node(child)))\n\n                if childstate == NODE_NO_STATE:\n                    children_not_visited.append(child)\n                elif childstate == NODE_PENDING:\n                    children_pending.add(child)\n                elif childstate == NODE_FAILED:\n                    children_failed = True\n\n                if childstate <= NODE_EXECUTING:\n                    children_not_ready.append(child)\n\n            # These nodes have not even been visited yet.  Add\n            # them to the list so that on some next pass we can\n            # take a stab at evaluating them (or their children).\n            children_not_visited.reverse()\n            self.candidates.extend(self.order(children_not_visited))\n\n            # if T and children_not_visited:\n            #    T.write(self.trace_message('     adding to candidates: %s' % map(str, children_not_visited)))\n            #    T.write(self.trace_message('     candidates now: %s\\n' % map(str, self.candidates)))\n\n            # Skip this node if any of its children have failed.\n            #\n            # This catches the case where we're descending a top-level\n            # target and one of our children failed while trying to be\n            # built by a *previous* descent of an earlier top-level\n            # target.\n            #\n            # It can also occur if a node is reused in multiple\n            # targets. One first descends though the one of the\n            # target, the next time occurs through the other target.\n            #\n            # Note that we can only have failed_children if the\n            # --keep-going flag was used, because without it the build\n            # will stop before diving in the other branch.\n            #\n            # Note that even if one of the children fails, we still\n            # added the other children to the list of candidate nodes\n            # to keep on building (--keep-going).\n            if children_failed:\n                for n in executor.get_action_targets():\n                    n.set_state(NODE_FAILED)\n\n                if S: S.child_failed = S.child_failed + 1\n                if T: T.write(self.trace_message('****** %s\\n' % self.trace_node(node)))\n                continue\n\n            if children_not_ready:\n                for child in children_not_ready:\n                    # We're waiting on one or more derived targets\n                    # that have not yet finished building.\n                    if S: S.not_built = S.not_built + 1\n\n                    # Add this node to the waiting parents lists of\n                    # anything we're waiting on, with a reference\n                    # count so we can be put back on the list for\n                    # re-evaluation when they've all finished.\n                    node.ref_count =  node.ref_count + child.add_to_waiting_parents(node)\n                    if T: T.write(self.trace_message(u'     adjusted ref count: %s, child %s' %\n                                  (self.trace_node(node), repr(str(child)))))\n\n                if T:\n                    for pc in children_pending:\n                        T.write(self.trace_message('       adding %s to the pending children set\\n' %\n                                self.trace_node(pc)))\n                self.pending_children = self.pending_children | children_pending\n\n                continue\n\n            # Skip this node if it has side-effects that are\n            # currently being built:\n            wait_side_effects = False\n            for se in executor.get_action_side_effects():\n                if se.get_state() == NODE_EXECUTING:\n                    se.add_to_waiting_s_e(node)\n                    wait_side_effects = True\n\n            if wait_side_effects:\n                if S: S.side_effects = S.side_effects + 1\n                continue\n\n            # The default when we've gotten through all of the checks above:\n            # this node is ready to be built.\n            if S: S.build = S.build + 1\n            if T: T.write(self.trace_message(u'Evaluating %s\\n' %\n                                             self.trace_node(node)))\n\n            # For debugging only:\n            #\n            # try:\n            #     self._validate_pending_children()\n            # except:\n            #     self.ready_exc = sys.exc_info()\n            #     return node\n\n            return node\n\n        return None", "response": "This method finds the next ready node in the candidates list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the next Task to be executed.", "response": "def next_task(self):\n        \"\"\"\n        Returns the next task to be executed.\n\n        This simply asks for the next Node to be evaluated, and then wraps\n        it in the specific Task subclass with which we were initialized.\n        \"\"\"\n        node = self._find_next_ready_node()\n\n        if node is None:\n            return None\n\n        executor = node.get_executor()\n        if executor is None:\n            return None\n\n        tlist = executor.get_all_targets()\n\n        task = self.tasker(self, tlist, node in self.original_top, node)\n        try:\n            task.make_ready()\n        except Exception as e :\n            # We had a problem just trying to get this task ready (like\n            # a child couldn't be linked to a VariantDir when deciding\n            # whether this node is current).  Arrange to raise the\n            # exception when the Task is \"executed.\"\n            self.ready_exc = sys.exc_info()\n\n        if self.ready_exc:\n            task.exception_set(self.ready_exc)\n\n        self.ready_exc = None\n\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform clean - up about nodes that will never be built. Invokes node_func on all of these nodes.", "response": "def will_not_build(self, nodes, node_func=lambda n: None):\n        \"\"\"\n        Perform clean-up about nodes that will never be built. Invokes\n        a user defined function on all of these nodes (including all\n        of their parents).\n        \"\"\"\n\n        T = self.trace\n\n        pending_children = self.pending_children\n\n        to_visit = set(nodes)\n        pending_children = pending_children - to_visit\n\n        if T:\n            for n in nodes:\n                T.write(self.trace_message('       removing node %s from the pending children set\\n' %\n                        self.trace_node(n)))\n        try:\n            while len(to_visit):\n                node = to_visit.pop()\n                node_func(node)\n\n                # Prune recursion by flushing the waiting children\n                # list immediately.\n                parents = node.waiting_parents\n                node.waiting_parents = set()\n\n                to_visit = to_visit | parents\n                pending_children = pending_children - parents\n\n                for p in parents:\n                    p.ref_count = p.ref_count - 1\n                    if T: T.write(self.trace_message('       removing parent %s from the pending children set\\n' %\n                                  self.trace_node(p)))\n        except KeyError:\n            # The container to_visit has been emptied.\n            pass\n\n        # We have the stick back the pending_children list into the\n        # taskmaster because the python 1.5.2 compatibility does not\n        # allow us to use in-place updates\n        self.pending_children = pending_children"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking for dependency cycles.", "response": "def cleanup(self):\n        \"\"\"\n        Check for dependency cycles.\n        \"\"\"\n        if not self.pending_children:\n            return\n\n        nclist = [(n, find_cycle([n], set())) for n in self.pending_children]\n\n        genuine_cycles = [\n            node for node,cycle in nclist\n                     if cycle or node.get_state() != NODE_EXECUTED\n        ]\n        if not genuine_cycles:\n            # All of the \"cycles\" found were single nodes in EXECUTED state,\n            # which is to say, they really weren't cycles.  Just return.\n            return\n\n        desc = 'Found dependency cycle(s):\\n'\n        for node, cycle in nclist:\n            if cycle:\n                desc = desc + \"  \" + \" -> \".join(map(str, cycle)) + \"\\n\"\n            else:\n                desc = desc + \\\n                    \"  Internal Error: no cycle found for node %s (%s) in state %s\\n\" %  \\\n                    (node, repr(node), StateString[node.get_state()])\n\n        raise SCons.Errors.UserError(desc)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, sensor_graph, model):\n\n        # This check can be done if there is 1 input and it is count == 1\n        # and the stream type is input or unbuffered\n\n        for node, inputs, outputs in sensor_graph.iterate_bfs():\n            if node.num_inputs != 1:\n                continue\n\n            input_a, trigger_a = node.inputs[0]\n            if input_a.selector.match_type not in [DataStream.InputType, DataStream.UnbufferedType]:\n                continue\n\n            if not isinstance(trigger_a, InputTrigger):\n                continue\n\n            if trigger_a.comp_string != u'==':\n                continue\n\n            if not trigger_a.use_count:\n                continue\n\n            if trigger_a.reference != 1:\n                continue\n\n            # here we're looking at count input | unbuffered X == 1\n            node.inputs[0] = (input_a, TrueTrigger())", "response": "This function runs the optimization pass on the sensor graph and model."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads and unpack a release iotile component by name and version range into destfolder.", "response": "def pull_release(self, name, version, destfolder=\".\", force=False):\n        \"\"\"Download and unpack a released iotile component by name and version range\n\n        If the folder that would be created already exists, this command fails unless\n        you pass force=True\n\n        Args:\n            name (string): The name of the component to download\n            version (SemanticVersionRange): The valid versions of the component to fetch\n            destfolder (string): The folder into which to unpack the result, defaults to\n                the current working directory\n            force (bool): Forcibly overwrite whatever is currently in the folder that would\n                be fetched.\n\n        Raises:\n            ExternalError: If the destination folder exists and force is not specified\n            ArgumentError: If the specified component could not be found with the required version\n        \"\"\"\n\n        unique_id = name.replace('/', '_')\n\n        depdict = {\n            'name': name,\n            'unique_id': unique_id,\n            'required_version': version,\n            'required_version_string': str(version)\n        }\n\n        destdir = os.path.join(destfolder, unique_id)\n        if os.path.exists(destdir):\n            if not force:\n                raise ExternalError(\"Output directory exists and force was not specified, aborting\",\n                                    output_directory=destdir)\n\n            shutil.rmtree(destdir)\n\n        result = self.update_dependency(None, depdict, destdir)\n        if result != \"installed\":\n            raise ArgumentError(\"Could not find component to satisfy name/version combination\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to install or update a dependency to the latest version.", "response": "def update_dependency(self, tile, depinfo, destdir=None):\n        \"\"\"Attempt to install or update a dependency to the latest version.\n\n        Args:\n            tile (IOTile): An IOTile object describing the tile that has the dependency\n            depinfo (dict): a dictionary from tile.dependencies specifying the dependency\n            destdir (string): An optional folder into which to unpack the dependency\n\n        Returns:\n            string: a string indicating the outcome.  Possible values are:\n                \"already installed\"\n                \"installed\"\n                \"updated\"\n                \"not found\"\n        \"\"\"\n\n        if destdir is None:\n            destdir = os.path.join(tile.folder, 'build', 'deps', depinfo['unique_id'])\n\n        has_version = False\n        had_version = False\n        if os.path.exists(destdir):\n            has_version = True\n            had_version = True\n\n        for priority, rule in self.rules:\n            if not self._check_rule(rule, depinfo):\n                continue\n\n            resolver = self._find_resolver(rule)\n\n            if has_version:\n                deptile = IOTile(destdir)\n\n                # If the dependency is not up to date, don't do anything\n                depstatus = self._check_dep(depinfo, deptile, resolver)\n                if depstatus is False:\n                    shutil.rmtree(destdir)\n                    has_version = False\n                else:\n                    continue\n\n            # Now try to resolve this dependency with the latest version\n            result = resolver.resolve(depinfo, destdir)\n            if not result['found'] and result.get('stop', False):\n                return 'not found'\n\n            if not result['found']:\n                continue\n\n            settings = {\n                'resolver': resolver.__class__.__name__,\n                'factory_args': rule[2]\n            }\n\n            if 'settings' in result:\n                settings['settings'] = result['settings']\n\n            self._save_depsettings(destdir, settings)\n\n            if had_version:\n                return \"updated\"\n\n            return \"installed\"\n\n        if has_version:\n            return \"already installed\"\n\n        return \"not found\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a dependency tile is up to date.", "response": "def _check_dep(self, depinfo, deptile, resolver):\n        \"\"\"Check if a dependency tile is up to date\n\n        Returns:\n            bool: True if it is up to date, False if it not and None if this resolver\n                cannot assess whether or not it is up to date.\n        \"\"\"\n\n        try:\n            settings = self._load_depsettings(deptile)\n        except IOError:\n            return False\n\n        # If this dependency was initially resolved with a different resolver, then\n        # we cannot check if it is up to date\n        if settings['resolver'] != resolver.__class__.__name__:\n            return None\n\n        resolver_settings = {}\n        if 'settings' in settings:\n            resolver_settings = settings['settings']\n\n        return resolver.check(depinfo, deptile, resolver_settings)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs any exception raised by future.", "response": "def _log_future_exception(future, logger):\n    \"\"\"Log any exception raised by future.\"\"\"\n\n    if not future.done():\n        return\n\n    try:\n        future.result()\n    except:  #pylint:disable=bare-except;This is a background logging helper\n        logger.warning(\"Exception in ignored future: %s\", future, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_subtask(self, cor, name=None, stop_timeout=1.0):\n\n        if self.stopped:\n            raise InternalError(\"Cannot add a subtask to a parent that is already stopped\")\n\n        subtask = BackgroundTask(cor, name, loop=self._loop, stop_timeout=stop_timeout)\n        self.add_subtask(subtask)\n        return subtask", "response": "Create and add a subtask from a coroutine."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlinks a subtask to this task.", "response": "def add_subtask(self, subtask):\n        \"\"\"Link a subtask to this parent task.\n\n        This will cause stop() to block until the subtask has also\n        finished.  Calling stop will not directly cancel the subtask.\n        It is expected that your finalizer for this parent task will\n        cancel or otherwise stop the subtask.\n\n        Args:\n            subtask (BackgroundTask): Another task that will be stopped\n                when this task is stopped.\n        \"\"\"\n\n        if self.stopped:\n            raise InternalError(\"Cannot add a subtask to a parent that is already stopped\")\n\n        if not isinstance(subtask, BackgroundTask):\n            raise ArgumentError(\"Subtasks must inherit from BackgroundTask, task={}\".format(subtask))\n\n        #pylint:disable=protected-access;It is the same class as us so is equivalent to self access.\n        if subtask._loop != self._loop:\n            raise ArgumentError(\"Subtasks must run in the same BackgroundEventLoop as their parent\",\n                                subtask=subtask, parent=self)\n\n        self.subtasks.append(subtask)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def stop(self):\n\n        if self.stopped:\n            return\n\n        self._logger.debug(\"Stopping task %s\", self.name)\n\n        if self._finalizer is not None:\n            try:\n                result = self._finalizer(self)\n                if inspect.isawaitable(result):\n                    await result\n            except:  #pylint:disable=bare-except;We need to make sure we always wait for the task\n                self._logger.exception(\"Error running finalizer for task %s\",\n                                       self.name)\n        elif self.task is not None:\n            self.task.cancel()\n\n        tasks = []\n        if self.task is not None:\n            tasks.append(self.task)\n\n        tasks.extend(x.task for x in self.subtasks)\n        finished = asyncio.gather(*tasks, return_exceptions=True)\n        outcomes = []\n\n        try:\n            outcomes = await asyncio.wait_for(finished, timeout=self._stop_timeout)\n        except asyncio.TimeoutError as err:\n            # See discussion here: https://github.com/python/asyncio/issues/253#issuecomment-120138132\n            # This prevents a nuisance log error message, finished is guaranteed\n            # to be cancelled but not awaited when wait_for() has a timeout.\n            try:\n                outcomes = await finished\n            except asyncio.CancelledError:\n                pass\n\n            # See https://mail.python.org/pipermail/python-3000/2008-May/013740.html\n            # for why we need to explictly name the error here\n            raise err\n        finally:\n            self.stopped = True\n            for outcome in outcomes:\n                if isinstance(outcome, Exception) and not isinstance(outcome, asyncio.CancelledError):\n                    self._logger.error(outcome)\n\n            if self in self._loop.tasks:\n                self._loop.tasks.remove(self)", "response": "Stop this task and wait until all subtasks end."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop this task from another thread and wait for it to finish.", "response": "def stop_threadsafe(self):\n        \"\"\"Stop this task from another thread and wait for it to finish.\n\n        This method must not be called from within the BackgroundEventLoop but\n        will inject self.stop() into the event loop and block until it\n        returns.\n\n        Raises:\n            TimeoutExpiredError: If the task does not stop in the given\n                timeout specified in __init__()\n        \"\"\"\n\n        if self.stopped:\n            return\n\n        try:\n            self._loop.run_coroutine(self.stop())\n        except asyncio.TimeoutError:\n            raise TimeoutExpiredError(\"Timeout stopping task {} with {} subtasks\".format(self.name, len(self.subtasks)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, aug='EventLoopThread'):\n\n        if self.stopping:\n            raise LoopStoppingError(\"Cannot perform action while loop is stopping.\")\n\n        if not self.loop:\n            self._logger.debug(\"Starting event loop\")\n            self.loop = asyncio.new_event_loop()\n            self.thread = threading.Thread(target=self._loop_thread_main, name=aug, daemon=True)\n            self.thread.start()", "response": "Start the background event loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for_interrupt(self, check_interval=1.0, max_time=None):\n\n        self.start()\n\n        wait = max(check_interval, 0.01)\n        accum = 0\n\n        try:\n            while max_time is None or accum < max_time:\n                try:\n                    time.sleep(wait)\n                except IOError:\n                    pass  # IOError comes when this call is interrupted in a signal handler\n\n                accum += wait\n        except KeyboardInterrupt:\n            pass", "response": "This method will run the event loop until we receive a ctrl - c interrupt or max_time passes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _stop_internal(self):\n\n        # Make sure we only try to stop once\n        if self.stopping is True:\n            return\n\n        self.stopping = True\n\n        awaitables = [task.stop() for task in self.tasks]\n        results = await asyncio.gather(*awaitables, return_exceptions=True)\n        for task, result in zip(self.tasks, results):\n            if isinstance(result, Exception):\n                self._logger.error(\"Error stopping task %s: %s\", task.name, repr(result))\n\n        # It is important to defer this call by one loop cycle so\n        # that this coroutine is finalized and anyone blocking on it\n        # resumes execution.\n        self.loop.call_soon(self.loop.stop)", "response": "Cleanly stop the event loop after shutting down all tasks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_task(self, cor, name=None, finalizer=None, stop_timeout=1.0, parent=None):\n\n        if self.stopping:\n            raise LoopStoppingError(\"Cannot add task because loop is stopping\")\n\n        # Ensure the loop exists and is started\n        self.start()\n\n        if parent is not None and parent not in self.tasks:\n            raise ArgumentError(\"Designated parent task {} is not registered\".format(parent))\n\n        task = BackgroundTask(cor, name, finalizer, stop_timeout, loop=self)\n        if parent is None:\n            self.tasks.add(task)\n            self._logger.debug(\"Added primary task %s\", task.name)\n        else:\n            parent.add_subtask(task)\n            self._logger.debug(\"Added subtask %s to parent %s\", task.name, parent.name)\n\n        return task", "response": "This method will add a task to the background event loop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_coroutine(self, cor, *args, **kwargs):\n\n        if self.stopping:\n            raise LoopStoppingError(\"Could not launch coroutine because loop is shutting down: %s\" % cor)\n\n        self.start()\n\n        cor = _instaniate_coroutine(cor, args, kwargs)\n\n        if self.inside_loop():\n            raise InternalError(\"BackgroundEventLoop.run_coroutine called from inside event loop, \"\n                                \"would have deadlocked.\")\n\n        future = self.launch_coroutine(cor)\n        return future.result()", "response": "Runs a coroutine to completion and return its result."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a coroutine task and return a blockable or awaitable object.", "response": "def launch_coroutine(self, cor, *args, **kwargs):\n        \"\"\"Start a coroutine task and return a blockable/awaitable object.\n\n        If this method is called from inside the event loop, it will return an\n        awaitable object.  If it is called from outside the event loop it will\n        return an concurrent Future object that can block the calling thread\n        until the operation is finished.\n\n        Args:\n            cor (coroutine): The coroutine that we wish to run in the\n                background and wait until it finishes.\n\n        Returns:\n            Future or asyncio.Task: A future representing the coroutine.\n\n            If this method is called from within the background loop\n            then an awaitable asyncio.Tasks is returned.  Otherwise,\n            a concurrent Future object is returned that you can call\n            ``result()`` on to block the calling thread.\n        \"\"\"\n\n        if self.stopping:\n            raise LoopStoppingError(\"Could not launch coroutine because loop is shutting down: %s\" % cor)\n\n        # Ensure the loop exists and is started\n        self.start()\n\n        cor = _instaniate_coroutine(cor, args, kwargs)\n\n        if self.inside_loop():\n            return asyncio.ensure_future(cor, loop=self.loop)\n\n        return asyncio.run_coroutine_threadsafe(cor, loop=self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_coroutine(self, cor, *args, **kwargs):\n\n        if self.stopping:\n            raise LoopStoppingError(\"Could not launch coroutine because loop is shutting down: %s\" % cor)\n\n        self.start()\n\n        cor = _instaniate_coroutine(cor, args, kwargs)\n\n        def _run_and_log():\n            task = self.loop.create_task(cor)\n            task.add_done_callback(lambda x: _log_future_exception(x, self._logger))\n\n        if self.inside_loop():\n            _run_and_log()\n        else:\n            self.loop.call_soon_threadsafe(_run_and_log)", "response": "Run a coroutine logging any exception raised by the coroutine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef link_cloud(self, username=None, password=None, device_id=None):\n\n    reg = ComponentRegistry()\n\n    domain = self.get('cloud:server')\n\n    if username is None:\n        prompt_str = \"Please enter your IOTile.cloud email: \"\n\n        username = input(prompt_str)\n\n    if password is None:\n        prompt_str = \"Please enter your IOTile.cloud password: \"\n\n        password = getpass.getpass(prompt_str)\n\n    cloud = Api(domain=domain)\n    ok_resp = cloud.login(email=username, password=password)\n    if not ok_resp:\n        raise ArgumentError(\"Could not login to iotile.cloud as user %s\" % username)\n\n    reg.set_config('arch:cloud_user', cloud.username)\n    reg.set_config('arch:cloud_token', cloud.token)\n    reg.set_config('arch:cloud_token_type', cloud.token_type)\n\n    if device_id is not None:\n        cloud = IOTileCloud()\n        cloud.impersonate_device(device_id)", "response": "Create and store a token for interacting with the IOTile Cloud API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading all entries from json backing file", "response": "def _load_file(self):\n        \"\"\"Load all entries from json backing file\n        \"\"\"\n\n        if not os.path.exists(self.file):\n            return {}\n\n        with open(self.file, \"r\") as infile:\n            data = json.load(infile)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _save_file(self, data):\n\n        if platform.system() == 'Windows':\n            with open(self.file, \"w\") as outfile:\n                json.dump(data, outfile)\n        else:\n            newpath = self.file + '.new'\n\n            with open(newpath, \"w\") as outfile:\n                json.dump(data, outfile)\n\n            os.rename(\n                os.path.realpath(newpath),\n                os.path.realpath(self.file)\n            )", "response": "Save the data into the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self, key):\n\n        data = self._load_file()\n        del data[key]\n        self._save_file(data)", "response": "Removes a key from the data store"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the value of a key in the cache", "response": "def set(self, key, value):\n        \"\"\"Set the value of a key\n\n        Args:\n            key (string): The key used to store this value\n            value (string): The value to store\n        \"\"\"\n\n        data = self._load_file()\n        data[key] = value\n        self._save_file(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trigger_chain(self):\n\n        trigger_stream = self.allocator.attach_stream(self.trigger_stream)\n        return (trigger_stream, self.trigger_cond)", "response": "Return a tuple for creating a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding common C compiler variables that are used by multiple tools.", "response": "def add_common_cc_variables(env):\n    \"\"\"\n    Add underlying common \"C compiler\" variables that\n    are used by multiple tools (specifically, c++).\n    \"\"\"\n    if '_CCCOMCOM' not in env:\n        env['_CCCOMCOM'] = '$CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS'\n        # It's a hack to test for darwin here, but the alternative\n        # of creating an applecc.py to contain this seems overkill.\n        # Maybe someday the Apple platform will require more setup and\n        # this logic will be moved.\n        env['FRAMEWORKS'] = SCons.Util.CLVar('')\n        env['FRAMEWORKPATH'] = SCons.Util.CLVar('')\n        if env['PLATFORM'] == 'darwin':\n            env['_CCCOMCOM'] = env['_CCCOMCOM'] + ' $_FRAMEWORKPATH'\n\n    if 'CCFLAGS' not in env:\n        env['CCFLAGS']   = SCons.Util.CLVar('')\n\n    if 'SHCCFLAGS' not in env:\n        env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for the tool to an Environment.", "response": "def generate(env):\n    \"\"\"\n    Add Builders and construction variables for C compilers to an Environment.\n    \"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in CSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.CAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ShCAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n        shared_obj.add_emitter(suffix, SCons.Defaults.SharedObjectEmitter)\n\n    add_common_cc_variables(env)\n\n    if 'CC' not in env:\n        env['CC']    = env.Detect(compilers) or compilers[0]\n    env['CFLAGS']    = SCons.Util.CLVar('')\n    env['CCCOM']     = '$CC -o $TARGET -c $CFLAGS $CCFLAGS $_CCCOMCOM $SOURCES'\n    env['SHCC']      = '$CC'\n    env['SHCFLAGS'] = SCons.Util.CLVar('$CFLAGS')\n    env['SHCCCOM']   = '$SHCC -o $TARGET -c $SHCFLAGS $SHCCFLAGS $_CCCOMCOM $SOURCES'\n\n    env['CPPDEFPREFIX']  = '-D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '-I'\n    env['INCSUFFIX']  = ''\n    env['SHOBJSUFFIX'] = '.os'\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 0\n\n    env['CFILESUFFIX'] = '.c'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_args():\n\n    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)\n    parser.add_argument(u'sensor_graph', type=str, help=u\"The sensor graph file to load and run.\")\n    parser.add_argument(u'--stop', u'-s', action=u\"append\", default=[], type=str, help=u\"A stop condition for when the simulation should end.\")\n    parser.add_argument(u'--realtime', u'-r', action=u\"store_true\", help=u\"Do not accelerate the simulation, pin the ticks to wall clock time\")\n    parser.add_argument(u'--watch', u'-w', action=u\"append\", default=[], help=u\"A stream to watch and print whenever writes are made.\")\n    parser.add_argument(u'--trace', u'-t', help=u\"Trace all writes to output streams to a file\")\n    parser.add_argument(u'--disable-optimizer', action=\"store_true\", help=u\"disable the sensor graph optimizer completely\")\n    parser.add_argument(u\"--mock-rpc\", u\"-m\", action=u\"append\", type=str, default=[], help=u\"mock an rpc, format should be <slot id>:<rpc_id> = value.  For example -m \\\"slot 1:0x500a = 10\\\"\")\n    parser.add_argument(u\"--port\", u\"-p\", help=u\"The port to use to connect to a device if we are semihosting\")\n    parser.add_argument(u\"--semihost-device\", u\"-d\", type=lambda x: int(x, 0), help=u\"The device id of the device we should semihost this sensor graph on.\")\n    parser.add_argument(u\"-c\", u\"--connected\", action=\"store_true\", help=u\"Simulate with a user connected to the device (to enable realtime outputs)\")\n    parser.add_argument(u\"-i\", u\"--stimulus\", action=u\"append\", default=[], help=\"Push a value to an input stream at the specified time (or before starting).  The syntax is [time: ][system ]input X = Y where X and Y are integers\")\n    return parser", "response": "Build command line arguments for the Seismic Network simulation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_mock_rpc(input_string):\n\n    spec, equals, value = input_string.partition(u'=')\n\n    if len(equals) == 0:\n        print(\"Could not parse mock RPC argument: {}\".format(input_string))\n        sys.exit(1)\n\n    try:\n        value = int(value.strip(), 0)\n    except ValueError as exc:\n        print(\"Could not parse mock RPC value: {}\".format(str(exc)))\n        sys.exit(1)\n\n    slot, part, rpc_id = spec.partition(u\":\")\n    if len(part) == 0:\n        print(\"Could not parse mock RPC slot/rpc definition: {}\".format(spec))\n        sys.exit(1)\n\n    try:\n        slot = SlotIdentifier.FromString(slot)\n    except ArgumentError as exc:\n        print(\"Could not parse slot id in mock RPC definition: {}\".format(exc.msg))\n        sys.exit(1)\n\n    try:\n        rpc_id = int(rpc_id, 0)\n    except ValueError as exc:\n        print(\"Could not parse mock RPC number: {}\".format(str(exc)))\n        sys.exit(1)\n\n    return slot, rpc_id, value", "response": "Process a mock RPC argument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a watched value.", "response": "def watch_printer(watch, value):\n    \"\"\"Print a watched value.\n\n    Args:\n        watch (DataStream): The stream that was watched\n        value (IOTileReading): The value to was seen\n    \"\"\"\n\n    print(\"({: 8} s) {}: {}\".format(value.raw_time, watch, value.value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _verify_tile_versions(self, hw):\n        for tile, expected_tile_version in self._tile_versions.items():\n            actual_tile_version = str(hw.get(tile).tile_version())\n            if expected_tile_version != actual_tile_version:\n                raise ArgumentError(\"Tile has incorrect firmware\", tile=tile, \\\n                    expected_version=expected_tile_version, actual_version=actual_tile_version)", "response": "Verify that the tile versions are correct."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the os and app tags and versions are set correctly.", "response": "def _verify_os_app_settings(self, hw):\n        \"\"\"Verify that the os and app tags/versions are set correctly\n        \"\"\"\n        con = hw.controller()\n        info = con.test_interface().get_info()\n        if self._os_tag is not None:\n            if info['os_tag'] != self._os_tag:\n                raise ArgumentError(\"Incorrect os_tag\", actual_os_tag=info['os_tag'],\\\n                        expected_os_tag=self._os_tag)\n        if self._app_tag is not None:\n            if info['app_tag'] != self._app_tag:\n                raise ArgumentError(\"Incorrect app_tag\", actual_os_tag=info['app_tag'],\\\n                        expected_os_tag=self._app_tag)\n        if self._os_version is not None:\n            if info['os_version'] != self._os_version:\n                raise ArgumentError(\"Incorrect os_version\", actual_os_version=info['os_version'],\\\n                        expected_os_version=self._os_version)\n        if self._app_version is not None:\n            if info['app_version'] != self._app_version:\n                raise ArgumentError(\"Incorrect app_version\", actual_os_version=info['app_version'],\\\n                        expected_os_version=self._app_version)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _verify_realtime_streams(self, hw):\n        print(\"--> Testing realtime data (takes 2 seconds)\")\n        time.sleep(2.1)\n        reports = [x for x in hw.iter_reports()]\n        reports_seen = {key: 0 for key in self._realtime_streams}\n\n        for report in reports:\n            stream_value = report.visible_readings[0].stream\n            if reports_seen.get(stream_value) is not None:\n                reports_seen[stream_value] += 1\n\n        for stream in reports_seen.keys():\n            if reports_seen[stream] < 2:\n                raise ArgumentError(\"Realtime Stream not pushing any reports\", stream=hex(stream), \\\n                    reports_seen=reports_seen[stream])", "response": "Check that the realtime streams are being produced"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the potential file in the current directory.", "response": "def _update_pot_file(target, source, env):\n    \"\"\" Action function for `POTUpdate` builder \"\"\"\n    import re\n    import os\n    import SCons.Action\n    nop = lambda target, source, env: 0\n\n    # Save scons cwd and os cwd (NOTE: they may be different. After the job, we\n    # revert each one to its original state).\n    save_cwd = env.fs.getcwd()\n    save_os_cwd = os.getcwd()\n    chdir = target[0].dir\n    chdir_str = repr(chdir.get_abspath())\n    # Print chdir message (employ SCons.Action.Action for that. It knows better\n    # than me how to to this correctly).\n    env.Execute(SCons.Action.Action(nop, \"Entering \" + chdir_str))\n    # Go to target's directory and do our job\n    env.fs.chdir(chdir, 1)  # Go into target's directory\n    try:\n        cmd = _CmdRunner('$XGETTEXTCOM', '$XGETTEXTCOMSTR')\n        action = SCons.Action.Action(cmd, strfunction=cmd.strfunction)\n        status = action([target[0]], source, env)\n    except:\n        # Something went wrong.\n        env.Execute(SCons.Action.Action(nop, \"Leaving \" + chdir_str))\n        # Revert working dirs to previous state and re-throw exception.\n        env.fs.chdir(save_cwd, 0)\n        os.chdir(save_os_cwd)\n        raise\n    # Print chdir message.\n    env.Execute(SCons.Action.Action(nop, \"Leaving \" + chdir_str))\n    # Revert working dirs to previous state.\n    env.fs.chdir(save_cwd, 0)\n    os.chdir(save_os_cwd)\n    # If the command was not successfull, return error code.\n    if status: return status\n\n    new_content = cmd.out\n\n    if not new_content:\n        # When xgettext finds no internationalized messages, no *.pot is created\n        # (because we don't want to bother translators with empty POT files).\n        needs_update = False\n        explain = \"no internationalized messages encountered\"\n    else:\n        if target[0].exists():\n            # If the file already exists, it's left unaltered unless its messages\n            # are outdated (w.r.t. to these recovered by xgettext from sources).\n            old_content = target[0].get_text_contents()\n            re_cdate = re.compile(r'^\"POT-Creation-Date: .*\"$[\\r\\n]?', re.M)\n            old_content_nocdate = re.sub(re_cdate, \"\", old_content)\n            new_content_nocdate = re.sub(re_cdate, \"\", new_content)\n            if (old_content_nocdate == new_content_nocdate):\n                # Messages are up-to-date\n                needs_update = False\n                explain = \"messages in file found to be up-to-date\"\n            else:\n                # Messages are outdated\n                needs_update = True\n                explain = \"messages in file were outdated\"\n        else:\n            # No POT file found, create new one\n            needs_update = True\n            explain = \"new file\"\n    if needs_update:\n        # Print message employing SCons.Action.Action for that.\n        msg = \"Writing \" + repr(str(target[0])) + \" (\" + explain + \")\"\n        env.Execute(SCons.Action.Action(nop, msg))\n        f = open(str(target[0]), \"w\")\n        f.write(new_content)\n        f.close()\n        return 0\n    else:\n        # Print message employing SCons.Action.Action for that.\n        msg = \"Not writing \" + repr(str(target[0])) + \" (\" + explain + \")\"\n        env.Execute(SCons.Action.Action(nop, msg))\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing POTFILES. in - like files and returns list of extracted file names.", "response": "def _scan_xgettext_from_files(target, source, env, files=None, path=None):\n    \"\"\" Parses `POTFILES.in`-like file and returns list of extracted file names.\n    \"\"\"\n    import re\n    import SCons.Util\n    import SCons.Node.FS\n\n    if files is None:\n        return 0\n    if not SCons.Util.is_List(files):\n        files = [files]\n\n    if path is None:\n        if 'XGETTEXTPATH' in env:\n            path = env['XGETTEXTPATH']\n        else:\n            path = []\n    if not SCons.Util.is_List(path):\n        path = [path]\n\n    path = SCons.Util.flatten(path)\n\n    dirs = ()\n    for p in path:\n        if not isinstance(p, SCons.Node.FS.Base):\n            if SCons.Util.is_String(p):\n                p = env.subst(p, source=source, target=target)\n            p = env.arg2nodes(p, env.fs.Dir)\n        dirs += tuple(p)\n    # cwd is the default search path (when no path is defined by user)\n    if not dirs:\n        dirs = (env.fs.getcwd(),)\n\n    # Parse 'POTFILE.in' files.\n    re_comment = re.compile(r'^#[^\\n\\r]*$\\r?\\n?', re.M)\n    re_emptyln = re.compile(r'^[ \\t\\r]*$\\r?\\n?', re.M)\n    re_trailws = re.compile(r'[ \\t\\r]+$')\n    for f in files:\n        # Find files in search path $XGETTEXTPATH\n        if isinstance(f, SCons.Node.FS.Base) and f.rexists():\n            contents = f.get_text_contents()\n            contents = re_comment.sub(\"\", contents)\n            contents = re_emptyln.sub(\"\", contents)\n            contents = re_trailws.sub(\"\", contents)\n            depnames = contents.splitlines()\n            for depname in depnames:\n                depfile = SCons.Node.FS.find_file(depname, dirs)\n                if not depfile:\n                    depfile = env.arg2nodes(depname, dirs[0].File)\n                env.Depends(target, depfile)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pot_update_emitter(target, source, env):\n    from SCons.Tool.GettextCommon import _POTargetFactory\n    import SCons.Util\n    import SCons.Node.FS\n\n    if 'XGETTEXTFROM' in env:\n        xfrom = env['XGETTEXTFROM']\n    else:\n        return target, source\n    if not SCons.Util.is_List(xfrom):\n        xfrom = [xfrom]\n\n    xfrom = SCons.Util.flatten(xfrom)\n\n    # Prepare list of 'POTFILE.in' files.\n    files = []\n    for xf in xfrom:\n        if not isinstance(xf, SCons.Node.FS.Base):\n            if SCons.Util.is_String(xf):\n                # Interpolate variables in strings\n                xf = env.subst(xf, source=source, target=target)\n            xf = env.arg2nodes(xf)\n        files.extend(xf)\n    if files:\n        env.Depends(target, files)\n        _scan_xgettext_from_files(target, source, env, files)\n    return target, source", "response": "Emits the target and source for POTUpdate."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a POTUpdate builder object", "response": "def _POTUpdateBuilder(env, **kw):\n    \"\"\" Creates `POTUpdate` builder object \"\"\"\n    import SCons.Action\n    from SCons.Tool.GettextCommon import _POTargetFactory\n    kw['action'] = SCons.Action.Action(_update_pot_file, None)\n    kw['suffix'] = '$POTSUFFIX'\n    kw['target_factory'] = _POTargetFactory(env, alias='$POTUPDATE_ALIAS').File\n    kw['emitter'] = _pot_update_emitter\n    return _POTBuilder(**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(env, **kw):\n    import SCons.Util\n    from SCons.Tool.GettextCommon import RPaths, _detect_xgettext\n\n    try:\n        env['XGETTEXT'] = _detect_xgettext(env)\n    except:\n        env['XGETTEXT'] = 'xgettext'\n    # NOTE: sources=\"$SOURCES\" would work as well. However, we use following\n    # construction to convert absolute paths provided by scons onto paths\n    # relative to current working dir. Note, that scons expands $SOURCE(S) to\n    # absolute paths for sources $SOURCE(s) outside of current subtree (e.g. in\n    # \"../\"). With source=$SOURCE these absolute paths would be written to the\n    # resultant *.pot file (and its derived *.po files) as references to lines in\n    # source code (e.g. referring lines in *.c files). Such references would be\n    # correct (e.g. in poedit) only on machine on which *.pot was generated and\n    # would be of no use on other hosts (having a copy of source code located\n    # in different place in filesystem).\n    sources = '$( ${_concat( \"\", SOURCES, \"\", __env__, XgettextRPaths, TARGET' \\\n              + ', SOURCES)} $)'\n\n    # NOTE: the output from $XGETTEXTCOM command must go to stdout, not to a file.\n    # This is required by the POTUpdate builder's action.\n    xgettextcom = '$XGETTEXT $XGETTEXTFLAGS $_XGETTEXTPATHFLAGS' \\\n                  + ' $_XGETTEXTFROMFLAGS -o - ' + sources\n\n    xgettextpathflags = '$( ${_concat( XGETTEXTPATHPREFIX, XGETTEXTPATH' \\\n                        + ', XGETTEXTPATHSUFFIX, __env__, RDirs, TARGET, SOURCES)} $)'\n    xgettextfromflags = '$( ${_concat( XGETTEXTFROMPREFIX, XGETTEXTFROM' \\\n                        + ', XGETTEXTFROMSUFFIX, __env__, target=TARGET, source=SOURCES)} $)'\n\n    env.SetDefault(\n        _XGETTEXTDOMAIN='${TARGET.filebase}',\n        XGETTEXTFLAGS=[],\n        XGETTEXTCOM=xgettextcom,\n        XGETTEXTCOMSTR='',\n        XGETTEXTPATH=[],\n        XGETTEXTPATHPREFIX='-D',\n        XGETTEXTPATHSUFFIX='',\n        XGETTEXTFROM=None,\n        XGETTEXTFROMPREFIX='-f',\n        XGETTEXTFROMSUFFIX='',\n        _XGETTEXTPATHFLAGS=xgettextpathflags,\n        _XGETTEXTFROMFLAGS=xgettextfromflags,\n        POTSUFFIX=['.pot'],\n        POTUPDATE_ALIAS='pot-update',\n        XgettextRPaths=RPaths(env)\n    )\n    env.Append(BUILDERS={\n        '_POTUpdateBuilder': _POTUpdateBuilder(env)\n    })\n    env.AddMethod(_POTUpdateBuilderWrapper, 'POTUpdate')\n    env.AlwaysBuild(env.Alias('$POTUPDATE_ALIAS'))", "response": "Generate xgettext - related tool"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(env):\n\n    if 'CC' not in env:\n        env['CC'] = env.Detect(compilers) or compilers[0]\n\n    cc.generate(env)\n\n    if env['PLATFORM'] in ['cygwin', 'win32']:\n        env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS')\n    else:\n        env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS -fPIC')\n    # determine compiler version\n    version = detect_version(env, env['CC'])\n    if version:\n        env['CCVERSION'] = version", "response": "Add Builders and construction variables for gcc to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetecting the version of the GNU compiler.", "response": "def detect_version(env, cc):\n    \"\"\"Return the version of the GNU compiler, or None if it is not a GNU compiler.\"\"\"\n    cc = env.subst(cc)\n    if not cc:\n        return None\n    version = None\n    #pipe = SCons.Action._subproc(env, SCons.Util.CLVar(cc) + ['-dumpversion'],\n    pipe = SCons.Action._subproc(env, SCons.Util.CLVar(cc) + ['--version'],\n                                 stdin = 'devnull',\n                                 stderr = 'devnull',\n                                 stdout = subprocess.PIPE)\n    # -dumpversion was added in GCC 3.0.  As long as we're supporting\n    # GCC versions older than that, we should use --version and a\n    # regular expression.\n    #line = pipe.stdout.read().strip()\n    #if line:\n    #    version = line\n    line = SCons.Util.to_str(pipe.stdout.readline())\n    match = re.search(r'[0-9]+(\\.[0-9]+)+', line)\n    if match:\n        version = match.group(0)\n    # Non-GNU compiler's output (like AIX xlc's) may exceed the stdout buffer:\n    # So continue with reading to let the child process actually terminate.\n    while SCons.Util.to_str(pipe.stdout.readline()):\n        pass\n    ret = pipe.wait()\n    if ret != 0:\n        return None\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_to_id(s, id_set):\n    charset = 'ABCDEFGHIJKLMNOPQRSTUVWXYabcdefghijklmnopqrstuvwxyz0123456789_.'\n    if s[0] in '0123456789.':\n        s += '_'+s\n    id = [c for c in s if c in charset]\n\n    # did we already generate an id for this file?\n    try:\n        return id_set[id][s]\n    except KeyError:\n        # no we did not, so initialize with the id\n        if id not in id_set: id_set[id] = { s : id }\n        # there is a collision, generate an id which is unique by appending\n        # the collision number\n        else: id_set[id][s] = id + str(len(id_set[id]))\n\n        return id_set[id][s]", "response": "Convert a string to an id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_dos_short_file_name(file):\n    fname, ext = os.path.splitext(file)\n    proper_ext = len(ext) == 0 or (2 <= len(ext) <= 4) # the ext contains the dot\n    proper_fname = file.isupper() and len(fname) <= 8\n\n    return proper_ext and proper_fname", "response": "Examine if the given file is in the 8. 3 form."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_dos_short_file_name(file, filename_set):\n    # guard this to not confuse the generation\n    if is_dos_short_file_name(file):\n        return file\n\n    fname, ext = os.path.splitext(file) # ext contains the dot\n\n    # first try if it suffices to convert to upper\n    file = file.upper()\n    if is_dos_short_file_name(file):\n        return file\n\n    # strip forbidden characters.\n    forbidden = '.\"/[]:;=, '\n    fname = [c for c in fname if c not in forbidden]\n\n    # check if we already generated a filename with the same number:\n    # thisis1.txt, thisis2.txt etc.\n    duplicate, num = not None, 1\n    while duplicate:\n        shortname = \"%s%s\" % (fname[:8-len(str(num))].upper(),\\\n                              str(num))\n        if len(ext) >= 2:\n            shortname = \"%s%s\" % (shortname, ext[:4].upper())\n\n        duplicate, num = shortname in filename_set, num+1\n\n    assert( is_dos_short_file_name(shortname) ), 'shortname is %s, longname is %s' % (shortname, file)\n    filename_set.append(shortname)\n    return shortname", "response": "Generate a dos short filename from a file name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a dictionary of files that can be used to collect files in a base directory.", "response": "def create_feature_dict(files):\n    \"\"\" X_MSI_FEATURE and doc FileTag's can be used to collect files in a\n        hierarchy. This function collects the files into this hierarchy.\n    \"\"\"\n    dict = {}\n\n    def add_to_dict( feature, file ):\n        if not SCons.Util.is_List( feature ):\n            feature = [ feature ]\n\n        for f in feature:\n            if f not in dict:\n                dict[ f ] = [ file ]\n            else:\n                dict[ f ].append( file )\n\n    for file in files:\n        if hasattr( file, 'PACKAGING_X_MSI_FEATURE' ):\n            add_to_dict(file.PACKAGING_X_MSI_FEATURE, file)\n        elif hasattr( file, 'PACKAGING_DOC' ):\n            add_to_dict( 'PACKAGING_DOC', file )\n        else:\n            add_to_dict( 'default', file )\n\n    return dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates globally unique identifiers for parts of the xml which need them.", "response": "def generate_guids(root):\n    \"\"\" generates globally unique identifiers for parts of the xml which need\n    them.\n\n    Component tags have a special requirement. Their UUID is only allowed to\n    change if the list of their contained resources has changed. This allows\n    for clean removal and proper updates.\n\n    To handle this requirement, the uuid is generated with an md5 hashing the\n    whole subtree of a xml node.\n    \"\"\"\n    from hashlib import md5\n\n    # specify which tags need a guid and in which attribute this should be stored.\n    needs_id = { 'Product'   : 'Id',\n                 'Package'   : 'Id',\n                 'Component' : 'Guid',\n               }\n\n    # find all XMl nodes matching the key, retrieve their attribute, hash their\n    # subtree, convert hash to string and add as a attribute to the xml node.\n    for (key,value) in needs_id.items():\n        node_list = root.getElementsByTagName(key)\n        attribute = value\n        for node in node_list:\n            hash = md5(node.toxml()).hexdigest()\n            hash_str = '%s-%s-%s-%s-%s' % ( hash[:8], hash[8:12], hash[12:16], hash[16:20], hash[20:] )\n            node.attributes[attribute] = hash_str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a. wxs file from the keywords given in env and generates the XML file.", "response": "def build_wxsfile(target, source, env):\n    \"\"\" Compiles a .wxs file from the keywords given in env['msi_spec'] and\n        by analyzing the tree of source nodes and their tags.\n    \"\"\"\n    file = open(target[0].get_abspath(), 'w')\n\n    try:\n        # Create a document with the Wix root tag\n        doc  = Document()\n        root = doc.createElement( 'Wix' )\n        root.attributes['xmlns']='http://schemas.microsoft.com/wix/2003/01/wi'\n        doc.appendChild( root )\n\n        filename_set = [] # this is to circumvent duplicates in the shortnames\n        id_set       = {} # this is to circumvent duplicates in the ids\n\n        # Create the content\n        build_wxsfile_header_section(root, env)\n        build_wxsfile_file_section(root, source, env['NAME'], env['VERSION'], env['VENDOR'], filename_set, id_set)\n        generate_guids(root)\n        build_wxsfile_features_section(root, source, env['NAME'], env['VERSION'], env['SUMMARY'], id_set)\n        build_wxsfile_default_gui(root)\n        build_license_file(target[0].get_dir(), env)\n\n        # write the xml to a file\n        file.write( doc.toprettyxml() )\n\n        # call a user specified function\n        if 'CHANGE_SPECFILE' in env:\n            env['CHANGE_SPECFILE'](target, source)\n\n    except KeyError as e:\n        raise SCons.Errors.UserError( '\"%s\" package field for MSI is missing.' % e.args[0] )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_default_directory_layout(root, NAME, VERSION, VENDOR, filename_set):\n    doc = Document()\n    d1  = doc.createElement( 'Directory' )\n    d1.attributes['Id']   = 'TARGETDIR'\n    d1.attributes['Name'] = 'SourceDir'\n\n    d2  = doc.createElement( 'Directory' )\n    d2.attributes['Id']   = 'ProgramFilesFolder'\n    d2.attributes['Name'] = 'PFiles'\n\n    d3 = doc.createElement( 'Directory' )\n    d3.attributes['Id']       = 'VENDOR_folder'\n    d3.attributes['Name']     = escape( gen_dos_short_file_name( VENDOR, filename_set ) )\n    d3.attributes['LongName'] = escape( VENDOR )\n\n    d4 = doc.createElement( 'Directory' )\n    project_folder            = \"%s-%s\" % ( NAME, VERSION )\n    d4.attributes['Id']       = 'MY_DEFAULT_FOLDER'\n    d4.attributes['Name']     = escape( gen_dos_short_file_name( project_folder, filename_set ) )\n    d4.attributes['LongName'] = escape( project_folder )\n\n    d1.childNodes.append( d2 )\n    d2.childNodes.append( d3 )\n    d3.childNodes.append( d4 )\n\n    root.getElementsByTagName('Product')[0].childNodes.append( d1 )\n\n    return d4", "response": "Create the wix default target directory layout and return the innermost directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the wxs file section.", "response": "def build_wxsfile_file_section(root, files, NAME, VERSION, VENDOR, filename_set, id_set):\n    \"\"\" Builds the Component sections of the wxs file with their included files.\n\n    Files need to be specified in 8.3 format and in the long name format, long\n    filenames will be converted automatically.\n\n    Features are specficied with the 'X_MSI_FEATURE' or 'DOC' FileTag.\n    \"\"\"\n    root       = create_default_directory_layout( root, NAME, VERSION, VENDOR, filename_set )\n    components = create_feature_dict( files )\n    factory    = Document()\n\n    def get_directory( node, dir ):\n        \"\"\" Returns the node under the given node representing the directory.\n\n        Returns the component node if dir is None or empty.\n        \"\"\"\n        if dir == '' or not dir:\n            return node\n\n        Directory = node\n        dir_parts = dir.split(os.path.sep)\n\n        # to make sure that our directory ids are unique, the parent folders are\n        # consecutively added to upper_dir\n        upper_dir = ''\n\n        # walk down the xml tree finding parts of the directory\n        dir_parts = [d for d in dir_parts if d != '']\n        for d in dir_parts[:]:\n            already_created = [c for c in Directory.childNodes\n                               if c.nodeName == 'Directory'\n                               and c.attributes['LongName'].value == escape(d)] \n\n            if already_created != []:\n                Directory = already_created[0]\n                dir_parts.remove(d)\n                upper_dir += d\n            else:\n                break\n\n        for d in dir_parts:\n            nDirectory = factory.createElement( 'Directory' )\n            nDirectory.attributes['LongName'] = escape( d )\n            nDirectory.attributes['Name']     = escape( gen_dos_short_file_name( d, filename_set ) )\n            upper_dir += d\n            nDirectory.attributes['Id']       = convert_to_id( upper_dir, id_set )\n\n            Directory.childNodes.append( nDirectory )\n            Directory = nDirectory\n\n        return Directory\n\n    for file in files:\n        drive, path = os.path.splitdrive( file.PACKAGING_INSTALL_LOCATION )\n        filename = os.path.basename( path )\n        dirname  = os.path.dirname( path )\n\n        h = {\n            # tagname                   : default value\n            'PACKAGING_X_MSI_VITAL'     : 'yes',\n            'PACKAGING_X_MSI_FILEID'    : convert_to_id(filename, id_set),\n            'PACKAGING_X_MSI_LONGNAME'  : filename,\n            'PACKAGING_X_MSI_SHORTNAME' : gen_dos_short_file_name(filename, filename_set),\n            'PACKAGING_X_MSI_SOURCE'    : file.get_path(),\n            }\n\n        # fill in the default tags given above.\n        for k,v in [ (k, v) for (k,v) in h.items() if not hasattr(file, k) ]:\n            setattr( file, k, v )\n\n        File = factory.createElement( 'File' )\n        File.attributes['LongName'] = escape( file.PACKAGING_X_MSI_LONGNAME )\n        File.attributes['Name']     = escape( file.PACKAGING_X_MSI_SHORTNAME )\n        File.attributes['Source']   = escape( file.PACKAGING_X_MSI_SOURCE )\n        File.attributes['Id']       = escape( file.PACKAGING_X_MSI_FILEID )\n        File.attributes['Vital']    = escape( file.PACKAGING_X_MSI_VITAL )\n\n        # create the <Component> Tag under which this file should appear\n        Component = factory.createElement('Component')\n        Component.attributes['DiskId'] = '1'\n        Component.attributes['Id']     = convert_to_id( filename, id_set )\n\n        # hang the component node under the root node and the file node\n        # under the component node.\n        Directory = get_directory( root, dirname )\n        Directory.childNodes.append( Component )\n        Component.childNodes.append( File )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_wxsfile_default_gui(root):\n    factory = Document()\n    Product = root.getElementsByTagName('Product')[0]\n\n    UIRef   = factory.createElement('UIRef')\n    UIRef.attributes['Id'] = 'WixUI_Mondo'\n    Product.childNodes.append(UIRef)\n\n    UIRef   = factory.createElement('UIRef')\n    UIRef.attributes['Id'] = 'WixUI_ErrorProgressText'\n    Product.childNodes.append(UIRef)", "response": "This function adds a default GUI to the wxs file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a License. rtf file with the content of X_MSI_LICENSE_TEXT", "response": "def build_license_file(directory, spec):\n    \"\"\" Creates a License.rtf file with the content of \"X_MSI_LICENSE_TEXT\"\n    in the given directory\n    \"\"\"\n    name, text = '', ''\n\n    try:\n        name = spec['LICENSE']\n        text = spec['X_MSI_LICENSE_TEXT']\n    except KeyError:\n        pass # ignore this as X_MSI_LICENSE_TEXT is optional\n\n    if name!='' or text!='':\n        file = open( os.path.join(directory.get_path(), 'License.rtf'), 'w' )\n        file.write('{\\\\rtf')\n        if text!='':\n             file.write(text.replace('\\n', '\\\\par '))\n        else:\n             file.write(name+'\\\\par\\\\par')\n        file.write('}')\n        file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the xml file header section.", "response": "def build_wxsfile_header_section(root, spec):\n    \"\"\" Adds the xml file node which define the package meta-data.\n    \"\"\"\n    # Create the needed DOM nodes and add them at the correct position in the tree.\n    factory = Document()\n    Product = factory.createElement( 'Product' )\n    Package = factory.createElement( 'Package' )\n\n    root.childNodes.append( Product )\n    Product.childNodes.append( Package )\n\n    # set \"mandatory\" default values\n    if 'X_MSI_LANGUAGE' not in spec:\n        spec['X_MSI_LANGUAGE'] = '1033' # select english\n\n    # mandatory sections, will throw a KeyError if the tag is not available\n    Product.attributes['Name']         = escape( spec['NAME'] )\n    Product.attributes['Version']      = escape( spec['VERSION'] )\n    Product.attributes['Manufacturer'] = escape( spec['VENDOR'] )\n    Product.attributes['Language']     = escape( spec['X_MSI_LANGUAGE'] )\n    Package.attributes['Description']  = escape( spec['SUMMARY'] )\n\n    # now the optional tags, for which we avoid the KeyErrror exception\n    if 'DESCRIPTION' in spec:\n        Package.attributes['Comments'] = escape( spec['DESCRIPTION'] )\n\n    if 'X_MSI_UPGRADE_CODE' in spec:\n        Package.attributes['X_MSI_UPGRADE_CODE'] = escape( spec['X_MSI_UPGRADE_CODE'] )\n\n    # We hardcode the media tag as our current model cannot handle it.\n    Media = factory.createElement('Media')\n    Media.attributes['Id']       = '1'\n    Media.attributes['Cabinet']  = 'default.cab'\n    Media.attributes['EmbedCab'] = 'yes'\n    root.getElementsByTagName('Product')[0].childNodes.append(Media)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(env):\n    path, cxx, shcxx, version = get_cppc(env)\n    if path:\n        cxx = os.path.join(path, cxx)\n        shcxx = os.path.join(path, shcxx)\n\n    cplusplus.generate(env)\n\n    env['CXX'] = cxx\n    env['SHCXX'] = shcxx\n    env['CXXVERSION'] = version\n    env['SHCXXFLAGS']   = SCons.Util.CLVar('$CXXFLAGS -KPIC')\n    env['SHOBJPREFIX']  = 'so_'\n    env['SHOBJSUFFIX']  = '.o'", "response": "Add Builders and construction variables for SunPRO C ++."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a FlexibleDictionaryReport object from a list of readings and events.", "response": "def FromReadings(cls, uuid, readings, events, report_id=IOTileReading.InvalidReadingID,\n                     selector=0xFFFF, streamer=0x100, sent_timestamp=0, received_time=None):\n        \"\"\"Create a flexible dictionary report from a list of readings and events.\n\n        Args:\n            uuid (int): The uuid of the device that this report came from\n            readings (list of IOTileReading): A list of IOTileReading objects containing the data in the report\n            events (list of IOTileEvent): A list of the events contained in the report.\n            report_id (int): The id of the report.  If not provided it defaults to IOTileReading.InvalidReadingID.\n                Note that you can specify anything you want for the report id but for actual IOTile devices\n                the report id will always be greater than the id of all of the readings contained in the report\n                since devices generate ids sequentially.\n            selector (int): The streamer selector of this report.  This can be anything but if the report came from\n                a device, it would correspond with the query the device used to pick readings to go into the report.\n            streamer (int): The streamer id that this reading was sent from.\n            sent_timestamp (int): The device's uptime that sent this report.\n            received_time(datetime): The UTC time when this report was received from an IOTile device.  If it is being\n                created now, received_time defaults to datetime.utcnow().\n\n        Returns:\n            FlexibleDictionaryReport: A report containing the readings and events passed in.\n        \"\"\"\n\n        lowest_id = IOTileReading.InvalidReadingID\n        highest_id = IOTileReading.InvalidReadingID\n\n        for item in itertools.chain(iter(readings), iter(events)):\n            if item.reading_id == IOTileReading.InvalidReadingID:\n                continue\n\n            if lowest_id == IOTileReading.InvalidReadingID or item.reading_id < lowest_id:\n                lowest_id = item.reading_id\n            if highest_id == IOTileReading.InvalidReadingID or item.reading_id > highest_id:\n                highest_id = item.reading_id\n\n        reading_list = [x.asdict() for x in readings]\n        event_list = [x.asdict() for x in events]\n\n        report_dict = {\n            \"format\": cls.FORMAT_TAG,\n            \"device\": uuid,\n            \"streamer_index\": streamer,\n            \"streamer_selector\": selector,\n            \"incremental_id\": report_id,\n            \"lowest_id\": lowest_id,\n            \"highest_id\": highest_id,\n            \"device_sent_timestamp\": sent_timestamp,\n            \"events\": event_list,\n            \"data\": reading_list\n        }\n\n        encoded = msgpack.packb(report_dict, default=_encode_datetime, use_bin_type=True)\n        return FlexibleDictionaryReport(encoded, signed=False, encrypted=False, received_time=received_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndecodes this report from a msgpack encoded binary blob.", "response": "def decode(self):\n        \"\"\"Decode this report from a msgpack encoded binary blob.\"\"\"\n\n        report_dict = msgpack.unpackb(self.raw_report, raw=False)\n\n        events = [IOTileEvent.FromDict(x) for x in report_dict.get('events', [])]\n        readings = [IOTileReading.FromDict(x) for x in report_dict.get('data', [])]\n\n        if 'device' not in report_dict:\n            raise DataError(\"Invalid encoded FlexibleDictionaryReport that did not \"\n                            \"have a device key set with the device uuid\")\n\n        self.origin = report_dict['device']\n        self.report_id = report_dict.get(\"incremental_id\", IOTileReading.InvalidReadingID)\n        self.sent_timestamp = report_dict.get(\"device_sent_timestamp\", 0)\n        self.origin_streamer = report_dict.get(\"streamer_index\")\n        self.streamer_selector = report_dict.get(\"streamer_selector\")\n        self.lowest_id = report_dict.get('lowest_id')\n        self.highest_id = report_dict.get('highest_id')\n\n        return readings, events"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _callable_contents(obj):\n    try:\n        # Test if obj is a method.\n        return _function_contents(obj.__func__)\n\n    except AttributeError:\n        try:\n            # Test if obj is a callable object.\n            return _function_contents(obj.__call__.__func__)\n\n        except AttributeError:\n            try:\n                # Test if obj is a code object.\n                return _code_contents(obj)\n\n            except AttributeError:\n                # Test if obj is a function object.\n                return _function_contents(obj)", "response": "Return the signature contents of a callable Python object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _object_contents(obj):\n    try:\n        # Test if obj is a method.\n        return _function_contents(obj.__func__)\n\n    except AttributeError:\n        try:\n            # Test if obj is a callable object.\n            return _function_contents(obj.__call__.__func__)\n\n        except AttributeError:\n            try:\n                # Test if obj is a code object.\n                return _code_contents(obj)\n\n            except AttributeError:\n                try:\n                    # Test if obj is a function object.\n                    return _function_contents(obj)\n\n                except AttributeError as ae:\n                    # Should be a pickle-able Python object.\n                    try:\n                        return _object_instance_content(obj)\n                        # pickling an Action instance or object doesn't yield a stable\n                        # content as instance property may be dumped in different orders\n                        # return pickle.dumps(obj, ACTION_SIGNATURE_PICKLE_PROTOCOL)\n                    except (pickle.PicklingError, TypeError, AttributeError) as ex:\n                        # This is weird, but it seems that nested classes\n                        # are unpickable. The Python docs say it should\n                        # always be a PicklingError, but some Python\n                        # versions seem to return TypeError.  Just do\n                        # the best we can.\n                        return bytearray(repr(obj), 'utf-8')", "response": "Return the signature contents of any Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the signature contents of a Python code object.", "response": "def _code_contents(code, docstring=None):\n    \"\"\"Return the signature contents of a code object.\n\n    By providing direct access to the code object of the\n    function, Python makes this extremely easy.  Hooray!\n\n    Unfortunately, older versions of Python include line\n    number indications in the compiled byte code.  Boo!\n    So we remove the line number byte codes to prevent\n    recompilations from moving a Python function.\n\n    See:\n      - https://docs.python.org/2/library/inspect.html\n      - http://python-reference.readthedocs.io/en/latest/docs/code/index.html\n\n    For info on what each co\\_ variable provides\n\n    The signature is as follows (should be byte/chars):\n    co_argcount, len(co_varnames), len(co_cellvars), len(co_freevars),\n    ( comma separated signature for each object in co_consts ),\n    ( comma separated signature for each object in co_names ),\n    ( The bytecode with line number bytecodes removed from  co_code )\n\n    co_argcount - Returns the number of positional arguments (including arguments with default values).\n    co_varnames - Returns a tuple containing the names of the local variables (starting with the argument names).\n    co_cellvars - Returns a tuple containing the names of local variables that are referenced by nested functions.\n    co_freevars - Returns a tuple containing the names of free variables. (?)\n    co_consts   - Returns a tuple containing the literals used by the bytecode.\n    co_names    - Returns a tuple containing the names used by the bytecode.\n    co_code     - Returns a string representing the sequence of bytecode instructions.\n\n    \"\"\"\n\n    # contents = []\n\n    # The code contents depends on the number of local variables\n    # but not their actual names.\n    contents = bytearray(\"{}, {}\".format(code.co_argcount, len(code.co_varnames)), 'utf-8')\n\n    contents.extend(b\", \")\n    contents.extend(bytearray(str(len(code.co_cellvars)), 'utf-8'))\n    contents.extend(b\", \")\n    contents.extend(bytearray(str(len(code.co_freevars)), 'utf-8'))\n\n    # The code contents depends on any constants accessed by the\n    # function. Note that we have to call _object_contents on each\n    # constants because the code object of nested functions can\n    # show-up among the constants.\n\n    z = [_object_contents(cc) for cc in code.co_consts[1:]]\n    contents.extend(b',(')\n    contents.extend(bytearray(',', 'utf-8').join(z))\n    contents.extend(b')')\n\n    # The code contents depends on the variable names used to\n    # accessed global variable, as changing the variable name changes\n    # the variable actually accessed and therefore changes the\n    # function result.\n    z= [bytearray(_object_contents(cc)) for cc in code.co_names]\n    contents.extend(b',(')\n    contents.extend(bytearray(',','utf-8').join(z))\n    contents.extend(b')')\n\n    # The code contents depends on its actual code!!!\n    contents.extend(b',(')\n    contents.extend(code.co_code)\n    contents.extend(b')')\n\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _function_contents(func):\n\n    contents = [_code_contents(func.__code__, func.__doc__)]\n\n    # The function contents depends on the value of defaults arguments\n    if func.__defaults__:\n\n        function_defaults_contents = [_object_contents(cc) for cc in func.__defaults__]\n\n        defaults = bytearray(b',(')\n        defaults.extend(bytearray(b',').join(function_defaults_contents))\n        defaults.extend(b')')\n\n        contents.append(defaults)\n    else:\n        contents.append(b',()')\n\n    # The function contents depends on the closure captured cell values.\n    closure = func.__closure__ or []\n\n    try:\n        closure_contents = [_object_contents(x.cell_contents) for x in closure]\n    except AttributeError:\n        closure_contents = []\n\n    contents.append(b',(')\n    contents.append(bytearray(b',').join(closure_contents))\n    contents.append(b')')\n\n    retval = bytearray(b'').join(contents)\n    return retval", "response": "Returns the signature contents of a function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _object_instance_content(obj):\n    retval = bytearray()\n\n    if obj is None:\n        return b'N.'\n\n    if isinstance(obj, SCons.Util.BaseStringTypes):\n        return SCons.Util.to_bytes(obj)\n\n    inst_class = obj.__class__\n    inst_class_name = bytearray(obj.__class__.__name__,'utf-8')\n    inst_class_module = bytearray(obj.__class__.__module__,'utf-8')\n    inst_class_hierarchy = bytearray(repr(inspect.getclasstree([obj.__class__,])),'utf-8')\n    # print(\"ICH:%s : %s\"%(inst_class_hierarchy, repr(obj)))\n\n    properties = [(p, getattr(obj, p, \"None\")) for p in dir(obj) if not (p[:2] == '__' or inspect.ismethod(getattr(obj, p)) or inspect.isbuiltin(getattr(obj,p))) ]\n    properties.sort()\n    properties_str = ','.join([\"%s=%s\"%(p[0],p[1]) for p in properties])\n    properties_bytes = bytearray(properties_str,'utf-8')\n\n    methods = [p for p in dir(obj) if inspect.ismethod(getattr(obj, p))]\n    methods.sort()\n\n    method_contents = []\n    for m in methods:\n        # print(\"Method:%s\"%m)\n        v = _function_contents(getattr(obj, m))\n        # print(\"[%s->]V:%s [%s]\"%(m,v,type(v)))\n        method_contents.append(v)\n\n    retval = bytearray(b'{')\n    retval.extend(inst_class_name)\n    retval.extend(b\":\")\n    retval.extend(inst_class_module)\n    retval.extend(b'}[[')\n    retval.extend(inst_class_hierarchy)\n    retval.extend(b']]{{')\n    retval.extend(bytearray(b\",\").join(method_contents))\n    retval.extend(b\"}}{{{\")\n    retval.extend(properties_bytes)\n    retval.extend(b'}}}')\n    return retval", "response": "Returns a byte string representing the object s instance content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _do_create_list_action(act, kw):\n    acts = []\n    for a in act:\n        aa = _do_create_action(a, kw)\n        if aa is not None: acts.append(aa)\n    if not acts:\n        return ListAction([])\n    elif len(acts) == 1:\n        return acts[0]\n    else:\n        return ListAction(acts)", "response": "A factory for list actions. Convert the input list into Actions\n    and then wrap them in a ListAction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _string_from_cmd_list(cmd_list):\n    cl = []\n    for arg in map(str, cmd_list):\n        if ' ' in arg or '\\t' in arg:\n            arg = '\"' + arg + '\"'\n        cl.append(arg)\n    return ' '.join(cl)", "response": "Takes a list of command line arguments and returns a pretty\n    representation for printing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_default_ENV(env):\n    global default_ENV\n    try:\n        return env['ENV']\n    except KeyError:\n        if not default_ENV:\n            import SCons.Environment\n            # This is a hideously expensive way to get a default shell\n            # environment.  What it really should do is run the platform\n            # setup to get the default ENV.  Fortunately, it's incredibly\n            # rare for an Environment not to have a shell environment, so\n            # we're not going to worry about it overmuch.\n            default_ENV = SCons.Environment.Environment()['ENV']\n        return default_ENV", "response": "Get the default environment for a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndoes common setup for a subprocess.Popen() call This function is still in draft mode. We're going to need something like it in the long run as more and more places use subprocess, but I'm sure it'll have to be tweaked to get the full desired functionality. one special arg (so far?), 'error', to tell what to do with exceptions.", "response": "def _subproc(scons_env, cmd, error = 'ignore', **kw):\n    \"\"\"Do common setup for a subprocess.Popen() call\n\n    This function is still in draft mode.  We're going to need something like\n    it in the long run as more and more places use subprocess, but I'm sure\n    it'll have to be tweaked to get the full desired functionality.\n    one special arg (so far?), 'error', to tell what to do with exceptions.\n    \"\"\"\n    # allow std{in,out,err} to be \"'devnull'\"\n    io = kw.get('stdin')\n    if is_String(io) and io == 'devnull':\n        kw['stdin'] = open(os.devnull)\n    io = kw.get('stdout')\n    if is_String(io) and io == 'devnull':\n        kw['stdout'] = open(os.devnull, 'w')\n    io = kw.get('stderr')\n    if is_String(io) and io == 'devnull':\n        kw['stderr'] = open(os.devnull, 'w')\n\n    # Figure out what shell environment to use\n    ENV = kw.get('env', None)\n    if ENV is None: ENV = get_default_ENV(scons_env)\n\n    # Ensure that the ENV values are all strings:\n    new_env = {}\n    for key, value in ENV.items():\n        if is_List(value):\n            # If the value is a list, then we assume it is a path list,\n            # because that's a pretty common list-like value to stick\n            # in an environment variable:\n            value = SCons.Util.flatten_sequence(value)\n            new_env[key] = os.pathsep.join(map(str, value))\n        else:\n            # It's either a string or something else.  If it's a string,\n            # we still want to call str() because it might be a *Unicode*\n            # string, which makes subprocess.Popen() gag.  If it isn't a\n            # string or a list, then we just coerce it to a string, which\n            # is the proper way to handle Dir and File instances and will\n            # produce something reasonable for just about everything else:\n            new_env[key] = str(value)\n    kw['env'] = new_env\n\n    try:\n        return subprocess.Popen(cmd, **kw)\n    except EnvironmentError as e:\n        if error == 'raise': raise\n        # return a dummy Popen instance that only returns error\n        class dummyPopen(object):\n            def __init__(self, e): self.exception = e\n            def communicate(self, input=None): return ('', '')\n            def wait(self): return -self.exception.errno\n            stdin = None\n            class f(object):\n                def read(self): return ''\n                def readline(self): return ''\n                def __iter__(self): return iter(())\n            stdout = stderr = f()\n        return dummyPopen(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_cmd_line(self, s, target, source, env):\n        try:\n            sys.stdout.write(s + u\"\\n\")\n        except UnicodeDecodeError:\n            sys.stdout.write(s + \"\\n\")", "response": "Print a command line to sys. stdout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a command action.", "response": "def execute(self, target, source, env, executor=None):\n        \"\"\"Execute a command action.\n\n        This will handle lists of commands as well as individual commands,\n        because construction variable substitution may turn a single\n        \"command\" into a list.  This means that this class can actually\n        handle lists of commands, even though that's not how we use it\n        externally.\n        \"\"\"\n        escape_list = SCons.Subst.escape_list\n        flatten_sequence = SCons.Util.flatten_sequence\n\n        try:\n            shell = env['SHELL']\n        except KeyError:\n            raise SCons.Errors.UserError('Missing SHELL construction variable.')\n\n        try:\n            spawn = env['SPAWN']\n        except KeyError:\n            raise SCons.Errors.UserError('Missing SPAWN construction variable.')\n        else:\n            if is_String(spawn):\n                spawn = env.subst(spawn, raw=1, conv=lambda x: x)\n\n        escape = env.get('ESCAPE', lambda x: x)\n\n        ENV = get_default_ENV(env)\n\n        # Ensure that the ENV values are all strings:\n        for key, value in ENV.items():\n            if not is_String(value):\n                if is_List(value):\n                    # If the value is a list, then we assume it is a\n                    # path list, because that's a pretty common list-like\n                    # value to stick in an environment variable:\n                    value = flatten_sequence(value)\n                    ENV[key] = os.pathsep.join(map(str, value))\n                else:\n                    # If it isn't a string or a list, then we just coerce\n                    # it to a string, which is the proper way to handle\n                    # Dir and File instances and will produce something\n                    # reasonable for just about everything else:\n                    ENV[key] = str(value)\n\n        if executor:\n            target = executor.get_all_targets()\n            source = executor.get_all_sources()\n        cmd_list, ignore, silent = self.process(target, list(map(rfile, source)), env, executor)\n\n        # Use len() to filter out any \"command\" that's zero-length.\n        for cmd_line in filter(len, cmd_list):\n            # Escape the command line for the interpreter we are using.\n            cmd_line = escape_list(cmd_line, escape)\n            result = spawn(shell, escape, cmd_line[0], cmd_line, ENV)\n            if not ignore and result:\n                msg = \"Error %s\" % result\n                return SCons.Errors.BuildError(errstr=msg,\n                                               status=result,\n                                               action=self,\n                                               command=cmd_line)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_presig(self, target, source, env, executor=None):\n        from SCons.Subst import SUBST_SIG\n        cmd = self.cmd_list\n        if is_List(cmd):\n            cmd = ' '.join(map(str, cmd))\n        else:\n            cmd = str(cmd)\n        if executor:\n            return env.subst_target_source(cmd, SUBST_SIG, executor=executor)\n        else:\n            return env.subst_target_source(cmd, SUBST_SIG, target, source)", "response": "Return the signature contents of this action s command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the signature contents of this action s command line.", "response": "def get_presig(self, target, source, env, executor=None):\n        \"\"\"Return the signature contents of this action's command line.\n\n        This strips $(-$) and everything in between the string,\n        since those parts don't affect signatures.\n        \"\"\"\n        return self._generate(target, source, env, 1, executor).get_presig(target, source, env)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_presig(self, target, source, env):\n        try:\n            return self.gc(target, source, env)\n        except AttributeError:\n            return self.funccontents", "response": "Return the signature contents of this callable action."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the signature contents of this action list.", "response": "def get_presig(self, target, source, env):\n        \"\"\"Return the signature contents of this action list.\n\n        Simple concatenation of the signatures of the elements.\n        \"\"\"\n        return b\"\".join([bytes(x.get_contents(target, source, env)) for x in self.list])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds Builders and construction variables for ar to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for ar to an Environment.\"\"\"\n    SCons.Tool.createStaticLibBuilder(env)\n    \n    if env.Detect('CC'):\n        env['AR']          = 'CC'\n        env['ARFLAGS']     = SCons.Util.CLVar('-ar')\n        env['ARCOM']       = '$AR $ARFLAGS -o $TARGET $SOURCES'\n    else:\n        env['AR']          = 'ar'\n        env['ARFLAGS']     = SCons.Util.CLVar('r')\n        env['ARCOM']       = '$AR $ARFLAGS $TARGET $SOURCES'\n        \n    env['SHLINK']      = '$LINK'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -shared')\n    env['SHLINKCOM']   = '$SHLINK $SHLINKFLAGS -o $TARGET $SOURCES $_LIBDIRFLAGS $_LIBFLAGS'\n    env['LIBPREFIX']   = 'lib'\n    env['LIBSUFFIX']   = '.a'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnotifying updates on a service to anyone who cares.", "response": "async def _notify_update(self, name, change_type, change_info=None, directed_client=None):\n        \"\"\"Notify updates on a service to anyone who cares.\"\"\"\n\n        for monitor in self._monitors:\n            try:\n                result = monitor(name, change_type, change_info, directed_client=directed_client)\n                if inspect.isawaitable(result):\n                    await result\n            except Exception:\n                # We can't allow any exceptions in a monitor routine to break the server.\n                self._logger.warning(\"Error calling monitor with update %s\", name, exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def update_state(self, short_name, state):\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Service name is unknown\", short_name=short_name)\n\n        if state not in states.KNOWN_STATES:\n            raise ArgumentError(\"Invalid service state\", state=state)\n\n        serv = self.services[short_name]['state']\n\n        if serv.state == state:\n            return\n\n        update = {}\n        update['old_status'] = serv.state\n        update['new_status'] = state\n        update['new_status_string'] = states.KNOWN_STATES[state]\n\n        serv.state = state\n        await self._notify_update(short_name, 'state_change', update)", "response": "Updates the state of a service."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_service(self, name, long_name, preregistered=False, notify=True):\n\n        if name in self.services:\n            raise ArgumentError(\"Could not add service because the long_name is taken\", long_name=long_name)\n\n        serv_state = states.ServiceState(name, long_name, preregistered)\n\n        service = {\n            'state': serv_state,\n            'heartbeat_threshold': 600\n        }\n\n        self.services[name] = service\n\n        if notify:\n            return self._notify_update(name, 'new_service', self.service_info(name))\n\n        return None", "response": "Add a service to the list of tracked services."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the long_name and preregistered info of a service.", "response": "def service_info(self, short_name):\n        \"\"\"Get static information about a service.\n\n        Args:\n            short_name (string): The short name of the service to query\n\n        Returns:\n            dict: A dictionary with the long_name and preregistered info\n                on this service.\n        \"\"\"\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        info = {}\n        info['short_name'] = short_name\n        info['long_name'] = self.services[short_name]['state'].long_name\n        info['preregistered'] = self.services[short_name]['state'].preregistered\n\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of ServiceMessages stored for a service.", "response": "def service_messages(self, short_name):\n        \"\"\"Get the messages stored for a service.\n\n        Args:\n            short_name (string): The short name of the service to get messages for\n\n        Returns:\n            list(ServiceMessage): A list of the ServiceMessages stored for this service\n        \"\"\"\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        return list(self.services[short_name]['state'].messages)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the headline stored for a service.", "response": "def service_headline(self, short_name):\n        \"\"\"Get the headline stored for a service.\n\n        Args:\n            short_name (string): The short name of the service to get messages for\n\n        Returns:\n            ServiceMessage: the headline or None if there is no headline\n        \"\"\"\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        return self.services[short_name]['state'].headline"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the current status of a service.", "response": "def service_status(self, short_name):\n        \"\"\"Get the current status of a service.\n\n        Returns information about the service such as the length since the last\n        heartbeat, any status messages that have been posted about the service\n        and whether the heartbeat should be considered out of the ordinary.\n\n        Args:\n            short_name (string): The short name of the service to query\n\n        Returns:\n            dict: A dictionary with the status of the service\n        \"\"\"\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        info = {}\n\n        service = self.services[short_name]['state']\n\n        info['heartbeat_age'] = monotonic() - service.last_heartbeat\n        info['numeric_status'] = service.state\n        info['string_status'] = service.string_state\n\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nposts a message for a service.", "response": "async def send_message(self, name, level, message):\n        \"\"\"Post a message for a service.\n\n        Args:\n            name (string): The short name of the service to query\n            level (int): The level of the message (info, warning, error)\n            message (string): The message contents\n        \"\"\"\n\n        if name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=name)\n\n        msg = self.services[name]['state'].post_message(level, message)\n        await self._notify_update(name, 'new_message', msg.to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the sticky headline for a service.", "response": "async def set_headline(self, name, level, message):\n        \"\"\"Set the sticky headline for a service.\n\n        Args:\n            name (string): The short name of the service to query\n            level (int): The level of the message (info, warning, error)\n            message (string): The message contents\n        \"\"\"\n\n        if name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=name)\n\n        self.services[name]['state'].set_headline(level, message)\n\n        headline = self.services[name]['state'].headline.to_dict()\n        await self._notify_update(name, 'new_headline', headline)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def send_heartbeat(self, short_name):\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        self.services[short_name]['state'].heartbeat()\n        await self._notify_update(short_name, 'heartbeat')", "response": "Post a heartbeat for a service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a client id that handlers commands for a service.", "response": "def set_agent(self, short_name, client_id):\n        \"\"\"Register a client id that handlers commands for a service.\n\n        Args:\n            short_name (str): The name of the service to set an agent\n                for.\n            client_id (str): A globally unique id for the client that\n                should receive commands for this service.\n        \"\"\"\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        self.agents[short_name] = client_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_agent(self, short_name, client_id):\n\n        if short_name not in self.services:\n            raise ArgumentError(\"Unknown service name\", short_name=short_name)\n\n        if short_name not in self.agents:\n            raise ArgumentError(\"No agent registered for service\", short_name=short_name)\n\n        if client_id != self.agents[short_name]:\n            raise ArgumentError(\"Client was not registered for service\", short_name=short_name,\n                                client_id=client_id, current_client=self.agents[short_name])\n\n        del self.agents[short_name]", "response": "Remove an agent from being the command handler for a service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def send_rpc_command(self, short_name, rpc_id, payload, sender_client, timeout=1.0):\n\n\n        rpc_tag = str(uuid.uuid4())\n\n        self.rpc_results.declare(rpc_tag)\n\n        if short_name in self.services and short_name in self.agents:\n            agent_tag = self.agents[short_name]\n            rpc_message = {\n                'rpc_id': rpc_id,\n                'payload': payload,\n                'response_uuid': rpc_tag\n            }\n\n            self.in_flight_rpcs[rpc_tag] = InFlightRPC(sender_client, short_name,\n                                                       monotonic(), timeout)\n            await self._notify_update(short_name, 'rpc_command', rpc_message, directed_client=agent_tag)\n        else:\n            response = dict(result='service_not_found', response=b'')\n            self.rpc_results.set(rpc_tag, response)\n\n        return rpc_tag", "response": "Send an RPC to a service using its registered agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_rpc_response(self, rpc_tag, result, response):\n\n        if rpc_tag not in self.in_flight_rpcs:\n            raise ArgumentError(\"In flight RPC could not be found, it may have timed out\", rpc_tag=rpc_tag)\n\n        del self.in_flight_rpcs[rpc_tag]\n\n        response_message = {\n            'response': response,\n            'result': result\n        }\n\n        try:\n            self.rpc_results.set(rpc_tag, response_message)\n        except KeyError:\n            self._logger.warning(\"RPC response came but no one was waiting: response=%s\", response)", "response": "Send a response to an RPC."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if any RPC has expired and remove it from the in flight list.", "response": "def periodic_service_rpcs(self):\n        \"\"\"Check if any RPC has expired and remove it from the in flight list.\n\n        This function should be called periodically to expire any RPCs that never complete.\n        \"\"\"\n\n        to_remove = []\n\n        now = monotonic()\n        for rpc_tag, rpc in self.in_flight_rpcs.items():\n            expiry = rpc.sent_timestamp + rpc.timeout\n            if now > expiry:\n                to_remove.append(rpc_tag)\n\n        for tag in to_remove:\n            del self.in_flight_rpcs[tag]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a key help default for the package list option.", "response": "def PackageVariable(key, help, default, searchfunc=None):\n    # NB: searchfunc is currently undocumented and unsupported\n    \"\"\"\n    The input parameters describe a 'package list' option, thus they\n    are returned with the correct converter and validator appended. The\n    result is usable for input to opts.Add() .\n\n    A 'package list' option may either be 'all', 'none' or a list of\n    package names (separated by space).\n    \"\"\"\n    help = '\\n    '.join(\n        (help, '( yes | no | /path/to/%s )' % key))\n    return (key, help, default,\n            lambda k, v, e: _validator(k,v,e,searchfunc),\n            _converter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef settings_directory():\n\n    system = platform.system()\n\n    basedir = None\n\n    if system == 'Windows':\n        if 'APPDATA' in os.environ:\n            basedir = os.environ['APPDATA']\n\n    # If we're not on Windows assume we're on some\n    # kind of posix system or Mac, where the appropriate place would be\n    # ~/.config\n    if basedir is None:\n        basedir = os.path.expanduser('~')\n        basedir = os.path.join(basedir, '.config')\n\n    settings_dir = os.path.abspath(os.path.join(basedir, 'IOTile-Core'))\n    return settings_dir", "response": "Find a per user settings directory that is appropriate for each\n    type of system that we are installed on."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    global GhostscriptAction\n    # The following try-except block enables us to use the Tool\n    # in standalone mode (without the accompanying pdf.py),\n    # whenever we need an explicit call of gs via the Gs()\n    # Builder ...\n    try:\n        if GhostscriptAction is None:\n            GhostscriptAction = SCons.Action.Action('$GSCOM', '$GSCOMSTR')\n    \n        from SCons.Tool import pdf\n        pdf.generate(env)\n    \n        bld = env['BUILDERS']['PDF']\n        bld.add_action('.ps', GhostscriptAction)\n    except ImportError as e:\n        pass\n\n    gsbuilder = SCons.Builder.Builder(action = SCons.Action.Action('$GSCOM', '$GSCOMSTR'))\n    env['BUILDERS']['Gs'] = gsbuilder\n    \n    env['GS']      = gs\n    env['GSFLAGS'] = SCons.Util.CLVar('-dNOPAUSE -dBATCH -sDEVICE=pdfwrite')\n    env['GSCOM']   = '$GS $GSFLAGS -sOutputFile=$TARGET $SOURCES'", "response": "Add Builders and construction variables for Ghostscript to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resource_path(relative_path=None, expect=None):\n\n    if expect not in (None, 'file', 'folder'):\n        raise ArgumentError(\"Invalid expect parameter, must be None, 'file' or 'folder'\",\n                            expect=expect)\n\n    this_dir = os.path.dirname(__file__)\n    _resource_path = os.path.join(this_dir, '..', 'config')\n\n    if relative_path is not None:\n        path = os.path.normpath(relative_path)\n        _resource_path = os.path.join(_resource_path, path)\n\n    if expect == 'file' and not os.path.isfile(_resource_path):\n        raise DataError(\"Expected resource %s to be a file and it wasn't\" % _resource_path)\n    elif expect == 'folder' and not os.path.isdir(_resource_path):\n        raise DataError(\"Expected resource %s to be a folder and it wasn't\" % _resource_path)\n\n    return os.path.abspath(_resource_path)", "response": "Return the absolute path to a resource in iotile - build."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlaunching any background tasks associated with this subsystem.", "response": "async def initialize(self, timeout=2.0):\n        \"\"\"Launch any background tasks associated with this subsystem.\n\n        This method will synchronously await self.initialized() which makes\n        sure that the background tasks start up correctly.\n        \"\"\"\n\n        if self.initialized.is_set():\n            raise InternalError(\"initialize called when already initialized\")\n\n        self._emulator.add_task(8, self._reset_vector())\n\n        await asyncio.wait_for(self.initialized.wait(), timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_registry_type(folder=None):\n\n    folder = _registry_folder(folder)\n\n    default_file = os.path.join(folder, 'registry_type.txt')\n\n    try:\n        with open(default_file, \"r\") as infile:\n            data = infile.read()\n            data = data.strip()\n\n            ComponentRegistry.SetBackingStore(data)\n    except IOError:\n        pass", "response": "Check if the user has placed a default registry type file and update the ComponentRegistry class parameters with the default backing store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring that the given module is loaded as a submodule.", "response": "def _ensure_package_loaded(path, component):\n    \"\"\"Ensure that the given module is loaded as a submodule.\n\n    Returns:\n        str: The name that the module should be imported as.\n    \"\"\"\n\n    logger = logging.getLogger(__name__)\n\n    packages = component.find_products('support_package')\n    if len(packages) == 0:\n        return None\n    elif len(packages) > 1:\n        raise ExternalError(\"Component had multiple products declared as 'support_package\", products=packages)\n\n    if len(path) > 2 and ':' in path[2:]:  # Don't flag windows C: type paths\n        path, _, _ = path.rpartition(\":\")\n\n    package_base = packages[0]\n    relative_path = os.path.normpath(os.path.relpath(path, start=package_base))\n    if relative_path.startswith('..'):\n        raise ExternalError(\"Component had python product output of support_package\",\n                            package=package_base, product=path, relative_path=relative_path)\n\n    if not relative_path.endswith('.py'):\n        raise ExternalError(\"Python product did not end with .py\", path=path)\n\n    relative_path = relative_path[:-3]\n    if os.pathsep in relative_path:\n        raise ExternalError(\"Python support wheels with multiple subpackages not yet supported\",\n                            relative_path=relative_path)\n\n    support_distro = component.support_distribution\n    if support_distro not in sys.modules:\n        logger.debug(\"Creating dynamic support wheel package: %s\", support_distro)\n        file, path, desc = imp.find_module(os.path.basename(package_base), [os.path.dirname(package_base)])\n        imp.load_module(support_distro, file, path, desc)\n\n    return \"{}.{}\".format(support_distro, relative_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _try_load_module(path, import_name=None):\n\n    logger = logging.getLogger(__name__)\n\n    obj_name = None\n    if len(path) > 2 and ':' in path[2:]:  # Don't flag windows C: type paths\n        path, _, obj_name = path.rpartition(\":\")\n\n    folder, basename = os.path.split(path)\n    if folder == '':\n        folder = './'\n\n    if basename == '' or not os.path.exists(path):\n        raise ArgumentError(\"Could not find python module to load extension\", path=path)\n\n    basename, ext = os.path.splitext(basename)\n    if ext not in (\".py\", \".pyc\", \"\"):\n        raise ArgumentError(\"Attempted to load module is not a python package or module (.py or .pyc)\", path=path)\n\n    if import_name is None:\n        import_name = basename\n    else:\n        logger.debug(\"Importing module as subpackage: %s\", import_name)\n\n    try:\n        fileobj = None\n        fileobj, pathname, description = imp.find_module(basename, [folder])\n\n        # Don't load modules twice\n        if basename in sys.modules:\n            mod = sys.modules[basename]\n        else:\n            mod = imp.load_module(import_name, fileobj, pathname, description)\n\n        if obj_name is not None:\n            if obj_name not in mod.__dict__:\n                raise ArgumentError(\"Cannot find named object '%s' inside module '%s'\" % (obj_name, basename), path=path)\n\n            mod = mod.__dict__[obj_name]\n\n        return basename, mod\n    finally:\n        if fileobj is not None:\n            fileobj.close()", "response": "Try to load a python module by path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frozen(self):\n\n        frozen_path = os.path.join(_registry_folder(), 'frozen_extensions.json')\n        return os.path.isfile(frozen_path)", "response": "Return whether we have a cached list of all installed entry_points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kvstore(self):\n\n        if self._kvstore is None:\n            self._kvstore = self.BackingType(self.BackingFileName, respect_venv=True)\n\n        return self._kvstore", "response": "Lazily load the underlying key - value store backing this registry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plugins(self):\n\n        if self._plugins is None:\n            self._plugins = {}\n\n            for _, plugin in self.load_extensions('iotile.plugin'):\n                links = plugin()\n                for name, value in links:\n                    self._plugins[name] = value\n\n        return self._plugins", "response": "Lazy load iotile plugins only on demand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister an extension. Args: group (str): The type of the extension name (str): A name for the extension extension (str or class): If this is a string, then it will be interpreted as a path to import and load. Otherwise it will be treated as the extension object itself.", "response": "def register_extension(self, group, name, extension):\n        \"\"\"Register an extension.\n\n        Args:\n            group (str): The type of the extension\n            name (str): A name for the extension\n            extension (str or class): If this is a string, then it will be\n                interpreted as a path to import and load.  Otherwise it\n                will be treated as the extension object itself.\n        \"\"\"\n\n        if isinstance(extension, str):\n            name, extension = self.load_extension(extension)[0]\n\n        if group not in self._registered_extensions:\n            self._registered_extensions[group] = []\n\n        self._registered_extensions[group].append((name, extension))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear all previously registered extensions.", "response": "def clear_extensions(self, group=None):\n        \"\"\"Clear all previously registered extensions.\"\"\"\n\n        if group is None:\n            ComponentRegistry._registered_extensions = {}\n            return\n\n        if group in self._registered_extensions:\n            self._registered_extensions[group] = []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef freeze_extensions(self):\n\n        output_path = os.path.join(_registry_folder(), 'frozen_extensions.json')\n\n        with open(output_path, \"w\") as outfile:\n            json.dump(self._dump_extensions(), outfile)", "response": "Freeze the set of extensions into a single file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unfreeze_extensions(self):\n\n        output_path = os.path.join(_registry_folder(), 'frozen_extensions.json')\n        if not os.path.isfile(output_path):\n            raise ExternalError(\"There is no frozen extension list\")\n\n        os.remove(output_path)\n        ComponentRegistry._frozen_extensions = None", "response": "Remove a previously frozen list of extensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_extension(self, path, name_filter=None, class_filter=None, unique=False, component=None):\n\n        import_name = None\n        if component is not None:\n            import_name = _ensure_package_loaded(path, component)\n\n        name, ext = _try_load_module(path, import_name=import_name)\n\n        if name_filter is not None and name != name_filter:\n            return []\n\n        found = [(name, x) for x in self._filter_subclasses(ext, class_filter)]\n        found = [(name, x) for name, x in found if self._filter_nonextensions(x)]\n\n        if not unique:\n            return found\n\n        if len(found) > 1:\n            raise ArgumentError(\"Extension %s should have had exactly one instance of class %s, found %d\"\n                                % (path, class_filter.__name__, len(found)), classes=found)\n        elif len(found) == 0:\n            raise ArgumentError(\"Extension %s had no instances of class %s\" % (path, class_filter.__name__))\n\n        return found[0]", "response": "Loads a single python module extension."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _filter_nonextensions(cls, obj):\n\n        # Not all objects have __dict__ attributes.  For example, tuples don't.\n        # and tuples are used in iotile.build for some entry points.\n        if hasattr(obj, '__dict__') and obj.__dict__.get('__NO_EXTENSION__', False) is True:\n            return False\n\n        return True", "response": "Remove all classes marked as not extensions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SetBackingStore(cls, backing):\n\n        if backing not in ['json', 'sqlite', 'memory']:\n            raise ArgumentError(\"Unknown backing store type that is not json or sqlite\", backing=backing)\n\n        if backing == 'json':\n            cls.BackingType = JSONKVStore\n            cls.BackingFileName = 'component_registry.json'\n        elif backing == 'memory':\n            cls.BackingType = InMemoryKVStore\n            cls.BackingFileName = None\n        else:\n            cls.BackingType = SQLiteKVStore\n            cls.BackingFileName = 'component_registry.db'", "response": "Sets the global backing type used by the ComponentRegistry from this point forward\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_component(self, component, temporary=False):\n\n        tile = IOTile(component)\n        value = os.path.normpath(os.path.abspath(component))\n\n        if temporary is True:\n            self._component_overlays[tile.name] = value\n        else:\n            self.kvstore.set(tile.name, value)", "response": "Register a component with ComponentRegistry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all of the plugins that have been registered for the iotile program on this computer", "response": "def list_plugins(self):\n        \"\"\"\n        List all of the plugins that have been registerd for the iotile program on this computer\n        \"\"\"\n\n        vals = self.plugins.items()\n\n        return {x: y for x, y in vals}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_components(self):\n\n        ComponentRegistry._component_overlays = {}\n\n        for key in self.list_components():\n            self.remove_component(key)", "response": "Clear all of the registered components"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_components(self):\n\n        overlays = list(self._component_overlays)\n        items = self.kvstore.get_all()\n\n        return overlays + [x[0] for x in items if not x[0].startswith('config:')]", "response": "List all of the registered component names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iter_components(self):\n\n        names = self.list_components()\n\n        for name in names:\n            yield self.get_component(name)", "response": "Iterate over all defined components yielding IOTile objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_config(self):\n        items = self.kvstore.get_all()\n        return [\"{0}={1}\".format(x[0][len('config:'):], x[1])\n                for x in items if x[0].startswith('config:')]", "response": "List all of the configuration variables"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_config(self, key, value):\n\n        keyname = \"config:\" + key\n\n        self.kvstore.set(keyname, value)", "response": "Set a persistent config key to a value stored in the registry\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of a persistent config key from the registry", "response": "def get_config(self, key, default=MISSING):\n        \"\"\"Get the value of a persistent config key from the registry\n\n        If no default is specified and the key is not found ArgumentError is raised.\n\n        Args:\n            key (string): The key name to fetch\n            default (string): an optional value to be returned if key cannot be found\n\n        Returns:\n            string: the key's value\n        \"\"\"\n\n        keyname = \"config:\" + key\n\n        try:\n            return self.kvstore.get(keyname)\n        except KeyError:\n            if default is MISSING:\n                raise ArgumentError(\"No config value found for key\", key=key)\n\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute_action_list(obj, target, kw):\n    env = obj.get_build_env()\n    kw = obj.get_kw(kw)\n    status = 0\n    for act in obj.get_action_list():\n        args = ([], [], env)\n        status = act(*args, **kw)\n        if isinstance(status, SCons.Errors.BuildError):\n            status.executor = obj\n            raise status\n        elif status:\n            msg = \"Error %s\" % status\n            raise SCons.Errors.BuildError(\n                errstr=msg, \n                node=obj.batches[0].targets,\n                executor=obj, \n                action=act)\n    return status", "response": "Actually execute the action list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all targets for all batches of this Executor.", "response": "def get_all_targets(self):\n        \"\"\"Returns all targets for all batches of this Executor.\"\"\"\n        result = []\n        for batch in self.batches:\n            result.extend(batch.targets)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all sources for all batches of this Executor.", "response": "def get_all_sources(self):\n        \"\"\"Returns all sources for all batches of this Executor.\"\"\"\n        result = []\n        for batch in self.batches:\n            result.extend(batch.sources)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all unique children for all batches", "response": "def get_all_children(self):\n        \"\"\"Returns all unique children (dependencies) for all batches\n        of this Executor.\n\n        The Taskmaster can recognize when it's already evaluated a\n        Node, so we don't have to make this list unique for its intended\n        canonical use case, but we expect there to be a lot of redundancy\n        (long lists of batched .cc files #including the same .h files\n        over and over), so removing the duplicates once up front should\n        save the Taskmaster a lot of work.\n        \"\"\"\n        result = SCons.Util.UniqueList([])\n        for target in self.get_all_targets():\n            result.extend(target.children())\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_prerequisites(self):\n        result = SCons.Util.UniqueList([])\n        for target in self.get_all_targets():\n            if target.prerequisites is not None:\n                result.extend(target.prerequisites)\n        return result", "response": "Returns all unique prerequisites for all batches\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all side effects for all batches of this Action.", "response": "def get_action_side_effects(self):\n\n        \"\"\"Returns all side effects for all batches of this\n        Executor used by the underlying Action.\n        \"\"\"\n        result = SCons.Util.UniqueList([])\n        for target in self.get_action_targets():\n            result.extend(target.side_effects)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching or create the appropriate build Environment for this Executor.", "response": "def get_build_env(self):\n        \"\"\"Fetch or create the appropriate build Environment\n        for this Executor.\n        \"\"\"\n        try:\n            return self._memo['get_build_env']\n        except KeyError:\n            pass\n\n        # Create the build environment instance with appropriate\n        # overrides.  These get evaluated against the current\n        # environment's construction variables so that users can\n        # add to existing values by referencing the variable in\n        # the expansion.\n        overrides = {}\n        for odict in self.overridelist:\n            overrides.update(odict)\n\n        import SCons.Defaults\n        env = self.env or SCons.Defaults.DefaultEnvironment()\n        build_env = env.Override(overrides)\n\n        self._memo['get_build_env'] = build_env\n\n        return build_env"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches the scanner path for this executor s targets and sources.", "response": "def get_build_scanner_path(self, scanner):\n        \"\"\"Fetch the scanner path for this executor's targets and sources.\n        \"\"\"\n        env = self.get_build_env()\n        try:\n            cwd = self.batches[0].targets[0].cwd\n        except (IndexError, AttributeError):\n            cwd = None\n        return scanner.path(env, cwd,\n                            self.get_all_targets(),\n                            self.get_all_sources())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding source files to this Executor s list.", "response": "def add_sources(self, sources):\n        \"\"\"Add source files to this Executor's list.  This is necessary\n        for \"multi\" Builders that can be called repeatedly to build up\n        a source file list for a given target.\"\"\"\n        # TODO(batch):  extend to multiple batches\n        assert (len(self.batches) == 1)\n        # TODO(batch):  remove duplicates?\n        sources = [x for x in sources if x not in self.batches[0].sources]\n        self.batches[0].sources.extend(sources)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_batch(self, targets, sources):\n        self.batches.append(Batch(targets, sources))", "response": "Add a batch to this Executor s list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing for building the target files.", "response": "def prepare(self):\n        \"\"\"\n        Preparatory checks for whether this Executor can go ahead\n        and (try to) build its targets.\n        \"\"\"\n        for s in self.get_all_sources():\n            if s.missing():\n                msg = \"Source `%s' not found, needed by target `%s'.\"\n                raise SCons.Errors.StopError(msg % (s, self.batches[0].targets[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_contents(self):\n        try:\n            return self._memo['get_contents']\n        except KeyError:\n            pass\n        env = self.get_build_env()\n\n        action_list = self.get_action_list()\n        all_targets = self.get_all_targets()\n        all_sources = self.get_all_sources()\n\n        result = bytearray(\"\",'utf-8').join([action.get_contents(all_targets,\n                                                                 all_sources,\n                                                                 env)\n                                             for action in action_list])\n\n        self._memo['get_contents'] = result\n        return result", "response": "Fetch the signature contents."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan(self, scanner, node_list):\n        env = self.get_build_env()\n        path = self.get_build_scanner_path\n        kw = self.get_kw()\n\n        # TODO(batch):  scan by batches)\n        deps = []\n\n        for node in node_list:\n            node.disambiguate()\n            deps.extend(node.get_implicit_deps(env, scanner, path, kw))\n\n        deps.extend(self.get_implicit_deps())\n\n        for tgt in self.get_all_targets():\n            tgt.add_to_implicit(deps)", "response": "Scan a list of files for\n        implicit dependencies and update all of the targets with them."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_implicit_deps(self):\n        result = []\n        build_env = self.get_build_env()\n        for act in self.get_action_list():\n            deps = act.get_implicit_deps(self.get_all_targets(),\n                                         self.get_all_sources(),\n                                         build_env)\n            result.extend(deps)\n        return result", "response": "Return the executor s implicit dependencies i. e. the nodes of\n        the commands to be executed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode this record into binary suitable for embedded into an update script.", "response": "def encode(self):\n        \"\"\"Encode this record into binary, suitable for embedded into an update script.\n\n        This function just adds the required record header and delegates all\n        work to the subclass implementation of encode_contents().\n\n        Returns:\n            bytearary: The binary version of the record that could be parsed via\n                a call to UpdateRecord.FromBinary()\n        \"\"\"\n\n        contents = self.encode_contents()\n        record_type = self.MatchType()\n\n        header = struct.pack(\"<LB3x\", len(contents) + UpdateRecord.HEADER_LENGTH, record_type)\n\n        return bytearray(header) + contents"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all registered iotile. update_record plugins.", "response": "def LoadPlugins(cls):\n        \"\"\"Load all registered iotile.update_record plugins.\"\"\"\n\n        if cls.PLUGINS_LOADED:\n            return\n\n        reg = ComponentRegistry()\n        for _, record in reg.load_extensions('iotile.update_record'):\n            cls.RegisterRecordType(record)\n\n        cls.PLUGINS_LOADED = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RegisterRecordType(cls, record_class):\n\n        record_type = record_class.MatchType()\n        if record_type not in UpdateRecord.KNOWN_CLASSES:\n            UpdateRecord.KNOWN_CLASSES[record_type] = []\n\n        UpdateRecord.KNOWN_CLASSES[record_type].append(record_class)", "response": "Registers a known record type in KNOWN_CLASSES."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FromBinary(cls, record_data, record_count=1):\n\n        # Make sure any external record types are registered\n        cls.LoadPlugins()\n\n        if len(record_data) < UpdateRecord.HEADER_LENGTH:\n            raise ArgumentError(\"Record data is too short to contain a record header\",\n                                length=len(record_data), header_length=UpdateRecord.HEADER_LENGTH)\n\n        total_length, record_type = struct.unpack_from(\"<LB3x\", record_data)\n\n        if record_count == 1 and len(record_data) != total_length:\n            raise ArgumentError(\"Record data is corrupt, embedded length does not agree with actual length\",\n                                length=len(record_data), embedded_length=total_length)\n\n        record_classes = UpdateRecord.KNOWN_CLASSES.get(record_type, [])\n        if len(record_classes) == 0:\n            raise DataError(\"No matching record type found for record\", record_type=record_type,\n                            known_types=[x for x in UpdateRecord.KNOWN_CLASSES])\n\n        best_match = MatchQuality.NoMatch\n        matching_class = None\n\n        for record_class in record_classes:\n            match_data = record_data[UpdateRecord.HEADER_LENGTH:]\n\n            if record_count > 1:\n                match_data = record_data\n\n            quality = record_class.MatchQuality(match_data, record_count)\n\n            if quality > best_match:\n                best_match = quality\n                matching_class = record_class\n\n        if best_match == MatchQuality.DeferMatch:\n            raise DeferMatching(matching_class)\n        elif best_match == MatchQuality.PartialMatch:\n            raise DeferMatching(matching_class, matching_class.FromBinary(match_data, record_count))\n\n        if matching_class is None:\n            raise DataError(\"Record type found but no specific class reported a match\",\n                            record_type=record_type, considered_classes=record_classes)\n\n        return matching_class.FromBinary(match_data, record_count)", "response": "Create an UpdateRecord subclass from binary record data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _setup(self):\n\n        # Create a root system ticks and user configurable ticks\n        systick = self.allocator.allocate_stream(DataStream.CounterType, attach=True)\n        fasttick = self.allocator.allocate_stream(DataStream.CounterType, attach=True)\n        user1tick = self.allocator.allocate_stream(DataStream.CounterType, attach=True)\n        user2tick = self.allocator.allocate_stream(DataStream.CounterType, attach=True)\n\n        self.sensor_graph.add_node(\"({} always) => {} using copy_all_a\".format(system_tick, systick))\n        self.sensor_graph.add_node(\"({} always) => {} using copy_all_a\".format(fast_tick, fasttick))\n        self.sensor_graph.add_config(SlotIdentifier.FromString('controller'), config_fast_tick_secs, 'uint32_t', 1)\n\n        self.sensor_graph.add_node(\"({} always) => {} using copy_all_a\".format(tick_1, user1tick))\n        self.sensor_graph.add_node(\"({} always) => {} using copy_all_a\".format(tick_2, user2tick))\n        self.system_tick = systick\n        self.fast_tick = fasttick\n        self.user1_tick = user1tick\n        self.user2_tick = user2tick", "response": "Prepare for code generation by setting up root clock nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clock(self, interval, basis=\"system\"):\n\n        if basis == \"system\":\n            if (interval % 10) == 0:\n                tick = self.allocator.attach_stream(self.system_tick)\n                count = interval // 10\n            else:\n                tick = self.allocator.attach_stream(self.fast_tick)\n                count = interval\n\n            trigger = InputTrigger(u'count', '>=', count)\n            return (tick, trigger)\n        elif basis == 'tick_1':\n            tick = self.allocator.attach_stream(self.user1_tick)\n            trigger = InputTrigger(u'count', '>=', interval)\n            return (tick, trigger)\n        elif basis == 'tick_2':\n            tick = self.allocator.attach_stream(self.user2_tick)\n            trigger = InputTrigger(u'count', '>=', interval)\n            return (tick, trigger)\n\n        raise SensorGraphSemanticError(\"Unkwown tick source specified in RootScope.clock\", basis=basis)", "response": "Return a tuple for triggering an event every interval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd Builders and construction variables for g ++ to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for g++ to an Environment.\"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    if 'CXX' not in env:\n        env['CXX']    = env.Detect(compilers) or compilers[0]\n\n    cxx.generate(env)\n\n    # platform specific settings\n    if env['PLATFORM'] == 'aix':\n        env['SHCXXFLAGS'] = SCons.Util.CLVar('$CXXFLAGS -mminimal-toc')\n        env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 1\n        env['SHOBJSUFFIX'] = '$OBJSUFFIX'\n    elif env['PLATFORM'] == 'hpux':\n        env['SHOBJSUFFIX'] = '.pic.o'\n    elif env['PLATFORM'] == 'sunos':\n        env['SHOBJSUFFIX'] = '.pic.o'\n    # determine compiler version\n    version = gcc.detect_version(env, env['CXX'])\n    if version:\n        env['CXXVERSION'] = version"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to find a proxy plugin that is provided by a specific component", "response": "def find_proxy_plugin(component, plugin_name):\n    \"\"\" Attempt to find a proxy plugin provided by a specific component\n\n    Args:\n        component (string): The name of the component that provides the plugin\n        plugin_name (string): The name of the plugin to load\n\n    Returns:\n        TileBuxProxyPlugin: The plugin, if found, otherwise raises DataError\n    \"\"\"\n\n    reg = ComponentRegistry()\n\n    plugins = reg.load_extensions('iotile.proxy_plugin', comp_filter=component, class_filter=TileBusProxyPlugin,\n                                  product_name='proxy_plugin')\n\n    for _name, plugin in plugins:\n        if plugin.__name__ == plugin_name:\n            return plugin\n\n    raise DataError(\"Could not find proxy plugin module in registered components or installed distributions\",\n                    component=component, name=plugin_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying that the object conforms to this verifier s schema COOKIENAME.", "response": "def verify(self, obj):\n        \"\"\"Verify that the object conforms to this verifier's schema\n\n        Args:\n            obj (object): A python object to verify\n\n        Raises:\n            ValidationError: If there is a problem verifying the dictionary, a\n                ValidationError is thrown with at least the reason key set indicating\n                the reason for the lack of validation.\n        \"\"\"\n\n        if not isinstance(obj, bool):\n            raise ValidationError(\"Object is not a bool\", reason='object is not a bool', object=obj)\n\n        if self._require_value is not None and obj != self._require_value:\n            raise ValidationError(\"Boolean is not equal to specified literal\", reason='boolean value %s should be %s'\n                                                                                      % (str(obj), str(self._require_value)))\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat this verifier string", "response": "def format(self, indent_level, indent_size=4):\n        \"\"\"Format this verifier\n\n        Returns:\n            string: A formatted string\n        \"\"\"\n\n        name = self.format_name('Boolean', indent_size)\n\n        if self._require_value is not None:\n            if self.long_desc is not None:\n                name += '\\n'\n\n            name += self.wrap_lines('must be %s\\n' % str(self._require_value).lower(), 1, indent_size)\n\n        return self.wrap_lines(name, indent_level, indent_size)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FromBinary(cls, record_data, record_count=1):\n\n        _cmd, address, _resp_length, payload = cls._parse_rpc_info(record_data)\n\n        descriptor = parse_binary_descriptor(payload)\n        return AddNodeRecord(descriptor, address=address)", "response": "Create an UpdateRecord subclass from a binary record data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_trigger(self, trigger_def, parent):\n\n        if trigger_def.explicit_stream is None:\n            stream = parent.resolve_identifier(trigger_def.named_event, DataStream)\n            trigger = TrueTrigger()\n        else:\n            stream = trigger_def.explicit_stream\n            trigger = trigger_def.explicit_trigger\n\n        return (stream, trigger)", "response": "Convert a TriggerDefinition into a stream and trigger pair."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a named event or explicit stream trigger into a TriggerDefinition.", "response": "def _parse_trigger(self, trigger_clause):\n        \"\"\"Parse a named event or explicit stream trigger into a TriggerDefinition.\"\"\"\n\n        cond = trigger_clause[0]\n\n        named_event = None\n        explicit_stream = None\n        explicit_trigger = None\n\n        # Identifier parse tree is Group(Identifier)\n        if cond.getName() == 'identifier':\n            named_event = cond[0]\n        elif cond.getName() == 'stream_trigger':\n            trigger_type = cond[0]\n            stream = cond[1]\n            oper = cond[2]\n            ref = cond[3]\n\n            trigger = InputTrigger(trigger_type, oper, ref)\n            explicit_stream = stream\n            explicit_trigger = trigger\n        elif cond.getName() == 'stream_always':\n            stream = cond[0]\n            trigger = TrueTrigger()\n            explicit_stream = stream\n            explicit_trigger = trigger\n        else:\n            raise ArgumentError(\"OnBlock created from an invalid ParseResults object\", parse_results=trigger_clause)\n\n        return TriggerDefinition(named_event, explicit_stream, explicit_trigger)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_before(self, sensor_graph, scope_stack):\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        stream_a, trigger_a = self._convert_trigger(self.trigger_a, parent)\n\n        if self.trigger_b is None:\n            new_scope = TriggerScope(sensor_graph, scope_stack, (stream_a, trigger_a))\n        else:\n            stream_b, trigger_b = self._convert_trigger(self.trigger_b, parent)\n            trigger_stream = alloc.allocate_stream(DataStream.UnbufferedType)\n\n            if self.combiner == u'and':\n                combiner = '&&'\n            else:\n                combiner = '||'\n\n            if stream_a.input and not stream_b.input:\n                unbuffered_stream = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n                sensor_graph.add_node(u\"({} always) => {} using copy_latest_a\".format(stream_a, unbuffered_stream))\n                sensor_graph.add_node(u\"({} {} {} {} {}) => {} using copy_latest_a\".format(unbuffered_stream, trigger_a, combiner, stream_b, trigger_b, trigger_stream))\n            elif stream_b.input and not stream_a.input:\n                unbuffered_stream = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n                sensor_graph.add_node(u\"({} always) => {} using copy_latest_a\".format(stream_b, unbuffered_stream))\n                sensor_graph.add_node(u\"({} {} {} {} {}) => {} using copy_latest_a\".format(stream_a, trigger_a, combiner, unbuffered_stream, trigger_b, trigger_stream))\n            else:\n                sensor_graph.add_node(u\"({} {} {} {} {}) => {} using copy_latest_a\".format(stream_a, trigger_a, combiner, stream_b, trigger_b, trigger_stream))\n            new_scope = TriggerScope(sensor_graph, scope_stack, (trigger_stream, TrueTrigger()))\n\n        scope_stack.append(new_scope)", "response": "Execute statement before children are executed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the platform string for our execution environment.", "response": "def platform_default():\n    \"\"\"Return the platform string for our execution environment.\n\n    The returned value should map to one of the SCons/Platform/*.py\n    files.  Since we're architecture independent, though, we don't\n    care about the machine architecture.\n    \"\"\"\n    osname = os.name\n    if osname == 'java':\n        osname = os._osType\n    if osname == 'posix':\n        if sys.platform == 'cygwin':\n            return 'cygwin'\n        elif sys.platform.find('irix') != -1:\n            return 'irix'\n        elif sys.platform.find('sunos') != -1:\n            return 'sunos'\n        elif sys.platform.find('hp-ux') != -1:\n            return 'hpux'\n        elif sys.platform.find('aix') != -1:\n            return 'aix'\n        elif sys.platform.find('darwin') != -1:\n            return 'darwin'\n        else:\n            return 'posix'\n    elif os.name == 'os2':\n        return 'os2'\n    else:\n        return sys.platform"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef platform_module(name = platform_default()):\n    full_name = 'SCons.Platform.' + name\n    if full_name not in sys.modules:\n        if os.name == 'java':\n            eval(full_name)\n        else:\n            try:\n                file, path, desc = imp.find_module(name,\n                                        sys.modules['SCons.Platform'].__path__)\n                try:\n                    mod = imp.load_module(full_name, file, path, desc)\n                finally:\n                    if file:\n                        file.close()\n            except ImportError:\n                try:\n                    import zipimport\n                    importer = zipimport.zipimporter( sys.modules['SCons.Platform'].__path__[0] )\n                    mod = importer.load_module(full_name)\n                except ImportError:\n                    raise SCons.Errors.UserError(\"No platform named '%s'\" % name)\n            setattr(SCons.Platform, name, mod)\n    return sys.modules[full_name]", "response": "Returns the imported module for the platform."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Platform(name = platform_default()):\n    module = platform_module(name)\n    spec = PlatformSpec(name, module.generate)\n    return spec", "response": "Select a canned Platform specification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jarManifest(target, source, env, for_signature):\n    for src in source:\n        contents = src.get_text_contents()\n        if contents[:16] == \"Manifest-Version\":\n            return src\n    return ''", "response": "Look in sources for a manifest file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef jarFlags(target, source, env, for_signature):\n    jarflags = env.subst('$JARFLAGS', target=target, source=source)\n    for src in source:\n        contents = src.get_text_contents()\n        if contents[:16] == \"Manifest-Version\":\n            if not 'm' in jarflags:\n                return jarflags + 'm'\n            break\n    return jarflags", "response": "Return the jar flags for the given target and source."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(env):\n    SCons.Tool.CreateJarBuilder(env)\n\n    SCons.Tool.CreateJavaFileBuilder(env)\n    SCons.Tool.CreateJavaClassFileBuilder(env)\n    SCons.Tool.CreateJavaClassDirBuilder(env)\n\n    env.AddMethod(Jar)\n\n    env['JAR']        = 'jar'\n    env['JARFLAGS']   = SCons.Util.CLVar('cf')\n    env['_JARFLAGS']  = jarFlags\n    env['_JARMANIFEST'] = jarManifest\n    env['_JARSOURCES'] = jarSources\n    env['_JARCOM']    = '$JAR $_JARFLAGS $TARGET $_JARMANIFEST $_JARSOURCES'\n    env['JARCOM']     = \"${TEMPFILE('$_JARCOM','$JARCOMSTR')}\"\n    env['JARSUFFIX']  = '.jar'", "response": "Add Builders and construction variables for jar to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore a mock return value for an RPC.", "response": "def mock(self, slot, rpc_id, value):\n        \"\"\"Store a mock return value for an RPC\n\n        Args:\n            slot (SlotIdentifier): The slot we are mocking\n            rpc_id (int): The rpc we are mocking\n            value (int): The value that should be returned\n                when the RPC is called.\n        \"\"\"\n\n        address = slot.address\n\n        if address not in self.mock_rpcs:\n            self.mock_rpcs[address] = {}\n\n        self.mock_rpcs[address][rpc_id] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rpc(self, address, rpc_id):\n\n        # Always allow mocking an RPC to override whatever the defaul behavior is\n        if address in self.mock_rpcs and rpc_id in self.mock_rpcs[address]:\n            value = self.mock_rpcs[address][rpc_id]\n            return value\n\n        result = self._call_rpc(address, rpc_id, bytes())\n\n        if len(result) != 4:\n            self.warn(u\"RPC 0x%X on address %d: response had invalid length %d not equal to 4\" % (rpc_id, address, len(result)))\n\n        if len(result) < 4:\n            raise HardwareError(\"Response from RPC was not long enough to parse as an integer\", rpc_id=rpc_id, address=address, response_length=len(result))\n\n        if len(result) > 4:\n            result = result[:4]\n\n        res, = struct.unpack(\"<L\", result)\n        return res", "response": "Call an RPC and receive the result as an integer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_modules(src):\n    directors = 0\n    mnames = []\n    try:\n        matches = _reModule.findall(open(src).read())\n    except IOError:\n        # If the file's not yet generated, guess the module name from the file stem\n        matches = []\n        mnames.append(os.path.splitext(os.path.basename(src))[0])\n\n    for m in matches:\n        mnames.append(m[2])\n        directors = directors or m[0].find('directors') >= 0\n    return mnames, directors", "response": "Find all modules referenced by %module lines in src a SWIG. i file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_swig_version(env, swig):\n    swig = env.subst(swig)\n    pipe = SCons.Action._subproc(env, SCons.Util.CLVar(swig) + ['-version'],\n                                 stdin = 'devnull',\n                                 stderr = 'devnull',\n                                 stdout = subprocess.PIPE)\n    if pipe.wait() != 0: return\n\n    # MAYBE:   out = SCons.Util.to_str (pipe.stdout.read())\n    out = SCons.Util.to_str(pipe.stdout.read())\n    match = re.search('SWIG Version\\s+(\\S+).*', out, re.MULTILINE)\n    if match:\n        if verbose: print(\"Version is:%s\"%match.group(1))\n        return match.group(1)\n    else:\n        if verbose: print(\"Unable to detect version: [%s]\"%out)", "response": "Run the SWIG command line tool to get and return the version number"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for swig to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for swig to an Environment.\"\"\"\n    c_file, cxx_file = SCons.Tool.createCFileBuilders(env)\n\n    c_file.suffix['.i'] = swigSuffixEmitter\n    cxx_file.suffix['.i'] = swigSuffixEmitter\n\n    c_file.add_action('.i', SwigAction)\n    c_file.add_emitter('.i', _swigEmitter)\n    cxx_file.add_action('.i', SwigAction)\n    cxx_file.add_emitter('.i', _swigEmitter)\n\n    java_file = SCons.Tool.CreateJavaFileBuilder(env)\n\n    java_file.suffix['.i'] = swigSuffixEmitter\n\n    java_file.add_action('.i', SwigAction)\n    java_file.add_emitter('.i', _swigEmitter)\n\n    if 'SWIG' not in env:\n        env['SWIG'] = env.Detect(swigs) or swigs[0]\n    env['SWIGVERSION']       = _get_swig_version(env, env['SWIG'])\n    env['SWIGFLAGS']         = SCons.Util.CLVar('')\n    env['SWIGDIRECTORSUFFIX'] = '_wrap.h'\n    env['SWIGCFILESUFFIX']   = '_wrap$CFILESUFFIX'\n    env['SWIGCXXFILESUFFIX'] = '_wrap$CXXFILESUFFIX'\n    env['_SWIGOUTDIR']       = r'${\"-outdir \\\"%s\\\"\" % SWIGOUTDIR}'\n    env['SWIGPATH']          = []\n    env['SWIGINCPREFIX']     = '-I'\n    env['SWIGINCSUFFIX']     = ''\n    env['_SWIGINCFLAGS']     = '$( ${_concat(SWIGINCPREFIX, SWIGPATH, SWIGINCSUFFIX, __env__, RDirs, TARGET, SOURCE)} $)'\n    env['SWIGCOM']           = '$SWIG -o $TARGET ${_SWIGOUTDIR} ${_SWIGINCFLAGS} $SWIGFLAGS $SOURCES'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nselects multiplexer channel. Currently uses a FTDI chip via pylibftdi", "response": "def _select_ftdi_channel(channel):\n    \"\"\"Select multiplexer channel. Currently uses a FTDI chip via pylibftdi\"\"\"\n    if channel < 0 or channel > 8:\n        raise ArgumentError(\"FTDI-selected multiplexer only has channels 0-7 valid, \"\n                            \"make sure you specify channel with -c channel=number\", channel=channel)\n    from pylibftdi import BitBangDevice\n    bb = BitBangDevice(auto_detach=False)\n    bb.direction = 0b111\n    bb.port = channel"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a binary streamer descriptor into a string descriptor.", "response": "def parse_binary_descriptor(bindata, sensor_log=None):\n    \"\"\"Convert a binary streamer descriptor into a string descriptor.\n\n    Binary streamer descriptors are 20-byte binary structures that encode all\n    information needed to create a streamer.  They are used to communicate\n    that information to an embedded device in an efficent format.  This\n    function exists to turn such a compressed streamer description back into\n    an understandable string.\n\n    Args:\n        bindata (bytes): The binary streamer descriptor that we want to\n            understand.\n        sensor_log (SensorLog): Optional sensor_log to add this streamer to\n            a an underlying data store.\n\n    Returns:\n        DataStreamer: A DataStreamer object representing the streamer.\n\n        You can get a useful human readable string by calling str() on the\n        return value.\n    \"\"\"\n\n    if len(bindata) != 14:\n        raise ArgumentError(\"Invalid length of binary data in streamer descriptor\", length=len(bindata), expected=14, data=bindata)\n\n    dest_tile, stream_id, trigger, format_code, type_code = struct.unpack(\"<8sHBBBx\", bindata)\n\n    dest_id = SlotIdentifier.FromEncoded(dest_tile)\n    selector = DataStreamSelector.FromEncoded(stream_id)\n\n    format_name = DataStreamer.KnownFormatCodes.get(format_code)\n    type_name = DataStreamer.KnownTypeCodes.get(type_code)\n\n    if format_name is None:\n        raise ArgumentError(\"Unknown format code\", code=format_code, known_code=DataStreamer.KnownFormatCodes)\n    if type_name is None:\n        raise ArgumentError(\"Unknown type code\", code=type_code, known_codes=DataStreamer.KnownTypeCodes)\n\n    with_other = None\n    if trigger & (1 << 7):\n        auto = False\n        with_other = trigger & ((1 << 7) - 1)\n    elif trigger == 0:\n        auto = False\n    elif trigger == 1:\n        auto = True\n    else:\n        raise ArgumentError(\"Unknown trigger type for streamer\", trigger_code=trigger)\n\n    return DataStreamer(selector, dest_id, format_name, auto, type_name, with_other=with_other, sensor_log=sensor_log)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a packed binary descriptor of a DataStreamer object.", "response": "def create_binary_descriptor(streamer):\n    \"\"\"Create a packed binary descriptor of a DataStreamer object.\n\n    Args:\n        streamer (DataStreamer): The streamer to create a packed descriptor for\n\n    Returns:\n        bytes: A packed 14-byte streamer descriptor.\n    \"\"\"\n\n    trigger = 0\n    if streamer.automatic:\n        trigger = 1\n    elif streamer.with_other is not None:\n        trigger = (1 << 7) | streamer.with_other\n\n    return struct.pack(\"<8sHBBBx\", streamer.dest.encode(), streamer.selector.encode(), trigger, streamer.KnownFormats[streamer.format], streamer.KnownTypes[streamer.report_type])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a string descriptor into a DataStreamer object.", "response": "def parse_string_descriptor(string_desc):\n    \"\"\"Parse a string descriptor of a streamer into a DataStreamer object.\n\n    Args:\n        string_desc (str): The string descriptor that we wish to parse.\n\n    Returns:\n        DataStreamer: A DataStreamer object representing the streamer.\n    \"\"\"\n\n    if not isinstance(string_desc, str):\n        string_desc = str(string_desc)\n\n    if not string_desc.endswith(';'):\n        string_desc += ';'\n\n    parsed = get_streamer_parser().parseString(string_desc)[0]\n\n    realtime = 'realtime' in parsed\n    broadcast = 'broadcast' in parsed\n    encrypted = 'security' in parsed and parsed['security'] == 'encrypted'\n    signed = 'security' in parsed and parsed['security'] == 'signed'\n    auto = 'manual' not in parsed\n\n    with_other = None\n    if 'with_other' in parsed:\n        with_other = parsed['with_other']\n        auto = False\n\n    dest = SlotIdentifier.FromString('controller')\n    if 'explicit_tile' in parsed:\n        dest = parsed['explicit_tile']\n\n    selector = parsed['selector']\n\n    # Make sure all of the combination are valid\n    if realtime and (encrypted or signed):\n        raise SensorGraphSemanticError(\"Realtime streamers cannot be either signed or encrypted\")\n\n    if broadcast and (encrypted or signed):\n        raise SensorGraphSemanticError(\"Broadcast streamers cannot be either signed or encrypted\")\n\n    report_type = 'broadcast' if broadcast else 'telegram'\n    dest = dest\n    selector = selector\n\n    if realtime or broadcast:\n        report_format = u'individual'\n    elif signed:\n        report_format = u'signedlist_userkey'\n    elif encrypted:\n        raise SensorGraphSemanticError(\"Encrypted streamers are not yet supported\")\n    else:\n        report_format = u'hashedlist'\n\n    return DataStreamer(selector, dest, report_format, auto, report_type=report_type, with_other=with_other)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nverifies that the object conforms to this verifier s schema.", "response": "def verify(self, obj):\n        \"\"\"Verify that the object conforms to this verifier's schema.\n\n        Args:\n            obj (object): A python object to verify\n\n        Raises:\n            ValidationError: If there is a problem verifying the dictionary, a\n                ValidationError is thrown with at least the reason key set indicating\n                the reason for the lack of validation.\n        \"\"\"\n\n        if not isinstance(obj, float):\n            raise ValidationError(\"Object is not a float\", reason='object is not a float', object=obj)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_before(self, sensor_graph, scope_stack):\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        # We want to create a gated clock that only fires when there is a connection\n        # to a communication tile.  So we create a latching constant stream that is used to gate the\n        # clock passed through from the previous scope.\n        connect_stream = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n        disconnect_stream = alloc.allocate_stream(DataStream.UnbufferedType, attach=True)\n        latch_stream = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n        latch_on_stream = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n        latch_off_stream = alloc.allocate_stream(DataStream.ConstantType, attach=True)\n\n        sensor_graph.add_node(u\"({} always) => {} using copy_latest_a\".format(user_connected, connect_stream))\n        sensor_graph.add_node(u\"({} always) => {} using copy_latest_a\".format(user_disconnected, disconnect_stream))\n\n        sensor_graph.add_node(u\"({} always && {} when value=={}) => {} using copy_latest_a\".format(latch_on_stream, connect_stream, self.slot_id.address, latch_stream))\n        sensor_graph.add_node(u\"({} always && {} when value=={}) => {} using copy_latest_a\".format(latch_off_stream, disconnect_stream, self.slot_id.address, latch_stream))\n\n        sensor_graph.add_constant(latch_on_stream, 1)\n        sensor_graph.add_constant(latch_off_stream, 0)\n        sensor_graph.add_constant(latch_stream, 0)\n\n        new_scope = GatedClockScope(sensor_graph, scope_stack, (latch_stream, InputTrigger(u'value', u'==', 1)))\n\n        # Add two new identifiers to the scope for supporting on connect and on disconnect events\n        new_scope.add_identifier('connect', connect_stream)\n        new_scope.add_identifier('disconnect', disconnect_stream)\n        scope_stack.append(new_scope)", "response": "Execute statement before children are executed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding Builders and construction variables for applelink to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for applelink to an\n    Environment.\"\"\"\n    link.generate(env)\n\n    env['FRAMEWORKPATHPREFIX'] = '-F'\n    env['_FRAMEWORKPATH'] = '${_concat(FRAMEWORKPATHPREFIX, FRAMEWORKPATH, \"\", __env__)}'\n    env['_FRAMEWORKS'] = '${_concat(\"-framework \", FRAMEWORKS, \"\", __env__)}'\n    env['LINKCOM'] = env['LINKCOM'] + ' $_FRAMEWORKPATH $_FRAMEWORKS $FRAMEWORKSFLAGS'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -dynamiclib')\n    env['SHLINKCOM'] = env['SHLINKCOM'] + ' $_FRAMEWORKPATH $_FRAMEWORKS $FRAMEWORKSFLAGS'\n\n\n    # TODO: Work needed to generate versioned shared libraries\n    # Leaving this commented out, and also going to disable versioned library checking for now\n    # see: http://docstore.mik.ua/orelly/unix3/mac/ch05_04.htm  for proper naming\n    #link._setup_versioned_lib_variables(env, tool = 'applelink')#, use_soname = use_soname)\n    #env['LINKCALLBACKS'] = link._versioned_lib_callbacks()\n\n\n    # override the default for loadable modules, which are different\n    # on OS X than dynamic shared libs.  echoing what XCode does for\n    # pre/suffixes:\n    env['LDMODULEPREFIX'] = '' \n    env['LDMODULESUFFIX'] = '' \n    env['LDMODULEFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -bundle')\n    env['LDMODULECOM'] = '$LDMODULE -o ${TARGET} $LDMODULEFLAGS $SOURCES $_LIBDIRFLAGS $_LIBFLAGS $_FRAMEWORKPATH $_FRAMEWORKS $FRAMEWORKSFLAGS'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generateGUID(slnfile, name):\n    m = hashlib.md5()\n    # Normalize the slnfile path to a Windows path (\\ separators) so\n    # the generated file has a consistent GUID even if we generate\n    # it on a non-Windows platform.\n    m.update(bytearray(ntpath.normpath(str(slnfile)) + str(name),'utf-8'))\n    solution = m.hexdigest().upper()\n    # convert most of the signature to GUID form (discard the rest)\n    solution = \"{\" + solution[:8] + \"-\" + solution[8:12] + \"-\" + solution[12:16] + \"-\" + solution[16:20] + \"-\" + solution[20:32] + \"}\"\n    return solution", "response": "This function generates a dummy GUID for the project."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef msvs_parse_version(s):\n    num, suite = version_re.match(s).groups()\n    return float(num), suite", "response": "Parse a version string into its number and trailing version portion."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeHierarchy(sources):\n    '''Break a list of files into a hierarchy; for each value, if it is a string,\n       then it is a file.  If it is a dictionary, it is a folder.  The string is\n       the original path of the file.'''\n\n    hierarchy = {}\n    for file in sources:\n        path = splitFully(file)\n        if len(path):\n            dict = hierarchy\n            for part in path[:-1]:\n                if part not in dict:\n                    dict[part] = {}\n                dict = dict[part]\n            dict[path[-1]] = file\n        #else:\n        #    print 'Warning: failed to decompose path for '+str(file)\n    return hierarchy", "response": "Break a list of files into a hierarchy ; for each value it is a string is\n       then it is a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GenerateDSP(dspfile, source, env):\n\n    version_num = 6.0\n    if 'MSVS_VERSION' in env:\n        version_num, suite = msvs_parse_version(env['MSVS_VERSION'])\n    if version_num >= 10.0:\n        g = _GenerateV10DSP(dspfile, source, env)\n        g.Build()\n    elif version_num >= 7.0:\n        g = _GenerateV7DSP(dspfile, source, env)\n        g.Build()\n    else:\n        g = _GenerateV6DSP(dspfile, source, env)\n        g.Build()", "response": "Generates a DSP file based on the version of MSVS that is being used"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a Solution or Workspace file based on the version of MSVS that is being used", "response": "def GenerateDSW(dswfile, source, env):\n    \"\"\"Generates a Solution/Workspace file based on the version of MSVS that is being used\"\"\"\n\n    version_num = 6.0\n    if 'MSVS_VERSION' in env:\n        version_num, suite = msvs_parse_version(env['MSVS_VERSION'])\n    if version_num >= 7.0:\n        g = _GenerateV7DSW(dswfile, source, env)\n        g.Build()\n    else:\n        g = _GenerateV6DSW(dswfile, source, env)\n        g.Build()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef projectEmitter(target, source, env):\n\n    # todo: Not sure what sets source to what user has passed as target,\n    # but this is what happens. When that is fixed, we also won't have\n    # to make the user always append env['MSVSPROJECTSUFFIX'] to target.\n    if source[0] == target[0]:\n        source = []\n\n    # make sure the suffix is correct for the version of MSVS we're running.\n    (base, suff) = SCons.Util.splitext(str(target[0]))\n    suff = env.subst('$MSVSPROJECTSUFFIX')\n    target[0] = base + suff\n\n    if not source:\n        source = 'prj_inputs:'\n        source = source + env.subst('$MSVSSCONSCOM', 1)\n        source = source + env.subst('$MSVSENCODING', 1)\n\n        # Project file depends on CPPDEFINES and CPPPATH\n        preprocdefs = xmlify(';'.join(processDefines(env.get('CPPDEFINES', []))))\n        includepath_Dirs = processIncludes(env.get('CPPPATH', []), env, None, None)\n        includepath = xmlify(';'.join([str(x) for x in includepath_Dirs]))\n        source = source + \"; ppdefs:%s incpath:%s\"%(preprocdefs, includepath)\n\n        if 'buildtarget' in env and env['buildtarget'] != None:\n            if SCons.Util.is_String(env['buildtarget']):\n                source = source + ' \"%s\"' % env['buildtarget']\n            elif SCons.Util.is_List(env['buildtarget']):\n                for bt in env['buildtarget']:\n                    if SCons.Util.is_String(bt):\n                        source = source + ' \"%s\"' % bt\n                    else:\n                        try: source = source + ' \"%s\"' % bt.get_abspath()\n                        except AttributeError: raise SCons.Errors.InternalError(\"buildtarget can be a string, a node, a list of strings or nodes, or None\")\n            else:\n                try: source = source + ' \"%s\"' % env['buildtarget'].get_abspath()\n                except AttributeError: raise SCons.Errors.InternalError(\"buildtarget can be a string, a node, a list of strings or nodes, or None\")\n\n        if 'outdir' in env and env['outdir'] != None:\n            if SCons.Util.is_String(env['outdir']):\n                source = source + ' \"%s\"' % env['outdir']\n            elif SCons.Util.is_List(env['outdir']):\n                for s in env['outdir']:\n                    if SCons.Util.is_String(s):\n                        source = source + ' \"%s\"' % s\n                    else:\n                        try: source = source + ' \"%s\"' % s.get_abspath()\n                        except AttributeError: raise SCons.Errors.InternalError(\"outdir can be a string, a node, a list of strings or nodes, or None\")\n            else:\n                try: source = source + ' \"%s\"' % env['outdir'].get_abspath()\n                except AttributeError: raise SCons.Errors.InternalError(\"outdir can be a string, a node, a list of strings or nodes, or None\")\n\n        if 'name' in env:\n            if SCons.Util.is_String(env['name']):\n                source = source + ' \"%s\"' % env['name']\n            else:\n                raise SCons.Errors.InternalError(\"name must be a string\")\n\n        if 'variant' in env:\n            if SCons.Util.is_String(env['variant']):\n                source = source + ' \"%s\"' % env['variant']\n            elif SCons.Util.is_List(env['variant']):\n                for variant in env['variant']:\n                    if SCons.Util.is_String(variant):\n                        source = source + ' \"%s\"' % variant\n                    else:\n                        raise SCons.Errors.InternalError(\"name must be a string or a list of strings\")\n            else:\n                raise SCons.Errors.InternalError(\"variant must be a string or a list of strings\")\n        else:\n            raise SCons.Errors.InternalError(\"variant must be specified\")\n\n        for s in _DSPGenerator.srcargs:\n            if s in env:\n                if SCons.Util.is_String(env[s]):\n                    source = source + ' \"%s' % env[s]\n                elif SCons.Util.is_List(env[s]):\n                    for t in env[s]:\n                        if SCons.Util.is_String(t):\n                            source = source + ' \"%s\"' % t\n                        else:\n                            raise SCons.Errors.InternalError(s + \" must be a string or a list of strings\")\n                else:\n                    raise SCons.Errors.InternalError(s + \" must be a string or a list of strings\")\n\n        source = source + ' \"%s\"' % str(target[0])\n        source = [SCons.Node.Python.Value(source)]\n\n    targetlist = [target[0]]\n    sourcelist = source\n\n    if env.get('auto_build_solution', 1):\n        env['projects'] = [env.File(t).srcnode() for t in targetlist]\n        t, s = solutionEmitter(target, target, env)\n        targetlist = targetlist + t\n\n    # Beginning with Visual Studio 2010 for each project file (.vcxproj) we have additional file (.vcxproj.filters)\n    version_num = 6.0\n    if 'MSVS_VERSION' in env:\n        version_num, suite = msvs_parse_version(env['MSVS_VERSION'])\n    if version_num >= 10.0:\n        targetlist.append(targetlist[0] + '.filters')\n\n    return (targetlist, sourcelist)", "response": "Sets up the DSP dependencies for the specified source file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset up the DSW dependencies.", "response": "def solutionEmitter(target, source, env):\n    \"\"\"Sets up the DSW dependencies.\"\"\"\n\n    # todo: Not sure what sets source to what user has passed as target,\n    # but this is what happens. When that is fixed, we also won't have\n    # to make the user always append env['MSVSSOLUTIONSUFFIX'] to target.\n    if source[0] == target[0]:\n        source = []\n\n    # make sure the suffix is correct for the version of MSVS we're running.\n    (base, suff) = SCons.Util.splitext(str(target[0]))\n    suff = env.subst('$MSVSSOLUTIONSUFFIX')\n    target[0] = base + suff\n\n    if not source:\n        source = 'sln_inputs:'\n\n        if 'name' in env:\n            if SCons.Util.is_String(env['name']):\n                source = source + ' \"%s\"' % env['name']\n            else:\n                raise SCons.Errors.InternalError(\"name must be a string\")\n\n        if 'variant' in env:\n            if SCons.Util.is_String(env['variant']):\n                source = source + ' \"%s\"' % env['variant']\n            elif SCons.Util.is_List(env['variant']):\n                for variant in env['variant']:\n                    if SCons.Util.is_String(variant):\n                        source = source + ' \"%s\"' % variant\n                    else:\n                        raise SCons.Errors.InternalError(\"name must be a string or a list of strings\")\n            else:\n                raise SCons.Errors.InternalError(\"variant must be a string or a list of strings\")\n        else:\n            raise SCons.Errors.InternalError(\"variant must be specified\")\n\n        if 'slnguid' in env:\n            if SCons.Util.is_String(env['slnguid']):\n                source = source + ' \"%s\"' % env['slnguid']\n            else:\n                raise SCons.Errors.InternalError(\"slnguid must be a string\")\n\n        if 'projects' in env:\n            if SCons.Util.is_String(env['projects']):\n                source = source + ' \"%s\"' % env['projects']\n            elif SCons.Util.is_List(env['projects']):\n                for t in env['projects']:\n                    if SCons.Util.is_String(t):\n                        source = source + ' \"%s\"' % t\n\n        source = source + ' \"%s\"' % str(target[0])\n        source = [SCons.Node.Python.Value(source)]\n\n    return ([target[0]], source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(env):\n    try:\n        env['BUILDERS']['MSVSProject']\n    except KeyError:\n        env['BUILDERS']['MSVSProject'] = projectBuilder\n\n    try:\n        env['BUILDERS']['MSVSSolution']\n    except KeyError:\n        env['BUILDERS']['MSVSSolution'] = solutionBuilder\n\n    env['MSVSPROJECTCOM'] = projectAction\n    env['MSVSSOLUTIONCOM'] = solutionAction\n\n    if SCons.Script.call_stack:\n        # XXX Need to find a way to abstract this; the build engine\n        # shouldn't depend on anything in SCons.Script.\n        env['MSVSSCONSCRIPT'] = SCons.Script.call_stack[0].sconscript\n    else:\n        global default_MSVS_SConscript\n        if default_MSVS_SConscript is None:\n            default_MSVS_SConscript = env.File('SConstruct')\n        env['MSVSSCONSCRIPT'] = default_MSVS_SConscript\n\n    env['MSVSSCONS'] = '\"%s\" -c \"%s\"' % (python_executable, getExecScriptMain(env))\n    env['MSVSSCONSFLAGS'] = '-C \"${MSVSSCONSCRIPT.dir.get_abspath()}\" -f ${MSVSSCONSCRIPT.name}'\n    env['MSVSSCONSCOM'] = '$MSVSSCONS $MSVSSCONSFLAGS'\n    env['MSVSBUILDCOM'] = '$MSVSSCONSCOM \"$MSVSBUILDTARGET\"'\n    env['MSVSREBUILDCOM'] = '$MSVSSCONSCOM \"$MSVSBUILDTARGET\"'\n    env['MSVSCLEANCOM'] = '$MSVSSCONSCOM -c \"$MSVSBUILDTARGET\"'\n\n    # Set-up ms tools paths for default version\n    msvc_setup_env_once(env)\n\n    if 'MSVS_VERSION' in env:\n        version_num, suite = msvs_parse_version(env['MSVS_VERSION'])\n    else:\n        (version_num, suite) = (7.0, None) # guess at a default\n    if 'MSVS' not in env:\n        env['MSVS'] = {}\n    if (version_num < 7.0):\n        env['MSVS']['PROJECTSUFFIX']  = '.dsp'\n        env['MSVS']['SOLUTIONSUFFIX'] = '.dsw'\n    elif (version_num < 10.0):\n        env['MSVS']['PROJECTSUFFIX']  = '.vcproj'\n        env['MSVS']['SOLUTIONSUFFIX'] = '.sln'\n    else:\n        env['MSVS']['PROJECTSUFFIX']  = '.vcxproj'\n        env['MSVS']['SOLUTIONSUFFIX'] = '.sln'\n\n    if (version_num >= 10.0):\n        env['MSVSENCODING'] = 'utf-8'\n    else:\n        env['MSVSENCODING'] = 'Windows-1252'\n\n    env['GET_MSVSPROJECTSUFFIX']  = GetMSVSProjectSuffix\n    env['GET_MSVSSOLUTIONSUFFIX']  = GetMSVSSolutionSuffix\n    env['MSVSPROJECTSUFFIX']  = '${GET_MSVSPROJECTSUFFIX}'\n    env['MSVSSOLUTIONSUFFIX']  = '${GET_MSVSSOLUTIONSUFFIX}'\n    env['SCONS_HOME'] = os.environ.get('SCONS_HOME')", "response": "Add Builders and construction variables for Microsoft Visual\n    Studio project files to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef PrintSolution(self):\n        self.file.write('Microsoft Visual Studio Solution File, Format Version %s\\n' % self.versionstr)\n        if self.version_num >= 12.0:\n            self.file.write('# Visual Studio 14\\n')\n        elif self.version_num >= 11.0:\n            self.file.write('# Visual Studio 11\\n')\n        elif self.version_num >= 10.0:\n            self.file.write('# Visual Studio 2010\\n')\n        elif self.version_num >= 9.0:\n            self.file.write('# Visual Studio 2008\\n')\n        elif self.version_num >= 8.0:\n            self.file.write('# Visual Studio 2005\\n')\n\n        for dspinfo in self.dspfiles_info:\n            name = dspinfo['NAME']\n            base, suffix = SCons.Util.splitext(name)\n            if suffix == '.vcproj':\n                name = base\n            self.file.write('Project(\"%s\") = \"%s\", \"%s\", \"%s\"\\n'\n                            % (external_makefile_guid, name, dspinfo['SLN_RELATIVE_FILE_PATH'], dspinfo['GUID']))\n            if self.version_num >= 7.1 and self.version_num < 8.0:\n                self.file.write('\\tProjectSection(ProjectDependencies) = postProject\\n'\n                                '\\tEndProjectSection\\n')\n            self.file.write('EndProject\\n')\n\n        self.file.write('Global\\n')\n\n        env = self.env\n        if 'MSVS_SCC_PROVIDER' in env:\n            scc_number_of_projects = len(self.dspfiles) + 1\n            slnguid = self.slnguid\n            scc_provider = env.get('MSVS_SCC_PROVIDER', '').replace(' ', r'\\u0020')\n            scc_project_name = env.get('MSVS_SCC_PROJECT_NAME', '').replace(' ', r'\\u0020')\n            scc_connection_root = env.get('MSVS_SCC_CONNECTION_ROOT', os.curdir)\n            scc_local_path = os.path.relpath(scc_connection_root, self.dsw_folder_path).replace('\\\\', '\\\\\\\\')\n            self.file.write('\\tGlobalSection(SourceCodeControl) = preSolution\\n'\n                            '\\t\\tSccNumberOfProjects = %(scc_number_of_projects)d\\n'\n                            '\\t\\tSccProjectName0 = %(scc_project_name)s\\n'\n                            '\\t\\tSccLocalPath0 = %(scc_local_path)s\\n'\n                            '\\t\\tSccProvider0 = %(scc_provider)s\\n'\n                            '\\t\\tCanCheckoutShared = true\\n'  % locals())\n            sln_relative_path_from_scc = os.path.relpath(self.dsw_folder_path, scc_connection_root)\n            if sln_relative_path_from_scc != os.curdir:\n                self.file.write('\\t\\tSccProjectFilePathRelativizedFromConnection0 = %s\\\\\\\\\\n'\n                                % sln_relative_path_from_scc.replace('\\\\', '\\\\\\\\'))\n            if self.version_num < 8.0:\n                # When present, SolutionUniqueID is automatically removed by VS 2005\n                # TODO: check for Visual Studio versions newer than 2005\n                self.file.write('\\t\\tSolutionUniqueID = %s\\n' % slnguid)\n            for dspinfo in self.dspfiles_info:\n                i = self.dspfiles_info.index(dspinfo) + 1\n                dsp_relative_file_path = dspinfo['SLN_RELATIVE_FILE_PATH'].replace('\\\\', '\\\\\\\\')\n                dsp_scc_relative_folder_path = os.path.relpath(dspinfo['FOLDER_PATH'], scc_connection_root).replace('\\\\', '\\\\\\\\')\n                self.file.write('\\t\\tSccProjectUniqueName%(i)s = %(dsp_relative_file_path)s\\n'\n                                '\\t\\tSccLocalPath%(i)d = %(scc_local_path)s\\n'\n                                '\\t\\tCanCheckoutShared = true\\n'\n                                '\\t\\tSccProjectFilePathRelativizedFromConnection%(i)s = %(dsp_scc_relative_folder_path)s\\\\\\\\\\n'\n                                % locals())\n            self.file.write('\\tEndGlobalSection\\n')\n        if self.version_num >= 8.0:\n            self.file.write('\\tGlobalSection(SolutionConfigurationPlatforms) = preSolution\\n')\n        else:\n            self.file.write('\\tGlobalSection(SolutionConfiguration) = preSolution\\n')\n\n        confkeys = sorted(self.configs.keys())\n        cnt = 0\n        for name in confkeys:\n            variant = self.configs[name].variant\n            platform = self.configs[name].platform\n            if self.version_num >= 8.0:\n                self.file.write('\\t\\t%s|%s = %s|%s\\n' % (variant, platform, variant, platform))\n            else:\n                self.file.write('\\t\\tConfigName.%d = %s\\n' % (cnt, variant))\n            cnt = cnt + 1\n        self.file.write('\\tEndGlobalSection\\n')\n        if self.version_num <= 7.1:\n            self.file.write('\\tGlobalSection(ProjectDependencies) = postSolution\\n'\n                            '\\tEndGlobalSection\\n')\n        if self.version_num >= 8.0:\n            self.file.write('\\tGlobalSection(ProjectConfigurationPlatforms) = postSolution\\n')\n        else:\n            self.file.write('\\tGlobalSection(ProjectConfiguration) = postSolution\\n')\n\n        for name in confkeys:\n            variant = self.configs[name].variant\n            platform = self.configs[name].platform\n            if self.version_num >= 8.0:\n                for dspinfo in self.dspfiles_info:\n                    guid = dspinfo['GUID']\n                    self.file.write('\\t\\t%s.%s|%s.ActiveCfg = %s|%s\\n'\n                                    '\\t\\t%s.%s|%s.Build.0 = %s|%s\\n'  % (guid,variant,platform,variant,platform,guid,variant,platform,variant,platform))\n            else:\n                for dspinfo in self.dspfiles_info:\n                    guid = dspinfo['GUID']\n                    self.file.write('\\t\\t%s.%s.ActiveCfg = %s|%s\\n'\n                                    '\\t\\t%s.%s.Build.0 = %s|%s\\n'  %(guid,variant,variant,platform,guid,variant,variant,platform))\n\n        self.file.write('\\tEndGlobalSection\\n')\n\n        if self.version_num >= 8.0:\n            self.file.write('\\tGlobalSection(SolutionProperties) = preSolution\\n'\n                            '\\t\\tHideSolutionNode = FALSE\\n'\n                            '\\tEndGlobalSection\\n')\n        else:\n            self.file.write('\\tGlobalSection(ExtensibilityGlobals) = postSolution\\n'\n                            '\\tEndGlobalSection\\n'\n                            '\\tGlobalSection(ExtensibilityAddIns) = postSolution\\n'\n                            '\\tEndGlobalSection\\n')\n        self.file.write('EndGlobal\\n')\n        if self.nokeep == 0:\n            pdata = pickle.dumps(self.configs,PICKLE_PROTOCOL)\n            pdata = base64.encodestring(pdata).decode()\n            self.file.write(pdata)\n            self.file.write('\\n')", "response": "Writes a solution file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a DSW file", "response": "def PrintWorkspace(self):\n        \"\"\" writes a DSW file \"\"\"\n        name = self.name\n        dspfile = os.path.relpath(self.dspfiles[0], self.dsw_folder_path)\n        self.file.write(V6DSWHeader % locals())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over all waiters in unspecified order.", "response": "def waiters(self, path=None):\n        \"\"\"Iterate over all waiters.\n\n        This method will return the waiters in unspecified order\n        including the future or callback object that will be invoked\n        and a list containing the keys/value that are being matched.\n\n        Yields:\n            list, future or callable\n        \"\"\"\n\n        context = self._waiters\n\n        if path is None:\n            path = []\n\n        for key in path:\n            context = context[key]\n\n        if self._LEAF in context:\n            for future in context[self._LEAF]:\n                yield (path, future)\n\n        for key in context:\n            if key is self._LEAF:\n                continue\n\n            yield from self.waiters(path=path + [key])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninvokes callback every time a matching message is received.", "response": "def every_match(self, callback, **kwargs):\n        \"\"\"Invoke callback every time a matching message is received.\n\n        The callback will be invoked directly inside process_message so that\n        you can guarantee that it has been called by the time process_message\n        has returned.\n\n        The callback can be removed by a call to remove_waiter(), passing the\n        handle object returned by this call to identify it.\n\n        Args:\n            callback (callable): A callable function that will be called as\n                callback(message) whenever a matching message is received.\n\n        Returns:\n            object: An opaque handle that can be passed to remove_waiter().\n\n            This handle is the only way to remove this callback if you no\n            longer want it to be called.\n        \"\"\"\n\n        if len(kwargs) == 0:\n            raise ArgumentError(\"You must specify at least one message field to wait on\")\n\n        spec = MessageSpec(**kwargs)\n        responder = self._add_waiter(spec, callback)\n\n        return (spec, responder)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a message callback.", "response": "def remove_waiter(self, waiter_handle):\n        \"\"\"Remove a message callback.\n\n        This call will remove a callback previously registered using\n        every_match.\n\n        Args:\n            waiter_handle (object): The opaque handle returned by the\n                previous call to every_match().\n        \"\"\"\n\n        spec, waiter = waiter_handle\n        self._remove_waiter(spec, waiter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self):\n\n        for _, waiter in self.waiters():\n            if isinstance(waiter, asyncio.Future) and not waiter.done():\n                waiter.set_exception(asyncio.CancelledError())\n\n        self._waiters = {}", "response": "Clear all waiters.\n\n        This method will remove any current scheduled waiter with an\n        asyncio.CancelledError exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for(self, timeout=None, **kwargs):\n\n        if len(kwargs) == 0:\n            raise ArgumentError(\"You must specify at least one message field to wait on\")\n\n        spec = MessageSpec(**kwargs)\n        future = self._add_waiter(spec)\n        future.add_done_callback(lambda x: self._remove_waiter(spec, future))\n\n        return asyncio.wait_for(future, timeout=timeout)", "response": "Wait for a specific matching message or timeout."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def process_message(self, message, wait=True):\n\n        to_check = deque([self._waiters])\n        ignored = True\n\n        while len(to_check) > 0:\n            context = to_check.popleft()\n\n            waiters = context.get(OperationManager._LEAF, [])\n            for waiter in waiters:\n                if isinstance(waiter, asyncio.Future):\n                    waiter.set_result(message)\n                else:\n                    try:\n                        await _wait_or_launch(self._loop, waiter, message, wait)\n                    except:  #pylint:disable=bare-except;We can't let a user callback break this routine\n                        self._logger.warning(\"Error calling every_match callback, callback=%s, message=%s\",\n                                             waiter, message, exc_info=True)\n\n                ignored = False\n\n            for key in context:\n                if key is OperationManager._LEAF:\n                    continue\n\n                message_val = _get_key(message, key)\n                if message_val is _MISSING:\n                    continue\n\n                next_level = context[key]\n                if message_val in next_level:\n                    to_check.append(next_level[message_val])\n\n        return not ignored", "response": "Process a message and wait until all waiters have finished."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    try:\n        bld = env['BUILDERS']['Zip']\n    except KeyError:\n        bld = ZipBuilder\n        env['BUILDERS']['Zip'] = bld\n\n    env['ZIP']        = 'zip'\n    env['ZIPFLAGS']   = SCons.Util.CLVar('')\n    env['ZIPCOM']     = zipAction\n    env['ZIPCOMPRESSION'] =  zipcompression\n    env['ZIPSUFFIX']  = '.zip'\n    env['ZIPROOT']    = SCons.Util.CLVar('')", "response": "Add Builders and construction variables for zip to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FromBinary(cls, record_data, record_count=1):\n\n        _cmd, address, _resp_length, _payload = cls._parse_rpc_info(record_data)\n\n        if address != 8:\n            raise ArgumentError(\"Clear config variables sent to non-controller tile\")\n\n        return ClearConfigVariablesRecord()", "response": "Create an UpdateRecord subclass from binary record data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_rpc(self, conn_id, address, rpc_id, payload, timeout):\n\n        try:\n            return await super(EmulatedDeviceAdapter, self).send_rpc(conn_id, address, rpc_id, payload, timeout)\n        finally:\n            for dev in self.devices.values():\n                dev.wait_idle()", "response": "Asynchronously send an RPC to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def debug(self, conn_id, name, cmd_args):\n\n\n        device = self._get_property(conn_id, 'device')\n\n        retval = None\n\n        try:\n            if name == 'dump_state':\n                retval = device.dump_state()\n            elif name == 'restore_state':\n                state = cmd_args['snapshot']\n                device.restore_state(state)\n            elif name == 'load_scenario':\n                scenario = cmd_args['scenario']\n                device.load_metascenario(scenario)\n            elif name == 'track_changes':\n                if cmd_args['enabled']:\n                    device.state_history.enable()\n                else:\n                    device.state_history.disable()\n            elif name == 'dump_changes':\n                outpath = cmd_args['path']\n                device.state_history.dump(outpath)\n            else:\n                reason = \"Unknown command %s\" % name\n                raise DeviceAdapterError(conn_id, 'debug {}'.format(name), reason)\n        except Exception as exc:\n            self._logger.exception(\"Error processing debug command %s: args=%s\", name, cmd_args)\n            reason = \"Exception %s occurred during processing\" % str(exc)\n            raise DeviceAdapterError(conn_id, 'debug {}'.format(name), reason) from exc\n\n        return retval", "response": "Asynchronously complete a named debug command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the object conforms to this verifier s schema.", "response": "def verify(self, obj):\n        \"\"\"Verify that the object conforms to this verifier's schema.\n\n        Args:\n            obj (object): A python object to verify\n\n        Raises:\n            ValidationError: If there is a problem verifying the object, a\n                ValidationError is thrown with at least the reason key set indicating\n                the reason for the lack of validation.\n        \"\"\"\n\n        if obj not in self.options:\n            raise ValidationError(\"Object is not in list of enumerated options\",\n                                  reason='not in list of enumerated options', object=obj, options=self.options)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a one line description of a class.", "response": "def one_line_desc(obj):\n    \"\"\"Get a one line description of a class.\"\"\"\n\n    logger = logging.getLogger(__name__)\n\n    try:\n        doc = ParsedDocstring(obj.__doc__)\n        return doc.short_desc\n    except:  # pylint:disable=bare-except; We don't want a misbehaving exception to break the program\n        logger.warning(\"Could not parse docstring for %s\", obj, exc_info=True)\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserves access to a virtual IOTile device using a virtual iotile interface.", "response": "def main(argv=None, loop=SharedLoop):\n    \"\"\"Serve access to a virtual IOTile device using a virtual iotile interface.\"\"\"\n\n    if argv is None:\n        argv = sys.argv[1:]\n\n    list_parser = argparse.ArgumentParser(add_help=False)\n    list_parser.add_argument('-l', '--list', action='store_true', help=\"List all known installed interfaces and devices and then exit\")\n    list_parser.add_argument('-v', '--verbose', action=\"count\", default=0, help=\"Increase logging level (goes error, warn, info, debug)\")\n\n    parser = argparse.ArgumentParser(description=\"Serve acess to a virtual IOTile device using a virtual IOTile interface\")\n\n    parser.add_argument('interface', help=\"The name of the virtual device interface to use\")\n    parser.add_argument('device', help=\"The name of the virtual device to create\")\n    parser.add_argument('-c', '--config', help=\"An optional JSON config file with arguments for the interface and device\")\n    parser.add_argument('-l', '--list', action='store_true', help=\"List all known installed interfaces and devices and then exit\")\n    parser.add_argument('-n', '--scenario', help=\"Load a test scenario from the given file\")\n    parser.add_argument('-s', '--state', help=\"Load a given state into the device before starting to serve it.  Only works with emulated devices.\")\n    parser.add_argument('-d', '--dump', help=\"Dump the device's state when we exit the program.  Only works with emulated devices.\")\n    parser.add_argument('-t', '--track', help=\"Track all changes to the device's state.  Only works with emulated devices.\")\n    parser.add_argument('-v', '--verbose', action=\"count\", default=0, help=\"Increase logging level (goes error, warn, info, debug)\")\n\n    args, _rest = list_parser.parse_known_args(argv)\n\n    if args.list:\n        configure_logging(args.verbose)\n\n        reg = ComponentRegistry()\n        print(\"Installed Device Servers:\")\n        for name, _iface in reg.load_extensions('iotile.device_server', class_filter=AbstractDeviceServer):\n            print('- {}'.format(name))\n\n        print(\"\\nInstalled Virtual Devices:\")\n        for name, dev in reg.load_extensions('iotile.virtual_device', class_filter=VirtualIOTileDevice,\n                                             product_name=\"virtual_device\"):\n            print('- {}: {}'.format(name, one_line_desc(dev)))\n\n        return 0\n\n    args = parser.parse_args(argv)\n\n    configure_logging(args.verbose)\n\n    config = {}\n    if args.config is not None:\n        with open(args.config, \"r\") as conf_file:\n            config = json.load(conf_file)\n\n    started = False\n    device = None\n    stop_immediately = args.interface == 'null'\n    try:\n        server = instantiate_interface(args.interface, config, loop)\n        device = instantiate_device(args.device, config, loop)\n\n        if args.state is not None:\n            print(\"Loading device state from file %s\" % args.state)\n            device.load_state(args.state)\n\n        if args.scenario is not None:\n            print(\"Loading scenario from file %s\" % args.scenario)\n\n            with open(args.scenario, \"r\") as infile:\n                scenario = json.load(infile)\n\n            # load_metascenario expects a list of scenarios even when there is only one\n            if isinstance(scenario, dict):\n                scenario = [scenario]\n\n            device.load_metascenario(scenario)\n\n        if args.track is not None:\n            print(\"Tracking all state changes to device\")\n            device.state_history.enable()\n\n        adapter = VirtualDeviceAdapter(devices=[device], loop=loop)\n        server.adapter = adapter\n\n        loop.run_coroutine(adapter.start())\n\n        try:\n            loop.run_coroutine(server.start())\n        except:\n            loop.run_coroutine(adapter.stop())\n            adapter = None\n            raise\n\n        started = True\n\n        print(\"Starting to serve virtual IOTile device\")\n\n        if stop_immediately:\n            return 0\n\n        # We need to periodically process events that are queued up in the interface\n        while True:\n            time.sleep(0.5)\n\n    except KeyboardInterrupt:\n        print(\"Break received, cleanly exiting...\")\n    finally:\n        if args.dump is not None and device is not None:\n            print(\"Dumping final device state to %s\" % args.dump)\n            device.save_state(args.dump)\n\n        if started:\n            loop.run_coroutine(server.stop())\n            loop.run_coroutine(adapter.stop())\n\n        if args.track is not None and device is not None:\n            print(\"Saving state history to file %s\" % args.track)\n            device.state_history.dump(args.track)\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a virtual device by name and instantiate it", "response": "def instantiate_device(virtual_dev, config, loop):\n    \"\"\"Find a virtual device by name and instantiate it\n\n    Args:\n        virtual_dev (string): The name of the pkg_resources entry point corresponding to\n            the device.  It should be in group iotile.virtual_device.  If virtual_dev ends\n            in .py, it is interpreted as a python script and loaded directly from the script.\n        config (dict): A dictionary with a 'device' key with the config info for configuring\n            this virtual device.  This is optional.\n\n    Returns:\n        VirtualIOTileDevice: The instantiated subclass of VirtualIOTileDevice\n    \"\"\"\n    conf = {}\n    if 'device' in config:\n        conf = config['device']\n\n    # If we're given a path to a script, try to load and use that rather than search for an installed module\n    try:\n        reg = ComponentRegistry()\n\n        if virtual_dev.endswith('.py'):\n            _name, dev = reg.load_extension(virtual_dev, class_filter=VirtualIOTileDevice, unique=True)\n        else:\n            _name, dev = reg.load_extensions('iotile.virtual_device', name_filter=virtual_dev,\n                                             class_filter=VirtualIOTileDevice,\n                                             product_name=\"virtual_device\", unique=True)\n\n        return dev(conf)\n    except ArgumentError as err:\n        print(\"ERROR: Could not load virtual device (%s): %s\" % (virtual_dev, err.msg))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a virtual interface by name and instantiate it", "response": "def instantiate_interface(virtual_iface, config, loop):\n    \"\"\"Find a virtual interface by name and instantiate it\n\n    Args:\n        virtual_iface (string): The name of the pkg_resources entry point corresponding to\n            the interface.  It should be in group iotile.virtual_interface\n        config (dict): A dictionary with a 'interface' key with the config info for configuring\n            this virtual interface.  This is optional.\n\n    Returns:\n        VirtualInterface: The instantiated subclass of VirtualInterface\n    \"\"\"\n\n    # Allow the null virtual interface for testing\n    if virtual_iface == 'null':\n        return StandardDeviceServer(None, {}, loop=loop)\n\n    conf = {}\n    if 'interface' in config:\n        conf = config['interface']\n\n    try:\n        reg = ComponentRegistry()\n        if virtual_iface.endswith('.py'):\n            _name, iface = reg.load_extension(virtual_iface, class_filter=AbstractDeviceServer, unique=True)\n        else:\n            _name, iface = reg.load_extensions('iotile.device_server', name_filter=virtual_iface,\n                                               class_filter=AbstractDeviceServer, unique=True)\n\n        return iface(None, conf, loop=loop)\n    except ArgumentError as err:\n        print(\"ERROR: Could not load device_server (%s): %s\" % (virtual_iface, err.msg))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(env):\n    try:\n        bld = env['BUILDERS']['Tar']\n    except KeyError:\n        bld = TarBuilder\n        env['BUILDERS']['Tar'] = bld\n\n    env['TAR']        = env.Detect(tars) or 'gtar'\n    env['TARFLAGS']   = SCons.Util.CLVar('-c')\n    env['TARCOM']     = '$TAR $TARFLAGS -f $TARGET $SOURCES'\n    env['TARSUFFIX']  = '.tar'", "response": "Add Builders and construction variables for tar to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_command(self, name, handler, validator):\n\n        self._commands[name] = (handler, validator)", "response": "Register a coroutine command handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def start(self):\n\n        if self._server_task is not None:\n            self._logger.debug(\"AsyncValidatingWSServer.start() called twice, ignoring\")\n            return\n\n        started_signal = self._loop.create_future()\n        self._server_task = self._loop.add_task(self._run_server_task(started_signal))\n\n        await started_signal\n\n        if self.port is None:\n            self.port = started_signal.result()", "response": "Start the websocket server."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a BackgroundTask to manage the server.", "response": "async def _run_server_task(self, started_signal):\n        \"\"\"Create a BackgroundTask to manage the server.\n\n        This allows subclasess to attach their server related tasks as\n        subtasks that are properly cleaned up when this parent task is\n        stopped and not require them all to overload start() and stop()\n        to perform this action.\n        \"\"\"\n\n        try:\n            server = await websockets.serve(self._manage_connection, self.host, self.port)\n            port = server.sockets[0].getsockname()[1]\n            started_signal.set_result(port)\n        except Exception as err:\n            self._logger.exception(\"Error starting server on host %s, port %s\", self.host, self.port)\n            started_signal.set_exception(err)\n            return\n\n        try:\n            while True:\n                await asyncio.sleep(1)\n        except asyncio.CancelledError:\n            self._logger.info(\"Stopping server due to stop() command\")\n        finally:\n            server.close()\n            await server.wait_closed()\n\n        self._logger.debug(\"Server stopped, exiting task\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends an event to a client connection.", "response": "async def send_event(self, con, name, payload):\n        \"\"\"Send an event to a client connection.\n\n        This method will push an event message to the client with the given\n        name and payload.  You need to have access to the the ``connection``\n        object for the client, which is only available once the client has\n        connected and passed to self.prepare_conn(connection).\n\n        Args:\n            con (websockets.Connection): The connection to use to send\n                the event.\n            name (str): The name of the event to send.\n            payload (object): The msgpack-serializable object so send\n                as the event's payload.\n        \"\"\"\n\n        message = dict(type=\"event\", name=name, payload=payload)\n        encoded = pack(message)\n        await con.send(encoded)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes this record into binary suitable for embedded into an update script.", "response": "def encode(self):\n        \"\"\"Encode this record into binary, suitable for embedded into an update script.\n\n        This function just adds the required record header and copies the raw data\n        we were passed in verbatim since we don't know what it means\n\n        Returns:\n            bytearary: The binary version of the record that could be parsed via\n                a call to UpdateRecord.FromBinary()\n        \"\"\"\n\n        header = struct.pack(\"<LB3x\", len(self.record_contents) + UpdateRecord.HEADER_LENGTH, self.record_type)\n        return bytearray(header) + self.record_contents"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DviPdfPsFunction(XXXDviAction, target = None, source= None, env=None):\n\n    try:\n        abspath = source[0].attributes.path\n    except AttributeError :\n        abspath =  ''\n\n    saved_env = SCons.Scanner.LaTeX.modify_env_var(env, 'TEXPICTS', abspath)\n\n    result = XXXDviAction(target, source, env)\n\n    if saved_env is _null:\n        try:\n            del env['ENV']['TEXPICTS']\n        except KeyError:\n            pass # was never set\n    else:\n        env['ENV']['TEXPICTS'] = saved_env\n\n    return result", "response": "A builder for DVI files that sets the TEXPICTS environment variable before running dvi2ps or dvipdf."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DviPdfStrFunction(target = None, source= None, env=None):\n    if env.GetOption(\"no_exec\"):\n        result = env.subst('$DVIPDFCOM',0,target,source)\n    else:\n        result = ''\n    return result", "response": "A strfunction for dvipdf that returns the appropriate\n    command string for the no_exec option."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef PDFEmitter(target, source, env):\n    def strip_suffixes(n):\n        return not SCons.Util.splitext(str(n))[1] in ['.aux', '.log']\n    source = [src for src in source if strip_suffixes(src)]\n    return (target, source)", "response": "This function is used to emit the PDF files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for dvipdf to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for dvipdf to an Environment.\"\"\"\n    global PDFAction\n    if PDFAction is None:\n        PDFAction = SCons.Action.Action('$DVIPDFCOM', '$DVIPDFCOMSTR')\n\n    global DVIPDFAction\n    if DVIPDFAction is None:\n        DVIPDFAction = SCons.Action.Action(DviPdfFunction, strfunction = DviPdfStrFunction)\n\n    from . import pdf\n    pdf.generate(env)\n\n    bld = env['BUILDERS']['PDF']\n    bld.add_action('.dvi', DVIPDFAction)\n    bld.add_emitter('.dvi', PDFEmitter)\n\n    env['DVIPDF']      = 'dvipdf'\n    env['DVIPDFFLAGS'] = SCons.Util.CLVar('')\n    env['DVIPDFCOM']   = 'cd ${TARGET.dir} && $DVIPDF $DVIPDFFLAGS ${SOURCE.file} ${TARGET.file}'\n\n    # Deprecated synonym.\n    env['PDFCOM']      = ['$DVIPDFCOM']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing this stop condition from a string representation.", "response": "def FromString(cls, desc):\n        \"\"\"Parse this stop condition from a string representation.\n\n        The string needs to match:\n        run_time number [seconds|minutes|hours|days|months|years]\n\n        Args:\n            desc (str): The description\n\n        Returns:\n            TimeBasedStopCondition\n        \"\"\"\n\n        parse_exp = Literal(u'run_time').suppress() + time_interval(u'interval')\n\n        try:\n            data = parse_exp.parseString(desc)\n            return TimeBasedStopCondition(data[u'interval'][0])\n        except ParseException:\n            raise ArgumentError(u\"Could not parse time based stop condition\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(env):\n    SCons.Tool.createStaticLibBuilder(env)\n    SCons.Tool.createSharedLibBuilder(env)\n    SCons.Tool.createProgBuilder(env)\n\n    env['AR'] = 'mwld'\n    env['ARCOM'] = '$AR $ARFLAGS -library -o $TARGET $SOURCES'\n\n    env['LIBDIRPREFIX'] = '-L'\n    env['LIBDIRSUFFIX'] = ''\n    env['LIBLINKPREFIX'] = '-l'\n    env['LIBLINKSUFFIX'] = '.lib'\n\n    env['LINK'] = 'mwld'\n    env['LINKCOM'] = '$LINK $LINKFLAGS -o $TARGET $SOURCES $_LIBDIRFLAGS $_LIBFLAGS'\n\n    env['SHLINK'] = '$LINK'\n    env['SHLINKFLAGS'] = '$LINKFLAGS'\n    env['SHLINKCOM']   = shlib_action\n    env['SHLIBEMITTER']= shlib_emitter\n    env['LDMODULEEMITTER']= shlib_emitter", "response": "Add Builders and construction variables for lib to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncollect all source files into a tar. gz file.", "response": "def collectintargz(target, source, env):\n    \"\"\" Puts all source files into a tar.gz file. \"\"\"\n    # the rpm tool depends on a source package, until this is changed\n    # this hack needs to be here that tries to pack all sources in.\n    sources = env.FindSourceFiles()\n\n    # filter out the target we are building the source list for.\n    sources = [s for s in sources if s not in target]\n\n    # find the .spec file for rpm and add it since it is not necessarily found\n    # by the FindSourceFiles function.\n    sources.extend( [s for s in source if str(s).rfind('.spec')!=-1] )\n    # sort to keep sources from changing order across builds\n    sources.sort()\n\n    # as the source contains the url of the source package this rpm package\n    # is built from, we extract the target name\n    tarball = (str(target[0])+\".tar.gz\").replace('.rpm', '')\n    try:\n        tarball = env['SOURCE_URL'].split('/')[-1]\n    except KeyError as e:\n        raise SCons.Errors.UserError( \"Missing PackageTag '%s' for RPM packager\" % e.args[0] )\n\n    tarball = src_targz.package(env, source=sources, target=tarball,\n                                PACKAGEROOT=env['PACKAGEROOT'], )\n\n    return (target, tarball)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_specfile(target, source, env):\n    file = open(target[0].get_abspath(), 'w')\n\n    try:\n        file.write( build_specfile_header(env) )\n        file.write( build_specfile_sections(env) )\n        file.write( build_specfile_filesection(env, source) )\n        file.close()\n\n        # call a user specified function\n        if 'CHANGE_SPECFILE' in env:\n            env['CHANGE_SPECFILE'](target, source)\n\n    except KeyError as e:\n        raise SCons.Errors.UserError( '\"%s\" package field for RPM is missing.' % e.args[0] )", "response": "Builds a RPM specfile from a dictionary with string metadata and\n    by analyzing a tree of nodes and analyzing the tree of nodes and writing the contents of the nodes to the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the sections of a rpm specfile.", "response": "def build_specfile_sections(spec):\n    \"\"\" Builds the sections of a rpm specfile.\n    \"\"\"\n    str = \"\"\n\n    mandatory_sections = {\n        'DESCRIPTION'  : '\\n%%description\\n%s\\n\\n', }\n\n    str = str + SimpleTagCompiler(mandatory_sections).compile( spec )\n\n    optional_sections = {\n        'DESCRIPTION_'        : '%%description -l %s\\n%s\\n\\n',\n        'CHANGELOG'           : '%%changelog\\n%s\\n\\n',\n        'X_RPM_PREINSTALL'    : '%%pre\\n%s\\n\\n',\n        'X_RPM_POSTINSTALL'   : '%%post\\n%s\\n\\n',\n        'X_RPM_PREUNINSTALL'  : '%%preun\\n%s\\n\\n',\n        'X_RPM_POSTUNINSTALL' : '%%postun\\n%s\\n\\n',\n        'X_RPM_VERIFY'        : '%%verify\\n%s\\n\\n',\n\n        # These are for internal use but could possibly be overridden\n        'X_RPM_PREP'          : '%%prep\\n%s\\n\\n',\n        'X_RPM_BUILD'         : '%%build\\n%s\\n\\n',\n        'X_RPM_INSTALL'       : '%%install\\n%s\\n\\n',\n        'X_RPM_CLEAN'         : '%%clean\\n%s\\n\\n',\n        }\n\n    # Default prep, build, install and clean rules\n    # TODO: optimize those build steps, to not compile the project a second time\n    if 'X_RPM_PREP' not in spec:\n        spec['X_RPM_PREP'] = '[ -n \"$RPM_BUILD_ROOT\" -a \"$RPM_BUILD_ROOT\" != / ] && rm -rf \"$RPM_BUILD_ROOT\"' + '\\n%setup -q'\n\n    if 'X_RPM_BUILD' not in spec:\n        spec['X_RPM_BUILD'] = '[ ! -e \"$RPM_BUILD_ROOT\" -a \"$RPM_BUILD_ROOT\" != / ] && mkdir \"$RPM_BUILD_ROOT\"'\n\n    if 'X_RPM_INSTALL' not in spec:\n        spec['X_RPM_INSTALL'] = 'scons --install-sandbox=\"$RPM_BUILD_ROOT\" \"$RPM_BUILD_ROOT\"'\n\n    if 'X_RPM_CLEAN' not in spec:\n        spec['X_RPM_CLEAN'] = '[ -n \"$RPM_BUILD_ROOT\" -a \"$RPM_BUILD_ROOT\" != / ] && rm -rf \"$RPM_BUILD_ROOT\"'\n\n    str = str + SimpleTagCompiler(optional_sections, mandatory=0).compile( spec )\n\n    return str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_specfile_header(spec):\n    str = \"\"\n\n    # first the mandatory sections\n    mandatory_header_fields = {\n        'NAME'           : '%%define name %s\\nName: %%{name}\\n',\n        'VERSION'        : '%%define version %s\\nVersion: %%{version}\\n',\n        'PACKAGEVERSION' : '%%define release %s\\nRelease: %%{release}\\n',\n        'X_RPM_GROUP'    : 'Group: %s\\n',\n        'SUMMARY'        : 'Summary: %s\\n',\n        'LICENSE'        : 'License: %s\\n', }\n\n    str = str + SimpleTagCompiler(mandatory_header_fields).compile( spec )\n\n    # now the optional tags\n    optional_header_fields = {\n        'VENDOR'              : 'Vendor: %s\\n',\n        'X_RPM_URL'           : 'Url: %s\\n',\n        'SOURCE_URL'          : 'Source: %s\\n',\n        'SUMMARY_'            : 'Summary(%s): %s\\n',\n        'X_RPM_DISTRIBUTION'  : 'Distribution: %s\\n',\n        'X_RPM_ICON'          : 'Icon: %s\\n',\n        'X_RPM_PACKAGER'      : 'Packager: %s\\n',\n        'X_RPM_GROUP_'        : 'Group(%s): %s\\n',\n\n        'X_RPM_REQUIRES'      : 'Requires: %s\\n',\n        'X_RPM_PROVIDES'      : 'Provides: %s\\n',\n        'X_RPM_CONFLICTS'     : 'Conflicts: %s\\n',\n        'X_RPM_BUILDREQUIRES' : 'BuildRequires: %s\\n',\n\n        'X_RPM_SERIAL'        : 'Serial: %s\\n',\n        'X_RPM_EPOCH'         : 'Epoch: %s\\n',\n        'X_RPM_AUTOREQPROV'   : 'AutoReqProv: %s\\n',\n        'X_RPM_EXCLUDEARCH'   : 'ExcludeArch: %s\\n',\n        'X_RPM_EXCLUSIVEARCH' : 'ExclusiveArch: %s\\n',\n        'X_RPM_PREFIX'        : 'Prefix: %s\\n',\n\n        # internal use\n        'X_RPM_BUILDROOT'     : 'BuildRoot: %s\\n', }\n\n    # fill in default values:\n    # Adding a BuildRequires renders the .rpm unbuildable under System, which\n    # are not managed by rpm, since the database to resolve this dependency is\n    # missing (take Gentoo as an example)\n#    if not s.has_key('x_rpm_BuildRequires'):\n#        s['x_rpm_BuildRequires'] = 'scons'\n\n    if 'X_RPM_BUILDROOT' not in spec:\n        spec['X_RPM_BUILDROOT'] = '%{_tmppath}/%{name}-%{version}-%{release}'\n\n    str = str + SimpleTagCompiler(optional_header_fields, mandatory=0).compile( spec )\n    return str", "response": "Builds the header of the rpm specfile"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_specfile_filesection(spec, files):\n    str  = '%files\\n'\n\n    if 'X_RPM_DEFATTR' not in spec:\n        spec['X_RPM_DEFATTR'] = '(-,root,root)'\n\n    str = str + '%%defattr %s\\n' % spec['X_RPM_DEFATTR']\n\n    supported_tags = {\n        'PACKAGING_CONFIG'           : '%%config %s',\n        'PACKAGING_CONFIG_NOREPLACE' : '%%config(noreplace) %s',\n        'PACKAGING_DOC'              : '%%doc %s',\n        'PACKAGING_UNIX_ATTR'        : '%%attr %s',\n        'PACKAGING_LANG_'            : '%%lang(%s) %s',\n        'PACKAGING_X_RPM_VERIFY'     : '%%verify %s',\n        'PACKAGING_X_RPM_DIR'        : '%%dir %s',\n        'PACKAGING_X_RPM_DOCDIR'     : '%%docdir %s',\n        'PACKAGING_X_RPM_GHOST'      : '%%ghost %s', }\n\n    for file in files:\n        # build the tagset\n        tags = {}\n        for k in list(supported_tags.keys()):\n            try:\n                v = file.GetTag(k)\n                if v:\n                    tags[k] = v\n            except AttributeError:\n                pass\n\n        # compile the tagset\n        str = str + SimpleTagCompiler(supported_tags, mandatory=0).compile( tags )\n\n        str = str + ' '\n        str = str + file.GetTag('PACKAGING_INSTALL_LOCATION')\n        str = str + '\\n\\n'\n\n    return str", "response": "builds the %file section of the specfile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string containing the result of the tagset compiles the tagset and returns the result of the tagset compiles the result and returns the result", "response": "def compile(self, values):\n        \"\"\" Compiles the tagset and returns a str containing the result\n        \"\"\"\n        def is_international(tag):\n            return tag.endswith('_')\n\n        def get_country_code(tag):\n            return tag[-2:]\n\n        def strip_country_code(tag):\n            return tag[:-2]\n\n        replacements = list(self.tagset.items())\n\n        str = \"\"\n        domestic = [t for t in replacements if not is_international(t[0])]\n        for key, replacement in domestic:\n            try:\n                str = str + replacement % values[key]\n            except KeyError as e:\n                if self.mandatory:\n                    raise e\n\n        international = [t for t in replacements if is_international(t[0])]\n        for key, replacement in international:\n            try:\n                x = [t for t in values.items() if strip_country_code(t[0]) == key]\n                int_values_for_key = [(get_country_code(t[0]),t[1]) for t in x]\n                for v in int_values_for_key:\n                    str = str + replacement % v\n            except KeyError as e:\n                if self.mandatory:\n                    raise e\n\n        return str"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate(env):\n    fscan = FortranScan(\"FORTRANPATH\")\n    SCons.Tool.SourceFileScanner.add_scanner('.i', fscan)\n    SCons.Tool.SourceFileScanner.add_scanner('.i90', fscan)\n\n    if 'FORTRANFILESUFFIXES' not in env:\n        env['FORTRANFILESUFFIXES'] = ['.i']\n    else:\n        env['FORTRANFILESUFFIXES'].append('.i')\n\n    if 'F90FILESUFFIXES' not in env:\n        env['F90FILESUFFIXES'] = ['.i90']\n    else:\n        env['F90FILESUFFIXES'].append('.i90')\n\n    add_all_to_env(env)\n\n    env['FORTRAN']        = 'ifl'\n    env['SHFORTRAN']      = '$FORTRAN'\n    env['FORTRANCOM']     = '$FORTRAN $FORTRANFLAGS $_FORTRANINCFLAGS /c $SOURCES /Fo$TARGET'\n    env['FORTRANPPCOM']   = '$FORTRAN $FORTRANFLAGS $CPPFLAGS $_CPPDEFFLAGS $_FORTRANINCFLAGS /c $SOURCES /Fo$TARGET'\n    env['SHFORTRANCOM']   = '$SHFORTRAN $SHFORTRANFLAGS $_FORTRANINCFLAGS /c $SOURCES /Fo$TARGET'\n    env['SHFORTRANPPCOM'] = '$SHFORTRAN $SHFORTRANFLAGS $CPPFLAGS $_CPPDEFFLAGS $_FORTRANINCFLAGS /c $SOURCES /Fo$TARGET'", "response": "Add Builders and construction variables for ifl to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Builders and construction variables for bcc to an Environment.", "response": "def generate(env):\n    findIt('bcc32', env)\n    \"\"\"Add Builders and construction variables for bcc to an\n    Environment.\"\"\"\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n    for suffix in ['.c', '.cpp']:\n        static_obj.add_action(suffix, SCons.Defaults.CAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ShCAction)\n        static_obj.add_emitter(suffix, SCons.Defaults.StaticObjectEmitter)\n        shared_obj.add_emitter(suffix, SCons.Defaults.SharedObjectEmitter)\n\n    env['CC']        = 'bcc32'\n    env['CCFLAGS']   = SCons.Util.CLVar('')\n    env['CFLAGS']   = SCons.Util.CLVar('')\n    env['CCCOM']     = '$CC -q $CFLAGS $CCFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS -c -o$TARGET $SOURCES'\n    env['SHCC']      = '$CC'\n    env['SHCCFLAGS'] = SCons.Util.CLVar('$CCFLAGS')\n    env['SHCFLAGS'] = SCons.Util.CLVar('$CFLAGS')\n    env['SHCCCOM']   = '$SHCC -WD $SHCFLAGS $SHCCFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS -c -o$TARGET $SOURCES'\n    env['CPPDEFPREFIX']  = '-D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '-I'\n    env['INCSUFFIX']  = ''\n    env['SHOBJSUFFIX'] = '.dll'\n    env['STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME'] = 0\n    env['CFILESUFFIX'] = '.cpp'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef require(builder_name):\n\n    reg = ComponentRegistry()\n    for _name, autobuild_func in reg.load_extensions('iotile.autobuild', name_filter=builder_name):\n        return autobuild_func\n\n    raise BuildError('Cannot find required autobuilder, make sure the distribution providing it is installed',\n                     name=builder_name)", "response": "Find an advertised autobuilder and return it"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autobuild_onlycopy():\n    try:\n        # Build only release information\n        family = utilities.get_family('module_settings.json')\n        autobuild_release(family)\n\n        Alias('release', os.path.join('build', 'output'))\n        Default(['release'])\n    except unit_test.IOTileException as e:\n        print(e.format())\n        Exit(1)", "response": "Autobuild a project that does not require building firmware pcb or documentation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autobuild_release(family=None):\n\n    if family is None:\n        family = utilities.get_family('module_settings.json')\n\n    env = Environment(tools=[])\n    env['TILE'] = family.tile\n\n    target = env.Command(['#build/output/module_settings.json'], ['#module_settings.json'],\n                         action=env.Action(create_release_settings_action, \"Creating release manifest\"))\n    env.AlwaysBuild(target)\n\n    # Copy over release notes if they exist\n    if os.path.exists('RELEASE.md'):\n        env.Command(['build/output/RELEASE.md'], ['RELEASE.md'], Copy(\"$TARGET\", \"$SOURCE\"))\n\n    # Now copy across the build products that are not copied automatically\n    copy_include_dirs(family.tile)\n    copy_tilebus_definitions(family.tile)\n    copy_dependency_docs(family.tile)\n    copy_linker_scripts(family.tile)\n\n    # Allow users to specify a hide_dependency_images flag that does not copy over all firmware images\n    if not family.tile.settings.get('hide_dependency_images', False):\n        copy_dependency_images(family.tile)\n\n    copy_extra_files(family.tile)\n    build_python_distribution(family.tile)", "response": "Automatically builds a new release manifest."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds an ARM module for all targets and build all unit tests.", "response": "def autobuild_arm_program(elfname, test_dir=os.path.join('firmware', 'test'), patch=True):\n    \"\"\"\n    Build the an ARM module for all targets and build all unit tests. If pcb files are given, also build those.\n    \"\"\"\n\n    try:\n        #Build for all targets\n        family = utilities.get_family('module_settings.json')\n        family.for_all_targets(family.tile.short_name, lambda x: arm.build_program(family.tile, elfname, x, patch=patch))\n\n        #Build all unit tests\n        unit_test.build_units(os.path.join('firmware','test'), family.targets(family.tile.short_name))\n\n        Alias('release', os.path.join('build', 'output'))\n        Alias('test', os.path.join('build', 'test', 'output'))\n        Default(['release', 'test'])\n\n        autobuild_release(family)\n\n        if os.path.exists('doc'):\n            autobuild_documentation(family.tile)\n\n    except IOTileException as e:\n        print(e.format())\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef autobuild_doxygen(tile):\n\n    iotile = IOTile('.')\n\n    doxydir = os.path.join('build', 'doc')\n    doxyfile = os.path.join(doxydir, 'doxygen.txt')\n\n    outfile = os.path.join(doxydir, '%s.timestamp' % tile.unique_id)\n    env = Environment(ENV=os.environ, tools=[])\n    env['IOTILE'] = iotile\n\n    # There is no /dev/null on Windows\n    if platform.system() == 'Windows':\n        action = 'doxygen %s > NUL' % doxyfile\n    else:\n        action = 'doxygen %s > /dev/null' % doxyfile\n\n    Alias('doxygen', doxydir)\n    env.Clean(outfile, doxydir)\n\n    inputfile = doxygen_source_path()\n\n    env.Command(doxyfile, inputfile, action=env.Action(lambda target, source, env: generate_doxygen_file(str(target[0]), iotile), \"Creating Doxygen Config File\"))\n    env.Command(outfile, doxyfile, action=env.Action(action, \"Building Firmware Documentation\"))", "response": "Generate documentation for firmware in this module using doxygen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autobuild_documentation(tile):\n\n    docdir = os.path.join('#doc')\n    docfile = os.path.join(docdir, 'conf.py')\n    outdir = os.path.join('build', 'output', 'doc', tile.unique_id)\n    outfile = os.path.join(outdir, '%s.timestamp' % tile.unique_id)\n\n    env = Environment(ENV=os.environ, tools=[])\n\n    # Only build doxygen documentation if we have C firmware to build from\n    if os.path.exists('firmware'):\n        autobuild_doxygen(tile)\n        env.Depends(outfile, 'doxygen')\n\n    # There is no /dev/null on Windows\n    # Also disable color output on Windows since it seems to leave powershell\n    # in a weird state.\n    if platform.system() == 'Windows':\n        action = 'sphinx-build --no-color -b html %s %s > NUL' % (docdir[1:], outdir)\n    else:\n        action = 'sphinx-build -b html %s %s > /dev/null' % (docdir[1:], outdir)\n\n    env.Command(outfile, docfile, action=env.Action(action, \"Building Component Documentation\"))\n    Alias('documentation', outdir)\n    env.Clean(outfile, outdir)", "response": "Generate documentation for this module using a combination of sphinx and breathe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autobuild_trub_script(file_name, slot_assignments=None, os_info=None, sensor_graph=None,\n                          app_info=None, use_safeupdate=False):\n    \"\"\"Build a trub script that loads given firmware into the given slots.\n\n    slot_assignments should be a list of tuples in the following form:\n    (\"slot X\" or \"controller\", firmware_image_name)\n\n    The output of this autobuild action will be a trub script in\n    build/output/<file_name> that assigns the given firmware to each slot in\n    the order specified in the slot_assignments list.\n\n    Args:\n        file_name (str): The name of the output file that we should create.\n            This file name should end in .trub\n        slot_assignments (list of (str, str)): A list of tuples containing\n            the slot name and the firmware image that we should use to build\n            our update script. Optional\n        os_info (tuple(int, str)): A tuple of OS version tag and X.Y version\n            number that will be set as part of the OTA script if included. Optional.\n        sensor_graph (str): Name of sgf file. Optional.\n        app_info (tuple(int, str)): A tuple of App version tag and X.Y version\n            number that will be set as part of the OTA script if included. Optional.\n        use_safeupdate (bool): If True, Enables safemode before the firmware update records, then\n            disables them after the firmware update records.\n    \"\"\"\n\n    build_update_script(file_name, slot_assignments, os_info, sensor_graph, app_info, use_safeupdate)", "response": "Build a trub script that loads given firmware into the given slots."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncombine multiple firmware images into a single bootstrap hex file.", "response": "def autobuild_bootstrap_file(file_name, image_list):\n    \"\"\"Combine multiple firmware images into a single bootstrap hex file.\n\n    The files listed in image_list must be products of either this tile or any\n    dependency tile and should correspond exactly with the base name listed on\n    the products section of the module_settings.json file of the corresponding\n    tile.  They must be listed as firmware_image type products.\n\n    This function keeps a global map of all of the intermediate files that it\n    has had to create so that we don't try to build them multiple times.\n\n    Args:\n        file_name(str): Full name of the output bootstrap hex file.\n        image_list(list of str): List of files that will be combined into a\n            single hex file that will be used to flash a chip.\n    \"\"\"\n\n    family = utilities.get_family('module_settings.json')\n    target = family.platform_independent_target()\n    resolver = ProductResolver.Create()\n\n    env = Environment(tools=[])\n\n    output_dir = target.build_dirs()['output']\n    build_dir = target.build_dirs()['build']\n\n    build_output_name = os.path.join(build_dir, file_name)\n    full_output_name = os.path.join(output_dir, file_name)\n\n    processed_input_images = []\n\n    for image_name in image_list:\n        image_info = resolver.find_unique('firmware_image', image_name)\n        image_path = image_info.full_path\n\n        hex_path = arm.ensure_image_is_hex(image_path)\n        processed_input_images.append(hex_path)\n\n    env.Command(build_output_name, processed_input_images,\n                action=Action(arm.merge_hex_executables,\n                              \"Merging %d hex files into $TARGET\" % len(processed_input_images)))\n    env.Command(full_output_name, build_output_name, Copy(\"$TARGET\", \"$SOURCE\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_identifier(self, name, obj):\n\n        name = str(name)\n        self._known_identifiers[name] = obj", "response": "Add a known identifier resolution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves an identifier to an object.", "response": "def resolve_identifier(self, name, expected_type=None):\n        \"\"\"Resolve an identifier to an object.\n\n        There is a single namespace for identifiers so the user also should\n        pass an expected type that will be checked against what the identifier\n        actually resolves to so that there are no surprises.\n\n        Args:\n            name (str): The name that we want to resolve\n            expected_type (type): The type of object that we expect to receive.\n                This is an optional parameter.  If None is passed, no type checking\n                is performed.\n\n        Returns:\n            object: The resolved object\n        \"\"\"\n\n        name = str(name)\n\n        if name in self._known_identifiers:\n            obj = self._known_identifiers[name]\n            if expected_type is not None and not isinstance(obj, expected_type):\n                raise UnresolvedIdentifierError(u\"Identifier resolved to an object of an unexpected type\", name=name, expected_type=expected_type.__name__, resolved_type=obj.__class__.__name__)\n\n            return obj\n\n        if self.parent is not None:\n            try:\n                return self.parent.resolve_identifier(name)\n            except UnresolvedIdentifierError:\n                pass\n\n        raise UnresolvedIdentifierError(u\"Could not resolve identifier\", name=name, scope=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating an instance of the report format from a list of readings and a uuid.", "response": "def FromReadings(cls, uuid, readings, root_key=AuthProvider.NoKey, signer=None,\n                     report_id=IOTileReading.InvalidReadingID, selector=0xFFFF, streamer=0, sent_timestamp=0):\n        \"\"\"Generate an instance of the report format from a list of readings and a uuid.\n\n        The signed list report is created using the passed readings and signed using the specified method\n        and AuthProvider.  If no auth provider is specified, the report is signed using the default authorization\n        chain.\n\n        Args:\n            uuid (int): The uuid of the deviec that this report came from\n            readings (list): A list of IOTileReading objects containing the data in the report\n            root_key (int): The key that should be used to sign the report (must be supported\n                by an auth_provider)\n            signer (AuthProvider): An optional preconfigured AuthProvider that should be used to sign this\n                report.  If no AuthProvider is provided, the default ChainedAuthProvider is used.\n            report_id (int): The id of the report.  If not provided it defaults to IOTileReading.InvalidReadingID.\n                Note that you can specify anything you want for the report id but for actual IOTile devices\n                the report id will always be greater than the id of all of the readings contained in the report\n                since devices generate ids sequentially.\n            selector (int): The streamer selector of this report.  This can be anything but if the report came from\n                a device, it would correspond with the query the device used to pick readings to go into the report.\n            streamer (int): The streamer id that this reading was sent from.\n            sent_timestamp (int): The device's uptime that sent this report.\n        \"\"\"\n\n        lowest_id = IOTileReading.InvalidReadingID\n        highest_id = IOTileReading.InvalidReadingID\n\n        report_len = 20 + 16*len(readings) + 24\n        len_low = report_len & 0xFF\n        len_high = report_len >> 8\n\n        unique_readings = [x.reading_id for x in readings if x.reading_id != IOTileReading.InvalidReadingID]\n        if len(unique_readings) > 0:\n            lowest_id = min(unique_readings)\n            highest_id = max(unique_readings)\n\n        header = struct.pack(\"<BBHLLLBBH\", cls.ReportType, len_low, len_high, uuid, report_id,\n                             sent_timestamp, root_key, streamer, selector)\n        header = bytearray(header)\n\n        packed_readings = bytearray()\n\n        for reading in readings:\n            packed_reading = struct.pack(\"<HHLLL\", reading.stream, 0, reading.reading_id,\n                                         reading.raw_time, reading.value)\n            packed_readings += bytearray(packed_reading)\n\n        footer_stats = struct.pack(\"<LL\", lowest_id, highest_id)\n\n        if signer is None:\n            signer = ChainedAuthProvider()\n\n        # If we are supposed to encrypt this report, do the encryption\n        if root_key != signer.NoKey:\n            enc_data = packed_readings\n\n            try:\n                result = signer.encrypt_report(uuid, root_key, enc_data, report_id=report_id,\n                                               sent_timestamp=sent_timestamp)\n            except NotFoundError:\n                raise ExternalError(\"Could not encrypt report because no AuthProvider supported \"\n                                    \"the requested encryption method for the requested device\",\n                                    device_id=uuid, root_key=root_key)\n\n            signed_data = header + result['data'] + footer_stats\n        else:\n            signed_data = header + packed_readings + footer_stats\n\n        try:\n            signature = signer.sign_report(uuid, root_key, signed_data, report_id=report_id,\n                                           sent_timestamp=sent_timestamp)\n        except NotFoundError:\n            raise ExternalError(\"Could not sign report because no AuthProvider supported the requested \"\n                                \"signature method for the requested device\", device_id=uuid, root_key=root_key)\n\n        footer = struct.pack(\"16s\", bytes(signature['signature'][:16]))\n        footer = bytearray(footer)\n\n        data = signed_data + footer\n        return SignedListReport(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode(self):\n\n        fmt, len_low, len_high, device_id, report_id, sent_timestamp, signature_flags, \\\n        origin_streamer, streamer_selector = unpack(\"<BBHLLLBBH\", self.raw_report[:20])\n\n        assert fmt == 1\n        length = (len_high << 8) | len_low\n\n        self.origin = device_id\n        self.report_id = report_id\n        self.sent_timestamp = sent_timestamp\n        self.origin_streamer = origin_streamer\n        self.streamer_selector = streamer_selector\n        self.signature_flags = signature_flags\n\n        assert len(self.raw_report) == length\n\n        remaining = self.raw_report[20:]\n        assert len(remaining) >= 24\n        readings = remaining[:-24]\n        footer = remaining[-24:]\n\n        lowest_id, highest_id, signature = unpack(\"<LL16s\", footer)\n        signature = bytearray(signature)\n\n        self.lowest_id = lowest_id\n        self.highest_id = highest_id\n        self.signature = signature\n\n        signed_data = self.raw_report[:-16]\n        signer = ChainedAuthProvider()\n\n        if signature_flags == AuthProvider.NoKey:\n            self.encrypted = False\n        else:\n            self.encrypted = True\n\n        try:\n            verification = signer.verify_report(device_id, signature_flags, signed_data, signature,\n                                                report_id=report_id, sent_timestamp=sent_timestamp)\n            self.verified = verification['verified']\n        except NotFoundError:\n            self.verified = False\n\n        # If we were not able to verify the report, do not try to parse or decrypt it since we\n        # can't guarantee who it came from.\n        if not self.verified:\n            return [], []\n\n        # If the report is encrypted, try to decrypt it before parsing the readings\n        if self.encrypted:\n            try:\n                result = signer.decrypt_report(device_id, signature_flags, readings,\n                                               report_id=report_id, sent_timestamp=sent_timestamp)\n                readings = result['data']\n            except NotFoundError:\n                return [], []\n\n        # Now parse all of the readings\n        # Make sure this report has an integer number of readings\n        assert (len(readings) % 16) == 0\n\n        time_base = self.received_time - datetime.timedelta(seconds=sent_timestamp)\n        parsed_readings = []\n\n        for i in range(0, len(readings), 16):\n            reading = readings[i:i+16]\n            stream, _, reading_id, timestamp, value = unpack(\"<HHLLL\", reading)\n\n            parsed = IOTileReading(timestamp, stream, value, time_base=time_base, reading_id=reading_id)\n            parsed_readings.append(parsed)\n\n        return parsed_readings, []", "response": "Decode this report into a list of readings and a list of readings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_property(self, name, default_value):\n\n        name = str(name)\n        self._properties[name] = default_value", "response": "Add a device property with a given default value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(self, name, value):\n\n        name = str(name)\n        if name not in self._properties:\n            raise ArgumentError(\"Unknown property in DeviceModel\", name=name)\n\n        self._properties[name] = value", "response": "Set a property in a device model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, name):\n\n        name = str(name)\n        if name not in self._properties:\n            raise ArgumentError(\"Unknown property in DeviceModel\", name=name)\n\n        return self._properties[name]", "response": "Get a device model property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a typed value to a binary array", "response": "def _convert_to_bytes(type_name, value):\n    \"\"\"Convert a typed value to a binary array\"\"\"\n\n    int_types = {'uint8_t': 'B', 'int8_t': 'b', 'uint16_t': 'H', 'int16_t': 'h', 'uint32_t': 'L', 'int32_t': 'l'}\n\n    type_name = type_name.lower()\n\n    if type_name not in int_types and type_name not in ['string', 'binary']:\n        raise ArgumentError('Type must be a known integer type, integer type array, string', known_integers=int_types.keys(), actual_type=type_name)\n\n    if type_name == 'string':\n        #value should be passed as a string\n        bytevalue = bytes(value)\n    elif type_name == 'binary':\n        bytevalue = bytes(value)\n    else:\n        bytevalue = struct.pack(\"<%s\" % int_types[type_name], value)\n\n    return bytevalue"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_rpcs(self, address):\n\n        rpc_list = []\n\n        for offset in range(2, len(self.data), 16):\n            rpc = (address, rpcs.SET_CONFIG_VARIABLE, self.var_id, offset - 2, self.data[offset:offset + 16])\n            rpc_list.append(rpc)\n\n        return rpc_list", "response": "Generate the RPCs needed to stream this config variable to a tile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all invalid config entries.", "response": "def compact(self):\n        \"\"\"Remove all invalid config entries.\"\"\"\n\n        saved_length = 0\n        to_remove = []\n        for i, entry in enumerate(self.entries):\n            if not entry.valid:\n                to_remove.append(i)\n                saved_length += entry.data_space()\n\n        for i in reversed(to_remove):\n            del self.entries[i]\n\n        self.data_index -= saved_length"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbegins a new config database entry.", "response": "def start_entry(self, target, var_id):\n        \"\"\"Begin a new config database entry.\n\n        If there is a current entry in progress, it is aborted but the\n        data was already committed to persistent storage so that space\n        is wasted.\n\n        Args:\n            target (SlotIdentifer): The target slot for this config variable.\n            var_id (int): The config variable ID\n\n        Returns:\n            int: An error code from the global Errors enum.\n        \"\"\"\n\n        self.in_progress = ConfigEntry(target, var_id, b'')\n\n        if self.data_size - self.data_index < self.in_progress.data_space():\n            return Error.DESTINATION_BUFFER_TOO_SMALL\n\n        self.in_progress.data += struct.pack(\"<H\", var_id)\n        self.data_index += self.in_progress.data_space()\n\n        return Error.NO_ERROR"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds data to the currently in progress entry.", "response": "def add_data(self, data):\n        \"\"\"Add data to the currently in progress entry.\n\n        Args:\n            data (bytes): The data that we want to add.\n\n        Returns:\n            int: An error code\n        \"\"\"\n\n        if self.data_size - self.data_index < len(data):\n            return Error.DESTINATION_BUFFER_TOO_SMALL\n\n        if self.in_progress is not None:\n            self.in_progress.data += data\n\n        return Error.NO_ERROR"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfinish a previously started config database entry. This commits the currently in progress entry and adds the new data to the config database.", "response": "def end_entry(self):\n        \"\"\"Finish a previously started config database entry.\n\n        This commits the currently in progress entry.  The expected flow is\n        that start_entry() is called followed by 1 or more calls to add_data()\n        followed by a single call to end_entry().\n\n        Returns:\n            int: An error code\n        \"\"\"\n\n        # Matching current firmware behavior\n        if self.in_progress is None:\n            return Error.NO_ERROR\n\n        # Make sure there was actually data stored\n        if self.in_progress.data_space() == 2:\n            return Error.INPUT_BUFFER_WRONG_SIZE\n\n        # Invalidate all previous copies of this config variable so we\n        # can properly compact.\n        for entry in self.entries:\n            if entry.target == self.in_progress.target and entry.var_id == self.in_progress.var_id:\n                entry.valid = False\n\n        self.entries.append(self.in_progress)\n        self.data_index += self.in_progress.data_space() - 2  # Add in the rest of the entry size (we added two bytes at start_entry())\n        self.in_progress = None\n\n        return Error.NO_ERROR"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of RPCs needed to stream matching config variables to the given tile.", "response": "def stream_matching(self, address, name):\n        \"\"\"Return the RPCs needed to stream matching config variables to the given tile.\n\n        This function will return a list of tuples suitable for passing to\n        EmulatedDevice.deferred_rpc.\n\n        Args:\n            address (int): The address of the tile that we wish to stream to\n            name (str or bytes): The 6 character name of the target tile.\n\n        Returns:\n            list of tuple: The list of RPCs to send to stream these variables to a tile.\n        \"\"\"\n\n        matching = [x for x in self.entries if x.valid and x.target.matches(address, name)]\n\n        rpc_list = []\n        for var in matching:\n            rpc_list.extend(var.generate_rpcs(address))\n\n        return rpc_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_config_var_entry(self, var_id, encoded_selector):\n\n        selector = SlotIdentifier.FromEncoded(encoded_selector)\n\n        err = self.config_database.start_entry(selector, var_id)\n        return [err]", "response": "Start a new config variable entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the metadata from the selected config variable entry.", "response": "def get_config_var_entry(self, index):\n        \"\"\"Get the metadata from the selected config variable entry.\"\"\"\n\n        if index == 0 or index > len(self.config_database.entries):\n            return [Error.INVALID_ARRAY_KEY, 0, 0, 0, b'\\0'*8, 0, 0]\n\n        entry = self.config_database.entries[index - 1]\n        if not entry.valid:\n            return [ConfigDatabaseError.OBSOLETE_ENTRY, 0, 0, 0, b'\\0'*8, 0, 0]\n\n        offset = sum(x.data_space() for x in self.config_database.entries[:index - 1])\n        return [Error.NO_ERROR, self.config_database.ENTRY_MAGIC, offset, entry.data_space(), entry.target.encode(), 0xFF, 0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_config_var_data(self, index, offset):\n\n        if index == 0 or index > len(self.config_database.entries):\n            return [Error.INVALID_ARRAY_KEY, b'']\n\n        entry = self.config_database.entries[index - 1]\n        if not entry.valid:\n            return [ConfigDatabaseError.OBSOLETE_ENTRY, b'']\n\n        if offset >= len(entry.data):\n            return [Error.INVALID_ARRAY_KEY, b'']\n\n        data_chunk = entry.data[offset:offset + 16]\n        return [Error.NO_ERROR, data_chunk]", "response": "Get a chunk of data for a config variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmark a config variable as invalid.", "response": "def invalidate_config_var_entry(self, index):\n        \"\"\"Mark a config variable as invalid.\"\"\"\n\n        if index == 0 or index > len(self.config_database.entries):\n            return [Error.INVALID_ARRAY_KEY, b'']\n\n        entry = self.config_database.entries[index - 1]\n        if not entry.valid:\n            return [ConfigDatabaseError.OBSOLETE_ENTRY, b'']\n\n        entry.valid = False\n        return [Error.NO_ERROR]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_config_database_info(self):\n\n        max_size = self.config_database.data_size\n        max_entries = self.config_database.max_entries()\n        used_size = self.config_database.data_index\n        used_entries = len(self.config_database.entries)\n        invalid_size = sum(x.data_space() for x in self.config_database.entries if not x.valid)\n        invalid_entries = sum(1 for x in self.config_database.entries if not x.valid)\n\n        return [max_size, used_size, invalid_size, used_entries, invalid_entries, max_entries, 0]", "response": "Get memory usage and space statistics on the config database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind an installed VirtualTile by name.", "response": "def FindByName(cls, name):\n        \"\"\"Find an installed VirtualTile by name.\n\n        This function searches for installed virtual tiles\n        using the pkg_resources entry_point `iotile.virtual_tile`.\n\n        If name is a path ending in .py, it is assumed to point to\n        a module on disk and loaded directly rather than using\n        pkg_resources.\n\n        Args:\n            name (str): The name of the tile to search\n                for.\n\n        Returns:\n            VirtualTile class: A virtual tile subclass that can be\n                instantiated to create a virtual tile.\n        \"\"\"\n\n        if name.endswith('.py'):\n            return cls.LoadFromFile(name)\n\n        reg = ComponentRegistry()\n        for _name, tile in reg.load_extensions('iotile.virtual_tile', name_filter=name, class_filter=VirtualTile):\n            return tile\n\n        raise ArgumentError(\"VirtualTile could not be found by name\", name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef LoadFromFile(cls, script_path):\n\n        _name, dev = ComponentRegistry().load_extension(script_path, class_filter=VirtualTile, unique=True)\n        return dev", "response": "Loads a virtual tile from a file rather than an installed module."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstages python packages for release verifying everything we can about them.", "response": "def stage(self):\n        \"\"\"Stage python packages for release, verifying everything we can about them.\"\"\"\n\n        if 'PYPI_USER' not in os.environ or 'PYPI_PASS' not in os.environ:\n            raise BuildError(\"You must set the PYPI_USER and PYPI_PASS environment variables\")\n\n        try:\n            import twine\n        except ImportError:\n            raise BuildError(\"You must install twine in order to release python packages\",\n                             suggestion=\"pip install twine\")\n\n        if not self.component.has_wheel:\n            raise BuildError(\"You can't release a component to a PYPI repository if it doesn't have python packages\")\n\n        # Make sure we have built distributions ready to upload\n        wheel = self.component.support_wheel\n        sdist = \"%s-%s.tar.gz\" % (self.component.support_distribution, self.component.parsed_version.pep440_string())\n\n        wheel_path = os.path.realpath(os.path.abspath(os.path.join(self.component.output_folder, 'python', wheel)))\n        sdist_path = os.path.realpath(os.path.abspath(os.path.join(self.component.output_folder, 'python', sdist)))\n\n        if not os.path.isfile(wheel_path) or not os.path.isfile(sdist_path):\n            raise BuildError(\"Could not find built wheel or sdist matching current built version\",\n                             sdist_path=sdist_path, wheel_path=wheel_path)\n\n        self.dists = [sdist_path, wheel_path]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _upload_dists(self, repo, dists):\n\n        from twine.commands.upload import upload\n\n        if 'PYPI_USER' in os.environ and 'PYPI_PASS' in os.environ:\n            pypi_user = os.environ['PYPI_USER']\n            pypi_pass = os.environ['PYPI_PASS']\n        else:\n            pypi_user = None\n            pypi_pass = None\n\n        # Invoke upload this way since subprocess call of twine cli has cross platform issues\n        upload(dists, repo, False, None, pypi_user, pypi_pass, None, None, '~/.pypirc', False, None, None, None)", "response": "Upload a given set of distributions to pypi"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_data(self, data):\n\n        if self.state == self.ErrorState:\n            return\n\n        self.raw_data += bytearray(data)\n\n        still_processing = True\n        while still_processing:\n            still_processing = self.process_data()", "response": "Add data to our stream emitting reports as each new one is seen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_data(self):\n\n        further_processing = False\n\n        if self.state == self.WaitingForReportType and len(self.raw_data) > 0:\n            self.current_type = self.raw_data[0]\n\n            try:\n                self.current_header_size = self.calculate_header_size(self.current_type)\n                self.state = self.WaitingForReportHeader\n                further_processing = True\n            except Exception as exc:\n                self.state = self.ErrorState\n\n                if self.error_callback:\n                    self.error_callback(self.ErrorFindingReportType, str(exc), self.context)\n                else:\n                    raise\n\n        if self.state == self.WaitingForReportHeader and len(self.raw_data) >= self.current_header_size:\n            try:\n                self.current_report_size = self.calculate_report_size(self.current_type,\n                                                                      self.raw_data[:self.current_header_size])\n                self.state = self.WaitingForCompleteReport\n                further_processing = True\n            except Exception as exc:\n                self.state = self.ErrorState\n\n                if self.error_callback:\n                    self.error_callback(self.ErrorParsingReportHeader, str(exc), self.context)\n                else:\n                    raise\n\n        if self.state == self.WaitingForCompleteReport and len(self.raw_data) >= self.current_report_size:\n            try:\n                report_data = self.raw_data[:self.current_report_size]\n                self.raw_data = self.raw_data[self.current_report_size:]\n\n                report = self.parse_report(self.current_type, report_data)\n                self._handle_report(report)\n                self.state = self.WaitingForReportType\n                further_processing = True\n            except Exception as exc:\n                self.state = self.ErrorState\n\n                if self.error_callback:\n                    self.error_callback(self.ErrorParsingCompleteReport, str(exc), self.context)\n                else:\n                    raise\n\n        return further_processing", "response": "Attempts to extract a report from the current data stream contents and processes it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_report_size(self, current_type, report_header):\n\n        fmt = self.known_formats[current_type]\n        return fmt.ReportLength(report_header)", "response": "Determine the size of a report given its type and header"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_report(self, current_type, report_data):\n\n        fmt = self.known_formats[current_type]\n        return fmt(report_data)", "response": "Parse a report into an IOTileReport subclass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_report(self, report):\n\n        keep_report = True\n\n        if self.report_callback is not None:\n            keep_report = self.report_callback(report, self.context)\n\n        if keep_report:\n            self.reports.append(report)", "response": "Handle a report and keep a copy of it"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the flag to be used when we run * msginit ( 1)* in non - interactive mode.", "response": "def _optional_no_translator_flag(env):\n  \"\"\" Return '--no-translator' flag if we run *msginit(1)*  in non-interactive\n      mode.\"\"\"\n  import SCons.Util\n  if 'POAUTOINIT' in env:\n    autoinit = env['POAUTOINIT']\n  else:\n    autoinit = False\n  if autoinit:\n    return [SCons.Util.CLVar('--no-translator')]\n  else:\n    return [SCons.Util.CLVar('')]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a POInit builder object.", "response": "def _POInitBuilder(env, **kw):\n  \"\"\" Create builder object for `POInit` builder. \"\"\"\n  import SCons.Action\n  from SCons.Tool.GettextCommon import _init_po_files, _POFileBuilder\n  action = SCons.Action.Action(_init_po_files, None)\n  return _POFileBuilder(env, action=action, target_alias='$POCREATE_ALIAS')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _POInitBuilderWrapper(env, target=None, source=_null, **kw):\n  if source is _null:\n    if 'POTDOMAIN' in kw:\n      domain = kw['POTDOMAIN']\n    elif 'POTDOMAIN' in env:\n      domain = env['POTDOMAIN']\n    else:\n      domain = 'messages'\n    source = [ domain ] # NOTE: Suffix shall be appended automatically\n  return env._POInitBuilder(target, source, **kw)", "response": "Wrapper for _POFileBuilder. We use it to make user's life easier.\n  \n  This wrapper checks for `$POTDOMAIN` construction variable (or override in\n  `**kw`) and treats it appropriatelly."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(env,**kw):\n  import SCons.Util\n  from SCons.Tool.GettextCommon import _detect_msginit\n  try:\n    env['MSGINIT'] = _detect_msginit(env)\n  except:\n    env['MSGINIT'] = 'msginit'\n  msginitcom = '$MSGINIT ${_MSGNoTranslator(__env__)} -l ${_MSGINITLOCALE}' \\\n             + ' $MSGINITFLAGS -i $SOURCE -o $TARGET'\n  # NOTE: We set POTSUFFIX here, in case the 'xgettext' is not loaded\n  #       (sometimes we really don't need it)\n  env.SetDefault(\n    POSUFFIX = ['.po'],\n    POTSUFFIX = ['.pot'],\n    _MSGINITLOCALE = '${TARGET.filebase}',\n    _MSGNoTranslator = _optional_no_translator_flag,\n    MSGINITCOM = msginitcom,\n    MSGINITCOMSTR = '',\n    MSGINITFLAGS = [ ],\n    POAUTOINIT = False,\n    POCREATE_ALIAS = 'po-create'\n  )\n  env.Append( BUILDERS = { '_POInitBuilder' : _POInitBuilder(env) } )\n  env.AddMethod(_POInitBuilderWrapper, 'POInit')\n  env.AlwaysBuild(env.Alias('$POCREATE_ALIAS'))", "response": "Generate the msginit tool"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(env):\n    path, _cxx, version = get_xlc(env)\n    if path and _cxx:\n        _cxx = os.path.join(path, _cxx)\n\n    if 'CXX' not in env:\n        env['CXX'] = _cxx\n\n    cplusplus.generate(env)\n\n    if version:\n        env['CXXVERSION'] = version", "response": "Add Builders and construction variables for xlC / Visual Age\n    suite to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    cc.generate(env)\n\n    env['CC']         = 'icc'\n    env['CCCOM']      = '$CC $CFLAGS $CCFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS /c $SOURCES /Fo$TARGET'\n    env['CXXCOM']     = '$CXX $CXXFLAGS $CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS /c $SOURCES /Fo$TARGET'\n    env['CPPDEFPREFIX']  = '/D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '/I'\n    env['INCSUFFIX']  = ''\n    env['CFILESUFFIX'] = '.c'\n    env['CXXFILESUFFIX'] = '.cc'", "response": "Add Builders and construction variables for the OS / 2 utility to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open_bled112(port, logger):\n\n    if port is not None and port != '<auto>':\n        logger.info(\"Using BLED112 adapter at %s\", port)\n        return serial.Serial(port, _BAUD_RATE, timeout=0.01, rtscts=True, exclusive=True)\n\n    return _find_available_bled112(logger)", "response": "Open a BLED112 adapter either by name or the first available."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of the available and powered BLE controllers", "response": "def _find_ble_controllers(self):\n        \"\"\"Get a list of the available and powered BLE controllers\"\"\"\n        controllers = self.bable.list_controllers()\n        return [ctrl for ctrl in controllers if ctrl.powered and ctrl.low_energy]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the device adapter by removing all active connections and resetting scan and advertising to have a clean starting state.", "response": "def _initialize_system_sync(self):\n        \"\"\"Initialize the device adapter by removing all active connections and resetting scan and advertising to have\n        a clean starting state.\"\"\"\n        connected_devices = self.bable.list_connected_devices()\n        for device in connected_devices:\n            context = {\n                'connection_id': len(self.connections.get_connections()),\n                'connection_handle': device.connection_handle,\n                'connection_string': device.address\n            }\n            self.connections.add_connection(context['connection_id'], device.address, context)\n            self.disconnect_sync(context['connection_id'])\n\n        self.stop_scan()\n\n        try:\n            self.bable.set_advertising(enabled=False)\n        except bable_interface.BaBLEException:\n            # If advertising is already disabled\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_scan(self, active):\n        try:\n            self.bable.start_scan(self._on_device_found, active_scan=active, sync=True)\n        except bable_interface.BaBLEException as err:\n            # If we are already scanning, raise an error only we tried to change the active scan param\n            if self._active_scan != active:\n                raise err\n\n        self._active_scan = active\n        self.scanning = True", "response": "Start a scan. Will call self. _on_device_found for each device found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to a device by its connection_string and calls callback when finished.", "response": "def connect_async(self, connection_id, connection_string, callback, retries=4, context=None):\n        \"\"\"Connect to a device by its connection_string\n\n        This function asynchronously connects to a device by its BLE address + address type passed in the\n        connection_string parameter and calls callback when finished. Callback is called on either success\n        or failure with the signature:\n            callback(connection_id: int, result: bool, value: None)\n        The optional retries argument specifies how many times we should retry the connection\n        if the connection fails due to an early disconnect.  Early disconnects are expected ble failure\n        modes in busy environments where the slave device misses the connection packet and the master\n        therefore fails immediately. Retrying a few times should succeed in this case.\n\n        Args:\n            connection_string (string): A BLE address information in AA:BB:CC:DD:EE:FF,<address_type> format\n            connection_id (int): A unique integer set by the caller for referring to this connection once created\n            callback (callable): A callback function called when the connection has succeeded or failed\n            retries (int): The number of attempts to connect to this device that can end in early disconnect\n                before we give up and report that we could not connect. A retry count of 0 will mean that\n                we fail as soon as we receive the first early disconnect.\n            context (dict): If we are retrying to connect, passes the context to not considering it as a new connection.\n        \"\"\"\n        if context is None:\n            # It is the first attempt to connect: begin a new connection\n            context = {\n                'connection_id': connection_id,\n                'retries': retries,\n                'retry_connect': False,\n                'connection_string': connection_string,\n                'connect_time': time.time(),\n                'callback': callback\n            }\n\n            self.connections.begin_connection(\n                connection_id,\n                connection_string,\n                callback,\n                context,\n                self.get_config('default_timeout')\n            )\n\n        # Don't scan while we attempt to connect to this device\n        if self.scanning:\n            self.stop_scan()\n\n        address, address_type = connection_string.split(',')\n\n        # First, cancel any pending connection to prevent errors when starting a new one\n        self.bable.cancel_connection(sync=False)\n\n        # Send a connect request\n        self.bable.connect(\n            address=address,\n            address_type=address_type,\n            connection_interval=[7.5, 7.5],\n            on_connected=[self._on_connection_finished, context],\n            on_disconnected=[self._on_unexpected_disconnection, context]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _on_connection_finished(self, success, result, failure_reason, context):\n        connection_id = context['connection_id']\n\n        if not success:\n            self._logger.error(\"Error while connecting to the device err=%s\", failure_reason)\n\n            # If connection failed to be established, we just should retry to connect\n            if failure_reason.packet.native_class == 'HCI' and failure_reason.packet.native_status == 0x3e:\n                context['retry_connect'] = True\n\n            self._on_connection_failed(connection_id, self.id, success, failure_reason)\n            return\n\n        context['connection_handle'] = result['connection_handle']\n\n        # After connection has been done, probe GATT services\n        self.bable.probe_services(\n            connection_handle=context['connection_handle'],\n            on_services_probed=[self._on_services_probed, context]\n        )", "response": "Callback called when the connection attempt to a BLE device has finished."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _on_connection_failed(self, connection_id, adapter_id, success, failure_reason):\n        self._logger.info(\"_on_connection_failed connection_id=%d, reason=%s\", connection_id, failure_reason)\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            self._logger.info(\"Unable to obtain connection data on unknown connection %d\", connection_id)\n            context = {}\n\n        # Cancel the connection to be able to resend a connect request later (else the controller sends an error)\n        self.bable.cancel_connection(sync=False)\n\n        if context.get('retry_connect') and context.get('retries') > 0:\n            context['retries'] -= 1\n            self.connect_async(\n                connection_id,\n                context['connection_string'],\n                context['callback'],\n                context['retries'],\n                context\n            )\n        else:\n            self.connections.finish_connection(\n                connection_id,\n                False,\n                context.get('failure_reason', failure_reason)\n            )", "response": "Callback function called when a connection has failed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef disconnect_async(self, connection_id, callback):\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self.connections.begin_disconnection(connection_id, callback, self.get_config('default_timeout'))\n\n        self.bable.disconnect(\n            connection_handle=context['connection_handle'],\n            on_disconnected=[self._on_disconnection_finished, context]\n        )", "response": "Asynchronously disconnect from a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_unexpected_disconnection(self, success, result, failure_reason, context):\n        connection_id = context['connection_id']\n\n        self._logger.warn('Unexpected disconnection event, handle=%d, reason=0x%X, state=%s',\n                          result['connection_handle'],\n                          result['code'],\n                          self.connections.get_state(connection_id))\n\n        self.connections.unexpected_disconnect(connection_id)\n        self._trigger_callback('on_disconnect', self.id, connection_id)", "response": "Callback function called when an unexpected disconnection occurs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nenable RPC interface for this IOTile device.", "response": "def _open_rpc_interface(self, connection_id, callback):\n        \"\"\"Enable RPC interface for this IOTile device\n\n        Args:\n            connection_id (int): The unique identifier for the connection\n            callback (callback): Callback to be called when this command finishes\n                callback(conn_id, adapter_id, success, failure_reason)\n        \"\"\"\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self.connections.begin_operation(connection_id, 'open_interface', callback, self.get_config('default_timeout'))\n\n        try:\n            service = context['services'][TileBusService]\n            header_characteristic = service[ReceiveHeaderChar]\n            payload_characteristic = service[ReceivePayloadChar]\n        except KeyError:\n            self.connections.finish_operation(connection_id, False, \"Can't find characteristics to open rpc interface\")\n            return\n\n        # Enable notification from ReceiveHeaderChar characteristic (ReceivePayloadChar will be enable just after)\n        self.bable.set_notification(\n            enabled=True,\n            connection_handle=context['connection_handle'],\n            characteristic=header_characteristic,\n            on_notification_set=[self._on_interface_opened, context, payload_characteristic],\n            on_notification_received=self._on_notification_received,\n            sync=False\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _open_script_interface(self, connection_id, callback):\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        success = HighSpeedChar in context['services'][TileBusService]\n        reason = None\n        if not success:\n            reason = 'Could not find high speed streaming characteristic'\n\n        callback(connection_id, self.id, success, reason)", "response": "Enable script streaming interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenabling streaming interface for this IOTile device.", "response": "def _open_streaming_interface(self, connection_id, callback):\n        \"\"\"Enable streaming interface for this IOTile device\n\n        Args:\n            connection_id (int): The unique identifier for the connection\n            callback (callback): Callback to be called when this command finishes\n                callback(conn_id, adapter_id, success, failure_reason)\n        \"\"\"\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self._logger.info(\"Attempting to enable streaming\")\n        self.connections.begin_operation(connection_id, 'open_interface', callback, self.get_config('default_timeout'))\n\n        try:\n            characteristic = context['services'][TileBusService][StreamingChar]\n        except KeyError:\n            self.connections.finish_operation(\n                connection_id,\n                False,\n                \"Can't find characteristic to open streaming interface\"\n            )\n            return\n\n        context['parser'] = IOTileReportParser(report_callback=self._on_report, error_callback=self._on_report_error)\n        context['parser'].context = connection_id\n\n        def on_report_chunk_received(report_chunk):\n            \"\"\"Callback function called when a report chunk has been received.\"\"\"\n            context['parser'].add_data(report_chunk)\n\n        # Register our callback function in the notifications callbacks\n        self._register_notification_callback(\n            context['connection_handle'],\n            characteristic.value_handle,\n            on_report_chunk_received\n        )\n\n        self.bable.set_notification(\n            enabled=True,\n            connection_handle=context['connection_handle'],\n            characteristic=characteristic,\n            on_notification_set=[self._on_interface_opened, context],\n            on_notification_received=self._on_notification_received,\n            timeout=1.0,\n            sync=False\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _open_tracing_interface(self, connection_id, callback):\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self._logger.info(\"Attempting to enable tracing\")\n        self.connections.begin_operation(connection_id, 'open_interface', callback, self.get_config('default_timeout'))\n\n        try:\n            characteristic = context['services'][TileBusService][TracingChar]\n        except KeyError:\n            self.connections.finish_operation(\n                connection_id,\n                False,\n                \"Can't find characteristic to open tracing interface\"\n            )\n            return\n\n        # Register a callback function in the notifications callbacks, to trigger `on_trace` callback when a trace is\n        # notified.\n        self._register_notification_callback(\n            context['connection_handle'],\n            characteristic.value_handle,\n            lambda trace_chunk: self._trigger_callback('on_trace', connection_id, bytearray(trace_chunk))\n        )\n\n        self.bable.set_notification(\n            enabled=True,\n            connection_handle=context['connection_handle'],\n            characteristic=characteristic,\n            on_notification_set=[self._on_interface_opened, context],\n            on_notification_received=self._on_notification_received,\n            timeout=1.0,\n            sync=False\n        )", "response": "Enable tracing interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _close_rpc_interface(self, connection_id, callback):\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self.connections.begin_operation(connection_id, 'close_interface', callback, self.get_config('default_timeout'))\n\n        try:\n            service = context['services'][TileBusService]\n            header_characteristic = service[ReceiveHeaderChar]\n            payload_characteristic = service[ReceivePayloadChar]\n        except KeyError:\n            self.connections.finish_operation(connection_id, False, \"Can't find characteristics to open rpc interface\")\n            return\n\n        self.bable.set_notification(\n            enabled=False,\n            connection_handle=context['connection_handle'],\n            characteristic=header_characteristic,\n            on_notification_set=[self._on_interface_closed, context, payload_characteristic],\n            timeout=1.0\n        )", "response": "Disable the RPC interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_report(self, report, connection_id):\n        self._logger.info('Received report: %s', str(report))\n        self._trigger_callback('on_report', connection_id, report)\n\n        return False", "response": "Callback function called when a report has been processed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_rpc_async(self, connection_id, address, rpc_id, payload, timeout, callback):\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        connection_handle = context['connection_handle']\n\n        self.connections.begin_operation(connection_id, 'rpc', callback, timeout)\n\n        try:\n            service = context['services'][TileBusService]\n            send_header_characteristic = service[SendHeaderChar]\n            send_payload_characteristic = service[SendPayloadChar]\n            receive_header_characteristic = service[ReceiveHeaderChar]\n            receive_payload_characteristic = service[ReceivePayloadChar]\n        except KeyError:\n            self.connections.finish_operation(connection_id, False, \"Can't find characteristics to open rpc interface\")\n            return\n\n        length = len(payload)\n        if length < 20:\n            payload += b'\\x00'*(20 - length)\n        if length > 20:\n            self.connections.finish_operation(connection_id, False, \"Payload is too long, must be at most 20 bytes\")\n            return\n\n        header = bytearray([length, 0, rpc_id & 0xFF, (rpc_id >> 8) & 0xFF, address])\n        result = {}\n\n        def on_header_received(value):\n            \"\"\"Callback function called when a notification has been received with the RPC header response.\"\"\"\n            result['status'] = value[0]\n            result['length'] = value[3]\n\n            if result['length'] == 0:\n                # Simulate a empty payload received to end the RPC response\n                self._on_notification_received(True, {\n                    'connection_handle': connection_handle,\n                    'attribute_handle': receive_payload_characteristic.value_handle,\n                    'value': b'\\x00'*20\n                }, None)\n\n        def on_payload_received(value):\n            \"\"\"Callback function called when a notification has been received with the RPC payload response.\"\"\"\n            result['payload'] = value[:result['length']]\n            self.connections.finish_operation(\n                connection_id,\n                True,\n                None,\n                result['status'],\n                result['payload']\n            )\n\n        # Register the header notification callback\n        self._register_notification_callback(\n            connection_handle,\n            receive_header_characteristic.value_handle,\n            on_header_received,\n            once=True\n        )\n\n        # Register the payload notification callback\n        self._register_notification_callback(\n            connection_handle,\n            receive_payload_characteristic.value_handle,\n            on_payload_received,\n            once=True\n        )\n\n        if length > 0:\n            # If payload is not empty, send it first\n            self.bable.write_without_response(\n                connection_handle=connection_handle,\n                attribute_handle=send_payload_characteristic.value_handle,\n                value=bytes(payload)\n            )\n\n        self.bable.write_without_response(\n            connection_handle=connection_handle,\n            attribute_handle=send_header_characteristic.value_handle,\n            value=bytes(header)\n        )", "response": "Asynchronously send an RPC to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_script_async(self, connection_id, data, progress_callback, callback):\n\n        try:\n            context = self.connections.get_context(connection_id)\n        except ArgumentError:\n            callback(connection_id, self.id, False, \"Could not find connection information\")\n            return\n\n        self.connections.begin_operation(connection_id, 'script', callback, self.get_config('default_timeout'))\n        mtu = int(self.get_config('mtu', 20))  # Split script payloads larger than this\n\n        high_speed_char = context['services'][TileBusService][HighSpeedChar]\n\n        # Count number of chunks to send\n        nb_chunks = 1\n        if len(data) > mtu:\n            nb_chunks = len(data) // mtu\n            if len(data) % mtu != 0:\n                nb_chunks += 1\n\n        def send_script():\n            \"\"\"Function sending every chunks of the script. Executed in a separated thread.\"\"\"\n            for i in range(0, nb_chunks):\n                start = i * mtu\n                chunk = data[start: start + mtu]\n                sent = False\n\n                while not sent:\n                    try:\n                        self.bable.write_without_response(\n                            connection_handle=context['connection_handle'],\n                            attribute_handle=high_speed_char.value_handle,\n                            value=bytes(chunk)\n                        )\n                        sent = True\n                    except bable_interface.BaBLEException as err:\n                        if err.packet.status == 'Rejected':  # If we are streaming too fast, back off and try again\n                            time.sleep(0.05)\n                        else:\n                            self.connections.finish_operation(connection_id, False, err.message)\n                            return\n\n                progress_callback(i, nb_chunks)\n\n            self.connections.finish_operation(connection_id, True, None)\n\n        # Start the thread to send the script asynchronously\n        send_script_thread = threading.Thread(target=send_script, name='SendScriptThread')\n        send_script_thread.daemon = True\n        send_script_thread.start()", "response": "Asynchronously send a script to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a callback function to be called when a notification with the matching is received.", "response": "def _register_notification_callback(self, connection_handle, attribute_handle, callback, once=False):\n        \"\"\"Register a callback as a notification callback. It will be called if a notification with the matching\n        connection_handle and attribute_handle is received.\n\n        Args:\n            connection_handle (int): The connection handle to watch\n            attribute_handle (int): The attribute handle to watch\n            callback (func): The callback function to call once the notification has been received\n            once (bool): Should the callback only be called once (and then removed from the notification callbacks)\n        \"\"\"\n        notification_id = (connection_handle, attribute_handle)\n        with self.notification_callbacks_lock:\n            self.notification_callbacks[notification_id] = (callback, once)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _on_notification_received(self, success, result, failure_reason):\n        if not success:\n            self._logger.info(\"Notification received with failure failure_reason=%s\", failure_reason)\n\n        notification_id = (result['connection_handle'], result['attribute_handle'])\n\n        callback = None\n        with self.notification_callbacks_lock:\n            if notification_id in self.notification_callbacks:\n                callback, once = self.notification_callbacks[notification_id]\n\n                if once:\n                    del self.notification_callbacks[notification_id]\n\n        if callback is not None:\n            callback(result['value'])", "response": "Callback function called when a notification has been received."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop_sync(self):\n        # Stop to scan\n        if self.scanning:\n            self.stop_scan()\n\n        # Disconnect all connected devices\n        for connection_id in list(self.connections.get_connections()):\n            self.disconnect_sync(connection_id)\n\n        # Stop the baBLE interface\n        self.bable.stop()\n        # Stop the connection manager\n        self.connections.stop()\n\n        self.stopped = True", "response": "Safely stop this BLED112 instance without leaving it in a weird state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the sensor graph as iotile command snippets.", "response": "def format_snippet(sensor_graph):\n    \"\"\"Format this sensor graph as iotile command snippets.\n\n    This includes commands to reset and clear previously stored\n    sensor graphs.\n\n    Args:\n        sensor_graph (SensorGraph): the sensor graph that we want to format\n    \"\"\"\n\n    output = []\n\n    # Clear any old sensor graph\n    output.append(\"disable\")\n    output.append(\"clear\")\n    output.append(\"reset\")\n\n    # Load in the nodes\n    for node in sensor_graph.dump_nodes():\n        output.append('add_node \"{}\"'.format(node))\n\n    # Load in the streamers\n    for streamer in sensor_graph.streamers:\n        line = \"add_streamer '{}' '{}' {} {} {}\".format(streamer.selector, streamer.dest, streamer.automatic, streamer.format, streamer.report_type)\n\n        if streamer.with_other is not None:\n            line += ' --withother {}'.format(streamer.with_other)\n\n        output.append(line)\n\n    # Load all the constants\n    for stream, value in sorted(sensor_graph.constant_database.items(), key=lambda x: x[0].encode()):\n        output.append(\"set_constant '{}' {}\".format(stream, value))\n\n    # Persist the sensor graph\n    output.append(\"persist\")\n\n    output.append(\"back\")\n\n    # If we have an app tag and version set program them in\n    app_tag = sensor_graph.metadata_database.get('app_tag')\n    app_version = sensor_graph.metadata_database.get('app_version')\n\n    if app_tag is not None:\n        if app_version is None:\n            app_version = \"0.0\"\n\n        output.append(\"test_interface\")\n        output.append(\"set_version app %d --version '%s'\" % (app_tag, app_version))\n        output.append(\"back\")\n\n    # Load in the config variables if any\n    output.append(\"config_database\")\n    output.append(\"clear_variables\")\n\n    for slot, conf_vars in sensor_graph.config_database.items():\n        for conf_var, conf_def in conf_vars.items():\n            conf_type, conf_val = conf_def\n\n            if conf_type == 'binary':\n                conf_val = 'hex:' + hexlify(conf_val)\n            elif isinstance(conf_val, str):\n                conf_val = '\"%s\"' % conf_val\n\n            output.append(\"set_variable '{}' {} {} {}\".format(slot, conf_var, conf_type, conf_val))\n\n    # Restart the device to load in the new sg\n    output.append(\"back\")\n    output.append(\"reset\")\n\n    return \"\\n\".join(output) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlooking for BLED112 devices on this computer and start an instance on each one", "response": "def find_bled112_devices(cls):\n        \"\"\"Look for BLED112 dongles on this computer and start an instance on each one\"\"\"\n        found_devs = []\n\n        ports = serial.tools.list_ports.comports()\n        for port in ports:\n            if not hasattr(port, 'pid') or not hasattr(port, 'vid'):\n                continue\n\n            # Check if the device matches the BLED112's PID/VID combination\n            if port.pid == 1 and port.vid == 9304:\n                found_devs.append(port.device)\n\n        return found_devs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the scan event statistics for this adapter.", "response": "def get_scan_stats(self):\n        \"\"\"Return the scan event statistics for this adapter\n\n        Returns:\n            int : total scan events\n            int : total v1 scan count\n            int : total v1 scan response count\n            int : total v2 scan count\n            dict : device-specific scan counts\n            float : seconds since last reset\n        \"\"\"\n        time_spent = time.time()\n        return self._scan_event_count, self._v1_scan_count, self._v1_scan_response_count, \\\n            self._v2_scan_count, self._device_scan_counts.copy(), \\\n            (time_spent - self._last_reset_time)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear the scan event statistics and updates the last reset time", "response": "def reset_scan_stats(self):\n        \"\"\"Clears the scan event statistics and updates the last reset time\"\"\"\n        self._scan_event_count = 0\n        self._v1_scan_count = 0\n        self._v1_scan_response_count = 0\n        self._v2_scan_count = 0\n        self._device_scan_counts = {}\n        self._last_reset_time = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_sync(self):\n\n        if self.scanning:\n            self.stop_scan()\n\n        # Make a copy since this will change size as we disconnect\n        con_copy = copy.copy(self._connections)\n\n        for _, context in con_copy.items():\n            self.disconnect_sync(context['connection_id'])\n\n        self._command_task.stop()\n        self._stream.stop()\n        self._serial_port.close()\n\n        self.stopped = True", "response": "Safely stop this BLED112 instance without leaving it in a weird state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_scan(self, active):\n        self._command_task.sync_command(['_start_scan', active])\n        self.scanning = True", "response": "Start the scanning task"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to a device by its connection_string asynchronously.", "response": "def connect_async(self, connection_id, connection_string, callback, retries=4):\n        \"\"\"Connect to a device by its connection_string\n\n        This function asynchronously connects to a device by its BLE address passed in the\n        connection_string parameter and calls callback when finished.  Callback is called\n        on either success or failure with the signature:\n\n        callback(conn_id: int, result: bool, value: None)\n\n        The optional retries argument specifies how many times we should retry the connection\n        if the connection fails due to an early disconnect.  Early disconnects are expected ble failure\n        modes in busy environments where the slave device misses the connection packet and the master\n        therefore fails immediately.  Retrying a few times should succeed in this case.\n\n        Args:\n            connection_string (string): A BLE address is XX:YY:ZZ:AA:BB:CC format\n            connection_id (int): A unique integer set by the caller for referring to this connection\n                once created\n            callback (callable): A callback function called when the connection has succeeded or\n                failed\n            retries (int): The number of attempts to connect to this device that can end in early disconnect\n                before we give up and report that we could not connect.  A retry count of 0 will mean that\n                we fail as soon as we receive the first early disconnect.\n        \"\"\"\n        context = {}\n        context['connection_id'] = connection_id\n        context['callback'] = callback\n        context['retries'] = retries\n        context['connection_string'] = connection_string\n\n        # Don't scan while we attempt to connect to this device\n        if self.scanning:\n            self.stop_scan()\n\n        with self.count_lock:\n            self.connecting_count += 1\n\n        self._command_task.async_command(['_connect', connection_string],\n                                         self._on_connection_finished, context)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef disconnect_async(self, conn_id, callback):\n\n        found_handle = None\n        # Find the handle by connection id\n        for handle, conn in self._connections.items():\n            if conn['connection_id'] == conn_id:\n                found_handle = handle\n\n        if found_handle is None:\n            callback(conn_id, self.id, False, 'Invalid connection_id')\n            return\n\n        self._command_task.async_command(['_disconnect', found_handle], self._on_disconnect,\n                                         {'connection_id': conn_id, 'handle': found_handle,\n                                          'callback': callback})", "response": "Asynchronously disconnect from a device that has previously been connected to this adapter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_rpc_async(self, conn_id, address, rpc_id, payload, timeout, callback):\n\n        found_handle = None\n        # Find the handle by connection id\n        for handle, conn in self._connections.items():\n            if conn['connection_id'] == conn_id:\n                found_handle = handle\n\n        if found_handle is None:\n            callback(conn_id, self.id, False, 'Invalid connection_id', None, None)\n            return\n\n        services = self._connections[found_handle]['services']\n\n        self._command_task.async_command(['_send_rpc', found_handle, services, address, rpc_id, payload, timeout], self._send_rpc_finished,\n                                         {'connection_id': conn_id, 'handle': found_handle,\n                                          'callback': callback})", "response": "Asynchronously send an RPC to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_script_async(self, conn_id, data, progress_callback, callback):\n\n        found_handle = None\n        # Find the handle by connection id\n        for handle, conn in self._connections.items():\n            if conn['connection_id'] == conn_id:\n                found_handle = handle\n\n        if found_handle is None:\n            callback(conn_id, self.id, False, 'Invalid connection_id')\n            return\n\n        services = self._connections[found_handle]['services']\n\n        self._command_task.async_command(['_send_script', found_handle, services, data, 0, progress_callback],\n                                         self._send_script_finished, {'connection_id': conn_id,\n                                                                      'callback': callback})", "response": "Asynchronously send a script to this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _open_script_interface(self, conn_id, callback):\n\n        try:\n            handle = self._find_handle(conn_id)\n            services = self._connections[handle]['services']\n        except (ValueError, KeyError):\n            callback(conn_id, self.id, False, 'Connection closed unexpectedly before we could open the script interface')\n            return\n\n        success = TileBusHighSpeedCharacteristic in services[TileBusService]['characteristics']\n        reason = None\n        if not success:\n            reason = 'Could not find high speed streaming characteristic'\n\n        callback(conn_id, self.id, success, reason)", "response": "Enable script streaming interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _open_tracing_interface(self, conn_id, callback):\n\n        try:\n            handle = self._find_handle(conn_id)\n            services = self._connections[handle]['services']\n        except (ValueError, KeyError):\n            callback(conn_id, self.id, False, 'Connection closed unexpectedly before we could open the streaming interface')\n            return\n\n        self._command_task.async_command(['_enable_tracing', handle, services],\n                                         self._on_interface_finished, {'connection_id': conn_id, 'callback': callback})", "response": "Enable the debug tracing interface for this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the BLE advertisement packet and determine if it matches V1 or V2.", "response": "def _process_scan_event(self, response):\n        \"\"\"Parse the BLE advertisement packet.\n\n        If it's an IOTile device, parse and add to the scanned devices. Then,\n        parse advertisement and determine if it matches V1 or V2.  There are\n        two supported type of advertisements:\n\n        v1: There is both an advertisement and a scan response (if active scanning\n            is enabled).\n        v2: There is only an advertisement and no scan response.\n        \"\"\"\n\n        payload = response.payload\n        length = len(payload) - 10\n\n        if length < 0:\n            return\n\n        rssi, packet_type, sender, _addr_type, _bond, data = unpack(\"<bB6sBB%ds\" % length, payload)\n        string_address = ':'.join([format(x, \"02X\") for x in bytearray(sender[::-1])])\n\n        # Scan data is prepended with a length\n        if len(data) > 0:\n            data = bytearray(data[1:])\n        else:\n            data = bytearray([])\n\n        self._scan_event_count += 1\n\n        # If this is an advertisement packet, see if its an IOTile device\n        # packet_type = 4 is scan_response, 0, 2 and 6 are advertisements\n        if packet_type in (0, 2, 6):\n            if len(data) != 31:\n                return\n\n            if data[22] == 0xFF and data[23] == 0xC0 and data[24] == 0x3:\n                self._v1_scan_count += 1\n                self._parse_v1_advertisement(rssi, string_address, data)\n            elif data[3] == 27 and data[4] == 0x16 and data[5] == 0xdd and data[6] == 0xfd:\n                self._v2_scan_count += 1\n                self._parse_v2_advertisement(rssi, string_address, data)\n            else:\n                pass # This just means the advertisement was from a non-IOTile device\n        elif packet_type == 4:\n            self._v1_scan_response_count += 1\n            self._parse_v1_scan_response(string_address, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the IOTile Specific advertisement packet and return the corresponding entry in the dict.", "response": "def _parse_v2_advertisement(self, rssi, sender, data):\n        \"\"\" Parse the IOTile Specific advertisement packet\"\"\"\n\n        if len(data) != 31:\n            return\n\n        # We have already verified that the device is an IOTile device\n        # by checking its service data uuid in _process_scan_event so\n        # here we just parse out the required information\n\n        device_id, reboot_low, reboot_high_packed, flags, timestamp, \\\n        battery, counter_packed, broadcast_stream_packed, broadcast_value, \\\n        _mac = unpack(\"<LHBBLBBHLL\", data[7:])\n\n        reboots = (reboot_high_packed & 0xF) << 16 | reboot_low\n        counter = counter_packed & ((1 << 5) - 1)\n        broadcast_multiplex = counter_packed >> 5\n        broadcast_toggle = broadcast_stream_packed >> 15\n        broadcast_stream = broadcast_stream_packed & ((1 << 15) - 1)\n\n        # Flags for version 2 are:\n        #   bit 0: Has pending data to stream\n        #   bit 1: Low voltage indication\n        #   bit 2: User connected\n        #   bit 3: Broadcast data is encrypted\n        #   bit 4: Encryption key is device key\n        #   bit 5: Encryption key is user key\n        #   bit 6: broadcast data is time synchronized to avoid leaking\n        #   information about when it changes\n\n        self._device_scan_counts.setdefault(device_id, {'v1': 0, 'v2': 0})['v2'] += 1\n\n        info = {'connection_string': sender,\n                'uuid': device_id,\n                'pending_data': bool(flags & (1 << 0)),\n                'low_voltage': bool(flags & (1 << 1)),\n                'user_connected': bool(flags & (1 << 2)),\n                'signal_strength': rssi,\n                'reboot_counter': reboots,\n                'sequence': counter,\n                'broadcast_toggle': broadcast_toggle,\n                'timestamp': timestamp,\n                'battery': battery / 32.0,\n                'advertising_version':2}\n\n        self._trigger_callback('on_scan', self.id, info, self.ExpirationTime)\n\n        # If there is a valid reading on the advertising data, broadcast it\n        if broadcast_stream != 0xFFFF & ((1 << 15) - 1):\n            if self._throttle_broadcast and \\\n               self._check_update_seen_broadcast(sender, timestamp, broadcast_stream, broadcast_value,\n                                                 broadcast_toggle, counter=counter, channel=broadcast_multiplex):\n                return\n\n            reading = IOTileReading(timestamp, broadcast_stream, broadcast_value, reading_time=datetime.datetime.utcnow())\n            report = BroadcastReport.FromReadings(info['uuid'], [reading], timestamp)\n            self._trigger_callback('on_report', None, report)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef probe_services(self, handle, conn_id, callback):\n\n        self._command_task.async_command(['_probe_services', handle], callback,\n                                         {'connection_id': conn_id, 'handle': handle})", "response": "Probe for the GATT services and characteristics of a device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprobe a device for all characteristics defined in its GATT table.", "response": "def probe_characteristics(self, conn_id, handle, services):\n        \"\"\"Probe a device for all characteristics defined in its GATT table\n\n        This routine must be called after probe_services and passed the services dictionary\n        produced by that method.\n\n        Args:\n            handle (int): a handle to the connection on the BLED112 dongle\n            conn_id (int): a unique identifier for this connection on the DeviceManager\n                that owns this adapter.\n            services (dict): A dictionary of GATT services produced by probe_services()\n        \"\"\"\n        self._command_task.async_command(['_probe_characteristics', handle, services],\n                                         self._probe_characteristics_finished, {'connection_id': conn_id,\n                                                                                'handle': handle,\n                                                                                'services': services})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_system_sync(self):\n\n        retval = self._command_task.sync_command(['_query_systemstate'])\n\n        self.maximum_connections = retval['max_connections']\n\n        for conn in retval['active_connections']:\n            self._connections[conn] = {'handle': conn, 'connection_id': len(self._connections)}\n            self.disconnect_sync(0)\n\n        # If the dongle was previously left in a dirty state while still scanning, it will\n        # not allow new scans to be started.  So, forcibly stop any in progress scans.\n        # This throws a hardware error if scanning is not in progress which should be ignored.\n        try:\n            self.stop_scan()\n        except HardwareError:\n            # If we errored our it is because we were not currently scanning, so make sure\n            # we update our self.scanning flag (which would not be updated by stop_scan since\n            # it raised an exception.)\n            self.scanning = False\n\n        self._command_task.sync_command(['_set_mode', 0, 0]) #Disable advertising\n\n        self._logger.info(\"BLED112 adapter supports %d connections\", self.maximum_connections)", "response": "Initialize the internal state of the system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _on_disconnect(self, result):\n\n        success, _, context = self._parse_return(result)\n\n        callback = context['callback']\n        connection_id = context['connection_id']\n        handle = context['handle']\n\n        callback(connection_id, self.id, success, \"No reason given\")\n        self._remove_connection(handle)", "response": "Callback called when a disconnection command finishes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_return(cls, result):\n\n        return_value = None\n        success = result['result']\n        context = result['context']\n\n        if 'return_value' in result:\n            return_value = result['return_value']\n\n        return success, return_value, context", "response": "Extract the result return value and context from a result object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_connection(self, handle, expect_state=None):\n\n        conndata = self._connections.get(handle)\n\n        if conndata and expect_state is not None and conndata['state'] != expect_state:\n            self._logger.error(\"Connection in unexpected state, wanted=%s, got=%s\", expect_state,\n                               conndata['state'])\n        return conndata", "response": "Get a connection object from the pool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _probe_services_finished(self, result):\n\n        #If we were disconnected before this function is called, don't proceed\n        handle = result['context']['handle']\n        conn_id = result['context']['connection_id']\n\n        conndata = self._get_connection(handle, 'preparing')\n\n        if conndata is None:\n            self._logger.info('Connection disconnected before prob_services_finished, conn_id=%d',\n                              conn_id)\n            return\n\n        if result['result'] is False:\n            conndata['failed'] = True\n            conndata['failure_reason'] = 'Could not probe GATT services'\n            self.disconnect_async(conn_id, self._on_connection_failed)\n        else:\n            conndata['services_done_time'] = time.time()\n            self.probe_characteristics(result['context']['connection_id'], result['context']['handle'], result['return_value']['services'])", "response": "Callback called after a BLE device has had its GATT table completely probed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an update script that loads given firmware into the given slots.", "response": "def build_update_script(file_name, slot_assignments=None, os_info=None, sensor_graph=None,\n                        app_info=None, use_safeupdate=False):\n    \"\"\"Build a trub script that loads given firmware into the given slots.\n\n    slot_assignments should be a list of tuples in the following form:\n    (\"slot X\" or \"controller\", firmware_image_name)\n\n    The output of this autobuild action will be a trub script in\n    build/output/<file_name> that assigns the given firmware to each slot in\n    the order specified in the slot_assignments list.\n\n    Args:\n        file_name (str): The name of the output file that we should create.\n            This file name should end in .trub\n        slot_assignments (list of (str, str)): A list of tuples containing\n            the slot name and the firmware image that we should use to build\n            our update script. Optional\n        os_info (tuple(int, str)): A tuple of OS version tag and X.Y version\n            number that will be set as part of the OTA script if included. Optional.\n        sensor_graph (str): Name of sgf file. Optional.\n        app_info (tuple(int, str)): A tuple of App version tag and X.Y version\n            number that will be set as part of the OTA script if included. Optional.\n        use_safeupdate (bool): Enables safe firmware update\n    \"\"\"\n\n    resolver = ProductResolver.Create()\n    env = Environment(tools=[])\n    files = []\n\n    if slot_assignments is not None:\n        slots = [_parse_slot(x[0]) for x in slot_assignments]\n        files = [ensure_image_is_hex(resolver.find_unique(\"firmware_image\", x[1]).full_path) for x in slot_assignments]\n        env['SLOTS'] = slots\n    else:\n        env['SLOTS'] = None\n\n    env['USE_SAFEUPDATE'] = use_safeupdate\n    env['OS_INFO'] = os_info\n    env['APP_INFO'] = app_info\n    env['UPDATE_SENSORGRAPH'] = False\n\n    if sensor_graph is not None:\n        files.append(sensor_graph)\n        env['UPDATE_SENSORGRAPH'] = True\n\n    env.Command([os.path.join('build', 'output', file_name)], files,\n                action=Action(_build_reflash_script_action, \"Building TRUB script at $TARGET\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a TRUB script containing tile and controller reflashes and or sensorgraphs.", "response": "def _build_reflash_script_action(target, source, env):\n    \"\"\"Create a TRUB script containing tile and controller reflashes and/or sensorgraph\n\n    If the app_info is provided, then the final source file will be a sensorgraph.\n    All subsequent files in source must be in intel hex format. This is guaranteed\n    by the ensure_image_is_hex call in build_update_script.\n    \"\"\"\n\n    out_path = str(target[0])\n    source = [str(x) for x in source]\n    records = []\n\n    if env['USE_SAFEUPDATE']:\n        sgf_off = SendRPCRecord(8,0x2005,bytearray([0])) # Disable Sensorgraph\n        records.append(sgf_off)\n        safemode_enable = SendRPCRecord(8,0x1006,bytearray([1])) # Enable Safemode\n        records.append(safemode_enable)\n\n    # Update application firmwares\n    if env['SLOTS'] is not None:\n        for (controller, slot_id), image_path in zip(env['SLOTS'], source):\n            hex_data = IntelHex(image_path)\n            hex_data.padding = 0xFF\n\n            offset = hex_data.minaddr()\n            bin_data = bytearray(hex_data.tobinarray(offset, hex_data.maxaddr()))\n\n            if controller:\n                record = ReflashControllerRecord(bin_data, offset)\n            else:\n                record = ReflashTileRecord(slot_id, bin_data, offset)\n\n            records.append(record)\n\n    # Update sensorgraph\n    if env['UPDATE_SENSORGRAPH']:\n        sensor_graph_file = source[-1]\n        sensor_graph = compile_sgf(sensor_graph_file)\n        output = format_script(sensor_graph)\n        records += UpdateScript.FromBinary(output).records\n\n    # Update App and OS Tag\n    os_info = env['OS_INFO']\n    app_info = env['APP_INFO']\n    if os_info is not None:\n        os_tag, os_version = os_info\n        records.append(SetDeviceTagRecord(os_tag=os_tag, os_version=os_version))\n    if app_info is not None:\n        app_tag, app_version = app_info\n        records.append(SetDeviceTagRecord(app_tag=app_tag, app_version=app_version))\n\n    if env['USE_SAFEUPDATE']:\n        safemode_disable = SendRPCRecord(8,0x1006,bytearray([0]))  # Disable safemode\n        records.append(safemode_disable)\n        sgf_on = SendRPCRecord(8,0x2005,bytearray([1]))  # Enable Sensorgraph\n        records.append(sgf_on)\n\n    script = UpdateScript(records)\n\n    with open(out_path, \"wb\") as outfile:\n        outfile.write(script.encode())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_to_BuildError(status, exc_info=None):\n\n    if not exc_info and isinstance(status, Exception):\n        exc_info = (status.__class__, status, None)\n\n\n    if isinstance(status, BuildError):\n        buildError = status\n        buildError.exitstatus = 2   # always exit with 2 on build errors\n    elif isinstance(status, ExplicitExit):\n        status = status.status\n        errstr = 'Explicit exit, status %s' % status\n        buildError = BuildError(\n            errstr=errstr,\n            status=status,      # might be 0, OK here\n            exitstatus=status,      # might be 0, OK here\n            exc_info=exc_info)\n    elif isinstance(status, (StopError, UserError)):\n        buildError = BuildError(\n            errstr=str(status),\n            status=2,\n            exitstatus=2,\n            exc_info=exc_info)\n    elif isinstance(status, shutil.SameFileError):\n        # PY3 has a exception for when copying file to itself\n        # It's object provides info differently than below\n        try:\n            filename = status.filename\n        except AttributeError:\n            filename = None\n        \n        buildError = BuildError( \n            errstr=status.args[0],\n            status=status.errno,\n            exitstatus=2,\n            filename=filename,\n            exc_info=exc_info)\n\n    elif isinstance(status, (EnvironmentError, OSError, IOError)):\n        # If an IOError/OSError happens, raise a BuildError.\n        # Report the name of the file or directory that caused the\n        # error, which might be different from the target being built\n        # (for example, failure to create the directory in which the\n        # target file will appear).\n        try:\n            filename = status.filename\n        except AttributeError:\n            filename = None\n\n        buildError = BuildError( \n            errstr=status.strerror,\n            status=status.errno,\n            exitstatus=2,\n            filename=filename,\n            exc_info=exc_info)\n    elif isinstance(status, Exception):\n        buildError = BuildError(\n            errstr='%s : %s' % (status.__class__.__name__, status),\n            status=2,\n            exitstatus=2,\n            exc_info=exc_info)\n    elif SCons.Util.is_String(status):\n        buildError = BuildError(\n            errstr=status,\n            status=2,\n            exitstatus=2)\n    else:\n        buildError = BuildError(\n            errstr=\"Error %s\" % status,\n            status=status,\n            exitstatus=2)\n    \n    #import sys\n    #sys.stderr.write(\"convert_to_BuildError: status %s => (errstr %s, status %s)\\n\"%(status,buildError.errstr, buildError.status))\n    return buildError", "response": "Convert any return code a BuildError Exception."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the config variables from this sensor graph in ASCII format.", "response": "def format_config(sensor_graph):\n    \"\"\"Extract the config variables from this sensor graph in ASCII format.\n\n    Args:\n        sensor_graph (SensorGraph): the sensor graph that we want to format\n\n    Returns:\n        str: The ascii output lines concatenated as a single string\n    \"\"\"\n\n    cmdfile = CommandFile(\"Config Variables\", \"1.0\")\n\n    for slot in sorted(sensor_graph.config_database, key=lambda x: x.encode()):\n        for conf_var, conf_def in sorted(sensor_graph.config_database[slot].items()):\n            conf_type, conf_val = conf_def\n\n            if conf_type == 'binary':\n                conf_val = 'hex:' + hexlify(conf_val)\n\n            cmdfile.add(\"set_variable\", slot, conf_var, conf_type, conf_val)\n\n    return cmdfile.dump()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(env):\n    path, _f77, _shf77, version = get_xlf77(env)\n    if path:\n        _f77 = os.path.join(path, _f77)\n        _shf77 = os.path.join(path, _shf77)\n\n    f77.generate(env)\n\n    env['F77'] = _f77\n    env['SHF77'] = _shf77", "response": "Add Builders and construction variables for the Visual Age FORTRAN\n    compiler to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a prototype Scanner instance for scanning on - disk directories for on - disk files.", "response": "def DirScanner(**kw):\n    \"\"\"Return a prototype Scanner instance for scanning\n    directories for on-disk files\"\"\"\n    kw['node_factory'] = SCons.Node.FS.Entry\n    kw['recursive'] = only_dirs\n    return SCons.Scanner.Base(scan_on_disk, \"DirScanner\", **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DirEntryScanner(**kw):\n    kw['node_factory'] = SCons.Node.FS.Entry\n    kw['recursive'] = None\n    return SCons.Scanner.Base(scan_in_memory, \"DirEntryScanner\", **kw)", "response": "Returns a prototype Scanner instance for scanning a directory Node for their in - memory entries"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scan_on_disk(node, env, path=()):\n    try:\n        flist = node.fs.listdir(node.get_abspath())\n    except (IOError, OSError):\n        return []\n    e = node.Entry\n    for f in  filter(do_not_scan, flist):\n        # Add ./ to the beginning of the file name so if it begins with a\n        # '#' we don't look it up relative to the top-level directory.\n        e('./' + f)\n    return scan_in_memory(node, env, path)", "response": "Scan a directory for on - disk files and directories therein."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nscans a Node. FS. Dir for its in - memory entries.", "response": "def scan_in_memory(node, env, path=()):\n    \"\"\"\n    \"Scans\" a Node.FS.Dir for its in-memory entries.\n    \"\"\"\n    try:\n        entries = node.entries\n    except AttributeError:\n        # It's not a Node.FS.Dir (or doesn't look enough like one for\n        # our purposes), which can happen if a target list containing\n        # mixed Node types (Dirs and Files, for example) has a Dir as\n        # the first entry.\n        return []\n    entry_list = sorted(filter(do_not_scan, list(entries.keys())))\n    return [entries[n] for n in entry_list]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_result(self, result):\n\n        if self.is_finished():\n            raise InternalError(\"set_result called on finished AsynchronousResponse\",\n                                result=self._result, exception=self._exception)\n\n        self._result = result\n        self.finish()", "response": "Finish this response and set the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_exception(self, exc_class, exc_info, exc_stack):\n\n        if self.is_finished():\n            raise InternalError(\"set_exception called on finished AsynchronousResponse\",\n                                result=self._result, exception=self._exception)\n\n        self._exception = (exc_class, exc_info, exc_stack)\n        self.finish()", "response": "Set an exception as the result of this operation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for this operation to finish.", "response": "def wait(self, timeout=None):\n        \"\"\"Wait for this operation to finish.\n\n        You can specify an optional timeout that defaults to no timeout if\n        None is passed.  The result of the operation is returned from this\n        method. If the operation raised an exception, it is reraised from this\n        method.\n\n        Args:\n            timeout (float): The maximum number of seconds to wait before timing\n                out.\n        \"\"\"\n\n        flag = self._finished.wait(timeout=timeout)\n        if flag is False:\n            raise TimeoutExpiredError(\"Timeout waiting for response to event loop operation\")\n\n        if self._exception is not None:\n            self._raise_exception()\n\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for this operation to finish.", "response": "async def wait(self, timeout=None):\n        \"\"\"Wait for this operation to finish.\n\n        You can specify an optional timeout that defaults to no timeout if\n        None is passed.  The result of the operation is returned from this\n        method. If the operation raised an exception, it is reraised from this\n        method.\n\n        Args:\n            timeout (float): The maximum number of seconds to wait before timing\n                out.\n        \"\"\"\n\n        await asyncio.wait_for(self._future, timeout)\n\n        if self._exception is not None:\n            self._raise_exception()\n\n        return self._result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_released_versions(component):\n\n    releases = get_tags()\n    releases = sorted([(x[0], [int(y) for y in x[1].split('.')]) for x in releases], key=lambda x: x[1])[::-1]\n\n    return [(x[0], \".\".join(map(str, x[1]))) for x in releases if x[0] == component]", "response": "Get all released versions of the given component ordered newest to oldest\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting all releases for the given component", "response": "def do_releases(self, subcmd, opts, component):\n        \"\"\"${cmd_name}: print all releases for the given component\n\n        ${cmd_usage}\n        ${cmd_option_list}\n        \"\"\"\n\n        releases = get_released_versions(component)\n        for x in releases:\n            print(\"{} - {}\".format(*x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_dirty(self, subcmd, opts):\n\n        for comp_name, comp in components.comp_names.items():\n            releases = get_released_versions(comp_name)\n            if len(releases) == 0:\n                print(comp_name + ' - ' + 'No tagged releases')\n            else:\n                latest_tag = '-'.join(releases[0])\n                data = get_changed_since_tag(latest_tag, comp.path)\n                if len(data) > 0:\n                    print(comp_name + ' - ' + 'Changed files in component tree')", "response": "Check if any of the components have unreleased changes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_changed(self, subcmd, opts, component):\n\n        releases = get_released_versions(component)\n        latest = releases[0]\n\n        filter_dir = components.comp_names[component].path\n\n        latest_tag = '-'.join(latest)\n        data = get_changed_since_tag(latest_tag, filter_dir)\n\n        if len(data) > 0:\n            print(data)", "response": "print all files changes in component since the latest release"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading all tile dependencies and filter only the products from each that we are targeting", "response": "def load_dependencies(orig_tile, build_env):\n    \"\"\"Load all tile dependencies and filter only the products from each that we use\n\n    build_env must define the architecture that we are targeting so that we get the\n    correct dependency list and products per dependency since that may change\n    when building for different architectures\n    \"\"\"\n\n    if 'DEPENDENCIES' not in build_env:\n        build_env['DEPENDENCIES'] = []\n\n    dep_targets = []\n    chip = build_env['ARCH']\n    raw_arch_deps = chip.property('depends')\n\n    # Properly separate out the version information from the name of the dependency\n    # The raw keys come back as name,version\n    arch_deps = {}\n    for key, value in raw_arch_deps.items():\n        name, _, _ = key.partition(',')\n        arch_deps[name] = value\n\n    for dep in orig_tile.dependencies:\n        try:\n            tile = IOTile(os.path.join('build', 'deps', dep['unique_id']))\n\n            # Make sure we filter products using the view of module dependency products\n            # as seen in the target we are targeting.\n            if dep['name'] not in arch_deps:\n                tile.filter_products([])\n            else:\n                tile.filter_products(arch_deps[dep['name']])\n        except (ArgumentError, EnvironmentError):\n            raise BuildError(\"Could not find required dependency\", name=dep['name'])\n\n        build_env['DEPENDENCIES'].append(tile)\n\n        target = os.path.join(tile.folder, 'module_settings.json')\n        dep_targets.append(target)\n\n    return dep_targets"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all python wheel objects created by dependencies of this tile", "response": "def find_dependency_wheels(tile):\n    \"\"\"Return a list of all python wheel objects created by dependencies of this tile\n\n    Args:\n        tile (IOTile): Tile that we should scan for dependencies\n\n    Returns:\n        list: A list of paths to dependency wheels\n    \"\"\"\n\n    return [os.path.join(x.folder, 'python', x.support_wheel) for x in _iter_dependencies(tile) if x.has_wheel]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_ver_range(self, version, ver_range):\n\n        lower, upper, lower_inc, upper_inc = ver_range\n\n        #If the range extends over everything, we automatically match\n        if lower is None and upper is None:\n            return True\n\n        if lower is not None:\n            if lower_inc and version < lower:\n                return False\n            elif not lower_inc and version <= lower:\n                return False\n\n        if upper is not None:\n            if upper_inc and version > upper:\n                return False\n            elif not upper_inc and version >= upper:\n                return False\n\n        # Prereleases have special matching requirements\n        if version.is_prerelease:\n            # Prereleases cannot match ranges that are not defined as prereleases\n            if (lower is None or not lower.is_prerelease) and (upper is None or not upper.is_prerelease):\n                return False\n\n            # Prereleases without the same major.minor.patch as a range end point cannot match\n            if (lower is not None and version.release_tuple != lower.release_tuple) and \\\n               (upper is not None and version.release_tuple != upper.release_tuple):\n                return False\n\n        return True", "response": "Check if version is included in ver_range\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that a version is inside all of a list of ranges", "response": "def _check_insersection(self, version, ranges):\n        \"\"\"Check that a version is inside all of a list of ranges\"\"\"\n\n        for ver_range in ranges:\n            if not self._check_ver_range(version, ver_range):\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that a version is inside this SemanticVersionRange", "response": "def check(self, version):\n        \"\"\"Check that a version is inside this SemanticVersionRange\n\n        Args:\n            version (SemanticVersion): The version to check\n\n        Returns:\n            bool: True if the version is included in the range, False if not\n        \"\"\"\n\n        for disjunct in self._disjuncts:\n            if self._check_insersection(version, disjunct):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfiltering all of the versions in an iterable that match this version range Returns a list of the versions that match this range", "response": "def filter(self, versions, key=lambda x: x):\n        \"\"\"Filter all of the versions in an iterable that match this version range\n\n        Args:\n            versions (iterable): An iterable of SemanticVersion objects\n\n        Returns:\n            list: A list of the SemanticVersion objects that matched this range\n        \"\"\"\n\n        return [x for x in versions if self.check(key(x))]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FromString(cls, range_string):\n\n        disjuncts = None\n\n        range_string = range_string.strip()\n\n        if len(range_string) == 0:\n            raise ArgumentError(\"You must pass a finite string to SemanticVersionRange.FromString\",\n                                range_string=range_string)\n\n        # Check for *\n        if len(range_string) == 1 and range_string[0] == '*':\n            conj = (None, None, True, True)\n            disjuncts = [[conj]]\n\n        # Check for ^X.Y.Z\n        elif range_string[0] == '^':\n            ver = range_string[1:]\n\n            try:\n                ver = SemanticVersion.FromString(ver)\n            except DataError as err:\n                raise ArgumentError(\"Could not parse ^X.Y.Z version\", parse_error=str(err), range_string=range_string)\n\n            lower = ver\n            upper = ver.inc_first_nonzero()\n\n            conj = (lower, upper, True, False)\n            disjuncts = [[conj]]\n\n        elif range_string[0] == '=':\n            ver = range_string[1:]\n\n            try:\n                ver = SemanticVersion.FromString(ver)\n            except DataError as err:\n                raise ArgumentError(\"Could not parse =X.Y.Z version\", parse_error=str(err), range_string=range_string)\n\n            conj = (ver, ver, True, True)\n            disjuncts = [[conj]]\n\n        if disjuncts is None:\n            raise ArgumentError(\"Invalid range specification that could not be parsed\", range_string=range_string)\n\n        return SemanticVersionRange(disjuncts)", "response": "Parse a string representing a version range into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call_rpc(self, address, rpc_id, payload):\n\n        # FIXME: Set a timeout of 1.1 seconds to make sure we fail if the device hangs but\n        #        this should be long enough to accommodate any actual RPCs we need to send.\n\n        status, response = self.hw.stream.send_rpc(address, rpc_id, payload, timeout=1.1)\n        return response", "response": "Call an RPC with the given information and return its response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FromReadings(cls, uuid, readings):\n\n        if len(readings) != 1:\n            raise ArgumentError(\"IndividualReading reports must be created with exactly one reading\",\n                                num_readings=len(readings))\n\n        reading = readings[0]\n        data = struct.pack(\"<BBHLLLL\", 0, 0, reading.stream, uuid, 0, reading.raw_time, reading.value)\n        return IndividualReadingReport(data)", "response": "Generate an instance of the report format from a list of readings and a uuid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(self):\n\n        fmt, _, stream, uuid, sent_timestamp, reading_timestamp, reading_value = unpack(\"<BBHLLLL\", self.raw_report)\n        assert fmt == 0\n\n        # Estimate the UTC time when this device was turned on\n        time_base = self.received_time - datetime.timedelta(seconds=sent_timestamp)\n\n        reading = IOTileReading(reading_timestamp, stream, reading_value, time_base=time_base)\n        self.origin = uuid\n        self.sent_timestamp = sent_timestamp\n\n        return [reading], []", "response": "Decode this report into a single reading"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning this report into a serialized bytearray that could be decoded with a call to decode", "response": "def encode(self):\n        \"\"\"Turn this report into a serialized bytearray that could be decoded with a call to decode\"\"\"\n\n        reading = self.visible_readings[0]\n        data = struct.pack(\"<BBHLLLL\", 0, 0, reading.stream, self.origin,\n                           self.sent_timestamp, reading.raw_time, reading.value)\n\n        return bytearray(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscan a file list to decide if it s TeX - or LaTeX - flavored.", "response": "def is_LaTeX(flist,env,abspath):\n    \"\"\"Scan a file list to decide if it's TeX- or LaTeX-flavored.\"\"\"\n\n    # We need to scan files that are included in case the\n    # \\documentclass command is in them.\n\n    # get path list from both env['TEXINPUTS'] and env['ENV']['TEXINPUTS']\n    savedpath = modify_env_var(env, 'TEXINPUTS', abspath)\n    paths = env['ENV']['TEXINPUTS']\n    if SCons.Util.is_List(paths):\n        pass\n    else:\n        # Split at os.pathsep to convert into absolute path\n        paths = paths.split(os.pathsep)\n\n    # now that we have the path list restore the env\n    if savedpath is _null:\n        try:\n            del env['ENV']['TEXINPUTS']\n        except KeyError:\n            pass # was never set\n    else:\n        env['ENV']['TEXINPUTS'] = savedpath\n    if Verbose:\n        print(\"is_LaTeX search path \",paths)\n        print(\"files to search :\",flist)\n\n    # Now that we have the search path and file list, check each one\n    for f in flist:\n        if Verbose:\n            print(\" checking for Latex source \",str(f))\n\n        content = f.get_text_contents()\n        if LaTeX_re.search(content):\n            if Verbose:\n                print(\"file %s is a LaTeX file\" % str(f))\n            return 1\n        if Verbose:\n            print(\"file %s is not a LaTeX file\" % str(f))\n\n        # now find included files\n        inc_files = [ ]\n        inc_files.extend( include_re.findall(content) )\n        if Verbose:\n            print(\"files included by '%s': \"%str(f),inc_files)\n        # inc_files is list of file names as given. need to find them\n        # using TEXINPUTS paths.\n\n        # search the included files\n        for src in inc_files:\n            srcNode = FindFile(src,['.tex','.ltx','.latex'],paths,env,requireExt=False)\n            # make this a list since is_LaTeX takes a list.\n            fileList = [srcNode,]\n            if Verbose:\n                print(\"FindFile found \",srcNode)\n            if srcNode is not None:\n                file_test = is_LaTeX(fileList, env, abspath)\n\n            # return on first file that finds latex is needed.\n            if file_test:\n                return file_test\n\n        if Verbose:\n            print(\" done scanning \",str(f))\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tex_pdf_emitter(target, source, env):\n    (target, source) = tex_emitter_core(target, source, env, LatexGraphics)\n\n    return (target, source)", "response": "An emitter for TeX and LaTeX sources when pdftex or pdflatex is executing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscan the file for graphics files and add them to aux_files", "response": "def ScanFiles(theFile, target, paths, file_tests, file_tests_search, env, graphics_extensions, targetdir, aux_files):\n    \"\"\" For theFile (a Node) update any file_tests and search for graphics files\n    then find all included files and call ScanFiles recursively for each of them\"\"\"\n\n    content = theFile.get_text_contents()\n    if Verbose:\n        print(\" scanning \",str(theFile))\n\n    for i in range(len(file_tests_search)):\n        if file_tests[i][0] is None:\n            if Verbose:\n                print(\"scan i \",i,\" files_tests[i] \",file_tests[i], file_tests[i][1])\n            file_tests[i][0] = file_tests_search[i].search(content)\n            if Verbose and file_tests[i][0]:\n                print(\"   found match for \",file_tests[i][1][-1])\n            # for newglossary insert the suffixes in file_tests[i]\n            if file_tests[i][0] and file_tests[i][1][-1] == 'newglossary':\n                findresult = file_tests_search[i].findall(content)\n                for l in range(len(findresult)) :\n                    (file_tests[i][1]).insert(0,'.'+findresult[l][3])\n                    (file_tests[i][1]).insert(0,'.'+findresult[l][2])\n                    (file_tests[i][1]).insert(0,'.'+findresult[l][0])\n                    suffix_list = ['.'+findresult[l][0],'.'+findresult[l][2],'.'+findresult[l][3] ]\n                    newglossary_suffix.append(suffix_list)\n                if Verbose:\n                    print(\" new suffixes for newglossary \",newglossary_suffix)\n\n\n    incResult = includeOnly_re.search(content)\n    if incResult:\n        aux_files.append(os.path.join(targetdir, incResult.group(1)))\n    if Verbose:\n        print(\"\\include file names : \", aux_files)\n    # recursively call this on each of the included files\n    inc_files = [ ]\n    inc_files.extend( include_re.findall(content) )\n    if Verbose:\n        print(\"files included by '%s': \"%str(theFile),inc_files)\n    # inc_files is list of file names as given. need to find them\n    # using TEXINPUTS paths.\n\n    for src in inc_files:\n        srcNode = FindFile(src,['.tex','.ltx','.latex'],paths,env,requireExt=False)\n        if srcNode is not None:\n            file_tests = ScanFiles(srcNode, target, paths, file_tests, file_tests_search, env, graphics_extensions, targetdir, aux_files)\n    if Verbose:\n        print(\" done scanning \",str(theFile))\n    return file_tests"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd Builders and construction variables for TeX to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for TeX to an Environment.\"\"\"\n\n    global TeXLaTeXAction\n    if TeXLaTeXAction is None:\n        TeXLaTeXAction = SCons.Action.Action(TeXLaTeXFunction,\n                              strfunction=TeXLaTeXStrFunction)\n\n    env.AppendUnique(LATEXSUFFIXES=SCons.Tool.LaTeXSuffixes)\n\n    generate_common(env)\n\n    from . import dvi\n    dvi.generate(env)\n\n    bld = env['BUILDERS']['DVI']\n    bld.add_action('.tex', TeXLaTeXAction)\n    bld.add_emitter('.tex', tex_eps_emitter)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_common(env):\n\n    # Add OSX system paths so TeX tools can be found\n    # when a list of tools is given the exists() method is not called\n    generate_darwin(env)\n\n    # A generic tex file Action, sufficient for all tex files.\n    global TeXAction\n    if TeXAction is None:\n        TeXAction = SCons.Action.Action(\"$TEXCOM\", \"$TEXCOMSTR\")\n\n    # An Action to build a latex file.  This might be needed more\n    # than once if we are dealing with labels and bibtex.\n    global LaTeXAction\n    if LaTeXAction is None:\n        LaTeXAction = SCons.Action.Action(\"$LATEXCOM\", \"$LATEXCOMSTR\")\n\n    # Define an action to run BibTeX on a file.\n    global BibTeXAction\n    if BibTeXAction is None:\n        BibTeXAction = SCons.Action.Action(\"$BIBTEXCOM\", \"$BIBTEXCOMSTR\")\n\n    # Define an action to run Biber on a file.\n    global BiberAction\n    if BiberAction is None:\n        BiberAction = SCons.Action.Action(\"$BIBERCOM\", \"$BIBERCOMSTR\")\n\n    # Define an action to run MakeIndex on a file.\n    global MakeIndexAction\n    if MakeIndexAction is None:\n        MakeIndexAction = SCons.Action.Action(\"$MAKEINDEXCOM\", \"$MAKEINDEXCOMSTR\")\n\n    # Define an action to run MakeIndex on a file for nomenclatures.\n    global MakeNclAction\n    if MakeNclAction is None:\n        MakeNclAction = SCons.Action.Action(\"$MAKENCLCOM\", \"$MAKENCLCOMSTR\")\n\n    # Define an action to run MakeIndex on a file for glossaries.\n    global MakeGlossaryAction\n    if MakeGlossaryAction is None:\n        MakeGlossaryAction = SCons.Action.Action(\"$MAKEGLOSSARYCOM\", \"$MAKEGLOSSARYCOMSTR\")\n\n    # Define an action to run MakeIndex on a file for acronyms.\n    global MakeAcronymsAction\n    if MakeAcronymsAction is None:\n        MakeAcronymsAction = SCons.Action.Action(\"$MAKEACRONYMSCOM\", \"$MAKEACRONYMSCOMSTR\")\n\n    try:\n        environ = env['ENV']\n    except KeyError:\n        environ = {}\n        env['ENV'] = environ\n\n    # Some Linux platforms have pdflatex set up in a way\n    # that requires that the HOME environment variable be set.\n    # Add it here if defined.\n    v = os.environ.get('HOME')\n    if v:\n        environ['HOME'] = v\n\n    CDCOM = 'cd '\n    if platform.system() == 'Windows':\n        # allow cd command to change drives on Windows\n        CDCOM = 'cd /D '\n\n    env['TEX']      = 'tex'\n    env['TEXFLAGS'] = SCons.Util.CLVar('-interaction=nonstopmode -recorder')\n    env['TEXCOM']   = CDCOM + '${TARGET.dir} && $TEX $TEXFLAGS ${SOURCE.file}'\n\n    env['PDFTEX']      = 'pdftex'\n    env['PDFTEXFLAGS'] = SCons.Util.CLVar('-interaction=nonstopmode -recorder')\n    env['PDFTEXCOM']   = CDCOM + '${TARGET.dir} && $PDFTEX $PDFTEXFLAGS ${SOURCE.file}'\n\n    env['LATEX']        = 'latex'\n    env['LATEXFLAGS']   = SCons.Util.CLVar('-interaction=nonstopmode -recorder')\n    env['LATEXCOM']     = CDCOM + '${TARGET.dir} && $LATEX $LATEXFLAGS ${SOURCE.file}'\n    env['LATEXRETRIES'] = 4\n\n    env['PDFLATEX']      = 'pdflatex'\n    env['PDFLATEXFLAGS'] = SCons.Util.CLVar('-interaction=nonstopmode -recorder')\n    env['PDFLATEXCOM']   = CDCOM + '${TARGET.dir} && $PDFLATEX $PDFLATEXFLAGS ${SOURCE.file}'\n\n    env['BIBTEX']      = 'bibtex'\n    env['BIBTEXFLAGS'] = SCons.Util.CLVar('')\n    env['BIBTEXCOM']   = CDCOM + '${TARGET.dir} && $BIBTEX $BIBTEXFLAGS ${SOURCE.filebase}'\n\n    env['BIBER']      = 'biber'\n    env['BIBERFLAGS'] = SCons.Util.CLVar('')\n    env['BIBERCOM']   = CDCOM + '${TARGET.dir} && $BIBER $BIBERFLAGS ${SOURCE.filebase}'\n\n    env['MAKEINDEX']      = 'makeindex'\n    env['MAKEINDEXFLAGS'] = SCons.Util.CLVar('')\n    env['MAKEINDEXCOM']   = CDCOM + '${TARGET.dir} && $MAKEINDEX $MAKEINDEXFLAGS ${SOURCE.file}'\n\n    env['MAKEGLOSSARY']      = 'makeindex'\n    env['MAKEGLOSSARYSTYLE'] = '${SOURCE.filebase}.ist'\n    env['MAKEGLOSSARYFLAGS'] = SCons.Util.CLVar('-s ${MAKEGLOSSARYSTYLE} -t ${SOURCE.filebase}.glg')\n    env['MAKEGLOSSARYCOM']   = CDCOM + '${TARGET.dir} && $MAKEGLOSSARY ${SOURCE.filebase}.glo $MAKEGLOSSARYFLAGS -o ${SOURCE.filebase}.gls'\n\n    env['MAKEACRONYMS']      = 'makeindex'\n    env['MAKEACRONYMSSTYLE'] = '${SOURCE.filebase}.ist'\n    env['MAKEACRONYMSFLAGS'] = SCons.Util.CLVar('-s ${MAKEACRONYMSSTYLE} -t ${SOURCE.filebase}.alg')\n    env['MAKEACRONYMSCOM']   = CDCOM + '${TARGET.dir} && $MAKEACRONYMS ${SOURCE.filebase}.acn $MAKEACRONYMSFLAGS -o ${SOURCE.filebase}.acr'\n\n    env['MAKENCL']      = 'makeindex'\n    env['MAKENCLSTYLE'] = 'nomencl.ist'\n    env['MAKENCLFLAGS'] = '-s ${MAKENCLSTYLE} -t ${SOURCE.filebase}.nlg'\n    env['MAKENCLCOM']   = CDCOM + '${TARGET.dir} && $MAKENCL ${SOURCE.filebase}.nlo $MAKENCLFLAGS -o ${SOURCE.filebase}.nls'\n\n    env['MAKENEWGLOSSARY']      = 'makeindex'\n    env['MAKENEWGLOSSARYCOM']   = CDCOM + '${TARGET.dir} && $MAKENEWGLOSSARY '", "response": "This function creates the common LaTeX and LaTeX files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true if running on Windows 64 bits.", "response": "def is_win64():\n    \"\"\"Return true if running on windows 64 bits.\n\n    Works whether python itself runs in 64 bits or 32 bits.\"\"\"\n    # Unfortunately, python does not provide a useful way to determine\n    # if the underlying Windows OS is 32-bit or 64-bit.  Worse, whether\n    # the Python itself is 32-bit or 64-bit affects what it returns,\n    # so nothing in sys.* or os.* help.\n\n    # Apparently the best solution is to use env vars that Windows\n    # sets.  If PROCESSOR_ARCHITECTURE is not x86, then the python\n    # process is running in 64 bit mode (on a 64-bit OS, 64-bit\n    # hardware, obviously).\n    # If this python is 32-bit but the OS is 64, Windows will set\n    # ProgramW6432 and PROCESSOR_ARCHITEW6432 to non-null.\n    # (Checking for HKLM\\Software\\Wow6432Node in the registry doesn't\n    # work, because some 32-bit installers create it.)\n    global _is_win64\n    if _is_win64 is None:\n        # I structured these tests to make it easy to add new ones or\n        # add exceptions in the future, because this is a bit fragile.\n        _is_win64 = False\n        if os.environ.get('PROCESSOR_ARCHITECTURE', 'x86') != 'x86':\n            _is_win64 = True\n        if os.environ.get('PROCESSOR_ARCHITEW6432'):\n            _is_win64 = True\n        if os.environ.get('ProgramW6432'):\n            _is_win64 = True\n    return _is_win64"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_reg(value):\n    try:\n        SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE, value)\n        ret = True\n    except SCons.Util.WinError:\n        ret = False\n    return ret", "response": "Return True if the given key exists in HKEY_LOCAL_MACHINE False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a dictionary representing a shell environment add the variables from os. environ needed for processing of vcvarsall. bat files.", "response": "def normalize_env(env, keys, force=False):\n    \"\"\"Given a dictionary representing a shell environment, add the variables\n    from os.environ needed for the processing of .bat files; the keys are\n    controlled by the keys argument.\n\n    It also makes sure the environment values are correctly encoded.\n\n    If force=True, then all of the key values that exist are copied\n    into the returned dictionary.  If force=false, values are only\n    copied if the key does not already exist in the copied dictionary.\n\n    Note: the environment is copied.\"\"\"\n    normenv = {}\n    if env:\n        for k in list(env.keys()):\n            normenv[k] = copy.deepcopy(env[k])\n\n        for k in keys:\n            if k in os.environ and (force or not k in normenv):\n                normenv[k] = os.environ[k]\n\n    # This shouldn't be necessary, since the default environment should include system32,\n    # but keep this here to be safe, since it's needed to find reg.exe which the MSVC\n    # bat scripts use.\n    sys32_dir = os.path.join(os.environ.get(\"SystemRoot\",\n                                            os.environ.get(\"windir\", r\"C:\\Windows\\system32\")),\n                             \"System32\")\n\n    if sys32_dir not in normenv['PATH']:\n        normenv['PATH'] = normenv['PATH'] + os.pathsep + sys32_dir\n\n    # Without Wbem in PATH, vcvarsall.bat has a \"'wmic' is not recognized\"\n    # error starting with Visual Studio 2017, although the script still\n    # seems to work anyway.\n    sys32_wbem_dir = os.path.join(sys32_dir, 'Wbem')\n    if sys32_wbem_dir not in normenv['PATH']:\n        normenv['PATH'] = normenv['PATH'] + os.pathsep + sys32_wbem_dir\n\n    debug(\"PATH: %s\"%normenv['PATH'])\n\n    return normenv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the output of given vcbat with given args.", "response": "def get_output(vcbat, args = None, env = None):\n    \"\"\"Parse the output of given bat file, with given args.\"\"\"\n\n    if env is None:\n        # Create a blank environment, for use in launching the tools\n        env = SCons.Environment.Environment(tools=[])\n\n    # TODO:  This is a hard-coded list of the variables that (may) need\n    # to be imported from os.environ[] for v[sc]*vars*.bat file\n    # execution to work.  This list should really be either directly\n    # controlled by vc.py, or else derived from the common_tools_var\n    # settings in vs.py.\n    vs_vc_vars = [\n        'COMSPEC',\n        # VS100 and VS110: Still set, but modern MSVC setup scripts will\n        # discard these if registry has values.  However Intel compiler setup\n        # script still requires these as of 2013/2014.\n        'VS140COMNTOOLS',\n        'VS120COMNTOOLS',\n        'VS110COMNTOOLS',\n        'VS100COMNTOOLS',\n        'VS90COMNTOOLS',\n        'VS80COMNTOOLS',\n        'VS71COMNTOOLS',\n        'VS70COMNTOOLS',\n        'VS60COMNTOOLS',\n    ]\n    env['ENV'] = normalize_env(env['ENV'], vs_vc_vars, force=False)\n\n    if args:\n        debug(\"Calling '%s %s'\" % (vcbat, args))\n        popen = SCons.Action._subproc(env,\n                                      '\"%s\" %s & set' % (vcbat, args),\n                                      stdin='devnull',\n                                      stdout=subprocess.PIPE,\n                                      stderr=subprocess.PIPE)\n    else:\n        debug(\"Calling '%s'\" % vcbat)\n        popen = SCons.Action._subproc(env,\n                                      '\"%s\" & set' % vcbat,\n                                      stdin='devnull',\n                                      stdout=subprocess.PIPE,\n                                      stderr=subprocess.PIPE)\n\n    # Use the .stdout and .stderr attributes directly because the\n    # .communicate() method uses the threading module on Windows\n    # and won't work under Pythons not built with threading.\n    stdout = popen.stdout.read()\n    stderr = popen.stderr.read()\n\n    # Extra debug logic, uncomment if necessary\n#     debug('get_output():stdout:%s'%stdout)\n#     debug('get_output():stderr:%s'%stderr)\n\n    if stderr:\n        # TODO: find something better to do with stderr;\n        # this at least prevents errors from getting swallowed.\n        import sys\n        sys.stderr.write(stderr)\n    if popen.wait() != 0:\n        raise IOError(stderr.decode(\"mbcs\"))\n\n    output = stdout.decode(\"mbcs\")\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_output(output, keep=(\"INCLUDE\", \"LIB\", \"LIBPATH\", \"PATH\")):\n\n    # dkeep is a dict associating key: path_list, where key is one item from\n    # keep, and pat_list the associated list of paths\n    dkeep = dict([(i, []) for i in keep])\n\n    # rdk will  keep the regex to match the .bat file output line starts\n    rdk = {}\n    for i in keep:\n        rdk[i] = re.compile('%s=(.*)' % i, re.I)\n\n    def add_env(rmatch, key, dkeep=dkeep):\n        path_list = rmatch.group(1).split(os.pathsep)\n        for path in path_list:\n            # Do not add empty paths (when a var ends with ;)\n            if path:\n                # XXX: For some reason, VC98 .bat file adds \"\" around the PATH\n                # values, and it screws up the environment later, so we strip\n                # it.\n                path = path.strip('\"')\n                dkeep[key].append(str(path))\n\n    for line in output.splitlines():\n        for k, value in rdk.items():\n            match = value.match(line)\n            if match:\n                add_env(match, k)\n\n    return dkeep", "response": "Parse output from running visual c ++ and running set\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(env):\n    for t in SCons.Tool.tool_list(env['PLATFORM'], env):\n        SCons.Tool.Tool(t)(env)", "response": "Add default tools to the given Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify that the object conforms to this verifier s schema", "response": "def verify(self, obj):\n        \"\"\"Verify that the object conforms to this verifier's schema\n\n        Args:\n            obj (object): A python object to verify\n\n        Raises:\n            ValidationError: If there is a problem verifying the dictionary, a\n                ValidationError is thrown with at least the reason key set indicating\n                the reason for the lack of validation.\n        \"\"\"\n\n        if not isinstance(obj, int):\n            raise ValidationError(\"Object is not a int\", reason='object is not a int', object=obj,\n                                  type=type(obj), int_type=int)\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_conv(obj):\n    try:\n        get = obj.get\n    except AttributeError:\n        if isinstance(obj, SCons.Node.Node) or SCons.Util.is_Sequence( obj ):\n            result = obj\n        else:\n            result = str(obj)\n    else:\n        result = get()\n    return result", "response": "This is the string conversion routine that we can use to return Nodes not strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subst_path(self, env, target, source):\n        result = []\n        for type, value in self.pathlist:\n            if type == TYPE_STRING_SUBST:\n                value = env.subst(value, target=target, source=source,\n                                  conv=node_conv)\n                if SCons.Util.is_Sequence(value):\n                    result.extend(SCons.Util.flatten(value))\n                elif value:\n                    result.append(value)\n            elif type == TYPE_OBJECT:\n                value = node_conv(value)\n                if value:\n                    result.append(value)\n            elif value:\n                result.append(value)\n        return tuple(result)", "response": "Substitute a path in the PathList with the target and source."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the key for memoization of a pathlist.", "response": "def _PathList_key(self, pathlist):\n        \"\"\"\n        Returns the key for memoization of PathLists.\n\n        Note that we want this to be pretty quick, so we don't completely\n        canonicalize all forms of the same list.  For example,\n        'dir1:$ROOT/dir2' and ['$ROOT/dir1', 'dir'] may logically\n        represent the same list if you're executing from $ROOT, but\n        we're not going to bother splitting strings into path elements,\n        or massaging strings into Nodes, to identify that equivalence.\n        We just want to eliminate obvious redundancy from the normal\n        case of re-using exactly the same cloned value for a path.\n        \"\"\"\n        if SCons.Util.is_Sequence(pathlist):\n            pathlist = tuple(SCons.Util.flatten(pathlist))\n        return pathlist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a _PathList object for the specified pathlist creating and caching a new object as necessary.", "response": "def PathList(self, pathlist):\n        \"\"\"\n        Returns the cached _PathList object for the specified pathlist,\n        creating and caching a new object as necessary.\n        \"\"\"\n        pathlist = self._PathList_key(pathlist)\n        try:\n            memo_dict = self._memo['PathList']\n        except KeyError:\n            memo_dict = {}\n            self._memo['PathList'] = memo_dict\n        else:\n            try:\n                return memo_dict[pathlist]\n            except KeyError:\n                pass\n\n        result = _PathList(pathlist)\n\n        memo_dict[pathlist] = result\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DefaultEnvironment(*args, **kw):\n    global _default_env\n    if not _default_env:\n        import SCons.Util\n        _default_env = SCons.Environment.Environment(*args, **kw)\n        if SCons.Util.md5:\n            _default_env.Decider('MD5')\n        else:\n            _default_env.Decider('timestamp-match')\n        global DefaultEnvironment\n        DefaultEnvironment = _fetch_DefaultEnvironment\n        _default_env._CacheDir_path = None\n    return _default_env", "response": "Returns a new default construction tree for the specified environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_func(dest, src, symlinks=True):\n\n    dest = str(dest)\n    src = str(src)\n\n    SCons.Node.FS.invalidate_node_memos(dest)\n    if SCons.Util.is_List(src) and os.path.isdir(dest):\n        for file in src:\n            shutil.copy2(file, dest)\n        return 0\n    elif os.path.islink(src):\n        if symlinks:\n            return os.symlink(os.readlink(src), dest)\n        else:\n            return copy_func(dest, os.path.realpath(src))\n    elif os.path.isfile(src):\n        shutil.copy2(src, dest)\n        return 0\n    else:\n        shutil.copytree(src, dest, symlinks)\n        # copytree returns None in python2 and destination string in python3\n        # A error is raised in both cases, so we can just return 0 for success\n        return 0", "response": "Copy a file or directory to a new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconcatenates the given list with the given prefix and suffix.", "response": "def _concat(prefix, list, suffix, env, f=lambda x: x, target=None, source=None):\n    \"\"\"\n    Creates a new list from 'list' by first interpolating each element\n    in the list using the 'env' dictionary and then calling f on the\n    list, and finally calling _concat_ixes to concatenate 'prefix' and\n    'suffix' onto each element of the list.\n    \"\"\"\n    if not list:\n        return list\n\n    l = f(SCons.PathList.PathList(list).subst_path(env, target, source))\n    if l is not None:\n        list = l\n\n    return _concat_ixes(prefix, list, suffix, env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _concat_ixes(prefix, list, suffix, env):\n\n    result = []\n\n    # ensure that prefix and suffix are strings\n    prefix = str(env.subst(prefix, SCons.Subst.SUBST_RAW))\n    suffix = str(env.subst(suffix, SCons.Subst.SUBST_RAW))\n\n    for x in list:\n        if isinstance(x, SCons.Node.FS.File):\n            result.append(x)\n            continue\n        x = str(x)\n        if x:\n\n            if prefix:\n                if prefix[-1] == ' ':\n                    result.append(prefix[:-1])\n                elif x[:len(prefix)] != prefix:\n                    x = prefix + x\n\n            result.append(x)\n\n            if suffix:\n                if suffix[0] == ' ':\n                    result.append(suffix[1:])\n                elif x[-len(suffix):] != suffix:\n                    result[-1] = result[-1]+suffix\n\n    return result", "response": "Concatenates the prefix and suffix arguments onto each element of the list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _stripixes(prefix, itms, suffix, stripprefixes, stripsuffixes, env, c=None):\n\n    if not itms:\n        return itms\n\n    if not callable(c):\n        env_c = env['_concat']\n        if env_c != _concat and callable(env_c):\n            # There's a custom _concat() method in the construction\n            # environment, and we've allowed people to set that in\n            # the past (see test/custom-concat.py), so preserve the\n            # backwards compatibility.\n            c = env_c\n        else:\n            c = _concat_ixes\n\n    stripprefixes = list(map(env.subst, SCons.Util.flatten(stripprefixes)))\n    stripsuffixes = list(map(env.subst, SCons.Util.flatten(stripsuffixes)))\n\n    stripped = []\n    for l in SCons.PathList.PathList(itms).subst_path(env, None, None):\n        if isinstance(l, SCons.Node.FS.File):\n            stripped.append(l)\n            continue\n\n        if not SCons.Util.is_String(l):\n            l = str(l)\n\n        for stripprefix in stripprefixes:\n            lsp = len(stripprefix)\n            if l[:lsp] == stripprefix:\n                l = l[lsp:]\n                # Do not strip more than one prefix\n                break\n\n        for stripsuffix in stripsuffixes:\n            lss = len(stripsuffix)\n            if l[-lss:] == stripsuffix:\n                l = l[:-lss]\n                # Do not strip more than one suffix\n                break\n\n        stripped.append(l)\n\n    return c(prefix, stripped, suffix, env)", "response": "This function is used to strips the prefix or suffix from the list items and returns the list items that are found in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess defines resolving strings lists dictionaries into a list of strings", "response": "def processDefines(defs):\n    \"\"\"process defines, resolving strings, lists, dictionaries, into a list of\n    strings\n    \"\"\"\n    if SCons.Util.is_List(defs):\n        l = []\n        for d in defs:\n            if d is None:\n                continue\n            elif SCons.Util.is_List(d) or isinstance(d, tuple):\n                if len(d) >= 2:\n                    l.append(str(d[0]) + '=' + str(d[1]))\n                else:\n                    l.append(str(d[0]))\n            elif SCons.Util.is_Dict(d):\n                for macro,value in d.items():\n                    if value is not None:\n                        l.append(str(macro) + '=' + str(value))\n                    else:\n                        l.append(str(macro))\n            elif SCons.Util.is_String(d):\n                l.append(str(d))\n            else:\n                raise SCons.Errors.UserError(\"DEFINE %s is not a list, dict, string or None.\"%repr(d))\n    elif SCons.Util.is_Dict(defs):\n        # The items in a dictionary are stored in random order, but\n        # if the order of the command-line options changes from\n        # invocation to invocation, then the signature of the command\n        # line will change and we'll get random unnecessary rebuilds.\n        # Consequently, we have to sort the keys to ensure a\n        # consistent order...\n        l = []\n        for k,v in sorted(defs.items()):\n            if v is None:\n                l.append(str(k))\n            else:\n                l.append(str(k) + '=' + str(v))\n    else:\n        l = [str(defs)]\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning this optimization pass on the sensor graph If necessary, information on the device model being targeted can be found in the associated model argument. Args: sensor_graph (SensorGraph): The sensor graph to optimize model (DeviceModel): The device model we're using", "response": "def run(self, sensor_graph, model):\n        \"\"\"Run this optimization pass on the sensor graph\n\n        If necessary, information on the device model being targeted\n        can be found in the associated model argument.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph to optimize\n            model (DeviceModel): The device model we're using\n        \"\"\"\n\n        # We can only eliminate a node if the following checks are true\n        # 1. It has no other nodes connected to it\n        # 2. Its stream is not an output of the entire sensor graph\n        # 3. Its stream is autogenerated by the compiler\n        # 4. Its operation has no side effects\n        # 5. Its stream is not buffered so the value will not be accessible\n\n        for node, inputs, outputs in sensor_graph.iterate_bfs():\n            can_remove = False\n\n            # Check 1\n            if len(outputs) != 0:\n                continue\n\n            # Check 2\n            if sensor_graph.is_output(node.stream):\n                continue\n\n            # Check 3\n            if node.stream.stream_id < StreamAllocator.StartingID:\n                continue\n\n            # Check 4\n            if node.func_name == u'call_rpc':\n                continue\n\n            # Check 5\n            if node.stream.buffered:\n                # FIXME: Add a warning here if the stream is buffered since\n                # its weird for the user to be saving useless data to flash\n                continue\n\n            # Check 6\n            if node.func_name == u'trigger_streamer':\n                continue\n\n            # If all of the checks above have passed, we have found a useless\n            # node, let's remove it and return True so we run the pass again\n            # and look for additional nodes that are now made useles because\n            # of the removal of this one.\n            for input_node in inputs:\n                input_node.outputs.remove(node)\n\n            if node in sensor_graph.roots:\n                sensor_graph.roots.remove(node)\n\n            sensor_graph.nodes.remove(node)\n\n            # FIXME: Check if we need to destroy any walkers here\n\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ReportLength(cls, header):\n\n        parsed_header = cls._parse_header(header)\n\n        auth_size = cls._AUTH_BLOCK_LENGTHS.get(parsed_header.auth_type)\n        if auth_size is None:\n            raise DataError(\"Unknown auth block size in BroadcastReport\")\n\n        return cls._HEADER_LENGTH + parsed_header.reading_length + auth_size", "response": "Calculates the total length of this report."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FromReadings(cls, uuid, readings, sent_timestamp=0):\n\n        header = struct.pack(\"<BBHLLL\", cls.ReportType, 0, len(readings)*16, uuid, sent_timestamp, 0)\n\n        packed_readings = bytearray()\n\n        for reading in readings:\n            packed_reading = struct.pack(\"<HHLLL\", reading.stream, 0, reading.reading_id,\n                                         reading.raw_time, reading.value)\n            packed_readings += bytearray(packed_reading)\n\n        return BroadcastReport(bytearray(header) + packed_readings)", "response": "Generate a broadcast report from a list of readings and a uuid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes this report into a list of visible readings.", "response": "def decode(self):\n        \"\"\"Decode this report into a list of visible readings.\"\"\"\n\n        parsed_header = self._parse_header(self.raw_report[:self._HEADER_LENGTH])\n\n        auth_size = self._AUTH_BLOCK_LENGTHS.get(parsed_header.auth_type)\n        assert auth_size is not None\n        assert parsed_header.reading_length % 16 == 0\n\n        time_base = self.received_time - datetime.timedelta(seconds=parsed_header.sent_timestamp)\n\n        readings = self.raw_report[self._HEADER_LENGTH:self._HEADER_LENGTH + parsed_header.reading_length]\n        parsed_readings = []\n\n        for i in range(0, len(readings), 16):\n            reading = readings[i:i+16]\n            stream, _, reading_id, timestamp, value = struct.unpack(\"<HHLLL\", reading)\n\n            parsed = IOTileReading(timestamp, stream, value, time_base=time_base, reading_id=reading_id)\n            parsed_readings.append(parsed)\n\n        self.sent_timestamp = parsed_header.sent_timestamp\n        self.origin = parsed_header.uuid\n\n        return parsed_readings, []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the device adapter by removing all active connections and resetting scan and advertising to have a clean starting state.", "response": "def _initialize_system_sync(self):\n        \"\"\"Initialize the device adapter by removing all active connections and resetting scan and advertising to have\n        a clean starting state.\"\"\"\n        connected_devices = self.bable.list_connected_devices()\n        for device in connected_devices:\n            self.disconnect_sync(device.connection_handle)\n\n        self.stop_scan()\n\n        self.set_advertising(False)\n\n        # Register the GATT table to send the right services and characteristics when probed (like an IOTile device)\n        self.register_gatt_table()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self, device):\n\n        super(NativeBLEVirtualInterface, self).start(device)\n        self.set_advertising(True)", "response": "Start serving access to this VirtualIOTileDevice."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_gatt_table(self):\n        services = [BLEService, TileBusService]\n\n        characteristics = [\n            NameChar,\n            AppearanceChar,\n            ReceiveHeaderChar,\n            ReceivePayloadChar,\n            SendHeaderChar,\n            SendPayloadChar,\n            StreamingChar,\n            HighSpeedChar,\n            TracingChar\n        ]\n\n        self.bable.set_gatt_table(services, characteristics)", "response": "Register the GATT table into the BLE."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _scan_response(self):\n        voltage = struct.pack(\"<H\", int(self.voltage*256))\n        reading = struct.pack(\"<HLLL\", 0xFFFF, 0, 0, 0)\n\n        response = voltage + reading\n\n        return response", "response": "Create scan response data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disconnect_sync(self, connection_handle):\n\n        self.bable.disconnect(connection_handle=connection_handle, sync=True)", "response": "Synchronously disconnect from whoever has connected to us\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_connected(self, device):\n        self._logger.debug(\"Device connected event: {}\".format(device))\n\n        self.connected = True\n        self._connection_handle = device['connection_handle']\n        self.device.connected = True\n        self._audit('ClientConnected')", "response": "Callback function called when a connected event has been received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_disconnected(self, device):\n\n        self._logger.debug(\"Device disconnected event: {}\".format(device))\n\n        if self.streaming:\n            self.device.close_streaming_interface()\n            self.streaming = False\n\n        if self.tracing:\n            self.device.close_tracing_interface()\n            self.tracing = False\n\n        self.device.connected = False\n        self.connected = False\n        self._connection_handle = 0\n        self.header_notif = False\n        self.payload = False\n\n        self._clear_reports()\n        self._clear_traces()\n\n        self._defer(self.set_advertising, [True])\n        self._audit('ClientDisconnected')", "response": "Callback function called when a device is disconnected."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling an RPC given a header and possibly a previously sent payload.", "response": "def _call_rpc(self, header):\n        \"\"\"Call an RPC given a header and possibly a previously sent payload\n        It is executed in the baBLE working thread: should not be blocking.\n\n        Args:\n            header (bytearray): The RPC header we should call\n        \"\"\"\n\n        length, _, cmd, feature, address = struct.unpack(\"<BBBBB\", bytes(header))\n        rpc_id = (feature << 8) | cmd\n\n        payload = self.rpc_payload[:length]\n\n        status = (1 << 6)\n        try:\n            response = self.device.call_rpc(address, rpc_id, bytes(payload))\n            if len(response) > 0:\n                status |= (1 << 7)\n        except (RPCInvalidIDError, RPCNotFoundError):\n            status = 2  # FIXME: Insert the correct ID here\n            response = b''\n        except TileNotFoundError:\n            status = 0xFF\n            response = b''\n        except Exception:\n            status = 3\n            response = b''\n            self._logger.exception(\"Exception raise while calling rpc, header=%s, payload=%s\", header, payload)\n\n        self._audit(\n            \"RPCReceived\",\n            rpc_id=rpc_id,\n            address=address,\n            payload=binascii.hexlify(payload),\n            status=status,\n            response=binascii.hexlify(response)\n        )\n\n        resp_header = struct.pack(\"<BBBB\", status, 0, 0, len(response))\n\n        if len(response) > 0:\n            self._send_rpc_response(\n                (ReceiveHeaderChar.value_handle, resp_header),\n                (ReceivePayloadChar.value_handle, response)\n            )\n        else:\n            self._send_rpc_response((ReceiveHeaderChar.value_handle, resp_header))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_notification(self, handle, payload):\n\n        self.bable.notify(\n            connection_handle=self._connection_handle,\n            attribute_handle=handle,\n            value=payload\n        )", "response": "Send a notification over the BLE"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _send_rpc_response(self, *packets):\n\n        if len(packets) == 0:\n            return\n\n        handle, payload = packets[0]\n\n        try:\n            self._send_notification(handle, payload)\n        except bable_interface.BaBLEException as err:\n            if err.packet.status == 'Rejected':  # If we are streaming too fast, back off and try again\n                time.sleep(0.05)\n                self._defer(self._send_rpc_response, list(packets))\n            else:\n                self._audit('ErrorSendingRPCResponse')\n                self._logger.exception(\"Error while sending RPC response, handle=%s, payload=%s\", handle, payload)\n\n            return\n\n        if len(packets) > 1:\n            self._defer(self._send_rpc_response, list(packets[1:]))", "response": "Send an RPC response to one or more packets."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _stream_data(self, chunk=None):\n\n        # If we failed to transmit a chunk, we will be requeued with an argument\n        self._stream_sm_running = True\n\n        if chunk is None:\n            chunk = self._next_streaming_chunk(20)\n\n        if chunk is None or len(chunk) == 0:\n            self._stream_sm_running = False\n            return\n\n        try:\n            self._send_notification(StreamingChar.value_handle, chunk)\n            self._defer(self._stream_data)\n        except bable_interface.BaBLEException as err:\n            if err.packet.status == 'Rejected':  # If we are streaming too fast, back off and try again\n                time.sleep(0.05)\n                self._defer(self._stream_data, [chunk])\n            else:\n                self._audit('ErrorStreamingReport')  # If there was an error, stop streaming but don't choke\n                self._logger.exception(\"Error while streaming data\")", "response": "Stream the next 20 byte chunks of data from the ble client."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends tracing data to the ble client.", "response": "def _send_trace(self, chunk=None):\n        \"\"\"Stream tracing data to the ble client in 20 byte chunks\n\n        Args:\n            chunk (bytearray): A chunk that should be sent instead of requesting a\n                new chunk from the pending reports.\n        \"\"\"\n\n        self._trace_sm_running = True\n        # If we failed to transmit a chunk, we will be requeued with an argument\n        if chunk is None:\n            chunk = self._next_tracing_chunk(20)\n\n        if chunk is None or len(chunk) == 0:\n            self._trace_sm_running = False\n            return\n\n        try:\n            self._send_notification(TracingChar.value_handle, chunk)\n            self._defer(self._send_trace)\n        except bable_interface.BaBLEException as err:\n            if err.packet.status == 'Rejected':  # If we are streaming too fast, back off and try again\n                time.sleep(0.05)\n                self._defer(self._send_trace, [chunk])\n            else:\n                self._audit('ErrorStreamingTrace')  # If there was an error, stop streaming but don't choke\n                self._logger.exception(\"Error while tracing data\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _populate_name_map(self):\n\n        services = await self.sync_services()\n\n        with self._state_lock:\n            self.services = services\n\n            for i, name in enumerate(self.services.keys()):\n                self._name_map[i] = name", "response": "Populate the name map of the services as reported by the supervisor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the locally synced information for a service.", "response": "def local_service(self, name_or_id):\n        \"\"\"Get the locally synced information for a service.\n\n        This method is safe to call outside of the background event loop\n        without any race condition.  Internally it uses a thread-safe mutex to\n        protect the local copies of supervisor data and ensure that it cannot\n        change while this method is iterating over it.\n\n        Args:\n            name_or_id (string or int): Either a short name for the service or\n                a numeric id.\n\n        Returns:\n            ServiceState: the current state of the service synced locally\n                at the time of the call.\n        \"\"\"\n\n        if not self._loop.inside_loop():\n            self._state_lock.acquire()\n\n        try:\n            if isinstance(name_or_id, int):\n                if name_or_id not in self._name_map:\n                    raise ArgumentError(\"Unknown ID used to look up service\", id=name_or_id)\n                name = self._name_map[name_or_id]\n            else:\n                name = name_or_id\n            if name not in self.services:\n                raise ArgumentError(\"Unknown service name\", name=name)\n\n            return copy(self.services[name])\n        finally:\n            if not self._loop.inside_loop():\n                self._state_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of id name pairs for all of the known synced services.", "response": "def local_services(self):\n        \"\"\"Get a list of id, name pairs for all of the known synced services.\n\n        This method is safe to call outside of the background event loop\n        without any race condition.  Internally it uses a thread-safe mutex to\n        protect the local copies of supervisor data and ensure that it cannot\n        change while this method is iterating over it.\n\n        Returns:\n            list (id, name): A list of tuples with id and service name sorted by id\n                from low to high\n        \"\"\"\n\n        if not self._loop.inside_loop():\n            self._state_lock.acquire()\n\n        try:\n            return sorted([(index, name) for index, name in self._name_map.items()], key=lambda element: element[0])\n        finally:\n            if not self._loop.inside_loop():\n                self._state_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def sync_services(self):\n\n        services = {}\n        servs = await self.list_services()\n\n        for i, serv in enumerate(servs):\n            info = await self.service_info(serv)\n            status = await self.service_status(serv)\n            messages = await self.get_messages(serv)\n            headline = await self.get_headline(serv)\n\n            services[serv] = states.ServiceState(info['short_name'], info['long_name'], info['preregistered'], i)\n            services[serv].state = status['numeric_status']\n\n            for message in messages:\n                services[serv].post_message(message.level, message.message, message.count, message.created)\n            if headline is not None:\n                services[serv].set_headline(headline.level, headline.message, headline.created)\n\n        return services", "response": "Poll the current state of all services."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget stored messages for a service.", "response": "async def get_messages(self, name):\n        \"\"\"Get stored messages for a service.\n\n        Args:\n            name (string): The name of the service to get messages from.\n\n        Returns:\n            list(ServiceMessage): A list of the messages stored for this service\n        \"\"\"\n\n        resp = await self.send_command(OPERATIONS.CMD_QUERY_MESSAGES, {'name': name},\n                                       MESSAGES.QueryMessagesResponse, timeout=5.0)\n\n        return [states.ServiceMessage.FromDictionary(x) for x in resp]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the headline for a service.", "response": "async def get_headline(self, name):\n        \"\"\"Get stored messages for a service.\n\n        Args:\n            name (string): The name of the service to get messages from.\n\n        Returns:\n            ServiceMessage: the headline or None if no headline has been set\n        \"\"\"\n\n        resp = await self.send_command(OPERATIONS.CMD_QUERY_HEADLINE, {'name': name},\n                                       MESSAGES.QueryHeadlineResponse, timeout=5.0)\n\n        if resp is not None:\n            resp = states.ServiceMessage.FromDictionary(resp)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npulling descriptive info of a service by name.", "response": "async def service_info(self, name):\n        \"\"\"Pull descriptive info of a service by name.\n\n        Information returned includes the service's user friendly\n        name and whether it was preregistered or added dynamically.\n\n        Returns:\n            dict: A dictionary of service information with the following keys\n                set:\n                long_name (string): The user friendly name of the service\n                preregistered (bool): Whether the service was explicitly\n                    called out as a preregistered service.\n        \"\"\"\n\n        return await self.send_command(OPERATIONS.CMD_QUERY_INFO, {'name': name},\n                                       MESSAGES.QueryInfoResponse, timeout=5.0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a heartbeat for a specific service.", "response": "async def send_heartbeat(self, name):\n        \"\"\"Send a heartbeat for a service.\n\n        Args:\n            name (string): The name of the service to send a heartbeat for\n        \"\"\"\n\n        await self.send_command(OPERATIONS.CMD_HEARTBEAT, {'name': name},\n                                MESSAGES.HeartbeatResponse, timeout=5.0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def update_state(self, name, state):\n\n        await self.send_command(OPERATIONS.CMD_UPDATE_STATE,\n                                {'name': name, 'new_status': state},\n                                MESSAGES.UpdateStateResponse, timeout=5.0)", "response": "Update the state of a service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_headline(self, name, level, message):\n\n        self.post_command(OPERATIONS.CMD_SET_HEADLINE,\n                          {'name': name, 'level': level, 'message': message})", "response": "Asynchronously update the sticky headline for a service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_state(self, name, state):\n\n        self.post_command(OPERATIONS.CMD_UPDATE_STATE,\n                          {'name': name, 'new_status': state})", "response": "Asynchronously update the state of a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def service_status(self, name):\n\n        return await self.send_command(OPERATIONS.CMD_QUERY_STATUS, {'name': name},\n                                       MESSAGES.QueryStatusResponse, timeout=5.0)", "response": "Pull the current status of a service by name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send_rpc(self, name, rpc_id, payload, timeout=1.0):\n\n        msg = dict(name=name, rpc_id=rpc_id, payload=payload, timeout=timeout)\n\n        try:\n            resp = await self.send_command(OPERATIONS.CMD_SEND_RPC, msg,\n                                           MESSAGES.SendRPCResponse, timeout=timeout + 1)\n        except asyncio.TimeoutError:\n            resp = dict(result='timeout', response=b'')\n\n        return resp", "response": "Send an RPC to a service and synchronously wait for the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def register_service(self, short_name, long_name, allow_duplicate=True):\n\n        try:\n            await self.send_command(OPERATIONS.CMD_REGISTER_SERVICE, dict(name=short_name, long_name=long_name),\n                                    MESSAGES.RegisterServiceResponse)\n        except ArgumentError:\n            if not allow_duplicate:\n                raise", "response": "Register a new service with the service manager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister to act as the RPC agent for this service.", "response": "async def register_agent(self, short_name):\n        \"\"\"Register to act as the RPC agent for this service.\n\n        After this call succeeds, all requests to send RPCs to this service\n        will be routed through this agent.\n\n        Args:\n            short_name (str): A unique short name for this service that functions\n                as an id\n        \"\"\"\n\n        await self.send_command(OPERATIONS.CMD_SET_AGENT, {'name': short_name},\n                                MESSAGES.SetAgentResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _on_status_change(self, update):\n\n        info = update['payload']\n        new_number = info['new_status']\n        name = update['service']\n\n        if name not in self.services:\n            return\n\n        with self._state_lock:\n            is_changed = self.services[name].state != new_number\n            self.services[name].state = new_number\n\n        # Notify about this service state change if anyone is listening\n        if self._on_change_callback and is_changed:\n            self._on_change_callback(name, self.services[name].id, new_number, False, False)", "response": "Update a service that has its status updated."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new service.", "response": "async def _on_service_added(self, update):\n        \"\"\"Add a new service.\"\"\"\n\n        info = update['payload']\n        name = info['short_name']\n\n        if name in self.services:\n            return\n\n        with self._state_lock:\n            new_id = len(self.services)\n            serv = states.ServiceState(name, info['long_name'],\n                                       info['preregistered'], new_id)\n            self.services[name] = serv\n            self._name_map[new_id] = name\n\n        # Notify about this new service if anyone is listening\n        if self._on_change_callback:\n            self._on_change_callback(name, new_id, serv.state, True, False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreceive a new heartbeat for a service.", "response": "async def _on_heartbeat(self, update):\n        \"\"\"Receive a new heartbeat for a service.\"\"\"\n\n        name = update['service']\n\n        if name not in self.services:\n            return\n\n        with self._state_lock:\n            self.services[name].heartbeat()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _on_message(self, update):\n\n        name = update['service']\n        message_obj = update['payload']\n\n        if name not in self.services:\n            return\n\n        with self._state_lock:\n            self.services[name].post_message(message_obj['level'], message_obj['message'])", "response": "Receive a message from a service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _on_headline(self, update):\n\n        name = update['service']\n        message_obj = update['payload']\n        new_headline = False\n\n        if name not in self.services:\n            return\n\n        with self._state_lock:\n            self.services[name].set_headline(message_obj['level'], message_obj['message'])\n\n            if self.services[name].headline.count == 1:\n                new_headline = True\n\n        # Notify about this service state change if anyone is listening\n        # headline changes are only reported if they are not duplicates\n        if self._on_change_callback and new_headline:\n            self._on_change_callback(name, self.services[name].id, self.services[name].state, False, True)", "response": "Receive a headline from a service."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles an RPC command.", "response": "async def _on_rpc_command(self, event):\n        \"\"\"Received an RPC command that we should execute.\"\"\"\n\n        payload = event['payload']\n        rpc_id = payload['rpc_id']\n        tag = payload['response_uuid']\n        args = payload['payload']\n\n        result = 'success'\n        response = b''\n\n        if self._rpc_dispatcher is None or not self._rpc_dispatcher.has_rpc(rpc_id):\n            result = 'rpc_not_found'\n        else:\n            try:\n                response = self._rpc_dispatcher.call_rpc(rpc_id, args)\n                if inspect.iscoroutine(response):\n                    response = await response\n            except RPCInvalidArgumentsError:\n                result = 'invalid_arguments'\n            except RPCInvalidReturnValueError:\n                result = 'invalid_response'\n            except Exception: #pylint:disable=broad-except;We are being called in a background task\n                self._logger.exception(\"Exception handling RPC 0x%04X\", rpc_id)\n                result = 'execution_exception'\n\n        message = dict(response_uuid=tag, result=result, response=response)\n\n        try:\n            await self.send_command(OPERATIONS.CMD_RESPOND_RPC, message,\n                                    MESSAGES.RespondRPCResponse)\n        except:  #pylint:disable=bare-except;We are being called in a background worker\n            self._logger.exception(\"Error sending response to RPC 0x%04X\", rpc_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the stored messages for a service.", "response": "def get_messages(self, name):\n        \"\"\"Get stored messages for a service.\n\n        Args:\n            name (string): The name of the service to get messages from.\n\n        Returns:\n            list(ServiceMessage): A list of the messages stored for this service\n        \"\"\"\n\n        return self._loop.run_coroutine(self._client.get_messages(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the headline for a service.", "response": "def get_headline(self, name):\n        \"\"\"Get stored messages for a service.\n\n        Args:\n            name (string): The name of the service to get messages from.\n\n        Returns:\n            ServiceMessage: the headline or None if no headline has been set\n        \"\"\"\n\n        return self._loop.run_coroutine(self._client.get_headline(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_heartbeat(self, name):\n\n        return self._loop.run_coroutine(self._client.send_heartbeat(name))", "response": "Send a heartbeat for a specific service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npull descriptive info of a service by name.", "response": "def service_info(self, name):\n        \"\"\"Pull descriptive info of a service by name.\n\n        Information returned includes the service's user friendly\n        name and whether it was preregistered or added dynamically.\n\n        Returns:\n            dict: A dictionary of service information with the following keys\n                set:\n                long_name (string): The user friendly name of the service\n                preregistered (bool): Whether the service was explicitly\n                    called out as a preregistered service.\n        \"\"\"\n\n        return self._loop.run_coroutine(self._client.service_info(name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_state(self, name, state):\n\n        self._loop.run_coroutine(self._client.update_state(name, state))", "response": "Updates the state of a service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_headline(self, name, level, message):\n\n        self._client.post_headline(name, level, message)", "response": "Asynchronously update the sticky headline for a service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npull the current status of a service by name.", "response": "def service_status(self, name):\n        \"\"\"Pull the current status of a service by name.\n\n        Returns:\n            dict: A dictionary of service status\n        \"\"\"\n\n        return self._loop.run_coroutine(self._client.service_status(name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an RPC to a service and synchronously wait for the response.", "response": "def send_rpc(self, name, rpc_id, payload, timeout=1.0):\n        \"\"\"Send an RPC to a service and synchronously wait for the response.\n\n        Args:\n            name (str): The short name of the service to send the RPC to\n            rpc_id (int): The id of the RPC we want to call\n            payload (bytes): Any binary arguments that we want to send\n            timeout (float): The number of seconds to wait for the RPC to finish\n                before timing out and returning\n\n        Returns:\n            dict: A response dictionary with 1 or 2 keys set\n                'result': one of 'success', 'service_not_found',\n                    or 'rpc_not_found', 'timeout'\n                'response': the binary response object if the RPC was successful\n        \"\"\"\n\n        return self._loop.run_coroutine(self._client.send_rpc(name, rpc_id, payload, timeout))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new service with the service manager.", "response": "def register_service(self, short_name, long_name, allow_duplicate=True):\n        \"\"\"Register a new service with the service manager.\n\n        Args:\n            short_name (string): A unique short name for this service that functions\n                as an id\n            long_name (string): A user facing name for this service\n            allow_duplicate (boolean): Don't throw an error if this service is already\n                registered.  This is important if the service is preregistered for example.\n        Raises:\n            ArgumentError: if the short_name is already taken\n        \"\"\"\n\n        self._loop.run_coroutine(self._client.register_service(short_name, long_name, allow_duplicate))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_agent(self, short_name):\n\n        self._loop.run_coroutine(self._client.register_agent(short_name))", "response": "Register to act as the RPC agent for this service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute statement before children are executed.", "response": "def execute_before(self, sensor_graph, scope_stack):\n        \"\"\"Execute statement before children are executed.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        parent = scope_stack[-1]\n        new_scope = TriggerScope(sensor_graph, scope_stack, parent.clock(self.interval, basis=self.basis))\n        scope_stack.append(new_scope)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute this statement on the sensor_graph given the current scope tree.", "response": "def execute(self, sensor_graph, scope_stack):\n        \"\"\"Execute this statement on the sensor_graph given the current scope tree.\n\n        This adds a single node to the sensor graph with subtract as the function\n        so that the current scope's trigger stream has the subtract_stream's value\n        subtracted from it.\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        if self.subtract_stream.stream_type != DataStream.ConstantType:\n            raise SensorGraphSemanticError(\"You can only subtract a constant value currently\", stream=self.subtract_stream)\n\n        parent = scope_stack[-1]\n        alloc = parent.allocator\n\n        trigger_stream, trigger_cond = parent.trigger_chain()\n\n        sensor_graph.add_node(u\"({} always && {} {}) => {} using {}\".format(self.subtract_stream, trigger_stream, trigger_cond, self.stream, 'subtract_afromb'))\n\n        value = self.default\n        if value is None:\n            value = 0\n\n        if self.default is not None and self.subtract_stream in sensor_graph.constant_database:\n            raise SensorGraphSemanticError(\"Attempted to set the same constant stream twice\", stream=self.subtract_stream, new_value=self.default)\n        elif self.default is None and self.subtract_stream in sensor_graph.constant_database:\n            return\n\n        sensor_graph.add_constant(self.subtract_stream, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndecode a msgpacked datetime.", "response": "def _decode_datetime(obj):\n    \"\"\"Decode a msgpack'ed datetime.\"\"\"\n\n    if '__datetime__' in obj:\n        obj = datetime.datetime.strptime(obj['as_str'].decode(), \"%Y%m%dT%H:%M:%S.%f\")\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding a msgpcked datetime.", "response": "def _encode_datetime(obj):\n    \"\"\"Encode a msgpck'ed datetime.\"\"\"\n\n    if isinstance(obj, datetime.datetime):\n        obj = {'__datetime__': True, 'as_str': obj.strftime(\"%Y%m%dT%H:%M:%S.%f\").encode()}\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating versioned shared library suffix from a unversioned one.", "response": "def _versioned_lib_suffix(env, suffix, version):\n    \"\"\"Generate versioned shared library suffix from a unversioned one.\n       If suffix='.dll', and version='0.1.2', then it returns '-0-1-2.dll'\"\"\"\n    Verbose = False\n    if Verbose:\n        print(\"_versioned_lib_suffix: suffix= \", suffix)\n        print(\"_versioned_lib_suffix: version= \", version)\n    cygversion = re.sub('\\.', '-', version)\n    if not suffix.startswith('-' + cygversion):\n        suffix = '-' + cygversion + suffix\n    if Verbose:\n        print(\"_versioned_lib_suffix: return suffix= \", suffix)\n    return suffix"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _versioned_implib_symlinks(env, libnode, version, prefix, suffix, **kw):\n    Verbose = False\n\n    if Verbose:\n        print(\"_versioned_implib_symlinks: libnode=%r\" % libnode.get_path())\n        print(\"_versioned_implib_symlinks: version=%r\" % version)\n\n    try: libtype = kw['libtype']\n    except KeyError: libtype = 'ShLib'\n\n\n    linkdir = os.path.dirname(libnode.get_path())\n    if Verbose:\n        print(\"_versioned_implib_symlinks: linkdir=%r\" % linkdir)\n\n    name = SCons.Tool.ImpLibNameGenerator(env, libnode,\n                                          implib_libtype=libtype,\n                                          generator_libtype=libtype+'ImpLib')\n    if Verbose:\n        print(\"_versioned_implib_symlinks: name=%r\" % name)\n\n    major = version.split('.')[0]\n\n    link0 = env.fs.File(os.path.join(linkdir, name))\n    symlinks = [(link0, libnode)]\n\n    if Verbose:\n        print(\"_versioned_implib_symlinks: return symlinks=%r\" % SCons.Tool.StringizeLibSymlinks(symlinks))\n\n    return symlinks", "response": "Generate link names that should be created for a versioned shared library."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding Builders and construction variables for cyglink to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for cyglink to an Environment.\"\"\"\n    gnulink.generate(env)\n\n    env['LINKFLAGS']   = SCons.Util.CLVar('-Wl,-no-undefined')\n\n    env['SHLINKCOM'] = shlib_action\n    env['LDMODULECOM'] = ldmod_action\n    env.Append(SHLIBEMITTER = [shlib_emitter])\n    env.Append(LDMODULEEMITTER = [ldmod_emitter])\n\n    env['SHLIBPREFIX']         = 'cyg'\n    env['SHLIBSUFFIX']         = '.dll'\n\n    env['IMPLIBPREFIX']        = 'lib'\n    env['IMPLIBSUFFIX']        = '.dll.a'\n\n    # Variables used by versioned shared libraries\n    env['_SHLIBVERSIONFLAGS']      = '$SHLIBVERSIONFLAGS'\n    env['_LDMODULEVERSIONFLAGS']   = '$LDMODULEVERSIONFLAGS'\n\n    # SHLIBVERSIONFLAGS and LDMODULEVERSIONFLAGS are same as in gnulink...\n\n    # LINKCALLBACKS are NOT inherited from gnulink\n    env['LINKCALLBACKS'] = {\n        'VersionedShLibSuffix'          : _versioned_lib_suffix,\n        'VersionedLdModSuffix'          : _versioned_lib_suffix,\n        'VersionedImpLibSuffix'         : _versioned_lib_suffix,\n        'VersionedShLibName'            : link._versioned_shlib_name,\n        'VersionedLdModName'            : link._versioned_ldmod_name,\n        'VersionedShLibImpLibName'      : lambda *args: _versioned_implib_name(*args, libtype='ShLib'),\n        'VersionedLdModImpLibName'      : lambda *args: _versioned_implib_name(*args, libtype='LdMod'),\n        'VersionedShLibImpLibSymlinks'  : lambda *args: _versioned_implib_symlinks(*args, libtype='ShLib'),\n        'VersionedLdModImpLibSymlinks'  : lambda *args: _versioned_implib_symlinks(*args, libtype='LdMod'),\n    }\n\n    # these variables were set by gnulink but are not used in cyglink\n    try: del env['_SHLIBSONAME']\n    except KeyError: pass\n    try: del env['_LDMODULESONAME']\n    except KeyError: pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for xlc / Visual Age suite to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for xlc / Visual Age\n    suite to an Environment.\"\"\"\n    path, _cc, version = get_xlc(env)\n    if path and _cc:\n        _cc = os.path.join(path, _cc)\n\n    if 'CC' not in env:\n        env['CC'] = _cc\n\n    cc.generate(env)\n\n    if version:\n        env['CCVERSION'] = version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndispatching a message to a callback based on its schema.", "response": "def dispatch(self, message):\n        \"\"\"Dispatch a message to a callback based on its schema.\n\n        Args:\n            message (dict): The message to dispatch\n        \"\"\"\n\n        for validator, callback in self.validators:\n            if not validator.matches(message):\n                continue\n\n            callback(message)\n            return\n\n        raise ArgumentError(\"No handler was registered for message\", message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_parser():\n\n    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)\n\n    parser.add_argument('firmware_image', nargs=\"?\", help=\"The firmware image that you wish to load into the emulator\")\n    parser.add_argument('--gdb', '-g', type=int, help=\"Start a GDB server on the given port and wait for a connection\")\n    return parser", "response": "Create command line argument parser."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the iotile-emulate script. Args: raw_args (list): Optional list of commmand line arguments. If not passed these are pulled from sys.argv.", "response": "def main(raw_args=None):\n    \"\"\"Run the iotile-emulate script.\n\n    Args:\n        raw_args (list): Optional list of commmand line arguments.  If not\n            passed these are pulled from sys.argv.\n    \"\"\"\n\n    if raw_args is None:\n        raw_args = sys.argv[1:]\n\n    parser = build_parser()\n    args = parser.parse_args(raw_args)\n\n    if args.firmware_image is None and args.gdb is None:\n        print(\"You must specify either a firmware image or attach a debugger with --gdb <PORT>\")\n        return 1\n\n    test_args = ['qemu-system-gnuarmeclipse', '-verbose', '-verbose', '-board', 'STM32F0-Discovery',\n                 '-nographic', '-monitor', 'null', '-serial', 'null', '--semihosting-config',\n                 'enable=on,target=native', '-d', 'unimp,guest_errors']\n\n    if args.firmware_image:\n        test_args += ['-image', args.firmware_image]\n\n    if args.gdb:\n        test_args += ['--gdb', 'tcp::%d' % args.gdb]\n\n    proc = subprocess.Popen(test_args, stdout=sys.stdout, stderr=sys.stderr)\n\n    try:\n        proc.communicate()\n    except KeyboardInterrupt:\n        proc.terminate()\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate(env):\n    CLVar = SCons.Util.CLVar\n    Action = SCons.Action.Action\n    Builder = SCons.Builder.Builder\n\n    env.SetDefault(QTDIR  = _detect(env),\n                   QT_BINPATH = os.path.join('$QTDIR', 'bin'),\n                   QT_CPPPATH = os.path.join('$QTDIR', 'include'),\n                   QT_LIBPATH = os.path.join('$QTDIR', 'lib'),\n                   QT_MOC = os.path.join('$QT_BINPATH','moc'),\n                   QT_UIC = os.path.join('$QT_BINPATH','uic'),\n                   QT_LIB = 'qt', # may be set to qt-mt\n\n                   QT_AUTOSCAN = 1, # scan for moc'able sources\n\n                   # Some QT specific flags. I don't expect someone wants to\n                   # manipulate those ...\n                   QT_UICIMPLFLAGS = CLVar(''),\n                   QT_UICDECLFLAGS = CLVar(''),\n                   QT_MOCFROMHFLAGS = CLVar(''),\n                   QT_MOCFROMCXXFLAGS = CLVar('-i'),\n\n                   # suffixes/prefixes for the headers / sources to generate\n                   QT_UICDECLPREFIX = '',\n                   QT_UICDECLSUFFIX = '.h',\n                   QT_UICIMPLPREFIX = 'uic_',\n                   QT_UICIMPLSUFFIX = '$CXXFILESUFFIX',\n                   QT_MOCHPREFIX = 'moc_',\n                   QT_MOCHSUFFIX = '$CXXFILESUFFIX',\n                   QT_MOCCXXPREFIX = '',\n                   QT_MOCCXXSUFFIX = '.moc',\n                   QT_UISUFFIX = '.ui',\n\n                   # Commands for the qt support ...\n                   # command to generate header, implementation and moc-file\n                   # from a .ui file\n                   QT_UICCOM = [\n                    CLVar('$QT_UIC $QT_UICDECLFLAGS -o ${TARGETS[0]} $SOURCE'),\n                    CLVar('$QT_UIC $QT_UICIMPLFLAGS -impl ${TARGETS[0].file} '\n                          '-o ${TARGETS[1]} $SOURCE'),\n                    CLVar('$QT_MOC $QT_MOCFROMHFLAGS -o ${TARGETS[2]} ${TARGETS[0]}')],\n                   # command to generate meta object information for a class\n                   # declarated in a header\n                   QT_MOCFROMHCOM = (\n                          '$QT_MOC $QT_MOCFROMHFLAGS -o ${TARGETS[0]} $SOURCE'),\n                   # command to generate meta object information for a class\n                   # declarated in a cpp file\n                   QT_MOCFROMCXXCOM = [\n                    CLVar('$QT_MOC $QT_MOCFROMCXXFLAGS -o ${TARGETS[0]} $SOURCE'),\n                    Action(checkMocIncluded,None)])\n\n    # ... and the corresponding builders\n    uicBld = Builder(action=SCons.Action.Action('$QT_UICCOM', '$QT_UICCOMSTR'),\n                     emitter=uicEmitter,\n                     src_suffix='$QT_UISUFFIX',\n                     suffix='$QT_UICDECLSUFFIX',\n                     prefix='$QT_UICDECLPREFIX',\n                     source_scanner=uicScanner)\n    mocBld = Builder(action={}, prefix={}, suffix={})\n    for h in header_extensions:\n        act = SCons.Action.Action('$QT_MOCFROMHCOM', '$QT_MOCFROMHCOMSTR')\n        mocBld.add_action(h, act)\n        mocBld.prefix[h] = '$QT_MOCHPREFIX'\n        mocBld.suffix[h] = '$QT_MOCHSUFFIX'\n    for cxx in cxx_suffixes:\n        act = SCons.Action.Action('$QT_MOCFROMCXXCOM', '$QT_MOCFROMCXXCOMSTR')\n        mocBld.add_action(cxx, act)\n        mocBld.prefix[cxx] = '$QT_MOCCXXPREFIX'\n        mocBld.suffix[cxx] = '$QT_MOCCXXSUFFIX'\n\n    # register the builders \n    env['BUILDERS']['Uic'] = uicBld\n    env['BUILDERS']['Moc'] = mocBld\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n    static_obj.add_src_builder('Uic')\n    shared_obj.add_src_builder('Uic')\n\n    # We use the emitters of Program / StaticLibrary / SharedLibrary\n    # to scan for moc'able files\n    # We can't refer to the builders directly, we have to fetch them\n    # as Environment attributes because that sets them up to be called\n    # correctly later by our emitter.\n    env.AppendUnique(PROGEMITTER =[AutomocStatic],\n                     SHLIBEMITTER=[AutomocShared],\n                     LDMODULEEMITTER=[AutomocShared],\n                     LIBEMITTER  =[AutomocStatic],\n                     # Of course, we need to link against the qt libraries\n                     CPPPATH=[\"$QT_CPPPATH\"],\n                     LIBPATH=[\"$QT_LIBPATH\"],\n                     LIBS=['$QT_LIB'])", "response": "Add Builders and construction variables for qt to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CPP_to_Python(s):\n    s = CPP_to_Python_Ops_Expression.sub(CPP_to_Python_Ops_Sub, s)\n    for expr, repl in CPP_to_Python_Eval_List:\n        s = expr.sub(repl, s)\n    return s", "response": "Converts a C pre - processor expression into an equivalent\n    Python expression that can be evaluated."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns the contents of a file into a list of easily - processed tuples describing the CPP lines in the file.", "response": "def tupleize(self, contents):\n        \"\"\"\n        Turns the contents of a file into a list of easily-processed\n        tuples describing the CPP lines in the file.\n\n        The first element of each tuple is the line's preprocessor\n        directive (#if, #include, #define, etc., minus the initial '#').\n        The remaining elements are specific to the type of directive, as\n        pulled apart by the regular expression.\n        \"\"\"\n        global CPP_Expression, Table\n        contents = line_continuations.sub('', contents)\n        cpp_tuples = CPP_Expression.findall(contents)\n        return  [(m[0],) + Table[m[0]].match(m[1]).groups() for m in cpp_tuples]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the current dispatch table on the stack and re - initialises the current dispatch table to the default.", "response": "def save(self):\n        \"\"\"\n        Pushes the current dispatch table on the stack and re-initializes\n        the current dispatch table to the default.\n        \"\"\"\n        self.stack.append(self.dispatch_table)\n        self.dispatch_table = self.default_table.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates a C preprocessor expression.", "response": "def eval_expression(self, t):\n        \"\"\"\n        Evaluates a C preprocessor expression.\n\n        This is done by converting it to a Python equivalent and\n        eval()ing it in the C preprocessor namespace we use to\n        track #define values.\n        \"\"\"\n        t = CPP_to_Python(' '.join(t[1:]))\n        try: return eval(t, self.cpp_namespace)\n        except (NameError, TypeError): return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the include file for a given preprocessor tuple.", "response": "def find_include_file(self, t):\n        \"\"\"\n        Finds the #include file for a given preprocessor tuple.\n        \"\"\"\n        fname = t[2]\n        for d in self.searchpath[t[1]]:\n            if d == os.curdir:\n                f = fname\n            else:\n                f = os.path.join(d, fname)\n            if os.path.isfile(f):\n                return f\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_handling_includes(self, t=None):\n        d = self.dispatch_table\n        p = self.stack[-1] if self.stack else self.default_table\n\n        for k in ('import', 'include', 'include_next'):\n            d[k] = p[k]", "response": "Start handling include lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop processing the include and include_next lines.", "response": "def stop_handling_includes(self, t=None):\n        \"\"\"\n        Causes the PreProcessor object to stop processing #import,\n        #include and #include_next lines.\n\n        This method will be called when a #if, #ifdef, #ifndef or #elif\n        evaluates False, or when we reach the #else in a #if, #ifdef,\n        #ifndef or #elif block where a condition already evaluated True.\n        \"\"\"\n        d = self.dispatch_table\n        d['import'] = self.do_nothing\n        d['include'] =  self.do_nothing\n        d['include_next'] =  self.do_nothing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_elif(self, t):\n        d = self.dispatch_table\n        if self.eval_expression(t):\n            self.start_handling_includes()\n            d['elif'] = self.stop_handling_includes\n            d['else'] = self.stop_handling_includes", "response": "Default handling of a #elif line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting handling of a define line.", "response": "def do_define(self, t):\n        \"\"\"\n        Default handling of a #define line.\n        \"\"\"\n        _, name, args, expansion = t\n        try:\n            expansion = int(expansion)\n        except (TypeError, ValueError):\n            pass\n        if args:\n            evaluator = FunctionEvaluator(name, args[1:-1], expansion)\n            self.cpp_namespace[name] = evaluator\n        else:\n            self.cpp_namespace[name] = expansion"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefault handling of a #include line.", "response": "def do_include(self, t):\n        \"\"\"\n        Default handling of a #include line.\n        \"\"\"\n        t = self.resolve_include(t)\n        include_file = self.find_include_file(t)\n        if include_file:\n            #print(\"include_file =\", include_file)\n            self.result.append(include_file)\n            contents = self.read_file(include_file)\n            new_tuples = [('scons_current_file', include_file)] + \\\n                         self.tupleize(contents) + \\\n                         [('scons_current_file', self.current_file)]\n            self.tuples[:] = new_tuples + self.tuples"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_include(self, t):\n\n        s = t[1]\n        while not s[0] in '<\"':\n            #print(\"s =\", s)\n            try:\n                s = self.cpp_namespace[s]\n            except KeyError:\n                m = function_name.search(s)\n                s = self.cpp_namespace[m.group(1)]\n                if callable(s):\n                    args = function_arg_separator.split(m.group(2))\n                    s = s(*args)\n            if not s:\n                return None\n        return (t[0], s[0], s[1:-1])", "response": "Resolve a tuple -ized include line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef emit_rmic_classes(target, source, env):\n    class_suffix = env.get('JAVACLASSSUFFIX', '.class')\n    classdir = env.get('JAVACLASSDIR')\n\n    if not classdir:\n        try:\n            s = source[0]\n        except IndexError:\n            classdir = '.'\n        else:\n            try:\n                classdir = s.attributes.java_classdir\n            except AttributeError:\n                classdir = '.'\n    classdir = env.Dir(classdir).rdir()\n    if str(classdir) == '.':\n        c_ = None\n    else:\n        c_ = str(classdir) + os.sep\n\n    slist = []\n    for src in source:\n        try:\n            classname = src.attributes.java_classname\n        except AttributeError:\n            classname = str(src)\n            if c_ and classname[:len(c_)] == c_:\n                classname = classname[len(c_):]\n            if class_suffix and classname[:-len(class_suffix)] == class_suffix:\n                classname = classname[-len(class_suffix):]\n        s = src.rfile()\n        s.attributes.java_classdir = classdir\n        s.attributes.java_classname = classname\n        slist.append(s)\n\n    stub_suffixes = ['_Stub']\n    if env.get('JAVAVERSION') == '1.4':\n        stub_suffixes.append('_Skel')\n\n    tlist = []\n    for s in source:\n        for suff in stub_suffixes:\n            fname = s.attributes.java_classname.replace('.', os.sep) + \\\n                    suff + class_suffix\n            t = target[0].File(fname)\n            t.attributes.java_lookupdir = target[0]\n            tlist.append(t)\n\n    return tlist, source", "response": "Create and return lists of Java RMI stub and skeleton class files to be created from a set of class files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Builders and construction variables for rmic to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for rmic to an Environment.\"\"\"\n    env['BUILDERS']['RMIC'] = RMICBuilder\n\n    env['RMIC']            = 'rmic'\n    env['RMICFLAGS']       = SCons.Util.CLVar('')\n    env['RMICCOM']         = '$RMIC $RMICFLAGS -d ${TARGET.attributes.java_lookupdir} -classpath ${SOURCE.attributes.java_classdir} ${SOURCES.attributes.java_classname}'\n    env['JAVACLASSSUFFIX']  = '.class'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the scan interval and window in units of ms and set whether active scanning is performed", "response": "def _set_scan_parameters(self, interval=2100, window=2100, active=False):\n        \"\"\"\n        Set the scan interval and window in units of ms and set whether active scanning is performed\n        \"\"\"\n\n        active_num = 0\n        if bool(active):\n            active_num = 1\n\n        interval_num = int(interval*1000/625)\n        window_num = int(window*1000/625)\n\n        payload = struct.pack(\"<HHB\", interval_num, window_num, active_num)\n\n        try:\n            response = self._send_command(6, 7, payload)\n            if response.payload[0] != 0:\n                return False, {'reason': \"Could not set scanning parameters\", 'error': response.payload[0]}\n        except InternalTimeoutError:\n            return False, {'reason': 'Timeout waiting for response'}\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying the system state of the adapter.", "response": "def _query_systemstate(self):\n        \"\"\"Query the maximum number of connections supported by this adapter\n        \"\"\"\n\n        def status_filter_func(event):\n            if event.command_class == 3 and event.command == 0:\n                return True\n\n            return False\n\n        try:\n            response = self._send_command(0, 6, [])\n            maxconn, = unpack(\"<B\", response.payload)\n        except InternalTimeoutError:\n            return False, {'reason': 'Timeout waiting for command response'}\n\n        events = self._wait_process_events(0.5, status_filter_func, lambda x: False)\n\n        conns = []\n        for event in events:\n            handle, flags, addr, addr_type, interval, timeout, lat, bond = unpack(\"<BB6sBHHHB\", event.payload)\n\n            if flags != 0:\n                conns.append(handle)\n\n        return True, {'max_connections': maxconn, 'active_connections': conns}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts scanning forever for BLE devices.", "response": "def _start_scan(self, active):\n        \"\"\"Begin scanning forever\n        \"\"\"\n\n        success, retval = self._set_scan_parameters(active=active)\n        if not success:\n            return success, retval\n\n        try:\n            response = self._send_command(6, 2, [2])\n            if response.payload[0] != 0:\n                self._logger.error('Error starting scan for devices, error=%d', response.payload[0])\n                return False, {'reason': \"Could not initiate scan for ble devices, error_code=%d, response=%s\" % (response.payload[0], response)}\n        except InternalTimeoutError:\n            return False, {'reason': \"Timeout waiting for response\"}\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops scanning for BLE devices", "response": "def _stop_scan(self):\n        \"\"\"Stop scanning for BLE devices\n        \"\"\"\n\n        try:\n            response = self._send_command(6, 4, [])\n            if response.payload[0] != 0:\n                # Error code 129 means we just were not currently scanning\n                if response.payload[0] != 129:\n                    self._logger.error('Error stopping scan for devices, error=%d', response.payload[0])\n\n                return False, {'reason': \"Could not stop scan for ble devices\"}\n        except InternalTimeoutError:\n            return False, {'reason': \"Timeout waiting for response\"}\n        except DeviceNotConfiguredError:\n            return True, {'reason': \"Device not connected (did you disconnect the dongle?\"}\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _probe_services(self, handle):\n\n        code = 0x2800\n\n        def event_filter_func(event):\n            if (event.command_class == 4 and event.command == 2):\n                event_handle, = unpack(\"B\", event.payload[0:1])\n                return event_handle == handle\n\n            return False\n\n        def end_filter_func(event):\n            if (event.command_class == 4 and event.command == 1):\n                event_handle, = unpack(\"B\", event.payload[0:1])\n                return event_handle == handle\n\n            return False\n\n        payload = struct.pack('<BHHBH', handle, 1, 0xFFFF, 2, code)\n\n        try:\n            response = self._send_command(4, 1, payload)\n        except InternalTimeoutError:\n            return False, {'reason': 'Timeout waiting for command response'}\n\n        handle, result = unpack(\"<BH\", response.payload)\n        if result != 0:\n            return False, None\n\n        events = self._wait_process_events(0.5, event_filter_func, end_filter_func)\n        gatt_events = [x for x in events if event_filter_func(x)]\n        end_events = [x for x in events if end_filter_func(x)]\n\n        if len(end_events) == 0:\n            return False, None\n\n        #Make sure we successfully probed the gatt table\n        end_event = end_events[0]\n        _, result, _ = unpack(\"<BHH\", end_event.payload)\n        if result != 0:\n            self._logger.warn(\"Error enumerating GATT table, protocol error code = %d (0x%X)\" % (result, result))\n            return False, None\n\n        services = {}\n        for event in gatt_events:\n            process_gatt_service(services, event)\n\n        return True, {'services': services}", "response": "Probe for all primary services and characteristics in those services\n            Returns True and the result of the probe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprobe gatt services for all associated characteristics in a BLE device.", "response": "def _probe_characteristics(self, conn, services, timeout=5.0):\n        \"\"\"Probe gatt services for all associated characteristics in a BLE device\n\n        Args:\n            conn (int): the connection handle to probe\n            services (dict): a dictionary of services produced by probe_services()\n            timeout (float): the maximum number of seconds to spend in any single task\n        \"\"\"\n\n        for service in services.values():\n            success, result = self._enumerate_handles(conn, service['start_handle'],\n                                                      service['end_handle'])\n\n            if not success:\n                return False, None\n\n            attributes = result['attributes']\n\n            service['characteristics'] = {}\n\n            last_char = None\n            for handle, attribute in attributes.items():\n                if attribute['uuid'].hex[-4:] == '0328':\n                    success, result = self._read_handle(conn, handle, timeout)\n                    if not success:\n                        return False, None\n\n                    value = result['data']\n                    char = parse_characteristic_declaration(value)\n                    service['characteristics'][char['uuid']] = char\n                    last_char = char\n                elif attribute['uuid'].hex[-4:] == '0229':\n                    if last_char is None:\n                        return False, None\n\n                    success, result = self._read_handle(conn, handle, timeout)\n                    if not success:\n                        return False, None\n\n                    value = result['data']\n                    assert len(value) == 2\n                    value, = unpack(\"<H\", value)\n\n                    last_char['client_configuration'] = {'handle': handle, 'value': value}\n\n        return True, {'services': services}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables RPCs for this device.", "response": "def _enable_rpcs(self, conn, services, timeout=1.0):\n        \"\"\"Prepare this device to receive RPCs\n        \"\"\"\n\n        #FIXME: Check for characteristic existence in a try/catch and return failure if not found\n\n        success, result = self._set_notification(conn, services[TileBusService]['characteristics'][TileBusReceiveHeaderCharacteristic], True, timeout)\n        if not success:\n            return success, result\n\n        return self._set_notification(conn, services[TileBusService]['characteristics'][TileBusReceivePayloadCharacteristic], True, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _disable_rpcs(self, conn, services, timeout=1.0):\n\n        success, result = self._set_notification(conn, services[TileBusService]['characteristics'][TileBusReceiveHeaderCharacteristic], False, timeout)\n        if not success:\n            return success, result\n\n        return self._set_notification(conn, services[TileBusService]['characteristics'][TileBusReceivePayloadCharacteristic], False, timeout)", "response": "Prevent this device from receiving more RPCs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_handle(self, conn, handle, ack, value, timeout=1.0):\n\n        conn_handle = conn\n        char_handle = handle\n\n        def write_handle_acked(event):\n            if event.command_class == 4 and event.command == 1:\n                conn, _, char = unpack(\"<BHH\", event.payload)\n\n                return conn_handle == conn and char_handle == char\n\n        data_len = len(value)\n        if data_len > 20:\n            return False, {'reason': 'Data too long to write'}\n\n        payload = struct.pack(\"<BHB%ds\" % data_len, conn_handle, char_handle, data_len, value)\n\n        try:\n            if ack:\n                response = self._send_command(4, 5, payload)\n            else:\n                response = self._send_command(4, 6, payload)\n        except InternalTimeoutError:\n            return False, {'reason': 'Timeout waiting for response to command in _write_handle'}\n\n        _, result = unpack(\"<BH\", response.payload)\n        if result != 0:\n            return False, {'reason': 'Error writing to handle', 'error_code': result}\n\n        if ack:\n            events = self._wait_process_events(timeout, lambda x: False, write_handle_acked)\n            if len(events) == 0:\n                return False, {'reason': 'Timeout waiting for acknowledge on write'}\n\n            _, result, _ = unpack(\"<BHH\", events[0].payload)\n            if result != 0:\n                return False, {'reason': 'Error received during write to handle', 'error_code': result}\n\n        return True, None", "response": "Write to a BLE device characteristic by its handle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_advertising_data(self, packet_type, data):\n\n        payload = struct.pack(\"<BB%ss\" % (len(data)), packet_type, len(data), bytes(data))\n        response = self._send_command(6, 9, payload)\n\n        result, = unpack(\"<H\", response.payload)\n        if result != 0:\n            return False, {'reason': 'Error code from BLED112 setting advertising data', 'code': result}\n\n        return True, None", "response": "Set the advertising data for the current BLED112 system"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the mode of the BLED112", "response": "def _set_mode(self, discover_mode, connect_mode):\n        \"\"\"Set the mode of the BLED112, used to enable and disable advertising\n\n        To enable advertising, use 4, 2.\n        To disable advertising use 0, 0.\n\n        Args:\n            discover_mode (int): The discoverability mode, 0 for off, 4 for on (user data)\n            connect_mode (int): The connectability mode, 0 for of, 2 for undirected connectable\n        \"\"\"\n\n        payload = struct.pack(\"<BB\", discover_mode, connect_mode)\n        response = self._send_command(6, 1, payload)\n\n        result, = unpack(\"<H\", response.payload)\n        if result != 0:\n            return False, {'reason': 'Error code from BLED112 setting mode', 'code': result}\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_notification(self, handle, value):\n\n        value_len = len(value)\n        value = bytes(value)\n\n        payload = struct.pack(\"<BHB%ds\" % value_len, 0xFF, handle, value_len, value)\n\n        response = self._send_command(2, 5, payload)\n        result, = unpack(\"<H\", response.payload)\n        if result != 0:\n            return False, {'reason': 'Error code from BLED112 notifying a value', 'code': result, 'handle': handle, 'value': value}\n\n        return True, None", "response": "Send a notification to all connected clients on a characteristic\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables or disable notifications on a GATT characteristic", "response": "def _set_notification(self, conn, char, enabled, timeout=1.0):\n        \"\"\"Enable/disable notifications on a GATT characteristic\n\n        Args:\n            conn (int): The connection handle for the device we should interact with\n            char (dict): The characteristic we should modify\n            enabled (bool): Should we enable or disable notifications\n            timeout (float): How long to wait before failing\n        \"\"\"\n\n        if 'client_configuration' not in char:\n            return False, {'reason': 'Cannot enable notification without a client configuration attribute for characteristic'}\n\n        props = char['properties']\n        if not props.notify:\n            return False, {'reason': 'Cannot enable notification on a characteristic that does not support it'}\n\n        value = char['client_configuration']['value']\n\n        #Check if we don't have to do anything\n        current_state = bool(value & (1 << 0))\n        if current_state == enabled:\n            return\n\n        if enabled:\n            value |= 1 << 0\n        else:\n            value &= ~(1 << 0)\n\n        char['client_configuration']['value'] = value\n\n        valarray = struct.pack(\"<H\", value)\n        return self._write_handle(conn, char['client_configuration']['handle'], True, valarray, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to a device given its uuid", "response": "def _connect(self, address):\n        \"\"\"Connect to a device given its uuid\n        \"\"\"\n\n        latency = 0\n        conn_interval_min = 6\n        conn_interval_max = 100\n        timeout = 1.0\n\n        try:\n            #Allow passing either a binary address or a hex string\n            if isinstance(address, str) and len(address) > 6:\n                address = address.replace(':', '')\n                address = bytes(bytearray.fromhex(address)[::-1])\n        except ValueError:\n            return False, None\n\n        #Allow simple determination of whether a device has a public or private address\n        #This is not foolproof\n        private_bits = bytearray(address)[-1] >> 6\n        if private_bits == 0b11:\n            address_type = 1\n        else:\n            address_type = 0\n\n        payload = struct.pack(\"<6sBHHHH\", address, address_type, conn_interval_min,\n                              conn_interval_max, int(timeout*100.0), latency)\n        response = self._send_command(6, 3, payload)\n\n        result, handle = unpack(\"<HB\", response.payload)\n        if result != 0:\n            return False, None\n\n        #Now wait for the connection event that says we connected or kill the attempt after timeout\n        def conn_succeeded(event):\n            if event.command_class == 3 and event.command == 0:\n                event_handle, = unpack(\"B\", event.payload[0:1])\n                return event_handle == handle\n\n        #FIXME Hardcoded timeout\n        events = self._wait_process_events(4.0, lambda x: False, conn_succeeded)\n        if len(events) != 1:\n            self._stop_scan()\n            return False, None\n\n        handle, _, addr, _, interval, timeout, latency, _ = unpack(\"<BB6sBHHHB\", events[0].payload)\n        formatted_addr = \":\".join([\"%02X\" % x for x in bytearray(addr)])\n        self._logger.info('Connected to device %s with interval=%d, timeout=%d, latency=%d',\n                          formatted_addr, interval, timeout, latency)\n\n        connection = {\"handle\": handle}\n        return True, connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _disconnect(self, handle):\n\n        payload = struct.pack('<B', handle)\n        response = self._send_command(3, 0, payload)\n\n        conn_handle, result = unpack(\"<BH\", response.payload)\n        if result != 0:\n            self._logger.info(\"Disconnection failed result=%d\", result)\n            return False, None\n\n        assert conn_handle == handle\n\n        def disconnect_succeeded(event):\n            if event.command_class == 3 and event.command == 4:\n                event_handle, = unpack(\"B\", event.payload[0:1])\n                return event_handle == handle\n\n            return False\n\n        #FIXME Hardcoded timeout\n        events = self._wait_process_events(3.0, lambda x: False, disconnect_succeeded)\n        if len(events) != 1:\n            return False, None\n\n        return True, {'handle': handle}", "response": "Disconnect from a device that we have previously connected to a specific entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a BGAPI packet to the dongle and return the response", "response": "def _send_command(self, cmd_class, command, payload, timeout=3.0):\n        \"\"\"\n        Send a BGAPI packet to the dongle and return the response\n        \"\"\"\n\n        if len(payload) > 60:\n            return ValueError(\"Attempting to send a BGAPI packet with length > 60 is not allowed\", actual_length=len(payload), command=command, command_class=cmd_class)\n\n        header = bytearray(4)\n        header[0] = 0\n        header[1] = len(payload)\n        header[2] = cmd_class\n        header[3] = command\n\n        packet = header + bytearray(payload)\n        self._stream.write(bytes(packet))\n\n        #Every command has a response so wait for the response here\n        response = self._receive_packet(timeout)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _receive_packet(self, timeout=3.0):\n\n        while True:\n            response_data = self._stream.read_packet(timeout=timeout)\n            response = BGAPIPacket(is_event=(response_data[0] == 0x80), command_class=response_data[2], command=response_data[3], payload=response_data[4:])\n\n            if response.is_event:\n                if self.event_handler is not None:\n                    self.event_handler(response)\n\n                continue\n\n            return response", "response": "Receive a response packet from a command we re currently interested in."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self, client_id):\n\n        if self.client is not None:\n            raise InternalError(\"Connect called on an alreaded connected MQTT client\")\n\n        client = AWSIoTPythonSDK.MQTTLib.AWSIoTMQTTClient(client_id, useWebsocket=self.websockets)\n\n        if self.websockets:\n            client.configureEndpoint(self.endpoint, 443)\n            client.configureCredentials(self.root)\n\n            if self.iam_session is None:\n                client.configureIAMCredentials(self.iam_key, self.iam_secret)\n            else:\n                client.configureIAMCredentials(self.iam_key, self.iam_secret, self.iam_session)\n        else:\n            client.configureEndpoint(self.endpoint, 8883)\n            client.configureCredentials(self.root, self.key, self.cert)\n\n        client.configureOfflinePublishQueueing(0)\n\n        try:\n            client.connect()\n            self.client = client\n        except operationError as exc:\n            raise InternalError(\"Could not connect to AWS IOT\", message=exc.message)\n\n        self.sequencer.reset()", "response": "Connect to the given client_id and return the unique ID of the created MQTT client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disconnect(self):\n\n        if self.client is None:\n            return\n\n        try:\n            self.client.disconnect()\n        except operationError as exc:\n            raise InternalError(\"Could not disconnect from AWS IOT\", message=exc.message)", "response": "Disconnect from AWS IOT message broker"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publish(self, topic, message):\n\n        seq = self.sequencer.next_id(topic)\n\n        packet = {\n            'sequence': seq,\n            'message': message\n        }\n        # Need to encode bytes types for json.dumps\n        if 'key' in packet['message']:\n            packet['message']['key'] = packet['message']['key'].decode('utf8')\n        if 'payload' in packet['message']:\n            packet['message']['payload'] = packet['message']['payload'].decode('utf8')\n        if 'script' in packet['message']:\n            packet['message']['script'] = packet['message']['script'].decode('utf8')\n        if 'trace' in packet['message']:\n            packet['message']['trace'] = packet['message']['trace'].decode('utf8')\n        if 'report' in packet['message']:\n            packet['message']['report'] = packet['message']['report'].decode('utf8')\n        if 'received_time' in packet['message']:\n            packet['message']['received_time'] = packet['message']['received_time'].decode('utf8')\n\n        serialized_packet = json.dumps(packet)\n\n        try:\n            # Limit how much we log in case the message is very long\n            self._logger.debug(\"Publishing %s on topic %s\", serialized_packet[:256], topic)\n            self.client.publish(topic, serialized_packet, 1)\n        except operationError as exc:\n            raise InternalError(\"Could not publish message\", topic=topic, message=exc.message)", "response": "Publish a json message to a topic with a type and a sequence number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubscribing to messages on the given topic.", "response": "def subscribe(self, topic, callback, ordered=True):\n        \"\"\"Subscribe to future messages in the given topic\n\n        The contents of topic should be in the format created by self.publish with a\n        sequence number of message type encoded as a json string.\n\n        Wildcard topics containing + and # are allowed and\n\n        Args:\n            topic (string): The MQTT topic to subscribe to\n            callback (callable): The callback to call when a new mesage is received\n                The signature of callback should be callback(sequence, topic, type, message)\n            ordered (bool): Whether messages on this topic have a sequence number that must\n                be checked and queued to ensure that packets are received in order\n        \"\"\"\n\n        if '+' in topic or '#' in topic:\n            regex = re.compile(topic.replace('+', '[^/]+').replace('#', '.*'))\n            self.wildcard_queues.append((topic, regex, callback, ordered))\n        else:\n            self.queues[topic] = PacketQueue(0, callback, ordered)\n\n        try:\n            self.client.subscribe(topic, 1, self._on_receive)\n        except operationError as exc:\n            raise InternalError(\"Could not subscribe to topic\", topic=topic, message=exc.message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting the expected sequence number for a topic.", "response": "def reset_sequence(self, topic):\n        \"\"\"Reset the expected sequence number for a topic\n\n        If the topic is unknown, this does nothing.  This behaviour is\n        useful when you have wildcard topics that only create queues\n        once they receive the first message matching the topic.\n\n        Args:\n            topic (string): The topic to reset the packet queue on\n        \"\"\"\n\n        if topic in self.queues:\n            self.queues[topic].reset()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unsubscribe(self, topic):\n\n        del self.queues[topic]\n\n        try:\n            self.client.unsubscribe(topic)\n        except operationError as exc:\n            raise InternalError(\"Could not unsubscribe from topic\", topic=topic, message=exc.message)", "response": "Unsubscribe from messages on a given topic"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _on_receive(self, client, userdata, message):\n\n        topic = message.topic\n        encoded = message.payload\n\n        try:\n            packet = json.loads(encoded)\n        except ValueError:\n            self._logger.warn(\"Could not decode json packet: %s\", encoded)\n            return\n\n        try:\n            seq = packet['sequence']\n            message_data = packet['message']\n        except KeyError:\n            self._logger.warn(\"Message received did not have required sequence and message keys: %s\", packet)\n            return\n\n        # If we received a packet that does not fit into a queue, check our wildcard\n        # queues\n        if topic not in self.queues:\n            found = False\n            for _, regex, callback, ordered in self.wildcard_queues:\n                if regex.match(topic):\n                    self.queues[topic] = PacketQueue(0, callback, ordered)\n                    found = True\n                    break\n\n            if not found:\n                self._logger.warn(\"Received message for unknown topic: %s\", topic)\n                return\n\n        self.queues[topic].receive(seq, [seq, topic, message_data])", "response": "Callback called when a message is received on a topic."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the RTC timestamp to UTC.", "response": "def run(self, resources):\n        \"\"\"Sets the RTC timestamp to UTC.\n\n        Args:\n            resources (dict): A dictionary containing the required resources that\n                we needed access to in order to perform this step.\n        \"\"\"\n        hwman = resources['connection']\n        con = hwman.hwman.controller()\n        test_interface = con.test_interface()\n        try:\n            test_interface.synchronize_clock()\n            print('Time currently set at %s' % test_interface.current_time_str())\n        except:\n            raise ArgumentError('Error setting RTC time, check if controller actually has RTC or if iotile-support-lib-controller-3 is updated')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, command, *args):\n\n        cmd = Command(command, args)\n        self.commands.append(cmd)", "response": "Add a command to this command file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave this command file as an ascii file.", "response": "def save(self, outpath):\n        \"\"\"Save this command file as an ascii file.\n\n        Agrs:\n            outpath (str): The output path to save.\n        \"\"\"\n\n        with open(outpath, \"w\") as outfile:\n            outfile.write(self.dump())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self):\n\n        out = []\n\n        out.append(self.filetype)\n        out.append(\"Format: {}\".format(self.version))\n        out.append(\"Type: ASCII\")\n        out.append(\"\")\n\n        for cmd in self.commands:\n            out.append(self.encode(cmd))\n\n        return \"\\n\".join(out) + \"\\n\"", "response": "Dump all commands in this object to a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a CommandFile from a string.", "response": "def FromString(cls, indata):\n        \"\"\"Load a CommandFile from a string.\n\n        The string should be produced from a previous call to\n        encode.\n\n        Args:\n            indata (str): The encoded input data.\n\n        Returns:\n            CommandFile: The decoded CommandFile object.\n        \"\"\"\n\n        lines = [x.strip() for x in indata.split(\"\\n\") if not x.startswith('#') and not x.strip() == \"\"]\n\n        if len(lines) < 3:\n            raise DataError(\"Invalid CommandFile string that did not contain 3 header lines\", lines=lines)\n\n        fmt_line, version_line, ascii_line = lines[:3]\n\n        if not version_line.startswith(\"Format: \"):\n            raise DataError(\"Invalid format version that did not start with 'Format: '\", line=version_line)\n\n        version = version_line[8:]\n\n        if ascii_line != \"Type: ASCII\":\n            raise DataError(\"Unknown file type line (expected Type: ASCII)\", line=ascii_line)\n\n        cmds = [cls.decode(x) for x in lines[3:]]\n        return CommandFile(fmt_line, version, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FromFile(cls, inpath):\n\n        with open(inpath, \"r\") as infile:\n            indata = infile.read()\n\n        return cls.FromString(indata)", "response": "Load a CommandFile from a path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencodes a command as an unambiguous string.", "response": "def encode(cls, command):\n        \"\"\"Encode a command as an unambiguous string.\n\n        Args:\n            command (Command): The command to encode.\n\n        Returns:\n            str: The encoded command\n        \"\"\"\n\n        args = []\n        for arg in command.args:\n            if not isinstance(arg, str):\n                arg = str(arg)\n\n            if \",\" in arg or arg.startswith(\" \") or arg.endswith(\" \") or arg.startswith(\"hex:\"):\n                arg = \"hex:{}\".format(hexlify(arg.encode('utf-8')).decode('utf-8'))\n\n            args.append(arg)\n\n        argstr = \"\"\n\n        if len(args) > 0:\n            argstr = \" {\" + \",\".join(args) + \"}\"\n\n        return command.name + argstr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecode a string encoded command into a Command object.", "response": "def decode(cls, command_str):\n        \"\"\"Decode a string encoded command back into a Command object.\n\n        Args:\n            command_str (str): The encoded command string output from a\n                previous call to encode.\n\n        Returns:\n            Command: The decoded Command object.\n        \"\"\"\n\n        name, _, arg = command_str.partition(\" \")\n\n        args = []\n\n        if len(arg) > 0:\n            if arg[0] != '{' or arg[-1] != '}':\n                raise DataError(\"Invalid command, argument is not contained in { and }\", arg=arg, cmd=name)\n\n            arg = arg[1:-1]\n            args = arg.split(\",\")\n\n        proc = []\n\n        for arg in args:\n            if arg.startswith(\"hex:\"):\n                arg = unhexlify(arg[4:]).decode('utf-8')\n\n            proc.append(arg)\n\n        return Command(name, proc)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef receive(self, sequence, args):\n\n        # If we are told to ignore sequence numbers, just pass the packet on\n        if not self._reorder:\n            self._callback(*args)\n            return\n\n        # If this packet is in the past, drop it\n        if self._next_expected is not None and sequence < self._next_expected:\n            print(\"Dropping out of order packet, seq=%d\" % sequence)\n            return\n\n        self._out_of_order.append((sequence, args))\n        self._out_of_order.sort(key=lambda x: x[0])\n\n        # If we have received packets, attempt to process them in order\n        while len(self._out_of_order) > 0:\n            seq, args = self._out_of_order[0]\n\n            if self._next_expected is not None and seq != self._next_expected:\n                return\n\n            self._callback(*args)\n            self._out_of_order.pop(0)\n            self._next_expected = seq+1", "response": "Receive one packet from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_vars(env):\n    desired = env.get('MWCW_VERSION', '')\n\n    # return right away if the variables are already set\n    if isinstance(desired, MWVersion):\n        return 1\n    elif desired is None:\n        return 0\n\n    versions = find_versions()\n    version = None\n\n    if desired:\n        for v in versions:\n            if str(v) == desired:\n                version = v\n    elif versions:\n        version = versions[-1]\n\n    env['MWCW_VERSIONS'] = versions\n    env['MWCW_VERSION'] = version\n\n    if version is None:\n      return 0\n\n    env.PrependENVPath('PATH', version.clpath)\n    env.PrependENVPath('PATH', version.dllpath)\n    ENV = env['ENV']\n    ENV['CWFolder'] = version.path\n    ENV['LM_LICENSE_FILE'] = version.license\n    plus = lambda x: '+%s' % x\n    ENV['MWCIncludes'] = os.pathsep.join(map(plus, version.includes))\n    ENV['MWLibraries'] = os.pathsep.join(map(plus, version.libs))\n    return 1", "response": "Set the variables MWCW_VERSION and MWCW_VERSIONS in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of MWVersion objects representing installed versions of the other system on the other system.", "response": "def find_versions():\n    \"\"\"Return a list of MWVersion objects representing installed versions\"\"\"\n    versions = []\n\n    ### This function finds CodeWarrior by reading from the registry on\n    ### Windows. Some other method needs to be implemented for other\n    ### platforms, maybe something that calls env.WhereIs('mwcc')\n\n    if SCons.Util.can_read_reg:\n        try:\n            HLM = SCons.Util.HKEY_LOCAL_MACHINE\n            product = 'SOFTWARE\\\\Metrowerks\\\\CodeWarrior\\\\Product Versions'\n            product_key = SCons.Util.RegOpenKeyEx(HLM, product)\n\n            i = 0\n            while True:\n                name = product + '\\\\' + SCons.Util.RegEnumKey(product_key, i)\n                name_key = SCons.Util.RegOpenKeyEx(HLM, name)\n\n                try:\n                    version = SCons.Util.RegQueryValueEx(name_key, 'VERSION')\n                    path = SCons.Util.RegQueryValueEx(name_key, 'PATH')\n                    mwv = MWVersion(version[0], path[0], 'Win32-X86')\n                    versions.append(mwv)\n                except SCons.Util.RegError:\n                    pass\n\n                i = i + 1\n\n        except SCons.Util.RegError:\n            pass\n\n    return versions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding Builders and construction variables for the mwcc to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for the mwcc to an Environment.\"\"\"\n    import SCons.Defaults\n    import SCons.Tool\n\n    set_vars(env)\n\n    static_obj, shared_obj = SCons.Tool.createObjBuilders(env)\n\n    for suffix in CSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.CAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ShCAction)\n\n    for suffix in CXXSuffixes:\n        static_obj.add_action(suffix, SCons.Defaults.CXXAction)\n        shared_obj.add_action(suffix, SCons.Defaults.ShCXXAction)\n\n    env['CCCOMFLAGS'] = '$CPPFLAGS $_CPPDEFFLAGS $_CPPINCFLAGS -nolink -o $TARGET $SOURCES'\n\n    env['CC']         = 'mwcc'\n    env['CCCOM']      = '$CC $CFLAGS $CCFLAGS $CCCOMFLAGS'\n\n    env['CXX']        = 'mwcc'\n    env['CXXCOM']     = '$CXX $CXXFLAGS $CCCOMFLAGS'\n\n    env['SHCC']       = '$CC'\n    env['SHCCFLAGS']  = '$CCFLAGS'\n    env['SHCFLAGS']   = '$CFLAGS'\n    env['SHCCCOM']    = '$SHCC $SHCFLAGS $SHCCFLAGS $CCCOMFLAGS'\n\n    env['SHCXX']       = '$CXX'\n    env['SHCXXFLAGS']  = '$CXXFLAGS'\n    env['SHCXXCOM']    = '$SHCXX $SHCXXFLAGS $CCCOMFLAGS'\n\n    env['CFILESUFFIX'] = '.c'\n    env['CXXFILESUFFIX'] = '.cpp'\n    env['CPPDEFPREFIX']  = '-D'\n    env['CPPDEFSUFFIX']  = ''\n    env['INCPREFIX']  = '-I'\n    env['INCSUFFIX']  = ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the flash step.", "response": "def run(self, resources):\n        \"\"\"Runs the flash step\n\n        Args:\n            resources (dict): A dictionary containing the required resources that\n                we needed access to in order to perform this step.\n        \"\"\"\n        if not resources['connection']._port.startswith('jlink'):\n            raise ArgumentError(\"FlashBoardStep is currently only possible through jlink\", invalid_port=args['port'])\n\n        hwman = resources['connection']\n        debug = hwman.hwman.debug(self._debug_string)\n        debug.flash(self._file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the path of the source to be under the target", "response": "def copyto_emitter(target, source, env):\n    \"\"\" changes the path of the source to be under the target (which\n    are assumed to be directories.\n    \"\"\"\n    n_target = []\n\n    for t in target:\n        n_target = n_target + [t.File( str( s ) ) for s in source]\n\n    return (n_target, source)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the registry to find the installed path of the Phar Lap ETS development kit.", "response": "def getPharLapPath():\n    \"\"\"Reads the registry to find the installed path of the Phar Lap ETS\n    development kit.\n\n    Raises UserError if no installed version of Phar Lap can\n    be found.\"\"\"\n\n    if not SCons.Util.can_read_reg:\n        raise SCons.Errors.InternalError(\"No Windows registry module was found\")\n    try:\n        k=SCons.Util.RegOpenKeyEx(SCons.Util.HKEY_LOCAL_MACHINE,\n                                  'SOFTWARE\\\\Pharlap\\\\ETS')\n        val, type = SCons.Util.RegQueryValueEx(k, 'BaseDir')\n\n        # The following is a hack...there is (not surprisingly)\n        # an odd issue in the Phar Lap plug in that inserts\n        # a bunch of junk data after the phar lap path in the\n        # registry.  We must trim it.\n        idx=val.find('\\0')\n        if idx >= 0:\n            val = val[:idx]\n                    \n        return os.path.normpath(val)\n    except SCons.Util.RegError:\n        raise SCons.Errors.UserError(\"Cannot find Phar Lap ETS path in the registry.  Is it installed properly?\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getPharLapVersion():\n\n    include_path = os.path.join(getPharLapPath(), os.path.normpath(\"include/embkern.h\"))\n    if not os.path.exists(include_path):\n        raise SCons.Errors.UserError(\"Cannot find embkern.h in ETS include directory.\\nIs Phar Lap ETS installed properly?\")\n    mo = REGEX_ETS_VER.search(open(include_path, 'r').read())\n    if mo:\n        return int(mo.group(1))\n    # Default return for Phar Lap 9.1\n    return 910", "response": "Returns the version of the installed ETS Tool Suite as a\n    decimal number."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_or_init_po_files(target, source, env):\n  import SCons.Action\n  from SCons.Tool.GettextCommon import _init_po_files\n  for tgt in target:\n    if tgt.rexists():\n      action = SCons.Action.Action('$MSGMERGECOM', '$MSGMERGECOMSTR')\n    else:\n      action = _init_po_files\n    status = action([tgt], source, env)\n    if status : return status\n  return 0", "response": "Action function for POUpdate builder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an object of POUpdate builder.", "response": "def _POUpdateBuilder(env, **kw):\n  \"\"\" Create an object of `POUpdate` builder \"\"\"\n  import SCons.Action\n  from SCons.Tool.GettextCommon import _POFileBuilder\n  action = SCons.Action.Action(_update_or_init_po_files, None)\n  return _POFileBuilder(env, action=action, target_alias='$POUPDATE_ALIAS')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap for `POUpdate` builder - make user's life easier", "response": "def _POUpdateBuilderWrapper(env, target=None, source=_null, **kw):\n  \"\"\" Wrapper for `POUpdate` builder - make user's life easier \"\"\"\n  if source is _null:\n    if 'POTDOMAIN' in kw:\n      domain = kw['POTDOMAIN']\n    elif 'POTDOMAIN' in env and env['POTDOMAIN']:\n      domain = env['POTDOMAIN']\n    else:\n      domain = 'messages'\n    source = [ domain ] # NOTE: Suffix shall be appended automatically\n  return env._POUpdateBuilder(target, source, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the xgettext tool", "response": "def generate(env,**kw):\n  \"\"\" Generate the `xgettext` tool \"\"\"\n  from SCons.Tool.GettextCommon import _detect_msgmerge\n  try:\n    env['MSGMERGE'] = _detect_msgmerge(env)\n  except:\n    env['MSGMERGE'] = 'msgmerge'\n  env.SetDefault(\n    POTSUFFIX = ['.pot'],\n    POSUFFIX = ['.po'],\n    MSGMERGECOM = '$MSGMERGE  $MSGMERGEFLAGS --update $TARGET $SOURCE',\n    MSGMERGECOMSTR = '',\n    MSGMERGEFLAGS = [ ],\n    POUPDATE_ALIAS = 'po-update'\n  )\n  env.Append(BUILDERS = { '_POUpdateBuilder':_POUpdateBuilder(env) })\n  env.AddMethod(_POUpdateBuilderWrapper, 'POUpdate')\n  env.AlwaysBuild(env.Alias('$POUPDATE_ALIAS'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a filter of all of the dependency products that we have selected.", "response": "def _create_filter(self):\n        \"\"\"Create a filter of all of the dependency products that we have selected.\"\"\"\n\n        self._product_filter = {}\n\n        for chip in itertools.chain(iter(self._family.targets(self._tile.short_name)),\n                                    iter([self._family.platform_independent_target()])):\n            for key, prods in chip.property('depends', {}).items():\n                name, _, _ = key.partition(',')\n\n                for prod in prods:\n                    if prod not in self._product_filter:\n                        self._product_filter[prod] = set()\n\n                    self._product_filter[prod].add(name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a map of all products produced by this or a dependency.", "response": "def _create_product_map(self):\n        \"\"\"Create a map of all products produced by this or a dependency.\"\"\"\n\n        self._product_map = {}\n\n        for dep in self._tile.dependencies:\n            try:\n                dep_tile = IOTile(os.path.join('build', 'deps', dep['unique_id']))\n            except (ArgumentError, EnvironmentError):\n                raise BuildError(\"Could not find required dependency\", name=dep['name'])\n\n            self._add_products(dep_tile)\n\n        self._add_products(self._tile, show_all=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding all products from a tile into our product map.", "response": "def _add_products(self, tile, show_all=False):\n        \"\"\"Add all products from a tile into our product map.\"\"\"\n\n        products = tile.products\n        unique_id = tile.unique_id\n        base_path = tile.output_folder\n\n        for prod_path, prod_type in products.items():\n            # We need to handle include_directories and tilebus_definitions\n            # specially since those are stored reversed in module_settings.json\n            # for historical reasons.  Currently we don't support resolving\n            # tilebus_definitions or include_directories in ProductResolver\n            if prod_path == 'tilebus_definitions' or prod_path == 'include_directories':\n                continue\n\n            if prod_type in self.IGNORED_PRODUCTS:\n                continue\n\n            prod_base = os.path.basename(prod_path)\n            if prod_type not in self._product_map:\n                self._product_map[prod_type] = {}\n\n            prod_map = self._product_map[prod_type]\n            if prod_base not in prod_map:\n                prod_map[prod_base] = []\n\n            full_path = os.path.normpath(os.path.join(base_path, prod_path))\n            info = ProductInfo(prod_base, full_path, unique_id, not show_all and prod_base not in self._product_filter)\n            prod_map[prod_base].append(info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds all providers of a given product by its short name. This function will return all providers of a given product. If you want to ensure that a product's name is unique among all dependencies, you should use find_unique. Args: product_type (str): The type of product that we are looking for, like firmware_image, library etc. short_name (str): The short name of the product that we wish to find, usually its os.path.basename() include_hidden (bool): Return products that are hidden and not selected as visible in the depends section of this tile's module settings. This defaults to False. Returns: list of ProductInfo: A list of all of the matching products. If no matching products are found, an empty list is returned. If you want to raise a BuildError in that case use find_unique.", "response": "def find_all(self, product_type, short_name, include_hidden=False):\n        \"\"\"Find all providers of a given product by its short name.\n\n        This function will return all providers of a given product. If you\n        want to ensure that a product's name is unique among all dependencies,\n        you should use find_unique.\n\n        Args:\n            product_type (str): The type of product that we are looking for, like\n                firmware_image, library etc.\n            short_name (str): The short name of the product that we wish to find,\n                usually its os.path.basename()\n            include_hidden (bool): Return products that are hidden and not selected\n                as visible in the depends section of this tile's module settings.\n                This defaults to False.\n\n        Returns:\n            list of ProductInfo: A list of all of the matching products.  If no matching\n                products are found, an empty list is returned.  If you want to raise\n                a BuildError in that case use find_unique.\n        \"\"\"\n\n        all_prods = []\n\n        # If product_type is not return products of all types\n        if product_type is None:\n            for prod_dict in self._product_map.values():\n                all_prods.extend([prod for prod in prod_dict.get(short_name, []) if include_hidden or not prod.hidden])\n\n            return all_prods\n\n        all_prods = self._product_map.get(product_type, {})\n        return [prod for prod in all_prods.get(short_name, []) if include_hidden or not prod.hidden]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the unique provider of a given product by its short name. This function will ensure that the product is only provided by exactly one tile (either this tile or one of its dependencies and raise a BuildError if not. Args: product_type (str): The type of product that we are looking for, like firmware_image, library etc. short_name (str): The short name of the product that we wish to find, usually its os.path.basename() include_hidden (bool): Return products that are hidden and not selected as visible in the depends section of this tile's module settings. This defaults to False. Returns: ProductInfo: The information of the one unique provider of this product.", "response": "def find_unique(self, product_type, short_name, include_hidden=False):\n        \"\"\"Find the unique provider of a given product by its short name.\n\n        This function will ensure that the product is only provided by exactly\n        one tile (either this tile or one of its dependencies and raise a\n        BuildError if not.\n\n        Args:\n            product_type (str): The type of product that we are looking for, like\n                firmware_image, library etc.\n            short_name (str): The short name of the product that we wish to find,\n                usually its os.path.basename()\n            include_hidden (bool): Return products that are hidden and not selected\n                as visible in the depends section of this tile's module settings.\n                This defaults to False.\n\n        Returns:\n            ProductInfo: The information of the one unique provider of this product.\n        \"\"\"\n\n        prods = self.find_all(product_type, short_name, include_hidden)\n\n        if len(prods) == 0:\n            raise BuildError(\"Could not find product by name in find_unique\", name=short_name, type=product_type)\n\n        if len(prods) > 1:\n            raise BuildError(\"Multiple providers of the same product in find_unique\", name=short_name, type=product_type, products=prods)\n\n        if self._tracking:\n            self._resolved_products.append(prods[0])\n\n        return prods[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate command line argument parser.", "response": "def build_parser():\n    \"\"\"Create command line argument parser.\"\"\"\n\n    parser = argparse.ArgumentParser(description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter)\n\n    parser.add_argument('-o', '--output', help=\"The output file to save.  If multiple files are generated \"\n                                               \"this is the output prefix for them all.\")\n    parser.add_argument('-f', '--format', default=\"json\", choices=['c_files', 'command_map_c', 'command_map_h',\n                                                                   'config_map_c', 'config_map_h', 'json'],\n                        type=str, help=u\"the output format for the compiled result.\")\n    parser.add_argument('bus_definition', nargs=\"+\", help=\"One or more tilebus definition files to compile\")\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(raw_args=None):\n\n    multifile_choices = frozenset(['c_files'])\n\n    if raw_args is None:\n        raw_args = sys.argv[1:]\n\n    parser = build_parser()\n    args = parser.parse_args(raw_args)\n\n    if args.output is None and args.format in multifile_choices:\n        print(\"You must specify an output file with -o, --output when \"\n              \"using a format that produces multiple files (-f %s)\" % args.format)\n        return 1\n\n    desc = TBDescriptor(args.bus_definition)\n\n    if args.format == 'json':\n        print(\"JSON output is not yet supported\")\n        return 1\n\n    block = desc.get_block()\n\n    template_map = {\n        'command_map_c': 'command_map_c.c.tpl',\n        'command_map_h': 'command_map_c.h.tpl',\n        'config_map_c': 'config_variables_c.c.tpl',\n        'config_map_h': 'config_variables_c.h.tpl'\n    }\n\n    template_name = template_map.get(args.format)\n    data = block.render_template(template_name)\n    print(data)\n\n    return 0", "response": "Main function for iotile - tbcompile script."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate(env):\n    \"Add RPCGEN Builders and construction variables for an Environment.\"\n    \n    client  = Builder(action=rpcgen_client,  suffix='_clnt.c', src_suffix='.x')\n    header  = Builder(action=rpcgen_header,  suffix='.h',      src_suffix='.x')\n    service = Builder(action=rpcgen_service, suffix='_svc.c',  src_suffix='.x')\n    xdr     = Builder(action=rpcgen_xdr,     suffix='_xdr.c',  src_suffix='.x')\n    env.Append(BUILDERS={'RPCGenClient'  : client,\n                         'RPCGenHeader'  : header,\n                         'RPCGenService' : service,\n                         'RPCGenXDR'     : xdr})\n    env['RPCGEN'] = 'rpcgen'\n    env['RPCGENFLAGS'] = SCons.Util.CLVar('')\n    env['RPCGENCLIENTFLAGS'] = SCons.Util.CLVar('')\n    env['RPCGENHEADERFLAGS'] = SCons.Util.CLVar('')\n    env['RPCGENSERVICEFLAGS'] = SCons.Util.CLVar('')\n    env['RPCGENXDRFLAGS'] = SCons.Util.CLVar('')", "response": "Add RPCGEN Builders and construction variables for an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a message to the slack channel", "response": "def send_slack_message(message):\n    \"\"\"Send a message to the slack channel #coretools\"\"\"\n\n    if 'SLACK_WEB_HOOK' not in os.environ:\n        raise EnvironmentError(\"Could not find SLACK_WEB_HOOK environment variable\")\n\n    webhook = os.environ['SLACK_WEB_HOOK']\n\n    r = requests.post(webhook, json={'text':message, 'username': 'Release Bot'})\n    if r.status_code != 200:\n        raise RuntimeError(\"Could not post message to slack channel\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit the argument passed on the command line into a component name and expected version", "response": "def get_release_component(comp):\n    \"\"\"Split the argument passed on the command line into a component name and expected version\"\"\"\n\n    name, vers = comp.split(\"-\")\n\n    if name not in comp_names:\n        print(\"Known components:\")\n        for comp in comp_names:\n            print(\"- %s\" % comp)\n\n        raise EnvironmentError(\"Unknown release component name '%s'\" % name)\n\n    return name, vers"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_compatibility(name):\n\n    comp = comp_names[name]\n\n    if sys.version_info.major < 3 and comp.compat == \"python3\":\n        return False\n\n    if sys.version_info.major >= 3 and comp.compat != \"python3\":\n        return False\n\n    return True", "response": "Verify if we can release this component on the running interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_version(component, expected_version):\n\n    comp = comp_names[component]\n\n    compath = os.path.realpath(os.path.abspath(comp.path))\n    sys.path.insert(0, compath)\n\n    import version\n\n    if version.version != expected_version:\n        raise EnvironmentError(\"Version mismatch during release, expected={}, found={}\".format(expected_version, version.version))", "response": "Check that the version of the component in setuptools matches the expected version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an sdist and wheel for the desired component", "response": "def build_component(component):\n    \"\"\"Create an sdist and a wheel for the desired component\"\"\"\n\n    comp = comp_names[component]\n\n    curr = os.getcwd()\n    os.chdir(comp.path)\n\n    args = ['-q', 'clean', 'sdist', 'bdist_wheel']\n    if comp.compat == 'universal':\n        args.append('--universal')\n\n    try:\n        setuptools.sandbox.run_setup('setup.py', args)\n    finally:\n        os.chdir(curr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload_component(component):\n\n    if 'PYPI_USER' in os.environ and 'PYPI_PASS' in os.environ:\n        pypi_user = os.environ['PYPI_USER']\n        pypi_pass = os.environ['PYPI_PASS']\n    else:\n        pypi_user = None\n        pypi_pass = None\n        print(\"No PYPI user information in environment\")\n\n    comp = comp_names[component]\n    distpath = os.path.join(comp.path, 'dist', '*')\n    distpath = os.path.realpath(os.path.abspath(distpath))\n    dists = glob.glob(distpath)\n\n    if pypi_user is None:\n        args = ['twine', 'upload', distpath]\n    else:\n        args = ['twine', 'upload', '-u', pypi_user, '-p', pypi_pass, distpath]\n\n    # Invoke upload this way since subprocess call of twine cli has cross platform issues\n    upload(dists, 'pypi', False, None, pypi_user, pypi_pass, None, None, '~/.pypirc', False, None, None, None)", "response": "Upload a given component to pypi"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uuid_to_slug(uuid):\n    if not isinstance(uuid, int):\n        raise ArgumentError(\"Invalid id that is not an integer\", id=uuid)\n\n    if uuid < 0 or uuid > 0x7fffffff:\n        # For now, limiting support to a signed integer (which on some platforms, can be 32bits)\n        raise ArgumentError(\"Integer should be a positive number and smaller than 0x7fffffff\", id=uuid)\n\n    return '--'.join(['d', int64gid(uuid)])", "response": "Converts a UUID to a IOTile Cloud compatible Device Slug"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_specfiles(source, target, env):\n    #\n    # At first we care for the CONTROL/control file, which is the main file for ipk.\n    #\n    # For this we need to open multiple files in random order, so we store into\n    # a dict so they can be easily accessed.\n    #\n    #\n    opened_files={}\n    def open_file(needle, haystack):\n        try:\n            return opened_files[needle]\n        except KeyError:\n            file=filter(lambda x: x.get_path().rfind(needle)!=-1, haystack)[0]\n            opened_files[needle]=open(file.get_abspath(), 'w')\n            return opened_files[needle]\n\n    control_file=open_file('control', target)\n\n    if 'X_IPK_DESCRIPTION' not in env:\n        env['X_IPK_DESCRIPTION']=\"%s\\n %s\"%(env['SUMMARY'],\n                                            env['DESCRIPTION'].replace('\\n', '\\n '))\n\n\n    content = \"\"\"\nPackage: $NAME\nVersion: $VERSION\nPriority: $X_IPK_PRIORITY\nSection: $X_IPK_SECTION\nSource: $SOURCE_URL\nArchitecture: $ARCHITECTURE\nMaintainer: $X_IPK_MAINTAINER\nDepends: $X_IPK_DEPENDS\nDescription: $X_IPK_DESCRIPTION\n\"\"\"\n\n    control_file.write(env.subst(content))\n\n    #\n    # now handle the various other files, which purpose it is to set post-, \n    # pre-scripts and mark files as config files.\n    #\n    # We do so by filtering the source files for files which are marked with\n    # the \"config\" tag and afterwards we do the same for x_ipk_postrm,\n    # x_ipk_prerm, x_ipk_postinst and x_ipk_preinst tags.\n    #\n    # The first one will write the name of the file into the file\n    # CONTROL/configfiles, the latter add the content of the x_ipk_* variable\n    # into the same named file.\n    #\n    for f in [x for x in source if 'PACKAGING_CONFIG' in dir(x)]:\n        config=open_file('conffiles')\n        config.write(f.PACKAGING_INSTALL_LOCATION)\n        config.write('\\n')\n\n    for str in 'POSTRM PRERM POSTINST PREINST'.split():\n        name=\"PACKAGING_X_IPK_%s\"%str\n        for f in [x for x in source if name in dir(x)]:\n            file=open_file(name)\n            file.write(env[str])\n\n    #\n    # close all opened files\n    for f in list(opened_files.values()):\n        f.close()\n\n    # call a user specified function\n    if 'CHANGE_SPECFILE' in env:\n        content += env['CHANGE_SPECFILE'](target)\n\n    return 0", "response": "Build the specfiles for the ipk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(env):\n    java_javah = SCons.Tool.CreateJavaHBuilder(env)\n    java_javah.emitter = emit_java_headers\n\n    env['_JAVAHOUTFLAG']    = JavaHOutFlagGenerator\n    env['JAVAH']            = 'javah'\n    env['JAVAHFLAGS']       = SCons.Util.CLVar('')\n    env['_JAVAHCLASSPATH']  = getJavaHClassPath\n    env['JAVAHCOM']         = '$JAVAH $JAVAHFLAGS $_JAVAHOUTFLAG $_JAVAHCLASSPATH ${SOURCES.attributes.java_classname}'\n    env['JAVACLASSSUFFIX']  = '.class'", "response": "Add Builders and construction variables for javah to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump(self):\n\n        return {\n            u'storage_data': [x.asdict() for x in self.storage_data],\n            u'streaming_data': [x.asdict() for x in self.streaming_data]\n        }", "response": "Serialize the state of this InMemoryStorageEngine to a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore the state of this InMemoryStorageEngine from a dict.", "response": "def restore(self, state):\n        \"\"\"Restore the state of this InMemoryStorageEngine from a dict.\"\"\"\n\n        storage_data = state.get(u'storage_data', [])\n        streaming_data = state.get(u'streaming_data', [])\n\n        if len(storage_data) > self.storage_length or len(streaming_data) > self.streaming_length:\n            raise ArgumentError(\"Cannot restore InMemoryStorageEngine, too many readings\",\n                                storage_size=len(storage_data), storage_max=self.storage_length,\n                                streaming_size=len(streaming_data), streaming_max=self.streaming_length)\n\n        self.storage_data = [IOTileReading.FromDict(x) for x in storage_data]\n        self.streaming_data = [IOTileReading.FromDict(x) for x in streaming_data]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count_matching(self, selector, offset=0):\n\n        if selector.output:\n            data = self.streaming_data\n        elif selector.buffered:\n            data = self.storage_data\n        else:\n            raise ArgumentError(\"You can only pass a buffered selector to count_matching\", selector=selector)\n\n        count = 0\n        for i in range(offset, len(data)):\n            reading = data[i]\n\n            stream = DataStream.FromEncoded(reading.stream)\n            if selector.matches(stream):\n                count += 1\n\n        return count", "response": "Count the number of matching readings for a given selector."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over streaming or storage areas calling callable.", "response": "def scan_storage(self, area_name, callable, start=0, stop=None):\n        \"\"\"Iterate over streaming or storage areas, calling callable.\n\n        Args:\n            area_name (str): Either 'storage' or 'streaming' to indicate which\n                storage area to scan.\n            callable (callable): A function that will be called as (offset, reading)\n                for each reading between start_offset and end_offset (inclusive).  If\n                the scan function wants to stop early it can return True.  If it returns\n                anything else (including False or None), scanning will continue.\n            start (int): Optional offset to start at (included in scan).\n            stop (int): Optional offset to end at (included in scan).\n\n        Returns:\n            int: The number of entries scanned.\n        \"\"\"\n\n        if area_name == u'storage':\n            data = self.storage_data\n        elif area_name == u'streaming':\n            data = self.streaming_data\n        else:\n            raise ArgumentError(\"Unknown area name in scan_storage (%s) should be storage or streaming\" % area_name)\n\n        if len(data) == 0:\n            return 0\n\n        if stop is None:\n            stop = len(data) - 1\n        elif stop >= len(data):\n            raise ArgumentError(\"Given stop offset is greater than the highest offset supported\", length=len(data), stop_offset=stop)\n\n        scanned = 0\n        for i in range(start, stop + 1):\n            scanned += 1\n\n            should_break = callable(i, data[i])\n            if should_break is True:\n                break\n\n        return scanned"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush a new value for the given stream.", "response": "def push(self, value):\n        \"\"\"Store a new value for the given stream.\n\n        Args:\n            value (IOTileReading): The value to store.  The stream\n                parameter must have the correct value\n        \"\"\"\n\n        stream = DataStream.FromEncoded(value.stream)\n\n        if stream.stream_type == DataStream.OutputType:\n            if len(self.streaming_data) == self.streaming_length:\n                raise StorageFullError('Streaming buffer full')\n\n            self.streaming_data.append(value)\n        else:\n            if len(self.storage_data) == self.storage_length:\n                raise StorageFullError('Storage buffer full')\n\n            self.storage_data.append(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a reading from the given buffer at the given offset.", "response": "def get(self, buffer_type, offset):\n        \"\"\"Get a reading from the buffer at offset.\n\n        Offset is specified relative to the start of the data buffer.\n        This means that if the buffer rolls over, the offset for a given\n        item will appear to change.  Anyone holding an offset outside of this\n        engine object will need to be notified when rollovers happen (i.e.\n        popn is called so that they can update their offset indices)\n\n        Args:\n            buffer_type (str): The buffer to pop from (either u\"storage\" or u\"streaming\")\n            offset (int): The offset of the reading to get\n        \"\"\"\n\n        if buffer_type == u'streaming':\n            chosen_buffer = self.streaming_data\n        else:\n            chosen_buffer = self.storage_data\n\n        if offset >= len(chosen_buffer):\n            raise StreamEmptyError(\"Invalid index given in get command\", requested=offset, stored=len(chosen_buffer), buffer=buffer_type)\n\n        return chosen_buffer[offset]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves and return the oldest count values from the named buffer.", "response": "def popn(self, buffer_type, count):\n        \"\"\"Remove and return the oldest count values from the named buffer\n\n        Args:\n            buffer_type (str): The buffer to pop from (either u\"storage\" or u\"streaming\")\n            count (int): The number of readings to pop\n\n        Returns:\n            list(IOTileReading): The values popped from the buffer\n        \"\"\"\n\n        buffer_type = str(buffer_type)\n\n        if buffer_type == u'streaming':\n            chosen_buffer = self.streaming_data\n        else:\n            chosen_buffer = self.storage_data\n\n        if count > len(chosen_buffer):\n            raise StreamEmptyError(\"Not enough data in buffer for popn command\", requested=count, stored=len(chosen_buffer), buffer=buffer_type)\n\n        popped = chosen_buffer[:count]\n        remaining = chosen_buffer[count:]\n\n        if buffer_type == u'streaming':\n            self.streaming_data = remaining\n        else:\n            self.storage_data = remaining\n\n        return popped"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def connect(self, conn_id, connection_string):\n\n        self._ensure_connection(conn_id, False)\n\n        msg = dict(connection_string=connection_string)\n        await self._send_command(OPERATIONS.CONNECT, msg, COMMANDS.ConnectResponse)\n\n        self._setup_connection(conn_id, connection_string)", "response": "Connect to a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def disconnect(self, conn_id):\n\n        self._ensure_connection(conn_id, True)\n\n        msg = dict(connection_string=self._get_property(conn_id, \"connection_string\"))\n\n        try:\n            await self._send_command(OPERATIONS.DISCONNECT, msg, COMMANDS.DisconnectResponse)\n        finally:\n            self._teardown_connection(conn_id)", "response": "Disconnect from a connected device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def open_interface(self, conn_id, interface):\n\n        self._ensure_connection(conn_id, True)\n        connection_string = self._get_property(conn_id, \"connection_string\")\n\n        msg = dict(interface=interface, connection_string=connection_string)\n        await self._send_command(OPERATIONS.OPEN_INTERFACE, msg, COMMANDS.OpenInterfaceResponse)", "response": "Open an interface on an IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def close_interface(self, conn_id, interface):\n\n        self._ensure_connection(conn_id, True)\n        connection_string = self._get_property(conn_id, \"connection_string\")\n\n        msg = dict(interface=interface, connection_string=connection_string)\n        await self._send_command(OPERATIONS.CLOSE_INTERFACE, msg, COMMANDS.CloseInterfaceResponse)", "response": "Close an interface on this IOTile device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def send_rpc(self, conn_id, address, rpc_id, payload, timeout):\n\n        self._ensure_connection(conn_id, True)\n        connection_string = self._get_property(conn_id, \"connection_string\")\n\n        msg = dict(address=address, rpc_id=rpc_id, payload=base64.b64encode(payload),\n                   timeout=timeout, connection_string=connection_string)\n\n        response = await self._send_command(OPERATIONS.SEND_RPC, msg, COMMANDS.SendRPCResponse,\n                                            timeout=timeout)\n\n        return unpack_rpc_response(response.get('status'), response.get('payload'),\n                                   rpc_id=rpc_id, address=address)", "response": "Send an RPC to a device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a script to the IOTile device.", "response": "async def send_script(self, conn_id, data):\n        \"\"\"Send a a script to this IOTile device\n\n        Args:\n            conn_id (int): A unique identifier that will refer to this connection\n            data (bytes): the script to send to the device\n        \"\"\"\n\n        self._ensure_connection(conn_id, True)\n        connection_string = self._get_property(conn_id, \"connection_string\")\n\n        msg = dict(connection_string=connection_string, fragment_count=1, fragment_index=0,\n                   script=base64.b64encode(data))\n        await self._send_command(OPERATIONS.SEND_SCRIPT, msg, COMMANDS.SendScriptResponse)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _on_progress_notification(self, progress):\n\n        conn_string = progress.get('connection_string')\n        done = progress.get('done_count')\n        total = progress.get('total_count')\n        operation = progress.get('operation')\n\n        await self.notify_progress(conn_string, operation, done, total, wait=True)", "response": "Callback function called when a progress notification is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _on_websocket_disconnect(self, _event):\n\n        self.logger.info('Forcibly disconnected from the WebSocket server')\n\n        conns = self._connections.copy()\n        for conn_id in conns:\n            conn_string = self._get_property(conn_id, 'connection_string')\n            self._teardown_connection(conn_id)\n            self.notify_event(conn_string, 'disconnect', \"Websocket connection closed\")", "response": "Callback function called when the WebSocket connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _complete_parameters(param, variables):\n    if isinstance(param, list):\n        return [_complete_parameters(x, variables) for x in param]\n    elif isinstance(param, dict):\n        return {key: _complete_parameters(value, variables) for key, value in param.items()}\n    elif isinstance(param, str):\n        try:\n            return Template(param).substitute(variables)\n        except KeyError as exc:\n            raise RecipeVariableNotPassed(\"Variable undefined in recipe\", undefined_variable=exc.args[0])\n\n    return param", "response": "Replace any parameters passed in\nTaxonomy with the variable names that are passed in\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_variables(param):\n\n    variables = set()\n\n    if isinstance(param, list):\n        variables.update(*[_extract_variables(x) for x in param])\n    elif isinstance(param, dict):\n        variables.update(*[_extract_variables(x) for x in param.values()])\n    elif isinstance(param, str):\n        for match in re.finditer(TEMPLATE_REGEX, param):\n            if match.group('short_id') is not None:\n                variables.add(match.group('short_id'))\n            else:\n                variables.add(match.group('long_id'))\n\n    return variables", "response": "Find all template variables in args."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_step(step_obj, step_declaration, initialized_resources):\n\n    start_time = time.time()\n\n    # Open any resources that need to be opened before we run this step\n    for res_name in step_declaration.resources.opened:\n        initialized_resources[res_name].open()\n\n    # Create a dictionary of all of the resources that are required for this step\n    used_resources = {local_name: initialized_resources[global_name] for local_name, global_name in step_declaration.resources.used.items()}\n\n    # Allow steps with no resources to not need a resources keyword parameter\n    if len(used_resources) > 0:\n        out = step_obj.run(resources=used_resources)\n    else:\n        out = step_obj.run()\n\n    # Close any resources that need to be closed before we run this step\n    for res_name in step_declaration.resources.closed:\n        initialized_resources[res_name].close()\n\n    end_time = time.time()\n\n    return (end_time - start_time, out)", "response": "Actually run a step."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\narchive this recipe and all associated files into a. ship archive.", "response": "def archive(self, output_path):\n        \"\"\"Archive this recipe and all associated files into a .ship archive.\n\n        Args:\n            output_path (str): The path where the .ship file should be saved.\n        \"\"\"\n\n        if self.path is None:\n            raise ArgumentError(\"Cannot archive a recipe yet without a reference to its original yaml file in self.path\")\n\n        outfile = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n\n        outfile.write(self.path, arcname=\"recipe_script.yaml\")\n\n        written_files = set()\n\n        for _factory, args, _resources, files in self.steps:\n            for arg_name in files:\n                file_path = args[arg_name]\n\n                if file_path in written_files:\n                    continue\n\n                if os.path.basename(file_path) != file_path:\n                    raise ArgumentError(\"Cannot archive a recipe yet that references file not in the same directory as the recipe\")\n\n                full_path = os.path.join(os.path.dirname(self.path), file_path)\n                outfile.write(full_path, arcname=file_path)\n                written_files.add(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FromArchive(cls, path, actions_dict, resources_dict, temp_dir=None):\n\n        if not path.endswith(\".ship\"):\n            raise ArgumentError(\"Attempted to unpack a recipe archive from a file that did not end in .ship\", path=path)\n\n        name = os.path.basename(path)[:-5]\n\n        if temp_dir is None:\n            temp_dir = tempfile.mkdtemp()\n\n        extract_path = os.path.join(temp_dir, name)\n        archive = zipfile.ZipFile(path, \"r\")\n        archive.extractall(extract_path)\n\n        recipe_yaml = os.path.join(extract_path, 'recipe_script.yaml')\n        return cls.FromFile(recipe_yaml, actions_dict, resources_dict, name=name)", "response": "Create a RecipeObject from a. ship archive."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a RecipeObject from a file.", "response": "def FromFile(cls, path, actions_dict, resources_dict, file_format=\"yaml\", name=None):\n        \"\"\"Create a RecipeObject from a file.\n\n        The file should be a specially constructed yaml file that describes\n        the recipe as well as the actions that it performs.\n\n        Args:\n            path (str): The path to the recipe file that we wish to load\n            actions_dict (dict): A dictionary of named RecipeActionObject\n                types that is used to look up all of the steps listed in\n                the recipe file.\n            resources_dict (dict): A dictionary of named RecipeResource types\n                that is used to look up all of the shared resources listed in\n                the recipe file.\n            file_format (str): The file format of the recipe file.  Currently\n                we only support yaml.\n            name (str): The name of this recipe if we created it originally from an\n                archive.\n        \"\"\"\n\n        format_map = {\n            \"yaml\": cls._process_yaml\n        }\n\n        format_handler = format_map.get(file_format)\n        if format_handler is None:\n            raise ArgumentError(\"Unknown file format or file extension\", file_format=file_format, \\\n                known_formats=[x for x in format_map if format_map[x] is not None])\n        recipe_info = format_handler(path)\n\n        if name is None:\n            name, _ext = os.path.splitext(os.path.basename(path))\n\n        # Validate that the recipe file is correctly formatted\n        try:\n            recipe_info = RecipeSchema.verify(recipe_info)\n        except ValidationError as exc:\n            raise RecipeFileInvalid(\"Recipe file does not match expected schema\", file=path, error_message=exc.msg, **exc.params)\n\n        description = recipe_info.get('description')\n\n        # Parse out global default and shared resource information\n        try:\n            resources = cls._parse_resource_declarations(recipe_info.get('resources', []), resources_dict)\n            defaults = cls._parse_variable_defaults(recipe_info.get(\"defaults\", []))\n\n            steps = []\n            for i, action in enumerate(recipe_info.get('actions', [])):\n                action_name = action.pop('name')\n                if action_name is None:\n                    raise RecipeFileInvalid(\"Action is missing required name parameter\", \\\n                        parameters=action, path=path)\n\n                action_class = actions_dict.get(action_name)\n                if action_class is None:\n                    raise UnknownRecipeActionType(\"Unknown step specified in recipe\", \\\n                        action=action_name, step=i + 1, path=path)\n\n                # Parse out any resource usage in this step and make sure we only\n                # use named resources\n                step_resources = cls._parse_resource_usage(action, declarations=resources)\n                fixed_files, _variable_files = cls._parse_file_usage(action_class, action)\n\n                step = RecipeStep(action_class, action, step_resources, fixed_files)\n                steps.append(step)\n\n            return RecipeObject(name, description, steps, resources, defaults, path)\n        except RecipeFileInvalid as exc:\n            cls._future_raise(RecipeFileInvalid, RecipeFileInvalid(exc.msg, recipe=name, **exc.params),\n                              sys.exc_info()[2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind all external files referenced by an action.", "response": "def _parse_file_usage(cls, action_class, args):\n        \"\"\"Find all external files referenced by an action.\"\"\"\n\n        fixed_files = {}\n        variable_files = []\n\n        if not hasattr(action_class, 'FILES'):\n            return fixed_files, variable_files\n\n        for file_arg in action_class.FILES:\n            arg_value = args.get(file_arg)\n            if arg_value is None:\n                raise RecipeFileInvalid(\"Action lists a file argument but none was given\", declared_argument=file_arg, passed_arguments=args)\n\n            variables = _extract_variables(arg_value)\n            if len(variables) == 0:\n                fixed_files[file_arg] = arg_value\n            else:\n                variable_files.append(arg_value)\n\n        return fixed_files, variable_files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_resource_declarations(cls, declarations, resource_map):\n\n        resources = {}\n\n        for decl in declarations:\n            name = decl.pop('name')\n            typename = decl.pop('type')\n            desc = decl.pop('description', None)\n            autocreate = decl.pop('autocreate', False)\n\n            args = decl\n\n            res_type = resource_map.get(typename)\n            if res_type is None:\n                raise UnknownRecipeResourceType(\"Could not find shared resource type\", type=typename, name=name)\n\n            # If the resource defines an argument schema, make sure we enforce it.\n            if hasattr(res_type, \"ARG_SCHEMA\"):\n                try:\n                    args = res_type.ARG_SCHEMA.verify(args)\n                except ValidationError as exc:\n                    raise RecipeFileInvalid(\"Recipe file resource declarttion has invalid parameters\", resource=name, error_message=exc.msg, **exc.params)\n\n            if name in resources:\n                raise RecipeFileInvalid(\"Attempted to add two shared resources with the same name\", name=name)\n\n            res = ResourceDeclaration(name, resource_map.get(typename), args, autocreate, desc, typename)\n            resources[name] = res\n\n        return resources", "response": "Parse out what resources are declared as shared for this recipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses out all of the variable defaults.", "response": "def _parse_variable_defaults(cls, defaults):\n        \"\"\"Parse out all of the variable defaults.\"\"\"\n\n        default_dict = {}\n\n        for item in defaults:\n            key = next(iter(item))\n            value = item[key]\n\n            if key in default_dict:\n                raise RecipeFileInvalid(\"Default variable value specified twice\", name=key, old_value=default_dict[key], new_value=value)\n\n            default_dict[key] = value\n\n        return default_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses out what resources are used opened and closed in an action step.", "response": "def _parse_resource_usage(cls, action_dict, declarations):\n        \"\"\"Parse out what resources are used, opened and closed in an action step.\"\"\"\n\n        raw_used = action_dict.pop('use', [])\n        opened = [x.strip() for x in action_dict.pop('open_before', [])]\n        closed = [x.strip() for x in action_dict.pop('close_after', [])]\n\n        used = {}\n\n        for resource in raw_used:\n            if 'as' in resource:\n                global_name, _, local_name = resource.partition('as')\n                global_name = global_name.strip()\n                local_name = local_name.strip()\n\n                if len(global_name) == 0 or len(local_name) == 0:\n                    raise RecipeFileInvalid(\"Resource usage specified in action with invalid name using 'as' statement\", global_name=global_name, local_name=local_name, statement=resource)\n            else:\n                global_name = resource.strip()\n                local_name = global_name\n\n            if local_name in used:\n                raise RecipeFileInvalid(\"Resource specified twice for action\", args=action_dict, resource=local_name, used_resources=used)\n\n            used[local_name] = global_name\n\n        # Make sure we only use, open and close declared resources\n        for name in (x for x in used.values() if x not in declarations):\n            raise RecipeFileInvalid(\"Action makes use of non-declared shared resource\", name=name)\n\n        for name in (x for x in opened if x not in declarations):\n            raise RecipeFileInvalid(\"Action specified a non-declared shared resource in open_before\", name=name)\n\n        for name in (x for x in closed if x not in declarations):\n            raise RecipeFileInvalid(\"Action specified a non-declared shared resource in close_after\", name=name)\n\n        return ResourceUsage(used, opened, closed)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare(self, variables):\n        initializedsteps = []\n        if variables is None:\n            variables = dict()\n        for step, params, _resources, _files in self.steps:\n            new_params = _complete_parameters(params, variables)\n            initializedsteps.append(step(new_params))\n        return initializedsteps", "response": "Initialize all steps in this recipe using their parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and optionally open all shared resources.", "response": "def _prepare_resources(self, variables, overrides=None):\n        \"\"\"Create and optionally open all shared resources.\"\"\"\n\n        if overrides is None:\n            overrides = {}\n\n        res_map = {}\n        own_map = {}\n\n        for decl in self.resources.values():\n            resource = overrides.get(decl.name)\n\n            if resource is None:\n                args = _complete_parameters(decl.args, variables)\n                resource = decl.type(args)\n                own_map[decl.name] = resource\n\n            if decl.autocreate:\n                resource.open()\n\n            res_map[decl.name] = resource\n\n        return res_map, own_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, variables=None, overrides=None):\n\n        old_dir = os.getcwd()\n        try:\n            os.chdir(self.run_directory)\n\n            initialized_steps = self.prepare(variables)\n            owned_resources = {}\n\n            try:\n                print(\"Running in %s\" % self.run_directory)\n                initialized_resources, owned_resources = self._prepare_resources(variables, overrides)\n\n                for i, (step, decl) in enumerate(zip(initialized_steps, self.steps)):\n                    print(\"===> Step %d: %s\\t Description: %s\" % (i+1, self.steps[i][0].__name__, \\\n                        self.steps[i][1].get('description', '')))\n\n                    runtime, out = _run_step(step, decl, initialized_resources)\n\n                    print(\"======> Time Elapsed: %.2f seconds\" % runtime)\n                    if out is not None:\n                        print(out[1])\n            finally:\n                self._cleanup_resources(owned_resources)\n        finally:\n            os.chdir(old_dir)", "response": "Initialize and run this recipe."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(env):\n    c_file, cxx_file = SCons.Tool.createCFileBuilders(env)\n\n    # C\n    c_file.add_action('.y', YaccAction)\n    c_file.add_emitter('.y', yEmitter)\n\n    c_file.add_action('.yacc', YaccAction)\n    c_file.add_emitter('.yacc', yEmitter)\n\n    # Objective-C\n    c_file.add_action('.ym', YaccAction)\n    c_file.add_emitter('.ym', ymEmitter)\n\n    # C++\n    cxx_file.add_action('.yy', YaccAction)\n    cxx_file.add_emitter('.yy', yyEmitter)\n\n    env['YACC']      = env.Detect('bison') or 'yacc'\n    env['YACCFLAGS'] = SCons.Util.CLVar('')\n    env['YACCCOM']   = '$YACC $YACCFLAGS -o $TARGET $SOURCES'\n    env['YACCHFILESUFFIX'] = '.h'\n\n    env['YACCHXXFILESUFFIX'] = '.hpp'\n\n    env['YACCVCGFILESUFFIX'] = '.vcg'", "response": "Add Builders and construction variables for yacc to an Environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for Borland ilink to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for Borland ilink to an\n    Environment.\"\"\"\n    SCons.Tool.createSharedLibBuilder(env)\n    SCons.Tool.createProgBuilder(env)\n\n    env['LINK']        = '$CC'\n    env['LINKFLAGS']   = SCons.Util.CLVar('')\n    env['LINKCOM']     = '$LINK -q $LINKFLAGS -e$TARGET $SOURCES $LIBS'\n    env['LIBDIRPREFIX']=''\n    env['LIBDIRSUFFIX']=''\n    env['LIBLINKPREFIX']=''\n    env['LIBLINKSUFFIX']='$LIBSUFFIX'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to find the MS SDK directory from the registry. Return None if failed.", "response": "def find_sdk_dir(self):\n        \"\"\"Try to find the MS SDK from the registry.\n\n        Return None if failed or the directory does not exist.\n        \"\"\"\n        if not SCons.Util.can_read_reg:\n            debug('find_sdk_dir(): can not read registry')\n            return None\n\n        hkey = self.HKEY_FMT % self.hkey_data\n        debug('find_sdk_dir(): checking registry:{}'.format(hkey))\n\n        try:\n            sdk_dir = common.read_reg(hkey)\n        except SCons.Util.WinError as e:\n            debug('find_sdk_dir(): no SDK registry key {}'.format(repr(hkey)))\n            return None\n\n        debug('find_sdk_dir(): Trying SDK Dir: {}'.format(sdk_dir))\n\n        if not os.path.exists(sdk_dir):\n            debug('find_sdk_dir():  {} not on file system'.format(sdk_dir))\n            return None\n\n        ftc = os.path.join(sdk_dir, self.sanity_check_file)\n        if not os.path.exists(ftc):\n            debug(\"find_sdk_dir(): sanity check {} not found\".format(ftc))\n            return None\n\n        return sdk_dir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the MSSSDK given the version string.", "response": "def get_sdk_dir(self):\n        \"\"\"Return the MSSSDK given the version string.\"\"\"\n        try:\n            return self._sdk_dir\n        except AttributeError:\n            sdk_dir = self.find_sdk_dir()\n            self._sdk_dir = sdk_dir\n            return sdk_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sdk_vc_script(self,host_arch, target_arch):\n\n        if (host_arch == 'amd64' and target_arch == 'x86'):\n            # No cross tools needed compiling 32 bits on 64 bit machine\n            host_arch=target_arch\n\n        arch_string=target_arch\n        if (host_arch != target_arch):\n            arch_string='%s_%s'%(host_arch,target_arch)\n\n        debug(\"sdk.py: get_sdk_vc_script():arch_string:%s host_arch:%s target_arch:%s\"%(arch_string,\n                                                           host_arch,\n                                                           target_arch))\n        file=self.vc_setup_scripts.get(arch_string,None)\n        debug(\"sdk.py: get_sdk_vc_script():file:%s\"%file)\n        return file", "response": "Return the script to initialize the VC compiler installed by SDK\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, sensor_graph, scope_stack):\n\n        parent = scope_stack[-1]\n\n        try:\n            slot = parent.resolve_identifier('current_slot', SlotIdentifier)\n        except UnresolvedIdentifierError:\n            raise SensorGraphSemanticError(\"set config statement used outside of config block\")\n\n        if self.explicit_type is None or not isinstance(self.identifier, int):\n            raise SensorGraphSemanticError(\"Config variable type definitions are not yet supported\")\n\n        if isinstance(self.value, (bytes, bytearray)) and not self.explicit_type == 'binary':\n            raise SensorGraphSemanticError(\"You must pass the binary variable type when using encoded binary data\")\n\n        if not isinstance(self.value, (bytes, bytearray)) and self.explicit_type == 'binary':\n            raise SensorGraphSemanticError(\"You must pass an encoded binary value with binary type config variables\")\n\n        sensor_graph.add_config(slot, self.identifier, self.explicit_type, self.value)", "response": "Execute this statement on the current sensor graph given the current scope tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting an RPC call and response.", "response": "def format_rpc(data):\n    \"\"\"Format an RPC call and response.\n\n    Args:\n        data (tuple): A tuple containing the address, rpc_id, argument and\n            response payloads and any error code.\n\n    Returns:\n        str: The formated RPC string.\n    \"\"\"\n\n    address, rpc_id, args, resp, _status = data\n\n    name = rpc_name(rpc_id)\n\n    if isinstance(args, (bytes, bytearray)):\n        arg_str = hexlify(args)\n    else:\n        arg_str = repr(args)\n\n    if isinstance(resp, (bytes, bytearray)):\n        resp_str = hexlify(resp)\n    else:\n        resp_str = repr(resp)\n\n    #FIXME: Check and print status as well\n    return \"%s called on address %d, payload=%s, response=%s\" % (name, address, arg_str, resp_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, sensor_graph, scope_stack):\n\n        self.execute_before(sensor_graph, scope_stack)\n\n        for child in self.children:\n            child.execute(sensor_graph, scope_stack)\n\n        self.execute_after(sensor_graph, scope_stack)", "response": "Execute this statement on the sensor_graph given the current scope tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _cleanup_old_connections(self):\n\n        retval = await self._command_task.future_command(['_query_systemstate'])\n\n        for conn in retval['active_connections']:\n            self._logger.info(\"Forcible disconnecting connection %d\", conn)\n            await self._command_task.future_command(['_disconnect', conn])", "response": "Remove all active connections and disconnect them"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def start(self):\n\n        self._command_task.start()\n\n        try:\n            await self._cleanup_old_connections()\n        except Exception:\n            await self.stop()\n            raise\n\n        #FIXME: This is a temporary hack, get the actual device we are serving.\n        iotile_id = next(iter(self.adapter.devices))\n        self.device = self.adapter.devices[iotile_id]\n\n        self._logger.info(\"Serving device 0x%04X over BLED112\", iotile_id)\n        await self._update_advertisement()\n\n        self.setup_client(self.CLIENT_ID, scan=False, broadcast=True)", "response": "Start serving access to devices over bluetooth."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls an RPC given a header and possibly a previously sent payload.", "response": "async def _call_rpc(self, header):\n        \"\"\"Call an RPC given a header and possibly a previously sent payload\n\n        Args:\n            header (bytearray): The RPC header we should call\n        \"\"\"\n\n        length, _, cmd, feature, address = struct.unpack(\"<BBBBB\", bytes(header))\n        rpc_id = (feature << 8) | cmd\n\n        payload = self.rpc_payload[:length]\n\n        self._logger.debug(\"Calling RPC %d:%04X with %s\", address, rpc_id, binascii.hexlify(payload))\n\n        exception = None\n        response = None\n\n        try:\n            response = await self.send_rpc(self.CLIENT_ID, str(self.device.iotile_id), address, rpc_id, bytes(payload), timeout=30.0)\n        except VALID_RPC_EXCEPTIONS as err:\n            exception = err\n        except Exception as err:\n            self._logger.exception(\"Error calling RPC %d:%04X\", address, rpc_id)\n            exception = err\n\n        status, response = pack_rpc_response(response, exception)\n        resp_header = struct.pack(\"<BBBB\", status, 0, 0, len(response))\n\n        await self._send_notification(self.ReceiveHeaderHandle, resp_header)\n\n        if len(response) > 0:\n            await self._send_notification(self.ReceivePayloadHandle, response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_script(sensor_graph):\n\n    records = []\n\n    records.append(SetGraphOnlineRecord(False, address=8))\n    records.append(ClearDataRecord(address=8))\n    records.append(ResetGraphRecord(address=8))\n\n    for node in sensor_graph.nodes:\n        records.append(AddNodeRecord(str(node), address=8))\n\n    for streamer in sensor_graph.streamers:\n        records.append(AddStreamerRecord(streamer, address=8))\n\n    for stream, value in sorted(sensor_graph.constant_database.items(), key=lambda x: x[0].encode()):\n        records.append(SetConstantRecord(stream, value, address=8))\n\n    records.append(PersistGraphRecord(address=8))\n\n    records.append(ClearConfigVariablesRecord())\n    for slot in sorted(sensor_graph.config_database, key=lambda x: x.encode()):\n        for config_id in sorted(sensor_graph.config_database[slot]):\n            config_type, value = sensor_graph.config_database[slot][config_id]\n            byte_value = _convert_to_bytes(config_type, value)\n\n            records.append(SetConfigRecord(slot, config_id, byte_value))\n\n    # If we have an app tag and version set program them in\n    app_tag = sensor_graph.metadata_database.get('app_tag')\n    app_version = sensor_graph.metadata_database.get('app_version')\n\n    if app_tag is not None:\n        records.append(SetDeviceTagRecord(app_tag=app_tag, app_version=app_version))\n\n    script = UpdateScript(records)\n    return script.encode()", "response": "Create a binary script containing this sensor graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the state of this SensorLog.", "response": "def dump(self):\n        \"\"\"Dump the state of this SensorLog.\n\n        The purpose of this method is to be able to restore the same state\n        later.  However there are links in the SensorLog for stream walkers.\n\n        So the dump process saves the state of each stream walker and upon\n        restore, it looks through the current set of stream walkers and\n        restores each one that existed when dump() was called to its state.\n\n        Returns:\n            dict: The serialized state of this SensorLog.\n        \"\"\"\n\n        walkers = {}\n        walkers.update({str(walker.selector): walker.dump() for walker in self._queue_walkers})\n        walkers.update({str(walker.selector): walker.dump() for walker in self._virtual_walkers})\n\n        return {\n            u'engine': self._engine.dump(),\n            u'rollover_storage': self._rollover_storage,\n            u'rollover_streaming': self._rollover_streaming,\n            u'last_values': {str(stream): reading.asdict() for stream, reading in self._last_values.items()},\n            u'walkers': walkers\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrestores a previously - dumped state from a state dict.", "response": "def restore(self, state, permissive=False):\n        \"\"\"Restore a state previously dumped by a call to dump().\n\n        The purpose of this method is to be able to restore a previously\n        dumped state.  However there are links in the SensorLog for stream\n        walkers.\n\n        So the restore process looks through the current set of stream walkers\n        and restores each one that existed when dump() was called to its\n        state.  If there are walkers allocated that were not present when\n        dump() was called, an exception is raised unless permissive=True,\n        in which case they are ignored.\n\n        Args:\n            state (dict): The previous state to restore, from a prior call\n                to dump().\n            permissive (bool): Whether to raise an exception is new stream\n                walkers are present that do not have dumped contents().\n\n        Raises:\n            ArgumentError: There are new stream walkers present in the current\n                SensorLog and permissive==False.\n        \"\"\"\n\n        self._engine.restore(state.get(u'engine'))\n        self._last_values = {DataStream.FromString(stream): IOTileReading.FromDict(reading) for\n                             stream, reading in state.get(u\"last_values\", {}).items()}\n\n        self._rollover_storage = state.get(u'rollover_storage', True)\n        self._rollover_streaming = state.get(u'rollover_streaming', True)\n\n        old_walkers = {DataStreamSelector.FromString(selector): dump for selector, dump in\n                       state.get(u\"walkers\").items()}\n\n        for walker in self._virtual_walkers:\n            if walker.selector in old_walkers:\n                walker.restore(old_walkers[walker.selector])\n            elif not permissive:\n                raise ArgumentError(\"Cannot restore SensorLog, walker %s exists in restored log but did not exist before\" % str(walker.selector))\n\n        for walker in self._queue_walkers:\n            if walker.selector in old_walkers:\n                walker.restore(old_walkers[walker.selector])\n            elif not permissive:\n                raise ArgumentError(\"Cannot restore SensorLog, walker %s exists in restored log but did not exist before\" % str(walker.selector))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_rollover(self, area, enabled):\n\n        if area == u'streaming':\n            self._rollover_streaming = enabled\n        elif area == u'storage':\n            self._rollover_storage = enabled\n        else:\n            raise ArgumentError(\"You must pass one of 'storage' or 'streaming' to set_rollover\", area=area)", "response": "Configure whether rollover is enabled for streaming or storage streams."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump_constants(self):\n\n        constants = []\n\n        for walker in self._virtual_walkers:\n            if not walker.selector.inexhaustible:\n                continue\n\n            constants.append((walker.selector.as_stream(), walker.reading))\n\n        return constants", "response": "Dump all of the defined constants for all constant streams."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling a function whenever a new entry in the cache is pushed.", "response": "def watch(self, selector, callback):\n        \"\"\"Call a function whenever a stream changes.\n\n        Args:\n            selector (DataStreamSelector): The selector to watch.\n                If this is None, it is treated as a wildcard selector\n                that matches every stream.\n            callback (callable): The function to call when a new\n                reading is pushed.  Callback is called as:\n                callback(stream, value)\n        \"\"\"\n\n        if selector not in self._monitors:\n            self._monitors[selector] = set()\n\n        self._monitors[selector].add(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a stream walker based on the given selector.", "response": "def create_walker(self, selector, skip_all=True):\n        \"\"\"Create a stream walker based on the given selector.\n\n        This function returns a StreamWalker subclass that will\n        remain up to date and allow iterating over and popping readings\n        from the stream(s) specified by the selector.\n\n        When the stream walker is done, it should be passed to\n        destroy_walker so that it is removed from internal lists that\n        are used to always keep it in sync.\n\n        Args:\n            selector (DataStreamSelector): The selector describing the\n                streams that we want to iterate over.\n            skip_all (bool): Whether to start at the beginning of the data\n                or to skip everything and start at the end.  Defaults\n                to skipping everything.  This parameter only has any\n                effect on buffered stream selectors.\n\n        Returns:\n            StreamWalker: A properly updating stream walker with the given selector.\n        \"\"\"\n\n        if selector.buffered:\n            walker = BufferedStreamWalker(selector, self._engine, skip_all=skip_all)\n            self._queue_walkers.append(walker)\n            return walker\n\n        if selector.match_type == DataStream.CounterType:\n            walker = CounterStreamWalker(selector)\n        else:\n            walker = VirtualStreamWalker(selector)\n\n        self._virtual_walkers.append(walker)\n\n        return walker"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndestroy a previously created stream walker.", "response": "def destroy_walker(self, walker):\n        \"\"\"Destroy a previously created stream walker.\n\n        Args:\n            walker (StreamWalker): The walker to remove from internal updating\n                lists.\n        \"\"\"\n\n        if walker.buffered:\n            self._queue_walkers.remove(walker)\n        else:\n            self._virtual_walkers.remove(walker)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restore_walker(self, dumped_state):\n\n        selector_string = dumped_state.get(u'selector')\n        if selector_string is None:\n            raise ArgumentError(\"Invalid stream walker state in restore_walker, missing 'selector' key\", state=dumped_state)\n\n        selector = DataStreamSelector.FromString(selector_string)\n\n        walker = self.create_walker(selector)\n        walker.restore(dumped_state)\n        return walker", "response": "Restore a stream walker that was previously serialized."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n\n        for walker in self._virtual_walkers:\n            walker.skip_all()\n\n        self._engine.clear()\n\n        for walker in self._queue_walkers:\n            walker.skip_all()\n\n        self._last_values = {}", "response": "Clear all data from this sensor_log."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npushing a reading into a stream updating any associated stream walkers.", "response": "def push(self, stream, reading):\n        \"\"\"Push a reading into a stream, updating any associated stream walkers.\n\n        Args:\n            stream (DataStream): the stream to push the reading into\n            reading (IOTileReading): the reading to push\n        \"\"\"\n\n        # Make sure the stream is correct\n        reading = copy.copy(reading)\n        reading.stream = stream.encode()\n\n        if stream.buffered:\n            output_buffer = stream.output\n\n            if self.id_assigner is not None:\n                reading.reading_id = self.id_assigner(stream, reading)\n\n            try:\n                self._engine.push(reading)\n            except StorageFullError:\n                # If we are in fill-stop mode, don't auto erase old data.\n                if (stream.output and not self._rollover_streaming) or (not stream.output and not self._rollover_storage):\n                    raise\n\n                self._erase_buffer(stream.output)\n                self._engine.push(reading)\n\n            for walker in self._queue_walkers:\n                # Only notify the walkers that are on this queue\n                if walker.selector.output == output_buffer:\n                    walker.notify_added(stream)\n\n        # Activate any monitors we have for this stream\n        for selector in self._monitors:\n            if selector is None or selector.matches(stream):\n                for callback in self._monitors[selector]:\n                    callback(stream, reading)\n\n        # Virtual streams live only in their walkers, so update each walker\n        # that contains this stream.\n        for walker in self._virtual_walkers:\n            if walker.matches(stream):\n                walker.push(stream, reading)\n\n        self._last_values[stream] = reading"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _erase_buffer(self, output_buffer):\n\n        erase_size = self._model.get(u'buffer_erase_size')\n\n        buffer_type = u'storage'\n        if output_buffer:\n            buffer_type = u'streaming'\n\n        old_readings = self._engine.popn(buffer_type, erase_size)\n\n        # Now go through all of our walkers that could match and\n        # update their availability counts and data buffer pointers\n        for reading in old_readings:\n            stream = DataStream.FromEncoded(reading.stream)\n\n            for walker in self._queue_walkers:\n                # Only notify the walkers that are on this queue\n                if walker.selector.output == output_buffer:\n                    walker.notify_rollover(stream)", "response": "Erase readings in the specified buffer to make space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the last value pushed into a stream. This function works even if the stream is virtual and no virtual walker has been created for it. It is primarily useful to aid in debugging sensor graphs. Args: stream (DataStream): The stream to inspect. only_allocated (bool): Optional parameter to only allow inspection of allocated virtual streams. This is useful for mimicking the behavior of an embedded device that does not have a _last_values array. Returns: IOTileReading: The data in the stream Raises: StreamEmptyError: if there has never been data written to the stream. UnresolvedIdentifierError: if only_allocated is True and there has not been a virtual stream walker allocated to listen to this stream.", "response": "def inspect_last(self, stream, only_allocated=False):\n        \"\"\"Return the last value pushed into a stream.\n\n        This function works even if the stream is virtual and no\n        virtual walker has been created for it.  It is primarily\n        useful to aid in debugging sensor graphs.\n\n        Args:\n            stream (DataStream): The stream to inspect.\n            only_allocated (bool): Optional parameter to only allow inspection\n                of allocated virtual streams.  This is useful for mimicking the\n                behavior of an embedded device that does not have a _last_values\n                array.\n\n        Returns:\n            IOTileReading: The data in the stream\n\n        Raises:\n            StreamEmptyError: if there has never been data written to\n                the stream.\n            UnresolvedIdentifierError: if only_allocated is True and there has not\n                been a virtual stream walker allocated to listen to this stream.\n        \"\"\"\n\n        if only_allocated:\n            found = False\n            for walker in self._virtual_walkers:\n                if walker.matches(stream):\n                    found = True\n                    break\n\n            if not found:\n                raise UnresolvedIdentifierError(\"inspect_last could not find an allocated virtual streamer for the desired stream\", stream=stream)\n\n        if stream in self._last_values:\n            return self._last_values[stream]\n\n        raise StreamEmptyError(u\"inspect_last called on stream that has never been written to\", stream=stream)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _run_exitfuncs():\n\n    while _exithandlers:\n        func, targs, kargs =  _exithandlers.pop()\n        func(*targs, **kargs)", "response": "run any registered exit functions\n    _exithandlers is traversed in reverse order so functions are executed in reverse order so they are executed in reverse order."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds Builders and construction variables for gnulink to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for gnulink to an Environment.\"\"\"\n    link.generate(env)\n\n    if env['PLATFORM'] == 'hpux':\n        env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS -shared -fPIC')\n\n    # __RPATH is set to $_RPATH in the platform specification if that\n    # platform supports it.\n    env['RPATHPREFIX'] = '-Wl,-rpath='\n    env['RPATHSUFFIX'] = ''\n    env['_RPATH'] = '${_concat(RPATHPREFIX, RPATH, RPATHSUFFIX, __env__)}'\n\n    # OpenBSD doesn't usually use SONAME for libraries\n    use_soname = not sys.platform.startswith('openbsd')\n    link._setup_versioned_lib_variables(env, tool = 'gnulink', use_soname = use_soname)\n    env['LINKCALLBACKS'] = link._versioned_lib_callbacks()\n\n    # For backward-compatibility with older SCons versions\n    env['SHLIBVERSIONFLAGS'] = SCons.Util.CLVar('-Wl,-Bsymbolic')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _windowsLdmodTargets(target, source, env, for_signature):\n    return _dllTargets(target, source, env, for_signature, 'LDMODULE')", "response": "Get targets for loadable modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget sources for loadable modules.", "response": "def _windowsLdmodSources(target, source, env, for_signature):\n    \"\"\"Get sources for loadable modules.\"\"\"\n    return _dllSources(target, source, env, for_signature, 'LDMODULE')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _dllEmitter(target, source, env, paramtp):\n    SCons.Tool.msvc.validate_vars(env)\n\n    extratargets = []\n    extrasources = []\n\n    dll = env.FindIxes(target, '%sPREFIX' % paramtp, '%sSUFFIX' % paramtp)\n    no_import_lib = env.get('no_import_lib', 0)\n\n    if not dll:\n        raise SCons.Errors.UserError('A shared library should have exactly one target with the suffix: %s' % env.subst('$%sSUFFIX' % paramtp))\n\n    insert_def = env.subst(\"$WINDOWS_INSERT_DEF\")\n    if not insert_def in ['', '0', 0] and \\\n       not env.FindIxes(source, \"WINDOWSDEFPREFIX\", \"WINDOWSDEFSUFFIX\"):\n\n        # append a def file to the list of sources\n        extrasources.append(\n            env.ReplaceIxes(dll,\n                            '%sPREFIX' % paramtp, '%sSUFFIX' % paramtp,\n                            \"WINDOWSDEFPREFIX\", \"WINDOWSDEFSUFFIX\"))\n\n    version_num, suite = SCons.Tool.msvs.msvs_parse_version(env.get('MSVS_VERSION', '6.0'))\n    if version_num >= 8.0 and \\\n            (env.get('WINDOWS_INSERT_MANIFEST', 0) or env.get('WINDOWS_EMBED_MANIFEST', 0)):\n        # MSVC 8 and above automatically generate .manifest files that must be installed\n        extratargets.append(\n            env.ReplaceIxes(dll,\n                            '%sPREFIX' % paramtp, '%sSUFFIX' % paramtp,\n                            \"WINDOWSSHLIBMANIFESTPREFIX\", \"WINDOWSSHLIBMANIFESTSUFFIX\"))\n\n    if 'PDB' in env and env['PDB']:\n        pdb = env.arg2nodes('$PDB', target=target, source=source)[0]\n        extratargets.append(pdb)\n        target[0].attributes.pdb = pdb\n\n    if version_num >= 11.0 and env.get('PCH', 0):\n        # MSVC 11 and above need the PCH object file to be added to the link line,\n        # otherwise you get link error LNK2011.\n        pchobj = SCons.Util.splitext(str(env['PCH']))[0] + '.obj'\n        # print \"prog_emitter, version %s, appending pchobj %s\"%(version_num, pchobj)\n        if pchobj not in extrasources:\n            extrasources.append(pchobj)\n\n    if not no_import_lib and \\\n       not env.FindIxes(target, \"LIBPREFIX\", \"LIBSUFFIX\"):\n        # Append an import library to the list of targets.\n        extratargets.append(\n            env.ReplaceIxes(dll,\n                            '%sPREFIX' % paramtp, '%sSUFFIX' % paramtp,\n                            \"LIBPREFIX\", \"LIBSUFFIX\"))\n        # and .exp file is created if there are exports from a DLL\n        extratargets.append(\n            env.ReplaceIxes(dll,\n                            '%sPREFIX' % paramtp, '%sSUFFIX' % paramtp,\n                            \"WINDOWSEXPPREFIX\", \"WINDOWSEXPSUFFIX\"))\n\n    return (target+extratargets, source+extrasources)", "response": "Common implementation of dll emitter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef embedManifestDllCheck(target, source, env):\n    if env.get('WINDOWS_EMBED_MANIFEST', 0):\n        manifestSrc = target[0].get_abspath() + '.manifest'\n        if os.path.exists(manifestSrc):\n            ret = (embedManifestDllAction) ([target[0]],None,env)        \n            if ret:\n                raise SCons.Errors.UserError(\"Unable to embed manifest into %s\" % (target[0]))\n            return ret\n        else:\n            print('(embed: no %s.manifest found; not embedding.)'%str(target[0]))\n    return 0", "response": "Function run by embedManifestDllCheckAction to check for existence of manifest\n    and other conditions and embed the manifest into the target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef embedManifestExeCheck(target, source, env):\n    if env.get('WINDOWS_EMBED_MANIFEST', 0):\n        manifestSrc = target[0].get_abspath() + '.manifest'\n        if os.path.exists(manifestSrc):\n            ret = (embedManifestExeAction) ([target[0]],None,env)\n            if ret:\n                raise SCons.Errors.UserError(\"Unable to embed manifest into %s\" % (target[0]))\n            return ret\n        else:\n            print('(embed: no %s.manifest found; not embedding.)'%str(target[0]))\n    return 0", "response": "Function run by embedManifestExeCheckAction to check for existence of manifest\n    and other conditions and embed the manifest into the target."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds Builders and construction variables for ar to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for ar to an Environment.\"\"\"\n    SCons.Tool.createSharedLibBuilder(env)\n    SCons.Tool.createProgBuilder(env)\n\n    env['SHLINK']      = '$LINK'\n    env['SHLINKFLAGS'] = SCons.Util.CLVar('$LINKFLAGS /dll')\n    env['_SHLINK_TARGETS'] = windowsShlinkTargets\n    env['_SHLINK_SOURCES'] = windowsShlinkSources\n    env['SHLINKCOM']   =  compositeShLinkAction\n    env.Append(SHLIBEMITTER = [windowsLibEmitter])\n    env.Append(LDMODULEEMITTER = [windowsLibEmitter])\n    env['LINK']        = 'link'\n    env['LINKFLAGS']   = SCons.Util.CLVar('/nologo')\n    env['_PDB'] = pdbGenerator\n    env['LINKCOM'] = compositeLinkAction\n    env.Append(PROGEMITTER = [prog_emitter])\n    env['LIBDIRPREFIX']='/LIBPATH:'\n    env['LIBDIRSUFFIX']=''\n    env['LIBLINKPREFIX']=''\n    env['LIBLINKSUFFIX']='$LIBSUFFIX'\n\n    env['WIN32DEFPREFIX']        = ''\n    env['WIN32DEFSUFFIX']        = '.def'\n    env['WIN32_INSERT_DEF']      = 0\n    env['WINDOWSDEFPREFIX']      = '${WIN32DEFPREFIX}'\n    env['WINDOWSDEFSUFFIX']      = '${WIN32DEFSUFFIX}'\n    env['WINDOWS_INSERT_DEF']    = '${WIN32_INSERT_DEF}'\n\n    env['WIN32EXPPREFIX']        = ''\n    env['WIN32EXPSUFFIX']        = '.exp'\n    env['WINDOWSEXPPREFIX']      = '${WIN32EXPPREFIX}'\n    env['WINDOWSEXPSUFFIX']      = '${WIN32EXPSUFFIX}'\n\n    env['WINDOWSSHLIBMANIFESTPREFIX'] = ''\n    env['WINDOWSSHLIBMANIFESTSUFFIX'] = '${SHLIBSUFFIX}.manifest'\n    env['WINDOWSPROGMANIFESTPREFIX']  = ''\n    env['WINDOWSPROGMANIFESTSUFFIX']  = '${PROGSUFFIX}.manifest'\n\n    env['REGSVRACTION'] = regServerCheck\n    env['REGSVR'] = os.path.join(SCons.Platform.win32.get_system_root(),'System32','regsvr32')\n    env['REGSVRFLAGS'] = '/s '\n    env['REGSVRCOM'] = '$REGSVR $REGSVRFLAGS ${TARGET.windows}'\n\n    env['WINDOWS_EMBED_MANIFEST'] = 0\n    env['MT'] = 'mt'\n    #env['MTFLAGS'] = ['-hashupdate']\n    env['MTFLAGS'] = SCons.Util.CLVar('/nologo')\n    # Note: use - here to prevent build failure if no manifest produced.\n    # This seems much simpler than a fancy system using a function action to see\n    # if the manifest actually exists before trying to run mt with it.\n    env['MTEXECOM']   = '-$MT $MTFLAGS -manifest ${TARGET}.manifest $_MANIFEST_SOURCES -outputresource:$TARGET;1'\n    env['MTSHLIBCOM'] = '-$MT $MTFLAGS -manifest ${TARGET}.manifest $_MANIFEST_SOURCES -outputresource:$TARGET;2'\n    # TODO Future work garyo 27-Feb-11\n    env['_MANIFEST_SOURCES'] = None # _windowsManifestSources\n\n    # Set-up ms tools paths\n    msvc_setup_env_once(env)\n\n\n    # Loadable modules are on Windows the same as shared libraries, but they\n    # are subject to different build parameters (LDMODULE* variables).\n    # Therefore LDMODULE* variables correspond as much as possible to\n    # SHLINK*/SHLIB* ones.\n    SCons.Tool.createLoadableModuleBuilder(env)\n    env['LDMODULE'] = '$SHLINK'\n    env['LDMODULEPREFIX'] = '$SHLIBPREFIX'\n    env['LDMODULESUFFIX'] = '$SHLIBSUFFIX'\n    env['LDMODULEFLAGS'] = '$SHLINKFLAGS'\n    env['_LDMODULE_TARGETS'] = _windowsLdmodTargets\n    env['_LDMODULE_SOURCES'] = _windowsLdmodSources\n    env['LDMODULEEMITTER'] = [ldmodEmitter]\n    env['LDMODULECOM'] = compositeLdmodAction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd Builders and construction variables for dvips to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for dvips to an Environment.\"\"\"\n    global PSAction\n    if PSAction is None:\n        PSAction = SCons.Action.Action('$PSCOM', '$PSCOMSTR')\n\n    global DVIPSAction\n    if DVIPSAction is None:\n        DVIPSAction = SCons.Action.Action(DviPsFunction, strfunction = DviPsStrFunction)\n\n    global PSBuilder\n    if PSBuilder is None:\n        PSBuilder = SCons.Builder.Builder(action = PSAction,\n                                          prefix = '$PSPREFIX',\n                                          suffix = '$PSSUFFIX',\n                                          src_suffix = '.dvi',\n                                          src_builder = 'DVI',\n                                          single_source=True)\n\n    env['BUILDERS']['PostScript'] = PSBuilder\n    \n    env['DVIPS']      = 'dvips'\n    env['DVIPSFLAGS'] = SCons.Util.CLVar('')\n    # I'm not quite sure I got the directories and filenames right for variant_dir\n    # We need to be in the correct directory for the sake of latex \\includegraphics eps included files.\n    env['PSCOM']      = 'cd ${TARGET.dir} && $DVIPS $DVIPSFLAGS -o ${TARGET.file} ${SOURCE.file}'\n    env['PSPREFIX'] = ''\n    env['PSSUFFIX'] = '.ps'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting this statement on the sensor_graph given the current scope tree.", "response": "def execute(self, sensor_graph, scope_stack):\n        \"\"\"Execute this statement on the sensor_graph given the current scope tree.\n\n        This adds a single DataStreamer to the current sensor graph\n\n        Args:\n            sensor_graph (SensorGraph): The sensor graph that we are building or\n                modifying\n            scope_stack (list(Scope)): A stack of nested scopes that may influence\n                how this statement allocates clocks or other stream resources.\n        \"\"\"\n\n        streamer = DataStreamer(self.selector, self.dest, self.report_format, self.auto, report_type=self.report_type, with_other=self.with_other)\n        sensor_graph.add_streamer(streamer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_program(tile, elfname, chip, patch=True):\n\n    dirs = chip.build_dirs()\n\n    output_name = '%s_%s.elf' % (elfname, chip.arch_name(),)\n    output_binname = '%s_%s.bin' % (elfname, chip.arch_name(),)\n    patched_name = '%s_%s_patched.elf' % (elfname, chip.arch_name(),)\n    patchfile_name = '%s_%s_patchcommand.txt' % (elfname, chip.arch_name(),)\n    map_name = '%s_%s.map' % (elfname, chip.arch_name(),)\n\n    VariantDir(dirs['build'], os.path.join('firmware', 'src'), duplicate=0)\n\n    args_file = os.path.join('.', dirs['build'], 'gcc_args.txt')\n    prog_env = setup_environment(chip, args_file=args_file)\n\n    prog_env['OUTPUT'] = output_name\n    prog_env['BUILD_DIR'] = dirs['build']\n    prog_env['OUTPUT_PATH'] = os.path.join(dirs['build'], output_name)\n    prog_env['OUTPUTBIN'] = os.path.join(dirs['build'], output_binname)\n    prog_env['PATCHED'] = os.path.join(dirs['build'], patched_name)\n    prog_env['PATCH_FILE'] = os.path.join(dirs['build'], patchfile_name)\n    prog_env['PATCH_FILENAME'] = patchfile_name\n    prog_env['MODULE'] = elfname\n\n    # Setup all of our dependencies and make sure our output depends on them being built\n    tilebus_defs = setup_dependencies(tile, prog_env)\n\n    # Setup specific linker flags for building a program\n    # Specify the linker script\n    # We can find a linker script in one of two places, either in a dependency or in an explicit 'linker' property\n    # First check for a linker script in our dependencies\n    ldscripts = list(itertools.chain(*[x.find_products('linker_script') for x in prog_env['DEPENDENCIES']]))\n\n    # Make sure we don't have multiple linker scripts coming in from dependencies\n    if len(ldscripts) > 1:\n        raise BuildError(\"Multiple linker scripts included from dependencies, at most one may be included\",\n                         linker_scripts=ldscripts)\n\n    # Make sure we don't have a linker script from a dependency and explicity specified\n    if len(ldscripts) == 1 and chip.property('linker', None) is not None:\n        raise BuildError(\"Linker script specified in dependency and explicitly in module_settings\",\n                         explicit_script=chip.property('linker'), dependency_script=ldscripts[0])\n\n    if len(ldscripts) == 1:\n        ldscript = ldscripts[0]\n    else:\n        ldscript = utilities.join_path(chip.property('linker'))\n\n    # Find the linker script directory in case it includes other linker scripts in the same directory\n    lddir = os.path.abspath(os.path.dirname(ldscript))\n    prog_env['LIBPATH'] += [lddir]\n\n    prog_env['LINKFLAGS'].append('-T\"%s\"' % ldscript)\n\n    # Specify the output map file\n    prog_env['LINKFLAGS'].extend(['-Xlinker', '-Map=\"%s\"' % os.path.join(dirs['build'], map_name)])\n    Clean(os.path.join(dirs['build'], output_name), [os.path.join(dirs['build'], map_name)])\n\n    # Compile the TileBus command and config variable definitions\n    # Try to use the modern 'tilebus' directory or the old 'cdb' directory\n    tbname = os.path.join('firmware', 'src', 'tilebus', prog_env[\"MODULE\"] + \".bus\")\n    if not os.path.exists(tbname):\n        tbname = os.path.join('firmware', 'src', 'cdb', prog_env[\"MODULE\"] + \".cdb\")\n\n    compile_tilebus(tilebus_defs + [tbname], prog_env)\n\n    # Ensure that our argument file to gcc is created\n    args_node = prog_env.Command([args_file], [],\n                                 action=prog_env.Action(create_arg_file, \"Creating GCC Arguments\"))\n    prog_env.AlwaysBuild(args_node)\n\n    # Compile an elf for the firmware image\n    objs = SConscript(os.path.join(dirs['build'], 'SConscript'), exports='prog_env')\n    for obj in objs:\n        Depends(obj, args_file)\n\n    outfile = prog_env.Program(os.path.join(dirs['build'], prog_env['OUTPUT']), objs)\n\n    if patch:\n        # Create a patched ELF including a proper checksum\n        # First create a binary dump of the program flash\n        outbin = prog_env.Command(prog_env['OUTPUTBIN'], os.path.join(dirs['build'], prog_env['OUTPUT']),\n                                  \"arm-none-eabi-objcopy -O binary $SOURCES $TARGET\")\n\n        # Now create a command file containing the linker command needed to patch the elf\n        outhex = prog_env.Command(prog_env['PATCH_FILE'], outbin, action=prog_env.Action(checksum_creation_action,\n                                                                                         \"Generating checksum file\"))\n\n        # Next relink a new version of the binary using that patch file to define the image checksum\n        patch_env = prog_env.Clone()\n        patch_env['LINKFLAGS'].append(['-Xlinker', '@%s' % patch_env['PATCH_FILE']])\n\n        patched_file = patch_env.Program(prog_env['PATCHED'], objs)\n        patch_env.Depends(patched_file, [os.path.join(dirs['build'], output_name), patch_env['PATCH_FILE']])\n\n        prog_env.Depends(os.path.join(dirs['build'], output_name), [ldscript])\n\n        prog_env.InstallAs(os.path.join(dirs['output'], output_name), os.path.join(dirs['build'], patched_name))\n    else:\n        prog_env.InstallAs(os.path.join(dirs['output'], output_name), outfile)\n\n    prog_env.InstallAs(os.path.join(dirs['output'], map_name), os.path.join(dirs['build'], map_name))\n\n    return os.path.join(dirs['output'], output_name)", "response": "Build an ARM cortex executable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_library(tile, libname, chip):\n\n    dirs = chip.build_dirs()\n\n    output_name = '%s_%s.a' % (libname, chip.arch_name())\n\n    # Support both firmware/src and just src locations for source code\n    if os.path.exists('firmware'):\n        VariantDir(dirs['build'], os.path.join('firmware', 'src'), duplicate=0)\n    else:\n        VariantDir(dirs['build'], 'src', duplicate=0)\n\n    library_env = setup_environment(chip)\n    library_env['OUTPUT'] = output_name\n    library_env['OUTPUT_PATH'] = os.path.join(dirs['build'], output_name)\n    library_env['BUILD_DIR'] = dirs['build']\n\n    # Check for any dependencies this library has\n    tilebus_defs = setup_dependencies(tile, library_env)\n\n    # Create header files for all tilebus config variables and commands that are defined in ourselves\n    # or in our dependencies\n    tilebus_defs += tile.find_products('tilebus_definitions')\n    compile_tilebus(tilebus_defs, library_env, header_only=True)\n\n    SConscript(os.path.join(dirs['build'], 'SConscript'), exports='library_env')\n\n    library_env.InstallAs(os.path.join(dirs['output'], output_name), os.path.join(dirs['build'], output_name))\n\n    # See if we should copy any files over to the output:\n    for src, dst in chip.property('copy_files', []):\n        srcpath = os.path.join(*src)\n        destpath = os.path.join(dirs['output'], dst)\n        library_env.InstallAs(destpath, srcpath)\n\n    return os.path.join(dirs['output'], output_name)", "response": "Build a static ARM cortex library"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_environment(chip, args_file=None):\n\n    config = ConfigManager()\n\n    # Make sure we never get MSVC settings for windows since that has the wrong command line flags for gcc\n    if platform.system() == 'Windows':\n        env = Environment(tools=['mingw'], ENV=os.environ)\n    else:\n        env = Environment(tools=['default'], ENV=os.environ)\n\n    env['INCPREFIX'] = '-I\"'\n    env['INCSUFFIX'] = '\"'\n    env['CPPDEFPREFIX'] = ''\n    env['CPPDEFSUFFIX'] = ''\n\n    env['CPPPATH'] = chip.includes()\n    env['ARCH'] = chip\n\n    # Setup Cross Compiler\n    env['CC'] = 'arm-none-eabi-gcc'\n    env['AS'] = 'arm-none-eabi-gcc'\n    env['LINK'] = 'arm-none-eabi-gcc'\n    env['AR'] = 'arm-none-eabi-ar'\n    env['RANLIB'] = 'arm-none-eabi-ranlib'\n\n    # AS command line is by default setup for call as directly so we need\n    # to modify it to call via *-gcc to allow for preprocessing\n    env['ASCOM'] = \"$AS $ASFLAGS -o $TARGET -c $SOURCES\"\n\n    # Setup nice display strings unless we're asked to show raw commands\n    if not config.get('build:show-commands'):\n        env['CCCOMSTR'] = \"Compiling $TARGET\"\n        env['ARCOMSTR'] = \"Building static library $TARGET\"\n        env['RANLIBCOMSTR'] = \"Indexing static library $TARGET\"\n        env['LINKCOMSTR'] = \"Linking $TARGET\"\n\n    # Setup Compiler Flags\n    env['CCFLAGS'] = chip.combined_properties('cflags')\n    env['LINKFLAGS'] = chip.combined_properties('ldflags')\n    env['ARFLAGS'].append(chip.combined_properties('arflags')) # There are default ARFLAGS that are necessary to keep\n    env['ASFLAGS'].append(chip.combined_properties('asflags'))\n\n    # Add in compile tile definitions\n    defines = utilities.build_defines(chip.property('defines', {}))\n    env['CPPDEFINES'] = defines\n\n    if args_file is not None:\n        env['CCCOM'] = \"$CC $CCFLAGS $CPPFLAGS @{} -c -o $TARGET $SOURCES\".format(args_file)\n\n    # Setup Target Architecture\n    env['CCFLAGS'].append('-mcpu=%s' % chip.property('cpu'))\n    env['ASFLAGS'].append('-mcpu=%s' % chip.property('cpu'))\n    env['LINKFLAGS'].append('-mcpu=%s' % chip.property('cpu'))\n\n    # Initialize library paths (all libraries are added via dependencies)\n    env['LIBPATH'] = []\n    env['LIBS'] = []\n\n    return env", "response": "Setup the SCons environment for compiling arm cortex code."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a list of files and an Environment object and a list of files and an Environment object return a Command object containing the CommandMap and CommandMap headers containing the information.", "response": "def compile_tilebus(files, env, outdir=None, header_only=False):\n    \"\"\"Given a path to a *.cdb file, process it and generate c tables and/or headers containing the information.\"\"\"\n\n    if outdir is None:\n        dirs = env[\"ARCH\"].build_dirs()\n        outdir = dirs['build']\n\n    cmdmap_c_path = os.path.join(outdir, 'command_map_c.c')\n    cmdmap_h_path = os.path.join(outdir, 'command_map_c.h')\n    config_c_path = os.path.join(outdir, 'config_variables_c.c')\n    config_h_path = os.path.join(outdir, 'config_variables_c.h')\n\n    if header_only:\n        return env.Command([cmdmap_h_path, config_h_path], files,\n                           action=env.Action(tb_h_file_creation, \"Creating header files from TileBus definitions\"))\n    else:\n        env['MIBFILE'] = '#' + cmdmap_c_path\n        return env.Command([cmdmap_c_path, cmdmap_h_path, config_c_path, config_h_path], files,\n                           action=env.Action(tb_c_file_creation, \"Compiling TileBus commands and config variables\"))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile tilebus file into a. h. c pair for compilation into an ARM object", "response": "def tb_c_file_creation(target, source, env):\n    \"\"\"Compile tilebus file into a .h/.c pair for compilation into an ARM object\"\"\"\n\n    files = [str(x) for x in source]\n\n    try:\n        desc = TBDescriptor(files)\n    except pyparsing.ParseException as e:\n        raise BuildError(\"Could not parse tilebus file\", parsing_exception=e)\n\n    block = desc.get_block()\n    block.render_template(block.CommandFileTemplate, out_path=str(target[0]))\n    block.render_template(block.CommandHeaderTemplate, out_path=str(target[1]))\n    block.render_template(block.ConfigFileTemplate, out_path=str(target[2]))\n    block.render_template(block.ConfigHeaderTemplate, out_path=str(target[3]))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tb_h_file_creation(target, source, env):\n\n    files = [str(x) for x in source]\n\n    try:\n        desc = TBDescriptor(files)\n    except pyparsing.ParseException as e:\n        raise BuildError(\"Could not parse tilebus file\", parsing_exception=e)\n\n    block = desc.get_block(config_only=True)\n    block.render_template(block.CommandHeaderTemplate, out_path=str(target[0]))\n    block.render_template(block.ConfigHeaderTemplate, out_path=str(target[1]))", "response": "Compile tilebus file into only. h files corresponding to config variables for inclusion in a library"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a linker command file for patching an application checksum into a firmware image", "response": "def checksum_creation_action(target, source, env):\n    \"\"\"Create a linker command file for patching an application checksum into a firmware image\"\"\"\n\n    # Important Notes:\n    # There are apparently many ways to calculate a CRC-32 checksum, we use the following options\n    # Initial seed value prepended to the input: 0xFFFFFFFF\n    # Whether the input is fed into the shift register least-significant bit or most-significant bit first: LSB\n    # Whether each data word is inverted: No\n    # Whether the final CRC value is inverted: No\n    # *These settings must agree between the executive and this function*\n\n    import crcmod\n    crc32_func = crcmod.mkCrcFun(0x104C11DB7, initCrc=0xFFFFFFFF, rev=False, xorOut=0)\n\n    with open(str(source[0]), 'rb') as f:\n        data = f.read()\n\n        # Ignore the last four bytes of the file since that is where the checksum will go\n        data = data[:-4]\n\n        # Make sure the magic number is correct so that we're dealing with an actual firmware image\n        magicbin = data[-4:]\n        magic, = struct.unpack('<L', magicbin)\n\n        if magic != 0xBAADDAAD:\n            raise BuildError(\"Attempting to patch a file that is not a CDB binary or has the wrong size\", reason=\"invalid magic number found\", actual_magic=magic, desired_magic=0xBAADDAAD)\n\n        # Calculate CRC32 in the same way as its done in the target microcontroller\n        checksum = crc32_func(data) & 0xFFFFFFFF\n\n    with open(str(target[0]), 'w') as f:\n        # hex strings end with L on windows and possibly some other systems\n        checkhex = hex(checksum)\n        if checkhex[-1] == 'L':\n            checkhex = checkhex[:-1]\n\n        f.write(\"--defsym=__image_checksum=%s\\n\" % checkhex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an argument file containing - I and - D arguments to gcc.", "response": "def create_arg_file(target, source, env):\n    \"\"\"Create an argument file containing -I and -D arguments to gcc.\n\n    This file will be passed to gcc using @<path>.\n    \"\"\"\n\n    output_name = str(target[0])\n\n    with open(output_name, \"w\") as outfile:\n        for define in env.get('CPPDEFINES', []):\n            outfile.write(define + '\\n')\n\n        include_folders = target[0].RDirs(tuple(env.get('CPPPATH', [])))\n        include_folders.append('.')\n\n        for include_folder in include_folders:\n            include_folder = str(include_folder)\n\n            if not include_folder.startswith('build'):\n                include_folder = os.path.join('firmware', 'src', include_folder)\n\n            outfile.write('\"-I{}\"\\n'.format(include_folder.replace('\\\\', '\\\\\\\\')))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining all hex files into a singular executable file.", "response": "def merge_hex_executables(target, source, env):\n    \"\"\"Combine all hex files into a singular executable file.\"\"\"\n    output_name = str(target[0])\n\n    hex_final = IntelHex()\n    for image in source:\n        file = str(image)\n        root, ext = os.path.splitext(file)\n        file_format = ext[1:]\n        if file_format == 'elf':\n            file = root + '.hex'\n        hex_data = IntelHex(file)\n\n        # merge will throw errors on mismatched Start Segment Addresses, which we don't need\n        # See <https://stackoverflow.com/questions/26295776/what-are-the-intel-hex-records-type-03-or-05-doing-in-ihex-program-for-arm>\n        hex_data.start_addr = None\n        hex_final.merge(hex_data, overlap='error')\n\n    with open(output_name, 'w') as outfile:\n        hex_final.write_hex_file(outfile)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure that the input file is in hex format.", "response": "def ensure_image_is_hex(input_path):\n    \"\"\"Return a path to a hex version of a firmware image.\n\n    If the input file is already in hex format then input_path\n    is returned and nothing is done.  If it is not in hex format\n    then an SCons action is added to convert it to hex and the\n    target output file path is returned.\n\n    A cache is kept so that each file is only converted once.\n\n    Args:\n        input_path (str): A path to a firmware image.\n\n    Returns:\n        str: The path to a hex version of input_path, this may\n            be equal to input_path if it is already in hex format.\n    \"\"\"\n\n    family = utilities.get_family('module_settings.json')\n    target = family.platform_independent_target()\n    build_dir = target.build_dirs()['build']\n\n    if platform.system() == 'Windows':\n        env = Environment(tools=['mingw'], ENV=os.environ)\n    else:\n        env = Environment(tools=['default'], ENV=os.environ)\n\n    input_path = str(input_path)\n    image_name = os.path.basename(input_path)\n\n    root, ext = os.path.splitext(image_name)\n    if len(ext) == 0:\n        raise BuildError(\"Unknown file format or missing file extension in ensure_image_is_hex\", file_name=input_path)\n\n    file_format = ext[1:]\n\n    if file_format == 'hex':\n        return input_path\n\n    if file_format == 'elf':\n        new_file = os.path.join(build_dir, root + '.hex')\n\n        if new_file not in CONVERTED_HEX_FILES:\n            env.Command(new_file, input_path, action=Action(\"arm-none-eabi-objcopy -O ihex $SOURCE $TARGET\",\n                                                            \"Creating intel hex file from: $SOURCE\"))\n            CONVERTED_HEX_FILES.add(new_file)\n\n        return new_file\n\n    raise BuildError(\"Unknown file format extension in ensure_image_is_hex\",\n                     file_name=input_path, extension=file_format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dispatch_rpc(self, address, rpc_id, arg_payload):\n\n        if self.emulator.is_tile_busy(address):\n            self._track_change('device.rpc_busy_response', (address, rpc_id, arg_payload, None, None), formatter=format_rpc)\n            raise BusyRPCResponse()\n\n        try:\n            # Send the RPC immediately and wait for the response\n            resp = super(EmulatedDevice, self).call_rpc(address, rpc_id, arg_payload)\n            self._track_change('device.rpc_sent', (address, rpc_id, arg_payload, resp, None), formatter=format_rpc)\n\n            return resp\n        except AsynchronousRPCResponse:\n            self._track_change('device.rpc_started', (address, rpc_id, arg_payload, None, None), formatter=format_rpc)\n            raise\n        except Exception as exc:\n            self._track_change('device.rpc_exception', (address, rpc_id, arg_payload, None, exc), formatter=format_rpc)\n            raise", "response": "Dispatches an RPC to the device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfinish an asynchronous RPC.", "response": "def finish_async_rpc(self, address, rpc_id, response):\n        \"\"\"Finish a previous asynchronous RPC.\n\n        This method should be called by a peripheral tile that previously\n        had an RPC called on it and chose to response asynchronously by\n        raising ``AsynchronousRPCResponse`` in the RPC handler itself.\n\n        The response passed to this function will be returned to the caller\n        as if the RPC had returned it immediately.\n\n        The rpc response will be sent in the RPC thread.  By default this\n        method will block until the response is finished.  If you don't\n        want to block, you can pass sync=False\n\n        Args:\n            address (int): The tile address the RPC was called on.\n            rpc_id (int): The ID of the RPC that was called.\n            response (bytes): The bytes that should be returned to\n                the caller of the RPC.\n        \"\"\"\n\n        try:\n            self.emulator.finish_async_rpc(address, rpc_id, response)\n            self._track_change('device.rpc_finished', (address, rpc_id, None, response, None), formatter=format_rpc)\n        except Exception as exc:\n            self._track_change('device.rpc_exception', (address, rpc_id, None, response, exc), formatter=format_rpc)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts this emulated device.", "response": "def start(self, channel=None):\n        \"\"\"Start this emulated device.\n\n        This triggers the controller to call start on all peripheral tiles in\n        the device to make sure they start after the controller does and then\n        it waits on each one to make sure they have finished initializing\n        before returning.\n\n        Args:\n            channel (IOTilePushChannel): the channel with a stream and trace\n                routine for streaming and tracing data through a VirtualInterface\n        \"\"\"\n\n        super(EmulatedDevice, self).start(channel)\n        self.emulator.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump_state(self):\n\n        state = {}\n\n        state['tile_states'] = {}\n\n        for address, tile in self._tiles.items():\n            state['tile_states'][address] = tile.dump_state()\n\n        return state", "response": "Dump the current state of this emulated object as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rpc(self, address, rpc_id, *args, **kwargs):\n\n        if isinstance(rpc_id, RPCDeclaration):\n            arg_format = rpc_id.arg_format\n            resp_format = rpc_id.resp_format\n            rpc_id = rpc_id.rpc_id\n        else:\n            arg_format = kwargs.get('arg_format', None)\n            resp_format = kwargs.get('resp_format', None)\n\n        arg_payload = b''\n\n        if arg_format is not None:\n            arg_payload = pack_rpc_payload(arg_format, args)\n\n        self._logger.debug(\"Sending rpc to %d:%04X, payload=%s\", address, rpc_id, args)\n\n        resp_payload = self.call_rpc(address, rpc_id, arg_payload)\n        if resp_format is None:\n            return []\n\n        resp = unpack_rpc_payload(resp_format, resp_payload)\n        return resp", "response": "Dispatch an RPC to the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling an RPC by its address and ID. This will send the RPC to the background rpc dispatch thread and synchronously wait for the response. Args: address (int): The address of the mock tile this RPC is for rpc_id (int): The number of the RPC payload (bytes): A byte string of payload parameters up to 20 bytes Returns: bytes: The response payload from the RPC", "response": "def call_rpc(self, address, rpc_id, payload=b\"\"):\n        \"\"\"Call an RPC by its address and ID.\n\n        This will send the RPC to the background rpc dispatch thread and\n        synchronously wait for the response.\n\n        Args:\n            address (int): The address of the mock tile this RPC is for\n            rpc_id (int): The number of the RPC\n            payload (bytes): A byte string of payload parameters up to 20 bytes\n\n        Returns:\n            bytes: The response payload from the RPC\n        \"\"\"\n\n        return self.emulator.call_rpc_external(address, rpc_id, payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trace_sync(self, data, timeout=5.0):\n\n        done = AwaitableResponse()\n        self.trace(data, callback=done.set_result)\n        return done.wait(timeout)", "response": "Send tracing data and wait for it to finish."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stream_sync(self, report, timeout=120.0):\n\n        done = AwaitableResponse()\n        self.stream(report, callback=done.set_result)\n        return done.wait(timeout)", "response": "Send a report and wait for it to finish."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef synchronize_task(self, func, *args, **kwargs):\n\n        async def _runner():\n            return func(*args, **kwargs)\n\n        return self.emulator.run_task_external(_runner())", "response": "This method will run a callable in the rpc thread and wait for it to finish."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore_state(self, state):\n\n        tile_states = state.get('tile_states', {})\n\n        for address, tile_state in tile_states.items():\n            address = int(address)\n            tile = self._tiles.get(address)\n            if tile is None:\n                raise DataError(\"Invalid dumped state, tile does not exist at address %d\" % address, address=address)\n\n            tile.restore_state(tile_state)", "response": "Restore the current state of this emulated device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_metascenario(self, scenario_list):\n\n        for scenario in scenario_list:\n            name = scenario.get('name')\n            if name is None:\n                raise DataError(\"Scenario in scenario list is missing a name parameter\", scenario=scenario)\n\n            tile_address = scenario.get('tile')\n            args = scenario.get('args', {})\n\n            dest = self\n            if tile_address is not None:\n                dest = self._tiles.get(tile_address)\n\n                if dest is None:\n                    raise DataError(\"Attempted to load a scenario into a tile address that does not exist\", address=tile_address, valid_addresses=list(self._tiles))\n\n            dest.load_scenario(name, **args)", "response": "Load one or more scenarios into a device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding Builders and construction variables for lib to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for lib to an Environment.\"\"\"\n    SCons.Tool.createStaticLibBuilder(env)\n\n    # Set-up ms tools paths\n    msvc_setup_env_once(env)\n\n    env['AR']          = 'lib'\n    env['ARFLAGS']     = SCons.Util.CLVar('/nologo')\n    env['ARCOM']       = \"${TEMPFILE('$AR $ARFLAGS /OUT:$TARGET $SOURCES','$ARCOMSTR')}\"\n    env['LIBPREFIX']   = ''\n    env['LIBSUFFIX']   = '.lib'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling an RPC by its ID.", "response": "def call_rpc(self, rpc_id, payload=bytes()):\n        \"\"\"Call an RPC by its ID.\n\n        Args:\n            rpc_id (int): The number of the RPC\n            payload (bytes): A byte string of payload parameters up to 20 bytes\n\n        Returns:\n            str: The response payload from the RPC\n        \"\"\"\n\n        # If we define the RPC locally, call that one.  We use this for reporting\n        # our status\n        if super(ServiceDelegateTile, self).has_rpc(rpc_id):\n            return super(ServiceDelegateTile, self).call_rpc(rpc_id, payload)\n\n        async def _awaitable_wrapper():\n\n            # FIXME: We set the timeout here to a very large number since we don't\n            # know what an appropriate timeout is and don't want to restrict the\n            # run time of RPCs that could be long running.  The caller of the RPC\n            # through the tile will know what an appropriate timeout is for the\n            # RPC that they are trying to call.\n            resp = await self._client.send_rpc(self._service, rpc_id, payload, timeout=120.0)\n            result = resp['result']\n\n            if result == 'success':\n                return resp['response']\n            elif result == 'service_not_found':\n                raise TileNotFoundError(\"Could not find service by name\", name=self._service)\n            elif result == 'rpc_not_found':\n                raise RPCNotFoundError(\"Could not find RPC on service\", name=self._service, rpc_id=rpc_id)\n            elif result == 'invalid_arguments':\n                raise RPCInvalidArgumentsError(\"Invalid arguments to RPC\", name=self._service, rpc_id=rpc_id)\n            elif result == 'invalid_response':\n                raise RPCInvalidReturnValueError(\"Invalid response from RPC\", name=self._service, rpc_id=rpc_id)\n            elif result == 'execution_exception':\n                raise InternalError(\"Exception raised during processing RPC\", name=self._service, rpc_id=rpc_id)\n            else:\n                raise InternalError(\"Unknown response received from delegated RPC\", name=self._service, rpc_id=rpc_id, result=result)\n\n        return _awaitable_wrapper()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the corresponding output or storage stream for an important system input.", "response": "def associated_stream(self):\n        \"\"\"Return the corresponding output or storage stream for an important system input.\n\n        Certain system inputs are designed as important and automatically\n        copied to output streams without requiring any manual interaction.\n\n        This method returns the corresponding stream for an important system\n        input.  It will raise an InternalError unlesss the self.important\n        property is True.\n\n        Returns:\n            DataStream: The corresponding output or storage stream.\n\n        Raises:\n            InternalError: If this stream is not marked as an important system input.\n        \"\"\"\n\n        if not self.important:\n            raise InternalError(\"You may only call autocopied_stream on when DataStream.important is True\", stream=self)\n\n        if self.stream_id >= DataStream.ImportantSystemStorageStart:\n            stream_type = DataStream.BufferedType\n        else:\n            stream_type = DataStream.OutputType\n\n        return DataStream(stream_type, self.stream_id, True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a DataStream from a string representation.", "response": "def FromString(cls, string_rep):\n        \"\"\"Create a DataStream from a string representation.\n\n        The format for stream designators when encoded as strings is:\n        [system] (buffered|unbuffered|constant|input|count|output) <integer>\n\n        Args:\n            string_rep (str): The string representation to turn into a\n                DataStream\n        \"\"\"\n\n        rep = str(string_rep)\n\n        parts = rep.split()\n        if len(parts) > 3:\n            raise ArgumentError(\"Too many whitespace separated parts of stream designator\", input_string=string_rep)\n        elif len(parts) == 3 and parts[0] != u'system':\n            raise ArgumentError(\"Too many whitespace separated parts of stream designator\", input_string=string_rep)\n        elif len(parts) < 2:\n            raise ArgumentError(\"Too few components in stream designator\", input_string=string_rep)\n\n        # Now actually parse the string\n        if len(parts) == 3:\n            system = True\n            stream_type = parts[1]\n            stream_id = parts[2]\n        else:\n            system = False\n            stream_type = parts[0]\n            stream_id = parts[1]\n\n        try:\n            stream_id = int(stream_id, 0)\n        except ValueError as exc:\n            raise ArgumentError(\"Could not convert stream id to integer\", error_string=str(exc), stream_id=stream_id)\n\n        try:\n            stream_type = cls.StringToType[stream_type]\n        except KeyError:\n            raise ArgumentError(\"Invalid stream type given\", stream_type=stream_type, known_types=cls.StringToType.keys())\n\n        return DataStream(stream_type, stream_id, system)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FromEncoded(self, encoded):\n\n        stream_type = (encoded >> 12) & 0b1111\n        stream_system = bool(encoded & (1 << 11))\n        stream_id = (encoded & ((1 << 11) - 1))\n\n        return DataStream(stream_type, stream_id, stream_system)", "response": "Create a DataStream object from an encoded 16 - bit unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts this selector to a DataStream.", "response": "def as_stream(self):\n        \"\"\"Convert this selector to a DataStream.\n\n        This function will only work if this is a singular selector that\n        matches exactly one DataStream.\n        \"\"\"\n\n        if not self.singular:\n            raise ArgumentError(\"Attempted to convert a non-singular selector to a data stream, it matches multiple\", selector=self)\n\n        return DataStream(self.match_type, self.match_id, self.match_spec == DataStreamSelector.MatchSystemOnly)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FromStream(cls, stream):\n\n        if stream.system:\n            specifier = DataStreamSelector.MatchSystemOnly\n        else:\n            specifier = DataStreamSelector.MatchUserOnly\n\n        return DataStreamSelector(stream.stream_type, stream.stream_id, specifier)", "response": "Create a DataStreamSelector from a DataStream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FromEncoded(cls, encoded):\n\n        match_spec = encoded & ((1 << 11) | (1 << 15))\n        match_type = (encoded & (0b111 << 12)) >> 12\n        match_id = encoded & ((1 << 11) - 1)\n\n        if match_spec not in cls.SpecifierEncodingMap:\n            raise ArgumentError(\"Unknown encoded match specifier\", match_spec=match_spec, known_specifiers=cls.SpecifierEncodingMap.keys())\n\n        spec_name = cls.SpecifierEncodingMap[match_spec]\n\n        # Handle wildcard matches\n        if match_id == cls.MatchAllCode:\n            match_id = None\n\n        return DataStreamSelector(match_type, match_id, spec_name)", "response": "Create a DataStreamSelector from an encoded 16 - bit value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a DataStreamSelector from a string representation.", "response": "def FromString(cls, string_rep):\n        \"\"\"Create a DataStreamSelector from a string.\n\n        The format of the string should either be:\n\n        all <type>\n        OR\n        <type> <id>\n\n        Where type is [system] <stream type>, with <stream type>\n        defined as in DataStream\n\n        Args:\n            rep (str): The string representation to convert to a DataStreamSelector\n        \"\"\"\n\n        rep = str(string_rep)\n\n        rep = rep.replace(u'node', '')\n        rep = rep.replace(u'nodes', '')\n\n        if rep.startswith(u'all'):\n            parts = rep.split()\n\n            spec_string = u''\n\n            if len(parts) == 3:\n                spec_string = parts[1]\n                stream_type = parts[2]\n            elif len(parts) == 2:\n                stream_type = parts[1]\n            else:\n                raise ArgumentError(\"Invalid wildcard stream selector\", string_rep=string_rep)\n\n            try:\n                # Remove pluralization that can come with e.g. 'all system outputs'\n                if stream_type.endswith(u's'):\n                    stream_type = stream_type[:-1]\n\n                stream_type = DataStream.StringToType[stream_type]\n            except KeyError:\n                raise ArgumentError(\"Invalid stream type given\", stream_type=stream_type, known_types=DataStream.StringToType.keys())\n\n            stream_spec = DataStreamSelector.SpecifierNames.get(spec_string, None)\n            if stream_spec is None:\n                raise ArgumentError(\"Invalid stream specifier given (should be system, user, combined or blank)\", string_rep=string_rep, spec_string=spec_string)\n\n            return DataStreamSelector(stream_type, None, stream_spec)\n\n        # If we're not matching a wildcard stream type, then the match is exactly\n        # the same as a DataStream identifier, so use that to match it.\n\n        stream = DataStream.FromString(rep)\n        return DataStreamSelector.FromStream(stream)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if this selector matches the given stream", "response": "def matches(self, stream):\n        \"\"\"Check if this selector matches the given stream\n\n        Args:\n            stream (DataStream): The stream to check\n\n        Returns:\n            bool: True if this selector matches the stream\n        \"\"\"\n\n        if self.match_type != stream.stream_type:\n            return False\n\n        if self.match_id is not None:\n            return self.match_id == stream.stream_id\n\n        if self.match_spec == DataStreamSelector.MatchUserOnly:\n            return not stream.system\n        elif self.match_spec == DataStreamSelector.MatchSystemOnly:\n            return stream.system\n        elif self.match_spec == DataStreamSelector.MatchUserAndBreaks:\n            return (not stream.system) or (stream.system and (stream.stream_id in DataStream.KnownBreakStreams))\n\n        # The other case is that match_spec is MatchCombined, which matches everything\n        # regardless of system of user flag\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self):\n\n        match_id = self.match_id\n        if match_id is None:\n            match_id = (1 << 11) - 1\n\n        return (self.match_type << 12) | DataStreamSelector.SpecifierEncodings[self.match_spec] | match_id", "response": "Encode this stream as a packed 16 - bit unsigned integer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef EnumVariable(key, help, default, allowed_values, map={}, ignorecase=0):\n\n    help = '%s (%s)' % (help, '|'.join(allowed_values))\n    # define validator\n    if ignorecase >= 1:\n        validator = lambda key, val, env: \\\n                    _validator(key, val.lower(), env, allowed_values)\n    else:\n        validator = lambda key, val, env: \\\n                    _validator(key, val, env, allowed_values)\n    # define converter\n    if ignorecase == 2:\n        converter = lambda val: map.get(val.lower(), val).lower()\n    elif ignorecase == 1:\n        converter = lambda val: map.get(val.lower(), val)\n    else:\n        converter = lambda val: map.get(val, val)\n    return (key, help, default, validator, converter)", "response": "This function returns a key help default validator and converter for the option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Builders and construction variables for m4 to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for m4 to an Environment.\"\"\"\n    M4Action = SCons.Action.Action('$M4COM', '$M4COMSTR')\n    bld = SCons.Builder.Builder(action = M4Action, src_suffix = '.m4')\n\n    env['BUILDERS']['M4'] = bld\n\n    # .m4 files might include other files, and it would be pretty hard\n    # to write a scanner for it, so let's just cd to the dir of the m4\n    # file and run from there.\n    # The src_suffix setup is like so: file.c.m4 -> file.c,\n    # file.cpp.m4 -> file.cpp etc.\n    env['M4']      = 'm4'\n    env['M4FLAGS'] = SCons.Util.CLVar('-E')\n    env['M4COM']   = 'cd ${SOURCE.rsrcdir} && $M4 $M4FLAGS < ${SOURCE.file} > ${TARGET.abspath}'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def future_command(self, cmd):\n\n        if self._asyncio_cmd_lock is None:\n            raise HardwareError(\"Cannot use future_command because no event loop attached\")\n\n        async with self._asyncio_cmd_lock:\n            return await self._future_command_unlocked(cmd)", "response": "Run command as a coroutine and return a future."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _future_command_unlocked(self, cmd):\n\n        future = self._loop.create_future()\n        asyncio_loop = self._loop.get_loop()\n\n        def _done_callback(result):\n            retval = result['return_value']\n\n            if not result['result']:\n                future.set_exception(HardwareError(\"Error executing synchronous command\",\n                                                   command=cmd, return_value=retval))\n            else:\n                future.set_result(retval)\n\n        callback = functools.partial(asyncio_loop.call_soon_threadsafe, _done_callback)\n        self._commands.put((cmd, callback, True, None))\n\n        return future", "response": "Run command as a coroutine and return a future."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Builders and construction variables for LaTeX to an Environment.", "response": "def generate(env):\n    \"\"\"Add Builders and construction variables for LaTeX to an Environment.\"\"\"\n\n    env.AppendUnique(LATEXSUFFIXES=SCons.Tool.LaTeXSuffixes)\n\n    from . import dvi\n    dvi.generate(env)\n\n    from . import pdf\n    pdf.generate(env)\n\n    bld = env['BUILDERS']['DVI']\n    bld.add_action('.ltx', LaTeXAuxAction)\n    bld.add_action('.latex', LaTeXAuxAction)\n    bld.add_emitter('.ltx', SCons.Tool.tex.tex_eps_emitter)\n    bld.add_emitter('.latex', SCons.Tool.tex.tex_eps_emitter)\n\n    SCons.Tool.tex.generate_common(env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes the facility and priority.", "response": "def encode_priority(self, facility, priority):\n        \"\"\"\n        Encode the facility and priority. You can pass in strings or\n        integers - if strings are passed, the facility_names and\n        priority_names mapping dictionaries are used to convert them to\n        integers.\n        \"\"\"\n        return (facility << 3) | self.priority_map.get(priority, self.LOG_WARNING)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nemitting a record to the syslog server.", "response": "def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        The record is formatted, and then sent to the syslog server. If\n        exception information is present, it is NOT sent to the server.\n        \"\"\"\n        try:\n            syslog_msg = self.build_msg(record)\n            self.transport.transmit(syslog_msg)\n        except Exception:\n            self.handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self, msg=None, kwargs=None):\n        hostname = kwargs.pop('hostname', None)\n        appname = kwargs.pop('appname', None)\n        procid = kwargs.pop('procid', None)\n        msgid = kwargs.pop('msgid', None)\n        structured_data = kwargs.pop('sd', None)\n\n        if structured_data is None:\n            structured_data = kwargs.pop('structured_data', None)\n\n        extra = self.extra.copy()\n        extra.update(kwargs.get('extra', {}))\n        kwargs['extra'] = extra\n\n        if hostname:\n            kwargs['extra']['hostname'] = hostname\n        if appname:\n            kwargs['extra']['appname'] = appname\n        if procid:\n            kwargs['extra']['procid'] = procid\n        if msgid:\n            kwargs['extra']['msgid'] = msgid\n        if structured_data:\n            kwargs['extra']['structured_data'] = structured_data\n\n        return msg, kwargs", "response": "Process the logging message and keyword arguments passed in to\n        and return the message and keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction for finding external location of the bioio module", "response": "def sonTraceRootPath():\n    \"\"\"\n    function for finding external location\n    \"\"\"\n    import sonLib.bioio\n    i = os.path.abspath(sonLib.bioio.__file__)\n    return os.path.split(os.path.split(os.path.split(i)[0])[0])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes a linear regression starting at zero computes a linear regression starting at zero", "response": "def linOriginRegression(points):\n    \"\"\"\n    computes a linear regression starting at zero\n    \"\"\"\n    j = sum([ i[0] for i in points ])\n    k = sum([ i[1] for i in points ])\n    if j != 0:\n        return k/j, j, k\n    return 1, j, k"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(i, j, tolerance):\n    return i <= j + tolerance and i >= j - tolerance", "response": "check two float values are within a bound of one another"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering alignments to be non - overlapping.", "response": "def filterOverlappingAlignments(alignments):\n    \"\"\"Filter alignments to be non-overlapping.\n    \"\"\"\n    l = []\n    alignments = alignments[:]\n    sortAlignments(alignments)\n    alignments.reverse()\n    for pA1 in alignments:\n        for pA2 in l:\n            if pA1.contig1 == pA2.contig1 and getPositiveCoordinateRangeOverlap(pA1.start1+1, pA1.end1, pA2.start1+1, pA2.end1) is not None: #One offset, inclusive coordinates\n                break\n            if pA1.contig2 == pA2.contig2 and getPositiveCoordinateRangeOverlap(pA1.start2+1, pA1.end2, pA2.start2+1, pA2.end2) is not None: #One offset, inclusive coordinates\n                break\n            if pA1.contig2 == pA2.contig1 and getPositiveCoordinateRangeOverlap(pA1.start2+1, pA1.end2, pA2.start1+1, pA2.end1) is not None: #One offset, inclusive coordinates\n                break\n            if pA1.contig1 == pA2.contig2 and getPositiveCoordinateRangeOverlap(pA1.start1+1, pA1.end1, pA2.start2+1, pA2.end2) is not None: #One offset, inclusive coordinates\n                break\n        else:\n            l.append(pA1)\n    l.reverse()\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget mid - order depth first tree numbers", "response": "def binaryTree_depthFirstNumbers(binaryTree, labelTree=True, dontStopAtID=True):\n    \"\"\"\n    get mid-order depth first tree numbers\n    \"\"\"\n    traversalIDs = {}\n    def traverse(binaryTree, mid=0, leafNo=0):\n        if binaryTree.internal and (dontStopAtID or binaryTree.iD is None):\n            midStart = mid\n            j, leafNo = traverse(binaryTree.left, mid, leafNo)\n            mid = j\n            j, leafNo = traverse(binaryTree.right, j+1, leafNo)\n            traversalIDs[binaryTree] = TraversalID(midStart, mid, j)\n            return j, leafNo\n        traversalID = TraversalID(mid, mid, mid+1)\n        traversalID.leafNo = leafNo\n        #thus nodes must be unique\n        traversalIDs[binaryTree] = traversalID\n        return mid+1, leafNo+1\n    traverse(binaryTree)\n    if labelTree:\n        for binaryTree in traversalIDs.keys():\n            binaryTree.traversalID = traversalIDs[binaryTree]\n    return traversalIDs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a random binary tree.", "response": "def makeRandomBinaryTree(leafNodeNumber=None):\n    \"\"\"Creates a random binary tree.\n    \"\"\"\n    while True:\n        nodeNo = [-1]\n        def fn():\n            nodeNo[0] += 1\n            if random.random() > 0.6:\n                i = str(nodeNo[0])\n                return BinaryTree(0.00001 + random.random()*0.8, True, fn(), fn(), i)\n            else:\n                return BinaryTree(0.00001 + random.random()*0.8, False, None, None, str(nodeNo[0]))\n        tree = fn()\n        def fn2(tree):\n            if tree.internal:\n                return fn2(tree.left) + fn2(tree.right)\n            return 1\n        if leafNodeNumber is None or fn2(tree) == leafNodeNumber:\n            return tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets random binary tree node.", "response": "def getRandomBinaryTreeLeafNode(binaryTree):\n    \"\"\"Get random binary tree node.\n    \"\"\"\n    if binaryTree.internal == True:\n        if random.random() > 0.5:\n            return getRandomBinaryTreeLeafNode(binaryTree.left)\n        else:\n            return getRandomBinaryTreeLeafNode(binaryTree.right)\n    else:\n        return binaryTree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming wV by given substitution matrix wV by given distance", "response": "def transformByDistance(wV, subModel, alphabetSize=4):\n    \"\"\"\n    transform wV by given substitution matrix\n    \"\"\"\n    nc = [0.0]*alphabetSize\n    for i in xrange(0, alphabetSize):\n        j = wV[i]\n        k = subModel[i]\n        for l in xrange(0, alphabetSize):\n            nc[l] += j * k[l]\n    return nc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normaliseWV(wV, normFac=1.0):\n    f = sum(wV) / normFac\n    return [ i/f for i in wV ]", "response": "normalise the probs of a single word in a list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nannotating a tree in an external array using the given function", "response": "def annotateTree(bT, fn):\n    \"\"\"\n    annotate a tree in an external array using the given function\n    \"\"\"\n    l = [None]*bT.traversalID.midEnd\n    def fn2(bT):\n        l[bT.traversalID.mid] = fn(bT)\n        if bT.internal:\n            fn2(bT.left)\n            fn2(bT.right)\n    fn2(bT)\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remodelTreeRemovingRoot(root, node):\n    import bioio\n    assert root.traversalID.mid != node\n    hash = {}\n    def fn(bT):\n        if bT.traversalID.mid == node:\n            assert bT.internal == False\n            return [ bT ]\n        elif bT.internal:\n            i = fn(bT.left)\n            if i is None:\n                i = fn(bT.right)\n            if i is not None:\n                hash[i[-1]]= bT\n                i.append(bT)\n            return  i\n        return None\n    l = fn(root)\n    def fn2(i, j):\n        if i.left == j:\n            return i.right\n        assert i.right == j\n        return i.left\n    def fn3(bT):\n        if hash[bT] == root:\n            s = '(' + bioio.printBinaryTree(fn2(hash[bT], bT), bT, True)[:-1] + ')'\n        else:\n            s = '(' + bioio.printBinaryTree(fn2(hash[bT], bT), bT, True)[:-1] + ',' + fn3(hash[bT]) + ')'\n        return s + \":\" + str(bT.distance)\n    s = fn3(l[0]) + ';'\n    t = bioio.newickTreeParser(s)\n    return t", "response": "remodelTreeRemoves root from the tree"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef moveRoot(root, branch):\n    import bioio\n    if root.traversalID.mid == branch:\n        return bioio.newickTreeParser(bioio.printBinaryTree(root, True))\n    def fn2(tree, seq):\n        if seq is not None:\n            return '(' + bioio.printBinaryTree(tree, True)[:-1] + ',' + seq + ')'\n        return bioio.printBinaryTree(tree, True)[:-1]\n    def fn(tree, seq):\n        if tree.traversalID.mid == branch:\n            i = tree.distance\n            tree.distance /= 2\n            seq = '(' + bioio.printBinaryTree(tree, True)[:-1] + ',(' + seq + ('):%s' % tree.distance) + ');'\n            tree.distance = i\n            return seq\n        if tree.internal:\n            if branch < tree.traversalID.mid:\n                seq = fn2(tree.right, seq)\n                return fn(tree.left, seq)\n            else:\n                assert branch > tree.traversalID.mid\n                seq = fn2(tree.left, seq)\n                return fn(tree.right, seq)\n        else:\n            return bioio.printBinaryTree(tree, True)[:-1]\n    s = fn(root, None)\n    return bioio.newickTreeParser(s)", "response": "Moves the root to the mid point along the given branch"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to check that all ids in a species tree match the gene tree", "response": "def checkGeneTreeMatchesSpeciesTree(speciesTree, geneTree, processID):\n    \"\"\"\n    Function to check ids in gene tree all match nodes in species tree\n    \"\"\"\n    def fn(tree, l):\n        if tree.internal:\n            fn(tree.left, l)\n            fn(tree.right, l)\n        else:\n            l.append(processID(tree.iD))\n    l = []\n    fn(speciesTree, l)\n    l2 = []\n    fn(geneTree, l2)\n    for i in l2:\n        #print \"node\", i, l\n        assert i in l"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreconcile the given species tree and the given gene tree and report the number of needed duplications and losses by conciling trees.", "response": "def calculateDupsAndLossesByReconcilingTrees(speciesTree, geneTree, processID):\n    \"\"\"\n    Reconciles the given gene tree with the species tree and\n    report the number of needed duplications and losses\n    \"\"\"  \n    checkGeneTreeMatchesSpeciesTree(speciesTree, geneTree, processID)   \n    def fn(tree, m):  \n        if tree.internal:\n            nodes = fn(tree.left, m)\n            nodes = nodes.union(fn(tree.right, m))\n            m[tree.traversalID.mid] = nodes\n        else:\n            m[tree.traversalID.mid] = set((processID(tree.iD),))\n        return m[tree.traversalID.mid]\n    a = {}\n    fn(speciesTree, a)\n    b = {}\n    fn(geneTree, b)\n    def fn2(nodes, speciesTree):\n        assert nodes.issubset(a[speciesTree.traversalID.mid])\n        if speciesTree.internal:\n            if nodes.issubset(a[speciesTree.left.traversalID.mid]):\n                return fn2(nodes, speciesTree.left)\n            if nodes.issubset(a[speciesTree.right.traversalID.mid]):\n                return fn2(nodes, speciesTree.right)\n        return speciesTree.traversalID.mid\n    for iD in b.keys():\n        nodes = b[iD]\n        b[iD] = fn2(nodes, speciesTree)\n    dups = []\n    def fn3(geneTree):\n        if geneTree.internal:\n            i = b[geneTree.traversalID.mid]\n            if b[geneTree.left.traversalID.mid] == i or b[geneTree.right.traversalID.mid] == i:\n                dups.append(geneTree.traversalID.mid)\n            fn3(geneTree.left)\n            fn3(geneTree.right)\n    fn3(geneTree)\n    lossMap = {}\n    def fn4(speciesTree):\n        nodes = [(speciesTree.traversalID.mid, -1)]\n        lossMap[(speciesTree.traversalID.mid, speciesTree.traversalID.mid)] = 0\n        if speciesTree.internal:\n            for node, losses in fn4(speciesTree.left) + fn4(speciesTree.right):\n                lossMap[(speciesTree.traversalID.mid, node)] = losses+1\n                nodes.append((node, losses+1))\n        return nodes\n    for node, losses in fn4(speciesTree):\n        lossMap[(sys.maxint, node)] = losses+1\n    losses = [0]\n    def fn5(geneTree, ancestor):\n        if geneTree.internal:\n            i = b[geneTree.traversalID.mid]\n            if geneTree.traversalID.mid in dups:\n                losses[0] += lossMap[(ancestor, b[geneTree.left.traversalID.mid])]\n                losses[0] += lossMap[(ancestor, b[geneTree.right.traversalID.mid])]\n            else:\n                losses[0] += lossMap[(i, b[geneTree.left.traversalID.mid])]\n                losses[0] += lossMap[(i, b[geneTree.right.traversalID.mid])]\n            fn5(geneTree.left, i)\n            fn5(geneTree.right, i)\n    ancestorHolder = [None]\n    def fn6(speciesTree, ancestor, node):\n        if speciesTree.traversalID.mid == node:\n            ancestorHolder[0] = ancestor\n        if speciesTree.internal:\n            fn6(speciesTree.left, speciesTree.traversalID.mid, node)\n            fn6(speciesTree.right, speciesTree.traversalID.mid, node)\n    ancestor = fn6(speciesTree, sys.maxint, b[geneTree.traversalID.mid])\n    assert ancestorHolder[0] is not None\n    fn5(geneTree, ancestorHolder[0])\n    return len(dups), losses[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the probability of a root of a gene tree.", "response": "def calculateProbableRootOfGeneTree(speciesTree, geneTree, processID=lambda x : x):\n    \"\"\"\n    Goes through each root possible branch making it the root. \n    Returns tree that requires the minimum number of duplications.\n    \"\"\"\n    #get all rooted trees\n    #run dup calc on each tree\n    #return tree with fewest number of dups\n    if geneTree.traversalID.midEnd <= 3:\n        return (0, 0, geneTree)\n    checkGeneTreeMatchesSpeciesTree(speciesTree, geneTree, processID)\n    l = []\n    def fn(tree):\n        if tree.traversalID.mid != geneTree.left.traversalID.mid and tree.traversalID.mid != geneTree.right.traversalID.mid:\n            newGeneTree = moveRoot(geneTree, tree.traversalID.mid)\n            binaryTree_depthFirstNumbers(newGeneTree)\n            dupCount, lossCount = calculateDupsAndLossesByReconcilingTrees(speciesTree, newGeneTree, processID)\n            l.append((dupCount, lossCount, newGeneTree))\n        if tree.internal:\n            fn(tree.left)\n            fn(tree.right)\n    fn(geneTree)\n    l.sort()\n    return l[0][2], l[0][0], l[0][1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting the stream of a stream handler to a different stream", "response": "def redirectLoggerStreamHandlers(oldStream, newStream):\n    \"\"\"Redirect the stream of a stream handler to a different stream\n    \"\"\"\n    for handler in list(logger.handlers): #Remove old handlers\n        if handler.stream == oldStream:\n            handler.close()\n            logger.removeHandler(handler)\n    for handler in logger.handlers: #Do not add a duplicate handler\n        if handler.stream == newStream:\n           return\n    logger.addHandler(logging.StreamHandler(newStream))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _addLoggingOptions(addOptionFn):\n    ##################################################\n    # BEFORE YOU ADD OR REMOVE OPTIONS TO THIS FUNCTION, KNOW THAT\n    # YOU MAY ONLY USE VARIABLES ACCEPTED BY BOTH optparse AND argparse\n    # FOR EXAMPLE, YOU MAY NOT USE default=%default OR default=%(default)s\n    ##################################################\n    addOptionFn(\"--logOff\", dest=\"logOff\", action=\"store_true\", default=False,\n                     help=\"Turn off logging. (default is CRITICAL)\")\n    addOptionFn(\n        \"--logInfo\", dest=\"logInfo\", action=\"store_true\", default=False,\n        help=\"Turn on logging at INFO level. (default is CRITICAL)\")\n    addOptionFn(\n        \"--logDebug\", dest=\"logDebug\", action=\"store_true\", default=False,\n        help=\"Turn on logging at DEBUG level. (default is CRITICAL)\")\n    addOptionFn(\n        \"--logLevel\", dest=\"logLevel\", default='CRITICAL',\n        help=(\"Log at level (may be either OFF/INFO/DEBUG/CRITICAL). \"\n              \"(default is CRITICAL)\"))\n    addOptionFn(\"--logFile\", dest=\"logFile\", help=\"File to log in\")\n    addOptionFn(\n        \"--rotatingLogging\", dest=\"logRotating\", action=\"store_true\",\n        default=False, help=(\"Turn on rotating logging, which prevents log \"\n                             \"files getting too big.\"))", "response": "Adds logging options to the base log file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setLoggingFromOptions(options):\n    #We can now set up the logging info.\n    if options.logLevel is not None:\n        setLogLevel(options.logLevel) #Use log level, unless flags are set..\n\n    if options.logOff:\n        setLogLevel(\"OFF\")\n    elif options.logInfo:\n        setLogLevel(\"INFO\")\n    elif options.logDebug:\n        setLogLevel(\"DEBUG\")\n\n    logger.info(\"Logging set at level: %s\" % logLevelString)\n\n    if options.logFile is not None:\n        addLoggingFileHandler(options.logFile, options.logRotating)\n\n    logger.info(\"Logging to file: %s\" % options.logFile)", "response": "Sets the logging from a dictionary of name value options."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a command and captures standard out in the given temp file.", "response": "def popen(command, tempFile):\n    \"\"\"Runs a command and captures standard out in the given temp file.\n    \"\"\"\n    fileHandle = open(tempFile, 'w')\n    logger.debug(\"Running the command: %s\" % command)\n    sts = subprocess.call(command, shell=True, stdout=fileHandle, bufsize=-1)\n    fileHandle.close()\n    if sts != 0:\n        raise RuntimeError(\"Command: %s exited with non-zero status %i\" % (command, sts))\n    return sts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef popenCatch(command, stdinString=None):\n    logger.debug(\"Running the command: %s\" % command)\n    if stdinString != None:\n        process = subprocess.Popen(command, shell=True,\n                                   stdin=subprocess.PIPE, stdout=subprocess.PIPE, bufsize=-1)\n        output, nothing = process.communicate(stdinString)\n    else:\n        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=sys.stderr, bufsize=-1)\n        output, nothing = process.communicate() #process.stdout.read().strip()\n    sts = process.wait()\n    if sts != 0:\n        raise RuntimeError(\"Command: %s with stdin string '%s' exited with non-zero status %i\" % (command, stdinString, sts))\n    return output", "response": "Runs a command and returns standard out."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getTotalCpuTimeAndMemoryUsage():\n    me = resource.getrusage(resource.RUSAGE_SELF)\n    childs = resource.getrusage(resource.RUSAGE_CHILDREN)\n    totalCpuTime = me.ru_utime+me.ru_stime+childs.ru_utime+childs.ru_stime\n    totalMemoryUsage = me.ru_maxrss+ me.ru_maxrss\n    return totalCpuTime, totalMemoryUsage", "response": "Gives the total cpu time and memory usage of the root node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saveInputs(savedInputsDir, listOfFilesAndDirsToSave):\n    logger.info(\"Saving the inputs: %s to the directory: %s\" % (\" \".join(listOfFilesAndDirsToSave), savedInputsDir))\n    assert os.path.isdir(savedInputsDir)\n    #savedInputsDir = getTempDirectory(saveInputsDir)\n    createdFiles = []\n    for fileName in listOfFilesAndDirsToSave:\n        if os.path.isfile(fileName):\n            copiedFileName = os.path.join(savedInputsDir, os.path.split(fileName)[-1])\n            system(\"cp %s %s\" % (fileName, copiedFileName))\n        else:\n            copiedFileName = os.path.join(savedInputsDir, os.path.split(fileName)[-1]) + \".tar\"\n            system(\"tar -cf %s %s\" % (copiedFileName, fileName))\n        createdFiles.append(copiedFileName)\n    return createdFiles", "response": "Copies the list of files to a directory created in the save inputs dir and returns the name of this directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nameValue(name, value, valueType=str, quotes=False):\n    if valueType == bool:\n        if value:\n            return \"--%s\" % name\n        return \"\"\n    if value is None:\n        return \"\"\n    if quotes:\n        return \"--%s '%s'\" % (name, valueType(value))\n    return \"--%s %s\" % (name, valueType(value))", "response": "Return a name value string for the given command."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a given subdirectory if it doesn t already exist making sure it us public.", "response": "def makeSubDir(dirName):\n    \"\"\"Makes a given subdirectory if it doesn't already exist, making sure it us public.\n    \"\"\"\n    if not os.path.exists(dirName):\n        os.mkdir(dirName)\n        os.chmod(dirName, 0777)\n    return dirName"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTempFile(suffix=\"\", rootDir=None):\n    if rootDir is None:\n        handle, tmpFile = tempfile.mkstemp(suffix)\n        os.close(handle)\n        return tmpFile\n    else:\n        tmpFile = os.path.join(rootDir, \"tmp_\" + getRandomAlphaNumericString() + suffix)\n        open(tmpFile, 'w').close()\n        os.chmod(tmpFile, 0777) #Ensure everyone has access to the file.\n        return tmpFile", "response": "Returns a string representing a temporary file that must be manually deleted by everyone."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a temporary directory that must be manually deleted. rootDir is the root directory of the file that will be used to create the file.", "response": "def getTempDirectory(rootDir=None):\n    \"\"\"\n    returns a temporary directory that must be manually deleted. rootDir will be\n    created if it does not exist.\n    \"\"\"\n    if rootDir is None:\n        return tempfile.mkdtemp()\n    else:\n        if not os.path.exists(rootDir):\n            try:\n                os.makedirs(rootDir)\n            except OSError:\n                # Maybe it got created between the test and the makedirs call?\n                pass\n            \n        while True:\n            # Keep trying names until we find one that doesn't exist. If one\n            # does exist, don't nest inside it, because someone else may be\n            # using it for something.\n            tmpDir = os.path.join(rootDir, \"tmp_\" + getRandomAlphaNumericString())\n            if not os.path.exists(tmpDir):\n                break\n                \n        os.mkdir(tmpDir)\n        os.chmod(tmpDir, 0777) #Ensure everyone has access to the file.\n        return tmpDir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef catFiles(filesToCat, catFile):\n    if len(filesToCat) == 0: #We must handle this case or the cat call will hang waiting for input\n        open(catFile, 'w').close()\n        return\n    maxCat = 25\n    system(\"cat %s > %s\" % (\" \".join(filesToCat[:maxCat]), catFile))\n    filesToCat = filesToCat[maxCat:]\n    while len(filesToCat) > 0:\n        system(\"cat %s >> %s\" % (\" \".join(filesToCat[:maxCat]), catFile))\n        filesToCat = filesToCat[maxCat:]", "response": "Cats a bunch of files into one file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a pretty - printed XML string for the ElementTree Element.", "response": "def prettyXml(elem):\n    \"\"\" Return a pretty-printed XML string for the ElementTree Element.\n    \"\"\"\n    roughString = ET.tostring(elem, \"utf-8\")\n    reparsed = minidom.parseString(roughString)\n    return reparsed.toprettyxml(indent=\"  \")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isNewer(firstFile, secondFile):\n    assert os.path.exists(firstFile)\n    assert os.path.exists(secondFile)\n    return os.path.getctime(firstFile) > os.path.getctime(secondFile)", "response": "Returns True if the first file was modified more recently than the second file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding the fasta header", "response": "def fastaEncodeHeader(attributes):\n    \"\"\"Decodes the fasta header\n    \"\"\"\n    for i in attributes:\n        assert len(str(i).split()) == 1\n    return \"|\".join([ str(i) for i in attributes ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fastaRead(fileHandleOrFile):\n    fileHandle = _getFileHandle(fileHandleOrFile)\n    line = fileHandle.readline()\n    chars_to_remove = \"\\n \"\n    valid_chars = {x for x in string.ascii_letters + \"-\"}\n    while line != '':\n        if line[0] == '>':\n            name = line[1:-1]\n            line = fileHandle.readline()\n            seq = array.array('c')\n            while line != '' and line[0] != '>':\n                line = line.translate(None, chars_to_remove)\n                if len(line) > 0 and line[0] != '#':\n                    seq.extend(line)\n                line = fileHandle.readline()\n            try:\n                assert all(x in valid_chars for x in seq)\n            except AssertionError:\n                bad_chars = {x for x in seq if x not in valid_chars}\n                raise RuntimeError(\"Invalid FASTA character(s) see in fasta sequence: {}\".format(bad_chars))\n            yield name, seq.tostring()\n        else:\n            line = fileHandle.readline()\n    if isinstance(fileHandleOrFile, \"\".__class__):\n        fileHandle.close()", "response": "iteratively yields a sequence for each '>' it encounters ignores '#' lines\n    yields a sequence for each '>' it encounters ignores '#' lines\n    yields a sequence for each '>' it encounters ignores '#' lines\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting out a FASTA file containing the sequence seq.", "response": "def fastaWrite(fileHandleOrFile, name, seq, mode=\"w\"):\n    \"\"\"Writes out fasta file\n    \"\"\"\n    fileHandle = _getFileHandle(fileHandleOrFile, mode)\n    valid_chars = {x for x in string.ascii_letters + \"-\"}\n    try:\n        assert any([isinstance(seq, unicode), isinstance(seq, str)])\n    except AssertionError:\n        raise RuntimeError(\"Sequence is not unicode or string\")\n    try:\n        assert all(x in valid_chars for x in seq)\n    except AssertionError:\n        bad_chars = {x for x in seq if x not in valid_chars}\n        raise RuntimeError(\"Invalid FASTA character(s) see in fasta sequence: {}\".format(bad_chars))\n    fileHandle.write(\">%s\\n\" % name)\n    chunkSize = 100\n    for i in xrange(0, len(seq), chunkSize):\n        fileHandle.write(\"%s\\n\" % seq[i:i+chunkSize])\n    if isinstance(fileHandleOrFile, \"\".__class__):\n        fileHandle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fastqRead(fileHandleOrFile):\n    fileHandle = _getFileHandle(fileHandleOrFile)\n    line = fileHandle.readline()\n    while line != '':\n        if line[0] == '@':\n            name = line[1:-1]\n            seq = fileHandle.readline()[:-1]\n            plus = fileHandle.readline()\n            if plus[0] != '+':\n                raise RuntimeError(\"Got unexpected line: %s\" % plus)\n            qualValues = [ ord(i) for i in fileHandle.readline()[:-1] ]\n            if len(seq) != len(qualValues):\n                logger.critical(\"Got a mismatch between the number of sequence characters (%s) and number of qual values (%s) for sequence: %s, ignoring returning None\" % (len(seq), len(qualValues), name))\n                qualValues = None\n            else:\n                for i in qualValues:\n                    if i < 33 or i > 126:\n                        raise RuntimeError(\"Got a qual value out of range %s (range is 33 to 126)\" % i)\n            for i in seq:\n                #For safety and sanity I only allows roman alphabet characters in fasta sequences.\n                if not ((i >= 'A' and i <= 'Z') or (i >= 'a' and i <= 'z') or i == '-'):\n                    raise RuntimeError(\"Invalid FASTQ character, ASCII code = \\'%d\\', found in input sequence %s\" % (ord(i), name))\n            yield name, seq, qualValues\n        line = fileHandle.readline()\n    if isinstance(fileHandleOrFile, \"\".__class__):\n        fileHandle.close()", "response": "Reads a fastq file iteratively\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fastqWrite(fileHandleOrFile, name, seq, qualValues, mode=\"w\"):\n    fileHandle = _getFileHandle(fileHandleOrFile, mode)\n    assert seq.__class__ == \"\".__class__\n    for i in seq:\n        if not ((i >= 'A' and i <= 'Z') or (i >= 'a' and i <= 'z') or i == '-'): #For safety and sanity I only allows roman alphabet characters in fasta sequences.\n            raise RuntimeError(\"Invalid FASTQ character, ASCII code = \\'%d\\', char = '%s' found in input sequence %s\" % (ord(i), i, name))\n    if qualValues != None and qualValues != '*':\n        if len(seq) != len(qualValues):\n            raise RuntimeError(\"Got a mismatch between the number of sequence characters (%s) and number of qual values (%s) for sequence: %s \" % (len(seq), len(qualValues), name))\n        for i in qualValues:\n            if i < 33 or i > 126:\n                raise RuntimeError(\"Got a qual value out of range %s (range is 33 to 126)\" % i)\n        fileHandle.write(\"@%s\\n%s\\n+\\n%s\\n\" % (name, seq, \"\".join([ chr(i) for i in qualValues ])))\n    else:\n        fileHandle.write(\"@%s\\n%s\\n+\\n*\\n\" % (name, seq))\n    if isinstance(fileHandleOrFile, \"\".__class__):\n        fileHandle.close()", "response": "Writes out a fastq file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading in columns of multiple alignment and returns them iteratively", "response": "def _getMultiFastaOffsets(fasta):\n    \"\"\"Reads in columns of multiple alignment and returns them iteratively\n    \"\"\"\n    f = open(fasta, 'r')\n    i = 0\n    j = f.read(1)\n    l = []\n    while j != '':\n        i += 1\n        if j == '>':\n            i += 1\n            while f.read(1) != '\\n':\n                i += 1\n            l.append(i)\n        j = f.read(1)\n    f.close()\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of fasta header lines excluding", "response": "def fastaReadHeaders(fasta):\n    \"\"\"Returns a list of fasta header lines, excluding\n    \"\"\"\n    headers = []\n    fileHandle = open(fasta, 'r')\n    line = fileHandle.readline()\n    while line != '':\n        assert line[-1] == '\\n'\n        if line[0] == '>':\n            headers.append(line[1:-1])\n        line = fileHandle.readline()\n    fileHandle.close()\n    return headers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fastaAlignmentRead(fasta, mapFn=(lambda x : x), l=None):\n    if l is None:\n        l = _getMultiFastaOffsets(fasta)\n    else:\n        l = l[:]\n    seqNo = len(l)\n    for i in xrange(0, seqNo):\n        j = open(fasta, 'r')\n        j.seek(l[i])\n        l[i] = j\n    column = [sys.maxint]*seqNo\n    if seqNo != 0:\n        while True:\n            for j in xrange(0, seqNo):\n                i = l[j].read(1)\n                while i == '\\n':\n                    i = l[j].read(1)\n                column[j] = i\n            if column[0] == '>' or column[0] == '':\n                for j in xrange(1, seqNo):\n                    assert column[j] == '>' or column[j] == ''\n                break\n            for j in xrange(1, seqNo):\n                 assert column[j] != '>' and column[j] != ''\n                 column[j] = mapFn(column[j])\n            yield column[:]\n    for i in l:\n        i.close()", "response": "reads in columns of multiple alignment and returns them iteratively"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out column alignment to given file multi - fasta format", "response": "def fastaAlignmentWrite(columnAlignment, names, seqNo, fastaFile,\n                        filter=lambda x : True):\n    \"\"\"\n    Writes out column alignment to given file multi-fasta format\n    \"\"\"\n    fastaFile = open(fastaFile, 'w')\n    columnAlignment = [ i for i in columnAlignment if filter(i) ]\n    for seq in xrange(0, seqNo):\n        fastaFile.write(\">%s\\n\" % names[seq])\n        for column in columnAlignment:\n            fastaFile.write(column[seq])\n        fastaFile.write(\"\\n\")\n    fastaFile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a random name and sequence.", "response": "def getRandomSequence(length=500):\n    \"\"\"Generates a random name and sequence.\n    \"\"\"\n    fastaHeader = \"\"\n    for i in xrange(int(random.random()*100)):\n        fastaHeader = fastaHeader + random.choice([ 'A', 'C', '0', '9', ' ', '\\t' ])\n    return (fastaHeader, \\\n            \"\".join([ random.choice([ 'A', 'C', 'T', 'G', 'A', 'C', 'T', 'G', 'A', 'C', 'T', 'G', 'A', 'C', 'T', 'G', 'A', 'C', 'T', 'G', 'N' ]) for i in xrange((int)(random.random() * length))]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mutateSequence(seq, distance):\n    subProb=distance\n    inProb=0.05*distance\n    deProb=0.05*distance\n    contProb=0.9\n    l = []\n    bases = [ 'A', 'C', 'T', 'G' ]\n    i=0\n    while i < len(seq):\n        if random.random() < subProb:\n            l.append(random.choice(bases))\n        else:\n            l.append(seq[i])\n        if random.random() < inProb:\n            l += getRandomSequence(_expLength(0, contProb))[1]\n        if random.random() < deProb:\n            i += int(_expLength(0, contProb))\n        i += 1\n    return \"\".join(l)", "response": "Mutates the DNA sequence for use in testing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newickTreeParser(newickTree, defaultDistance=DEFAULT_DISTANCE, \\\n                     sortNonBinaryNodes=False, reportUnaryNodes=False):\n    \"\"\"\n    lax newick tree parser\n    \"\"\"\n    newickTree = newickTree.replace(\"(\", \" ( \")\n    newickTree = newickTree.replace(\")\", \" ) \")\n    newickTree = newickTree.replace(\":\", \" : \")\n    newickTree = newickTree.replace(\";\", \"\")\n    newickTree = newickTree.replace(\",\", \" , \")\n\n    newickTree = re.compile(\"[\\s]*\").split(newickTree)\n    while \"\" in newickTree:\n        newickTree.remove(\"\")\n    def fn(newickTree, i):\n        if i[0] < len(newickTree):\n            if newickTree[i[0]] == ':':\n                d = float(newickTree[i[0]+1])\n                i[0] += 2\n                return d\n        return defaultDistance\n    def fn2(newickTree, i):\n        if i[0] < len(newickTree):\n            j = newickTree[i[0]]\n            if j != ':' and j != ')' and j != ',':\n                i[0] += 1\n                return j\n        return None\n    def fn3(newickTree, i):\n        if newickTree[i[0]] == '(':\n            #subTree1 = None\n            subTreeList = []\n            i[0] += 1\n            k = []\n            while newickTree[i[0]] != ')':\n                if newickTree[i[0]] == ',':\n                    i[0] += 1\n                subTreeList.append(fn3(newickTree, i))\n            i[0] += 1\n            def cmp(i, j):\n                if i.distance < j.distance:\n                    return -1\n                if i.distance > j.distance:\n                    return 1\n                return 0\n            if sortNonBinaryNodes:\n                subTreeList.sort(cmp)\n            subTree1 = subTreeList[0]\n            if len(subTreeList) > 1:\n                for subTree2 in subTreeList[1:]:\n                    subTree1 = BinaryTree(0.0, True, subTree1, subTree2, None)\n                subTree1.iD = fn2(newickTree, i)\n                subTree1.distance += fn(newickTree, i)\n            elif reportUnaryNodes:\n                subTree1 = BinaryTree(0.0, True, subTree1, None, None)\n                subTree1.iD = fn2(newickTree, i)\n                subTree1.distance += fn(newickTree, i)\n            else:\n                fn2(newickTree, i)\n                subTree1.distance += fn(newickTree, i)\n            return subTree1\n        leafID = fn2(newickTree, i)\n        return BinaryTree(fn(newickTree, i), False, None, None, leafID)\n    return fn3(newickTree, [0])", "response": "Parses a newick tree into a tree of newick language objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pWMRead(fileHandle, alphabetSize=4):\n    lines = fileHandle.readlines()\n    assert len(lines) == alphabetSize\n    l = [ [ float(i) ] for i in lines[0].split() ]\n    for line in lines[1:]:\n        l2 = [ float(i) for i in line.split() ]\n        assert len(l) == len(l2)\n        for i in xrange(0, len(l)):\n            l[i].append(l2[i])\n    for i in xrange(0, len(l)):\n        j = sum(l[i]) + 0.0\n        l[i] = [ k/j for k in l[i] ]\n    return l", "response": "reads in standard position weight matrix format"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pWMWrite(fileHandle, pWM, alphabetSize=4):\n    for i in xrange(0, alphabetSize):\n        fileHandle.write(\"%s\\n\" % ' '.join([ str(pWM[j][i]) for j in xrange(0, len(pWM)) ]))", "response": "Writes a PWM file in standard PWM format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a list of pairwise alignment structures into a pairwise alignment structure.", "response": "def cigarRead(fileHandleOrFile):\n    \"\"\"Reads a list of pairwise alignments into a pairwise alignment structure.\n\n    Query and target are reversed!\n    \"\"\"\n    fileHandle = _getFileHandle(fileHandleOrFile)\n    #p = re.compile(\"cigar:\\\\s+(.+)\\\\s+([0-9]+)\\\\s+([0-9]+)\\\\s+([\\\\+\\\\-\\\\.])\\\\s+(.+)\\\\s+([0-9]+)\\\\s+([0-9]+)\\\\s+([\\\\+\\\\-\\\\.])\\\\s+(.+)\\\\s+(.*)\\\\s*)*\")\n    p = re.compile(\"cigar:\\\\s+(.+)\\\\s+([0-9]+)\\\\s+([0-9]+)\\\\s+([\\\\+\\\\-\\\\.])\\\\s+(.+)\\\\s+([0-9]+)\\\\s+([0-9]+)\\\\s+([\\\\+\\\\-\\\\.])\\\\s+([^\\\\s]+)(\\\\s+(.*)\\\\s*)*\")\n    line = fileHandle.readline()\n    while line != '':\n        pA = cigarReadFromString(line)\n        if pA != None:\n            yield pA\n        line = fileHandle.readline()\n    if isinstance(fileHandleOrFile, \"\".__class__):\n        fileHandle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cigarWrite(fileHandle, pairwiseAlignment, withProbs=True):\n    if len(pairwiseAlignment.operationList) == 0:\n        logger.info(\"Writing zero length pairwiseAlignment to file!\")\n\n    strand1 = \"+\"\n    if not pairwiseAlignment.strand1:\n        strand1 = \"-\"\n\n    strand2 = \"+\"\n    if not pairwiseAlignment.strand2:\n        strand2 = \"-\"\n\n    fileHandle.write(\"cigar: %s %i %i %s %s %i %i %s %f\" % (pairwiseAlignment.contig2, pairwiseAlignment.start2, pairwiseAlignment.end2, strand2,\\\n                                                            pairwiseAlignment.contig1, pairwiseAlignment.start1, pairwiseAlignment.end1, strand1,\\\n                                                            pairwiseAlignment.score))\n    if withProbs == True:\n        hashMap = { PairwiseAlignment.PAIRWISE_INDEL_Y:'Z',PairwiseAlignment.PAIRWISE_INDEL_X:'Y', PairwiseAlignment.PAIRWISE_MATCH:'X' }\n        for op in pairwiseAlignment.operationList:\n            fileHandle.write(' %s %i %f' % (hashMap[op.type], op.length, op.score))\n    else:\n        hashMap = { PairwiseAlignment.PAIRWISE_INDEL_Y:'I',PairwiseAlignment.PAIRWISE_INDEL_X:'D', PairwiseAlignment.PAIRWISE_MATCH:'M' }\n        for op in pairwiseAlignment.operationList:\n            fileHandle.write(' %s %i' % (hashMap[op.type], op.length))\n    fileHandle.write(\"\\n\")", "response": "Writes out the pairwiseAlignment to the file stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a random pairwiseAlignment.", "response": "def getRandomPairwiseAlignment():\n    \"\"\"Gets a random pairwiseAlignment.\n    \"\"\"\n    i, j, k, l = _getRandomSegment()\n    m, n, o, p = _getRandomSegment()\n    score = random.choice(xrange(-1000, 1000))\n    return PairwiseAlignment(i, j, k, l, m, n, o, p, score, getRandomOperationList(abs(k - j), abs(o - n)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addNodeToGraph(nodeName, graphFileHandle, label, width=0.3, height=0.3, shape=\"circle\", colour=\"black\", fontsize=14):\n    graphFileHandle.write(\"node[width=%s,height=%s,shape=%s,colour=%s,fontsize=%s];\\n\" % (width, height, shape, colour, fontsize))\n    graphFileHandle.write(\"%s [label=\\\"%s\\\"];\\n\" % (nodeName, label))", "response": "Adds a node to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addEdgeToGraph(parentNodeName, childNodeName, graphFileHandle, colour=\"black\", length=\"10\", weight=\"1\", dir=\"none\", label=\"\", style=\"\"):\n    graphFileHandle.write('edge[color=%s,len=%s,weight=%s,dir=%s,label=\"%s\",style=%s];\\n' % (colour, length, weight, dir, label, style))\n    graphFileHandle.write(\"%s -- %s;\\n\" % (parentNodeName, childNodeName))", "response": "Adds an edge to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the temporary file in the temp file dir checking its in the temp file tree.", "response": "def destroyTempFile(self, tempFile):\n        \"\"\"Removes the temporary file in the temp file dir, checking its in the temp file tree.\n        \"\"\"\n        #Do basic assertions for goodness of the function\n        assert os.path.isfile(tempFile)\n        assert os.path.commonprefix((self.rootDir, tempFile)) == self.rootDir #Checks file is part of tree\n        #Update stats.\n        self.tempFilesDestroyed += 1\n        #Do the actual removal\n        os.remove(tempFile)\n        self.__destroyFile(tempFile)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a temporary directory in the temp file tree.", "response": "def destroyTempDir(self, tempDir):\n        \"\"\"Removes a temporary directory in the temp file dir, checking its in the temp file tree.\n        The dir will be removed regardless of if it is empty.\n        \"\"\"\n        #Do basic assertions for goodness of the function\n        assert os.path.isdir(tempDir)\n        assert os.path.commonprefix((self.rootDir, tempDir)) == self.rootDir #Checks file is part of tree\n        #Update stats.\n        self.tempFilesDestroyed += 1\n        #Do the actual removal\n        try:\n            os.rmdir(tempDir)\n        except OSError:\n            shutil.rmtree(tempDir)\n            #system(\"rm -rf %s\" % tempDir)\n        self.__destroyFile(tempDir)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef listFiles(self):\n        def fn(dirName, level, files):\n            if level == self.levelNo-1:\n                for fileName in os.listdir(dirName):\n                    if fileName != \"lock\":\n                        absFileName = os.path.join(dirName, fileName)\n                        files.append(absFileName)\n            else:\n                for subDir in os.listdir(dirName):\n                    if subDir != \"lock\":\n                        absDirName = os.path.join(dirName, subDir)\n                        assert os.path.isdir(absDirName)\n                        fn(absDirName, level+1, files)\n        files = []\n        fn(self.rootDir, 0, files)\n        return files", "response": "Gets all files in the temp file tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndestroying all temp files.", "response": "def destroyTempFiles(self):\n        \"\"\"Destroys all temp temp file hierarchy, getting rid of all files.\n        \"\"\"\n        os.system(\"rm -rf %s\" % self.rootDir)\n        logger.debug(\"Temp files created: %s, temp files actively destroyed: %s\" % (self.tempFilesCreated, self.tempFilesDestroyed))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a mutable JSONField.", "response": "def mutable_json_field(  # pylint: disable=keyword-arg-before-vararg\n    enforce_string=False,  # type: bool\n    enforce_unicode=False,  # type: bool\n    json=json,  # type: typing.Union[types.ModuleType, typing.Any]\n    *args,  # type: typing.Any\n    **kwargs  # type: typing.Any\n):  # type: (...) -> JSONField\n    \"\"\"Mutable JSONField creator.\n\n    :param enforce_string: enforce String(UnicodeText) type usage\n    :type enforce_string: bool\n    :param enforce_unicode: do not encode non-ascii data\n    :type enforce_unicode: bool\n    :param json: JSON encoding/decoding library.\n                 By default: standard json package.\n    :return: Mutable JSONField via MutableDict.as_mutable\n    :rtype: JSONField\n    \"\"\"\n    return sqlalchemy.ext.mutable.MutableDict.as_mutable(\n        JSONField(enforce_string=enforce_string, enforce_unicode=enforce_unicode, json=json, *args, **kwargs)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_dialect_impl(self, dialect):  # type: (DefaultDialect) -> TypeEngine\n        if self.__use_json(dialect):\n            return dialect.type_descriptor(self.__json_type)\n        return dialect.type_descriptor(sqlalchemy.UnicodeText)", "response": "Select impl by dialect."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nencodes data if required.", "response": "def process_bind_param(self, value, dialect):  # type: (typing.Any, DefaultDialect) -> typing.Union[str, typing.Any]\n        \"\"\"Encode data, if required.\"\"\"\n        if self.__use_json(dialect) or value is None:\n            return value\n\n        return self.__json_codec.dumps(value, ensure_ascii=not self.__enforce_unicode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes data if required.", "response": "def process_result_value(\n        self,\n        value,  # type: typing.Union[str, typing.Any]\n        dialect  # type: DefaultDialect\n    ):  # type: (...) -> typing.Any\n        \"\"\"Decode data, if required.\"\"\"\n        if self.__use_json(dialect) or value is None:\n            return value\n\n        return self.__json_codec.loads(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a subsystem based on the given executor.", "response": "def for_executor(cls, executor: Optional[Executor]) -> 'Subsystem':\n        \"\"\"Return a subsystem based on the given executor. If ``executor`` is\n        None, use :mod:`asyncio`. If ``executor`` is a\n        :class:`concurrent.futures.ThreadPoolExecutor`, use :mod:`threading`.\n\n        Args:\n            executor: The executor in use, if any.\n\n        \"\"\"\n        if isinstance(executor, ThreadPoolExecutor):\n            return _ThreadingSubsystem(executor)\n        elif executor is None:\n            return _AsyncioSubsystem()\n        else:\n            raise TypeError(executor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def login(cls, credentials: AuthenticationCredentials,\n                    config: Config) -> 'Session':\n        \"\"\"Checks the given credentials for a valid login and returns a new\n        session.\n\n        \"\"\"\n        redis = await create_redis(config.address)\n        namespace = await cls._check_user(redis, config, credentials)\n        if config.select is not None:\n            await redis.select(config.select)\n        mailbox_set = MailboxSet(redis, namespace)\n        try:\n            await mailbox_set.add_mailbox('INBOX')\n        except MailboxConflict:\n            pass\n        filter_set = FilterSet(redis, namespace)\n        return cls(redis, credentials.identity, config,\n                   mailbox_set, filter_set)", "response": "Checks the given credentials for a valid login and returns a new session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the message with the given UID.", "response": "async def get(self, uid: int, cached_msg: CachedMessage = None,\n                  requirement: FetchRequirement = FetchRequirement.METADATA) \\\n            -> Optional[MessageT]:\n        \"\"\"Return the message with the given UID.\n\n        Args:\n            uid: The message UID.\n            cached_msg: The last known cached message.\n            requirement: The data required from each message.\n\n        Raises:\n            IndexError: The UID is not valid in the mailbox.\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the permanent flags of each message.", "response": "async def update_flags(self, messages: Sequence[MessageT],\n                           flag_set: FrozenSet[Flag], mode: FlagOp) -> None:\n        \"\"\"Update the permanent flags of each messages.\n\n        Args:\n            messages: The message objects.\n            flag_set: The set of flags for the update operation.\n            flag_op: The mode to change the flags.\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def find(self, seq_set: SequenceSet, selected: SelectedMailbox,\n                   requirement: FetchRequirement = FetchRequirement.METADATA) \\\n            -> AsyncIterable[Tuple[int, MessageT]]:\n        \"\"\"Find the active message UID and message pairs in the mailbox that\n        are contained in the given sequences set. Message sequence numbers\n        are resolved by the selected mailbox session.\n\n        Args:\n            seq_set: The sequence set of the desired messages.\n            selected: The selected mailbox session.\n            requirement: The data required from each message.\n\n        \"\"\"\n        for seq, cached_msg in selected.messages.get_all(seq_set):\n            msg = await self.get(cached_msg.uid, cached_msg, requirement)\n            if msg is not None:\n                yield (seq, msg)", "response": "Find the active message UID and message pairs in the mailbox that are contained in the given sequences set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all the active message UIDs that have the \\\\ Deleted flag set.", "response": "async def find_deleted(self, seq_set: SequenceSet,\n                           selected: SelectedMailbox) -> Sequence[int]:\n        \"\"\"Return all the active message UIDs that have the ``\\\\Deleted`` flag.\n\n        Args:\n            seq_set: The sequence set of the possible messages.\n            selected: The selected mailbox session.\n\n        \"\"\"\n        session_flags = selected.session_flags\n        return [msg.uid async for _, msg in self.find(seq_set, selected)\n                if Deleted in msg.get_flags(session_flags)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef message_id(self) -> Optional[UnstructuredHeader]:\n        try:\n            return cast(UnstructuredHeader, self[b'message-id'][0])\n        except (KeyError, IndexError):\n            return None", "response": "The Message - Id header."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef content_language(self) -> Optional[UnstructuredHeader]:\n        try:\n            return cast(UnstructuredHeader, self[b'content-language'][0])\n        except (KeyError, IndexError):\n            return None", "response": "The Content - Language header."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef content_id(self) -> Optional[UnstructuredHeader]:\n        try:\n            return cast(UnstructuredHeader, self[b'content-id'][0])\n        except (KeyError, IndexError):\n            return None", "response": "The Content - Id header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self, *, continuations: List[memoryview] = None,\n             expected: Sequence[Type['Parseable']] = None,\n             list_expected: Sequence[Type['Parseable']] = None,\n             command_name: bytes = None,\n             uid: bool = None,\n             charset: str = None,\n             tag: bytes = None,\n             max_append_len: int = None,\n             allow_continuations: bool = None) -> 'Params':\n        \"\"\"Copy the parameters, possibly replacing a subset.\"\"\"\n        kwargs: Dict[str, Any] = {}\n        self._set_if_none(kwargs, 'continuations', continuations)\n        self._set_if_none(kwargs, 'expected', expected)\n        self._set_if_none(kwargs, 'list_expected', list_expected)\n        self._set_if_none(kwargs, 'command_name', command_name)\n        self._set_if_none(kwargs, 'uid', uid)\n        self._set_if_none(kwargs, 'charset', charset)\n        self._set_if_none(kwargs, 'tag', tag)\n        self._set_if_none(kwargs, 'max_append_len', max_append_len)\n        self._set_if_none(kwargs, 'allow_continuations', allow_continuations)\n        return Params(**kwargs)", "response": "Returns a copy of the parameters possibly replacing a subset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the given buffer and returns the parsed object.", "response": "def parse(cls, buf: memoryview, params: Params) \\\n            -> Tuple[Parseable, memoryview]:\n        \"\"\"Parses the given buffer by attempting to parse the list of\n        :attr:`~Params.expected` types until one of them succeeds,\n        then returns the parsed object.\n\n        Args:\n            buf: The bytes containing the data to be parsed.\n            params: The parameters used by some parseable types.\n\n        \"\"\"\n        for data_type in params.expected:\n            try:\n                return data_type.parse(buf, params)\n            except NotParseable:\n                pass\n        raise UnexpectedType(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef string(self) -> bytes:\n        if self._raw is not None:\n            return self._raw\n        self._raw = raw = BytesFormat(b' ').join(\n            [b'CAPABILITY', b'IMAP4rev1'] + self.capabilities)\n        return raw", "response": "The capabilities string without the enclosing square brackets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_untagged(self, *responses: 'Response') -> None:\n        for resp in responses:\n            try:\n                merge_key = resp.merge_key\n            except TypeError:\n                self._untagged.append(resp)\n            else:\n                key = (type(resp), merge_key)\n                try:\n                    untagged_idx = self._mergeable[key]\n                except KeyError:\n                    untagged_idx = len(self._untagged)\n                    self._mergeable[key] = untagged_idx\n                    self._untagged.append(resp)\n                else:\n                    merged = self._untagged[untagged_idx].merge(resp)\n                    self._untagged[untagged_idx] = merged\n        self._raw = None", "response": "Add an untagged response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_untagged_ok(self, text: MaybeBytes,\n                        code: Optional[ResponseCode] = None) -> None:\n        \"\"\"Add an untagged ``OK`` response.\n\n        See Also:\n            :meth:`.add_untagged`, :class:`ResponseOk`\n\n        Args:\n            text: The response text.\n            code: Optional response code.\n\n        \"\"\"\n        response = ResponseOk(b'*', text, code)\n        self.add_untagged(response)", "response": "Add an untagged OK response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_terminal(self) -> bool:\n        for resp in self._untagged:\n            if resp.is_terminal:\n                return True\n        return False", "response": "True if the response contains an untagged BYE response indicating that the session should be terminated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write(self, writer: WriteStream) -> None:\n        for untagged in self._untagged:\n            untagged.write(writer)\n        writer.write(b'%b %b\\r\\n' % (self.tag, self.text))", "response": "Writes the object to the output stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrue if the sequence set contains at least one entry and has at least one value.", "response": "def is_all(self) -> bool:\n        \"\"\"True if the sequence set starts at ``1`` and ends at the maximum\n        value.\n\n        This may be used to optimize cases of checking for a value in the set,\n        avoiding the need to provide ``max_value`` in :meth:`.flatten` or\n        :meth:`.iter`.\n\n        \"\"\"\n        first = self.sequences[0]\n        return isinstance(first, tuple) \\\n            and first[0] == 1 and isinstance(first[1], MaxValue)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a set of all values contained in the sequence set.", "response": "def flatten(self, max_value: int) -> FrozenSet[int]:\n        \"\"\"Return a set of all values contained in the sequence set.\n\n        Args:\n            max_value: The maximum value, in place of any ``*``.\n\n        \"\"\"\n        return frozenset(self.iter(max_value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate through the set of sequence numbers contained in the set bounded by the given maximum value.", "response": "def iter(self, max_value: int) -> Iterator[int]:\n        \"\"\"Iterates through the sequence numbers contained in the set, bounded\n        by the given maximum value (in place of any ``*``).\n\n        Args:\n            max_value: The maximum value of the set.\n\n        \"\"\"\n        return chain.from_iterable(\n            (self._get_range(elem, max_value) for elem in self.sequences))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a new sequence set that contains the given values using as few groups as possible.", "response": "def build(cls, seqs: Iterable[int], uid: bool = False) -> 'SequenceSet':\n        \"\"\"Build a new sequence set that contains the given values using as\n        few groups as possible.\n\n        Args:\n            seqs: The sequence values to build.\n            uid: True if the sequences refer to message UIDs.\n\n        \"\"\"\n        seqs_list = sorted(set(seqs))\n        groups: List[Union[int, Tuple[int, int]]] = []\n        group: Union[int, Tuple[int, int]] = seqs_list[0]\n        for i in range(1, len(seqs_list)):\n            group_i = seqs_list[i]\n            if isinstance(group, int):\n                if group_i == group + 1:\n                    group = (group, group_i)\n                else:\n                    groups.append(group)\n                    group = group_i\n            elif isinstance(group, tuple):\n                if group_i == group[1] + 1:\n                    group = (group[0], group_i)\n                else:\n                    groups.append(group)\n                    group = group_i\n        groups.append(group)\n        return SequenceSet(groups, uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attributes(self) -> Sequence[bytes]:\n        ret: List[bytes] = []\n        if not self.exists:\n            ret.append(b'Noselect')\n        if self.has_children:\n            ret.append(b'HasChildren')\n        else:\n            ret.append(b'HasNoChildren')\n        if self.marked is True:\n            ret.append(b'Marked')\n        elif self.marked is False:\n            ret.append(b'Unmarked')\n        return ret", "response": "The mailbox attributes that should be returned with the mailbox\n            in a LIST response e. g. \\\\ Noselect \\\\ HasChildren \\\\ HasNoChildren \\\\ Unmarked \\\\ Unmarked."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds all the mailbox names to the tree filling in any missing nodes.", "response": "def update(self, *names: str) -> 'ListTree':\n        \"\"\"Add all the mailbox names to the tree, filling in any missing nodes.\n\n        Args:\n            names: The names of the mailboxes.\n\n        \"\"\"\n        for name in names:\n            parts = name.split(self._delimiter)\n            self._root.add(*parts)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd or remove the \\\\ Marked and \\\\ Unmarked attributes.", "response": "def set_marked(self, name: str, marked: bool = False,\n                   unmarked: bool = False) -> None:\n        \"\"\"Add or remove the ``\\\\Marked`` and ``\\\\Unmarked`` mailbox\n        attributes.\n\n        Args:\n            name: The name of the mailbox.\n            marked: True if the ``\\\\Marked`` attribute should be added.\n            unmarked: True if the ``\\\\Unmarked`` attribute should be added.\n\n        \"\"\"\n        if marked:\n            self._marked[name] = True\n        elif unmarked:\n            self._marked[name] = False\n        else:\n            self._marked.pop(name, None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, name: str) -> Optional[ListEntry]:\n        parts = name.split(self._delimiter)\n        try:\n            node = self._find(self._root, *parts)\n        except KeyError:\n            return None\n        else:\n            marked = self._marked.get(name)\n            return ListEntry(name, node.exists, marked, bool(node.children))", "response": "Return the named entry in the list tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tuples for all mailboxes that must be renamed for the given rename operation.", "response": "def get_renames(self, from_name: str, to_name: str) \\\n            -> Sequence[Tuple[str, str]]:\n        \"\"\"Return a list of tuples for all mailboxes that must be renamed, for\n        the given rename operation. This should include\n        ``(from_name, to_name)`` as well as all inferior names in the heirarchy\n        that must also be renamed. If ``from_name`` does not exist, an empty\n        list is returned.\n\n        See Also:\n            `RFC 3501 6.3.5\n            <https://tools.ietf.org/html/rfc3501#section-6.3.5>`_\n\n        Args:\n            from_name: The original name of the mailbox.\n            to_name: The intended new name of the mailbox.\n\n        \"\"\"\n        from_parts = from_name.split(self._delimiter)\n        try:\n            from_node = self._find(self._root, *from_parts)\n        except KeyError:\n            return []\n        from_names = (entry.name for entry in self._iter(from_node, from_name)\n                      if entry.exists)\n        to_names = (entry.name for entry in self._iter(from_node, to_name)\n                    if entry.exists)\n        return list(zip(from_names, to_names))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all the entries in the list tree.", "response": "def list(self) -> Iterable[ListEntry]:\n        \"\"\"Return all the entries in the list tree.\"\"\"\n        for entry in self._iter(self._root, ''):\n            yield entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_matching(self, ref_name: str, filter_: str) \\\n            -> Iterable[ListEntry]:\n        \"\"\"Return all the entries in the list tree that match the given query.\n\n        Args:\n            ref_name: Mailbox reference name.\n            filter_: Mailbox name with possible wildcards.\n\n        \"\"\"\n        canonical, canonical_i = self._get_pattern(ref_name + filter_)\n        for entry in self.list():\n            if entry.name == 'INBOX':\n                if canonical_i.match('INBOX'):\n                    yield entry\n            elif canonical.match(entry.name):\n                yield entry", "response": "Return all the entries in the list tree that match the given query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging the other FETCH response into this FETCH response.", "response": "def merge(self: 'FetchResponse', other: 'FetchResponse') \\\n            -> 'FetchResponse':\n        \"\"\"Merge the other FETCH response, adding any fetch attributes that do\n        not already exist in this FETCH response. For example::\n\n            * 3 FETCH (UID 119)\n            * 3 FETCH (FLAGS (\\\\Seen))\n\n        Would merge into::\n\n            * 3 FETCH (UID 119 FLAGS (\\\\Seen))\n\n        Args:\n            other: The other response to merge.\n\n        \"\"\"\n        if self.seq != other.seq:\n            raise ValueError(other)\n        new_data = OrderedDict(self.data)\n        new_data.update(other.data)\n        return FetchResponse(self.seq, list(new_data.items()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(cls: Type[MessageT], uid: int, data: bytes,\n              permanent_flags: Iterable[Flag], internal_date: datetime,\n              expunged: bool = False, **kwargs: Any) -> MessageT:\n        \"\"\"Parse the given file object containing a MIME-encoded email message\n        into a :class:`BaseLoadedMessage` object.\n\n        Args:\n            uid: The UID of the message.\n            data: The raw contents of the message.\n            permanent_flags: Permanent flags for the message.\n            internal_date: The internal date of the message.\n            expunged: True if this message has been expunged from the mailbox.\n\n        \"\"\"\n        content = MessageContent.parse(data)\n        return cls(uid, permanent_flags, internal_date, expunged,\n                   content, **kwargs)", "response": "Parse the given MIME - encoded email message\n        into a Message object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, selected: 'SelectedMailbox', *,\n            replace: 'SelectedMailbox' = None) -> None:\n        \"\"\"Add a new selected mailbox object to the set, which may then be\n        returned by :meth:`.any_selected`.\n\n        Args:\n            selected: The new selected mailbox object.\n            replace: An existing selected mailbox object that should be removed\n                from the weak set.\n\n        \"\"\"\n        if replace is not None:\n            self._set.discard(replace)\n        self._set.add(selected)", "response": "Add a new selected mailbox object to the weak set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the given cached message.", "response": "def get(self, uid: int) -> Optional[CachedMessage]:\n        \"\"\"Return the given cached message.\n\n        Args:\n            uid: The message UID.\n\n        \"\"\"\n        return self._cache.get(uid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the cached messages and their sequence numbers for the given sequence set.", "response": "def get_all(self, seq_set: SequenceSet) \\\n            -> Sequence[Tuple[int, CachedMessage]]:\n        \"\"\"Return the cached messages, and their sequence numbers, for the\n        given sequence set.\n\n        Args:\n            seq_set: The message sequence set.\n\n        \"\"\"\n        if seq_set.uid:\n            all_uids = seq_set.flatten(self.max_uid) & self._uids\n            return [(seq, self._cache[uid])\n                    for seq, uid in enumerate(self._sorted, 1)\n                    if uid in all_uids]\n        else:\n            all_seqs = seq_set.flatten(self.exists)\n            return [(seq, self._cache[uid])\n                    for seq, uid in enumerate(self._sorted, 1)\n                    if seq in all_seqs]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the messages in the selected mailboxes with the given set of messages and the set of expunged messages.", "response": "def add_updates(self, messages: Iterable[CachedMessage],\n                    expunged: Iterable[int]) -> None:\n        \"\"\"Update the messages in the selected mailboxes. The ``messages``\n        should include non-expunged messages in the mailbox that should be\n        checked for updates. The ``expunged`` argument is the set of UIDs that\n        have been expunged from the mailbox.\n\n        In an optimized implementation, ``messages`` only includes new messages\n        or messages with metadata updates.  This minimizes the comparison\n        needed to determine what untagged responses are necessary. The\n        :attr:`.mod_sequence` attribute may be used to support this\n        optimization.\n\n        If a backend implementation lacks the ability to determine the subset\n        of messages that have been updated, it should instead use\n        :meth:`.set_messages`.\n\n        Args:\n            messages: The cached message objects to add.\n            expunged: The set of message UIDs that have been expunged.\n\n        \"\"\"\n        self._messages._update(messages)\n        self._messages._remove(expunged, self._hide_expunged)\n        if not self._hide_expunged:\n            self._session_flags.remove(expunged)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_messages(self, messages: Sequence[CachedMessage]) -> None:\n        uids = {msg.uid for msg in messages}\n        expunged = self._messages._uids - uids\n        return self.add_updates(messages, expunged)", "response": "This method is used to set the set of messages in the mailbox."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef silence(self, seq_set: SequenceSet, flag_set: AbstractSet[Flag],\n                flag_op: FlagOp) -> None:\n        \"\"\"Runs the flags update against the cached flags, to prevent untagged\n        FETCH responses unless other updates have occurred.\n\n        For example, if a session adds ``\\\\Deleted`` and calls this method,\n        the FETCH response will be silenced. But if another added ``\\\\Seen``\n        at the same time, the FETCH response will be sent.\n\n        Args:\n            seq_set: The sequence set of messages.\n            flag_set: The set of flags for the update operation.\n            flag_op: The mode to change the flags.\n\n        \"\"\"\n        session_flags = self.session_flags\n        permanent_flag_set = self.permanent_flags & flag_set\n        session_flag_set = session_flags & flag_set\n        for seq, msg in self._messages.get_all(seq_set):\n            msg_flags = msg.permanent_flags\n            msg_sflags = session_flags.get(msg.uid)\n            updated_flags = flag_op.apply(msg_flags, permanent_flag_set)\n            updated_sflags = flag_op.apply(msg_sflags, session_flag_set)\n            if msg_flags != updated_flags:\n                self._silenced_flags.add((msg.uid, updated_flags))\n            if msg_sflags != updated_sflags:\n                self._silenced_sflags.add((msg.uid, updated_sflags))", "response": "Runs the flags update against the cached flags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fork(self, command: Command) \\\n            -> Tuple['SelectedMailbox', Iterable[Response]]:\n        \"\"\"Compares the state of the current object to that of the last fork,\n        returning the untagged responses that reflect any changes. A new copy\n        of the object is also returned, ready for the next command.\n\n        Args:\n            command: The command that was finished.\n\n        \"\"\"\n        frozen = _Frozen(self)\n        cls = type(self)\n        copy = cls(self._guid, self._readonly, self._permanent_flags,\n                   self._session_flags, self._selected_set, self._lookup,\n                   _mod_sequence=self._mod_sequence,\n                   _prev=frozen, _messages=self._messages)\n        if self._prev is not None:\n            with_uid: bool = getattr(command, 'uid', False)\n            untagged = self._compare(self._prev, frozen, with_uid)\n        else:\n            untagged = []\n        return copy, untagged", "response": "Returns the state of the current object and the untagged responses that reflect any changes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the headers from the message or a message / rfc822 sub - part of the message.", "response": "def get_message_headers(self, section: Sequence[int] = None,\n                            subset: Collection[bytes] = None,\n                            inverse: bool = False) -> Writeable:\n        \"\"\"Get the headers from the message or a ``message/rfc822`` sub-part of\n        the message..\n\n        The ``section`` argument can index a nested sub-part of the message.\n        For example, ``[2, 3]`` would get the 2nd sub-part of the message and\n        then index it for its 3rd sub-part.\n\n        Args:\n            section: Optional nested list of sub-part indexes.\n            subset: Subset of headers to get.\n            inverse: If ``subset`` is given, this flag will invert it so that\n                the headers *not* in ``subset`` are returned.\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the continuation line sent by the client to end the IDLE command.", "response": "def parse_done(self, buf: memoryview) -> Tuple[bool, memoryview]:\n        \"\"\"Parse the continuation line sent by the client to end the ``IDLE``\n        command.\n\n        Args:\n            buf: The continuation line to parse.\n\n        \"\"\"\n        match = self._pattern.match(buf)\n        if not match:\n            raise NotParseable(buf)\n        done = match.group(1).upper() == self.continuation\n        buf = buf[match.end(0):]\n        return done, buf"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the subscribed status of a folder.", "response": "def set(self, folder: str, subscribed: bool) -> None:\n        \"\"\"Set the subscribed status of a folder.\"\"\"\n        if subscribed:\n            self.add(folder)\n        else:\n            self.remove(folder)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_uid_validity(cls) -> int:\n        time_part = int(time.time()) % 4096\n        rand_part = random.randint(0, 1048576)\n        return (time_part << 20) + rand_part", "response": "Generate a new UID validity value for a mailbox."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_maildir(self, flags: Iterable[Union[bytes, Flag]]) -> str:\n        codes = []\n        for flag in flags:\n            if isinstance(flag, bytes):\n                flag = Flag(flag)\n            from_sys = self._from_sys.get(flag)\n            if from_sys is not None:\n                codes.append(from_sys)\n            else:\n                from_kwd = self._from_kwd.get(flag)\n                if from_kwd is not None:\n                    codes.append(from_kwd)\n        return ''.join(codes)", "response": "Returns the string of letter codes that are used to map to defined\n        IMAP flags and keywords."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the set of IMAP flags that correspond to the letter codes.", "response": "def from_maildir(self, codes: str) -> FrozenSet[Flag]:\n        \"\"\"Return the set of IMAP flags that correspond to the letter codes.\n\n        Args:\n            codes: The letter codes to map.\n\n        \"\"\"\n        flags = set()\n        for code in codes:\n            if code == ',':\n                break\n            to_sys = self._to_sys.get(code)\n            if to_sys is not None:\n                flags.add(to_sys)\n            else:\n                to_kwd = self._to_kwd.get(code)\n                if to_kwd is not None:\n                    flags.add(to_kwd)\n        return frozenset(flags)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck the given credentials for a valid login and returns a new Session object.", "response": "async def login(cls, credentials: AuthenticationCredentials,\n                    config: Config) -> 'Session':\n        \"\"\"Checks the given credentials for a valid login and returns a new\n        session. The mailbox data is shared between concurrent and future\n        sessions, but only for the lifetime of the process.\n\n        \"\"\"\n        user = credentials.authcid\n        password = cls._get_password(config, user)\n        if user != credentials.identity:\n            raise InvalidAuth()\n        elif not credentials.check_secret(password):\n            raise InvalidAuth()\n        mailbox_set, filter_set = config.set_cache.get(user, (None, None))\n        if not mailbox_set or not filter_set:\n            mailbox_set = MailboxSet()\n            filter_set = FilterSet()\n            if config.demo_data:\n                await cls._load_demo(mailbox_set, filter_set)\n            config.set_cache[user] = (mailbox_set, filter_set)\n        return cls(credentials.identity, config, mailbox_set, filter_set)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a decoder from the message header object.", "response": "def of(cls, msg_header: MessageHeader) -> 'MessageDecoder':\n        \"\"\"Return a decoder from the message header object.\n\n        See Also:\n            :meth:`.of_cte`\n\n        Args:\n            msg_header: The message header object.\n\n        \"\"\"\n        cte_hdr = msg_header.parsed.content_transfer_encoding\n        return cls.of_cte(cte_hdr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a decoder from the CTE header value.", "response": "def of_cte(cls, header: Optional[ContentTransferEncodingHeader]) \\\n            -> 'MessageDecoder':\n        \"\"\"Return a decoder from the CTE header value.\n\n        There is built-in support for ``7bit``, ``8bit``, ``quoted-printable``,\n        and ``base64`` CTE header values. Decoders can be added or overridden\n        with the :attr:`.registry` dictionary.\n\n        Args:\n            header: The CTE header value.\n\n        \"\"\"\n        if header is None:\n            return _NoopDecoder()\n        hdr_str = str(header).lower()\n        custom = cls.registry.get(hdr_str)\n        if custom is not None:\n            return custom\n        elif hdr_str in ('7bit', '8bit'):\n            return _NoopDecoder()\n        elif hdr_str == 'quoted-printable':\n            return _QuotedPrintableDecoder()\n        elif hdr_str == 'base64':\n            return _Base64Decoder()\n        else:\n            raise NotImplementedError(hdr_str)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_localhost(self) -> bool:\n        sock_family = self.socket.family\n        if sock_family == _socket.AF_UNIX:\n            return True\n        elif sock_family not in (_socket.AF_INET, _socket.AF_INET6):\n            return False\n        sock_address, *_ = self.peername\n        ip = ipaddress.ip_address(sock_address)\n        if ip.version == 6 and ip.ipv4_mapped is not None:\n            ip = ipaddress.ip_address(ip.ipv4_mapped)\n        return ip.is_loopback", "response": "True if the socket is a connection from a localhost."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def run(self, login: LoginProtocol):\n        self._print('%d +++| %s', bytes(socket_info.get()))\n        await self._do_greeting(login)\n        while True:\n            resp: Response\n            try:\n                cmd = await self._read_command()\n            except (ConnectionError, EOFError):\n                break\n            except NotParseable as exc:\n                resp = BadCommandResponse(exc)\n            else:\n                try:\n                    if isinstance(cmd, NoOpCommand):\n                        resp = NoOpResponse(cmd.tag)\n                    elif isinstance(cmd, LogoutCommand):\n                        resp = Response(Condition.BYE)\n                    elif isinstance(cmd, CapabilityCommand):\n                        resp = CapabilitiesResponse(self.capabilities)\n                    elif self._session is None:\n                        if isinstance(cmd, AuthenticateCommand):\n                            resp = await self._do_authenticate(login, cmd)\n                        elif isinstance(cmd, StartTLSCommand):\n                            resp = await self._do_starttls()\n                        else:\n                            resp = Response(Condition.NO, text='Bad command.')\n                    else:\n                        if isinstance(cmd, UnauthenticateCommand):\n                            resp = await self._do_unauthenticate()\n                        else:\n                            assert self._session.filter_set is not None\n                            state = FilterState(self._session.filter_set,\n                                                self.config)\n                            resp = await state.run(cmd)\n                except Exception:\n                    _log.exception('Unhandled exception')\n                    resp = Response(Condition.NO, text='Server error.')\n            await self._write_response(resp)\n            if resp.is_bye:\n                break\n        self._print('%d ---| %s', b'<disconnected>')", "response": "Start the socket communication with the server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart the command cycle.", "response": "async def run(self, state: ConnectionState) -> None:\n        \"\"\"Start the socket communication with the IMAP greeting, and then\n        enter the command/response cycle.\n\n        Args:\n            state: Defines the interaction with the backend plugin.\n\n        \"\"\"\n        self._print('%d +++| %s', bytes(socket_info.get()))\n        bad_commands = 0\n        try:\n            greeting = await self._exec(state.do_greeting())\n        except ResponseError as exc:\n            resp = exc.get_response(b'*')\n            resp.condition = ResponseBye.condition\n            await self.write_response(resp)\n            return\n        else:\n            await self.write_response(greeting)\n        while True:\n            try:\n                cmd = await self.read_command()\n            except (ConnectionError, EOFError):\n                break\n            except CancelledError:\n                await self.send_error_disconnect()\n                break\n            except Exception:\n                await self.send_error_disconnect()\n                raise\n            else:\n                prev_cmd = current_command.set(cmd)\n                try:\n                    if isinstance(cmd, AuthenticateCommand):\n                        creds = await self.authenticate(state, cmd.mech_name)\n                        response, _ = await self._exec(\n                            state.do_authenticate(cmd, creds))\n                    elif isinstance(cmd, IdleCommand):\n                        response = await self.idle(state, cmd)\n                    else:\n                        response = await self._exec(state.do_command(cmd))\n                except ResponseError as exc:\n                    resp = exc.get_response(cmd.tag)\n                    await self.write_response(resp)\n                    if resp.is_terminal:\n                        break\n                except AuthenticationError as exc:\n                    msg = bytes(str(exc), 'utf-8', 'surrogateescape')\n                    resp = ResponseBad(cmd.tag, msg)\n                    await self.write_response(resp)\n                except TimeoutError:\n                    resp = ResponseNo(cmd.tag, b'Operation timed out.',\n                                      ResponseCode.of(b'TIMEOUT'))\n                    await self.write_response(resp)\n                except CancelledError:\n                    await self.send_error_disconnect()\n                    break\n                except Exception:\n                    await self.send_error_disconnect()\n                    raise\n                else:\n                    await self.write_response(response)\n                    if response.is_bad:\n                        bad_commands += 1\n                        if self.bad_command_limit \\\n                                and bad_commands >= self.bad_command_limit:\n                            msg = b'Too many errors, disconnecting.'\n                            response.add_untagged(ResponseBye(msg))\n                    else:\n                        bad_commands = 0\n                    if response.is_terminal:\n                        break\n                    if isinstance(cmd, StartTLSCommand) and state.ssl_context \\\n                            and isinstance(response, ResponseOk):\n                        await self.start_tls(state.ssl_context)\n                finally:\n                    await state.do_cleanup()\n                    current_command.reset(prev_cmd)\n        self._print('%d ---| %s', b'<disconnected>')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the given credentials for a valid login and returns a new session.", "response": "async def login(cls: Type[_SessionT],\n                    credentials: AuthenticationCredentials,\n                    config: Config) -> _SessionT:\n        \"\"\"Checks the given credentials for a valid login and returns a new\n        session.\n\n        \"\"\"\n        user = credentials.authcid\n        password, user_dir = await cls.find_user(config, user)\n        if user != credentials.identity:\n            raise InvalidAuth()\n        elif not credentials.check_secret(password):\n            raise InvalidAuth()\n        maildir, layout = cls._load_maildir(config, user_dir)\n        mailbox_set = MailboxSet(maildir, layout)\n        filter_set = FilterSet(layout.path)\n        return cls(credentials.identity, config, mailbox_set, filter_set)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the user ID and its mailbox path.", "response": "async def find_user(cls, config: Config, user: str) \\\n            -> Tuple[str, str]:\n        \"\"\"If the given user ID exists, return its expected password and\n        mailbox path. Override this method to implement custom login logic.\n\n        Args:\n            config: The maildir config object.\n            user: The expected user ID.\n\n        Raises:\n            InvalidAuth: The user ID was not valid.\n\n        \"\"\"\n        with open(config.users_file, 'r') as users_file:\n            for line in users_file:\n                this_user, user_dir, password = line.split(':', 2)\n                if user == this_user:\n                    return password.rstrip('\\r\\n'), user_dir or user\n        raise InvalidAuth()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modutf7_encode(data: str) -> bytes:\n    ret = bytearray()\n    is_usascii = True\n    encode_start = None\n    for i, symbol in enumerate(data):\n        charpoint = ord(symbol)\n        if is_usascii:\n            if charpoint == 0x26:\n                ret.extend(b'&-')\n            elif 0x20 <= charpoint <= 0x7e:\n                ret.append(charpoint)\n            else:\n                encode_start = i\n                is_usascii = False\n        else:\n            if 0x20 <= charpoint <= 0x7e:\n                to_encode = data[encode_start:i]\n                encoded = _modified_b64encode(to_encode)\n                ret.append(0x26)\n                ret.extend(encoded)\n                ret.extend((0x2d, charpoint))\n                is_usascii = True\n    if not is_usascii:\n        to_encode = data[encode_start:]\n        encoded = _modified_b64encode(to_encode)\n        ret.append(0x26)\n        ret.extend(encoded)\n        ret.append(0x2d)\n    return bytes(ret)", "response": "Encode the string using modified UTF - 7."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modutf7_decode(data: bytes) -> str:\n    parts = []\n    is_usascii = True\n    buf = memoryview(data)\n    while buf:\n        byte = buf[0]\n        if is_usascii:\n            if buf[0:2] == b'&-':\n                parts.append('&')\n                buf = buf[2:]\n            elif byte == 0x26:\n                is_usascii = False\n                buf = buf[1:]\n            else:\n                parts.append(chr(byte))\n                buf = buf[1:]\n        else:\n            for i, byte in enumerate(buf):\n                if byte == 0x2d:\n                    to_decode = buf[:i].tobytes()\n                    decoded = _modified_b64decode(to_decode)\n                    parts.append(decoded)\n                    buf = buf[i + 1:]\n                    is_usascii = True\n                    break\n    if not is_usascii:\n        to_decode = buf.tobytes()\n        decoded = _modified_b64decode(to_decode)\n        parts.append(decoded)\n    return ''.join(parts)", "response": "Decode the bytestring using modified UTF - 7."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format(self, data: Iterable[_FormatArg]) -> bytes:\n        fix_arg = self._fix_format_arg\n        return self.how % tuple(fix_arg(item) for item in data)", "response": "String interpolation into the format string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef join(self, *data: Iterable[MaybeBytes]) -> bytes:\n        return self.how.join([bytes(item) for item in chain(*data)])", "response": "Iterable join on a delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply the filter and return the mailbox where it should be appended and the message to be appended.", "response": "async def apply(self, sender: str, recipient: str, mailbox: str,\n                    append_msg: AppendMessage) \\\n            -> Tuple[Optional[str], AppendMessage]:\n        \"\"\"Run the filter and return the mailbox where it should be appended,\n        or None to discard, and the message to be appended, which is usually\n        the same as ``append_msg``.\n\n        Args:\n            sender: The envelope sender of the message.\n            recipient: The envelope recipient of the message.\n            mailbox: The intended mailbox to append the message.\n            append_msg: The message to be appended.\n\n        raises:\n            :exc:`~pymap.exceptions.AppendFailure`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists the mailboxes owned by the user.", "response": "async def list_mailboxes(self, ref_name: str, filter_: str,\n                             subscribed: bool = False,\n                             selected: SelectedMailbox = None) \\\n            -> Tuple[Iterable[Tuple[str, Optional[str], Sequence[bytes]]],\n                     Optional[SelectedMailbox]]:\n        \"\"\"List the mailboxes owned by the user.\n\n        See Also:\n            `RFC 3501 6.3.8.\n            <https://tools.ietf.org/html/rfc3501#section-6.3.8>`_,\n            `RFC 3501 6.3.9.\n            <https://tools.ietf.org/html/rfc3501#section-6.3.9>`_\n\n        Args:\n            ref_name: Mailbox reference name.\n            filter_: Mailbox name with possible wildcards.\n            subscribed: If True, only list the subscribed mailboxes.\n            selected: If applicable, the currently selected mailbox name.\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_mailbox(self, name: str, selected: SelectedMailbox = None) \\\n            -> Tuple[MailboxInterface, Optional[SelectedMailbox]]:\n        \"\"\"Retrieves a :class:`~pymap.interfaces.mailbox.MailboxInterface`\n        object corresponding to an existing mailbox owned by the user. Raises\n        an exception if the mailbox does not yet exist.\n\n        Args:\n            name: The name of the mailbox.\n            selected: If applicable, the currently selected mailbox name.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n\n        \"\"\"\n        ...", "response": "Retrieves a mailbox object corresponding to the given name and optional selected mailbox."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenames the mailbox owned by the user.", "response": "async def rename_mailbox(self, before_name: str, after_name: str,\n                             selected: SelectedMailbox = None) \\\n            -> Optional[SelectedMailbox]:\n        \"\"\"Renames the mailbox owned by the user.\n\n        See Also:\n            `RFC 3501 6.3.5.\n            <https://tools.ietf.org/html/rfc3501#section-6.3.5>`_\n\n        Args:\n            before_name: The name of the mailbox before the rename.\n            after_name: The name of the mailbox after the rename.\n            selected: If applicable, the currently selected mailbox name.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n            :class:`~pymap.exceptions.MailboxConflict`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend a message to the end of the mailbox.", "response": "async def append_messages(self, name: str,\n                              messages: Sequence[AppendMessage],\n                              selected: SelectedMailbox = None) \\\n            -> Tuple[AppendUid, Optional[SelectedMailbox]]:\n        \"\"\"Appends a message to the end of the mailbox.\n\n        See Also:\n            `RFC 3502 6.3.11.\n            <https://tools.ietf.org/html/rfc3502#section-6.3.11>`_\n\n        Args:\n            name: The name of the mailbox.\n            messages: The messages to append.\n            selected: If applicable, the currently selected mailbox name.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n            :class:`~pymap.exceptions.AppendFailure`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nselecting an existing mailbox owned by the user.", "response": "async def select_mailbox(self, name: str, readonly: bool = False) \\\n            -> Tuple[MailboxInterface, SelectedMailbox]:\n        \"\"\"Selects an existing mailbox owned by the user. The returned session\n        is then used as the ``selected`` argument to other methods to fetch\n        mailbox updates.\n\n        See Also:\n            `RFC 3501 6.3.1.\n            <https://tools.ietf.org/html/rfc3501#section-6.3.1>`_,\n            `RFC 3501 6.3.2.\n            <https://tools.ietf.org/html/rfc3501#section-6.3.2>`_\n\n        Args:\n            name: The name of the mailbox.\n            readonly: True if the mailbox is read-only.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def check_mailbox(self, selected: SelectedMailbox, *,\n                            wait_on: Event = None,\n                            housekeeping: bool = False) -> SelectedMailbox:\n        \"\"\"Checks for any updates in the mailbox.\n\n        If ``wait_on`` is given, this method should block until either this\n        event is signalled or the mailbox has detected updates. This method may\n        be called continuously as long as ``wait_on`` is not signalled.\n\n        If ``housekeeping`` is True, perform any house-keeping necessary by the\n        mailbox backend, which may be a slower operation.\n\n        See Also:\n            `RFC 3501 6.1.2.\n            <https://tools.ietf.org/html/rfc3501#section-6.1.2>`_,\n            `RFC 3501 6.4.1.\n            <https://tools.ietf.org/html/rfc3501#section-6.4.1>`_\n            `RFC 2177 <https://tools.ietf.org/html/rfc2177>`_\n\n        Args:\n            selected: The selected mailbox session.\n            wait_on: If given, block until this event signals.\n            housekeeping: If True, the backend may perform additional\n                housekeeping operations if necessary.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n\n        \"\"\"\n        ...", "response": "Checks if a mailbox has any updates in it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def fetch_messages(self, selected: SelectedMailbox,\n                             sequence_set: SequenceSet,\n                             attributes: FrozenSet[FetchAttribute]) \\\n            -> Tuple[Iterable[Tuple[int, MessageInterface]], SelectedMailbox]:\n        \"\"\"Get a list of loaded message objects corresponding to given sequence\n        set.\n\n        Args:\n            selected: The selected mailbox session.\n            sequence_set: Sequence set of message sequences or UIDs.\n            attributes: Fetch attributes for the messages.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n\n        \"\"\"\n        ...", "response": "Fetch all messages from the selected mailbox session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch the mailbox for messages that meet all of the given search criteria.", "response": "async def search_mailbox(self, selected: SelectedMailbox,\n                             keys: FrozenSet[SearchKey]) \\\n            -> Tuple[Iterable[Tuple[int, MessageInterface]], SelectedMailbox]:\n        \"\"\"Get the messages in the current mailbox that meet all of the\n        given search criteria.\n\n        See Also:\n            `RFC 3501 7.2.5.\n            <https://tools.ietf.org/html/rfc3501#section-7.2.5>`_\n\n        Args:\n            selected: The selected mailbox session.\n            keys: Search keys specifying the message criteria.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies a set of messages into the given mailbox.", "response": "async def copy_messages(self, selected: SelectedMailbox,\n                            sequence_set: SequenceSet,\n                            mailbox: str) \\\n            -> Tuple[Optional[CopyUid], SelectedMailbox]:\n        \"\"\"Copy a set of messages into the given mailbox.\n\n        See Also:\n            `RFC 3501 6.4.7.\n            <https://tools.ietf.org/html/rfc3501#section-6.4.7>`_\n\n        Args:\n            selected: The selected mailbox session.\n            sequence_set: Sequence set of message sequences or UIDs.\n            mailbox: Name of the mailbox to copy messages into.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n            :class:`~pymap.exceptions.MailboxReadOnly`\n\n        \"\"\"\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def update_flags(self, selected: SelectedMailbox,\n                           sequence_set: SequenceSet,\n                           flag_set: FrozenSet[Flag],\n                           mode: FlagOp = FlagOp.REPLACE) \\\n            -> Tuple[Iterable[Tuple[int, MessageInterface]], SelectedMailbox]:\n        \"\"\"Update the flags for the given set of messages.\n\n        See Also:\n            `RFC 3501 6.4.6.\n            <https://tools.ietf.org/html/rfc3501#section-6.4.6>`_\n\n        Args:\n            selected: The selected mailbox session.\n            sequence_set: Sequence set of message sequences or UIDs.\n            flag_set: Set of flags to update.\n            mode: Update mode for the flag set.\n\n        Raises:\n            :class:`~pymap.exceptions.MailboxNotFound`\n            :class:`~pymap.exceptions.MailboxReadOnly`\n\n        \"\"\"\n        ...", "response": "Updates the flags for the given set of messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reduce(cls, requirements: Iterable['FetchRequirement']) \\\n            -> 'FetchRequirement':\n        \"\"\"Reduce a set of fetch requirements into a single requirement.\n\n        Args:\n            requirements: The set of fetch requirements.\n\n        \"\"\"\n        return reduce(lambda x, y: x | y, requirements, cls.NONE)", "response": "Reduce a set of fetch requirements into a single requirement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requirement(self) -> FetchRequirement:\n        key_name = self.key\n        if key_name == b'ALL':\n            return FetchRequirement.NONE\n        elif key_name == b'KEYSET':\n            keyset_reqs = {key.requirement for key in self.filter_key_set}\n            return FetchRequirement.reduce(keyset_reqs)\n        elif key_name == b'OR':\n            left, right = self.filter_key_or\n            key_or_reqs = {left.requirement, right.requirement}\n            return FetchRequirement.reduce(key_or_reqs)\n        elif key_name in (b'SENTBEFORE', b'SENTON', b'SENTSINCE', b'BCC',\n                          b'CC', b'FROM', b'SUBJECT', b'TO', b'HEADER'):\n            return FetchRequirement.HEADERS\n        elif key_name in (b'BODY', b'TEXT', b'LARGER', b'SMALLER'):\n            return FetchRequirement.BODY\n        else:\n            return FetchRequirement.METADATA", "response": "Indicates the data required to fulfill this search key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds and return a new : class : IMAPConfig using command - line arguments.", "response": "def from_args(cls: Type[ConfigT], args: Namespace) -> ConfigT:\n        \"\"\"Build and return a new :class:`IMAPConfig` using command-line\n        arguments.\n\n        Args:\n            args: The arguments parsed from the command-line.\n\n        \"\"\"\n        parsed_args = cls.parse_args(args)\n        return cls(args, host=args.host, port=args.port, debug=args.debug,\n                   reject_insecure_auth=not args.insecure_login,\n                   cert_file=args.cert, key_file=args.key,\n                   **parsed_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef claim_new(self) -> Iterable[str]:\n        new_subdir = self._paths['new']\n        cur_subdir = self._paths['cur']\n        for name in os.listdir(new_subdir):\n            new_path = os.path.join(new_subdir, name)\n            cur_path = os.path.join(cur_subdir, name)\n            try:\n                os.rename(new_path, cur_path)\n            except FileNotFoundError:\n                pass\n            else:\n                yield name.rsplit(self.colon, 1)[0]", "response": "Checks for messages in the new subdirectory moving them to cur and returning their keys."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_message_metadata(self, key: str) -> MaildirMessage:\n        msg = MaildirMessage()\n        subpath = self._lookup(key)\n        subdir, name = os.path.split(subpath)\n        msg.set_subdir(subdir)\n        if self.colon in name:\n            msg.set_info(name.rsplit(self.colon, 1)[-1])\n        msg.set_date(os.path.getmtime(os.path.join(self._path, subpath)))\n        return msg", "response": "Get the metadata for a message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_metadata(self, key: str, msg: MaildirMessage) -> None:\n        subpath = self._lookup(key)\n        subdir, name = os.path.split(subpath)\n        new_subdir = msg.get_subdir()\n        new_name = key + self.colon + msg.get_info()\n        if subdir != new_subdir:\n            raise ValueError('Message subdir may not be updated')\n        elif name != new_name:\n            new_subpath = os.path.join(msg.get_subdir(), new_name)\n            old_path = os.path.join(self._path, subpath)\n            new_path = os.path.join(self._path, new_subpath)\n            os.rename(old_path, new_path)\n            self._toc[key] = new_subpath", "response": "Updates the metadata of the specified message by replacing the original file with the new one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def Append(self, stream) -> None:\n        from .grpc.admin_pb2 import AppendRequest, AppendResponse, \\\n            ERROR_RESPONSE\n        request: AppendRequest = await stream.recv_message()\n        mailbox = request.mailbox or 'INBOX'\n        flag_set = frozenset(Flag(flag) for flag in request.flags)\n        when = datetime.fromtimestamp(request.when, timezone.utc)\n        append_msg = AppendMessage(request.data, flag_set, when,\n                                   ExtensionOptions.empty())\n        try:\n            session = await self._login_as(request.user)\n            if self._with_filter and session.filter_set is not None:\n                filter_value = await session.filter_set.get_active()\n                if filter_value is not None:\n                    filter_ = await session.filter_set.compile(filter_value)\n                    new_mailbox, append_msg = await filter_.apply(\n                        request.sender, request.recipient, mailbox, append_msg)\n                    if new_mailbox is None:\n                        await stream.send_message(AppendResponse())\n                        return\n                    else:\n                        mailbox = new_mailbox\n            append_uid, _ = await session.append_messages(\n                mailbox, [append_msg])\n        except ResponseError as exc:\n            resp = AppendResponse(result=ERROR_RESPONSE,\n                                  error_type=type(exc).__name__,\n                                  error_response=bytes(exc.get_response(b'.')),\n                                  mailbox=mailbox)\n            await stream.send_message(resp)\n        else:\n            validity = append_uid.validity\n            uid = next(iter(append_uid.uids))\n            resp = AppendResponse(mailbox=mailbox, validity=validity, uid=uid)\n            await stream.send_message(resp)", "response": "Append a message to a specific mailbox."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extended(self) -> ListP:\n        parts = [part.extended for part in self.parts]\n        return ListP([_Concatenated(parts), String.build(self.subtype),\n                      _ParamsList(self.content_type_params),\n                      String.build(self.content_disposition),\n                      String.build(self.content_language),\n                      String.build(self.content_location)])", "response": "The body structure attributes with extension data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies the flag operation on the two sets returning the result.", "response": "def apply(self, flag_set: AbstractSet[Flag], operand: AbstractSet[Flag]) \\\n            -> FrozenSet[Flag]:\n        \"\"\"Apply the flag operation on the two sets, returning the result.\n\n        Args:\n            flag_set: The flag set being operated on.\n            operand: The flags to use as the operand.\n\n        \"\"\"\n        if self == FlagOp.ADD:\n            return frozenset(flag_set | operand)\n        elif self == FlagOp.DELETE:\n            return frozenset(flag_set - operand)\n        else:  # op == FlagOp.REPLACE\n            return frozenset(operand)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef intersect(self, other: Iterable[Flag]) -> FrozenSet[Flag]:\n        if Wildcard in self._defined:\n            return frozenset(other)\n        else:\n            return self._defined & frozenset(other)", "response": "Returns the subset of flags in self that are also in\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the set of flags for the mailbox session.", "response": "def get(self, uid: int) -> FrozenSet[Flag]:\n        \"\"\"Return the session flags for the mailbox session.\n\n        Args:\n            uid: The message UID value.\n\n        \"\"\"\n        recent = _recent_set if uid in self._recent else frozenset()\n        flags = self._flags.get(uid)\n        return recent if flags is None else (flags | recent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, uids: Iterable[int]) -> None:\n        for uid in uids:\n            self._recent.discard(uid)\n            self._flags.pop(uid, None)", "response": "Removes any flags for the given message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, uid: int, flag_set: Iterable[Flag],\n               op: FlagOp = FlagOp.REPLACE) -> FrozenSet[Flag]:\n        \"\"\"Update the flags for the session, returning the resulting flags.\n\n        Args:\n            uid: The message UID value.\n            flag_set: The set of flags for the update operation.\n            op: The type of update.\n\n        \"\"\"\n        orig_set = self._flags.get(uid, frozenset())\n        new_flags = op.apply(orig_set, self & flag_set)\n        if new_flags:\n            self._flags[uid] = new_flags\n        else:\n            self._flags.pop(uid, None)\n        return new_flags", "response": "Updates the flags for the specified message UID value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_system_flags() -> FrozenSet[Flag]:\n    return frozenset({Seen, Recent, Deleted, Flagged, Answered, Draft})", "response": "Return the set of implemented system flags."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a new IMAP command.", "response": "def register(self, cmd: Type[Command]) -> None:\n        \"\"\"Register a new IMAP command.\n\n        Args:\n            cmd: The new command type.\n\n        \"\"\"\n        self.commands[cmd.command] = cmd"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, buf: memoryview, params: Params) \\\n            -> Tuple[Command, memoryview]:\n        \"\"\"Parse the given bytes into a command. The basic syntax is a tag\n        string, a command name, possibly some arguments, and then an endline.\n        If the command has a complete structure but cannot be parsed, an\n        :class:`InvalidCommand` is returned.\n\n        Args:\n            buf: The bytes to parse.\n            params: The parsing parameters.\n\n        \"\"\"\n        try:\n            tag, buf = Tag.parse(buf, params)\n        except NotParseable as exc:\n            return InvalidCommand(params, exc), buf[0:0]\n        else:\n            params = params.copy(tag=tag.value)\n        cmd_parts: List[bytes] = []\n        while True:\n            try:\n                _, buf = Space.parse(buf, params)\n                atom, buf = Atom.parse(buf, params)\n                cmd_parts.append(atom.value.upper())\n            except NotParseable as exc:\n                return InvalidCommand(params, exc), buf[0:0]\n            command = b' '.join(cmd_parts)\n            cmd_type = self.commands.get(command)\n            if not cmd_type:\n                return InvalidCommand(params, None, command), buf[0:0]\n            elif not cmd_type.compound:\n                break\n        params = params.copy(command_name=command)\n        try:\n            return cmd_type.parse(buf, params)\n        except NotParseable as exc:\n            return InvalidCommand(params, exc, command, cmd_type), buf[0:0]", "response": "Parses the given bytes into a command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a string from the contents of the data.", "response": "def build(cls, value: object, binary: bool = False,\n              fallback: object = None) -> Union[Nil, 'String']:\n        \"\"\"Produce either a :class:`QuotedString` or :class:`LiteralString`\n        based on the contents of ``data``. This is useful to improve\n        readability of response data.\n\n        Args:\n            value: The string to serialize.\n            binary: True if the string should be transmitted as binary.\n            fallback: The default value to use if ``value`` is None.\n\n        \"\"\"\n        if value is None:\n            if fallback is None:\n                return Nil()\n            else:\n                return cls.build(fallback, binary)\n        elif not value:\n            return QuotedString(b'')\n        elif isinstance(value, bytes):\n            ascii_ = value\n        elif isinstance(value, memoryview):\n            ascii_ = bytes(value)\n        elif hasattr(value, '__bytes__'):\n            ascii_ = bytes(cast(SupportsBytes, value))\n        elif isinstance(value, str) or hasattr(value, '__str__'):\n            value = str(value)\n            try:\n                ascii_ = bytes(value, 'ascii')\n            except UnicodeEncodeError:\n                ascii_ = bytes(value, 'utf-8', 'replace')\n                return LiteralString(ascii_, binary)\n        else:\n            raise TypeError(value)\n        if not binary and len(ascii_) < 64 \\\n                and b'\\n' not in ascii_ \\\n                and b'\\x00' not in ascii_:\n            return QuotedString(ascii_)\n        else:\n            return LiteralString(ascii_, binary)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_as(self, cls: Type[MaybeBytesT]) -> Sequence[MaybeBytesT]:\n        _ = cls  # noqa\n        return cast(Sequence[MaybeBytesT], self.items)", "response": "Return the list of parsed objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all(self, attrs: Iterable[FetchAttribute]) \\\n            -> Sequence[Tuple[FetchAttribute, MaybeBytes]]:\n        \"\"\"Return a list of tuples containing the attribute iself and the bytes\n        representation of that attribute from the message.\n\n        Args:\n            attrs: The fetch attributes.\n\n        \"\"\"\n        ret: List[Tuple[FetchAttribute, MaybeBytes]] = []\n        for attr in attrs:\n            try:\n                ret.append((attr.for_response, self.get(attr)))\n            except NotFetchable:\n                pass\n        return ret", "response": "Returns a list of tuples containing the attribute iself and the bytes\n        representation of that attribute from the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the bytes representation of the given message attribue.", "response": "def get(self, attr: FetchAttribute) -> MaybeBytes:\n        \"\"\"Return the bytes representation of the given message attribue.\n\n        Args:\n            attr: The fetch attribute.\n\n        Raises:\n            :class:`NotFetchable`\n\n        \"\"\"\n        attr_name = attr.value.decode('ascii')\n        method = getattr(self, '_get_' + attr_name.replace('.', '_'))\n        return method(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef of(cls, key: SearchKey, params: SearchParams) -> 'SearchCriteria':\n        key_name = key.value\n        if key_name in params.disabled:\n            raise SearchNotAllowed(key_name)\n        elif key.inverse:\n            return InverseSearchCriteria(key.not_inverse, params)\n        elif key_name == b'SEQSET':\n            return SequenceSetSearchCriteria(key.filter_sequence_set, params)\n        elif key_name == b'KEYSET':\n            return SearchCriteriaSet(key.filter_key_set, params)\n        elif key_name == b'ALL':\n            return AllSearchCriteria(params)\n        elif key_name == b'OR':\n            left_key, right_key = key.filter_key_or\n            return OrSearchCriteria(left_key, right_key, params)\n        elif key_name == b'ANSWERED':\n            return HasFlagSearchCriteria(Answered, True, params)\n        elif key_name == b'UNANSWERED':\n            return HasFlagSearchCriteria(Answered, False, params)\n        elif key_name == b'DELETED':\n            return HasFlagSearchCriteria(Deleted, True, params)\n        elif key_name == b'UNDELETED':\n            return HasFlagSearchCriteria(Deleted, False, params)\n        elif key_name == b'DRAFT':\n            return HasFlagSearchCriteria(Draft, True, params)\n        elif key_name == b'UNDRAFT':\n            return HasFlagSearchCriteria(Draft, False, params)\n        elif key_name == b'FLAGGED':\n            return HasFlagSearchCriteria(Flagged, True, params)\n        elif key_name == b'UNFLAGGED':\n            return HasFlagSearchCriteria(Flagged, False, params)\n        elif key_name == b'RECENT':\n            return HasFlagSearchCriteria(Recent, True, params)\n        elif key_name == b'OLD':\n            return HasFlagSearchCriteria(Recent, False, params)\n        elif key_name == b'SEEN':\n            return HasFlagSearchCriteria(Seen, True, params)\n        elif key_name == b'UNSEEN':\n            return HasFlagSearchCriteria(Seen, False, params)\n        elif key_name == b'KEYWORD':\n            return HasFlagSearchCriteria(key.filter_flag, True, params)\n        elif key_name == b'UNKEYWORD':\n            return HasFlagSearchCriteria(key.filter_flag, False, params)\n        elif key_name == b'NEW':\n            return NewSearchCriteria(params)\n        elif key_name == b'BEFORE':\n            return DateSearchCriteria(key.filter_datetime, '<', params)\n        elif key_name == b'ON':\n            return DateSearchCriteria(key.filter_datetime, '=', params)\n        elif key_name == b'SINCE':\n            return DateSearchCriteria(key.filter_datetime, '>=', params)\n        elif key_name == b'SENTBEFORE':\n            return HeaderDateSearchCriteria(key.filter_datetime, '<', params)\n        elif key_name == b'SENTON':\n            return HeaderDateSearchCriteria(key.filter_datetime, '=', params)\n        elif key_name == b'SENTSINCE':\n            return HeaderDateSearchCriteria(key.filter_datetime, '>=', params)\n        elif key_name == b'SMALLER':\n            return SizeSearchCriteria(key.filter_int, '<', params)\n        elif key_name == b'LARGER':\n            return SizeSearchCriteria(key.filter_int, '>', params)\n        elif key_name in (b'BCC', b'CC', b'FROM', b'SUBJECT', b'TO'):\n            return EnvelopeSearchCriteria(key_name, key.filter_str, params)\n        elif key_name == b'HEADER':\n            name, value = key.filter_header\n            return HeaderSearchCriteria(name, value, params)\n        elif key_name in (b'BODY', b'TEXT'):\n            return BodySearchCriteria(key.filter_str, params)\n        raise SearchNotAllowed(key_name)", "response": "Returns a new instance of the appropriate search criteria subclass."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sequence_set(self) -> SequenceSet:\n        try:\n            seqset_crit = next(crit for crit in self.all_criteria\n                               if isinstance(crit, SequenceSetSearchCriteria))\n        except StopIteration:\n            return SequenceSet.all()\n        else:\n            return seqset_crit.seq_set", "response": "The sequence set that will be used when finding the messages to match against."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate through the message and all its nested sub - parts in the order they occur.", "response": "def walk(self) -> Iterable['MessageContent']:\n        \"\"\"Iterate through the message and all its nested sub-parts in the\n        order they occur.\n\n        \"\"\"\n        if self.body.has_nested:\n            return chain([self], *(part.walk() for part in self.body.nested))\n        else:\n            return [self]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_rfc822(self) -> bool:\n        ct_hdr = self.header.parsed.content_type\n        if ct_hdr is None:\n            return False\n        else:\n            return ct_hdr.content_type == 'message/rfc822'", "response": "True if the content - type of the message is RFC822."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the bytestring into a MessageContent object.", "response": "def parse(cls, data: bytes) -> 'MessageContent':\n        \"\"\"Parse the bytestring into message content.\n\n        Args:\n            data: The bytestring to parse.\n\n        \"\"\"\n        lines = cls._find_lines(data)\n        view = memoryview(data)\n        return cls._parse(data, view, lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the header and body bytestrings into message content.", "response": "def parse_split(cls, header: bytes, body: bytes) -> 'MessageContent':\n        \"\"\"Parse the header and body bytestrings into message content.\n\n        Args:\n            header: The header bytestring to parse.\n            body: The body bytestring to parse.\n\n        \"\"\"\n        header_lines = cls._find_lines(header)\n        body_lines = cls._find_lines(body)\n        header_view = memoryview(header)\n        body_view = memoryview(body)\n        return cls._parse_split([header_view, body_view], header, body,\n                                header_view, body_view,\n                                header_lines, body_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the object to the output stream.", "response": "def write(self, writer: WriteStream) -> None:\n        \"\"\"Write the object to the stream, with one or more calls to\n        :meth:`~pymap.bytes.WriteStream.write`.\n\n        Args:\n            writer: The output stream.\n\n        \"\"\"\n        for part in self._raw:\n            writer.write(bytes(part))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all(self, uids: Iterable[int]) -> Mapping[int, Record]:\n        return {uid: self._records[uid] for uid in uids\n                if uid in self._records}", "response": "Get all records by a set of UIDs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spell(word):\n    w = Word(word)\n    candidates = (common([word]) or exact([word]) or known([word]) or\n                  known(w.typos()) or common(w.double_typos()) or\n                  [word])\n    correction = max(candidates, key=NLP_COUNTS.get)\n    return get_case(word, correction)", "response": "most likely correction for a word"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef words_from_archive(filename, include_dups=False, map_case=False):\n    bz2 = os.path.join(PATH, BZ2)\n    tar_path = '{}/{}'.format('words', filename)\n    with closing(tarfile.open(bz2, 'r:bz2')) as t:\n        with closing(t.extractfile(tar_path)) as f:\n            words = re.findall(RE, f.read().decode(encoding='utf-8'))\n    if include_dups:\n        return words\n    elif map_case:\n        return {w.lower():w for w in words}\n    else:\n        return set(words)", "response": "extract words from a text file in the archive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntallying word popularity using novel extracts etc", "response": "def parse(lang_sample):\n    \"\"\"tally word popularity using novel extracts, etc\"\"\"\n    words = words_from_archive(lang_sample, include_dups=True)\n    counts = zero_default_dict()\n    for word in words:\n        counts[word] += 1\n    return set(words), counts"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_case(word, correction):\n    if word.istitle():\n        return correction.title()\n    if word.isupper():\n        return correction.upper()\n    if correction == word and not word.islower():\n        return word\n    if len(word) > 2 and word[:2].isupper():\n        return correction.title()\n    if not known_as_lower([correction]): #expensive\n        try:\n            return CASE_MAPPED[correction]\n        except KeyError:\n            pass\n    return correction", "response": "Returns the best guess of intended case."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples that are transposed by the caller.", "response": "def _transposes(self):\n        \"\"\"teh\"\"\"\n        return {concat(a, reversed(b[:2]), b[2:])\n                for a, b in self.slices[:-2]}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of all the keys that are replaced by the values in self.", "response": "def _replaces(self):\n        \"\"\"tge\"\"\"\n        return {concat(a, c, b[1:])\n                for a, b in self.slices[:-1]\n                for c in ALPHABET}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples that are inserted into the database.", "response": "def _inserts(self):\n        \"\"\"thwe\"\"\"\n        return {concat(a, c, b)\n                for a, b in self.slices\n                for c in ALPHABET}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef typos(self):\n        return (self._deletes() | self._transposes() |\n                self._replaces() | self._inserts())", "response": "letter combinations one typo away from word"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef double_typos(self):\n        return {e2 for e1 in self.typos()\n                for e2 in Word(e1).typos()}", "response": "letter combinations two typos away from word"}
