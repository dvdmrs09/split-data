{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef participating_ec_states(self):\n        '''The state of each execution context this component is participating\n        in.\n\n        '''\n        with self._mutex:\n            if not self._participating_ec_states:\n                if self.participating_ecs:\n                    states = []\n                    for ec in self.participating_ecs:\n                        states.append(self._get_ec_state(ec))\n                    self._participating_ec_states = states\n                else:\n                    self._participating_ec_states = []\n        return self._participating_ec_states", "response": "The state of each execution context this component is participating\n        in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef participating_ecs(self):\n        '''A list of the execution contexts this component is participating in.\n\n        '''\n        with self._mutex:\n            if not self._participating_ecs:\n                self._participating_ecs = [ExecutionContext(ec,\n                                    self._obj.get_context_handle(ec)) \\\n                             for ec in self._obj.get_participating_contexts()]\n        return self._participating_ecs", "response": "A list of the execution contexts this component is participating in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef state(self):\n        '''The merged state of all the execution context states, which can be\n        used as the overall state of this component.\n\n        The order of precedence is:\n            Error > Active > Inactive > Created > Unknown\n\n        '''\n        def merge_state(current, new):\n            if new == self.ERROR:\n                return self.ERROR\n            elif new == self.ACTIVE and current != self.ERROR:\n                return self.ACTIVE\n            elif new == self.INACTIVE and \\\n                    current not in [self.ACTIVE, self.ERROR]:\n                return self.INACTIVE\n            elif new == self.CREATED and \\\n                    current not in [self.ACTIVE, self.ERROR, self.INACTIVE]:\n                return self.CREATED\n            elif current not in [self.ACTIVE, self.ERROR, self.INACTIVE,\n                                 self.CREATED]:\n                return self.UNKNOWN\n            return current\n\n        with self._mutex:\n            if not self.owned_ec_states and not self.participating_ec_states:\n                return self.UNKNOWN\n            merged_state = self.CREATED\n            if self.owned_ec_states:\n                for ec_state in self.owned_ec_states:\n                    merged_state = merge_state(merged_state, ec_state)\n            if self.participating_ec_states:\n                for ec_state in self.participating_ec_states:\n                    merged_state = merge_state(merged_state, ec_state)\n            return merged_state", "response": "Returns the merged state of all the execution context states which can be used as the overall state of this component."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a reference to the ExtendedFsmService object", "response": "def get_extended_fsm_service(self):\n        '''Get a reference to the ExtendedFsmService.\n\n        @return A reference to the ExtendedFsmService object\n        @raises InvalidSdoServiceError\n\n        '''\n        with self._mutex:\n            try:\n                return self._obj.get_sdo_service(RTC.ExtendedFsmService._NP_RepositoryId)._narrow(RTC.ExtendedFsmService)\n            except:\n                raise exceptions.InvalidSdoServiceError('ExtendedFsmService')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a port of this component by name.", "response": "def get_port_by_name(self, port_name):\n        '''Get a port of this component by name.'''\n        with self._mutex:\n            for p in self.ports:\n                if p.name == port_name:\n                    return p\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a port of this component by reference to a CORBA PortService object.", "response": "def get_port_by_ref(self, port_ref):\n        '''Get a port of this component by reference to a CORBA PortService\n        object.\n\n        '''\n        with self._mutex:\n            for p in self.ports:\n                if p.object._is_equivalent(port_ref):\n                    return p\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_port_by_name(self, port_name):\n        '''Check if this component has a port by the given name.'''\n        with self._mutex:\n            if self.get_port_by_name(port_name):\n                return True\n            return False", "response": "Check if this component has a port by the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if this component has a port by the given reference to a CORBA PortService object.", "response": "def has_port_by_ref(self, port_ref):\n        '''Check if this component has a port by the given reference to a CORBA\n        PortService object.\n\n        '''\n        with self._mutex:\n            if self.get_port_by_ref(self, port_ref):\n                return True\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connected_svcports(self):\n        '''The list of all service ports belonging to this component that are\n        connected to one or more other ports.\n\n        '''\n        return [p for p in self.ports \\\n                if p.__class__.__name__ == 'CorbaPort' and p.is_connected]", "response": "The list of all service ports connected to one or more other ports."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ports(self):\n        '''The list of all ports belonging to this component.'''\n        with self._mutex:\n            if not self._ports:\n                self._ports = [ports.parse_port(port, self) \\\n                               for port in self._obj.get_ports()]\n        return self._ports", "response": "The list of all ports belonging to this component."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_logger(self, cb, level='NORMAL', filters='ALL'):\n        '''Add a callback to receive log events from this component.\n\n        @param cb The callback function to receive log events. It must have the\n            signature cb(name, time, source, level, message), where name is the\n            name of the component the log record came from, time is a\n            floating-point time stamp, source is the name of the logger that\n            provided the log record, level is the log level of the record and\n            message is a text string.\n        @param level The maximum level of log records to receive.\n        @param filters Filter the objects from which to receive log messages.\n        @return An ID for this logger. Use this ID in future operations such as\n                removing this logger.\n        @raises AddLoggerError\n\n        '''\n        with self._mutex:\n            obs = sdo.RTCLogger(self, cb)\n            uuid_val = uuid.uuid4()\n            intf_type = obs._this()._NP_RepositoryId\n            props = {'logger.log_level': level,\n                    'logger.filter': filters}\n            props = utils.dict_to_nvlist(props)\n            sprof = SDOPackage.ServiceProfile(id=uuid_val.get_bytes(),\n                    interface_type=intf_type, service=obs._this(),\n                    properties=props)\n            conf = self.object.get_configuration()\n            res = conf.add_service_profile(sprof)\n            if res:\n                self._loggers[uuid_val] = obs\n                return uuid_val\n            raise exceptions.AddLoggerError(self.name)", "response": "Add a callback to receive log events from this component."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a logger from the log.", "response": "def remove_logger(self, cb_id):\n        '''Remove a logger.\n\n        @param cb_id The ID of the logger to remove.\n        @raises NoLoggerError\n\n        '''\n        if cb_id not in self._loggers:\n            raise exceptions.NoLoggerError(cb_id, self.name)\n        conf = self.object.get_configuration()\n        res = conf.remove_service_profile(cb_id.get_bytes())\n        del self._loggers[cb_id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nactivates a configuration set by name.", "response": "def activate_conf_set(self, set_name):\n        '''Activate a configuration set by name.\n\n        @raises NoSuchConfSetError\n\n        '''\n        with self._mutex:\n            if not set_name in self.conf_sets:\n                raise exceptions.NoSuchConfSetError(set_name)\n            self._conf.activate_configuration_set(set_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_conf_set_value(self, set_name, param, value):\n        '''Set a configuration set parameter value.\n\n        @param set_name The name of the configuration set the destination\n                        parameter is in.\n        @param param The name of the parameter to set.\n        @param value The new value for the parameter.\n        @raises NoSuchConfSetError, NoSuchConfParamError\n\n        '''\n        with self._mutex:\n            if not set_name in self.conf_sets:\n                raise exceptions.NoSuchConfSetError(set_name)\n            if not self.conf_sets[set_name].has_param(param):\n                raise exceptions.NoSuchConfParamError(param)\n            self.conf_sets[set_name].set_param(param, value)\n            self._conf.set_configuration_set_values(\\\n                    self.conf_sets[set_name].object)", "response": "Set a configuration set parameter value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef active_conf_set(self):\n        '''The currently-active configuration set.'''\n        with self._mutex:\n            if not self.conf_sets:\n                return None\n            if not self._active_conf_set:\n                return None\n            return self.conf_sets[self._active_conf_set]", "response": "The currently - active configuration set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_condition(statement, condition, key, value):\n    if isinstance(statement, list):\n        statement.append({condition: {key: value}})\n    if isinstance(statement, dict):\n        statement[condition] = {key: value}", "response": "Append a condition to a list of log entries in the log statement."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing an Elasticsearch client by specified hosts list.", "response": "def from_normal(self, hosts=default.ELASTICSEARCH_HOSTS, **kwargs):\n        \"\"\"\n        Initialize a Elasticsearch client by specified hosts list.\n\n        :param hosts: list of nodes we should connect to. Node should be a\n            dictionary ({\"host\": \"localhost\", \"port\": 9200}), the entire dictionary\n            will be passed to the :class:`~elasticsearch.Connection` class as\n            kwargs, or a string in the format of ``host[:port]`` which will be\n            translated to a dictionary automatically.  If no value is given the\n            :class:`~elasticsearch.Urllib3HttpConnection` class defaults will be used\n\n        :return: void\n        \"\"\"\n        self.client = Elasticsearch(hosts=hosts, **kwargs)\n        logger.info('Initialize normal Elasticsearch Client: %s.' % self.client)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize an Elasticsearch client for use with sniffing.", "response": "def from_sniffing(self,\n                      active_nodes,\n                      sniff_on_start=True,\n                      sniff_on_connection_fail=True,\n                      sniffer_timeout=60, **kwargs):\n        \"\"\"\n        Initialize a Elasticsearch client for specify to sniff on startup to\n        inspect the cluster and load balance across all nodes.\n        The client can be configured to inspect the cluster state to get\n        a list of nodes upon startup, periodically and/or on failure.\n\n        :param active_nodes: the list of active nodes\n        :param sniff_on_start: flag indicating whether to obtain a list of nodes\n            from the cluser at startup time\n        :param sniff_on_connection_fail: flag controlling if connection failure triggers a sniff\n        :param sniffer_timeout: number of seconds between automatic sniffs\n        :return: void\n        \"\"\"\n        self.client = Elasticsearch(active_nodes,\n                                    sniff_on_start=sniff_on_start,\n                                    sniff_on_connection_fail=sniff_on_connection_fail,\n                                    sniffer_timeout=sniffer_timeout, **kwargs)\n        logger.info('Initialize sniffing Elasticsearch Client: %s.' % self.client)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_ssl(self,\n                 ca_certs,\n                 client_cert,\n                 client_key,\n                 hosts=default.ELASTICSEARCH_HOSTS,\n                 use_ssl=True,\n                 verify_certs=True, **kwargs):\n        \"\"\"\n        Initialize a Elasticsearch client by SSL.\n\n        :param ca_certs: optional path to CA bundle. See\n        https://urllib3.readthedocs.io/en/latest/security.html#using-certifi-with-urllib3\n        :param client_cert: path to the file containing the private key and the\n        certificate, or cert only if using client_key\n        :param client_key: path to the file containing the private key if using\n        separate cert and key files (client_cert will contain only the cert)\n        :param hosts: hostname of the node\n        :param use_ssl: use ssl for the connection if `True`\n        :param verify_certs: whether to verify SSL certificates\n        :return: void\n        \"\"\"\n        self.client = Elasticsearch(hosts=hosts,\n                                    use_ssl=use_ssl,\n                                    verify_certs=verify_certs,\n                                    ca_certs=ca_certs,\n                                    client_cert=client_cert,\n                                    client_key=client_key, **kwargs)\n        logger.info('Initialize SSL Elasticsearch Client: %s.' % self.client)", "response": "Initialize an Elasticsearch client by SSL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transfer_data_from_mongo(self,\n                                 index,\n                                 doc_type,\n                                 use_mongo_id=False,\n                                 indexed_flag_field_name='',\n                                 mongo_query_params={},\n                                 mongo_host=default.MONGO_HOST,\n                                 mongo_port=default.MONGO_PORT,\n                                 mongo_db=default.MONGO_DB,\n                                 mongo_collection=default.MONGO_COLLECTION):\n        \"\"\"\n        Transfer data from MongoDB into the Elasticsearch, the hostname, port, database and\n        collection name in MongoDB default from load in default.py\n\n        :param index: The name of the index\n        :param doc_type: The type of the document\n        :param use_mongo_id: Use id of MongoDB in the Elasticsearch if is true otherwise automatic generation\n        :param indexed_flag_field_name: the name of the field of the document,\n                    if associated value is False will synchronize data for it\n        :param mongo_client_params: The dictionary for client params of MongoDB\n        :param mongo_query_params: The dictionary for query params of MongoDB\n        :param mongo_host: The name of the hostname from MongoDB\n        :param mongo_port: The number of the port from MongoDB\n        :param mongo_db: The name of the database from MongoDB\n        :param mongo_collection: The name of the collection from MongoDB\n        :return: void\n        \"\"\"\n        mongo_client = MongoClient(host=mongo_host, port=int(mongo_port))\n        try:\n            collection = mongo_client[mongo_db][mongo_collection]\n            if indexed_flag_field_name != '':\n                mongo_query_params.update({indexed_flag_field_name: False})\n            mongo_docs = collection.find(mongo_query_params)\n        finally:\n            mongo_client.close()\n        # Joint actions of Elasticsearch for execute bulk api\n        actions = []\n        id_array = []\n        for doc in mongo_docs:\n            action = {\n                '_op_type': 'index',\n                '_index': index,\n                '_type': doc_type\n            }\n            id_array.append(doc['_id'])\n            if not use_mongo_id:\n                doc.pop('_id')\n            else:\n                doc['id'] = str(doc['_id'])\n                doc.pop('_id')\n            action['_source'] = doc\n            actions.append(action)\n        success, failed = es_helpers.bulk(self.client, actions, request_timeout=60 * 60)\n        logger.info(\n            'Transfer data from MongoDB(%s:%s) into the Elasticsearch(%s) success: %s, failed: %s' % (\n                mongo_host, mongo_port, self.client, success, failed))\n\n        # Back update flag\n        if indexed_flag_field_name != '':\n            t = threading.Thread(target=ElasticsearchClient._back_update_mongo,\n                                 args=(self, mongo_host, mongo_port, mongo_db, mongo_collection, id_array,\n                                       {indexed_flag_field_name: True}),\n                                 name='mongodb_back_update')\n            t.start()\n        return success, failed", "response": "Transfer data from MongoDB into Elasticsearch"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bulk(self, actions, stats_only=False, **kwargs):\n        success, failed = es_helpers.bulk(self.client, actions, stats_only, **kwargs)\n        logger.info('Bulk is done success %s failed %s actions: \\n %s' % (success, failed, actions))", "response": "Executes bulk api by elasticsearch. helpers. bulk.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef automatic_syn_data_from_mongo(self,\n                                      index,\n                                      doc_type,\n                                      indexed_flag_field_name,\n                                      thread_name='automatic_syn_data_thread',\n                                      interval=60,\n                                      use_mongo_id=False,\n                                      mongo_query_params={},\n                                      mongo_host=default.MONGO_HOST,\n                                      mongo_port=default.MONGO_PORT,\n                                      mongo_db=default.MONGO_DB,\n                                      mongo_collection=default.MONGO_COLLECTION):\n        \"\"\"\n        Automatic synchronize data that from MongoDB into the Elasticsearch by schedule task,\n        it will synchronize this data if the indexed_flag_field_name of the field of the document is False.\n        Noteworthy that the function may be no good please you caution use it.\n\n        :param indexed_flag_field_name: the name of the field of the document,\n                    if associated value is False will synchronize data for it\n        :param thread_name: the name of the schedule task thread\n        :param interval: the time that executes interval of the scheduled task every time (unit second)\n        :return: the thread id, you can use this id to cancel associated task\n        \"\"\"\n        thread_id = self._generate_thread_id(thread_name)\n        if thread_id in ElasticsearchClient.automatic_syn_data_flag:\n            lock.acquire()\n            try:\n                thread_name = thread_name + '-%s' % ElasticsearchClient.automatic_thread_name_counter\n                ElasticsearchClient.automatic_thread_name_counter += 1\n                thread_id = self._generate_thread_id(thread_name)\n            finally:\n                lock.release()\n        ElasticsearchClient.automatic_syn_data_flag[thread_id] = True\n\n        t = threading.Thread(target=ElasticsearchClient._automatic_syn_data_from_mongo_worker,\n                             args=(self, thread_id, index, doc_type,\n                                   indexed_flag_field_name, interval, use_mongo_id,\n                                   mongo_query_params,\n                                   mongo_host, mongo_port,\n                                   mongo_db, mongo_collection),\n                             name=thread_name)\n\n        t.start()\n        return thread_id", "response": "This function will synchronize data that from MongoDB into Elasticsearch by schedule task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_simple_info_for_index(self, index=None, params={}, **kwargs):\n        raw = self.client.cat.indices(index, params=params, **kwargs).split('\\n')\n        list = []\n        for r in raw:\n            alter = r.split(' ')\n            if len(alter) < 10: continue\n            dict = {\n                'health': alter[0],\n                'status': alter[1],\n                'index': alter[2],\n            }\n            if len(alter) == 11:\n                # May appear split fail (alter[3] is a empty string)\n                dict['uuid'] = alter[4]\n                i = 5\n            else:\n                dict['uuid'] = alter[3]\n                i = 4\n            dict['pri'] = alter[i]\n            i += 1\n            dict['rep'] = alter[i]\n            i += 1\n            dict['docs_count'] = alter[i]\n            i += 1\n            dict['docs_deleted'] = alter[i]\n            i += 1\n            dict['store_size'] = alter[i]\n            i += 1\n            dict['pri_store_size'] = alter[i]\n            list.append(dict)\n        logger.info('Acquire simple information of the index is done succeeded: %s' % len(list))\n        return list", "response": "Return a list of simple info for the specified index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cluster_health_for_indices(self, index=None, params={}, **kwargs):\n        params['level'] = 'indices'\n        result = self.cluster_health(index, params, **kwargs)\n        return self._process_cluster_health_info(result)", "response": "Returns a list of cluster health information for the specified indices"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cluster_health_for_shards(self, index=None, params={}, **kwargs):\n        params['level'] = 'shards'\n        result = self.cluster_health(index, params, **kwargs)\n        return self._process_cluster_health_info(result)", "response": "Returns a list of cluster health of specified indices and append shards information of each index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of the nodes simple info that key is a column name and that value is a column name such as 127. 1111. 1111.", "response": "def nodes_simple_info(self, params={}, **kwargs):\n        \"\"\"\n        Return a dictionary of the nodes simple info that key is a column name,\n        such as [{\"http_address\": \"192.111.111.111\", \"name\" : \"test\", ...}, ...]\n        \"\"\"\n        h = ['name', 'pid', 'http_address', 'version', 'jdk', 'disk.total', 'disk.used_percent', 'heap.current',\n             'heap.percent', 'ram.current', 'ram.percent', 'uptime', 'node.role']\n        result = self.client.cat.nodes(v=True, h=h, **kwargs, params=params)\n        result = [x.strip().split(' ') for x in result.split('\\n')]\n        # Clean up the space\n        result.remove(result[-1])\n        for i in range(len(result)):\n            result[i] = list(filter(lambda x: x != '', result[i]))\n        # Packing into the dictionary\n        dicts = []\n        for i in range(len(result) - 1):\n            dict = {}\n            for k, v in zip(result[0], result[i + 1]):\n                dict[k] = v\n            dicts.append(dict)\n\n        logger.info('Acquire simple information of the nodes is done succeeded: %s' % len(dicts))\n        return dicts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread and return a sequence of lines that represent a single FASTA query record.", "response": "def __read_single_fasta_query_lines(f):\n    '''\n    Read and return sequence of lines (including newlines) that\n    represent a single FASTA query record. The provided file is\n    expected to be blocking.\n\n    Returns None if there are no more query sequences in the file.\n    '''\n\n    def readline():\n        l = f.readline()\n        if l == '':\n            raise EOFError()\n        return l\n\n    rec = None\n    try:\n        l = readline()\n        assert l.startswith('>')\n\n        rec = [l]\n        while True:\n            pos = f.tell()\n            l = readline()\n            if l.startswith('>'):\n                f.seek(pos, 0)\n                break\n            rec += [l]\n    except EOFError:\n        pass\n\n    return rec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __read_single_query_result(rs, field_names):\n    '''\n    Read the result of a single query from the given string,\n    returning a tuple of (record, remaining-string). If no complete\n    record could be read, the first element of the tuple is None and\n    the second element is the original imput string.\n    '''\n\n    rf = StringIO.StringIO(rs)\n\n    def readline():\n        l = rf.readline()\n        if not l.endswith('\\n'):\n            raise EOFError()\n        return l.strip()\n\n    result = Result()\n\n    try:\n        l = readline()\n        assert l.startswith('# BLAST')\n\n        l = readline()\n        assert l.startswith('# Query: ')\n        query_str = l[len('# Query: '):].strip()\n        if query_str:\n            if ' ' in query_str:\n                result.id, result.description = [\n                    s.strip() for s in query_str.split(' ', 1)]\n            else:\n                result.id = query_str\n\n        l = readline()\n        assert l.startswith('# Database: ')\n\n        l = readline()\n        if l.startswith('# Fields: '):\n            fns = l[len('# Fields: '):].split(', ')\n            assert len(field_names) == len(fns)\n            l = readline()\n\n        assert l.endswith(' hits found')\n        nhits = int(l[len('# '):-1 * len(' hits found')])\n\n        while nhits > 0:\n            l = readline()\n            field_vals = l.split('\\t')\n            assert len(field_vals) == len(field_names)\n\n            fields = dict(zip(field_names, field_vals))\n            result.hits.append(Hit(fields))\n            nhits -= 1\n\n        return result, rf.read()\n    except EOFError:\n        return None, rs", "response": "Read the result of a single query from the given string returning a tuple of ( record remaining - string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __run_blast_select_loop(input_file, popens, fields):\n    '''\n    Run the select(2) loop to handle blast I/O to the given set of Popen\n    objects.\n\n    Yields records back that have been read from blast processes.\n    '''\n\n    def make_nonblocking(f):\n        fl = fcntl.fcntl(f.fileno(), fcntl.F_GETFL)\n        fl |= os.O_NONBLOCK\n        fcntl.fcntl(f.fileno(), fcntl.F_SETFL, fl)\n\n    rfds = set()\n    wfds = set()\n    fd_map = {}\n\n    for p in popens:\n        make_nonblocking(p.stdout)\n        rfds.add(p.stdout.fileno())\n        fd_map[p.stdout.fileno()] = {\n            'popen': p,\n            'query_buffer': '',\n            'result_buffer': ''}\n\n        make_nonblocking(p.stdin)\n        wfds.add(p.stdin.fileno())\n        fd_map[p.stdin.fileno()] = fd_map[p.stdout.fileno()]\n\n    while len(rfds) + len(wfds) > 0:\n        # XXX: Should we be tracking excepted file descriptors as well?\n        rl, wl, _ = select.select(rfds, wfds, [])\n\n        # For each of our readable blast processes, read response\n        # records and emit them\n        for fd in rl:\n            rs = fd_map[fd]['result_buffer']\n            rbuf = os.read(fd, select.PIPE_BUF)\n\n            # The blast process has finished emitting records. Stop\n            # attempting to read from or write to it. If we have\n            # excess data in our result_buffer, c'est la vie.\n            if rbuf == '':\n                p = fd_map[fd]['popen']\n\n                rfds.remove(p.stdout.fileno())\n                p.stdout.close()\n\n                if not p.stdin.closed:\n                    wfds.remove(p.stdin.fileno())\n                    p.stdin.close()\n                \n                continue\n\n            rs += rbuf\n            while True:\n                rec, rs = __read_single_query_result(rs, fields)\n                if rec is None:\n                    break\n                yield rec\n\n            fd_map[fd]['result_buffer'] = rs\n\n        # For each of our writable blast processes, grab a new query\n        # sequence and send it off to them.\n        for fd in wl:\n            qs = fd_map[fd]['query_buffer']\n            if not qs:\n                ql = __read_single_fasta_query_lines(input_file)\n\n                # No more input records available. Close the pipe to\n                # signal this to the blast process.\n                if ql is None:\n                    p = fd_map[fd]['popen']\n\n                    wfds.remove(p.stdin.fileno())\n                    p.stdin.close()\n\n                    continue\n\n                qs = ''.join(ql)\n\n            # XXX: For some reason, despite select(2) indicating that\n            #      this file descriptor is writable, writes can fail\n            #      with EWOULDBLOCK. Handle this gracefully.\n            try:\n                written = os.write(fd, qs)\n                qs = qs[written:]\n            except OSError, e:\n                assert e.errno == errno.EWOULDBLOCK\n\n            fd_map[fd]['query_buffer'] = qs", "response": "Run the select loop to handle blast I/O to the given set of Popens."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __run_blast(blast_command, input_file, *args, **kwargs):\n    '''\n    Run a blast variant on the given input file.\n    '''\n\n    # XXX: Eventually, translate results on the fly as requested? Or\n    #      just always use our parsed object?\n    if 'outfmt' in kwargs:\n        raise Exception('Use of the -outfmt option is not supported')\n\n    num_processes = kwargs.get(\n        'pb_num_processes', os.sysconf('SC_NPROCESSORS_ONLN'))\n    fields = kwargs.get('pb_fields', DEFAULT_HIT_FIELDS)\n\n    blast_args = [blast_command]\n    blast_args += ['-outfmt', '7 {}'.format(' '.join(fields))]\n    for a in args:\n        blast_args += ['-' + a]\n    for k, v in kwargs.iteritems():\n        if not k.startswith('pb_'):\n            blast_args += ['-' + k, str(v)]\n\n    popens = []\n    for _ in range(num_processes):\n        popens.append(\n            subprocess.Popen(\n                args=blast_args, stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n                stderr=None, close_fds=True))\n\n    try:\n        for r in __run_blast_select_loop(input_file, popens, fields):\n            yield r\n    finally:\n        for p in popens:\n            if p.poll() is None:\n                p.terminate()\n            p.wait()", "response": "Run a blast command on the given input file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_frames(self, channels=2):\n        tmp_frame = self.track.current_frame\n        self.track.current_frame = self.start\n        frames = self.track.read_frames(self.duration, channels=channels)\n        self.track.current_frame = tmp_frame\n\n        for effect in self.effects:\n            frames = effect.apply_to(frames, self.samplerate)\n\n        return frames.copy()", "response": "Get numpy array of frames corresponding to the segment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the duration of the composition", "response": "def duration(self):\n        \"\"\"Get duration of composition\n        \"\"\"\n        return max([x.comp_location + x.duration\n                    for x in self.segments])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_segment(self, segment):\n        self.tracks.add(segment.track)\n        self.segments.append(segment)", "response": "Add a segment to the composition\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_segments(self, segments):\n        self.tracks.update([seg.track for seg in segments])\n        self.segments.extend(segments)", "response": "Adds a list of segments to the composition\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fade_in(self, segment, duration, fade_type=\"linear\"):\n        f = Fade(segment.track, segment.comp_location_in_seconds,\n                 duration, 0.0, 1.0, fade_type=fade_type)\n        self.add_dynamic(f)\n        return f", "response": "Adds a fade - in to a segment in the composition\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fade_out(self, segment, duration, fade_type=\"linear\"):\n        score_loc_in_seconds = segment.comp_location_in_seconds +\\\n            segment.duration_in_seconds - duration\n\n        f = Fade(segment.track, score_loc_in_seconds, duration, 1.0, 0.0,\n                 fade_type=fade_type)\n        # bug fixing... perhaps\n        f.comp_location = segment.comp_location + segment.duration -\\\n            int(duration * segment.track.samplerate)\n        self.add_dynamic(f)\n        return f", "response": "Adds a fade - out to a segment in the composition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a fade - in to a segment that extends the beginning of the segment.", "response": "def extended_fade_in(self, segment, duration):\n        \"\"\"Add a fade-in to a segment that extends the beginning of the\n        segment.\n\n        :param segment: Segment to fade in\n        :type segment: :py:class:`radiotool.composer.Segment`\n        :param duration: Duration of fade-in (in seconds)\n        :returns: The fade that has been added to the composition\n        :rtype: :py:class:`Fade`\n        \"\"\"\n        dur = int(duration * segment.track.samplerate)\n        if segment.start - dur >= 0:\n            segment.start -= dur\n        else:\n            raise Exception(\n                \"Cannot create fade-in that extends \"\n                \"past the track's beginning\")\n        if segment.comp_location - dur >= 0:\n            segment.comp_location -= dur\n        else:\n            raise Exception(\n                \"Cannot create fade-in the extends past the score's beginning\")\n\n        segment.duration += dur\n\n        f = Fade(segment.track, segment.comp_location_in_seconds,\n                 duration, 0.0, 1.0)\n        self.add_dynamic(f)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a fade - out to a segment that extends the beginning of the segment.", "response": "def extended_fade_out(self, segment, duration):\n        \"\"\"Add a fade-out to a segment that extends the beginning of the\n        segment.\n\n        :param segment: Segment to fade out\n        :type segment: :py:class:`radiotool.composer.Segment`\n        :param duration: Duration of fade-out (in seconds)\n        :returns: The fade that has been added to the composition\n        :rtype: :py:class:`Fade`\n        \"\"\"\n        dur = int(duration * segment.track.samplerate)\n        if segment.start + segment.duration + dur <\\\n                segment.track.duration:\n            segment.duration += dur\n        else:\n            raise Exception(\n                \"Cannot create fade-out that extends past the track's end\")\n        score_loc_in_seconds = segment.comp_location_in_seconds +\\\n            segment.duration_in_seconds - duration\n        f = Fade(segment.track, score_loc_in_seconds, duration, 1.0, 0.0)\n        self.add_dynamic(f)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cross_fade(self, seg1, seg2, duration):\n\n        if seg1.comp_location + seg1.duration - seg2.comp_location < 2:\n            dur = int(duration * seg1.track.samplerate)\n\n            if dur % 2 == 1:\n                dur -= 1\n\n            if dur / 2 > seg1.duration:\n                dur = seg1.duration * 2\n\n            if dur / 2 > seg2.duration:\n                dur = seg2.duration * 2\n\n            # we're going to compute the crossfade and then create a RawTrack\n            # for the resulting frames\n\n            if seg2.start - (dur / 2) < 0:\n                diff = seg2.start\n                seg2.start = 0\n                seg2.duration -= diff\n                seg2.comp_location -= diff\n                dur = 2 * diff\n            else:\n                seg2.start -= (dur / 2)\n                seg2.duration += (dur / 2)\n                seg2.comp_location -= (dur / 2)\n\n            seg1.duration += (dur / 2)\n            out_frames = seg1.get_frames(channels=self.channels)[-dur:]\n            seg1.duration -= dur\n\n            in_frames = seg2.get_frames(channels=self.channels)[:dur]\n            seg2.start += dur\n            seg2.duration -= dur\n            seg2.comp_location += dur\n\n            # compute the crossfade\n            in_frames = in_frames[:min(map(len, [in_frames, out_frames]))]\n            out_frames = out_frames[:min(map(len, [in_frames, out_frames]))]\n\n            cf_frames = radiotool.utils.linear(out_frames, in_frames)\n            # cf_frames = equal_power(out_frames, in_frames)\n\n            raw_track = RawTrack(cf_frames, name=\"crossfade\",\n                                 samplerate=seg1.track.samplerate)\n\n            rs_comp_location = (seg1.comp_location + seg1.duration) /\\\n                float(seg1.track.samplerate)\n\n            rs_duration = raw_track.duration / float(raw_track.samplerate)\n\n            raw_seg = Segment(raw_track, rs_comp_location, 0.0, rs_duration)\n            # will this fix a bug?\n            raw_seg.duration = raw_track.duration\n            raw_seg.comp_location = seg1.comp_location + seg1.duration\n\n            self.add_track(raw_track)\n            self.add_segment(raw_seg)\n\n            return raw_seg\n\n        else:\n            print seg1.comp_location + seg1.duration, seg2.comp_location\n            raise Exception(\"Segments must be adjacent\"\n                            \"to add a crossfade ({}, {})\".format(\n                            seg1.comp_location + seg1.duration,\n                            seg2.comp_location))", "response": "Add a linear crossfade between two segments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests whether the composition contains any segments in the composition that overlap the given time and the given duration.", "response": "def empty_over_span(self, time, duration):\n        \"\"\"Helper method that tests whether composition contains any segments\n        at a given time for a given duration. \n\n        :param time: Time (in seconds) to start span\n        :param duration: Duration (in seconds) of span\n        :returns: `True` if there are no segments in the composition that overlap the span starting at `time` and lasting for `duration` seconds. `False` otherwise.\n        \"\"\"\n        for seg in self.segments:\n            # starts in range\n            if seg.comp_location_in_seconds >= time and\\\n                seg.comp_location_in_seconds < time + duration:\n                return False\n            # or, ends in range\n            elif seg.comp_location_in_seconds + seg.duration_in_seconds >= time and\\\n                seg.comp_location_in_seconds + seg.duration_in_seconds < time + duration:\n                return False\n            # or, spans entire range\n            elif seg.comp_location_in_seconds < time and\\\n                seg.comp_location_in_seconds + seg.duration_in_seconds >= time + duration:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contract(self, time, duration, min_contraction=0.0):\n\n        # remove audio from the composition starting at time\n        # for duration\n\n        contract_dur = 0.0\n        contract_start = time\n\n        if self.empty_over_span(time, duration):\n            contract_dur = duration\n            contract_start = time\n        else:\n            starts = [s.comp_location_in_seconds for s in self.segments]\n            ends = [s.comp_location_in_seconds + s.duration_in_seconds\n                    for s in self.segments]\n\n            key_starts = []\n            key_ends = []\n\n            for start in starts:\n                if start >= time and start < time + duration:\n                    # does a segment cover the location right before this start?\n                    is_key_start = True\n                    for seg in self.segments:\n                        if seg.comp_location_in_seconds < start and\\\n                            seg.comp_location_in_seconds + seg.duration_in_seconds >= start:\n                            is_key_start = False\n                            break\n                    if is_key_start:\n                        key_starts.append(start)\n\n            for end in ends:\n                if end >= time and end < time + duration:\n                    # does a segment cover the location right before this start?\n                    is_key_end = True\n                    for seg in self.segments:\n                        if seg.comp_location_in_seconds <= end and\\\n                            seg.comp_location_in_seconds + seg.duration_in_seconds > end:\n                            is_key_end = False\n                            break\n                    if is_key_end:\n                        key_ends.append(end)\n\n            if len(key_starts) + len(key_ends) == 0: return 0, 0\n\n            # combine key starts and key ends\n            key_both = [s for s in key_starts]\n            key_both.extend([s for s in key_ends])\n            key_both = sorted(key_both)\n\n            first_key = key_both[0]\n            if first_key in key_starts:\n                contract_start = time\n                contract_dur = first_key - time\n            else:\n                contract_start = first_key\n                if len(key_both) >= 2:\n                    contract_dur = key_both[1] - first_key\n                else:\n                    contract_dur = time + duration - first_key\n\n        if contract_dur > min_contraction:\n            for seg in self.segments:\n                if seg.comp_location_in_seconds > contract_start:\n                    dur_samples = int(seg.samplerate * contract_dur)\n                    seg.comp_location -= dur_samples\n            for dyn in self.dynamics:\n                if dyn.comp_location_in_seconds > contract_start:\n                    dur_samples = int(seg.samplerate * contract_dur)\n                    dyn.comp_location -= dur_samples\n            return contract_start, contract_dur\n        else:\n            return 0.0, 0.0", "response": "This function will contract the audio segments in the composition starting at a given time for a given duration."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a music cue to the composition.", "response": "def add_music_cue(self, track, comp_cue, song_cue, duration=6.0,\n                      padding_before=12.0, padding_after=12.0):\n        \"\"\"Add a music cue to the composition. This doesn't do any audio\n        analysis, it just aligns a specified point in the track\n        (presumably music) with a location in the composition. See\n        UnderScore_ for a visualization of what this is doing to the\n        music track.\n\n        .. _UnderScore: http://vis.berkeley.edu/papers/underscore/\n\n        :param track: Track to align in the composition\n        :type track: :py:class:`radiotool.composer.Track`\n        :param float comp_cue: Location in composition to align music cue (in seconds)\n        :param float song_cue: Location in the music track to align with the composition cue (in seconds)\n        :param float duration: Duration of music after the song cue before the music starts to fade out (in seconds)\n        :param float padding_before: Duration of music playing softly before the music cue/composition cue (in seconds)\n        :param float padding_after: Duration of music playing softly after the music cue/composition cue (in seconds)\n        \"\"\"\n\n        self.tracks.add(track)\n        \n        pre_fade = 3\n        post_fade = 3\n        \n        if padding_before + pre_fade > song_cue:\n            padding_before = song_cue - pre_fade\n            \n        if padding_before + pre_fade > score_cue:\n            padding_before = score_cue - pre_fade\n\n        s = Segment(track, score_cue - padding_before - pre_fade,\n                    song_cue - padding_before - pre_fade,\n                    pre_fade + padding_before + duration +\n                    padding_after + post_fade)\n\n        self.add_segment(s)\n        \n        d = []\n\n        dyn_adj = 1\n        \n        track.current_frame = 0\n        \n        d.append(Fade(track, score_cue - padding_before - pre_fade, pre_fade,\n                      0, .1*dyn_adj, fade_type=\"linear\"))\n\n        d.append(Fade(track, score_cue - padding_before, padding_before,\n                      .1*dyn_adj, .4*dyn_adj, fade_type=\"exponential\"))\n\n        d.append(Volume(track, score_cue, duration, .4*dyn_adj))\n\n        d.append(Fade(track, score_cue + duration, padding_after,\n                      .4*dyn_adj, 0, fade_type=\"exponential\"))\n\n        d.append(Fade(track, score_cue + duration + padding_after, post_fade,\n                      .1*dyn_adj, 0, fade_type=\"linear\"))\n        self.add_dynamics(d)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a numpy array from the composition.", "response": "def build(self, track_list=None, adjust_dynamics=False,\n        min_length=None, channels=None):\n        \"\"\"\n        Create a numpy array from the composition.\n\n        :param track_list: List of tracks to include in composition generation (``None`` means all tracks will be used)\n        :type track_list: list of :py:class:`radiotool.composer.Track`\n        :param int min_length: Minimum length of output array (in frames). Will zero pad extra length.\n        :param bool. adjust_dynamics: Automatically adjust dynamics. Will document later.\n        \"\"\"\n        if track_list is None:\n            track_list = self.tracks\n\n        if channels is None:\n            channels = self.channels\n\n        parts = {}\n        starts = {}\n        \n        # for universal volume adjustment\n        all_frames = np.array([])\n        song_frames = np.array([])\n        speech_frames = np.array([])\n        \n        longest_part = max([x.comp_location + x.duration\n                            for x in self.segments])\n        if len(self.dynamics) > 0:\n            longest_part = max((longest_part,\n                max([x.comp_location + x.duration\n                     for x in self.dynamics])))\n        \n        for track_idx, track in enumerate(track_list):\n            segments = sorted([v for v in self.segments if v.track == track], \n                              key=lambda k: k.comp_location + k.duration)\n            dyns = sorted([d for d in self.dynamics if d.track == track],\n                           key=lambda k: k.comp_location)\n\n            if len(segments) > 0:\n                start_loc = min([x.comp_location for x in segments])\n                end_loc = max([x.comp_location + x.duration for x in segments])\n                if len(dyns) > 0:\n                    start_loc = min((start_loc, \n                         min([d.comp_location for d in dyns])))\n                    end_loc = max((end_loc,\n                        max([d.comp_location + d.duration for d in dyns])))\n                \n                starts[track] = start_loc\n\n                parts[track] = np.zeros((end_loc - start_loc, channels))\n                \n                for s in segments:\n\n                    frames = s.get_frames(channels=channels).\\\n                        reshape(-1, channels)\n                    \n                    # for universal volume adjustment\n                    if adjust_dynamics:\n                        all_frames = np.append(all_frames,\n                            self._remove_end_silence(frames.flatten()))\n                        if isinstance(track, Song):\n                            song_frames = np.append(song_frames,\n                                self._remove_end_silence(frames.flatten()))\n                        elif isinstance(track, Speech):\n                            speech_frames = np.append(speech_frames,\n                                self._remove_end_silence(frames.flatten()))\n                                \n                    parts[track][s.comp_location - start_loc:\n                                 s.comp_location - start_loc + s.duration,\n                                 :] = frames\n\n            for d in dyns:\n                vol_frames = d.to_array(channels)\n\n                parts[track][d.comp_location - start_loc :\n                             d.comp_location - start_loc + d.duration,\n                             :] *= vol_frames\n\n\n        if adjust_dynamics:\n            total_energy = RMS_energy(all_frames)\n            song_energy = RMS_energy(song_frames)\n            speech_energy = RMS_energy(speech_frames)\n                \n        # dyn_adj = 0.10 / total_energy\n        # dyn_adj = speech_energy / sqrt(song_energy) * 5\n        if adjust_dynamics:\n            if not np.isnan(speech_energy) and not np.isnan(song_energy):\n                dyn_adj = sqrt(speech_energy / song_energy) * 1.15\n            else:\n                dyn_adj = 1\n        else:\n            dyn_adj = 1\n\n        if longest_part < min_length:\n            longest_part = min_length\n        out = np.zeros((longest_part, channels))\n        for track, part in parts.iteritems():\n            out[starts[track]:starts[track] + len(part)] += part\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate audio file from composition.", "response": "def export(self, **kwargs):\n        \"\"\"\n        Generate audio file from composition.\n\n        :param str. filename: Output filename (no extension)\n        :param str. filetype: Output file type (only .wav supported for now)\n        :param integer samplerate: Sample rate of output audio\n        :param integer channels: Channels in output audio, if different than originally specified\n        :param bool. separate_tracks: Also generate audio file for each track in composition\n        :param int min_length: Minimum length of output array (in frames). Will zero pad extra length.\n        :param bool. adjust_dynamics: Automatically adjust dynamics (will document later)\n\n        \"\"\"\n        # get optional args\n        filename = kwargs.pop('filename', 'out')\n        filetype = kwargs.pop('filetype', 'wav')\n        adjust_dynamics = kwargs.pop('adjust_dynamics', False)\n        samplerate = kwargs.pop('samplerate', None)\n        channels = kwargs.pop('channels', self.channels)\n        separate_tracks = kwargs.pop('separate_tracks', False)\n        min_length = kwargs.pop('min_length', None)\n        \n        if samplerate is None:\n            samplerate = np.min([track.samplerate for track in self.tracks])\n\n        encoding = 'pcm16'\n        to_mp3 = False\n        if filetype == 'ogg':\n            encoding = 'vorbis'\n        elif filetype == 'mp3':\n            filetype = 'wav'\n            to_mp3 = True\n\n        if separate_tracks:\n            # build the separate parts of the composition if desired\n            for track in self.tracks:\n                out = self.build(track_list=[track],\n                                 adjust_dynamics=adjust_dynamics,\n                                 min_length=min_length,\n                                 channels=channels)\n                out_file = Sndfile(\"%s-%s.%s\" %\n                                   (filename, track.name, filetype),\n                                   'w',\n                                   Format(filetype, encoding=encoding),\n                                   channels, samplerate)\n                out_file.write_frames(out)\n                out_file.close()\n\n        # always build the complete composition\n        out = self.build(adjust_dynamics=adjust_dynamics,\n                         min_length=min_length,\n                         channels=channels)\n\n        out_filename = \"%s.%s\" % (filename, filetype)\n        out_file = Sndfile(out_filename, 'w',\n                           Format(filetype, encoding=encoding), \n                           channels, samplerate)\n        out_file.write_frames(out)\n        out_file.close()\n\n        if LIBXMP and filetype == \"wav\":\n            xmp = libxmp.XMPMeta()\n            ns = libxmp.consts.XMP_NS_DM\n            p = xmp.get_prefix_for_namespace(ns)\n            xpath = p + 'Tracks'\n            xmp.append_array_item(ns, xpath, None, \n                array_options={\"prop_value_is_array\": True},\n                prop_value_is_struct=True)\n\n            xpath += '[1]/' + p\n            xmp.set_property(ns, xpath + \"trackName\", \"CuePoint Markers\")\n            xmp.set_property(ns, xpath + \"trackType\", \"Cue\")\n            xmp.set_property(ns, xpath + \"frameRate\", \"f%d\" % samplerate)\n\n            for i, lab in enumerate(self.labels):\n                xmp.append_array_item(ns, xpath + \"markers\", None,\n                    array_options={\"prop_value_is_array\": True},\n                    prop_value_is_struct=True)\n                xmp.set_property(ns,\n                    xpath + \"markers[%d]/%sname\" % (i + 1, p), lab.name)\n                xmp.set_property(ns,\n                    xpath + \"markers[%d]/%sstartTime\" % (i + 1, p),\n                    str(lab.sample(samplerate))) \n\n            xmpfile = libxmp.XMPFiles(file_path=out_filename, open_forupdate=True)\n            if xmpfile.can_put_xmp(xmp):\n                xmpfile.put_xmp(xmp)\n            xmpfile.close_file()\n\n        if to_mp3:\n            wav_to_mp3(out_filename, delete_wav=True)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_episode_types(db) -> Iterator[EpisodeType]:\n    cur = db.cursor()\n    cur.execute('SELECT id, name, prefix FROM episode_type')\n    for type_id, name, prefix in cur:\n        yield EpisodeType(type_id, name, prefix)", "response": "Get all episode types."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the epno for an episode instance.", "response": "def get_epno(self, episode: Episode):\n        \"\"\"Return epno for an Episode instance.\n\n        epno is a string formatted with the episode number and type, e.g., S1,\n        T2.\n\n        >>> x = EpisodeTypes([EpisodeType(1, 'foo', 'F')])\n        >>> ep = Episode(type=1, number=2)\n        >>> x.get_epno(ep)\n        'F2'\n\n        \"\"\"\n        return '{}{}'.format(self[episode.type].prefix, episode.number)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_discovery_update(self, name, new_config):\n        for service in self.configurables[Service].values():\n            if service.discovery == name:\n                service.reset_status()", "response": "Called when a Discovery is updated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when a new service is added to the cache.", "response": "def on_service_add(self, service):\n        \"\"\"\n        When a new service is added, a worker thread is launched to\n        periodically run the checks for that service.\n        \"\"\"\n        self.launch_thread(service.name, self.check_loop, service)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwhile the reporter is not shutting down and the service being checked is present in the reporter's configuration, this method will launch a job to run all of the service's checks and then pause for the configured interval.", "response": "def check_loop(self, service):\n        \"\"\"\n        While the reporter is not shutting down and the service being checked\n        is present in the reporter's configuration, this method will launch a\n        job to run all of the service's checks and then pause for the\n        configured interval.\n        \"\"\"\n        logger.info(\"Starting check loop for service '%s'\", service.name)\n\n        def handle_checks_result(f):\n            try:\n                came_up, went_down = f.result()\n            except Exception:\n                logger.exception(\"Error checking service '%s'\", service.name)\n                return\n\n            if not came_up and not went_down:\n                return\n\n            discovery = self.configurables[Discovery][service.discovery]\n\n            for port in came_up:\n                logger.debug(\"Reporting %s, port %d up\", service.name, port)\n                discovery.report_up(service, port)\n            for port in went_down:\n                logger.debug(\"Reporting %s, port %d down\", service.name, port)\n                discovery.report_down(service, port)\n\n        while (\n                service in self.configurables[Service].values() and\n                not self.shutdown.is_set()\n        ):\n            self.work_pool.submit(\n                self.run_checks, service\n            ).add_done_callback(\n                handle_checks_result\n            )\n\n            logger.debug(\"sleeping for %s seconds\", service.check_interval)\n            wait_on_event(self.shutdown, timeout=service.check_interval)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_checks(self, service):\n        logger.debug(\"Running checks. (%s)\", service.name)\n\n        if service.discovery not in self.configurables[Discovery]:\n            logger.warn(\n                \"Service %s is using Unknown/unavailable discovery '%s'.\",\n                service.name, service.discovery\n            )\n            return set(), set()\n\n        service.update_ports()\n\n        came_up, went_down = service.run_checks()\n\n        return came_up, went_down", "response": "Runs each check for the service and reports to the service s discovery\n            method based on the results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _do_api_call(self, method, data):\n\n        # Developer API keys, auth tokens, and other standard, required args.\n        data.update({\n            \"key\": self.api_key,\n            # No API methods currently use this, but we're ready for it,\n            # should that change.\n            \"token\": self.api_auth_token,\n        })\n\n        # Ends up being a full URL+path.\n        url = \"%s%s\" % (self.endpoint, method)\n        # Bombs away!\n        response = requests.get(url, params=data)\n\n        # Parse and return an ElementTree instance containing the document.\n        root = etree.fromstring(response.content)\n\n        # If this is anything but '100', it's an error.\n        status_code = root.find(\"header/status/code\").text\n        # If this comes back as non-None, we know we've got problems.\n        exc_class = _get_exception_class_from_status_code(status_code)\n        if exc_class:\n            # Sheet, sheet, errar! Raise the appropriate error, and pass\n            # the accompanying error message as the exception message.\n            error_message = root.find(\"header/status/message\").text\n            #noinspection PyCallingNonCallable\n            raise exc_class(error_message)\n\n        return root", "response": "This method is used to carry out a standard API call against the Petfinder API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive an API method, the arguments passed to it, and a function to hand parsing off to, loop through the record sets in the API call until all records have been yielded. This is mostly done this way to reduce duplication through the various API methods. :param basestring method: The API method on the endpoint. :param dict kwargs: The kwargs from the top-level API method. :param callable parser_func: A callable that is used for parsing the output from the API call. :rtype: generator :returns: Returns a generator that may be returned by the top-level API method.", "response": "def _do_autopaginating_api_call(self, method, kwargs, parser_func):\n        \"\"\"\n        Given an API method, the arguments passed to it, and a function to\n        hand parsing off to, loop through the record sets in the API call\n        until all records have been yielded.\n\n        This is mostly done this way to reduce duplication through the various\n        API methods.\n\n        :param basestring method: The API method on the endpoint.\n        :param dict kwargs: The kwargs from the top-level API method.\n        :param callable parser_func: A callable that is used for parsing the\n            output from the API call.\n        :rtype: generator\n        :returns: Returns a generator that may be returned by the top-level\n            API method.\n        \"\"\"\n        # Used to determine whether to fail noisily if no results are returned.\n        has_records = {\"has_records\": False}\n\n        while True:\n            try:\n                root = self._do_api_call(method, kwargs)\n            except RecordDoesNotExistError:\n                if not has_records[\"has_records\"]:\n                    # No records seen yet, this really is empty.\n                    raise\n                    # We've seen some records come through. We must have hit the\n                # end of the result set. Finish up silently.\n                return\n\n            # This is used to track whether this go around the call->parse\n            # loop yielded any records.\n            records_returned_by_this_loop = False\n            for record in parser_func(root, has_records):\n                yield record\n                # We saw a record, mark our tracker accordingly.\n                records_returned_by_this_loop = True\n                # There is a really fun bug in the Petfinder API with\n            # shelter.getpets where an offset is returned with no pets,\n            # causing an infinite loop.\n            if not records_returned_by_this_loop:\n                return\n\n            # This will determine at what offset we start the next query.\n            last_offset = root.find(\"lastOffset\").text\n            kwargs[\"offset\"] = last_offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_datetime_str(self, dtime_str):\n\n        return datetime.datetime.strptime(\n            dtime_str,\n            \"%Y-%m-%dT%H:%M:%SZ\"\n        ).replace(tzinfo=pytz.utc)", "response": "Parses a standard datetime string into a datetime instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a lxml. etree. _Element root parse out the pet record.", "response": "def _parse_pet_record(self, root):\n        \"\"\"\n        Given a <pet> Element from a pet.get or pet.getRandom response, pluck\n        out the pet record.\n\n        :param lxml.etree._Element root: A <pet> tag Element.\n        :rtype: dict\n        :returns: An assembled pet record.\n        \"\"\"\n        record = {\n            \"breeds\": [],\n            \"photos\": [],\n            \"options\": [],\n            \"contact\": {},\n        }\n\n        # These fields can just have their keys and text values copied\n        # straight over to the dict record.\n        straight_copy_fields = [\n            \"id\", \"shelterId\", \"shelterPetId\", \"name\", \"animal\", \"mix\",\n            \"age\", \"sex\", \"size\", \"description\", \"status\", \"lastUpdate\",\n        ]\n\n        for field in straight_copy_fields:\n            # For each field, just take the tag name and the text value to\n            # copy to the record as key/val.\n            node = root.find(field)\n            if node is None:\n                print(\"SKIPPING %s\" % field)\n                continue\n            record[field] = node.text\n\n        # Pets can be of multiple breeds. Find all of the <breed> tags and\n        # stuff their text (breed names) into the record.\n        for breed in root.findall(\"breeds/breed\"):\n            record[\"breeds\"].append(breed.text)\n\n        # We'll deviate slightly from the XML format here, and simply append\n        # each photo entry to the record's \"photo\" key.\n        for photo in root.findall(\"media/photos/photo\"):\n            photo = {\n                \"id\": photo.get(\"id\"),\n                \"size\": photo.get(\"size\"),\n                \"url\": photo.text,\n            }\n            record[\"photos\"].append(photo)\n\n        # Has shots, no cats, altered, etc.\n        for option in root.findall(\"options/option\"):\n            record[\"options\"].append(option.text)\n\n        # <contact> tag has some sub-tags that can be straight copied over.\n        contact = root.find(\"contact\")\n        if contact is not None:\n            for field in contact:\n                record[\"contact\"][field.tag] = field.text\n\n        # Parse lastUpdate so we have a useable datetime.datime object.\n        record[\"lastUpdate\"] = self._parse_datetime_str(record[\"lastUpdate\"])\n\n        return record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping for breed. list. Returns a list of breed names strings.", "response": "def breed_list(self, **kwargs):\n        \"\"\"\n        breed.list wrapper. Returns a list of breed name strings.\n\n        :rtype: list\n        :returns: A list of breed names.\n        \"\"\"\n\n        root = self._do_api_call(\"breed.list\", kwargs)\n\n        breeds = []\n        for breed in root.find(\"breeds\"):\n            breeds.append(breed.text)\n        return breeds"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pet_get(self, **kwargs):\n        root = self._do_api_call(\"pet.get\", kwargs)\n\n        return self._parse_pet_record(root.find(\"pet\"))", "response": "Wrapper for the pet. get method. Returns a record dict for the requested pet."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pet_getrandom(self, **kwargs):\n        root = self._do_api_call(\"pet.getRandom\", kwargs)\n\n        output_brevity = kwargs.get(\"output\", \"id\")\n\n        if output_brevity == \"id\":\n            return root.find(\"petIds/id\").text\n        else:\n            return self._parse_pet_record(root.find(\"pet\"))", "response": "Wrapper for the pet. getRandom method. Returns a dict or Petfinder ID\n        for a random pet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pet_find(self, **kwargs):\n\n        def pet_find_parser(root, has_records):\n            \"\"\"\n            The parser that is used with the ``_do_autopaginating_api_call``\n            method for auto-pagination.\n\n            :param lxml.etree._Element root: The root Element in the response.\n            :param dict has_records: A dict that we track the loop state in.\n                dicts are passed by references, which is how this works.\n            \"\"\"\n            for pet in root.findall(\"pets/pet\"):\n                # This is changed in the original record, since it's passed\n                # by reference.\n                has_records[\"has_records\"] = True\n                yield self._parse_pet_record(pet)\n\n        return self._do_autopaginating_api_call(\n            \"pet.find\", kwargs, pet_find_parser\n        )", "response": "Wrapper for the pet. find method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps for the shelter. find method.", "response": "def shelter_find(self, **kwargs):\n        \"\"\"\n        shelter.find wrapper. Returns a generator of shelter record dicts\n        matching your search criteria.\n\n        :rtype: generator\n        :returns: A generator of shelter record dicts.\n        :raises: :py:exc:`petfinder.exceptions.LimitExceeded` once you have\n            reached the maximum number of records your credentials allow you\n            to receive.\n        \"\"\"\n\n        def shelter_find_parser(root, has_records):\n            \"\"\"\n            The parser that is used with the ``_do_autopaginating_api_call``\n            method for auto-pagination.\n\n            :param lxml.etree._Element root: The root Element in the response.\n            :param dict has_records: A dict that we track the loop state in.\n                dicts are passed by references, which is how this works.\n            \"\"\"\n            for shelter in root.find(\"shelters\"):\n                has_records[\"has_records\"] = True\n                record = {}\n                for field in shelter:\n                    record[field.tag] = field.text\n                yield record\n\n        return self._do_autopaginating_api_call(\n            \"shelter.find\", kwargs, shelter_find_parser\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shelter_get(self, **kwargs):\n\n        root = self._do_api_call(\"shelter.get\", kwargs)\n\n        shelter = root.find(\"shelter\")\n        for field in shelter:\n            record = {}\n            for field in shelter:\n                record[field.tag] = field.text\n            return record", "response": "Wrapper for the shelter. get method. Given a shelter ID retrieve its details in\n        dict form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps for the shelter. getPets API call.", "response": "def shelter_getpets(self, **kwargs):\n        \"\"\"\n        shelter.getPets wrapper. Given a shelter ID, retrieve either a list of\n        pet IDs (if ``output`` is ``'id'``), or a generator of pet record\n        dicts (if ``output`` is ``'full'`` or ``'basic'``).\n\n        :rtype: generator\n        :returns: Either a generator of pet ID strings or pet record dicts,\n            depending on the value of the ``output`` keyword.\n        :raises: :py:exc:`petfinder.exceptions.LimitExceeded` once you have\n            reached the maximum number of records your credentials allow you\n            to receive.\n        \"\"\"\n\n        def shelter_getpets_parser_ids(root, has_records):\n            \"\"\"\n            Parser for output=id.\n            \"\"\"\n            pet_ids = root.findall(\"petIds/id\")\n            for pet_id in pet_ids:\n                yield pet_id.text\n\n        def shelter_getpets_parser_records(root, has_records):\n            \"\"\"\n            Parser for output=full or output=basic.\n            \"\"\"\n            for pet in root.findall(\"pets/pet\"):\n                yield self._parse_pet_record(pet)\n\n\n        # Depending on the output value, select the correct parser.\n        if kwargs.get(\"output\", \"id\") == \"id\":\n            shelter_getpets_parser = shelter_getpets_parser_ids\n        else:\n            shelter_getpets_parser = shelter_getpets_parser_records\n\n        return self._do_autopaginating_api_call(\n            \"shelter.getPets\", kwargs, shelter_getpets_parser\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping for shelter. listByBreed.", "response": "def shelter_listbybreed(self, **kwargs):\n        \"\"\"\n        shelter.listByBreed wrapper. Given a breed and an animal type, list\n        the shelter IDs with pets of said breed.\n\n        :rtype: generator\n        :returns: A generator of shelter IDs that have breed matches.\n        \"\"\"\n\n        root = self._do_api_call(\"shelter.listByBreed\", kwargs)\n\n        shelter_ids = root.findall(\"shelterIds/id\")\n        for shelter_id in shelter_ids:\n            yield shelter_id.text"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_callback(self, event, cb, args=None):\n        '''Add a callback to this node.\n\n        Callbacks are called when the specified event occurs. The available\n        events depends on the specific node type. Args should be a value to\n        pass to the callback when it is called. The callback should be of the\n        format:\n\n        def callback(node, value, cb_args):\n\n        where node will be the node that called the function, value is the\n        relevant information for the event, and cb_args are the arguments you\n        registered with the callback.\n\n        '''\n        if event not in self._cbs:\n            raise exceptions.NoSuchEventError\n        self._cbs[event] = [(cb, args)]", "response": "Add a callback to this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_node(self, path):\n        '''Get a child node of this node, or this node, based on a path.\n\n        @param path A list of path elements pointing to a node in the tree.\n                    For example, ['/', 'localhost', 'dir.host']. The first\n                    element in this path should be this node's name.\n        @return The node pointed to by @ref path, or None if the path does not\n                point to a node in the tree below this node.\n\n        Example:\n        >>> c1 = TreeNode(name='c1')\n        >>> c2 = TreeNode(name='c2')\n        >>> p = TreeNode(name='p', children={'c1':c1, 'c2':c2})\n        >>> c1._parent = p\n        >>> c2._parent = p\n        >>> p.get_node(['p', 'c1']) == c1\n        True\n        >>> p.get_node(['p', 'c2']) == c2\n        True\n        '''\n        with self._mutex:\n            if path[0] == self._name:\n                if len(path) == 1:\n                    return self\n                elif path[1] in self._children:\n                    return self._children[path[1]].get_node(path[1:])\n                else:\n                    return None\n            else:\n                return None", "response": "Get a child node of this node or this node based on a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_path(self, path):\n        '''Check if a path exists below this node.\n\n        @param path A list of path elements pointing to a node in the tree.\n                    For example, ['/', 'localhost', 'dir.host']. The first\n                    element in this path should be this node's name.\n        @return True if the path points to a node in the tree below this node,\n                or this node itself (for paths one element long). False\n                otherwise.\n\n        Example:\n        >>> c1 = TreeNode(name='c1')\n        >>> c2 = TreeNode(name='c2')\n        >>> p = TreeNode(name='p', children={'c1':c1, 'c2':c2})\n        >>> c1._parent = p\n        >>> c2._parent = p\n        >>> p.has_path(['p', 'c1'])\n        True\n        >>> p.has_path(['p', 'c3'])\n        False\n        '''\n        with self._mutex:\n            if path[0] == self._name:\n                if len(path) == 1:\n                    return True\n                elif path[1] in self._children:\n                    return self._children[path[1]].has_path(path[1:])\n                else:\n                    return False\n            else:\n                return False", "response": "Check if a path exists below this node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall a function on this node and recursively all its children.", "response": "def iterate(self, func, args=None, filter=[]):\n        '''Call a function on this node, and recursively all its children.\n\n        This is a depth-first iteration.\n\n        @param func The function to call. Its declaration must be\n                    'def blag(node, args)', where 'node' is the current node\n                    in the iteration and args is the value of @ref args.\n        @param args Extra arguments to pass to the function at each iteration.\n                    Pass multiple arguments in as a tuple.\n        @param filter A list of filters to apply before calling func for each\n                      node in the iteration. If the filter is not True,\n                      @ref func will not be called for that node. Each filter\n                      entry should be a string, representing one of the is_*\n                      properties (is_component, etc), or a function object.\n        @return The results of the calls to @ref func in a list.\n\n        Example:\n        >>> c1 = TreeNode(name='c1')\n        >>> c2 = TreeNode(name='c2')\n        >>> p = TreeNode(name='p', children={'c1':c1, 'c2':c2})\n        >>> c1._parent = p\n        >>> c2._parent = p\n        >>> def hello(n, args):\n        ...     return args[0] + ' ' + n._name\n        >>> p.iterate(hello, args=['hello'])\n        ['hello p', 'hello c2', 'hello c1']\n        >>> p.iterate(hello, args=['hello'], filter=['_name==\"c1\"'])\n        ['hello c1']\n        '''\n        with self._mutex:\n            result = []\n            if filter:\n                filters_passed = True\n                for f in filter:\n                    if type(f) == str:\n                        if not eval('self.' + f):\n                            filters_passed = False\n                            break\n                    else:\n                        if not f(self):\n                            filters_passed = False\n                            break\n                if filters_passed:\n                    result = [func(self, args)]\n            else:\n                result = [func(self, args)]\n            for child in self._children:\n                result += self._children[child].iterate(func, args, filter)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rem_callback(self, event, cb):\n        '''Remove a callback from this node.\n\n        The callback is removed from the specified event.\n\n        @param cb The callback function to remove.\n\n        '''\n        if event not in self._cbs:\n            raise exceptions.NoSuchEventError(self.name, event)\n        c = [(x[0], x[1]) for x in self._cbs[event]]\n        if not c:\n            raise exceptions.NoCBError(self.name, event, cb)\n        self._cbs[event].remove(c[0])", "response": "Remove a callback from this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nameserver(self):\n        '''The name server of the node (i.e. its top-most parent below /).'''\n        with self._mutex:\n            if not self._parent:\n                # The root node does not have a name server\n                return None\n            elif self._parent.name == '/':\n                return self\n            else:\n                return self._parent.nameserver", "response": "The name server of the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef orb(self):\n        '''The ORB used to access this object.\n\n        This property's value will be None if no object above this object is a\n        name server.\n\n        '''\n        with self._mutex:\n            if self._parent.name == '/':\n                return None\n            return self._parent.orb", "response": "The ORB used to access this object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef root(self):\n        '''The root node of the tree this node is in.'''\n        with self._mutex:\n            if self._parent:\n                return self._parent.root\n            else:\n                return self", "response": "The root node of the tree this node is in."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upsert(db, table, key_cols, update_dict):\n    with db:\n        cur = db.cursor()\n        cur.execute(\n            'UPDATE {} SET {} WHERE {}'.format(\n                table,\n                ','.join(_sqlpformat(col) for col in update_dict.keys()),\n                ' AND '.join(_sqlpformat(col) for col in key_cols),\n            ),\n            update_dict,\n        )\n        if db.changes() == 0:\n            keys, values = zip(*update_dict.items())\n            cur.execute(\n                'INSERT INTO {} ({}) VALUES ({})'.format(\n                    table,\n                    ','.join(keys),\n                    ','.join('?' for _ in values)),\n                values)", "response": "Fabled upsert for SQLiteDB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an anime from an AniDB search.", "response": "def command(state, args):\n    \"\"\"Add an anime from an AniDB search.\"\"\"\n    if len(args) < 2:\n        print(f'Usage: {args[0]} {{ID|aid:AID}}')\n        return\n    aid = state.results.parse_aid(args[1], default_key='anidb')\n    anime = request_anime(aid)\n    query.update.add(state.db, anime)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the sum of the Omega lambda and Omega field.", "response": "def Ode(self, z):\n        \"\"\"\n        Returns the sum of :func:`~classylss.binding.Background.Omega_lambda`\n        and :func:`~classylss.binding.Background.Omega_fld`.\n        \"\"\"\n        return self.bg.Omega_lambda(z) + self.bg.Omega_fld(z)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the sum of the NCDM and URs for the given locale.", "response": "def Onu(self, z):\n        \"\"\"\n        Returns the sum of :func:`~classylss.binding.Background.Omega_ncdm`\n        and :func:`~classylss.binding.Background.Omega_ur`.\n        \"\"\"\n        return self.bg.Omega_ncdm(z) + self.bg.Omega_ur(z)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Node instance representing the current service node.", "response": "def current(cls, service, port):\n        \"\"\"\n        Returns a Node instance representing the current service node.\n\n        Collects the host and IP information for the current machine and\n        the port information from the given service.\n        \"\"\"\n        host = socket.getfqdn()\n        return cls(\n            host=host,\n            ip=socket.gethostbyname(host),\n            port=port,\n            metadata=service.metadata\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(self):\n        return json.dumps({\n            \"port\": self.port,\n            \"ip\": self.ip,\n            \"host\": self.host,\n            \"peer\": self.peer.serialize() if self.peer else None,\n            \"metadata\": json.dumps(self.metadata or {}, sort_keys=True),\n        }, sort_keys=True)", "response": "Serializes the node data as a JSON map string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new Node instance via a JSON map string. Note that `port` and `ip` and are required keys for the JSON map, `peer` and `host` are optional. If `peer` is not present, the new Node instance will use the current peer. If `host` is not present, the hostname of the given `ip` is looked up.", "response": "def deserialize(cls, value):\n        \"\"\"\n        Creates a new Node instance via a JSON map string.\n\n        Note that `port` and `ip` and are required keys for the JSON map,\n        `peer` and `host` are optional.  If `peer` is not present, the new Node\n        instance will use the current peer.  If `host` is not present, the\n        hostname of the given `ip` is looked up.\n        \"\"\"\n        if getattr(value, \"decode\", None):\n            value = value.decode()\n\n        logger.debug(\"Deserializing node data: '%s'\", value)\n        parsed = json.loads(value)\n\n        if \"port\" not in parsed:\n            raise ValueError(\"No port defined for node.\")\n        if \"ip\" not in parsed:\n            raise ValueError(\"No IP address defined for node.\")\n        if \"host\" not in parsed:\n            host, aliases, ip_list = socket.gethostbyaddr(parsed[\"ip\"])\n            parsed[\"host\"] = socket.get_fqdn(host)\n        if \"peer\" in parsed:\n            peer = Peer.deserialize(parsed[\"peer\"])\n        else:\n            peer = None\n\n        return cls(\n            parsed[\"host\"], parsed[\"ip\"], parsed[\"port\"],\n            peer=peer, metadata=parsed.get(\"metadata\")\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart config file monitor threads for each of the watched configurabes.", "response": "def start(self):\n        \"\"\"\n        Iterates over the `watched_configurabes` attribute and starts a\n        config file monitor for each.  The resulting observer threads are\n        kept in an `observers` list attribute.\n        \"\"\"\n        for config_class in self.watched_configurables:\n            monitor = ConfigFileMonitor(config_class, self.config_dir)\n            self.observers.append(\n                monitor.start(\n                    self.add_configurable,\n                    self.update_configurable,\n                    self.remove_configurable\n                )\n            )\n\n        wait_on_event(self.shutdown)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlaunch a named thread in the thread pool.", "response": "def launch_thread(self, name, fn, *args, **kwargs):\n        \"\"\"\n        Adds a named thread to the \"thread pool\" dictionary of Thread objects.\n\n        A daemon thread that executes the passed-in function `fn` with the\n        given args and keyword args is started and tracked in the `thread_pool`\n        attribute with the given `name` as the key.\n        \"\"\"\n        logger.debug(\n            \"Launching thread '%s': %s(%s, %s)\", name,\n            fn, args, kwargs\n        )\n        self.thread_pool[name] = threading.Thread(\n            target=fn, args=args, kwargs=kwargs\n        )\n        self.thread_pool[name].daemon = True\n        self.thread_pool[name].start()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kill_thread(self, name):\n        if name not in self.thread_pool:\n            return\n\n        self.thread_pool[name].join()\n        del self.thread_pool[name]", "response": "Kills the thread with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_configurable(self, configurable_class, name, config):\n        configurable_class_name = configurable_class.__name__.lower()\n\n        logger.info(\n            \"updating %s: '%s'\", configurable_class_name, name\n        )\n\n        registry = self.registry_for(configurable_class)\n\n        if name not in registry:\n            logger.warn(\n                \"Tried to update unknown %s: '%s'\",\n                configurable_class_name, name\n            )\n            self.add_configurable(\n                configurable_class,\n                configurable_class.from_config(name, config)\n            )\n            return\n\n        registry[name].apply_config(config)\n\n        hook = self.hook_for(configurable_class, \"update\")\n        if not hook:\n            return\n\n        def done(f):\n            try:\n                f.result()\n            except Exception:\n                logger.exception(\"Error updating configurable '%s'\", name)\n\n        self.work_pool.submit(hook, name, config).add_done_callback(done)", "response": "Updates a configurable instance in the registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_configurable(self, configurable_class, name):\n        configurable_class_name = configurable_class.__name__.lower()\n\n        logger.info(\"Removing %s: '%s'\", configurable_class_name, name)\n\n        registry = self.registry_for(configurable_class)\n\n        if name not in registry:\n            logger.warn(\n                \"Tried to remove unknown active %s: '%s'\",\n                configurable_class_name, name\n            )\n            return\n\n        hook = self.hook_for(configurable_class, action=\"remove\")\n        if not hook:\n            registry.pop(name)\n            return\n\n        def done(f):\n            try:\n                f.result()\n                registry.pop(name)\n            except Exception:\n                logger.exception(\"Error removing configurable '%s'\", name)\n\n        self.work_pool.submit(hook, name).add_done_callback(done)", "response": "Removes a configurable instance from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hook_for(self, configurable_class, action):\n        configurable_class_name = configurable_class.__name__.lower()\n\n        return getattr(\n            self,\n            \"on_\" + configurable_class_name + \"_\" + action,\n            None\n        )", "response": "Returns the hook method that is used to determine if an on_<configurable class >_<action> is present."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops the config file observers and threads and work pool.", "response": "def stop(self):\n        \"\"\"\n        Method for shutting down the watcher.\n\n        All config file observers are stopped and their threads joined, along\n        with the worker thread pool.\n        \"\"\"\n        self.shutdown.set()\n\n        for monitor in self.observers:\n            monitor.stop()\n\n        self.wind_down()\n\n        for monitor in self.observers:\n            monitor.join()\n\n        for thread in self.thread_pool.values():\n            thread.join()\n\n        self.work_pool.shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_attributes(self, **kwargs):\n        if self._subresource_map:\n            self.set_subresources(**kwargs)\n            for key in self._subresource_map.keys():\n                # Don't let these attributes be overridden later\n                kwargs.pop(key, None)\n        for field, value in kwargs.items():\n            if field in self.Meta.attributes:\n                setattr(self, field, value)", "response": "Set the resource attributes from the kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_resource_url(cls, resource, base_url):\n        if resource.Meta.resource_name:\n            url = '{}/{}'.format(base_url, resource.Meta.resource_name)\n        else:\n            p = inflect.engine()\n            plural_name = p.plural(resource.Meta.name.lower())\n            url = '{}/{}'.format(base_url, plural_name)\n        return cls._parse_url_and_validate(url)", "response": "Construct the URL for talking to this resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct the URL for talking to an individual resource.", "response": "def get_url(cls, url, uid, **kwargs):\n        \"\"\"\n        Construct the URL for talking to an individual resource.\n\n        http://myapi.com/api/resource/1\n\n        Args:\n            url: The url for this resource\n            uid: The unique identifier for an individual resource\n            kwargs: Additional keyword argueents\n        returns:\n            final_url: The URL for this individual resource\n        \"\"\"\n        if uid:\n            url = '{}/{}'.format(url, uid)\n        else:\n            url = url\n        return cls._parse_url_and_validate(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_method_name(resource, method_type):\n        return '{}_{}'.format(method_type.lower(), resource.Meta.name.lower())", "response": "Generate a method name based on the method type and resource name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_url_and_validate(cls, url):\n        parsed_url = urlparse(url)\n        if parsed_url.scheme and parsed_url.netloc:\n            final_url = parsed_url.geturl()\n        else:\n            raise BadURLException\n        return final_url", "response": "Recieves a URL string and validates it using urlparse. geturl and returns the final URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the related method on the object based on the resource and full_resource_url.", "response": "def set_related_method(self, resource, full_resource_url):\n        \"\"\"\n        Using reflection, generate the related method and return it.\n        \"\"\"\n        method_name = self.get_method_name(resource, 'get')\n\n        def get(self, **kwargs):\n            return self._call_api_single_related_resource(\n                resource, full_resource_url, method_name, **kwargs\n            )\n\n        def get_list(self, **kwargs):\n            return self._call_api_many_related_resources(\n                resource, full_resource_url, method_name, **kwargs\n            )\n\n        if isinstance(full_resource_url, list):\n            setattr(\n                self, method_name,\n                types.MethodType(get_list, self)\n            )\n        else:\n            setattr(\n                self, method_name,\n                types.MethodType(get, self)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying and match them up to resources in the related_resources attribute.", "response": "def match_urls_to_resources(self, url_values):\n        \"\"\"\n        For the list of valid URLs, try and match them up\n        to resources in the related_resources attribute.\n\n        Args:\n            url_values: A dictionary of keys and URL strings that\n                        could be related resources.\n        Returns:\n            valid_values: The values that are valid\n        \"\"\"\n        valid_values = {}\n        for resource in self.Meta.related_resources:\n            for k, v in url_values.items():\n                resource_url = resource.get_resource_url(\n                    resource, resource.Meta.base_url)\n                if isinstance(v, list):\n                    if all([resource_url in i for i in v]):\n                        self.set_related_method(resource, v)\n                        valid_values[k] = v\n                elif resource_url in v:\n                    self.set_related_method(resource, v)\n                    valid_values[k] = v\n        return valid_values"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_attributes(self, **kwargs):\n        if not self.Meta.related_resources:\n            # Just do what the normal BaseResource does\n            super(HypermediaResource, self).set_attributes(**kwargs)\n            return\n\n        # Extract all the values that are URLs\n        url_values = {}\n        for k, v in kwargs.items():\n            try:\n                if isinstance(v, list):\n                    [self._parse_url_and_validate(i) for i in v]\n                else:\n                    self._parse_url_and_validate(v)\n                url_values[k] = v\n            except BadURLException:\n                # This is a badly formed URL or not a URL at all, so skip\n                pass\n        # Assign the valid method values and then remove them from the kwargs\n        assigned_values = self.match_urls_to_resources(url_values)\n        for k in assigned_values.keys():\n            kwargs.pop(k, None)\n        # Assign the rest as attributes.\n        for field, value in kwargs.items():\n            if field in self.Meta.attributes:\n                setattr(self, field, value)", "response": "This method will set the attributes of the resource based on the kwargs and then assign them to the attributes of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the resource attributes from the kwargs.", "response": "def set_attributes(self, **kwargs):\n        \"\"\"\n        Set the resource attributes from the kwargs.\n        Only sets items in the `self.Meta.attributes` white list.\n\n        Args:\n            kwargs: Keyword arguements passed into the init of this class\n        \"\"\"\n        for field, value in kwargs.items():\n            if field in self.Meta.attributes:\n                setattr(self, field, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(db, anime):\n    aid = anime.aid\n    values = {\n        'aid': aid,\n        'title': anime.title,\n        'type': anime.type,\n        'episodecount': anime.episodecount,\n    }\n    if anime.startdate is not None:\n        values['startdate'] = datets.to_ts(anime.startdate)\n    if anime.enddate is not None:\n        values['enddate'] = datets.to_ts(anime.enddate)\n    with db:\n        upsert(db, 'anime', ['aid'], values)\n        our_anime = lookup(db, anime.aid, episode_fields=ALL)\n        our_episodes = our_anime.episodes\n        for episode in anime.episodes:\n            add_episode(db, aid, episode)\n            our_episodes = [\n                ep for ep in our_episodes\n                if not (ep.type == episode.type and ep.number == episode.number)\n            ]\n        # Remove extra episodes that we have.\n        for episode in our_episodes:\n            delete_episode(db, aid, episode)", "response": "Add an anime to the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_episode(db, aid, episode):\n    values = {\n        'aid': aid,\n        'type': episode.type,\n        'number': episode.number,\n        'title': episode.title,\n        'length': episode.length,\n    }\n    upsert(db, 'episode', ['aid', 'type', 'number'], values)", "response": "Add an episode to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_watched(db, aid, ep_type, number):\n    db.cursor().execute(\n        \"\"\"UPDATE episode SET user_watched=:watched\n        WHERE aid=:aid AND type=:type AND number=:number\"\"\",\n        {\n            'aid': aid,\n            'type': ep_type,\n            'number': number,\n            'watched': 1,\n        })", "response": "Set the user_watched flag for the given episode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bump(db, aid):\n    anime = lookup(db, aid)\n    if anime.complete:\n        return\n    episode = anime.watched_episodes + 1\n    with db:\n        set_watched(db, aid, get_eptype(db, 'regular').id, episode)\n        set_status(\n            db, aid,\n            anime.enddate and episode >= anime.episodecount,\n            episode)", "response": "Bump anime regular episode count."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting the count for anime.", "response": "def reset(db, aid, episode):\n    \"\"\"Reset episode count for anime.\"\"\"\n    params = {\n        'aid': aid,\n        'type': get_eptype(db, 'regular').id,\n        'watched': 1,\n        'number': episode,\n    }\n    with db:\n        cur = db.cursor()\n        cur.execute(\n            \"\"\"UPDATE episode SET user_watched=:watched\n            WHERE aid=:aid AND type=:type AND number<=:number\"\"\",\n            params)\n        params['watched'] = 0\n        cur.execute(\n            \"\"\"UPDATE episode SET user_watched=:watched\n            WHERE aid=:aid AND type=:type AND number>:number\"\"\",\n            params)\n        cache_status(db, aid, force=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntrains an IDF model on a list of files.", "response": "def train_idf(tokens_stream, out=None, **kwargs):\n    \"\"\"\n    Train a IDF model on a list of files (parallelized).\n    \"\"\"\n    idfs = parallel(count_idf, tokens_stream, n_jobs=-1)\n    N = len(idfs) # n docs\n    idf = merge(idfs)\n\n    for k, v in idf.items():\n        idf[k] = math.log(N/v)\n        # v ~= N/(math.e ** idf[k])\n\n    # Keep track of N to update IDFs\n    idf['_n_docs'] = N\n\n    if out is not None:\n        with open(out, 'w') as f:\n            json.dump(idf, f)\n\n    return idf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __authenticate(self):\n        if self.api_token:\n            # verify current API token\n            check_auth_uri = self.uri.split('/api/v1')[0] + '/check_token'\n            req = self.request(check_auth_uri)\n            try:\n                ping = req.get().json()\n            except Exception as exc:\n                if str(exc).startswith('User not authenticated'):\n                    self.api_token = None\n            else:\n                if self.email == ping['hello']:\n                    return\n                print \"Authentication failed\"\n                sys.exit(1)\n\n        auth_uri = self.uri.split('/api/v1')[0] + '/auth'\n        payload = {\n            'email': self.email,\n            'password': self.password,\n            'org_id': self.org_name\n        }\n        data = json.dumps(payload)\n        req = self.request(auth_uri, data=data)\n        response = req.post().json()\n        token = response.get('mist_api_token', None)\n        if token:\n            # backwards compatibility with old Authentication system\n            self.api_token = \"mist_1 %s:%s\" % (self.email, token)\n        else:\n            self.api_token = response.get('token', None)", "response": "Authenticate the user to get the API token"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the user info information from the API", "response": "def user_info(self):\n        \"\"\"\n        General user info information as returned in /account in our API\n        \"\"\"\n        account_uri = self.uri.split('/api/v1')[0] + '/account'\n        req = self.request(account_uri)\n        account_info = req.get()\n        user_data = HTMLParser(account_info.content)\n        return user_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequest a list of all available providers", "response": "def supported_providers(self):\n        \"\"\"\n        Request a list of all available providers\n\n        :returns: A list of all available providers (e.g. {'provider':\n        'ec2_ap_northeast', 'title': 'EC2 AP NORTHEAST'})\n        \"\"\"\n        req = self.request(self.uri + '/providers', api_version=2)\n        providers = req.get().json()\n        supported_providers = providers['supported_providers']\n        return supported_providers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting a list of all added clouds.", "response": "def _list_clouds(self):\n        \"\"\"\n        Request a list of all added clouds.\n\n        Populates self._clouds dict with mist.client.model.Cloud instances\n        \"\"\"\n        req = self.request(self.uri + '/clouds')\n        clouds = req.get().json()\n        if clouds:\n            for cloud in clouds:\n                self._clouds[cloud['id']] = Cloud(cloud, self)\n        else:\n            self._clouds = {}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clouds(self, id=None, name=None, provider=None, search=None):\n        if self._clouds is None:\n            self._clouds = {}\n            self._list_clouds()\n\n        if id:\n            return [self._clouds[cloud_id] for cloud_id in self._clouds.keys()\n                    if id == self._clouds[cloud_id].id]\n        elif name:\n            return [self._clouds[cloud_id] for cloud_id in self._clouds.keys()\n                    if name == self._clouds[cloud_id].title]\n        elif provider:\n            return [self._clouds[cloud_id] for cloud_id in self._clouds.keys()\n                    if provider == self._clouds[cloud_id].provider]\n        elif search:\n            return [self._clouds[cloud_id] for cloud_id in self._clouds.keys()\n                    if search in self._clouds[cloud_id].title\n                    or search in self._clouds[cloud_id].id\n                    or search in self._clouds[cloud_id].provider]\n        else:\n            return [self._clouds[cloud_id] for cloud_id in self._clouds.keys()]", "response": "Property - like function to call the _list_clouds function in order to populate self. _clouds dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a list of all added Keys and populates the self. _keys dict with Key instances", "response": "def _list_keys(self):\n        \"\"\"\n        Retrieves a list of all added Keys and populates the\n        self._keys dict with Key instances\n\n        :returns: A list of Keys instances\n        \"\"\"\n        req = self.request(self.uri + '/keys')\n        keys = req.get().json()\n        if keys:\n            self._keys = {}\n            for key in keys:\n                self._keys[key['id']] = Key(key, self)\n        else:\n            self._keys = {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keys(self, id=None, search=None):\n        if self._keys is None:\n            self._keys = {}\n            self._list_keys()\n\n        if id:\n            return [self._keys[key_id] for key_id in self._keys.keys()\n                    if id == self._keys[key_id].id]\n        elif search:\n            return [self._keys[key_id] for key_id in self._keys.keys()\n                    if (search in self._keys[key_id].id) or (search in self._keys[key_id].name)]\n        else:\n            return [self._keys[key_id] for key_id in self._keys.keys()]", "response": "Property - like function to call the _list_keys function in order to populate self. _keys dict with the keys of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_key(self):\n        req = self.request(self.uri + \"/keys\")\n        private_key = req.post().json()\n        return private_key['priv']", "response": "Ask mist. io to randomly generate a private ssh - key to be\n        used with the creation of a new Key\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new key to mist. io.", "response": "def add_key(self, key_name, private):\n        \"\"\"\n        Add a new key to mist.io\n\n        :param key_name: Name of the new key (it will be used as the key's id as well).\n        :param private: Private ssh-key in string format (see also generate_key() ).\n\n        :returns: An updated list of added keys.\n        \"\"\"\n        payload = {\n            'name': key_name,\n            'priv': private\n        }\n\n        data = json.dumps(payload)\n\n        req = self.request(self.uri + '/keys', data=data)\n        response = req.put().json()\n\n        self.update_keys()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a priority rule for files.", "response": "def command(state, args):\n    \"\"\"Add a priority rule for files.\"\"\"\n    args = parser.parse_args(args[1:])\n    row_id = query.files.add_priority_rule(state.db, args.regexp, args.priority)\n    del state.file_picker\n    print('Added rule {}'.format(row_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes an anime API request.", "response": "def request_anime(aid: int) -> 'Anime':\n    \"\"\"Make an anime API request.\"\"\"\n    anime_info = alib.request_anime(_CLIENT, aid)\n    return Anime._make(anime_info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef number(self) -> int:\n        match = self._NUMBER_SUFFIX.search(self.epno)\n        return int(match.group(1))", "response": "Episode number.\n\n        Unique for an anime and episode type, but not unique across episode\n        types for the same anime."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef title(self) -> str:\n        for title in self.titles:\n            if title.lang == 'ja':\n                return title.title\n        # In case there's no Japanese title.\n        return self.titles[0].title", "response": "Return the title of the episode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(self, query: 're.Pattern') -> 'Iterable[_WorkTitles]':\n        titles: 'Titles'\n        for titles in self._titles_list:\n            title: 'AnimeTitle'\n            for title in titles.titles:\n                if query.search(title.title):\n                    yield WorkTitles(\n                        aid=titles.aid,\n                        main_title=_get_main_title(titles.titles),\n                        titles=[t.title for t in titles.titles],\n                    )\n                    continue", "response": "Search titles using a compiled RE query."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts pkg_resources. working_set into a list of Package objects.", "response": "def _get_packages():\n    # type: () -> List[Package]\n    \"\"\"Convert `pkg_resources.working_set` into a list of `Package` objects.\n\n    :return: list\n    \"\"\"\n    return [Package(pkg_obj=pkg) for pkg in sorted(pkg_resources.working_set,\n                                                   key=lambda x: str(x).lower())]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_whitelist_licenses(config_path):\n    # type: (str) -> List[str]\n    \"\"\"Get whitelist license names from config file.\n\n    :param config_path: str\n    :return: list\n    \"\"\"\n\n    whitelist_licenses = []\n\n    try:\n        print('config path', config_path)\n        with open(config_path) as config:\n            whitelist_licenses = [line.rstrip() for line in config]\n    except IOError:  # pragma: no cover\n        print('Warning: No {} file was found.'.format(LICENSE_CHECKER_CONFIG_NAME))\n\n    return whitelist_licenses", "response": "Get whitelist license names from config file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_license_checker(config_path):\n    # type: (str) -> None\n    \"\"\"Generate table of installed packages and check for license\n    warnings based off user defined restricted license values.\n\n    :param config_path: str\n    :return:\n    \"\"\"\n    whitelist_licenses = _get_whitelist_licenses(config_path)\n    table = PrintTable(ROW_HEADERS)\n\n    warnings = []\n\n    for pkg in _get_packages():\n        allowed = pkg.license in whitelist_licenses\n        table.add_row((pkg.name, pkg.version, pkg.license, str(allowed)))\n\n        if not allowed:\n            warnings.append(pkg)\n\n    print(table)\n\n    print('{} RESTRICTED LICENSES DETECTED'.format(len(warnings)))", "response": "Runs license checker on the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef include_fields(self, *args):\n        for arg in args:\n            self._includefields.append(arg)\n        return self", "response": "r Include fields that you want to return when searching for."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the start and end times for this search.", "response": "def timeframe(self, start, end):\n        r\"\"\"\n            When you want to search bugs for a certain time frame.\n\n            :param start:\n            :param end:\n            :returns: :class:`Search`\n        \"\"\"\n        if start:\n            self._time_frame['chfieldfrom'] = start\n        if end:\n            self._time_frame['chfieldto'] = end\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self):\n        params = {}\n        params.update(self._time_frame.items())\n\n        if self._includefields:\n            params['include_fields'] = list(self._includefields)\n        if self._bug_numbers:\n            bugs = []\n            for bug in self._bug_numbers:\n                result = self._bugsy.request('bug/%s' % bug,\n                                             params=params)\n                bugs.append(Bug(self._bugsy, **result['bugs'][0]))\n\n            return bugs\n        else:\n            if self._component:\n                params['component'] = list(self._component)\n            if self._product:\n                params['product'] = list(self._product)\n            if self._keywords:\n                params['keywords'] = list(self._keywords)\n            if self._assigned:\n                params['assigned_to'] = list(self._assigned)\n            if self._summaries:\n                params['short_desc_type'] = 'allwordssubstr'\n                params['short_desc'] = list(self._summaries)\n            if self._whiteboard:\n                params['short_desc_type'] = 'allwordssubstr'\n                params['whiteboard'] = list(self._whiteboard)\n            if self._change_history['fields']:\n                params['chfield'] = self._change_history['fields']\n            if self._change_history.get('value', None):\n                params['chfieldvalue'] = self._change_history['value']\n\n            try:\n                results = self._bugsy.request('bug', params=params)\n            except Exception as e:\n                raise SearchException(e.msg, e.code)\n\n            return [Bug(self._bugsy, **bug) for bug in results['bugs']]", "response": "This method will call Bugzilla s search_for method and returns a list of bugs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing an ISO format date.", "response": "def _parse_date(string: str) -> datetime.date:\n    \"\"\"Parse an ISO format date (YYYY-mm-dd).\n\n    >>> _parse_date('1990-01-02')\n    datetime.date(1990, 1, 2)\n    \"\"\"\n    return datetime.datetime.strptime(string, '%Y-%m-%d').date()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync_remote_to_local(force=\"no\"):\n\n    assert \"local_wp_dir\" in env, \"Missing local_wp_dir in env\"\n\n    if force != \"yes\":\n        message = \"This will replace your local database with your \"\\\n            \"remote, are you sure [y/n]\"\n        answer = prompt(message, \"y\")\n\n        if answer != \"y\":\n            logger.info(\"Sync stopped\")\n            return\n\n    init_tasks()  # Bootstrap fabrik\n\n    remote_file = \"sync_%s.sql\" % int(time.time()*1000)\n    remote_path = \"/tmp/%s\" % remote_file\n\n    with env.cd(paths.get_current_path()):\n        env.run(\"wp db export %s\" % remote_path)\n\n    local_wp_dir = env.local_wp_dir\n    local_path = \"/tmp/%s\" % remote_file\n\n    # Download sync file\n    get(remote_path, local_path)\n\n    with lcd(local_wp_dir):\n        elocal(\"wp db import %s\" % local_path)\n\n    # Cleanup\n    env.run(\"rm %s\" % remote_path)\n    elocal(\"rm %s\" % local_path)", "response": "Syncs a remote database with the local database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget file priority rules.", "response": "def get_priority_rules(db) -> Iterable[PriorityRule]:\n    \"\"\"Get file priority rules.\"\"\"\n    cur = db.cursor()\n    cur.execute('SELECT id, regexp, priority FROM file_priority')\n    for row in cur:\n        yield PriorityRule(*row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a file priority rule.", "response": "def add_priority_rule(\n        db, regexp: str, priority: Optional[int] = None,\n) -> int:\n    \"\"\"Add a file priority rule.\"\"\"\n    with db:\n        cur = db.cursor()\n        if priority is None:\n            cur.execute('SELECT MAX(priority) FROM file_priority')\n            highest_priority = cur.fetchone()[0]\n            if highest_priority is None:\n                priority = 1\n            else:\n                priority = highest_priority + 1\n        cur.execute(\"\"\"\n            INSERT INTO file_priority (regexp, priority)\n            VALUES (?, ?)\"\"\", (regexp, priority))\n        row_id = db.last_insert_rowid()\n    return row_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_priority_rule(db, rule_id: int) -> None:\n    with db:\n        cur = db.cursor()\n        cur.execute('DELETE FROM file_priority WHERE id=?', (rule_id,))", "response": "Delete a file priority rule."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncaching files for anime.", "response": "def cache_files(db, aid: int, anime_files: AnimeFiles) -> None:\n    \"\"\"Cache files for anime.\"\"\"\n    with db:\n        cache_status(db, aid)\n        db.cursor().execute(\n            \"\"\"UPDATE cache_anime\n            SET anime_files=?\n            WHERE aid=?\"\"\",\n            (anime_files.to_json(), aid))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_files(conn, aid: int) -> AnimeFiles:\n    with conn:\n        cur = conn.cursor().execute(\n            'SELECT anime_files FROM cache_anime WHERE aid=?',\n            (aid,))\n        row = cur.fetchone()\n        if row is None:\n            raise ValueError('No cached files')\n        return AnimeFiles.from_json(row[0])", "response": "Get cached files for anime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to add a file.", "response": "def add(self, filename):\n        \"\"\"Try to add a file.\"\"\"\n        basename = os.path.basename(filename)\n        match = self.regexp.search(basename)\n        if match:\n            self.by_episode[int(match.group('ep'))].add(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string of available episodes.", "response": "def available_string(self, episode):\n        \"\"\"Return a string of available episodes.\"\"\"\n        available = [ep for ep in self if ep > episode]\n        string = ','.join(str(ep) for ep in available[:self.EPISODES_TO_SHOW])\n        if len(available) > self.EPISODES_TO_SHOW:\n            string += '...'\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_json(cls, string):\n        obj = json.loads(string)\n        return cls(obj['regexp'], obj['files'])", "response": "Create AnimeFiles from JSON string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns replaced db_name and collection_name with the same name as the given spider.", "response": "def _replace_placeholder(self, spider):\n        \"\"\"\n        Returns replaced db_name and collection_name(base on spider's name).\n        if your db_name or collection_name does not have a placeholder or\n        your db_name or collection_name that not base on spider's name\n        you must override this function.\n        \"\"\"\n        return self.db_name % {'spider': spider.name}, self.collection_name % {'spider': spider.name}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a full plex request URI with params.", "response": "def construct_url(self):\n        \"\"\"Construct a full plex request URI, with `params`.\"\"\"\n        path = [self.path]\n        path.extend([str(x) for x in self.params])\n\n        url = self.client.base_url + '/'.join(x for x in path if x)\n        query = self.kwargs.get('query')\n\n        if query:\n            # Dict -> List\n            if type(query) is dict:\n                query = query.items()\n\n            # Remove items with `None` value\n            query = [\n                (k, v) for (k, v) in query\n                if v is not None\n            ]\n\n            # Encode query, append to URL\n            url += '?' + urlencode(query)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login_required(f):\n\n    @wraps(f)\n    def check_login(cls, *args, **kwargs):\n        if not cls.logged_in:\n            raise FMBaseError('Please login to use this method')\n\n        return f(cls, *args, **kwargs)\n\n    return check_login", "response": "Decorator to check if user is logged in."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_config():\n\n    configfile = get_configfile()\n\n    if not os.path.exists(configfile):\n        data = {\n            'apikey': 'GET KEY AT: https://www.filemail.com/apidoc/ApiKey.aspx'\n            }\n\n        save_config(data)\n\n    with open(configfile, 'rb') as f:\n        return json.load(f)", "response": "Load configuration file containing API KEY and other settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_config(config):\n\n    configfile = get_configfile()\n\n    if not os.path.exists(configfile):\n        configdir = os.path.dirname(configfile)\n\n        if not os.path.exists(configdir):\n            os.makedirs(configdir)\n\n    data = config\n\n    with open(configfile, 'wb') as f:\n        json.dump(data, f, indent=2)", "response": "Save the configuration file to users data location."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning full path to configuration file.", "response": "def get_configfile():\n    \"\"\"Return full path to configuration file.\n\n     - Linux: ~/.local/share/pyfilemail\n     - OSX: ~/Library/Application Support/pyfilemail\n     - Windows: C:\\\\\\Users\\\\\\{username}\\\\\\AppData\\\\\\Local\\\\\\pyfilemail\n\n     :rtype: str\n    \"\"\"\n\n    ad = appdirs.AppDirs('pyfilemail')\n    configdir = ad.user_data_dir\n    configfile = os.path.join(configdir, 'pyfilemail.cfg')\n\n    return configfile"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_config(cls, name, config):\n        if name != cls.name:\n            return\n\n        return super(Logging, cls).from_config(name, config)", "response": "Override of base. from_config that returns None if the name of the config file isn t logging."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking for local config overrides for flake8 and adds them in the correct flake8 options format.", "response": "def get_flake8_options(config_dir='.'):\n    # type: (str) -> List[str]\n    \"\"\"Checks for local config overrides for `flake8`\n    and add them in the correct `flake8` `options` format.\n\n    :param config_dir:\n    :return: List[str]\n    \"\"\"\n    if FLAKE8_CONFIG_NAME in os.listdir(config_dir):\n        flake8_config_path = FLAKE8_CONFIG_NAME\n    else:\n        flake8_config_path = DEFAULT_FLAKE8_CONFIG_PATH\n\n    return ['--config={}'.format(flake8_config_path)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_license_checker_config_path(config_dir='.'):\n    # type: (str) -> List[str]\n    \"\"\"Checks for local config overrides for license checker,\n    if not found it returns the package default.\n\n    :param config_dir:\n    :return: str\n    \"\"\"\n    if LICENSE_CHECKER_CONFIG_NAME in os.listdir(config_dir):\n        license_checker_config_path = LICENSE_CHECKER_CONFIG_NAME\n    else:\n        license_checker_config_path = DEFAULT_LICENSE_CHECKER_CONFIG_PATH\n\n    return license_checker_config_path", "response": "Checks for local config overrides for license checker"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pylint_options(config_dir='.'):\n    # type: (str) -> List[str]\n    \"\"\"Checks for local config overrides for `pylint`\n    and add them in the correct `pylint` `options` format.\n\n    :param config_dir:\n    :return: List [str]\n    \"\"\"\n    if PYLINT_CONFIG_NAME in os.listdir(config_dir):\n        pylint_config_path = PYLINT_CONFIG_NAME\n    else:\n        pylint_config_path = DEFAULT_PYLINT_CONFIG_PATH\n\n    return ['--rcfile={}'.format(pylint_config_path)]", "response": "Checks for local config overrides for pylint and adds them in the correct pylint options format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_on_event(event, timeout=None):\n    if timeout is not None:\n        event.wait(timeout)\n        return\n\n    if six.PY2:\n        # Thanks to a bug in python 2's threading lib, we can't simply call\n        # .wait() with no timeout since it would wind up ignoring signals.\n        while not event.is_set():\n            event.wait(sys.maxint)\n    else:\n        event.wait()", "response": "Waits on an event with an optional timeout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that the given config file path control socket file path and PID file path are all present in the HAProxy config.", "response": "def validate_config(cls, config):\n        \"\"\"\n        Validates that a config file path and a control socket file path\n        and pid file path are all present in the HAProxy config.\n        \"\"\"\n        if \"config_file\" not in config:\n            raise ValueError(\"No config file path given\")\n        if \"socket_file\" not in config:\n            raise ValueError(\"No control socket path given\")\n        if \"pid_file\" not in config:\n            raise ValueError(\"No PID file path given\")\n        if \"stats\" in config and \"port\" not in config[\"stats\"]:\n            raise ValueError(\"Stats interface defined, but no port given\")\n        if \"proxies\" in config:\n            cls.validate_proxies_config(config[\"proxies\"])\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_proxies_config(cls, proxies):\n        for name, proxy in six.iteritems(proxies):\n            if \"port\" not in proxy:\n                raise ValueError(\"No port defined for proxy %s\" % name)\n            if \"upstreams\" not in proxy:\n                raise ValueError(\n                    \"No upstreams defined for proxy %s\" % name\n                )\n            for upstream in proxy[\"upstreams\"]:\n                if \"host\" not in upstream:\n                    raise ValueError(\n                        \"No host defined for upstream in proxy %s\" % name\n                    )\n                if \"port\" not in upstream:\n                    raise ValueError(\n                        \"No port defined for upstream in proxy %s\" % name\n                    )", "response": "Validate that the proxies config is well - formed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_config(self, config):\n        self.haproxy_config_path = config[\"config_file\"]\n\n        global_stanza = Stanza(\"global\")\n        global_stanza.add_lines(config.get(\"global\", []))\n        global_stanza.add_lines([\n            \"stats socket %s mode 600 level admin\" % config[\"socket_file\"],\n            \"stats timeout 2m\"\n        ])\n\n        defaults_stanza = Stanza(\"defaults\")\n        defaults_stanza.add_lines(config.get(\"defaults\", []))\n\n        proxy_stanzas = [\n            ProxyStanza(\n                name, proxy[\"port\"], proxy[\"upstreams\"],\n                proxy.get(\"options\", []),\n                proxy.get(\"bind_address\")\n            )\n            for name, proxy in six.iteritems(config.get(\"proxies\", {}))\n        ]\n\n        stats_stanza = None\n        if \"stats\" in config:\n            stats_stanza = StatsStanza(\n                config[\"stats\"][\"port\"], config[\"stats\"].get(\"uri\", \"/\")\n            )\n            for timeout in (\"client\", \"connect\", \"server\"):\n                if timeout in config[\"stats\"].get(\"timeouts\", {}):\n                    stats_stanza.add_line(\n                        \"timeout %s %d\" % (\n                            timeout,\n                            config[\"stats\"][\"timeouts\"][timeout]\n                        )\n                    )\n\n        self.config_file = HAProxyConfig(\n            global_stanza, defaults_stanza,\n            proxy_stanzas=proxy_stanzas, stats_stanza=stats_stanza,\n            meta_clusters=config.get(\"meta_clusters\", {}),\n            bind_address=config.get(\"bind_address\")\n        )\n\n        self.control = HAProxyControl(\n            config[\"config_file\"], config[\"socket_file\"], config[\"pid_file\"],\n        )", "response": "Applies the given configuration to the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_file(self, clusters):\n        logger.info(\"Updating HAProxy config file.\")\n        if not self.restart_required:\n            self.sync_nodes(clusters)\n\n        version = self.control.get_version()\n\n        with open(self.haproxy_config_path, \"w\") as f:\n            f.write(self.config_file.generate(clusters, version=version))\n\n        if self.restart_required:\n            with self.restart_lock:\n                self.restart()", "response": "Generates new HAProxy config file content and writes it to the file at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restart(self):\n        delay = (self.last_restart - time.time()) + self.restart_interval\n\n        if delay > 0:\n            time.sleep(delay)\n\n        self.control.restart()\n\n        self.last_restart = time.time()\n        self.restart_required = False", "response": "Tells the HAProxy control object to restart the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_current_nodes(self, clusters):\n        current_nodes = self.control.get_active_nodes()\n        enabled_nodes = collections.defaultdict(list)\n\n        for cluster in clusters:\n            if not cluster.nodes:\n                continue\n\n            if cluster.name not in current_nodes:\n                logger.debug(\n                    \"New cluster '%s' added, restart required.\",\n                    cluster.name\n                )\n                self.restart_required = True\n\n            for node in cluster.nodes:\n                if node.name not in [\n                        current_node[\"svname\"]\n                        for current_node in current_nodes.get(cluster.name, [])\n                ]:\n                    logger.debug(\n                        \"New node added to cluster '%s', restart required.\",\n                        cluster.name\n                    )\n                    self.restart_required = True\n\n                enabled_nodes[cluster.name].append(node.name)\n\n        return current_nodes, enabled_nodes", "response": "Returns two dictionaries the current nodes and the enabled nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the given config is valid.", "response": "def validate_config(cls, config):\n        \"\"\"\n        Runs a check on the given config to make sure that `port`/`ports` and\n        `discovery` is defined.\n        \"\"\"\n        if \"discovery\" not in config:\n            raise ValueError(\"No discovery method defined.\")\n\n        if not any([item in config for item in [\"port\", \"ports\"]]):\n            raise ValueError(\"No port(s) defined.\")\n\n        cls.validate_check_configs(config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_check_configs(cls, config):\n        if \"checks\" not in config:\n            raise ValueError(\"No checks defined.\")\n        if \"interval\" not in config[\"checks\"]:\n            raise ValueError(\"No check interval defined.\")\n\n        for check_name, check_config in six.iteritems(config[\"checks\"]):\n            if check_name == \"interval\":\n                continue\n\n            Check.from_config(check_name, check_config)", "response": "Validate the health check configurations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_config(self, config):\n        self.host = config.get(\"host\", \"127.0.0.1\")\n\n        self.configured_ports = config.get(\"ports\", [config.get(\"port\")])\n\n        self.discovery = config[\"discovery\"]\n\n        self.metadata = config.get(\"metadata\", {})\n\n        self.update_ports()\n\n        self.check_interval = config[\"checks\"][\"interval\"]\n\n        self.update_checks(config[\"checks\"])", "response": "Applies a validated config dictionary and sets the instance\n        attribute for each one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the ports attribute of the object based on the current configuration.", "response": "def update_ports(self):\n        \"\"\"\n        Sets the `ports` attribute to the set of valid port values set in\n        the configuration.\n        \"\"\"\n        ports = set()\n\n        for port in self.configured_ports:\n            try:\n                ports.add(int(port))\n            except ValueError:\n                logger.error(\"Invalid port value: %s\", port)\n                continue\n\n        self.ports = ports"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the checks attribute with the given list of check_configs.", "response": "def update_checks(self, check_configs):\n        \"\"\"\n        Maintains the values in the `checks` attribute's dictionary.  Each\n        key in the dictionary is a port, and each value is a nested dictionary\n        mapping each check's name to the Check instance.\n\n        This method makes sure the attribute reflects all of the properly\n        configured checks and ports.  Removing no-longer-configured ports\n        is left to the `run_checks` method.\n        \"\"\"\n        for check_name, check_config in six.iteritems(check_configs):\n            if check_name == \"interval\":\n                continue\n\n            for port in self.ports:\n                try:\n                    check = Check.from_config(check_name, check_config)\n                    check.host = self.host\n                    check.port = port\n                    self.checks[port][check_name] = check\n                except ValueError as e:\n                    logger.error(\n                        \"Error when configuring check '%s' for service %s: %s\",\n                        check_name, self.name, str(e)\n                    )\n                    continue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the checks on each of the ports and returns a two - element tuple that is the set of ports that have been transitioned from up to down.", "response": "def run_checks(self):\n        \"\"\"\n        Iterates over the configured ports and runs the checks on each one.\n\n        Returns a two-element tuple: the first is the set of ports that\n        transitioned from down to up, the second is the set of ports that\n        transitioned from up to down.\n\n        Also handles the case where a check for a since-removed port is run,\n        marking the port as down regardless of the check's result and removing\n        the check(s) for the port.\n        \"\"\"\n        came_up = set()\n        went_down = set()\n\n        for port in self.ports:\n            checks = self.checks[port].values()\n\n            if not checks:\n                logger.warn(\"No checks defined for self: %s\", self.name)\n\n            for check in checks:\n                check.run()\n\n            checks_pass = all([check.passing for check in checks])\n\n            if self.is_up[port] in (False, None) and checks_pass:\n                came_up.add(port)\n                self.is_up[port] = True\n            elif self.is_up[port] in (True, None) and not checks_pass:\n                went_down.add(port)\n                self.is_up[port] = False\n\n        for unused_port in set(self.checks.keys()) - self.ports:\n            went_down.add(unused_port)\n            del self.checks[unused_port]\n\n        return came_up, went_down"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the output data folder and store the results in the database.", "response": "def parse_with_retrieved(self, retrieved):\n        \"\"\"\n        Parse output data folder, store results in database.\n\n        :param retrieved: a dictionary of retrieved nodes, where\n          the key is the link name\n        :returns: a tuple with two values ``(bool, node_list)``,\n          where:\n\n          * ``bool``: variable to tell if the parsing succeeded\n          * ``node_list``: list of new nodes to be stored in the db\n            (as a list of tuples ``(link_name, node)``)\n        \"\"\"\n        from aiida.orm.data.singlefile import SinglefileData\n        success = False\n        node_list = []\n\n        # Check that the retrieved folder is there\n        try:\n            out_folder = retrieved['retrieved']\n        except KeyError:\n            self.logger.error(\"No retrieved folder found\")\n            return success, node_list\n\n        # Check the folder content is as expected\n        list_of_files = out_folder.get_folder_list()\n        output_files = self._calc.inp.parameters.output_files\n        # Note: set(A) <= set(B) checks whether A is a subset\n        if set(output_files) <= set(list_of_files):\n            pass\n        else:\n            self.logger.error(\n                \"Not all expected output files {} were found\".format(\n                    output_files))\n            return success, node_list\n\n        output_links = self._calc.inp.parameters.output_links\n        for fname, link in list(zip(output_files, output_links)):\n\n            parsed = SinglefileData(file=out_folder.get_abs_path(fname))\n            node_list.append((link, parsed))\n\n        success = True\n        return success, node_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mark_deactivated(self,request,queryset):\n        rows_updated = queryset.update(Active=False, End=datetime.date.today() )\n        if rows_updated == 1:\n            message_bit = \"1 cage was\"\n        else:\n            message_bit = \"%s cages were\" % rows_updated\n        self.message_user(request, \"%s successfully marked as deactivated.\" % message_bit)", "response": "An admin action for marking several cages as inactive. This action sets the selected cages as Active = False and Death = today."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the program with an optional main function and argv list.", "response": "def run(main=None, argv=None):\n    \"\"\"Runs the program with an optional 'main' function and 'argv' list.\"\"\"\n    flags_obj = flags.FLAGS\n    absl_flags_obj = absl_flags.FLAGS\n\n    # Extract the args from the optional `argv` list.\n    args = argv[1:] if argv else None\n\n    # Parse the known flags from that list, or from the command\n    # line otherwise.\n    # pylint: disable=protected-access\n    flags_passthrough = flags_obj._parse_flags(args=args)\n    # pylint: enable=protected-access\n\n    # Immediately after flags are parsed, bump verbosity to INFO if the flag has\n    # not been set.\n    if absl_flags_obj[\"verbosity\"].using_default_value:\n        absl_flags_obj.verbosity = 0\n\n    main = main or sys.modules['__main__'].main\n\n    # Call the main function, passing through any arguments\n    # to the final program.\n    sys.exit(main(sys.argv[:1] + flags_passthrough))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_unicode(s, encoding='utf-8', encoding_errors='strict'):\n    if not isinstance(s, unicode):\n        if not isinstance(s, basestring):\n            return unicode(str(s), encoding, encoding_errors)\n        return unicode(s, encoding, encoding_errors)\n    return s", "response": "Return the unicode version of an input."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef html_escape(s, encoding='utf-8', encoding_errors='strict'):\n    return escape(make_unicode(s, encoding, encoding_errors), quote=True)", "response": "Return the HTML - escaped version of an input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a composition of a song that changes its length to a given duration.", "response": "def retarget_to_length(song, duration, start=True, end=True, slack=5,\n                       beats_per_measure=None):\n    \"\"\"Create a composition of a song that changes its length\n    to a given duration.\n\n    :param song: Song to retarget\n    :type song: :py:class:`radiotool.composer.Song`\n    :param duration: Duration of retargeted song (in seconds)\n    :type duration: float\n    :param start: Start the retargeted song at the\n                  beginning of the original song\n    :type start: boolean\n    :param end: End the retargeted song at the end of the original song\n    :type end: boolean\n    :param slack: Track will be within slack seconds of the target\n                  duration (more slack allows for better-sounding music)\n    :type slack: float\n    :returns: Composition of retargeted song\n    :rtype: :py:class:`radiotool.composer.Composition`\n    \"\"\"\n\n    duration = float(duration)\n\n    constraints = [\n        rt_constraints.TimbrePitchConstraint(\n            context=0, timbre_weight=1.0, chroma_weight=1.0),\n        rt_constraints.EnergyConstraint(penalty=.5),\n        rt_constraints.MinimumLoopConstraint(8),\n    ]\n\n    if beats_per_measure is not None:\n        constraints.append(\n            rt_constraints.RhythmConstraint(beats_per_measure, .125))\n\n    if start:\n        constraints.append(\n            rt_constraints.StartAtStartConstraint(padding=0))\n\n    if end:\n        constraints.append(\n            rt_constraints.EndAtEndConstraint(padding=slack))\n\n    comp, info = retarget(\n        [song], duration, constraints=[constraints],\n        fade_in_len=None, fade_out_len=None)\n\n    # force the new track to extend to the end of the song\n    if end:\n        last_seg = sorted(\n            comp.segments,\n            key=lambda seg:\n            seg.comp_location_in_seconds + seg.duration_in_seconds\n        )[-1]\n\n        last_seg.duration_in_seconds = (\n            song.duration_in_seconds - last_seg.start_in_seconds)\n\n    path_cost = info[\"path_cost\"]\n    total_nonzero_cost = []\n    total_nonzero_points = []\n    for node in path_cost:\n        if float(node.name) > 0.0:\n            total_nonzero_cost.append(float(node.name))\n            total_nonzero_points.append(float(node.time))\n\n    transitions = zip(total_nonzero_points, total_nonzero_cost)\n\n    for transition in transitions:\n        comp.add_label(Label(\"crossfade\", transition[0]))\n    return comp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a composition of a song that reaches a given duration that reaches a given change point at a given times.", "response": "def retarget_with_change_points(song, cp_times, duration):\n    \"\"\"Create a composition of a song of a given duration that reaches\n    music change points at specified times. This is still under\n    construction. It might not work as well with more than\n    2 ``cp_times`` at the moment.\n\n    Here's an example of retargeting music to be 40 seconds long and\n    hit a change point at the 10 and 30 second marks::\n\n        song = Song(\"instrumental_music.wav\")\n        composition, change_points =\\\n            retarget.retarget_with_change_points(song, [10, 30], 40)\n        composition.export(filename=\"retargeted_instrumental_music.\")\n\n    :param song: Song to retarget\n    :type song: :py:class:`radiotool.composer.Song`\n    :param cp_times: Times to reach change points (in seconds)\n    :type cp_times: list of floats\n    :param duration: Target length of retargeted music (in seconds)\n    :type duration: float\n    :returns: Composition of retargeted song and list of locations of\n        change points in the retargeted composition\n    :rtype: (:py:class:`radiotool.composer.Composition`, list)\n    \"\"\"\n    analysis = song.analysis\n\n    beat_length = analysis[BEAT_DUR_KEY]\n    beats = np.array(analysis[\"beats\"])\n\n    # find change points\n    cps = np.array(novelty(song, nchangepoints=4))\n    cp_times = np.array(cp_times)\n\n    # mark change points in original music\n    def music_labels(t):\n        # find beat closest to t\n        closest_beat_idx = np.argmin(np.abs(beats - t))\n        closest_beat = beats[closest_beat_idx]\n        closest_cp = cps[np.argmin(np.abs(cps - closest_beat))]\n\n        if np.argmin(np.abs(beats - closest_cp)) == closest_beat_idx:\n            return \"cp\"\n        else:\n            return \"noncp\"\n\n    # mark where we want change points in the output music\n    # (a few beats of slack to improve the quality of the end result)\n    def out_labels(t):\n        if np.min(np.abs(cp_times - t)) < 1.5 * beat_length:\n            return \"cp\"\n        return \"noncp\"\n\n    m_labels = [music_labels(i) for i in\n                np.arange(0, song.duration_in_seconds, beat_length)]\n    o_labels = [out_labels(i) for i in np.arange(0, duration, beat_length)]\n\n    constraints = [\n        rt_constraints.TimbrePitchConstraint(\n            context=0, timbre_weight=1.0, chroma_weight=1.0),\n        rt_constraints.EnergyConstraint(penalty=.5),\n        rt_constraints.MinimumLoopConstraint(8),\n        rt_constraints.NoveltyConstraint(m_labels, o_labels, 1.0)\n    ]\n\n    comp, info = retarget(\n        [song], duration, constraints=[constraints],\n        fade_in_len=None, fade_out_len=None)\n\n    final_cp_locations = [beat_length * i\n                          for i, label in enumerate(info['result_labels'])\n                          if label == 'cp']\n\n    return comp, final_cp_locations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_command_set(self, scrapyd_url):\n\n        if scrapyd_url[-1:] != '/':\n            scrapyd_url = scrapyd_url + '/'\n        self['daemonstatus'] = [scrapyd_url + 'daemonstatus.json', http_utils.METHOD_GET]\n        self['addversion'] = [scrapyd_url + 'addversion.json', http_utils.METHOD_POST]\n        self['schedule'] = [scrapyd_url + 'schedule.json', http_utils.METHOD_POST]\n        self['cancel'] = [scrapyd_url + 'cancel.json', http_utils.METHOD_POST]\n        self['listprojects'] = [scrapyd_url + 'listprojects.json', http_utils.METHOD_GET]\n        self['listversions'] = [scrapyd_url + 'listversions.json', http_utils.METHOD_GET]\n        self['listspiders'] = [scrapyd_url + 'listspiders.json', http_utils.METHOD_GET]\n        self['listjobs'] = [scrapyd_url + 'listjobs.json', http_utils.METHOD_GET]\n        self['delversion'] = [scrapyd_url + 'delversion.json', http_utils.METHOD_POST]\n        self['delproject'] = [scrapyd_url + 'delproject.json', http_utils.METHOD_POST]\n        self['logs'] = [scrapyd_url + 'logs/', http_utils.METHOD_GET]", "response": "Initialize the command set by the given scrapyd_url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_load_status(self):\n        url, method = self.command_set['daemonstatus'][0], self.command_set['daemonstatus'][1]\n        response = http_utils.request(url, method_type=method, return_type=http_utils.RETURN_JSON)\n        if response is None:\n            logging.warning('%s failure: not found or connection fail' % sys._getframe().f_code.co_name)\n            response = DaemonStatus().__dict__\n        return response", "response": "Get the load status of a service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schedule(self,\n                 project_name,\n                 spider_name,\n                 priority=0,\n                 setting=None,\n                 job_id=None,\n                 version=None,\n                 args={}):\n        \"\"\"\n        Schedule a spider run (also known as a job), returning the job id.\n        :param project_name: the project name\n        :param spider_name: the spider name\n        :param priority: the run priority\n        :param setting: a Scrapy setting to use when running the spider\n        :param job_id: a job id used to identify the job, overrides the default generated UUID\n        :param version: the version of the project to use\n        :param args: passed as spider argument\n        :return: a dictionary that status message\n                 example: {\"status\": \"ok\", \"jobid\": \"6487ec79947edab326d6db28a2d86511e8247444\"}\n        \"\"\"\n        url, method = self.command_set['schedule'][0], self.command_set['schedule'][1]\n        data = {}\n        data['project'] = project_name\n        data['spider'] = spider_name\n        data['priority'] = priority\n        if setting is not None:\n            data['setting'] = setting\n        if job_id is not None:\n            data['jobid'] = job_id\n        if version is not None:\n            data['_version'] = version\n        for k, v in args.items():\n            data[k] = v\n        response = http_utils.request(url, method_type=method, data=data, return_type=http_utils.RETURN_JSON)\n        if response is None:\n            logging.warning('%s failure: not found or connection fail' % sys._getframe().f_code.co_name)\n            response = ScheduleResultSet().__dict__\n        return response", "response": "This method is used to schedule a spider run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncancel a spider run.", "response": "def cancel(self, project_name, job_id):\n        \"\"\"\n        Cancel a spider run (aka. job). If the job is pending, it will be removed. If the job is running, it will be terminated.\n        :param project_name: the project name\n        :param job_id: the job id\n        :return: a dictionary that status message\n                 example: {\"status\": \"ok\", \"prevstate\": \"running\"}\n        \"\"\"\n        url, method = self.command_set['cancel'][0], self.command_set['cancel'][1]\n        data = {}\n        data['project'] = project_name\n        data['job'] = job_id\n        response = http_utils.request(url, method_type=method, data=data, return_type=http_utils.RETURN_JSON)\n        if response is None:\n            logging.warning('%s failure: not found or connection fail' % sys._getframe().f_code.co_name)\n            response = CancelResultSet().__dict__\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_spider_list(self, project_name, version=None):\n        url, method = self.command_set['listspiders'][0], self.command_set['listspiders'][1]\n        data = {}\n        data['project'] = project_name\n        if version is not None:\n            data['_version'] = version\n        response = http_utils.request(url, method_type=method, data=data, return_type=http_utils.RETURN_JSON)\n        if response is None:\n            logging.warning('%s failure: not found or connection fail' % sys._getframe().f_code.co_name)\n            response = SpiderList().__dict__\n        return response", "response": "Get the list of spiders available in the last version of some project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_job_list(self, project_name):\n        url, method = self.command_set['listjobs'][0], self.command_set['listjobs'][1]\n        data = {'project': project_name}\n        response = http_utils.request(url, method_type=method, data=data, return_type=http_utils.RETURN_JSON)\n        if response is None:\n            logging.warning('%s failure: not found or connection fail' % sys._getframe().f_code.co_name)\n            response = JobList().__dict__\n        return response", "response": "Get the list of pending running and finished jobs of some project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_logs(self, project_name, spider_name):\n        url, method = self.command_set['logs'][0] + project_name + '/' + spider_name + '/', self.command_set['logs'][1]\n        response = http_utils.request(url, method_type=method)\n        html_parser = ScrapydLogsPageHTMLParser()\n        html_parser.feed(response)\n        html_parser.clean_enter_sign()\n        return html_parser.result, [url + x for x in html_parser.result]", "response": "Get urls that scrapyd logs file by project name and spider name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollecting PCI information and return its list.", "response": "def lspci(vendor=None, device=None):\n    \"\"\"Collect PCI information and return its list.\n    \n    Parameters\n    ----------\n    vendor : int\n        Return only devices with specified vendor ID.\n    \n    device : int\n        Return only devices with specified device ID.\n    \n    Returns\n    -------\n    list\n        List of PCI device information.\n        Information are stored in PCIConfigHeader namedtuple object.\n    \n    Examples\n    --------\n    >>> b = pypci.lspci(vendor=0x1147, device=3214)\n    \n    >>> b[0].vendor_id\n    4423\n    \n    >>> b[0].bar\n    [BaseAddressRegister(type='mem', addr=2421170176, size=64),\n     BaseAddressRegister(type='mem', addr=2421166080, size=64),\n     BaseAddressRegister(type='mem', addr=2421174272, size=32)]\n    \"\"\"\n    lspci_cmd = ['lspci', '-xxxx', '-v']\n    lspci_results = subprocess.run(lspci_cmd, stdout=subprocess.PIPE)\n    lspci_stdout = lspci_results.stdout.decode('utf-8')\n    config = [parse_lspci_output(stdout) for stdout\n              in lspci_stdout.split('\\n\\n') if stdout != '']\n    \n    if vendor is not None:\n        config = [c for c in config if c.vendor_id==vendor]\n        pass\n    \n    if device is not None:\n        config = [c for c in config if c.device_id==device]\n        pass\n    \n    return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads from the PCI data register.", "response": "def read(bar, offset, size):\n    \"\"\"Read PCI data register.\n    \n    Parameters\n    ----------\n    bar : BaseAddressRegister\n        BAR to read.\n    \n    offset : int\n        Address offset in BAR to read.\n    \n    size : int\n        Data size to read.\n        \n    Returns\n    -------\n    bytes\n        Data read from BAR\n        \n    Examples\n    --------\n    >>> b = pypci.lspci(vendor=0x1147, device=3214)\n    >>> pypci.read(b[0].bar[2], 0x0c, 4)\n    b'\\x00\\x00\\x00\\x0c'\n    \"\"\"\n    verify_access_range(bar, offset, size)\n    if bar.type == 'io': return io_read(bar, offset, size)\n    if bar.type == 'mem': return mem_read(bar, offset, size)\n    return b''"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites data to the specified base address register.", "response": "def write(bar, offset, data):\n    \"\"\"Write data to PCI board.\n    \n    Parameters\n    ----------\n    bar : BaseAddressRegister\n        BAR to write.\n    \n    offset : int\n        Address offset in BAR to write.\n        \n    data : bytes\n        Data to write.\n    \n    Returns\n    -------\n    None\n    \n    Examples\n    --------\n    >>> b = pypci.lspci(vendor=0x1147, device=3214)\n    \n    >>> pypci.write(b[0].bar[2], 0x04, b'\\x01')\n    \n    >>> data = struct.pack('<I', 1234567)\n    >>> pypci.write(b[0].bar[2], 0x00, data)\n    \"\"\"\n    if type(data) not in [bytes, bytearray]:\n        msg = 'data should be bytes or bytearray type'\n        raise TypeError(msg)\n    \n    size = len(data)\n    verify_access_range(bar, offset, size)\n    if bar.type == 'io': return io_write(bar, offset, data)\n    if bar.type == 'mem': return mem_write(bar, offset, data)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the path of data files which are installed to the package directory.", "response": "def get_data_files():\n    \"\"\"\n    Returns the path of data files, which are installed to the package directory.\n    \"\"\"\n    import os\n\n    path = os.path.dirname(__file__)\n    path = os.path.join(path, 'data')\n    r = dict(\n        Alpha_inf_hyrec_file = os.path.join(path, 'hyrec', 'Alpha_inf.dat'),\n        R_inf_hyrec_file = os.path.join(path, 'hyrec', 'R_inf.dat'),\n        two_photon_tables_hyrec_file = os.path.join(path, 'hyrec', 'two_photon_tables.dat'),\n        sBBN_file = os.path.join(path, 'bbn', 'sBBN.dat'),\n    )\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the file path in the available data directory.", "response": "def _find_file(filename):\n    \"\"\"\n    Find the file path, first checking if it exists and then looking in the\n    data directory\n    \"\"\"\n    import os\n    if os.path.exists(filename):\n        path = filename\n    else:\n        path = os.path.dirname(__file__)\n        path = os.path.join(path, 'data', filename)\n\n    if not os.path.exists(path):\n        raise ValueError(\"cannot locate file '%s'\" %filename)\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_precision(filename):\n    # also look in data dir\n    path = _find_file(filename)\n\n    r = dict()\n    with open(path, 'r') as f:\n        exec(f.read(), {}, r)\n\n    return r", "response": "Loads a CLASS precision file into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_ini(filename):\n    # also look in data dir\n    path = _find_file(filename)\n\n    pars = {}\n    with open(path, 'r') as ff:\n\n        # loop over lines\n        for lineno, line in enumerate(ff):\n            if not line: continue\n\n            # skip any commented lines with #\n            if '#' in line: line = line[line.index('#')+1:]\n\n            # must have an equals sign to be valid\n            if \"=\" not in line: continue\n\n            # extract key and value pairs\n            fields = line.split(\"=\")\n            if len(fields) != 2:\n                import warnings\n                warnings.warn(\"skipping line number %d: '%s'\" %(lineno,line))\n                continue\n            pars[fields[0].strip()] = fields[1].strip()\n\n    return pars", "response": "Read a CLASS. ini file and return a dictionary of parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_noun_phrases(tagged_doc):\n    tags = _normalize_tags(tagged_doc)\n    merge = True\n    while merge:\n        merge = False\n        for x in range(0, len(tags) - 1):\n            t1 = tags[x]\n            t2 = tags[x + 1]\n            key = t1[1], t2[1]\n            value = CFG.get(key, '')\n            if value:\n                merge = True\n                tags.pop(x)\n                tags.pop(x)\n                match = '%s %s' % (t1[0], t2[0])\n                pos = value\n                tags.insert(x, (match, pos))\n                break\n\n    matches = [t[0] for t in tags if t[1] in ['NNP', 'NNI']]\n    return matches", "response": "Extract noun phrases from a document."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _normalize_tags(chunk):\n    ret = []\n    for word, tag in chunk:\n        if tag == 'NP-TL' or tag == 'NP':\n            ret.append((word, 'NNP'))\n            continue\n        if tag.endswith('-TL'):\n            ret.append((word, tag[:-3]))\n            continue\n        if tag.endswith('S'):\n            ret.append((word, tag[:-1]))\n            continue\n        ret.append((word, tag))\n    return ret", "response": "Normalize the corpus tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves a ScalarPatternUniform object patt to file.", "response": "def save_patt(patt, filename):\n    \"\"\"Saves ScalarPatternUniform object 'patt' to file. The first line of the \n    file has the number of rows and the number of columns in the pattern \n    separated by a comma (single sphere data). The remaining lines have the \n    form:\n    \n        0, 1, 3.14, 2.718\n\n    The first two numbers are index for the row and index for the column \n    respectively. The last two numbers are the real and imaginary part of the \n    number associated with the row and column.\n    \"\"\"\n\n    nrows = patt.nrows\n    ncols = patt.ncols\n    frmstr = \"{0},{1},{2:.16e},{3:.16e}\\n\"\n\n    ar = patt.array\n\n    with open(filename, 'w') as f: \n        f.write(\"{0},{1}\\n\".format(nrows, ncols))\n        for nr in xrange(0, nrows):\n            for nc in xrange(0, ncols):\n                f.write(frmstr.format(nr, nc, ar[nr, nc].real,\n                                            ar[nr, nc].imag))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving ScalarCoeffs object scoef to file.", "response": "def save_coef(scoef, filename):\n    \"\"\"Saves ScalarCoeffs object 'scoef' to file. The first line of the \n    file has the max number N and the max number M of the scoef structure \n    separated by a comma. The remaining lines have the form\n    \n        3.14, 2.718\n\n    The first number is the real part of the mode and the second is the \n    imaginary. \n    \"\"\"\n    \n    nmax = scoef.nmax\n    mmax = scoef.mmax\n\n    frmstr = \"{0:.16e},{1:.16e}\\n\"\n\n    L = (nmax + 1) + mmax * (2 * nmax - mmax + 1);\n\n    with open(filename, 'w') as f: \n        f.write(\"{0},{1}\\n\".format(nmax, mmax))\n        for n in xrange(0, L):\n            f.write(frmstr.format(scoef._vec[n].real,\n                                  scoef._vec[n].imag))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_patt(filename):\n\n    with open(filename) as f: \n        lines = f.readlines()\n\n        lst = lines[0].split(',')\n\n        patt = np.zeros([int(lst[0]), int(lst[1])],\n                        dtype=np.complex128)\n\n        lines.pop(0)\n\n        for line in lines:\n            lst = line.split(',')\n            n = int(lst[0])\n            m = int(lst[1])\n            re = float(lst[2])\n            im = float(lst[3])\n            patt[n, m] = re + 1j * im\n\n    return sp.ScalarPatternUniform(patt, doublesphere=False)", "response": "Loads a file that was saved with the save_patt routine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_vpatt(filename1, filename2):\n\n    with open(filename1) as f: \n        lines = f.readlines()\n\n        lst = lines[0].split(',')\n\n        patt1 = np.zeros([int(lst[0]), int(lst[1])],\n                        dtype=np.complex128)\n\n        lines.pop(0)\n\n        for line in lines:\n            lst = line.split(',')\n            n = int(lst[0])\n            m = int(lst[1])\n            re = float(lst[2])\n            im = float(lst[3])\n            patt1[n, m] = re + 1j * im\n\n    with open(filename2) as f: \n        lines2 = f.readlines()\n\n        lst = lines2[0].split(',')\n\n        patt2 = np.zeros([int(lst[0]), int(lst[1])],\n                        dtype=np.complex128)\n\n        lines2.pop(0)\n\n        for line in lines2:\n            lst = line.split(',')\n            n = int(lst[0])\n            m = int(lst[1])\n            re = float(lst[2])\n            im = float(lst[3])\n            patt2[n, m] = re + 1j * im\n\n    return sp.VectorPatternUniform(patt1, patt2)", "response": "Loads a VectorPatternUniform pattern that is saved between two files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_coef(filename):\n    \n    with open(filename) as f: \n        lines = f.readlines()\n\n        lst = lines[0].split(',')\n\n        nmax = int(lst[0])\n        mmax = int(lst[1])\n\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1);\n\n        vec = np.zeros(L, dtype=np.complex128)\n   \n        lines.pop(0)\n\n        for n, line in enumerate(lines):\n            lst = line.split(',')\n            re = float(lst[0])\n            im = float(lst[1])\n            vec[n] = re + 1j * im\n\n    return sp.ScalarCoefs(vec, nmax, mmax)", "response": "Loads a file that was saved with save_coef."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_vcoef(filename):\n\n    with open(filename) as f: \n        lines = f.readlines()\n\n        lst = lines[0].split(',')\n\n        nmax = int(lst[0])\n        mmax = int(lst[1])\n        directivity = float(lst[2])\n\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1);\n\n        vec1 = np.zeros(L, dtype=np.complex128)\n        vec2 = np.zeros(L, dtype=np.complex128)\n   \n        lines.pop(0)\n\n        n = 0\n        in_vec2 = False\n        for line in lines:\n\n            if line.strip() == 'break':\n                n = 0\n                in_vec2 = True;\n            else:\n                lst = line.split(',')\n                re = float(lst[0])\n                im = float(lst[1])\n\n                if in_vec2:\n                    vec2[n] = re + 1j * im\n                else:\n                    vec1[n] = re + 1j * im\n\n                n += 1\n\n    return (sp.VectorCoefs(vec1, vec2, nmax, mmax), directivity)", "response": "Loads a set of vector coefficients that were saved in MATLAB. The first line is the directivity calculated within the MATLAB\n    code. The second line is the directivity calculated within the MATLAB\n    code."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses barcode from gudhi output.", "response": "def parse(cls, filename, max_life=None):\n        \"\"\" Parse barcode from gudhi output. \"\"\"\n        data = np.genfromtxt(filename)\n        #data = np.genfromtxt(filename, dtype= (int, int, float, float))\n\n        if max_life is not None:\n            data[np.isinf(data)] = max_life\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting barcode using matplotlib.", "response": "def plot(self, dimension):\n        \"\"\" Plot barcode using matplotlib. \"\"\"\n        import matplotlib.pyplot as plt\n        life_lines = self.get_life_lines(dimension)\n        x, y = zip(*life_lines)\n        plt.scatter(x, y)\n\n        plt.xlabel(\"Birth\")\n        plt.ylabel(\"Death\")\n\n        if self.max_life is not None:\n            plt.xlim([0, self.max_life])\n\n        plt.title(\"Persistence Homology Dimension {}\".format(dimension))\n\n        #TODO: remove this\n        plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Configurable instance with the given name and config.", "response": "def from_config(cls, name, config):\n        \"\"\"\n        Returns a Configurable instance with the given name and config.\n\n        By default this is a simple matter of calling the constructor, but\n        subclasses that are also `Pluggable` instances override this in order\n        to check that the plugin is installed correctly first.\n        \"\"\"\n\n        cls.validate_config(config)\n\n        instance = cls()\n        if not instance.name:\n            instance.name = config.get(\"name\", name)\n        instance.apply_config(config)\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_args():\n\n    parser = argparse.ArgumentParser(\n        description=\"Provision multiple VM's through mist.io. You can get \"\n        \"information returned with the name of the virtual machine created \"\n        \"and its main mac and ip address in IPv4 format. A post-script can be \"\n        \"specified for post-processing.\")\n    parser.add_argument('-b', '--basename', nargs=1, required=True,\n                        help='Basename of the newly deployed VMs',\n                        dest='basename', type=str)\n    parser.add_argument('-d', '--debug', required=False,\n                        help='Enable debug output', dest='debug',\n                        action='store_true')\n    parser.add_argument('-i', '--print-ips', required=False,\n                        help='Enable IP output', dest='ips',\n                        action='store_true')\n    parser.add_argument('-m', '--print-macs', required=False,\n                        help='Enable MAC output', dest='macs',\n                        action='store_true')\n    parser.add_argument('-l', '--log-file', nargs=1, required=False,\n                        help='File to log to (default = stdout)',\n                        dest='logfile', type=str)\n    parser.add_argument('-n', '--number', nargs=1, required=False,\n                        help='Amount of VMs to deploy (default = 1)',\n                        dest='quantity', type=int, default=[1])\n    parser.add_argument('-M', '--monitoring', required=False,\n                        help='Enable monitoring on the virtual machines',\n                        dest='monitoring', action='store_true')\n    parser.add_argument('-B', '--backend-name', required=False,\n                        help='The name of the backend to use for provisioning.'\n                        ' Defaults to the first available backend',\n                        dest='backend_name', type=str)\n    parser.add_argument('-I', '--image-id', required=True,\n                        help='The image to deploy', dest='image_id')\n    parser.add_argument('-S', '--size-id', required=True,\n                        help='The id of the size/flavor to use',\n                        dest='size_id')\n    parser.add_argument('-N', '--networks', required=False, nargs='+',\n                        help='The ids of the networks to assign to the VMs',\n                        dest='networks')\n    parser.add_argument('-s', '--post-script', nargs=1, required=False,\n                        help='Script to be called after each VM is created and'\n                        ' booted.', dest='post_script', type=str)\n    parser.add_argument('-P', '--script-params', nargs=1, required=False,\n                        help='Script to be called after each VM is created and'\n                        ' booted.', dest='script_params', type=str)\n    parser.add_argument('-H', '--host', required=False,\n                        help='mist.io instance to connect to', dest='host',\n                        type=str, default='https://mist.io')\n    parser.add_argument('-u', '--user', nargs=1, required=False,\n                        help='email registered to mist.io', dest='username',\n                        type=str)\n    parser.add_argument('-p', '--password', nargs=1, required=False,\n                        help='The password with which to connect to the host. '\n                        'If not specified, the user is prompted at runtime for'\n                        ' a password', dest='password', type=str)\n    parser.add_argument('-v', '--verbose', required=False,\n                        help='Enable verbose output', dest='verbose',\n                        action='store_true')\n    parser.add_argument('-w', '--wait-max', nargs=1, required=False,\n                        help='Maximum amount of seconds to wait when gathering'\n                        ' information (default = 600)', dest='maxwait',\n                        type=int, default=[600])\n    parser.add_argument('-f', '--associate-floating-ip', required=False, action='store_true',\n                        help='Auto-associates floating ips to vms in Openstack backens',\n                        dest='associate_floating_ip',)\n    args = parser.parse_args()\n    return args", "response": "Returns the command - line arguments for the provisioning process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists file priority rules.", "response": "def command(state, args):\n    \"\"\"List file priority rules.\"\"\"\n    rules = query.files.get_priority_rules(state.db)\n    print(tabulate(rules, headers=['ID', 'Regexp', 'Priority']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfilters candidates to a frequent set by some minimum support.", "response": "def filter_support(candidates, transactions, min_sup):\n    \"\"\"\n    Filter candidates to a frequent set by some minimum support.\n    \"\"\"\n    counts = defaultdict(lambda: 0)\n    for transaction in transactions:\n        for c in (c for c in candidates if set(c).issubset(transaction)):\n            counts[c] += 1\n    return {i for i in candidates if counts[i]/len(transactions) >= min_sup}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate candidates for an iteration.", "response": "def generate_candidates(freq_set, k):\n    \"\"\"\n    Generate candidates for an iteration.\n    Use this only for k >= 2.\n    \"\"\"\n    single_set = {(i,) for i in set(flatten(freq_set))}\n\n    # TO DO generating all combinations gets very slow for large documents.\n    # Is there a way of doing this without exhaustively searching all combinations?\n    cands = [flatten(f) for f in combinations(single_set, k)]\n    return [cand for cand in cands if validate_candidate(cand, freq_set, k)]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if we should keep a candidate.", "response": "def validate_candidate(candidate, freq_set, k):\n    \"\"\"\n    Checks if we should keep a candidate.\n    We keep a candidate if all its k-1-sized subsets\n    are present in the frequent sets.\n    \"\"\"\n    for subcand in combinations(candidate, k-1):\n        if subcand not in freq_set:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tokenize(self, docs):\n        if self.min_sup < 1/len(docs):\n            raise Exception('`min_sup` must be greater than or equal to `1/len(docs)`.')\n\n        # First pass\n        candidates = set()\n        transactions = []\n\n        # Use nouns and noun phrases.\n        for doc in POSTokenizer().tokenize(docs):\n            transaction = set(doc)\n            candidates = candidates.union({(t,) for t in transaction})\n            transactions.append(transaction)\n        freq_set = filter_support(candidates, transactions, self.min_sup)\n\n        # Iterate\n        k = 2\n        last_set = set()\n        while freq_set != set():\n            last_set = freq_set\n            cands = generate_candidates(freq_set, k)\n            freq_set = filter_support(cands, transactions, self.min_sup)\n            k += 1\n\n        # Map documents to their keywords.\n        keywords = flatten(last_set)\n        return prune([[kw for kw in keywords if kw in doc] for doc in docs])", "response": "Given a list of documents return a list of lists of tokens that are valid for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_tag_re(self, tags):\n        return re.compile(self.raw_tag_re % tags, self.re_flags)", "response": "Return the regex used to look for Mustache tags in the tags list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        # Note: Remember to use orm['appname.ModelName'] rather than \"from appname.models...\"\n\n        User = orm[user_orm_label]\n\n        try:\n            user = User.objects.all()[0]\n\n            for article in orm.Article.objects.all():\n                article.author = user\n                article.save()\n\n        except IndexError:\n            pass", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a python object into a tnetstring.", "response": "def dumps(value,encoding=None):\n    \"\"\"dumps(object,encoding=None) -> string\n\n    This function dumps a python object as a tnetstring.\n    \"\"\"\n    #  This uses a deque to collect output fragments in reverse order,\n    #  then joins them together at the end.  It's measurably faster\n    #  than creating all the intermediate strings.\n    #  If you're reading this to get a handle on the tnetstring format,\n    #  consider the _gdumps() function instead; it's a standard top-down\n    #  generator that's simpler to understand but much less efficient.\n    q = deque()\n    _rdumpq(q,0,value,encoding)\n    return \"\".join(q)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping a value into a deque instance.", "response": "def _rdumpq(q,size,value,encoding=None):\n    \"\"\"Dump value as a tnetstring, to a deque instance, last chunks first.\n\n    This function generates the tnetstring representation of the given value,\n    pushing chunks of the output onto the given deque instance.  It pushes\n    the last chunk first, then recursively generates more chunks.\n\n    When passed in the current size of the string in the queue, it will return\n    the new size of the string in the queue.\n\n    Operating last-chunk-first makes it easy to calculate the size written\n    for recursive structures without having to build their representation as\n    a string.  This is measurably faster than generating the intermediate\n    strings, especially on deeply nested structures.\n    \"\"\"\n    write = q.appendleft\n    if value is None:\n        write(\"0:~\")\n        return size + 3\n    if value is True:\n        write(\"4:true!\")\n        return size + 7\n    if value is False:\n        write(\"5:false!\")\n        return size + 8\n    if isinstance(value,(int,long)):\n        data = str(value) \n        ldata = len(data)\n        span = str(ldata)\n        write(\"#\")\n        write(data)\n        write(\":\")\n        write(span)\n        return size + 2 + len(span) + ldata\n    if isinstance(value,(float,)):\n        #  Use repr() for float rather than str().\n        #  It round-trips more accurately.\n        #  Probably unnecessary in later python versions that\n        #  use David Gay's ftoa routines.\n        data = repr(value) \n        ldata = len(data)\n        span = str(ldata)\n        write(\"^\")\n        write(data)\n        write(\":\")\n        write(span)\n        return size + 2 + len(span) + ldata\n    if isinstance(value,str):\n        lvalue = len(value)\n        span = str(lvalue)\n        write(\",\")\n        write(value)\n        write(\":\")\n        write(span)\n        return size + 2 + len(span) + lvalue\n    if isinstance(value,(list,tuple,)):\n        write(\"]\")\n        init_size = size = size + 1\n        for item in reversed(value):\n            size = _rdumpq(q,size,item,encoding)\n        span = str(size - init_size)\n        write(\":\")\n        write(span)\n        return size + 1 + len(span)\n    if isinstance(value,dict):\n        write(\"}\")\n        init_size = size = size + 1\n        for (k,v) in value.iteritems():\n            size = _rdumpq(q,size,v,encoding)\n            size = _rdumpq(q,size,k,encoding)\n        span = str(size - init_size)\n        write(\":\")\n        write(span)\n        return size + 1 + len(span)\n    if isinstance(value,unicode):\n        if encoding is None:\n            raise ValueError(\"must specify encoding to dump unicode strings\")\n        value = value.encode(encoding)\n        lvalue = len(value)\n        span = str(lvalue)\n        write(\",\")\n        write(value)\n        write(\":\")\n        write(span)\n        return size + 2 + len(span) + lvalue\n    raise ValueError(\"unserializable object\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _gdumps(value,encoding):\n    if value is None:\n        yield \"0:~\"\n    elif value is True:\n        yield \"4:true!\"\n    elif value is False:\n        yield \"5:false!\"\n    elif isinstance(value,(int,long)):\n        data = str(value) \n        yield str(len(data))\n        yield \":\"\n        yield data\n        yield \"#\"\n    elif isinstance(value,(float,)):\n        data = repr(value) \n        yield str(len(data))\n        yield \":\"\n        yield data\n        yield \"^\"\n    elif isinstance(value,(str,)):\n        yield str(len(value))\n        yield \":\"\n        yield value\n        yield \",\"\n    elif isinstance(value,(list,tuple,)):\n        sub = []\n        for item in value:\n            sub.extend(_gdumps(item))\n        sub = \"\".join(sub)\n        yield str(len(sub))\n        yield \":\"\n        yield sub\n        yield \"]\"\n    elif isinstance(value,(dict,)):\n        sub = []\n        for (k,v) in value.iteritems():\n            sub.extend(_gdumps(k))\n            sub.extend(_gdumps(v))\n        sub = \"\".join(sub)\n        yield str(len(sub))\n        yield \":\"\n        yield sub\n        yield \"}\"\n    elif isinstance(value,(unicode,)):\n        if encoding is None:\n            raise ValueError(\"must specify encoding to dump unicode strings\")\n        value = value.encode(encoding)\n        yield str(len(value))\n        yield \":\"\n        yield value\n        yield \",\"\n    else:\n        raise ValueError(\"unserializable object\")", "response": "Generate a list of all the fragments of a value in a tnetstring."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(string,encoding=None):\n    #  Parse out data length, type and remaining string.\n    try:\n        (dlen,rest) = string.split(\":\",1)\n        dlen = int(dlen)\n    except ValueError:\n        raise ValueError(\"not a tnetstring: missing or invalid length prefix\")\n    try:\n        (data,type,remain) = (rest[:dlen],rest[dlen],rest[dlen+1:])\n    except IndexError:\n        #  This fires if len(rest) < dlen, meaning we don't need\n        #  to further validate that data is the right length.\n        raise ValueError(\"not a tnetstring: invalid length prefix\")\n    #  Parse the data based on the type tag.\n    if type == \",\":\n        if encoding is not None:\n            return (data.decode(encoding),remain)\n        return (data,remain)\n    if type == \"#\":\n        try:\n            return (int(data),remain)\n        except ValueError:\n            raise ValueError(\"not a tnetstring: invalid integer literal\")\n    if type == \"^\":\n        try:\n            return (float(data),remain)\n        except ValueError:\n            raise ValueError(\"not a tnetstring: invalid float literal\")\n    if type == \"!\":\n        if data == \"true\":\n            return (True,remain)\n        elif data == \"false\":\n            return (False,remain)\n        else:\n            raise ValueError(\"not a tnetstring: invalid boolean literal\")\n    if type == \"~\":\n        if data:\n            raise ValueError(\"not a tnetstring: invalid null literal\")\n        return (None,remain)\n    if type == \"]\":\n        l = []\n        while data:\n            (item,data) = pop(data,encoding)\n            l.append(item)\n        return (l,remain)\n    if type == \"}\":\n        d = {}\n        while data:\n            (key,data) = pop(data,encoding)\n            (val,data) = pop(data,encoding)\n            d[key] = val\n        return (d,remain)\n    raise ValueError(\"unknown type tag\")", "response": "This function parses a tnetstring into a python object and returns a tuple giving the parsed object and the remaining data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_magnitude_spectrum(frames):\n    return N.log(N.abs(N.fft.rfft(frames)).clip(1e-5, N.inf))", "response": "Compute the log of the magnitude spectrum of frames"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RMS_energy(frames):\n    f = frames.flatten()\n    return N.sqrt(N.mean(f * f))", "response": "Computes the RMS energy of frames"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_features(features):\n    return (features - N.min(features)) / (N.max(features) - N.min(features))", "response": "Standardizes features array to fall between 0 and 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zero_crossing_last(frames):\n    frames = N.array(frames)\n\n    crossings = N.where(N.diff(N.sign(frames)))\n    # crossings = N.where(frames[:n] * frames[1:n + 1] < 0)\n\n    if len(crossings[0]) == 0:\n        print \"No zero crossing\"\n        return len(frames) - 1\n    return crossings[0][-1]", "response": "Finds the last zero crossing in frames"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef linear(arr1, arr2):\n    n = N.shape(arr1)[0]\n    try:\n        channels = N.shape(arr1)[1]\n    except:\n        channels = 1\n\n    f_in = N.linspace(0, 1, num=n)\n    f_out = N.linspace(1, 0, num=n)\n\n    # f_in = N.arange(n) / float(n - 1)\n    # f_out = N.arange(n - 1, -1, -1) / float(n)\n\n    if channels > 1:\n        f_in = N.tile(f_in, (channels, 1)).T\n        f_out = N.tile(f_out, (channels, 1)).T\n\n    vals = f_out * arr1 + f_in * arr2\n    return vals", "response": "Create a linear blend of arr1 and arr2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef equal_power(arr1, arr2):\n    n = N.shape(arr1)[0]\n    try:\n        channels = N.shape(arr1)[1]\n    except:\n        channels = 1\n\n    f_in = N.arange(n) / float(n - 1)\n    f_out = N.arange(n - 1, -1, -1) / float(n)\n\n    if channels > 1:\n        f_in = N.tile(f_in, (channels, 1)).T\n        f_out = N.tile(f_out, (channels, 1)).T\n\n    vals = log_factor(f_out) * arr1 + log_factor(f_in) * arr2\n\n    return limiter(vals)", "response": "Create an equal power blend of arr1 and arr2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsegments array into chunks of a specified length with a specified proportion overlap.", "response": "def segment_array(arr, length, overlap=.5):\n    \"\"\"\n    Segment array into chunks of a specified length, with a specified\n    proportion overlap.\n\n    Operates on axis 0.\n\n    :param integer length: Length of each segment\n    :param float overlap: Proportion overlap of each frame\n    \"\"\"\n\n    arr = N.array(arr)\n\n    offset = float(overlap) * length\n    total_segments = int((N.shape(arr)[0] - length) / offset) + 1\n    # print \"total segments\", total_segments\n\n    other_shape = N.shape(arr)[1:]\n    out_shape = [total_segments, length]\n    out_shape.extend(other_shape)\n\n    out = N.empty(out_shape)\n\n    for i in xrange(total_segments):\n        out[i][:] = arr[i * offset:i * offset + length]\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreorder the dict d by the keys in nkl", "response": "def _reorder_via_klist(d,nkl,**kwargs):\n    '''\n        d = {'scheme': 'http', 'path': '/index.php', 'params': 'params', 'query': 'username=query', 'fragment': 'frag', 'username': '', 'password': '', 'hostname': 'www.baidu.com', 'port': ''}\n        pobj(d)\n        nkl = ['scheme', 'username', 'password', 'hostname', 'port', 'path', 'params', 'query', 'fragment']\n        pobj(_reorder_via_klist(d,nkl))\n    '''\n    if('deepcopy' in kwargs):\n        deepcopy = kwargs['deepcopy']\n    else:\n        deepcopy = True\n    if(deepcopy):\n        d = copy.deepcopy(d)\n    else:\n        pass\n    nd = {}\n    lngth = nkl.__len__()\n    for i in range(0,lngth):\n        k = nkl[i]\n        nd[k] = d[k]\n    return(nd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _keys_via_value_nonrecur(d,v):\n    '''\n        #non-recursive\n        d = {1:'a',2:'b',3:'a'}\n        _keys_via_value_nonrecur(d,'a')\n    '''\n    rslt = []\n    for key in d:\n        if(d[key] == v):\n            rslt.append(key)\n    return(rslt)", "response": "Return a list of keys in d that are not in v."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _keys_via_value(d,value,**kwargs):\n    '''\n        d = {\n         'x':\n              {\n               'x2': 'x22',\n               'x1': 'x11'\n              },\n         'y':\n              {\n               'y1': 'v1',\n               'y2':\n                     {\n                      'y4': 'v4',\n                      'y3': 'v3',\n                     },\n               'xx': \n                    {\n                        'x2': 'x22',\n                        'x1': 'x11'\n                  }\n              },\n         't': 20,\n         'u':\n              {\n               'u1': 20\n              }\n        }\n    '''\n    km,vm = _d2kvmatrix(d)\n    rvmat = _get_rvmat(d)\n    depth = rvmat.__len__()\n    ##\n    #print(km)\n    ##\n    kdmat = _scankm(km)\n    if('leaf_only' in kwargs):\n        leaf_only = kwargs['leaf_only']\n    else:\n        leaf_only = False\n    if('non_leaf_only' in kwargs):\n        non_leaf_only = kwargs['non_leaf_only']\n    else:\n        non_leaf_only = False\n    if('from_lv' in kwargs):\n        from_lv = kwargs['from_lv']\n    else:\n        from_lv = 1\n    if('to_lv' in kwargs):\n        to_lv = kwargs['to_lv']\n    else:\n        if('from_lv' in kwargs):\n            to_lv = from_lv\n        else:\n            to_lv = depth\n    rslt = []\n    for i in range(from_lv,to_lv):\n        rvlevel = rvmat[i]\n        for j in range(0,rvlevel.__len__()):\n            v = rvlevel[j]\n            cond1 = (v == value)\n            if(leaf_only == True):\n                cond2 = (kdmat[i][j]['leaf'] == True)\n            elif(non_leaf_only == True):\n                cond2 = (kdmat[i][j]['leaf'] == False)\n            else:\n                cond2 = True\n            cond = (cond1 & cond2)\n            if(cond):\n                rslt.append(kdmat[i][j]['path'])\n            else:\n                pass\n    return(rslt)", "response": "Return a list of keys that are set to a given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting dict to list of key - value pairs.", "response": "def d2kvlist(d):\n    '''\n        d = {'GPSImgDirectionRef': 'M', 'GPSVersionID': b'\\x02\\x03\\x00\\x00', 'GPSImgDirection': (21900, 100)}\n        pobj(d)\n        kl,vl = d2kvlist(d)\n        pobj(kl)\n        pobj(vl)\n    '''\n    kl = list(d.keys())\n    vl = list(d.values())\n    return((kl,vl))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef brkl2d(arr,interval):\n    '''\n        arr = [\"color1\",\"r1\",\"g1\",\"b1\",\"a1\",\"color2\",\"r2\",\"g2\",\"b2\",\"a2\"]\n        >>> brkl2d(arr,5)\n        [{'color1': ['r1', 'g1', 'b1', 'a1']}, {'color2': ['r2', 'g2', 'b2', 'a2']}]\n    '''\n    lngth = arr.__len__()\n    brkseqs = elel.init_range(0,lngth,interval)\n    l = elel.broken_seqs(arr,brkseqs)\n    d = elel.mapv(l,lambda ele:{ele[0]:ele[1:]})\n    return(d)", "response": ">>> brkl2d arr interval >>>"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of all the keys in the dict d.", "response": "def _vksdesc(d):\n    '''\n        d = {'a':1,'b':2,'c':2,'d':4}\n        desc = _vksdesc(d)\n        pobj(desc)\n    '''\n    pt = copy.deepcopy(d)\n    seqs_for_del =[]\n    vset = set({})\n    for k in pt:\n        vset.add(pt[k])\n    desc = {}\n    for v in vset:\n        desc[v] = []\n    for k in pt:\n        desc[pt[k]].append(k)\n    return(desc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a dictionary into a list of tuples", "response": "def dict2tlist(this_dict,**kwargs):\n    '''\n        #sequence will be losted\n        d = {'a':'b','c':'d'}\n        dict2tlist(d)\n    '''\n    if('check' in kwargs):\n        check = kwargs['check']\n    else:\n        check = 1\n    if(check):\n        if(isinstance(this_dict,dict)):\n            pass\n        else:\n            return(None)\n    else:\n        pass\n    if('deepcopy' in kwargs):\n        deepcopy = kwargs['deepcopy']\n    else:\n        deepcopy = 1\n    tuple_list = []\n    if(deepcopy):\n        new = copy.deepcopy(this_dict)\n    else:\n        new = this_dict\n    i = 0\n    for key in this_dict:\n        value = this_dict[key]\n        tuple_list.append((key,value))\n    return(tuple_list)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_mirrable(d):\n    '''\n        d = {1:'a',2:'a',3:'b'}\n    '''\n    vl = list(d.values())\n    lngth1 = vl.__len__()\n    uvl = elel.uniqualize(vl)\n    lngth2 = uvl.__len__()\n    cond = (lngth1 == lngth2)\n    return(cond)", "response": "Check if a sequence of tokens is mirrable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmirror the keys of a dictionary into a single dict.", "response": "def dict_mirror(d,**kwargs):\n    '''\n        d = {1:'a',2:'a',3:'b'}\n    '''\n    md = {}\n    if('sort_func' in kwargs):\n        sort_func = kwargs['sort_func']\n    else:\n        sort_func = sorted\n    vl = list(d.values())\n    uvl = elel.uniqualize(vl)\n    for v in uvl:\n        kl = _keys_via_value_nonrecur(d,v)\n        k = sorted(kl)[0]\n        md[v] = k\n    return(md)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects the key of the current object that do not match the condition.", "response": "def _cond_select_key_nonrecur(d,cond_match=None,**kwargs):\n    '''\n        d = {\n            \"ActiveArea\":\"50829\", \n            \"Artist\":\"315\",                 \n            \"AsShotPreProfileMatrix\":\"50832\",\n            \"AnalogBalance\":\"50727\",          \n            \"AsShotICCProfile\":\"50831\",       \n            \"AsShotProfileName\":\"50934\",\n            \"AntiAliasStrength\":\"50738\",      \n            \"AsShotNeutral\":\"50728\",          \n            \"AsShotWhiteXY\":\"50729\"\n        }\n        _cond_select_key_nonrecur(d,\"An\")\n        _cond_select_key_nonrecur(d,\"As\")\n        regex = re.compile(\"e$\")\n        _cond_select_key_nonrecur(d,regex)\n    '''\n    if('cond_func' in kwargs):\n        cond_func = kwargs['cond_func']\n    else:\n        cond_func = _text_cond\n    if('cond_func_args' in kwargs):\n        cond_func_args = kwargs['cond_func_args']\n    else:\n        cond_func_args = []\n    rslt = {}\n    for key in d:\n        if(cond_func(key,cond_match,*cond_func_args)):\n            rslt[key] = d[key]\n        else:\n            pass\n    return(rslt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cond_select_value_nonrecur(d,cond_match=None,**kwargs):\n    '''\n        d = {\n            \"ActiveArea\":\"50829\", \n            \"Artist\":\"315\",                 \n            \"AsShotPreProfileMatrix\":\"50832\",\n            \"AnalogBalance\":\"50727\",          \n            \"AsShotICCProfile\":\"50831\",       \n            \"AsShotProfileName\":\"50934\",\n            \"AntiAliasStrength\":\"50738\",      \n            \"AsShotNeutral\":\"50728\",          \n            \"AsShotWhiteXY\":\"50729\"\n        }\n        _cond_select_value_nonrecur(d,\"50\")\n        _cond_select_value_nonrecur(d,\"72\")\n        regex = re.compile(\"8$\")\n        _cond_select_value_nonrecur(d,regex)\n    '''\n    if('cond_func' in kwargs):\n        cond_func = kwargs['cond_func']\n    else:\n        cond_func = _text_cond\n    if('cond_func_args' in kwargs):\n        cond_func_args = kwargs['cond_func_args']\n    else:\n        cond_func_args = []\n    rslt = {}\n    for key in d:\n        value = d[key]\n        if(cond_func(value,cond_match,*cond_func_args)):\n            rslt[key] = d[key]\n        else:\n            pass\n    return(rslt)", "response": "Select the value of the key - value pairs in a dictionary that does not contain the key - value pair."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of the differences between two log files.", "response": "def _diff_internal(d1,d2):\n    '''\n        d1 = {'a':'x','b':'y','c':'z'}\n        d2 = {'a':'x','b':'u','d':'v'}\n        _diff_internal(d1,d2)\n        _diff_internald2,d1)\n    '''\n    same =[]\n    kdiff =[]\n    vdiff = []\n    for key in d1:\n        value = d1[key]\n        if(key in d2):\n            if(value == d2[key]):\n                same.append(key)\n            else:\n                vdiff.append(key)\n        else:\n            kdiff.append(key)\n    return({'same':same,'kdiff':kdiff,'vdiff':vdiff})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new set of unique names that are in d1 and d2.", "response": "def _union(d1,d2):\n    '''\n        d1 = {'a':'x','b':'y','c':'z'}\n        d2 = {'a':'x','b':'u','d':'v'}\n        _union(d1,d2)\n        _union(d2,d1)\n    '''\n    u = {}\n    ds = _diff_internal(d1,d2)\n    for key in ds['same']:\n        u[key] = d1[key]\n    for key in ds['vdiff']:\n        u[key] = d1[key]\n    for key in ds['kdiff']:\n        u[key] = d1[key]\n    ds = _diff_internal(d2,d1)\n    for key in ds['kdiff']:\n        u[key] = d2[key]\n    return(u)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _diff(d1,d2):\n    '''\n        d1 = {'a':'x','b':'y','c':'z'}\n        d2 = {'a':'x','b':'u','d':'v'}\n        _diff(d1,d2)\n        _diff(d2,d1)\n    '''\n    d = {}\n    ds = _diff_internal(d1,d2)\n    for key in ds['vdiff']:\n        d[key] = d1[key]\n    for key in ds['kdiff']:\n        d[key] = d1[key]\n    return(d)", "response": "Return a dictionary of the differences between two log entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the intersection of two sets of resources.", "response": "def _intersection(d1,d2):\n    '''\n        d1 = {'a':'x','b':'y','c':'z'}\n        d2 = {'a':'x','b':'u','d':'v'}\n        _intersection(d1,d2)\n        _intersection(d2,d1)\n    '''\n    i = {}\n    ds = _diff_internal(d1,d2)\n    for key in ds['same']:\n        i[key] = d1[key]\n    return(i)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncomplement two sets of names", "response": "def _complement(d1,d2):\n    '''\n        d1 = {'a':'x','b':'y','c':'z'}\n        d2 = {'a':'x','b':'u','d':'v'}\n        complement(d1,d2)\n        complement(d2,d1)\n    '''\n    u = _union(d1,d2)\n    c = _diff(u,d1)\n    return(c)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extend(dict1,dict2,**kwargs):\n    '''\n        dict1 = {1:'a',2:'b',3:'c',4:'d'}\n        dict2 = {5:'u',2:'v',3:'w',6:'x',7:'y'}\n        d = _extend(dict1,dict2)\n        pobj(d)\n        dict1 = {1:'a',2:'b',3:'c',4:'d'}\n        dict2 = {5:'u',2:'v',3:'w',6:'x',7:'y'}\n        d = _extend(dict1,dict2,overwrite=1)\n        pobj(d)\n    '''\n    if('deepcopy' in kwargs):\n        deepcopy=kwargs['deepcopy']\n    else:\n        deepcopy=1\n    if('overwrite' in kwargs):\n        overwrite=kwargs['overwrite']\n    else:\n        overwrite=0\n    if(deepcopy):\n        dict1 = copy.deepcopy(dict1)\n        dict2 = copy.deepcopy(dict2)\n    else:\n        pass\n    d = dict1\n    for key in dict2:\n        if(key in dict1):\n            if(overwrite):\n                d[key] = dict2[key]\n            else:\n                pass\n        else:\n            d[key] = dict2[key]\n    return(d)", "response": "extend dict1 with dict2 with duplicate keys"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if dict1 and dict2 are comprise.", "response": "def _comprise(dict1,dict2):\n    '''\n        dict1 = {'a':1,'b':2,'c':3,'d':4}\n        dict2 = {'b':2,'c':3}\n        _comprise(dict1,dict2)\n    '''\n    len_1 = dict1.__len__()\n    len_2 = dict2.__len__()\n    if(len_2>len_1):\n        return(False)\n    else:\n        for k2 in dict2:\n            v2 = dict2[k2]\n            if(k2 in dict1):\n                v1 = dict1[k2]\n                if(v1 == v2):\n                    return(True)\n                else:\n                    return(False)\n            else:\n                return(False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_intersection(dict1,dict2,**kwargs):\n    '''\n        dict1 = {1:'a',2:'b',3:'c',4:'d'}\n        dict2 = {5:'u',2:'v',3:'w',6:'x',7:'y'}\n        _update_intersection(dict1,dict2)\n        pobj(dict1)\n        pobj(dict2)\n    '''\n    if('deepcopy' in kwargs):\n        deepcopy = kwargs['deepcopy']\n    else:\n        deepcopy = 1\n    if(deepcopy == 1):\n        dict1 = copy.deepcopy(dict1)\n    else:\n        pass\n    for key in dict2:\n        if(key in dict1):\n            dict1[key] = dict2[key]\n    return(dict1)", "response": "Update the dictionary1 with the intersection of dict2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update(dict1,dict2,**kwargs):\n    '''\n        dict1 = {1:'a',2:'b',3:'c',4:'d'}\n        dict2 = {5:'u',2:'v',3:'w',6:'x',7:'y'}\n        _update(dict1,dict2)\n        pobj(dict1)\n        pobj(dict2)\n    '''\n    if('deepcopy' in kwargs):\n        deepcopy = kwargs['deepcopy']\n    else:\n        deepcopy = 1\n    if(deepcopy == 1):\n        dict1 = copy.deepcopy(dict1)\n    else:\n        pass\n    dict1 = _extend(dict1,dict2,overwrite=True,deepcopy=deepcopy)\n    return(dict1)", "response": "Update dict1 with dict2."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setdefault_via_pathlist(external_dict,path_list,**kwargs):\n    '''\n        #if path_list already in external_dict, will do nothing\n        y = {}\n        path_list = ['c','b']\n        _setdefault_via_pathlist(y,path_list)\n        y\n        _setdefault_via_pathlist(y,path_list)\n        y = {}\n        _setdefault_via_pathlist(y,path_list)\n        y\n    '''\n    if('s2n' in kwargs):\n        s2n = kwargs['s2n']\n    else:\n        s2n = 0\n    if('n2s' in kwargs):\n        n2s = kwargs['n2s']\n    else:\n        n2s = 0\n    if('default_element' in kwargs):\n        default_element = kwargs['default_element']\n    else:\n        default_element = {}\n    this = external_dict\n    for i in range(0,path_list.__len__()):\n        key = path_list[i]\n        if(n2s ==1):\n            key = str(key)\n        if(s2n==1):\n            try:\n                int(key)\n            except:\n                pass\n            else:\n                key = int(key)\n        try:\n            this.__getitem__(key)\n        except:\n            try:\n                # necessary ,when default_element = {} or []\n                de = copy.deepcopy(default_element)\n                this.__setitem__(key,de)\n            except:\n                return(external_dict)\n            else:\n                pass\n            this = this.__getitem__(key)\n        else:\n            this = this.__getitem__(key)\n    return(external_dict)", "response": "This function sets the default value of the internal dictionary based on the path_list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setitem_via_pathlist(external_dict,path_list,value,**kwargs):\n    '''\n        y = {'c': {'b': {}}}\n        _setitem_via_pathlist(y,['c','b'],200)\n    '''\n    if('s2n' in kwargs):\n        s2n = kwargs['s2n']\n    else:\n        s2n = 0\n    if('n2s' in kwargs):\n        n2s = kwargs['n2s']\n    else:\n        n2s = 0\n    this = external_dict\n    for i in range(0,path_list.__len__()-1):\n        key = path_list[i]\n        if(n2s ==1):\n            key = str(key)\n        if(s2n==1):\n            try:\n                int(key)\n            except:\n                pass\n            else:\n                key = int(key)\n        this = this.__getitem__(key)\n    this.__setitem__(path_list[-1],value)\n    return(external_dict)", "response": "Set the value of the item in the external_dict based on the path_list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _include_pathlist(external_dict,path_list,**kwargs):\n    '''\n        y = {\n            'a':\n                {'x':88},\n            'b':\n                {\n                    'x':\n                        {'c':66}\n                }\n        }\n        _include_pathlist(y,['a'])\n        _include_pathlist(y,['a','x'])\n        _include_pathlist(y,['b','x','c'])\n    '''\n    if('s2n' in kwargs):\n        s2n = kwargs['s2n']\n    else:\n        s2n = 0\n    if('n2s' in kwargs):\n        n2s = kwargs['n2s']\n    else:\n        n2s = 0\n    this = external_dict\n    for i in range(0,path_list.__len__()):\n        key = path_list[i]\n        if(n2s ==1):\n            key = str(key)\n        if(s2n==1):\n            try:\n                int(key)\n            except:\n                pass\n            else:\n                key = int(key)\n        try:\n            this = this.__getitem__(key)\n        except:\n            return(False)\n        else:\n            pass\n    return(True)", "response": "Include the path_list in the external_dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the maximum word width of the dictionary.", "response": "def max_word_width(myDict):\n    '''\n        currd = {0:'AutoPauseSpeed', 125:'HRLimitLow', 6:'Activity'}\n        max_wordwidth(currd)\n    '''\n    maxValueWidth = 0\n    for each in myDict:\n        eachValueWidth = myDict[each].__len__()\n        if(eachValueWidth > maxValueWidth):\n            maxValueWidth = eachValueWidth\n    return(maxValueWidth)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef max_display_width(myDict):\n    '''\n        currd = {0:'\u4f60\u4eec\u5927\u5bb6\u597d', 125:'ABCDE', 6:'1234567'}\n        dict_get_max_word_displaywidth(currd)\n    '''\n    maxValueWidth = 0\n    for each in myDict:\n        eachValueWidth = str_display_width(myDict[each])\n        if(eachValueWidth > maxValueWidth):\n            maxValueWidth = eachValueWidth\n    return(maxValueWidth)", "response": "Returns the maximum display width of the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_leaf(obj):\n    '''\n        the below is for nested-dict\n        any type is not dict will be treated as a leaf\n        empty dict will be treated as a leaf\n        from edict.edict import *\n        is_leaf(1)\n        is_leaf({1:2})\n        is_leaf({})\n    '''\n    if(is_dict(obj)):\n        length = obj.__len__()\n        if(length == 0):\n            return(True)\n        else:\n            return(False)\n    else:\n        return(True)", "response": "returns True if the object is a leaf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting dict to kvmatrix", "response": "def _d2kvmatrix(d):\n    '''\n        d = {1: 2, 3: {'a': 'b'}}\n        km,vm = _d2kvmatrix(d)\n        d = {1: {2:{22:222}}, 3: {'a': 'b'}}\n        km,vm = _d2kvmatrix(d)\n        ##\n        km: \u6309\u7167\u5c42\u6b21\u5b58\u50a8pathlist,\u5c42\u6b21\u4ece0\u5f00\u59cb\uff0c\n        {\n         1: 2,\n         3:\n            {\n             'a': 'b'\n            }\n        }\n        km[0] = [[1],[3]]\n        km[1] = [[3,'a']]\n        vm: vm\u6bd4\u8f83\u7279\u6b8a\uff0c\u4e0d\u592a\u597d\u7406\u89e3\uff0c\u8bf7\u53c2\u7167\u51fd\u6570elel.get_wfs \u548c_kvmatrix2d\n            vm\u7684\u6570\u7ec4\u8868\u793a\u5c42\u6b21\n        rvmat: \u4e0ekm\u5bf9\u5e94\uff0c\u5b58\u50a8key\u5bf9\u5e94\u7684value,\u4e0d\u8fc7\u5bf9\u5e94\u5c42\u6b21\u4f7fkm\u7684\u5c42\u6b21+1\n    '''\n    km = []\n    vm = [list(d.values())]\n    vm_history ={0:[0]}\n    unhandled = [{'data':d,'kpl':[]}]\n    while(unhandled.__len__()>0):\n        next_unhandled = []\n        keys_level = []\n        next_vm_history = {}\n        for i in range(0,unhandled.__len__()):\n            data = unhandled[i]['data']\n            kpl = unhandled[i]['kpl']\n            values = list(data.values())\n            _setitem_via_pathlist(vm,vm_history[i],values)\n            vm_pl = vm_history[i]\n            del vm_history[i]\n            keys = data.keys()\n            keys = elel.array_map(keys,_gen_sonpl,kpl)\n            keys_level.extend(keys)\n            for j in range(0,values.__len__()):\n                v = values[j]\n                cond = is_leaf(v)\n                if(cond):\n                    pass\n                else:\n                    kpl = copy.deepcopy(keys[j])\n                    next_unhandled.append({'data':v,'kpl':kpl})\n                    vpl = copy.deepcopy(vm_pl)\n                    vpl.append(j)\n                    next_vm_history[next_unhandled.__len__()-1] = vpl\n        vm_history = next_vm_history\n        km.append(keys_level)\n        unhandled = next_unhandled\n    vm = vm[0]\n    return((km,vm))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows the kmatrix of the current hierarchy", "response": "def show_kmatrix(km):\n    '''\n        d = {1: {2: {22: 222}}, 3: {'a': 'b'}}\n        km = [[[1], [3]], [[1, 2], [3, 'a']], [[1, 2, 22]]]\n        show_kmatrix(km)\n    '''\n    rslt = []\n    for i in range(0,km.__len__()):\n        level = km[i]\n        for j in range(0,level.__len__()):\n            kpl = level[j]\n            print(kpl)\n            rslt.append(kpl)\n    return(rslt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_vmatrix(vm):\n    '''\n        d = {1: {2: {22: 222}}, 3: {'a': 'b'}}\n        vm = [[[222]], ['b']]\n        show_vmatrix(vm)\n    '''\n    unhandled = vm\n    while(unhandled.__len__()>0):\n        next_unhandled = []\n        for i in range(0,unhandled.__len__()):\n            ele = unhandled[i]\n            print(ele)\n            cond = elel.is_leaf(ele)\n            if(cond):\n                pass\n            else:\n                children = ele[0]\n                next_unhandled.append(children)\n        unhandled = next_unhandled", "response": "d = {1: {2: {22: 222}}, 3: {'a': 'b'}}\n        vm = [[[222]], ['b']]\n        show_vmatrix(vm)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert kmatrix to dict.", "response": "def _kvmatrix2d(km,vm):\n    '''\n        \n        km = [[[1], [3]], [[1, 2], [3, 'a']], [[1, 2, 22]]]\n        show_kmatrix(km)\n        vm = [[[222]], ['b']]\n        show_vmatrix(vm)\n        \n        d = _kvmatrix2d(km,vm)\n    '''\n    d = {}\n    kmwfs = get_kmwfs(km)\n    vmwfs = elel.get_wfs(vm)\n    lngth = vmwfs.__len__()\n    for i in range(0,lngth):\n        value = elel.getitem_via_pathlist(vm,vmwfs[i])\n        cond = elel.is_leaf(value)\n        if(cond):\n            _setitem_via_pathlist(d,kmwfs[i],value)\n        else:\n            _setdefault_via_pathlist(d,kmwfs[i])\n    return(d)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the rvmat from a dictionary", "response": "def _get_rvmat(d):\n    '''\n        d = {\n         'x':\n              {\n               'x2': 'x22',\n               'x1': 'x11'\n              },\n         'y':\n              {\n               'y1': 'v1',\n               'y2':\n                     {\n                      'y4': 'v4',\n                      'y3': 'v3'\n                     }\n              },\n         't': 20,\n         'u':\n              {\n               'u1': 'u2'\n              }\n        }\n        \n        \n    '''\n    km,vm = _d2kvmatrix(d)\n    def map_func(ele,indexc,indexr):\n        return(_getitem_via_pathlist(d,ele))\n    rvmat = elel.matrix_map(km,map_func)\n    rvmat = elel.prepend(rvmat,[])\n    return(rvmat)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_vndmat_attr(d,keypath,attr,**kwargs):\n    '''\n        get_vndmat_attr(d,['x'],'lsib_path',path2keypath=True)\n        get_vndmat_attr(d,['t'],'lsib_path',path2keypath=True)\n        get_vndmat_attr(d,['u'],'lsib_path',path2keypath=True)\n        get_vndmat_attr(d,['y'],'lsib_path',path2keypath=True)\n    '''\n    kt,vn = _d2kvmatrix(d)\n    kdmat = _scankm(kt)\n    ltree = elel.ListTree(vn)\n    vndmat = ltree.desc\n    loc = get_kdmat_loc(kdmat,keypath)\n    rslt = vndmat[loc[0]][loc[1]][attr]\n    if(rslt == None):\n        pass\n    elif(elel.is_matrix(rslt,mode='loose')):\n        if('path2loc' in kwargs):\n            rslt = elel.array_map(rslt,ltree.path2loc)\n        else:\n            pass\n        if('path2keypath' in kwargs):\n            nlocs = elel.array_map(rslt,ltree.path2loc)\n            def cond_func(ele,kdmat):\n                return(kdmat[ele[0]][ele[1]]['path'])\n            rslt = elel.array_map(nlocs,cond_func,kdmat)\n        else:\n            pass        \n    else:\n        if('path2loc' in kwargs):\n            rslt = ltree.path2loc(rslt)\n        else:\n            pass\n        if('path2keypath' in kwargs):\n            nloc = ltree.path2loc(rslt)\n            rslt = kdmat[nloc[0]][nloc[1]]['path']\n        else:\n            pass\n    return(rslt)", "response": "get an attribute of a VD MAT file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sub_via_value(self,*vs,**kwargs):\n        '''\n            d= {1:'a',2:'b',3:'a',4:'d',5:'e'}\n            ed = eded.Edict(d)\n            ed.sub_via_value('a','d')\n        '''\n        sd = _select_norecur_via_value(self.dict,*vs,**kwargs)\n        return(Edict(sd))", "response": "Return a new eded. Edict object with the values in vs selected."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef radpress_get_markup_descriptions():\n    result = []\n    for markup in get_markup_choices():\n        markup_name = markup[0]\n        result.append({\n            'name': markup_name,\n            'title': markup[1],\n            'description': trim(get_reader(markup=markup_name).description)\n        })\n    return result", "response": "Provides markup options. It used for adding descriptions in admin and\n    zenith mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_parser(description):\n    parser = argparse.ArgumentParser(description=description)\n    parser.add_argument('key', help=\"Camellia key.\")\n    parser.add_argument('input_file', nargs='*',\n                        help=\"File(s) to read as input data. If none are \"\n                        \"provided, assume STDIN.\")\n    parser.add_argument('-o', '--output_file',\n                        help=\"Output file. If not provided, assume STDOUT.\")\n    parser.add_argument('-l', '--keylen', type=int, default=128,\n                        help=\"Length of 'key' in bits, must be in one of %s \"\n                        \"(default 128).\" % camcrypt.ACCEPTABLE_KEY_LENGTHS)\n    parser.add_argument('-H', '--hexkey', action='store_true',\n                        help=\"Treat 'key' as a hex string rather than binary.\")\n\n    return parser", "response": "Build an ArgumentParser with common arguments for both operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a camcrypt. CamCrypt object based on keylen hexkey and key.", "response": "def _get_crypto(keylen, hexkey, key):\n    \"\"\"Return a camcrypt.CamCrypt object based on keylen, hexkey, and key.\"\"\"\n    if keylen not in camcrypt.ACCEPTABLE_KEY_LENGTHS:\n        raise ValueError(\"key length must be one of 128, 192, or 256\")\n\n    if hexkey:\n        key = key.decode('hex')\n\n    return camcrypt.CamCrypt(keylen=keylen, key=key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread data from file or STDIN.", "response": "def _get_data(filenames):\n    \"\"\"Read data from file(s) or STDIN.\n\n    Args:\n        filenames (list): List of files to read to get data. If empty or\n            None, read from STDIN.\n    \"\"\"\n    if filenames:\n        data = \"\"\n        for filename in filenames:\n            with open(filename, \"rb\") as f:\n                data += f.read()\n    else:\n        data = sys.stdin.read()\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints data to a file or STDOUT.", "response": "def _print_results(filename, data):\n    \"\"\"Print data to a file or STDOUT.\n\n    Args:\n        filename (str or None): If None, print to STDOUT; otherwise, print\n            to the file with this name.\n        data (str): Data to print.\n    \"\"\"\n    if filename:\n        with open(filename, 'wb') as f:\n            f.write(data)\n    else:\n        print data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the timestamp of the message.", "response": "def timestamp(self, value):\n        \"\"\"\n        The local time when the message was written.\n\n        Must follow the format 'Mmm DD HH:MM:SS'.  If\n        the day of the month is less than 10, then it\n        MUST be represented as a space and then the\n        number.\n\n        \"\"\"\n        if not self._timestamp_is_valid(value):\n            value = self._calculate_current_timestamp()\n        self._timestamp = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the hostname of the log message.", "response": "def hostname(self, value):\n        \"\"\"\n        The hostname where the log message was created.\n\n        Should be the first part of the hostname, or\n        an IP address. Should NOT be set to a fully\n        qualified domain name.\n\n        \"\"\"\n        if value is None:\n            value = socket.gethostname()\n        self._hostname = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to all registered hosts.", "response": "def log(self, facility, level, text, pid=False):\n        \"\"\"Send the message text to all registered hosts.\n\n        The facility and level will be used to create the packet's PRI\n        part. The HEADER will be automatically determined from the\n        current time and hostname. The MSG will be set from the\n        running program's name and the text parameter.\n\n        This is the simplest way to use reSyslog.Syslog, creating log\n        messages containing the current time, hostname, program name,\n        etc. This is how you do it::\n\n            logger = syslog.Syslog()\n            logger.add_host(\"localhost\")\n            logger.log(Facility.USER, Level.INFO, \"Hello World\")\n\n        If pid is True the process ID will be prepended to the text\n        parameter, enclosed in square brackets and followed by a\n        colon.\n\n        \"\"\"\n        pri = PRI(facility, level)\n        header = HEADER()\n        if pid:\n            msg = MSG(content=text, pid=os.getpid())\n        else:\n            msg = MSG(content=text)\n        packet = Packet(pri, header, msg)\n        self._send_packet_to_hosts(packet)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self, count_common=4, min_common=1000, timeout=20):\n        start = time()\n        while time() - start < timeout:\n            tokens = [token for token, pos in self.brown.get_tagged_sent()]\n            current_count = 0\n            for word, commonness in self.sentence_tool.rate(tokens):\n                if commonness > min_common:\n                    current_count += 1\n                if current_count >= count_common:\n                    self.tokens = tokens\n                    return self.tokens\n\n        raise TimeoutError", "response": "Generate a new sentence and return a list of tokens on success"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new common diceware password and a sentence.", "response": "def new_common_diceware_password(self, number_of_words=6, hint=''):\n        \"\"\"\n        Return a suggested password\n        :param int number_of_words: number of words generated\n        :param str hint:\n        :return tuple: a suggested password and a sentence\n\n        >>> GeneratePassword().new_common_diceware_password()\n        ('rive2sidelauraarchitectss!mplytheOreticalassessMeNt$', [('Mynheer', False), (',', False), ('Sir', False), ('Francis', False), (',', False), ('the', False), ('riverside', True), ('laura', True), (',', False), ('the', False), ('very', False), ('architects', True), ('of', False), ('the', False), ('river', False), ('on', False), ('his', False), ('right', False), ('purling', False), ('simply', True), ('to', False), ('the', False), ('bay', False), ('past', False), ('fish', False), ('weirs', False), ('and', False), ('rocks', False), (',', False), ('and', False), ('ahead', False), ('the', False), ('theoretical', True), ('assessments', True)])\n        \"\"\"\n        keywords = [self.wordlist.get_random_word() for _ in range(number_of_words)]\n        password = self.conformizer.conformize(keywords)\n        if hint:\n            keywords = [hint] + keywords\n        return password, self.to_sentence.from_keywords(keywords)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a suggested PIN based on the generated PIN.", "response": "def new_pin(self, min_length=4, min_common=1000, timeout=20, refresh_timeout=3):\n        \"\"\"\n        Return a suggested PIN\n\n        :param int min_length: minimum length of the PIN generated\n        :param int min_common: the minimal commonness to be considered convertible to a PIN\n        :param float timeout: main timeout in seconds\n        :param float refresh_timeout: timeout to new sentence\n        :return str: a string of digits\n\n        >>> GeneratePassword().new_pin()\n        ('32700', [('His', False), ('mouth', True), ('was', False), ('open', False), (',', False), ('his', False), ('neck', True), ('corded', True), ('with', False), ('the', False), ('strain', True), ('of', False), ('his', False), ('screams', True)])\n        \"\"\"\n        self.refresh(count_common=min_length, min_common=min_common, timeout=refresh_timeout)\n        rating = self.sentence_tool.rate(self.tokens)\n\n        start = time()\n        while time() - start < timeout:\n            pin = ''\n            for token, commonness in rating:\n                if commonness >= min_common:\n                    key = self.mnemonic.word_to_key('major_system', token.lower())\n                    if key is not None:\n                        pin += key\n\n            if len(pin) < min_length:\n                self.refresh(count_common=min_length, min_common=min_common, timeout=refresh_timeout)\n                rating = self.sentence_tool.rate(self.tokens)\n            else:\n                return pin, list(self.overlap_pin(pin, self.tokens))\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_check_config(self, config):\n        self.uri = config[\"uri\"]\n        self.use_https = config.get(\"https\", False)\n        self.method = config.get(\"method\", \"GET\")", "response": "Applies a validated config dictionary to the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform(self):\n        if self.use_https:\n            conn = client.HTTPSConnection(self.host, self.port)\n        else:\n            conn = client.HTTPConnection(self.host, self.port)\n\n        conn.request(self.method, self.uri)\n\n        response = conn.getresponse()\n\n        conn.close()\n\n        return bool(response.status >= 200 and response.status < 300)", "response": "Perform a simple HTTP request against the configured url and returns\n        true if the response has a 2xx code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync_balancer_files(self):\n\n        def sync():\n            for balancer in self.configurables[Balancer].values():\n                balancer.sync_file(self.configurables[Cluster].values())\n\n        self.work_pool.submit(sync)", "response": "Synchronizes the config files for each present Balancer instance and the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when a load balancer config file is removed from the load balancer.", "response": "def on_balancer_remove(self, name):\n        \"\"\"\n        The removal of a load balancer config isn't supported just yet.\n\n        If the balancer being removed is the only configured one we fire\n        a critical log message saying so.  A writer setup with no balancers\n        is less than useless.\n        \"\"\"\n        if len(self.configurables[Balancer]) == 1:\n            logger.critical(\n                \"'%s' config file removed! It was the only balancer left!\",\n                name\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_discovery_add(self, discovery):\n        discovery.connect()\n\n        for cluster in self.configurables[Cluster].values():\n            if cluster.discovery != discovery.name:\n                continue\n\n            self.launch_thread(\n                cluster.name, discovery.start_watching,\n                cluster, self.sync_balancer_files\n            )\n\n        self.sync_balancer_files()", "response": "Called when a discovery is added to the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_discovery_remove(self, name):\n        self.configurables[Discovery][name].stop()\n\n        self.sync_balancer_files()", "response": "Called when a Discovery is removed from the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a new cluster is added to the sync balancer.", "response": "def on_cluster_add(self, cluster):\n        \"\"\"\n        Once a cluster is added we tell its associated discovery method to\n        start watching for changes to the cluster's child nodes (if the\n        discovery method is configured and available).\n        \"\"\"\n        if cluster.discovery not in self.configurables[Discovery]:\n            return\n\n        discovery = self.configurables[Discovery][cluster.discovery]\n\n        self.launch_thread(\n            cluster.name, discovery.start_watching,\n            cluster, self.sync_balancer_files\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_cluster_update(self, name, new_config):\n        cluster = self.configurables[Cluster][name]\n\n        old_discovery = cluster.discovery\n        new_discovery = new_config[\"discovery\"]\n        if old_discovery == new_discovery:\n            self.sync_balancer_files()\n            return\n\n        logger.info(\n            \"Switching '%s' cluster discovery from '%s' to '%s'\",\n            name, old_discovery, new_discovery\n        )\n\n        if old_discovery in self.configurables[Discovery]:\n            self.configurables[Discovery][old_discovery].stop_watching(\n                cluster\n            )\n            self.kill_thread(cluster.name)\n        if new_discovery not in self.configurables[Discovery]:\n            logger.warn(\n                \"New discovery '%s' for cluster '%s' is unknown/unavailable.\",\n                new_discovery, name\n            )\n            self.sync_balancer_files()\n            return\n\n        discovery = self.configurables[Discovery][new_discovery]\n        self.launch_thread(\n            cluster.name,\n            discovery.start_watching, cluster, self.sync_balancer_files\n        )", "response": "Callback hook for when a cluster is updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_cluster_remove(self, name):\n        discovery_name = self.configurables[Cluster][name].discovery\n        if discovery_name in self.configurables[Discovery]:\n            self.configurables[Discovery][discovery_name].stop_watching(\n                self.configurables[Cluster][name]\n            )\n            self.kill_thread(name)\n\n        self.sync_balancer_files()", "response": "Called when a cluster is removed from the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_path(path):\r\n    '''Parses an address into directory and port parts.\r\n\r\n    The last segment of the address will be checked to see if it matches a port\r\n    specification (i.e. contains a colon followed by text). This will be\r\n    returned separately from the directory parts.\r\n\r\n    If a leading / is given, that will be returned as the first directory\r\n    component. All other / characters are removed.\r\n\r\n    All leading / characters are condensed into a single leading /.\r\n\r\n    Any path components that are . will be removed, as they just point to the\r\n    previous path component. For example, '/localhost/.' will become\r\n    '/localhost'. Any path components that are .. will be removed, along with\r\n    the previous path component. If this renders the path empty, it will be\r\n    replaced with '/'.\r\n\r\n    Examples:\r\n\r\n    >>> parse_path('localhost:30000/manager/comp0.rtc')\r\n    (['localhost:30000', 'manager', 'comp0.rtc'], None)\r\n    \r\n    >>> parse_path('localhost/manager/comp0.rtc:in')\r\n    (['localhost', 'manager', 'comp0.rtc'], 'in')\r\n    \r\n    >>> parse_path('/localhost/manager/comp0.rtc')\r\n    (['/', 'localhost', 'manager', 'comp0.rtc'], None)\r\n    \r\n    >>> parse_path('/localhost/manager/comp0.rtc:in')\r\n    (['/', 'localhost', 'manager', 'comp0.rtc'], 'in')\r\n    \r\n    >>> parse_path('manager/comp0.rtc')\r\n    (['manager', 'comp0.rtc'], None)\r\n    \r\n    >>> parse_path('comp0.rtc')\r\n    (['comp0.rtc'], None)\r\n\r\n    '''\r\n    bits = path.lstrip('/').split('/')\r\n    if not bits:\r\n        raise exceptions.BadPathError(path)\r\n\r\n    if bits[-1]:\r\n        bits[-1], port = get_port(bits[-1])\r\n    else:\r\n        port = None\r\n    if path[0] == '/':\r\n        bits = ['/'] + bits\r\n    condensed_bits = []\r\n    for bit in bits:\r\n        if bit == '.':\r\n            continue\r\n        if bit == '..':\r\n            condensed_bits = condensed_bits[:-1]\r\n            continue\r\n        condensed_bits.append(bit)\r\n    if not condensed_bits:\r\n        condensed_bits = ['/']\r\n    return condensed_bits, port", "response": "Parses a path into directory and port parts."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats a path in rtctree format as a string placing / between each component.", "response": "def format_path(path):\r\n    '''Formats a path as a string, placing / between each component.\r\n\r\n    @param path A path in rtctree format, as a tuple with the port name as the\r\n                second component.\r\n\r\n    Examples:\r\n\r\n    >>> format_path((['localhost:30000', 'manager', 'comp0.rtc'], None))\r\n    'localhost:30000/manager/comp0.rtc'\r\n\r\n    >>> format_path((['localhost', 'manager', 'comp0.rtc'], 'in'))\r\n    'localhost/manager/comp0.rtc:in'\r\n    \r\n    >>> format_path((['/', 'localhost', 'manager', 'comp0.rtc'], None))\r\n    '/localhost/manager/comp0.rtc'\r\n    \r\n    >>> format_path((['/', 'localhost', 'manager', 'comp0.rtc'], 'in'))\r\n    '/localhost/manager/comp0.rtc:in'\r\n\r\n    >>> format_path((['manager', 'comp0.rtc'], None))\r\n    'manager/comp0.rtc'\r\n    \r\n    >>> format_path((['comp0.rtc'], None))\r\n    'comp0.rtc'\r\n\r\n    '''\r\n    if path[1]:\r\n        port = ':' + path[1]\r\n    else:\r\n        port = ''\r\n    if type(path[0]) is str:\r\n        # Don't add slashes if the path is singular\r\n        return path[0] + port\r\n    if path[0][0] == '/':\r\n        starter = '/'\r\n        path = path[0][1:]\r\n    else:\r\n        starter = ''\r\n        path = path[0]\r\n    return starter + '/'.join(path) + port"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmdline_params(self,\n                       distance_matrix_file_name='distance.matrix',\n                       remote_folder_path=None):\n        \"\"\"Synthesize command line parameters\n\n        e.g. [ ['--output-file', 'out.barcode'], ['distance_matrix.file']]\n\n        :param distance_matrix_file_name: Name of distance matrix file\n        :param remote_folder_path: Path to remote folder containing distance matrix file\n\n        \"\"\"\n        parameters = []\n\n        pm_dict = self.get_dict()\n        for k, v in pm_dict.iteritems():\n            parameters += ['--' + k, v]\n\n        # distance matrix can be provided via remote folder\n        if remote_folder_path is None:\n            parameters += [distance_matrix_file_name]\n        else:\n            parameters += [remote_folder_path + distance_matrix_file_name]\n\n        return map(str, parameters)", "response": "Synthesize command line parameters e. g. [ - output - file out. barcode - distance_matrix. file - > remote_folder_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef color_string(color, string):\n    if not color_available:\n        return string\n\n    return color + string + colorama.Fore.RESET", "response": "Colorizes a given string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef color_for_level(level):\n    if not color_available:\n        return None\n\n    return {\n        logging.DEBUG: colorama.Fore.WHITE,\n        logging.INFO: colorama.Fore.BLUE,\n        logging.WARNING: colorama.Fore.YELLOW,\n        logging.ERROR: colorama.Fore.RED,\n        logging.CRITICAL: colorama.Fore.MAGENTA\n    }.get(level, colorama.Fore.WHITE)", "response": "Returns the colorama Fore color for a given log level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a never - ending cycle of colors to choose from for individual threads.", "response": "def create_thread_color_cycle():\n    \"\"\"\n    Generates a never-ending cycle of colors to choose from for individual\n    threads.\n\n    If color is not available, a cycle that repeats None every time is\n    returned instead.\n    \"\"\"\n    if not color_available:\n        return itertools.cycle([None])\n\n    return itertools.cycle(\n        (\n            colorama.Fore.CYAN,\n            colorama.Fore.BLUE,\n            colorama.Fore.MAGENTA,\n            colorama.Fore.GREEN,\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef color_for_thread(thread_id):\n    if thread_id not in seen_thread_colors:\n        seen_thread_colors[thread_id] = next(thread_colors)\n\n    return seen_thread_colors[thread_id]", "response": "Returns the next color for a thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format(self, record):\n        if not self.is_tty:\n            return super(CLIHandler, self).format(record)\n\n        level_abbrev = record.levelname[0]\n\n        time_and_level = color_string(\n            color_for_level(record.levelno),\n            \"[%(asctime)s \" + level_abbrev + \"]\"\n        )\n        thread = color_string(\n            color_for_thread(record.thread),\n            \"[%(threadName)s]\"\n        )\n        formatter = logging.Formatter(\n            time_and_level + thread + \" %(message)s\", \"%Y-%m-%d %H:%M:%S\"\n        )\n\n        return formatter.format(record)", "response": "Formats a given log record to include the timestamp log level thread and message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds bare metal cloud to the client.", "response": "def add_bare_metal_cloud(client, cloud, keys):\n    \"\"\"\n    Black magic is happening here. All of this wil change when we sanitize our API, however, this works until then\n    \"\"\"\n    title = cloud.get('title')\n    provider = cloud.get('provider')\n    key = cloud.get('apikey', \"\")\n    secret = cloud.get('apisecret', \"\")\n    tenant_name = cloud.get('tenant_name', \"\")\n    region = cloud.get('region', \"\")\n    apiurl = cloud.get('apiurl', \"\")\n    compute_endpoint = cloud.get('compute_endpoint', None)\n    machine_ip = cloud.get('machine_ip', None)\n    machine_key = cloud.get('machine_key', None)\n    machine_user = cloud.get('machine_user', None)\n    machine_port = cloud.get('machine_port', None)\n\n    if provider == \"bare_metal\":\n        machine_ids = cloud['machines'].keys()\n        bare_machine = cloud['machines'][machine_ids[0]]\n        machine_hostname = bare_machine.get('dns_name', None)\n        if not machine_hostname:\n            machine_hostname = bare_machine['public_ips'][0]\n\n        if not machine_ip:\n            machine_ip = machine_hostname\n        key = machine_hostname\n        machine_name = cloud['machines'][machine_ids[0]]['name']\n        machine_id = machine_ids[0]\n\n        keypairs = keys.keys()\n        for i in keypairs:\n            keypair_machines = keys[i]['machines']\n            if keypair_machines:\n                keypair_machs = keys[i]['machines']\n                for mach in keypair_machs:\n                    if mach[1] == machine_id:\n                        machine_key = i\n                        break\n            else:\n                pass\n\n    client.add_cloud(title, provider, key, secret, tenant_name=tenant_name, region=region, apiurl=apiurl,\n                       machine_ip=machine_ip, machine_key=machine_key, machine_user=machine_user,\n                       compute_endpoint=compute_endpoint, machine_port=machine_port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the array of volume multipliers for the dynamic", "response": "def to_array(self, channels=2):\n        \"\"\"Generate the array of volume multipliers for the dynamic\"\"\"\n        if self.fade_type == \"linear\":\n            return np.linspace(self.in_volume, self.out_volume,\n                self.duration * channels)\\\n                .reshape(self.duration, channels)\n        elif self.fade_type == \"exponential\":\n            if self.in_volume < self.out_volume:\n                return (np.logspace(8, 1, self.duration * channels,\n                    base=.5) * (\n                        self.out_volume - self.in_volume) / 0.5 + \n                        self.in_volume).reshape(self.duration, channels)\n            else:\n                return (np.logspace(1, 8, self.duration * channels, base=.5\n                    ) * (self.in_volume - self.out_volume) / 0.5 + \n                    self.out_volume).reshape(self.duration, channels)\n        elif self.fade_type == \"cosine\":\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a single SQL statement and return the result.", "response": "def sql(self, sql: str, *qmark_params, **named_params):\n        \"\"\"\n        :deprecated: use self.statement to execute properly-formatted sql statements\n        \"\"\"\n        statement = SingleSqlStatement(sql)\n        return self.statement(statement).execute(*qmark_params, **named_params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a single SQL query and return a cursor.", "response": "def _sql(self, sql: str, params=()):\n        \"\"\"\n        :deprecated: use self.sql instead\n        \"\"\"\n        statement = SingleSqlStatement(sql)\n        return self.statement(statement).execute_for_params(params).cursor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self):\n        if self.SacrificeDate:\n            self.Active = False\n        super(PlugEvents, self).save()", "response": "Over - rides the default save function for PlugEvents.\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a bash command which will load every dataset in a bucket at a prefix.", "response": "def load_prefix(s3_loc, success_only=None, recent_versions=None, exclude_regex=None, just_sql=False):\n    \"\"\"Get a bash command which will load every dataset in a bucket at a prefix.\n\n    For this to work, all datasets must be of the form `s3://$BUCKET_NAME/$PREFIX/$DATASET_NAME/v$VERSION/$PARTITIONS`.\n    Any other formats will be ignored.\n\n    :param bucket_name\n    :param prefix\n    \"\"\"\n    bucket_name, prefix = _get_bucket_and_prefix(s3_loc)\n    datasets = _get_common_prefixes(bucket_name, prefix)\n    bash_cmd = ''\n\n    for dataset in datasets:\n        dataset = _remove_trailing_backslash(dataset)\n        try:\n            bash_cmd += get_bash_cmd('s3://{}/{}'.format(bucket_name, dataset),\n                                     success_only=success_only, recent_versions=recent_versions,\n                                     exclude_regex=exclude_regex, just_sql=just_sql)\n        except Exception as e:\n            sys.stderr.write('Failed to process {}, {}\\n'.format(dataset, str(e)))\n    return bash_cmd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the contents of a file as a unicode string.", "response": "def read_unicode(path, encoding, encoding_errors):\n    \"\"\" Return the contents of a file as a unicode string. \"\"\"\n    try:\n      f = open(path, 'rb')\n      return make_unicode(f.read(), encoding, encoding_errors)\n    finally:\n      f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a template name a directory and an extension return the absolute path to the template.", "response": "def get_abs_template_path(template_name, directory, extension):\n    \"\"\" Given a template name, a directory, and an extension, return the\n    absolute path to the template. \"\"\"\n    # Get the relative path\n    relative_path = join(directory, template_name)\n    file_with_ext = template_name\n\n    if extension:\n        # If there is a default extension, but no file extension, then add it\n        file_name, file_ext = splitext(file_with_ext)\n        if not file_ext:\n            file_with_ext = extsep.join(\n                (file_name, extension.replace(extsep, '')))\n            # Rebuild the relative path\n            relative_path = join(directory, file_with_ext)\n\n    return abspath(relative_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a file into a unicode string.", "response": "def load_file(path, encoding, encoding_errors):\n    \"\"\" Given an existing path, attempt to load it as a unicode string. \"\"\"\n    abs_path = abspath(path)\n    if exists(abs_path):\n        return read_unicode(abs_path, encoding, encoding_errors)\n    raise IOError('File %s does not exist' % (abs_path))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a template and return its contents as a unicode string.", "response": "def load_template(name, directory, extension, encoding, encoding_errors):\n    \"\"\" Load a template and return its contents as a unicode string. \"\"\"\n    abs_path = get_abs_template_path(name, directory, extension)\n    return load_file(abs_path, encoding, encoding_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_http_request(self, method_type, params, **kwargs):\n        prepared_request = self.session.prepare_request(\n            requests.Request(method=method_type, **params)\n        )\n        return prepared_request", "response": "Prepares the HTTP REQUEST and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call_api(self, method_type, method_name,\n                 valid_status_codes, resource, data,\n                 uid, **kwargs):\n        \"\"\"\n        Make HTTP calls.\n\n        Args:\n            method_type: The HTTP method\n            method_name: The name of the python method making the HTTP call\n            valid_status_codes: A tuple of integer status codes\n                                deemed acceptable as response statuses\n            resource: The resource class that will be generated\n            data: The post data being sent.\n            uid: The unique identifier of the resource.\n        Returns:\n\n        kwargs is a list of keyword arguments. Additional custom keyword\n        arguments can be sent into this method and will be passed into\n        subclass methods:\n\n        - get_url\n        - prepare_http_request\n        - get_http_headers\n        \"\"\"\n        url = resource.get_resource_url(\n            resource, base_url=self.Meta.base_url\n        )\n        if method_type in SINGLE_RESOURCE_METHODS:\n            if not uid and not kwargs:\n                raise MissingUidException\n            url = resource.get_url(\n                url=url, uid=uid, **kwargs)\n        params = {\n            'headers': self.get_http_headers(\n                self.Meta.name, method_name, **kwargs),\n            'url': url\n        }\n        if method_type in ['POST', 'PUT', 'PATCH'] and isinstance(data, dict):\n            params.update(json=data)\n        prepared_request = self.prepare_http_request(\n            method_type, params, **kwargs)\n        response = self.session.send(prepared_request)\n        return self._handle_response(response, valid_status_codes, resource)", "response": "Makes a HTTP call to the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_response(self, response, valid_status_codes, resource):\n        if response.status_code not in valid_status_codes:\n            raise InvalidStatusCodeError(\n                status_code=response.status_code,\n                expected_status_codes=valid_status_codes\n                )\n        if response.content:\n            data = response.json()\n            if isinstance(data, list):\n                # A list of results is always rendered\n                return [resource(**x) for x in data]\n            else:\n                # Try and find the paginated resources\n                key = getattr(resource.Meta, 'pagination_key', None)\n                if isinstance(data.get(key), list):\n                    # Only return the paginated responses\n                    return [resource(**x) for x in data.get(key)]\n                else:\n                    # Attempt to render this whole response as a resource\n                    return [resource(**data)]\n        return []", "response": "Handles the response object and returns a list of Resource instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assign_methods(self, resource_class):\n        assert all([\n            x.upper() in VALID_METHODS for x in resource_class.Meta.methods])\n        for method in resource_class.Meta.methods:\n\n            self._assign_method(\n                resource_class,\n                method.upper()\n            )", "response": "Assign methods for communicating with a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _assign_method(self, resource_class, method_type):\n\n        \"\"\"\n        If we assigned the same method to each method, it's the same\n        method in memory, so we need one for each acceptable HTTP method.\n        \"\"\"\n        method_name = resource_class.get_method_name(\n            resource_class, method_type)\n        valid_status_codes = getattr(\n            resource_class.Meta,\n            'valid_status_codes',\n            DEFAULT_VALID_STATUS_CODES\n        )\n\n        # I know what you're going to say, and I'd love help making this nicer\n        # reflection assigns the same memory addr to each method otherwise.\n        def get(self, method_type=method_type, method_name=method_name,\n                valid_status_codes=valid_status_codes,\n                resource=resource_class, data=None, uid=None, **kwargs):\n            return self.call_api(\n                method_type, method_name,\n                valid_status_codes, resource,\n                data, uid=uid, **kwargs)\n\n        def put(self, method_type=method_type, method_name=method_name,\n                valid_status_codes=valid_status_codes,\n                resource=resource_class, data=None, uid=None, **kwargs):\n            return self.call_api(\n                method_type, method_name,\n                valid_status_codes, resource,\n                data, uid=uid, **kwargs)\n\n        def post(self, method_type=method_type, method_name=method_name,\n                 valid_status_codes=valid_status_codes,\n                 resource=resource_class, data=None, uid=None, **kwargs):\n            return self.call_api(\n                method_type, method_name,\n                valid_status_codes, resource,\n                data, uid=uid, **kwargs)\n\n        def patch(self, method_type=method_type, method_name=method_name,\n                  valid_status_codes=valid_status_codes,\n                  resource=resource_class, data=None, uid=None, **kwargs):\n            return self.call_api(\n                method_type, method_name,\n                valid_status_codes, resource,\n                data, uid=uid, **kwargs)\n\n        def delete(self, method_type=method_type, method_name=method_name,\n                   valid_status_codes=valid_status_codes,\n                   resource=resource_class, data=None, uid=None, **kwargs):\n            return self.call_api(\n                method_type, method_name,\n                valid_status_codes, resource,\n                data, uid=uid, **kwargs)\n\n        method_map = {\n            'GET': get,\n            'PUT': put,\n            'POST': post,\n            'PATCH': patch,\n            'DELETE': delete\n        }\n\n        setattr(\n            self, method_name,\n            types.MethodType(method_map[method_type], self)\n        )", "response": "Assign a new method to the current class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nappending a result row and check its length.", "response": "def append(self, row):\n        \"\"\"Append a result row and check its length.\n\n        >>> x = Results(['title', 'type'])\n        >>> x.append(('Konosuba', 'TV'))\n        >>> x\n        Results(['title', 'type'], [('Konosuba', 'TV')])\n\n        >>> x.append(('Konosuba',))\n        Traceback (most recent call last):\n            ...\n        ValueError: Wrong result row length\n\n        \"\"\"\n        row = tuple(row)\n        if len(row) != self.table_width:\n            raise ValueError('Wrong result row length')\n        self.results.append(row)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print(self):\n        print(tabulate(\n            ((i, *row) for i, row in enumerate(self.results, 1)),\n            headers=self.headers,\n        ))", "response": "Print results table.\n\n        >>> Results(['title'], [('Konosuba',), ('Oreimo',)]).print()\n          #  title\n        ---  --------\n          1  Konosuba\n          2  Oreimo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef novelty(song, k=64, wlen_ms=100, start=0, duration=None, nchangepoints=5, feature=\"rms\"):\n\n    if feature != \"rms\" and feature != \"mfcc\":\n        raise ValueError, \"novelty currently only supports 'rms' and 'mfcc' features\"\n\n    if feature == \"rms\":\n        frames = song.all_as_mono()\n\n        wlen_samples = int(wlen_ms * song.samplerate / 1000)\n\n        if duration is None:\n            frames = frames[start * song.samplerate:]\n        else:\n            frames = frames[start * song.samplerate:(start + duration) *\n                 song.samplerate]\n                 \n        # Compute energies\n        hamming = np.hamming(wlen_samples)\n        nwindows = int(2 * song.duration / wlen_samples - 1)\n        energies = np.empty(nwindows)\n        for i in range(nwindows):\n            energies[i] = RMS_energy(\n                hamming *\n                frames[i * wlen_samples / 2:\n                       i * wlen_samples / 2 + wlen_samples]\n            )\n\n        energies_list = [[x] for x in energies]\n    elif feature == \"mfcc\":\n        analysis = song.analysis\n        energies_list = np.array(analysis[\"timbres\"])\n    \n    # Compute similarities\n    S_matrix = 1 - scipy.spatial.distance.squareform(\n        scipy.spatial.distance.pdist(energies_list, 'euclidean'))\n                    \n    # smooth the C matrix with a gaussian taper\n    C_matrix = np.kron(np.eye(2), np.ones((k,k))) -\\\n               np.kron([[0, 1], [1, 0]], np.ones((k,k)))\n    g = scipy.signal.gaussian(2*k, k)\n    C_matrix = np.multiply(C_matrix, np.multiply.outer(g.T, g))\n    \n    # Created checkerboard kernel\n    \n    N_vec = np.zeros(np.shape(S_matrix)[0])\n    for i in xrange(k, len(N_vec) - k):\n        S_part = S_matrix[i - k:i + k, i - k:i + k]\n        N_vec[i] = np.sum(np.multiply(S_part, C_matrix))\n        \n    # Computed checkerboard response\n\n    peaks = naive_peaks(N_vec, k=k / 2 + 1)\n    out_peaks = []\n    \n    if feature == \"rms\":\n        # ensure that the points we return are more exciting\n        # after the change point than before the change point\n        for p in peaks:\n            frame = p[0]\n            if frame > k:\n                left_frames = frames[int((frame - k) * wlen_samples / 2):\n                                     int(frame * wlen_samples / 2)]\n                right_frames = frames[int(frame * wlen_samples / 2):\n                                      int((frame + k) * wlen_samples / 2)]\n                if RMS_energy(left_frames) <\\\n                   RMS_energy(right_frames):\n                   out_peaks.append(p)\n\n        out_peaks = [(x[0] * wlen_ms / 2000.0, x[1]) for x in out_peaks]\n        for i, p in enumerate(out_peaks):\n            if i == nchangepoints:\n                break\n        \n        return [x[0] for x in out_peaks[:nchangepoints]]\n\n    elif feature == \"mfcc\":\n        beats = analysis[\"beats\"]\n        return [beats[int(b[0])] for b in peaks[:nchangepoints]]", "response": "Return points of high novelty in a song\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smooth_hanning(x, size=11):\n\n    if x.ndim != 1:\n        raise ValueError, \"smooth_hanning only accepts 1-D arrays.\"\n    if x.size < size:\n        raise ValueError, \"Input vector needs to be bigger than window size.\"\n    if size < 3:\n        return x\n\n    s = np.r_[x[size - 1:0:-1], x, x[-1:-size:-1]]\n    w = np.hanning(size)\n    y = np.convolve(w / w.sum(), s, mode='valid')\n    return y", "response": "smooth a 1D array using a hanning window with requested size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a ScalarCoefs object or a VectorCoeffs object where each of the columns nmax and mmax are set to 0.", "response": "def zeros_coefs(nmax, mmax, coef_type=scalar):\r\n    \"\"\"Returns a ScalarCoefs object or a VectorCoeffs object where each of the \r\n    coefficients is set to 0. The structure is such that *nmax* is th largest \r\n    *n* can be in c[n, m], and *mmax* is the largest *m* can be for any *n*.\r\n    (See *ScalarCoefs* and *VectorCoefs* for details.)\r\n    \r\n\r\n    Examples::\r\n        \r\n        >>> c = spherepy.zeros_coefs(5, 3, coef_type = spherepy.scalar)\r\n        >>> c = spherepy.zeros_coefs(5, 3) # same as above\r\n        >>> vc = spherepy.zeros_coefs(5, 3, coef_type = spherepy.vector)\r\n\r\n    Args:\r\n          nmax (int): Largest *n* value in the set of modes.\r\n\r\n          mmax (int): Largest abs(*m*) value in the set of modes.\r\n\r\n          coef_type (int, optional): Set to 0 for scalar, and 1 for vector.\r\n          The default option is scalar. If you would like to return a set of \r\n          vector spherical hamonic coefficients, the preferred way to do so \r\n          is vc = spherepy.zeros_coefs( 10, 12, coef_type = spherepy.vector).\r\n\r\n    Returns:\r\n      coefs: Returns a ScalarCoefs object if coef_type is either blank or\r\n      set to 0. Returns a VectorCoefs object if coef_type = 1.\r\n\r\n    Raises:\r\n      TypeError: If coef_type is anything but 0 or 1.\r\n\r\n    \"\"\"\r\n\r\n    if(mmax > nmax):\r\n        raise ValueError(err_msg['nmax_g_mmax'])\r\n\r\n    if(coef_type == scalar):\r\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1)\r\n        vec = np.zeros(L, dtype=np.complex128)\r\n        return  ScalarCoefs(vec, nmax, mmax)\r\n    elif(coef_type == vector):\r\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1)\r\n        vec1 = np.zeros(L, dtype=np.complex128)\r\n        vec2 = np.zeros(L, dtype=np.complex128)\r\n        return  VectorCoefs(vec1, vec2, nmax, mmax)\r\n    else:\r\n        raise TypeError(err_msg['ukn_coef_t'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef random_coefs(nmax, mmax, mu=0.0, sigma=1.0, coef_type=scalar):\r\n\r\n    if(mmax > nmax):\r\n        raise ValueError(err_msg['nmax_g_mmax'])\r\n\r\n    if(coef_type == scalar):\r\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1)\r\n        vec = np.random.normal(mu, sigma, L) + \\\r\n              1j * np.random.normal(mu, sigma, L)\r\n        return  ScalarCoefs(vec, nmax, mmax)\r\n    elif(coef_type == vector):\r\n        L = (nmax + 1) + mmax * (2 * nmax - mmax + 1)\r\n        vec1 = np.random.normal(mu, sigma, L) + \\\r\n              1j * np.random.normal(mu, sigma, L)\r\n        vec1[0] = 0\r\n        vec2 = np.random.normal(mu, sigma, L) + \\\r\n              1j * np.random.normal(mu, sigma, L)\r\n        vec2[0] = 0\r\n        return  VectorCoefs(vec1, vec2, nmax, mmax)\r\n    else:\r\n        raise TypeError(err_msg['ukn_coef_t'])", "response": "Returns a ScalarCoefs object or VectorCoeffs object where each of the terms in nmax and mmax are random variables with mean 0 and standardardinal deviation 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef zeros_patt_uniform(nrows, ncols, patt_type=scalar):\r\n    \r\n    if np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n\r\n    if(patt_type == scalar):\r\n        cdata = np.zeros((2 * nrows - 2, ncols), dtype=np.complex128)\r\n        return ScalarPatternUniform(cdata, doublesphere=True)\r\n\r\n    elif(patt_type == vector):\r\n        tcdata = np.zeros((2 * nrows - 2, ncols), dtype=np.complex128)\r\n        pcdata = np.zeros((2 * nrows - 2, ncols), dtype=np.complex128)\r\n        return TransversePatternUniform(tcdata, pcdata, doublesphere=True)\r\n\r\n    else:\r\n        raise TypeError(err_msg['ukn_patt_t'])", "response": "Returns a new object with zeros set to 0."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a ScalarPatternUniform object or VectorPatternUniform object with each of the elements is set to a normal random variable with zero mean and unit standard deviation.", "response": "def random_patt_uniform(nrows, ncols, patt_type=scalar):\r\n    \"\"\"Returns a ScalarPatternUniform object or a VectorPatternUniform object\r\n    where each of the elements is set to a normal random variable with zero \r\n    mean and unit standard deviation. *nrows* is the number of rows in \r\n    the pattern, which corresponds to the theta axis. *ncols* must be even\r\n    and is the number of columns in the pattern and corresponds to the phi \r\n    axis.\r\n    (See *ScalarPatternUniform* and *VectorPatternUniform* for details.)\r\n    \r\n    Examples::\r\n        \r\n        >>> f = spherepy.random_patt_uniform(6, 8, coef_type = spherepy.scalar)\r\n        >>> f = spherepy.random_patt_uniform(6, 8) # same as above\r\n        >>> F = spherepy.random_patt_uniform(6, 8, coef_type = spherepy.vector)\r\n\r\n    Args:\r\n          nrows (int): Number of rows corresponding to the theta axis.\r\n\r\n          ncols (int): Number of columns corresponding to the phi axis. To get \r\n          the speed and accuracy I need, this value **must** be even. \r\n\r\n          coef_type (int, optional): Set to 0 for scalar, and 1 for vector.\r\n          The default option is scalar. \r\n\r\n    Returns:\r\n      coefs: Returns a ScalarPatternUniform object if coef_type is either \r\n      blank or set to 0. Returns a VectorPatternUniform object if \r\n      coef_type = 1.\r\n\r\n    Raises:\r\n      ValueError: If ncols is not even.\r\n\r\n      TypeError: If coef_type is anything but 0 or 1.\r\n\r\n    \"\"\"\r\n\r\n    if np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n\r\n    if(patt_type == scalar):\r\n        vec = np.random.normal(0.0, 1.0, nrows * ncols) + \\\r\n              1j * np.random.normal(0.0, 1.0, nrows * ncols)\r\n        return ScalarPatternUniform(vec.reshape((nrows, ncols)),\r\n                                    doublesphere=False)\r\n\r\n    elif(patt_type == vector):\r\n        vec1 = np.random.normal(0.0, 1.0, nrows * ncols) + \\\r\n              1j * np.random.normal(0.0, 1.0, nrows * ncols)\r\n        vec2 = np.random.normal(0.0, 1.0, nrows * ncols) + \\\r\n              1j * np.random.normal(0.0, 1.0, nrows * ncols)\r\n        return TransversePatternUniform(vec1.reshape((nrows, ncols)),\r\n                                    vec2.reshape((nrows, ncols)),\r\n                                    doublesphere=False)\r\n\r\n    else:\r\n        raise TypeError(err_msg['ukn_patt_t'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef double_sphere(cdata, sym):\r\n    \r\n    nrows = cdata.shape[0]\r\n    ncols = cdata.shape[1]\r\n\r\n    ddata = np.zeros([nrows, ncols], dtype=np.complex128)\r\n\r\n    for n in xrange(0, nrows):\r\n        for m in xrange(0, ncols):\r\n            s = sym * cdata[np.mod(nrows - n, nrows),\r\n                          np.mod(int(np.floor(ncols / 2)) + m, ncols)]\r\n            t = cdata[n, m]\r\n\r\n            if s * t == 0:\r\n                ddata[n, m] = s + t\r\n            else:\r\n                ddata[n, m] = (s + t) / 2\r\n\r\n    return ddata", "response": "Ensures that the data within cdata has double sphere symmetry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty_coefs(c):\r\n\r\n    cfit = c[0:2, :]\r\n    cvec = cfit._vec\r\n\r\n    sa = [_tiny_rep(val) for val in cvec]\r\n\r\n    while len(sa) < 9:\r\n        sa.append(\"\")\r\n\r\n    sa = [sa[n].center(13) for n in range(0, 9)]\r\n\r\n    print(pretty_display_string.format(sa[0], sa[1], sa[2],\r\n                                       sa[3], sa[4], sa[5],\r\n                                       sa[6], sa[7], sa[8]))", "response": "Prints out the coefficients of a ScalarCoeffs object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spht(ssphere, nmax=None, mmax=None):\r\n\r\n    if nmax == None:\r\n        nmax = ssphere.nrows - 2 \r\n        mmax = int(ssphere.ncols / 2) - 1\r\n    elif mmax == None:\r\n        mmax = nmax\r\n\r\n    if mmax > nmax:\r\n        raise ValueError(err_msg['nmax_g_mmax'])\r\n\r\n    if nmax >= ssphere.nrows - 1:\r\n        raise ValueError(err_msg['nmax_too_lrg'])\r\n\r\n    if mmax >= ssphere.ncols / 2:\r\n        raise ValueError(err_msg['mmax_too_lrg'])\r\n\r\n    dnrows = ssphere._dsphere.shape[0]\r\n    ncols = ssphere._dsphere.shape[1]\r\n\r\n    if np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n\r\n    fdata = np.fft.fft2(ssphere._dsphere) / (dnrows * ncols)\r\n    ops.fix_even_row_data_fc(fdata)\r\n    \r\n    fdata_extended = np.zeros([dnrows + 2, ncols], dtype=np.complex128)\r\n\r\n    ops.pad_rows_fdata(fdata, fdata_extended)\r\n\r\n    ops.sin_fc(fdata_extended)\r\n    \r\n    N = nmax + 1;\r\n    NC = N + mmax * (2 * N - mmax - 1);\r\n    sc = np.zeros(NC, dtype=np.complex128)\r\n    # check if we are using c extended versions of the code or not\r\n    if use_cext: \r\n        csphi.fc_to_sc(fdata_extended, sc, nmax, mmax)\r\n    else:   \r\n        sc = pysphi.fc_to_sc(fdata_extended, nmax, mmax)\r\n                                \r\n    return ScalarCoefs(sc, nmax, mmax)", "response": "Returns a new object containing the spherical harmonics of a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vspht(vsphere, nmax=None, mmax=None):\r\n    \r\n    if nmax == None:\r\n        nmax = vsphere.nrows - 2 \r\n        mmax = int(vsphere.ncols / 2) - 1\r\n    elif mmax == None:\r\n        mmax = nmax\r\n\r\n    if mmax > nmax:\r\n        raise ValueError(err_msg['nmax_g_mmax'])\r\n\r\n    if nmax >= vsphere.nrows - 1:\r\n        raise ValueError(err_msg['nmax_too_lrg'])\r\n\r\n    if mmax >= vsphere.ncols / 2:\r\n        raise ValueError(err_msg['mmax_too_lrg'])\r\n\r\n    dnrows = vsphere._tdsphere.shape[0]\r\n    ncols = vsphere._tdsphere.shape[1]\r\n\r\n    if np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n        \r\n    ft = np.fft.fft2(vsphere._tdsphere) / (dnrows * ncols)\r\n    ops.fix_even_row_data_fc(ft)\r\n    \r\n    ft_extended = np.zeros([dnrows + 2, ncols], dtype=np.complex128)\r\n    ops.pad_rows_fdata(ft, ft_extended)\r\n    \r\n    pt = np.fft.fft2(vsphere._pdsphere) / (dnrows * ncols)\r\n    ops.fix_even_row_data_fc(pt)\r\n    \r\n    pt_extended = np.zeros([dnrows + 2, ncols], dtype=np.complex128)\r\n    ops.pad_rows_fdata(pt, pt_extended)\r\n    \r\n    ftmp = np.copy(ft_extended)\r\n    ptmp = np.copy(pt_extended)\r\n    Lf1 = ops.sinLdot_fc(ft_extended, pt_extended)\r\n    Lf2 = ops.sinLdot_fc(-1j * ptmp, 1j * ftmp)\r\n    \r\n    # check if we are using c extended versions of the code or not\r\n    if use_cext: \r\n        N = nmax + 1;\r\n        NC = N + mmax * (2 * N - mmax - 1);\r\n        sc1 = np.zeros(NC, dtype=np.complex128)\r\n        sc2 = np.zeros(NC, dtype=np.complex128)\r\n        csphi.fc_to_sc(Lf1, sc1, nmax, mmax)\r\n        csphi.fc_to_sc(Lf2, sc2, nmax, mmax)\r\n    else:   \r\n        sc1 = pysphi.fc_to_sc(Lf1, nmax, mmax)\r\n        sc2 = pysphi.fc_to_sc(Lf2, nmax, mmax)\r\n\r\n    vcoefs = VectorCoefs(sc1, sc2, nmax, mmax)\r\n\r\n    nvec = np.zeros(nmax + 1, dtype=np.complex128)\r\n\r\n    for n in xrange(1, nmax + 1):\r\n        nvec[n] = 1.0 / np.sqrt(n * (n + 1.0))\r\n\r\n    vcoefs.scoef1.window(nvec)\r\n    vcoefs.scoef2.window(nvec)\r\n        \r\n    return vcoefs", "response": "Returns a VectorCoefs object containt the vector spherical harmonic coefficients of the VectorPatternUniform object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new object that is a set of scalar spherical harmonics that are not yet in use.", "response": "def spht_slow(ssphere, nmax, mmax):\r\n    \"\"\"(PURE PYTHON) Transforms ScalarPatternUniform object *ssphere* \r\n    into a set of scalar spherical harmonics stored in ScalarCoefs.\r\n\r\n    Example::\r\n\r\n        >>> p = spherepy.random_patt_uniform(6, 8)\r\n        >>> c = spherepy.spht(p)\r\n        >>> spherepy.pretty_coefs(c)\r\n\r\n    Args:\r\n      ssphere (ScalarPatternUniform): The pattern to be transformed.\r\n\r\n      nmax (int, optional): The maximum number of *n* values required. If a \r\n      value isn't passed, *nmax* is the number of rows in ssphere minus one.\r\n\r\n      mmax (int, optional): The maximum number of *m* values required. If a \r\n      value isn't passed, *mmax* is half the number of columns in ssphere\r\n      minus one.\r\n\r\n    Returns:\r\n      ScalarCoefs: The object containing the coefficients of the scalar\r\n      spherical harmonic transform.\r\n\r\n\r\n    Raises:\r\n      ValueError: If *nmax* and *mmax* are too large or *mmax* > *nmax*.\r\n\r\n    \"\"\"\r\n\r\n    if mmax > nmax:\r\n        raise ValueError(err_msg['nmax_g_mmax'])\r\n\r\n    nrows = ssphere._dsphere.shape[0]\r\n    ncols = ssphere._dsphere.shape[1]\r\n\r\n    if np.mod(nrows, 2) == 1 or np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n\r\n    fdata = np.fft.fft2(ssphere._dsphere) / (nrows * ncols)\r\n    ops.fix_even_row_data_fc(fdata)\r\n    \r\n    fdata_extended = np.zeros([nrows + 2, ncols], dtype=np.complex128)\r\n\r\n    ops.pad_rows_fdata(fdata, fdata_extended)\r\n\r\n    ops.sin_fc(fdata_extended)\r\n    \r\n    sc = pysphi.fc_to_sc(fdata_extended, nmax, mmax)\r\n                                \r\n    return ScalarCoefs(sc, nmax, mmax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new pattern that is a copy of the given scalars.", "response": "def ispht(scoefs, nrows=None, ncols=None):\r\n    \"\"\"Transforms ScalarCoefs object *scoefs* into a scalar pattern \r\n    ScalarPatternUniform.\r\n\r\n    Example::\r\n\r\n        >>> c = spherepy.random_coefs(3,3)\r\n        >>> p = spherepy.ispht(c)\r\n        >>> print(p)\r\n\r\n    Args:\r\n      scoefs (ScalarCoefs): The coefficients to be transformed to pattern\r\n      space.\r\n\r\n      nrows (int): The number of rows desired in the pattern.\r\n\r\n      ncols (int): The number of columns desired in the pattern. This must be \r\n      an even number.\r\n\r\n    Returns:\r\n      ScalarPatternUniform: This is the pattern. It contains a NumPy array that\r\n      can be viewed with *patt.cdata*.\r\n\r\n\r\n    Raises:\r\n      ValueError: Is raised if *ncols* isn't even.\r\n\r\n      ValueError: Is raised if *nrows* < *nmax* + 2 or *ncols* < 2 * *mmax* + 2.\r\n\r\n    \"\"\"\r\n\r\n    if nrows == None:\r\n        nrows = scoefs.nmax + 2 \r\n\r\n    if ncols == None:\r\n        ncols = 2 * scoefs.mmax + 2\r\n\r\n    if nrows <= scoefs.nmax:\r\n        raise ValueError(err_msg['inverse_terr'])\r\n\r\n    if ncols < 2 * scoefs.mmax + 2:\r\n        raise ValueError(err_msg['inverse_terr'])\r\n\r\n    dnrows = int(2 * nrows - 2)\r\n\r\n    if np.mod(ncols, 2) == 1:\r\n        raise ValueError(err_msg['ncols_even'])\r\n\r\n    if use_cext: \r\n        fdata = np.zeros([dnrows, ncols], dtype=np.complex128)\r\n        csphi.sc_to_fc(fdata, scoefs._vec, scoefs._nmax, scoefs._mmax)\r\n    else:   \r\n        fdata = pysphi.sc_to_fc(scoefs._vec,\r\n                            scoefs._nmax,\r\n                            scoefs._mmax,\r\n                            dnrows, ncols)\r\n    \r\n    ds = np.fft.ifft2(fdata) * dnrows * ncols\r\n\r\n    return ScalarPatternUniform(ds, doublesphere=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new array of n rows and ncols where the first n rows and second n columns are the same length.", "response": "def sph_harmonic_tp(nrows, ncols, n, m):\r\n    \"\"\"Produces Ynm(theta,phi)\r\n\r\n        theta runs from 0 to pi and has 'nrows' points.\r\n\r\n        phi runs from 0 to 2*pi - 2*pi/ncols and has 'ncols' points.\r\n    \r\n    \"\"\"\r\n    nuvec = pysphi.ynunm(n, m, n + 1)\r\n    num = nuvec[1:] * (-1) ** m\r\n    num = num[::-1]\r\n    yvec = np.concatenate([num, nuvec])\r\n    \r\n    theta = np.linspace(0.0, np.pi, nrows)\r\n    phi = np.linspace(0.0, 2.0 * np.pi - 2.0 * np.pi / ncols)\r\n    nu = np.array(range(-n, n + 1), dtype=np.complex128)\r\n    \r\n    out = np.zeros([nrows, ncols], dtype=np.complex128)\r\n\r\n    for nn in xrange(0, nrows):\r\n        exp_vec = np.exp(1j * nu * theta[nn])\r\n        for mm in xrange(0, ncols):          \r\n            vl = np.sum(yvec * exp_vec)\r\n            out[nn, mm] = 1j ** m * np.exp(1j * m * phi[mm]) * vl\r\n\r\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the size of the object in bytes.", "response": "def size(self):\r\n        \"\"\"Total number of coefficients in the ScalarCoefs structure.\r\n\r\n        Example::\r\n\r\n            >>> sz  = c.size\r\n            >>> N = c.nmax + 1\r\n            >>> L = N+ c.mmax * (2 * N - c.mmax - 1);\r\n            >>> assert sz == L\r\n        \"\"\"\r\n        N = self.nmax + 1;\r\n        NC = N + self.mmax * (2 * N - self.mmax - 1);\r\n        assert NC == len(self._vec)\r\n        return NC"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\r\n        vec = np.copy(self._vec)\r\n        return ScalarCoefs(vec, self.nmax, self.mmax)", "response": "Make a deep copy of this object. Example ::\r\n            >>>"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a window to the coefficients defined by vec.", "response": "def window(self, vec):\r\n        \"\"\"Apply a window to the coefficients defined by *vec*. *vec* must\r\n        have length *nmax* + 1.  This is good way to filter the pattern by\r\n        windowing in the coefficient domain.\r\n\r\n        Example::\r\n\r\n            >>> vec = numpy.linspace(0, 1, c.nmax + 1)\r\n            >>> c.window(vec)\r\n\r\n        Args:\r\n          vec (numpy.array): Vector of values to apply in the n direction of\r\n          the data. Has length *nmax* + 1.\r\n\r\n        Returns:\r\n          Nothing, applies the window to the data in place.\r\n\r\n        \"\"\"\r\n\r\n        slce = slice(None, None, None)\r\n        \r\n        self.__setitem__((slce, 0), self.__getitem__((slce, 0)) * vec)  \r\n        for m in xrange(1, self.mmax + 1):\r\n            self.__setitem__((slce, -m), self.__getitem__((slce, -m)) * vec[m:])\r\n            self.__setitem__((slce, m), self.__getitem__((slce, m)) * vec[m:])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef angular_power_spectrum(self):\r\n\r\n        # Added this routine as a result of my discussions with Ajinkya Nene\t \r\n        #https://github.com/anene\r\n        list_of_modes = self._reshape_m_vecs() \r\n        Nmodes = len(list_of_modes)\r\n\r\n        angular_power = np.zeros( Nmodes, dtype = np.double)\r\n\r\n        for n in range(0, Nmodes):\r\n            mode = np.array( list_of_modes[n], dtype = np.complex128 )\r\n            angular_power[n] = np.sum( np.abs(mode) ** 2 )\r\n            \r\n        return angular_power", "response": "Returns the angular power spectrum for the set of coefficients."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a 2D array that has nmax + 1 rows and 2 * mmax + 1 columns and provides a representation for the coefficients that makes plotting easier", "response": "def _array_2d_repr(self):\r\n        \"\"\"creates a 2D array that has nmax + 1 rows and 2*mmax + 1 columns\r\n        and provides a representation for the coefficients that makes \r\n        plotting easier\"\"\"\r\n\r\n        sc_array = np.zeros((self.nmax + 1, 2 * self.mmax + 1),\r\n                            dtype=np.complex128)\r\n\r\n        lst = self._reshape_n_vecs()\r\n        sc_array[0:self.nmax + 1, self.mmax] = lst[0]\r\n        for m in xrange(1, self.mmax + 1):\r\n            sc_array[m:self.nmax + 1, self.mmax - m] = lst[2 * m - 1]\r\n            sc_array[m:self.nmax + 1, self.mmax + m] = lst[2 * m]\r\n\r\n        return sc_array"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reshape_n_vecs(self):\r\n\r\n        lst = []\r\n        sl = slice(None, None, None)\r\n        lst.append(self.__getitem__((sl, 0)))\r\n        for m in xrange(1, self.mmax + 1):\r\n            lst.append(self.__getitem__((sl, -m)))\r\n            lst.append(self.__getitem__((sl, m)))\r\n        return lst", "response": "return list of arrays each array represents a different m mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of arrays each array represents a different n mode", "response": "def _reshape_m_vecs(self):\r\n        \"\"\"return list of arrays, each array represents a different n mode\"\"\"\r\n        \r\n        lst = []\r\n        for n in xrange(0, self.nmax + 1):\r\n            mlst = []\r\n            if n <= self.mmax:\r\n                nn = n\r\n            else:\r\n                nn = self.mmax            \r\n            for m in xrange(-nn, nn + 1):\r\n                mlst.append(self.__getitem__((n, m)))\r\n            lst.append(mlst)\r\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _scalar_coef_op_left(func):\r\n        @wraps(func)\r\n        def verif(self, scoef):\r\n            if isinstance(scoef, ScalarCoefs):\r\n                if len(self._vec) == len(scoef._vec):\r\n                    return ScalarCoefs(func(self, self._vec, scoef._vec),\r\n                                        self.nmax,\r\n                                        self.mmax)\r\n                else:\r\n                    raise ValueError(err_msg['SC_sz_msmtch'] % \\\r\n                                    (self.nmax, self.mmax,\r\n                                     scoef.nmax, scoef.mmax))\r\n        \r\n            elif isinstance(scoef, numbers.Number):\r\n                return ScalarCoefs(func(self, self._vec, scoef), self.nmax,\r\n                                   self.mmax)\r\n            else:\r\n                raise TypeError(err_msg['no_combi_SC'])\r\n        return verif", "response": "decorator for operator overloading when ScalarCoef is on the\r\n        left"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _scalar_coef_op_right(func):\r\n        @wraps(func)\r\n        def verif(self, scoef):\r\n            if isinstance(scoef, numbers.Number):\r\n                return ScalarCoefs(func(self, self._vec, scoef),\r\n                                   self.nmax, self.mmax)\r\n            else:\r\n                raise TypeError(err_msg['no_combi_SC'])\r\n        return verif", "response": "decorator for operator overloading when ScalarCoef is on the right"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a deep copy of this object. Example :: >>> c = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>> c2 = new VectorCoefs(); >>>", "response": "def copy(self):\r\n        \"\"\"Make a deep copy of this object.\r\n        \r\n        Example::\r\n\r\n            >>> c2 = c.copy()\r\n        \r\n        \"\"\"\r\n        vec1 = np.copy(self.scoef1._vec)\r\n        vec2 = np.copy(self.scoef2._vec)\r\n        return VectorCoefs(vec1, vec2, self.nmax, self.mmax)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _vector_coef_op_right(func):\r\n        @wraps(func)\r\n        def verif(self, vcoef):\r\n            if isinstance(vcoef, numbers.Number):\r\n                return VectorCoefs(func(self, self.scoef1._vec, vcoef),\r\n                                   func(self, self.scoef2._vec, vcoef),\r\n                                   self.nmax, self.mmax)\r\n            else:\r\n                raise TypeError(err_msg['no_combi_VC'])\r\n        return verif", "response": "decorator for operator overloading when VectorCoefs is on the right"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scalar_pattern_uniform_op_right(func):\r\n        @wraps(func)\r\n        def verif(self, patt):\r\n            if isinstance(patt, numbers.Number):\r\n                return ScalarPatternUniform(func(self, self._dsphere, patt),\r\n                                   doublesphere=True)\r\n            else:\r\n                raise TypeError(err_msg['no_combi_SP'])\r\n        return verif", "response": "Decorator for operator overloading when ScalarPatternUniform is on\r\n        the right."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef single_val(self):\r\n        \r\n        sv_t = self._sv(self._tdsphere)\r\n        sv_p = self._sv(self._tdsphere)\r\n        \r\n        return (sv_t, sv_p)", "response": "return relative error of worst point that might make the data none symmetric."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _vector_pattern_uniform_op_left(func):\r\n        @wraps(func)\r\n        def verif(self, patt):\r\n            if isinstance(patt, TransversePatternUniform):\r\n                if self._tdsphere.shape == patt._tdsphere.shape:\r\n                    return TransversePatternUniform(func(self, self._tdsphere,\r\n                                                     patt._tdsphere),\r\n                                                func(self, self._pdsphere,\r\n                                                     patt._pdsphere),\r\n                                                doublesphere=True)\r\n                else:\r\n                    raise ValueError(err_msg['VP_sz_msmtch'] % \\\r\n                                            (self.nrows, self.ncols,\r\n                                            patt.nrows, patt.ncols))\r\n        \r\n            elif isinstance(patt, numbers.Number):\r\n                return TransversePatternUniform(func(self, self._tdsphere, patt),\r\n                                            func(self, self._pdsphere, patt),\r\n                                            doublesphere=True)\r\n            else:\r\n                raise TypeError(err_msg['no_combi_VP'])\r\n        return verif", "response": "decorator for operator overloading when VectorPatternUniform is on \r\n topic the left"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def async_set_port_poe_mode(self, port_idx, mode):\n        no_existing_config = True\n        for port_override in self.port_overrides:\n            if port_idx == port_override['port_idx']:\n                port_override['poe_mode'] = mode\n                no_existing_config = False\n                break\n\n        if no_existing_config:\n            self.port_overrides.append({\n                'port_idx': port_idx,\n                'portconf_id': self.ports[port_idx].portconf_id,\n                'poe_mode': mode\n            })\n\n        url = 's/{site}/rest/device/' + self.id\n        data = {'port_overrides': self.port_overrides}\n\n        await self._request('put', url, json=data)", "response": "Set port poe mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the available remotes.", "response": "def list_remotes(device=None, address=None):\n    \"\"\"\n    List the available remotes.\n\n    All parameters are passed to irsend. See the man page for irsend\n    for details about their usage.\n\n    Parameters\n    ----------\n    device: str\n    address: str\n\n    Returns\n    -------\n    [str]\n\n    Notes\n    -----\n    No attempt is made to catch or handle errors. See the documentation\n    for subprocess.check_output to see the types of exceptions it may raise.\n\n    \"\"\"\n    output = _call([\"list\", \"\", \"\"], None, device, address)\n    remotes = [l.split()[-1] for l in output.splitlines() if l]\n    return remotes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_codes(remote, device=None, address=None):\n    output = _call([\"list\", remote, \"\"], None, device, address)\n    codes = [l.split()[-1] for l in output.splitlines() if l]\n    return codes", "response": "List the codes for a given remote."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_once(remote, codes, count=None, device=None, address=None):\n    args = ['send_once', remote] + codes\n    _call(args, count, device, address)", "response": "Send a single message to a single node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a single code to a remote node.", "response": "def send_start(remote, code, device=None, address=None):\n    \"\"\"\n    All parameters are passed to irsend. See the man page for irsend\n    for details about their usage.\n\n    Parameters\n    ----------\n    remote: str\n    code: str\n    device: str\n    address: str\n\n    Notes\n    -----\n    No attempt is made to catch or handle errors. See the documentation\n    for subprocess.check_output to see the types of exceptions it may raise.\n\n    \"\"\"\n    args = ['send_start', remote, code]\n    _call(args, device, address)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_stop(remote, code, device=None, address=None):\n    args = ['send_stop', remote, code]\n    _call(args, None, device, address)", "response": "Send a stop message to the specified remote device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_transmitters(transmitters, device=None, address=None):\n    args = ['set_transmitters'] + [str(i) for i in transmitters]\n    _call(args, None, device, address)", "response": "Set transmitters to the specified transmitters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_updates():\n    count, packages = fetch()\n    message = \"No news is good news !\"\n    if count > 0:\n        message = (\"{0} software updates are available\\n\".format(count))\n    return [message, count, packages]", "response": "Check and display upgraded packages"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsub function for init", "response": "def _init_check_upodates():\n    \"\"\"Sub function for init\n    \"\"\"\n    message, count, packages = check_updates()\n    if count > 0:\n        print(message)\n        for pkg in packages:\n            print(\"{0}\".format(pkg))\n    else:\n        print(message)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init():\n    su()\n    args = sys.argv\n    args.pop(0)\n    cmd = \"{0}sun_daemon\".format(bin_path)\n    if len(args) == 1:\n        if args[0] == \"start\":\n            print(\"Starting SUN daemon:  {0} &\".format(cmd))\n            subprocess.call(\"{0} &\".format(cmd), shell=True)\n        elif args[0] == \"stop\":\n            print(\"Stopping SUN daemon:  {0}\".format(cmd))\n            subprocess.call(\"killall sun_daemon\", shell=True)\n        elif args[0] == \"restart\":\n            print(\"Stopping SUN daemon:  {0}\".format(cmd))\n            subprocess.call(\"killall sun_daemon\", shell=True)\n            print(\"Starting SUN daemon:  {0} &\".format(cmd))\n            subprocess.call(\"{0} &\".format(cmd), shell=True)\n        elif args[0] == \"check\":\n            _init_check_upodates()\n        elif args[0] == \"status\":\n            print(daemon_status())\n        elif args[0] == \"help\":\n            usage()\n        elif args[0] == \"info\":\n            print(os_info())\n        else:\n            print(\"try: 'sun help'\")\n    elif len(args) == 2 and args[0] == \"start\" and args[1] == \"--gtk\":\n        subprocess.call(\"{0} {1}\".format(cmd, \"start--gtk\"), shell=True)\n    else:\n        print(\"try: 'sun help'\")", "response": "Initialize the current sun_daemon daemon"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts daemon when gtk loaded is not running", "response": "def daemon_start(self):\n        \"\"\"Start daemon when gtk loaded\n        \"\"\"\n        if daemon_status() == \"SUN not running\":\n            subprocess.call(\"{0} &\".format(self.cmd), shell=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a submenu for the current calendar", "response": "def sub_menu(self):\n        \"\"\"Create daemon submenu\n        \"\"\"\n        submenu = gtk.Menu()\n        self.start = gtk.ImageMenuItem(\"Start\")\n        self.stop = gtk.ImageMenuItem(\"Stop\")\n        self.restart = gtk.ImageMenuItem(\"Restart\")\n        self.status = gtk.ImageMenuItem(\"Status\")\n\n        self.start.show()\n        self.stop.show()\n        self.restart.show()\n        self.status.show()\n\n        img_Start = gtk.image_new_from_stock(gtk.STOCK_MEDIA_PLAY,\n                                             gtk.ICON_SIZE_MENU)\n        img_Start.show()\n        self.start.set_image(img_Start)\n\n        img_Stop = gtk.image_new_from_stock(gtk.STOCK_STOP,\n                                            gtk.ICON_SIZE_MENU)\n        img_Stop.show()\n        self.stop.set_image(img_Stop)\n\n        img_Restart = gtk.image_new_from_stock(gtk.STOCK_REFRESH,\n                                               gtk.ICON_SIZE_MENU)\n        img_Restart.show()\n        self.restart.set_image(img_Restart)\n\n        img_Status = gtk.image_new_from_stock(gtk.STOCK_DIALOG_QUESTION,\n                                              gtk.ICON_SIZE_MENU)\n        img_Status.show()\n        self.status.set_image(img_Status)\n\n        submenu.append(self.start)\n        submenu.append(self.stop)\n        submenu.append(self.restart)\n        submenu.append(self.status)\n\n        self.daemon = gtk.ImageMenuItem(\"Daemon\")\n        self.img_daemon = gtk.image_new_from_stock(self.daemon_STOCK,\n                                                   gtk.ICON_SIZE_MENU)\n        self.img_daemon.show()\n        self.daemon.set_submenu(submenu)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef menu(self, event_button, event_time, data=None):\n        self.sub_menu()\n        menu = gtk.Menu()\n        menu.append(self.daemon)\n\n        separator = gtk.SeparatorMenuItem()\n\n        menu_Check = gtk.ImageMenuItem(\"Check updates\")\n        img_Check = gtk.image_new_from_stock(gtk.STOCK_OK,\n                                             gtk.ICON_SIZE_MENU)\n        img_Check.show()\n\n        menu_Info = gtk.ImageMenuItem(\"OS Info\")\n        img_Info = gtk.image_new_from_stock(gtk.STOCK_INFO,\n                                            gtk.ICON_SIZE_MENU)\n        img_Info.show()\n\n        menu_About = gtk.ImageMenuItem(\"About\")\n        img_About = gtk.image_new_from_stock(gtk.STOCK_ABOUT,\n                                             gtk.ICON_SIZE_MENU)\n        img_About.show()\n\n        self.daemon.set_image(self.img_daemon)\n        menu.append(self.daemon)\n        self.daemon.show()\n\n        menu_Quit = gtk.ImageMenuItem(\"Quit\")\n        img_Quit = gtk.image_new_from_stock(gtk.STOCK_QUIT, gtk.ICON_SIZE_MENU)\n        img_Quit.show()\n\n        menu_Check.set_image(img_Check)\n        menu_Info.set_image(img_Info)\n        menu_About.set_image(img_About)\n        menu_Quit.set_image(img_Quit)\n\n        menu.append(menu_Check)\n        menu.append(menu_Info)\n        menu.append(separator)\n        menu.append(menu_About)\n        menu.append(menu_Quit)\n\n        separator.show()\n        menu_Check.show()\n        menu_Info.show()\n        menu_About.show()\n        menu_Quit.show()\n\n        menu_Check.connect_object(\"activate\", self._Check, \" \")\n        menu_Info.connect_object(\"activate\", self._Info, \"OS Info\")\n        menu_About.connect_object(\"activate\", self._About, \"SUN\")\n        self.start.connect_object(\"activate\", self._start, \"Start daemon   \")\n        self.stop.connect_object(\"activate\", self._stop, \"Stop daemon   \")\n        self.restart.connect_object(\"activate\", self._restart,\n                                    \"Restart daemon   \")\n        self.status.connect_object(\"activate\", self._status, daemon_status())\n        menu_Quit.connect_object(\"activate\", self._Quit, \"stop\")\n\n        menu.popup(None, None, None, event_button, event_time, data)", "response": "Create a menu with the specified event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to display messages to the user", "response": "def message(self, data):\n        \"\"\"Function to display messages to the user\n        \"\"\"\n        msg = gtk.MessageDialog(None, gtk.DIALOG_MODAL, gtk.MESSAGE_INFO,\n                                gtk.BUTTONS_CLOSE, data)\n        msg.set_resizable(1)\n        msg.set_title(self.dialog_title)\n        self.img.set_from_file(self.sun_icon)\n        msg.set_image(self.img)\n        msg.show_all()\n        msg.run()\n        msg.destroy()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a json response into an intent.", "response": "def parse(payload, candidate_classes):\n        \"\"\" Parse a json response into an intent.\n\n        :param payload: a JSON object representing an intent.\n        :param candidate_classes: a list of classes representing various\n                                  intents, each having their own `parse`\n                                  method to attempt parsing the JSON object\n                                  into the given intent class.\n        :return: An object version of the intent if one of the candidate\n                 classes managed to parse it, or None.\n        \"\"\"\n        for cls in candidate_classes:\n            intent = cls.parse(payload)\n            if intent:\n                return intent\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the parsed value of a slot. An intent has the form: { \"text\": \"brew me a cappuccino with 3 sugars tomorrow\", \"slots\": [ {\"value\": {\"slotName\": \"coffee_type\", \"value\": \"cappuccino\"}}, ... ] } This function extracts a slot value given its slot name, and parses it into a Python object if applicable (e.g. for dates). Slots can be of various forms, the simplest being just: {\"slotName\": \"coffee_sugar_amout\", \"value\": \"3\"} More complex examples are date times, where we distinguish between instant times, or intervals. Thus, a slot: { \"slotName\": \"weatherForecastStartDatetime\", \"value\": { \"kind\": \"InstantTime\", \"value\": { \"value\": \"2017-07-14 00:00:00 +00:00\", \"grain\": \"Day\", \"precision\": \"Exact\" } } } will be extracted as an `InstantTime` object, with datetime parsed and granularity set. Another example is a time interval: { \"slotName\": \"weatherForecastStartDatetime\", \"value\": { \"kind\": \"TimeInterval\", \"value\": { \"from\": \"2017-07-14 12:00:00 +00:00\", \"to\": \"2017-07-14 19:00:00 +00:00\" } }, } which will be extracted as a TimeInterval object. :param payload: the intent, in JSON format. :return: the parsed value, as described above.", "response": "def get_slot_value(payload, slot_name):\n        \"\"\" Return the parsed value of a slot. An intent has the form:\n\n            {\n                \"text\": \"brew me a cappuccino with 3 sugars tomorrow\",\n                \"slots\": [\n                    {\"value\": {\"slotName\": \"coffee_type\", \"value\": \"cappuccino\"}},\n                    ...\n                ]\n            }\n\n            This function extracts a slot value given its slot name, and parses\n            it into a Python object if applicable (e.g. for dates).\n\n            Slots can be of various forms, the simplest being just:\n\n            {\"slotName\": \"coffee_sugar_amout\", \"value\": \"3\"}\n\n            More complex examples are date times, where we distinguish between\n            instant times, or intervals. Thus, a slot:\n\n            {\n              \"slotName\": \"weatherForecastStartDatetime\",\n              \"value\": {\n                \"kind\": \"InstantTime\",\n                \"value\": {\n                  \"value\": \"2017-07-14 00:00:00 +00:00\",\n                  \"grain\": \"Day\",\n                  \"precision\": \"Exact\"\n                }\n              }\n            }\n\n            will be extracted as an `InstantTime` object, with datetime parsed\n            and granularity set.\n\n            Another example is a time interval:\n\n            {\n              \"slotName\": \"weatherForecastStartDatetime\",\n              \"value\": {\n                \"kind\": \"TimeInterval\",\n                \"value\": {\n                  \"from\": \"2017-07-14 12:00:00 +00:00\",\n                  \"to\": \"2017-07-14 19:00:00 +00:00\"\n                }\n              },\n            }\n\n            which will be extracted as a TimeInterval object.\n\n        :param payload: the intent, in JSON format.\n        :return: the parsed value, as described above.\n        \"\"\"\n\n        if not 'slots' in payload:\n            return []\n\n        slots = []\n        for candidate in payload['slots']:\n            if 'slotName' in candidate and candidate['slotName'] == slot_name:\n                slots.append(candidate)\n\n        result = []\n        for slot in slots:\n            kind = IntentParser.get_dict_value(slot, ['value', 'kind'])\n            if kind == \"InstantTime\":\n                result.append(IntentParser.parse_instant_time(slot))\n            elif kind == \"TimeInterval\":\n                result.append(IntentParser.parse_time_interval(slot))\n            else:\n                result.append(IntentParser.get_dict_value(slot, ['value', 'value', 'value']) \\\n                    or IntentParser.get_dict_value(slot, ['value', 'value']))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_instant_time(slot):\n        date = IntentParser.get_dict_value(slot, ['value', 'value'])\n        if not date:\n            return None\n        date = parse(date)\n        if not date:\n            return None\n        grain = InstantTime.parse_grain(\n            IntentParser.get_dict_value(slot,\n                                        ['value', 'grain']))\n        return InstantTime(date, grain)", "response": "Parse a slot into an InstantTime object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a slot into a TimeInterval object.", "response": "def parse_time_interval(slot):\n        \"\"\" Parse a slot into a TimeInterval object.\n\n        Sample response:\n\n        {\n          \"entity\": \"snips/datetime\",\n          \"range\": {\n            \"end\": 42,\n            \"start\": 13\n          },\n          \"rawValue\": \"between tomorrow and saturday\",\n          \"slotName\": \"weatherForecastStartDatetime\",\n          \"value\": {\n            \"from\": \"2017-09-15 00:00:00 +00:00\",\n            \"kind\": \"TimeInterval\",\n            \"to\": \"2017-09-17 00:00:00 +00:00\"\n          }\n        }\n\n        :param slot: a intent slot.\n        :return: a parsed TimeInterval object, or None.\n        \"\"\"\n        start = IntentParser.get_dict_value(\n            slot, ['value', 'from'])\n        end = IntentParser.get_dict_value(slot, ['value', 'to'])\n        if not start or not end:\n            return None\n        start = parse(start)\n        end = parse(end)\n        if not start or not end:\n            return None\n        return TimeInterval(start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dict_value(dictionary, path):\n        if len(path) == 0:\n            return None\n        temp_dictionary = dictionary\n        try:\n            for k in path:\n                temp_dictionary = temp_dictionary[k]\n            return temp_dictionary\n        except (KeyError, TypeError):\n            pass\n        return None", "response": "Safely get the value of a dictionary given a key path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef csview(self, view=False):\n        for starfile in fileio.read_files(self.from_path):\n            chains = starfile.chem_shifts_by_residue(amino_acids=self.amino_acids,\n                                                     atoms=self.atoms,\n                                                     amino_acids_and_atoms=self.amino_acids_and_atoms,\n                                                     nmrstar_version=self.nmrstar_version)\n\n            for idx, chemshifts_dict in enumerate(chains):\n                nodes = []\n                edges = []\n\n                for seq_id in chemshifts_dict:\n                    aaname = \"{}_{}\".format(chemshifts_dict[seq_id][\"AA3Code\"], seq_id)\n                    label = '\"{{{}|{}}}\"'.format(seq_id, chemshifts_dict[seq_id][\"AA3Code\"])\n                    color = 8\n                    aanode_entry = \"            {} [label={}, fillcolor={}]\".format(aaname, label, color)\n                    nodes.append(aanode_entry)\n                    currnodename = aaname\n\n                    for atom_type in chemshifts_dict[seq_id]:\n                        if atom_type in [\"AA3Code\", \"Seq_ID\"]:\n                            continue\n                        else:\n                            atname = \"{}_{}\".format(aaname, atom_type)\n                            label = '\"{{{}|{}}}\"'.format(atom_type, chemshifts_dict[seq_id][atom_type])\n                            if atom_type.startswith(\"H\"):\n                                color = 4\n                            elif atom_type.startswith(\"C\"):\n                                color = 6\n                            elif atom_type.startswith(\"N\"):\n                                color = 10\n                            else:\n                                color = 8\n                            atnode_entry = \"{} [label={}, fillcolor={}]\".format(atname, label, color)\n                            nextnodename = atname\n                            nodes.append(atnode_entry)\n                            edges.append(\"{} -> {}\".format(currnodename, nextnodename))\n                            currnodename = nextnodename\n\n                if self.filename is None:\n                    filename = \"{}_{}\".format(starfile.id, idx)\n                else:\n                    filename = \"{}_{}\".format(self.filename, idx)\n\n                src = Source(self.dot_template.format(\"\\n\".join(nodes), \"\\n\".join(edges)), format=self.csview_format)\n                src.render(filename=filename, view=view)", "response": "View chemical shift values organized by amino acid residue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the string representation of the current partition", "response": "def getStringPartition(self):\n        \"\"\"\n        Get the string representation of the current partition\n        @return string like \":-1,0:2\"\n        \"\"\"\n        res = ''\n        for s in self.partitions[self.index].getSlice():\n            start = ''\n            stop = ''\n            if s.start is not None:\n                start = int(s.start)\n            if s.stop is not None:\n                stop = int(s.stop)\n            res += '{0}:{1},'.format(start, stop)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens file and read Slackware version", "response": "def slack_ver():\n    \"\"\"Open file and read Slackware version\n    \"\"\"\n    dist = read_file(\"/etc/slackware-version\")\n    sv = re.findall(r\"\\d+\", dist)\n    if len(sv) > 2:\n        version = (\".\".join(sv[:2]))\n    else:\n        version = (\".\".join(sv))\n    return dist.split()[0], version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ins_packages():\n    count = 0\n    for pkg in os.listdir(pkg_path):\n        if not pkg.startswith(\".\"):\n            count += 1\n    return count", "response": "Count Slackware packages installed in the current directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread config file and return uncomment line", "response": "def read_config(config):\n    \"\"\"Read config file and return uncomment line\n    \"\"\"\n    for line in config.splitlines():\n        line = line.lstrip()\n        if line and not line.startswith(\"#\"):\n            return line\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget mirror from slackpkg mirrors file", "response": "def mirror():\n    \"\"\"Get mirror from slackpkg mirrors file\n    \"\"\"\n    slack_mirror = read_config(\n        read_file(\"{0}{1}\".format(etc_slackpkg, \"mirrors\")))\n    if slack_mirror:\n        return slack_mirror + changelog_txt\n    else:\n        print(\"\\nYou do not have any mirror selected in /etc/slackpkg/mirrors\"\n              \"\\nPlease edit that file and uncomment ONE mirror.\\n\")\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the list of upgraded packages from ChangeLog. txt file size and counts upgraded packages", "response": "def fetch():\n    \"\"\"Get ChangeLog.txt file size and counts upgraded packages\n    \"\"\"\n    mir, r, slackpkg_last_date = mirror(), \"\", \"\"\n    count, upgraded = 0, []\n    if mir:\n        tar = urlopen(mir)\n        try:\n            r = tar.read()\n        except AttributeError:\n            print(\"sun: error: can't read mirror\")\n    if os.path.isfile(var_lib_slackpkg + changelog_txt):\n        slackpkg_last_date = read_file(\"{0}{1}\".format(\n            var_lib_slackpkg, changelog_txt)).split(\"\\n\", 1)[0].strip()\n    else:\n        return [count, upgraded]\n    for line in r.splitlines():\n        if slackpkg_last_date == line.strip():\n            break\n        if (line.endswith(\"z:  Upgraded.\") or line.endswith(\"z:  Rebuilt.\") or\n                line.endswith(\"z:  Added.\") or line.endswith(\"z:  Removed.\")):\n            upgraded.append(line.split(\"/\")[-1])\n            count += 1\n        if (line.endswith(\"*:  Upgraded.\") or line.endswith(\"*:  Rebuilt.\") or\n                line.endswith(\"*:  Added.\") or line.endswith(\"*:  Removed.\")):\n            upgraded.append(line)\n            count += 1\n    return [count, upgraded]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config():\n    conf_args = {\n        \"INTERVAL\": 60,\n        \"STANDBY\": 3\n    }\n    config_file = read_file(\"{0}{1}\".format(conf_path, \"sun.conf\"))\n    for line in config_file.splitlines():\n        line = line.lstrip()\n        if line and not line.startswith(\"#\"):\n            conf_args[line.split(\"=\")[0]] = line.split(\"=\")[1]\n    return conf_args", "response": "Return sun. conf values"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the prime factor of given integer n", "response": "def getPrimeFactors(n):\n    \"\"\"\n    Get all the prime factor of given integer\n    @param n integer\n    @return list [1, ..., n]\n    \"\"\"\n    lo = [1]\n    n2 = n // 2\n    k = 2\n    for k in range(2, n2 + 1):\n        if (n // k)*k == n:\n            lo.append(k)\n    return lo + [n, ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getNeighborProc(self, proc, offset, periodic=None):\n\n        if self.mit is None:\n            # no decomp, just exit\n            return None\n\n        inds = [self.mit.getIndicesFromBigIndex(proc)[d] + offset[d]\n                for d in range(self.ndims)]\n\n        if periodic is not None and self.decomp is not None:\n            # apply modulo operation on periodic axes\n            for d in range(self.ndims):\n                if periodic[d]:\n                    inds[d] = inds[d] % self.decomp[d]\n\n        if self.mit.areIndicesValid(inds):\n            return self.mit.getBigIndexFromIndices(inds)\n        else:\n            return None", "response": "Get the neighbor to a processor"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes optimal dedomposition each sub - domain has the same volume in index space.", "response": "def __computeDecomp(self):\n        \"\"\"\n        Compute optimal dedomposition, each sub-domain has the\n        same volume in index space.\n        @return list if successful, empty list if not successful\n        \"\"\"\n        primeNumbers = [getPrimeFactors(d) for d in self.globalDims]\n\n        ns = [len(pns) for pns in primeNumbers]\n        validDecomps = []\n        self.validProcs = []\n        for it in MultiArrayIter(ns):\n            inds = it.getIndices()\n            decomp = [primeNumbers[d][inds[d]] for d in range(self.ndims)]\n            self.validProcs.append(reduce(operator.mul, decomp, 1))\n            if reduce(operator.mul, decomp, 1) == self.nprocs:\n                validDecomps.append(decomp)\n\n        # sort and remove duplicates\n        self.validProcs.sort()\n        vprocs = []\n        for vp in self.validProcs:\n            if len(vprocs) == 0 or (len(vprocs) >= 1 and vp != vprocs[-1]):\n                vprocs.append(vp)\n        self.validProcs = vprocs\n\n        if len(validDecomps) == 0:\n            # no solution\n            return\n\n        # find the optimal decomp among all valid decomps\n        minCost = float('inf')\n        bestDecomp = validDecomps[0]\n        for decomp in validDecomps:\n            sizes = [self.globalDims[d]//decomp[d] for d in range(self.ndims)]\n            volume = reduce(operator.mul, sizes, 1)\n            surface = 0\n            for d in range(self.ndims):\n                surface += 2*reduce(operator.mul, sizes[:d], 1) * \\\n                    reduce(operator.mul, sizes[d+1:], 1)\n            cost = surface / float(volume)\n            if cost < minCost:\n                bestDecomp = decomp\n                minCost = cost\n        self.decomp = bestDecomp\n\n        # ok, we have a valid decomp, now build the sub-domain iterator\n        self.mit = MultiArrayIter(self.decomp, rowMajor=self.rowMajor)\n\n        # fill in the proc to index set map\n        procId = 0\n        self.proc2IndexSet = {}\n        numCellsPerProc = [self.globalDims[d]//self.decomp[d]\n                           for d in range(self.ndims)]\n        for it in self.mit:\n            nps = it.getIndices()\n            self.proc2IndexSet[procId] = []\n            for d in range(self.ndims):\n                sbeg = nps[d]*numCellsPerProc[d]\n                send = (nps[d] + 1)*numCellsPerProc[d]\n                self.proc2IndexSet[procId].append(slice(sbeg, send))\n            procId += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new object of the specified type from a manager_config dictionary.", "response": "def _generate_manager(manager_config):\n        '''\n        Generate a manager from a manager_config dictionary\n\n        Parameters\n        ----------\n\n        manager_config : dict\n            Configuration with keys class, args, and kwargs\n            used to generate a new datafs.manager object\n\n        Returns\n        -------\n\n        manager : object\n            datafs.managers.MongoDBManager or\n            datafs.managers.DynamoDBManager object\n            initialized with *args, **kwargs\n\n        Examples\n        --------\n\n        Generate a dynamo manager:\n\n        .. code-block:: python\n\n        >>> mgr = APIConstructor._generate_manager({\n        ...     'class': 'DynamoDBManager',\n        ...     'kwargs': {\n        ...         'table_name': 'data-from-yaml',\n        ...         'session_args': {\n        ...             'aws_access_key_id': \"access-key-id-of-your-choice\",\n        ...             'aws_secret_access_key': \"secret-key-of-your-choice\"},\n        ...         'resource_args': {\n        ...             'endpoint_url':'http://localhost:8000/',\n        ...             'region_name':'us-east-1'}\n        ...     }\n        ... })\n        >>>\n        >>> from datafs.managers.manager_dynamo import DynamoDBManager\n        >>> assert isinstance(mgr, DynamoDBManager)\n        >>>\n        >>> 'data-from-yaml' in mgr.table_names\n        False\n        >>> mgr.create_archive_table('data-from-yaml')\n        >>> 'data-from-yaml' in mgr.table_names\n        True\n        >>> mgr.delete_table('data-from-yaml')\n\n        '''\n\n        if 'class' not in manager_config:\n            raise ValueError(\n                'Manager not fully specified. Give '\n                '\"class:manager_name\", e.g. \"class:MongoDBManager\".')\n\n        mgr_class_name = manager_config['class']\n\n        if mgr_class_name.lower()[:5] == 'mongo':\n            from datafs.managers.manager_mongo import (\n                MongoDBManager as mgr_class)\n\n        elif mgr_class_name.lower()[:6] == 'dynamo':\n            from datafs.managers.manager_dynamo import (\n                DynamoDBManager as mgr_class)\n\n        else:\n            raise KeyError(\n                'Manager class \"{}\" not recognized. Choose from {}'.format(\n                    mgr_class_name, 'MongoDBManager or DynamoDBManager'))\n\n        manager = mgr_class(\n            *manager_config.get('args', []),\n            **manager_config.get('kwargs', {}))\n\n        return manager"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_service(service_config):\n        '''\n        Generate a service from a service_config dictionary\n\n        Parameters\n        ----------\n\n        service_config : dict\n            Configuration with keys service, args, and\n            kwargs used to generate a new fs service\n            object\n\n        Returns\n        -------\n\n        service : object\n            fs service object initialized with *args,\n            **kwargs\n\n        Examples\n        --------\n\n        Generate a temporary filesystem (no arguments\n        required):\n\n        .. code-block:: python\n\n            >>> tmp = APIConstructor._generate_service(\n            ...     {'service': 'TempFS'})\n            ...\n            >>> from fs.tempfs import TempFS\n            >>> assert isinstance(tmp, TempFS)\n            >>> import os\n            >>> assert os.path.isdir(tmp.getsyspath('/'))\n            >>> tmp.close()\n\n        Generate a system filesystem in a temporary\n        directory:\n\n        .. code-block:: python\n\n            >>> import tempfile\n            >>> tempdir = tempfile.mkdtemp()\n            >>> local = APIConstructor._generate_service(\n            ...     {\n            ...         'service': 'OSFS',\n            ...         'args': [tempdir]\n            ...     })\n            ...\n            >>> from fs.osfs import OSFS\n            >>> assert isinstance(local, OSFS)\n            >>> import os\n            >>> assert os.path.isdir(local.getsyspath('/'))\n            >>> local.close()\n            >>> import shutil\n            >>> shutil.rmtree(tempdir)\n\n        Mock an S3 filesystem with moto:\n\n        .. code-block:: python\n\n            >>> import moto\n            >>> m = moto.mock_s3()\n            >>> m.start()\n            >>> s3 = APIConstructor._generate_service(\n            ...     {\n            ...         'service': 'S3FS',\n            ...         'args': ['bucket-name'],\n            ...         'kwargs': {\n            ...             'aws_access_key':'MY_KEY',\n            ...             'aws_secret_key':'MY_SECRET_KEY'\n            ...         }\n            ...     })\n            ...\n            >>> from fs.s3fs import S3FS\n            >>> assert isinstance(s3, S3FS)\n            >>> m.stop()\n\n        '''\n\n        filesystems = []\n\n        for _, modname, _ in pkgutil.iter_modules(fs.__path__):\n            if modname.endswith('fs'):\n                filesystems.append(modname)\n\n        service_mod_name = service_config['service'].lower()\n\n        assert_msg = 'Filesystem \"{}\" not found in pyFilesystem {}'.format(\n            service_mod_name, fs.__version__)\n\n        assert service_mod_name in filesystems, assert_msg\n\n        svc_module = importlib.import_module('fs.{}'.format(service_mod_name))\n        svc_class = svc_module.__dict__[service_config['service']]\n\n        service = svc_class(*service_config.get('args', []),\n                            **service_config.get('kwargs', {}))\n\n        return service", "response": "Generate a new object of the appropriate type for a service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addStencilBranch(self, disp, weight):\n        self.stencil[tuple(disp)] = weight\n        self.__setPartionLogic(disp)", "response": "Add a stencil branch to the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply(self, localArray):\n\n        # input dist array\n        inp = daZeros(localArray.shape, localArray.dtype)\n        inp[...] = localArray\n        inp.setComm(self.comm)\n\n        # output array\n        out = numpy.zeros(localArray.shape, localArray.dtype)\n\n        # expose the dist array windows\n        for disp, dpi in self.dpis.items():\n\n            srcs = dpi['srcs']\n            remoteWinIds = dpi['remoteWinIds']\n            numParts = len(srcs)\n            for i in range(numParts):\n                inp.expose(srcs[i], winID=remoteWinIds[i])\n\n        # apply the stencil\n        for disp, weight in self.stencil.items():\n\n            dpi = self.dpis[disp]\n\n            dpi = self.dpis[disp]\n\n            srcs = dpi['srcs']\n            dsts = dpi['dsts']\n            remoteRanks = dpi['remoteRanks']\n            remoteWinIds = dpi['remoteWinIds']\n            numParts = len(srcs)\n            for i in range(numParts):\n                srcSlce = srcs[i]\n                dstSlce = dsts[i]\n                remoteRank = remoteRanks[i]\n                remoteWinId = remoteWinIds[i]\n\n                # now apply the stencil\n                if remoteRank == self.myRank:\n                    # local updates\n                    out[dstSlce] += weight*inp[srcSlce]\n                else:\n                    # remote fetch\n                    out[dstSlce] += weight*inp.getData(remoteRank, remoteWinId)\n\n        # some implementations require this\n        inp.free()\n\n        return out", "response": "Apply stencil to data\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets index set from given big index", "response": "def getIndicesFromBigIndex(self, bigIndex):\n        \"\"\"\n        Get index set from given big index\n        @param bigIndex\n        @return index set\n        @note no checks are performed to ensure that the returned\n        big index is valid\n        \"\"\"\n        indices = numpy.array([0 for i in range(self.ndims)])\n        for i in range(self.ndims):\n            indices[i] = bigIndex // self.dimProd[i] % self.dims[i]\n        return indices"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the big index from a given set of indices", "response": "def getBigIndexFromIndices(self, indices):\n        \"\"\"\n        Get the big index from a given set of indices\n        @param indices\n        @return big index\n        @note no checks are performed to ensure that the returned\n        indices are valid\n        \"\"\"\n        return reduce(operator.add, [self.dimProd[i]*indices[i]\n                                     for i in range(self.ndims)], 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef areIndicesValid(self, inds):\n        return reduce(operator.and_, [0 <= inds[d] < self.dims[d]\n                                      for d in range(self.ndims)], True)", "response": "Test if indices are valid\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_setting(setting):\n    defaults = {\n        # The context to use for rendering fields\n        'TEMPLATE_FIELD_CONTEXT': {},\n        # When this is False, don't do any TemplateField rendering\n        'TEMPLATE_FIELD_RENDER': True\n    }\n    try:\n        return getattr(settings, setting, defaults[setting])\n    except KeyError:\n        msg = \"{0} is not specified in your settings\".format(setting)\n        raise ImproperlyConfigured(msg)", "response": "Get the specified django setting or the default value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef csv_line_items(self):\n        '''\n        Invoices from lists omit csv-line-items\n\n        '''\n        if not hasattr(self, '_csv_line_items'):\n            url = '{}/{}'.format(self.base_url, self.id)\n            self._csv_line_items = self.harvest._get_element_values(url, self.element_name).next().get('csv-line-items', '')\n        return self._csv_line_items", "response": "Get the list of CSV line items for this item from the Harvest server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_getters(self, klass):\n        '''\n        This method creates both the singular and plural getters for various\n        Harvest object classes.\n\n        '''\n        flag_name = '_got_' + klass.element_name\n        cache_name = '_' + klass.element_name\n        setattr(self, cache_name, {})\n        setattr(self, flag_name, False)\n        cache = getattr(self, cache_name)\n\n        def _get_item(id):\n            if id in cache:\n                return cache[id]\n            else:\n                url = '{}/{}'.format(klass.base_url, id)\n                item = self._get_element_values(url, klass.element_name).next()\n                item = klass(self, item)\n                cache[id] = item\n                return item\n\n        setattr(self, klass.element_name, _get_item)\n\n        def _get_items():\n            if getattr(self, flag_name):\n                for item in cache.values():\n                    yield item\n            else:\n                for element in self._get_element_values(klass.base_url, klass.element_name):\n                    item = klass(self, element)\n                    cache[item.id] = item\n                    yield item\n\n                setattr(self, flag_name, True)\n\n        setattr(self, klass.plural_name, _get_items)", "response": "This method creates both the singular and plural getters for various Harvest object classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef api_call(self, call, method, params=None, headers=None, data=None,\n\t\t\t\t json=None):\n\t\t\"\"\"\n\t\tThis is our generic api call function.  We will route all calls except\n\t\trequests that do not return JSON ('Export' and 'Experiment Metrics' are\n\t\texamples where this is the case).  This is beneficial because:\n\t\t\t1. Allows for easier debugging if a request fails\n\t\t\t2. Currently, Iterable only needs the API key from a security\n\t\t\tstandpoint. In the future, if it were to require an  \n\t\t\taccess token for each request we could easily manage the granting\n\t\t\tand expiration management of such a token.  \n\n\t\t\"\"\"\n\n\t\t# params(optional) Dictionary or bytes to be sent in the query string for the Request.\n\t\tif params is None:\n\t\t\tparams = {}\n\t\t# data- dict or list of tuples to be sent in body of Request\n\t\tif data is None:\n\t\t\tdata = {}\n\t\t# json- data to be sent in body of Request\n\t\tif json is None:\n\t\t\tjson ={}\n\n\t\t# make the request following the 'requests.request' method\n\t\tr = requests.request(method=method, url=self.base_uri+call, params=params,\n\t\t\t\t\t\t\t headers=self.headers, data=data, json=json)\t\n\n\t\tresponse = {\t\t\t\n\t\t\t\"body\": r.json(),\t\t\t\n\t\t\t\"code\": r.status_code,\n\t\t\t\"headers\": r.headers,\n\t\t\t\"url\": r.url\n\t\t}\n\n\t\treturn response", "response": "This is our generic api call function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef track_purchase(self, user, items, total, purchase_id= None, campaign_id=None, \n\t\t\t\t\t   template_id=None, created_at=None,\n\t\t\t\t\t   data_fields=None):\n\t\t\"\"\"\n\t\t\tThe 'purchase_id' argument maps to 'id' for this API endpoint.\n\t\t\tThis name is used to distinguish it from other instances where\n\t\t\t'id' is a part of the API request with other Iterable endpoints.\n\t\t\"\"\"\n\n\t\tcall=\"/api/commerce/trackPurchase\"\n\n\t\tpayload ={}\n\t\n\t\tif isinstance(user, dict):\n\t\t\tpayload[\"user\"]= user\n\t\telse:\n\t\t\traise TypeError('user key is not in Dictionary format')\n\n\t\tif isinstance(items, list):\n\t\t\tpayload[\"items\"]= items\n\t\telse:\n\t\t\traise TypeError('items are not in Array format')\n\n\t\tif isinstance(total, float):\n\t\t\tpayload[\"total\"]= total\n\t\telse:\n\t\t\traise TypeError('total is not in correct format')\n\n\t\tif purchase_id is not None:\n\t\t\tpayload[\"id\"]= str(purchase_id) \n\n\t\tif campaign_id is not None:\n\t\t\tpayload[\"campaignId\"]= campaign_id\n\n\t\tif template_id is not None:\n\t\t\tpayload[\"templateId\"]= template_id\t\t\n\n\t\tif created_at is not None:\n\t\t\tpayload[\"createdAt\"]= created_at\n\n\t\tif data_fields is not None:\n\t\t\tpayload[\"data_fields\"]= data_fields\n\n\t\treturn self.api_call(call=call, method=\"POST\", json=payload)", "response": "This method tracks a purchase of a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_data_json(self, return_response_object, \n\t\t\t\t\t\tchunk_size=1024, \n\t\t\t\t\t\tpath=None,\n\t\t\t\t\t\tdata_type_name=None, date_range=None,\n\t\t\t\t\t\tdelimiter=None, start_date_time=None,\n\t\t\t\t\t\tend_date_time=None, omit_fields=None,\n\t\t\t\t\t\tonly_fields=None, campaign_id=None):\n\n\t\t\"\"\"\n\t\tCustom Keyword arguments:\n\n\t\t1. return_response_object:\n\t\t\tif set to 'True', the 'r' response object will be returned.  The\n\t\t\tbenefit of this is that you can manipulate the data in any way you\n\t\t\twant.  If set to false, we will write the response to a file where each\n\t\t\tIterable activity you're exporting is a single-line JSON object.\n\t\t2. chunk_size:\n\t\t\tChunk size is used as a paremeter in the r.iter_content(chunk_size) method\n\t\t\tthat controls how big the response chunks are (in bytes).  Depending on the\n\t\t\tdevice used to make the request, this might change depending on the user. \n\t\t\tDefault is set to 1 MB. \n\t\t3. path:\n\t\t\tAllows you to choose the directory where the file is downloaded into.\n\t\t\t\tExample: \"/Users/username/Desktop/\"\n\t\t\tIf not set the file will download into the current directory.\n\t\t\t\n\t\t\"\"\"\n\t\tcall=\"/api/export/data.json\"\n\n\t\t# make sure correct ranges are being used\n\t\tdate_ranges = [\"Today\", \"Yesterday\", \"BeforeToday\", \"All\"]\t\t\n\t\t\n\t\tif isinstance(return_response_object, bool) is False:\n\t\t\traise ValueError(\"'return_iterator_object'parameter must be a boolean\") \n\t\t\n\t\tif chunk_size is not None and isinstance(chunk_size, int):\n\t\t\tpass\n\t\telse:\n\t\t\traise ValueError(\"'chunk_size' parameter must be a integer\")\n\n\t\tpayload={}\n\n\t\tif data_type_name is not None:\n\t\t\tpayload[\"dataTypeName\"]= data_type_name\n\n\t\tif date_range is not None and date_range in date_ranges:\n\t\t\tpayload[\"range\"]= date_range\n\n\t\tif start_date_time is not None:\n\t\t\tpayload[\"startDateTime\"]= start_date_time\n\n\t\tif end_date_time is not None:\n\t\t\tpayload[\"endDateTime\"]= end_date_time\n\n\t\tif omit_fields is not None:\n\t\t\tpayload[\"omitFields\"]= omit_fields\n\n\t\tif only_fields is not None and isinstance(only_fields, list):\n\t\t\tpayload[\"onlyFields\"]= only_fields\n\n\t\tif campaign_id is not None:\n\t\t\tpayload[\"campaignId\"]= campaign_id\n\n\t\treturn self.export_data_api(call=call, chunk_size=chunk_size, \n\t\t\t\t\t\t\t\t\tparams=payload, path=path,\n\t\t\t\t\t\t\t\t\treturn_response_object=return_response_object)", "response": "This method returns a JSON object that can be used to export the data in a single - line activity."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bulk_update_user(self, users):\n\n\t\t\"\"\"\n\t\tThe Iterable 'Bulk User Update' api Bulk update user data or adds \n\t\tit if does not exist. Data is merged - missing fields are not deleted\n\n\t\tThe body of the request takes 1 keys:\n\t\t\t1. users -- in the form of an array -- which is the list of users\n\t\t\t\tthat we're updating in sets of 50 users at a time, which is the \n\t\t\t\tmost that can be batched in a single request.  \n\t\t\"\"\"\n\n\t\tcall = \"/api/users/bulkUpdate\"\t\t\n\t\t\n\t\tpayload = {}\n\n\t\tif isinstance(users, list):\n\t\t\tpayload[\"users\"] = users\n\t\telse:\n\t\t\traise TypeError ('users are not in Arrary format')\t\t\n\n\t\treturn self.api_call(call=call, method=\"POST\", json=payload)", "response": "The Iterable 'Bulk User Update' api Bulk update user data or adds \n\t\tit if does not exist. Data is merged - missing fields are not deleted\n\n\t\tThe body of the request takes 1 keys:\n\t\t\t1. users -- in the form of an array -- which is the list of users\n\t\t\t\tthat we're updating in sets of 50 users at a time, which is the \n\t\t\t\tmost that can be batched in a single request."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the current configuration of the current object.", "response": "def configure(ctx, helper, edit):\n    '''\n    Update configuration\n    '''\n\n    ctx.obj.config = ConfigFile(ctx.obj.config_file)\n\n    if edit:\n        ctx.obj.config.edit_config_file()\n        return\n\n    if os.path.isfile(ctx.obj.config.config_file):\n        ctx.obj.config.read_config()\n\n    if ctx.obj.profile is None:\n        ctx.obj.profile = ctx.obj.config.default_profile\n\n    args, kwargs = _parse_args_and_kwargs(ctx.args)\n    assert len(args) == 0, 'Unrecognized arguments: \"{}\"'.format(args)\n\n    if ctx.obj.profile not in ctx.obj.config.config['profiles']:\n        ctx.obj.config.config['profiles'][ctx.obj.profile] = {\n            'api': {'user_config': {}}, 'manager': {}, 'authorities': {}}\n\n    profile_config = ctx.obj.config.config['profiles'][ctx.obj.profile]\n    profile_config['api']['user_config'].update(kwargs)\n\n    ctx.obj.config.write_config(ctx.obj.config_file)\n\n    _generate_api(ctx)\n\n    if ctx.obj.api.manager is not None:\n        check_requirements(\n            to_populate=profile_config['api']['user_config'],\n            prompts=ctx.obj.api.manager.required_user_config,\n            helper=helper)\n\n    ctx.obj.config.write_config(ctx.obj.config_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(\n        ctx,\n        archive_name,\n        bumpversion='patch',\n        prerelease=None,\n        dependency=None,\n        message=None,\n        string=False,\n        file=None):\n    '''\n    Update an archive with new contents\n    '''\n\n    _generate_api(ctx)\n\n    args, kwargs = _parse_args_and_kwargs(ctx.args)\n    assert len(args) == 0, 'Unrecognized arguments: \"{}\"'.format(args)\n\n    dependencies_dict = _parse_dependencies(dependency)\n\n    var = ctx.obj.api.get_archive(archive_name)\n    latest_version = var.get_latest_version()\n\n    if string:\n\n        with var.open(\n                'w+',\n                bumpversion=bumpversion,\n                prerelease=prerelease,\n                dependencies=dependencies_dict,\n                metadata=kwargs,\n                message=message) as f:\n\n            if file is None:\n                for line in sys.stdin:\n                    f.write(u(line))\n            else:\n                f.write(u(file))\n\n    else:\n        if file is None:\n            file = click.prompt('enter filepath')\n\n        var.update(\n            file,\n            bumpversion=bumpversion,\n            prerelease=prerelease,\n            dependencies=dependencies_dict,\n            metadata=kwargs,\n            message=message)\n\n    new_version = var.get_latest_version()\n\n    if latest_version is None and new_version is not None:\n        bumpmsg = ' new version {} created.'.format(\n            new_version)\n\n    elif new_version != latest_version:\n        bumpmsg = ' version bumped {} --> {}.'.format(\n            latest_version, new_version)\n\n    elif var.versioned:\n        bumpmsg = ' version remains {}.'.format(latest_version)\n    else:\n        bumpmsg = ''\n\n    click.echo('uploaded data to {}.{}'.format(var, bumpmsg))", "response": "Update an archive with new contents."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating an archive s metadata", "response": "def update_metadata(ctx, archive_name):\n    '''\n    Update an archive's metadata\n    '''\n\n    _generate_api(ctx)\n    args, kwargs = _parse_args_and_kwargs(ctx.args)\n    assert len(args) == 0, 'Unrecognized arguments: \"{}\"'.format(args)\n\n    var = ctx.obj.api.get_archive(archive_name)\n\n    var.update_metadata(metadata=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_dependencies(ctx, archive_name, dependency=None):\n    '''\n    Set the dependencies of an archive\n    '''\n\n    _generate_api(ctx)\n    kwargs = _parse_dependencies(dependency)\n\n    var = ctx.obj.api.get_archive(archive_name)\n\n    var.set_dependencies(dependencies=kwargs)", "response": "Sets the dependencies of an archive\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dependencies(ctx, archive_name, version):\n    '''\n    List the dependencies of an archive\n    '''\n\n    _generate_api(ctx)\n\n    var = ctx.obj.api.get_archive(archive_name)\n\n    deps = []\n\n    dependencies = var.get_dependencies(version=version)\n    for arch, dep in dependencies.items():\n        if dep is None:\n            deps.append(arch)\n        else:\n            deps.append('{}=={}'.format(arch, dep))\n\n    click.echo('\\n'.join(deps))", "response": "List the dependencies of an archive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding tags to an archive", "response": "def add_tags(ctx, archive_name, tags):\n    '''\n    Add tags to an archive\n    '''\n\n    _generate_api(ctx)\n\n    var = ctx.obj.api.get_archive(archive_name)\n\n    var.add_tags(*tags)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_tags(ctx, archive_name):\n    '''\n    Print tags assigned to an archive\n    '''\n\n    _generate_api(ctx)\n\n    var = ctx.obj.api.get_archive(archive_name)\n\n    click.echo(' '.join(var.get_tags()), nl=False)\n    print('')", "response": "Print tags assigned to an archive"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\necho the contents of an archive", "response": "def cat(ctx, archive_name, version):\n    '''\n    Echo the contents of an archive\n    '''\n\n    _generate_api(ctx)\n    var = ctx.obj.api.get_archive(archive_name)\n\n    with var.open('r', version=version) as f:\n        for chunk in iter(lambda: f.read(1024 * 1024), ''):\n            click.echo(chunk)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the version log for an archive", "response": "def log(ctx, archive_name):\n    '''\n    Get the version log for an archive\n    '''\n\n    _generate_api(ctx)\n    ctx.obj.api.get_archive(archive_name).log()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an archive s metadata", "response": "def metadata(ctx, archive_name):\n    '''\n    Get an archive's metadata\n    '''\n\n    _generate_api(ctx)\n    var = ctx.obj.api.get_archive(archive_name)\n    click.echo(pprint.pformat(var.get_metadata()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef history(ctx, archive_name):\n    '''\n    Get archive history\n    '''\n\n    _generate_api(ctx)\n    var = ctx.obj.api.get_archive(archive_name)\n    click.echo(pprint.pformat(var.get_history()))", "response": "Get the history of an archive"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an archive s versions", "response": "def versions(ctx, archive_name):\n    '''\n    Get an archive's versions\n    '''\n\n    _generate_api(ctx)\n\n    var = ctx.obj.api.get_archive(archive_name)\n    click.echo(pprint.pformat(map(str, var.get_versions())))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting all archives matching filter criteria", "response": "def filter_archives(ctx, prefix, pattern, engine):\n    '''\n    List all archives matching filter criteria\n    '''\n\n    _generate_api(ctx)\n\n    # want to achieve behavior like click.echo(' '.join(matches))\n\n    for i, match in enumerate(ctx.obj.api.filter(\n            pattern, engine, prefix=prefix)):\n\n        click.echo(match, nl=False)\n        print('')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist all archives matching tag search criteria", "response": "def search(ctx, tags, prefix=None):\n    '''\n    List all archives matching tag search criteria\n    '''\n\n    _generate_api(ctx)\n\n    for i, match in enumerate(ctx.obj.api.search(*tags, prefix=prefix)):\n\n        click.echo(match, nl=False)\n        print('')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listdir(ctx, location, authority_name=None):\n    '''\n    List archive path components at a given location\n\n    Note:\n\n    When using listdir on versioned archives, listdir will provide the\n    version numbers when a full archive path is supplied as the location\n    argument. This is because DataFS stores the archive path as a directory\n    and the versions as the actual files when versioning is on.\n\n    Parameters\n    ----------\n\n    location : str\n\n        Path of the \"directory\" to search\n\n        `location` can be a path relative to the authority root (e.g\n        `/MyFiles/Data`) or can include authority as a protocol (e.g.\n        `my_auth://MyFiles/Data`). If the authority is specified as a\n        protocol, the `authority_name` argument is ignored.\n\n    authority_name : str\n\n        Name of the authority to search (optional)\n\n        If no authority is specified, the default authority is used (if\n        only one authority is attached or if\n        :py:attr:`DefaultAuthorityName` is assigned).\n\n\n    Returns\n    -------\n\n    list\n\n        Archive path components that exist at the given \"directory\"\n        location on the specified authority\n\n    Raises\n    ------\n\n    ValueError\n\n        A ValueError is raised if the authority is ambiguous or invalid\n    '''\n\n    _generate_api(ctx)\n\n    for path_component in ctx.obj.api.listdir(\n            location,\n            authority_name=authority_name):\n\n        click.echo(path_component, nl=False)\n        print('')", "response": "List the archive path components at a given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createListRecursively(self,args):\n        resultList = []\n        dirDict = self.getDirectoryDictionary(args)\n        for key in dirDict:\n            for path,dirs,files in os.walk(key):    # Walk through the directory to find al\tl input\n                for d in dirs:\n                    resultList.append(os.path.join(path,d))\n                for f in files:    # Append the file if 'ALL' are allowed or the extension is allowed\n                        pattern = dirDict[key].split(',')\n                        if 'ALL' in pattern or os.path.splitext(f)[1] in pattern:\n                            resultList.append(os.path.join(path,f))\n        return list(set(resultList))", "response": "This method creates the list of input files or directories recursively starting at the provided directory or directories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getFiles(self,args):\n        fileList = []\n        if args.recursive:    # The list is created by going through the folder(s) recursively:\n            fileList = self.createListRecursively(args)\n        else:    # The list is created by going through the provided folder(s):\n            fileList = self.createList(args)\n        if args.directories:\n            # If directories are returned, the list is sorted in reverse order.\n            # This allows the processing of subfolders before the processing of the parent folder.\n            # Processing the parent folder first may not work because the command may remove\n            # or rename the folder, which would affect the subfolders.\n            fileList = [element for element in fileList if os.path.isdir(element)]\n            return sorted(fileList,reverse=True)\n        else:\n            # Filter out all directories:\n            fileList = [element for element in fileList if os.path.isfile(element)]\n\t    if args.extensions != None:    # Files are filtered based on their extensions:\n                extensionList = self.getExtensionList(args.extensions)\n                fileList = [element for element in fileList if os.path.splitext(element)[1] in extensionList]\n            # The files in the list are sorted in lexicographical order:\n            return sorted(fileList)", "response": "This method returns a list of all files or directories in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replaceInCommand(self,command, pattern, replacement, replacementAtBeginning):\n        # Turn the command into a list:\n        commandAsList = list(command)\n        # Get the indices of the pattern in the list:\n        indices = [index.start() for index in re.finditer(pattern, command)]\n        # Replace at the indices, unless the preceding character is the\n        # escape character:\n        for index in indices:\n            if index == 0:\n                commandAsList[index] = replacementAtBeginning\n            elif commandAsList[index-1] != MapConstants.escape_char:\n                commandAsList[index] = replacement\n        # Put the pieces of the new command together:\n        newCommand = ''.join(commandAsList)\n        # Remove superfluous slashes and return:\n        return newCommand.replace(\"//\",\"/\")", "response": "This method replaces a certain pattern in the provided command with a specific replacement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef buildPart(self,commandPart,fileNameWithPath,count,args):\n        # Get the path to the file:\n        filePath = os.path.split(fileNameWithPath)[0]\n        # Append '/' if there is a path, i.e., the file is not in the local directory:\n\tif filePath != '':\n            filePath = filePath +'/'\n        # Get the file name without the path:\n        fileNameWithoutPath = os.path.basename(fileNameWithPath)\n        # Get the file name without the path and without the extension:\n        plainFileName = os.path.splitext(fileNameWithoutPath)[0]\n        # Get the extension:\n        fileExtension = os.path.splitext(fileNameWithoutPath)[1]\n        \n        # The original command part is retained:\n        originalCommandPart = commandPart\n\n        # Replace the file placeholder character with the file:\n        commandPart = self.replaceInCommand(commandPart,MapConstants.placeholder,fileNameWithoutPath,fileNameWithPath)\n        # Replace the path placeholder with the path:\n        commandPart = self.replaceInCommand(commandPart,MapConstants.placeholderPath,filePath,filePath)\n        # Replace the plain file placeholder with the plain file:\n        commandPart = self.replaceInCommand(commandPart,MapConstants.placeholderFileName,plainFileName,plainFileName)\n        # Replace the extension placeholder with the extension:\n        commandPart = self.replaceInCommand(commandPart,MapConstants.placeholderExtension,fileExtension,fileExtension)\n        # Replace the placeholder for the counter with the actual count:\n        if args.number_length == 0:\n            replacementString = str(count)\n        else:\n            replacementString = ('{0:0'+str(args.number_length)+'d}').format(count)\n        commandPart = self.replaceInCommand(commandPart,MapConstants.placeholderCounter,replacementString,replacementString)\n        # If the command part changed, it is put in quotes to avoid problems with special characters:\n        if originalCommandPart != commandPart:\n            commandPart = '\\\"' + commandPart + '\\\"'\n        return commandPart", "response": "This method builds a command part for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buildCommands(self,files,args):\n        commands = []\n        count = args.count_from\n        # For each file, a command is created:\n        for fileName in files:\n            commands.append(self.buildCommand(fileName,count,args))\n            count = count+1\n        return commands", "response": "Builds all the commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef runCommands(self,commands,args):\n        errorCounter = 0\n        if args.list:\n            print '\\n'.join(commands)\n        else:\n            # Each command is executed sequentially:\n            for command in commands:\n                process = subprocess.Popen(command, stdout=subprocess.PIPE,stderr=subprocess.PIPE,shell=True)\n                stream = process.communicate()\n                output = stream[0]\n                erroroutput = stream[1]\n                returncode = process.returncode\n                if args.verbose:\n                    print 'Executing command: '+command\n                if returncode != 0:\n                    errorCounter = errorCounter + 1\n                    if args.verbose or not args.ignore_errors:\n                        print 'An error occurred:\\n'\n                        print erroroutput\n                    if not args.ignore_errors:\n                        print('Terminating map process.')\n                        break\n                if returncode == 0 and len(output) > 0:\n                    sys.stdout.write(output)\n        if args.verbose:\n            print 'Process completed successfully.'\n            if errorCounter > 0:\n                if errorCounter > 1:\n                    print str(errorCounter) + ' errors occurred during the process.'\n                else:\n                    print str(errorCounter) + ' error occurred during the process.'", "response": "Executes a list of commands and prints out the output of each command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_filenames(sources):\n\n    for source in sources:\n\n        if os.path.isdir(source):\n            for path, dirlist, filelist in os.walk(source):\n                for fname in filelist:\n                    if nmrstarlib.VERBOSE:\n                        print(\"Processing file: {}\".format(os.path.abspath(fname)))\n                    if GenericFilePath.is_compressed(fname):\n                        if nmrstarlib.VERBOSE:\n                            print(\"Skipping compressed file: {}\".format(os.path.abspath(fname)))\n                        continue\n                    else:\n                        yield os.path.join(path, fname)\n\n        elif os.path.isfile(source):\n            yield source\n\n        elif GenericFilePath.is_url(source):\n            yield source\n\n        elif source.isdigit():\n            try:\n                urlopen(nmrstarlib.BMRB_REST + source)\n                yield nmrstarlib.BMRB_REST + source\n            except HTTPError:\n                urlopen(nmrstarlib.PDB_REST + source + \".cif\")\n                yield nmrstarlib.PDB_REST + source + \".cif\"\n\n        elif re.match(\"[\\w\\d]{4}\", source):\n            yield nmrstarlib.PDB_REST + source + \".cif\"\n\n        else:\n            raise TypeError(\"Unknown file source.\")", "response": "Generate filenames.\n\n    :param tuple sources: Sequence of strings representing path to file(s).\n    :return: Path to file(s).\n    :rtype: :py:class:`str`"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a sequence of filenames one at a time producing file objects.", "response": "def _generate_handles(filenames):\n    \"\"\"Open a sequence of filenames one at time producing file objects.\n    The file is closed immediately when proceeding to the next iteration.\n\n    :param generator filenames: Generator object that yields the path to each file, one at a time.\n    :return: Filehandle to be processed into a :class:`~nmrstarlib.nmrstarlib.StarFile` instance.\n    \"\"\"\n    for fname in filenames:\n        if nmrstarlib.VERBOSE:\n            print(\"Processing file: {}\".format(os.path.abspath(fname)))\n        path = GenericFilePath(fname)\n        for filehandle, source in path.open():\n            yield filehandle, source\n            filehandle.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_files(*sources):\n    filenames = _generate_filenames(sources)\n    filehandles = _generate_handles(filenames)\n    for fh, source in filehandles:\n        starfile = nmrstarlib.StarFile.read(fh, source)\n        yield starfile", "response": "Construct a generator that yields nmrstarlib. StarFile instances for each of the sources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate(self, csdl, service='facebook'):\n        return self.request.post('validate', data=dict(csdl=csdl))", "response": "Validate the CSDL for analysis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart a recording with the provided hash.", "response": "def start(self, hash, name=None, service='facebook'):\n        \"\"\" Start a recording for the provided hash\n\n            :param hash: The hash to start recording with\n            :type hash: str\n            :param name: The name of the recording\n            :type name: str\n            :param service: The service for this API call (facebook, etc)\n            :type service: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'hash': hash}\n\n        if name:\n            params['name'] = name\n\n        return self.request.post(service + '/start', params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self, id, service='facebook'):\n        return self.request.post(service + '/stop', data=dict(id=id))", "response": "Stop recording for the provided id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, id, parameters, filter=None, start=None, end=None,\n                service='facebook'):\n        \"\"\" Analyze the recorded data for a given hash\n\n            :param id: The id of the recording\n            :type id: str\n            :param parameters: To set settings such as threshold and target\n            :type parameters: dict\n            :param filter: An optional secondary filter\n            :type filter: str\n            :param start: Determines time period of the analyze\n            :type start: int\n            :param end: Determines time period of the analyze\n            :type end: int\n            :param service: The service for this API call (facebook, etc)\n            :type service: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'id': id,\n                  'parameters': parameters}\n\n        if filter:\n            params['filter'] = filter\n        if start:\n            params['start'] = start\n        if end:\n            params['end'] = end\n\n        return self.request.post(service + '/analyze', params)", "response": "Analyze the recorded data for a given hash entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, id, service='facebook'):\n\n        params = {'id': id}\n\n        return self.request.get(service + '/get', params)", "response": "Get the existing analysis for a given hash."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, page=None, per_page=None, order_by='created_at',\n             order_dir='DESC', service='facebook'):\n\n        \"\"\" List pylon recordings\n\n            :param page: page number for pagination\n            :type page: int\n            :param per_page: number of items per page, default 20\n            :type per_page: int\n            :param order_by: field to order by, default request_time\n            :type order_by: str\n            :param order_dir: direction to order by, asc or desc, default desc\n            :type order_dir: str\n            :param service: The service for this API call (facebook, etc)\n            :type service: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {}\n\n        if page:\n            params['page'] = page\n        if per_page:\n            params['per_page'] = per_page\n        if order_by:\n            params['order_by'] = order_by\n        if order_dir:\n            params['order_dir'] = order_dir\n\n        return self.request.get(service + '/get', params)", "response": "List pylon recordings of a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tags(self, id, service='facebook'):\n        return self.request.get(service + '/tags', params=dict(id=id))", "response": "Get the existing analysis for a given hash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sample(self, id, count=None, start=None, end=None, filter=None,\n               service='facebook'):\n        \"\"\" Get sample interactions for a given hash\n\n            :param id: The hash to get tag analysis for\n            :type id: str\n            :param start: Determines time period of the sample data\n            :type start: int\n            :param end: Determines time period of the sample data\n            :type end: int\n            :param filter: An optional secondary filter\n            :type filter: str\n            :param service: The service for this API call (facebook, etc)\n            :type service: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'id': id}\n\n        if count:\n            params['count'] = count\n        if start:\n            params['start'] = start\n        if end:\n            params['end'] = end\n        if filter:\n            params['filter'] = filter\n\n        return self.request.get(service + '/sample', params)", "response": "Get sample interactions for a given hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, identity_id, service):\n\n        return self.request.get(str(identity_id) + '/limit/' + service)", "response": "Get the limit for the given identity and service"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of limits for the given service.", "response": "def list(self, service, per_page=20, page=1):\n        \"\"\" Get a list of limits for the given service\n\n            :param service: The service that the limit is linked to\n            :param per_page: The number of results per page returned\n            :param page: The page number of the results\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'per_page': per_page, 'page': page}\n\n        return self.request.get('limit/' + service, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the limit for the given identity and service.", "response": "def create(self, identity_id, service, total_allowance=None, analyze_queries=None):\n        \"\"\" Create the limit\n\n            :param identity_id: The ID of the identity to retrieve\n            :param service: The service that the token is linked to\n            :param total_allowance: The total allowance for this token's limit\n            :param analyze_queries: The number of analyze calls\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'service': service}\n\n        if total_allowance is not None:\n            params['total_allowance'] = total_allowance\n        if analyze_queries is not None:\n            params['analyze_queries'] = analyze_queries\n\n        return self.request.post(str(identity_id) + '/limit/', params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, identity_id, service, total_allowance=None, analyze_queries=None):\n\n        params = {'service': service}\n        if total_allowance is not None:\n            params['total_allowance'] = total_allowance\n        if analyze_queries is not None:\n            params['analyze_queries'] = analyze_queries\n        return self.request.put(str(identity_id) + '/limit/' + service, params)", "response": "Updates the limit for a specific token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, identity_id, service):\n\n        return self.request.delete(str(identity_id) + '/limit/' + service)", "response": "Delete the limit for the given identity and service"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reload(request):\n    refresh_packages.clean()\n    refresh_packages.local()\n    refresh_packages.remote()\n    url = request.META.get('HTTP_REFERER')\n    if url:\n        return HttpResponseRedirect(url)\n    else:\n        return HttpResponse('Local requirements list has been reloaded.')", "response": "Reload local requirements file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generate_processed_key_name(process_to, upload_name):\n        timestamp = datetime.now().strftime('%Y%m%d%H%M%S%f')\n        name, extension = os.path.splitext(upload_name)\n        digest = md5(''.join([timestamp, upload_name])).hexdigest()\n        return os.path.join(process_to, '{0}.{1}'.format(digest, extension))", "response": "Returns a key name to use after processing based on timestamp and\n        upload key name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that the bucket name in the provided data matches the bucket name from the storage backend.", "response": "def clean_bucket_name(self):\n        \"\"\"Validates that the bucket name in the provided data matches the\n        bucket name from the storage backend.\"\"\"\n        bucket_name = self.cleaned_data['bucket_name']\n        if not bucket_name == self.get_bucket_name():\n            raise forms.ValidationError('Bucket name does not validate.')\n        return bucket_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the key in the provided data starts with the necessary prefix and that it exists in the bucket.", "response": "def clean_key_name(self):\n        \"\"\"Validates that the key in the provided data starts with the\n        required prefix, and that it exists in the bucket.\"\"\"\n        key = self.cleaned_data['key_name']\n        # Ensure key starts with prefix\n        if not key.startswith(self.get_key_prefix()):\n            raise forms.ValidationError('Key does not have required prefix.')\n        # Ensure key exists\n        if not self.get_upload_key():\n            raise forms.ValidationError('Key does not exist.')\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the full path to use for the processed file.", "response": "def get_processed_key_name(self):\n        \"\"\"Return the full path to use for the processed file.\"\"\"\n        if not hasattr(self, '_processed_key_name'):\n            path, upload_name = os.path.split(self.get_upload_key().name)\n            key_name = self._generate_processed_key_name(\n                self.process_to, upload_name)\n            self._processed_key_name = os.path.join(\n                self.get_storage().location, key_name)\n        return self._processed_key_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_processed_path(self):\n        location = self.get_storage().location\n        return self.get_processed_key_name()[len(location):]", "response": "Returns the processed file path from the storage backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_upload(self, set_content_type=True):\n        metadata = self.get_upload_key_metadata()\n\n        if set_content_type:\n            content_type = self.get_upload_content_type()\n            metadata.update({b'Content-Type': b'{0}'.format(content_type)})\n\n        upload_key = self.get_upload_key()\n        processed_key_name = self.get_processed_key_name()\n        processed_key = upload_key.copy(upload_key.bucket.name,\n                                        processed_key_name, metadata)\n        processed_key.set_acl(self.get_processed_acl())\n        upload_key.delete()\n        return processed_key", "response": "Process the uploaded file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_upload_content_type(self):\n        if not hasattr(self, '_upload_content_type'):\n            with self.get_storage().open(self.get_upload_path()) as upload:\n                content_type = Magic(mime=True).from_buffer(upload.read(1024))\n            self._upload_content_type = content_type\n        return self._upload_content_type", "response": "Determine the actual content type of the upload."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_upload_key(self):\n\n        if not hasattr(self, '_upload_key'):\n            self._upload_key = self.get_storage().bucket.get_key(\n                self.cleaned_data['key_name'])\n        return self._upload_key", "response": "Get the Key from the S3 bucket for the uploaded file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_upload_key_metadata(self):\n        key = self.get_upload_key()\n        metadata = key.metadata.copy()\n\n        # Some http header properties which are stored on the key need to be\n        # copied to the metadata when updating\n        headers = {\n            # http header name, key attribute name\n            'Cache-Control': 'cache_control',\n            'Content-Type': 'content_type',\n            'Content-Disposition': 'content_disposition',\n            'Content-Encoding': 'content_encoding',\n        }\n\n        for header_name, attribute_name in headers.items():\n            attribute_value = getattr(key, attribute_name, False)\n            if attribute_value:\n                metadata.update({b'{0}'.format(header_name):\n                                 b'{0}'.format(attribute_value)})\n        return metadata", "response": "Generate metadata dictionary from a bucket key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_upload_path(self):\n        location = self.get_storage().location\n        return self.cleaned_data['key_name'][len(location):]", "response": "Returns the uploaded file path from the storage backend."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_state(self, cache=True):\n        self.use_cached_state = cache\n\n        endpoint = API_SESAME_ENDPOINT.format(self._device_id)\n        response = self.account.request('GET', endpoint)\n        if response is None or response.status_code != 200:\n            return\n\n        state = json.loads(response.text)\n        self._nickname = state['nickname']\n        self._is_unlocked = state['is_unlocked']\n        self._api_enabled = state['api_enabled']\n        self._battery = state['battery']", "response": "Update the internal state of the Sesame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlocking the Sesame. Return True on success else False.", "response": "def lock(self):\n        \"\"\"Lock the Sesame. Return True on success, else False.\"\"\"\n        endpoint = API_SESAME_CONTROL_ENDPOINT.format(self.device_id)\n        payload = {'type': 'lock'}\n        response = self.account.request('POST', endpoint, payload=payload)\n        if response is None:\n            return False\n        if response.status_code == 200 or response.status_code == 204:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating or update the config file from a DataAPI object.", "response": "def write_config_from_api(self, api, config_file=None, profile=None):\n        '''\n        Create/update the config file from a DataAPI object\n\n        Parameters\n        ----------\n\n        api : object\n            The :py:class:`datafs.DataAPI` object from which\n            to create the config profile\n\n        profile : str\n            Name of the profile to use in the config file\n            (default \"default-profile\")\n\n        config_file : str or file\n            Path or file in which to write config (default\n            is your OS's default datafs application\n            directory)\n\n        Examples\n        --------\n\n        Create a simple API and then write the config to a\n        buffer:\n\n        .. code-block:: python\n\n            >>> from datafs import DataAPI\n            >>> from datafs.managers.manager_mongo import MongoDBManager\n            >>> from fs.osfs import OSFS\n            >>> from fs.tempfs import TempFS\n            >>> import os\n            >>> import tempfile\n            >>> import shutil\n            >>>\n            >>> api = DataAPI(\n            ...      username='My Name',\n            ...      contact = 'me@demo.com')\n            >>>\n            >>> manager = MongoDBManager(\n            ...     database_name = 'MyDatabase',\n            ...     table_name = 'DataFiles')\n            >>>\n            >>> manager.create_archive_table(\n            ...     'DataFiles',\n            ...     raise_on_err=False)\n            >>>\n            >>> api.attach_manager(manager)\n            >>>\n            >>> tmpdir = tempfile.mkdtemp()\n            >>> local = OSFS(tmpdir)\n            >>>\n            >>> api.attach_authority('local', local)\n            >>>\n            >>> # Create a StringIO object for the config file\n            ...\n            >>> try:\n            ...   from StringIO import StringIO\n            ... except ImportError:\n            ...   from io import StringIO\n            ...\n            >>> conf = StringIO()\n            >>>\n            >>> config_file = ConfigFile(default_profile='my-api')\n            >>> config_file.write_config_from_api(\n            ...     api,\n            ...     profile='my-api',\n            ...     config_file=conf)\n            >>>\n            >>> print(conf.getvalue())   # doctest: +SKIP\n            default-profile: my-api\n            profiles:\n              my-api:\n                api:\n                  user_config: {contact: me@demo.com, username: My Name}\n                authorities:\n                  local:\n                    args: [...]\n                    service: OSFS\n                    kwargs: {}\n                manager:\n                  args: []\n                  class: MongoDBManager\n                  kwargs:\n                    client_kwargs: {}\n                    database_name: MyDatabase\n                    table_name: DataFiles\n            <BLANKLINE>\n            >>> conf.close()\n            >>> local.close()\n            >>> shutil.rmtree(tmpdir)\n\n        At this point, we can retrieve the api object from\n        the configuration file:\n\n        .. code-block:: python\n\n            >>> try:\n            ...   from StringIO import StringIO\n            ... except ImportError:\n            ...   from io import StringIO\n            ...\n            >>> conf = StringIO(\"\"\"\n            ... default-profile: my-api\n            ... profiles:\n            ...   my-api:\n            ...     api:\n            ...       user_config: {contact: me@demo.com, username: My Name}\n            ...     authorities:\n            ...       local:\n            ...         args: []\n            ...         service: TempFS\n            ...         kwargs: {}\n            ...     manager:\n            ...       args: []\n            ...       class: MongoDBManager\n            ...       kwargs:\n            ...         client_kwargs: {}\n            ...         database_name: MyDatabase\n            ...         table_name: DataFiles\n            ... \"\"\")\n            >>>\n            >>> import datafs\n            >>> from fs.tempfs import TempFS\n            >>> api = datafs.get_api(profile='my-api', config_file=conf)\n            >>>\n            >>> cache = TempFS()\n            >>> api.attach_cache(cache)\n            >>>\n            >>> conf2 = StringIO()\n            >>>\n            >>> config_file = ConfigFile(default_profile='my-api')\n            >>> config_file.write_config_from_api(\n            ...     api,\n            ...     profile='my-api',\n            ...     config_file=conf2)\n            >>>\n            >>> print(conf2.getvalue())   # doctest: +SKIP\n            default-profile: my-api\n            profiles:\n              my-api:\n                api:\n                  user_config: {contact: me@demo.com, username: My Name}\n                authorities:\n                  local:\n                    args: []\n                    service: TempFS\n                    kwargs: {}\n                cache:\n                    args: []\n                    service: TempFS\n                    kwargs: {}\n                manager:\n                  args: []\n                  class: MongoDBManager\n                  kwargs:\n                    client_kwargs: {}\n                    database_name: MyDatabase\n                    table_name: DataFiles\n            <BLANKLINE>\n        '''\n\n        if profile is None:\n            profile = self.default_profile\n\n        self.get_config_from_api(api, profile)\n        self.write_config(config_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves pypirc file with new configuration information.", "response": "def save(self):\n        \"\"\"Saves pypirc file with new configuration information.\"\"\"\n        for server, conf in self.servers.iteritems():\n            self._add_index_server()\n            for conf_k, conf_v in conf.iteritems():\n                if not self.conf.has_section(server):\n                    self.conf.add_section(server)\n                self.conf.set(server, conf_k, conf_v)\n\n        with open(self.rc_file, 'wb') as configfile:\n            self.conf.write(configfile)\n        self.conf.read(self.rc_file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting index - servers current configured in pypirc.", "response": "def _get_index_servers(self):\n        \"\"\"Gets index-servers current configured in pypirc.\"\"\"\n        idx_srvs = []\n        if 'index-servers' in self.conf.options('distutils'):\n            idx = self.conf.get('distutils', 'index-servers')\n            idx_srvs = [srv.strip() for srv in idx.split('\\n') if srv.strip()]\n        return idx_srvs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_index_server(self):\n        index_servers = '\\n\\t'.join(self.servers.keys())\n        self.conf.set('distutils', 'index-servers', index_servers)", "response": "Adds index - server to distutil s index - servers param."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef TCA_select(bus, addr, channel):\r\n    if addr < 0x70 or addr > 0x77:\r\n        print(\"The TCA address(\" + str(addr) + \") is invalid. Aborting\")\r\n        return False\r\n    if channel == \"off\":\r\n        bus.write_byte(addr, 0)\r\n    elif channel < 0 or channel > 3:\r\n        print(\"The requested channel does not exist.\")\r\n        return False\r\n    else:\r\n        bus.write_byte(addr, 1 << channel)\r\n\r\n    status = bus.read_byte(addr)\r\n    return status", "response": "This function is used to select a specific channel on the TCA module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef IO_expander_output(bus, addr, bank, mask):\r\n    IODIR_map = [0x00, 0x01]\r\n    output_map = [0x14, 0x15]\r\n\r\n    if (bank != 0) and (bank != 1):\r\n        print()\r\n        raise InvalidIOUsage(\"An invalid IO bank has been selected\")\r\n\r\n\r\n    IO_direction = IODIR_map[bank]\r\n    output_reg = output_map[bank]\r\n\r\n    current_status = bus.read_byte_data(addr, output_reg)\r\n    if current_status == mask:\r\n        # This means nothing needs to happen\r\n        print(\"Current control status matches requested controls. \" +\r\n              \"No action is required.\")\r\n        return True\r\n\r\n    bus.write_byte_data(addr, IO_direction, 0)\r\n    bus.write_byte_data(addr, output_reg, mask)", "response": "This method writes to the specified address the specified mask to the specified bank of the expander."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_IO_reg(bus, addr, bank):\r\n    output_map = [0x14, 0x15]\r\n    if (bank != 0) and (bank != 1):\r\n        print()\r\n        raise InvalidIOUsage(\"An invalid IO bank has been selected\")\r\n\r\n    output_reg = output_map[bank]\r\n    current_status = bus.read_byte_data(addr, output_reg)\r\n    return current_status", "response": "Method retrieves the status of the IO bank in the specified address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nspeaking a sentence using Google TTS.", "response": "def speak(self, sentence):\n        \"\"\" Speak a sentence using Google TTS.\n        :param sentence: the sentence to speak.\n        \"\"\"\n        temp_dir = \"/tmp/\"\n        filename = \"gtts.mp3\"\n        file_path = \"{}/{}\".format(temp_dir, filename)\n\n        if not os.path.exists(temp_dir):\n            os.makedirs(temp_dir)\n\n        def delete_file():\n            try:\n                os.remove(file_path)\n                if not os.listdir(temp_dir):\n                    try:\n                        os.rmdir(temp_dir)\n                    except OSError:\n                        pass\n            except:\n                pass\n\n        if self.logger is not None:\n            self.logger.info(\"Google TTS: {}\".format(sentence))\n        tts = gTTS(text=sentence, lang=self.locale)\n        tts.save(file_path)\n        AudioPlayer.play_async(file_path, delete_file)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_lux_count(lux_byte):\r\n    LUX_VALID_MASK = 0b10000000\r\n    LUX_CHORD_MASK = 0b01110000\r\n    LUX_STEP_MASK = 0b00001111\r\n    valid = lux_byte & LUX_VALID_MASK\r\n    if valid != 0:\r\n        step_num = (lux_byte & LUX_STEP_MASK)\r\n        # Shift to normalize value\r\n        chord_num = (lux_byte & LUX_CHORD_MASK) >> 4\r\n        step_val = 2**chord_num\r\n        chord_val = int(16.5 * (step_val - 1))\r\n        count = chord_val + step_val * step_num\r\n        return count\r\n    else:\r\n        raise SensorError(\"Invalid lux sensor data.\")", "response": "Method to convert data from the TSL2550D lux sensor into more easily usable ADC count values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the current lux value of the device.", "response": "def update_lux(self, extend=0):\r\n        \"\"\" Communicates with the TSL2550D light sensor and returns a \r\n            lux value. \r\n\r\n        Note that this method contains approximately 1 second of total delay.\r\n            This delay is necessary in order to obtain full resolution\r\n            compensated lux values.\r\n\r\n        Alternatively, the device could be put in extended mode, \r\n            which drops some resolution in favor of shorter delays.\r\n\r\n        \"\"\"\r\n        DEVICE_REG_OUT = 0x1d\r\n        LUX_PWR_ON = 0x03\r\n        if extend == 1:\r\n            LUX_MODE = 0x1d\r\n            delay = .08\r\n            scale = 5\r\n        else:\r\n            LUX_MODE = 0x18\r\n            delay = .4\r\n            scale = 1\r\n        LUX_READ_CH0 = 0x43\r\n        LUX_READ_CH1 = 0x83\r\n        # Select correct I2C mux channel on TCA module\r\n\r\n        TCA_select(SensorCluster.bus, self.mux_addr, SensorCluster.lux_chan)\r\n        # Make sure lux sensor is powered up.\r\n        SensorCluster.bus.write_byte(SensorCluster.lux_addr, LUX_PWR_ON)\r\n        lux_on = SensorCluster.bus.read_byte_data(SensorCluster.lux_addr, LUX_PWR_ON)\r\n        \r\n        # Check for successful powerup\r\n        if (lux_on == LUX_PWR_ON):\r\n            # Send command to initiate ADC on each channel\r\n            # Read each channel after the new data is ready\r\n            SensorCluster.bus.write_byte(SensorCluster.lux_addr, LUX_MODE)\r\n            SensorCluster.bus.write_byte(SensorCluster.lux_addr, LUX_READ_CH0)\r\n            sleep(delay)\r\n            adc_ch0 = SensorCluster.bus.read_byte(SensorCluster.lux_addr)\r\n            count0 = get_lux_count(adc_ch0) * scale  # 5x for extended mode\r\n            SensorCluster.bus.write_byte(SensorCluster.lux_addr, LUX_READ_CH1)\r\n            sleep(delay)\r\n            adc_ch1 = SensorCluster.bus.read_byte(SensorCluster.lux_addr)\r\n            count1 = get_lux_count(adc_ch1) * scale  # 5x for extended mode\r\n            ratio = count1 / (count0 - count1)\r\n            lux = (count0 - count1) * .39 * e**(-.181 * (ratio**2))\r\n            self.light_ratio = float(count1)/float(count0)\r\n            print(\"Light ratio Ch1/Ch0: \", self.light_ratio)\r\n            self.lux = round(lux, 3)\r\n            return TCA_select(SensorCluster.bus, self.mux_addr, \"off\")\r\n        else:\r\n            raise SensorError(\"The lux sensor is powered down.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_humidity_temp(self):\r\n        # Create mask for STATUS (first two bits of 64 bit wide result)\r\n        STATUS = 0b11 << 6\r\n\r\n        TCA_select(SensorCluster.bus, self.mux_addr, SensorCluster.humidity_chan)\r\n        SensorCluster.bus.write_quick(SensorCluster.humidity_addr)  # Begin conversion\r\n        sleep(.25)\r\n        # wait 100ms to make sure the conversion takes place.\r\n        data = SensorCluster.bus.read_i2c_block_data(SensorCluster.humidity_addr, 0, 4)\r\n        status = (data[0] & STATUS) >> 6\r\n        \r\n        if status == 0 or status == 1:  # will always pass for now.\r\n            humidity = round((((data[0] & 0x3f) << 8) |\r\n                              data[1]) * 100.0 / (2**14 - 2), 3)\r\n            self.humidity = humidity\r\n            self.temp = (round((((data[2] << 6) + ((data[3] & 0xfc) >> 2))\r\n                               * 165.0 / 16382.0 - 40.0), 3) * 9/5) + 32\r\n            return TCA_select(SensorCluster.bus, self.mux_addr, \"off\")\r\n        else:\r\n            raise I2CBusError(\"Unable to retrieve humidity\")", "response": "This method uses the sensor to read the current humidity and temperature and updates the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_soil_moisture(self):\r\n        SensorCluster.analog_sensor_power(SensorCluster.bus, \"on\")  # turn on sensor\r\n        sleep(.2)\r\n        TCA_select(SensorCluster.bus, self.mux_addr, SensorCluster.adc_chan)\r\n        moisture = get_ADC_value(\r\n            SensorCluster.bus, SensorCluster.adc_addr, SensorCluster.moisture_chan)\r\n        status = TCA_select(SensorCluster.bus, self.mux_addr, \"off\")  # Turn off mux.\r\n        SensorCluster.analog_sensor_power(SensorCluster.bus, \"off\")  # turn off sensor\r\n        if (moisture >= 0):\r\n            soil_moisture = moisture/2.048 # Scale to a percentage value \r\n            self.soil_moisture = round(soil_moisture,3)\r\n        else:\r\n            raise SensorError(\r\n                \"The soil moisture meter is not configured correctly.\")\r\n        return status", "response": "Method will select the ADC module and turn off the sensor and then scale the soil moisture meter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sensor_values(self):\r\n        self.update_instance_sensors(opt=\"all\")\r\n        return {\r\n            \"light\": self.lux,\r\n            \"water\": self.soil_moisture,\r\n            \"humidity\": self.humidity,\r\n            \"temperature\": self.temp\r\n        }", "response": "Returns a dictionary of values for all sensors in this cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_water_level(cls):\r\n        # ----------\r\n        # These values should be updated based on the real system parameters\r\n        vref = 4.95\r\n        tank_height = 17.5 # in centimeters (height of container)\r\n        rref = 2668  # Reference resistor\r\n        # ----------\r\n        val = 0\r\n        for i in range(5):\r\n            # Take five readings and do an average\r\n            # Fetch value from ADC (0x69 - ch1)\r\n            val = get_ADC_value(cls.bus, 0x6c, 1) + val\r\n        avg = val / 5\r\n        water_sensor_res = rref * avg/(vref - avg)\r\n        depth_cm = water_sensor_res * \\\r\n                    (-.0163) + 28.127 # measured transfer adjusted offset\r\n        if depth_cm < 1.0: # Below 1cm, the values should not be trusted.\r\n            depth_cm = 0\r\n        cls.water_remaining = depth_cm / tank_height\r\n        # Return the current depth in case the user is interested in\r\n        #   that parameter alone. (IE for automatic shut-off)\r\n        return depth_cm/tank_height", "response": "This method returns the current water tank level and the remaining in the tank."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nincrement the version and return the new version.", "response": "def bump(self, kind=None, prerelease=None, inplace=True):\n        '''\n        Increment the version and/or pre-release value\n\n        Parameters\n        ----------\n\n        kind : str\n            Increment the version. Can be ``major``, ``minor``, or ``patch``,\n            corresponding to the three segments of the version number (in\n            order). A value of ``None`` will not increment the version number\n            (default).\n\n        prerelease : str\n            Increment the version's pre-release value. Can be ``alpha`` or\n            ``beta``. A prerelease value of ``None`` will remove a pre-release\n            value if it exists (default).\n\n        inplace : bool\n            If false, returns a new ``BumpableVersion`` instance. If ``True``\n            (default), bumps the version in place.\n\n\n        Examples\n        --------\n\n        The ``kind`` argument increments the version:\n\n        .. code-block:: python\n\n            >>> v = BumpableVersion('1.0.1')\n            >>> v.bump('patch')\n            >>> v\n            BumpableVersion ('1.0.2')\n            >>>\n            >>> v.bump('minor')\n            >>> v\n            BumpableVersion ('1.1')\n            >>>\n            >>> v.bump('minor')\n            >>> v\n            BumpableVersion ('1.2')\n            >>>\n            >>> v.bump('major')\n            >>> v\n            BumpableVersion ('2.0')\n            >>>\n            >>> v.bump('release')   # doctest: +ELLIPSIS\n            Traceback (most recent call last):\n            ValueError: Bump kind \"release\" not understood\n\n        The prerelease argument increments the pre-release value. If ``kind``\n        is not supplied simultaneously the version is bumped with a patch\n        before entering pre-release:\n\n        .. code-block:: python\n\n            >>> v = BumpableVersion('1.0.0')\n            >>> v.bump(prerelease='alpha')\n            >>> v\n            BumpableVersion ('1.0.1a1')\n            >>>\n            >>> v.bump(prerelease='alpha')\n            >>> v\n            BumpableVersion ('1.0.1a2')\n            >>>\n            >>> v.bump(prerelease='beta')\n            >>> v\n            BumpableVersion ('1.0.1b1')\n            >>>\n            >>> v.bump('minor')\n            >>> v\n            BumpableVersion ('1.1')\n            >>>\n            >>> v.bump('minor', prerelease='beta')\n            >>> v\n            BumpableVersion ('1.2b1')\n            >>>\n            >>> v.bump(prerelease='beta')\n            >>> v\n            BumpableVersion ('1.2b2')\n            >>>\n            >>> v.bump('minor')\n            >>> v\n            BumpableVersion ('1.2')\n            >>>\n            >>> v.bump('minor', prerelease='beta')\n            >>> v\n            BumpableVersion ('1.3b1')\n            >>>\n            >>> v.bump('major', prerelease='alpha')\n            >>> v\n            BumpableVersion ('2.0a1')\n            >>>\n            >>> v.bump('major')\n            >>> v\n            BumpableVersion ('3.0')\n            >>>\n            >>> v.bump('patch', prerelease='beta')\n            >>> v\n            BumpableVersion ('3.0.1b1')\n            >>>\n            >>> v.bump('patch')\n            >>> v\n            BumpableVersion ('3.0.1')\n            >>>\n            >>> v.bump(prerelease='gamma')   # doctest: +ELLIPSIS\n            Traceback (most recent call last):\n            ValueError: Prerelease type \"gamma\" not understood\n\n        Releases cannot move from beta to alpha without a new major/minor/patch\n        bump:\n\n        .. code-block:: python\n\n            >>> v = BumpableVersion('0.2b1')\n            >>> v.bump(prerelease='alpha')    # doctest: \\\n            +ELLIPSIS +NORMALIZE_WHITESPACE\n            Traceback (most recent call last):\n            ...\n            ValueError: Cannot bump version \"0.2b1\" to prerelease stage \\\n            \"alpha\" - version already in beta\n            >>> v.bump('minor')\n            >>> v\n            BumpableVersion ('0.2')\n            >>>\n\n\n        Versions can return a new version or can be bumped in-place (default):\n\n        .. code-block:: python\n\n            >>> v = BumpableVersion('0.2')\n            >>> v.bump('minor', inplace=False)\n            BumpableVersion ('0.3')\n            >>> v\n            BumpableVersion ('0.2')\n\n        '''\n\n        if kind is not None:\n\n            # if already in pre-release and we want to move to pre-release,\n            # increment version + prerelease\n            if self.prerelease and prerelease:\n                new_prerelease = self._increment_prerelease(None, prerelease)\n                new_version = self._increment_version(self.version, kind)\n\n            # if already in pre-release and we want to exit pre-release,\n            # remove prerelease\n            elif self.prerelease:\n                new_prerelease = None\n                if self.version[2] == 0:\n                    if kind == 'minor':\n                        new_version = self.version\n                    else:\n                        new_version = self._increment_version(\n                            self.version, kind)\n                else:\n                    if kind == 'patch':\n                        new_version = self.version\n                    else:\n                        new_version = self._increment_version(\n                            self.version, kind)\n\n            else:\n                new_prerelease = self._increment_prerelease(None, prerelease)\n                new_version = self._increment_version(self.version, kind)\n\n        elif prerelease is not None:\n            if self.prerelease:\n                new_prerelease = self._increment_prerelease(\n                    self.prerelease, prerelease)\n                new_version = self.version\n\n            else:\n                new_prerelease = self._increment_prerelease(None, prerelease)\n                new_version = self._increment_version(self.version, 'patch')\n\n        else:\n            # default is bump patch\n\n            new_prerelease = None\n            new_version = self._increment_version(self.version, 'patch')\n\n        if inplace:\n            self.version = new_version\n            self.prerelease = new_prerelease\n\n        else:\n            new = BumpableVersion()\n            new.version = new_version\n            new.prerelease = new_prerelease\n\n            return new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve a dotted path into a symbol and return that.", "response": "def _imported_symbol(import_path):\n    \"\"\"Resolve a dotted path into a symbol, and return that.\n\n    For example...\n\n    >>> _imported_symbol('django.db.models.Model')\n    <class 'django.db.models.base.Model'>\n\n    Raise ImportError if there's no such module, AttributeError if no\n    such symbol.\n\n    \"\"\"\n    module_name, symbol_name = import_path.rsplit('.', 1)\n    module = import_module(module_name)\n    return getattr(module, symbol_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a parameter in the order they appear in the key - value section.", "response": "def Param(name, value=None, unit=None, ucd=None, dataType=None, utype=None,\n          ac=True):\n    \"\"\"\n    'Parameter', used as a general purpose key-value entry in the 'What' section.\n\n    May be assembled into a :class:`Group`.\n\n    NB ``name`` is not mandated by schema, but *is* mandated in full spec.\n\n    Args:\n        value(str): String representing parameter value.\n            Or, if ``ac`` is true, then 'autoconversion' is attempted, in which case\n            ``value`` can also be an instance of one of the following:\n\n             * :py:obj:`bool`\n             * :py:obj:`int`\n             * :py:obj:`float`\n             * :py:class:`datetime.datetime`\n\n            This allows you to create Params without littering your code\n            with string casts, or worrying if the passed value is a float or a\n            string, etc.\n            NB the value is always *stored* as a string representation,\n            as per VO spec.\n        unit(str): Units of value. See :class:`.definitions.units`\n        ucd(str): `unified content descriptor <http://arxiv.org/abs/1110.0525>`_.\n            For a list of valid UCDs, see:\n            http://vocabularies.referata.com/wiki/Category:IVOA_UCD.\n        dataType(str): Denotes type of ``value``; restricted to 3 options:\n            ``string`` (default), ``int`` , or ``float``.\n            (NB *not* to be confused with standard XML Datatypes, which have many\n            more possible values.)\n        utype(str): See http://wiki.ivoa.net/twiki/bin/view/IVOA/Utypes\n        ac(bool): Attempt automatic conversion of passed ``value`` to string,\n            and set ``dataType`` accordingly (only attempted if ``dataType``\n            is the default, i.e. ``None``).\n            (NB only supports types listed in _datatypes_autoconversion dict)\n\n    \"\"\"\n    # We use locals() to allow concise looping over the arguments.\n    atts = locals()\n    atts.pop('ac')\n    temp_dict = {}\n    temp_dict.update(atts)\n    for k in temp_dict.keys():\n        if atts[k] is None:\n            del atts[k]\n    if (ac\n        and value is not None\n        and (not isinstance(value, string_types))\n        and dataType is None\n        ):\n        if type(value) in _datatypes_autoconversion:\n            datatype, func = _datatypes_autoconversion[type(value)]\n            atts['dataType'] = datatype\n            atts['value'] = func(value)\n    return objectify.Element('Param', attrib=atts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngroups together Params for adding under the What section.", "response": "def Group(params, name=None, type=None):\n    \"\"\"Groups together Params for adding under the 'What' section.\n\n    Args:\n        params(list of :func:`Param`): Parameter elements to go in this group.\n        name(str): Group name. NB ``None`` is valid, since the group may be\n            best identified by its type.\n        type(str): Type of group, e.g. 'complex' (for real and imaginary).\n    \"\"\"\n    atts = {}\n    if name:\n        atts['name'] = name\n    if type:\n        atts['type'] = type\n    g = objectify.Element('Group', attrib=atts)\n    for p in params:\n        g.append(p)\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an ElementTree element representing the external information referenced by the given resource identifier.", "response": "def Reference(uri, meaning=None):\n    \"\"\"\n    Represents external information, typically original obs data and metadata.\n\n    Args:\n        uri(str): Uniform resource identifier for external data, e.g. FITS file.\n        meaning(str): The nature of the document referenced, e.g. what\n            instrument and filter was used to create the data?\n    \"\"\"\n    attrib = {'uri': uri}\n    if meaning is not None:\n        attrib['meaning'] = meaning\n    return objectify.Element('Reference', attrib)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrepresents a probable cause between this event and some prior.", "response": "def Inference(probability=None, relation=None, name=None, concept=None):\n    \"\"\"Represents a probable cause / relation between this event and some prior.\n\n    Args:\n        probability(float): Value 0.0 to 1.0.\n        relation(str): e.g. 'associated' or 'identified' (see Voevent spec)\n        name(str): e.g. name of identified progenitor.\n        concept(str): One of a 'formal UCD-like vocabulary of astronomical\n            concepts', e.g. http://ivoat.ivoa.net/stars.supernova.Ia - see\n            VOEvent spec.\n    \"\"\"\n    atts = {}\n    if probability is not None:\n        atts['probability'] = str(probability)\n    if relation is not None:\n        atts['relation'] = relation\n    inf = objectify.Element('Inference', attrib=atts)\n    if name is not None:\n        inf.Name = name\n    if concept is not None:\n        inf.Concept = concept\n    return inf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef EventIvorn(ivorn, cite_type):\n    # This is an ugly hack around the limitations of the  lxml.objectify API:\n    c = objectify.StringElement(cite=cite_type)\n    c._setText(ivorn)\n    c.tag = \"EventIVORN\"\n    return c", "response": "Used to cite earlier VOEvents."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Citation(ivorn, cite_type):\n    import warnings\n    warnings.warn(\n        \"\"\"\n        `Citation` class has been renamed `EventIvorn` to reflect naming\n        conventions in the VOEvent standard.\n        As such this class name is a deprecated alias and may be removed in a\n        future release.\n        \"\"\",\n        FutureWarning)\n    return EventIvorn(ivorn, cite_type)", "response": "Return an event object for the given ivorn and cite type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef batch(self, source_id, data):\n        if type(data) is not list or type(data[0]) is not dict:\n            raise BadRequest(\"Ingestion data must be a list of dicts\")\n        data = \"\\r\\n\".join(map(json.dumps, data))\n        return self.request.post(source_id, data, {'Accept-Encoding': 'application/text'})", "response": "Uploads data to the given source"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new PackageVersion from a requirement. Handles errors.", "response": "def create_package_version(requirement):\n    \"\"\"Create a new PackageVersion from a requirement. Handles errors.\"\"\"\n    try:\n        PackageVersion(requirement=requirement).save()\n        logger.info(\"Package '%s' added.\", requirement.name)  # noqa\n    except IntegrityError:\n        logger.info(\"Package '%s' already exists.\", requirement.name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading local requirements file.", "response": "def local():\n    \"\"\"Load local requirements file.\"\"\"\n    logger.info(\"Loading requirements from local file.\")\n    with open(REQUIREMENTS_FILE, 'r') as f:\n        requirements = parse(f)\n        for r in requirements:\n            logger.debug(\"Creating new package: %r\", r)\n            create_package_version(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remote():\n    logger.info(\"Fetching latest data from PyPI.\")\n    results = defaultdict(list)\n    packages = PackageVersion.objects.exclude(is_editable=True)\n    for pv in packages:\n        pv.update_from_pypi()\n        results[pv.diff_status].append(pv)\n        logger.debug(\"Updated package from PyPI: %r\", pv)\n    results['refreshed_at'] = tz_now()\n    return results", "response": "Update package info from PyPI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(self, *args, **options):\n        if options['clean']:\n            clean()\n\n        if options['local']:\n            local()\n\n        if options['remote']:\n            results = remote()\n            render = lambda t: render_to_string(t, results)\n            if options['notify']:\n                send_mail(\n                    options['subject'],\n                    render('summary.txt'),\n                    options['from'],\n                    [options['notify']],\n                    html_message=render('summary.html'),\n                    fail_silently=False,\n                )", "response": "Run the managemement command."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new hitorics preview job.", "response": "def create(self, stream, start, parameters, sources, end=None):\n        \"\"\" Create a hitorics preview job.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/previewcreate\n\n            :param stream: hash of the CSDL filter to create the job for\n            :type stream: str\n            :param start: Unix timestamp for the start of the period\n            :type start: int\n            :param parameters: list of historics preview parameters, can be found at http://dev.datasift.com/docs/api/rest-api/endpoints/previewcreate\n            :type parameters: list\n            :param sources: list of sources to include, eg. ['tumblr','facebook']\n            :type sources: list\n            :param end: (optional) Unix timestamp for the end of the period, defaults to min(start+24h, now-1h)\n            :type end: int\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.HistoricSourcesRequired`, :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        if len(sources) == 0:\n            raise HistoricSourcesRequired()\n        if isinstance(sources, six.string_types):\n            sources = [sources]\n        params = {'hash': stream, 'start': start, 'sources': ','.join(sources), 'parameters': ','.join(parameters)}\n        if end:\n            params['end'] = end\n        return self.request.post('create', params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, preview_id):\n        return self.request.get('get', params=dict(id=preview_id))", "response": "Retrieve a Historics preview job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare(self, hash, start, end, name, sources, sample=None):\n        if len(sources) == 0:\n            raise HistoricSourcesRequired()\n        if not isinstance(sources, list):\n            sources = [sources]\n\n        params = {'hash': hash, 'start': start, 'end': end, 'name': name, 'sources': ','.join(sources)}\n        if sample:\n            params['sample'] = sample\n        return self.request.post('prepare', params)", "response": "Prepares a new entry in the list of sources for a given key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self, historics_id):\n        return self.request.post('start', data=dict(id=historics_id))", "response": "Starts the given historics job with the given ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the name of the given Historics query.", "response": "def update(self, historics_id, name):\n        \"\"\" Update the name of the given Historics query.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/historicsupdate\n\n            :param historics_id: playback id of the job to start\n            :type historics_id: str\n            :param name: new name of the stream\n            :type name: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self.request.post('update', data=dict(id=historics_id, name=name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping an existing Historics job.", "response": "def stop(self, historics_id, reason=''):\n        \"\"\" Stop an existing Historics query.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/historicsstop\n\n            :param historics_id: playback id of the job to stop\n            :type historics_id: str\n            :param reason: optional reason for stopping the job\n            :type reason: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self.request.post('stop', data=dict(id=historics_id, reason=reason))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the data coverage in the Historics archive for a given interval.", "response": "def status(self, start, end, sources=None):\n        \"\"\" Check the data coverage in the Historics archive for a given interval.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/historicsstatus\n\n            :param start: Unix timestamp for the start time\n            :type start: int\n            :param end: Unix timestamp for the start time\n            :type end: int\n            :param sources: list of data sources to include.\n            :type sources: list\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        params = {'start': start, 'end': end}\n        if sources:\n            params['sources'] = ','.join(sources)\n        return self.request.get('status', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, historics_id):\n        return self.request.post('delete', data=dict(id=historics_id))", "response": "Delete one specified playback query."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the historical query for the given ID", "response": "def get_for(self, historics_id, with_estimate=None):\n        \"\"\" Get the historic query for the given ID\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/historicsget\n\n            :param historics_id: playback id of the query\n            :type historics_id: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self.get(historics_id, maximum=None, page=None, with_estimate=with_estimate)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, historics_id=None, maximum=None, page=None, with_estimate=None):\n        params = {'id': historics_id}\n        if maximum:\n            params['max'] = maximum\n        if page:\n            params['page'] = page\n\n        params['with_estimate'] = 1 if with_estimate else 0\n        return self.request.get('get', params=params)", "response": "Get the historics query with the given ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pause(self, historics_id, reason=\"\"):\n        params = {\"id\": historics_id}\n        if reason != \"\":\n            params[\"reason\"] = reason\n        return self.request.post('pause', data=params)", "response": "Pause an existing Historics query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresuming a paused Historics query.", "response": "def resume(self, historics_id):\n        \"\"\" Resume a paused Historics query.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/historicsresume\n\n            :param historics_id: id of the job to resume\n            :type historics_id: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self.request.post('resume', data=dict(id=historics_id))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, source_id, resource_ids):\n        params = {'id': source_id, 'resource_ids': resource_ids}\n        return self.request.post('remove', params)", "response": "Removes one or more resources from a Managed Source ID\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds one or more authorization credentials to a Managed Source ID", "response": "def add(self, source_id, auth, validate=True):\n        \"\"\" Add one or more sets of authorization credentials to a Managed Source\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/sourceauthadd\n\n            :param source_id: target Source ID\n            :type source_id: str\n            :param auth: An array of the source-specific authorization credential sets that you're adding.\n            :type auth: array of strings\n            :param validate: Allows you to suppress the validation of the authorization credentials, defaults to true.\n            :type validate: bool\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        params = {'id': source_id, 'auth': auth, 'validate': validate}\n        return self.request.post('add', params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, source_id, auth_ids):\n        params = {'id': source_id, 'auth_ids': auth_ids}\n        return self.request.post('remove', params)", "response": "Removes one or more authorization credentials from a Managed Source."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a managed source with the given parameters", "response": "def create(self, source_type, name, resources, auth=None, parameters=None, validate=True):\n        \"\"\" Create a managed source\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/sourcecreate\n\n            :param source_type: data source name e.g. facebook_page, googleplus, instagram, yammer\n            :type source_type: str\n            :param name: name to use to identify the managed source being created\n            :type name: str\n            :param resources: list of source-specific config dicts\n            :type resources: list\n            :param auth: list of source-specific authentication dicts\n            :type auth: list\n            :param parameters: (optional) dict with config information on how to treat each resource\n            :type parameters: dict\n            :param validate: bool to determine if validation should be performed on the source\n            :type validate: bool\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        assert resources, \"Need at least one resource\"\n\n        params = {\n            'source_type': source_type,\n            'name': name,\n            'resources': resources,\n            'validate': validate\n        }\n\n        if auth:\n            params['auth'] = auth\n        if parameters:\n            params['parameters'] = parameters\n\n        return self.request.post('create', params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, source_id, source_type, name, resources, auth, parameters=None, validate=True):\n        assert resources, \"Need at least one resource\"\n        assert auth, \"Need at least one authentication token\"\n        params = {'id': source_id, 'source_type': source_type, 'name': name, 'resources': resources, 'auth': auth, 'validate': validate}\n        if parameters:\n            params['parameters'] = parameters\n\n        return self.request.post('update', params)", "response": "Update a managed source s properties"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log(self, source_id, page=None, per_page=None):\n        params = {'id': source_id}\n        if page:\n            params['page'] = page\n        if per_page:\n            params['per_page'] = per_page\n\n        return self.request.get('log', params=params)", "response": "Get the log for a specific Managed Source."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, source_id=None, source_type=None, page=None, per_page=None):\n        params = {}\n        if source_type:\n            params['source_type'] = source_type\n        if source_id:\n            params['id'] = source_id\n        if page:\n            params['page'] = page\n        if per_page:\n            params['per_page'] = per_page\n\n        return self.request.get('get', params=params)", "response": "Get a specific managed source or a list of them."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(self, localArray):\n\n        # input dist array\n        inp = gdaZeros(localArray.shape, localArray.dtype, numGhosts=1)\n        # output array\n        out = numpy.zeros(localArray.shape, localArray.dtype)\n\n        # no displacement term\n        weight = self.stencil[self.zeros]\n        out[...] += weight * localArray\n\n        for disp in self.srcLocalDomains:\n\n            weight = self.stencil[disp]\n\n            # no communication required here\n            srcDom = self.srcLocalDomains[disp]\n            dstDom = self.dstLocalDomains[disp]\n\n            out[dstDom] += weight * localArray[srcDom]\n\n            #\n            # now the part that requires communication\n            #\n\n            # set the ghost values\n            srcSlab = self.srcSlab[disp]\n            # copy\n            inp[srcSlab] = localArray[srcSlab]\n\n            # send over to local process\n            dstSlab = self.dstSlab[disp]\n            winId = self.winIds[disp]\n            rk = self.neighRk[disp]\n\n            # remote fetch\n            out[dstSlab] += weight * inp.getData(rk, winId)\n\n        # some implementations require this\n        inp.free()\n\n        return out", "response": "Apply Laplacian stencil to data\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging in Naver and get cookie", "response": "def login(self, user_id, password, svctype = \"Android NDrive App ver\", auth = 0):\n        \"\"\"Log in Naver and get cookie\n\n        Agrs:\n            user_id: Naver account's login id\n            password: Naver account's login password\n\n        Returns:\n            True: Login success\n            False: Login failed\n\n        Remarks:\n            self.cookie is a dictionary with 5 keys: path, domain, NID_AUT, nid_inf, NID_SES\n        \"\"\"\n        self.user_id = user_id\n        self.password = password\n\n        if self.user_id == None or self.password == None:\n            print \"[*] Error __init__: user_id and password is needed\"\n            return False\n\n        try:\n            cookie = naver_login(user_id, password)\n        except:\n            return False\n\n        self.session.cookies.set('NID_AUT', cookie[\"NID_AUT\"])\n        self.session.cookies.set('NID_SES', cookie[\"NID_SES\"])\n\n        s = self.getRegisterUserInfo(svctype, auth)\n\n        if s is True:\n            return True\n        else:\n            print \"[*] Error getRegisterUserInfo: failed\"\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the user info of the current user in the system", "response": "def getRegisterUserInfo(self, svctype = \"Android NDrive App ver\", auth = 0):\n        \"\"\"Get registerUserInfo\n\n        Args:\n            svctype: Platform information\n            auth: ???\n\n        Returns:\n            True: Success\n            False: Failed\n\n        \"\"\"\n        data = {'userid': self.user_id, 'svctype': svctype, 'auth': auth}\n        r = self.session.get(nurls['getRegisterUserInfo'], params = data)\n\n        j = json.loads(r.text)\n\n        if j['message'] != 'success':\n            print \"[*] Error getRegisterUserInfo: \" + j['message']\n            return False\n\n        else:\n            self.useridx = j['resultvalue']['useridx']\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking status of the user", "response": "def checkStatus(self):\n        \"\"\"Check status\n\n        Args:\n\n        Returns:\n            True: Sucess\n            False: Failed\n\n        \"\"\"\n        checkAccount()\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx\n               }\n        r = self.session.post(nurls['checkStatus'], data = data)\n\n        p = re.compile(r'\\<message\\>(?P<message>.+)\\</message\\>')\n        message = p.search(r.text).group('message')\n\n        if message == 'success':\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a file to the Ndrive server.", "response": "def uploadFile(self, file_path, upload_path = '', overwrite = False):\n        \"\"\"uploadFile\n\n        Remarks:\n            How Ndrive uploads a file to its server:\n                1. POST /CheckStatus.ndrive\n                2. POST /GetDiskSpace.ndrive\n                3. POST /CheckUpload.ndrive\n                4. PUT /FILE_PATH\n                5. POST /GetList.ndrive\n                6. POST /GetWasteInfo.ndrive\n                7. POST /GetDiskSpace.ndrive\n        \"\"\"\n        s = self.checkStatus()\n        s = self.getDiskSpace()\n        s = self.checkUpload(file_path, upload_path, overwrite)\n\n        if s is True:\n            self.put(file_path, upload_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getDiskSpace(self, file_path, upload_path = '', overwrite = False):\n\n        self.checkAccount()\n\n        url = nurls['checkUpload']\n\n        file_size = os.stat(file_path).st_size\n        file_name = os.path.basename(file_path)\n\n        now = datetime.datetime.now().isoformat()\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'getlastmodified': now,\n                'dstresource': upload_path + file_name,\n                'overwrite': overwrite,\n                'uploadsize': file_size,\n               }\n        r = self.session.post(nurls['getDiskSpace'], data = data)\n\n        return resultManager(r.text)", "response": "This method returns the disk space of a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(self, file_path, upload_path = ''):\n        f = open(file_path, \"r\")\n        c = f.read()\n\n        file_name = os.path.basename(file_path)\n\n        now = datetime.datetime.now().isoformat()\n        url = nurls['put'] + upload_path + file_name\n\n        headers = {'userid': self.user_id,\n                   'useridx': self.useridx,\n                   'MODIFYDATE': now,\n                   'Content-Type': magic.from_file(file_path, mime=True),\n                   'charset': 'UTF-8',\n                   'Origin': 'http://ndrive2.naver.com',\n        }\n        r = self.session.put(url = url, data = c, headers = headers)\n\n        return self.resultManager(r.text)", "response": "Uploads a file to Ndrive"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a file in Ndrive", "response": "def delete(self, file_path):\n        \"\"\"DELETE\n\n        Args:\n            file_path: Full path for a file you want to delete \n            upload_path: Ndrive path where you want to delete file\n                ex) /Picture/\n\n        Returns:\n            True: Delete success\n            False: Delete failed\n\n        \"\"\"\n        now = datetime.datetime.now().isoformat()\n        url = nurls['put'] + upload_path + file_name\n\n        headers = {'userid': self.user_id,\n                   'useridx': self.useridx,\n                   'Content-Type': \"application/x-www-form-urlencoded; charset=UTF-8\",\n                   'charset': 'UTF-8',\n                   'Origin': 'http://ndrive2.naver.com',\n        }\n        r = self.session.delete(url = url, headers = headers)\n\n        return self.resultManager(r.text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget list of files for a user", "response": "def getList(self, dummy = 56184, orgresource = '/', type = 1, dept = 0, sort = 'name', order = 'asc', startnum = 0, pagingrow = 1000):\n        \"\"\"GetList\n\n        Args:\n            dummy: ???\n            orgresource: Directory path to get the file list\n                ex) /Picture/\n\n            type: 1 => only directories with idxfolder property\n                  2 => only files\n                  3 => directories and files with thumbnail info\n                      ex) viewHeight, viewWidth for Image file\n                  4 => only directories except idxfolder\n                  5 => directories and files without thumbnail info\n\n            depth: Dept for file list\n            sort: name => \uc774\ub984\n                  file => file type, \uc885\ub958\n                  length => size of file, \ud06c\uae30\n                  date => edited date, \uc218\uc815\ud55c \ub0a0\uc9dc\n                  credate => creation date, \uc62c\ub9b0 \ub0a0\uc9dc\n                  protect => protect or not, \uc911\uc694 \ud45c\uc2dc\n\n            order: Order by (asc, desc)\n            startnum: ???\n            pagingrow: start index ?\n\n        Returns:\n            FileInfo list: List of files for a path\n            False: Failed to get list\n\n        \"\"\"\n        \n        url = nurls['getList']\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                'orgresource': orgresource,\n                'type': type,\n                'dept': dept,\n                'sort': sort,\n                'order': order,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                }\n\n        r = self.session.post(url = url, data = data)\n\n        try:\n            j = json.loads(r.text)\n        except:\n            print '[*] Success checkUpload: 0 result'\n\n            return []\n\n        if j['message'] != 'success':\n            print '[*] Error checkUpload: ' + j['message']\n\n            return False\n        else:\n            files = []\n\n            for i in j['resultvalue']:\n                f = FileInfo()\n\n                f.protect = i['protect']\n                f.resourceno = i['resourceno']\n                f.copyright = i['copyright']\n                f.subfoldercnt = i['subfoldercnt']\n                f.resourcetype = i['resourcetype']\n                f.fileuploadstatus = i['fileuploadstatus']\n                f.prority = i['priority']\n                f.filelink = i['filelink']\n                f.href = i['href']\n                f.thumbnailpath = i['thumbnailpath']\n                f.sharedinfo = i['sharedinfo']\n                f.getlastmodified = i['getlastmodified']\n                f.shareno = i['shareno']\n                f.lastmodifieduser = i['lastmodifieduser']\n                f.getcontentlength = i['getcontentlength']\n                f.lastaccessed = i['lastaccessed']\n                f.virusstatus = i['virusstatus']\n                f.idxfolder = i['idxfolder']\n                f.creationdate = i['creationdate']\n                f.nocache = i['nocache']\n                f.viewWidth = i['viewWidth']\n                f.viewHeight = i['viewHeight']\n\n                f.setJson(j['resultvalue'])\n                \n                files.append(f)\n\n            return files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef doMove(self, orgresource, dstresource, dummy = 56184, stresource = 'F', bShareFireCopy = 'false'):\n\n        url = nurls['doMove']\n        \n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                'orgresource': orgresource,\n                'dstresource': dstresource,\n                'overwrite': overwrite,\n                'bShareFireCopy': bShareFireCopy,\n                }\n\n        r = self.session.post(url = url, data = data)\n\n        try:\n            j = json.loads(r.text)\n        except:\n            print '[*] Success checkUpload: 0 result'\n\n            return False\n\n        return self.resultManager(r.text)", "response": "This method is used to move a file from one location to another."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getProperty(self, orgresource, dummy = 56184):\n\n        url = nurls['getProperty']\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                'orgresource': orgresource,\n                }\n\n        r = self.session.post(url = url, data = data)\n        j = json.loads(r.text)\n\n        if self.resultManager(r.text):\n            f = FileInfo()\n            result = j['resultvalue']\n\n            f.resourcetype = result['resourcetype']\n            f.resourceno = result['resourceno']\n\n            return f\n\n        else:\n            return False", "response": "Get the properties of a file in a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the number of version list of a specific resource", "response": "def getVersionListCount(self, orgresource):\n        \"\"\"GetVersionListCount\n\n        Args:\n            orgresource: File path\n\n        Returns:\n            Integer number: # of version list\n            False: Failed to get property\n\n        \"\"\"\n\n        url = nurls['getVersionListCount']\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'orgresource': orgresource,\n                }\n\n        r = self.session.post(url = url, data = data)\n        j = json.loads(r.text)\n\n        if j['message'] != 'success':\n            print \"[*] Error getVersionListCount: \" + j['message']\n            return False\n        else:\n            return int(j['resultvalue']['count'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the property of the user in the nagios user.", "response": "def setProperty(self, orgresource, protect, dummy = 7046):\n        \"\"\"SetProperty\n\n        Args:\n            orgresource: File path\n            protect: 'Y' or 'N', \uc911\uc694 \ud45c\uc2dc\n\n        Returns:\n            Integer number: # of version list\n            False: Failed to get property\n\n        \"\"\"\n\n        url = nurls['setProperty']\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'orgresource': orgresource,\n                'protect': protect,\n                'dummy': dummy,\n                }\n\n        r = self.session.post(url = url, data = data)\n\n        return resultManager(r.text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getMusicAlbumList(self, tagtype = 0, startnum = 0, pagingrow = 100):\n\n        url = nurls['setProperty']\n\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n                'tagtype': tagtype,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                }\n\n        r = self.session.post(url = url, data = data)\n\n        return resultManager(r.text)", "response": "Get the list of music albums in a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the result manager was successful.", "response": "def resultManager(self, text):\n        \"\"\"\n        resultcode & message:\n            0 = success => if \"resultvalue\" = null: no result to show\n            11 = Not Exist Path\n            36 = File Infomation Not Found\n            2002 = Invalidation Cookie\n        \n        \"\"\"\n        j = json.loads(text)\n\n        if j['message'] != 'success':\n            print \"[*] Error : \" + j['message']\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the SQLAlchemy connection string with MySQL settings", "response": "def set_mysql(host, user, password, db, charset):\n    \"\"\"Set the SQLAlchemy connection string with MySQL settings\"\"\"\n    manager.database.set_mysql_connection(\n        host=host,\n        user=user,\n        password=password,\n        db=db,\n        charset=charset\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize a sequence of values via rank and Normal c. d. f.", "response": "def quantile_gaussianize(x):\n    \"\"\"Normalize a sequence of values via rank and Normal c.d.f.\n\n    Args:\n        x (array_like): sequence of values.\n\n    Returns:\n        Gaussian-normalized values.\n\n    Example:\n\n    .. doctest::\n\n        >>> from scipy_sugar.stats import quantile_gaussianize\n        >>> print(quantile_gaussianize([-1, 0, 2]))\n        [-0.67448975  0.          0.67448975]\n    \"\"\"\n    from scipy.stats import norm, rankdata\n\n    x = asarray(x, float).copy()\n    ok = isfinite(x)\n    x[ok] *= -1\n    y = empty_like(x)\n    y[ok] = rankdata(x[ok])\n    y[ok] = norm.isf(y[ok] / (sum(ok) + 1))\n    y[~ok] = x[~ok]\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply noise to dimensions within a peak.", "response": "def apply_noise(self, noise_generator, split_idx, ndigits=6):\n        \"\"\"Apply noise to dimensions within a peak.\n\n        :param noise_generator: Noise generator object.\n        :param int split_idx: Index specifying which peak list split parameters to use.\n        :return: None\n        :rtype: :py:obj:`None`\n        \"\"\"\n        noise = noise_generator.generate(self.labels, split_idx)\n        for dim, noise_value in zip(self, noise):\n            dim.chemshift = round(dim.chemshift + noise_value, ndigits)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the peak list into Sparky - formatted string.", "response": "def _to_sparky(self):\n        \"\"\"Save :class:`~nmrstarlib.plsimulator.PeakList` into Sparky-formatted string.\n\n        :return: Peak list representation in Sparky format.\n        :rtype: :py:class:`str`\n        \"\"\"\n        sparky_str = \"Assignment\\t\\t{}\\n\\n\".format(\"\\t\\t\".join([\"w\" + str(i + 1) for i in range(len(self.labels))]))\n        for peak in self:\n            assignment_str = \"-\".join(peak.assignments_list)\n            dimensions_str = \"\\t\\t\".join([str(chemshift) for chemshift in peak.chemshifts_list])\n            sparky_str += (\"{}\\t\\t{}\\n\".format(assignment_str, dimensions_str))\n        return sparky_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current state of the object into AutoAssign - formatted string.", "response": "def _to_autoassign(self):\n        \"\"\"Save :class:`~nmrstarlib.plsimulator.PeakList` into AutoAssign-formatted string.\n\n        :return: Peak list representation in AutoAssign format.\n        :rtype: :py:class:`str`\n        \"\"\"\n        autoassign_str = \"#Index\\t\\t{}\\t\\tIntensity\\t\\tWorkbook\\n\".format(\n            \"\\t\\t\".join([str(i + 1) + \"Dim\" for i in range(len(self.labels))]))\n        for peak_idx,  peak in enumerate(self):\n            dimensions_str = \"\\t\\t\".join([str(chemshift) for chemshift in peak.chemshifts_list])\n            autoassign_str += \"{}\\t\\t{}\\t\\t{}\\t\\t{}\\n\".format(peak_idx+1, dimensions_str, 0, self.spectrum_name)\n        return autoassign_str"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_json(self):\n        json_list = [{\"Assignment\": peak.assignments_list, \"Dimensions\": peak.chemshifts_list} for peak in self]\n        return json.dumps(json_list, sort_keys=True, indent=4)", "response": "Save the peak list into JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the current object to a file.", "response": "def write(self, filehandle, fileformat):\n        \"\"\"Write :class:`~nmrstarlib.plsimulator.PeakList` data into file.\n\n        :param filehandle: file-like object.\n        :type filehandle: :py:class:`io.TextIOWrapper`\n        :param str fileformat: Format to use to write data: `sparky`, `autoassign`, or `json`.\n        :return: None\n        :rtype: :py:obj:`None`\n        \"\"\"\n        try:\n            if fileformat == \"sparky\":\n                sparky_str = self._to_sparky()\n                filehandle.write(sparky_str)\n            elif fileformat == \"autoassign\":\n                autoassign_str = self._to_sparky()\n                filehandle.write(autoassign_str)\n            elif fileformat == \"json\":\n                json_str = self._to_json()\n                filehandle.write(json_str)\n            else:\n                raise TypeError(\"Unknown file format.\")\n        except IOError:\n            raise IOError('\"filehandle\" parameter must be writable.')\n        filehandle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if residues that sequence site is composed of are in sequential order.", "response": "def is_sequential(self):\n        \"\"\"Check if residues that sequence site is composed of are in sequential order.\n\n        :return: If sequence site is in valid sequential order (True) or not (False).\n        :rtype: :py:obj:`True` or :py:obj:`False`\n        \"\"\"\n        seq_ids = tuple(int(residue[\"Seq_ID\"]) for residue in self)\n        return seq_ids == tuple(range(int(seq_ids[0]), int(seq_ids[-1])+1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates list of DimensionGroups.", "response": "def create_dimension_groups(dimension_positions):\n        \"\"\"Create list of dimension groups.\n\n        :param zip dimension_positions: List of tuples describing dimension and its position within sequence site.\n        :return: List of dimension groups.\n        :rtype: :py:class:`list`\n        \"\"\"\n        dimension_groups = []\n        for dim_group_label, position in dimension_positions:\n            dim_group = DimensionGroup(dim_group_label, position)\n\n            for dim_label in nmrstarlib.RESONANCE_CLASSES[dim_group_label]:\n                dim_group.dimensions.append(Dimension(dim_label, position))\n            dimension_groups.append(dim_group)\n\n        return dimension_groups"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a list of concrete peak templates from a list of general peak descriptions.", "response": "def peak_templates(self):\n        \"\"\"Create a list of concrete peak templates from a list of general peak descriptions.\n\n        :return: List of peak templates.\n        :rtype: :py:class:`list`\n        \"\"\"\n        peak_templates = []\n        for peak_descr in self:\n            expanded_dims = [dim_group.dimensions for dim_group in peak_descr]\n            templates = product(*expanded_dims)\n            for template in templates:\n                peak_templates.append(PeakTemplate(template))\n        return peak_templates"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the length of a single sequence site based upon relative positions specified in peak descriptions.", "response": "def seq_site_length(self):\n        \"\"\"Calculate length of a single sequence site based upon relative positions specified in peak descriptions.\n\n        :return: Length of sequence site.\n        :rtype: :py:class:`int`\n        \"\"\"\n        relative_positions_set = set()\n        for peak_descr in self:\n            relative_positions_set.update(peak_descr.relative_positions)\n        return len(relative_positions_set)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize spectrum and peak descriptions.", "response": "def create_spectrum(spectrum_name):\n        \"\"\"Initialize spectrum and peak descriptions.\n\n        :param str spectrum_name: Name of the spectrum from which peak list will be simulated.\n        :return: Spectrum object.\n        :rtype: :class:`~nmrstarlib.plsimulator.Spectrum`\n        \"\"\"\n        try:\n            spectrum_description = nmrstarlib.SPECTRUM_DESCRIPTIONS[spectrum_name]\n        except KeyError:\n            raise NotImplementedError(\"Experiment type is not defined.\")\n\n        spectrum = plsimulator.Spectrum(spectrum_name, spectrum_description[\"Labels\"],\n                                        spectrum_description[\"MinNumberPeaksPerSpinSystem\"],\n                                        spectrum_description.get(\"ResonanceLimit\", None))\n\n        for peak_descr in spectrum_description[\"PeakDescriptions\"]:\n            spectrum.append(plsimulator.PeakDescription(peak_descr[\"fraction\"], peak_descr[\"dimensions\"]))\n\n        return spectrum"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_sequence_sites(chain, seq_site_length):\n        seq_ids = sorted(list(chain.keys()), key=int)  # make sure that sequence is sorted by sequence id\n        slices = [itertools.islice(seq_ids, i, None) for i in range(seq_site_length)]\n        seq_site_ids = list(zip(*slices))\n\n        sequence_sites = []\n        for seq_site_id in seq_site_ids:\n            seq_site = plsimulator.SequenceSite(chain[seq_id] for seq_id in seq_site_id)\n            if seq_site.is_sequential():\n                sequence_sites.append(seq_site)\n            else:\n                continue\n\n        return sequence_sites", "response": "Create a list of sequence sites using sequence ids."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating intervals for a given chunk sizes.", "response": "def calculate_intervals(chunk_sizes):\n        \"\"\"Calculate intervals for a given chunk sizes.\n\n        :param list chunk_sizes: List of chunk sizes.\n        :return: Tuple of intervals.\n        :rtype: :py:class:`tuple`\n        \"\"\"\n        start_indexes = [sum(chunk_sizes[:i]) for i in range(0, len(chunk_sizes))]\n        end_indexes = [sum(chunk_sizes[:i+1]) for i in range(0, len(chunk_sizes))]\n        return tuple(zip(start_indexes, end_indexes))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_by_percent(self, spin_systems_list):\n        chunk_sizes = [int((i*len(spin_systems_list))/100) for i in self.plsplit]\n        if sum(chunk_sizes) < len(spin_systems_list):\n            difference = len(spin_systems_list) - sum(chunk_sizes)\n            chunk_sizes[chunk_sizes.index(min(chunk_sizes))] += difference\n\n        assert sum(chunk_sizes) == len(spin_systems_list), \\\n            \"sum of chunk sizes must be equal to spin systems list length.\"\n\n        intervals = self.calculate_intervals(chunk_sizes)\n        chunks_of_spin_systems_by_percentage = [itertools.islice(spin_systems_list, *interval) for interval in intervals]\n        return chunks_of_spin_systems_by_percentage", "response": "Splits a list of spin systems by specified percentages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_peaklist(self, spectrum, chain, chain_idx, source):\n        sequence_sites = self.create_sequence_sites(chain, spectrum.seq_site_length)\n        spin_systems = []\n        peaklist = plsimulator.PeakList(spectrum.name, spectrum.labels, source, chain_idx)\n\n        for seq_site in sequence_sites:\n            spin_system = plsimulator.SpinSystem()\n            for template in spectrum.peak_templates:\n                peak = plsimulator.Peak(template.dimension_labels)\n                for dim in template:\n                    chemshift = seq_site[dim.position].get(dim.label, None)\n                    assignment = \"{}{}{}\".format(seq_site[dim.position][\"AA3Code\"],\n                                                 seq_site[dim.position][\"Seq_ID\"],\n                                                 dim.label)\n                    if chemshift and assignment:\n                        peak_dim = plsimulator.Dimension(dim.label, dim.position, assignment, float(chemshift))\n                        peak.append(peak_dim)\n                    else:\n                        continue\n\n                if len(peak) == len(template):\n                    spin_system.append(peak)\n                    peaklist.append(peak)\n                else:\n                    continue\n\n            spin_systems.append(spin_system)\n\n        if all(len(i) < spectrum.min_spin_system_peaks for i in spin_systems):\n            return None\n\n        if self.noise_generator is not None:\n            spin_systems_chunks = self.split_by_percent(spin_systems)\n            for split_idx, chunk in enumerate(spin_systems_chunks):\n                for spin_system in chunk:\n                    for peak in spin_system:\n                        peak.apply_noise(self.noise_generator, split_idx)\n\n        return peaklist", "response": "Create a peak list file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distArrayFactory(BaseClass):\n\n    class DistArrayAny(BaseClass):\n        \"\"\"\n        Distributed array. Each process owns data and can expose a subset\n        of the data to other processes. These are known as windows. Any\n        number of windows can be exposed and the data of windows can be\n        overlapping. Any process can access exposed windows from any other\n        process. This relies on MPI-2 one-sided get communication.\n        \"\"\"\n\n        def __new__(cls, *args, **kwargs):\n            return numpy.ndarray.__new__(cls, *args, **kwargs)\n\n        def __init__(self, shap, dtyp):\n            \"\"\"\n            Constructor\n            @param shap array shape\n            @param dtyp numpy type\n            \"\"\"\n\n            # default communicator\n            self.comm = MPI.COMM_WORLD\n\n            # winID: {'slice': slce,\n            #         'dataSrc': dataSrc,\n            #         'dataDst': dataDst,\n            #         'window': window}\n            self.windows = {}\n\n            # the type of data\n            self.dtyp = dtyp\n\n            # this process's MPI rank\n            self.rk = self.comm.Get_rank()\n\n            # number of processes\n            self.sz = self.comm.Get_size()\n\n            # mapping of numpy data types to MPI data types,\n            # assumes that the data are of some numpy variant\n            self.dtypMPI = None\n            if dtyp == numpy.float64:\n                self.dtypMPI = MPI.DOUBLE\n            elif dtyp == numpy.float32:\n                self.dtypeMPI = MPI.FLOAT\n            elif dtyp == numpy.int64:\n                self.dtypeMPI = MPI.INT64_T\n            elif dtyp == numpy.int32:\n                self.dtypeMPI = MPI.INT32_T\n            elif dtyp == numpy.int16:\n                self.dtypeMPI = MPI.INT16_T\n            elif dtyp == numpy.int8:\n                self.dtypeMPI = MPI.INT8_T\n            elif dtyp == numpy.bool_:\n                self.dtypeMPI = MPI.BYTE\n            else:\n                raise NotImplementedError\n\n        def setComm(self, comm):\n            \"\"\"\n            Set communicator\n            @param comm communicator\n            \"\"\"\n            self.comm = comm\n            self.rk = self.comm.Get_rank()\n            self.sz = self.comm.Get_size()\n\n        def getMPIRank(self):\n            \"\"\"\n            Get the MPI rank of this process\n            @return rank\n            \"\"\"\n            return self.rk\n\n        def getMPISize(self):\n            \"\"\"\n            Get the MPI size (number of processes) of this communicator\n            @return rank\n            \"\"\"\n            return self.sz\n\n        def expose(self, slce, winID):\n            \"\"\"\n            Collective operation to expose a sub-set of data\n            @param slce tuple of slice objects\n            @param winID the data window ID\n            \"\"\"\n            # buffer for source data\n            dataSrc = numpy.zeros(self[slce].shape, self.dtyp)\n            # buffer for destination data\n            dataDst = numpy.zeros(self[slce].shape, self.dtyp)\n\n            self.windows[winID] = {\n                'slice': slce,\n                'dataSrc': dataSrc,\n                'dataDst': dataDst,\n                'dataWindow': MPI.Win.Create(dataSrc, comm=self.comm),\n                }\n\n            if hasattr(self, 'mask'):\n                maskSrc = numpy.ones(self[slce].shape, numpy.bool_)\n                maskDst = numpy.ones(self[slce].shape, numpy.bool_)\n                iw = self.windows[winID]\n                iw['maskSrc'] = maskSrc\n                iw['maskDst'] = maskDst\n                iw['maskWindow'] = MPI.Win.Create(maskSrc, comm=self.comm)\n\n        def getMask(self, pe, winID):\n            \"\"\"\n            Access remote mask (collective operation)\n            @param pe remote processing element, if None then no operation\n            @param winID remote window\n            @return mask array or None (if there is no mask)\n            @note this is a no operation if there is no mask\n            attached to the data\n            \"\"\"\n            if 'maskWindow' not in self.windows:\n                # no mask, no op\n                return None\n\n            iw = self.windows[winID]\n            slce = iw['slice']\n            maskSrc = iw['maskSrc']\n            maskDst = iw['maskDst']\n\n            # copy src mask into buffer\n            maskSrc[...] = self.mask[slce]\n\n            win = iw['maskWindow']\n            win.Fence(MPI.MODE_NOPUT | MPI.MODE_NOPRECEDE)\n            if pe is not None:\n                win.Get([maskDst, MPI.BYTE], pe)\n            win.Fence(MPI.MODE_NOSUCCEED)\n\n            return maskDst\n\n        def getData(self, pe, winID):\n            \"\"\"\n            Access remote data (collective operation)\n            @param pe remote processing element, if None then no operation\n            @param winID remote window\n            @return array\n            \"\"\"\n            iw = self.windows[winID]\n\n            slce = iw['slice']\n            dataSrc = iw['dataSrc']\n            dataDst = iw['dataDst']\n\n\n            # copy src data into buffer\n            dataSrc[...] = self[slce]\n\n            win = iw['dataWindow']\n            win.Fence(MPI.MODE_NOPRECEDE) #MPI.MODE_NOPUT | MPI.MODE_NOPRECEDE)\n\n            if pe is not None:\n                win.Get([dataDst, self.dtypMPI], pe)\n\n            win.Fence(MPI.MODE_NOSUCCEED)\n\n            return dataDst\n\n        def free(self):\n            \"\"\"\n            Must be called to free all exposed windows\n            \"\"\"\n            for iw in self.windows:\n                self.windows[iw]['dataWindow'].Free()\n\n        def reduce(self, op, initializer=None, rootPe=0):\n            \"\"\"\n            Collective reduce operation\n            @param op function (e.g. lambda x,y:x+y)\n            @param initializer the return value if there are no elements\n            @param rootPe the root process which receives the result\n            @return result on rootPe, None on all other processes\n            \"\"\"\n            if len(self) == 0:\n                return initializer\n            val = functools.reduce(op, self.flat)\n            data = self.comm.gather(val, rootPe)\n            if self.rk == rootPe:\n                return functools.reduce(op, data)\n            else:\n                return None\n\n    return DistArrayAny", "response": "Returns a distributed array class that derives from BaseClass\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\narraying constructor for numpy distributed array", "response": "def daArray(arry, dtype=numpy.float):\n    \"\"\"\n    Array constructor for numpy distributed array\n    @param arry numpy-like array\n    \"\"\"\n    a = numpy.array(arry, dtype)\n    res = DistArray(a.shape, a.dtype)\n    res[:] = a\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef daZeros(shap, dtype=numpy.float):\n    res = DistArray(shap, dtype)\n    res[:] = 0\n    return res", "response": "Zero constructor for numpy distributed array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef daOnes(shap, dtype=numpy.float):\n    res = DistArray(shap, dtype)\n    res[:] = 1\n    return res", "response": "One constructor for numpy distributed array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mdaArray(arry, dtype=numpy.float, mask=None):\n    a = numpy.array(arry, dtype)\n    res = MaskedDistArray(a.shape, a.dtype)\n    res[:] = a\n    res.mask = mask\n    return res", "response": "Array constructor for masked distributed array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mdaZeros(shap, dtype=numpy.float, mask=None):\n    res = MaskedDistArray(shap, dtype)\n    res[:] = 0\n    res.mask = mask\n    return res", "response": "Zero constructor for masked distributed array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stash(self, storage, url):\n        result = {}\n        if self.is_valid():\n            upload = self.cleaned_data['upload']\n            name = storage.save(upload.name, upload)\n            result['filename'] = os.path.basename(name)\n            try:\n                result['url'] = storage.url(name)\n            except NotImplementedError:\n                result['url'] = None\n            result['stored'] = serialize_upload(name, storage, url)\n        return result", "response": "Stores the uploaded file in a temporary storage location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login(self, email=None, password=None, timeout=5):\n        if email is not None:\n            self.email = email\n        if password is not None:\n            self.password = password\n\n        url = self.api_url + API_LOGIN_ENDPOINT\n        data = json.dumps({'email': self.email, 'password': self.password})\n        headers = {'Content-Type': 'application/json'}\n        response = None\n\n        try:\n            response = self.session.post(url, data=data, headers=headers,\n                                         timeout=timeout)\n        except requests.exceptions.ConnectionError:\n            _LOGGER.warning(\"Unable to connect to %s\", url)\n        except requests.exceptions.Timeout:\n            _LOGGER.warning(\"No response from %s\", url)\n\n        if response is not None:\n            if response.status_code == 200:\n                self.auth_token = json.loads(response.text)['authorization']\n                return True\n            else:\n                _LOGGER.warning(\"Login failed for %s: %s\", self.email,\n                                response.text)\n        else:\n            _LOGGER.warning(\"Login failed for %s\", self.email)\n\n        return False", "response": "Log in to CANDY HOUSE account. Return True on success."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, method, endpoint, payload=None, timeout=5):\n        url = self.api_url + endpoint\n        data = None\n        headers = {}\n\n        if payload is not None:\n            data = json.dumps(payload)\n            headers['Content-Type'] = 'application/json'\n\n        try:\n            if self.auth_token is not None:\n                headers[API_AUTH_HEADER] = self.auth_token\n                response = self.session.request(method, url, data=data,\n                                                headers=headers,\n                                                timeout=timeout)\n                if response.status_code != 401:\n                    return response\n\n            _LOGGER.debug(\"Renewing auth token\")\n            if not self.login(timeout=timeout):\n                return None\n\n            # Retry  request\n            headers[API_AUTH_HEADER] = self.auth_token\n            return self.session.request(method, url, data=data,\n                                        headers=headers,\n                                        timeout=timeout)\n        except requests.exceptions.ConnectionError:\n            _LOGGER.warning(\"Unable to connect to %s\", url)\n        except requests.exceptions.Timeout:\n            _LOGGER.warning(\"No response from %s\", url)\n\n        return None", "response": "Send request to API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sesames(self):\n        response = self.request('GET', API_SESAME_LIST_ENDPOINT)\n        if response is not None and response.status_code == 200:\n            return json.loads(response.text)['sesames']\n\n        _LOGGER.warning(\"Unable to list Sesames\")\n        return []", "response": "Return list of Sesames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_api(\n        profile=None,\n        config_file=None,\n        requirements=None):\n    '''\n    Generate a datafs.DataAPI object from a config profile\n\n    ``get_api`` generates a DataAPI object based on a\n    pre-configured datafs profile specified in your datafs\n    config file.\n\n    To create a datafs config file, use the command line\n    tool ``datafs configure --helper`` or export an existing\n    DataAPI object with\n    :py:meth:`datafs.ConfigFile.write_config_from_api`\n\n    Parameters\n    ----------\n    profile : str\n        (optional) name of a profile in your datafs config\n        file. If profile is not provided, the default\n        profile specified in the file will be used.\n\n    config_file : str or file\n        (optional) path to your datafs configuration file.\n        By default, get_api uses your OS's default datafs\n        application directory.\n\n    Examples\n    --------\n\n    The following specifies a simple API with a MongoDB\n    manager and a temporary storage service:\n\n    .. code-block:: python\n\n        >>> try:\n        ...   from StringIO import StringIO\n        ... except ImportError:\n        ...   from io import StringIO\n        ...\n        >>> import tempfile\n        >>> tempdir = tempfile.mkdtemp()\n        >>>\n        >>> config_file = StringIO(\"\"\"\n        ... default-profile: my-data\n        ... profiles:\n        ...     my-data:\n        ...         manager:\n        ...             class: MongoDBManager\n        ...             kwargs:\n        ...                 database_name: 'MyDatabase'\n        ...                 table_name: 'DataFiles'\n        ...\n        ...         authorities:\n        ...             local:\n        ...                 service: OSFS\n        ...                 args: ['{}']\n        ... \"\"\".format(tempdir))\n        >>>\n        >>> # This file can be read in using the datafs.get_api helper function\n        ...\n        >>>\n        >>> api = get_api(profile='my-data', config_file=config_file)\n        >>> api.manager.create_archive_table(\n        ...     'DataFiles',\n        ...     raise_on_err=False)\n        >>>\n        >>> archive = api.create(\n        ...     'my_first_archive',\n        ...     metadata = dict(description = 'My test data archive'),\n        ...     raise_on_err=False)\n        >>>\n        >>> with archive.open('w+') as f:\n        ...     res = f.write(u'hello!')\n        ...\n        >>> with archive.open('r') as f:\n        ...     print(f.read())\n        ...\n        hello!\n        >>>\n        >>> # clean up\n        ...\n        >>> archive.delete()\n        >>> import shutil\n        >>> shutil.rmtree(tempdir)\n\n    '''\n\n    config = ConfigFile(config_file=config_file)\n    config.read_config()\n\n    if profile is None:\n        profile = config.config['default-profile']\n\n    profile_config = config.get_profile_config(profile)\n\n    default_versions = {}\n\n    if requirements is None:\n        requirements = config.config.get('requirements', None)\n\n    if requirements is not None and not os.path.isfile(requirements):\n        for reqline in re.split(r'[\\r\\n;]+', requirements):\n            if re.search(r'^\\s*$', reqline):\n                continue\n\n            archive, version = _parse_requirement(reqline)\n            default_versions[archive] = version\n\n    else:\n        if requirements is None:\n            requirements = 'requirements_data.txt'\n\n        if os.path.isfile(requirements):\n            with open_filelike(requirements, 'r') as reqfile:\n                for reqline in reqfile.readlines():\n                    if re.search(r'^\\s*$', reqline):\n                        continue\n\n                    archive, version = _parse_requirement(reqline)\n                    default_versions[archive] = version\n\n    api = APIConstructor.generate_api_from_config(profile_config)\n    api.default_versions = default_versions\n\n    APIConstructor.attach_manager_from_config(api, profile_config)\n    APIConstructor.attach_services_from_config(api, profile_config)\n    APIConstructor.attach_cache_from_config(api, profile_config)\n\n    return api", "response": "Generate a DataAPI object from a config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the required values are present in the to_populate dictionary.", "response": "def check_requirements(to_populate, prompts, helper=False):\n    '''\n    Iterates through required values, checking to_populate for required values\n\n    If a key in prompts is missing in to_populate and ``helper==True``,\n    prompts the user using the values in to_populate. Otherwise, raises an\n    error.\n\n    Parameters\n    ----------\n\n    to_populate : dict\n        Data dictionary to fill. Prompts given to the user are taken from this\n        dictionary.\n\n    prompts : dict\n        Keys and prompts to use when filling ``to_populate``\n    '''\n\n    for kw, prompt in prompts.items():\n        if helper:\n            if kw not in to_populate:\n                to_populate[kw] = click.prompt(prompt)\n        else:\n            msg = (\n                'Required value \"{}\" not found. '\n                'Use helper=True or the --helper '\n                'flag for assistance.'.format(kw))\n\n            assert kw in to_populate, msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites all the data to the log file.", "response": "def write_all(self, data):\n        \"\"\"\n        :param list[int] data:\n        \"\"\"\n        self._set_cursor_x(0)\n        self._set_cursor_y(0)\n\n        self.DC.on()\n\n        self._write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cli(parser):\n    '''\n    Simply calls out to easy_install --upgrade\n    '''\n    parser.add_argument('packages', nargs='*', default=local_packages(),\n        help='Packages to upgrade (defaults to all installed packages)')\n    parser.add_argument('-n', '--dry-run', action='store_true',\n        help='Print upgrade actions without running')\n    opts = parser.parse_args()\n\n    for package in opts.packages:\n        upgrade(package, execute=not opts.dry_run)", "response": "A simple command line interface to easy_install."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave file and return saved info or report errors.", "response": "def post(self, *args, **kwargs):\n        \"\"\"Save file and return saved info or report errors.\"\"\"\n        if self.upload_allowed():\n            form = self.get_upload_form()\n            result = {}\n            if form.is_valid():\n                storage = self.get_storage()\n                result['is_valid'] = True\n                info = form.stash(storage, self.request.path)\n                result.update(info)\n            else:\n                result.update({\n                    'is_valid': False,\n                    'errors': form.errors,\n                })\n            return HttpResponse(json.dumps(result), content_type='application/json')\n        else:\n            return HttpResponseForbidden()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct form for accepting file upload.", "response": "def get_upload_form(self):\n        \"\"\"Construct form for accepting file upload.\"\"\"\n        return self.form_class(self.request.POST, self.request.FILES)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_url(location):\n    req = urllib.request.Request(location)\n    with urllib.request.urlopen(req) as response:\n        the_page = response.read().decode()\n        return the_page", "response": "HTTP request for page at location returned as string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the description. xml file and return the serial number base ip and img url.", "response": "def parse_description_xml(location):\n    \"\"\" Extract serial number, base ip, and img url from description.xml\n\n    missing data from XML returns AttributeError\n    malformed XML returns ParseError\n\n    Refer to included example for URLBase and serialNumber elements\n    \"\"\"\n    class _URLBase(str):\n        \"\"\" Convenient access to hostname (ip) portion of the URL \"\"\"\n        @property\n        def hostname(self):\n            return urlsplit(self).hostname\n\n    # \"\"\"TODO: review error handling on xml\"\"\"\n    # may want to suppress ParseError in the event that it was caused\n    # by a none bridge device although this seems unlikely\n    try:\n        xml_str = from_url(location)\n    except urllib.request.HTTPError as error:\n        logger.info(\"No description for %s: %s\", location, error)\n        return None, error\n    except urllib.request.URLError as error:\n        logger.info(\"No HTTP server for %s: %s\", location, error)\n        return None, error\n    else:\n        root = ET.fromstring(xml_str)\n        rootname = {'root': root.tag[root.tag.find('{')+1:root.tag.find('}')]}\n        baseip = root.find('root:URLBase', rootname).text\n        device = root.find('root:device', rootname)\n        serial = device.find('root:serialNumber', rootname).text\n        # anicon = device.find('root:iconList', rootname).find('root:icon', rootname)\n        # imgurl = anicon.find('root:url', rootname).text\n\n        # Alternatively, could look directly in the modelDescription field\n        if all(x in xml_str.lower() for x in ['philips', 'hue']):\n            return serial, _URLBase(baseip)\n        else:\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild url for description. xml from ip", "response": "def _build_from(baseip):\n    \"\"\" Build URL for description.xml from ip \"\"\"\n    from ipaddress import ip_address\n    try:\n        ip_address(baseip)\n    except ValueError:\n        # \"\"\"attempt to construct url but the ip format has changed\"\"\"\n        # logger.warning(\"Format of internalipaddress changed: %s\", baseip)\n        if 'http' not in baseip[0:4].lower():\n            baseip = urlunsplit(['http', baseip, '', '', ''])\n        spl = urlsplit(baseip)\n        if '.xml' not in spl.path:\n            sep = '' if spl.path.endswith('/') else '/'\n            spl = spl._replace(path=spl.path+sep+'description.xml')\n        return spl.geturl()\n    else:\n        # construct url knowing baseip is a pure ip\n        return  urlunsplit(('http', baseip, '/description.xml', '', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_portal_json():\n    try:\n        json_str = from_url('https://www.meethue.com/api/nupnp')\n    except urllib.request.HTTPError as error:\n        logger.error(\"Problem at portal: %s\", error)\n        raise\n    except urllib.request.URLError as error:\n        logger.warning(\"Problem reaching portal: %s\", error)\n        return []\n    else:\n        portal_list = []\n        json_list = json.loads(json_str)\n        for bridge in json_list:\n            serial = bridge['id']\n            baseip = bridge['internalipaddress']\n            # baseip should look like \"192.168.0.1\"\n            xmlurl = _build_from(baseip)\n            # xmlurl should look like \"http://192.168.0.1/description.xml\"\n            portal_list.append((serial, xmlurl))\n        return portal_list", "response": "Extract id ip from https://www. meethue. com"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing SSDP to discover available Hue bridges and return them as a list of dicts.", "response": "def via_upnp():\n    \"\"\" Use SSDP as described by the Philips guide \"\"\"\n    ssdp_list = ssdp_discover(\"ssdp:all\", timeout=5)\n    #import pickle\n    #with open(\"ssdp.pickle\", \"wb\") as f:\n        #pickle.dump(ssdp_list,f)\n    bridges_from_ssdp = [u for u in ssdp_list if 'IpBridge' in u.server]\n    logger.info('SSDP returned %d items with %d Hue bridges(s).',\n                 len(ssdp_list), len(bridges_from_ssdp))\n    # Confirm SSDP gave an accessible bridge device by reading from the returned\n    # location.  Should look like: http://192.168.0.1:80/description.xml\n    found_bridges = {}\n    for bridge in bridges_from_ssdp:\n        serial, bridge_info = parse_description_xml(bridge.location)\n        if serial:\n            found_bridges[serial] = bridge_info\n\n    logger.debug('%s', found_bridges)\n    if found_bridges:\n        return found_bridges\n    else:\n        raise DiscoveryError('SSDP returned nothing')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing method 2 to get a list of bridges from NUPN portal.", "response": "def via_nupnp():\n    \"\"\" Use method 2 as described by the Philips guide \"\"\"\n    bridges_from_portal = parse_portal_json()\n    logger.info('Portal returned %d Hue bridges(s).',\n                 len(bridges_from_portal))\n    # Confirm Portal gave an accessible bridge device by reading from the returned\n    # location.  Should look like: http://192.168.0.1/description.xml\n    found_bridges = {}\n    for bridge in bridges_from_portal:\n        serial, bridge_info = parse_description_xml(bridge[1])\n        if serial:\n            found_bridges[serial] = bridge_info\n\n    logger.debug('%s', found_bridges)\n    if found_bridges:\n        return found_bridges\n    else:\n        raise DiscoveryError('Portal returned nothing')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef via_scan():\n    import socket\n    import ipaddress\n    import httpfind\n    bridges_from_scan = []\n    hosts = socket.gethostbyname_ex(socket.gethostname())[2]\n    for host in hosts:\n        bridges_from_scan += httpfind.survey(\n            # TODO: how do we determine subnet configuration?\n            ipaddress.ip_interface(host+'/24').network,\n            path='description.xml',\n            pattern='(P|p)hilips')\n        logger.info('Scan on %s', host)\n    logger.info('Scan returned %d Hue bridges(s).', len(bridges_from_scan))\n    # Confirm Scan gave an accessible bridge device by reading from the returned\n    # location.  Should look like: http://192.168.0.1/description.xml\n    found_bridges = {}\n    for bridge in bridges_from_scan:\n        serial, bridge_info = parse_description_xml(bridge)\n        if serial:\n            found_bridges[serial] = bridge_info\n\n    logger.debug('%s', found_bridges)\n    if found_bridges:\n        return found_bridges\n    else:\n        raise DiscoveryError('Scan returned nothing')", "response": "IP scan - now implemented"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfirm or locate IP addresses of Philips Hue bridges.", "response": "def find_bridges(prior_bridges=None):\n    \"\"\" Confirm or locate IP addresses of Philips Hue bridges.\n\n    `prior_bridges` -- optional list of bridge serial numbers\n    * omitted - all discovered bridges returned as dictionary\n    * single string - returns IP as string or None\n    * dictionary - validate provided ip's before attempting discovery\n    * collection or sequence - return dictionary of filtered sn:ip pairs\n      * if mutable then found bridges are removed from argument\n    \"\"\"\n    found_bridges = {}\n\n    # Validate caller's provided list\n    try:\n        prior_bridges_list = prior_bridges.items()\n    except AttributeError:\n        # if caller didnt provide dict then assume single SN or None\n        # in either case, the discovery must be executed\n        run_discovery = True\n    else:\n        for prior_sn, prior_ip in prior_bridges_list:\n            if prior_ip:\n                serial, baseip = parse_description_xml(_build_from(prior_ip))\n                if serial:\n                    # there is a bridge at provided IP, add to found\n                    found_bridges[serial] = baseip\n                else:\n                    # nothing usable at that ip\n                    logger.info('%s not found at %s', prior_sn, prior_ip)\n        run_discovery = found_bridges.keys() != prior_bridges.keys()\n\n    # prior_bridges is None, unknown, dict of unfound SNs, or empty dict\n    # found_bridges is dict of found SNs from prior, or empty dict\n    if run_discovery:\n        # do the discovery, not all IPs were confirmed\n        try:\n            found_bridges.update(via_upnp())\n        except DiscoveryError:\n            try:\n                found_bridges.update(via_nupnp())\n            except DiscoveryError:\n                try:\n                    found_bridges.update(via_scan())\n                except DiscoveryError:\n                    logger.warning(\"All discovery methods returned nothing\")\n\n    if prior_bridges:\n        # prior_bridges is either single SN or dict of unfound SNs\n        # first assume single Serial SN string\n        try:\n            ip_address = found_bridges[prior_bridges]\n        except TypeError:\n            # user passed an invalid type for key\n            # presumably it's a dict meant for alternate mode\n            logger.debug('Assuming alternate mode, prior_bridges is type %s.',\n                          type(prior_bridges))\n        except KeyError:\n            # user provided Serial Number was not found\n            # TODO: dropping tuples here if return none executed\n            # return None\n            pass # let it turn the string into a set, eww\n        else:\n            # user provided Serial Number found\n            return ip_address\n\n        # Filter the found list to subset of prior\n        prior_bridges_keys = set(prior_bridges)\n        keys_to_remove = prior_bridges_keys ^ found_bridges.keys()\n        logger.debug('Removing %s from found_bridges', keys_to_remove)\n        for key in keys_to_remove:\n            found_bridges.pop(key, None)\n\n        # Filter the prior dict to unfound only\n        keys_to_remove = prior_bridges_keys & found_bridges.keys()\n        logger.debug('Removing %s from prior_bridges', keys_to_remove)\n        for key in keys_to_remove:\n            try:\n                prior_bridges.pop(key, None)\n            except TypeError:\n                # not a dict, try as set or list\n                prior_bridges.remove(key)\n            except AttributeError:\n                # likely not mutable\n                break\n\n        keys_to_report = prior_bridges_keys - found_bridges.keys()\n        for serial in keys_to_report:\n            logger.warning('Could not locate bridge with Serial ID %s', serial)\n\n    else:\n        # prior_bridges is None or empty dict, return all found\n        pass\n\n    return found_bridges"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef matches(self, a, b, **config):\n        package_a = self.processor._u2p(a['msg']['update']['title'])[0]\n        package_b = self.processor._u2p(b['msg']['update']['title'])[0]\n        if package_a != package_b:\n            return False\n        return True", "response": "Returns True if the message matches by package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cli(parser):\n    '''\n    Currently a cop-out -- just calls easy_install\n    '''\n    parser.add_argument('-n', '--dry-run', action='store_true', help='Print uninstall actions without running')\n    parser.add_argument('packages', nargs='+', help='Packages to install')\n    opts = parser.parse_args()\n\n    for package in opts.packages:\n        install(package, execute=not opts.dry_run)", "response": "A simple command line interface for the easy_install command."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the value inside of a node in the dictionary.", "response": "def mset(m_dict, keys, value, delimiter=':'):\n    \"\"\"\n    :param m_dict: A dictionary to set the value inside of\n    :type m_dict: dict\n    :param keys: A list of keys\n    :type keys: str\n    :param value: The value to set inside of the dictionary\n    :param delimiter: The delimiter used in the keys list\n    :type delimiter: str\n    \"\"\"\n    val = m_dict\n    keys = keys.split(delimiter)\n    for i, key in enumerate(keys):\n        try:\n            if i == len(keys) - 1:\n                val[key] = value\n                return\n            else:\n                val = val[key]\n        except KeyError:\n            if i == len(keys) - 1:\n                val[key] = value\n                return\n            else:\n                val[key] = {}\n                val = val[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string representing a granularity.", "response": "def parse_grain(grain):\n        \"\"\" Parse a string to a granularity, e.g. \"Day\" to InstantTime.day.\n\n        :param grain: a string representing a granularity.\n        \"\"\"\n        if not grain:\n            return InstantTime.day\n        if grain.lower() == 'week':\n            return InstantTime.week\n        return InstantTime.day"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls get_latest_version and then save the object.", "response": "def update_from_pypi(self):\n        \"\"\"Call get_latest_version and then save the object.\"\"\"\n        package = pypi.Package(self.package_name)\n        self.licence = package.licence()\n        if self.is_parseable:\n            self.latest_version = package.latest_version()\n            self.next_version = package.next_version(self.current_version)\n            self.diff_status = pypi.version_diff(self.current_version, self.latest_version)\n            self.python_support = package.python_support()\n            self.django_support = package.django_support()\n            self.supports_py3 = package.supports_py3()\n        self.checked_pypi_at = tz_now()\n        self.save()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sendfile(self, data, zlib_compress=None, compress_level=6):\n        if hasattr(data, 'seek'):\n            data.seek(0)\n\n        chunk_size = CHUNK_SIZE\n\n        if zlib_compress:\n            chunk_size = BLOCK_SIZE\n            compressor = compressobj(compress_level)\n\n        while 1:\n            binarydata = data.read(chunk_size)\n            if binarydata == '':\n                break\n            if zlib_compress:\n                binarydata = compressor.compress(binarydata)\n                if not binarydata:\n                    continue\n            self.send(binarydata)\n\n        if zlib_compress:\n            remaining = compressor.flush()\n            while remaining:\n                binarydata = remaining[:BLOCK_SIZE]\n                remaining = remaining[BLOCK_SIZE:]\n                self.send(binarydata)", "response": "Send data from a file object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ghostedDistArrayFactory(BaseClass):\n\n    class GhostedDistArrayAny(BaseClass):\n        \"\"\"\n        Ghosted distributed array. Each process owns data and exposes the\n        halo region to other processes. These are accessed with tuples\n        such (1, 0) for north, (-1, 0) for south, etc.\n        \"\"\"\n\n        def __init__(self, shape, dtype):\n            \"\"\"\n            Constructor\n            @param shape shape of the array\n            @param dtype numpy data type\n            @param numGhosts the width of the halo\n            \"\"\"\n            # call the parent Ctor\n            BaseClass.__init__(self, shape, dtype)\n\n        def setNumberOfGhosts(self, numGhosts):\n            \"\"\"\n            Set the width of the ghost halo\n            @param numGhosts halo thickness\n            \"\"\"\n            # expose each window to other PE domains\n            ndim = len(self.shape)\n            for dim in range(ndim):\n                for drect in (-1, 1):\n                    # the window id uniquely specifies the\n                    # location of the window. we use 0's to indicate\n                    # a slab extending over the entire length for a\n                    # given direction, a 1 represents a layer of\n                    # thickness numGhosts on the high index side,\n                    # -1 on the low index side.\n                    winId = tuple([0 for i in range(dim)] +\n                                  [drect] +\n                                  [0 for i in range(dim+1, ndim)])\n\n                    slce = slice(0, numGhosts)\n                    if drect == 1:\n                        slce = slice(self.shape[dim] -\n                                     numGhosts, self.shape[dim])\n\n                    slab = self.getSlab(dim, slce)\n\n                    # expose MPI window\n                    self.expose(slab, winId)\n\n        def getSlab(self, dim, slce):\n            \"\"\"\n            Get slab. A slab is a multi-dimensional slice extending in\n            all directions except along dim where slce applies\n            @param dim dimension (0=first index, 1=2nd index...)\n            @param slce python slice object along dimension dim\n            @return slab\n            \"\"\"\n            shape = self.shape\n            ndim = len(shape)\n\n            slab = [slice(0, shape[i]) for i in range(dim)] + \\\n                   [slce] + [slice(0, shape[i]) for i in range(dim+1, ndim)]\n            return slab\n\n        def getEllipsis(self, winID):\n            \"\"\"\n            Get the ellipsis for a given halo side\n\n            @param winID a tuple of zeros and one +1 or -1.  To access\n               the \"north\" side for instance, set side=(1, 0),\n               (-1, 0) to access the south side, (0, 1) the east\n               side, etc. This does not involve any communication.\n\n            @return None if halo was not exposed (bad winID)\n            \"\"\"\n            if winID in self.windows:\n                return self.windows[winID]['slice']\n            else:\n                return None\n\n    return GhostedDistArrayAny", "response": "Returns a base class that derives from DistArray or MaskedDistArrayAny."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nghosts distributed array constructor @param arry numpy-like array @param numGhosts the number of ghosts (>= 0)", "response": "def gdaArray(arry, dtype, numGhosts=1):\n    \"\"\"\n    ghosted distributed array constructor\n    @param arry numpy-like array\n    @param numGhosts the number of ghosts (>= 0)\n    \"\"\"\n    a = numpy.array(arry, dtype)\n    res = GhostedDistArray(a.shape, a.dtype)\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = a\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nghosting distributed array zero constructor @param shape the shape of the array @param dtype the numpy data type @param numGhosts the number of ghosts (>= 0)", "response": "def gdaZeros(shape, dtype, numGhosts=1):\n    \"\"\"\n    ghosted distributed array zero constructor\n    @param shape the shape of the array\n    @param dtype the numpy data type\n    @param numGhosts the number of ghosts (>= 0)\n    \"\"\"\n    res = GhostedDistArray(shape, dtype)\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = 0\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nghost distributed array one constructor @param shape the shape of the array @param dtype the numpy data type @param numGhosts the number of ghosts (>= 0)", "response": "def gdaOnes(shape, dtype, numGhosts=1):\n    \"\"\"\n    ghosted distributed array one constructor\n    @param shape the shape of the array\n    @param dtype the numpy data type\n    @param numGhosts the number of ghosts (>= 0)\n    \"\"\"\n    res = GhostedDistArray(shape, dtype)\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = 1\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nghosting distributed array constructor @param arry numpy-like array @param numGhosts the number of ghosts (>= 0)", "response": "def gmdaArray(arry, dtype, mask=None, numGhosts=1):\n    \"\"\"\n    ghosted distributed array constructor\n    @param arry numpy-like array\n    @param numGhosts the number of ghosts (>= 0)\n    \"\"\"\n    a = numpy.array(arry, dtype)\n    res = GhostedMaskedDistArray(a.shape, a.dtype)\n    res.mask = mask\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = a\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gmdaZeros(shape, dtype, mask=None, numGhosts=1):\n    res = GhostedMaskedDistArray(shape, dtype)\n    res.mas = mask\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = 0\n    return res", "response": "gmdaZeros - returns a ghosted distributed array zero"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nghost distributed array one constructor @param shape the shape of the array @param dtype the numpy data type @param numGhosts the number of ghosts (>= 0)", "response": "def gmdaOnes(shape, dtype, mask=None, numGhosts=1):\n    \"\"\"\n    ghosted distributed array one constructor\n    @param shape the shape of the array\n    @param dtype the numpy data type\n    @param numGhosts the number of ghosts (>= 0)\n    \"\"\"\n    res = GhostedMaskedDistArray(shape, dtype)\n    res.mask = mask\n    res.setNumberOfGhosts(numGhosts)\n    res[:] = 1\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing uploaded file by name and storage. Namespaced by the upload url.", "response": "def serialize_upload(name, storage, url):\n    \"\"\"\n    Serialize uploaded file by name and storage. Namespaced by the upload url.\n    \"\"\"\n    if isinstance(storage, LazyObject):\n        # Unwrap lazy storage class\n        storage._setup()\n        cls = storage._wrapped.__class__\n    else:\n        cls = storage.__class__\n    return signing.dumps({\n        'name': name,\n        'storage': '%s.%s' % (cls.__module__, cls.__name__)\n    }, salt=url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestores file and name and storage from serialized value and the upload url.", "response": "def deserialize_upload(value, url):\n    \"\"\"\n    Restore file and name and storage from serialized value and the upload url.\n    \"\"\"\n    result = {'name': None, 'storage': None}\n    try:\n        result = signing.loads(value, salt=url)\n    except signing.BadSignature:\n        # TODO: Log invalid signature\n        pass\n    else:\n        try:\n            result['storage'] = get_storage_class(result['storage'])\n        except (ImproperlyConfigured, ImportError):\n            # TODO: Log invalid class\n            result = {'name': None, 'storage': None}\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_action(action):\n    if isinstance(action, types.StringTypes):\n        action = action.lower()\n\n    if action not in ['learn', 'forget', 'report', 'revoke']:\n        raise SpamCError('The action option is invalid')\n    return action", "response": "check for invalid actions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_response(cmd, conn):\n    resp = conn.socket().makefile('rb', -1)\n    resp_dict = dict(\n        code=0,\n        message='',\n        isspam=False,\n        score=0.0,\n        basescore=0.0,\n        report=[],\n        symbols=[],\n        headers={},\n    )\n\n    if cmd == 'TELL':\n        resp_dict['didset'] = False\n        resp_dict['didremove'] = False\n\n    data = resp.read()\n    lines = data.split('\\r\\n')\n    for index, line in enumerate(lines):\n        if index == 0:\n            match = RESPONSE_RE.match(line)\n            if not match:\n                raise SpamCResponseError(\n                    'spamd unrecognized response: %s' % data)\n            resp_dict.update(match.groupdict())\n            resp_dict['code'] = int(resp_dict['code'])\n        else:\n            if not line.strip():\n                continue\n            match = SPAM_RE.match(line)\n            if match:\n                tmp = match.groupdict()\n                resp_dict['score'] = float(tmp['score'])\n                resp_dict['basescore'] = float(tmp['basescore'])\n                resp_dict['isspam'] = tmp['isspam'] in ['True', 'Yes']\n            if not match:\n                if cmd == 'SYMBOLS':\n                    match = PART_RE.findall(line)\n                    for part in match:\n                        resp_dict['symbols'].append(part)\n            if not match and cmd != 'PROCESS':\n                match = RULE_RE.findall(line)\n                if match:\n                    resp_dict['report'] = []\n                    for part in match:\n                        score = part[0] + part[1]\n                        score = score.strip()\n                        resp_dict['report'].append(\n                            dict(score=score,\n                                 name=part[2],\n                                 description=SPACE_RE.sub(\" \", part[3])))\n            if line.startswith('DidSet:'):\n                resp_dict['didset'] = True\n            if line.startswith('DidRemove:'):\n                resp_dict['didremove'] = True\n    if cmd == 'PROCESS':\n        resp_dict['message'] = ''.join(lines[4:]) + '\\r\\n'\n    if cmd == 'HEADERS':\n        parser = Parser()\n        headers = parser.parsestr('\\r\\n'.join(lines[4:]), headersonly=True)\n        for key in headers.keys():\n            resp_dict['headers'][key] = headers[key]\n    return resp_dict", "response": "Return a response from the spamd server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new connection object based on the current settings.", "response": "def get_connection(self):\n        \"\"\"Creates a new connection\"\"\"\n        if self.host is None:\n            connector = SpamCUnixConnector\n            conn = connector(self.socket_file, self.backend_mod)\n        else:\n            connector = SpamCTcpConnector\n            conn = connector(\n                self.host,\n                self.port,\n                self.backend_mod,\n                is_ssl=self.is_ssl,\n                **self.ssl_args)\n        return conn"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the headers string based on command to execute", "response": "def get_headers(self, cmd, msg_length, extra_headers):\n        \"\"\"Returns the headers string based on command to execute\"\"\"\n        cmd_header = \"%s %s\" % (cmd, PROTOCOL_VERSION)\n        len_header = \"Content-length: %s\" % msg_length\n        headers = [cmd_header, len_header]\n        if self.user:\n            user_header = \"User: %s\" % self.user\n            headers.append(user_header)\n        if self.gzip:\n            headers.append(\"Compress: zlib\")\n        if extra_headers is not None:\n            for key in extra_headers:\n                if key.lower() != 'content-length':\n                    headers.append(\"%s: %s\" % (key, extra_headers[key]))\n        headers.append('')\n        headers.append('')\n        return '\\r\\n'.join(headers)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a call to the SpamC server.", "response": "def perform(self, cmd, msg='', extra_headers=None):\n        \"\"\"Perform the call\"\"\"\n        tries = 0\n        while 1:\n            conn = None\n            try:\n                conn = self.get_connection()\n                if hasattr(msg, 'read') and hasattr(msg, 'fileno'):\n                    msg_length = str(os.fstat(msg.fileno()).st_size)\n                elif hasattr(msg, 'read'):\n                    msg.seek(0, 2)\n                    msg_length = str(msg.tell() + 2)\n                else:\n                    if msg:\n                        try:\n                            msg_length = str(len(msg) + 2)\n                        except TypeError:\n                            conn.close()\n                            raise ValueError(\n                                'msg param should be a string or file handle')\n                    else:\n                        msg_length = '2'\n\n                headers = self.get_headers(cmd, msg_length, extra_headers)\n\n                if isinstance(msg, types.StringTypes):\n                    if self.gzip and msg:\n                        msg = compress(msg + '\\r\\n', self.compress_level)\n                    else:\n                        msg = msg + '\\r\\n'\n                    conn.send(headers + msg)\n                else:\n                    conn.send(headers)\n                    if hasattr(msg, 'read'):\n                        if hasattr(msg, 'seek'):\n                            msg.seek(0)\n                        conn.sendfile(msg, self.gzip, self.compress_level)\n                conn.send('\\r\\n')\n                try:\n                    conn.socket().shutdown(socket.SHUT_WR)\n                except socket.error:\n                    pass\n                return get_response(cmd, conn)\n            except socket.gaierror as err:\n                if conn is not None:\n                    conn.release()\n                raise SpamCError(str(err))\n            except socket.timeout as err:\n                if conn is not None:\n                    conn.release()\n                raise SpamCTimeOutError(str(err))\n            except socket.error as err:\n                if conn is not None:\n                    conn.close()\n                errors = (errno.EAGAIN, errno.EPIPE, errno.EBADF,\n                          errno.ECONNRESET)\n                if err[0] not in errors or tries >= self.max_tries:\n                    raise SpamCError(\"socket.error: %s\" % str(err))\n            except BaseException:\n                if conn is not None:\n                    conn.release()\n                raise\n            tries += 1\n            self.backend_mod.sleep(self.wait_tries)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tell(self, msg, action, learnas=''):\n        action = _check_action(action)\n        mode = learnas.upper()\n\n        headers = {\n            'Message-class': '',\n            'Set': 'local',\n        }\n\n        if action == 'learn':\n            if mode == 'SPAM':\n                headers['Message-class'] = 'spam'\n            elif mode in ['HAM', 'NOTSPAM', 'NOT_SPAM']:\n                headers['Message-class'] = 'ham'\n            else:\n                raise SpamCError('The learnas option is invalid')\n        elif action == 'forget':\n            del headers['Message-class']\n            del headers['Set']\n            headers['Remove'] = 'local'\n        elif action == 'report':\n            headers['Message-class'] = 'spam'\n            headers['Set'] = 'local, remote'\n        elif action == 'revoke':\n            headers['Message-class'] = 'ham'\n            headers['Remove'] = 'remote'\n        return self.perform('TELL', msg, headers)", "response": "Tell what type of we are to process and what should be done\n            with that message. This includes setting or removing a local and remote database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef learn(self, msg, learnas):\n        if not isinstance(learnas, types.StringTypes):\n            raise SpamCError('The learnas option is invalid')\n        if learnas.lower() == 'forget':\n            resp = self.tell(msg, 'forget')\n        else:\n            resp = self.tell(msg, 'learn', learnas)\n        return resp", "response": "Learn a message as spam or ham or forget"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a new random secret key at the given location on the the filesystem and returns its path", "response": "def generate_key(filepath):\n    ''' generates a new, random secret key at the given location on the\n    filesystem and returns its path\n    '''\n    fs = path.abspath(path.expanduser(filepath))\n    with open(fs, 'wb') as outfile:\n        outfile.write(Fernet.generate_key())\n    chmod(fs, 0o400)\n    return fs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_key(key=None, keyfile=None):\n    if key is None:\n        if keyfile is None:\n            key = environ.get('CRYPTOYAML_SECRET')\n            if key is None:\n                raise MissingKeyException(\n                    '''You must either provide a key value,'''\n                    ''' a path to a key or its value via the environment variable '''\n                    ''' CRYPTOYAML_SECRET'''\n                )\n            else:\n                key = key.encode('utf-8')\n        else:\n            key = open(keyfile, 'rb').read()\n    return key", "response": "returns a key given either its value a path to it on the filesystem\n    keyfile is a path to it on the filesystem\n    keyfile is a path to it on the filesystem\n    keyfile is a path to it on the filesystem\n    keyfile is a path to it on the filesystem\n    keyfile is a string that is used to read the file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread and decrypts the data from the filesystem", "response": "def read(self):\n        \"\"\" Reads and decrypts data from the filesystem \"\"\"\n        if path.exists(self.filepath):\n            with open(self.filepath, 'rb') as infile:\n                self.data = yaml.load(\n                    self.fernet.decrypt(infile.read()))\n        else:\n            self.data = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencrypts and writes the current state back onto the filesystem", "response": "def write(self):\n        \"\"\" Encrypts and writes the current state back onto the filesystem \"\"\"\n        with open(self.filepath, 'wb') as outfile:\n            outfile.write(\n                self.fernet.encrypt(\n                    yaml.dump(self.data, encoding='utf-8')))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_active_condition(self, condition, instances):\n        return_value = None\n        for instance in instances + [None]:\n            if not self.can_execute(instance):\n                continue\n            result = self.is_active(instance, condition)\n            if result is False:\n                return False\n            elif result is True:\n                return_value = True\n        return return_value", "response": "Returns a boolean representing if the condition active for the given list of instances and returns True if the condition active for the given instances."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the local installed version.", "response": "async def get_local_version(self):\n        \"\"\"Get the local installed version.\"\"\"\n        self._version_data[\"source\"] = \"Local\"\n        try:\n            from homeassistant.const import __version__ as localversion\n\n            self._version = localversion\n\n            _LOGGER.debug(\"Version: %s\", self.version)\n            _LOGGER.debug(\"Version data: %s\", self.version_data)\n        except ImportError as error:\n            _LOGGER.critical(\"Home Assistant not found - %s\", error)\n        except Exception as error:  # pylint: disable=broad-except\n            _LOGGER.critical(\"Something really wrong happend! - %s\", error)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_pypi_version(self):\n        self._version_data[\"beta\"] = self.beta\n        self._version_data[\"source\"] = \"PyPi\"\n\n        info_version = None\n        last_release = None\n\n        try:\n            async with async_timeout.timeout(5, loop=self.loop):\n                response = await self.session.get(URL[\"pypi\"])\n            data = await response.json()\n\n            info_version = data[\"info\"][\"version\"]\n            releases = data[\"releases\"]\n\n            for version in sorted(releases, reverse=True):\n                if re.search(r\"^(\\\\d+\\\\.)?(\\\\d\\\\.)?(\\\\*|\\\\d+)$\", version):\n                    continue\n                else:\n                    last_release = version\n                    break\n\n            self._version = info_version\n\n            if self.beta:\n                if info_version in last_release:\n                    self._version = info_version\n                else:\n                    self._version = last_release\n\n            _LOGGER.debug(\"Version: %s\", self.version)\n            _LOGGER.debug(\"Version data: %s\", self.version_data)\n        except asyncio.TimeoutError as error:\n            _LOGGER.error(\"Timeouterror fetching version information from PyPi\")\n        except KeyError as error:\n            _LOGGER.error(\"Error parsing version information from PyPi, %s\", error)\n        except TypeError as error:\n            _LOGGER.error(\"Error parsing version information from PyPi, %s\", error)\n        except aiohttp.ClientError as error:\n            _LOGGER.error(\"Error fetching version information from PyPi, %s\", error)\n        except socket.gaierror as error:\n            _LOGGER.error(\"Error fetching version information from PyPi, %s\", error)\n        except Exception as error:  # pylint: disable=broad-except\n            _LOGGER.critical(\"Something really wrong happend! - %s\", error)", "response": "Get version published to PyPi."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_hassio_version(self):\n        if self.image not in IMAGES:\n            _LOGGER.warning(\"%s is not a valid image using default\", self.image)\n            self.image = \"default\"\n\n        board = BOARDS.get(self.image, BOARDS[\"default\"])\n\n        self._version_data[\"source\"] = \"Hassio\"\n        self._version_data[\"beta\"] = self.beta\n        self._version_data[\"board\"] = board\n        self._version_data[\"image\"] = IMAGES[self.image][\"hassio\"]\n\n        try:\n            async with async_timeout.timeout(5, loop=self.loop):\n                response = await self.session.get(\n                    URL[\"hassio\"][\"beta\" if self.beta else \"stable\"]\n                )\n                data = await response.json()\n\n                self._version = data[\"homeassistant\"][IMAGES[self.image][\"hassio\"]]\n\n                self._version_data[\"hassos\"] = data[\"hassos\"][board]\n                self._version_data[\"supervisor\"] = data[\"supervisor\"]\n                self._version_data[\"hassos-cli\"] = data[\"hassos-cli\"]\n\n            _LOGGER.debug(\"Version: %s\", self.version)\n            _LOGGER.debug(\"Version data: %s\", self.version_data)\n        except asyncio.TimeoutError as error:\n            _LOGGER.error(\"Timeouterror fetching version information for hassio\")\n        except KeyError as error:\n            _LOGGER.error(\"Error parsing version information for hassio, %s\", error)\n        except TypeError as error:\n            _LOGGER.error(\"Error parsing version information for hassio, %s\", error)\n        except aiohttp.ClientError as error:\n            _LOGGER.error(\"Error fetching version information for hassio, %s\", error)\n        except socket.gaierror as error:\n            _LOGGER.error(\"Error fetching version information for hassio, %s\", error)\n        except Exception as error:  # pylint: disable=broad-except\n            _LOGGER.critical(\"Something really wrong happend! - %s\", error)", "response": "Get version published for Hassio."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_docker_version(self):\n        if self.image not in IMAGES:\n            _LOGGER.warning(\"%s is not a valid image using default\", self.image)\n            self.image = \"default\"\n\n        self._version_data[\"beta\"] = self.beta\n        self._version_data[\"source\"] = \"Docker\"\n        self._version_data[\"image\"] = IMAGES[self.image][\"docker\"]\n        try:\n            async with async_timeout.timeout(5, loop=self.loop):\n                response = await self.session.get(\n                    URL[\"docker\"].format(IMAGES[self.image][\"docker\"])\n                )\n                data = await response.json()\n                for version in data[\"results\"]:\n                    if version[\"name\"] in [\"latest\", \"landingpage\", \"rc\", \"dev\"]:\n                        continue\n                    elif re.search(r\"\\b.+b\\d\", version[\"name\"]):\n                        if self.beta:\n                            self._version = version[\"name\"]\n                            break\n                        else:\n                            continue\n                    else:\n                        self._version = version[\"name\"]\n\n                    if self._version is not None:\n                        break\n                    else:\n                        continue\n\n            _LOGGER.debug(\"Version: %s\", self.version)\n            _LOGGER.debug(\"Version data: %s\", self.version_data)\n        except asyncio.TimeoutError as error:\n            _LOGGER.error(\"Timeouterror fetching version information for docker\")\n        except KeyError as error:\n            _LOGGER.error(\"Error parsing version information for docker, %s\", error)\n        except TypeError as error:\n            _LOGGER.error(\"Error parsing version information for docker, %s\", error)\n        except aiohttp.ClientError as error:\n            _LOGGER.error(\"Error fetching version information for docker, %s\", error)\n        except socket.gaierror as error:\n            _LOGGER.error(\"Error fetching version information for docker, %s\", error)\n        except Exception as error:  # pylint: disable=broad-except\n            _LOGGER.critical(\"Something really wrong happend! - %s\", error)", "response": "Get version published for docker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef relative_playbook(playbook):\n    if playbook.startswith(fs_prefix):\n        return True, playbook[len(fs_prefix):]\n    else:\n        return False, playbook.split('/')[-1]", "response": "Returns a tuple containing a controlled and a playbook."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef matches(self, a, b, **config):\n        submitter_a = a['msg']['override']['submitter']['name']\n        submitter_b = b['msg']['override']['submitter']['name']\n        if submitter_a != submitter_b:\n            return False\n        return True", "response": "Check if the message matches by username"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_stream_subscriber(self):\n        if not self._stream_process_started:  # pragma: no cover\n            if sys.platform.startswith(\"win\"):  # if we're on windows we can't expect multiprocessing to work\n                self._stream_process_started = True\n                self._stream()\n            self._stream_process_started = True\n            self._stream_process.start()", "response": "Starts the stream consumer s main loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subscribe(self, stream):\n        if not self._stream_process_started:\n            raise StreamSubscriberNotStarted()\n\n        def real_decorator(func):\n            if not self._on_delete:\n                raise DeleteRequired(\"\"\"An on_delete function is required. You must process delete messages and remove\n                 them from your system (if stored) in order to remain compliant with the ToS\"\"\")\n            if hasattr(self.factory, 'datasift') and 'send_message' in self.factory.datasift:  # pragma: no cover\n                self.subscriptions[stream] = func\n                self.factory.datasift['send_message'](json.dumps({\"action\": \"subscribe\", \"hash\": stream}).encode(\"utf8\"))\n            else:  # pragma: no cover\n                raise StreamNotConnected('The client is not connected to DataSift, unable to subscribe to stream')\n\n        return real_decorator", "response": "A decorator that registers a function as a subscription to a specific stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to set the callback for the opening of a stream. Can be called manually:: def open_callback(data): setup_stream() client.on_open(open_callback) or as a decorator:: @client.on_open def open_callback(): setup_stream()", "response": "def on_open(self, func):\n        \"\"\" Function to set the callback for the opening of a stream.\n\n            Can be called manually::\n\n                def open_callback(data):\n                    setup_stream()\n                client.on_open(open_callback)\n\n            or as a decorator::\n\n                @client.on_open\n                def open_callback():\n                    setup_stream()\n        \"\"\"\n        self._on_open = func\n        if self.opened:  # pragma: no cover\n            self._on_open(self)\n        return func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stream(self):  # pragma: no cover\n        self.factory.protocol = LiveStream\n        self.factory.datasift = {\n            'on_open': self._on_open,\n            'on_close': self._on_close,\n            'on_message': self._on_message,\n            'send_message': None\n        }\n        if self.config.ssl:\n            from twisted.internet import ssl\n            options = ssl.optionsForClientTLS(hostname=WEBSOCKET_HOST)\n            connectWS(self.factory, options)\n        else:\n            connectWS(self.factory)\n        reactor.run()", "response": "Runs in a sub - process to perform stream consumption"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile(self, csdl):\n        return self.request.post('compile', data=dict(csdl=csdl))", "response": "Compiles the given CSDL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given CSDL is valid.", "response": "def is_valid(self, csdl):\n        \"\"\" Checks if the given CSDL is valid.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/validate\n\n            :param csdl: CSDL to validate\n            :type csdl: str\n            :returns: Boolean indicating the validity of the CSDL\n            :rtype: bool\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        try:\n            self.validate(csdl)\n        except DataSiftApiException as e:\n            if e.response.status_code == 400:\n                return False\n            else:\n                raise e\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the number of objects processed and delivered for a given time period", "response": "def usage(self, period='hour'):\n        \"\"\" Check the number of objects processed and delivered for a given time period\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/usage\n\n            :param period: (optional) time period to measure usage for, can be one of \"day\", \"hour\" or \"current\" (5 minutes), default is hour\n            :type period: str\n            :returns: dict with extra response data\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self.request.get('usage', params=dict(period=period))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dpu(self, hash=None, historics_id=None):\n        if hash:\n            return self.request.get('dpu', params=dict(hash=hash))\n        if historics_id:\n            return self.request.get('dpu', params=dict(historics_id=historics_id))", "response": "Calculate the DPU cost of consuming a stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pull(self, subscription_id, size=None, cursor=None):\n        params = {'id': subscription_id}\n        if size:\n            params['size'] = size\n        if cursor:\n            params['cursor'] = cursor\n        raw = self.request('get', 'pull', params=params)\n\n        def pull_parser(headers, data):\n            pull_type = headers.get(\"X-DataSift-Format\")\n            if pull_type in (\"json_meta\", \"json_array\"):\n                return json.loads(data)\n            else:\n                lines = data.strip().split(\"\\n\").__iter__()\n                return list(map(json.loads, lines))\n\n        return self.request.build_response(raw, parser=pull_parser)", "response": "Pulls a series of interactions from the queue for the given subscription ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_player_profile(self, player_handle):\r\n        url = self.pubg_url + player_handle\r\n        response = requests.request(\"GET\", url, headers=self.headers)\r\n        data = json.loads(response.text)\r\n        return data", "response": "Returns pubg player profile from PUBG api no filtering"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the full set of data on a player no filtering", "response": "def player(self, player_handle):\r\n        \"\"\"Returns the full set of data on a player, no filtering\"\"\"\r\n        try:\r\n            url = self.pubg_url + player_handle\r\n            response = requests.request(\"GET\", url, headers=self.headers)\r\n            return json.loads(response.text)\r\n        except BaseException as error:\r\n            print('Unhandled exception: ' + str(error))\r\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the full set of data on a player no filtering", "response": "def player_s(self, sid)       :\r\n        \"\"\"Returns the full set of data on a player, no filtering\"\"\"\r\n        try:\r\n            url = self.pubg_url_steam.format(str(sid))\r\n            response = requests.request(\"GET\", url, headers=self.headers)\r\n            return json.loads(response.text)\r\n        except BaseException as error:\r\n            print('Unhandled exception: ' + str(error))\r\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef player_mode_stats(self, player_handle, game_mode=constants.GAME_MODE_WILDCARD, game_region=constants.GAME_REGION_WILDCARD):\r\n        if game_mode not in constants.GAME_MODES:\r\n            raise APIException(\"game_mode must be one of: solo, duo, squad, all\")\r\n        if game_region not in constants.GAME_REGIONS:\r\n            raise APIException(\"game_region must be one of: as, na, agg, sea, eu, oc, sa, all\")\r\n        try:\r\n            data = self._get_player_profile(player_handle)\r\n            data = self._filter_gameplay_stats(data, game_mode, game_region)\r\n            return data\r\n        except BaseException as error:\r\n            print('Unhandled exception: ' + str(error))\r\n            raise", "response": "Returns the stats for a particular gamemode of play and game_region of play."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _filter_gameplay_stats(self, data, game_mode, game_region):\r\n        return_data = []\r\n        for stat in data['Stats']:\r\n            if self._is_target_game_mode(stat, game_mode) and self._is_target_region(stat, game_region):\r\n                return_data.append(stat)\r\n        return return_data", "response": "Returns a list of gameplay stats that are filtered by game_mode and game_region."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_target_game_mode(self, stat, game_mode):\r\n        if game_mode == constants.GAME_MODE_WILDCARD:\r\n            return True\r\n        return stat['Match'] == game_mode", "response": "Returns True if the stat matches target game mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the stat matches the target game region.", "response": "def _is_target_region(self, stat, game_region):\r\n        \"\"\"Returns if the stat matches target game region.\r\n\r\n            :param stat: Json of gameplay stat.\r\n            :type stat: dict\r\n            :param game_region: Target game region.\r\n            :type game_region: str\r\n            :return: return does the stat matches target game region.\r\n            :rtype: bool\r\n        \"\"\"\r\n        if game_region == constants.GAME_REGION_WILDCARD:\r\n            return True\r\n        return stat['Region'] == game_region"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef player_skill(self, player_handle, game_mode='solo'):\r\n        if game_mode not in constants.GAME_MODES:\r\n            raise APIException(\"game_mode must be one of: solo, duo, squad, all\")\r\n        try:\r\n            data = self._get_player_profile(player_handle)\r\n            player_stats = {}\r\n            return_data = []\r\n            for stat in data['Stats']:\r\n                if stat['Match'] == game_mode:\r\n                    for datas in stat['Stats']:\r\n                        if datas['label'] == 'Rating':\r\n                            player_stats[stat['Region']] = datas['value']\r\n            return player_stats\r\n        except BaseException as error:\r\n            print('Unhandled exception: ' + str(error))\r\n            raise", "response": "Returns the current skill rating of a player for a specified gamemode"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot(nxG, nyG, iBeg, iEnd, jBeg, jEnd, data, title=''):\n    sz = MPI.COMM_WORLD.Get_size()\n    rk = MPI.COMM_WORLD.Get_rank()\n    iBegs = MPI.COMM_WORLD.gather(iBeg, root=0)\n    iEnds = MPI.COMM_WORLD.gather(iEnd, root=0)\n    jBegs = MPI.COMM_WORLD.gather(jBeg, root=0)\n    jEnds = MPI.COMM_WORLD.gather(jEnd, root=0)\n    arrays = MPI.COMM_WORLD.gather(numpy.array(data), root=0)\n    if rk == 0:\n        bigArray = numpy.zeros((nxG, nyG), data.dtype)\n        for pe in range(sz):\n            bigArray[iBegs[pe]:iEnds[pe], jBegs[pe]:jEnds[pe]] = arrays[pe]\n        from matplotlib import pylab\n        pylab.pcolor(bigArray.transpose())\n        # add the decomp domains\n        for pe in range(sz):\n            pylab.plot([iBegs[pe], iBegs[pe]], [0, nyG - 1], 'w--')\n            pylab.plot([0, nxG - 1], [jBegs[pe], jBegs[pe]], 'w--')\n        pylab.title(title)\n        pylab.show()", "response": "Plot distributed array of all the decomp domains in a single global cell."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setValues(nxG, nyG, iBeg, iEnd, jBeg, jEnd, data):\n    nxGHalf = nxG/2.\n    nyGHalf = nyG/2.\n    nxGQuart = nxGHalf/2.\n    nyGQuart = nyGHalf/2.\n    for i in range(data.shape[0]):\n        iG = iBeg + i\n        di = iG - nxG\n        for j in range(data.shape[1]):\n            jG = jBeg + j\n            dj = jG - 0.8*nyG\n            data[i, j] = numpy.floor(1.9*numpy.exp(-di**2/nxGHalf**2 - dj**2/nyGHalf**2))", "response": "Set the values of the internal structures in the internal structures."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_ls(self, nothing = ''):\n        for d in self.dirs:\n            self.stdout.write(\"\\033[0;34m\" + ('%s\\n' % d) + \"\\033[0m\")\n\n        for f in self.files:\n            self.stdout.write('%s\\n' % f)", "response": "list files in current remote directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange current working directory", "response": "def do_cd(self, path = '/'):\n        \"\"\"change current working directory\"\"\"\n        path = path[0]\n\n        if path == \"..\":\n            self.current_path = \"/\".join(self.current_path[:-1].split(\"/\")[0:-1]) + '/'\n        elif path == '/':\n            self.current_path = \"/\"\n        else:\n            if path[-1] == '/':\n                self.current_path += path\n            else:\n                self.current_path += path + '/'\n\n        resp = self.n.getList(self.current_path, type=3)\n\n        if resp:\n            self.dirs = []\n            self.files = []\n\n            for f in resp:\n                name = f['href'].encode('utf-8')\n\n                if name[-1] == '/':\n                    self.dirs.append(os.path.basename(name[:-1]))\n                else:\n                    self.files.append(os.path.basename(name))\n\n        self.prompt = \"> %s@Ndrive:%s \" %(self.id, self.current_path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_cat(self, path):\n        path = path[0]\n        tmp_file_path = self.TMP_PATH + 'tmp'\n\n        if not os.path.exists(self.TMP_PATH):\n            os.makedirs(self.TMP_PATH)\n\n        f = self.n.downloadFile(self.current_path + path, tmp_file_path)\n        f = open(tmp_file_path, 'r')\n\n        self.stdout.write(f.read())\n        self.stdout.write(\"\\n\")", "response": "display the contents of a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new directory", "response": "def do_mkdir(self, path):\n        \"\"\"create a new directory\"\"\"\n        path = path[0]\n\n        self.n.makeDirectory(self.current_path + path)\n        self.dirs = self.dir_complete()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_rm(self, path):\n        path = path[0]\n\n        \"\"\"delete a file or directory\"\"\"\n        self.n.delete(self.current_path + path)\n        self.dirs = self.dir_complete()\n        self.files = self.file_complete()", "response": "delete a file or directory"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_mv(self, from_path, to_path, nothing = ''):\n        self.n.doMove(self.current_path + from_path,\n                      self.current_path + to_path)", "response": "Move a file or directory or directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy file from Ndrive to local file and print out the metadata.", "response": "def do_get(self, from_path, to_path):\n        \"\"\"\n        Copy file from Ndrive to local file and print out out the metadata.\n\n        Examples:\n          Ndrive> get file.txt ~/ndrive-file.txt\n        \"\"\"\n        to_file = open(os.path.expanduser(to_path), \"wb\")\n\n        self.n.downloadFile(self.current_path + \"/\" + from_path, to_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_put(self, from_path, to_path):\n        from_file = open(os.path.expanduser(from_path), \"rb\")\n\n        self.n.put(self.current_path + \"/\" + from_path, to_path)", "response": "Copy local file to Ndrive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching Ndrive for filenames containing the given string.", "response": "def do_search(self, string):\n        \"\"\"Search Ndrive for filenames containing the given string.\"\"\"\n        results = self.n.doSearch(string, full_path = self.current_path)\n\n        if results:\n            for r in results:\n                self.stdout.write(\"%s\\n\" % r['path'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tr(string1, string2, source, option=''):\n    if not is_valid_type(source):\n        raise TypeError('source must be unicode')\n\n    from_list = make_char_list(string1)\n    if option == 's':\n        from_list = to_unichr(from_list)\n        return squeeze(from_list, source)\n    elif 'c' in option:\n        from_list = to_unichr(from_list)\n        from_list = [ord(c) for c in set(source) - set(from_list)]\n        if 'd' in option:\n            to_list = [None for i in from_list]\n        else:\n            to_list = [string2[-1] for i in from_list]\n        source = translate(from_list, to_list, source)\n        if 's' in option:\n            source = squeeze(to_list, source)\n        return source\n    elif 'd' in option:\n        to_list = [None for i in from_list]\n        source = translate(from_list, to_list, source)\n        if 's' in option:\n            to_list = make_char_list(string2)\n            to_list = to_unichr(to_list)\n            source = squeeze(to_list, source)\n        return source\n    else:\n        to_list = make_char_list(string2)\n        length_diff = (len(from_list) - len(to_list))\n        if length_diff:\n            to_list += [to_list[-1]] * length_diff\n        to_list = to_unichr(to_list)\n        return translate(from_list, to_list, source)", "response": "This function translates two string into a single string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads a file to a service", "response": "def upload(self, filepath, service_path, remove=False):\n        '''\n        \"Upload\" a file to a service\n\n        This copies a file from the local filesystem into the ``DataService``'s\n        filesystem. If ``remove==True``, the file is moved rather than copied.\n\n        If ``filepath`` and ``service_path`` paths are the same, ``upload``\n        deletes the file if ``remove==True`` and returns.\n\n        Parameters\n        ----------\n        filepath : str\n            Relative or absolute path to the file to be uploaded on the user's\n            filesystem\n\n        service_path: str\n            Path to the destination for the file on the ``DataService``'s\n            filesystem\n\n        remove : bool\n            If true, the file is moved rather than copied\n        '''\n\n        local = OSFS(os.path.dirname(filepath))\n\n        # Skip if source and dest are the same\n        if self.fs.hassyspath(service_path) and (\n            self.fs.getsyspath(service_path) == local.getsyspath(\n                os.path.basename(filepath))):\n\n            if remove:\n                os.remove(filepath)\n\n            return\n\n        if not self.fs.isdir(fs.path.dirname(service_path)):\n            self.fs.makedir(\n                fs.path.dirname(service_path),\n                recursive=True,\n                allow_recreate=True)\n\n        if remove:\n            fs.utils.movefile(\n                local,\n                os.path.basename(filepath),\n                self.fs,\n                service_path)\n\n        else:\n            fs.utils.copyfile(\n                local,\n                os.path.basename(filepath),\n                self.fs,\n                service_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a storage path for the archive and version number.", "response": "def get_version_path(self, version=None):\n        '''\n        Returns a storage path for the archive and version\n\n        If the archive is versioned, the version number is used as the file\n        path and the archive path is the directory. If not, the archive path is\n        used as the file path.\n\n        Parameters\n        ----------\n        version : str or object\n            Version number to use as file name on versioned archives (default\n            latest unless ``default_version`` set)\n\n        Examples\n        --------\n\n        .. code-block:: python\n\n            >>> arch = DataArchive(None, 'arch', None, 'a1', versioned=False)\n            >>> print(arch.get_version_path())\n            a1\n            >>>\n            >>> ver = DataArchive(None, 'ver', None, 'a2', versioned=True)\n            >>> print(ver.get_version_path('0.0.0'))\n            a2/0.0\n            >>>\n            >>> print(ver.get_version_path('0.0.1a1'))\n            a2/0.0.1a1\n            >>>\n            >>> print(ver.get_version_path('latest')) # doctest: +ELLIPSIS\n            Traceback (most recent call last):\n            ...\n            AttributeError: 'NoneType' object has no attribute 'manager'\n\n        '''\n\n        version = _process_version(self, version)\n\n        if self.versioned:\n            return fs.path.join(self.archive_path, str(version))\n\n        else:\n            return self.archive_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(\n            self,\n            filepath,\n            cache=False,\n            remove=False,\n            bumpversion=None,\n            prerelease=None,\n            dependencies=None,\n            metadata=None,\n            message=None):\n        '''\n        Enter a new version to a DataArchive\n\n        Parameters\n        ----------\n\n        filepath : str\n            The path to the file on your local file system\n\n        cache : bool\n            Turn on caching for this archive if not already on before update\n\n        remove : bool\n            removes a file from your local directory\n\n        bumpversion : str\n            Version component to update on write if archive is versioned. Valid\n            bumpversion values are 'major', 'minor', and 'patch', representing\n            the three components of the strict version numbering system (e.g.\n            \"1.2.3\"). If bumpversion is None the version number is not updated\n            on write. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, bumpversion is\n            ignored.\n\n        prerelease : str\n            Prerelease component of archive version to update on write if\n            archive is versioned. Valid prerelease values are 'alpha' and\n            'beta'. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, prerelease is\n            ignored.\n\n        metadata : dict\n            Updates to archive metadata. Pass {key: None} to remove a key from\n            the archive's metadata.\n        '''\n\n        if metadata is None:\n            metadata = {}\n\n        latest_version = self.get_latest_version()\n\n        hashval = self.api.hash_file(filepath)\n\n        checksum = hashval['checksum']\n        algorithm = hashval['algorithm']\n\n        if checksum == self.get_latest_hash():\n            self.update_metadata(metadata)\n\n            if remove and os.path.isfile(filepath):\n                os.remove(filepath)\n\n            return\n\n        if self.versioned:\n            if latest_version is None:\n                latest_version = BumpableVersion()\n\n            next_version = latest_version.bump(\n                kind=bumpversion,\n                prerelease=prerelease,\n                inplace=False)\n\n        else:\n            next_version = None\n\n        next_path = self.get_version_path(next_version)\n\n        if cache:\n            self.cache(next_version)\n\n        if self.is_cached(next_version):\n            self.authority.upload(filepath, next_path)\n            self.api.cache.upload(filepath, next_path, remove=remove)\n\n        else:\n            self.authority.upload(filepath, next_path, remove=remove)\n\n        self._update_manager(\n            archive_metadata=metadata,\n            version_metadata=dict(\n                checksum=checksum,\n                algorithm=algorithm,\n                version=next_version,\n                dependencies=dependencies,\n                message=message))", "response": "Update the version number of a specific file on the local file system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget default dependencies for archive", "response": "def _get_default_dependencies(self):\n        '''\n        Get default dependencies for archive\n\n        Get default dependencies from requirements file or (if no requirements\n        file) from previous version\n        '''\n\n        # Get default dependencies from requirements file\n        default_dependencies = {\n            k: v for k,\n            v in self.api.default_versions.items() if k != self.archive_name}\n\n        # If no requirements file or is empty:\n        if len(default_dependencies) == 0:\n\n            # Retrieve dependencies from last archive record\n            history = self.get_history()\n\n            if len(history) > 0:\n                default_dependencies = history[-1].get('dependencies', {})\n\n        return default_dependencies"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open(\n            self,\n            mode='r',\n            version=None,\n            bumpversion=None,\n            prerelease=None,\n            dependencies=None,\n            metadata=None,\n            message=None,\n            *args,\n            **kwargs):\n        '''\n        Opens a file for read/write\n\n        Parameters\n        ----------\n        mode : str\n            Specifies the mode in which the file is opened (default 'r')\n\n        version : str\n            Version number of the file to open (default latest)\n\n        bumpversion : str\n            Version component to update on write if archive is versioned. Valid\n            bumpversion values are 'major', 'minor', and 'patch', representing\n            the three components of the strict version numbering system (e.g.\n            \"1.2.3\"). If bumpversion is None the version number is not updated\n            on write. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, bumpversion is\n            ignored.\n\n        prerelease : str\n            Prerelease component of archive version to update on write if\n            archive is versioned. Valid prerelease values are 'alpha' and\n            'beta'. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, prerelease is\n            ignored.\n\n        metadata : dict\n            Updates to archive metadata. Pass {key: None} to remove a key from\n            the archive's metadata.\n\n\n        args, kwargs sent to file system opener\n\n        '''\n\n        if metadata is None:\n            metadata = {}\n\n        latest_version = self.get_latest_version()\n        version = _process_version(self, version)\n\n        version_hash = self.get_version_hash(version)\n\n        if self.versioned:\n\n            if latest_version is None:\n                latest_version = BumpableVersion()\n\n            next_version = latest_version.bump(\n                kind=bumpversion,\n                prerelease=prerelease,\n                inplace=False)\n\n            msg = \"Version must be bumped on write. \" \\\n                \"Provide bumpversion and/or prerelease.\"\n\n            assert next_version > latest_version, msg\n\n            read_path = self.get_version_path(version)\n            write_path = self.get_version_path(next_version)\n\n        else:\n            read_path = self.archive_path\n            write_path = self.archive_path\n            next_version = None\n\n        # version_check returns true if fp's hash is current as of read\n        def version_check(chk):\n            return chk['checksum'] == version_hash\n\n        # Updater updates the manager with the latest version number\n        def updater(checksum, algorithm):\n            self._update_manager(\n                archive_metadata=metadata,\n                version_metadata=dict(\n                    version=next_version,\n                    dependencies=dependencies,\n                    checksum=checksum,\n                    algorithm=algorithm,\n                    message=message))\n\n        opener = data_file.open_file(\n            self.authority,\n            self.api.cache,\n            updater,\n            version_check,\n            self.api.hash_file,\n            read_path,\n            write_path,\n            mode=mode,\n            *args,\n            **kwargs)\n\n        with opener as f:\n            yield f", "response": "Opens a new file for read or write."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_local_path(\n            self,\n            version=None,\n            bumpversion=None,\n            prerelease=None,\n            dependencies=None,\n            metadata=None,\n            message=None):\n        '''\n        Returns a local path for read/write\n\n        Parameters\n        ----------\n        version : str\n            Version number of the file to retrieve (default latest)\n\n        bumpversion : str\n            Version component to update on write if archive is versioned. Valid\n            bumpversion values are 'major', 'minor', and 'patch', representing\n            the three components of the strict version numbering system (e.g.\n            \"1.2.3\"). If bumpversion is None the version number is not updated\n            on write. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, bumpversion is\n            ignored.\n\n        prerelease : str\n            Prerelease component of archive version to update on write if\n            archive is versioned. Valid prerelease values are 'alpha' and\n            'beta'. Either bumpversion or prerelease (or both) must be a\n            non-None value. If the archive is not versioned, prerelease is\n            ignored.\n\n        metadata : dict\n            Updates to archive metadata. Pass {key: None} to remove a key from\n            the archive's metadata.\n\n        '''\n\n        if metadata is None:\n            metadata = {}\n\n        latest_version = self.get_latest_version()\n        version = _process_version(self, version)\n\n        version_hash = self.get_version_hash(version)\n\n        if self.versioned:\n\n            if latest_version is None:\n                latest_version = BumpableVersion()\n\n            next_version = latest_version.bump(\n                kind=bumpversion,\n                prerelease=prerelease,\n                inplace=False)\n\n            msg = \"Version must be bumped on write. \" \\\n                \"Provide bumpversion and/or prerelease.\"\n\n            assert next_version > latest_version, msg\n\n            read_path = self.get_version_path(version)\n            write_path = self.get_version_path(next_version)\n\n        else:\n            read_path = self.archive_path\n            write_path = self.archive_path\n            next_version = None\n\n        # version_check returns true if fp's hash is current as of read\n        def version_check(chk):\n            return chk['checksum'] == version_hash\n\n        # Updater updates the manager with the latest version number\n        def updater(checksum, algorithm):\n            self._update_manager(\n                archive_metadata=metadata,\n                version_metadata=dict(\n                    version=next_version,\n                    dependencies=dependencies,\n                    checksum=checksum,\n                    algorithm=algorithm,\n                    message=message))\n\n        path = data_file.get_local_path(\n            self.authority,\n            self.api.cache,\n            updater,\n            version_check,\n            self.api.hash_file,\n            read_path,\n            write_path)\n\n        with path as fp:\n            yield fp", "response": "Returns a local path for the specified version number."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef download(self, filepath, version=None):\n        '''\n        Downloads a file from authority to local path\n\n        1. First checks in cache to check if file is there and if it is, is it\n           up to date\n        2. If it is not up to date, it will download the file to cache\n        '''\n\n        version = _process_version(self, version)\n\n        dirname, filename = os.path.split(\n            os.path.abspath(os.path.expanduser(filepath)))\n\n        assert os.path.isdir(dirname), 'Directory  not found: \"{}\"'.format(\n            dirname)\n\n        local = OSFS(dirname)\n\n        version_hash = self.get_version_hash(version)\n\n        # version_check returns true if fp's hash is current as of read\n        def version_check(chk):\n            return chk['checksum'] == version_hash\n\n        if os.path.exists(filepath):\n            if version_check(self.api.hash_file(filepath)):\n                return\n\n        read_path = self.get_version_path(version)\n\n        with data_file._choose_read_fs(\n                self.authority,\n                self.api.cache,\n                read_path,\n                version_check,\n                self.api.hash_file) as read_fs:\n\n            fs.utils.copyfile(\n                read_fs,\n                read_path,\n                local,\n                filename)", "response": "Downloads a file from authority to local path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the archive and all its versions.", "response": "def delete(self):\n        '''\n        Delete the archive\n\n        .. warning::\n\n            Deleting an archive will erase all data and metadata permanently.\n            For help setting user permissions, see\n            :ref:`Administrative Tools <admin>`\n\n        '''\n        versions = self.get_versions()\n        self.api.manager.delete_archive_record(self.archive_name)\n\n        for version in versions:\n            if self.authority.fs.exists(self.get_version_path(version)):\n                self.authority.fs.remove(self.get_version_path(version))\n\n            if self.api.cache:\n                if self.api.cache.fs.exists(self.get_version_path(version)):\n                    self.api.cache.fs.remove(self.get_version_path(version))\n\n        if self.authority.fs.exists(self.archive_name):\n            self.authority.fs.removedir(self.archive_name)\n\n        if self.api.cache:\n            if self.api.cache.fs.exists(self.archive_name):\n                self.api.cache.fs.removedir(self.archive_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isfile(self, version=None, *args, **kwargs):\n        '''\n        Check whether the path exists and is a file\n        '''\n        version = _process_version(self, version)\n\n        path = self.get_version_path(version)\n        self.authority.fs.isfile(path, *args, **kwargs)", "response": "Check whether the path exists and is a file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the archive contains a cached archive.", "response": "def is_cached(self, version=None):\n        '''\n        Set the cache property to start/stop file caching for this archive\n        '''\n        version = _process_version(self, version)\n\n        if self.api.cache and self.api.cache.fs.isfile(\n                self.get_version_path(version)):\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_dependencies(self, version=None):\n        '''\n        Parameters\n        ----------\n        version: str\n            string representing version number whose dependencies you are\n            looking up\n        '''\n\n        version = _process_version(self, version)\n        history = self.get_history()\n\n        for v in reversed(history):\n            if BumpableVersion(v['version']) == version:\n                return v['dependencies']\n\n        raise ValueError('Version {} not found'.format(version))", "response": "Returns the list of dependencies of the current version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_tags(self, *tags):\n        '''\n        Set tags for a given archive\n        '''\n        normed_tags = self.api.manager._normalize_tags(tags)\n        self.api.manager.add_tags(self.archive_name, normed_tags)", "response": "Set tags for a given archive\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(\n        file,\n        mode=\"r\",\n        buffering=-1,\n        encoding=None,\n        errors=None,\n        newline=None,\n        closefd=True,\n        opener=None,\n):\n    r\"\"\"Open file and return a stream.  Raise OSError upon failure.\n\n    file is either a text or byte string giving the name (and the path\n    if the file isn't in the current working directory) of the file to\n    be opened or an integer file descriptor of the file to be\n    wrapped. (If a file descriptor is given, it is closed when the\n    returned I/O object is closed, unless closefd is set to False.)\n\n    mode is an optional string that specifies the mode in which the file is\n    opened. It defaults to 'r' which means open for reading in text mode. Other\n    common values are 'w' for writing (truncating the file if it already\n    exists), 'x' for exclusive creation of a new file, and 'a' for appending\n    (which on some Unix systems, means that all writes append to the end of the\n    file regardless of the current seek position). In text mode, if encoding is\n    not specified the encoding used is platform dependent. (For reading and\n    writing raw bytes use binary mode and leave encoding unspecified.) The\n    available modes are:\n\n    ========= ===============================================================\n    Character Meaning\n    --------- ---------------------------------------------------------------\n    'r'       open for reading (default)\n    'w'       open for writing, truncating the file first\n    'x'       create a new file and open it for writing\n    'a'       open for writing, appending to the end of the file if it exists\n    'b'       binary mode\n    't'       text mode (default)\n    '+'       open a disk file for updating (reading and writing)\n    'U'       universal newline mode (deprecated)\n    ========= ===============================================================\n\n    The default mode is 'rt' (open for reading text). For binary random\n    access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n    'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n    raises an `FileExistsError` if the file already exists.\n\n    Python distinguishes between files opened in binary and text modes,\n    even when the underlying operating system doesn't. Files opened in\n    binary mode (appending 'b' to the mode argument) return contents as\n    bytes objects without any decoding. In text mode (the default, or when\n    't' is appended to the mode argument), the contents of the file are\n    returned as strings, the bytes having been first decoded using a\n    platform-dependent encoding or using the specified encoding if given.\n\n    'U' mode is deprecated and will raise an exception in future versions\n    of Python.  It has no effect in Python 3.  Use newline to control\n    universal newlines mode.\n\n    buffering is an optional integer used to set the buffering policy.\n    Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n    line buffering (only usable in text mode), and an integer > 1 to indicate\n    the size of a fixed-size chunk buffer.  When no buffering argument is\n    given, the default buffering policy works as follows:\n\n    * Binary files are buffered in fixed-size chunks; the size of the buffer\n      is chosen using a heuristic trying to determine the underlying device's\n      \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n      On many systems, the buffer will typically be 4096 or 8192 bytes long.\n\n    * \"Interactive\" text files (files for which isatty() returns True)\n      use line buffering.  Other text files use the policy described above\n      for binary files.\n\n    encoding is the str name of the encoding used to decode or encode the\n    file. This should only be used in text mode. The default encoding is\n    platform dependent, but any encoding supported by Python can be\n    passed.  See the codecs module for the list of supported encodings.\n\n    errors is an optional string that specifies how encoding errors are to\n    be handled---this argument should not be used in binary mode. Pass\n    'strict' to raise a ValueError exception if there is an encoding error\n    (the default of None has the same effect), or pass 'ignore' to ignore\n    errors. (Note that ignoring encoding errors can lead to data loss.)\n    See the documentation for codecs.register for a list of the permitted\n    encoding error strings.\n\n    newline is a string controlling how universal newlines works (it only\n    applies to text mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It\n    works as follows:\n\n    * On input, if newline is None, universal newlines mode is\n      enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n      these are translated into '\\n' before being returned to the\n      caller. If it is '', universal newline mode is enabled, but line\n      endings are returned to the caller untranslated. If it has any of\n      the other legal values, input lines are only terminated by the given\n      string, and the line ending is returned to the caller untranslated.\n\n    * On output, if newline is None, any '\\n' characters written are\n      translated to the system default line separator, os.linesep. If\n      newline is '', no translation takes place. If newline is any of the\n      other legal values, any '\\n' characters written are translated to\n      the given string.\n\n    closedfd is a bool. If closefd is False, the underlying file descriptor\n    will be kept open when the file is closed. This does not work when a file\n    name is given and must be True in that case.\n\n    The newly created file is non-inheritable.\n\n    A custom opener can be used by passing a callable as *opener*. The\n    underlying file descriptor for the file object is then obtained by calling\n    *opener* with (*file*, *flags*). *opener* must return an open file\n    descriptor (passing os.open as *opener* results in functionality similar to\n    passing None).\n\n    open() returns a file object whose type depends on the mode, and\n    through which the standard file operations such as reading and writing\n    are performed. When open() is used to open a file in a text mode ('w',\n    'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n    a file in a binary mode, the returned class varies: in read binary\n    mode, it returns a BufferedReader; in write binary and append binary\n    modes, it returns a BufferedWriter, and in read/write mode, it returns\n    a BufferedRandom.\n\n    It is also possible to use a string or bytearray as a file for both\n    reading and writing. For strings StringIO can be used like a file\n    opened in a text mode, and for bytes a BytesIO can be used like a file\n    opened in a binary mode.\n    \"\"\"\n    result = sync_io.open(\n        file,\n        mode,\n        buffering,\n        encoding,\n        errors,\n        newline,\n        closefd,\n        opener,\n    )\n\n    return wrap_file(result)", "response": "r Open file and return a stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a file like object in an async stream wrapper.", "response": "def wrap_file(file_like_obj):\n    \"\"\"Wrap a file like object in an async stream wrapper.\n\n    Files generated with `open()` may be one of several types. This\n    convenience function retruns the stream wrapped in the most appropriate\n    wrapper for the type. If the stream is already wrapped it is returned\n    unaltered.\n    \"\"\"\n    if isinstance(file_like_obj, AsyncIOBaseWrapper):\n\n        return file_like_obj\n\n    if isinstance(file_like_obj, sync_io.FileIO):\n\n        return AsyncFileIOWrapper(file_like_obj)\n\n    if isinstance(file_like_obj, sync_io.BufferedRandom):\n\n        return AsyncBufferedRandomWrapper(file_like_obj)\n\n    if isinstance(file_like_obj, sync_io.BufferedReader):\n\n        return AsyncBufferedReaderWrapper(file_like_obj)\n\n    if isinstance(file_like_obj, sync_io.BufferedWriter):\n\n        return AsyncBufferedWriterWrapper(file_like_obj)\n\n    if isinstance(file_like_obj, sync_io.TextIOWrapper):\n\n        return AsyncTextIOWrapperWrapper(file_like_obj)\n\n    raise TypeError(\n        'Unrecognized file stream type {}.'.format(file_like_obj.__class__),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BytesIO(*args, **kwargs):\n    raw = sync_io.BytesIO(*args, **kwargs)\n    return AsyncBytesIOWrapper(raw)", "response": "Returns an async wrapper for the BytesIO constructor."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove to new file position.", "response": "async def seek(self, pos, whence=sync_io.SEEK_SET):\n        \"\"\"Move to new file position.\n\n        Argument offset is a byte count.  Optional argument whence defaults to\n        SEEK_SET or 0 (offset from start of file, offset should be >= 0); other\n        values are SEEK_CUR or 1 (move relative to current position, positive\n        or negative), and SEEK_END or 2 (move relative to end of file, usually\n        negative, although many platforms allow seeking beyond the end of a\n        file).\n\n        Note that not all file objects are seekable.\n        \"\"\"\n        return self._stream.seek(pos, whence)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a limit to any query and allow a return as pandas. DataFrame", "response": "def _limit_and_df(self, query, limit, as_df=False):\n        \"\"\"adds a limit (limit==None := no limit) to any query and allow a return as pandas.DataFrame\n\n        :param bool as_df: if is set to True results return as pandas.DataFrame\n        :param `sqlalchemy.orm.query.Query` query: SQL Alchemy query \n        :param int limit: maximum number of results\n        :return: query result of pyctd.manager.models.XY objects\n        \"\"\"\n        if limit:\n            query = query.limit(limit)\n\n        if as_df:\n            results = read_sql(query.statement, self.engine)\n        else:\n            results = query.all()\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _join_gene(query, gene_name, gene_symbol, gene_id):\n        if gene_name or gene_symbol:\n            query = query.join(models.Gene)\n\n            if gene_symbol:\n                query = query.filter(models.Gene.gene_symbol.like(gene_symbol))\n\n            if gene_name:\n                query = query.filter(models.Gene.gene_name.like(gene_name))\n\n            if gene_id:\n                query = query.filter(models.Gene.gene_id.like(gene_id))\n\n        return query", "response": "helper function to add a query join to Gene model\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _join_chemical(query, cas_rn, chemical_id, chemical_name, chemical_definition):\n        if cas_rn or chemical_id or chemical_name or chemical_definition:\n            query = query.join(models.Chemical)\n\n            if cas_rn:\n                query = query.filter(models.Chemical.cas_rn.like(cas_rn))\n\n            if chemical_id:\n                query = query.filter(models.Chemical.chemical_id == chemical_id)\n\n            if chemical_name:\n                query = query.filter(models.Chemical.chemical_name.like(chemical_name))\n\n            if chemical_definition:\n                query = query.filter(models.Chemical.definition.like(chemical_definition))\n\n        return query", "response": "helper function to add a query join to Chemical model\n        "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _join_disease(query, disease_definition, disease_id, disease_name):\n        if disease_definition or disease_id or disease_name:\n            query = query.join(models.Disease)\n\n            if disease_definition:\n                query = query.filter(models.Disease.definition.like(disease_definition))\n\n            if disease_id:\n                query = query.filter(models.Disease.disease_id == disease_id)\n\n            if disease_name:\n                query = query.filter(models.Disease.disease_name.like(disease_name))\n\n        return query", "response": "helper function to add a query join to a Disease model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _join_pathway(query, pathway_id, pathway_name):\n        if pathway_id or pathway_name:\n            if pathway_id:\n                query = query.filter(models.Pathway.pathway_id.like(pathway_id))\n            if pathway_name:\n                query = query.filter(models.Pathway.pathway_name.like(pathway_name))\n\n        return query", "response": "helper function to add a query join to Pathway model"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of diseases for the current branch.", "response": "def get_disease(self, disease_name=None, disease_id=None, definition=None, parent_ids=None, tree_numbers=None,\n                    parent_tree_numbers=None, slim_mapping=None, synonym=None, alt_disease_id=None, limit=None,\n                    as_df=False):\n        \"\"\"\n        Get diseases\n\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param int limit: maximum number of results\n        :param str disease_name: disease name\n        :param str disease_id: disease identifier\n        :param str definition: definition of disease\n        :param str parent_ids: parent identifiers, delimiter |\n        :param str tree_numbers: tree numbers, delimiter |\n        :param str parent_tree_numbers: parent tree numbers, delimiter\n        :param str slim_mapping:  term derived from the MeSH tree structure for the \u201cDiseases\u201d [C] branch, \\\n        that classifies MEDIC diseases into high-level categories\n        :param str synonym: disease synonyms\n        :param str alt_disease_id: alternative disease identifiers\n        :return: list of :class:`pyctd.manager.models.Disease` object\n\n\n        .. seealso::\n\n            :class:`pyctd.manager.models.Disease`\n\n        .. todo::\n            normalize parent_ids, tree_numbers and parent_tree_numbers in :class:`pyctd.manager.models.Disease`\n        \"\"\"\n        q = self.session.query(models.Disease)\n\n        if disease_name:\n            q = q.filter(models.Disease.disease_name.like(disease_name))\n\n        if disease_id:\n            q = q.filter(models.Disease.disease_id == disease_id)\n\n        if definition:\n            q = q.filter(models.Disease.definition.like(definition))\n\n        if parent_ids:\n            q = q.filter(models.Disease.parent_ids.like(parent_ids))\n\n        if tree_numbers:\n            q = q.filter(models.Disease.tree_numbers.like(tree_numbers))\n\n        if parent_tree_numbers:\n            q = q.filter(models.Disease.parent_tree_numbers.like(parent_tree_numbers))\n\n        if slim_mapping:\n            q = q.join(models.DiseaseSlimmapping).filter(models.DiseaseSlimmapping.slim_mapping.like(slim_mapping))\n\n        if synonym:\n            q = q.join(models.DiseaseSynonym).filter(models.DiseaseSynonym.synonym.like(synonym))\n\n        if alt_disease_id:\n            q = q.join(models.DiseaseAltdiseaseid).filter(models.DiseaseAltdiseaseid.alt_disease_id == alt_disease_id)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of genes from the database.", "response": "def get_gene(self, gene_name=None, gene_symbol=None, gene_id=None, synonym=None, uniprot_id=None,\n                 pharmgkb_id=None, biogrid_id=None, alt_gene_id=None, limit=None, as_df=False):\n        \"\"\"Get genes\n\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param alt_gene_id: \n        :param str gene_name: gene name\n        :param str gene_symbol: HGNC gene symbol\n        :param int gene_id: NCBI Entrez Gene identifier\n        :param str synonym: Synonym\n        :param str uniprot_id: UniProt primary accession number\n        :param str pharmgkb_id: PharmGKB identifier \n        :param int biogrid_id: BioGRID identifier\n        :param int limit: maximum of results \n        :rtype: list[models.Gene]\n        \"\"\"\n        q = self.session.query(models.Gene)\n\n        if gene_symbol:\n            q = q.filter(models.Gene.gene_symbol.like(gene_symbol))\n\n        if gene_name:\n            q = q.filter(models.Gene.gene_name.like(gene_name))\n\n        if gene_id:\n            q = q.filter(models.Gene.gene_id.like(gene_id))\n\n        if synonym:\n            q = q.join(models.GeneSynonym).filter(models.GeneSynonym.synonym == synonym)\n\n        if uniprot_id:\n            q = q.join(models.GeneUniprot).filter(models.GeneUniprot.uniprot_id == uniprot_id)\n\n        if pharmgkb_id:\n            q = q.join(models.GenePharmgkb).filter(models.GenePharmgkb.pharmgkb_id == pharmgkb_id)\n\n        if biogrid_id:\n            q = q.join(models.GeneBiogrid).filter(models.GeneBiogrid.biogrid_id == biogrid_id)\n\n        if alt_gene_id:\n            q = q.join(models.GeneAltGeneId.alt_gene_id == alt_gene_id)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_pathway(self, pathway_name=None, pathway_id=None, limit=None, as_df=False):\n        q = self.session.query(models.Pathway)\n\n        if pathway_name:\n            q = q.filter(models.Pathway.pathway_name.like(pathway_name))\n\n        if pathway_id:\n            q = q.filter(models.Pathway.pathway_id.like(pathway_id))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Get pathway objects from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_chemical(self, chemical_name=None, chemical_id=None, cas_rn=None, drugbank_id=None, parent_id=None,\n                     parent_tree_number=None, tree_number=None, synonym=None, limit=None, as_df=False):\n        \"\"\"Get chemical\n\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param str chemical_name: chemical name\n        :param str chemical_id: cehmical identifier \n        :param str cas_rn: CAS registry number\n        :param str drugbank_id: DrugBank identifier \n        :param str parent_id: identifiers of the parent terms\n        :param str parent_tree_number: identifiers of the parent nodes\n        :param str tree_number: identifiers of the chemical's nodes\n        :param str synonym: chemical synonym\n        :param int limit: maximum number of results \n        :return: list of :class:`pyctd.manager.models.Chemical` objects\n        \n\n        .. seealso::\n\n            :class:`pyctd.manager.models.Chemical`\n        \"\"\"\n        q = self.session.query(models.Chemical)\n\n        if chemical_name:\n            q = q.filter(models.Chemical.chemical_name.like(chemical_name))\n\n        if chemical_id:\n            q = q.filter(models.Chemical.chemical_id == chemical_id)\n\n        if cas_rn:\n            q = q.filter(models.Chemical.cas_rn == cas_rn)\n\n        if drugbank_id:\n            q = q.join(models.ChemicalDrugbank).filter(models.ChemicalDrugbank.drugbank_id == drugbank_id)\n\n        if parent_id:\n            q = q.join(models.ChemicalParentid).filter(models.ChemicalParentid.parent_id == parent_id)\n\n        if tree_number:\n            q = q.join(models.ChemicalTreenumber) \\\n                .filter(models.ChemicalTreenumber.tree_number == tree_number)\n\n        if parent_tree_number:\n            q = q.join(models.ChemicalParenttreenumber) \\\n                .filter(models.ChemicalParenttreenumber.parent_tree_number == parent_tree_number)\n\n        if synonym:\n            q = q.join(models.ChemicalSynonym).filter(models.ChemicalSynonym.synonym.like(synonym))\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Get a list of chemical objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all interactions for a given gene or biological entity.", "response": "def get_chem_gene_interaction_actions(self, gene_name=None, gene_symbol=None, gene_id=None, limit=None,\n                                          cas_rn=None, chemical_id=None, chemical_name=None, organism_id=None,\n                                          interaction_sentence=None, chemical_definition=None,\n                                          gene_form=None, interaction_action=None, as_df=False):\n        \"\"\"Get all interactions for chemicals on a gene or biological entity (linked to this gene).\n\n        Chemicals can interact on different types of biological entities linked to a gene. A list of allowed\n        entities linked to a gene can be retrieved via the attribute :attr:`~.gene_forms`.\n\n        Interactions are classified by a combination of interaction ('affects', 'decreases', 'increases') \n        and actions ('activity', 'expression', ...  ). A complete list of all allowed\n        interaction_actions can be retrieved via the attribute :attr:`~.interaction_actions`.\n\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param str interaction_sentence: sentence describing the interactions \n        :param int organism_id: NCBI TaxTree identifier. Example: 9606 for Human.\n        :param str chemical_name: chemical name\n        :param str chemical_id: chemical identifier\n        :param str cas_rn: CAS registry number\n        :param str chemical_definition:\n        :param str gene_symbol: HGNC gene symbol\n        :param str gene_name: gene name\n        :param int gene_id: NCBI Entrez Gene identifier\n        :param str gene_form: gene form\n        :param str interaction_action: combination of interaction and actions\n        :param int limit: maximum number of results\n        :rtype: list[models.ChemGeneIxn]\n\n\n        .. seealso::\n\n            :class:`pyctd.manager.models.ChemGeneIxn` \n\n            which is linked to:\n            :class:`pyctd.manager.models.Chemical`\n            :class:`pyctd.manager.models.Gene`\n            :class:`pyctd.manager.models.ChemGeneIxnPubmed`\n\n            Available interaction_actions and gene_forms\n            :func:`pyctd.manager.database.Query.interaction_actions`\n            :func:`pyctd.manager.database.Query.gene_forms`\n\n        \"\"\"\n        q = self.session.query(models.ChemGeneIxn)\n\n        if organism_id:\n            q = q.filter(models.ChemGeneIxn.organism_id == organism_id)\n\n        if interaction_sentence:\n            q = q.filter(models.ChemGeneIxn.interaction == interaction_sentence)\n\n        if gene_form:\n            q = q.join(models.ChemGeneIxnGeneForm).filter(models.ChemGeneIxnGeneForm.gene_form == gene_form)\n\n        if interaction_action:\n            q = q.join(models.ChemGeneIxnInteractionAction) \\\n                .filter(models.ChemGeneIxnInteractionAction.interaction_action.like(interaction_action))\n\n        q = self._join_gene(query=q, gene_name=gene_name, gene_symbol=gene_symbol, gene_id=gene_id)\n\n        q = self._join_chemical(query=q, cas_rn=cas_rn, chemical_id=chemical_id, chemical_name=chemical_name,\n                                chemical_definition=chemical_definition)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gene_forms(self):\n        q = self.session.query(distinct(models.ChemGeneIxnGeneForm.gene_form))\n        return [x[0] for x in q.all()]", "response": "Returns a list of all available gene forms"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of strings for allowed interaction and actions combinations", "response": "def interaction_actions(self):\n        \"\"\"\n        :return: List of strings for allowed interaction/actions combinations\n        :rtype: list[str]\n        \"\"\"\n        r = self.session.query(distinct(models.ChemGeneIxnInteractionAction.interaction_action)).all()\n        return [x[0] for x in r]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef actions(self):\n        r = self.session.query(models.Action).all()\n        return [x.type_name for x in r]", "response": "Gets the list of allowed actions in the database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of all gene\u2013disease associations for a given gene.", "response": "def get_gene_disease(self, direct_evidence=None, inference_chemical_name=None, inference_score=None,\n                         gene_name=None, gene_symbol=None, gene_id=None, disease_name=None, disease_id=None,\n                         disease_definition=None, limit=None, as_df=False):\n        \"\"\"Get gene\u2013disease associations\n\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param int gene_id: gene identifier\n        :param str gene_symbol: gene symbol\n        :param str gene_name:  gene name\n        :param str direct_evidence: direct evidence\n        :param str inference_chemical_name: inference_chemical_name \n        :param float inference_score: inference score\n        :param str inference_chemical_name: chemical name\n        :param disease_name: disease name\n        :param disease_id: disease identifier \n        :param disease_definition: disease definition \n        :param int limit: maximum number of results\n        :return: list of :class:`pyctd.manager.database.models.GeneDisease` objects\n\n        .. seealso::\n            \n            :class:`pyctd.manager.models.GeneDisease`\n\n            which is linked to:\n            :class:`pyctd.manager.models.Chemical`\n            :class:`pyctd.manager.models.Gene`\n        \"\"\"\n        q = self.session.query(models.GeneDisease)\n\n        if direct_evidence:\n            q = q.filter(models.GeneDisease.direct_evidence == direct_evidence)\n\n        if inference_chemical_name:\n            q = q.filter(models.GeneDisease.inference_chemical_name == inference_chemical_name)\n\n        if inference_score:\n            q = q.filter(models.GeneDisease.inference_score == inference_score)\n\n        q = self._join_disease(query=q, disease_definition=disease_definition, disease_id=disease_id,\n                               disease_name=disease_name)\n\n        q = self._join_gene(q, gene_name=gene_name, gene_symbol=gene_symbol, gene_id=gene_id)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all direct evidences for gene disease correlations", "response": "def direct_evidences(self):\n        \"\"\"\n        :return: All available direct evidences for gene disease correlations\n        :rtype: list\n        \"\"\"\n        q = self.session.query(distinct(models.GeneDisease.direct_evidence))\n\n        return q.all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_disease_pathways(self, disease_id=None, disease_name=None, pathway_id=None, pathway_name=None,\n                             disease_definition=None, limit=None, as_df=False):\n        \"\"\"Get disease pathway link\n        \n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param disease_id: \n        :param disease_name: \n        :param pathway_id: \n        :param pathway_name:\n        :param disease_definition:\n        :param int limit: maximum number of results\n        :return: list of :class:`pyctd.manager.database.models.DiseasePathway` objects\n\n        .. seealso::\n            \n            :class:`pyctd.manager.models.DiseasePathway`\n\n            which is linked to:\n            :class:`pyctd.manager.models.Disease`\n            :class:`pyctd.manager.models.Pathway`\n        \"\"\"\n        q = self.session.query(models.DiseasePathway)\n\n        q = self._join_disease(query=q, disease_id=disease_id, disease_name=disease_name,\n                               disease_definition=disease_definition)\n\n        q = self._join_pathway(query=q, pathway_id=pathway_id, pathway_name=pathway_name)\n\n        return self._limit_and_df(q, limit, as_df)", "response": "Get a list of all disease pathway paths."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all chemical diseases associated with a given set of properties.", "response": "def get_chemical_diseases(self, direct_evidence=None, inference_gene_symbol=None, inference_score=None,\n                              inference_score_operator=None, cas_rn=None, chemical_name=None,\n                              chemical_id=None, chemical_definition=None, disease_definition=None,\n                              disease_id=None, disease_name=None, limit=None, as_df=False):\n        \"\"\"Get chemical\u2013disease associations with inference gene\n        \n        :param direct_evidence: direct evidence\n        :param inference_gene_symbol: inference gene symbol\n        :param inference_score: inference score\n        :param inference_score_operator: inference score operator\n        :param cas_rn:\n        :param chemical_name: chemical name\n        :param chemical_id:\n        :param chemical_definition:\n        :param disease_definition:\n        :param disease_id:\n        :param disease_name: disease name\n        :param int limit: maximum number of results\n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :return: list of :class:`pyctd.manager.database.models.ChemicalDisease` objects\n\n        .. seealso::\n            \n            :class:`pyctd.manager.models.ChemicalDisease`\n\n            which is linked to:\n            :class:`pyctd.manager.models.Disease`\n            :class:`pyctd.manager.models.Chemical`\n        \"\"\"\n        q = self.session.query(models.ChemicalDisease)\n\n        if direct_evidence:\n            q = q.filter(models.ChemicalDisease.direct_evidence.like(direct_evidence))\n\n        if inference_gene_symbol:\n            q = q.filter(models.ChemicalDisease.inference_gene_symbol.like(inference_gene_symbol))\n\n        if inference_score:\n            if inference_score_operator == \">\":\n                q = q.filter_by(models.ChemicalDisease.inference_score > inference_score)\n            elif inference_score_operator == \"<\":\n                q = q.filter_by(models.ChemicalDisease.inference_score > inference_score)\n\n        q = self._join_chemical(q, cas_rn=cas_rn, chemical_id=chemical_id, chemical_name=chemical_name,\n                                chemical_definition=chemical_definition)\n\n        q = self._join_disease(q, disease_definition=disease_definition, disease_id=disease_id,\n                               disease_name=disease_name)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of all the pathways linked to a gene.", "response": "def get_gene_pathways(self, gene_name=None, gene_symbol=None, gene_id=None, pathway_id=None,\n                          pathway_name=None, limit=None, as_df=False):\n        \"\"\"Get gene pathway link\n        \n        :param bool as_df: if set to True result returns as `pandas.DataFrame`\n        :param str gene_name: gene name \n        :param str gene_symbol: gene symbol\n        :param int gene_id: NCBI Gene identifier\n        :param pathway_id: \n        :param str pathway_name: pathway name\n        :param int limit: maximum number of results\n        :return: list of :class:`pyctd.manager.database.models.GenePathway` objects\n\n        .. seealso::\n            \n            :class:`pyctd.manager.models.GenePathway`\n\n            which is linked to:\n            :class:`pyctd.manager.models.Gene`\n            :class:`pyctd.manager.models.Pathway`\n        \"\"\"\n        q = self.session.query(models.GenePathway)\n        q = self._join_gene(q, gene_name=gene_name, gene_symbol=gene_symbol, gene_id=gene_id)\n        q = self._join_pathway(q, pathway_id=pathway_id, pathway_name=pathway_name)\n\n        return self._limit_and_df(q, limit, as_df)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_validate_upload_form_kwargs(self):\n\n        kwargs = {\n            'storage': self.get_storage(),\n            'upload_to': self.get_upload_to(),\n            'content_type_prefix': self.get_content_type_prefix(),\n            'process_to': self.get_process_to(),\n            'processed_key_generator': self.get_processed_key_generator(),\n        }\n\n        # ``data`` may be provided by a POST from the JavaScript if using a\n        # DropZone form, or as querystrings on a redirect GET request from\n        # Amazon if not.\n        data = {\n            'bucket_name': self._get_bucket_name(),\n            'key_name': self._get_key_name(),\n            'etag': self._get_etag(),\n        }\n        kwargs.update({'data': data})\n        return kwargs", "response": "Returns the keyword arguments for instantiating the upload form for validating\n        the upload."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplays sound for a given state.", "response": "def play(state):\n        \"\"\" Play sound for a given state.\n\n        :param state: a State value.\n        \"\"\"\n        filename = None\n        if state == SoundService.State.welcome:\n            filename = \"pad_glow_welcome1.wav\"\n        elif state == SoundService.State.goodbye:\n            filename = \"pad_glow_power_off.wav\"\n        elif state == SoundService.State.hotword_detected:\n            filename = \"pad_soft_on.wav\"\n        elif state == SoundService.State.asr_text_captured:\n            filename = \"pad_soft_off.wav\"\n        elif state == SoundService.State.error:\n            filename = \"music_marimba_error_chord_2x.wav\"\n\n        if filename is not None:\n            AudioPlayer.play_async(\"{}/{}\".format(ABS_SOUND_DIR, filename))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_readme():\n    pandoc = None\n    for path in os.environ[\"PATH\"].split(os.pathsep):\n        path = path.strip('\"')\n        pandoc = os.path.join(path, 'pandoc')\n        if os.path.isfile(pandoc) and os.access(pandoc, os.X_OK):\n            break\n        else:\n            pandoc = None\n    try:\n        if pandoc:\n            cmd = [pandoc, '-t', 'rst', 'README.md']\n            long_description = os.popen(' '.join(cmd)).read()\n        else:\n            raise ValueError\n    except BaseException:\n        long_description = open(\"README.md\").read()\n    return long_description", "response": "Generate long description from README. md"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _casual_timedelta_string(meeting):\n\n    now = datetime.datetime.utcnow()\n    mdate = meeting['meeting_date']\n    mtime = meeting['meeting_time_start']\n    dt_string = \"%s %s\" % (mdate, mtime)\n    meeting_dt = datetime.datetime.strptime(dt_string, \"%Y-%m-%d %H:%M:%S\")\n    relative_td = dateutil.relativedelta.relativedelta(meeting_dt, now)\n\n    denominations = ['years', 'months', 'days', 'hours', 'minutes']\n    for denomination in denominations:\n        value = getattr(relative_td, denomination)\n        if value:\n            # If the value is only one, then strip off the plural suffix.\n            if value == 1:\n                denomination = denomination[:-1]\n            return \"in %i %s\" % (value, denomination)\n\n    return \"right now\"", "response": "Return a casual timedelta string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef repo_name(msg):\n    try:\n        # git messages look like this now\n        path = msg['msg']['commit']['path']\n        project = path.split('.git')[0][9:]\n    except KeyError:\n        # they used to look like this, though\n        project = msg['msg']['commit']['repo']\n\n    return project", "response": "Get the repo name from a message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget account usage information.", "response": "def usage(self, period=None, start=None, end=None):\n        \"\"\" Get account usage information\n\n            :param period: Period is one of either hourly, daily or monthly\n            :type period: str\n            :param start: Determines time period of the usage\n            :type start: int\n            :param end: Determines time period of the usage\n            :type end: int\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {}\n\n        if period:\n            params['period'] = period\n        if start:\n            params['start'] = start\n        if end:\n            params['end'] = end\n\n        return self.request.get('usage', params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a standard name by following rules", "response": "def standard_db_name(file_column_name):\n    \"\"\"return a standard name by following rules:\n    1. find all regular expression partners ((IDs)|(ID)|([A-Z][a-z]+)|([A-Z]{2,}))\n    2. lower very part and join again with _\n    This method is only used if values in table[model]['columns'] are str\n\n    :param str file_column_name: name of column in file\n    :return: standard name\n    :rtype: str\n    \"\"\"\n    found = id_re.findall(file_column_name)\n\n    if not found:\n        return file_column_name\n\n    return '_'.join(x[0].lower() for x in found)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms text into a double - ended queue of single characters and multiline strings.", "response": "def transform_text(input_txt):\n    \"\"\"Transforms text into :py:class:`~collections.deque`, pre-processes\n    multiline strings.\n\n    :param str or bytes input_txt: Input text.\n    :return: Double-ended queue of single characters and multiline strings.\n    :rtype: :py:class:`~collections.deque`\n    \"\"\"\n    if isinstance(input_txt, str):\n        text = u\"{}\".format(input_txt)\n    elif isinstance(input_txt, bytes):\n        text = input_txt.decode(\"utf-8\")\n    else:\n        raise TypeError(\"Expecting <class 'str'> or <class 'bytes'>, but {} was passed\".format(type(input_txt)))\n\n    inputq = deque(text.split(u\"\\n\"))\n    outputq = deque()\n\n    while len(inputq) > 0:\n        line = inputq.popleft()\n\n        if line.lstrip().startswith(u\"#\"):\n            comment = u\"\" + line + u\"\\n\"\n            line = inputq.popleft()\n\n            while line.lstrip().startswith(u\"#\"):\n                comment += line + u\"\\n\"\n                line = inputq.popleft()\n\n            outputq.append(comment)\n\n            for character in line:\n                outputq.append(character)\n\n        elif line.startswith(u\";\"):\n            multiline = u\"\"\n            multiline += line + u\"\\n\"\n            line = inputq.popleft()\n\n            while not line.startswith(u\";\"):\n                multiline += line + u\"\\n\"\n                line = inputq.popleft()\n\n            multiline += line[:1]\n            outputq.append(multiline[1:-1])  # remove STAR syntax from multiline string\n\n            for character in line[1:]:\n                outputq.append(character)\n\n        else:\n            for character in line:\n                outputq.append(character)\n\n        outputq.append(u\"\\n\")\n\n    outputq.extend([u\"\\n\", u\"\"])  # end of file signal\n\n    return outputq"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bmrblex(text):\n    stream = transform_text(text)\n\n    wordchars = (u\"abcdfeghijklmnopqrstuvwxyz\"\n                 u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_\"\n                 u\"\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u00ff\"\n                 u\"\u00c0\u00c1\u00c2\u00c3\u00c4\u00c5\u00c6\u00c7\u00c8\u00c9\u00ca\u00cb\u00cc\u00cd\u00ce\u00cf\u00d0\u00d1\u00d2\u00d3\u00d4\u00d5\u00d6\u00d8\u00d9\u00da\u00db\u00dc\u00dd\u00de\"\n                 u\"!@$%^&*()_+:;?/>.<,~`|\\{[}]-=\")\n\n    whitespace = u\" \\t\\v\\r\\n\"\n    comment = u\"#\"\n    state = u\" \"\n    token = u\"\"\n    single_line_comment = u\"\"\n\n    while len(stream) > 0:\n        nextnextchar = stream.popleft()\n\n        while True:\n            nextchar = nextnextchar\n\n            if len(stream) > 0:\n                nextnextchar = stream.popleft()\n            else:\n                nextnextchar = u\"\"\n\n            # Process multiline string, comment, or single line comment\n            if len(nextchar) > 1:\n                state = u\" \"\n                token = nextchar\n                break  # emit current token\n\n            elif nextchar in whitespace and nextnextchar in comment and state not in (u\"'\", u'\"'):\n                single_line_comment = u\"\"\n                state = u\"#\"\n\n            if state is None:\n                token = u\"\"  # past end of file\n                break\n\n            elif state == u\" \":\n                if not nextchar:\n                    state = None\n                    break\n\n                elif nextchar in whitespace:\n                    if token:\n                        state = u\" \"\n                        break  # emit current token\n                    else:\n                        continue\n\n                elif nextchar in wordchars:\n                    token = nextchar\n                    state = u\"a\"\n\n                elif nextchar == u\"'\" or nextchar == u'\"':\n                    token = nextchar\n                    state = nextchar\n\n                else:\n                    token = nextchar\n                    if token:\n                        state = u\" \"\n                        break  # emit current token\n                    else:\n                        continue\n\n            # Process single-quoted or double-quoted token\n            elif state == u\"'\" or state == u'\"':\n                token += nextchar\n                if nextchar == state:\n                    if nextnextchar in whitespace:\n                        state = u\" \"\n                        token = token[1:-1]  # remove single or double quotes from the ends\n                        break\n\n            # Process single line comment\n            elif state == u\"#\":\n                single_line_comment += nextchar\n                if nextchar == u\"\\n\":\n                    state = u\" \"\n                    break\n\n            # Process regular (unquoted) token\n            elif state == u\"a\":\n                if not nextchar:\n                    state = None\n                    break\n                elif nextchar in whitespace:\n                    state = u\" \"\n                    if token:\n                        break  # emit current token\n                    else:\n                        continue\n                else:\n                    token += nextchar\n\n        if nextnextchar:\n            stream.appendleft(nextnextchar)\n\n        yield token\n        token = u\"\"", "response": "A lexical analyzer for the BMRB - STAR format syntax."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking external dependecies Return a tuple with the available generators.", "response": "def check_dependencies():\n    \"\"\"Check external dependecies\n    Return a tuple with the available generators.\n    \"\"\"\n    available = []\n    try:\n        shell('ebook-convert')\n        available.append('calibre')\n    except OSError:\n        pass\n    try:\n        shell('pandoc --help')\n        available.append('pandoc')\n    except OSError:\n        pass\n    if not available:\n        sys.exit(error('No generator found, you cannot use md2ebook.'))\n    check_dependency_epubcheck()\n    return available"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lock(self, key, owner, timeout=None, expire=None):\n        expire = datetime.utcnow() + timedelta(seconds=expire) if expire else None\n        try:\n            self.collection.insert({\n                '_id': key,\n                'locked': True,\n                'owner': owner,\n                'created': datetime.utcnow(),\n                'expire': expire\n            })\n            return True\n        except DuplicateKeyError:\n            start_time = datetime.utcnow()\n            while True:\n                if self._try_get_lock(key, owner, expire):\n                    return True\n\n                if not timeout or datetime.utcnow() >= start_time + timedelta(seconds=timeout):\n                    return False\n                time.sleep(self.acquire_retry_step)", "response": "Lock given key to owner."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreleases a lock with given name.", "response": "def release(self, key, owner):\n        \"\"\"Release lock with given name.\n          `key` - lock name\n          `owner` - name of application/component/whatever which held a lock\n        Raises `MongoLockException` if no such a lock.\n        \"\"\"\n        status = self.collection.find_and_modify(\n            {'_id': key, 'owner': owner},\n            {'locked': False, 'owner': None, 'created': None, 'expire': None}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrenewing lock to avoid expiration.", "response": "def touch(self, key, owner, expire=None):\n        \"\"\"Renew lock to avoid expiration. \"\"\"\n        lock = self.collection.find_one({'_id': key, 'owner': owner})\n        if not lock:\n            raise MongoLockException(u'Can\\'t find lock for {key}: {owner}'.format(key=key, owner=owner))\n        if not lock['expire']:\n            return\n        if not expire:\n            raise MongoLockException(u'Can\\'t touch lock without expire for {0}: {1}'.format(key, owner))\n        expire = datetime.utcnow() + timedelta(seconds=expire)\n        self.collection.update(\n            {'_id': key, 'owner': owner},\n            {'$set': {'expire': expire}}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_archive_listing(self, archive_name):\n        '''\n        Return full document for ``{_id:'archive_name'}``\n\n        .. note::\n\n            MongoDB specific results - do not expose to user\n        '''\n\n        res = self.collection.find_one({'_id': archive_name})\n\n        if res is None:\n            raise KeyError\n\n        return res", "response": "Return full document for archive_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbatching version of _get_archive_listing", "response": "def _batch_get_archive_listing(self, archive_names):\n        '''\n        Batched version of :py:meth:`~MongoDBManager._get_archive_listing`\n\n        Returns a list of full archive listings from an iterable of archive\n        names\n\n        .. note ::\n\n            Invalid archive names will simply not be returned, so the response\n            may not be the same length as the supplied `archive_names`.\n\n        Parameters\n        ----------\n\n        archive_names : list\n\n            List of archive names\n\n        Returns\n        -------\n\n        archive_listings : list\n\n            List of archive listings\n\n        '''\n\n        res = self.collection.find({'_id': {'$in': list(archive_names)}})\n\n        if res is None:\n            res = []\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a List or Dict response object.", "response": "def build_response(self, response, path=None, parser=json_decode_wrapper, async=False):\n        \"\"\" Builds a List or Dict response object.\n\n            Wrapper for a response from the DataSift REST API, can be accessed as a list.\n\n            :param response: HTTP response to wrap\n            :type response: :class:`~datasift.requests.DictResponse`\n            :param parser: optional parser to overload how the data is loaded\n            :type parser: func\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`~datasift.exceptions.DataSiftApiFailure`, :class:`~datasift.exceptions.AuthException`, :class:`requests.exceptions.HTTPError`, :class:`~datasift.exceptions.RateLimitException`\n        \"\"\"\n        if async:\n            response.process = lambda: self.build_response(response.result(), path=path, parser=parser, async=False)\n            return response\n        if response.status_code != 204:\n            try:\n                data = parser(response.headers, response.text)\n            except ValueError as e:\n                raise DataSiftApiFailure(u\"Unable to decode returned data: %s\" % e)\n            if \"error\" in data:\n                if response.status_code == 401:\n                    raise AuthException(data)\n                if response.status_code == 403 or response.status_code == 429:\n                    if not response.headers.get(\"X-RateLimit-Cost\"):\n                        raise DataSiftApiException(DictResponse(response, data))\n                    if int(response.headers.get(\"X-RateLimit-Cost\")) > int(response.headers.get(\"X-RateLimit-Remaining\")):\n                        raise RateLimitException(DictResponse(response, data))\n                raise DataSiftApiException(DictResponse(response, data))\n            response.raise_for_status()\n            if isinstance(data, dict):\n                r = DictResponse(response, data)\n            elif isinstance(data, (list, map)):\n                r = ListResponse(response, data)\n            self.outputmapper.outputmap(r)\n            return r\n\n        else:\n            # empty dict\n            return DictResponse(response, {})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of rate limit headers for the current user.", "response": "def ratelimits(self):\n        \"\"\" :returns: Rate Limit headers\n            :rtype: dict\n        \"\"\"\n        # can't use a dict comprehension because we want python2.6 support\n        r = {}\n        keys = filter(lambda x: x.startswith(\"x-ratelimit-\"), self.headers.keys())\n        for key in keys:\n            r[key.replace(\"x-ratelimit-\", \"\")] = int(self.headers[key])\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_instance_masks(cls):\n        # Compute required # of IO expanders needed, clear mask variable.\n        number_IO_expanders = ((len(cls._list) - 1) / 4) + 1\n        cls.master_mask = [0, 0] * number_IO_expanders\n\n        for ctrlobj in cls:\n            # Or masks together bank-by-banl\n            cls.master_mask[ctrlobj.bank] |= ctrlobj.mask\n            # Handle the pump request seperately\n            if ctrlobj.pump_request == 1:\n                cls.master_mask[cls.pump_bank] |= 1 << cls.pump_pin", "response": "Compiles instance masks into a master mask that is usable by the IO expander."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate control module knowledge of pump requests. If any sensor module requests water, the pump will turn on.", "response": "def manage_pump(self, operation):\n        \"\"\"\n        Updates control module knowledge of pump requests.\n        If any sensor module requests water, the pump will turn on.\n\n        \"\"\"\n        if operation == \"on\":\n            self.controls[\"pump\"] = \"on\"\n        elif operation == \"off\":\n            self.controls[\"pump\"] = \"off\"\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef control(self, on=[], off=[]):\n        controls = {\"light\", \"valve\", \"fan\", \"pump\"}\n\n        def cast_arg(arg):\n            if type(arg) is str:\n                if arg == \"all\":\n                    return controls\n                else:\n                    return {arg} & controls\n            else:\n                return set(arg) & controls\n\n        # User has requested individual controls.\n        for item in cast_arg(on):\n            self.manage(item, \"on\")\n        for item in cast_arg(off):\n            self.manage(item, \"off\")\n        sleep(.01) # Force delay to throttle requests\n        return self.update()", "response": "This method handles the control operation for the individual device and the batch control interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef restore_state(self):\n        current_mask = get_IO_reg(ControlCluster.bus,\n                                 self.IOexpander, \n                                 self.bank)\n        if current_mask & (1 << ControlCluster.pump_pin):\n            self.manage_pump(\"on\")\n        if current_mask & (1 << self.fan):\n            self.manage_fan(\"on\")\n        if current_mask & (1 << self.light):\n            self.manage_fan(\"on\")", "response": "Method should be called on obj. initialization\n            When called the method will attempt to restore the state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _key(key=''):\n    '''\n    Returns a Datastore key object, prefixed with the NAMESPACE.\n    '''\n    if not isinstance(key, datastore.Key):\n        # Switchboard uses ':' to denote one thing (parent-child) and datastore\n        # uses it for another, so replace ':' in the datastore version of the\n        # key.\n        safe_key = key.replace(':', '|')\n        key = datastore.Key(os.path.join(NAMESPACE, safe_key))\n    return key", "response": "Returns a Datastore key object prefixed with the NAMESPACE."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_or_create(cls, key, defaults={}):\n        '''\n        A port of functionality from the Django ORM. Defaults can be passed in\n        if creating a new document is necessary. Keyword args are used to\n        lookup the document. Returns a tuple of (object, created), where object\n        is the retrieved or created object and created is a boolean specifying\n        whether a new object was created.\n        '''\n        instance = cls.get(key)\n        if not instance:\n            created = True\n            data = dict(key=key)\n            data.update(defaults)\n            # Do an upsert here instead of a straight create to avoid a race\n            # condition with another instance creating the same record at\n            # nearly the same time.\n            instance = cls.update(data, data, upsert=True)\n        else:\n            created = False\n        return instance, created", "response": "A port of functionality from the Django ORM. Returns a tuple of object created if the object is not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the data of the object with the given spec.", "response": "def update(cls, spec, updates, upsert=False):\n        '''\n        The spec is used to search for the data to update, updates contains the\n        values to be updated, and upsert specifies whether to do an insert if\n        the original data is not found.\n        '''\n        if 'key' in spec:\n            previous = cls.get(spec['key'])\n        else:\n            previous = None\n        if previous:\n            # Update existing data.\n            current = cls(**previous.__dict__)\n        elif upsert:\n            # Create new data.\n            current = cls(**spec)\n        else:\n            current = None\n        # XXX Should there be any error thrown if this is a noop?\n        if current:\n            current.__dict__.update(updates)\n            current.save()\n        return current"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_condition(self, manager, condition_set, field_name, condition,\n                         commit=True):\n        \"\"\"\n        Removes a condition and updates the global ``operator`` switch manager.\n\n        If ``commit`` is ``False``, the data will not be written to the\n        database.\n\n        >>> switch = operator['my_switch'] #doctest: +SKIP\n        >>> cs_id = condition_set.get_id() #doctest: +SKIP\n        >>> switch.remove_condition(cs_id, 'percent', [0, 50]) #doctest: +SKIP\n        \"\"\"\n        condition_set = manager.get_condition_set_by_id(condition_set)\n\n        namespace = condition_set.get_namespace()\n\n        if namespace not in self.value:\n            return\n\n        if field_name not in self.value[namespace]:\n            return\n\n        conditions = self.value[namespace][field_name]\n        self.value[namespace][field_name] = ([c for c in conditions\n                                             if c[1] != condition])\n\n        if not self.value[namespace][field_name]:\n            del self.value[namespace][field_name]\n\n            if not self.value[namespace]:\n                del self.value[namespace]\n\n        if commit:\n            self.save()", "response": "Removes a condition from the global set and updates the global set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_active_conditions(self, manager):\n        '''\n        Returns a generator which yields groups of lists of conditions.\n\n        >>> conditions = switch.get_active_conditions()\n        >>> for label, set_id, field, value, exc in conditions: #doctest: +SKIP\n        >>>     print (\"%(label)s: %(field)s = %(value)s (exclude: %(exc)s)\"\n        >>>            % (label, field.label, value, exc)) #doctest: +SKIP\n        '''\n        for condition_set in sorted(manager.get_condition_sets(),\n                                    key=lambda x: x.get_group_label()):\n            ns = condition_set.get_namespace()\n            condition_set_id = condition_set.get_id()\n            if ns in self.value:\n                group = condition_set.get_group_label()\n                for name, field in condition_set.fields.iteritems():\n                    for value in self.value[ns].get(name, []):\n                        try:\n                            yield (condition_set_id, group, field, value[1],\n                                   value[0] == EXCLUDE)\n                        except TypeError:\n                            continue", "response": "Returns a generator which yields groups of lists of conditions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(self, output_type, output_params):\n        return self.request.post('validate',\n                                 dict(output_type=output_type, output_params=output_params))", "response": "Validate a single object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new push subscription using a given hash.", "response": "def create_from_hash(self, stream, name, output_type, output_params,\n                         initial_status=None, start=None, end=None):\n        \"\"\" Create a new push subscription using a live stream.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/pushcreate\n\n            :param stream: The hash of a DataSift stream.\n            :type stream: str\n            :param name: The name to give the newly created subscription\n            :type name: str\n            :param output_type: One of the supported output types e.g. s3\n            :type output_type: str\n            :param output_params: The set of parameters required for the given output type\n            :type output_params: dict\n            :param initial_status: The initial status of the subscription, active, paused or waiting_for_start\n            :type initial_status: str\n            :param start: Optionally specifies when the subscription should start\n            :type start: int\n            :param end: Optionally specifies when the subscription should end\n            :type end: int\n            :returns: dict with extra response data\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self._create(True, stream, name, output_type, output_params, initial_status, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new push subscription using the given Historic ID.", "response": "def create_from_historics(self, historics_id, name, output_type, output_params, initial_status=None, start=None,\n                              end=None):\n        \"\"\" Create a new push subscription using the given Historic ID.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/pushcreate\n\n            :param historics_id: The ID of a Historics query\n            :type historics_id: str\n            :param name: The name to give the newly created subscription\n            :type name: str\n            :param output_type: One of the supported output types e.g. s3\n            :type output_type: str\n            :param output_params: set of parameters required for the given output type, see dev.datasift.com\n            :type output_params: dict\n            :param initial_status: The initial status of the subscription, active, paused or waiting_for_start\n            :type initial_status: str\n            :param start: Optionally specifies when the subscription should start\n            :type start: int\n            :param end: Optionally specifies when the subscription should end\n            :type end: int\n            :returns: dict with extra response data\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        return self._create(False, historics_id, name, output_type, output_params, initial_status, start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pause(self, subscription_id):\n        return self.request.post('pause', data=dict(id=subscription_id))", "response": "Pause a Subscription and buffer the data for up to one hour."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resume(self, subscription_id):\n        return self.request.post('resume', data=dict(id=subscription_id))", "response": "Resumes a previously paused Push Subscription."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the name or output parameters for an existing Push Subscription.", "response": "def update(self, subscription_id, output_params, name=None):\n        \"\"\" Update the name or output parameters for an existing Subscription.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/pushupdate\n\n            :param subscription_id: id of an existing Push Subscription.\n            :type subscription_id: str\n            :param output_params: new output parameters for the subscription, see dev.datasift.com\n            :type output_params: dict\n            :param name: optional new name for the Subscription\n            :type name: str\n            :returns: dict with extra response data\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        params = {'id': subscription_id, 'output_params': output_params}\n        if name:\n            params['name'] = name\n        return self.request.post('update', params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, subscription_id):\n        return self.request.post('stop', data=dict(id=subscription_id))", "response": "Stop the given subscription from running."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, subscription_id):\n        return self.request.post('delete', data=dict(id=subscription_id))", "response": "Delete the given ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log(self, subscription_id=None, page=None, per_page=None, order_by=None, order_dir=None):\n        params = {}\n        if subscription_id:\n            params['id'] = subscription_id\n        if page:\n            params['page'] = page\n        if per_page:\n            params['per_page'] = per_page\n        if order_by:\n            params['order_by'] = order_by\n        if order_dir:\n            params['order_dir'] = order_dir\n\n        return self.request.get('log', params=params)", "response": "Retrieve any messages that have been logged for your subscription."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets details of the current state of a specific object.", "response": "def get(self, subscription_id=None, stream=None, historics_id=None,\n            page=None, per_page=None, order_by=None, order_dir=None,\n            include_finished=None):\n        \"\"\" Show details of the Subscriptions belonging to this user.\n\n            Uses API documented at http://dev.datasift.com/docs/api/rest-api/endpoints/pushget\n\n            :param subscription_id: optional id of an existing Push Subscription\n            :type subscription_id: str\n            :param hash: optional hash of a live stream\n            :type hash: str\n            :param playback_id: optional playback id of a Historics query\n            :type playback_id: str\n            :param page: optional page number for pagination\n            :type page: int\n            :param per_page: optional number of items per page, default 20\n            :type per_page: int\n            :param order_by: field to order by, default request_time\n            :type order_by: str\n            :param order_dir: direction to order by, asc or desc, default desc\n            :type order_dir: str\n            :param include_finished: boolean indicating if finished Subscriptions for Historics should be included\n            :type include_finished: bool\n            :returns: dict with extra response data\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`, :class:`requests.exceptions.HTTPError`\n        \"\"\"\n        params = {}\n        if subscription_id:\n            params['id'] = subscription_id\n        if stream:\n            params['hash'] = stream\n        if historics_id:\n            params['historics_id'] = historics_id\n        if page:\n            params['page'] = page\n        if per_page:\n            params['per_page'] = per_page\n        if order_by:\n            params['order_by'] = order_by\n        if order_dir:\n            params['order_dir'] = order_dir\n        if include_finished:\n            params['include_finished'] = 1 if include_finished else 0\n\n        return self.request.get('get', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_project(msg, key='project'):\n    ''' Return the project as `foo` or `user/foo` if the project is a\n    fork.\n    '''\n    project = msg[key]['name']\n    ns = msg[key].get('namespace')\n    if ns:\n        project = '/'.join([ns, project])\n    if msg[key]['parent']:\n        user = msg[key]['user']['name']\n        project = '/'.join(['fork', user, project])\n    return project", "response": "Return the project as foo or user / foo if the project is a\n    fork."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the subtitle for the first version of pagure git. receive messages.", "response": "def _git_receive_v1(msg, tmpl, **config):\n    ''' Return the subtitle for the first version of pagure git.receive\n    messages.\n    '''\n    repo = _get_project(msg['msg']['commit'], key='repo')\n    email = msg['msg']['commit']['email']\n    user = email2fas(email, **config)\n    summ = msg['msg']['commit']['summary']\n    whole = msg['msg']['commit']['message']\n    if summ.strip() != whole.strip():\n        summ += \" (..more)\"\n\n    branch = msg['msg']['commit']['branch']\n    if 'refs/heads/' in branch:\n        branch = branch.replace('refs/heads/', '')\n    return tmpl.format(user=user or email, repo=repo,\n                       branch=branch, summary=summ)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _git_receive_v2(msg, tmpl):\n    ''' Return the subtitle for the second version of pagure git.receive\n    messages.\n    '''\n    repo = _get_project(msg['msg'], key='repo')\n    user = msg['msg']['agent']\n    n_commits = msg['msg']['total_commits']\n    commit_lbl = 'commit' if str(n_commits) == '1' else 'commits'\n    branch = msg['msg']['branch']\n    if 'refs/heads/' in branch:\n        branch = branch.replace('refs/heads/', '')\n    return tmpl.format(user=user, repo=repo,\n                       branch=branch, n_commits=n_commits,\n                       commit_lbl=commit_lbl)", "response": "Return the subtitle for the second version of pagure git. receive\n    messages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, archive_name, version_metadata):\n        '''\n        Register a new version for archive ``archive_name``\n\n        .. note ::\n\n            need to implement hash checking to prevent duplicate writes\n        '''\n        version_metadata['updated'] = self.create_timestamp()\n        version_metadata['version'] = str(\n            version_metadata.get('version', None))\n\n        if version_metadata.get('message') is not None:\n            version_metadata['message'] = str(version_metadata['message'])\n\n        self._update(archive_name, version_metadata)", "response": "Update the version of an archive with the given metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates metadata for archive archive_name with archive_metadata.", "response": "def update_metadata(self, archive_name, archive_metadata):\n        '''\n        Update metadata for archive ``archive_name``\n        '''\n\n        required_metadata_keys = self.required_archive_metadata.keys()\n        for key, val in archive_metadata.items():\n            if key in required_metadata_keys and val is None:\n                raise ValueError(\n                    'Cannot remove required metadata attribute \"{}\"'.format(\n                        key))\n\n        self._update_metadata(archive_name, archive_metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new data archive and return it.", "response": "def create_archive(\n            self,\n            archive_name,\n            authority_name,\n            archive_path,\n            versioned,\n            raise_on_err=True,\n            metadata=None,\n            user_config=None,\n            tags=None,\n            helper=False):\n        '''\n        Create a new data archive\n\n        Returns\n        -------\n        archive : object\n            new :py:class:`~datafs.core.data_archive.DataArchive` object\n\n        '''\n\n        archive_metadata = self._create_archive_metadata(\n            archive_name=archive_name,\n            authority_name=authority_name,\n            archive_path=archive_path,\n            versioned=versioned,\n            raise_on_err=raise_on_err,\n            metadata=metadata,\n            user_config=user_config,\n            tags=tags,\n            helper=helper)\n\n        if raise_on_err:\n            self._create_archive(\n                archive_name,\n                archive_metadata)\n        else:\n            self._create_if_not_exists(\n                archive_name,\n                archive_metadata)\n\n        return self.get_archive(archive_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_archive(self, archive_name):\n        '''\n        Get a data archive given an archive name\n\n        Returns\n        -------\n        archive_specification : dict\n            archive_name: name of the archive to be retrieved\n            authority: name of the archive's authority\n            archive_path: service path of archive\n        '''\n\n        try:\n            spec = self._get_archive_spec(archive_name)\n            return spec\n\n        except KeyError:\n            raise KeyError('Archive \"{}\" not found'.format(archive_name))", "response": "Get a data archive given an archive name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tags(self, archive_name, tags):\n        '''\n        Add tags to an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to add to the archive\n\n        '''\n        updated_tag_list = list(self._get_tags(archive_name))\n        for tag in tags:\n            if tag not in updated_tag_list:\n                updated_tag_list.append(tag)\n\n        self._set_tags(archive_name, updated_tag_list)", "response": "Adds tags to an archive"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_tags(self, archive_name, tags):\n        '''\n        Delete tags from an archive\n\n        Parameters\n        ----------\n        archive_name:s tr\n            Name of archive\n\n        tags: list or tuple of strings\n            tags to delete from the archive\n\n        '''\n        updated_tag_list = list(self._get_tags(archive_name))\n        for tag in tags:\n            if tag in updated_tag_list:\n                updated_tag_list.remove(tag)\n\n        self._set_tags(archive_name, updated_tag_list)", "response": "Delete tags from an archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncoerces tags to lowercase strings", "response": "def _normalize_tags(self, tags):\n        '''\n        Coerces tags to lowercase strings\n\n        Parameters\n        ----------\n        tags: list or tuple of strings\n\n        '''\n\n        lowered_str_tags = []\n        for tag in tags:\n            lowered_str_tags.append(str(tag).lower())\n\n        return lowered_str_tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the project on the directory", "response": "def start(self):\n        \"Start the project on the directory\"\n        bookname = self.args.get('--bookname', None)\n        if not bookname:\n            bookname = 'book.md'\n        project_dir = self.args.get('<name>', None)\n        if not project_dir:\n            project_dir = join(self.cwd, 'Book')\n        project_dir = abspath(project_dir)\n\n        # create the working dir?\n        if not exists(project_dir) or self.args['--overwrite']:\n            if exists(project_dir):\n                if yesno(warning(\n                        'Are you sure you want to remove `%s`? '\n                        % project_dir)):\n                    shutil.rmtree(project_dir)\n                else:\n                    sys.exit(error('Operation aborted'))\n            os.makedirs(project_dir)\n            os.makedirs(join(project_dir, 'build'))\n            with codecs.open(\n                    join(project_dir, bookname), 'w', encoding=\"utf\") as fd:\n                fd.write('''# This is your book\n    You can start it right now and publish it away!\n    ''')\n        # What shall we do with the configuration file?\n        config_file = join(project_dir, 'book.json')\n        rewrite_config_file = True\n        if exists(config_file) and not self.args['--overwrite']:\n            print('A config file already exists. This step is skipped')\n            rewrite_config_file = False\n\n        if rewrite_config_file:\n            with codecs.open(config_file, 'w', encoding=\"utf\") as fd:\n                data = {\n                    'files': ['%s' % bookname],\n                    'author': \"%s\" % ask(\"What is your name? \"),\n                    'title': '%s' % ask(\"E-book title, please? \"),\n                }\n                data['fileroot'] = unidecode(data['title']).lower() \\\n                    .replace(' ', '-')\n                # pick a generator\n                if len(self.generators) == 1:\n                    data['generator'] = self.generators[0]\n                else:\n                    picked_generator = None\n                    while not picked_generator:\n                        picked_generator = ask(\n                            \"Which generator? [%s] \"\n                            % ', '.join(self.generators)\n                        )\n                        if picked_generator not in self.generators:\n                            print warning(\n                                'Wrong answer. Please pick one on the list')\n                            picked_generator = None\n                    # fine, we have one.\n                    data['generator'] = picked_generator\n                json.dump(data, fd, indent=4, encoding=\"utf\")\n\n        # Game over\n        print\n        sys.exit(\n            success('Now you can go to `%s` and start editing your book...'\n                    % project_dir))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating this DATABASE. @param sql: (Optional) A string of psql (such as might be generated by pg_dump); it will be executed by psql(1) after creating the database. @type sql: str @rtype: None", "response": "def create(self, sql=None):\n        \"\"\"CREATE this DATABASE.\n\n        @param sql: (Optional) A string of psql (such as might be generated\n        by pg_dump); it will be executed by psql(1) after creating the\n        database.\n        @type sql: str\n\n        @rtype: None\n        \"\"\"\n        create_sql = 'CREATE DATABASE {self.db_name} WITH OWNER {self.user}'\n        create_sql = create_sql.format(**vars())\n        self.super_psql(['-c', create_sql])\n        if sql:\n            self.psql_string(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the sql string using psql.", "response": "def psql_string(self, sql):\n        \"\"\"\n        Evaluate the sql file (possibly multiple statements) using psql.\n        \"\"\"\n        argv = [\n            PostgresFinder.find_root() / 'psql',\n            '--quiet',\n            '-U', self.user,\n            '-h', self.host,\n            '-p', self.port,\n            '-f', '-',\n            self.db_name,\n        ]\n        popen = subprocess.Popen(argv, stdin=subprocess.PIPE)\n        popen.communicate(input=sql.encode('utf-8'))\n        if popen.returncode != 0:\n            raise subprocess.CalledProcessError(popen.returncode, argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninvokes the psql command - line.", "response": "def psql(self, args):\n        r\"\"\"Invoke psql, passing the given command-line arguments.\n\n        Typical <args> values: ['-c', <sql_string>] or ['-f', <pathname>].\n\n        Connection parameters are taken from self.  STDIN, STDOUT,\n        and STDERR are inherited from the parent.\n\n        WARNING: This method uses the psql(1) program, which ignores SQL\n        errors\n        by default.  That hides many real errors, making our software less\n        reliable.  To overcome this flaw, add this line to the head of your\n        SQL:\n            \"\\set ON_ERROR_STOP TRUE\"\n\n        @return: None. Raises an exception upon error, but *ignores SQL\n        errors* unless \"\\set ON_ERROR_STOP TRUE\" is used.\n        \"\"\"\n        argv = [\n            PostgresFinder.find_root() / 'psql',\n            '--quiet',\n            '-U', self.user,\n            '-h', self.host,\n            '-p', self.port,\n        ] + args + [self.db_name]\n        subprocess.check_call(argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sql(self, input_string, *args):\n        \"\"\"\n        # I advise against using sqlalchemy here (it's more complicated than\n        # what we need), but here's an implementation Just In Case.  -jps\n        import psycopg2, sqlalchemy\n        engine = sqlalchemy.create_engine(\n            'postgres://%s@%s:%s/%s' %\n            (self.user, self.host, self.port, self.db_name),\n            echo=False, poolclass=sqlalchemy.pool.NullPool)\n        connection = engine.connect()\n        result = connection.execute(input_string, *args)\n        try:\n            # sqlalchemy 0.6.7 offers a result.returns_rows attribute, but\n            # no prior version offers anything comparable.  A tacky\n            # workaround...\n            try:\n                return result.fetchall()\n            except psycopg2.ProgrammingError:\n                return None\n        finally:\n            result.close()\n            connection.close()\n        \"\"\"\n        psycopg2 = importlib.import_module('psycopg2')\n        importlib.import_module('psycopg2.extensions')\n        connection = psycopg2.connect(\n            user=self.user, host=self.host,\n            port=self.port, database=self.db_name)\n        connection.set_isolation_level(\n            psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n        try:\n            cursor = connection.cursor()\n            cursor.execute(input_string, args)\n            # No way to ask whether any rows were returned, so just try it...\n            try:\n                return cursor.fetchall()\n            except psycopg2.ProgrammingError:\n                return None\n        finally:\n            connection.close()", "response": "Execute a SQL command using the Python DBI directly."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef super_psql(self, args):\n        argv = [\n            PostgresFinder.find_root() / 'psql',\n            '--quiet',\n            '-U', self.superuser,\n            '-h', self.host,\n            '-p', self.port,\n        ] + args\n        subprocess.check_call(argv)", "response": "Just like psql except that we connect to the superuser s database and we connect to the user s database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef destroy(self):\n        self.stop()\n        if self.base_pathname is not None:\n            self._robust_remove(self.base_pathname)", "response": "Undo the effects of initdb. destroy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the directory specified by path.", "response": "def _robust_remove(path):\n        \"\"\"\n        Remove the directory specified by `path`. Because we can't determine\n        directly if the path is in use, and on Windows, it's not possible to\n        remove a path if it is in use, retry a few times until the call\n        succeeds.\n        \"\"\"\n        tries = itertools.count()\n        max_tries = 50\n        while os.path.isdir(path):\n            try:\n                shutil.rmtree(path)\n            except WindowsError:\n                if next(tries) >= max_tries:\n                    raise\n                time.sleep(0.2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initdb(self, quiet=True, locale='en_US.UTF-8'):\n        # Defining base_pathname is deferred until this point because we don't\n        # want to create a temp directory unless it's needed.  And now it is!\n        if self.base_pathname in [None, '']:\n            self.base_pathname = tempfile.mkdtemp()\n        if not os.path.isdir(self.base_pathname):\n            os.mkdir(self.base_pathname)\n        stdout = DEV_NULL if quiet else None\n        # The database superuser needs no password at this point(!).\n        arguments = [\n            '--auth=trust',\n            '--username', self.superuser,\n        ]\n        if locale is not None:\n            arguments.extend(('--locale', locale))\n        cmd = [\n            PostgresFinder.find_root() / 'initdb',\n        ] + arguments + ['--pgdata', self.base_pathname]\n        log.info('Initializing PostgreSQL with command: {}'.format(\n            ' '.join(cmd)\n        ))\n        subprocess.check_call(cmd, stdout=stdout)", "response": "Bootstrap this DBMS from nothing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_running(self, tries=10):\n        # We can't possibly be running if our base_pathname isn't defined.\n        if not self.base_pathname:\n            return False\n\n        if tries < 1:\n            raise ValueError('tries must be > 0')\n\n        cmd = [\n            PostgresFinder.find_root() / 'pg_ctl',\n            'status',\n            '-D',\n            self.base_pathname,\n        ]\n        votes = 0\n        while abs(votes) < tries:\n            time.sleep(0.1)\n            running = (subprocess.call(cmd, stdout=DEV_NULL) == 0)\n            if running and votes >= 0:\n                votes += 1\n            elif not running and votes <= 0:\n                votes -= 1\n            else:\n                votes = 0\n\n        return votes > 0", "response": "Return True if the server is running according to pg_ctl."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ready(self):\n        cmd = self._psql_cmd()\n        for i in range(50, -1, -1):\n            res = subprocess.call(\n                cmd, stdin=DEV_NULL, stdout=DEV_NULL,\n                stderr=DEV_NULL)\n            if res == 0:\n                break\n            time.sleep(0.2)\n        return i != 0", "response": "Tests that pg_ctl is ready to connect to the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the Postgres version in tuple form e. g. 9 1", "response": "def get_version():\n        \"\"\"Returns the Postgres version in tuple form, e.g: (9, 1)\"\"\"\n        cmd = [PostgresFinder.find_root() / 'pg_ctl', '--version']\n        results = subprocess.check_output(cmd).decode('utf-8')\n        match = re.search(r'(\\d+\\.\\d+(\\.\\d+)?)', results)\n        if match:\n            ver_string = match.group(0)\n            return tuple(int(x) for x in ver_string.split('.'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlaunch this postgres server.", "response": "def start(self):\n        \"\"\"Launch this postgres server.  If it's already running, do nothing.\n\n        If the backing storage directory isn't configured, raise\n        NotInitializedError.\n\n        This method is optional.  If you're running in an environment\n        where the DBMS is provided as part of the basic infrastructure,\n        you probably want to skip this step!\n        \"\"\"\n        log.info('Starting PostgreSQL at %s:%s', self.host, self.port)\n        if not self.base_pathname:\n            tmpl = ('Invalid base_pathname: %r.  Did you forget to call '\n                    '.initdb()?')\n            raise NotInitializedError(tmpl % self.base_pathname)\n\n        conf_file = os.path.join(self.base_pathname, 'postgresql.conf')\n        if not os.path.exists(conf_file):\n            tmpl = 'No config file at: %r.  Did you forget to call .initdb()?'\n            raise NotInitializedError(tmpl % self.base_pathname)\n\n        if not self.is_running():\n            version = self.get_version()\n            if version and version >= (9, 3):\n                socketop = 'unix_socket_directories'\n            else:\n                socketop = 'unix_socket_directory'\n            postgres_options = [\n                # When running not as root, postgres might try to put files\n                #  where they're not writable (see\n                #  https://paste.yougov.net/YKdgi). So set the socket_dir.\n                '-c', '{}={}'.format(socketop, self.base_pathname),\n                '-h', self.host,\n                '-i',  # enable TCP/IP connections\n                '-p', self.port,\n            ]\n            subprocess.check_call([\n                PostgresFinder.find_root() / 'pg_ctl',\n                'start',\n                '-D', self.base_pathname,\n                '-l', os.path.join(self.base_pathname, 'postgresql.log'),\n                '-o', subprocess.list2cmdline(postgres_options),\n            ])\n\n        # Postgres may launch, then abort if it's unhappy with some parameter.\n        # This post-launch test helps us decide.\n        if not self.is_running():\n            tmpl = ('%s aborted immediately after launch, check '\n                    'postgresql.log in storage dir')\n            raise RuntimeError(tmpl % self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n        log.info('Stopping PostgreSQL at %s:%s', self.host, self.port)\n        if self._is_running():\n            cmd = [\n                PostgresFinder.find_root() / 'pg_ctl',\n                'stop',\n                '-D', self.base_pathname,\n                '-m', 'fast',\n            ]\n            subprocess.check_call(cmd)\n            # pg_ctl isn't reliable if it's called at certain critical times\n            if self.pid:\n                os.kill(self.pid, signal.SIGTERM)\n        # Can't use wait() because the server might not be our child\n        while self._is_running():\n            time.sleep(0.1)", "response": "Stop this DMBS daemon."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, db_name, **kwargs):\n        db = PostgresDatabase(\n            db_name, host=self.host, port=self.port,\n            superuser=self.superuser, **kwargs)\n        db.ensure_user()\n        db.create()\n        return db", "response": "Create a PostgresDatabase and return it on self."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _search(self, search_terms, begins_with=None):\n\n        kwargs = dict(\n            ProjectionExpression='#id',\n            ExpressionAttributeNames={\"#id\": \"_id\"})\n\n        if len(search_terms) > 0:\n            kwargs['FilterExpression'] = reduce(\n                lambda x, y: x & y,\n                [Attr('tags').contains(arg) for arg in search_terms])\n\n        if begins_with:\n            if 'FilterExpression' in kwargs:\n                kwargs['FilterExpression'] = kwargs[\n                    'FilterExpression'] & Key('_id').begins_with(begins_with)\n\n            else:\n                kwargs['FilterExpression'] = Key(\n                    '_id').begins_with(begins_with)\n\n        while True:\n            res = self._table.scan(**kwargs)\n            for r in res['Items']:\n                yield r['_id']\n            if 'LastEvaluatedKey' in res:\n                kwargs['ExclusiveStartKey'] = res['LastEvaluatedKey']\n            else:\n                break", "response": "Returns a list of Archive id s in the table on Dynamo\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the version specific metadata attribute in DynamoDB with the given dictionary of version metadata values.", "response": "def _update(self, archive_name, version_metadata):\n        '''\n        Updates the version specific metadata attribute in DynamoDB\n        In DynamoDB this is simply a list append on this attribute value\n\n        Parameters\n        ----------\n        archive_name: str\n            unique '_id' primary key\n\n        version_metadata: dict\n            dictionary of version metadata values\n\n        Returns\n        -------\n        dict\n            list of dictionaries of version_history\n        '''\n\n        command = \"SET version_history = list_append(version_history, :v)\"\n\n        self._table.update_item(\n            Key={'_id': archive_name},\n            UpdateExpression=command,\n            ExpressionAttributeValues={':v': [version_metadata]},\n            ReturnValues='ALL_NEW')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_archive_table(self, table_name):\n        '''\n        Dynamo implementation of BaseDataManager create_archive_table\n\n        waiter object is implemented to ensure table creation before moving on\n        this will slow down table creation. However, since we are only creating\n        table once this should no impact users.\n\n        Parameters\n        ----------\n        table_name: str\n\n        Returns\n        -------\n        None\n\n        '''\n        if table_name in self._get_table_names():\n            raise KeyError('Table \"{}\" already exists'.format(table_name))\n\n        try:\n            table = self._resource.create_table(\n                TableName=table_name,\n                KeySchema=[{'AttributeName': '_id', 'KeyType': 'HASH'}],\n                AttributeDefinitions=[\n                    {'AttributeName': '_id', 'AttributeType': 'S'}],\n                ProvisionedThroughput={\n                    'ReadCapacityUnits': 123,\n                    'WriteCapacityUnits': 123})\n\n            table.meta.client.get_waiter('table_exists').wait(\n                TableName=table_name)\n\n        except ValueError:\n            # Error handling for windows incompatability issue\n            msg = 'Table creation failed'\n            assert table_name in self._get_table_names(), msg", "response": "Dynamo implementation of BaseDataManager create_archive_table returning a new table object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_spec_config(self, table_name, spec_documents):\n        '''\n        Dynamo implementation of spec config creation\n\n        Called by `create_archive_table()` in\n        :py:class:`manager.BaseDataManager` Simply adds two rows to the spec\n        table\n\n        Parameters\n        ----------\n\n        table_name :\n\n            base table name (not including .spec suffix)\n\n        spec_documents : list\n\n            list of dictionary documents defining the manager spec\n\n\n        '''\n\n        _spec_table = self._resource.Table(table_name + '.spec')\n\n        for doc in spec_documents:\n            _spec_table.put_item(Item=doc)", "response": "Create the spec config for the base table with the given spec_documents."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the spec config for the specified document.", "response": "def _update_spec_config(self, document_name, spec):\n        '''\n        Dynamo implementation of project specific metadata spec\n\n        '''\n        # add the updated archive_metadata object to Dynamo\n        self._spec_table.update_item(\n            Key={'_id': '{}'.format(document_name)},\n            UpdateExpression=\"SET config = :v\",\n            ExpressionAttributeValues={':v': spec},\n            ReturnValues='ALL_NEW')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the metadata of the specific entry in the archive.", "response": "def _update_metadata(self, archive_name, archive_metadata):\n        \"\"\"\n        Appends the updated_metada dict to the Metadata Attribute list\n\n        Parameters\n        ----------\n        archive_name: str\n\n            ID of archive to update\n\n        updated_metadata: dict\n\n            dictionary of metadata keys and values to update. If the value\n            for a particular key is `None`, the key is removed.\n\n        \"\"\"\n\n        archive_metadata_current = self._get_archive_metadata(archive_name)\n        archive_metadata_current.update(archive_metadata)\n        for k, v in archive_metadata_current.items():\n            if v is None:\n                del archive_metadata_current[k]\n\n        # add the updated archive_metadata object to Dynamo\n        self._table.update_item(\n            Key={'_id': archive_name},\n            UpdateExpression=\"SET archive_metadata = :v\",\n            ExpressionAttributeValues={':v': archive_metadata_current},\n            ReturnValues='ALL_NEW')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _batch_get_archive_listing(self, archive_names):\n        '''\n        Batched version of :py:meth:`~DynamoDBManager._get_archive_listing`\n\n        Returns a list of full archive listings from an iterable of archive\n        names\n\n        .. note ::\n\n            Invalid archive names will simply not be returned, so the response\n            may not be the same length as the supplied `archive_names`.\n\n        Parameters\n        ----------\n\n        archive_names : list\n\n            List of archive names\n\n        Returns\n        -------\n\n        archive_listings : list\n\n            List of archive listings\n\n        '''\n\n        archive_names = list(archive_names)\n\n        MAX_QUERY_LENGTH = 100\n\n        archives = []\n\n        for query_index in range(0, len(archive_names), MAX_QUERY_LENGTH):\n            current_query = {\n                'Keys': [{'_id': i} for i in archive_names[\n                    query_index: query_index+MAX_QUERY_LENGTH]]}\n\n            attempts = 0\n            res = {}\n\n            while True:\n\n                if attempts > 0 and len(res.get('UnprocessedKeys', {})) > 0:\n                    current_query = res['UnprocessedKeys'][self._table_name]\n\n                elif attempts > 0 and len(res.get('UnprocessedKeys', {})) == 0:\n                    break\n\n                res = self._resource.batch_get_item(\n                    RequestItems={self._table_name: current_query})\n\n                archives.extend(res['Responses'][self._table_name])\n\n                attempts += 1\n\n        return archives", "response": "Batched version of _get_archive_listing"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new VOEvent element tree with specified IVORN and role.", "response": "def Voevent(stream, stream_id, role):\n    \"\"\"Create a new VOEvent element tree, with specified IVORN and role.\n\n    Args:\n\n        stream (str): used to construct the IVORN like so::\n\n                ivorn = 'ivo://' + stream + '#' + stream_id\n\n            (N.B. ``stream_id`` is converted to string if required.)\n            So, e.g. we might set::\n\n                stream='voevent.soton.ac.uk/super_exciting_events'\n                stream_id=77\n\n        stream_id (str): See above.\n\n        role (str): role as defined in VOEvent spec.\n            (See also  :py:class:`.definitions.roles`)\n\n    Returns:\n        Root-node of the VOEvent, as represented by an lxml.objectify element\n        tree ('etree'). See also\n        http://lxml.de/objectify.html#the-lxml-objectify-api\n    \"\"\"\n    parser = objectify.makeparser(remove_blank_text=True)\n    v = objectify.fromstring(voeventparse.definitions.v2_0_skeleton_str,\n                             parser=parser)\n    _remove_root_tag_prefix(v)\n    if not isinstance(stream_id, string_types):\n        stream_id = repr(stream_id)\n    v.attrib['ivorn'] = ''.join(('ivo://', stream, '#', stream_id))\n    v.attrib['role'] = role\n    # Presumably we'll always want the following children:\n    # (NB, valid to then leave them empty)\n    etree.SubElement(v, 'Who')\n    etree.SubElement(v, 'What')\n    etree.SubElement(v, 'WhereWhen')\n    v.Who.Description = (\n        'VOEvent created with voevent-parse, version {}. '\n        'See https://github.com/timstaley/voevent-parse for details.').format(\n        __version__\n    )\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loads(s, check_version=True):\n    # .. note::\n    #\n    # The namespace is removed from the root element tag to make\n    #        objectify access work as expected,\n    #        (see  :py:func:`._remove_root_tag_prefix`)\n    #        so we must re-insert it when we want to conform to schema.\n    v = objectify.fromstring(s)\n    _remove_root_tag_prefix(v)\n\n    if check_version:\n        version = v.attrib['version']\n        if not version == '2.0':\n            raise ValueError('Unsupported VOEvent schema version:' + version)\n\n    return v", "response": "Loads a VOEvent XML packet string from bytes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a VOEvent from a file object.", "response": "def load(file, check_version=True):\n    \"\"\"Load VOEvent from file object.\n\n    A simple wrapper to read a file before passing the contents to\n    :py:func:`.loads`. Use with an open file object, e.g.::\n\n        with open('/path/to/voevent.xml', 'rb') as f:\n            v = vp.load(f)\n\n    Args:\n        file (io.IOBase): An open file object (binary mode preferred), see also\n            http://lxml.de/FAQ.html :\n            \"Can lxml parse from file objects opened in unicode/text mode?\"\n\n        check_version (bool): (Default=True) Checks that the VOEvent is of a\n            supported schema version - currently only v2.0 is supported.\n    Returns:\n        :py:class:`Voevent`: Root-node of the  etree.\n    \"\"\"\n    s = file.read()\n    return loads(s, check_version)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a VOevent to a byte string.", "response": "def dumps(voevent, pretty_print=False, xml_declaration=True, encoding='UTF-8'):\n    \"\"\"Converts voevent to string.\n\n    .. note:: Default encoding is UTF-8, in line with VOE2.0 schema.\n        Declaring the encoding can cause diffs with the original loaded VOEvent,\n        but I think it's probably the right thing to do (and lxml doesn't\n        really give you a choice anyway).\n\n    Args:\n        voevent (:class:`Voevent`): Root node of the VOevent etree.\n        pretty_print (bool): indent the output for improved human-legibility\n            when possible. See also:\n            http://lxml.de/FAQ.html#why-doesn-t-the-pretty-print-option-reformat-my-xml-output\n        xml_declaration (bool): Prepends a doctype tag to the string output,\n            i.e. something like ``<?xml version='1.0' encoding='UTF-8'?>``\n    Returns:\n        bytes: Bytestring containing raw XML representation of VOEvent.\n\n    \"\"\"\n    vcopy = copy.deepcopy(voevent)\n    _return_to_standard_xml(vcopy)\n    s = etree.tostring(vcopy, pretty_print=pretty_print,\n                       xml_declaration=xml_declaration,\n                       encoding=encoding)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump(voevent, file, pretty_print=True, xml_declaration=True):\n    file.write(dumps(voevent, pretty_print, xml_declaration))", "response": "Dumps the voevent to the file object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntesting if a VOEvent conforms to the schema.", "response": "def valid_as_v2_0(voevent):\n    \"\"\"Tests if a voevent conforms to the schema.\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n    Returns:\n        bool: Whether VOEvent is valid\n    \"\"\"\n    _return_to_standard_xml(voevent)\n    valid_bool = voevent_v2_0_schema.validate(voevent)\n    _remove_root_tag_prefix(voevent)\n    return valid_bool"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the minimal Who attributes of a VOEvent.", "response": "def set_who(voevent, date=None, author_ivorn=None):\n    \"\"\"Sets the minimal 'Who' attributes:  date of authoring, AuthorIVORN.\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n        date(datetime.datetime): Date of authoring.\n            NB Microseconds are ignored, as per the VOEvent spec.\n        author_ivorn(str): Short author identifier,\n            e.g. ``voevent.4pisky.org/ALARRM``.\n            Note that the prefix ``ivo://`` will be prepended internally.\n\n    \"\"\"\n    if author_ivorn is not None:\n        voevent.Who.AuthorIVORN = ''.join(('ivo://', author_ivorn))\n    if date is not None:\n        voevent.Who.Date = date.replace(microsecond=0).isoformat()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_author(voevent, title=None, shortName=None, logoURL=None,\n               contactName=None, contactEmail=None, contactPhone=None,\n               contributor=None):\n    \"\"\"For setting fields in the detailed author description.\n\n    This can optionally be neglected if a well defined AuthorIVORN is supplied.\n\n    .. note:: Unusually for this library,\n        the args here use CamelCase naming convention,\n        since there's a direct mapping to the ``Author.*``\n        attributes to which they will be assigned.\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n            The rest of the arguments are strings corresponding to child elements.\n    \"\"\"\n    # We inspect all local variables except the voevent packet,\n    # Cycling through and assigning them on the Who.Author element.\n    AuthChildren = locals()\n    AuthChildren.pop('voevent')\n    if not voevent.xpath('Who/Author'):\n        etree.SubElement(voevent.Who, 'Author')\n    for k, v in AuthChildren.items():\n        if v is not None:\n            voevent.Who.Author[k] = v", "response": "Set fields in the detailed author description."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_where_when(voevent, coords, obs_time, observatory_location,\n                   allow_tz_naive_datetime=False):\n    \"\"\"\n    Add details of an observation to the WhereWhen section.\n\n    We\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n        coords(:class:`.Position2D`): Sky co-ordinates of event.\n        obs_time(datetime.datetime): Nominal DateTime of the observation. Must\n            either be timezone-aware, or should be carefully verified as\n            representing UTC and then set parameter\n            ``allow_tz_naive_datetime=True``.\n        observatory_location(str): Telescope locale, e.g. 'La Palma'.\n            May be a generic location as listed under\n            :class:`voeventparse.definitions.observatory_location`.\n        allow_tz_naive_datetime (bool): (Default False). Accept timezone-naive\n            datetime-timestamps. See comments for ``obs_time``.\n\n    \"\"\"\n\n    # .. todo:: Implement TimeError using datetime.timedelta\n    if obs_time.tzinfo is not None:\n        utc_naive_obs_time = obs_time.astimezone(pytz.utc).replace(tzinfo=None)\n    elif not allow_tz_naive_datetime:\n        raise ValueError(\n            \"Datetime passed without tzinfo, cannot be sure if it is really a \"\n            \"UTC timestamp. Please verify function call and either add tzinfo \"\n            \"or pass parameter 'allow_tz_naive_obstime=True', as appropriate\",\n        )\n    else:\n        utc_naive_obs_time = obs_time\n\n    obs_data = etree.SubElement(voevent.WhereWhen, 'ObsDataLocation')\n    etree.SubElement(obs_data, 'ObservatoryLocation', id=observatory_location)\n    ol = etree.SubElement(obs_data, 'ObservationLocation')\n    etree.SubElement(ol, 'AstroCoordSystem', id=coords.system)\n    ac = etree.SubElement(ol, 'AstroCoords',\n                          coord_system_id=coords.system)\n    time = etree.SubElement(ac, 'Time', unit='s')\n    instant = etree.SubElement(time, 'TimeInstant')\n    instant.ISOTime = utc_naive_obs_time.isoformat()\n    # iso_time = etree.SubElement(instant, 'ISOTime') = obs_time.isoformat()\n\n    pos2d = etree.SubElement(ac, 'Position2D', unit=coords.units)\n    pos2d.Name1 = 'RA'\n    pos2d.Name2 = 'Dec'\n    pos2d_val = etree.SubElement(pos2d, 'Value2')\n    pos2d_val.C1 = coords.ra\n    pos2d_val.C2 = coords.dec\n    pos2d.Error2Radius = coords.err", "response": "Add details of an observation to the WhereWhen section."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds descriptions or references to the How section of a VOEvent.", "response": "def add_how(voevent, descriptions=None, references=None):\n    \"\"\"Add descriptions or references to the How section.\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n        descriptions(str): Description string, or list of description\n            strings.\n        references(:py:class:`voeventparse.misc.Reference`): A reference element\n            (or list thereof).\n    \"\"\"\n    if not voevent.xpath('How'):\n        etree.SubElement(voevent, 'How')\n    if descriptions is not None:\n        for desc in _listify(descriptions):\n            # d = etree.SubElement(voevent.How, 'Description')\n            # voevent.How.Description[voevent.How.index(d)] = desc\n            ##Simpler:\n            etree.SubElement(voevent.How, 'Description')\n            voevent.How.Description[-1] = desc\n    if references is not None:\n        voevent.How.extend(_listify(references))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_why(voevent, importance=None, expires=None, inferences=None):\n    if not voevent.xpath('Why'):\n        etree.SubElement(voevent, 'Why')\n    if importance is not None:\n        voevent.Why.attrib['importance'] = str(importance)\n    if expires is not None:\n        voevent.Why.attrib['expires'] = expires.replace(\n            microsecond=0).isoformat()\n    if inferences is not None:\n        voevent.Why.extend(_listify(inferences))", "response": "Add Inferences or set importance and expires attributes of the Why section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd citations to other voevents.", "response": "def add_citations(voevent, event_ivorns):\n    \"\"\"Add citations to other voevents.\n\n    The schema mandates that the 'Citations' section must either be entirely\n    absent, or non-empty - hence we require this wrapper function for its\n    creation prior to listing the first citation.\n\n    Args:\n        voevent(:class:`Voevent`): Root node of a VOEvent etree.\n        event_ivorns (:class:`voeventparse.misc.EventIvorn`): List of EventIvorn\n            elements to add to citation list.\n\n    \"\"\"\n    if not voevent.xpath('Citations'):\n        etree.SubElement(voevent, 'Citations')\n    voevent.Citations.extend(_listify(event_ivorns))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_root_tag_prefix(v):\n    if v.prefix:\n        # Create subelement without a prefix via etree.SubElement\n        etree.SubElement(v, 'original_prefix')\n        # Now carefully access said named subelement (without prefix cascade)\n        # and alter the first value in the list of children with this name...\n        # LXML syntax is a minefield!\n        v['{}original_prefix'][0] = v.prefix\n        v.tag = v.tag.replace(''.join(('{', v.nsmap[v.prefix], '}')), '')\n        # Now v.tag = '{}VOEvent', v.prefix = None\n    return", "response": "Removes VOE namespace prefix from root tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning namespace prefix to root tag.", "response": "def _reinsert_root_tag_prefix(v):\n    \"\"\"\n    Returns namespace prefix to root tag, if it had one.\n    \"\"\"\n    if hasattr(v, 'original_prefix'):\n        original_prefix = v.original_prefix\n        del v.original_prefix\n        v.tag = ''.join(('{', v.nsmap[original_prefix], '}VOEvent'))\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring x is iterable and return it.", "response": "def _listify(x):\n    \"\"\"Ensure x is iterable; if not then enclose it in a list and return it.\"\"\"\n    if isinstance(x, string_types):\n        return [x]\n    elif isinstance(x, collections.Iterable):\n        return x\n    else:\n        return [x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, label=None, per_page=20, page=1):\n\n        params = {'per_page': per_page, 'page': page}\n\n        if label:\n            params['label'] = label\n\n        return self.request.get('', params)", "response": "Get a list of identities that have been created by the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, label, status=None, master=None):\n\n        params = {'label': label}\n\n        if status:\n            params['status'] = status\n        if master:\n            params['master'] = master\n\n        return self.request.post('', params)", "response": "Create an Identity\n\n            :param label: The label to give this new identity\n            :param status: The status of this identity. Default: 'active'\n            :param master: Represents whether this identity is a master.\n                Default: False\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, id, label=None, status=None, master=None):\n\n        params = {}\n\n        if label:\n            params['label'] = label\n        if status:\n            params['status'] = status\n        if master:\n            params['master'] = master\n\n        return self.request.put(str(id), params)", "response": "Update an Identity with optional label status master"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, id, service='facebook', type='analysis'):\n        return self.request.get(service + '/task/' + type + '/' + id)", "response": "Get a given Pylon task\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of Pylon tasks in a service.", "response": "def list(self, per_page=None, page=None, status=None, service='facebook'):\n        \"\"\" Get a list of Pylon tasks\n\n            :param per_page: How many tasks to display per page\n            :type per_page: int\n            :param page: Which page of tasks to display\n            :type page: int\n            :param status: The status of the tasks to list\n            :type page: string\n            :param service: The PYLON service (facebook)\n            :type service: str\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {}\n\n        if per_page is not None:\n            params['per_page'] = per_page\n        if page is not None:\n            params['page'] = page\n        if status:\n            params['status'] = status\n\n        return self.request.get(service + '/task', params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, subscription_id, name, parameters, type='analysis', service='facebook'):\n\n        params = {\n            'subscription_id': subscription_id,\n            'name': name,\n            'parameters': parameters,\n            'type': type\n        }\n\n        return self.request.post(service + '/task/', params)", "response": "Create a new task for a specific user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef value_from_datadict(self, data, files, name):\n        upload = super(StickyUploadWidget, self).value_from_datadict(data, files, name)\n        if upload is not None:\n            # File was posted or cleared as normal\n            return upload\n        else:\n            # Try the hidden input\n            hidden_name = self.get_hidden_name(name)\n            value = data.get(hidden_name, None)\n            if value is not None:\n                upload = open_stored_file(value, self.url)\n                if upload is not None:\n                    setattr(upload, '_seralized_location', value)\n        return upload", "response": "Returns uploaded file from serialized value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, name, value, attrs=None, renderer=None):\n        location = getattr(value, '_seralized_location', '')\n        if location and not hasattr(value, 'url'):\n            value.url = '#'\n            if hasattr(self, 'get_template_substitution_values'):\n                # Django 1.8-1.10\n                self.template_with_initial = (\n                    '%(initial_text)s: %(initial)s %(clear_template)s'\n                    '<br />%(input_text)s: %(input)s')\n        attrs = attrs or {}\n        attrs.update({'data-upload-url': self.url})\n        hidden_name = self.get_hidden_name(name)\n        kwargs = {}\n        if django_version >= (1, 11):\n            kwargs['renderer'] = renderer\n\n        parent = super(StickyUploadWidget, self).render(name, value, attrs=attrs, **kwargs)\n        hidden = forms.HiddenInput().render(hidden_name, location, **kwargs)\n\n        return mark_safe(parent + '\\n' + hidden)", "response": "Include a hidden input to store the serialized upload value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure Switchboard with the given configuration.", "response": "def configure(config={}, datastore=None, nested=False):\n    \"\"\"\n    Useful for when you need to control Switchboard's setup\n    \"\"\"\n    if nested:\n        config = nested_config(config)\n    # Re-read settings to make sure we have everything.\n    # XXX It would be really nice if we didn't need to do this.\n    Settings.init(**config)\n\n    if datastore:\n        Switch.ds = datastore\n\n    # Register the builtins\n    __import__('switchboard.builtins')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if switch is active.", "response": "def is_active(self, key, *instances, **kwargs):\n        \"\"\"\n        Returns ``True`` if any of ``instances`` match an active switch.\n        Otherwise returns ``False``.\n\n        >>> operator.is_active('my_feature', request) #doctest: +SKIP\n        \"\"\"\n        try:\n            default = kwargs.pop('default', False)\n\n            # Check all parents for a disabled state\n            parts = key.split(':')\n            if len(parts) > 1:\n                child_kwargs = kwargs.copy()\n                child_kwargs['default'] = None\n                result = self.is_active(':'.join(parts[:-1]), *instances,\n                                        **child_kwargs)\n\n                if result is False:\n                    return result\n                elif result is True:\n                    default = result\n\n            try:\n                switch = self[key]\n            except KeyError:\n                # switch is not defined, defer to parent\n                return default\n\n            if switch.status == GLOBAL:\n                return True\n            elif switch.status == DISABLED:\n                return False\n            elif switch.status == INHERIT:\n                return default\n\n            conditions = switch.value\n            # If no conditions are set, we inherit from parents\n            if not conditions:\n                return default\n\n            instances = list(instances) if instances else []\n            instances.extend(self.context.values())\n\n            # check each switch to see if it can execute\n            return_value = False\n\n            for namespace, condition in conditions.iteritems():\n                condition_set = registry_by_namespace.get(namespace)\n                if not condition_set:\n                    continue\n                result = condition_set.has_active_condition(condition,\n                                                            instances)\n                if result is False:\n                    return False\n                elif result is True:\n                    return_value = True\n        except:\n            log.exception('Error checking if switch \"%s\" is active', key)\n            return_value = False\n\n        # there were no matching conditions, so it must not be enabled\n        return return_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register(self, condition_set):\n\n        if callable(condition_set):\n            condition_set = condition_set()\n        registry[condition_set.get_id()] = condition_set\n        registry_by_namespace[condition_set.get_namespace()] = condition_set", "response": "Registers a condition set with the manager."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the probability of given url being a duplicate of some content ArcGIS content.", "response": "def get_dupe_prob(self, url):\n        \"\"\" A probability of given url being a duplicate of some content\n        that has already been seem.\n        \"\"\"\n        path, query = _parse_url(url)\n        dupestats = []\n        extend_ds = lambda x: dupestats.extend(filter(None, (\n            ds_dict.get(key) for ds_dict, key in x)))\n        if self.urls_by_path.get(path):\n            extend_ds([(self.path_dupstats, path)])\n        # If param is in the query\n        for param, value in query.items():\n            qwp_key = _q_key(_without_key(query, param))\n            # Have we seen the query with param changed or removed?\n            has_changed = self.urls_by_path_qwp.get((path, param, qwp_key))\n            has_removed = self.urls_by_path_q.get((path, qwp_key))\n            if has_changed or has_removed:\n                extend_ds(self._param_dupstats(path, param, qwp_key))\n            if has_removed:\n                extend_ds(self._param_value_dupstats(path, param, value))\n        # If param is not in the query, but we've crawled a page when it is\n        q_key = _q_key(query)\n        for param in (self.params_by_path.get(path, set()) - set(query)):\n            if self.urls_by_path_qwp.get((path, param, q_key)):\n                extend_ds(self._param_dupstats(path, param, q_key))\n                # FIXME - this could be a long list of param values,\n                # it's better to somehow store only high-probability values?\n                for value in self.param_values.get((path, param), set()):\n                    extend_ds(self._param_value_dupstats(path, param, value))\n        return max(ds.get_prob() for ds in dupestats) if dupestats else 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates prediction model with a page by given url and text content.", "response": "def update_model(self, url, text):\n        \"\"\" Update prediction model with a page by given url and text content.\n        Return a list of item duplicates (for testing purposes).\n        \"\"\"\n        min_hash = get_min_hash(text, self.too_common_shingles, self.num_perm)\n        item_url = canonicalize_url(url)\n        item_path, item_query = _parse_url(item_url)\n        all_duplicates = [\n            (url, self.seen_urls[url]) for url in self.lsh.query(min_hash)]\n        duplicates = [(url, m.query) for url, m in all_duplicates\n                      if m.path == item_path]\n        # Hypothesis (1) - just paths\n        n_path_nodup = self._nodup_filter(min_hash, (\n            self.urls_by_path.get(item_path, set())\n            .difference(url for url, _ in duplicates)))\n        self.path_dupstats[item_path].update(len(duplicates), n_path_nodup)\n        # Other hypotheses, if param is in the query\n        for param, value in item_query.items():\n            self._update_with_param(\n                duplicates, min_hash, item_path, item_query, param, [value])\n        # Other hypotheses, if param is not in the query\n        for param in (\n                self.params_by_path.get(item_path, set()) - set(item_query)):\n            self._update_with_param(\n                duplicates, min_hash, item_path, item_query, param,\n                self.param_values.get((item_path, param), set()))\n        # Update indexes\n        for param, value in item_query.items():\n            self.urls_by_path_q[item_path, _q_key(item_query)].add(item_url)\n            item_qwp_key = _q_key(_without_key(item_query, param))\n            self.urls_by_path_qwp[item_path, param, item_qwp_key].add(item_url)\n            self.params_by_path[item_path].add(param)\n            self.param_values[item_path, param].add(value)\n        if not item_query:\n            self.urls_by_path_q[item_path, ()].add(item_url)\n        self.urls_by_path[item_path].add(item_url)\n        if item_url in self.lsh:\n            self.lsh.remove(item_url)\n        self.lsh.insert(item_url, min_hash)\n        self.seen_urls[item_url] = URLMeta(item_path, item_query, min_hash)\n        if len(self.seen_urls) % 100 == 0:\n            self.log_dupstats()\n        return all_duplicates"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _nodup_filter(self, min_hash, all_urls, max_sample=200):\n        if not all_urls:\n            return 0\n        urls = random.sample(all_urls, max_sample) \\\n               if len(all_urls) > max_sample else all_urls\n        filtered = [\n            url for url in urls\n            if min_hash.jaccard(self.seen_urls[url].min_hash) <\n            self.jaccard_threshold]\n        return int(len(filtered) / len(urls) * len(all_urls))", "response": "This filters out the results that are considered not duplicates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove show_rendered from the context if it s there.", "response": "def get_queryset(self, request):\n        \"\"\" Remove ``show_rendered`` from the context, if it's there. \"\"\"\n        qs = super(UnrenderedAdmin, self).get_queryset(request)\n        if 'show_rendered' in qs.query.context:\n            del qs.query.context['show_rendered']\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a one case.", "response": "def get_one(self, cls=None, **kwargs):\n        \"\"\"Returns a one case.\"\"\"\n        case = cls() if cls else self._CasesClass()\n        for attr, value in kwargs.iteritems():\n            setattr(case, attr, value)\n        return case"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a generator that generates positive cases by each choice algorithm.", "response": "def get_each_choice(self, cls=None, **kwargs):\n        \"\"\"Returns a generator that generates positive cases by\n        \"each choice\" algorithm.\n        \"\"\"\n        defaults = {attr: kwargs[attr][0] for attr in kwargs}\n        for set_of_values in izip_longest(*kwargs.values()):\n            case = cls() if cls else self._CasesClass()\n            for attr, value in izip(kwargs.keys(), set_of_values):\n                if value is None:\n                    value = defaults[attr]\n                setattr(case, attr, value)\n            yield case"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_pairwise(self, cls=None, **kwargs):\n        for set_of_values in allpairs(kwargs.values()):\n            case = cls() if cls else self._CasesClass()\n            for attr, value in izip(kwargs.keys(), set_of_values):\n                setattr(case, attr, value)\n            yield case", "response": "Returns a generator that generates positive cases by pairwise algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a generator that generates negative cases by each negative value in separate case algorithm.", "response": "def get_negative(self, cls=None, **kwargs):\n        \"\"\"Returns a generator that generates negative cases by\n        \"each negative value in separate case\" algorithm.\n        \"\"\"\n        for attr, set_of_values in kwargs.iteritems():\n            defaults = {key: kwargs[key][-1][\"default\"] for key in kwargs}\n            defaults.pop(attr)\n            for value in set_of_values[:-1]:\n                case = cls() if cls else self._CasesClass()\n                setattr(case, attr, value)\n                for key in defaults:\n                    setattr(case, key, defaults[key])\n                yield case"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning function that returns sequence of characters of a given length from a given sample", "response": "def get_mix_gen(self, sample):\n        \"\"\"Returns function that returns sequence of characters of a\n        given length from a given sample\n        \"\"\"\n        def mix(length):\n            result = \"\".join(random.choice(sample) for _ in xrange(length)).strip()\n            if len(result) == length:\n                return result\n            return mix(length)\n        return mix"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(connection=None, urls=None, force_download=False):\n    db = DbManager(connection)\n    db.db_import(urls=urls, force_download=force_download)\n    db.session.close()", "response": "Updates CTD database with CTD data from given urls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the connection using MySQL Parameters", "response": "def set_mysql_connection(host='localhost', user='pyctd_user', password='pyctd_passwd', db='pyctd', charset='utf8'):\n    \"\"\"Sets the connection using MySQL Parameters\"\"\"\n    set_connection('mysql+pymysql://{user}:{passwd}@{host}/{db}?charset={charset}'.format(\n        host=host,\n        user=user,\n        passwd=password,\n        db=db,\n        charset=charset)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the connection string for SQLAlchemy", "response": "def set_connection(connection=defaults.sqlalchemy_connection_string_default):\n    \"\"\"Set the connection string for SQLAlchemy\n\n    :param str connection: SQLAlchemy connection string\n    \"\"\"\n    cfp = defaults.config_file_path\n    config = RawConfigParser()\n\n    if not os.path.exists(cfp):\n        with open(cfp, 'w') as config_file:\n            config['database'] = {'sqlalchemy_connection_string': connection}\n            config.write(config_file)\n            log.info('create configuration file %s', cfp)\n    else:\n        config.read(cfp)\n        config.set('database', 'sqlalchemy_connection_string', connection)\n        with open(cfp, 'w') as configfile:\n            config.write(configfile)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_connection_string_by_user_input(self):\n        user_connection = input(\n            bcolors.WARNING + \"\\nFor any reason connection to \" + bcolors.ENDC +\n            bcolors.FAIL + \"{}\".format(self.connection) + bcolors.ENDC +\n            bcolors.WARNING + \" is not possible.\\n\\n\" + bcolors.ENDC +\n            \"For more information about SQLAlchemy connection strings go to:\\n\" +\n            \"http://docs.sqlalchemy.org/en/latest/core/engines.html\\n\\n\"\n            \"Please insert a valid connection string:\\n\" +\n            bcolors.UNDERLINE + \"Examples:\\n\\n\" + bcolors.ENDC +\n            \"MySQL (recommended):\\n\" +\n            bcolors.OKGREEN + \"\\tmysql+pymysql://user:passwd@localhost/database?charset=utf8\\n\" + bcolors.ENDC +\n            \"PostgreSQL:\\n\" +\n            bcolors.OKGREEN + \"\\tpostgresql://scott:tiger@localhost/mydatabase\\n\" + bcolors.ENDC +\n            \"MsSQL (pyodbc have to be installed):\\n\" +\n            bcolors.OKGREEN + \"\\tmssql+pyodbc://user:passwd@database\\n\" + bcolors.ENDC +\n            \"SQLite (always works):\\n\" +\n            \" - Linux:\\n\" +\n            bcolors.OKGREEN + \"\\tsqlite:////absolute/path/to/database.db\\n\" + bcolors.ENDC +\n            \" - Windows:\\n\" +\n            bcolors.OKGREEN + \"\\tsqlite:///C:\\\\path\\\\to\\\\database.db\\n\" + bcolors.ENDC +\n            \"Oracle:\\n\" +\n            bcolors.OKGREEN + \"\\toracle://user:passwd@127.0.0.1:1521/database\\n\\n\" + bcolors.ENDC +\n            \"[RETURN] for standard connection {}:\\n\".format(defaults.sqlalchemy_connection_string_default)\n        )\n        if not (user_connection or user_connection.strip()):\n            user_connection = defaults.sqlalchemy_connection_string_default\n        set_connection(user_connection.strip())", "response": "Prompts the user to input a connection string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate all tables in the database.", "response": "def create_all(self, checkfirst=True):\n        \"\"\"Creates all tables from models in the database\n        \n        :param bool checkfirst: Check if tables already exists\n        \"\"\"\n        log.info('creating tables in %s', self.engine.url)\n        models.Base.metadata.create_all(self.engine, checkfirst=checkfirst)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndrop all tables in the database", "response": "def drop_all(self):\n        \"\"\"Drops all tables in the database\"\"\"\n        log.info('dropping tables in %s', self.engine.url)\n        self.session.commit()\n        models.Base.metadata.drop_all(self.engine)\n        self.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef db_import(self, urls=None, force_download=False):\n        if not urls:\n            urls = [\n                defaults.url_base + table_conf.tables[model]['file_name']\n                for model in table_conf.tables\n            ]\n\n        log.info('Update CTD database from %s', urls)\n\n        self.drop_all()\n        self.download_urls(urls=urls, force_download=force_download)\n        self.create_all()\n        self.import_tables()\n        self.session.close()", "response": "Updates the CTD database with the CTD files from the CTD database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mapper(self):\n        if not self.__mapper:\n            for model in table_conf.models_to_map:\n                domain = model.table_suffix\n                tab_conf = table_conf.tables[model]\n\n                file_path = os.path.join(self.pyctd_data_dir, tab_conf['file_name'])\n\n                col_name_in_file, col_name_in_db = tab_conf['domain_id_column']\n\n                column_index = self.get_index_of_column(col_name_in_file, file_path)\n\n                df = pd.read_table(\n                    file_path,\n                    names=[col_name_in_db],\n                    header=None,\n                    usecols=[column_index],\n                    comment='#',\n                    index_col=False,\n                    dtype=self.get_dtypes(model)\n                )\n\n                if domain == 'chemical':\n                    df[col_name_in_db] = df[col_name_in_db].str.replace('MESH:', '').str.strip()\n\n                df[domain + '__id'] = df.index + 1\n                self.__mapper[domain] = df\n        return self.__mapper", "response": "returns a dictionary with keys of pyctd. manager. table_con. domains_to_map and pandas. DataFrame as values. \n - domain name of the domain in the table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting all data in database tables", "response": "def import_tables(self, only_tables=None, exclude_tables=None):\n        \"\"\"Imports all data in database tables\n\n        :param set[str] only_tables: names of tables to be imported\n        :param set[str] exclude_tables: names of tables to be excluded\n        \"\"\"\n        for table in self.tables:\n            if only_tables is not None and table.name not in only_tables:\n                continue\n\n            if exclude_tables is not None and table.name in exclude_tables:\n                continue\n            self.import_table(table)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the index of a specific column in a CTD file", "response": "def get_index_of_column(cls, column, file_path):\n        \"\"\"Get index of a specific column name in a CTD file\n        \n        :param column: \n        :param file_path: \n        :return: Optional[int]\n        \"\"\"\n        columns = cls.get_column_names_from_file(file_path)\n        if column in columns:\n            return columns.index(column)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_table(self, table):\n        file_path = os.path.join(self.pyctd_data_dir, table.file_name)\n        log.info('importing %s data into table %s', file_path, table.name)\n        table_import_timer = time.time()\n\n        use_columns_with_index, column_names_in_db = self.get_index_and_columns_order(\n            table.columns_in_file_expected,\n            table.columns_dict,\n            file_path\n        )\n\n        self.import_table_in_db(file_path, use_columns_with_index, column_names_in_db, table)\n\n        for column_in_file, column_in_one2many_table in table.one_to_many:\n            o2m_column_index = self.get_index_of_column(column_in_file, file_path)\n\n            self.import_one_to_many(file_path, o2m_column_index, table, column_in_one2many_table)\n\n        log.info('done importing %s in %.2f seconds', table.name, time.time() - table_import_timer)", "response": "import table by Table object\n yi_table_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting a single to many entry from a file.", "response": "def import_one_to_many(self, file_path, column_index, parent_table, column_in_one2many_table):\n        \"\"\"\n        \n        :param file_path: \n        :param column_index: \n        :param parent_table:\n        :param column_in_one2many_table: \n        \"\"\"\n        chunks = pd.read_table(\n            file_path,\n            usecols=[column_index],\n            header=None,\n            comment='#',\n            index_col=False,\n            chunksize=1000000,\n            dtype=self.get_dtypes(parent_table.model)\n        )\n\n        for chunk in chunks:\n            child_values = []\n            parent_id_values = []\n\n            chunk.dropna(inplace=True)\n            chunk.index += 1\n\n            for parent_id, values in chunk.iterrows():\n                entry = values[column_index]\n                if not isinstance(entry, str):\n                    entry = str(entry)\n                for value in entry.split(\"|\"):\n                    parent_id_values.append(parent_id)\n                    child_values.append(value.strip())\n\n            parent_id_column_name = parent_table.name + '__id'\n            o2m_table_name = defaults.TABLE_PREFIX + parent_table.name + '__' + column_in_one2many_table\n\n            pd.DataFrame({\n                parent_id_column_name: parent_id_values,\n                column_in_one2many_table: child_values\n            }).to_sql(name=o2m_table_name, if_exists='append', con=self.engine, index=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_table_in_db(self, file_path, use_columns_with_index, column_names_in_db, table):\n        chunks = pd.read_table(\n            file_path,\n            usecols=use_columns_with_index,\n            names=column_names_in_db,\n            header=None, comment='#',\n            index_col=False,\n            chunksize=1000000,\n            dtype=self.get_dtypes(table.model)\n        )\n\n        for chunk in chunks:\n            # this is an evil hack because CTD is not using the MESH prefix in this table\n            if table.name == 'exposure_event':\n                chunk.disease_id = 'MESH:' + chunk.disease_id\n\n            chunk['id'] = chunk.index + 1\n\n            if table.model not in table_conf.models_to_map:\n                for model in table_conf.models_to_map:\n                    domain = model.table_suffix\n                    domain_id = domain + \"_id\"\n                    if domain_id in column_names_in_db:\n                        chunk = pd.merge(chunk, self.mapper[domain], on=domain_id, how='left')\n                        del chunk[domain_id]\n\n            chunk.set_index('id', inplace=True)\n\n            table_with_prefix = defaults.TABLE_PREFIX + table.name\n            chunk.to_sql(name=table_with_prefix, if_exists='append', con=self.engine)\n\n        del chunks", "response": "Imports data from CTD file into database"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns column names from CTD download file", "response": "def get_column_names_from_file(file_path):\n        \"\"\"returns column names from CTD download file\n\n        :param str file_path: path to CTD download file\n        \"\"\"\n        if file_path.endswith('.gz'):\n            file_handler = io.TextIOWrapper(io.BufferedReader(gzip.open(file_path)))\n        else:\n            file_handler = open(file_path, 'r')\n\n        fields_line = False\n        with file_handler as file:\n            for line in file:\n                line = line.strip()\n                if not fields_line and re.search('#\\s*Fields\\s*:$', line):\n                    fields_line = True\n                elif fields_line and not (line == '' or line == '#'):\n                    return [column.strip() for column in line[1:].split(\"\\t\")]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading all CTD URLs that don t exist", "response": "def download_urls(cls, urls, force_download=False):\n        \"\"\"Downloads all CTD URLs that don't exist\n    \n        :param iter[str] urls: iterable of URL of CTD\n        :param bool force_download: force method to download\n        \"\"\"\n        for url in urls:\n            file_path = cls.get_path_to_file_from_url(url)\n\n            if os.path.exists(file_path) and not force_download:\n                log.info('already downloaded %s to %s', url, file_path)\n            else:\n                log.info('downloading %s to %s', url, file_path)\n                download_timer = time.time()\n                urlretrieve(url, file_path)\n                log.info('downloaded in %.2f seconds', time.time() - download_timer)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef avatar_url_from_openid(openid, size=64, default='retro', dns=False):\n\n    if dns:\n        # This makes an extra DNS SRV query, which can slow down our webapps.\n        # It is necessary for libravatar federation, though.\n        import libravatar\n        return libravatar.libravatar_url(\n            openid=openid,\n            size=size,\n            default=default,\n        )\n    else:\n        params = _ordered_query_params([('s', size), ('d', default)])\n        query = parse.urlencode(params)\n        hash = sha256(openid.encode('utf-8')).hexdigest()\n        return \"https://seccdn.libravatar.org/avatar/%s?%s\" % (hash, query)", "response": "Return the URL of the avatar of the given openid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef avatar_url_from_email(email, size=64, default='retro', dns=False):\n\n    if dns:\n        # This makes an extra DNS SRV query, which can slow down our webapps.\n        # It is necessary for libravatar federation, though.\n        import libravatar\n        return libravatar.libravatar_url(\n            email=email,\n            size=size,\n            default=default,\n        )\n    else:\n        params = _ordered_query_params([('s', size), ('d', default)])\n        query = parse.urlencode(params)\n        hash = md5(email.encode('utf-8')).hexdigest()\n        return \"https://seccdn.libravatar.org/avatar/%s?%s\" % (hash, query)", "response": "Return the URL of the avatar of the given email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, target, args=()):\n        run_event = threading.Event()\n        run_event.set()\n        thread = threading.Thread(target=target, args=args + (run_event, ))\n        self.thread_pool.append(thread)\n        self.run_events.append(run_event)\n        thread.start()", "response": "Run a function in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops all functions running in the thread handler.", "response": "def stop(self):\n        \"\"\" Stop all functions running in the thread handler.\"\"\"\n        for run_event in self.run_events:\n            run_event.clear()\n\n        for thread in self.thread_pool:\n            thread.join()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self, labels, split_idx):\n        atom_labels = [label[0] for label in labels]\n\n        noise = []\n        distribution_function = distributions[self.distribution_name][\"function\"]\n        for label in atom_labels:\n            params = [self.parameters[\"{}_{}\".format(label, param)][split_idx]\n                      for param in self.distribution_parameter_names]\n\n            if None in params:\n                dim_noise = 0.0\n            else:\n                try:\n                    dim_noise = distribution_function(*params)\n                except ValueError:\n                    raise ValueError\n\n            noise.append(dim_noise)\n\n        return noise", "response": "Generate peak - specific noise abstract method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the cover from the config file.", "response": "def load_cover(self):\n        \"\"\"Load the cover out of the config, options and conventions.\n        Priority goes this way:\n\n        1. if a --cover option is set, use it.\n        2. if there's a \"cover\" key in the config file, use it.\n        3. if a cover.(png|jpg|jpeg|svg) exists in the directory, use it.\n\n        Once the choice is set, the program will check if the file exists\n        before using it. If it doesn't exist, you'll be warned and the default\n        (ugly) cover will be used.\n        \"\"\"\n        if not self.args:\n            return False\n        filename = self.args.get('--cover', None) \\\n            or self.config.get('cover', None) \\\n            or None\n        if not filename:\n            for extension in ('png', 'jpg', 'jpeg', 'svg'):\n                temp_filename = 'cover.%s' % extension\n                if exists(temp_filename):\n                    filename = temp_filename\n                    break\n        if filename:\n            if filename.startswith('http://') or \\\n               filename.startswith('https://'):\n                return filename\n            if not exists(filename):\n                print error('The designated cover (%s) does not exists.'\n                            ' Please check your settings.' % filename)\n                filename = None\n        if not filename:\n            print warning('No cover is set, will use the default (ugly) one.')\n            return False\n        return abspath(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_python(classifiers):\n    prefix = 'Programming Language :: Python ::'\n    python_classifiers = [c.split('::')[2].strip() for c in classifiers if c.startswith(prefix)]\n    return ', '.join([c for c in python_classifiers if parse_version(c)])", "response": "Parse out the versions of python supported a / c classifiers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses out the versions of django supported a. c classifiers.", "response": "def parse_django(classifiers):\n    \"\"\"Parse out the versions of django supported a/c classifiers.\"\"\"\n    prefix = 'Framework :: Django ::'\n    django_classifiers = [c.split('::')[2].strip() for c in classifiers if c.startswith(prefix)]\n    return ', '.join([c for c in django_classifiers if parse_version(c)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string representing the diff between two versions of the current package.", "response": "def version_diff(version1, version2):\n    \"\"\"Return string representing the diff between package versions.\n\n    We're interested in whether this is a major, minor, patch or 'other'\n    update. This method will compare the two versions and return None if\n    they are the same, else it will return a string value indicating the\n    type of diff - 'major', 'minor', 'patch', 'other'.\n\n    Args:\n        version1: the Version object we are interested in (e.g. current)\n        version2: the Version object to compare against (e.g. latest)\n\n    Returns a string - 'major', 'minor', 'patch', 'other', or None if the\n        two are identical.\n\n    \"\"\"\n    if version1 is None or version2 is None:\n        return 'unknown'\n    if version1 == version2:\n        return 'none'\n\n    for v in ('major', 'minor', 'patch'):\n        if getattr(version1, v) != getattr(version2, v):\n            return v\n\n    return 'other'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self):\n        key = cache_key(self.name)\n        data = cache.get(key)\n        if data is None:\n            logger.debug(\"Updating package info for %s from PyPI.\", self.name)\n            data = requests.get(self.url).json()\n            cache.set(key, data, PYPI_CACHE_EXPIRY)\n        return data", "response": "Fetch latest data from PyPI and cache for 30s."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _query_wrap(fun, *args, **kwargs):\n    with _query_lock:\n        global _last_query_time\n        since_last_query = time.time() - _last_query_time\n        if since_last_query < QUERY_WAIT_TIME:\n            time.sleep(QUERY_WAIT_TIME - since_last_query)\n        _last_query_time = time.time()\n        return fun(*args, **kwargs)", "response": "Wrap a function that takes a list of arguments and returns the result of the given function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef formdata_encode(fields):\n    BOUNDARY = '----form-data-boundary-ZmRkNzJkMjUtMjkyMC00'\n    out = []\n    for (key, value) in fields.items():\n        out.append('--' + BOUNDARY)\n        out.append('Content-Disposition: form-data; name=\"%s\"' % key)\n        out.append('')\n        out.append(value)\n    out.append('--' + BOUNDARY + '--')\n    out.append('')\n    body = '\\r\\n'.join(out)\n    content_type = 'multipart/form-data; boundary=%s' % BOUNDARY\n    return content_type, body", "response": "Encode a dict as a multipart / form - data HTTP request containing a multipart - data boundary. Returns a ( content type request body pair."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef formdata_post(url, fields):\n    content_type, data = formdata_encode(fields)\n    req = urllib2.Request(url, data)\n    req.add_header('Content-Type', content_type)\n    return urllib2.urlopen(req).read()", "response": "Send a HTTP request with a multipart / form - data body for the given URL and return the data returned by the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fpid_query(duration, fpdata, metadata=None):\n    metadata = metadata or {}\n    params = {\n        'artist': metadata.get('artist', ''),\n        'album': metadata.get('album', ''),\n        'track': metadata.get('title', ''),\n        'duration': duration,\n    }\n    url = '%s?%s' % (URL_FPID, urllib.urlencode(params))\n    try:\n        res = _query_wrap(formdata_post, url, {'fpdata': fpdata})\n    except urllib2.HTTPError:\n        raise CommunicationError('ID query failed')\n    except httplib.BadStatusLine:\n        raise CommunicationError('bad response in ID query')\n    except IOError:\n        raise CommunicationError('ID query failed')\n    \n    try:\n        fpid, status = res.split()[:2]\n        fpid = int(fpid)\n    except ValueError:\n        raise BadResponseError('malformed response: ' + res)\n\n    if status == 'NEW':\n        raise NotFoundError()\n    elif status == 'FOUND':\n        return fpid\n    else:\n        raise BadResponseError('unknown status: ' + res)", "response": "Send fingerprint data to Last. fm to get the corresponding\n    fingerprint ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nqueries the Last. fm servers for metadata about a given fingerprint ID. Returns the XML response.", "response": "def metadata_query(fpid, apikey):\n    \"\"\"Queries the Last.fm servers for metadata about a given\n    fingerprint ID (an integer). Returns the XML response (a string).\n    \"\"\"\n    params = {\n        'method': 'track.getFingerprintMetadata',\n        'fingerprintid': fpid,\n        'api_key': apikey,\n    }\n    url = '%s?%s' % (URL_METADATA, urllib.urlencode(params))\n    try:\n        fh = _query_wrap(urllib.urlopen, url)\n    except urllib2.HTTPError:\n        raise CommunicationError('metadata query failed')\n    except httplib.BadStatusLine:\n        raise CommunicationError('bad response in metadata query')\n    except IOError:\n        raise CommunicationError('metadata query failed')\n    return fh.read()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a PCM data stream extract fingerprint data from the audio. Returns a byte string of fingerprint data. Raises an ExtractionError if fingerprinting fails.", "response": "def extract(pcmiter, samplerate, channels, duration = -1):\n    \"\"\"Given a PCM data stream, extract fingerprint data from the\n    audio. Returns a byte string of fingerprint data. Raises an\n    ExtractionError if fingerprinting fails.\n    \"\"\"\n    extractor = _fplib.Extractor(samplerate, channels, duration)\n\n    # Get first block.\n    try:\n        next_block = next(pcmiter)\n    except StopIteration:\n        raise ExtractionError()\n\n    # Get and process subsequent blocks.\n    while True:\n        # Shift over blocks.\n        cur_block = next_block\n        try:\n            next_block = next(pcmiter)\n        except StopIteration:\n            next_block = None\n        done = next_block is None\n\n        # Process the block.\n        try:\n            if extractor.process(cur_block, done):\n                # Success!\n                break\n        except RuntimeError as exc:\n            # Exception from fplib. Most likely the file is too short.\n            raise ExtractionError(exc.args[0])\n\n        # End of file but processor never became ready?\n        if done:\n            raise ExtractionError()\n\n    # Get resulting fingerprint data.\n    out = extractor.result()\n    if out is None:\n        raise ExtractionError()\n    \n    # Free extractor memory.\n    extractor.free()\n    \n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a PCM data stream perform fingerprinting and look up the metadata for the audio.", "response": "def match(apikey, pcmiter, samplerate, duration, channels=2, metadata=None):\n    \"\"\"Given a PCM data stream, perform fingerprinting and look up the\n    metadata for the audio. pcmiter must be an iterable of blocks of\n    PCM data (buffers). duration is the total length of the track in\n    seconds (an integer). metadata may be a dictionary containing\n    existing metadata for the file (optional keys: \"artist\", \"album\",\n    and \"title\"). Returns a list of track info dictionaries\n    describing the candidate metadata returned by Last.fm. Raises a\n    subclass of FingerprintError if any step fails.\n    \"\"\"\n    fpdata = extract(pcmiter, samplerate, channels)\n    fpid = fpid_query(duration, fpdata, metadata)\n    return metadata_query(fpid, apikey)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_metadata(xml):\n    try:\n        root = etree.fromstring(xml)\n    except (ExpatError, etree.ParseError):\n        # The Last.fm API occasionally generates malformed XML when its\n        # includes an illegal character (UTF8-legal but prohibited by\n        # the XML standard).\n        raise CommunicationError('malformed XML response')\n    \n    status = root.attrib['status']\n    if status == 'failed':\n        error = root.find('error')\n        raise APIError(int(error.attrib['code']), error.text)\n    \n    out = []\n    for track in root.find('tracks').findall('track'):\n        out.append({\n            'rank': float(track.attrib['rank']),\n            'artist': track.find('artist').find('name').text,\n            'artist_mbid': track.find('artist').find('mbid').text,\n            'title': track.find('name').text,\n            'track_mbid': track.find('mbid').text,\n        })\n    return out", "response": "Given an XML document returned from metadata_query returns a list of track info dicts."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse the audioread library to decode an audio file and match it.", "response": "def match_file(apikey, path, metadata=None):\n    \"\"\"Uses the audioread library to decode an audio file and match it.\n    \"\"\"\n    import audioread\n    with audioread.audio_open(path) as f:\n        return match(apikey, iter(f), f.samplerate, int(f.duration),\n                     f.channels, metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the constant variables.", "response": "def update_constants(nmrstar2cfg=\"\", nmrstar3cfg=\"\", resonance_classes_cfg=\"\", spectrum_descriptions_cfg=\"\"):\n    \"\"\"Update constant variables.\n\n    :return: None\n    :rtype: :py:obj:`None`\n    \"\"\"\n    nmrstar_constants = {}\n    resonance_classes = {}\n    spectrum_descriptions = {}\n\n    this_directory = os.path.dirname(__file__)\n\n    nmrstar2_config_filepath = os.path.join(this_directory, \"conf/constants_nmrstar2.json\")\n    nmrstar3_config_filepath = os.path.join(this_directory, \"conf/constants_nmrstar3.json\")\n    resonance_classes_config_filepath = os.path.join(this_directory, \"conf/resonance_classes.json\")\n    spectrum_descriptions_config_filepath = os.path.join(this_directory, \"conf/spectrum_descriptions.json\")\n\n    with open(nmrstar2_config_filepath, \"r\") as nmrstar2config, open(nmrstar3_config_filepath, \"r\") as nmrstar3config:\n        nmrstar_constants[\"2\"] = json.load(nmrstar2config)\n        nmrstar_constants[\"3\"] = json.load(nmrstar3config)\n\n    with open(resonance_classes_config_filepath, \"r\") as config:\n        resonance_classes.update(json.load(config))\n\n    with open(spectrum_descriptions_config_filepath, \"r\") as config:\n        spectrum_descriptions.update(json.load(config))\n\n    if nmrstar2cfg:\n        with open(nmrstar2cfg, \"r\") as nmrstar2config:\n            nmrstar_constants[\"2\"].update(json.load(nmrstar2config))\n\n    if nmrstar3cfg:\n        with open(nmrstar2cfg, \"r\") as nmrstar3config:\n            nmrstar_constants[\"3\"].update(json.load(nmrstar3config))\n\n    if resonance_classes_cfg:\n        with open(nmrstar2cfg, \"r\") as config:\n            resonance_classes.update(json.load(config))\n\n    if spectrum_descriptions_cfg:\n        with open(spectrum_descriptions_cfg, \"r\") as config:\n            spectrum_descriptions.update(json.load(config))\n\n    NMRSTAR_CONSTANTS.update(nmrstar_constants)\n    RESONANCE_CLASSES.update(resonance_classes)\n    SPECTRUM_DESCRIPTIONS.update(spectrum_descriptions)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_spectrum_descriptions(*args):\n    if args:\n        for spectrum_name in args:\n            pprint.pprint({spectrum_name: SPECTRUM_DESCRIPTIONS.get(spectrum_name, None)}, width=120)\n    else:\n        pprint.pprint(SPECTRUM_DESCRIPTIONS, width=120)", "response": "List all available spectrum descriptions that can be used for peak list simulation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading data into a NMRStarFile or CIFFile instance.", "response": "def read(filehandle, source):\n        \"\"\"Read data into a :class:`~nmrstarlib.nmrstarlib.StarFile` instance.\n\n        :param filehandle: file-like object.\n        :type filehandle: :py:class:`io.TextIOWrapper`, :py:class:`gzip.GzipFile`,\n                          :py:class:`bz2.BZ2File`, :py:class:`zipfile.ZipFile`\n        :param str source: String indicating where file is coming from (path, url).\n        :return: subclass of :class:`~nmrstarlib.nmrstarlib.StarFile`.\n        :rtype: :class:`~nmrstarlib.nmrstarlib.NMRStarFile` or :class:`~nmrstarlib.nmrstarlib.CIFFile`\n        \"\"\"\n        input_str = filehandle.read()\n        nmrstar_str = StarFile._is_nmrstar(input_str)\n        cif_str = StarFile._is_cif(input_str)\n        json_str = StarFile._is_json(input_str)\n\n        if not input_str:\n            pass\n\n        elif nmrstar_str:\n            starfile = NMRStarFile(source)\n            starfile._build_file(nmrstar_str)\n            filehandle.close()\n            return starfile\n\n        elif cif_str:\n            starfile = CIFFile(source)\n            starfile._build_file(cif_str)\n            filehandle.close()\n            return starfile\n\n        elif json_str:\n            if u\"save_\" in json_str:\n                starfile = NMRStarFile(source)\n                starfile.update(json.loads(json_str, object_pairs_hook=OrderedDict))\n                starfile.id = starfile[u\"data\"]\n                filehandle.close()\n                return starfile\n\n            elif u\"entry.id\" in json_str:\n                starfile = CIFFile(source)\n                starfile.update(json.loads(json_str, object_pairs_hook=OrderedDict))\n                starfile.id = starfile[u\"data\"]\n                filehandle.close()\n                return starfile\n            else:\n                raise TypeError(\"Unknown file format\")\n        else:\n            raise TypeError(\"Unknown file format\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, filehandle, file_format):\n        try:\n            if file_format == \"json\":\n                json_str = self._to_json()\n                filehandle.write(json_str)\n            elif file_format == \"nmrstar\" and isinstance(self, NMRStarFile):\n                nmrstar_str = self._to_star()\n                filehandle.write(nmrstar_str)\n            elif file_format == \"cif\" and isinstance(self, CIFFile):\n                cif_str = self._to_star()\n                filehandle.write(cif_str)\n            else:\n                raise TypeError(\"Unknown file format.\")\n        except IOError:\n            raise IOError('\"filehandle\" parameter must be writable.')\n        filehandle.close()", "response": "Writes the data into file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the current NMR - STAR file into a string.", "response": "def _to_star(self):\n        \"\"\"Save :class:`~nmrstarlib.nmrstarlib.StarFile` into NMR-STAR or CIF formatted string.\n\n        :return: NMR-STAR string.\n        :rtype: :py:class:`str`\n        \"\"\"\n        star_str = io.StringIO()\n        self.print_file(star_str)\n        return star_str.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if input string is in NMR - STAR format.", "response": "def _is_nmrstar(string):\n        \"\"\"Test if input string is in NMR-STAR format.\n\n        :param string: Input string.\n        :type string: :py:class:`str` or :py:class:`bytes`\n        :return: Input string if in NMR-STAR format or False otherwise.\n        :rtype: :py:class:`str` or :py:obj:`False`\n        \"\"\"\n        if (string[0:5] == u\"data_\" and u\"save_\" in string) or (string[0:5] == b\"data_\" and b\"save_\" in string):\n            return string\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if input string is in CIF format.", "response": "def _is_cif(string):\n        \"\"\"Test if input string is in CIF format.\n        \n        :param string: Input string.\n        :type string: :py:class:`str` or :py:class:`bytes`\n        :return: Input string if in CIF format or False otherwise.\n        :rtype: :py:class:`str` or :py:obj:`False` \n        \"\"\"\n        if (string[0:5] == u\"data_\" and u\"_entry.id\" in string) or (string[0:5] == b\"data_\" and b\"_entry.id\" in string):\n            return string\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_json(string):\n        try:\n            if isinstance(string, bytes):\n                string = string.decode(\"utf-8\")\n                json.loads(string)\n            elif isinstance(string, str):\n                json.loads(string)\n            else:\n                raise TypeError(\"Expecting <class 'str'> or <class 'bytes'>, but {} was passed\".format(type(string)))\n            return string\n\n        except ValueError:\n            return False", "response": "Test if input string is in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_file(self, nmrstar_str):\n        odict = self\n        comment_count = 0\n        lexer = bmrblex(nmrstar_str)\n        token = next(lexer)\n\n        while token != u\"\":\n            try:\n                if token[0:5] == u\"save_\":\n                    name = token\n                    frame = self._build_saveframe(lexer)\n                    if frame:\n                        odict[name] = frame\n\n                elif token[0:5] == u\"data_\":\n                    self.id = token[5:]\n                    odict[u\"data\"] = self.id\n\n                elif token.lstrip().startswith(u\"#\"):\n                    odict[u\"comment_{}\".format(comment_count)] = token\n                    comment_count += 1\n\n                else:\n                    print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                    print(\"In _build_starfile try block\", file=sys.stderr)\n                    raise InvalidToken(\"{}\".format(token))\n\n            except IndexError:\n                print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                print(\"In _build_starfile except block\", file=sys.stderr)\n                raise\n\n            finally:\n                token = next(lexer)\n        return self", "response": "Build a NMR - STAR file from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_saveframe(self, lexer):\n        odict = OrderedDict()\n        loop_count = 0\n        token = next(lexer)\n\n        while token != u\"save_\":\n            try:\n                if token[0] == u\"_\":\n                    # This strips off the leading underscore of tagnames for readability\n                    odict[token[1:]] = next(lexer)\n\n                    # Skip the saveframe if it's not in the list of wanted categories\n                    if self._frame_categories:\n                        if token == \"_Saveframe_category\" and odict[token[1:]] not in self._frame_categories:\n                            raise SkipSaveFrame()\n\n                elif token == u\"loop_\":\n                    odict[u\"loop_{}\".format(loop_count)] = self._build_loop(lexer)\n                    loop_count += 1\n\n                elif token.lstrip().startswith(u\"#\"):\n                    continue\n\n                else:\n                    print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                    print(\"In _build_saveframe try block\", file=sys.stderr)\n                    raise InvalidToken(\"{}\".format(token))\n\n            except IndexError:\n                print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                print(\"In _build_saveframe except block\", file=sys.stderr)\n                raise\n            except SkipSaveFrame:\n                self._skip_saveframe(lexer)\n                odict = None\n            finally:\n                if odict is None:\n                    token = u\"save_\"\n                else:\n                    token = next(lexer)\n        return odict", "response": "Build a NMR - STAR file saveframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_loop(self, lexer):\n        fields = []\n        values = []\n\n        token = next(lexer)\n        while token[0] == u\"_\":\n            fields.append(token[1:])\n            token = next(lexer)\n\n        while token != u\"stop_\":\n            values.append(token)\n            token = next(lexer)\n\n        assert float(len(values) / len(fields)).is_integer(), \\\n            \"Error in loop construction: number of fields must be equal to number of values.\"\n\n        values = [OrderedDict(zip(fields, values[i:i + len(fields)])) for i in range(0, len(values), len(fields))]\n        return fields, values", "response": "Build the saveframe loop."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _skip_saveframe(self, lexer):\n        token = u\"\"\n        while token != u\"save_\":\n            token = next(lexer)", "response": "Skip entire saveframe - keep emitting tokens until the end of saveframe."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_file(self, f=sys.stdout, file_format=\"nmrstar\", tw=3):\n        if file_format == \"nmrstar\":\n            for saveframe in self.keys():\n                if saveframe == u\"data\":\n                    print(u\"{}_{}\\n\".format(saveframe, self[saveframe]), file=f)\n                elif saveframe.startswith(u\"comment\"):\n                    print(u\"{}\".format(self[saveframe]), file=f)\n                else:\n                    print(u\"{}\".format(saveframe), file=f)\n                    self.print_saveframe(saveframe, f, file_format, tw)\n                    print(u\"\\nsave_\\n\\n\", file=f)\n\n        elif file_format == \"json\":\n            print(self._to_json(), file=f)", "response": "Print the NMRStarFile into a file or stdout."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a saveframe into a file or stdout.", "response": "def print_saveframe(self, sf, f=sys.stdout, file_format=\"nmrstar\", tw=3):\n        \"\"\"Print saveframe into a file or stdout.\n        We need to keep track of how far over everything is tabbed. The \"tab width\"\n        variable tw does this for us.\n\n        :param str sf: Saveframe name.\n        :param io.StringIO f: writable file-like stream.\n        :param str file_format: Format to use: `nmrstar` or `json`.\n        :param int tw: Tab width.\n        :return: None\n        :rtype: :py:obj:`None`\n        \"\"\"\n        if file_format == \"nmrstar\":\n            for sftag in self[sf].keys():\n                # handle loops\n                if sftag[:5] == \"loop_\":\n                    print(u\"\\n{}loop_\".format(tw * u\" \"), file=f)\n                    self.print_loop(sf, sftag, f, file_format, tw * 2)\n                    print(u\"\\n{}stop_\".format(tw * u\" \"), file=f)\n\n                # handle the NMR-Star \"multiline string\"\n                elif self[sf][sftag].endswith(u\"\\n\"):\n                    print(u\"{}_{}\".format(tw * u\" \", sftag), file=f)\n                    print(u\";\\n{};\".format(self[sf][sftag]), file=f)\n\n                elif len(self[sf][sftag].split()) > 1:\n                    # need to escape value with quotes (i.e. u\"'{}'\".format()) if value consists of two or more words\n                    print(u\"{}_{}\\t {}\".format(tw * u\" \", sftag, u\"'{}'\".format(self[sf][sftag])), file=f)\n\n                else:\n                    print(u\"{}_{}\\t {}\".format(tw * u\" \", sftag, self[sf][sftag]), file=f)\n\n        elif file_format == \"json\":\n            print(json.dumps(self[sf], sort_keys=False, indent=4), file=f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_loop(self, sf, sftag, f=sys.stdout, file_format=\"nmrstar\", tw=3):\n        if file_format == \"nmrstar\":\n            # First print the fields\n            for field in self[sf][sftag][0]:\n                print(u\"{}_{}\".format(tw * u\" \", field), file=f)\n\n            print(u\"\", file=f)  # new line between fields and values\n\n            # Then print the values\n            for valuesdict in self[sf][sftag][1]:\n                # need to escape value with quotes (i.e. u\"'{}'\".format()) if value consists of two or more words\n                print(u\"{}{}\".format(tw * u\" \", u\" \".join([u\"'{}'\".format(value) if len(value.split()) > 1 else value for value\n                                                           in valuesdict.values()])), file=f)\n        elif file_format == \"json\":\n            print(json.dumps(self[sf][sftag], sort_keys=False, indent=4), file=f)", "response": "Print the entry in the database for a specific saveframe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef chem_shifts_by_residue(self, amino_acids=None, atoms=None, amino_acids_and_atoms=None, nmrstar_version=\"3\"):\n        if (amino_acids_and_atoms and amino_acids) or (amino_acids_and_atoms and atoms):\n            raise ValueError('\"amino_acids_and_atoms\" parameter cannot be used simultaneously with '\n                             '\"amino_acids\" and \"atoms\" parameters, one or another must be provided.')\n\n        chemshifts_loop = NMRSTAR_CONSTANTS[nmrstar_version][\"chemshifts_loop\"]\n        aminoacid_seq_id = NMRSTAR_CONSTANTS[nmrstar_version][\"aminoacid_seq_id\"]\n        aminoacid_code = NMRSTAR_CONSTANTS[nmrstar_version][\"aminoacid_code\"]\n        atom_code = NMRSTAR_CONSTANTS[nmrstar_version][\"atom_code\"]\n        chemshift_value = NMRSTAR_CONSTANTS[nmrstar_version][\"chemshift_value\"]\n\n        chains = []\n        for saveframe in self:\n            if saveframe == u\"data\" or saveframe.startswith(u\"comment\"):\n                continue\n            else:\n                for ind in self[saveframe].keys():\n                    if ind.startswith(u\"loop_\"):\n                        if list(self[saveframe][ind][0]) == chemshifts_loop:\n                            chem_shifts_dict = OrderedDict()\n                            for entry in self[saveframe][ind][1]:\n                                residue_id = entry[aminoacid_seq_id]\n                                chem_shifts_dict.setdefault(residue_id, OrderedDict())\n                                chem_shifts_dict[residue_id][u\"AA3Code\"] = entry[aminoacid_code]\n                                chem_shifts_dict[residue_id][u\"Seq_ID\"] = residue_id\n                                chem_shifts_dict[residue_id][entry[atom_code]] = entry[chemshift_value]\n                            chains.append(chem_shifts_dict)\n\n        if amino_acids_and_atoms:\n            for chem_shifts_dict in chains:\n                for aa_dict in list(chem_shifts_dict.values()):\n                    if aa_dict[u\"AA3Code\"].upper() not in list(amino_acids_and_atoms.keys()):\n                        chem_shifts_dict.pop(aa_dict[u\"Seq_ID\"])\n                    else:\n                        for resonance in list(aa_dict.keys()):\n                            if resonance in (u\"AA3Code\", u\"Seq_ID\") or resonance.upper() in amino_acids_and_atoms[aa_dict[u\"AA3Code\"]]:\n                                continue\n                            else:\n                                aa_dict.pop(resonance)\n        else:\n            if amino_acids:\n                for chem_shifts_dict in chains:\n                    for aa_dict in list(chem_shifts_dict.values()):\n                        if aa_dict[u\"AA3Code\"].upper() not in amino_acids:\n                            chem_shifts_dict.pop(aa_dict[u\"Seq_ID\"])\n\n            if atoms:\n                for chem_shifts_dict in chains:\n                    for aa_dict in chem_shifts_dict.values():\n                        for resonance in list(aa_dict.keys()):\n                            if resonance in (u\"AA3Code\", u\"Seq_ID\") or resonance.upper() in atoms:\n                                continue\n                            else:\n                                aa_dict.pop(resonance)\n        return chains", "response": "Organize chemical shifts by amino acid residue."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the NMR - STAR - formatted string and return a new object.", "response": "def _build_file(self, cif_str):\n        \"\"\"Build :class:`~nmrstarlib.nmrstarlib.CIFFile` object.\n\n        :param cif_str: NMR-STAR-formatted string.\n        :type cif_str: :py:class:`str` or :py:class:`bytes`\n        :return: instance of :class:`~nmrstarlib.nmrstarlib.CIFFile`.\n        :rtype: :class:`~nmrstarlib.nmrstarlib.CIFFile`\n        \"\"\"\n        odict = self\n        comment_count = 0\n        loop_count = 0\n        lexer = bmrblex(cif_str)\n        token = next(lexer)\n\n        while token != u\"\":\n            try:\n                if token[0:5] == u\"data_\":\n                    self.id = token[5:]\n                    self[u\"data\"] = self.id\n\n                elif token.lstrip().startswith(u\"#\"):\n                    odict[u\"comment_{}\".format(comment_count)] = token\n                    comment_count += 1\n\n                elif token[0] == u\"_\":\n                    # This strips off the leading underscore of tagnames for readability\n                    value = next(lexer)\n                    odict[token[1:]] = value\n\n                elif token == u\"loop_\":\n                    odict[u\"loop_{}\".format(loop_count)] = self._build_loop(lexer)\n                    loop_count += 1\n\n                else:\n                    print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                    print(\"In _build_file try block\", file=sys.stderr)\n                    raise InvalidToken(\"{}\".format(token))\n\n            except IndexError:\n                print(\"Error: Invalid token {}\".format(token), file=sys.stderr)\n                print(\"In _build_file except block\", file=sys.stderr)\n                raise\n\n            finally:\n                token = next(lexer)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_file(self, f=sys.stdout, file_format=\"cif\", tw=0):\n        if file_format == \"cif\":\n            for key in self.keys():\n                if key == u\"data\":\n                    print(u\"{}_{}\".format(key, self[key]), file=f)\n                elif key.startswith(u\"comment\"):\n                    print(u\"{}\".format(self[key].strip()), file=f)\n                elif key.startswith(u\"loop_\"):\n                    print(u\"{}loop_\".format(tw * u\" \"), file=f)\n                    self.print_loop(key, f, file_format, tw)\n                else:\n                    # handle the NMR-Star \"multiline string\"\n                    if self[key].endswith(u\"\\n\"):\n                        print(u\"{}_{}\".format(tw * u\" \", key), file=f)\n                        print(u\";{};\".format(self[key]), file=f)\n\n                    # need to escape value with quotes (i.e. u\"'{}'\".format()) if value consists of two or more words\n                    elif len(self[key].split()) > 1:\n                        print(u\"{}_{}\\t {}\".format(tw * u\" \", key, u\"'{}'\".format(self[key])), file=f)\n\n                    else:\n                        print(u\"{}_{}\\t {}\".format(tw * u\" \", key, self[key]), file=f)\n\n        elif file_format == \"json\":\n            print(self._to_json(), file=f)", "response": "Print the current object into a file or stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending GET request to execute Ndrive API and return the response.", "response": "def GET(self, func, data):\n        \"\"\"Send GET request to execute Ndrive API\n\n        :param func: The function name you want to execute in Ndrive API.\n        :param params: Parameter data for HTTP request.\n\n        :returns: metadata when success or False when failed\n        \"\"\"\n        if func not in ['getRegisterUserInfo']:\n            s, message = self.checkAccount()\n\n            if s is False:\n                return False, message\n\n        url = nurls[func]\n        r = self.session.get(url, params = data)\n        r.encoding = 'utf-8'\n\n        if self.debug:\n            print r.text\n\n        try:\n            try:\n                metadata = json.loads(r.text)\n            except:\n                metadata = json.loads(r.text[r.text.find('{'):-1])\n\n            message = metadata['message']\n            if message == 'success':\n                return True, metadata['resultvalue']\n            else:\n                return False, message\n        except:\n            for e in sys.exc_info():\n                print e\n            sys.exit(1)\n            return False, \"Error %s: Failed to send GET request\" %func"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef POST(self, func, data):\n        s, message = self.checkAccount()\n        if s is False:\n            return False, message\n\n        url = nurls[func]\n        r = self.session.post(url, data = data)\n        r.encoding = 'utf-8'\n\n        if self.debug:\n            print r.text.encode(\"utf-8\")\n\n        try:\n            metadata = json.loads(r.text)\n            message = metadata['message']\n            if message == 'success':\n                try:\n                    return True, metadata['resultvalue']\n                except:\n                    return True, metadata['resultcode']\n            else:\n                return False, \"Error %s: %s\" %(func, message)\n        except:\n            #for e in sys.exc_info():\n            #    print e\n            #sys.exit(1)\n            return False, \"Error %s: Failed to send POST request\" %func", "response": "Send POST request to execute Ndrive API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves information about useridx and svctype", "response": "def getRegisterUserInfo(self, svctype = \"Android NDrive App ver\", auth = 0):\n        \"\"\"Retrieve information about useridx\n\n        :param svctype: Information about the platform you are using right now.\n        :param auth: Authentication type\n\n        :return: ``True`` when success or ``False`` when failed\n        \"\"\"\n        data = {'userid': self.user_id,\n                'svctype': svctype,\n                'auth': auth\n               }\n\n        s, metadata = self.GET('getRegisterUserInfo', data)\n\n        if s is True:\n            self.useridx = metadata['useridx']\n            return True, metadata\n        else:\n            return False, metadata"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupload a file as Ndrive really do.", "response": "def uploadFile(self, file_obj, full_path, overwrite = False):\n        \"\"\"Upload a file as Ndrive really do.\n\n            >>> nd.uploadFile('~/flower.png','/Picture/flower.png',True)\n\n        This function imitates the process when Ndrive uploads a local file to its server. The process follows 7 steps:\n              1. POST /CheckStatus.ndrive\n              2. POST /GetDiskSpace.ndrive\n              3. POST /CheckUpload.ndrive\n              4. PUT /FILE_PATH\n              5. POST /GetList.ndrive\n              6. POST /GetWasteInfo.ndrive\n              7. POST /GetDiskSpace.ndrive\n\n            nd.uploadFile('./flower.png','/Picture/flower.png')\n\n        :param file_obj: A file-like object to check whether possible to upload. You can pass a string as a file_obj or a real file object.\n        :param full_path: The full path to upload the file to, *including the file name*. If the destination directory does not yet exist, it will be created. \n        :param overwrite: Whether to overwrite an existing file at the given path. (Default ``False``.)\n        \"\"\"\n        s = self.checkStatus()\n        s = self.getDiskSpace()\n        s = self.checkUpload(file_obj, full_path, overwrite)\n\n        if s is True:\n            self.put(file_obj, full_path, overwrite)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting disk space information.", "response": "def getDiskSpace(self):\n        \"\"\"Get disk space information.\n\n            >>> disk_info = nd.getDiskSpace()\n\n        :return: ``metadata`` if success or ``error message``\n\n        :metadata:\n              - expandablespace\n              - filemaxsize\n              - largefileminsize\n              - largefileunusedspace\n              - largefileusedspace\n              - paymentspace\n              - totallargespace\n              - totalspace\n              - unusedspace\n              - usedspace\n        \"\"\"\n        data = {'userid': self.user_id,\n                'useridx': self.useridx,\n               }\n        s, metadata = self.POST('getDiskSpace',data)\n\n        if s is True:\n            usedspace = byte_readable(metadata['usedspace'])\n            totalspace = byte_readable(metadata['totalspace'])\n            print \"Capacity: %s / %s\" % (usedspace, totalspace)\n\n            return metadata\n        else:\n            print message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether it is possible to upload a file.", "response": "def checkUpload(self, file_obj, full_path = '/', overwrite = False):\n        \"\"\"Check whether it is possible to upload a file.\n\n            >>> s = nd.checkUpload('~/flower.png','/Picture/flower.png')\n\n        :param file_obj: A file-like object to check whether possible to upload. You can pass a string as a file_obj or a real file object.\n        :param str full_path: The full path to upload the file to, *including the file name*. If the destination directory does not yet exist, it will be created. \n        :param overwrite: Whether to overwrite an existing file at the given path. (Default ``False``.)\n            \n        :return: ``True`` if possible to upload or ``False`` if impossible to upload.\n        \"\"\"\n        try:\n            file_obj = file_obj.name\n        except:\n            file_obj = file_obj # do nothing\n\n        file_size = os.stat(file_obj).st_size\n        now = datetime.datetime.now().isoformat()\n\n        data = {'uploadsize': file_size,\n                'overwrite': 'T' if overwrite else 'F',\n                'getlastmodified': now,\n                'dstresource': full_path,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                }\n\n        s, metadata = self.POST('checkUpload', data)\n\n        if not s:\n            print metadata\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef downloadFile(self, from_path, to_path = ''):\n\n        if to_path == '':\n            file_name = os.path.basename(from_path)\n            to_path = os.path.join(os.getcwd(), file_name)\n\n        url = nurls['download'] + from_path\n\n        data = {'attachment':2,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'NDriveSvcType': \"NHN/ND-WEB Ver\",\n               }\n\n        if '~' in to_path:\n            to_path = expanduser(to_path)\n\n        with open(to_path, 'wb') as handle:\n            request = self.session.get(url, params = data, stream=True)\n\n            for block in request.iter_content(1024):\n                if not block:\n                    break\n                handle.write(block)\n            return handle", "response": "Download a file from NHN."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a file to Ndrive2. naver. com.", "response": "def put(self, file_obj, full_path, overwrite = False):\n        \"\"\"Upload a file.\n\n            >>> nd.put('./flower.png','/Picture/flower.png')\n            >>> nd.put(open('./flower.png','r'),'/Picture/flower.png')\n\n        :param file_obj: A file-like object to check whether possible to upload. You can pass a string as a file_obj or a real file object.\n        :param full_path: The full path to upload the file to, *including the file name*. If the destination directory does not yet exist, it will be created.\n\n        :return: ``True`` when succcess to upload a file or ``False``\n        \"\"\"\n        try:\n            file_obj = open(file_obj, 'r')\n        except:\n            file_obj = file_obj # do nothing\n\n        content = file_obj.read()\n        file_name = os.path.basename(full_path)\n\n        now = datetime.datetime.now().isoformat()\n        url = nurls['put'] + full_path\n\n        if overwrite:\n            overwrite = 'T'\n        else:\n            overwrite = 'F'\n\n        headers = {'userid': self.user_id,\n                   'useridx': self.useridx,\n                   'MODIFYDATE': now,\n                   'Content-Type': magic.from_file(file_obj.name, mime=True),\n                   'charset': 'UTF-8',\n                   'Origin': 'http://ndrive2.naver.com',\n                   'OVERWRITE': overwrite,\n                   'X-Requested-With': 'XMLHttpRequest',\n                   'NDriveSvcType': 'NHN/DRAGDROP Ver',\n        }\n        r = self.session.put(url = url, data = content, headers = headers)\n        r.encoding = 'utf-8'\n\n        message = json.loads(r.text)['message']\n\n        if message != 'success':\n            print \"Error put: \" + message\n            return False\n        else:\n            print \"Success put: \" + file_obj.name\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, full_path):\n        now = datetime.datetime.now().isoformat()\n        url = nurls['delete'] + full_path\n\n        headers = {'userid': self.user_id,\n                   'useridx': self.useridx,\n                   'Content-Type': \"application/x-www-form-urlencoded; charset=UTF-8\",\n                   'charset': 'UTF-8',\n                   'Origin': 'http://ndrive2.naver.com',\n        }\n        try:\n            r = self.session.delete(url = url, headers = headers)\n            r.encoding = 'utf-8'\n        except:\n            print \"Error delete: wrong full_path\"\n            return False\n\n        message = json.loads(r.text)['message']\n\n        if message != 'success':\n            print \"Error delete: \" + message\n            return False\n        else:\n            return True", "response": "Delete a file in full_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getList(self, full_path, type = 1, dept = 0, sort = 'name', order = 'asc', startnum = 0, pagingrow = 1000, dummy = 56184):\n        if type not in range(1, 6):\n            print \"Error getList: `type` should be between 1 to 5\"\n            return False\n        data = {'orgresource': full_path,\n                'type': type,\n                'dept': dept,\n                'sort': sort,\n                'order': order,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n               }\n\n        s, metadata = self.POST('getList', data)\n\n        if s is True:\n            return metadata\n        else:\n            print metadata\n            return False", "response": "Get a list of files in a folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doMove(self, from_path, to_path, overwrite = False, bShareFireCopy = 'false', dummy = 56147):\n        if overwrite:\n            overwrite = 'F'\n        else:\n            overwrite = 'T'\n\n        data = {'orgresource': from_path,\n                'dstresource': to_path,\n                'overwrite': overwrite,\n                'bShareFireCopy': bShareFireCopy,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n\n        s, metadata = self.POST('doMove', data)\n\n        return s", "response": "Move a file or folder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a directory of the user", "response": "def makeDirectory(self, full_path, dummy = 40841):\n        \"\"\"Make a directory\n\n            >>> nd.makeDirectory('/test')\n        \n        :param full_path: The full path to get the directory property. Should be end with '/'.\n\n        :return: ``True`` when success to make a directory or ``False``\n        \"\"\"\n        if full_path[-1] is not '/':\n            full_path += '/'\n\n        data = {'dstresource': full_path,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n\n        s, metadata = self.POST('makeDirectory', data)\n\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef makeShareUrl(self, full_path, passwd):\n        if full_path[-1] is not '/':\n            full_path += '/'\n\n        data = {'_callback': 'window.__jindo_callback._347',\n                'path': full_path,\n                'passwd': passwd,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                }\n\n        s, metadata = self.GET('shareUrl', data)\n\n        if s:\n            print \"URL: %s\" % (metadata['href'])\n            return metadata['href']\n        else:\n            print \"Error makeShareUrl: %s\" % (metadata)\n            return False", "response": "This function makes a share url of a directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getFileLink(self, full_path):\n        prop = self.getProperty(full_path)\n\n        if not prop:\n            print \"Error getFileLink: wrong full_path\"\n            return False\n        else:\n            prop_url = prop['filelinkurl']\n            if prop_url:\n                print \"URL: \" + prop_url\n                return prop_url\n            else:\n                resourceno = prop[\"resourceno\"]\n                url = self.createFileLink(resourceno)\n\n                if url:\n                    return url\n                else:\n                    return False", "response": "Get a link of file or directory of file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a link of file MimeType", "response": "def createFileLink(self, resourceno):\n        \"\"\"Make a link of file\n\n        If you don't know ``resourceno``, you'd better use ``getFileLink``.\n\n        :param resourceno: Resource number of a file to create link\n\n        :return: ``Shared url`` or ``False`` when failed to share a file\n        \"\"\"\n        data = {'_callback': 'window.__jindo_callback._8920',\n                'resourceno': resourceno,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                }\n\n        s, metadata = self.GET('createFileLink', data)\n\n        if s:\n            print \"URL: %s\" % (metadata['short_url'])\n            return metadata['short_url']\n        else:\n            print \"Error createFileLink: %s\" % (metadata)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a file property.", "response": "def getProperty(self, full_path, dummy = 56184):\n        \"\"\"Get a file property\n\n        :param full_path: The full path to get the file or directory property.\n\n        :return: ``metadata`` if success or ``False`` if failed to get property\n\n        :metadata:\n              - creationdate\n              - exif\n              - filelink\n              - filelinkurl\n              - filetype => 1: document, 2: image, 3: video, 4: music, 5: zip\n              - fileuploadstatus\n              - getcontentlength\n              - getlastmodified\n              - href\n              - lastaccessed\n              - protect\n              - resourceno\n              - resourcetype\n              - thumbnail\n              - totalfilecnt\n              - totalfoldercnt\n              - virusstatus\n        \"\"\"\n        data = {'orgresource': full_path,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n\n        s, metadata = self.POST('getProperty', data)\n\n        if s is True:\n            return metadata\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a version list of a file or directory.", "response": "def getVersionList(self, full_path, startnum = 0, pagingrow = 50, dummy = 54213):\n        \"\"\"Get a version list of a file or dierectory.\n\n        :param full_path: The full path to get the file or directory property. Path should start with '/'\n        :param startnum: Start version index.\n        :param pagingrow: Max # of version list in one page.\n\n        :returns: ``metadata`` if succcess or ``False`` (failed to get history or there is no history)\n\n        :metadata:\n              - createuser\n              - filesize\n              - getlastmodified\n              - href\n              - versioninfo\n              - versionkey\n        \"\"\"\n        data = {'orgresource': full_path,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n\n        s, metadata = self.POST('getVersionList', data)\n\n        if s is True:\n            return metadata\n        else:\n            print \"Error getVersionList: Cannot get version list\"\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the property of a file or directory.", "response": "def setProperty(self, full_path, protect, dummy = 7046):\n        \"\"\"Set property of a file.\n\n        :param full_path: The full path to get the file or directory property.\n        :param protect: 'Y' or 'N', \uc911\uc694 \ud45c\uc2dc\n\n        :return: ``True`` when success to set property or ``False``\n        \"\"\"\n        data = {'orgresource': full_path,\n                'protect': protect,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n        s, metadata = self.POST('setProperty', data)\n\n        if s is True:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getMusicAlbumList(self, tagtype = 0, startnum = 0, pagingrow = 100, dummy = 51467):\n        data = {'tagtype': tagtype,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n        s, metadata = self.POST('getMusicAlbumList', data)\n\n        if s is True:\n            return metadata\n        else:\n            return False", "response": "Get music album list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for music albums.", "response": "def doSearch(self, filename, filetype = None, type = 3, full_path = '/', sharedowner = 'A', datatype = 'all', sort = 'update', order = 'desc', searchtype = 'filesearch', startnum = 0, pagingrow = 100, includeworks = 'N', bodysearch = 'N', dummy = 36644):\n        \"\"\"Get music album list.\n\n        There are 4 kinds in ``type``:\n            - 1 : only directories with idxfolder property\n            - 2 : only files\n            - 3 : directories and files with thumbnail info (like viewHeight, viewWidth for Image file)\n            - 4 : only directories except idxfolder\n            - 5 : directories and files without thumbnail info\n\n        Tyere are 5 kindes of ``filetype``:\n            ex) None: all, 1: document, 2:image, 3: video, 4: msuic, 5: zip\n\n        :param filename: Query to search.\n        :param filetype: Type of a file to search.\n        :param full_path: Directory path to search recursively.\n        :param sharedowner: File priority to search. (P: priority files only, A: all files.)\n        :param datatype: Data type of a file to search\n        :param sort: Order criteria of search result. ('update', 'date' ...)\n        :param order: Order of files. ('desc' or 'inc')\n        :param searchtype: ???\n        :param includeworks: Whether to include Naver Work files to result.\n        :param bodysearch: Search content of file.\n\n        :returns: ``metadata`` or ``False``\n\n        :metadata:\n            - authtoken\n            - content\n            - copyright\n            - creationdate\n            - domaintype\n            - filelink\n            - fileuploadstatus\n            - getcontentlength\n            - getlastmodified\n            - hilightfilename\n            - href\n            - lastaccessed\n            - owner\n            - ownerid\n            - owneridc\n            - owneridx\n            - ownership\n            - protect\n            - resourceno\n            - resourcetype\n            - root\n            - root_shareno\n            - s_type\n            - sharedfoldername\n            - sharedinfo\n            - shareno\n            - subpath\n            - thumbnailpath\n            - virusstatus\n        \"\"\"\n        data = {'filename': filename,\n                'filetype': filetype,\n                'dstresource': full_path,\n                'sharedowner': sharedowner,\n                'datatype': datatype,\n                'sort': sort,\n                'order': order,\n                'searchtype': searchtype,\n                'startnum': startnum,\n                'pagingrow': pagingrow,\n                'includeworks': includeworks,\n                'bodysearch': bodysearch,\n                'userid': self.user_id,\n                'useridx': self.useridx,\n                'dummy': dummy,\n                }\n        s, metadata = self.POST('doSearch', data)\n\n        if s is True:\n            if metadata:\n                print \"Success doSearch: no result found\"\n                return {}\n            return metadata\n        else:\n            print \"Failed doSearch: search failed\"\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _choose_read_fs(authority, cache, read_path, version_check, hasher):\n    '''\n    Context manager returning the appropriate up-to-date readable filesystem\n\n    Use ``cache`` if it is a valid filessystem and has a file at\n    ``read_path``, otherwise use ``authority``. If the file at\n    ``read_path`` is out of date, update the file in ``cache`` before\n    returning it.\n    '''\n\n    if cache and cache.fs.isfile(read_path):\n        if version_check(hasher(cache.fs.open(read_path, 'rb'))):\n            yield cache.fs\n\n        elif authority.fs.isfile(read_path):\n            fs.utils.copyfile(\n                authority.fs,\n                read_path,\n                cache.fs,\n                read_path)\n            yield cache.fs\n\n        else:\n            _makedirs(authority.fs, fs.path.dirname(read_path))\n            _makedirs(cache.fs, fs.path.dirname(read_path))\n            yield cache.fs\n\n    else:\n        if not authority.fs.isfile(read_path):\n            _makedirs(authority.fs, fs.path.dirname(read_path))\n\n        yield authority.fs", "response": "Context manager returning the appropriate up - to - date readable filesystem at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _prepare_write_fs(read_fs, cache, read_path, readwrite_mode=True):\n    '''\n    Prepare a temporary filesystem for writing to read_path\n\n    The file will be moved to write_path on close if modified.\n    '''\n\n    with _get_write_fs() as write_fs:\n\n        # If opening in read/write or append mode, make sure file data is\n        # accessible\n        if readwrite_mode:\n\n            if not write_fs.isfile(read_path):\n                _touch(write_fs, read_path)\n\n                if read_fs.isfile(read_path):\n                    fs.utils.copyfile(\n                        read_fs, read_path, write_fs, read_path)\n\n        else:\n            _touch(write_fs, read_path)\n\n        yield write_fs", "response": "Prepare a temporary filesystem for writing to read_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_local_path(\n        authority,\n        cache,\n        update,\n        version_check,\n        hasher,\n        read_path,\n        write_path=None,\n        cache_on_write=False):\n    '''\n    Context manager for retrieving a system path for I/O and updating on change\n\n\n    Parameters\n    ----------\n    authority : object\n\n        :py:mod:`pyFilesystem` filesystem object to use as the authoritative,\n        up-to-date source for the archive\n\n    cache : object\n\n        :py:mod:`pyFilesystem` filesystem object to use as the cache. Default\n        ``None``.\n\n    use_cache : bool\n\n         update, service_path, version_check, \\*\\*kwargs\n    '''\n\n    if write_path is None:\n        write_path = read_path\n\n    with _choose_read_fs(\n            authority, cache, read_path, version_check, hasher) as read_fs:\n\n        with _prepare_write_fs(\n                read_fs, cache, read_path, readwrite_mode=True) as write_fs:\n\n            yield write_fs.getsyspath(read_path)\n\n            if write_fs.isfile(read_path):\n\n                info = write_fs.getinfokeys(read_path, 'size')\n                if 'size' in info:\n                    if info['size'] == 0:\n                        return\n\n                with write_fs.open(read_path, 'rb') as f:\n                    checksum = hasher(f)\n\n                if not version_check(checksum):\n\n                    if (\n                        cache_on_write or\n                        (\n                            cache\n                            and (\n                                fs.path.abspath(read_path) ==\n                                fs.path.abspath(write_path))\n                            and cache.fs.isfile(read_path)\n                        )\n                    ):\n\n                        _makedirs(cache.fs, fs.path.dirname(write_path))\n                        fs.utils.copyfile(\n                            write_fs, read_path, cache.fs, write_path)\n\n                        _makedirs(authority.fs, fs.path.dirname(write_path))\n                        fs.utils.copyfile(\n                            cache.fs, write_path, authority.fs, write_path)\n                    else:\n                        _makedirs(authority.fs, fs.path.dirname(write_path))\n                        fs.utils.copyfile(\n                            write_fs, read_path, authority.fs, write_path)\n                    update(**checksum)\n\n            else:\n                raise OSError(\n                    'Local file removed during execution. '\n                    'Archive not updated.')", "response": "Context manager for retrieving a system path for I / O and updating on change."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_view(robot):\n    assert isinstance(robot, BaseRoBot),\\\n        \"RoBot should be an BaseRoBot instance.\"\n\n    @csrf_exempt\n    def werobot_view(request):\n        timestamp = request.GET.get(\"timestamp\", \"\")\n        nonce = request.GET.get(\"nonce\", \"\")\n        signature = request.GET.get(\"signature\", \"\")\n        if not robot.check_signature(\n            timestamp=timestamp,\n            nonce=nonce,\n            signature=signature\n        ):\n            return HttpResponseForbidden()\n        if request.method == \"GET\":\n            return HttpResponse(request.GET.get(\"echostr\", \"\"))\n        elif request.method == \"POST\":\n            body = request.body\n            message = parse_user_msg(body)\n            reply = robot.get_reply(message)\n            return HttpResponse(\n                create_reply(reply, message=message),\n                content_type=\"application/xml;charset=utf-8\"\n            )\n        return HttpResponseNotAllowed(['GET', 'POST'])\n\n    return werobot_view", "response": "Returns a Django view that can be used to view a single object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rst_to_json(text):\n    records = []\n    last_type = None\n    key = None\n    data = {}\n    directive = False\n\n    lines = text.splitlines()\n    for index, line in enumerate(lines):\n\n        # check for directives\n        if len(line) and line.strip().startswith(\"..\"):\n            directive = True\n            continue\n\n        # set the title\n        if len(line) and (line[0] in string.ascii_letters or line[0].isdigit()):\n            directive = False\n            try:\n                if lines[index + 1][0] not in DIVIDERS:\n                    continue\n            except IndexError:\n                continue\n            data = text_cleanup(data, key, last_type)\n            data = {\"title\": line.strip()}\n            records.append(\n                data\n            )\n            continue\n\n        # Grab standard fields (int, string, float)\n        if len(line) and line[0].startswith(\":\"):\n            data = text_cleanup(data, key, last_type)\n            index = line.index(\":\", 1)\n            key = line[1:index]\n            value = line[index + 1:].strip()\n            data[key], last_type = type_converter(value)\n            directive = False\n            continue\n\n        # Work on multi-line strings\n        if len(line) and line[0].startswith(\" \") and directive == False:\n            if not isinstance(data[key], str):\n                # Not a string so continue on\n                continue\n            value = line.strip()\n            if not len(value):\n                # empty string, continue on\n                continue\n            # add next line\n            data[key] += \"\\n{}\".format(value)\n            continue\n\n        if last_type == STRING_TYPE and not len(line):\n            if key in data.keys():\n                data[key] += \"\\n\"\n\n    return json.dumps(records)", "response": "I convert Restructured Text with field lists into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps msgpack. packb with use_bin_type = True by default", "response": "def packb(obj, **kwargs):\n    \"\"\"wrap msgpack.packb, setting use_bin_type=True by default\"\"\"\n    kwargs.setdefault('use_bin_type', True)\n    return msgpack.packb(obj, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef play(cls, file_path, on_done=None, logger=None):\n        pygame.mixer.init()\n        try:\n            pygame.mixer.music.load(file_path)\n        except pygame.error as e:\n            if logger is not None:\n                logger.warning(str(e))\n            return\n\n        pygame.mixer.music.play()\n        while pygame.mixer.music.get_busy():\n            time.sleep(0.1)\n            continue\n        if on_done:\n            on_done()", "response": "Play an audio file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplay an audio file asynchronously.", "response": "def play_async(cls, file_path, on_done=None):\n        \"\"\" Play an audio file asynchronously.\n\n        :param file_path: the path to the file to play.\n        :param on_done: callback when audio playback completes.\n        \"\"\"\n        thread = threading.Thread(\n            target=AudioPlayer.play, args=(file_path, on_done,))\n        thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract(self, disp):\n        res = copy.deepcopy(self)\n        for i in range(self.ndims):\n            d = disp[i]\n            s = self.domain[i]\n            if d > 0:\n                res.domain[i] = slice(s.start, d)\n            elif d < 0:\n                res.domain[i] = slice(d, s.stop)\n        return res", "response": "Extract the part of the domain that is exposed by the shift\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef home(self):\n        self.row = 0\n        self.column = 0\n\n        self.command(Command.RETURN_HOME)\n        msleep(2)", "response": "Return to initial position"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn the display on or off", "response": "def visible(self, status):\n        \"\"\"Turn the display on/off (quickly)\"\"\"\n        self._display_control = ByteUtil.apply_flag(self._display_control, Command.DISPLAY_ON, status)\n        self.command(self._display_control)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns underline cursor visibility on / off", "response": "def cursor(self, status):\n        \"\"\"Turn underline cursor visibility on/off\"\"\"\n        self._display_control = ByteUtil.apply_flag(self._display_control, Command.CURSOR_ON, status)\n        self.command(self._display_control)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nturns blink cursor visibility on / off", "response": "def blink(self, status):\n        \"\"\"Turn blink cursor visibility on/off\"\"\"\n        self._display_control = ByteUtil.apply_flag(self._display_control, Command.BLINKING_ON, status)\n        self.command(self._display_control)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef right_to_left(self):\n        self._entry_mode &= ~Command.MODE_INCREMENT\n        self.command(self._entry_mode)", "response": "This is for text that flows Right to Left"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_available_name(self, name, max_length=None):\n        tempdir = tempfile.mkdtemp(dir=self.base_location)\n        name = os.path.join(\n            os.path.basename(tempdir),\n            os.path.basename(name),\n        )\n        method = super(TempFileSystemStorage, self).get_available_name\n        return method(name, max_length=max_length)", "response": "Return relative path to name placed in random directory"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a list of dictionaries and prints a menu.", "response": "def menu(items, heading):\n    '''Takes list of dictionaries and prints a menu.\n        items parameter should be in the form of a list, containing\n        dictionaries with the keys: {\"key\", \"text\", \"function\"}.\n\n        Typing the key for a menuitem, followed by return, will run\n        \"function\".\n    '''\n\n    heading = \"\\n\"*5 + heading      # A little vertical padding\n\n    while True:\n        keydict = {}\n\n        clear_screen()\n        print(heading)\n\n        for item in items:\n            menustring = \"  \" + item[\"key\"] + \" \" + item[\"text\"]\n            keydict[item[\"key\"]] = item[\"function\"]\n            print(menustring)\n\n        key = input(\"\\nType key and Return (q to quit): \").strip()\n\n        if key.lower() == \"q\":\n            return\n        else:\n            try:\n                ret = keydict[key]()\n                if ret:    # If child returns non-false, exit menu.\n                    return 1\n            except KeyError: # Handle garbage input.\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a text prompt and presents it and returns True or False. Repeats itself on bad input.", "response": "def yn_prompt(text):\n    '''\n        Takes the text prompt, and presents it, takes only \"y\" or \"n\" for\n        answers, and returns True or False. Repeats itself on bad input.\n    '''\n\n    text = \"\\n\"+ text + \"\\n('y' or 'n'): \"\n\n\n    while True:\n        answer = input(text).strip()\n        if answer != 'y' and answer != 'n':\n            continue\n        elif answer == 'y':\n            return True\n        elif answer == 'n':\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef underline(text):\n    '''Takes a string, and returns it underscored.'''\n\n    text += \"\\n\"\n    for i in range(len(text)-1):\n        text += \"=\"\n    text += \"\\n\"\n    return text", "response": "Takes a string and returns it underscored."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the event time as UTC.", "response": "def get_event_time_as_utc(voevent, index=0):\n    \"\"\"\n    Extracts the event time from a given `WhereWhen.ObsDataLocation`.\n\n    Returns a datetime (timezone-aware, UTC).\n\n    Accesses a `WhereWhere.ObsDataLocation.ObservationLocation`\n    element and returns the AstroCoords.Time.TimeInstant.ISOTime element,\n    converted to a (UTC-timezoned) datetime.\n\n    Note that a packet may include multiple 'ObsDataLocation' entries\n    under the 'WhereWhen' section, for example giving locations of an object\n    moving over time. Most packets will have only one, however, so the\n    default is to access the first.\n\n    This function now implements conversion from the\n    TDB (Barycentric Dynamical Time) time scale in ISOTime format,\n    since this is the format used by GAIA VOEvents.\n    (See also http://docs.astropy.org/en/stable/time/#time-scale )\n\n    Other timescales (i.e. TT, GPS) will presumably be formatted as a\n    TimeOffset, parsing this format is not yet implemented.\n\n    Args:\n        voevent (:class:`voeventparse.voevent.Voevent`): Root node of the VOevent\n            etree.\n        index (int): Index of the ObsDataLocation to extract an ISOtime from.\n\n    Returns:\n        :class:`datetime.datetime`: Datetime representing the event-timestamp,\n        converted to UTC (timezone aware).\n\n    \"\"\"\n    try:\n        od = voevent.WhereWhen.ObsDataLocation[index]\n        ol = od.ObservationLocation\n        coord_sys = ol.AstroCoords.attrib['coord_system_id']\n        timesys_identifier = coord_sys.split('-')[0]\n\n        if timesys_identifier == 'UTC':\n            isotime_str = str(ol.AstroCoords.Time.TimeInstant.ISOTime)\n            return iso8601.parse_date(isotime_str)\n        elif (timesys_identifier == 'TDB'):\n            isotime_str = str(ol.AstroCoords.Time.TimeInstant.ISOTime)\n            isotime_dtime = iso8601.parse_date(isotime_str)\n            tdb_time = astropy.time.Time(isotime_dtime, scale='tdb')\n            return tdb_time.utc.to_datetime().replace(tzinfo=pytz.UTC)\n        elif (timesys_identifier == 'TT' or timesys_identifier == 'GPS'):\n            raise NotImplementedError(\n                \"Conversion from time-system '{}' to UTC not yet implemented\"\n            )\n        else:\n            raise ValueError(\n                'Unrecognised time-system: {} (badly formatted VOEvent?)'.format(\n                    timesys_identifier\n                )\n            )\n\n    except AttributeError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the AstroCoords from a given VOEvent etree.", "response": "def get_event_position(voevent, index=0):\n    \"\"\"Extracts the `AstroCoords` from a given `WhereWhen.ObsDataLocation`.\n\n    Note that a packet may include multiple 'ObsDataLocation' entries\n    under the 'WhereWhen' section, for example giving locations of an object\n    moving over time. Most packets will have only one, however, so the\n    default is to just return co-ords extracted from the first.\n\n    Args:\n        voevent (:class:`voeventparse.voevent.Voevent`): Root node of the\n            VOEvent etree.\n        index (int): Index of the ObsDataLocation to extract AstroCoords from.\n\n    Returns:\n        Position (:py:class:`.Position2D`): The sky position defined in the\n        ObsDataLocation.\n    \"\"\"\n    od = voevent.WhereWhen.ObsDataLocation[index]\n    ac = od.ObservationLocation.AstroCoords\n    ac_sys = voevent.WhereWhen.ObsDataLocation.ObservationLocation.AstroCoordSystem\n    sys = ac_sys.attrib['id']\n\n    if hasattr(ac.Position2D, \"Name1\"):\n        assert ac.Position2D.Name1 == 'RA' and ac.Position2D.Name2 == 'Dec'\n    posn = Position2D(ra=float(ac.Position2D.Value2.C1),\n                      dec=float(ac.Position2D.Value2.C2),\n                      err=float(ac.Position2D.Error2Radius),\n                      units=ac.Position2D.attrib['unit'],\n                      system=sys)\n    return posn"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a nested dict - like structure that represents the grouped Params of a voevent.", "response": "def get_grouped_params(voevent):\n    \"\"\"\n    Fetch grouped Params from the `What` section of a voevent as an omdict.\n\n    This fetches 'grouped' Params, i.e. those enclosed in a Group element,\n    and returns them as a nested dict-like structure, keyed by\n    GroupName->ParamName->AttribName.\n\n    Note that since multiple Params may share the same ParamName, the returned\n    data-structure is actually an\n    `orderedmultidict.omdict <https://github.com/gruns/orderedmultidict>`_\n    and has extra methods such as 'getlist' to allow retrieval of all values.\n\n    Args:\n        voevent (:class:`voeventparse.voevent.Voevent`): Root node of the VOevent etree.\n    Returns (orderedmultidict.omdict):\n        Mapping of ``ParamName->Attribs``.\n        Typical access like so::\n\n            foo_val = top_params['foo']['value']\n            # If there are multiple Param entries named 'foo':\n            all_foo_vals = [atts['value'] for atts in top_params.getlist('foo')]\n\n    \"\"\"\n    groups_omd = OMDict()\n    w = deepcopy(voevent.What)\n    lxml.objectify.deannotate(w)\n    if w.find('Group') is not None:\n        for grp in w.Group:\n            groups_omd.add(grp.attrib.get('name'),\n                           _get_param_children_as_omdict(grp))\n    return groups_omd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a nested dict - like structure with the toplevel Params as keys and the values of all the Parameters in the voevent.", "response": "def get_toplevel_params(voevent):\n    \"\"\"\n    Fetch ungrouped Params from the `What` section of a voevent as an omdict.\n\n    This fetches 'toplevel' Params, i.e. those not enclosed in a Group element,\n    and returns them as a nested dict-like structure, keyed like\n    ParamName->AttribName.\n\n    Note that since multiple Params may share the same ParamName, the returned\n    data-structure is actually an\n    `orderedmultidict.omdict <https://github.com/gruns/orderedmultidict>`_\n    and has extra methods such as 'getlist' to allow retrieval of all values.\n\n    Any Params with no defined name (technically off-spec, but not invalidated\n    by the XML schema) are returned under the dict-key ``None``.\n\n    Args:\n        voevent (:class:`voeventparse.voevent.Voevent`): Root node of the VOevent etree.\n    Returns (orderedmultidict.omdict):\n        Mapping of ``ParamName->Attribs``.\n        Typical access like so::\n\n            foo_val = top_params['foo']['value']\n            # If there are multiple Param entries named 'foo':\n            all_foo_vals = [atts['value'] for atts in top_params.getlist('foo')]\n\n    \"\"\"\n    result = OrderedDict()\n    w = deepcopy(voevent.What)\n    lxml.objectify.deannotate(w)\n    return _get_param_children_as_omdict(w)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull_astro_coords(voevent, index=0):\n    import warnings\n    warnings.warn(\n        \"\"\"\n        The function `pull_astro_coords` has been renamed to\n        `get_event_position`. This alias is preserved for backwards\n        compatibility, and may be removed in a future release.\n        \"\"\",\n        FutureWarning)\n    return get_event_position(voevent, index)", "response": "Get the astro coordinates of a given event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pull_isotime(voevent, index=0):\n    import warnings\n    warnings.warn(\n        \"\"\"\n        The function `pull_isotime` has been renamed to\n        `get_event_time_as_utc`. This alias is preserved for backwards\n        compatibility, and may be removed in a future release.\n        \"\"\",\n        FutureWarning)\n    return get_event_time_as_utc(voevent, index)", "response": "Get the isotime of the given event from the base calendar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pull_params(voevent):\n    import warnings\n    warnings.warn(\n        \"\"\"\n        The function `pull_params` has been deprecated in favour of the split\n        functions `get_toplevel_params` and `get_grouped_params`, due to \n        possible name-shadowing issues when combining multilevel-nested-dicts\n        (see docs for details).\n        \n        This alias is preserved for backwards compatibility, and may be \n        removed in a future release.\n        \"\"\",\n        FutureWarning)\n    result = OrderedDict()\n    w = deepcopy(voevent.What)\n    lxml.objectify.deannotate(w)\n    if w.countchildren() == 0:\n        return result\n    toplevel_params = OrderedDict()\n    result[None] = toplevel_params\n    if w.find('Param') is not None:\n        for p in w.Param:\n            toplevel_params[p.attrib.get('name')] = p.attrib\n    if w.find('Group') is not None:\n        for g in w.Group:\n            g_params = {}\n            result[g.attrib.get('name')] = g_params\n            if hasattr(g, 'Param'):\n                for p in g.Param:\n                    g_params[p.attrib.get('name')] = p.attrib\n    return result", "response": "Returns a nested dictionary of all parameters in the voevent."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints an element tree with nice indentation.", "response": "def prettystr(subtree):\n    \"\"\"Print an element tree with nice indentation.\n\n    Prettyprinting a whole VOEvent often doesn't seem to work, probably for\n    issues relating to whitespace cf.\n    http://lxml.de/FAQ.html#why-doesn-t-the-pretty-print-option-reformat-my-xml-output\n    This function is a quick workaround for prettyprinting a subsection\n    of a VOEvent, for easier desk-checking.\n\n    Args:\n        subtree(:class`lxml.etree.ElementTree`): A node in the VOEvent element tree.\n    Returns:\n        str: Prettyprinted string representation of the raw XML.\n    \"\"\"\n    subtree = deepcopy(subtree)\n    lxml.objectify.deannotate(subtree)\n    lxml.etree.cleanup_namespaces(subtree)\n    return lxml.etree.tostring(subtree, pretty_print=True).decode(\n        encoding=\"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a request to the API.", "response": "async def request(self, method, path, json=None):\n        \"\"\"Make a request to the API.\"\"\"\n        url = 'https://{}:{}/api/'.format(self.host, self.port)\n        url += path.format(site=self.site)\n\n        try:\n            async with self.session.request(method, url, json=json) as res:\n                if res.content_type != 'application/json':\n                    raise ResponseError(\n                        'Invalid content type: {}'.format(res.content_type))\n                response = await res.json()\n                _raise_on_error(response)\n                return response['data']\n\n        except client_exceptions.ClientError as err:\n            raise RequestError(\n                'Error requesting data from {}: {}'.format(self.host, err)\n            ) from None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        self.thread_handler.run(target=self.start_blocking)\n        self.thread_handler.start_run_loop()", "response": "Start the MQTT client."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_blocking(self, run_event):\n        topics = [(\"hermes/intent/#\", 0), (\"hermes/hotword/#\", 0), (\"hermes/asr/#\", 0), (\"hermes/nlu/#\", 0),\n                  (\"snipsmanager/#\", 0)]\n\n        self.log_info(\"Connecting to {} on port {}\".format(self.mqtt_hostname, str(self.mqtt_port)))\n\n        retry = 0\n        while True and run_event.is_set():\n            try:\n                self.log_info(\"Trying to connect to {}\".format(self.mqtt_hostname))\n                self.client.connect(self.mqtt_hostname, self.mqtt_port, 60)\n                break\n            except (socket_error, Exception) as e:\n                self.log_info(\"MQTT error {}\".format(e))\n                time.sleep(5 + int(retry / 5))\n                retry = retry + 1\n\n        topics = [\n            (MQTT_TOPIC_INTENT + '#', 0),\n            (MQTT_TOPIC_HOTWORD + '#', 0),\n            (MQTT_TOPIC_ASR + '#', 0),\n            (MQTT_TOPIC_SNIPSFILE, 0),\n            (MQTT_TOPIC_DIALOG_MANAGER + '#', 0),\n            (\"snipsmanager/#\", 0)\n        ]\n        self.client.subscribe(topics)\n\n        while run_event.is_set():\n            try:\n                self.client.loop()\n            except AttributeError as e:\n                self.log_info(\"Error in mqtt run loop {}\".format(e))\n                time.sleep(1)", "response": "Start the MQTT client as a blocking method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef on_connect(self, client, userdata, flags, result_code):\n        self.log_info(\"Connected with result code {}\".format(result_code))\n        self.state_handler.set_state(State.welcome)", "response": "Callback when the MQTT client is connected."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, identity_id, per_page=20, page=1):\n\n        params = {'per_page': per_page, 'page': page}\n\n        return self.request.get(str(identity_id) + '/token', params)", "response": "Get a list of tokens for a given identity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a token in the specified service.", "response": "def create(self, identity_id, service, token):\n        \"\"\" Create the token\n\n            :param identity_id: The ID of the identity to retrieve\n            :param service: The service that the token is linked to\n            :param token: The token provided by the the service\n            :param expires_at: Set an expiry for this token\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {'service': service, 'token': token}\n\n        return self.request.post(str(identity_id) + '/token', params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the token of the given identity.", "response": "def update(self, identity_id, service, token=None):\n        \"\"\" Update the token\n\n            :param identity_id: The ID of the identity to retrieve\n            :return: dict of REST API output with headers attached\n            :rtype: :class:`~datasift.request.DictResponse`\n            :raises: :class:`~datasift.exceptions.DataSiftApiException`,\n                :class:`requests.exceptions.HTTPError`\n        \"\"\"\n\n        params = {}\n\n        if token:\n            params['token'] = token\n\n        return self.request.put(str(identity_id) + '/token/' + service, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _func_router(self, msg, fname, **config):\n        FNAME = 'handle_%s_autocloud_%s'\n\n        if ('compose_id' in msg['msg'] or 'compose_job_id' in msg['msg'] or\n                'autocloud.compose' in msg['topic']):\n            return getattr(self, FNAME % ('v2', fname))(msg, **config)\n        else:\n            return getattr(self, FNAME % ('v1', fname))(msg, **config)", "response": "This method routes the messages based on the params and calls the appropriate method to process the message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn list of available Sesame objects.", "response": "def get_sesames(email, password, device_ids=None, nicknames=None, timeout=5):\n    \"\"\"Return list of available Sesame objects.\"\"\"\n    sesames = []\n    account = CandyHouseAccount(email, password, timeout=timeout)\n\n    for sesame in account.sesames:\n        if device_ids is not None and sesame['device_id'] not in device_ids:\n            continue\n        if nicknames is not None and sesame['nickname'] not in nicknames:\n            continue\n        sesames.append(Sesame(account, sesame))\n\n    return sesames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npulsing the current value of the current entry set into the table_values attribute.", "response": "def pulse(self):\n        \"\"\"\n        Calls when_rotated callback if detected changes\n        \"\"\"\n        new_b_value = self.gpio_b.is_active\n        new_a_value = self.gpio_a.is_active\n\n        value = self.table_values.value(new_b_value, new_a_value, self.old_b_value, self.old_a_value)\n\n        self.old_b_value = new_b_value\n        self.old_a_value = new_a_value\n\n        if value != 0:\n            self.when_rotated(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset archive default read versions by default.", "response": "def default_versions(self, default_versions):\n        '''\n        Set archive default read versions\n\n        Parameters\n        ----------\n        default_versions: dict\n            Dictionary of archive_name, version pairs. On read/download,\n            archives in this dictionary will download the specified version\n            by default. Before assignment, archive_names are checked and\n            normalized.\n        '''\n\n        default_versions = {\n            self._normalize_archive_name(arch)[1]: v\n            for arch, v in default_versions.items()}\n\n        self._default_versions = default_versions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(\n            self,\n            archive_name,\n            authority_name=None,\n            versioned=True,\n            raise_on_err=True,\n            metadata=None,\n            tags=None,\n            helper=False):\n        '''\n        Create a DataFS archive\n\n        Parameters\n        ----------\n\n        archive_name: str\n            Name of the archive\n\n        authority_name: str\n            Name of the data service to use as the archive's data authority\n\n        versioned: bool\n            If true, store all versions with explicit version numbers (defualt)\n\n        raise_on_err: bool\n            Raise an error if the archive already exists (default True)\n\n        metadata: dict\n            Dictionary of additional archive metadata\n\n        helper: bool\n            If true, interactively prompt for required metadata (default False)\n\n\n        '''\n\n        authority_name, archive_name = self._normalize_archive_name(\n            archive_name, authority_name=authority_name)\n\n        if authority_name is None:\n            authority_name = self.default_authority_name\n\n        self._validate_archive_name(archive_name)\n\n        if metadata is None:\n            metadata = {}\n\n        res = self.manager.create_archive(\n            archive_name,\n            authority_name,\n            archive_path=archive_name,\n            versioned=versioned,\n            raise_on_err=raise_on_err,\n            metadata=metadata,\n            user_config=self.user_config,\n            tags=tags,\n            helper=helper)\n\n        return self._ArchiveConstructor(\n            api=self,\n            **res)", "response": "Create a new DataFS archive with the specified name authority name and metadata."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_archive(self, archive_name, default_version=None):\n        '''\n        Retrieve a data archive\n\n        Parameters\n        ----------\n\n        archive_name: str\n            Name of the archive to retrieve\n\n        default_version: version\n            str or :py:class:`~distutils.StrictVersion` giving the default\n            version number to be used on read operations\n\n        Returns\n        -------\n        archive: object\n            New :py:class:`~datafs.core.data_archive.DataArchive` object\n\n        Raises\n        ------\n\n        KeyError:\n            A KeyError is raised when the ``archive_name`` is not found\n\n        '''\n\n        auth, archive_name = self._normalize_archive_name(archive_name)\n\n        res = self.manager.get_archive(archive_name)\n\n        if default_version is None:\n            default_version = self._default_versions.get(archive_name, None)\n\n        if (auth is not None) and (auth != res['authority_name']):\n            raise ValueError(\n                'Archive \"{}\" not found on {}.'.format(archive_name, auth) +\n                ' Did you mean \"{}://{}\"?'.format(\n                    res['authority_name'], archive_name))\n\n        return self._ArchiveConstructor(\n            api=self,\n            default_version=default_version,\n            **res)", "response": "Retrieve a data archive with the specified name and optional default version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef batch_get_archive(self, archive_names, default_versions=None):\n        '''\n        Batch version of :py:meth:`~DataAPI.get_archive`\n\n        Parameters\n        ----------\n\n        archive_names: list\n\n            Iterable of archive names to retrieve\n\n        default_versions: str, object, or dict\n\n            Default versions to assign to each returned archive. May be a dict\n            with archive names as keys and versions as values, or may be a\n            version, in which case the same version is used for all archives.\n            Versions must be a strict version number string, a\n            :py:class:`~distutils.version.StrictVersion`, or a\n            :py:class:`~datafs.core.versions.BumpableVersion` object.\n\n        Returns\n        -------\n\n        archives: list\n\n            List of :py:class:`~datafs.core.data_archive.DataArchive` objects.\n            If an archive is not found, it is omitted (``batch_get_archive``\n            does not raise a ``KeyError`` on invalid archive names).\n\n        '''\n\n        # toss prefixes and normalize names\n        archive_names = map(\n            lambda arch: self._normalize_archive_name(arch)[1],\n            archive_names)\n\n        responses = self.manager.batch_get_archive(archive_names)\n\n        archives = {}\n\n        if default_versions is None:\n            default_versions = {}\n\n        for res in responses:\n            res['archive_name'] = self._normalize_archive_name(\n                res['archive_name'])\n\n            archive_name = res['archive_name']\n\n            if hasattr(default_versions, 'get'):\n\n                # Get version number from default_versions or\n                # self._default_versions if key not present.\n                default_version = default_versions.get(\n                    archive_name,\n                    self._default_versions.get(archive_name, None))\n\n            else:\n                default_version = default_versions\n\n            archive = self._ArchiveConstructor(\n                api=self,\n                default_version=default_version,\n                **res)\n\n            archives[archive_name] = archive\n\n        return archives", "response": "Batch version of a Data API s get_archive method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listdir(self, location, authority_name=None):\n        '''\n        List archive path components at a given location\n\n        .. Note ::\n\n            When using listdir on versioned archives, listdir will provide the\n            version numbers when a full archive path is supplied as the\n            location argument. This is because DataFS stores the archive path\n            as a directory and the versions as the actual files when versioning\n            is on.\n\n        Parameters\n        ----------\n\n        location: str\n\n            Path of the \"directory\" to search\n\n            `location` can be a path relative to the authority root (e.g\n            `/MyFiles/Data`) or can include authority as a protocol (e.g.\n            `my_auth://MyFiles/Data`). If the authority is specified as a\n            protocol, the `authority_name` argument is ignored.\n\n        authority_name: str\n\n            Name of the authority to search (optional)\n\n            If no authority is specified, the default authority is used (if\n            only one authority is attached or if\n            :py:attr:`DefaultAuthorityName` is assigned).\n\n        Returns\n        -------\n\n        list\n\n            Archive path components that exist at the given \"directory\"\n            location on the specified authority\n\n        Raises\n        ------\n\n        ValueError\n\n            A ValueError is raised if the authority is ambiguous or invalid\n\n\n        '''\n\n        authority_name, location = self._normalize_archive_name(\n            location,\n            authority_name=authority_name)\n\n        if authority_name is None:\n            authority_name = self.default_authority_name\n\n        return self._authorities[authority_name].fs.listdir(location)", "response": "Returns a list of archive path components at a given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches based on tags specified by users .", "response": "def search(self, *query, **kwargs):\n        '''\n        Searches based on tags specified by users\n\n\n\n        Parameters\n        ---------\n        query: str\n            tags to search on. If multiple terms, provided in comma delimited\n            string format\n\n        prefix: str\n            start of archive name. Providing a start string improves search\n            speed.\n\n        '''\n\n        prefix = kwargs.get('prefix')\n\n        if prefix is not None:\n            prefix = fs.path.relpath(prefix)\n\n        return self.manager.search(query, begins_with=prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_archive_name(self, archive_name):\n        '''\n        Utility function for creating and validating archive names\n\n        Parameters\n        ----------\n\n        archive_name: str\n            Name of the archive from which to create a service path\n\n        Returns\n        -------\n\n        archive_path: str\n            Internal path used by services to reference archive data\n        '''\n        archive_name = fs.path.normpath(archive_name)\n        patterns = self.manager.required_archive_patterns\n\n        for pattern in patterns:\n            if not re.search(pattern, archive_name):\n                raise ValueError(\n                    \"archive name does not match pattern '{}'\".format(pattern))", "response": "Utility function for creating and validating archive names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hash_file(f):\n        '''\n        Utility function for hashing file contents\n\n        Overload this function to change the file equality checking algorithm\n\n        Parameters\n        ----------\n\n        f: file-like\n            File-like object or file path from which to compute checksum value\n\n\n        Returns\n        -------\n        checksum: dict\n            dictionary with {'algorithm': 'md5', 'checksum': hexdigest}\n\n        '''\n\n        md5 = hashlib.md5()\n\n        with open_filelike(f, 'rb') as f_obj:\n            for chunk in iter(lambda: f_obj.read(128 * md5.block_size), b''):\n                md5.update(chunk)\n\n        return {'algorithm': 'md5', 'checksum': md5.hexdigest()}", "response": "Utility function for hashing file contents with md5 hash algorithm"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts dict into formatted HTML.", "response": "def html_list(data):\n    \"\"\"Convert dict into formatted HTML.\"\"\"\n    if data is None:\n        return None\n    as_li = lambda v: \"<li>%s</li>\" % v\n    items = [as_li(v) for v in data]\n    return mark_safe(\"<ul>%s</ul>\" % ''.join(items))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating latest package info from PyPI.", "response": "def check_pypi(modeladmin, request, queryset):\n    \"\"\"Update latest package info from PyPI.\"\"\"\n    for p in queryset:\n        if p.is_editable:\n            logger.debug(\"Ignoring version update '%s' is editable\", p.package_name)\n        else:\n            p.update_from_pypi()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef queryset(self, request, queryset):\n        if self.value() == '-1':\n            return queryset.filter(latest_version__isnull=True)\n        elif self.value() == '0':\n            return (\n                queryset\n                .filter(\n                    current_version__isnull=False,\n                    latest_version__isnull=False,\n                    latest_version=F('current_version')\n                )\n            )\n        elif self.value() == '1':\n            return (\n                queryset\n                .filter(\n                    current_version__isnull=False,\n                    latest_version__isnull=False\n                ).exclude(\n                    latest_version=F('current_version')\n                )\n            )\n        else:\n            return queryset", "response": "Filter based on whether an update is available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if there are available updates.", "response": "def _updateable(self, obj):\n        \"\"\"Return True if there are available updates.\"\"\"\n        if obj.latest_version is None or obj.is_editable:\n            return None\n        else:\n            return obj.latest_version != obj.current_version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint out all versions ahead of the current one.", "response": "def available_updates(self, obj):\n        \"\"\"Print out all versions ahead of the current one.\"\"\"\n        from package_monitor import pypi\n        package = pypi.Package(obj.package_name)\n        versions = package.all_versions()\n        return html_list([v for v in versions if v > obj.current_version])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the agent from a message.", "response": "def get_agent(msg):\n    \"\"\" Handy hack to handle legacy messages where 'agent' was a list.  \"\"\"\n    agent = msg['msg']['agent']\n    if isinstance(agent, list):\n        agent = agent[0]\n    return agent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_suite(case, config, summary):\n    config[\"name\"] = case\n    model_dir = os.path.join(livvkit.model_dir, config['data_dir'], case)\n    bench_dir = os.path.join(livvkit.bench_dir, config['data_dir'], case)\n    tabs = []\n    case_summary = LIVVDict()\n    model_cases = functions.collect_cases(model_dir)\n    bench_cases = functions.collect_cases(bench_dir)\n\n    for subcase in sorted(six.iterkeys(model_cases)):\n        bench_subcases = bench_cases[subcase] if subcase in bench_cases else []\n        case_sections = []\n        for mcase in sorted(model_cases[subcase], key=functions.sort_processor_counts):\n            bpath = (os.path.join(bench_dir, subcase, mcase.replace(\"-\", os.path.sep))\n                     if mcase in bench_subcases else \"\")\n            mpath = os.path.join(model_dir, subcase, mcase.replace(\"-\", os.path.sep))\n            case_result = _analyze_case(mpath, bpath, config)\n            case_sections.append(elements.section(mcase, case_result))\n            case_summary[subcase] = _summarize_result(case_result,\n                                                      case_summary[subcase])\n        tabs.append(elements.tab(subcase, section_list=case_sections))\n\n    result = elements.page(case, config[\"description\"], tab_list=tabs)\n    summary[case] = case_summary\n    _print_summary(case, summary[case])\n    functions.create_page_from_template(\"verification.html\",\n                                        os.path.join(livvkit.index_dir,\n                                                     \"verification\",\n                                                     case + \".html\")\n                                        )\n    functions.write_json(result, os.path.join(livvkit.output_dir, \"verification\"), case+\".json\")", "response": "Run the full suite of verification tests."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning all of the verification checks on a particular case", "response": "def _analyze_case(model_dir, bench_dir, config):\n    \"\"\" Runs all of the verification checks on a particular case \"\"\"\n    bundle = livvkit.verification_model_module\n    model_out = functions.find_file(model_dir, \"*\"+config[\"output_ext\"])\n    bench_out = functions.find_file(bench_dir, \"*\"+config[\"output_ext\"])\n    model_config = functions.find_file(model_dir, \"*\"+config[\"config_ext\"])\n    bench_config = functions.find_file(bench_dir, \"*\"+config[\"config_ext\"])\n    model_log = functions.find_file(model_dir, \"*\"+config[\"logfile_ext\"])\n    el = [\n            bit_for_bit(model_out, bench_out, config),\n            diff_configurations(model_config, bench_config, bundle, bundle),\n            bundle.parse_log(model_log)\n         ]\n    return el"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting some statistics from the run", "response": "def _print_summary(case, summary):\n    \"\"\" Show some statistics from the run \"\"\"\n    for dof, data in summary.items():\n        b4b = data[\"Bit for Bit\"]\n        conf = data[\"Configurations\"]\n        stdout = data[\"Std. Out Files\"]\n        print(\"    \" + case + \" \" + str(dof))\n        print(\"    --------------------\")\n        print(\"     Bit for bit matches   : \" + str(b4b[0]) + \" of \" + str(b4b[1]))\n        print(\"     Configuration matches : \" + str(conf[0]) + \" of \" + str(conf[1]))\n        print(\"     Std. Out files parsed : \" + str(stdout))\n        print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _summarize_result(result, summary):\n    if \"Bit for Bit\" not in summary:\n        summary[\"Bit for Bit\"] = [0, 0]\n    if \"Configurations\" not in summary:\n        summary[\"Configurations\"] = [0, 0]\n    if \"Std. Out Files\" not in summary:\n        summary[\"Std. Out Files\"] = 0\n\n    # Get the number of bit for bit failures\n    total_count = 0\n    failure_count = 0\n    summary_data = None\n    for elem in result:\n        if elem[\"Type\"] == \"Bit for Bit\" and \"Data\" in elem:\n            elem_data = elem[\"Data\"]\n            summary_data = summary[\"Bit for Bit\"]\n            total_count += 1\n            for var in six.iterkeys(elem_data):\n                if elem_data[var][\"Max Error\"] != 0:\n                    failure_count += 1\n                    break\n    if summary_data is not None:\n        summary_data = np.add(summary_data, [total_count-failure_count, total_count]).tolist()\n        summary[\"Bit for Bit\"] = summary_data\n\n    # Get the number of config matches\n    summary_data = None\n    total_count = 0\n    failure_count = 0\n    for elem in result:\n        if elem[\"Title\"] == \"Configuration Comparison\" and elem[\"Type\"] == \"Diff\":\n            elem_data = elem[\"Data\"]\n            summary_data = summary[\"Configurations\"]\n            total_count += 1\n            failed = False\n            for section_name, varlist in elem_data.items():\n                for var, val in varlist.items():\n                    if not val[0]:\n                        failed = True\n            if failed:\n                failure_count += 1\n    if summary_data is not None:\n        success_count = total_count - failure_count\n        summary_data = np.add(summary_data, [success_count, total_count]).tolist()\n        summary[\"Configurations\"] = summary_data\n\n    # Get the number of files parsed\n    for elem in result:\n        if elem[\"Title\"] == \"Output Log\" and elem[\"Type\"] == \"Table\":\n            summary[\"Std. Out Files\"] += 1\n            break\n    return summary", "response": "Get some data to return for the index page"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether the given files have bit for bit solution matches on the given variable list.", "response": "def bit_for_bit(model_path, bench_path, config):\n    \"\"\"\n    Checks whether the given files have bit for bit solution matches\n    on the given variable list.\n\n    Args:\n        model_path: absolute path to the model dataset\n        bench_path: absolute path to the benchmark dataset\n        config: the configuration of the set of analyses\n\n    Returns:\n        A dictionary created by the elements object corresponding to\n        the results of the bit for bit testing\n    \"\"\"\n    fname = model_path.split(os.path.sep)[-1]\n    # Error handling\n    if not (os.path.isfile(bench_path) and os.path.isfile(model_path)):\n        return elements.error(\"Bit for Bit\",\n                              \"File named \" + fname + \" has no suitable match!\")\n    try:\n        model_data = Dataset(model_path)\n        bench_data = Dataset(bench_path)\n    except (FileNotFoundError, PermissionError):\n        return elements.error(\"Bit for Bit\",\n                              \"File named \" + fname + \" could not be read!\")\n    if not (netcdf.has_time(model_data) and netcdf.has_time(bench_data)):\n        return elements.error(\"Bit for Bit\",\n                              \"File named \" + fname + \" could not be read!\")\n\n    # Begin bit for bit analysis\n    headers = [\"Max Error\", \"Index of Max Error\", \"RMS Error\", \"Plot\"]\n    stats = LIVVDict()\n    for i, var in enumerate(config[\"bit_for_bit_vars\"]):\n        if var in model_data.variables and var in bench_data.variables:\n            m_vardata = model_data.variables[var][:]\n            b_vardata = bench_data.variables[var][:]\n            diff_data = m_vardata - b_vardata\n            if diff_data.any():\n                stats[var][\"Max Error\"] = np.amax(np.absolute(diff_data))\n                stats[var][\"Index of Max Error\"] = str(\n                        np.unravel_index(np.absolute(diff_data).argmax(), diff_data.shape))\n                stats[var][\"RMS Error\"] = np.sqrt(np.sum(np.square(diff_data).flatten()) /\n                                                  diff_data.size)\n                pf = plot_bit_for_bit(fname, var, m_vardata, b_vardata, diff_data)\n            else:\n                stats[var][\"Max Error\"] = stats[var][\"RMS Error\"] = 0\n                pf = stats[var][\"Index of Max Error\"] = \"N/A\"\n            stats[var][\"Plot\"] = pf\n        else:\n            stats[var] = {\"Max Error\": \"No Match\", \"RMS Error\": \"N/A\", \"Plot\": \"N/A\"}\n    model_data.close()\n    bench_data.close()\n    return elements.bit_for_bit(\"Bit for Bit\", headers, stats)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_bit_for_bit(case, var_name, model_data, bench_data, diff_data):\n    plot_title = \"\"\n    plot_name = case + \"_\" + var_name + \".png\"\n    plot_path = os.path.join(os.path.join(livvkit.output_dir, \"verification\", \"imgs\"))\n    functions.mkdir_p(plot_path)\n    m_ndim = np.ndim(model_data)\n    b_ndim = np.ndim(bench_data)\n    if m_ndim != b_ndim:\n        return \"Dataset dimensions didn't match!\"\n    if m_ndim == 3:\n        model_data = model_data[-1]\n        bench_data = bench_data[-1]\n        diff_data = diff_data[-1]\n        plot_title = \"Showing \"+var_name+\"[-1,:,:]\"\n    elif m_ndim == 4:\n        model_data = model_data[-1][0]\n        bench_data = bench_data[-1][0]\n        diff_data = diff_data[-1][0]\n        plot_title = \"Showing \"+var_name+\"[-1,0,:,:]\"\n    plt.figure(figsize=(12, 3), dpi=80)\n    plt.clf()\n\n    # Calculate min and max to scale the colorbars\n    _max = np.amax([np.amax(model_data), np.amax(bench_data)])\n    _min = np.amin([np.amin(model_data), np.amin(bench_data)])\n\n    # Plot the model output\n    plt.subplot(1, 3, 1)\n    plt.xlabel(\"Model Data\")\n    plt.ylabel(var_name)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(model_data, vmin=_min, vmax=_max, interpolation='nearest', cmap=colormaps.viridis)\n    plt.colorbar()\n\n    # Plot the benchmark data\n    plt.subplot(1, 3, 2)\n    plt.xlabel(\"Benchmark Data\")\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(bench_data, vmin=_min, vmax=_max, interpolation='nearest', cmap=colormaps.viridis)\n    plt.colorbar()\n\n    # Plot the difference\n    plt.subplot(1, 3, 3)\n    plt.xlabel(\"Difference\")\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(diff_data, interpolation='nearest', cmap=colormaps.viridis)\n    plt.colorbar()\n\n    plt.tight_layout(rect=(0, 0, 0.95, 0.9))\n    plt.suptitle(plot_title)\n\n    plot_file = os.path.sep.join([plot_path, plot_name])\n    if livvkit.publish:\n        plt.savefig(os.path.splitext(plot_file)[0]+'.eps', dpi=600)\n    plt.savefig(plot_file)\n    plt.close()\n    return os.path.join(os.path.relpath(plot_path,\n                                        os.path.join(livvkit.output_dir, \"verification\")),\n                        plot_name)", "response": "Create a bit for the given variable name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, *args, **kwargs):\n        campaign = super(Campaign, self).save(*args, **kwargs)\n        save_campaign_special_coverage_percolator.delay(self.tunic_campaign_id)\n        return campaign", "response": "Kicks off celery task to re - save associated special coverages to percolator\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_rows_duplicates(self, table, cols='*'):\n        return self.count_rows(table, '*') - self.count_rows_distinct(table, cols)", "response": "Get the number of rows that do not contain distinct values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the number of rows in a particular table.", "response": "def count_rows(self, table, cols='*'):\n        \"\"\"Get the number of rows in a particular table.\"\"\"\n        query = 'SELECT COUNT({0}) FROM {1}'.format(join_cols(cols), wrap(table))\n        result = self.fetch(query)\n        return result if result is not None else 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the number of distinct rows in a particular table.", "response": "def count_rows_distinct(self, table, cols='*'):\n        \"\"\"Get the number distinct of rows in a particular table.\"\"\"\n        return self.fetch('SELECT COUNT(DISTINCT {0}) FROM {1}'.format(join_cols(cols), wrap(table)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if any of the columns in a table contain exclusively unique values.", "response": "def get_unique_column(self, table):\n        \"\"\"Determine if any of the columns in a table contain exclusively unique values.\"\"\"\n        for col in self.get_columns(table):\n            if self.count_rows_duplicates(table, col) == 0:\n                return col"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_duplicate_vals(self, table, column):\n        query = 'SELECT {0} FROM {1} GROUP BY {0} HAVING COUNT(*) > 1'.format(join_cols(column), wrap(table))\n        return self.fetch(query)", "response": "Retrieve duplicate values in a column of a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the field s info.", "response": "def get_field_info(self, field):\n        \"\"\"\n        This method is basically a mirror from rest_framework==3.3.3\n\n        We are currently pinned to rest_framework==3.1.1. If we upgrade,\n        this can be refactored and simplified to rely more heavily on\n        rest_framework's built in logic.\n        \"\"\"\n\n        field_info = self.get_attributes(field)\n        field_info[\"required\"] = getattr(field, \"required\", False)\n        field_info[\"type\"] = self.get_label_lookup(field)\n\n        if getattr(field, \"child\", None):\n            field_info[\"child\"] = self.get_field_info(field.child)\n        elif getattr(field, \"fields\", None):\n            field_info[\"children\"] = self.get_serializer_info(field)\n\n        if (not isinstance(field, (serializers.RelatedField, serializers.ManyRelatedField)) and\n                hasattr(field, \"choices\")):\n            field_info[\"choices\"] = [\n                {\n                    \"value\": choice_value,\n                    \"display_name\": force_text(choice_name, strings_only=True)\n                }\n                for choice_value, choice_name in field.choices.items()\n            ]\n\n        return field_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef maxId(self):\n        if len(self.model.db) == 0:\n            return 0\n\n        return max(map(lambda obj: obj[\"id\"], self.model.db))", "response": "get the max id of objects"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add(self, obj):\n        if not isinstance(obj, dict):\n            raise TypeError(\"Add object should be a dict object\")\n        obj = self.validation(obj)\n        obj[\"id\"] = self.maxId + 1\n        obj = self._cast_model(obj)\n        self.model.db.append(obj)\n\n        if not self._batch.enable.is_set():\n            self.model.save_db()\n        return obj", "response": "Adds a object to the list of available object in the database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a object by id", "response": "def get(self, id):\n        \"\"\"Get a object by id\n            Args:\n                id (int): Object id\n\n            Returns:\n                Object: Object with specified id\n                None: If object not found\n        \"\"\"\n        for obj in self.model.db:\n            if obj[\"id\"] == id:\n                return self._cast_model(obj)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an object by id", "response": "def remove(self, id):\n        \"\"\"Remove a object by id\n            Args:\n                id (int): Object's id should be deleted\n            Returns:\n                len(int): affected rows\n        \"\"\"\n        before_len = len(self.model.db)\n        self.model.db = [t for t in self.model.db if t[\"id\"] != id]\n        if not self._batch.enable.is_set():\n            self.model.save_db()\n        return before_len - len(self.model.db)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all objects in the database.", "response": "def removeAll(self):\n        \"\"\"Remove all objects\n            Returns:\n                len(int): affected rows\n        \"\"\"\n        before_len = len(self.model.db)\n        self.model.db = []\n        if not self._batch.enable.is_set():\n            self.model.save_db()\n        return before_len - len(self.model.db)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, id, newObj):\n        newObj = self.validation(newObj)\n        for obj in self.model.db:\n            if obj[\"id\"] != id:\n                continue\n\n            newObj.pop(\"id\", None)\n            obj.update(newObj)\n            obj = self._cast_model(obj)\n            if not self._batch.enable.is_set():\n                self.model.save_db()\n            return obj\n\n        return None", "response": "Update a object in the database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a object in the database.", "response": "def set(self, id, newObj):\n        \"\"\"Set a object\n            Args:\n                id (int): Target Object ID\n                newObj (object): New object will be set\n            Returns:\n                Object: New object\n                None: If specified object id is not found\n                MultipleInvalid: If input object is invaild\n        \"\"\"\n        newObj = self.validation(newObj)\n        for index in xrange(0, len(self.model.db)):\n            if self.model.db[index][\"id\"] != id:\n                continue\n\n            newObj[\"id\"] = id\n            self.model.db[index] = self._cast_model(newObj)\n            if not self._batch.enable.is_set():\n                self.model.save_db()\n            return self.model.db[index]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAll(self):\n        objs = []\n        for obj in self.model.db:\n            objs.append(self._cast_model(obj))\n\n        return objs", "response": "Get all objects\n            Returns:\n                List: list of all objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _double_prefix(self):\n        new_len = max(len(self._buf[0]) * 2, (len(self._buf[0]) + len(self._buf[1])))\n        self._merge_prefix(new_len)", "response": "Grow the given deque by doubling but don t split the second chunk just\n        because the first one is small."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging the first size entries of a deque of strings with a single string of up to size bytes.", "response": "def _merge_prefix(self, size):\n        \"\"\"Replace the first entries in a deque of strings with a single\n        string of up to size bytes.\n\n        >>> d = collections.deque(['abc', 'de', 'fghi', 'j'])\n        >>> _merge_prefix(d, 5); print(d)\n        deque(['abcde', 'fghi', 'j'])\n\n        Strings will be split as necessary to reach the desired size.\n        >>> _merge_prefix(d, 7); print(d)\n        deque(['abcdefg', 'hi', 'j'])\n\n        >>> _merge_prefix(d, 3); print(d)\n        deque(['abc', 'defg', 'hi', 'j'])\n\n        >>> _merge_prefix(d, 100); print(d)\n        deque(['abcdefghij'])\n        \"\"\"\n        if len(self._buf) == 1 and len(self._buf[0]) <= size:\n            return\n        prefix = []\n        remaining = size\n        while self._buf and remaining > 0:\n            chunk = self._buf.popleft()\n            if len(chunk) > remaining:\n                self._buf.appendleft(chunk[remaining:])\n                chunk = chunk[:remaining]\n            prefix.append(chunk)\n            remaining -= len(chunk)\n        if prefix:\n            self._buf.appendleft(b''.join(prefix))\n        if not self._buf:\n            self._buf.appendleft(b'')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sponsored_special_coverages():\n    now = timezone.now()\n    qs = SpecialCoverage.objects.filter(\n        tunic_campaign_id__isnull=False,\n    )\n    return qs.filter(\n        start_date__lte=now,\n        end_date__gt=now\n    ) | qs.filter(\n        start_date__lte=now,\n        end_date__isnull=True\n    )", "response": "Returns Django query for all active special coverages with active campaigns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sponsored_special_coverage_query(only_recent=False):\n    special_coverages = get_sponsored_special_coverages()\n    es_query = SearchParty(special_coverages).search()\n    if only_recent:\n        offset = getattr(settings, \"RECENT_SPONSORED_OFFSET_HOURS\", 0)\n        es_query = es_query.filter(\n            Published(after=timezone.now() - timezone.timedelta(hours=offset))\n        )\n    return es_query", "response": "Returns a Djes. LazySearch query that returns all active sponsored special coverages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the application and conserve the traceback frames.", "response": "def debug_application(self, environ, start_response):\n        \"\"\"Run the application and conserve the traceback frames.\"\"\"\n        app_iter = None\n        try:\n            app_iter = self.app(environ, start_response)\n            for item in app_iter:\n                yield item\n            if hasattr(app_iter, 'close'):\n                app_iter.close()\n        except Exception:\n            if hasattr(app_iter, 'close'):\n                app_iter.close()\n\n            context = RequestContext({'environ':dict(environ)})\n            for injector in self.context_injectors:\n                context.update(injector(environ))\n\n            traceback = get_current_traceback(skip=1, show_hidden_frames=self.show_hidden_frames,\n                                              context=context)\n            for frame in traceback.frames:\n                self.frames[frame.id] = frame\n            self.tracebacks[traceback.id] = traceback\n\n            try:\n                start_response('500 INTERNAL SERVER ERROR', [\n                    ('Content-Type', 'text/html; charset=utf-8'),\n                    # Disable Chrome's XSS protection, the debug\n                    # output can cause false-positives.\n                    ('X-XSS-Protection', '0'),\n                    ])\n            except Exception:\n                # if we end up here there has been output but an error\n                # occurred.  in that situation we can do nothing fancy any\n                # more, better log something into the error log and fall\n                # back gracefully.\n                environ['wsgi.errors'].write(\n                    'Debugging middleware caught exception in streamed '\n                    'response at a point where response headers were already '\n                    'sent.\\n')\n            else:\n                yield traceback.render_full(\n                    evalex=self.evalex,\n                    secret=self.secret\n                ).encode('utf-8', 'replace')\n\n            # This will lead to double logging in case backlash logger is set to DEBUG\n            # but this is actually wanted as some environments, like WebTest, swallow\n            # wsgi.environ making the traceback totally disappear.\n            log.debug(traceback.plaintext)\n            traceback.log(environ['wsgi.errors'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a standalone shell.", "response": "def display_console(self, request):\n        \"\"\"Display a standalone shell.\"\"\"\n        if 0 not in self.frames:\n            self.frames[0] = _ConsoleFrame(self.console_init_func())\n        return Response(render_console_html(secret=self.secret),\n            content_type='text/html')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paste_traceback(self, request, traceback):\n        rv = traceback.paste()\n        return Response(json.dumps(rv), content_type='application/json')", "response": "Paste the traceback and return a JSON response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply the relevant behaviors to the view queryset.", "response": "def filter_queryset(self, request, queryset, view):\n        \"\"\"Apply the relevant behaviors to the view queryset.\"\"\"\n        start_value = self.get_start(request)\n        if start_value:\n            queryset = self.apply_published_filter(queryset, \"after\", start_value)\n        end_value = self.get_end(request)\n        if end_value:\n            # Forces the end_value to be the last second of the date provided in the query.\n            # Necessary currently as our Published filter for es only applies to gte & lte.\n            queryset = self.apply_published_filter(queryset, \"before\", end_value)\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies the appropriate Published filter to a given DJES queryset.", "response": "def apply_published_filter(self, queryset, operation, value):\n        \"\"\"\n        Add the appropriate Published filter to a given elasticsearch query.\n\n        :param queryset: The DJES queryset object to be filtered.\n        :param operation: The type of filter (before/after).\n        :param value: The date or datetime value being applied to the filter.\n        \"\"\"\n        if operation not in [\"after\", \"before\"]:\n            raise ValueError(\"\"\"Publish filters only use before or after for range filters.\"\"\")\n        return queryset.filter(Published(**{operation: value}))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the request for the provided query parameter and returns a rounded value.", "response": "def get_date_datetime_param(self, request, param):\n        \"\"\"Check the request for the provided query parameter and returns a rounded value.\n\n        :param request: WSGI request object to retrieve query parameter data.\n        :param param: the name of the query parameter.\n        \"\"\"\n        if param in request.GET:\n            param_value = request.GET.get(param, None)\n            # Match and interpret param if formatted as a date.\n            date_match = dateparse.date_re.match(param_value)\n            if date_match:\n                return timezone.datetime.combine(\n                    dateparse.parse_date(date_match.group(0)), timezone.datetime.min.time()\n                )\n            datetime_match = dateparse.datetime_re.match(param_value)\n            if datetime_match:\n                return timezone.datetime.combine(\n                    dateparse.parse_datetime(datetime_match.group(0)).date(),\n                    timezone.datetime.min.time()\n                )\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, message, mid=None, age=60, force=True):\n        with self.session_lock:\n            if not hasattr(message, \"id\"):\n                message.__setattr__(\"id\", \"event-%s\" % (uuid.uuid4().hex,))\n            if self.session_list.get(message.id, None) is not None:\n                if force is False:\n                    raise SessionError(\"Message id: %s duplicate!\" %\n                                       message.id)\n                else:\n                    message = Message(message.to_dict(), generate_id=True)\n\n            session = {\n                \"status\": Status.CREATED,\n                \"message\": message,\n                \"age\": age,\n                \"mid\": mid,\n                \"created_at\": time(),\n                \"is_published\": Event(),\n                \"is_resolved\": Event()\n            }\n            self.session_list.update({\n                message.id: session\n            })\n\n            return session", "response": "create a new session"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_quiz_submissions(self, quiz_id, course_id, include=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the quiz submission.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission\", \"quiz\", \"user\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions\".format(**path), data=data, params=params, no_data=True)", "response": "Returns a list of all submissions for a quiz."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new quiz submission and start a new quiz - taking session.", "response": "def create_quiz_submission_start_quiz_taking_session(self, quiz_id, course_id, access_code=None, preview=None):\r\n        \"\"\"\r\n        Create the quiz submission (start a quiz-taking session).\r\n\r\n        Start taking a Quiz by creating a QuizSubmission which you can use to answer\r\n        questions and submit your answers.\r\n        \r\n        <b>Responses</b>\r\n        \r\n        * <b>200 OK</b> if the request was successful\r\n        * <b>400 Bad Request</b> if the quiz is locked\r\n        * <b>403 Forbidden</b> if an invalid access code is specified\r\n        * <b>403 Forbidden</b> if the Quiz's IP filter restriction does not pass\r\n        * <b>409 Conflict</b> if a QuizSubmission already exists for this user and quiz\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - access_code\r\n        \"\"\"Access code for the Quiz, if any.\"\"\"\r\n        if access_code is not None:\r\n            data[\"access_code\"] = access_code\r\n\r\n        # OPTIONAL - preview\r\n        \"\"\"Whether this should be a preview QuizSubmission and not count towards\r\n        the user's course record. Teachers only.\"\"\"\r\n        if preview is not None:\r\n            data[\"preview\"] = preview\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_student_question_scores_and_comments(self, id, quiz_id, attempt, course_id, fudge_points=None, questions=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - attempt\r\n        \"\"\"The attempt number of the quiz submission that should be updated. This\r\n        attempt MUST be already completed.\"\"\"\r\n        data[\"attempt\"] = attempt\r\n\r\n        # OPTIONAL - fudge_points\r\n        \"\"\"Amount of positive or negative points to fudge the total score by.\"\"\"\r\n        if fudge_points is not None:\r\n            data[\"fudge_points\"] = fudge_points\r\n\r\n        # OPTIONAL - questions\r\n        \"\"\"A set of scores and comments for each question answered by the student.\r\n        The keys are the question IDs, and the values are hashes of `score` and\r\n        `comment` entries. See {Appendix: Manual Scoring} for more on this\r\n        parameter.\"\"\"\r\n        if questions is not None:\r\n            data[\"questions\"] = questions\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Updates the student question scores and comments for a student submission."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef complete_quiz_submission_turn_it_in(self, id, quiz_id, attempt, course_id, validation_token, access_code=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - attempt\r\n        \"\"\"The attempt number of the quiz submission that should be completed. Note\r\n        that this must be the latest attempt index, as earlier attempts can not\r\n        be modified.\"\"\"\r\n        data[\"attempt\"] = attempt\r\n\r\n        # REQUIRED - validation_token\r\n        \"\"\"The unique validation token you received when this Quiz Submission was\r\n        created.\"\"\"\r\n        data[\"validation_token\"] = validation_token\r\n\r\n        # OPTIONAL - access_code\r\n        \"\"\"Access code for the Quiz, if any.\"\"\"\r\n        if access_code is not None:\r\n            data[\"access_code\"] = access_code\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions/{id}/complete with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/submissions/{id}/complete\".format(**path), data=data, params=params, no_data=True)", "response": "Complete a quiz submission"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_args(args=None):\n    parser = argparse.ArgumentParser(description=\"Main script to run LIVVkit.\",\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n                                     fromfile_prefix_chars='@')\n\n    parser.add_argument('-o', '--out-dir',\n                        default=os.path.join(os.getcwd(), \"vv_\" + time.strftime(\"%Y-%m-%d\")),\n                        help='Location to output the LIVVkit webpages.'\n                        )\n\n    parser.add_argument('-v', '--verify',\n                        nargs=2,\n                        default=None,\n                        help=' '.join(['Specify the locations of the test and bench bundle to',\n                                       'compare (respectively).'\n                                       ])\n                        )\n\n    parser.add_argument('-V', '--validate',\n                        action='store',\n                        nargs='+',\n                        default=None,\n                        help=' '.join(['Specify the location of the configuration files for',\n                                       'validation tests.'\n                                       ])\n                        )\n\n    # FIXME: this just short-circuits to the validation option, and should become its own module\n    parser.add_argument('-e', '--extension',\n                        action='store',\n                        nargs='+',\n                        default=None,\n                        dest='validate',\n                        metavar='EXTENSION',\n                        help=' '.join(['Specify the location of the configuration files for',\n                                       'LIVVkit extensions.'\n                                       ])\n                        )\n\n    parser.add_argument('-p', '--publish',\n                        action='store_true',\n                        help=' '.join(['Also produce a publication quality copy of the figure in',\n                                       'the output directory (eps, 600d pi).'\n                                       ])\n                        )\n\n    parser.add_argument('-s', '--serve',\n                        nargs='?', type=int, const=8000,\n                        help=' '.join(['Start a simple HTTP server for the output website specified',\n                                       'by OUT_DIR on port SERVE.'\n                                       ])\n                        )\n\n    parser.add_argument('--version',\n                        action='version',\n                        version='LIVVkit {}'.format(livvkit.__version__),\n                        help=\"Show LIVVkit's version number and exit\"\n                        )\n\n    return init(parser.parse_args(args))", "response": "Parses the command line arguments for LIVVkit s command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the LIVVkit backend and initialize the LIVVkit object.", "response": "def init(options):\n    \"\"\" Initialize some defaults \"\"\"\n\n    # Set matlplotlib's backend so LIVVkit can plot to files.\n    import matplotlib\n    matplotlib.use('agg')\n\n    livvkit.output_dir = os.path.abspath(options.out_dir)\n    livvkit.index_dir = livvkit.output_dir\n    livvkit.verify = True if options.verify is not None else False\n    livvkit.validate = True if options.validate is not None else False\n    livvkit.publish = options.publish\n\n    # Get a list of bundles that provide model specific implementations\n    available_bundles = [mod for imp, mod, ispkg in pkgutil.iter_modules(bundles.__path__)]\n\n    if options.verify is not None:\n        livvkit.model_dir = os.path.normpath(options.verify[0])\n        livvkit.bench_dir = os.path.normpath(options.verify[1])\n        if not os.path.isdir(livvkit.model_dir):\n            print(\"\")\n            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n            print(\"                       UH OH!\")\n            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n            print(\"    Your comparison directory does not exist; please check\")\n            print(\"    the path:\")\n            print(\"\\n\"+livvkit.model_dir+\"\\n\\n\")\n            sys.exit(1)\n\n        if not os.path.isdir(livvkit.bench_dir):\n            print(\"\")\n            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n            print(\"                       UH OH!\")\n            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n            print(\"    Your benchmark directory does not exist; please check\")\n            print(\"    the path:\")\n            print(\"\\n\"+livvkit.bench_dir+\"\\n\\n\")\n            sys.exit(1)\n\n        livvkit.model_bundle = os.path.basename(livvkit.model_dir)\n        livvkit.bench_bundle = os.path.basename(livvkit.bench_dir)\n\n        if livvkit.model_bundle in available_bundles:\n            livvkit.numerics_model_config = os.path.join(\n                livvkit.bundle_dir, livvkit.model_bundle, \"numerics.json\")\n            livvkit.numerics_model_module = importlib.import_module(\n                \".\".join([\"livvkit.bundles\", livvkit.model_bundle, \"numerics\"]))\n\n            livvkit.verification_model_config = os.path.join(\n                 livvkit.bundle_dir, livvkit.model_bundle, \"verification.json\")\n            livvkit.verification_model_module = importlib.import_module(\n                 \".\".join([\"livvkit.bundles\", livvkit.model_bundle, \"verification\"]))\n\n            livvkit.performance_model_config = os.path.join(\n                 livvkit.bundle_dir, livvkit.model_bundle, \"performance.json\")\n            # NOTE: This isn't used right now...\n            # livvkit.performance_model_module = importlib.import_module(\n            #      \".\".join([\"livvkit.bundles\", livvkit.model_bundle, \"performance\"]))\n        else:\n            # TODO: Should implement some error checking here...\n            livvkit.verify = False\n\n    if options.validate is not None:\n        livvkit.validation_model_configs = options.validate\n\n    if not (livvkit.verify or livvkit.validate) and not options.serve:\n        print(\"\")\n        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        print(\"                       UH OH!\")\n        print(\"----------------------------------------------------------\")\n        print(\"    No verification or validation tests found/submitted!\")\n        print(\"\")\n        print(\"    Use either one or both of the --verify and\")\n        print(\"    --validate options to run tests.  For more \")\n        print(\"    information use the --help option, view the README\")\n        print(\"    or check https://livvkit.github.io/Docs/\")\n        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n        print(\"\")\n        sys.exit(1)\n\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist group categories for a context. Returns a list of group categories for a context in a context.", "response": "def list_group_categories_for_context_accounts(self, account_id):\r\n        \"\"\"\r\n        List group categories for a context.\r\n\r\n        Returns a list of group categories in a context\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/group_categories with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/group_categories\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_group_categories_for_context_courses(self, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/group_categories with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/group_categories\".format(**path), data=data, params=params, all_pages=True)", "response": "List group categories for a context. Returns a list of group categories in a context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a single group category. Returns the data for a single group category. Returns a 401 if the caller doesn t have the rights to see it. Returns the data for a single group category.", "response": "def get_single_group_category(self, group_category_id):\r\n        \"\"\"\r\n        Get a single group category.\r\n\r\n        Returns the data for a single group category, or a 401 if the caller doesn't have\r\n        the rights to see it.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_category_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_category_id\"] = group_category_id\r\n\r\n        self.logger.debug(\"GET /api/v1/group_categories/{group_category_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/group_categories/{group_category_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new group category. Returns the new group category.", "response": "def create_group_category_accounts(self, name, account_id, auto_leader=None, create_group_count=None, group_limit=None, self_signup=None, split_group_count=None):\r\n        \"\"\"\r\n        Create a Group Category.\r\n\r\n        Create a new group category\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - name\r\n        \"\"\"Name of the group category\"\"\"\r\n        data[\"name\"] = name\r\n\r\n        # OPTIONAL - self_signup\r\n        \"\"\"Allow students to sign up for a group themselves (Course Only).\r\n        valid values are:\r\n        \"enabled\":: allows students to self sign up for any group in course\r\n        \"restricted\":: allows students to self sign up only for groups in the\r\n                       same section null disallows self sign up\"\"\"\r\n        if self_signup is not None:\r\n            self._validate_enum(self_signup, [\"enabled\", \"restricted\"])\r\n            data[\"self_signup\"] = self_signup\r\n\r\n        # OPTIONAL - auto_leader\r\n        \"\"\"Assigns group leaders automatically when generating and allocating students to groups\r\n        Valid values are:\r\n        \"first\":: the first student to be allocated to a group is the leader\r\n        \"random\":: a random student from all members is chosen as the leader\"\"\"\r\n        if auto_leader is not None:\r\n            self._validate_enum(auto_leader, [\"first\", \"random\"])\r\n            data[\"auto_leader\"] = auto_leader\r\n\r\n        # OPTIONAL - group_limit\r\n        \"\"\"Limit the maximum number of users in each group (Course Only). Requires\r\n        self signup.\"\"\"\r\n        if group_limit is not None:\r\n            data[\"group_limit\"] = group_limit\r\n\r\n        # OPTIONAL - create_group_count\r\n        \"\"\"Create this number of groups (Course Only).\"\"\"\r\n        if create_group_count is not None:\r\n            data[\"create_group_count\"] = create_group_count\r\n\r\n        # OPTIONAL - split_group_count\r\n        \"\"\"(Deprecated)\r\n        Create this number of groups, and evenly distribute students\r\n        among them. not allowed with \"enable_self_signup\". because\r\n        the group assignment happens synchronously, it's recommended\r\n        that you instead use the assign_unassigned_members endpoint.\r\n        (Course Only)\"\"\"\r\n        if split_group_count is not None:\r\n            data[\"split_group_count\"] = split_group_count\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/group_categories with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/group_categories\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a group category. Deletes a group category and all groups under it. Returns the complete updated group category record record.", "response": "def delete_group_category(self, group_category_id):\r\n        \"\"\"\r\n        Delete a Group Category.\r\n\r\n        Deletes a group category and all groups under it. Protected group\r\n        categories can not be deleted, i.e. \"communities\" and \"student_organized\".\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_category_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_category_id\"] = group_category_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/group_categories/{group_category_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/group_categories/{group_category_id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting groups in a group category. Returns a list of groups in a group category.", "response": "def list_groups_in_group_category(self, group_category_id):\r\n        \"\"\"\r\n        List groups in group category.\r\n\r\n        Returns a list of groups in a group category\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_category_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_category_id\"] = group_category_id\r\n\r\n        self.logger.debug(\"GET /api/v1/group_categories/{group_category_id}/groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/group_categories/{group_category_id}/groups\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_users_in_group_category(self, group_category_id, search_term=None, unassigned=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_category_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_category_id\"] = group_category_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name or full ID of the users to match and return in the results\r\n        list. Must be at least 3 characters.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - unassigned\r\n        \"\"\"Set this value to true if you wish only to search unassigned users in the\r\n        group category.\"\"\"\r\n        if unassigned is not None:\r\n            params[\"unassigned\"] = unassigned\r\n\r\n        self.logger.debug(\"GET /api/v1/group_categories/{group_category_id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/group_categories/{group_category_id}/users\".format(**path), data=data, params=params, all_pages=True)", "response": "List users in a group category. Returns a list of users in the group category."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_unassigned_members(self, group_category_id, sync=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_category_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_category_id\"] = group_category_id\r\n\r\n        # OPTIONAL - sync\r\n        \"\"\"The assigning is done asynchronously by default. If you would like to\r\n        override this and have the assigning done synchronously, set this value\r\n        to true.\"\"\"\r\n        if sync is not None:\r\n            data[\"sync\"] = sync\r\n\r\n        self.logger.debug(\"POST /api/v1/group_categories/{group_category_id}/assign_unassigned_members with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/group_categories/{group_category_id}/assign_unassigned_members\".format(**path), data=data, params=params, single_item=True)", "response": "Assign unassigned members. Assigns unassigned members to student groups."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_client(self, *args, **kwargs):\n        ''' Se voc\u00ea possui informa\u00e7\u00f5es cadastradas sobre o comprador voc\u00ea pode utilizar\n        este m\u00e9todo para enviar estas informa\u00e7\u00f5es para o PagSeguro. \u00c9 uma boa pr\u00e1tica pois\n        evita que seu cliente tenha que preencher estas informa\u00e7\u00f5es novamente na p\u00e1gina\n        do PagSeguro.\n\n        Args:\n            name (str): (opcional) Nome do cliente\n            email (str): (opcional) Email do cliente\n            phone_area_code (str): (opcional) C\u00f3digo de \u00e1rea do telefone do cliente. Um n\u00famero com 2 digitos.\n            phone_number (str): (opcional) O n\u00famero de telefone do cliente.\n            cpf: (str): (opcional) N\u00famero do cpf do comprador\n            born_date: (date): Data de nascimento no formato dd/MM/yyyy\n\n        Exemplo:\n            >>> from pagseguro import Payment\n            >>> from pagseguro import local_settings\n            >>> payment = Payment(email=local_settings.PAGSEGURO_ACCOUNT_EMAIL, token=local_settings.PAGSEGURO_TOKEN, sandbox=True)\n            >>> payment.set_client(name=u'Adam  Yauch', phone_area_code=11)\n        '''\n        self.client = {}      \n        for arg, value in kwargs.iteritems():\n            if value:\n                self.client[arg] = value\n        client_schema(self.client)", "response": "Se voc\u00ea possui informa\u00e7\u00f5es cadastradas sobre o PagSeguro. Se voc\u00ea possui informa\u00e7\u00f5es cadastradas sobre o comprador voc\u00ea pode utilizar\n        esta m\u00e9todo para enviar esta informa\u00e7\u00f5es novamente na p\u00e1gina. Se voc\ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_shipping(self, *args, **kwargs):\n        ''' Define os atributos do frete\n\n        Args:\n            type (int): (opcional) Tipo de frete. Os valores v\u00e1lidos s\u00e3o: 1 para 'Encomenda normal (PAC).',\n                2 para 'SEDEX' e 3 para 'Tipo de frete n\u00e3o especificado.'\n            cost (float): (opcional) Valor total do frete. Deve ser maior que 0.00 e menor ou igual a 9999999.00.\n            street (str): (opcional) Nome da rua do endere\u00e7o de envio do produto\n            address_number: (opcional) N\u00famero do endere\u00e7o de envio do produto. \n            complement: (opcional) Complemento (bloco, apartamento, etc.) do endere\u00e7o de envio do produto. \n            district: (opcional) Bairro do endere\u00e7o de envio do produto.\n            postal_code: (opcional) CEP do endere\u00e7o de envio do produto.\n            city: (opcional) Cidade do endere\u00e7o de envio do produto.\n            state: (opcional) Estado do endere\u00e7o de envio do produto.\n            country: (opcional) Pa\u00eds do endere\u00e7o de envio do produto. Apenas o valor 'BRA' \u00e9 aceito.\n        \n        '''\n        self.shipping = {}\n        for arg, value in kwargs.iteritems():\n            self.shipping[arg] = value\n        shipping_schema(self.shipping)", "response": "Define os atributos do frete\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests a new object to the PagSeguro API.", "response": "def request(self):\n        '''\n        Faz a requisi\u00e7\u00e3o de pagamento ao servidor do PagSeguro.\n        '''\n#        try:\n        payment_v2_schema(self)\n#        except MultipleInvalid as e:\n#            raise PagSeguroPaymentValidationException(u'Erro na valida\u00e7\u00e3o dos dados: %s' % e.msg)\n        params = self._build_params()\n#         logger.debug(u'Parametros da requisicao ao PagSeguro: %s' % params)\n        req = requests.post(\n            self.PAGSEGURO_API_URL,\n            params=params,\n            headers={\n                'Content-Type':\n                'application/x-www-form-urlencoded; charset=ISO-8859-1'\n            }\n        )\n        if req.status_code == 200:\n            self.params = params\n            self.response = self._process_response_xml(req.text)\n        else:\n            raise PagSeguroApiException(\n                u'Erro ao fazer request para a API:' +\n                ' HTTP Status=%s - Response: %s' % (req.status_code, req.text))\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_params(self):\n        ''' m\u00e9todo que constr\u00f3i o dicionario com os parametros que ser\u00e3o usados\n        na requisi\u00e7\u00e3o HTTP Post ao PagSeguro\n        \n        Returns:\n            Um dicion\u00e1rio com os parametros definidos no objeto Payment.\n        '''\n        params = {}\n        params['email'] = self.email\n        params['token'] = self.token\n        params['currency'] = self.currency\n\n        # Atributos opcionais\n        if self.receiver_email:\n            params['receiver_email'] = self.receiver_email\n        if self.reference:\n            params['reference'] = self.reference\n        if self.extra_amount:\n            params['extra_amount'] = self.extra_amount\n        if self.redirect_url:\n            params['redirect_url'] = self.redirect_url\n        if self.notification_url:\n            params['notification_url'] = self.notification_url\n        if self.max_uses:\n            params['max_uses'] = self.max_uses\n        if self.max_age:\n            params['max_age'] = self.max_age\n\n        #TODO: Incluir metadata aqui\n\n        # Itens\n        for index, item in enumerate(self.items, start=1):\n            params['itemId%d' % index] = item['item_id']\n            params['itemDescription%d' % index] = item['description']\n            params['itemAmount%d' % index] = '%.2f' % item['amount']\n            params['itemQuantity%s' % index] = item['quantity']\n            if item.get('shipping_cost'):\n                params['itemShippingCost%d' % index] = item['shipping_cost']\n            if item.get('weight'):\n                params['itemWeight%d' % index] = item['weight']\n\n        # Sender\n        if self.client.get('email'):\n            params['senderEmail'] = self.client.get('email')\n        if self.client.get('name'):\n            params['senderName'] = ' '.join(self.client.get('name').split())\n        if self.client.get('phone_area_code'):\n            params['senderAreaCode'] = self.client.get('phone_area_code')\n        if self.client.get('phone_number'):\n            params['senderPhone'] = self.client.get('phone_number')\n        if self.client.get('cpf'):\n            params['senderCPF'] = self.client.get('cpf')\n        if self.client.get('sender_born_date'):\n            params['senderBornDate'] = self.client.get('sender_born_date')\n\n        # Shipping\n        if self.shipping.get('type'):\n            params['shippingType'] = self.shipping.get('type')\n        if self.shipping.get('cost'):\n            params['shippingCost'] = '%.2f' % self.shipping.get('cost')\n        if self.shipping.get('country'):\n            params['shippingAddressCountry'] = self.shipping.get('country')\n        if self.shipping.get('state'):\n            params['shippingAddressState'] = self.shipping.get('state')\n        if self.shipping.get('city'):\n            params['shippingAddressCity'] = self.shipping.get('city')\n        if self.shipping.get('postal_code'):\n            params['shippingAddressPostalCode'] = self.shipping.get('postal_code')\n        if self.shipping.get('district'):\n            params['shippingAddressDistrict'] = self.shipping.get('district')\n        if self.shipping.get('street'):\n            params['shippingAddressStreet'] = self.shipping.get('street')\n        if self.shipping.get('number'):\n            params['shippingAddressNumber'] = self.shipping.get('number')\n        if self.shipping.get('complement'):\n            params['shippingAddressComplement'] = self.shipping.get('complement')\n\n        return params", "response": "Build a dictionary of all the parameters that are defined in the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndoes series of DB operations.", "response": "def db_manager(self):\n        \"\"\"\n        \" Do series of DB operations.\n        \"\"\"\n        rc_create = self.create_db()    # for first create\n        try:\n            self.load_db()  # load existing/factory\n        except Exception as e:\n            _logger.debug(\"*** %s\" % str(e))\n            try:\n                self.recover_db(self.backup_json_db_path)\n            except Exception:\n                pass\n        else:\n            if rc_create is True:\n                self.db_status = \"factory\"\n            else:\n                self.db_status = \"existing\"\n            return True\n\n        try:\n            self.load_db()  # load backup\n        except Exception as b:\n            _logger.debug(\"*** %s\" % str(b))\n            self.recover_db(self.factory_json_db_path)\n            self.load_db()  # load factory\n            self.db_status = \"factory\"\n        else:\n            self.db_status = \"backup\"\n        finally:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_db(self):\n        if self.db_type != \"json\":\n            raise RuntimeError(\"db_type only supports json now\")\n\n        if os.path.exists(self.json_db_path):\n            return False\n\n        if os.path.exists(self.factory_json_db_path):\n            with self.db_mutex:\n                shutil.copy2(\n                    self.factory_json_db_path, self.json_db_path)\n            return True\n\n        _logger.debug(\n            \"*** NO such file: %s\" % self.factory_json_db_path)\n        raise RuntimeError(\"No *.json.factory file\")", "response": "   Create a db file for model if there is no db."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recover_db(self, src_file):\n        with self.db_mutex:\n            try:\n                shutil.copy2(src_file, self.json_db_path)\n            except IOError as e:\n                _logger.debug(\"*** NO: %s file.\" % src_file)\n                raise e", "response": "Recover DB from src_file to self. json_db_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a xxxxx. backup. json.", "response": "def backup_db(self):\n        \"\"\"\n        \" Generate a xxxxx.backup.json.\n        \"\"\"\n        with self.db_mutex:\n            if os.path.exists(self.json_db_path):\n                try:\n                    shutil.copy2(self.json_db_path, self.backup_json_db_path)\n                except (IOError, OSError):\n                    _logger.debug(\"*** No file to copy.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_db(self):\n        try:\n            with open(self.json_db_path) as fp:\n                self.db = json.load(fp)\n        except Exception as e:\n            _logger.debug(\"*** Open JSON DB error.\")\n            raise e", "response": "Load json db as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_db(self):\n        with self.db_mutex:\n            if not isinstance(self.db, dict) and not isinstance(self.db, list):\n                return False\n            try:\n                with open(self.json_db_path, \"w\") as fp:\n                    json.dump(self.db, fp, indent=4)\n            except Exception as e:\n                # disk full or something.\n                _logger.debug(\"*** Write JSON DB to file error.\")\n                raise e\n\n            else:\n                self.sync()\n                return True", "response": "Save json db to file system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreserve a port and optionally wait for it to come up.", "response": "def reserve(self, location=None, force=False, wait_for_up=True, timeout=80):\n        \"\"\" Reserve port and optionally wait for port to come up.\n\n        :param location: port location as 'ip/module/port'. If None, the location will be taken from the configuration.\n        :param force: whether to revoke existing reservation (True) or not (False).\n        :param wait_for_up: True - wait for port to come up, False - return immediately.\n        :param timeout: how long (seconds) to wait for port to come up.\n        \"\"\"\n\n        if not location or is_local_host(location):\n            return\n\n        hostname, card, port = location.split('/')\n        chassis = self.root.hw.get_chassis(hostname)\n\n        # todo - test if port owned by me.\n        if force:\n            chassis.get_card(int(card)).get_port(int(port)).release()\n\n        try:\n            phy_port = chassis.get_card(int(card)).get_port(int(port))\n        except KeyError as _:\n            raise TgnError('Physical port {} unreachable'.format(location))\n        self.set_attributes(commit=True, connectedTo=phy_port.ref)\n\n        while self.get_attribute('connectedTo') == '::ixNet::OBJ-null':\n            time.sleep(1)\n\n        if wait_for_up:\n            self.wait_for_up(timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_up(self, timeout=40):\n\n        self.wait_for_states(timeout, 'up')\n        connectionStatus = self.get_attribute('connectionStatus').strip()\n        if connectionStatus.split(':')[0] != self.get_attribute('assignedTo').split(':')[0]:\n            raise TgnError('Failed to reach up state, port connection status is {} after {} seconds'.\n                           format(connectionStatus, timeout))", "response": "Wait until the port is up and running."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits until one of the requested states.", "response": "def wait_for_states(self, timeout=40, *states):\n        \"\"\" Wait until port reaches one of the requested states.\n\n        :param timeout: max time to wait for requested port states.\n        \"\"\"\n\n        state = self.get_attribute('state')\n        for _ in range(timeout):\n            if state in states:\n                return\n            time.sleep(1)\n            state = self.get_attribute('state')\n        raise TgnError('Failed to reach states {}, port state is {} after {} seconds'.format(states, state, timeout))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a latitude and longitude as used in GPS to OSGB grid coordinates.", "response": "def WGS84toOSGB36(lat, lon):\n    \"\"\" Accept latitude and longitude as used in GPS.\n    Return OSGB grid coordinates: eastings and northings.\n\n    Usage:\n    >>> from latlon_to_bng import WGS84toOSGB36\n    >>> WGS84toOSGB36(51.4778, -0.0014)\n    (538890.1053365842, 177320.49650700082)\n    >>> WGS84toOSGB36(53.50713, -2.71766)\n    (352500.19520169357, 401400.01483428996)\n    \"\"\"\n    # First convert to radians\n    # These are on the wrong ellipsoid currently: GRS80. (Denoted by _1)\n    lat_1 = lat*pi/180\n    lon_1 = lon*pi/180\n\n    # Want to convert to the Airy 1830 ellipsoid, which has the following:\n    # The GSR80 semi-major and semi-minor axes used for WGS84(m)\n    a_1, b_1 = 6378137.000, 6356752.3141\n    e2_1 = 1 - (b_1*b_1)/(a_1*a_1)  # The eccentricity of the GRS80 ellipsoid\n    nu_1 = a_1/sqrt(1-e2_1*sin(lat_1)**2)\n\n    # First convert to cartesian from spherical polar coordinates\n    H = 0  # Third spherical coord.\n    x_1 = (nu_1 + H)*cos(lat_1)*cos(lon_1)\n    y_1 = (nu_1 + H)*cos(lat_1)*sin(lon_1)\n    z_1 = ((1-e2_1)*nu_1 + H)*sin(lat_1)\n\n    # Perform Helmut transform (to go between GRS80 (_1) and Airy 1830 (_2))\n    s = 20.4894*10**-6  # The scale factor -1\n    # The translations along x,y,z axes respectively\n    tx, ty, tz = -446.448, 125.157, -542.060\n    # The rotations along x,y,z respectively, in seconds\n    rxs, rys, rzs = -0.1502, -0.2470, -0.8421\n    # In radians\n    rx, ry, rz = rxs*pi/(180*3600.), rys*pi/(180*3600.), rzs*pi/(180*3600.)\n    x_2 = tx + (1+s)*x_1 + (-rz)*y_1 + (ry)*z_1\n    y_2 = ty + (rz)*x_1 + (1+s)*y_1 + (-rx)*z_1\n    z_2 = tz + (-ry)*x_1 + (rx)*y_1 + (1+s)*z_1\n\n    # Back to spherical polar coordinates from cartesian\n    # Need some of the characteristics of the new ellipsoid\n    # The GSR80 semi-major and semi-minor axes used for WGS84(m)\n    a, b = 6377563.396, 6356256.909\n    e2 = 1 - (b*b)/(a*a)  # The eccentricity of the Airy 1830 ellipsoid\n    p = sqrt(x_2**2 + y_2**2)\n\n    # Lat is obtained by an iterative proceedure:\n    lat = atan2(z_2, (p*(1-e2)))  # Initial value\n    latold = 2*pi\n    while abs(lat - latold) > 10**-16:\n        lat, latold = latold, lat\n        nu = a/sqrt(1-e2*sin(latold)**2)\n        lat = atan2(z_2+e2*nu*sin(latold), p)\n\n    # Lon and height are then pretty easy\n    lon = atan2(y_2, x_2)\n    H = p/cos(lat) - nu\n\n    # E, N are the British national grid coordinates - eastings and northings\n    F0 = 0.9996012717  # scale factor on the central meridian\n    lat0 = 49*pi/180  # Latitude of true origin (radians)\n    lon0 = -2*pi/180  # Longtitude of true origin and central meridian (radians)\n    N0, E0 = -100000, 400000  # Northing & easting of true origin (m)\n    n = (a-b)/(a+b)\n\n    # meridional radius of curvature\n    rho = a*F0*(1-e2)*(1-e2*sin(lat)**2)**(-1.5)\n    eta2 = nu*F0/rho-1\n\n    M1 = (1 + n + (5/4)*n**2 + (5/4)*n**3) * (lat-lat0)\n    M2 = (3*n + 3*n**2 + (21/8)*n**3) * sin(lat-lat0) * cos(lat+lat0)\n    M3 = ((15/8)*n**2 + (15/8)*n**3) * sin(2*(lat-lat0)) * cos(2*(lat+lat0))\n    M4 = (35/24)*n**3 * sin(3*(lat-lat0)) * cos(3*(lat+lat0))\n\n    # meridional arc\n    M = b * F0 * (M1 - M2 + M3 - M4)\n\n    I = M + N0\n    II = nu*F0*sin(lat)*cos(lat)/2\n    III = nu*F0*sin(lat)*cos(lat)**3*(5 - tan(lat)**2 + 9*eta2)/24\n    IIIA = nu*F0*sin(lat)*cos(lat)**5*(61 - 58*tan(lat)**2 + tan(lat)**4)/720\n    IV = nu*F0*cos(lat)\n    V = nu*F0*cos(lat)**3*(nu/rho - tan(lat)**2)/6\n    VI = nu*F0*cos(lat)**5*(5 - 18*tan(lat)**2 + tan(lat)**4 + 14*eta2 - 58*eta2*tan(lat)**2)/120\n\n    N = I + II*(lon-lon0)**2 + III*(lon-lon0)**4 + IIIA*(lon-lon0)**6\n    E = E0 + IV*(lon-lon0) + V*(lon-lon0)**3 + VI*(lon-lon0)**5\n\n    # Job's a good'n.\n    return E, N"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, form=None, **kwargs):\n        context = self.get_context(**kwargs)\n        return self.render_to_response(context)", "response": "Returns the HttpResponse with the context data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_to_response(self, context):\n        self.setup_forms()\n        return TemplateResponse(\n            self.request, self.form_template,\n            context, current_app=self.admin_site.name)", "response": "Render the template and return a response ready to be displayed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing this method to build the django - xadmin context data for the template", "response": "def get_context(self, **kwargs):\n        \"\"\"Use this method to built context data for the template\n\n        Mix django wizard context data with django-xadmin context\n\n        \"\"\"\n        context = self.get_context_data(form=self.form_obj, **kwargs)\n        context.update(super(FormAdminView, self).get_context())\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n\n        print(\"\", file=sys.stderr)\n        print(\"Going to merge/convert RNF-FASTQ files.\", file=sys.stderr)\n        print(\"\", file=sys.stderr)\n        print(\"   mode:          \", self.mode, file=sys.stderr)\n        print(\"   input files:   \", \", \".join(self.input_files_fn), file=sys.stderr)\n        print(\"   output files:  \", \", \".join(self.output_files_fn), file=sys.stderr)\n        print(\"\", file=sys.stderr)\n\n        while len(self.i_files_weighted) > 0:\n            file_id = self.rng.randint(0, len(self.i_files_weighted) - 1)\n            for i in range(READS_IN_GROUP * self._reads_in_tuple):\n                if self.i_files_weighted[file_id].closed:\n                    del self.i_files_weighted[file_id]\n                    break\n\n                ln1 = self.i_files_weighted[file_id].readline()\n                ln2 = self.i_files_weighted[file_id].readline()\n                ln3 = self.i_files_weighted[file_id].readline()\n                ln4 = self.i_files_weighted[file_id].readline()\n\n                if ln1 == \"\" or ln2 == \"\" or ln3 == \"\" or ln4 == \"\":\n                    self.i_files_weighted[file_id].close()\n                    del self.i_files_weighted[file_id]\n                    break\n                assert ln1[0] == \"@\", ln1\n                assert ln3[0] == \"+\", ln3\n                self.output.save_read(ln1, ln2, ln3, ln4)\n        self.output.close()", "response": "This method is called by the merge method. It will run the merging process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether v is of type list dict or Config", "response": "def is_config_container(v):\n    \"\"\"\n    checks whether v is of type list,dict or Config\n    \"\"\"\n\n    cls = type(v)\n\n    return (\n        issubclass(cls, list) or\n        issubclass(cls, dict) or\n        issubclass(cls, Config)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the values specified in key_name are sane according to the config attributes defined as properties on this class.", "response": "def check(cls, cfg, key_name, path, parent_cfg=None):\n        \"\"\"\n        Checks that the config values specified in key name is\n        sane according to config attributes defined as properties\n        on this class\n        \"\"\"\n\n        attr = getattr(cls, key_name, None)\n\n        if path != \"\":\n            attr_full_name = \"%s.%s\" % (path, key_name)\n        else:\n            attr_full_name = key_name\n\n        if not attr:\n            # attribute specified by key_name is unknown, warn\n            raise vodka.exceptions.ConfigErrorUnknown(attr_full_name)\n\n        if attr.deprecated:\n            vodka.log.warn(\"[config deprecated] %s is being deprecated in version %s\" % (\n                attr_full_name,\n                attr.deprecated\n            ))\n\n        # prepare data\n        for prepare in attr.prepare:\n            cfg[key_name] = prepare(cfg[key_name])\n\n        if hasattr(cls, \"prepare_%s\" % key_name):\n            prepare = getattr(cls, \"prepare_%s\" % key_name)\n            cfg[key_name] = prepare(cfg[key_name], config=cfg)\n\n        value = cfg.get(key_name)\n\n        if isinstance(attr.expected_type, types.FunctionType):\n            # expected type holds a validator function\n            p, reason = attr.expected_type(value)\n            if not p:\n                # validator did not pass\n                raise vodka.exceptions.ConfigErrorValue(\n                    attr_full_name,\n                    attr,\n                    value,\n                    reason=reason\n                )\n\n        elif attr.expected_type != type(value):\n            # attribute type mismatch\n            raise vodka.exceptions.ConfigErrorType(\n                attr_full_name,\n                attr\n            )\n\n        if attr.choices and value not in attr.choices:\n            # attribute value not valid according to\n            # available choices\n            raise vodka.exceptions.ConfigErrorValue(\n                attr_full_name,\n                attr,\n                value\n            )\n\n        if hasattr(cls, \"validate_%s\" % key_name):\n            # custom validator for this attribute was found\n            validator = getattr(cls, \"validate_%s\" % key_name)\n            valid, reason = validator(value)\n            if not valid:\n                # custom validator failed\n                raise vodka.exceptions.ConfigErrorValue(\n                    attr_full_name,\n                    attr,\n                    value,\n                    reason=reason\n                )\n\n        num_crit = 0\n        num_warn = 0\n\n\n        if is_config_container(value) and attr.handler:\n            if type(value) == dict or issubclass(type(value), Config):\n                keys = list(value.keys())\n            elif type(value) == list:\n                keys = list(range(0, len(value)))\n            else:\n                return\n            for k in keys:\n                if not is_config_container(value[k]):\n                    continue\n                handler = attr.handler(k, value[k])\n                if issubclass(handler, Handler):\n                    h = handler\n                else:\n                    h = getattr(handler, \"Configuration\", None)\n\n                #h = getattr(attr.handler(k, value[k]), \"Configuration\", None)\n                if h:\n                    if type(k) == int and type(value[k]) == dict and value[k].get(\"name\"):\n                        _path = \"%s.%s\" % (\n                            attr_full_name, value[k].get(\"name\"))\n                    else:\n                        _path = \"%s.%s\" % (attr_full_name, k)\n                    _num_crit, _num_warn = h.validate(value[k], path=_path, nested=attr.nested, parent_cfg=cfg)\n                    h.finalize(\n                        value,\n                        k,\n                        value[k],\n                        attr=attr,\n                        attr_name=key_name,\n                        parent_cfg=cfg\n                    )\n                    num_crit += _num_crit\n                    num_warn += _num_warn\n\n        attr.finalize(cfg, key_name, value, num_crit=num_crit)\n\n        return (num_crit, num_warn)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attributes(cls):\n\n        for k in dir(cls):\n            v = getattr(cls, k)\n            if isinstance(v, Attribute):\n                yield k,v", "response": "Yields tuples for all attributes defined on this handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread from a config file.", "response": "def read(self, config_dir=None, clear=False, config_file=None):\n        \"\"\"\n        The munge Config's read function only allows to read from\n        a config directory, but we also want to be able to read\n        straight from a config file as well\n        \"\"\"\n\n        if config_file:\n            data_file = os.path.basename(config_file)\n            data_path = os.path.dirname(config_file)\n\n            if clear:\n                self.clear()\n\n            config = munge.load_datafile(data_file, data_path, default=None)\n\n            if not config:\n                raise IOError(\"Config file not found: %s\" % config_file)\n\n            munge.util.recursive_update(self.data, config)\n            self._meta_config_dir = data_path\n            return\n        else:\n            return super(Config, self).read(config_dir=config_dir, clear=clear)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a group from favorites. Removes a group from the current user s favorites. Returns the updated group record record.", "response": "def remove_group_from_favorites(self, id):\r\n        \"\"\"\r\n        Remove group from favorites.\r\n\r\n        Remove a group from the current user's favorites.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"the ID or SIS ID of the group to remove\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/self/favorites/groups/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/self/favorites/groups/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reset_course_favorites(self):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/self/favorites/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/self/favorites/courses\".format(**path), data=data, params=params, no_data=True)", "response": "Reset course favorites to the default list of enrolled courses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of conversations that can be sent to the current user.", "response": "def find_recipients_conversations(self, context=None, exclude=None, from_conversation_id=None, permissions=None, search=None, type=None, user_id=None):\r\n        \"\"\"\r\n        Find recipients.\r\n\r\n        Find valid recipients (users, courses and groups) that the current user\r\n        can send messages to. The /api/v1/search/recipients path is the preferred\r\n        endpoint, /api/v1/conversations/find_recipients is deprecated.\r\n        \r\n        Pagination is supported.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - search\r\n        \"\"\"Search terms used for matching users/courses/groups (e.g. \"bob smith\"). If\r\n        multiple terms are given (separated via whitespace), only results matching\r\n        all terms will be returned.\"\"\"\r\n        if search is not None:\r\n            params[\"search\"] = search\r\n\r\n        # OPTIONAL - context\r\n        \"\"\"Limit the search to a particular course/group (e.g. \"course_3\" or \"group_4\").\"\"\"\r\n        if context is not None:\r\n            params[\"context\"] = context\r\n\r\n        # OPTIONAL - exclude\r\n        \"\"\"Array of ids to exclude from the search. These may be user ids or\r\n        course/group ids prefixed with \"course_\" or \"group_\" respectively,\r\n        e.g. exclude[]=1&exclude[]=2&exclude[]=course_3\"\"\"\r\n        if exclude is not None:\r\n            params[\"exclude\"] = exclude\r\n\r\n        # OPTIONAL - type\r\n        \"\"\"Limit the search just to users or contexts (groups/courses).\"\"\"\r\n        if type is not None:\r\n            self._validate_enum(type, [\"user\", \"context\"])\r\n            params[\"type\"] = type\r\n\r\n        # OPTIONAL - user_id\r\n        \"\"\"Search for a specific user id. This ignores the other above parameters,\r\n        and will never return more than one result.\"\"\"\r\n        if user_id is not None:\r\n            params[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - from_conversation_id\r\n        \"\"\"When searching by user_id, only users that could be normally messaged by\r\n        this user will be returned. This parameter allows you to specify a\r\n        conversation that will be referenced for a shared context -- if both the\r\n        current user and the searched user are in the conversation, the user will\r\n        be returned. This is used to start new side conversations.\"\"\"\r\n        if from_conversation_id is not None:\r\n            params[\"from_conversation_id\"] = from_conversation_id\r\n\r\n        # OPTIONAL - permissions\r\n        \"\"\"Array of permission strings to be checked for each matched context (e.g.\r\n        \"send_messages\"). This argument determines which permissions may be\r\n        returned in the response; it won't prevent contexts from being returned if\r\n        they don't grant the permission(s).\"\"\"\r\n        if permissions is not None:\r\n            params[\"permissions\"] = permissions\r\n\r\n        self.logger.debug(\"GET /api/v1/conversations/find_recipients with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/conversations/find_recipients\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all courses. Returns a list of all courses that are visible in the public index.", "response": "def list_all_courses(self, open_enrollment_only=None, public_only=None, search=None):\r\n        \"\"\"\r\n        List all courses.\r\n\r\n        List all courses visible in the public index\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - search\r\n        \"\"\"Search terms used for matching users/courses/groups (e.g. \"bob smith\"). If\r\n        multiple terms are given (separated via whitespace), only results matching\r\n        all terms will be returned.\"\"\"\r\n        if search is not None:\r\n            params[\"search\"] = search\r\n\r\n        # OPTIONAL - public_only\r\n        \"\"\"Only return courses with public content. Defaults to false.\"\"\"\r\n        if public_only is not None:\r\n            params[\"public_only\"] = public_only\r\n\r\n        # OPTIONAL - open_enrollment_only\r\n        \"\"\"Only return courses that allow self enrollment. Defaults to false.\"\"\"\r\n        if open_enrollment_only is not None:\r\n            params[\"open_enrollment_only\"] = open_enrollment_only\r\n\r\n        self.logger.debug(\"GET /api/v1/search/all_courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/search/all_courses\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_communication_channel(self, user_id, communication_channel_type, communication_channel_address, communication_channel_token=None, skip_confirmation=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - communication_channel[address]\r\n        \"\"\"An email address or SMS number. Not required for \"push\" type channels.\"\"\"\r\n        data[\"communication_channel[address]\"] = communication_channel_address\r\n\r\n        # REQUIRED - communication_channel[type]\r\n        \"\"\"The type of communication channel.\r\n        \r\n        In order to enable push notification support, the server must be\r\n        properly configured (via sns.yml) to communicate with Amazon\r\n        Simple Notification Services, and the developer key used to create\r\n        the access token from this request must have an SNS ARN configured on\r\n        it.\"\"\"\r\n        self._validate_enum(communication_channel_type, [\"email\", \"sms\", \"push\"])\r\n        data[\"communication_channel[type]\"] = communication_channel_type\r\n\r\n        # OPTIONAL - communication_channel[token]\r\n        \"\"\"A registration id, device token, or equivalent token given to an app when\r\n        registering with a push notification provider. Only valid for \"push\" type channels.\"\"\"\r\n        if communication_channel_token is not None:\r\n            data[\"communication_channel[token]\"] = communication_channel_token\r\n\r\n        # OPTIONAL - skip_confirmation\r\n        \"\"\"Only valid for site admins and account admins making requests; If true, the channel is\r\n        automatically validated and no confirmation email or SMS is sent.\r\n        Otherwise, the user must respond to a confirmation message to confirm the\r\n        channel.\"\"\"\r\n        if skip_confirmation is not None:\r\n            data[\"skip_confirmation\"] = skip_confirmation\r\n\r\n        self.logger.debug(\"POST /api/v1/users/{user_id}/communication_channels with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/users/{user_id}/communication_channels\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new communication channel for the specified user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a communication channel. Delete an existing communication channel.", "response": "def delete_communication_channel_id(self, id, user_id):\r\n        \"\"\"\r\n        Delete a communication channel.\r\n\r\n        Delete an existing communication channel.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/{user_id}/communication_channels/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/{user_id}/communication_channels/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a literal from a string representation of a set of key - value pairs.", "response": "def from_str(cls, string):\n        \"\"\"\n        Creates a literal from a string\n\n        Parameters\n        ----------\n        string : str\n            If the string starts with '!', it's interpreted as a negated variable\n\n        Returns\n        -------\n        caspo.core.literal.Literal\n            Created object instance\n        \"\"\"\n        if string[0] == '!':\n            signature = -1\n            variable = string[1:]\n        else:\n            signature = 1\n            variable = string\n\n        return cls(variable, signature)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_signature(func):\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if kwargs:\n            args = args, kwargs\n\n        if len(args) is 1:\n            args = args[0]\n\n        return func(args)\n\n    return wrapper", "response": "Decorator that converts args and kwargs to single item tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove certain queries from a list of SQL commands.", "response": "def filter_commands(commands, invalid_query_starts=('DROP', 'UNLOCK', 'LOCK')):\n    \"\"\"\n    Remove particular queries from a list of SQL commands.\n\n    :param commands: List of SQL commands\n    :param invalid_query_starts: Type of SQL command to remove\n    :return: Filtered list of SQL commands\n    \"\"\"\n    commands_with_drops = len(commands)\n    filtered_commands = [c for c in commands if not c.startswith(invalid_query_starts)]\n    if commands_with_drops - len(filtered_commands) > 0:\n        print(\"\\t\" + str(invalid_query_starts) + \" commands removed\", commands_with_drops - len(filtered_commands))\n    return filtered_commands"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepare_sql(sql, add_semicolon=True, invalid_starts=('--', '/*', '*/', ';')):\n    return PrepareSQL(sql, add_semicolon, invalid_starts).prepared", "response": "Wrapper method for PrepareSQL class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _split_sql(self, sql):\n        bookends = (\"\\n\", \";\", \"--\", \"/*\", \"*/\")\n        last_bookend_found = None\n        start = 0\n\n        while start <= len(sql):\n            results = self._get_next_occurrence(sql, start, bookends)\n            if results is None:\n                yield (last_bookend_found, None, sql[start:])\n                start = len(sql) + 1\n            else:\n                (end, bookend) = results\n                yield (last_bookend_found, bookend, sql[start:end])\n                start = end + len(bookend)\n                last_bookend_found = bookend", "response": "Split the SQL string into two tuples of beginning and closing bookends and contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds next occurence of one of the needles in the haystack.", "response": "def _get_next_occurrence(haystack, offset, needles):\n        \"\"\"\n        Find next occurence of one of the needles in the haystack\n\n        :return: tuple of (index, needle found)\n             or: None if no needle was found\"\"\"\n        # make map of first char to full needle (only works if all needles\n        # have different first characters)\n        firstcharmap = dict([(n[0], n) for n in needles])\n        firstchars = firstcharmap.keys()\n        while offset < len(haystack):\n            if haystack[offset] in firstchars:\n                possible_needle = firstcharmap[haystack[offset]]\n                if haystack[offset:offset + len(possible_needle)] == possible_needle:\n                    return offset, possible_needle\n            offset += 1\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export_content_courses(self, course_id, export_type, skip_notifications=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - export_type\r\n        \"\"\"\"common_cartridge\":: Export the contents of the course in the Common Cartridge (.imscc) format\r\n        \"qti\":: Export quizzes from a course in the QTI format\r\n        \"zip\":: Export files from a course, group, or user in a zip file\"\"\"\r\n        self._validate_enum(export_type, [\"common_cartridge\", \"qti\", \"zip\"])\r\n        data[\"export_type\"] = export_type\r\n\r\n        # OPTIONAL - skip_notifications\r\n        \"\"\"Don't send the notifications about the export to the user. Default: false\"\"\"\r\n        if skip_notifications is not None:\r\n            data[\"skip_notifications\"] = skip_notifications\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/content_exports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/content_exports\".format(**path), data=data, params=params, single_item=True)", "response": "This method exports the content of a course group or user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef export_content_groups(self, group_id, export_type, skip_notifications=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - export_type\r\n        \"\"\"\"common_cartridge\":: Export the contents of the course in the Common Cartridge (.imscc) format\r\n        \"qti\":: Export quizzes from a course in the QTI format\r\n        \"zip\":: Export files from a course, group, or user in a zip file\"\"\"\r\n        self._validate_enum(export_type, [\"common_cartridge\", \"qti\", \"zip\"])\r\n        data[\"export_type\"] = export_type\r\n\r\n        # OPTIONAL - skip_notifications\r\n        \"\"\"Don't send the notifications about the export to the user. Default: false\"\"\"\r\n        if skip_notifications is not None:\r\n            data[\"skip_notifications\"] = skip_notifications\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/content_exports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/content_exports\".format(**path), data=data, params=params, single_item=True)", "response": "This API endpoint allows you to export the contents of a course group or user in a zip file. Returns the url of the export."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports content. Begin a content export job for a course, group, or user. You can use the {api:ProgressController#show Progress API} to track the progress of the export. The migration's progress is linked to with the _progress_url_ value. When the export completes, use the {api:ContentExportsApiController#show Show content export} endpoint to retrieve a download URL for the exported content.", "response": "def export_content_users(self, user_id, export_type, skip_notifications=None):\r\n        \"\"\"\r\n        Export content.\r\n\r\n        Begin a content export job for a course, group, or user.\r\n        \r\n        You can use the {api:ProgressController#show Progress API} to track the\r\n        progress of the export. The migration's progress is linked to with the\r\n        _progress_url_ value.\r\n        \r\n        When the export completes, use the {api:ContentExportsApiController#show Show content export} endpoint\r\n        to retrieve a download URL for the exported content.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - export_type\r\n        \"\"\"\"common_cartridge\":: Export the contents of the course in the Common Cartridge (.imscc) format\r\n        \"qti\":: Export quizzes from a course in the QTI format\r\n        \"zip\":: Export files from a course, group, or user in a zip file\"\"\"\r\n        self._validate_enum(export_type, [\"common_cartridge\", \"qti\", \"zip\"])\r\n        data[\"export_type\"] = export_type\r\n\r\n        # OPTIONAL - skip_notifications\r\n        \"\"\"Don't send the notifications about the export to the user. Default: false\"\"\"\r\n        if skip_notifications is not None:\r\n            data[\"skip_notifications\"] = skip_notifications\r\n\r\n        self.logger.debug(\"POST /api/v1/users/{user_id}/content_exports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/users/{user_id}/content_exports\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a Y / n question prompt and return a boolean", "response": "def ask(question, no_input=False):\n    \"\"\"Display a Y/n question prompt, and return a boolean\"\"\"\n    if no_input:\n        return True\n    else:\n        input_ = input('%s [Y/n] ' % question)\n        input_ = input_.strip().lower()\n        if input_ in ('y', 'yes', ''):\n            return True\n        if input_ in ('n', 'no'):\n            return False\n        print('Invalid selection')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender a jinja template", "response": "def render_template(template_name, context):\n    \"\"\"Render a jinja template\"\"\"\n    return Environment(\n        loader=PackageLoader('remarkable')\n    ).get_template(template_name).render(context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a template directory", "response": "def render_template_directory(deck, arguments):\n    \"\"\"Render a template directory\"\"\"\n    output_directory = dir_name_from_title(deck.title)\n\n    if os.path.exists(output_directory):\n        if sys.stdout.isatty():\n            if ask(\n                '%s already exists, shall I delete it?' % output_directory,\n                arguments.get('--noinput')\n            ):\n                shutil.rmtree(output_directory)\n        else:\n            shutil.rmtree(output_directory)\n\n    # copy support files to output directory\n    template_directory_path = (\n        '%s/templates/%s' %\n        (remarkable.__path__[0], deck.presentation_type)\n    )\n    shutil.copytree(\n        template_directory_path,\n        output_directory,\n    )\n\n    # copy resources\n    if os.path.exists('resources'):\n        log.info('Copying resources')\n        shutil.copytree('resources', '%s/resources' % output_directory)\n    else:\n        log.info('No resources to copy')\n\n    # render template\n    template_filename = '%s/index.html' % deck.presentation_type\n    html = render_template(template_filename, deck.json)\n\n    # write index to output directory\n    index_filename = '%s/index.html' % output_directory\n    write_file(index_filename, html)\n\n    return output_directory"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_proxies(self, ajax_endpoint):\n    \n        ''' request the xml object '''\n        proxy_xml = requests.get(ajax_endpoint)\n        print(proxy_xml.content)\n        root = etree.XML(proxy_xml.content)\n        quote = root.xpath('quote')[0]\n        \n        ''' extract the raw text from the body of the quote tag '''\n        raw_text = quote.text\n        \n        ''' eliminate the stuff we don't need '''\n        proxy_data = raw_text.split('You will definitely love it! Give it a try!</td></tr>')[1]\n        \n        ''' get rid of the </table> at the end of proxy_data '''\n        proxy_data = proxy_data[:-len('</table>')]\n        \n        ''' split proxy_data into rows '''\n        table_rows = proxy_data.split('<tr>')\n        \n        ''' convert each row into a Proxy object '''\n        for row in table_rows:\n            \n            ''' get rid of the </tr> at the end of each row '''\n            row = row[:-len('</tr>')]\n        \n            ''' split each row into a list of items '''\n            items = row.split('<td>')\n            \n            ''' sometimes we get weird lists containing only an empty string '''\n            if len(items) != 7:\n                continue\n    \n            ''' we'll use this to remove the </td> from the end of each item '''\n            tdlen = len('</td>')\n    \n            ''' create proxy dict '''\n            proxy = Proxy(\n                ip=items[1][:-tdlen],\n                port=int(items[2][:-tdlen]),\n                https=bool(items[3][:-tdlen]),\n                latency=int(items[4][:-tdlen]),\n                last_checked=items[5][:-tdlen],\n                country=items[6][:-tdlen],\n            )\n            yield proxy", "response": "extracts the proxies from the xml object and yields them as a generator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the proxy passes the filters", "response": "def _passes_filter(self, proxy):\n\n\n        ''' avoid redudant and space consuming calls to 'self' '''\n        \n        ''' validate proxy based on provided filters '''\n        if self.allowed_countries is not None and proxy['country'] not in self.allowed_countries:\n            return False\n        if self.denied_countries is not None and  proxy['country'] in self.denied_countries:\n            return False\n        if self.https_only and proxy['https'] == False:\n            return False\n\n        if not self.all_ports and str(proxy.port) not in self.ports:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting the endpoints from the raw HTML document", "response": "def _extract_ajax_endpoints(self):\n    \n        ''' make a GET request to freeproxylists.com/elite.html '''\n        url = '/'.join([DOC_ROOT, ELITE_PAGE])\n        response = requests.get(url)\n    \n        ''' extract the raw HTML doc from the response '''\n        raw_html = response.text\n    \n        ''' convert raw html into BeautifulSoup object '''\n        soup = BeautifulSoup(raw_html, 'lxml')\n\n        for url in soup.select('table tr td table tr td a'):\n            if 'elite #' in url.text:\n                yield '%s/load_elite_d%s' % (DOC_ROOT, url['href'].lstrip('elite/'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating over all mappings and return the next pair of mappings.", "response": "def iteritems(self):\n        \"\"\"\n        Iterates over all mappings\n\n\n        Yields\n        ------\n        (int,Mapping)\n            The next pair (index, mapping)\n        \"\"\"\n        for m in self.mappings:\n            yield self.indexes[m.clause][m.target], m"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a mapping from a string representation of a set of key - value pairs.", "response": "def from_str(cls, string):\n        \"\"\"\n        Creates a mapping from a string\n\n        Parameters\n        ----------\n        string : str\n            String of the form `target<-clause` where `clause` is a valid string for :class:`caspo.core.clause.Clause`\n\n        Returns\n        -------\n        caspo.core.mapping.Mapping\n            Created object instance\n        \"\"\"\n        if \"<-\" not in string:\n            raise ValueError(\"Cannot parse the given string to a mapping\")\n\n        target, clause_str = string.split('<-')\n\n        return cls(Clause.from_str(clause_str), target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists user logins. Returns a list of user s logins for the given account.", "response": "def list_user_logins_users(self, user_id):\r\n        \"\"\"\r\n        List user logins.\r\n\r\n        Given a user ID, return that user's logins for the given account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/logins with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/logins\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_user_login(self, user_id, account_id, login_unique_id, login_authentication_provider_id=None, login_integration_id=None, login_password=None, login_sis_user_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - user[id]\r\n        \"\"\"The ID of the user to create the login for.\"\"\"\r\n        data[\"user[id]\"] = user_id\r\n\r\n        # REQUIRED - login[unique_id]\r\n        \"\"\"The unique ID for the new login.\"\"\"\r\n        data[\"login[unique_id]\"] = login_unique_id\r\n\r\n        # OPTIONAL - login[password]\r\n        \"\"\"The new login's password.\"\"\"\r\n        if login_password is not None:\r\n            data[\"login[password]\"] = login_password\r\n\r\n        # OPTIONAL - login[sis_user_id]\r\n        \"\"\"SIS ID for the login. To set this parameter, the caller must be able to\r\n        manage SIS permissions on the account.\"\"\"\r\n        if login_sis_user_id is not None:\r\n            data[\"login[sis_user_id]\"] = login_sis_user_id\r\n\r\n        # OPTIONAL - login[integration_id]\r\n        \"\"\"Integration ID for the login. To set this parameter, the caller must be able to\r\n        manage SIS permissions on the account. The Integration ID is a secondary\r\n        identifier useful for more complex SIS integrations.\"\"\"\r\n        if login_integration_id is not None:\r\n            data[\"login[integration_id]\"] = login_integration_id\r\n\r\n        # OPTIONAL - login[authentication_provider_id]\r\n        \"\"\"The authentication provider this login is associated with. Logins\r\n        associated with a specific provider can only be used with that provider.\r\n        Legacy providers (LDAP, CAS, SAML) will search for logins associated with\r\n        them, or unassociated logins. New providers will only search for logins\r\n        explicitly associated with them. This can be the integer ID of the\r\n        provider, or the type of the provider (in which case, it will find the\r\n        first matching provider).\"\"\"\r\n        if login_authentication_provider_id is not None:\r\n            data[\"login[authentication_provider_id]\"] = login_authentication_provider_id\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/logins with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/logins\".format(**path), data=data, params=params, no_data=True)", "response": "Create a new user login for an existing user in the given account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit_user_login(self, id, account_id, login_integration_id=None, login_password=None, login_sis_user_id=None, login_unique_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - login[unique_id]\r\n        \"\"\"The new unique ID for the login.\"\"\"\r\n        if login_unique_id is not None:\r\n            data[\"login[unique_id]\"] = login_unique_id\r\n\r\n        # OPTIONAL - login[password]\r\n        \"\"\"The new password for the login. Can only be set by an admin user if admins\r\n        are allowed to change passwords for the account.\"\"\"\r\n        if login_password is not None:\r\n            data[\"login[password]\"] = login_password\r\n\r\n        # OPTIONAL - login[sis_user_id]\r\n        \"\"\"SIS ID for the login. To set this parameter, the caller must be able to\r\n        manage SIS permissions on the account.\"\"\"\r\n        if login_sis_user_id is not None:\r\n            data[\"login[sis_user_id]\"] = login_sis_user_id\r\n\r\n        # OPTIONAL - login[integration_id]\r\n        \"\"\"Integration ID for the login. To set this parameter, the caller must be able to\r\n        manage SIS permissions on the account. The Integration ID is a secondary\r\n        identifier useful for more complex SIS integrations.\"\"\"\r\n        if login_integration_id is not None:\r\n            data[\"login[integration_id]\"] = login_integration_id\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{account_id}/logins/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{account_id}/logins/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Edit a user login."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_user_login(self, id, user_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/{user_id}/logins/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/{user_id}/logins/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Delete a user login. Delete a user login."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting QuizQuestions in a quiz or a submission. Returns the list of QuizQuestions in this quiz or a submission.", "response": "def list_questions_in_quiz_or_submission(self, quiz_id, course_id, quiz_submission_attempt=None, quiz_submission_id=None):\r\n        \"\"\"\r\n        List questions in a quiz or a submission.\r\n\r\n        Returns the list of QuizQuestions in this quiz.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - quiz_submission_id\r\n        \"\"\"If specified, the endpoint will return the questions that were presented\r\n        for that submission. This is useful if the quiz has been modified after\r\n        the submission was created and the latest quiz version's set of questions\r\n        does not match the submission's.\r\n        NOTE: you must specify quiz_submission_attempt as well if you specify this\r\n        parameter.\"\"\"\r\n        if quiz_submission_id is not None:\r\n            params[\"quiz_submission_id\"] = quiz_submission_id\r\n\r\n        # OPTIONAL - quiz_submission_attempt\r\n        \"\"\"The attempt of the submission you want the questions for.\"\"\"\r\n        if quiz_submission_attempt is not None:\r\n            params[\"quiz_submission_attempt\"] = quiz_submission_attempt\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/quizzes/{quiz_id}/questions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/questions\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_single_quiz_question(self, quiz_id, course_id, question_answers=None, question_correct_comments=None, question_incorrect_comments=None, question_neutral_comments=None, question_points_possible=None, question_position=None, question_question_name=None, question_question_text=None, question_question_type=None, question_quiz_group_id=None, question_text_after_answers=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - question[question_name]\r\n        \"\"\"The name of the question.\"\"\"\r\n        if question_question_name is not None:\r\n            data[\"question[question_name]\"] = question_question_name\r\n\r\n        # OPTIONAL - question[question_text]\r\n        \"\"\"The text of the question.\"\"\"\r\n        if question_question_text is not None:\r\n            data[\"question[question_text]\"] = question_question_text\r\n\r\n        # OPTIONAL - question[quiz_group_id]\r\n        \"\"\"The id of the quiz group to assign the question to.\"\"\"\r\n        if question_quiz_group_id is not None:\r\n            data[\"question[quiz_group_id]\"] = question_quiz_group_id\r\n\r\n        # OPTIONAL - question[question_type]\r\n        \"\"\"The type of question. Multiple optional fields depend upon the type of question to be used.\"\"\"\r\n        if question_question_type is not None:\r\n            self._validate_enum(question_question_type, [\"calculated_question\", \"essay_question\", \"file_upload_question\", \"fill_in_multiple_blanks_question\", \"matching_question\", \"multiple_answers_question\", \"multiple_choice_question\", \"multiple_dropdowns_question\", \"numerical_question\", \"short_answer_question\", \"text_only_question\", \"true_false_question\"])\r\n            data[\"question[question_type]\"] = question_question_type\r\n\r\n        # OPTIONAL - question[position]\r\n        \"\"\"The order in which the question will be displayed in the quiz in relation to other questions.\"\"\"\r\n        if question_position is not None:\r\n            data[\"question[position]\"] = question_position\r\n\r\n        # OPTIONAL - question[points_possible]\r\n        \"\"\"The maximum amount of points received for answering this question correctly.\"\"\"\r\n        if question_points_possible is not None:\r\n            data[\"question[points_possible]\"] = question_points_possible\r\n\r\n        # OPTIONAL - question[correct_comments]\r\n        \"\"\"The comment to display if the student answers the question correctly.\"\"\"\r\n        if question_correct_comments is not None:\r\n            data[\"question[correct_comments]\"] = question_correct_comments\r\n\r\n        # OPTIONAL - question[incorrect_comments]\r\n        \"\"\"The comment to display if the student answers incorrectly.\"\"\"\r\n        if question_incorrect_comments is not None:\r\n            data[\"question[incorrect_comments]\"] = question_incorrect_comments\r\n\r\n        # OPTIONAL - question[neutral_comments]\r\n        \"\"\"The comment to display regardless of how the student answered.\"\"\"\r\n        if question_neutral_comments is not None:\r\n            data[\"question[neutral_comments]\"] = question_neutral_comments\r\n\r\n        # OPTIONAL - question[text_after_answers]\r\n        \"\"\"no description\"\"\"\r\n        if question_text_after_answers is not None:\r\n            data[\"question[text_after_answers]\"] = question_text_after_answers\r\n\r\n        # OPTIONAL - question[answers]\r\n        \"\"\"no description\"\"\"\r\n        if question_answers is not None:\r\n            data[\"question[answers]\"] = question_answers\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/questions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/questions\".format(**path), data=data, params=params, single_item=True)", "response": "Creates a new single quiz question."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nescape special characters &lt and < and > to HTML - safe sequences.", "response": "def escape(s, quote=False):\n    \"\"\"Replace special characters \"&\", \"<\" and \">\" to HTML-safe sequences.  If\n    the optional flag `quote` is `True`, the quotation mark character is\n    also translated.\n\n    There is a special handling for `None` which escapes to an empty string.\n\n    :param s: the string to escape.\n    :param quote: set to true to also escape double quotes.\n    \"\"\"\n    if s is None:\n        return ''\n    if hasattr(s, '__html__'):\n        return s.__html__()\n    if not isinstance(s, (text_type, binary_type)):\n        s = text_type(s)\n    if isinstance(s, binary_type):\n        try:\n            s.decode('ascii')\n        except:\n            s = s.decode('utf-8', 'replace')\n    s = s.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n    if quote:\n        s = s.replace('\"', \"&quot;\")\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, action, data={}, headers={}, method='GET'):\n        data = self.merge(data, {'user': self.username, 'password': self.password, 'api_id': self.apiId})\n        return Transport.request(self, action, data, headers, method)", "response": "This method is called by the client to send a request to every incoming request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a message to the specified list of entries.", "response": "def sendMessage(self, to, message, extra={}):\n        \"\"\"\n        If the 'to' parameter is a single entry, we will parse it into a list.\n        We will merge default values into the request data and the extra parameters\n        provided by the user.\n        \"\"\"\n        to = to if isinstance(to, list) else [to]\n        to = [str(i) for i in to]\n\n        data = {'to': ','.join(to), 'text': message}\n        data = self.merge(data, {'callback': 7, 'mo': 1}, extra)\n\n        try:\n            content = self.parseLegacy(self.request('http/sendmsg', data));\n        except ClickatellError as e:\n            # The error that gets catched here will only be raised if the request was for\n            # one number only. We can safely assume we are only dealing with a single response\n            # here.\n            content = {'error': e.message, 'errorCode': e.code, 'To': to[0]}\n\n        # Force all responses to behave like a list, for consistency\n        content = content if isinstance(content, list) else [content]\n        result = []\n\n        # Sending messages will also result in a \"stable\" response. The reason\n        # for this is that we can't actually know if the request failed or not...a message\n        # that could not be delivered is different from a failed request...so errors are returned\n        # per message. In the case of global failures (like authentication) all messages will contain\n        # the specific error as part of the response body.\n        for index, entry in enumerate(content):\n            entry = self.merge({'ID': False, 'To': to[index], 'error': False, 'errorCode': False}, entry)\n            result.append({\n                'id': entry['ID'],\n                'destination': entry['To'],\n                'error': entry['error'],\n                'errorCode': entry['errorCode']\n            });\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stopMessage(self, apiMsgId):\n        content =  self.parseLegacy(self.request('http/delmsg', {'apimsgid': apiMsgId}))\n\n        return {\n            'id': content['ID'],\n            'status': content['Status'],\n            'description': self.getStatus(content['Status'])\n        }", "response": "Stop a message from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the charge of a message.", "response": "def getMessageCharge(self, apiMsgId):\n        \"\"\"\n        See parent method for documentation\n        \"\"\"\n        content = self.parseLegacy(self.request('http/getmsgcharge', {'apimsgid': apiMsgId}))\n\n        return {\n            'id': apiMsgId,\n            'status': content['status'],\n            'description': self.getStatus(content['status']),\n            'charge': float(content['charge'])\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef routeCoverage(self, msisdn):\n        try:\n            content = self.parseLegacy(self.request('utils/routeCoverage', {'msisdn': msisdn}))\n\n            return {\n                'routable': True,\n                'destination': msisdn,\n                'charge': float(content['Charge'])\n            }\n        except Exception:\n            # If we encounter any error, we will treat it like it's \"not covered\"\n            # TODO perhaps catch different types of exceptions so we can isolate certain global exceptions\n            # like authentication\n            return {\n                'routable': False,\n                'destination': msisdn,\n                'charge': 0\n            }", "response": "Returns a dict of the route coverage information for a given msisdn."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that the end_date value is less than the start_date value.", "response": "def clean_publish_dates(self):\n        \"\"\"\n        If an end_date value is provided, the start_date must be less.\n        \"\"\"\n        if self.end_date:\n            if not self.start_date:\n                raise ValidationError(\"\"\"The End Date requires a Start Date value.\"\"\")\n            elif self.end_date <= self.start_date:\n                raise ValidationError(\"\"\"The End Date must not precede the Start Date.\"\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that all values in the video list are integer ids.", "response": "def clean_videos(self):\n        \"\"\"\n        Validates that all values in the video list are integer ids and removes all None values.\n        \"\"\"\n        if self.videos:\n            self.videos = [int(v) for v in self.videos if v is not None and is_valid_digit(v)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean_super_features(self):\n        if self.super_features:\n            self.super_features = [int(sf) for sf in self.super_features\n                                   if sf is not None and is_valid_digit(sf)]", "response": "Removes any null & non - integer values from the super feature list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the special coverage record.", "response": "def save(self, *args, **kwargs):\n        \"\"\"Saving ensures that the slug, if not set, is set to the slugified name.\"\"\"\n        self.clean()\n\n        if not self.slug:\n            self.slug = slugify(self.name)\n\n        super(SpecialCoverage, self).save(*args, **kwargs)\n\n        if self.query and self.query != {}:\n            # Always save and require client to filter active date range\n            self._save_percolator()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _save_percolator(self):\n        index = Content.search_objects.mapping.index\n        query_filter = self.get_content(published=False).to_dict()\n\n        q = {}\n\n        if \"query\" in query_filter:\n            q = {\"query\": query_filter.get(\"query\", {})}\n        else:\n            # We don't know how to save this\n            return\n\n        # We'll need this data, to decide which special coverage section to use\n        q[\"sponsored\"] = bool(self.tunic_campaign_id)\n        # Elasticsearch v1.4 percolator \"field_value_factor\" does not\n        # support missing fields, so always need to include\n\n        q[\"start_date\"] = self.start_date\n        # NOTE: set end_date to datetime.max if special coverage has no end date\n        # (i.e. is a neverending special coverage)\n        q[\"end_date\"] = self.end_date if self.end_date else datetime.max.replace(tzinfo=pytz.UTC)\n\n        # Elasticsearch v1.4 percolator range query does not support DateTime range queries\n        # (PercolateContext.nowInMillisImpl is not implemented).\n        if q[\"start_date\"]:\n            q['start_date_epoch'] = datetime_to_epoch_seconds(q[\"start_date\"])\n        if q[\"end_date\"]:\n            q['end_date_epoch'] = datetime_to_epoch_seconds(q[\"end_date\"])\n\n        # Store manually included IDs for percolator retrieval scoring (boost\n        # manually included content).\n        if self.query:\n            q['included_ids'] = self.query.get('included_ids', [])\n\n        es.index(\n            index=index,\n            doc_type=\".percolator\",\n            body=q,\n            id=self.es_id\n        )", "response": "Save the query field as an elasticsearch percolator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contents(self):\n        if not hasattr(self, \"_content\"):\n            self._content = self.get_content()\n        return self._content", "response": "returns the content of the object in a dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_pinned_content(self):\n        if \"query\" in self.query:\n            q = self.query[\"query\"]\n        else:\n            q = self.query\n        if \"pinned_ids\" in q:\n            return bool(len(q.get(\"pinned_ids\", [])))\n        return False", "response": "determines if the there is a pinned object in the search\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the name of the custom special coverage template we want.", "response": "def custom_template_name(self):\n        \"\"\"\n        Returns the path for the custom special coverage template we want.\n        \"\"\"\n        base_path = getattr(settings, \"CUSTOM_SPECIAL_COVERAGE_PATH\", \"special_coverage/custom\")\n        if base_path is None:\n            base_path = \"\"\n        return \"{0}/{1}_custom.html\".format(\n            base_path, self.slug.replace(\"-\", \"_\")\n        ).lstrip(\"/\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef train_token(self, word, count):\n        if word not in self.tokens:\n            self.tokens[word] = 0\n\n        self.tokens[word] += count\n        self.tally += count", "response": "Train a particular token in the log."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef untrain_token(self, word, count):\n        if word not in self.tokens:\n            return\n\n        # If we're trying to untrain more tokens than we have, we end at 0\n        count = min(count, self.tokens[word])\n\n        self.tokens[word] -= count\n        self.tally -= count", "response": "Untrains a particular token in the corpus."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync_apps(self, connection, app_labels):\n        \"Runs the old syncdb-style operation on a list of app_labels.\"\n        cursor = connection.cursor()\n\n        try:\n            # Get a list of already installed *models* so that references work right.\n            tables = connection.introspection.table_names(cursor)\n            created_models = set()\n\n            # Build the manifest of apps and models that are to be synchronized\n            all_models = [\n                (app_config.label,\n                 router.get_migratable_models(app_config, connection.alias, include_auto_created=False))\n                for app_config in apps.get_app_configs()\n                if app_config.models_module is not None and app_config.label in app_labels\n                ]\n\n            def model_installed(model):\n                opts = model._meta\n                converter = connection.introspection.table_name_converter\n                # Note that if a model is unmanaged we short-circuit and never try to install it\n                return not (\n                    (converter(opts.db_table) in tables) or\n                    (opts.auto_created and converter(opts.auto_created._meta.db_table) in tables)\n                )\n\n            manifest = OrderedDict(\n                (app_name, list(filter(model_installed, model_list)))\n                for app_name, model_list in all_models\n            )\n\n            # Create the tables for each model\n            if self.verbosity >= 1:\n                self.stdout.write(\"  Creating tables...\\n\")\n\n            with transaction.atomic(using=connection.alias, savepoint=connection.features.can_rollback_ddl):\n\n                with connection.schema_editor() as editor:\n                    editor.execute(\"CREATE SCHEMA {}\".format(settings.POSTGRES_TEMPLATE_SCHEMA))\n                    statements = editor.connection.ops.prepare_sql_script(CLONE_SCHEMA)\n                    for statement in statements:\n                        editor.execute(statement, params=None)\n\n                schema_deferred_sql = {}\n\n                with connection.schema_editor() as editor:\n                    schema_model = apps.get_model(settings.POSTGRES_SCHEMA_MODEL)\n                    editor.create_model(schema_model, verbosity=self.verbosity)\n                    schema_deferred_sql.update(editor.schema_deferred_sql)\n                    editor.schema_deferred_sql = {}\n                    created_models.add(schema_model)\n\n                for app_name, model_list in manifest.items():\n                    for model in model_list:\n                        if not model._meta.can_migrate(connection):\n                            continue\n                        if model in created_models:\n                            continue  # probably schema model\n                        if self.verbosity >= 3:\n                            self.stdout.write(\n                                \"    Processing %s.%s model\\n\" % (app_name, model._meta.object_name)\n                            )\n                        with connection.schema_editor() as editor:\n                            editor.schema_deferred_sql.update(schema_deferred_sql)\n                            editor.create_model(model, verbosity=self.verbosity)\n                            schema_deferred_sql.update(editor.schema_deferred_sql)\n                            editor.schema_deferred_sql = {}\n                            created_models.add(model)\n\n                if self.verbosity >= 1:\n                    self.stdout.write(\"\\n    Running deferred SQL...\\n\")\n                with connection.schema_editor() as editor:\n                    editor.schema_deferred_sql = schema_deferred_sql\n\n        finally:\n            cursor.close()\n\n        return created_models", "response": "Runs the old syncdb - style operation on a list of app_labels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_database_rows(self, tables=None, database=None):\n        # Get table data and columns from source database\n        source = database if database else self.database\n        tables = tables if tables else self.tables\n\n        # Get database select queries\n        commands = self._get_select_commands(source, tables)\n\n        # Execute select commands\n        return self._execute_select_commands(source, commands)", "response": "Retrieve a dictionary of table keys and list of rows values for every table."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_select_commands(self, source, tables):\n        # Create dictionary of select queries\n        row_queries = {tbl: self.select_all(tbl, execute=False) for tbl in\n                       tqdm(tables, total=len(tables), desc='Getting {0} select queries'.format(source))}\n\n        # Convert command strings into lists of commands\n        for tbl, command in row_queries.items():\n            if isinstance(command, str):\n                row_queries[tbl] = [command]\n\n        # Pack commands into list of tuples\n        return [(tbl, cmd) for tbl, cmds in row_queries.items() for cmd in cmds]", "response": "Create select queries for all of the tables from a source database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes select queries for all of the tables from a source database.", "response": "def _execute_select_commands(self, source, commands):\n        \"\"\"Execute select queries for all of the tables from a source database.\"\"\"\n        rows = {}\n        for tbl, command in tqdm(commands, total=len(commands), desc='Executing {0} select queries'.format(source)):\n            # Add key to dictionary\n            if tbl not in rows:\n                rows[tbl] = []\n            rows[tbl].extend(self.fetch(command, commit=True))\n        self._commit()\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_database_columns(self, tables=None, database=None):\n        # Get table data and columns from source database\n        source = database if database else self.database\n        tables = tables if tables else self.tables\n        return {tbl: self.get_columns(tbl) for tbl in tqdm(tables, total=len(tables),\n                                                           desc='Getting {0} columns'.format(source))}", "response": "Retrieve a dictionary of columns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving dictionary of insert statements to be executed.", "response": "def _get_insert_commands(self, rows, cols):\n        \"\"\"Retrieve dictionary of insert statements to be executed.\"\"\"\n        # Get insert queries\n        insert_queries = {}\n        for table in tqdm(list(rows.keys()), total=len(list(rows.keys())), desc='Getting insert rows queries'):\n            insert_queries[table] = {}\n            _rows = rows.pop(table)\n            _cols = cols.pop(table)\n\n            if len(_rows) > 1:\n                insert_queries[table]['insert_many'] = self.insert_many(table, _cols, _rows, execute=False)\n            elif len(_rows) == 1:\n                insert_queries[table]['insert'] = self.insert(table, _cols, _rows, execute=False)\n        return insert_queries"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies multiple tables from one database to another.", "response": "def copy_database_structure(self, source, destination, tables=None):\n        \"\"\"Copy multiple tables from one database to another.\"\"\"\n        # Change database to source\n        self.change_db(source)\n\n        if tables is None:\n            tables = self.tables\n\n        # Change database to destination\n        self.change_db(destination)\n        for t in tqdm(tables, total=len(tables), desc='Copying {0} table structure'.format(source)):\n            self.copy_table_structure(source, destination, t)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy a table from one database to another.", "response": "def copy_table_structure(self, source, destination, table):\n        \"\"\"\n        Copy a table from one database to another.\n\n        :param source: Source database\n        :param destination: Destination database\n        :param table: Table name\n        \"\"\"\n        self.execute('CREATE TABLE {0}.{1} LIKE {2}.{1}'.format(destination, wrap(table), source))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy the data from one database to another.", "response": "def copy_database_data(self, source, destination, optimized=False):\n        \"\"\"\n        Copy the data from one database to another.\n\n        Retrieve existing data from the source database and insert that data into the destination database.\n        \"\"\"\n        # Change database to source\n        self.enable_printing = False\n        self.change_db(source)\n        tables = self.tables\n\n        # Copy database data by executing INSERT and SELECT commands in a single query\n        if optimized:\n            self._copy_database_data_serverside(source, destination, tables)\n\n        # Generate and execute SELECT and INSERT commands\n        else:\n            self._copy_database_data_clientside(tables, source, destination)\n\n        self.enable_printing = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _copy_database_data_serverside(self, source, destination, tables):\n        for table in tqdm(tables, total=len(tables), desc='Copying table data (optimized)'):\n            self.execute('INSERT INTO {0}.{1} SELECT * FROM {2}.{1}'.format(destination, wrap(table), source))", "response": "Copy data from a source database to a destination database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _copy_database_data_clientside(self, tables, source, destination):\n        # Retrieve database rows\n        rows = self.get_database_rows(tables, source)\n\n        # Retrieve database columns\n        cols = self.get_database_columns(tables, source)\n\n        # Validate rows and columns\n        for r in list(rows.keys()):\n            assert r in tables\n        for c in list(cols.keys()):\n            assert c in tables\n\n        # Change database to destination\n        self.change_db(destination)\n\n        # Get insert queries\n        insert_queries = self._get_insert_commands(rows, cols)\n\n        # Execute insert queries\n        self._execute_insert_commands(insert_queries)", "response": "Copy the data from a table into another table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_database(self, source, destination):\n        print('\\tCopying database {0} structure and data to database {1}'.format(source, destination))\n        with Timer('\\nSuccess! Copied database {0} to {1} in '.format(source, destination)):\n            # Create destination database if it does not exist\n            if destination in self.databases:\n                self.truncate_database(destination)\n            # Truncate database if it does exist\n            else:\n                self.create_database(destination)\n\n            # Copy database structure and data\n            self.change_db(source)\n            tables = self.tables\n\n            # Change database to destination\n            self.change_db(destination)\n            print('\\n')\n            _enable_printing = self.enable_printing\n            self.enable_printing = False\n\n            # Copy tables structure\n            for table in tqdm(tables, total=len(tables), desc='Copying {0} table structures'.format(source)):\n                self.execute('CREATE TABLE {0}.{1} LIKE {2}.{1}'.format(destination, wrap(table), source))\n\n            # Copy tables data\n            for table in tqdm(tables, total=len(tables), desc='Copying {0} table data'.format(source)):\n                self.execute('INSERT INTO {0}.{1} SELECT * FROM {2}.{1}'.format(destination, wrap(table), source))\n            self.enable_printing = _enable_printing", "response": "Copy a database structure and data to a new database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recode_curesim_reads(\n        curesim_fastq_fo,\n        rnf_fastq_fo,\n        fai_fo,\n        genome_id,\n        number_of_read_tuples=10**9,\n        recode_random=False,\n    ):\n        \"\"\"Recode CuReSim output FASTQ file to the RNF-compatible output FASTQ file.\n\n\t\tArgs:\n\t\t\tcuresim_fastq_fo (file object): File object of CuReSim FASTQ file.\n\t\t\tfastq_rnf_fo (file object): File object of RNF FASTQ.\n\t\t\tfai_fo (file object): File object for FAI file of the reference genome.\n\t\t\tgenome_id (int): RNF genome ID to be used.\n\t\t\tnumber_of_read_tuples (int): Expected number of read tuples (to estimate number of digits in RNF).\n\t\t\trecode_random (bool): Recode random reads.\n\n\t\tRaises:\n\t\t\tValueError\n\t\t\"\"\"\n\n        curesim_pattern = re.compile('@(.*)_([0-9]+)_([0-9]+)_([0-9]+)_([0-9]+)_([0-9]+)_([0-9]+)_([0-9]+)')\n        \"\"\"\n\t\t\tCuReSim read name format\n\n\t\t\t@<#1>_<#2>_<#3>_<#4>_<#5>_<#6>_<#7>_<#8>\n\n\t\t\t1: contig name\n\t\t\t2: original position\n\t\t\t3: strand (0=forward;1=reverse)\n\t\t\t4: random read (0=non-random;1=random)\n\t\t\t5: number of insertions\n\t\t\t6: number of deletions\n\t\t\t7: number of substitution\n\t\t\t8: read number (unique within a genome)\n\t\t\"\"\"\n\n        max_seq_len = 0\n\n        fai_index = rnftools.utils.FaIdx(fai_fo=fai_fo)\n        read_tuple_id_width = len(format(number_of_read_tuples, 'x'))\n\n        fq_creator = rnftools.rnfformat.FqCreator(\n            fastq_fo=rnf_fastq_fo,\n            read_tuple_id_width=read_tuple_id_width,\n            genome_id_width=2,\n            chr_id_width=fai_index.chr_id_width,\n            coor_width=fai_index.coor_width,\n            info_reads_in_tuple=True,\n            info_simulator=\"curesim\",\n        )\n\n        # parsing FQ file\n        read_tuple_id = 0\n\n        i = 0\n        for line in curesim_fastq_fo:\n            if i % 4 == 0:\n                m = curesim_pattern.search(line)\n                if m is None:\n                    rnftools.utils.error(\n                        \"Read '{}' was not generated by CuReSim.\".format(line[1:]), program=\"RNFtools\",\n                        subprogram=\"MIShmash\", exception=ValueError\n                    )\n\n                contig_name = m.group(1)\n                start_pos = int(m.group(2))\n                direction = \"R\" if int(m.group(3)) else \"F\"\n                random = bool(m.group(4))\n                ins_nb = int(m.group(5))\n                del_nb = int(m.group(6))\n                subst_nb = int(m.group(7))\n                rd_id = int(m.group(8))\n\n                end_pos = start_pos - 1 - ins_nb + del_nb\n\n                chr_id = 0\n\n                random = contig_name[:4] == \"rand\"\n\n            # TODO: uncomment when the chromosome naming bug in curesim is corrected\n            # chr_id = self.dict_chr_ids[contig_name] if self.dict_chr_ids!={} else \"0\"\n\n            elif i % 4 == 1:\n                bases = line.strip()\n                end_pos += len(bases)\n\n                if recode_random:\n                    left = 0\n                    right = 0\n                else:\n                    left = start_pos + 1\n                    right = end_pos\n\n                segment = rnftools.rnfformat.Segment(\n                    genome_id=genome_id,\n                    chr_id=chr_id,\n                    direction=direction,\n                    left=left,\n                    right=right,\n                )\n\n            elif i % 4 == 2:\n                pass\n\n            elif i % 4 == 3:\n                qualities = line.strip()\n\n                if random == recode_random:\n                    fq_creator.add_read(\n                        read_tuple_id=read_tuple_id,\n                        bases=bases,\n                        qualities=qualities,\n                        segments=[segment],\n                    )\n\n                read_tuple_id += 1\n\n            i += 1\n\n        fq_creator.flush_read_tuple()", "response": "Recode CuReSim output FASTQ file to RNF - compatible output FASTQ file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the configuration directory.", "response": "def get_config_dir(program='', system_wide=False):\n\t'''Get the configuration directory.\n\n\tGet the configuration directories, optionally for a specific program.\n\n\tArgs:\n\t\t\tprogram\t(str) : The name of the program whose configuration directories have to be found.\n\t\t\tsystem_wide (bool): Gets the system-wide configuration directories.\n\n\tReturns:\n\t\t\tlist: A list of all matching configuration directories found.\n\t'''\n\n\tconfig_homes = []\n\n\tif system_wide:\n\t\tif os.name == 'nt':\n\t\t\tconfig_homes.append(\n\t\t\t\twinreg.ExpandEnvironmentStrings('%PROGRAMDATA%'))\n\n\t\telse:\n\t\t\tconfig_homes.append('/etc')\n\t\t\tconfig_homes.append('/etc/xdg')\n\n\t\t\tif os.name == 'darwin':\n\t\t\t\tconfig_homes.append('/Library')\n\n\telse:\n\t\tif os.name == 'nt':\n\t\t\timport winreg\n\t\t\tconfig_homes.append(\n\t\t\t\twinreg.ExpandEnvironmentStrings('%LOCALAPPDATA%'))\n\t\t\tconfig_homes.append(\n\t\t\t\tos.path.join(\n\t\t\t\t\twinreg.ExpandEnvironmentStrings('%APPDATA%'),\n\t\t\t\t\t'Roaming'))\n\t\telse:\n\t\t\tif os.getenv('XDG_CONFIG_HOME'):\n\t\t\t\tconfig_homes.append(os.getenv('XDG_CONFIG_HOME'))\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\tfrom xdg import BaseDirectory\n\t\t\t\t\tconfig_homes.append(BaseDirectory.xdg_config_home)\n\t\t\t\texcept ImportError:\n\t\t\t\t\tconfig_homes.append(os.path.expanduser('~/.config'))\n\n\t\t\t\tconfig_homes.append(os.path.expanduser('~'))\n\n\t\t\t\tif os.name == 'darwin':\n\t\t\t\t\tconfig_homes.append(os.path.expanduser('~/Library'))\n\n\tif program:\n\t\tdef __find_homes(app, dirs):\n\n\t\t\thomes = []\n\n\t\t\tfor home in dirs:\n\t\t\t\tif os.path.isdir(os.path.join(home, app)):\n\t\t\t\t\thomes.append(os.path.join(home, app))\n\n\t\t\t\tif os.path.isdir(os.path.join(home, '.' + app)):\n\t\t\t\t\thomes.append(os.path.join(home, '.' + app))\n\n\t\t\t\tif os.path.isdir(os.path.join(home, app + '.d')):\n\t\t\t\t\thomes.append(os.path.join(home, app + '.d'))\n\n\t\t\treturn homes\n\n\t\tapp_homes = __find_homes(program, config_homes)\n\n\t\t# Special Cases\n\n\t\tif program == 'vim':\n\t\t\tapp_homes.extend(__find_homes('vimfiles', config_homes))\n\n\t\telif program == 'chrome':\n\t\t\tapp_homes.extend(__find_homes('google-chrome', config_homes))\n\n\t\telif program in ['firefox', 'thunderbird']:\n\t\t\tapp_homes.extend(\n\t\t\t\t__find_homes(\n\t\t\t\t\tprogram, [\n\t\t\t\t\t\tos.path.expanduser('~/.mozilla')]))\n\n\t\treturn app_homes\n\n\treturn config_homes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the configuration file for a given program.", "response": "def get_config_file(program, system_wide=False):\n\t'''Get the configuration file for a program.\n\n\tGets the configuration file for a given program, assuming it stores it in\n\ta standard location. See also :func:`get_config_dir()`.\n\n\tArgs:\n\t\t\tprogram\t (str): The program for which to get the configuration file.\n\t\t\tsystem_wide (bool):Whether to get the system-wide file for the program.\n\n\tReturns:\n\t\t\tlist: A list of all matching configuration files found.\n\t'''\n\n\tprogram_config_homes = get_config_dir(program, system_wide)\n\tconfig_homes = get_config_dir(system_wide=system_wide)\n\tconfig_files = []\n\n\tfor home in config_homes:\n\t\tfor sub in os.listdir(home):\n\t\t\tif os.path.isfile(os.path.join(home, sub)):\n\t\t\t\tif sub.startswith(program):\n\t\t\t\t\tconfig_files.append(os.path.join(home, sub))\n\n\tif not program.startswith('.'):\n\t\tconfig_files.extend(get_config_file('.' + program, system_wide))\n\n\tfor home in program_config_homes:\n\t\tfor sub in os.listdir(home):\n\t\t\tif os.path.isfile(os.path.join(home, sub)\n\t\t\t\t\t\t\t  ) and sub.startswith(program):\n\t\t\t\tconfig_files.append(os.path.join(home, sub))\n\n\treturn config_files"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of tasks that were changed recently.", "response": "def get_tasks_changed_since(self, since):\n        \"\"\" Returns a list of tasks that were changed recently.\"\"\"\n        changed_tasks = []\n\n        for task in self.client.filter_tasks({'status': 'pending'}):\n            if task.get(\n                'modified',\n                task.get(\n                    'entry',\n                    datetime.datetime(2000, 1, 1).replace(tzinfo=pytz.utc)\n                )\n            ) >= since:\n                changed_tasks.append(task)\n\n        return changed_tasks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evergreen(self, included_channel_ids=None, excluded_channel_ids=None, **kwargs):\n        eqs = self.search(**kwargs)\n        eqs = eqs.filter(Evergreen())\n        if included_channel_ids:\n            eqs = eqs.filter(VideohubChannel(included_ids=included_channel_ids))\n        if excluded_channel_ids:\n            eqs = eqs.filter(VideohubChannel(excluded_ids=excluded_channel_ids))\n        return eqs", "response": "Search containing any evergreen piece of Content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evergreen_video(self, **kwargs):\n        eqs = self.evergreen(**kwargs)\n        eqs = eqs.filter(VideohubVideo())\n        return eqs", "response": "Filter evergreen content to exclusively video content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef instant_articles(self, **kwargs):\n        eqs = self.search(**kwargs).sort('-last_modified', '-published')\n        return eqs.filter(InstantArticle())", "response": "Returns a QuerySet containing all instant articles published for this locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sponsored(self, **kwargs):\n        eqs = self.search(**kwargs)\n        eqs = eqs.filter(AllSponsored())\n        published_offset = getattr(settings, \"RECENT_SPONSORED_OFFSET_HOURS\", None)\n        if published_offset:\n            now = timezone.now()\n            eqs = eqs.filter(\n                Published(\n                    after=now - timezone.timedelta(hours=published_offset),\n                    before=now\n                )\n            )\n        return eqs", "response": "Search containing any sponsored pieces of Content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, **kwargs):\n        search_query = super(ContentManager, self).search()\n\n        if \"query\" in kwargs:\n            search_query = search_query.query(\"match\", _all=kwargs.get(\"query\"))\n        else:\n            search_query = search_query.sort('-published', '-last_modified')\n\n        # Right now we have \"Before\", \"After\" (datetimes),\n        # and \"published\" (a boolean). Should simplify this in the future.\n        if \"before\" in kwargs or \"after\" in kwargs:\n            published_filter = Published(before=kwargs.get(\"before\"), after=kwargs.get(\"after\"))\n            search_query = search_query.filter(published_filter)\n        else:\n            # TODO: kill this \"published\" param. it sucks\n            if kwargs.get(\"published\", True) and \"status\" not in kwargs:\n                published_filter = Published()\n                search_query = search_query.filter(published_filter)\n\n        if \"status\" in kwargs:\n            search_query = search_query.filter(Status(kwargs[\"status\"]))\n\n        if \"excluded_ids\" in kwargs:\n            exclusion_filter = ~es_filter.Ids(values=kwargs.get(\"excluded_ids\", []))\n            search_query = search_query.filter(exclusion_filter)\n\n        tag_filter = Tags(kwargs.get(\"tags\", []))\n        search_query = search_query.filter(tag_filter)\n\n        author_filter = Authors(kwargs.get(\"authors\", []))\n        search_query = search_query.filter(author_filter)\n\n        feature_type_filter = FeatureTypes(kwargs.get(\"feature_types\", []))\n        search_query = search_query.filter(feature_type_filter)\n\n        # Is this good enough? Are we even using this feature at all?\n        types = kwargs.pop(\"types\", [])\n        if types:\n            search_query._doc_type = types\n        return search_query", "response": "Search using ElasticSearch returning an elasticsearch queryset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_obj_class(self, obj_type):\n\n        if obj_type in IxnObject.str_2_class:\n            if type(IxnObject.str_2_class[obj_type]) is dict:\n                if self.obj_type() in IxnObject.str_2_class[obj_type]:\n                    return IxnObject.str_2_class[obj_type][self.obj_type()]\n                elif self.obj_parent().obj_type() in IxnObject.str_2_class[obj_type]:\n                    return IxnObject.str_2_class[obj_type][self.obj_parent().obj_type()]\n            else:\n                return IxnObject.str_2_class[obj_type]\n        return IxnObject", "response": "Returns the object class based on the object type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the value of an attribute.", "response": "def get_attribute(self, attribute):\n        \"\"\"\n        :param attribute: requested attributes.\n        :return: attribute value.\n        :raise TgnError: if invalid attribute.\n        \"\"\"\n        value = self.api.getAttribute(self.obj_ref(), attribute)\n        # IXN returns '::ixNet::OK' for invalid attributes. We want error.\n        if value == '::ixNet::OK':\n            raise TgnError(self.ref + ' does not have attribute ' + attribute)\n        return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting list attribute value.", "response": "def get_list_attribute(self, attribute):\n        \"\"\"\n        :return: attribute value as Python list.\n        \"\"\"\n        list_attribute = self.api.getListAttribute(self.obj_ref(), attribute)\n        # IXN returns '::ixNet::OK' for invalid attributes. We want error.\n        if list_attribute == ['::ixNet::OK']:\n            raise TgnError(self.ref + ' does not have attribute ' + attribute)\n        return list_attribute"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_children(self, *types):\n\n        children_objs = OrderedDict()\n        if not types:\n            types = self.get_all_child_types(self.obj_ref())\n        for child_type in types:\n            children_list = self.api.getList(self.obj_ref(), child_type)\n            children_objs.update(self._build_children_objs(child_type, children_list))\n        return list(children_objs.values())", "response": "Read ( getList ) children from IXN."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the child object with the requested object type and sequence number.", "response": "def get_child_static(self, objType, seq_number=None):\n        \"\"\" Returns IxnObject representing the requested child without reading it from the IXN.\n\n        Statically build the child object reference based on the requested object type and sequence number and build\n        the IxnObject with this calculated object reference.\n        Ideally we would prefer to never use this function and always read the child dynamically but this has huge\n        impact on performance so we use the static approach wherever possible.\n        \"\"\"\n        child_obj_ref = self.obj_ref() + '/' + objType\n        if seq_number:\n            child_obj_ref += ':' + str(seq_number)\n        child_obj = self.get_object_by_ref(child_obj_ref)\n        child_obj_type = self.get_obj_class(objType)\n        return child_obj if child_obj else child_obj_type(parent=self, objType=objType, objRef=child_obj_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_ref_indices(self):\n\n        ixn_obj = self\n        ref_indices = []\n        while ixn_obj != ixn_obj.root:\n            ref_indices.append(ixn_obj.ref.split(':')[-1])\n            ixn_obj = ixn_obj.parent\n        return ref_indices[::-1]", "response": "Returns a list of all indices in object reference."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_conversations(self, filter=None, filter_mode=None, include=None, include_all_conversation_ids=None, interleave_submissions=None, scope=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"When set, only return conversations of the specified type. For example,\r\n        set to \"unread\" to return only conversations that haven't been read.\r\n        The default behavior is to return all non-archived conversations (i.e.\r\n        read and unread).\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"unread\", \"starred\", \"archived\"])\r\n            params[\"scope\"] = scope\r\n\r\n        # OPTIONAL - filter\r\n        \"\"\"When set, only return conversations for the specified courses, groups\r\n        or users. The id should be prefixed with its type, e.g. \"user_123\" or\r\n        \"course_456\". Can be an array (by setting \"filter[]\") or single value\r\n        (by setting \"filter\")\"\"\"\r\n        if filter is not None:\r\n            params[\"filter\"] = filter\r\n\r\n        # OPTIONAL - filter_mode\r\n        \"\"\"When filter[] contains multiple filters, combine them with this mode,\r\n        filtering conversations that at have at least all of the contexts (\"and\")\r\n        or at least one of the contexts (\"or\")\"\"\"\r\n        if filter_mode is not None:\r\n            self._validate_enum(filter_mode, [\"and\", \"or\", \"default or\"])\r\n            params[\"filter_mode\"] = filter_mode\r\n\r\n        # OPTIONAL - interleave_submissions\r\n        \"\"\"(Obsolete) Submissions are no\r\n        longer linked to conversations. This parameter is ignored.\"\"\"\r\n        if interleave_submissions is not None:\r\n            params[\"interleave_submissions\"] = interleave_submissions\r\n\r\n        # OPTIONAL - include_all_conversation_ids\r\n        \"\"\"Default is false. If true,\r\n        the top-level element of the response will be an object rather than\r\n        an array, and will have the keys \"conversations\" which will contain the\r\n        paged conversation data, and \"conversation_ids\" which will contain the\r\n        ids of all conversations under this scope/filter in the same order.\"\"\"\r\n        if include_all_conversation_ids is not None:\r\n            params[\"include_all_conversation_ids\"] = include_all_conversation_ids\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"\"participant_avatars\":: Optionally include an \"avatar_url\" key for each user participanting in the conversation\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"participant_avatars\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/conversations with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/conversations\".format(**path), data=data, params=params, all_pages=True)", "response": "Returns a list of conversations for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_conversation(self, body, recipients, attachment_ids=None, context_code=None, filter=None, filter_mode=None, group_conversation=None, media_comment_id=None, media_comment_type=None, mode=None, scope=None, subject=None, user_note=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - recipients\r\n        \"\"\"An array of recipient ids. These may be user ids or course/group ids\r\n        prefixed with \"course_\" or \"group_\" respectively, e.g.\r\n        recipients[]=1&recipients[]=2&recipients[]=course_3\"\"\"\r\n        data[\"recipients\"] = recipients\r\n\r\n        # OPTIONAL - subject\r\n        \"\"\"The subject of the conversation. This is ignored when reusing a\r\n        conversation. Maximum length is 255 characters.\"\"\"\r\n        if subject is not None:\r\n            data[\"subject\"] = subject\r\n\r\n        # REQUIRED - body\r\n        \"\"\"The message to be sent\"\"\"\r\n        data[\"body\"] = body\r\n\r\n        # OPTIONAL - group_conversation\r\n        \"\"\"Defaults to false. If true, this will be a group conversation (i.e. all\r\n        recipients may see all messages and replies). If false, individual private\r\n        conversations will be started with each recipient. Must be set false if the\r\n        number of recipients is over the set maximum (default is 100).\"\"\"\r\n        if group_conversation is not None:\r\n            data[\"group_conversation\"] = group_conversation\r\n\r\n        # OPTIONAL - attachment_ids\r\n        \"\"\"An array of attachments ids. These must be files that have been previously\r\n        uploaded to the sender's \"conversation attachments\" folder.\"\"\"\r\n        if attachment_ids is not None:\r\n            data[\"attachment_ids\"] = attachment_ids\r\n\r\n        # OPTIONAL - media_comment_id\r\n        \"\"\"Media comment id of an audio of video file to be associated with this\r\n        message.\"\"\"\r\n        if media_comment_id is not None:\r\n            data[\"media_comment_id\"] = media_comment_id\r\n\r\n        # OPTIONAL - media_comment_type\r\n        \"\"\"Type of the associated media file\"\"\"\r\n        if media_comment_type is not None:\r\n            self._validate_enum(media_comment_type, [\"audio\", \"video\"])\r\n            data[\"media_comment_type\"] = media_comment_type\r\n\r\n        # OPTIONAL - user_note\r\n        \"\"\"Will add a faculty journal entry for each recipient as long as the user\r\n        making the api call has permission, the recipient is a student and\r\n        faculty journals are enabled in the account.\"\"\"\r\n        if user_note is not None:\r\n            data[\"user_note\"] = user_note\r\n\r\n        # OPTIONAL - mode\r\n        \"\"\"Determines whether the messages will be created/sent synchronously or\r\n        asynchronously. Defaults to sync, and this option is ignored if this is a\r\n        group conversation or there is just one recipient (i.e. it must be a bulk\r\n        private message). When sent async, the response will be an empty array\r\n        (batch status can be queried via the {api:ConversationsController#batches batches API})\"\"\"\r\n        if mode is not None:\r\n            self._validate_enum(mode, [\"sync\", \"async\"])\r\n            data[\"mode\"] = mode\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"unread\", \"starred\", \"archived\"])\r\n            data[\"scope\"] = scope\r\n\r\n        # OPTIONAL - filter\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter is not None:\r\n            data[\"filter\"] = filter\r\n\r\n        # OPTIONAL - filter_mode\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter_mode is not None:\r\n            self._validate_enum(filter_mode, [\"and\", \"or\", \"default or\"])\r\n            data[\"filter_mode\"] = filter_mode\r\n\r\n        # OPTIONAL - context_code\r\n        \"\"\"The course or group that is the context for this conversation. Same format\r\n        as courses or groups in the recipients argument.\"\"\"\r\n        if context_code is not None:\r\n            data[\"context_code\"] = context_code\r\n\r\n        self.logger.debug(\"POST /api/v1/conversations with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/conversations\".format(**path), data=data, params=params, no_data=True)", "response": "Create a new private conversation with the given body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_single_conversation(self, id, auto_mark_as_read=None, filter=None, filter_mode=None, interleave_submissions=None, scope=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - interleave_submissions\r\n        \"\"\"(Obsolete) Submissions are no\r\n        longer linked to conversations. This parameter is ignored.\"\"\"\r\n        if interleave_submissions is not None:\r\n            params[\"interleave_submissions\"] = interleave_submissions\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"unread\", \"starred\", \"archived\"])\r\n            params[\"scope\"] = scope\r\n\r\n        # OPTIONAL - filter\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter is not None:\r\n            params[\"filter\"] = filter\r\n\r\n        # OPTIONAL - filter_mode\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter_mode is not None:\r\n            self._validate_enum(filter_mode, [\"and\", \"or\", \"default or\"])\r\n            params[\"filter_mode\"] = filter_mode\r\n\r\n        # OPTIONAL - auto_mark_as_read\r\n        \"\"\"Default true. If true, unread\r\n        conversations will be automatically marked as read. This will default\r\n        to false in a future API release, so clients should explicitly send\r\n        true if that is the desired behavior.\"\"\"\r\n        if auto_mark_as_read is not None:\r\n            params[\"auto_mark_as_read\"] = auto_mark_as_read\r\n\r\n        self.logger.debug(\"GET /api/v1/conversations/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/conversations/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Returns a single conversation for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edit_conversation(self, id, conversation_starred=None, conversation_subscribed=None, conversation_workflow_state=None, filter=None, filter_mode=None, scope=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - conversation[workflow_state]\r\n        \"\"\"Change the state of this conversation\"\"\"\r\n        if conversation_workflow_state is not None:\r\n            self._validate_enum(conversation_workflow_state, [\"read\", \"unread\", \"archived\"])\r\n            data[\"conversation[workflow_state]\"] = conversation_workflow_state\r\n\r\n        # OPTIONAL - conversation[subscribed]\r\n        \"\"\"Toggle the current user's subscription to the conversation (only valid for\r\n        group conversations). If unsubscribed, the user will still have access to\r\n        the latest messages, but the conversation won't be automatically flagged\r\n        as unread, nor will it jump to the top of the inbox.\"\"\"\r\n        if conversation_subscribed is not None:\r\n            data[\"conversation[subscribed]\"] = conversation_subscribed\r\n\r\n        # OPTIONAL - conversation[starred]\r\n        \"\"\"Toggle the starred state of the current user's view of the conversation.\"\"\"\r\n        if conversation_starred is not None:\r\n            data[\"conversation[starred]\"] = conversation_starred\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"unread\", \"starred\", \"archived\"])\r\n            data[\"scope\"] = scope\r\n\r\n        # OPTIONAL - filter\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter is not None:\r\n            data[\"filter\"] = filter\r\n\r\n        # OPTIONAL - filter_mode\r\n        \"\"\"Used when generating \"visible\" in the API response. See the explanation\r\n        under the {api:ConversationsController#index index API action}\"\"\"\r\n        if filter_mode is not None:\r\n            self._validate_enum(filter_mode, [\"and\", \"or\", \"default or\"])\r\n            data[\"filter_mode\"] = filter_mode\r\n\r\n        self.logger.debug(\"PUT /api/v1/conversations/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/conversations/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Updates the attributes of a single conversation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd recipients to an existing conversation. Returns the full response with the newly added message.", "response": "def add_recipients(self, id, recipients):\r\n        \"\"\"\r\n        Add recipients.\r\n\r\n        Add recipients to an existing group conversation. Response is similar to\r\n        the GET/show action, except that only includes the\r\n        latest message (e.g. \"joe was added to the conversation by bob\")\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - recipients\r\n        \"\"\"An array of recipient ids. These may be user ids or course/group ids\r\n        prefixed with \"course_\" or \"group_\" respectively, e.g.\r\n        recipients[]=1&recipients[]=2&recipients[]=course_3\"\"\"\r\n        data[\"recipients\"] = recipients\r\n\r\n        self.logger.debug(\"POST /api/v1/conversations/{id}/add_recipients with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/conversations/{id}/add_recipients\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_message(self, id, body, attachment_ids=None, included_messages=None, media_comment_id=None, media_comment_type=None, recipients=None, user_note=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - body\r\n        \"\"\"The message to be sent.\"\"\"\r\n        data[\"body\"] = body\r\n\r\n        # OPTIONAL - attachment_ids\r\n        \"\"\"An array of attachments ids. These must be files that have been previously\r\n        uploaded to the sender's \"conversation attachments\" folder.\"\"\"\r\n        if attachment_ids is not None:\r\n            data[\"attachment_ids\"] = attachment_ids\r\n\r\n        # OPTIONAL - media_comment_id\r\n        \"\"\"Media comment id of an audio of video file to be associated with this\r\n        message.\"\"\"\r\n        if media_comment_id is not None:\r\n            data[\"media_comment_id\"] = media_comment_id\r\n\r\n        # OPTIONAL - media_comment_type\r\n        \"\"\"Type of the associated media file.\"\"\"\r\n        if media_comment_type is not None:\r\n            self._validate_enum(media_comment_type, [\"audio\", \"video\"])\r\n            data[\"media_comment_type\"] = media_comment_type\r\n\r\n        # OPTIONAL - recipients\r\n        \"\"\"no description\"\"\"\r\n        if recipients is not None:\r\n            data[\"recipients\"] = recipients\r\n\r\n        # OPTIONAL - included_messages\r\n        \"\"\"no description\"\"\"\r\n        if included_messages is not None:\r\n            data[\"included_messages\"] = included_messages\r\n\r\n        # OPTIONAL - user_note\r\n        \"\"\"Will add a faculty journal entry for each recipient as long as the user\r\n        making the api call has permission, the recipient is a student and\r\n        faculty journals are enabled in the account.\"\"\"\r\n        if user_note is not None:\r\n            data[\"user_note\"] = user_note\r\n\r\n        self.logger.debug(\"POST /api/v1/conversations/{id}/add_message with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/conversations/{id}/add_message\".format(**path), data=data, params=params, no_data=True)", "response": "Adds a new message to an existing conversation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_message(self, id, remove):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - remove\r\n        \"\"\"Array of message ids to be deleted\"\"\"\r\n        data[\"remove\"] = remove\r\n\r\n        self.logger.debug(\"POST /api/v1/conversations/{id}/remove_messages with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/conversations/{id}/remove_messages\".format(**path), data=data, params=params, no_data=True)", "response": "Deletes a message from a conversation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef batch_update_conversations(self, event, conversation_ids):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - conversation_ids\r\n        \"\"\"List of conversations to update. Limited to 500 conversations.\"\"\"\r\n        data[\"conversation_ids\"] = conversation_ids\r\n\r\n        # REQUIRED - event\r\n        \"\"\"The action to take on each conversation.\"\"\"\r\n        self._validate_enum(event, [\"mark_as_read\", \"mark_as_unread\", \"star\", \"unstar\", \"archive\", \"destroy\"])\r\n        data[\"event\"] = event\r\n\r\n        self.logger.debug(\"PUT /api/v1/conversations with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/conversations\".format(**path), data=data, params=params, single_item=True)", "response": "This method allows you to batch update conversations. You can use this method to update a set of conversations. You can use the list of conversations to update. You can use the list of conversations to update."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists preferences for a given communication channel. Returns a list of all preferences for the given user and communication channel.", "response": "def list_preferences_communication_channel_id(self, user_id, communication_channel_id):\r\n        \"\"\"\r\n        List preferences.\r\n\r\n        Fetch all preferences for the given communication channel\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - communication_channel_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"communication_channel_id\"] = communication_channel_id\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/communication_channels/{communication_channel_id}/notification_preferences with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/communication_channels/{communication_channel_id}/notification_preferences\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_preferences_type(self, type, user_id, address):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - type\r\n        \"\"\"ID\"\"\"\r\n        path[\"type\"] = type\r\n\r\n        # REQUIRED - PATH - address\r\n        \"\"\"ID\"\"\"\r\n        path[\"address\"] = address\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/communication_channels/{type}/{address}/notification_preferences with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/communication_channels/{type}/{address}/notification_preferences\".format(**path), data=data, params=params, all_pages=True)", "response": "List preferences for a given communication channel type and address. Returns a list of all preferences for the given communication channel type and address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_preference_communication_channel_id(self, user_id, notification, communication_channel_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - communication_channel_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"communication_channel_id\"] = communication_channel_id\r\n\r\n        # REQUIRED - PATH - notification\r\n        \"\"\"ID\"\"\"\r\n        path[\"notification\"] = notification\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/communication_channels/{communication_channel_id}/notification_preferences/{notification} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/communication_channels/{communication_channel_id}/notification_preferences/{notification}\".format(**path), data=data, params=params, single_item=True)", "response": "Get a preference for a given notification for a given communicaiton channel. Returns the ID of the preference for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a preference for a given type for a given communicaiton", "response": "def get_preference_type(self, type, user_id, address, notification):\r\n        \"\"\"\r\n        Get a preference.\r\n\r\n        Fetch the preference for the given notification for the given communicaiton channel\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - type\r\n        \"\"\"ID\"\"\"\r\n        path[\"type\"] = type\r\n\r\n        # REQUIRED - PATH - address\r\n        \"\"\"ID\"\"\"\r\n        path[\"address\"] = address\r\n\r\n        # REQUIRED - PATH - notification\r\n        \"\"\"ID\"\"\"\r\n        path[\"notification\"] = notification\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/communication_channels/{type}/{address}/notification_preferences/{notification} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/communication_channels/{type}/{address}/notification_preferences/{notification}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_preference_communication_channel_id(self, notification, communication_channel_id, notification_preferences_frequency):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - communication_channel_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"communication_channel_id\"] = communication_channel_id\r\n\r\n        # REQUIRED - PATH - notification\r\n        \"\"\"ID\"\"\"\r\n        path[\"notification\"] = notification\r\n\r\n        # REQUIRED - notification_preferences[frequency]\r\n        \"\"\"The desired frequency for this notification\"\"\"\r\n        data[\"notification_preferences[frequency]\"] = notification_preferences_frequency\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/self/communication_channels/{communication_channel_id}/notification_preferences/{notification} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/self/communication_channels/{communication_channel_id}/notification_preferences/{notification}\".format(**path), data=data, params=params, no_data=True)", "response": "Update a preference for a single notification for a single communication channel"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the preference for a single notification for a single communication channel", "response": "def update_preference_type(self, type, address, notification, notification_preferences_frequency):\r\n        \"\"\"\r\n        Update a preference.\r\n\r\n        Change the preference for a single notification for a single communication channel\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - type\r\n        \"\"\"ID\"\"\"\r\n        path[\"type\"] = type\r\n\r\n        # REQUIRED - PATH - address\r\n        \"\"\"ID\"\"\"\r\n        path[\"address\"] = address\r\n\r\n        # REQUIRED - PATH - notification\r\n        \"\"\"ID\"\"\"\r\n        path[\"notification\"] = notification\r\n\r\n        # REQUIRED - notification_preferences[frequency]\r\n        \"\"\"The desired frequency for this notification\"\"\"\r\n        data[\"notification_preferences[frequency]\"] = notification_preferences_frequency\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/self/communication_channels/{type}/{address}/notification_preferences/{notification} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/self/communication_channels/{type}/{address}/notification_preferences/{notification}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates preferences by category. Updates the preferences for multiple notifications based on the category for a single communication channel. Returns the updated list of preferences for a single notification in the given category.", "response": "def update_preferences_by_category(self, category, communication_channel_id, notification_preferences_frequency):\r\n        \"\"\"\r\n        Update preferences by category.\r\n\r\n        Change the preferences for multiple notifications based on the category for a single communication channel\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - communication_channel_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"communication_channel_id\"] = communication_channel_id\r\n\r\n        # REQUIRED - PATH - category\r\n        \"\"\"The name of the category. Must be parameterized (e.g. The category \"Course Content\" should be \"course_content\")\"\"\"\r\n        path[\"category\"] = category\r\n\r\n        # REQUIRED - notification_preferences[frequency]\r\n        \"\"\"The desired frequency for each notification in the category\"\"\"\r\n        data[\"notification_preferences[frequency]\"] = notification_preferences_frequency\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/self/communication_channels/{communication_channel_id}/notification_preference_categories/{category} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/self/communication_channels/{communication_channel_id}/notification_preference_categories/{category}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(cl_args=None):\n\n    if cl_args is None and len(sys.argv) > 1:\n        cl_args = sys.argv[1:]\n    args = options.parse_args(cl_args)\n\n    print(\"-------------------------------------------------------------------\")\n    print(\"                      __   _____   ___   ____    _ __     \")\n    print(\"                     / /  /  _/ | / / | / / /__ (_) /_    \")\n    print(\"                    / /___/ / | |/ /| |/ /  '_// / __/    \")\n    print(\"                   /____/___/ |___/ |___/_/\\_\\/_/\\__/     \")\n    print(\"\")\n    print(\"                   Land Ice Verification & Validation     \")\n    print(\"-------------------------------------------------------------------\")\n    print(\"\")\n    print(\"  Current run: \" + livvkit.timestamp)\n    print(\"  User: \" + livvkit.user)\n    print(\"  OS Type: \" + livvkit.os_type)\n    print(\"  Machine: \" + livvkit.machine)\n    print(\"  \" + livvkit.comment)\n\n    from livvkit.components import numerics\n    from livvkit.components import verification\n    from livvkit.components import performance\n    from livvkit.components import validation\n    from livvkit import scheduler\n    from livvkit.util import functions\n    from livvkit.util import elements\n\n    summary_elements = []\n\n    if livvkit.verify or livvkit.validate:\n        functions.setup_output()\n\n    if livvkit.verify:\n        summary_elements.append(scheduler.run(\"numerics\", numerics,\n                                              functions.read_json(livvkit.numerics_model_config)))\n        summary_elements.append(scheduler.run(\"verification\", verification,\n                                              functions.read_json(livvkit.verification_model_config)))\n        summary_elements.append(scheduler.run(\"performance\", performance,\n                                              functions.read_json(livvkit.performance_model_config)))\n    if livvkit.validate:\n        print(\" -----------------------------------------------------------------\")\n        print(\"   Beginning the validation test suite \")\n        print(\" -----------------------------------------------------------------\")\n        print(\"\")\n        validation_config = {}\n        for conf in livvkit.validation_model_configs:\n            validation_config = functions.merge_dicts(validation_config,\n                                                      functions.read_json(conf))\n        summary_elements.extend(scheduler.run_quiet(validation, validation_config,\n                                                    group=False))\n        print(\" -----------------------------------------------------------------\")\n        print(\"   Validation test suite complete \")\n        print(\" -----------------------------------------------------------------\")\n        print(\"\")\n\n    if livvkit.verify or livvkit.validate:\n        result = elements.page(\"Summary\", \"\", element_list=summary_elements)\n        functions.write_json(result, livvkit.output_dir, \"index.json\")\n        print(\"-------------------------------------------------------------------\")\n        print(\" Done!  Results can be seen in a web browser at:\")\n        print(\"  \" + os.path.join(livvkit.output_dir, 'index.html'))\n        print(\"-------------------------------------------------------------------\")\n\n    if args.serve:\n        try:\n            # Python 3\n            import http.server as server\n            import socketserver as socket\n        except ImportError:\n            # Python 2\n            # noinspection PyPep8Naming\n            import SimpleHTTPServer as server\n            # noinspection PyPep8Naming\n            import SocketServer as socket\n\n        httpd = socket.TCPServer(('', args.serve), server.SimpleHTTPRequestHandler)\n\n        sa = httpd.socket.getsockname()\n        print('\\nServing HTTP on {host} port {port} (http://{host}:{port}/)'.format(host=sa[0], port=sa[1]))\n        print('\\nView the generated website by navigating to:')\n        print('\\n    http://{host}:{port}/{path}/index.html'.format(host=sa[0], port=sa[1],\n                                                                    path=os.path.relpath(livvkit.output_dir)\n                                                                    ))\n        print('\\nExit by pressing `ctrl+c` to send a keyboard interrupt.\\n')\n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            print('\\nKeyboard interrupt received, exiting.\\n')\n            sys.exit(0)", "response": "Main function for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_users_in_account(self, account_id, search_term=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name or full ID of the users to match and return in the\r\n        results list. Must be at least 3 characters.\r\n        \r\n        Note that the API will prefer matching on canonical user ID if the ID has\r\n        a numeric form. It will only search against other fields if non-numeric\r\n        in form, or if the numeric value doesn't yield any matches. Queries by\r\n        administrative users will search on SIS ID, name, or email address; non-\r\n        administrative queries will only be compared against name.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/users\".format(**path), data=data, params=params, all_pages=True)", "response": "List users in an account. Returns a list of users in the specified account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new user and pseudonym for an account. Returns a new user and pseudonym.", "response": "def create_user(self, account_id, pseudonym_unique_id, communication_channel_address=None, communication_channel_confirmation_url=None, communication_channel_skip_confirmation=None, communication_channel_type=None, enable_sis_reactivation=None, force_validations=None, pseudonym_authentication_provider_id=None, pseudonym_force_self_registration=None, pseudonym_integration_id=None, pseudonym_password=None, pseudonym_send_confirmation=None, pseudonym_sis_user_id=None, user_birthdate=None, user_locale=None, user_name=None, user_short_name=None, user_skip_registration=None, user_sortable_name=None, user_terms_of_use=None, user_time_zone=None):\r\n        \"\"\"\r\n        Create a user.\r\n\r\n        Create and return a new user and pseudonym for an account.\r\n        \r\n        If you don't have the \"Modify login details for users\" permission, but\r\n        self-registration is enabled on the account, you can still use this\r\n        endpoint to register new users. Certain fields will be required, and\r\n        others will be ignored (see below).\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - user[name]\r\n        \"\"\"The full name of the user. This name will be used by teacher for grading.\r\n        Required if this is a self-registration.\"\"\"\r\n        if user_name is not None:\r\n            data[\"user[name]\"] = user_name\r\n\r\n        # OPTIONAL - user[short_name]\r\n        \"\"\"User's name as it will be displayed in discussions, messages, and comments.\"\"\"\r\n        if user_short_name is not None:\r\n            data[\"user[short_name]\"] = user_short_name\r\n\r\n        # OPTIONAL - user[sortable_name]\r\n        \"\"\"User's name as used to sort alphabetically in lists.\"\"\"\r\n        if user_sortable_name is not None:\r\n            data[\"user[sortable_name]\"] = user_sortable_name\r\n\r\n        # OPTIONAL - user[time_zone]\r\n        \"\"\"The time zone for the user. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if user_time_zone is not None:\r\n            data[\"user[time_zone]\"] = user_time_zone\r\n\r\n        # OPTIONAL - user[locale]\r\n        \"\"\"The user's preferred language, from the list of languages Canvas supports.\r\n        This is in RFC-5646 format.\"\"\"\r\n        if user_locale is not None:\r\n            data[\"user[locale]\"] = user_locale\r\n\r\n        # OPTIONAL - user[birthdate]\r\n        \"\"\"The user's birth date.\"\"\"\r\n        if user_birthdate is not None:\r\n            data[\"user[birthdate]\"] = user_birthdate\r\n\r\n        # OPTIONAL - user[terms_of_use]\r\n        \"\"\"Whether the user accepts the terms of use. Required if this is a\r\n        self-registration and this canvas instance requires users to accept\r\n        the terms (on by default).\r\n        \r\n        If this is true, it will mark the user as having accepted the terms of use.\"\"\"\r\n        if user_terms_of_use is not None:\r\n            data[\"user[terms_of_use]\"] = user_terms_of_use\r\n\r\n        # OPTIONAL - user[skip_registration]\r\n        \"\"\"Automatically mark the user as registered.\r\n        \r\n        If this is true, it is recommended to set <tt>\"pseudonym[send_confirmation]\"</tt> to true as well.\r\n        Otherwise, the user will not receive any messages about their account creation.\r\n        \r\n        The users communication channel confirmation can be skipped by setting\r\n        <tt>\"communication_channel[skip_confirmation]\"</tt> to true as well.\"\"\"\r\n        if user_skip_registration is not None:\r\n            data[\"user[skip_registration]\"] = user_skip_registration\r\n\r\n        # REQUIRED - pseudonym[unique_id]\r\n        \"\"\"User's login ID. If this is a self-registration, it must be a valid\r\n        email address.\"\"\"\r\n        data[\"pseudonym[unique_id]\"] = pseudonym_unique_id\r\n\r\n        # OPTIONAL - pseudonym[password]\r\n        \"\"\"User's password. Cannot be set during self-registration.\"\"\"\r\n        if pseudonym_password is not None:\r\n            data[\"pseudonym[password]\"] = pseudonym_password\r\n\r\n        # OPTIONAL - pseudonym[sis_user_id]\r\n        \"\"\"SIS ID for the user's account. To set this parameter, the caller must be\r\n        able to manage SIS permissions.\"\"\"\r\n        if pseudonym_sis_user_id is not None:\r\n            data[\"pseudonym[sis_user_id]\"] = pseudonym_sis_user_id\r\n\r\n        # OPTIONAL - pseudonym[integration_id]\r\n        \"\"\"Integration ID for the login. To set this parameter, the caller must be able to\r\n        manage SIS permissions. The Integration ID is a secondary\r\n        identifier useful for more complex SIS integrations.\"\"\"\r\n        if pseudonym_integration_id is not None:\r\n            data[\"pseudonym[integration_id]\"] = pseudonym_integration_id\r\n\r\n        # OPTIONAL - pseudonym[send_confirmation]\r\n        \"\"\"Send user notification of account creation if true.\r\n        Automatically set to true during self-registration.\"\"\"\r\n        if pseudonym_send_confirmation is not None:\r\n            data[\"pseudonym[send_confirmation]\"] = pseudonym_send_confirmation\r\n\r\n        # OPTIONAL - pseudonym[force_self_registration]\r\n        \"\"\"Send user a self-registration style email if true.\r\n        Setting it means the users will get a notification asking them\r\n        to \"complete the registration process\" by clicking it, setting\r\n        a password, and letting them in.  Will only be executed on\r\n        if the user does not need admin approval.\r\n        Defaults to false unless explicitly provided.\"\"\"\r\n        if pseudonym_force_self_registration is not None:\r\n            data[\"pseudonym[force_self_registration]\"] = pseudonym_force_self_registration\r\n\r\n        # OPTIONAL - pseudonym[authentication_provider_id]\r\n        \"\"\"The authentication provider this login is associated with. Logins\r\n        associated with a specific provider can only be used with that provider.\r\n        Legacy providers (LDAP, CAS, SAML) will search for logins associated with\r\n        them, or unassociated logins. New providers will only search for logins\r\n        explicitly associated with them. This can be the integer ID of the\r\n        provider, or the type of the provider (in which case, it will find the\r\n        first matching provider).\"\"\"\r\n        if pseudonym_authentication_provider_id is not None:\r\n            data[\"pseudonym[authentication_provider_id]\"] = pseudonym_authentication_provider_id\r\n\r\n        # OPTIONAL - communication_channel[type]\r\n        \"\"\"The communication channel type, e.g. 'email' or 'sms'.\"\"\"\r\n        if communication_channel_type is not None:\r\n            data[\"communication_channel[type]\"] = communication_channel_type\r\n\r\n        # OPTIONAL - communication_channel[address]\r\n        \"\"\"The communication channel address, e.g. the user's email address.\"\"\"\r\n        if communication_channel_address is not None:\r\n            data[\"communication_channel[address]\"] = communication_channel_address\r\n\r\n        # OPTIONAL - communication_channel[confirmation_url]\r\n        \"\"\"Only valid for account admins. If true, returns the new user account\r\n        confirmation URL in the response.\"\"\"\r\n        if communication_channel_confirmation_url is not None:\r\n            data[\"communication_channel[confirmation_url]\"] = communication_channel_confirmation_url\r\n\r\n        # OPTIONAL - communication_channel[skip_confirmation]\r\n        \"\"\"Only valid for site admins and account admins making requests; If true, the channel is\r\n        automatically validated and no confirmation email or SMS is sent.\r\n        Otherwise, the user must respond to a confirmation message to confirm the\r\n        channel.\r\n        \r\n        If this is true, it is recommended to set <tt>\"pseudonym[send_confirmation]\"</tt> to true as well.\r\n        Otherwise, the user will not receive any messages about their account creation.\"\"\"\r\n        if communication_channel_skip_confirmation is not None:\r\n            data[\"communication_channel[skip_confirmation]\"] = communication_channel_skip_confirmation\r\n\r\n        # OPTIONAL - force_validations\r\n        \"\"\"If true, validations are performed on the newly created user (and their associated pseudonym)\r\n        even if the request is made by a privileged user like an admin. When set to false,\r\n        or not included in the request parameters, any newly created users are subject to\r\n        validations unless the request is made by a user with a 'manage_user_logins' right.\r\n        In which case, certain validations such as 'require_acceptance_of_terms' and\r\n        'require_presence_of_name' are not enforced. Use this parameter to return helpful json\r\n        errors while building users with an admin request.\"\"\"\r\n        if force_validations is not None:\r\n            data[\"force_validations\"] = force_validations\r\n\r\n        # OPTIONAL - enable_sis_reactivation\r\n        \"\"\"When true, will first try to re-activate a deleted user with matching sis_user_id if possible.\"\"\"\r\n        if enable_sis_reactivation is not None:\r\n            data[\"enable_sis_reactivation\"] = enable_sis_reactivation\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/users\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselfs register a user. Self register and return a new user and pseudonym for an account. If self-registration is enabled on the account, you can use this endpoint to self register new users.", "response": "def self_register_user(self, user_name, account_id, user_terms_of_use, pseudonym_unique_id, communication_channel_address=None, communication_channel_type=None, user_birthdate=None, user_locale=None, user_short_name=None, user_sortable_name=None, user_time_zone=None):\r\n        \"\"\"\r\n        Self register a user.\r\n\r\n        Self register and return a new user and pseudonym for an account.\r\n        \r\n        If self-registration is enabled on the account, you can use this\r\n        endpoint to self register new users.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - user[name]\r\n        \"\"\"The full name of the user. This name will be used by teacher for grading.\"\"\"\r\n        data[\"user[name]\"] = user_name\r\n\r\n        # OPTIONAL - user[short_name]\r\n        \"\"\"User's name as it will be displayed in discussions, messages, and comments.\"\"\"\r\n        if user_short_name is not None:\r\n            data[\"user[short_name]\"] = user_short_name\r\n\r\n        # OPTIONAL - user[sortable_name]\r\n        \"\"\"User's name as used to sort alphabetically in lists.\"\"\"\r\n        if user_sortable_name is not None:\r\n            data[\"user[sortable_name]\"] = user_sortable_name\r\n\r\n        # OPTIONAL - user[time_zone]\r\n        \"\"\"The time zone for the user. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if user_time_zone is not None:\r\n            data[\"user[time_zone]\"] = user_time_zone\r\n\r\n        # OPTIONAL - user[locale]\r\n        \"\"\"The user's preferred language, from the list of languages Canvas supports.\r\n        This is in RFC-5646 format.\"\"\"\r\n        if user_locale is not None:\r\n            data[\"user[locale]\"] = user_locale\r\n\r\n        # OPTIONAL - user[birthdate]\r\n        \"\"\"The user's birth date.\"\"\"\r\n        if user_birthdate is not None:\r\n            data[\"user[birthdate]\"] = user_birthdate\r\n\r\n        # REQUIRED - user[terms_of_use]\r\n        \"\"\"Whether the user accepts the terms of use.\"\"\"\r\n        data[\"user[terms_of_use]\"] = user_terms_of_use\r\n\r\n        # REQUIRED - pseudonym[unique_id]\r\n        \"\"\"User's login ID. Must be a valid email address.\"\"\"\r\n        data[\"pseudonym[unique_id]\"] = pseudonym_unique_id\r\n\r\n        # OPTIONAL - communication_channel[type]\r\n        \"\"\"The communication channel type, e.g. 'email' or 'sms'.\"\"\"\r\n        if communication_channel_type is not None:\r\n            data[\"communication_channel[type]\"] = communication_channel_type\r\n\r\n        # OPTIONAL - communication_channel[address]\r\n        \"\"\"The communication channel address, e.g. the user's email address.\"\"\"\r\n        if communication_channel_address is not None:\r\n            data[\"communication_channel[address]\"] = communication_channel_address\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/self_registration with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/self_registration\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a user s settings. Updates an existing user s settings.", "response": "def update_user_settings(self, id, collapse_global_nav=None, manual_mark_as_read=None):\r\n        \"\"\"\r\n        Update user settings.\r\n\r\n        Update an existing user's settings.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - manual_mark_as_read\r\n        \"\"\"If true, require user to manually mark discussion posts as read (don't\r\n        auto-mark as read).\"\"\"\r\n        if manual_mark_as_read is not None:\r\n            params[\"manual_mark_as_read\"] = manual_mark_as_read\r\n\r\n        # OPTIONAL - collapse_global_nav\r\n        \"\"\"If true, the user's page loads with the global navigation collapsed\"\"\"\r\n        if collapse_global_nav is not None:\r\n            params[\"collapse_global_nav\"] = collapse_global_nav\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{id}/settings with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{id}/settings\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets custom color for a user. Returns the custom colors that have been saved for a given context.", "response": "def get_custom_color(self, id, asset_string):\r\n        \"\"\"\r\n        Get custom color.\r\n\r\n        Returns the custom colors that have been saved for a user for a given context.\r\n        \r\n        The asset_string parameter should be in the format 'context_id', for example\r\n        'course_42'.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - asset_string\r\n        \"\"\"ID\"\"\"\r\n        path[\"asset_string\"] = asset_string\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{id}/colors/{asset_string} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{id}/colors/{asset_string}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit_user(self, id, user_avatar_token=None, user_avatar_url=None, user_email=None, user_locale=None, user_name=None, user_short_name=None, user_sortable_name=None, user_time_zone=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - user[name]\r\n        \"\"\"The full name of the user. This name will be used by teacher for grading.\"\"\"\r\n        if user_name is not None:\r\n            data[\"user[name]\"] = user_name\r\n\r\n        # OPTIONAL - user[short_name]\r\n        \"\"\"User's name as it will be displayed in discussions, messages, and comments.\"\"\"\r\n        if user_short_name is not None:\r\n            data[\"user[short_name]\"] = user_short_name\r\n\r\n        # OPTIONAL - user[sortable_name]\r\n        \"\"\"User's name as used to sort alphabetically in lists.\"\"\"\r\n        if user_sortable_name is not None:\r\n            data[\"user[sortable_name]\"] = user_sortable_name\r\n\r\n        # OPTIONAL - user[time_zone]\r\n        \"\"\"The time zone for the user. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if user_time_zone is not None:\r\n            data[\"user[time_zone]\"] = user_time_zone\r\n\r\n        # OPTIONAL - user[email]\r\n        \"\"\"The default email address of the user.\"\"\"\r\n        if user_email is not None:\r\n            data[\"user[email]\"] = user_email\r\n\r\n        # OPTIONAL - user[locale]\r\n        \"\"\"The user's preferred language, from the list of languages Canvas supports.\r\n        This is in RFC-5646 format.\"\"\"\r\n        if user_locale is not None:\r\n            data[\"user[locale]\"] = user_locale\r\n\r\n        # OPTIONAL - user[avatar][token]\r\n        \"\"\"A unique representation of the avatar record to assign as the user's\r\n        current avatar. This token can be obtained from the user avatars endpoint.\r\n        This supersedes the user [avatar] [url] argument, and if both are included\r\n        the url will be ignored. Note: this is an internal representation and is\r\n        subject to change without notice. It should be consumed with this api\r\n        endpoint and used in the user update endpoint, and should not be\r\n        constructed by the client.\"\"\"\r\n        if user_avatar_token is not None:\r\n            data[\"user[avatar][token]\"] = user_avatar_token\r\n\r\n        # OPTIONAL - user[avatar][url]\r\n        \"\"\"To set the user's avatar to point to an external url, do not include a\r\n        token and instead pass the url here. Warning: For maximum compatibility,\r\n        please use 128 px square images.\"\"\"\r\n        if user_avatar_url is not None:\r\n            data[\"user[avatar][url]\"] = user_avatar_url\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Edit a user. Updates the user s login information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging a user into another user. Merge a user into another user.", "response": "def merge_user_into_another_user_destination_user_id(self, id, destination_user_id):\r\n        \"\"\"\r\n        Merge user into another user.\r\n\r\n        Merge a user into another user.\r\n        To merge users, the caller must have permissions to manage both users. This\r\n        should be considered irreversible. This will delete the user and move all\r\n        the data into the destination user.\r\n        \r\n        When finding users by SIS ids in different accounts the\r\n        destination_account_id is required.\r\n        \r\n        The account can also be identified by passing the domain in destination_account_id.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - destination_user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"destination_user_id\"] = destination_user_id\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/{id}/merge_into/{destination_user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/{id}/merge_into/{destination_user_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the user profile for the specified user.", "response": "def get_user_profile(self, user_id):\r\n        \"\"\"\r\n        Get user profile.\r\n\r\n        Returns user profile data, including user id, name, and profile pic.\r\n        \r\n        When requesting the profile for the user accessing the API, the user's\r\n        calendar feed URL will be returned as well.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/profile with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/profile\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_user_page_views(self, user_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want page views.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want page views.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/page_views with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/page_views\".format(**path), data=data, params=params, all_pages=True)", "response": "List user page views. Returns the user s page view history in json format similar to the list_user_page_views_as_json format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef store_custom_data(self, ns, data, user_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - ns\r\n        \"\"\"The namespace under which to store the data.  This should be something other\r\n        Canvas API apps aren't likely to use, such as a reverse DNS for your organization.\"\"\"\r\n        data[\"ns\"] = ns\r\n\r\n        # REQUIRED - data\r\n        \"\"\"The data you want to store for the user, at the specified scope.  If the data is\r\n        composed of (possibly nested) JSON objects, scopes will be generated for the (nested)\r\n        keys (see examples).\"\"\"\r\n        data[\"data\"] = data\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/{user_id}/custom_data with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/{user_id}/custom_data\".format(**path), data=data, params=params, no_data=True)", "response": "Stores arbitrary user s custom data as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of course nicknames.", "response": "def list_course_nicknames(self):\r\n        \"\"\"\r\n        List course nicknames.\r\n\r\n        Returns all course nicknames you have set.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        self.logger.debug(\"GET /api/v1/users/self/course_nicknames with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/self/course_nicknames\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a nickname for the given course. This will replace the course s name with the given nickname.", "response": "def set_course_nickname(self, nickname, course_id):\r\n        \"\"\"\r\n        Set course nickname.\r\n\r\n        Set a nickname for the given course. This will replace the course's name\r\n        in output of API calls you make subsequently, as well as in selected\r\n        places in the Canvas web user interface.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - nickname\r\n        \"\"\"The nickname to set.  It must be non-empty and shorter than 60 characters.\"\"\"\r\n        data[\"nickname\"] = nickname\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/self/course_nicknames/{course_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/self/course_nicknames/{course_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the list of SIS imports for an account. Returns the list of SIS imports for an account.", "response": "def get_sis_import_list(self, account_id, created_since=None):\r\n        \"\"\"\r\n        Get SIS import list.\r\n\r\n        Returns the list of SIS imports for an account\r\n\r\n        Example:\r\n          curl 'https://<canvas>/api/v1/accounts/<account_id>/sis_imports' \\\r\n            -H \"Authorization: Bearer <token>\"\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - created_since\r\n        \"\"\"If set, only shows imports created after the specified date (use ISO8601 format)\"\"\"\r\n        if created_since is not None:\r\n            if issubclass(created_since.__class__, basestring):\r\n                created_since = self._validate_iso8601_string(created_since)\r\n            elif issubclass(created_since.__class__, date) or issubclass(created_since.__class__, datetime):\r\n                created_since = created_since.strftime('%Y-%m-%dT%H:%M:%S+00:00')\r\n            params[\"created_since\"] = created_since\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/sis_imports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/sis_imports\".format(**path), data=data, params=params, data_key='sis_imports', all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport SIS data. Import SIS data into Canvas. Must be on a root account with SIS imports enabled. For more information on the format that's expected here, please see the \"SIS CSV\" section in the API docs.", "response": "def import_sis_data(self, account_id, add_sis_stickiness=None, attachment=None, batch_mode=None, batch_mode_term_id=None, clear_sis_stickiness=None, diffing_data_set_identifier=None, diffing_remaster_data_set=None, extension=None, import_type=None, override_sis_stickiness=None):\r\n        \"\"\"\r\n        Import SIS data.\r\n\r\n        Import SIS data into Canvas. Must be on a root account with SIS imports\r\n        enabled.\r\n\r\n        For more information on the format that's expected here, please see the\r\n        \"SIS CSV\" section in the API docs.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n        files = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - import_type\r\n        \"\"\"Choose the data format for reading SIS data. With a standard Canvas\r\n        install, this option can only be 'instructure_csv', and if unprovided,\r\n        will be assumed to be so. Can be part of the query string.\"\"\"\r\n        if import_type is not None:\r\n            data[\"import_type\"] = import_type\r\n\r\n        # OPTIONAL - attachment\r\n        \"\"\"There are two ways to post SIS import data - either via a\r\n        multipart/form-data form-field-style attachment, or via a non-multipart\r\n        raw post request.\r\n\r\n        'attachment' is required for multipart/form-data style posts. Assumed to\r\n        be SIS data from a file upload form field named 'attachment'.\r\n\r\n        Examples:\r\n          curl -F attachment=@<filename> -H \"Authorization: Bearer <token>\" \\\r\n              'https://<canvas>/api/v1/accounts/<account_id>/sis_imports.json?import_type=instructure_csv'\r\n\r\n        If you decide to do a raw post, you can skip the 'attachment' argument,\r\n        but you will then be required to provide a suitable Content-Type header.\r\n        You are encouraged to also provide the 'extension' argument.\r\n\r\n        Examples:\r\n          curl -H 'Content-Type: application/octet-stream' --data-binary @<filename>.zip \\\r\n              -H \"Authorization: Bearer <token>\" \\\r\n              'https://<canvas>/api/v1/accounts/<account_id>/sis_imports.json?import_type=instructure_csv&extension=zip'\r\n\r\n          curl -H 'Content-Type: application/zip' --data-binary @<filename>.zip \\\r\n              -H \"Authorization: Bearer <token>\" \\\r\n              'https://<canvas>/api/v1/accounts/<account_id>/sis_imports.json?import_type=instructure_csv'\r\n\r\n          curl -H 'Content-Type: text/csv' --data-binary @<filename>.csv \\\r\n              -H \"Authorization: Bearer <token>\" \\\r\n              'https://<canvas>/api/v1/accounts/<account_id>/sis_imports.json?import_type=instructure_csv'\r\n\r\n          curl -H 'Content-Type: text/csv' --data-binary @<filename>.csv \\\r\n              -H \"Authorization: Bearer <token>\" \\\r\n              'https://<canvas>/api/v1/accounts/<account_id>/sis_imports.json?import_type=instructure_csv&batch_mode=1&batch_mode_term_id=15'\"\"\"\r\n        if attachment is not None:\r\n            if type(attachment) is file:\r\n                files['attachment'] = (os.path.basename(attachment.name), attachment)\r\n            elif os.path.exists(attachment):\r\n                files['attachment'] = (os.path.basename(attachment), open(attachment, 'rb'))\r\n            else:\r\n                raise ValueError('The attachment must be an open file or a path to a readable file.')\r\n\r\n        # OPTIONAL - extension\r\n        \"\"\"Recommended for raw post request style imports. This field will be used to\r\n        distinguish between zip, xml, csv, and other file format extensions that\r\n        would usually be provided with the filename in the multipart post request\r\n        scenario. If not provided, this value will be inferred from the\r\n        Content-Type, falling back to zip-file format if all else fails.\"\"\"\r\n        if extension is not None:\r\n            data[\"extension\"] = extension\r\n\r\n        # OPTIONAL - batch_mode\r\n        \"\"\"If set, this SIS import will be run in batch mode, deleting any data\r\n        previously imported via SIS that is not present in this latest import.\r\n        See the SIS CSV Format page for details.\"\"\"\r\n        if batch_mode is not None:\r\n            data[\"batch_mode\"] = batch_mode\r\n\r\n        # OPTIONAL - batch_mode_term_id\r\n        \"\"\"Limit deletions to only this term. Required if batch mode is enabled.\"\"\"\r\n        if batch_mode_term_id is not None:\r\n            data[\"batch_mode_term_id\"] = batch_mode_term_id\r\n\r\n        # OPTIONAL - override_sis_stickiness\r\n        \"\"\"Many fields on records in Canvas can be marked \"sticky,\" which means that\r\n        when something changes in the UI apart from the SIS, that field gets\r\n        \"stuck.\" In this way, by default, SIS imports do not override UI changes.\r\n        If this field is present, however, it will tell the SIS import to ignore\r\n        \"stickiness\" and override all fields.\"\"\"\r\n        if override_sis_stickiness is not None:\r\n            data[\"override_sis_stickiness\"] = override_sis_stickiness\r\n\r\n        # OPTIONAL - add_sis_stickiness\r\n        \"\"\"This option, if present, will process all changes as if they were UI\r\n        changes. This means that \"stickiness\" will be added to changed fields.\r\n        This option is only processed if 'override_sis_stickiness' is also provided.\"\"\"\r\n        if add_sis_stickiness is not None:\r\n            data[\"add_sis_stickiness\"] = add_sis_stickiness\r\n\r\n        # OPTIONAL - clear_sis_stickiness\r\n        \"\"\"This option, if present, will clear \"stickiness\" from all fields touched\r\n        by this import. Requires that 'override_sis_stickiness' is also provided.\r\n        If 'add_sis_stickiness' is also provided, 'clear_sis_stickiness' will\r\n        overrule the behavior of 'add_sis_stickiness'\"\"\"\r\n        if clear_sis_stickiness is not None:\r\n            data[\"clear_sis_stickiness\"] = clear_sis_stickiness\r\n\r\n        # OPTIONAL - diffing_data_set_identifier\r\n        \"\"\"If set on a CSV import, Canvas will attempt to optimize the SIS import by\r\n        comparing this set of CSVs to the previous set that has the same data set\r\n        identifier, and only appliying the difference between the two. See the\r\n        SIS CSV Format documentation for more details.\"\"\"\r\n        if diffing_data_set_identifier is not None:\r\n            data[\"diffing_data_set_identifier\"] = diffing_data_set_identifier\r\n\r\n        # OPTIONAL - diffing_remaster_data_set\r\n        \"\"\"If true, and diffing_data_set_identifier is sent, this SIS import will be\r\n        part of the data set, but diffing will not be performed. See the SIS CSV\r\n        Format documentation for details.\"\"\"\r\n        if diffing_remaster_data_set is not None:\r\n            data[\"diffing_remaster_data_set\"] = diffing_remaster_data_set\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/sis_imports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/sis_imports\".format(**path), data=data, params=params, files=files, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abort_all_pending_sis_imports(self, account_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{account_id}/sis_imports/abort_all_pending with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{account_id}/sis_imports/abort_all_pending\".format(**path), data=data, params=params)", "response": "Abort all pending SIS imports. Abort all pending SIS imports."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_finder(dirname=\".\"):\n\timport distutils.log\n\tdirname = dirname or '.'\n\ttry:\n\t\tvalid_mgrs = managers.RepoManager.get_valid_managers(dirname)\n\t\tvalid_mgrs = managers.RepoManager.existing_only(valid_mgrs)\n\t\tfor mgr in valid_mgrs:\n\t\t\ttry:\n\t\t\t\treturn mgr.find_all_files()\n\t\t\texcept Exception:\n\t\t\t\te = sys.exc_info()[1]\n\t\t\t\tdistutils.log.warn(\n\t\t\t\t\t\"hgtools.%s could not find files: %s\",\n\t\t\t\t\tmgr, e)\n\texcept Exception:\n\t\te = sys.exc_info()[1]\n\t\tdistutils.log.warn(\n\t\t\t\"Unexpected error finding valid managers in \"\n\t\t\t\"hgtools.file_finder_plugin: %s\", e)\n\treturn []", "response": "Find the files in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npatch egg_info. tagged_version to use the mercurial version if indicated.", "response": "def patch_egg_info(force_hg_version=False):\n\t\"\"\"\n\tA hack to replace egg_info.tagged_version with a wrapped version\n\tthat will use the mercurial version if indicated.\n\n\t`force_hg_version` is used for hgtools itself.\n\t\"\"\"\n\tfrom setuptools.command.egg_info import egg_info\n\tfrom pkg_resources import safe_version\n\timport functools\n\torig_ver = egg_info.tagged_version\n\n\t@functools.wraps(orig_ver)\n\tdef tagged_version(self):\n\t\tvcs_param = (\n\t\t\tgetattr(self.distribution, 'use_vcs_version', False)\n\t\t\tor getattr(self.distribution, 'use_hg_version', False)\n\t\t)\n\t\tusing_hg_version = force_hg_version or vcs_param\n\t\tif force_hg_version:\n\t\t\t# disable patched `tagged_version` to avoid affecting\n\t\t\t#  subsequent installs in the same interpreter instance.\n\t\t\tegg_info.tagged_version = orig_ver\n\t\tif using_hg_version:\n\t\t\tresult = safe_version(self.distribution.get_version())\n\t\telse:\n\t\t\tresult = orig_ver(self)\n\t\tself.tag_build = result\n\t\treturn result\n\tegg_info.tagged_version = tagged_version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef version_calc(dist, attr, value):\n\texpected_attrs = 'use_hg_version', 'use_vcs_version'\n\tif not value or attr not in expected_attrs:\n\t\treturn\n\toptions = value if isinstance(value, dict) else {}\n\tdist.metadata.version = calculate_version(options)\n\tpatch_egg_info()", "response": "Calculate version of the specified distribution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the storage space with the specified name or creates it if it does not exist.", "response": "def get_or_create(name,  value):\n\n    \"\"\"\n    returns the storage space defined by name\n\n    if space does not exist yet it will first be created with the\n    specified value\n    \"\"\"\n\n    if name not in storage:\n        storage[name] = value\n    return storage[name]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_module(module):\n    '''Parse a module's attributes and generate a markdown document.'''\n    attributes = [\n        (name, type_)\n        for (name, type_) in getmembers(module)\n        if (isclass(type_) or isfunction(type_))\n        and type_.__module__ == module.__name__\n        and not type_.__name__.startswith('_')\n    ]\n\n    attribute_docs = ['## {0}'.format(module.__name__), '']\n\n    if module.__doc__:\n        docstring, _ = _parse_docstring(module.__doc__)\n        attribute_docs.append(docstring)\n\n    if hasattr(module, '__all__'):\n        for name in module.__all__:\n            link = '+ [{0}](./{0}.md)'.format(name)\n            attribute_docs.append(link)\n\n    for (name, type_) in attributes:\n        if isfunction(type_):\n            attribute_docs.append(_parse_function(module, name, type_))\n        else:\n            attribute_docs.append(_parse_class(module, name, type_))\n\n    return u'{0}\\n'.format(\n        u'\\n'.join(attribute_docs).strip()\n    )", "response": "Parse a module s attributes and generate a markdown document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noptioning retry True, infinity retries False, no retries Number, retries times interval time period for retry return None if no success Message if success", "response": "def Retry(target=None, args=[], kwargs={},\n          options={\"retry\": True, \"interval\": 1}):\n    \"\"\"\n    options\n        retry\n            True, infinity retries\n            False, no retries\n            Number, retries times\n        interval\n            time period for retry\n        return\n            None if no success\n            Message if success\n    \"\"\"\n    retry = options[\"retry\"]\n    interval = options[\"interval\"]\n\n    while True:\n        try:\n            resp = target(*args, **kwargs)\n            # status error\n            if resp.code == 200:\n                return resp\n\n            _logger.debug(\"Request got response status: %s\"\n                          % (resp.code,) + \" retry: %s\" % (retry,))\n        except TimeoutError:\n            _logger.debug(\"Request message is timeout\")\n            _logger.debug(args)\n            _logger.debug(kwargs)\n\n        # register unsuccessful goes here\n        # infinity retry\n        if retry is True:\n            sleep(interval)\n            continue\n\n        # no retry\n        if retry is False:\n            return None\n\n        # retrying\n        try:\n            retry = retry - 1\n            if retry <= 0:\n                return None\n        except TypeError as e:\n            raise e\n        sleep(interval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_crud_func(self, method, request_type=\"CRUD\"):\n        def _crud(resource,\n                  data=None,\n                  block=True,\n                  timeout=60,\n                  topic=\"/controller\",\n                  tunnel=None,\n                  qos=0):\n            \"\"\"\n            _crud\n\n            block\n                True: wait until response arrival\n                False: wait until message is already published to local broker\n            \"\"\"\n            headers = {\n                \"resource\": resource,\n                \"method\": method\n            }\n\n            # DIRECT message needs put tunnel in headers for controller\n            if request_type == \"DIRECT\":\n                if tunnel is not None:\n                    headers[\"tunnel\"] = tunnel\n                elif self._conn.tunnels[\"view\"][0] is not None:\n                    headers[\"tunnel\"] = self._conn.tunnels[\"view\"][0]\n                elif self._conn.tunnels[\"model\"][0] is not None:\n                    headers[\"tunnel\"] = self._conn.tunnels[\"model\"][0]\n                else:\n                    headers[\"tunnel\"] = self._conn.tunnels[\"internel\"][0]\n\n            message = self._create_message(headers, data)\n            with self._session.session_lock:\n                mid = self._conn.publish(topic=topic,\n                                         qos=qos,\n                                         payload=message.to_dict())\n                session = self._session.create(message, mid=mid, age=timeout)\n                session[\"status\"] = Status.SENDING\n\n            # blocking, until we get response or published\n            if block is False:\n                return self._wait_published(session)\n            return self._wait_resolved(session)\n        return _crud", "response": "create_crud_func returns a function that creates a CRUD message and returns it"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning function for response", "response": "def create_response(self, message, sign):\n        \"\"\"\n        return function for response\n        \"\"\"\n        def _response(code=200, data=None):\n            \"\"\"\n            _response\n            \"\"\"\n            resp_msg = message.to_response(code=code, data=data, sign=sign)\n\n            with self._session.session_lock:\n                mid = self._conn.publish(topic=\"/controller\",\n                                         qos=0, payload=resp_msg.to_dict())\n                session = self._session.create(resp_msg, mid=mid, age=10)\n            logging.debug(\"sending response as mid: %s\" % mid)\n            return self._wait_published(session, no_response=True)\n        return _response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_assignment_groups(self, course_id, exclude_assignment_submission_types=None, grading_period_id=None, include=None, override_assignment_dates=None, scope_assignments_to_student=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group. \"discussion_topic\", \"all_dates\"\r\n        \"assignment_visibility\" & \"submission\" are only valid are only valid if \"assignments\" is also included.\r\n        The \"assignment_visibility\" option additionally requires that the Differentiated Assignments course feature be turned on.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"assignments\", \"discussion_topic\", \"all_dates\", \"assignment_visibility\", \"overrides\", \"submission\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - exclude_assignment_submission_types\r\n        \"\"\"If \"assignments\" are included, those with the specified submission types\r\n        will be excluded from the assignment groups.\"\"\"\r\n        if exclude_assignment_submission_types is not None:\r\n            self._validate_enum(exclude_assignment_submission_types, [\"online_quiz\", \"discussion_topic\", \"wiki_page\", \"external_tool\"])\r\n            params[\"exclude_assignment_submission_types\"] = exclude_assignment_submission_types\r\n\r\n        # OPTIONAL - override_assignment_dates\r\n        \"\"\"Apply assignment overrides for each assignment, defaults to true.\"\"\"\r\n        if override_assignment_dates is not None:\r\n            params[\"override_assignment_dates\"] = override_assignment_dates\r\n\r\n        # OPTIONAL - grading_period_id\r\n        \"\"\"The id of the grading period in which assignment groups are being requested\r\n        (Requires the Multiple Grading Periods feature turned on.)\"\"\"\r\n        if grading_period_id is not None:\r\n            params[\"grading_period_id\"] = grading_period_id\r\n\r\n        # OPTIONAL - scope_assignments_to_student\r\n        \"\"\"If true, all assignments returned will apply to the current user in the\r\n        specified grading period. If assignments apply to other students in the\r\n        specified grading period, but not the current user, they will not be\r\n        returned. (Requires the grading_period_id argument and the Multiple Grading\r\n        Periods feature turned on. In addition, the current user must be a student.)\"\"\"\r\n        if scope_assignments_to_student is not None:\r\n            params[\"scope_assignments_to_student\"] = scope_assignments_to_student\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignment_groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignment_groups\".format(**path), data=data, params=params, all_pages=True)", "response": "Returns a list of assignment groups for the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_assignment_group(self, course_id, assignment_group_id, grading_period_id=None, include=None, override_assignment_dates=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_group_id\"] = assignment_group_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group. \"discussion_topic\" and \"assignment_visibility\" and \"submission\"\r\n        are only valid if \"assignments\" is also included. The \"assignment_visibility\" option additionally\r\n        requires that the Differentiated Assignments course feature be turned on.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"assignments\", \"discussion_topic\", \"assignment_visibility\", \"submission\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - override_assignment_dates\r\n        \"\"\"Apply assignment overrides for each assignment, defaults to true.\"\"\"\r\n        if override_assignment_dates is not None:\r\n            params[\"override_assignment_dates\"] = override_assignment_dates\r\n\r\n        # OPTIONAL - grading_period_id\r\n        \"\"\"The id of the grading period in which assignment groups are being requested\r\n        (Requires the Multiple Grading Periods account feature turned on)\"\"\"\r\n        if grading_period_id is not None:\r\n            params[\"grading_period_id\"] = grading_period_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignment_groups/{assignment_group_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignment_groups/{assignment_group_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Get an Assignment Group. Returns the Assignment Group with the given id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_assignment_group(self, course_id, group_weight=None, integration_data=None, name=None, position=None, rules=None, sis_source_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"The assignment group's name\"\"\"\r\n        if name is not None:\r\n            data[\"name\"] = name\r\n\r\n        # OPTIONAL - position\r\n        \"\"\"The position of this assignment group in relation to the other assignment groups\"\"\"\r\n        if position is not None:\r\n            data[\"position\"] = position\r\n\r\n        # OPTIONAL - group_weight\r\n        \"\"\"The percent of the total grade that this assignment group represents\"\"\"\r\n        if group_weight is not None:\r\n            data[\"group_weight\"] = group_weight\r\n\r\n        # OPTIONAL - sis_source_id\r\n        \"\"\"The sis source id of the Assignment Group\"\"\"\r\n        if sis_source_id is not None:\r\n            data[\"sis_source_id\"] = sis_source_id\r\n\r\n        # OPTIONAL - integration_data\r\n        \"\"\"The integration data of the Assignment Group\"\"\"\r\n        if integration_data is not None:\r\n            data[\"integration_data\"] = integration_data\r\n\r\n        # OPTIONAL - rules\r\n        \"\"\"The grading rules that are applied within this assignment group\r\n        See the Assignment Group object definition for format\"\"\"\r\n        if rules is not None:\r\n            data[\"rules\"] = rules\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/assignment_groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/assignment_groups\".format(**path), data=data, params=params, single_item=True)", "response": "Create an Assignment Group. Creates a new Assignment Group with the specified parameters. Returns the new Assignment Group object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef edit_assignment_group(self, course_id, assignment_group_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_group_id\"] = assignment_group_id\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/assignment_groups/{assignment_group_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/assignment_groups/{assignment_group_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Edit an Assignment Group. Updates an existing Assignment Group. Returns the updated assignment group record record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new question group.", "response": "def create_question_group(self, quiz_id, course_id, quiz_groups_assessment_question_bank_id=None, quiz_groups_name=None, quiz_groups_pick_count=None, quiz_groups_question_points=None):\r\n        \"\"\"\r\n        Create a question group.\r\n\r\n        Create a new question group for this quiz\r\n        \r\n        <b>201 Created</b> response code is returned if the creation was successful.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - quiz_groups[name]\r\n        \"\"\"The name of the question group.\"\"\"\r\n        if quiz_groups_name is not None:\r\n            data[\"quiz_groups[name]\"] = quiz_groups_name\r\n\r\n        # OPTIONAL - quiz_groups[pick_count]\r\n        \"\"\"The number of questions to randomly select for this group.\"\"\"\r\n        if quiz_groups_pick_count is not None:\r\n            data[\"quiz_groups[pick_count]\"] = quiz_groups_pick_count\r\n\r\n        # OPTIONAL - quiz_groups[question_points]\r\n        \"\"\"The number of points to assign to each question in the group.\"\"\"\r\n        if quiz_groups_question_points is not None:\r\n            data[\"quiz_groups[question_points]\"] = quiz_groups_question_points\r\n\r\n        # OPTIONAL - quiz_groups[assessment_question_bank_id]\r\n        \"\"\"The id of the assessment question bank to pull questions from.\"\"\"\r\n        if quiz_groups_assessment_question_bank_id is not None:\r\n            data[\"quiz_groups[assessment_question_bank_id]\"] = quiz_groups_assessment_question_bank_id\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/groups\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_question_group(self, id, quiz_id, course_id, quiz_groups_name=None, quiz_groups_pick_count=None, quiz_groups_question_points=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - quiz_groups[name]\r\n        \"\"\"The name of the question group.\"\"\"\r\n        if quiz_groups_name is not None:\r\n            data[\"quiz_groups[name]\"] = quiz_groups_name\r\n\r\n        # OPTIONAL - quiz_groups[pick_count]\r\n        \"\"\"The number of questions to randomly select for this group.\"\"\"\r\n        if quiz_groups_pick_count is not None:\r\n            data[\"quiz_groups[pick_count]\"] = quiz_groups_pick_count\r\n\r\n        # OPTIONAL - quiz_groups[question_points]\r\n        \"\"\"The number of points to assign to each question in the group.\"\"\"\r\n        if quiz_groups_question_points is not None:\r\n            data[\"quiz_groups[question_points]\"] = quiz_groups_question_points\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/quizzes/{quiz_id}/groups/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/groups/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Update a question group. Updates the question group with the specified parameters. Returns the updated group record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreordering a quiz question group.", "response": "def reorder_question_groups(self, id, quiz_id, order_id, course_id, order_type=None):\r\n        \"\"\"\r\n        Reorder question groups.\r\n\r\n        Change the order of the quiz questions within the group\r\n        \r\n        <b>204 No Content<b> response code is returned if the reorder was successful.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - order[id]\r\n        \"\"\"The associated item's unique identifier\"\"\"\r\n        data[\"order[id]\"] = order_id\r\n\r\n        # OPTIONAL - order[type]\r\n        \"\"\"The type of item is always 'question' for a group\"\"\"\r\n        if order_type is not None:\r\n            self._validate_enum(order_type, [\"question\"])\r\n            data[\"order[type]\"] = order_type\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/groups/{id}/reorder with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/groups/{id}/reorder\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of active courses for the current user.", "response": "def list_your_courses(self, enrollment_role=None, enrollment_role_id=None, enrollment_state=None, enrollment_type=None, include=None, state=None):\r\n        \"\"\"\r\n        List your courses.\r\n\r\n        Returns the list of active courses for the current user.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - enrollment_type\r\n        \"\"\"When set, only return courses where the user is enrolled as this type. For\r\n        example, set to \"teacher\" to return only courses where the user is\r\n        enrolled as a Teacher.  This argument is ignored if enrollment_role is given.\"\"\"\r\n        if enrollment_type is not None:\r\n            self._validate_enum(enrollment_type, [\"teacher\", \"student\", \"ta\", \"observer\", \"designer\"])\r\n            params[\"enrollment_type\"] = enrollment_type\r\n\r\n        # OPTIONAL - enrollment_role\r\n        \"\"\"Deprecated\r\n        When set, only return courses where the user is enrolled with the specified\r\n        course-level role.  This can be a role created with the\r\n        {api:RoleOverridesController#add_role Add Role API} or a base role type of\r\n        'StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment', 'ObserverEnrollment',\r\n        or 'DesignerEnrollment'.\"\"\"\r\n        if enrollment_role is not None:\r\n            params[\"enrollment_role\"] = enrollment_role\r\n\r\n        # OPTIONAL - enrollment_role_id\r\n        \"\"\"When set, only return courses where the user is enrolled with the specified\r\n        course-level role.  This can be a role created with the\r\n        {api:RoleOverridesController#add_role Add Role API} or a built_in role type of\r\n        'StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment', 'ObserverEnrollment',\r\n        or 'DesignerEnrollment'.\"\"\"\r\n        if enrollment_role_id is not None:\r\n            params[\"enrollment_role_id\"] = enrollment_role_id\r\n\r\n        # OPTIONAL - enrollment_state\r\n        \"\"\"When set, only return courses where the user has an enrollment with the given state.\r\n        This will respect section/course/term date overrides.\"\"\"\r\n        if enrollment_state is not None:\r\n            self._validate_enum(enrollment_state, [\"active\", \"invited_or_pending\", \"completed\"])\r\n            params[\"enrollment_state\"] = enrollment_state\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"needs_grading_count\": Optional information to include with each Course.\r\n          When needs_grading_count is given, and the current user has grading\r\n          rights, the total number of submissions needing grading for all\r\n          assignments is returned.\r\n        - \"syllabus_body\": Optional information to include with each Course.\r\n          When syllabus_body is given the user-generated html for the course\r\n          syllabus is returned.\r\n        - \"public_description\": Optional information to include with each Course.\r\n          When public_description is given the user-generated text for the course\r\n          public description is returned.\r\n        - \"total_scores\": Optional information to include with each Course.\r\n          When total_scores is given, any student enrollments will also\r\n          include the fields 'computed_current_score', 'computed_final_score',\r\n          'computed_current_grade', and 'computed_final_grade' (see Enrollment\r\n          documentation for more information on these fields). This argument\r\n          is ignored if the course is configured to hide final grades.\r\n        - \"current_grading_period_scores\": Optional information to include with\r\n          each Course. When current_grading_period_scores is given and total_scores\r\n          is given, any student enrollments will also include the fields\r\n          'multiple_grading_periods_enabled',\r\n          'totals_for_all_grading_periods_option', 'current_grading_period_title',\r\n          'current_grading_period_id', current_period_computed_current_score',\r\n          'current_period_computed_final_score',\r\n          'current_period_computed_current_grade', and\r\n          'current_period_computed_final_grade' (see Enrollment documentation for\r\n          more information on these fields). In addition, when this argument is\r\n          passed, the course will have a 'multiple_grading_periods_enabled' attribute\r\n          on it. This argument is ignored if the course is configured to hide final\r\n          grades or if the total_scores argument is not included.\r\n        - \"term\": Optional information to include with each Course. When\r\n          term is given, the information for the enrollment term for each course\r\n          is returned.\r\n        - \"course_progress\": Optional information to include with each Course.\r\n          When course_progress is given, each course will include a\r\n          'course_progress' object with the fields: 'requirement_count', an integer\r\n          specifying the total number of requirements in the course,\r\n          'requirement_completed_count', an integer specifying the total number of\r\n          requirements in this course that have been completed, and\r\n          'next_requirement_url', a string url to the next requirement item, and\r\n          'completed_at', the date the course was completed (null if incomplete).\r\n          'next_requirement_url' will be null if all requirements have been\r\n          completed or the current module does not require sequential progress.\r\n          \"course_progress\" will return an error message if the course is not\r\n          module based or the user is not enrolled as a student in the course.\r\n        - \"sections\": Section enrollment information to include with each Course.\r\n          Returns an array of hashes containing the section ID (id), section name\r\n          (name), start and end dates (start_at, end_at), as well as the enrollment\r\n          type (enrollment_role, e.g. 'StudentEnrollment').\r\n        - \"storage_quota_used_mb\": The amount of storage space used by the files in this course\r\n        - \"total_students\": Optional information to include with each Course.\r\n          Returns an integer for the total amount of active and invited students.\r\n        - \"passback_status\": Include the grade passback_status\r\n        - \"favorites\": Optional information to include with each Course.\r\n          Indicates if the user has marked the course as a favorite course.\r\n        - \"teachers\": Teacher information to include with each Course.\r\n          Returns an array of hashes containing the {api:Users:UserDisplay UserDisplay} information\r\n          for each teacher in the course.\r\n        - \"observed_users\": Optional information to include with each Course.\r\n          Will include data for observed users if the current user has an\r\n          observer enrollment.\r\n        - \"tabs\": Optional information to include with each Course.\r\n          Will include the list of tabs configured for each course.  See the\r\n          {api:TabsController#index List available tabs API} for more information.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"needs_grading_count\", \"syllabus_body\", \"public_description\", \"total_scores\", \"current_grading_period_scores\", \"term\", \"course_progress\", \"sections\", \"storage_quota_used_mb\", \"total_students\", \"passback_status\", \"favorites\", \"teachers\", \"observed_users\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"If set, only return courses that are in the given state(s).\r\n        By default, \"available\" is returned for students and observers, and\r\n        anything except \"deleted\", for all other enrollment types\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"unpublished\", \"available\", \"completed\", \"deleted\"])\r\n            params[\"state\"] = state\r\n\r\n        self.logger.debug(\"GET /api/v1/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of active courses for a given user.", "response": "def list_courses_for_user(self, user_id, enrollment_state=None, include=None, state=None):\r\n        \"\"\"\r\n        List courses for a user.\r\n\r\n        Returns a list of active courses for this user. To view the course list for a user other than yourself, you must be either an observer of that user or an administrator.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"needs_grading_count\": Optional information to include with each Course.\r\n          When needs_grading_count is given, and the current user has grading\r\n          rights, the total number of submissions needing grading for all\r\n          assignments is returned.\r\n        - \"syllabus_body\": Optional information to include with each Course.\r\n          When syllabus_body is given the user-generated html for the course\r\n          syllabus is returned.\r\n        - \"public_description\": Optional information to include with each Course.\r\n          When public_description is given the user-generated text for the course\r\n          public description is returned.\r\n        - \"total_scores\": Optional information to include with each Course.\r\n          When total_scores is given, any student enrollments will also\r\n          include the fields 'computed_current_score', 'computed_final_score',\r\n          'computed_current_grade', and 'computed_final_grade' (see Enrollment\r\n          documentation for more information on these fields). This argument\r\n          is ignored if the course is configured to hide final grades.\r\n        - \"current_grading_period_scores\": Optional information to include with\r\n          each Course. When current_grading_period_scores is given and total_scores\r\n          is given, any student enrollments will also include the fields\r\n          'multiple_grading_periods_enabled',\r\n          'totals_for_all_grading_periods_option', 'current_grading_period_title',\r\n          'current_grading_period_id', current_period_computed_current_score',\r\n          'current_period_computed_final_score',\r\n          'current_period_computed_current_grade', and\r\n          'current_period_computed_final_grade' (see Enrollment documentation for\r\n          more information on these fields). In addition, when this argument is\r\n          passed, the course will have a 'multiple_grading_periods_enabled' attribute\r\n          on it. This argument is ignored if the course is configured to hide final\r\n          grades or if the total_scores argument is not included.\r\n        - \"term\": Optional information to include with each Course. When\r\n          term is given, the information for the enrollment term for each course\r\n          is returned.\r\n        - \"course_progress\": Optional information to include with each Course.\r\n          When course_progress is given, each course will include a\r\n          'course_progress' object with the fields: 'requirement_count', an integer\r\n          specifying the total number of requirements in the course,\r\n          'requirement_completed_count', an integer specifying the total number of\r\n          requirements in this course that have been completed, and\r\n          'next_requirement_url', a string url to the next requirement item, and\r\n          'completed_at', the date the course was completed (null if incomplete).\r\n          'next_requirement_url' will be null if all requirements have been\r\n          completed or the current module does not require sequential progress.\r\n          \"course_progress\" will return an error message if the course is not\r\n          module based or the user is not enrolled as a student in the course.\r\n        - \"sections\": Section enrollment information to include with each Course.\r\n          Returns an array of hashes containing the section ID (id), section name\r\n          (name), start and end dates (start_at, end_at), as well as the enrollment\r\n          type (enrollment_role, e.g. 'StudentEnrollment').\r\n        - \"storage_quota_used_mb\": The amount of storage space used by the files in this course\r\n        - \"total_students\": Optional information to include with each Course.\r\n          Returns an integer for the total amount of active and invited students.\r\n        - \"passback_status\": Include the grade passback_status\r\n        - \"favorites\": Optional information to include with each Course.\r\n          Indicates if the user has marked the course as a favorite course.\r\n        - \"teachers\": Teacher information to include with each Course.\r\n          Returns an array of hashes containing the {api:Users:UserDisplay UserDisplay} information\r\n          for each teacher in the course.\r\n        - \"observed_users\": Optional information to include with each Course.\r\n          Will include data for observed users if the current user has an\r\n          observer enrollment.\r\n        - \"tabs\": Optional information to include with each Course.\r\n          Will include the list of tabs configured for each course.  See the\r\n          {api:TabsController#index List available tabs API} for more information.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"needs_grading_count\", \"syllabus_body\", \"public_description\", \"total_scores\", \"current_grading_period_scores\", \"term\", \"course_progress\", \"sections\", \"storage_quota_used_mb\", \"total_students\", \"passback_status\", \"favorites\", \"teachers\", \"observed_users\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"If set, only return courses that are in the given state(s).\r\n        By default, \"available\" is returned for students and observers, and\r\n        anything except \"deleted\", for all other enrollment types\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"unpublished\", \"available\", \"completed\", \"deleted\"])\r\n            params[\"state\"] = state\r\n\r\n        # OPTIONAL - enrollment_state\r\n        \"\"\"When set, only return courses where the user has an enrollment with the given state.\r\n        This will respect section/course/term date overrides.\"\"\"\r\n        if enrollment_state is not None:\r\n            self._validate_enum(enrollment_state, [\"active\", \"invited_or_pending\", \"completed\"])\r\n            params[\"enrollment_state\"] = enrollment_state\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/courses\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_new_course(self, account_id, course_allow_student_forum_attachments=None, course_allow_student_wiki_edits=None, course_allow_wiki_comments=None, course_apply_assignment_group_weights=None, course_course_code=None, course_course_format=None, course_end_at=None, course_grading_standard_id=None, course_hide_final_grades=None, course_integration_id=None, course_is_public=None, course_is_public_to_auth_users=None, course_license=None, course_name=None, course_open_enrollment=None, course_public_description=None, course_public_syllabus=None, course_public_syllabus_to_auth=None, course_restrict_enrollments_to_course_dates=None, course_self_enrollment=None, course_sis_course_id=None, course_start_at=None, course_syllabus_body=None, course_term_id=None, course_time_zone=None, enable_sis_reactivation=None, enroll_me=None, offer=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - course[name]\r\n        \"\"\"The name of the course. If omitted, the course will be named \"Unnamed\r\n        Course.\" \"\"\"\r\n        if course_name is not None:\r\n            data[\"course[name]\"] = course_name\r\n\r\n        # OPTIONAL - course[course_code]\r\n        \"\"\"The course code for the course.\"\"\"\r\n        if course_course_code is not None:\r\n            data[\"course[course_code]\"] = course_course_code\r\n\r\n        # OPTIONAL - course[start_at]\r\n        \"\"\"Course start date in ISO8601 format, e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_start_at is not None:\r\n            data[\"course[start_at]\"] = course_start_at\r\n\r\n        # OPTIONAL - course[end_at]\r\n        \"\"\"Course end date in ISO8601 format. e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_end_at is not None:\r\n            data[\"course[end_at]\"] = course_end_at\r\n\r\n        # OPTIONAL - course[license]\r\n        \"\"\"The name of the licensing. Should be one of the following abbreviations\r\n        (a descriptive name is included in parenthesis for reference):\r\n        - 'private' (Private Copyrighted)\r\n        - 'cc_by_nc_nd' (CC Attribution Non-Commercial No Derivatives)\r\n        - 'cc_by_nc_sa' (CC Attribution Non-Commercial Share Alike)\r\n        - 'cc_by_nc' (CC Attribution Non-Commercial)\r\n        - 'cc_by_nd' (CC Attribution No Derivatives)\r\n        - 'cc_by_sa' (CC Attribution Share Alike)\r\n        - 'cc_by' (CC Attribution)\r\n        - 'public_domain' (Public Domain).\"\"\"\r\n        if course_license is not None:\r\n            data[\"course[license]\"] = course_license\r\n\r\n        # OPTIONAL - course[is_public]\r\n        \"\"\"Set to true if course is public to both authenticated and unauthenticated users.\"\"\"\r\n        if course_is_public is not None:\r\n            data[\"course[is_public]\"] = course_is_public\r\n\r\n        # OPTIONAL - course[is_public_to_auth_users]\r\n        \"\"\"Set to true if course is public only to authenticated users.\"\"\"\r\n        if course_is_public_to_auth_users is not None:\r\n            data[\"course[is_public_to_auth_users]\"] = course_is_public_to_auth_users\r\n\r\n        # OPTIONAL - course[public_syllabus]\r\n        \"\"\"Set to true to make the course syllabus public.\"\"\"\r\n        if course_public_syllabus is not None:\r\n            data[\"course[public_syllabus]\"] = course_public_syllabus\r\n\r\n        # OPTIONAL - course[public_syllabus_to_auth]\r\n        \"\"\"Set to true to make the course syllabus public for authenticated users.\"\"\"\r\n        if course_public_syllabus_to_auth is not None:\r\n            data[\"course[public_syllabus_to_auth]\"] = course_public_syllabus_to_auth\r\n\r\n        # OPTIONAL - course[public_description]\r\n        \"\"\"A publicly visible description of the course.\"\"\"\r\n        if course_public_description is not None:\r\n            data[\"course[public_description]\"] = course_public_description\r\n\r\n        # OPTIONAL - course[allow_student_wiki_edits]\r\n        \"\"\"If true, students will be able to modify the course wiki.\"\"\"\r\n        if course_allow_student_wiki_edits is not None:\r\n            data[\"course[allow_student_wiki_edits]\"] = course_allow_student_wiki_edits\r\n\r\n        # OPTIONAL - course[allow_wiki_comments]\r\n        \"\"\"If true, course members will be able to comment on wiki pages.\"\"\"\r\n        if course_allow_wiki_comments is not None:\r\n            data[\"course[allow_wiki_comments]\"] = course_allow_wiki_comments\r\n\r\n        # OPTIONAL - course[allow_student_forum_attachments]\r\n        \"\"\"If true, students can attach files to forum posts.\"\"\"\r\n        if course_allow_student_forum_attachments is not None:\r\n            data[\"course[allow_student_forum_attachments]\"] = course_allow_student_forum_attachments\r\n\r\n        # OPTIONAL - course[open_enrollment]\r\n        \"\"\"Set to true if the course is open enrollment.\"\"\"\r\n        if course_open_enrollment is not None:\r\n            data[\"course[open_enrollment]\"] = course_open_enrollment\r\n\r\n        # OPTIONAL - course[self_enrollment]\r\n        \"\"\"Set to true if the course is self enrollment.\"\"\"\r\n        if course_self_enrollment is not None:\r\n            data[\"course[self_enrollment]\"] = course_self_enrollment\r\n\r\n        # OPTIONAL - course[restrict_enrollments_to_course_dates]\r\n        \"\"\"Set to true to restrict user enrollments to the start and end dates of the\r\n        course.\"\"\"\r\n        if course_restrict_enrollments_to_course_dates is not None:\r\n            data[\"course[restrict_enrollments_to_course_dates]\"] = course_restrict_enrollments_to_course_dates\r\n\r\n        # OPTIONAL - course[term_id]\r\n        \"\"\"The unique ID of the term to create to course in.\"\"\"\r\n        if course_term_id is not None:\r\n            data[\"course[term_id]\"] = course_term_id\r\n\r\n        # OPTIONAL - course[sis_course_id]\r\n        \"\"\"The unique SIS identifier.\"\"\"\r\n        if course_sis_course_id is not None:\r\n            data[\"course[sis_course_id]\"] = course_sis_course_id\r\n\r\n        # OPTIONAL - course[integration_id]\r\n        \"\"\"The unique Integration identifier.\"\"\"\r\n        if course_integration_id is not None:\r\n            data[\"course[integration_id]\"] = course_integration_id\r\n\r\n        # OPTIONAL - course[hide_final_grades]\r\n        \"\"\"If this option is set to true, the totals in student grades summary will\r\n        be hidden.\"\"\"\r\n        if course_hide_final_grades is not None:\r\n            data[\"course[hide_final_grades]\"] = course_hide_final_grades\r\n\r\n        # OPTIONAL - course[apply_assignment_group_weights]\r\n        \"\"\"Set to true to weight final grade based on assignment groups percentages.\"\"\"\r\n        if course_apply_assignment_group_weights is not None:\r\n            data[\"course[apply_assignment_group_weights]\"] = course_apply_assignment_group_weights\r\n\r\n        # OPTIONAL - course[time_zone]\r\n        \"\"\"The time zone for the course. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if course_time_zone is not None:\r\n            data[\"course[time_zone]\"] = course_time_zone\r\n\r\n        # OPTIONAL - offer\r\n        \"\"\"If this option is set to true, the course will be available to students\r\n        immediately.\"\"\"\r\n        if offer is not None:\r\n            data[\"offer\"] = offer\r\n\r\n        # OPTIONAL - enroll_me\r\n        \"\"\"Set to true to enroll the current user as the teacher.\"\"\"\r\n        if enroll_me is not None:\r\n            data[\"enroll_me\"] = enroll_me\r\n\r\n        # OPTIONAL - course[syllabus_body]\r\n        \"\"\"The syllabus body for the course\"\"\"\r\n        if course_syllabus_body is not None:\r\n            data[\"course[syllabus_body]\"] = course_syllabus_body\r\n\r\n        # OPTIONAL - course[grading_standard_id]\r\n        \"\"\"The grading standard id to set for the course.  If no value is provided for this argument the current grading_standard will be un-set from this course.\"\"\"\r\n        if course_grading_standard_id is not None:\r\n            data[\"course[grading_standard_id]\"] = course_grading_standard_id\r\n\r\n        # OPTIONAL - course[course_format]\r\n        \"\"\"Optional. Specifies the format of the course. (Should be 'on_campus', 'online', or 'blended')\"\"\"\r\n        if course_course_format is not None:\r\n            data[\"course[course_format]\"] = course_course_format\r\n\r\n        # OPTIONAL - enable_sis_reactivation\r\n        \"\"\"When true, will first try to re-activate a deleted course with matching sis_course_id if possible.\"\"\"\r\n        if enable_sis_reactivation is not None:\r\n            data[\"enable_sis_reactivation\"] = enable_sis_reactivation\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/courses\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new course. Returns a new course with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of users in a course.", "response": "def list_users_in_course_users(self, course_id, enrollment_role=None, enrollment_role_id=None, enrollment_state=None, enrollment_type=None, include=None, search_term=None, user_id=None, user_ids=None):\r\n        \"\"\"\r\n        List users in course.\r\n\r\n        Returns the list of users in this course. And optionally the user's enrollments in the course.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name or full ID of the users to match and return in the results list.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - enrollment_type\r\n        \"\"\"When set, only return users where the user is enrolled as this type.\r\n        \"student_view\" implies include[]=test_student.\r\n        This argument is ignored if enrollment_role is given.\"\"\"\r\n        if enrollment_type is not None:\r\n            self._validate_enum(enrollment_type, [\"teacher\", \"student\", \"student_view\", \"ta\", \"observer\", \"designer\"])\r\n            params[\"enrollment_type\"] = enrollment_type\r\n\r\n        # OPTIONAL - enrollment_role\r\n        \"\"\"Deprecated\r\n        When set, only return users enrolled with the specified course-level role.  This can be\r\n        a role created with the {api:RoleOverridesController#add_role Add Role API} or a\r\n        base role type of 'StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment',\r\n        'ObserverEnrollment', or 'DesignerEnrollment'.\"\"\"\r\n        if enrollment_role is not None:\r\n            params[\"enrollment_role\"] = enrollment_role\r\n\r\n        # OPTIONAL - enrollment_role_id\r\n        \"\"\"When set, only return courses where the user is enrolled with the specified\r\n        course-level role.  This can be a role created with the\r\n        {api:RoleOverridesController#add_role Add Role API} or a built_in role id with type\r\n        'StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment', 'ObserverEnrollment',\r\n        or 'DesignerEnrollment'.\"\"\"\r\n        if enrollment_role_id is not None:\r\n            params[\"enrollment_role_id\"] = enrollment_role_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"email\": Optional user email.\r\n        - \"enrollments\":\r\n        Optionally include with each Course the user's current and invited\r\n        enrollments. If the user is enrolled as a student, and the account has\r\n        permission to manage or view all grades, each enrollment will include a\r\n        'grades' key with 'current_score', 'final_score', 'current_grade' and\r\n        'final_grade' values.\r\n        - \"locked\": Optionally include whether an enrollment is locked.\r\n        - \"avatar_url\": Optionally include avatar_url.\r\n        - \"bio\": Optionally include each user's bio.\r\n        - \"test_student\": Optionally include the course's Test Student,\r\n        if present. Default is to not include Test Student.\r\n        - \"custom_links\": Optionally include plugin-supplied custom links for each student,\r\n        such as analytics information\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"email\", \"enrollments\", \"locked\", \"avatar_url\", \"test_student\", \"bio\", \"custom_links\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - user_id\r\n        \"\"\"If this parameter is given and it corresponds to a user in the course,\r\n        the +page+ parameter will be ignored and the page containing the specified user\r\n        will be returned instead.\"\"\"\r\n        if user_id is not None:\r\n            params[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - user_ids\r\n        \"\"\"If included, the course users set will only include users with IDs\r\n        specified by the param. Note: this will not work in conjunction\r\n        with the \"user_id\" argument but multiple user_ids can be included.\"\"\"\r\n        if user_ids is not None:\r\n            params[\"user_ids\"] = user_ids\r\n\r\n        # OPTIONAL - enrollment_state\r\n        \"\"\"When set, only return users where the enrollment workflow state is of one of the given types.\r\n        \"active\" and \"invited\" enrollments are returned by default.\"\"\"\r\n        if enrollment_state is not None:\r\n            self._validate_enum(enrollment_state, [\"active\", \"invited\", \"rejected\", \"completed\", \"inactive\"])\r\n            params[\"enrollment_state\"] = enrollment_state\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/users\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconcludes a course. Conclude a course. Delete or conclude an existing course. Conclude an existing course. Conclude an existing course. Conclude an existing course.", "response": "def conclude_course(self, id, event):\r\n        \"\"\"\r\n        Conclude a course.\r\n\r\n        Delete or conclude an existing course\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - event\r\n        \"\"\"The action to take on the course.\"\"\"\r\n        self._validate_enum(event, [\"delete\", \"conclude\"])\r\n        params[\"event\"] = event\r\n\r\n        self.logger.debug(\"DELETE /api/v1/courses/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/courses/{id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_course_settings(self, course_id, allow_student_discussion_editing=None, allow_student_discussion_topics=None, allow_student_forum_attachments=None, allow_student_organized_groups=None, hide_distribution_graphs=None, hide_final_grades=None, home_page_announcement_limit=None, lock_all_announcements=None, restrict_student_future_view=None, restrict_student_past_view=None, show_announcements_on_home_page=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - allow_student_discussion_topics\r\n        \"\"\"Let students create discussion topics\"\"\"\r\n        if allow_student_discussion_topics is not None:\r\n            data[\"allow_student_discussion_topics\"] = allow_student_discussion_topics\r\n\r\n        # OPTIONAL - allow_student_forum_attachments\r\n        \"\"\"Let students attach files to discussions\"\"\"\r\n        if allow_student_forum_attachments is not None:\r\n            data[\"allow_student_forum_attachments\"] = allow_student_forum_attachments\r\n\r\n        # OPTIONAL - allow_student_discussion_editing\r\n        \"\"\"Let students edit or delete their own discussion posts\"\"\"\r\n        if allow_student_discussion_editing is not None:\r\n            data[\"allow_student_discussion_editing\"] = allow_student_discussion_editing\r\n\r\n        # OPTIONAL - allow_student_organized_groups\r\n        \"\"\"Let students organize their own groups\"\"\"\r\n        if allow_student_organized_groups is not None:\r\n            data[\"allow_student_organized_groups\"] = allow_student_organized_groups\r\n\r\n        # OPTIONAL - hide_final_grades\r\n        \"\"\"Hide totals in student grades summary\"\"\"\r\n        if hide_final_grades is not None:\r\n            data[\"hide_final_grades\"] = hide_final_grades\r\n\r\n        # OPTIONAL - hide_distribution_graphs\r\n        \"\"\"Hide grade distribution graphs from students\"\"\"\r\n        if hide_distribution_graphs is not None:\r\n            data[\"hide_distribution_graphs\"] = hide_distribution_graphs\r\n\r\n        # OPTIONAL - lock_all_announcements\r\n        \"\"\"Disable comments on announcements\"\"\"\r\n        if lock_all_announcements is not None:\r\n            data[\"lock_all_announcements\"] = lock_all_announcements\r\n\r\n        # OPTIONAL - restrict_student_past_view\r\n        \"\"\"Restrict students from viewing courses after end date\"\"\"\r\n        if restrict_student_past_view is not None:\r\n            data[\"restrict_student_past_view\"] = restrict_student_past_view\r\n\r\n        # OPTIONAL - restrict_student_future_view\r\n        \"\"\"Restrict students from viewing courses before start date\"\"\"\r\n        if restrict_student_future_view is not None:\r\n            data[\"restrict_student_future_view\"] = restrict_student_future_view\r\n\r\n        # OPTIONAL - show_announcements_on_home_page\r\n        \"\"\"Show the most recent announcements on the Course home page (if a Wiki, defaults to five announcements, configurable via home_page_announcement_limit)\"\"\"\r\n        if show_announcements_on_home_page is not None:\r\n            data[\"show_announcements_on_home_page\"] = show_announcements_on_home_page\r\n\r\n        # OPTIONAL - home_page_announcement_limit\r\n        \"\"\"Limit the number of announcements on the home page if enabled via show_announcements_on_home_page\"\"\"\r\n        if home_page_announcement_limit is not None:\r\n            data[\"home_page_announcement_limit\"] = home_page_announcement_limit\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/settings with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/settings\".format(**path), data=data, params=params, no_data=True)", "response": "Updates the course settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a course. Returns the full course record for the given course.", "response": "def update_course(self, id, course_account_id=None, course_allow_student_forum_attachments=None, course_allow_student_wiki_edits=None, course_allow_wiki_comments=None, course_apply_assignment_group_weights=None, course_course_code=None, course_course_format=None, course_end_at=None, course_event=None, course_grading_standard_id=None, course_hide_final_grades=None, course_image_id=None, course_image_url=None, course_integration_id=None, course_is_public=None, course_is_public_to_auth_users=None, course_license=None, course_name=None, course_open_enrollment=None, course_public_description=None, course_public_syllabus=None, course_public_syllabus_to_auth=None, course_remove_image=None, course_restrict_enrollments_to_course_dates=None, course_self_enrollment=None, course_sis_course_id=None, course_start_at=None, course_storage_quota_mb=None, course_syllabus_body=None, course_term_id=None, course_time_zone=None, offer=None):\r\n        \"\"\"\r\n        Update a course.\r\n\r\n        Update an existing course.\r\n        \r\n        Arguments are the same as Courses#create, with a few exceptions (enroll_me).\r\n        \r\n        If a user has content management rights, but not full course editing rights, the only attribute\r\n        editable through this endpoint will be \"syllabus_body\"\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - course[account_id]\r\n        \"\"\"The unique ID of the account to move the course to.\"\"\"\r\n        if course_account_id is not None:\r\n            data[\"course[account_id]\"] = course_account_id\r\n\r\n        # OPTIONAL - course[name]\r\n        \"\"\"The name of the course. If omitted, the course will be named \"Unnamed\r\n        Course.\" \"\"\"\r\n        if course_name is not None:\r\n            data[\"course[name]\"] = course_name\r\n\r\n        # OPTIONAL - course[course_code]\r\n        \"\"\"The course code for the course.\"\"\"\r\n        if course_course_code is not None:\r\n            data[\"course[course_code]\"] = course_course_code\r\n\r\n        # OPTIONAL - course[start_at]\r\n        \"\"\"Course start date in ISO8601 format, e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_start_at is not None:\r\n            data[\"course[start_at]\"] = course_start_at\r\n\r\n        # OPTIONAL - course[end_at]\r\n        \"\"\"Course end date in ISO8601 format. e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_end_at is not None:\r\n            data[\"course[end_at]\"] = course_end_at\r\n\r\n        # OPTIONAL - course[license]\r\n        \"\"\"The name of the licensing. Should be one of the following abbreviations\r\n        (a descriptive name is included in parenthesis for reference):\r\n        - 'private' (Private Copyrighted)\r\n        - 'cc_by_nc_nd' (CC Attribution Non-Commercial No Derivatives)\r\n        - 'cc_by_nc_sa' (CC Attribution Non-Commercial Share Alike)\r\n        - 'cc_by_nc' (CC Attribution Non-Commercial)\r\n        - 'cc_by_nd' (CC Attribution No Derivatives)\r\n        - 'cc_by_sa' (CC Attribution Share Alike)\r\n        - 'cc_by' (CC Attribution)\r\n        - 'public_domain' (Public Domain).\"\"\"\r\n        if course_license is not None:\r\n            data[\"course[license]\"] = course_license\r\n\r\n        # OPTIONAL - course[is_public]\r\n        \"\"\"Set to true if course is public to both authenticated and unauthenticated users.\"\"\"\r\n        if course_is_public is not None:\r\n            data[\"course[is_public]\"] = course_is_public\r\n\r\n        # OPTIONAL - course[is_public_to_auth_users]\r\n        \"\"\"Set to true if course is public only to authenticated users.\"\"\"\r\n        if course_is_public_to_auth_users is not None:\r\n            data[\"course[is_public_to_auth_users]\"] = course_is_public_to_auth_users\r\n\r\n        # OPTIONAL - course[public_syllabus]\r\n        \"\"\"Set to true to make the course syllabus public.\"\"\"\r\n        if course_public_syllabus is not None:\r\n            data[\"course[public_syllabus]\"] = course_public_syllabus\r\n\r\n        # OPTIONAL - course[public_syllabus_to_auth]\r\n        \"\"\"Set to true to make the course syllabus to public for authenticated users.\"\"\"\r\n        if course_public_syllabus_to_auth is not None:\r\n            data[\"course[public_syllabus_to_auth]\"] = course_public_syllabus_to_auth\r\n\r\n        # OPTIONAL - course[public_description]\r\n        \"\"\"A publicly visible description of the course.\"\"\"\r\n        if course_public_description is not None:\r\n            data[\"course[public_description]\"] = course_public_description\r\n\r\n        # OPTIONAL - course[allow_student_wiki_edits]\r\n        \"\"\"If true, students will be able to modify the course wiki.\"\"\"\r\n        if course_allow_student_wiki_edits is not None:\r\n            data[\"course[allow_student_wiki_edits]\"] = course_allow_student_wiki_edits\r\n\r\n        # OPTIONAL - course[allow_wiki_comments]\r\n        \"\"\"If true, course members will be able to comment on wiki pages.\"\"\"\r\n        if course_allow_wiki_comments is not None:\r\n            data[\"course[allow_wiki_comments]\"] = course_allow_wiki_comments\r\n\r\n        # OPTIONAL - course[allow_student_forum_attachments]\r\n        \"\"\"If true, students can attach files to forum posts.\"\"\"\r\n        if course_allow_student_forum_attachments is not None:\r\n            data[\"course[allow_student_forum_attachments]\"] = course_allow_student_forum_attachments\r\n\r\n        # OPTIONAL - course[open_enrollment]\r\n        \"\"\"Set to true if the course is open enrollment.\"\"\"\r\n        if course_open_enrollment is not None:\r\n            data[\"course[open_enrollment]\"] = course_open_enrollment\r\n\r\n        # OPTIONAL - course[self_enrollment]\r\n        \"\"\"Set to true if the course is self enrollment.\"\"\"\r\n        if course_self_enrollment is not None:\r\n            data[\"course[self_enrollment]\"] = course_self_enrollment\r\n\r\n        # OPTIONAL - course[restrict_enrollments_to_course_dates]\r\n        \"\"\"Set to true to restrict user enrollments to the start and end dates of the\r\n        course.\"\"\"\r\n        if course_restrict_enrollments_to_course_dates is not None:\r\n            data[\"course[restrict_enrollments_to_course_dates]\"] = course_restrict_enrollments_to_course_dates\r\n\r\n        # OPTIONAL - course[term_id]\r\n        \"\"\"The unique ID of the term to create to course in.\"\"\"\r\n        if course_term_id is not None:\r\n            data[\"course[term_id]\"] = course_term_id\r\n\r\n        # OPTIONAL - course[sis_course_id]\r\n        \"\"\"The unique SIS identifier.\"\"\"\r\n        if course_sis_course_id is not None:\r\n            data[\"course[sis_course_id]\"] = course_sis_course_id\r\n\r\n        # OPTIONAL - course[integration_id]\r\n        \"\"\"The unique Integration identifier.\"\"\"\r\n        if course_integration_id is not None:\r\n            data[\"course[integration_id]\"] = course_integration_id\r\n\r\n        # OPTIONAL - course[hide_final_grades]\r\n        \"\"\"If this option is set to true, the totals in student grades summary will\r\n        be hidden.\"\"\"\r\n        if course_hide_final_grades is not None:\r\n            data[\"course[hide_final_grades]\"] = course_hide_final_grades\r\n\r\n        # OPTIONAL - course[time_zone]\r\n        \"\"\"The time zone for the course. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if course_time_zone is not None:\r\n            data[\"course[time_zone]\"] = course_time_zone\r\n\r\n        # OPTIONAL - course[apply_assignment_group_weights]\r\n        \"\"\"Set to true to weight final grade based on assignment groups percentages.\"\"\"\r\n        if course_apply_assignment_group_weights is not None:\r\n            data[\"course[apply_assignment_group_weights]\"] = course_apply_assignment_group_weights\r\n\r\n        # OPTIONAL - course[storage_quota_mb]\r\n        \"\"\"Set the storage quota for the course, in megabytes. The caller must have\r\n        the \"Manage storage quotas\" account permission.\"\"\"\r\n        if course_storage_quota_mb is not None:\r\n            data[\"course[storage_quota_mb]\"] = course_storage_quota_mb\r\n\r\n        # OPTIONAL - offer\r\n        \"\"\"If this option is set to true, the course will be available to students\r\n        immediately.\"\"\"\r\n        if offer is not None:\r\n            data[\"offer\"] = offer\r\n\r\n        # OPTIONAL - course[event]\r\n        \"\"\"The action to take on each course.\r\n        * 'claim' makes a course no longer visible to students. This action is also called \"unpublish\" on the web site.\r\n          A course cannot be unpublished if students have received graded submissions.\r\n        * 'offer' makes a course visible to students. This action is also called \"publish\" on the web site.\r\n        * 'conclude' prevents future enrollments and makes a course read-only for all participants. The course still appears\r\n          in prior-enrollment lists.\r\n        * 'delete' completely removes the course from the web site (including course menus and prior-enrollment lists).\r\n          All enrollments are deleted. Course content may be physically deleted at a future date.\r\n        * 'undelete' attempts to recover a course that has been deleted. (Recovery is not guaranteed; please conclude\r\n          rather than delete a course if there is any possibility the course will be used again.) The recovered course\r\n          will be unpublished. Deleted enrollments will not be recovered.\"\"\"\r\n        if course_event is not None:\r\n            self._validate_enum(course_event, [\"claim\", \"offer\", \"conclude\", \"delete\", \"undelete\"])\r\n            data[\"course[event]\"] = course_event\r\n\r\n        # OPTIONAL - course[syllabus_body]\r\n        \"\"\"The syllabus body for the course\"\"\"\r\n        if course_syllabus_body is not None:\r\n            data[\"course[syllabus_body]\"] = course_syllabus_body\r\n\r\n        # OPTIONAL - course[grading_standard_id]\r\n        \"\"\"The grading standard id to set for the course.  If no value is provided for this argument the current grading_standard will be un-set from this course.\"\"\"\r\n        if course_grading_standard_id is not None:\r\n            data[\"course[grading_standard_id]\"] = course_grading_standard_id\r\n\r\n        # OPTIONAL - course[course_format]\r\n        \"\"\"Optional. Specifies the format of the course. (Should be either 'on_campus' or 'online')\"\"\"\r\n        if course_course_format is not None:\r\n            data[\"course[course_format]\"] = course_course_format\r\n\r\n        # OPTIONAL - course[image_id]\r\n        \"\"\"This is a file ID corresponding to an image file in the course that will\r\n        be used as the course image.\r\n        This will clear the course's image_url setting if set.  If you attempt\r\n        to provide image_url and image_id in a request it will fail.\"\"\"\r\n        if course_image_id is not None:\r\n            data[\"course[image_id]\"] = course_image_id\r\n\r\n        # OPTIONAL - course[image_url]\r\n        \"\"\"This is a URL to an image to be used as the course image.\r\n        This will clear the course's image_id setting if set.  If you attempt\r\n        to provide image_url and image_id in a request it will fail.\"\"\"\r\n        if course_image_url is not None:\r\n            data[\"course[image_url]\"] = course_image_url\r\n\r\n        # OPTIONAL - course[remove_image]\r\n        \"\"\"If this option is set to true, the course image url and course image\r\n        ID are both set to nil\"\"\"\r\n        if course_remove_image is not None:\r\n            data[\"course[remove_image]\"] = course_remove_image\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating multiple courses in an account. Operates asynchronously ; use the ProgressController#show progress endpoint.", "response": "def update_courses(self, event, account_id, course_ids):\r\n        \"\"\"\r\n        Update courses.\r\n\r\n        Update multiple courses in an account.  Operates asynchronously; use the {api:ProgressController#show progress endpoint}\r\n        to query the status of an operation.\r\n        \r\n        The action to take on each course.  Must be one of 'offer', 'conclude', 'delete', or 'undelete'.\r\n          * 'offer' makes a course visible to students. This action is also called \"publish\" on the web site.\r\n          * 'conclude' prevents future enrollments and makes a course read-only for all participants. The course still appears\r\n            in prior-enrollment lists.\r\n          * 'delete' completely removes the course from the web site (including course menus and prior-enrollment lists).\r\n            All enrollments are deleted. Course content may be physically deleted at a future date.\r\n          * 'undelete' attempts to recover a course that has been deleted. (Recovery is not guaranteed; please conclude\r\n            rather than delete a course if there is any possibility the course will be used again.) The recovered course\r\n            will be unpublished. Deleted enrollments will not be recovered.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - course_ids\r\n        \"\"\"List of ids of courses to update. At most 500 courses may be updated in one call.\"\"\"\r\n        data[\"course_ids\"] = course_ids\r\n\r\n        # REQUIRED - event\r\n        \"\"\"no description\"\"\"\r\n        self._validate_enum(event, [\"offer\", \"conclude\", \"delete\", \"undelete\"])\r\n        data[\"event\"] = event\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{account_id}/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{account_id}/courses\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_course(self, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/reset_content with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/reset_content\".format(**path), data=data, params=params, single_item=True)", "response": "Reset a course. Deletes the current course and creates a new equivalent course with all sections and users moved over. Returns the updated course."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the list of effective student due dates for each assignment in the course. Returns a collection of the student IDs and values representing the student s ID and corresponding due date along with some Multiple Grading Periods data.", "response": "def get_effective_due_dates(self, course_id, assignment_ids=None):\r\n        \"\"\"\r\n        Get effective due dates.\r\n\r\n        For each assignment in the course, returns each assigned student's ID\r\n        and their corresponding due date along with some Multiple Grading Periods\r\n        data. Returns a collection with keys representing assignment IDs and values\r\n        as a collection containing keys representing student IDs and values representing\r\n        the student's effective due_at, the grading_period_id of which the due_at falls\r\n        in, and whether or not the grading period is closed (in_closed_grading_period)\r\n        \r\n        The list of assignment IDs for which effective student due dates are\r\n        requested. If not provided, all assignments in the course will be used.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - assignment_ids\r\n        \"\"\"no description\"\"\"\r\n        if assignment_ids is not None:\r\n            params[\"assignment_ids\"] = assignment_ids\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/effective_due_dates with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/effective_due_dates\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef permissions(self, course_id, permissions=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - permissions\r\n        \"\"\"List of permissions to check against authenticated user\"\"\"\r\n        if permissions is not None:\r\n            params[\"permissions\"] = permissions\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/permissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/permissions\".format(**path), data=data, params=params, no_data=True)", "response": "Returns the list of permissions for the given course & current user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_course_content(self, course_id, exclude=None, only=None, source_course=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - source_course\r\n        \"\"\"ID or SIS-ID of the course to copy the content from\"\"\"\r\n        if source_course is not None:\r\n            data[\"source_course\"] = source_course\r\n\r\n        # OPTIONAL - except\r\n        \"\"\"A list of the course content types to exclude, all areas not listed will\r\n        be copied.\"\"\"\r\n        if exclude is not None:\r\n            self._validate_enum(exclude, [\"course_settings\", \"assignments\", \"external_tools\", \"files\", \"topics\", \"calendar_events\", \"quizzes\", \"wiki_pages\", \"modules\", \"outcomes\"])\r\n            data[\"except\"] = exclude\r\n\r\n        # OPTIONAL - only\r\n        \"\"\"A list of the course content types to copy, all areas not listed will not\r\n        be copied.\"\"\"\r\n        if only is not None:\r\n            self._validate_enum(only, [\"course_settings\", \"assignments\", \"external_tools\", \"files\", \"topics\", \"calendar_events\", \"quizzes\", \"wiki_pages\", \"modules\", \"outcomes\"])\r\n            data[\"only\"] = only\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/course_copy with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/course_copy\".format(**path), data=data, params=params, no_data=True)", "response": "This method copies the content from one course into another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dictionary representing a new page containing multiple elements and or tabs.", "response": "def page(title, description, element_list=None, tab_list=None):\n    \"\"\"\n    Returns a dictionary representing a new page to display elements.\n    This can be thought of as a simple container for displaying multiple\n    types of information. The ``section`` method can be used to create\n    separate tabs.\n\n    Args:\n        title: The title to display\n        description: A description of the section\n        element_list: The list of elements to display. If a single element is\n                      given it will be wrapped in a list.\n        tab_list: A list of tabs to display.\n\n    Returns:\n        A dictionary with metadata specifying that it is to be rendered\n        as a page containing multiple elements and/or tabs.\n    \"\"\"\n    _page = {\n             'Type': 'Page',\n             'Title': title,\n             'Description': description,\n             'Data': {},\n             }\n\n    if element_list is not None:\n        if isinstance(element_list, list):\n            _page['Data']['Elements'] = element_list\n        else:\n            _page['Data']['Elements'] = [element_list]\n    if tab_list is not None:\n        if isinstance(tab_list, list):\n            _page['Data']['Tabs'] = tab_list\n        else:\n            _page['Data']['Tabs'] = [tab_list]\n    return _page"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary representing a new tab to display elements.", "response": "def tab(tab_name, element_list=None, section_list=None):\n    \"\"\"\n    Returns a dictionary representing a new tab to display elements.\n    This can be thought of as a simple container for displaying multiple\n    types of information.\n\n    Args:\n        tab_name: The title to display\n        element_list: The list of elements to display. If a single element is\n                      given it will be wrapped in a list.\n        section_list: A list of sections to display.\n\n    Returns:\n        A dictionary with metadata specifying that it is to be rendered\n        as a page containing multiple elements and/or tab.\n    \"\"\"\n    _tab = {\n            'Type': 'Tab',\n            'Title': tab_name,\n            }\n\n    if element_list is not None:\n        if isinstance(element_list, list):\n            _tab['Elements'] = element_list\n        else:\n            _tab['Elements'] = [element_list]\n    if section_list is not None:\n        if isinstance(section_list, list):\n            _tab['Sections'] = section_list\n        else:\n            if 'Elements' not in section_list:\n                _tab['Elements'] = element_list\n            else:\n                _tab['Elements'].append(element_list)\n    return _tab"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef section(title, element_list):\n    sect = {\n            'Type': 'Section',\n            'Title': title,\n            }\n\n    if isinstance(element_list, list):\n        sect['Elements'] = element_list\n    else:\n        sect['Elements'] = [element_list]\n    return sect", "response": "Returns a dictionary representing a new section."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef image(title, desc, image_name, group=None, height=None):\n    ie = {\n          'Type': 'Image',\n          'Title': title,\n          'Description': desc,\n          'Plot File': image_name,\n          }\n    if group:\n        ie['Group'] = group\n    if height:\n        ie['Height'] = height\n    return ie", "response": "Builds an image element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commands(self):\n        # Retrieve all commands via split function or splitting on ';'\n        print('\\tRetrieving commands from', self.sql_script)\n        print('\\tUsing command splitter algorithm {0}'.format(self.split_algo))\n\n        with Timer('\\tRetrieved commands in'):\n            # Split commands\n            # sqlparse packages split function combined with sql_split function\n            if self.split_algo is 'sql_parse':\n                commands = SplitCommands(self.sql_script).sql_parse\n\n            # Split on every ';' (unreliable)\n            elif self.split_algo is 'simple_split':\n                commands = SplitCommands(self.sql_script).simple_split()\n\n            # sqlparse package without additional splitting\n            elif self.split_algo is 'sql_parse_nosplit':\n                commands = SplitCommands(self.sql_script).sql_parse_nosplit\n\n            # Parse every char of the SQL commands and determine breakpoints\n            elif self.split_algo is 'sql_split':\n                commands = SplitCommands(self.sql_script).sql_split(disable_tqdm=False)\n            else:\n                commands = SplitCommands(self.sql_script).sql_split(disable_tqdm=False)\n\n            # remove dbo. prefixes from table names\n            cleaned_commands = [com.replace(\"dbo.\", '') for com in commands]\n        return cleaned_commands", "response": "Fetches individual SQL commands from a SQL commands containing many commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(self, commands=None, ignored_commands=('DROP', 'UNLOCK', 'LOCK'), execute_fails=True,\n                max_executions=MAX_EXECUTION_ATTEMPTS):\n        \"\"\"\n        Sequentially execute a list of SQL commands.\n\n        Check if commands property has already been fetched, if so use the\n        fetched_commands rather than getting them again.\n\n        :param commands: List of SQL commands\n        :param ignored_commands: Boolean, skip SQL commands that begin with 'DROP'\n        :param execute_fails: Boolean, attempt to execute failed commands again\n        :param max_executions: Int, max number of attempted executions\n        :return: Successful and failed commands\n        \"\"\"\n        # Break connection\n        self._MySQL.disconnect()\n        self._execute_iters += 1\n        if self._execute_iters > 0:\n            print('\\tExecuting commands attempt #{0}'.format(self._execute_iters))\n\n        # Retrieve commands from sql_script if no commands are provided\n        commands = self.commands if not commands else commands\n\n        # Remove 'DROP' commands\n        if ignored_commands:\n            commands = filter_commands(commands, ignored_commands)\n\n        # Reestablish connection\n        self._MySQL.reconnect()\n\n        # Execute list of commands\n        fail, success = self._execute_commands(commands)\n\n        # Dump failed commands to text files\n        print('\\t' + str(success), 'successful commands')\n        if len(fail) > 1 and self._dump_fails:\n            # Dump failed commands\n            dump_dir = self.dump_commands(fail)\n\n            # Execute failed commands\n            if execute_fails and self._execute_iters < max_executions:\n                return self._execute_commands_from_dir(dump_dir)\n        return fail, success", "response": "Execute a list of SQL commands."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting commands and get list of failed commands and count of successful commands", "response": "def _execute_commands(self, commands, fails=False):\n        \"\"\"Execute commands and get list of failed commands and count of successful commands\"\"\"\n        # Confirm that prepare_statements flag is on\n        if self._prep_statements:\n            prepared_commands = [prepare_sql(c) for c in tqdm(commands, total=len(commands),\n                                                              desc='Prepping SQL Commands')]\n            print('\\tCommands prepared', len(prepared_commands))\n        else:\n            prepared_commands = commands\n\n        desc = 'Executing SQL Commands' if not fails else 'Executing Failed SQL Commands'\n        fail, success = [], 0\n        for command in tqdm(prepared_commands, total=len(prepared_commands), desc=desc):\n            # Attempt to execute command and skip command if error is raised\n            try:\n                self._MySQL.executemore(command)\n                success += 1\n            except:\n                fail.append(command)\n        self._MySQL._commit()\n        return fail, success"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps commands wrapper for external access.", "response": "def dump_commands(self, commands):\n        \"\"\"Dump commands wrapper for external access.\"\"\"\n        # Get base directory\n        directory = os.path.join(os.path.dirname(self.sql_script), 'fails')\n\n        # Get file name to be used for folder name\n        fname = os.path.basename(self.sql_script.rsplit('.')[0])\n\n        return dump_commands(commands, directory, fname)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef suppress_output(reverse=False):\n    if reverse:\n        sys.stdout = sys.__stdout__\n        sys.stderr = sys.__stderr__\n    else:\n        sys.stdout = os.devnull\n        sys.stderr = os.devnull", "response": "Suppress output from the current process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_unresolved_variables(f):\n    reporter = RReporter()\n    checkPath(f, reporter=reporter)\n    return dict(reporter.messages)", "response": "Gets unresolved vars from file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nindexes objs from all modules in the order they appear in the modules list.", "response": "def index_modules(idx=None, path=None):\n    \"\"\"\n    Indexes objs from all modules\n    \"\"\"\n    suppress_output()\n    modules = defaultdict(list)\n    pkglist = pkgutil.walk_packages(onerror=lambda x: True)\n    print(pkglist)\n    if path:\n        pkglist = pkgutil.walk_packages(path, onerror=lambda x: True)\n    for modl, name, ispkg in pkglist:\n        try:\n            path = os.path.join(modl.path, name.split('.')[-1])\n        except AttributeError:\n            # Triggered on zipimport.zipimporter\n            continue\n\n        if os.path.isdir(path):\n            path = os.path.join(path, '__init__')\n        path += '.py'\n\n        objs = []\n\n        if os.path.exists(path):\n            try:\n                objs = read_objs_from_path(path)\n            except:\n                continue\n        elif not re.search(MODULE_BLACKLIST, name):\n            try:\n                mod = __import__(name)\n                objs = [k for k in dir(mod) if not k.startswith('__')]\n            except:\n                continue\n        else:\n            continue\n\n        for obj in objs:\n            if name not in modules[obj]:\n                modules[obj].append(name)\n    suppress_output(True)\n    return merge_dicts(idx, dict(modules))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict of suggestions for a given unresolved set of sources.", "response": "def get_suggestions(idx, unresolved):\n    \"\"\"\n    Returns suggestions\n    \"\"\"\n    result = {}\n    for u, lines in unresolved.items():\n        paths = idx.get(u)\n        if paths:\n            result[u] = {'paths': paths, 'lineno': lines}\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn includes from config", "response": "def includes(self):\n        \"\"\" return includes from config \"\"\"\n        r = dict([(k, sorted(copy.deepcopy(v).values(), key=lambda x:x.get(\"order\",0))) for k,v in self.get_config(\"includes\").items()])\n        if self.version is not None:\n            for k,v in r.items():\n                for j in v:\n                    j[\"path\"] = self.versioned_url(j[\"path\"])\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render(self, tmpl_name, request_env):\n        return super(WebApplication, self).render(tmpl_name, request_env)", "response": "Render the specified template and return the output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef submit_assignment_courses(self, course_id, assignment_id, submission_submission_type, comment_text_comment=None, submission_body=None, submission_file_ids=None, submission_media_comment_id=None, submission_media_comment_type=None, submission_url=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - comment[text_comment]\r\n        \"\"\"Include a textual comment with the submission.\"\"\"\r\n        if comment_text_comment is not None:\r\n            data[\"comment[text_comment]\"] = comment_text_comment\r\n\r\n        # REQUIRED - submission[submission_type]\r\n        \"\"\"The type of submission being made. The assignment submission_types must\r\n        include this submission type as an allowed option, or the submission will be rejected with a 400 error.\r\n        \r\n        The submission_type given determines which of the following parameters is\r\n        used. For instance, to submit a URL, submission [submission_type] must be\r\n        set to \"online_url\", otherwise the submission [url] parameter will be\r\n        ignored.\"\"\"\r\n        self._validate_enum(submission_submission_type, [\"online_text_entry\", \"online_url\", \"online_upload\", \"media_recording\", \"basic_lti_launch\"])\r\n        data[\"submission[submission_type]\"] = submission_submission_type\r\n\r\n        # OPTIONAL - submission[body]\r\n        \"\"\"Submit the assignment as an HTML document snippet. Note this HTML snippet\r\n        will be sanitized using the same ruleset as a submission made from the\r\n        Canvas web UI. The sanitized HTML will be returned in the response as the\r\n        submission body. Requires a submission_type of \"online_text_entry\".\"\"\"\r\n        if submission_body is not None:\r\n            data[\"submission[body]\"] = submission_body\r\n\r\n        # OPTIONAL - submission[url]\r\n        \"\"\"Submit the assignment as a URL. The URL scheme must be \"http\" or \"https\",\r\n        no \"ftp\" or other URL schemes are allowed. If no scheme is given (e.g.\r\n        \"www.example.com\") then \"http\" will be assumed. Requires a submission_type\r\n        of \"online_url\" or \"basic_lti_launch\".\"\"\"\r\n        if submission_url is not None:\r\n            data[\"submission[url]\"] = submission_url\r\n\r\n        # OPTIONAL - submission[file_ids]\r\n        \"\"\"Submit the assignment as a set of one or more previously uploaded files\r\n        residing in the submitting user's files section (or the group's files\r\n        section, for group assignments).\r\n        \r\n        To upload a new file to submit, see the submissions {api:SubmissionsApiController#create_file Upload a file API}.\r\n        \r\n        Requires a submission_type of \"online_upload\".\"\"\"\r\n        if submission_file_ids is not None:\r\n            data[\"submission[file_ids]\"] = submission_file_ids\r\n\r\n        # OPTIONAL - submission[media_comment_id]\r\n        \"\"\"The media comment id to submit. Media comment ids can be submitted via\r\n        this API, however, note that there is not yet an API to generate or list\r\n        existing media comments, so this functionality is currently of limited use.\r\n        \r\n        Requires a submission_type of \"media_recording\".\"\"\"\r\n        if submission_media_comment_id is not None:\r\n            data[\"submission[media_comment_id]\"] = submission_media_comment_id\r\n\r\n        # OPTIONAL - submission[media_comment_type]\r\n        \"\"\"The type of media comment being submitted.\"\"\"\r\n        if submission_media_comment_type is not None:\r\n            self._validate_enum(submission_media_comment_type, [\"audio\", \"video\"])\r\n            data[\"submission[media_comment_type]\"] = submission_media_comment_type\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/assignments/{assignment_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/submissions\".format(**path), data=data, params=params, no_data=True)", "response": "Submits an assignment for a given course."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist assignment submissions. Returns a list of existing submissions for an assignment.", "response": "def list_assignment_submissions_courses(self, course_id, assignment_id, grouped=None, include=None):\r\n        \"\"\"\r\n        List assignment submissions.\r\n\r\n        Get all existing submissions for an assignment.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group.  \"group\" will add group_id and group_name.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission_history\", \"submission_comments\", \"rubric_assessment\", \"assignment\", \"visibility\", \"course\", \"user\", \"group\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - grouped\r\n        \"\"\"If this argument is true, the response will be grouped by student groups.\"\"\"\r\n        if grouped is not None:\r\n            params[\"grouped\"] = grouped\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignments/{assignment_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/submissions\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_assignment_submissions_sections(self, section_id, assignment_id, grouped=None, include=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - section_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"section_id\"] = section_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group.  \"group\" will add group_id and group_name.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission_history\", \"submission_comments\", \"rubric_assessment\", \"assignment\", \"visibility\", \"course\", \"user\", \"group\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - grouped\r\n        \"\"\"If this argument is true, the response will be grouped by student groups.\"\"\"\r\n        if grouped is not None:\r\n            params[\"grouped\"] = grouped\r\n\r\n        self.logger.debug(\"GET /api/v1/sections/{section_id}/assignments/{assignment_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/sections/{section_id}/assignments/{assignment_id}/submissions\".format(**path), data=data, params=params, all_pages=True)", "response": "List assignment submissions. Returns a list of existing submissions for the given section and assignment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_submissions_for_multiple_assignments_courses(self, course_id, assignment_ids=None, grading_period_id=None, grouped=None, include=None, order=None, order_direction=None, student_ids=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - student_ids\r\n        \"\"\"List of student ids to return submissions for. If this argument is\r\n        omitted, return submissions for the calling user. Students may only list\r\n        their own submissions. Observers may only list those of associated\r\n        students. The special id \"all\" will return submissions for all students\r\n        in the course/section as appropriate.\"\"\"\r\n        if student_ids is not None:\r\n            params[\"student_ids\"] = student_ids\r\n\r\n        # OPTIONAL - assignment_ids\r\n        \"\"\"List of assignments to return submissions for. If none are given,\r\n        submissions for all assignments are returned.\"\"\"\r\n        if assignment_ids is not None:\r\n            params[\"assignment_ids\"] = assignment_ids\r\n\r\n        # OPTIONAL - grouped\r\n        \"\"\"If this argument is present, the response will be grouped by student,\r\n        rather than a flat array of submissions.\"\"\"\r\n        if grouped is not None:\r\n            params[\"grouped\"] = grouped\r\n\r\n        # OPTIONAL - grading_period_id\r\n        \"\"\"The id of the grading period in which submissions are being requested\r\n        (Requires the Multiple Grading Periods account feature turned on)\"\"\"\r\n        if grading_period_id is not None:\r\n            params[\"grading_period_id\"] = grading_period_id\r\n\r\n        # OPTIONAL - order\r\n        \"\"\"The order submissions will be returned in.  Defaults to \"id\".  Doesn't\r\n        affect results for \"grouped\" mode.\"\"\"\r\n        if order is not None:\r\n            self._validate_enum(order, [\"id\", \"graded_at\"])\r\n            params[\"order\"] = order\r\n\r\n        # OPTIONAL - order_direction\r\n        \"\"\"Determines whether ordered results are retured in ascending or descending\r\n        order.  Defaults to \"ascending\".  Doesn't affect results for \"grouped\" mode.\"\"\"\r\n        if order_direction is not None:\r\n            self._validate_enum(order_direction, [\"ascending\", \"descending\"])\r\n            params[\"order_direction\"] = order_direction\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group. `total_scores` requires the\r\n        `grouped` argument.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission_history\", \"submission_comments\", \"rubric_assessment\", \"assignment\", \"total_scores\", \"visibility\", \"course\", \"user\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/students/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/students/submissions\".format(**path), data=data, params=params, no_data=True)", "response": "Returns a list of existing submissions for a given set of students and assignments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_single_submission_courses(self, user_id, course_id, assignment_id, include=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission_history\", \"submission_comments\", \"rubric_assessment\", \"visibility\", \"course\", \"user\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignments/{assignment_id}/submissions/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/submissions/{user_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Get a single submission based on user id. Returns the single submission for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a single submission based on user id. Returns the full submission for the given user.", "response": "def get_single_submission_sections(self, user_id, section_id, assignment_id, include=None):\r\n        \"\"\"\r\n        Get a single submission.\r\n\r\n        Get a single submission, based on user id.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - section_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"section_id\"] = section_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the group.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission_history\", \"submission_comments\", \"rubric_assessment\", \"visibility\", \"course\", \"user\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/sections/{section_id}/assignments/{assignment_id}/submissions/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/sections/{section_id}/assignments/{assignment_id}/submissions/{user_id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef upload_file_sections(self, user_id, section_id, assignment_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - section_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"section_id\"] = section_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"POST /api/v1/sections/{section_id}/assignments/{assignment_id}/submissions/{user_id}/files with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/sections/{section_id}/assignments/{assignment_id}/submissions/{user_id}/files\".format(**path), data=data, params=params, no_data=True)", "response": "Uploads a file to a section in a submission. Returns the new file id and the file id of the file uploaded to the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngrade or comment on a submission. Comment on and/or update the grading for a student's assignment submission. If any submission or rubric_assessment arguments are provided, the user must have permission to manage grades in the appropriate context (course or section).", "response": "def grade_or_comment_on_submission_courses(self, user_id, course_id, assignment_id, comment_file_ids=None, comment_group_comment=None, comment_media_comment_id=None, comment_media_comment_type=None, comment_text_comment=None, include_visibility=None, rubric_assessment=None, submission_excuse=None, submission_posted_grade=None):\r\n        \"\"\"\r\n        Grade or comment on a submission.\r\n\r\n        Comment on and/or update the grading for a student's assignment submission.\r\n        If any submission or rubric_assessment arguments are provided, the user\r\n        must have permission to manage grades in the appropriate context (course or\r\n        section).\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - comment[text_comment]\r\n        \"\"\"Add a textual comment to the submission.\"\"\"\r\n        if comment_text_comment is not None:\r\n            data[\"comment[text_comment]\"] = comment_text_comment\r\n\r\n        # OPTIONAL - comment[group_comment]\r\n        \"\"\"Whether or not this comment should be sent to the entire group (defaults\r\n        to false). Ignored if this is not a group assignment or if no text_comment\r\n        is provided.\"\"\"\r\n        if comment_group_comment is not None:\r\n            data[\"comment[group_comment]\"] = comment_group_comment\r\n\r\n        # OPTIONAL - comment[media_comment_id]\r\n        \"\"\"Add an audio/video comment to the submission. Media comments can be added\r\n        via this API, however, note that there is not yet an API to generate or\r\n        list existing media comments, so this functionality is currently of\r\n        limited use.\"\"\"\r\n        if comment_media_comment_id is not None:\r\n            data[\"comment[media_comment_id]\"] = comment_media_comment_id\r\n\r\n        # OPTIONAL - comment[media_comment_type]\r\n        \"\"\"The type of media comment being added.\"\"\"\r\n        if comment_media_comment_type is not None:\r\n            self._validate_enum(comment_media_comment_type, [\"audio\", \"video\"])\r\n            data[\"comment[media_comment_type]\"] = comment_media_comment_type\r\n\r\n        # OPTIONAL - comment[file_ids]\r\n        \"\"\"Attach files to this comment that were previously uploaded using the\r\n        Submission Comment API's files action\"\"\"\r\n        if comment_file_ids is not None:\r\n            data[\"comment[file_ids]\"] = comment_file_ids\r\n\r\n        # OPTIONAL - include[visibility]\r\n        \"\"\"Whether this assignment is visible to the owner of the submission\"\"\"\r\n        if include_visibility is not None:\r\n            data[\"include[visibility]\"] = include_visibility\r\n\r\n        # OPTIONAL - submission[posted_grade]\r\n        \"\"\"Assign a score to the submission, updating both the \"score\" and \"grade\"\r\n        fields on the submission record. This parameter can be passed in a few\r\n        different formats:\r\n        \r\n        points:: A floating point or integral value, such as \"13.5\". The grade\r\n          will be interpreted directly as the score of the assignment.\r\n          Values above assignment.points_possible are allowed, for awarding\r\n          extra credit.\r\n        percentage:: A floating point value appended with a percent sign, such as\r\n           \"40%\". The grade will be interpreted as a percentage score on the\r\n           assignment, where 100% == assignment.points_possible. Values above 100%\r\n           are allowed, for awarding extra credit.\r\n        letter grade:: A letter grade, following the assignment's defined letter\r\n           grading scheme. For example, \"A-\". The resulting score will be the high\r\n           end of the defined range for the letter grade. For instance, if \"B\" is\r\n           defined as 86% to 84%, a letter grade of \"B\" will be worth 86%. The\r\n           letter grade will be rejected if the assignment does not have a defined\r\n           letter grading scheme. For more fine-grained control of scores, pass in\r\n           points or percentage rather than the letter grade.\r\n        \"pass/complete/fail/incomplete\":: A string value of \"pass\" or \"complete\"\r\n           will give a score of 100%. \"fail\" or \"incomplete\" will give a score of\r\n           0.\r\n        \r\n        Note that assignments with grading_type of \"pass_fail\" can only be\r\n        assigned a score of 0 or assignment.points_possible, nothing inbetween. If\r\n        a posted_grade in the \"points\" or \"percentage\" format is sent, the grade\r\n        will only be accepted if the grade equals one of those two values.\"\"\"\r\n        if submission_posted_grade is not None:\r\n            data[\"submission[posted_grade]\"] = submission_posted_grade\r\n\r\n        # OPTIONAL - submission[excuse]\r\n        \"\"\"Sets the \"excused\" status of an assignment.\"\"\"\r\n        if submission_excuse is not None:\r\n            data[\"submission[excuse]\"] = submission_excuse\r\n\r\n        # OPTIONAL - rubric_assessment\r\n        \"\"\"Assign a rubric assessment to this assignment submission. The\r\n        sub-parameters here depend on the rubric for the assignment. The general\r\n        format is, for each row in the rubric:\r\n        \r\n        The points awarded for this row.\r\n          rubric_assessment[criterion_id][points]\r\n        \r\n        Comments to add for this row.\r\n          rubric_assessment[criterion_id][comments]\r\n        \r\n        For example, if the assignment rubric is (in JSON format):\r\n          !!!javascript\r\n          [\r\n            {\r\n              'id': 'crit1',\r\n              'points': 10,\r\n              'description': 'Criterion 1',\r\n              'ratings':\r\n              [\r\n                { 'description': 'Good', 'points': 10 },\r\n                { 'description': 'Poor', 'points': 3 }\r\n              ]\r\n            },\r\n            {\r\n              'id': 'crit2',\r\n              'points': 5,\r\n              'description': 'Criterion 2',\r\n              'ratings':\r\n              [\r\n                { 'description': 'Complete', 'points': 5 },\r\n                { 'description': 'Incomplete', 'points': 0 }\r\n              ]\r\n            }\r\n          ]\r\n        \r\n        Then a possible set of values for rubric_assessment would be:\r\n            rubric_assessment[crit1][points]=3&rubric_assessment[crit2][points]=5&rubric_assessment[crit2][comments]=Well%20Done.\"\"\"\r\n        if rubric_assessment is not None:\r\n            data[\"rubric_assessment\"] = rubric_assessment\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/assignments/{assignment_id}/submissions/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/submissions/{user_id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse operator and value from filter s data.", "response": "def parse(self, data):\n        \"\"\"Parse operator and value from filter's data.\"\"\"\n        val = data.get(self.name, missing)\n        if not isinstance(val, dict):\n            return (self.operators['$eq'], self.field.deserialize(val)),\n\n        return tuple(\n            (\n                self.operators[op],\n                (self.field.deserialize(val)) if op not in self.list_ops else [\n                    self.field.deserialize(v) for v in val])\n            for (op, val) in val.items() if op in self.operators\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(self, collection, ops, **kwargs):\n        validator = lambda obj: all(op(obj, val) for (op, val) in ops)  # noqa\n        return [o for o in collection if validator(o)]", "response": "Apply the filter to collection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert(self, args, handler=None):\n        name = args\n        field = attr = None\n        opts = ()\n        if isinstance(args, (list, tuple)):\n            name, *opts = args\n            if opts:\n                attr = opts.pop()\n            if opts:\n                field = opts.pop()\n\n        if not field and handler and handler.Schema:\n            field = handler.Schema._declared_fields.get(attr or name) or \\\n                self.FILTER_CLASS.field_cls()\n            field.attribute = field.attribute or attr or name\n        return self.FILTER_CLASS(name, attr=attr, field=field, *opts)", "response": "Convert the list of arguments into a new instance of the FILTER_CLASS class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        PERM_CONF = {\n            \"publish_content\": \"Can publish content\",\n            \"publish_own_content\": \"Can publish own content\",\n            \"change_content\": \"Can change content\",\n            \"promote_content\": \"Can promote content\"\n        }\n        GROUP_CONF = dict(\n            contributor=(),\n            author=(\"publish_own_content\",),\n            editor=(\n                \"publish_content\",\n                \"change_content\",\n                \"promote_content\",\n            ),\n            admin=(\n                \"publish_content\",\n                \"change_content\",\n                \"promote_content\",\n            )\n        )\n        content_ct, _ = orm[\"contenttypes.ContentType\"].objects.get_or_create(\n            model=\"content\", app_label=\"content\"\n        )\n        for group_name, group_perms in GROUP_CONF.items():\n            group, _ = orm[\"auth.Group\"].objects.get_or_create(\n                name=group_name\n            )\n            for perm_name in group_perms:\n                perm, _ = orm[\"auth.Permission\"].objects.get_or_create(\n                    content_type=content_ct,\n                    codename=perm_name,\n                    defaults={\n                        \"name\": PERM_CONF[perm_name]\n                    }\n                )\n                group.permissions.add(perm)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist PollChoices in a poll. Returns the list of PollChoices in this poll.", "response": "def list_poll_choices_in_poll(self, poll_id):\r\n        \"\"\"\r\n        List poll choices in a poll.\r\n\r\n        Returns the list of PollChoices in this poll.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - poll_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_id\"] = poll_id\r\n\r\n        self.logger.debug(\"GET /api/v1/polls/{poll_id}/poll_choices with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/polls/{poll_id}/poll_choices\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a single poll choice. Creates a new poll choice for this poll.", "response": "def create_single_poll_choice(self, poll_id, poll_choices_text, poll_choices_is_correct=None, poll_choices_position=None):\r\n        \"\"\"\r\n        Create a single poll choice.\r\n\r\n        Create a new poll choice for this poll\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - poll_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_id\"] = poll_id\r\n\r\n        # REQUIRED - poll_choices[text]\r\n        \"\"\"The descriptive text of the poll choice.\"\"\"\r\n        data[\"poll_choices[text]\"] = poll_choices_text\r\n\r\n        # OPTIONAL - poll_choices[is_correct]\r\n        \"\"\"Whether this poll choice is considered correct or not. Defaults to false.\"\"\"\r\n        if poll_choices_is_correct is not None:\r\n            data[\"poll_choices[is_correct]\"] = poll_choices_is_correct\r\n\r\n        # OPTIONAL - poll_choices[position]\r\n        \"\"\"The order this poll choice should be returned in the context it's sibling poll choices.\"\"\"\r\n        if poll_choices_position is not None:\r\n            data[\"poll_choices[position]\"] = poll_choices_position\r\n\r\n        self.logger.debug(\"POST /api/v1/polls/{poll_id}/poll_choices with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/polls/{poll_id}/poll_choices\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sso_redirect(request, scopes=list([]), return_to=None):\n    logger.debug(\"Initiating redirect of {0} session {1}\".format(request.user, request.session.session_key[:5]))\n    if isinstance(scopes, string_types):\n        scopes = list([scopes])\n\n    # ensure only one callback redirect model per session\n    CallbackRedirect.objects.filter(session_key=request.session.session_key).delete()\n\n    # ensure session installed in database\n    if not request.session.exists(request.session.session_key):\n        logger.debug(\"Creating new session before redirect.\")\n        request.session.create()\n\n    if return_to:\n        url = reverse(return_to)\n    else:\n        url = request.get_full_path()\n\n    oauth = OAuth2Session(app_settings.ESI_SSO_CLIENT_ID, redirect_uri=app_settings.ESI_SSO_CALLBACK_URL, scope=scopes)\n    redirect_url, state = oauth.authorization_url(app_settings.ESI_OAUTH_LOGIN_URL)\n\n    CallbackRedirect.objects.create(session_key=request.session.session_key, state=state, url=url)\n    logger.debug(\"Redirecting {0} session {1} to SSO. Callback will be redirected to {2}\".format(request.user, request.session.session_key[:5], url))\n    return redirect(redirect_url)", "response": "Creates a new SSO redirect model for the specified request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef receive_callback(request):\n    logger.debug(\"Received callback for {0} session {1}\".format(request.user, request.session.session_key[:5]))\n    # make sure request has required parameters\n    code = request.GET.get('code', None)\n    state = request.GET.get('state', None)\n    try:\n        assert code\n        assert state\n    except AssertionError:\n        logger.debug(\"Missing parameters for code exchange.\")\n        return HttpResponseBadRequest()\n\n    callback = get_object_or_404(CallbackRedirect, state=state, session_key=request.session.session_key)\n    token = Token.objects.create_from_request(request)\n    callback.token = token\n    callback.save()\n    logger.debug(\n        \"Processed callback for {0} session {1}. Redirecting to {2}\".format(request.user, request.session.session_key[:5], callback.url))\n    return redirect(callback.url)", "response": "Handles the SSO callback request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npresents the user with a selection of applicable tokens for the requested view.", "response": "def select_token(request, scopes='', new=False):\n    \"\"\"\n    Presents the user with a selection of applicable tokens for the requested view.\n    \"\"\"\n\n    @tokens_required(scopes=scopes, new=new)\n    def _token_list(r, tokens):\n        context = {\n            'tokens': tokens,\n            'base_template': app_settings.ESI_BASE_TEMPLATE,\n        }\n        return render(r, 'esi/select_token.html', context=context)\n\n    return _token_list(request)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the column which is the primary key for a table.", "response": "def get_primary_key(self, table):\n        \"\"\"Retrieve the column which is the primary key for a table.\"\"\"\n        for column in self.get_schema(table):\n            if len(column) > 3 and 'pri' in column[3].lower():\n                return column[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_primary_key(self, table, column):\n        self.execute('ALTER TABLE {0} ADD PRIMARY KEY ({1})'.format(wrap(table), column))\n        self._printer('\\tAdded primary key to {0} on column {1}'.format(wrap(table), column))", "response": "Create a Primary Key constraint on a specific column when the table is already created."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating primary keys for every table in the connected database.", "response": "def set_primary_keys_auto(self, tables=None):\n        \"\"\"\n        Create primary keys for every table in the connected database.\n\n        Checks that each table has a primary key.  If a table does not have a key\n        then each column is analyzed to determine if it contains only unique values.\n        If no columns exist containing only unique values then a new 'ID' column\n        is created to serve as a auto_incrementing primary key.\n        \"\"\"\n        # Retrieve list of tables if not provided\n        tables = tables if tables else self.tables\n\n        # Resolve primary keys and return list of table, primary_key tuples\n        return [(table, self.set_primary_key_auto(table)) for table in tables]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_primary_key_auto(self, table):\n        # Confirm no primary key exists\n        pk = self.get_primary_key(table)\n        if not pk:\n            # Determine if there is a unique column that can become the PK\n            unique_col = self.get_unique_column(table)\n\n            # Set primary key\n            if unique_col:\n                self.set_primary_key(table, unique_col)\n\n            # Create unique 'ID' column\n            else:\n                unique_col = self.add_column(table, primary_key=True)\n            return unique_col\n        else:\n            return pk", "response": "Set a primary key by creating a new column if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndrop a Primary Key constraint for a specific table.", "response": "def drop_primary_key(self, table):\n        \"\"\"Drop a Primary Key constraint for a specific table.\"\"\"\n        if self.get_primary_key(table):\n            self.execute('ALTER TABLE {0} DROP PRIMARY KEY'.format(wrap(table)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Foreign Key constraint on a column from a table.", "response": "def set_foreign_key(self, parent_table, parent_column, child_table, child_column):\n        \"\"\"Create a Foreign Key constraint on a column from a table.\"\"\"\n        self.execute('ALTER TABLE {0} ADD FOREIGN KEY ({1}) REFERENCES {2}({3})'.format(parent_table, parent_column,\n                                                                                        child_table, child_column))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_api_key_correct(request):\n    api_key = getattr(settings, 'GECKOBOARD_API_KEY', None)\n    if api_key is None:\n        return True\n    auth = request.META.get('HTTP_AUTHORIZATION', '').split()\n    if len(auth) == 2:\n        if auth[0].lower() == b'basic':\n            request_key = base64.b64decode(auth[1]).split(b':')[0]\n            return request_key == api_key\n    return False", "response": "Return whether the Geckoboard API key on the request is correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _render(request, data, encrypted, format=None):\n    if not format:\n        format = request.POST.get('format', '')\n    if not format:\n        format = request.GET.get('format', '')\n    if format == 'json' or format == '2':\n        return _render_json(data, encrypted)\n    else:\n        return _render_xml(data, encrypted)", "response": "Render the data to Geckoboard."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse ipmitool to run commands with ipmi protocol", "response": "def ipmi_method(self, command):       \n        \"\"\"Use ipmitool to run commands with ipmi protocol\n        \"\"\"\n        ipmi = ipmitool(self.console, self.password, self.username)\n        \n        if command == \"reboot\":\n            self.ipmi_method(command=\"status\")\n            if self.output == \"Chassis Power is off\":\n                command = \"on\"\n        \n        ipmi.execute(self.ipmi_map[command])\n        \n        if ipmi.status:\n            self.error = ipmi.error.strip()\n        else:\n            self.output = ipmi.output.strip()        \n        self.status = ipmi.status"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting thread run here", "response": "def run(self):\n        \"\"\"Start thread run here\n        \"\"\"\n        try:\n            if self.command == \"pxer\":\n                self.ipmi_method(command=\"pxe\")\n                if self.status == 0 or self.status == None:\n                    self.command = \"reboot\"\n                else:\n                    return\n                    \n            self.ipmi_method(self.command)\n        \n        except Exception as e:\n            self.error = str(e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate new object on IXNetwork.", "response": "def _create(self):\n        \"\"\" Create new object on IxNetwork.\n\n        :return: IXN object reference.\n        \"\"\"\n\n        if 'name' in self._data:\n            obj_ref = self.api.add(self.obj_parent(), self.obj_type(), name=self.obj_name())\n        else:\n            obj_ref = self.api.add(self.obj_parent(), self.obj_type())\n        self.api.commit()\n        return self.api.remapIds(obj_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, *args):\n        values = []\n\n        for entry in args:\n            values = values + list(entry.items())\n\n        return dict(values)", "response": "Merge multiple dictionary objects into one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parseLegacy(self, response):\n        lines = response.splitlines()\n        result = []\n        pattern = re.compile('([A-Za-z]+):((.(?![A-Za-z]+:))*)')\n\n        for line in lines:\n            matches = pattern.findall(line)\n            row = {}\n\n            for match in matches:\n                row[match[0]] = match[1].strip()\n\n            try:\n                error = row['ERR'].split(',')\n            except KeyError:\n                pass\n            else:\n                row['code'] = error[0] if len(error) == 2 else 0\n                row['error'] = error[1].strip() if len(error) == 2 else error[0]\n                del row['ERR']\n\n                # If this response is a single row response, then we will throw\n                # an exception to alert the user of any failures.\n                if (len(lines) == 1):\n                    raise ClickatellError(row['error'], row['code'])\n            finally:\n                result.append(row)\n\n        return result if len(result) > 1 else result[0]", "response": "Parse a legacy response and try and catch any errors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a REST response.", "response": "def parseRest(self, response):\n        \"\"\"\n        Parse a REST response. If the response contains an error field, we will\n        raise it as an exception.\n        \"\"\"\n        body = json.loads(response)\n\n        try:\n            error = body['error']['description']\n            code = body['error']['code']\n        except Exception:\n            return body['data']\n        else:\n            raise ClickatellError(error, code);"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(self, action, data={}, headers={}, method='GET'):\n        url = ('https' if self.secure else 'http') + '://' + self.endpoint\n        url = url + '/' + action\n\n        # Set the User-Agent\n        userAgent = \"\".join([\"ClickatellPython/0.1.2\", \" \", \"Python/\", platform.python_version()])\n        headers = self.merge({ \"User-Agent\": userAgent }, headers)\n\n        try:\n            func = getattr(requests, method.lower())\n        except AttributeError:\n            raise Exception('HTTP method ' + method + ' unsupported.')\n\n        resp = func(url, params=data, data=json.dumps(data), headers=headers)\n\n        # Set the coding before unwrapping the text\n        resp.encoding = 'utf-8'\n        content = resp.text\n        return content", "response": "Run the HTTP request against Clickatell API and return the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize a list of operations into JSON.", "response": "def serialize_operations(self, operations):\n        \"\"\"Serialize a list of operations into JSON.\"\"\"\n\n        serialized_ops = []\n        for operation in operations:\n            serializer = self.get_serializer_class(operation.__class__)\n            serialized_ops.append(serializer(operation).data)\n        return serialized_ops"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all the operations for a given pzone.", "response": "def get(self, request, pzone_pk):\n        \"\"\"Get all the operations for a given pzone.\"\"\"\n\n        # attempt to get given pzone\n        try:\n            pzone = PZone.objects.get(pk=pzone_pk)\n        except PZone.DoesNotExist:\n            raise Http404(\"Cannot find given pzone.\")\n\n        # bulid filters\n        filters = {\"pzone\": pzone}\n\n        if \"from\" in request.GET:\n            parsed = dateparse.parse_datetime(request.GET[\"from\"])\n            if parsed is not None:\n                filters[\"when__gte\"] = parsed\n\n        if \"to\" in request.GET:\n            parsed = dateparse.parse_datetime(request.GET[\"to\"])\n            if parsed is not None:\n                filters[\"when__lt\"] = parsed\n\n        # get operations and serialize them\n        operations = PZoneOperation.objects.filter(**filters)\n\n        # return a json response with serialized operations\n        return Response(self.serialize_operations(operations), content_type=\"application/json\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new operation to the given pzone return json of the new operation.", "response": "def post(self, request, pzone_pk):\n        \"\"\"Add a new operation to the given pzone, return json of the new operation.\"\"\"\n\n        # attempt to get given content list\n        pzone = None\n        try:\n            pzone = PZone.objects.get(pk=pzone_pk)\n        except PZone.DoesNotExist:\n            raise Http404(\"Cannot find given pzone.\")\n\n        json_obj = []\n        http_status = 500\n\n        json_op = json.loads(request.body.decode(\"utf8\"))\n        if not isinstance(json_op, list):\n            json_op = [json_op]\n\n        for data in json_op:\n            try:\n                serializer = self.get_serializer_class_by_name(data[\"type_name\"])\n            except ContentType.DoesNotExist as e:\n                json_obj = {\"errors\": [str(e)]}\n                http_status = 400\n                break\n\n            serialized = serializer(data=data)\n            if serialized.is_valid():\n                # object is valid, save it\n                serialized.save()\n\n                # set response data\n                json_obj.append(serialized.data)\n                http_status = 200\n            else:\n                # object is not valid, return errors in a 400 response\n                json_obj = serialized.errors\n                http_status = 400\n                break\n\n        if http_status == 200 and len(json_obj) == 1:\n            json_obj = json_obj[0]\n\n        # cache the time in seconds until the next operation occurs\n        next_ops = PZoneOperation.objects.filter(when__lte=timezone.now())\n        if len(next_ops) > 0:\n            # we have at least one operation, ordered soonest first\n            next_op = next_ops[0]\n            # cache with expiry number of seconds until op should exec\n            cache.set('pzone-operation-expiry-' + pzone.name, next_op.when, 60 * 60 * 5)\n\n        return Response(\n            json_obj,\n            status=http_status,\n            content_type=\"application/json\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, request, pzone_pk, operation_pk):\n\n        # note : we're not using the pzone_pk here since it's not actually\n        #   necessary for getting an operation by pk, but it sure makes the urls\n        #   nicer!\n\n        # attempt to delete operation\n        try:\n            operation = PZoneOperation.objects.get(pk=operation_pk)\n        except PZoneOperation.DoesNotExist:\n            raise Http404(\"Cannot find given operation.\")\n\n        # delete operation\n        operation.delete()\n\n        # successful delete, return 204\n        return Response(\"\", 204)", "response": "Remove an operation from the given pzone."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef perform_update(self, serializer):\n        instance = serializer.save()\n        # create history object\n        instance.history.create(data=instance.data)", "response": "creates a record in the bulbs. promotion. PZoneHistory object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef retrieve(self, request, *args, **kwargs):\n\n        when_param = get_query_params(self.request).get(\"preview\", None)\n        pk = self.kwargs[\"pk\"]\n\n        when = None\n        if when_param:\n            try:\n                when = parse_date(when_param)\n            except ValueError:\n                # invalid format, set back to None\n                when = None\n\n        pzone = None\n        if when:\n            # we have a date, use it\n            pzone = PZone.objects.preview(pk=pk, when=when)\n        else:\n            # we have no date, just get the pzone\n            pzone = PZone.objects.applied(pk=pk)\n\n        # turn content list into json\n        return Response(PZoneSerializer(pzone).data, content_type=\"application/json\")", "response": "Retrieve pzone as a preview or applied if no preview is provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef design(self, max_stimuli=-1, max_inhibitors=-1, max_experiments=10, relax=False, configure=None):\n        self.designs = []\n\n        args = ['-c maxstimuli=%s' % max_stimuli, '-c maxinhibitors=%s' % max_inhibitors, '-Wno-atom-undefined']\n\n        clingo = gringo.Control(args)\n        clingo.conf.solve.opt_mode = 'optN'\n        if configure is not None:\n            configure(clingo.conf)\n\n        clingo.add(\"base\", [], self.instance)\n        clingo.load(self.encodings['design'])\n\n        clingo.ground([(\"base\", [])])\n\n        if relax:\n            parts = [(\"step\", [step]) for step in xrange(1, max_experiments+1)]\n            parts.append((\"diff\", [max_experiments + 1]))\n            clingo.ground(parts)\n            ret = clingo.solve(on_model=self.__save__)\n        else:\n            step, ret = 0, gringo.SolveResult.UNKNOWN\n            while step <= max_experiments and ret != gringo.SolveResult.SAT:\n                parts = []\n                parts.append((\"check\", [step]))\n                if step > 0:\n                    clingo.release_external(gringo.Fun(\"query\", [step-1]))\n                    parts.append((\"step\", [step]))\n                    clingo.cleanup_domains()\n\n                clingo.ground(parts)\n                clingo.assign_external(gringo.Fun(\"query\", [step]), True)\n                ret, step = clingo.solve(on_model=self.__save__), step + 1\n\n        self.stats['time_optimum'] = clingo.stats['time_solve']\n        self.stats['time_enumeration'] = clingo.stats['time_total']\n\n        self._logger.info(\"%s optimal experimental designs found in %.4fs\", len(self.designs), self.stats['time_enumeration'])", "response": "This method finds all optimal experimental designs for each experiment and adds them to the internal designs attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef current(cls):\n        try:\n            return _tls.loop\n        except AttributeError:\n            # create loop only for main thread\n            if threading.current_thread().name == 'MainThread':\n                _tls.loop = cls()\n                return _tls.loop\n            raise RuntimeError('there is no event loop created in the current thread')", "response": "Get the current event loop singleton object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches account domains. Returns a list of up to 5 matching account domains.", "response": "def search_account_domains(self, domain=None, latitude=None, longitude=None, name=None):\r\n        \"\"\"\r\n        Search account domains.\r\n\r\n        Returns a list of up to 5 matching account domains\r\n        \r\n        Partial match on name / domain are supported\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"campus name\"\"\"\r\n        if name is not None:\r\n            params[\"name\"] = name\r\n\r\n        # OPTIONAL - domain\r\n        \"\"\"no description\"\"\"\r\n        if domain is not None:\r\n            params[\"domain\"] = domain\r\n\r\n        # OPTIONAL - latitude\r\n        \"\"\"no description\"\"\"\r\n        if latitude is not None:\r\n            params[\"latitude\"] = latitude\r\n\r\n        # OPTIONAL - longitude\r\n        \"\"\"no description\"\"\"\r\n        if longitude is not None:\r\n            params[\"longitude\"] = longitude\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/search with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/search\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the volume. Sets the volume to a given percentage (integer between 0 and 100). Args: percentage (int): The percentage (as a 0 to 100 integer) to set the volume to. Raises: ValueError: if the percentage is >100 or <0.", "response": "def set_volume(percentage):\n\t'''Set the volume.\n\n\tSets the volume to a given percentage (integer between 0 and 100).\n\n\tArgs:\n\t\t\tpercentage (int): The percentage (as a 0 to 100 integer) to set the volume to.\n\n\tRaises:\n\t\t\tValueError: if the percentage is >100 or <0.\n\t'''\n\n\tif percentage > 100 or percentage < 0:\n\t\traise ValueError('percentage must be an integer between 0 and 100')\n\n\tif system.get_name() == 'windows':\n\t\t# TODO: Implement volume for Windows. Looks like WinAPI is the\n\t\t# solution...\n\t\tpass\n\n\telif system.get_name() == 'mac':\n\t\t# OS X uses 0-10 instead of percentage\n\t\tvolume_int = percentage / 10\n\n\t\tsp.Popen(['osascript', '-e', 'set Volume %d' % volume_int]).wait()\n\n\telse:\n\t\t# Linux/Unix\n\t\tformatted = str(percentage) + '%'\n\t\tsp.Popen(['amixer', '--quiet', 'sset', 'Master', formatted]).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_volume():\n\t'''Get the volume.\n\n\tGet the current volume.\n\n\tReturns:\n\t\t\tint: The current volume (percentage, between 0 and 100).\n\t'''\n\n\tif system.get_name() == 'windows':\n\t\t# TODO: Implement volume for Windows. Looks like WinAPI is the\n\t\t# solution...\n\t\tpass\n\n\telif system.get_name() == 'mac':\n\t\tvolume = system.get_cmd_out(\n\t\t\t['osascript', '-e', 'set ovol to output volume of (get volume settings); return the quoted form of ovol'])\n\t\treturn int(volume) * 10\n\n\telse:\n\t\t# Linux/Unix\n\t\tvolume = system.get_cmd_out(\n\t\t\t\t('amixer get Master |grep % |awk \\'{print $5}\\'|'\n\t\t\t\t 'sed -e \\'s/\\[//\\' -e \\'s/\\]//\\' | head -n1'))\n\t\treturn int(volume.replace('%', ''))", "response": "Get the volume.\n\n\tGet the current volume.\n\n\tReturns:\n\t\t\tint: The current volume (percentage, between 0 and 100)."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nincreases the volume by a given percentage.", "response": "def increase_volume(percentage):\n\t'''Increase the volume.\n\n\tIncrease the volume by a given percentage.\n\n\tArgs:\n\t\t\tpercentage (int): The percentage (as an integer between 0 and 100) to increase the volume by.\n\n\tRaises:\n\t\t\tValueError: if the percentage is >100 or <0.\n\t'''\n\n\tif percentage > 100 or percentage < 0:\n\t\traise ValueError('percentage must be an integer between 0 and 100')\n\n\tif system.get_name() == 'windows':\n\t\t# TODO: Implement volume for Windows. Looks like WinAPI is the\n\t\t# solution...\n\t\tpass\n\n\telif system.get_name() == 'mac':\n\t\tvolume_int = percentage / 10\n\t\told_volume = get()\n\n\t\tnew_volume = old_volume + volume_int\n\n\t\tif new_volume > 10:\n\t\t\tnew_volume = 10\n\n\t\tset_volume(new_volume * 10)\n\n\telse:\n\t\t# Linux/Unix\n\t\tformatted = '%d%%+' % percentage\n\t\t# + or - increases/decreases in amixer\n\n\t\tsp.Popen(['amixer', '--quiet', 'sset', 'Master', formatted]).wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mute():\n\t'''Mute the volume.\n\n\tMutes the volume.\n\t'''\n\n\t# NOTE: mute != 0 volume\n\n\tif system.get_name() == 'windows':\n\t\t# TODO: Implement volume for Windows. Looks like WinAPI is the\n\t\t# solution...\n\t\tpass\n\n\telif system.get_name() == 'mac':\n\t\tsp.Popen(['osascript', '-e', 'set volume output muted true']).wait()\n\n\telse:\n\t\t# Linux/Unix\n\t\tif unix_is_pulseaudio_server():\n\t\t\tsp.Popen(['amixer', '--quiet', '-D', 'pulse', 'sset',\n\t\t\t\t\t  'Master', 'mute']).wait()  # sset is *not* a typo\n\n\t\telse:\n\t\t\tsp.Popen(['amixer', '--quiet', 'sset', 'Master', 'mute']).wait()", "response": "Mute the volume.\n\n\tMutes the volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unmute():\n\t'''Unmute the volume.\n\n\tUnmutes the system volume.\n\n\tNote:\n\t\t\tOn some systems, volume is restored to its previous level after unmute, or set to 100.\n\t'''\n\n\tif system.get_name() == 'windows':\n\t\t# TODO: Implement volume for Windows. Looks like WinAPI is the\n\t\t# solution...\n\t\tpass\n\n\telif system.get_name() == 'mac':\n\t\tsp.Popen(['osascript', '-e', 'set volume output muted false']).wait()\n\n\telse:\n\t\t# Linux/Unix\n\t\tif unix_is_pulseaudio_server():\n\t\t\tsp.Popen(['amixer', '--quiet', '-D', 'pulse', 'sset',\n\t\t\t\t\t  'Master', 'unmute']).wait()  # sset is *not* a typo\n\n\t\telse:\n\t\t\tsp.Popen(['amixer', '--quiet', 'sset', 'Master', 'unmute']).wait()", "response": "Unmute the system volume."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_serializers(self):\n        acceptable_offers = self.request.accept.acceptable_offers(self.response.supported_mime_types)\n        if len(acceptable_offers) > 0:\n            best_accept_match = acceptable_offers[0][0]\n        else:\n            best_accept_match = self.response.default_serializer.content_type()\n\n        # best_accept_match = self.request.accept.best_match(\n        #     self.response.supported_mime_types,\n        #     default_match=self.response.default_serializer.content_type()\n        # )\n\n        self.logger.info(\"%s determined as best match for accept header: %s\" % (\n            best_accept_match,\n            self.request.accept\n        ))\n\n        # if content_type is not acceptable it will raise UnsupportedVocabulary\n        self.response.content_type = best_accept_match", "response": "Setup the return serializer based on the Accept header and the Accept header of the response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n\n        rows = db.execute(\"select distinct feature_type from content_content\")\n        for row in rows:\n            feature_type = row[0]\n            try:\n                ft = orm.FeatureType.objects.get(slug=slugify(feature_type))\n            except orm.FeatureType.DoesNotExist:\n                ft = orm.FeatureType.objects.create(\n                    name=feature_type,\n                    slug=slugify(feature_type)\n                )\n            db.execute(\"update content_content set feature_type_id = %s where feature_type = %s\", [ft.id, feature_type])", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_by_login(self, login_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - login_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"login_id\"] = login_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/authentication/logins/{login_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/authentication/logins/{login_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Query by login. Returns a list of authentication events for a given login."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying by account. Returns the list of authentication events for a given account.", "response": "def query_by_account(self, account_id, end_time=None, start_time=None):\r\n        \"\"\"\r\n        Query by account.\r\n\r\n        List authentication events for a given account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/authentication/accounts/{account_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/authentication/accounts/{account_id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_by_user(self, user_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/authentication/users/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/authentication/users/{user_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Query by user. Returns a list of authentication events for a given user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter the blacklist entries and return a nested dictionary of plugins with the same name and version.", "response": "def _filter(self, blacklist=None, newest_only=False, type_filter=None, **kwargs):\n        \"\"\"\n        Args:\n            blacklist(tuple): Iterable of of BlacklistEntry objects\n            newest_only(bool): Only the newest version of each plugin is returned\n            type(str): Plugin type to retrieve\n            name(str): Plugin name to retrieve\n            version(str): Plugin version to retrieve\n\n        Returns nested dictionary of plugins\n\n        If a blacklist is supplied, plugins are evaluated against the blacklist entries\n        \"\"\"\n\n        plugins = DictWithDotNotation()\n        filtered_name = kwargs.get(self._key_attr, None)\n\n        for key, val in self._items(type_filter, filtered_name):\n            plugin_blacklist = None\n            skip = False\n\n            if blacklist:\n\n                # Assume blacklist is correct format since it is checked by PluginLoade\n\n                plugin_blacklist = []\n                for entry in blacklist:\n                    if getattr(entry, self._key_attr) not in (key, None):\n                        continue\n                    if all(getattr(entry, attr) is None for attr in self._bl_skip_attrs):\n                        if not self._skip_empty:\n                            plugins[key] = None if filtered_name else self._bl_empty()\n                        skip = True\n                        break\n\n                    plugin_blacklist.append(entry)\n\n            if not skip:\n                # pylint: disable=protected-access\n                result = val._filter(plugin_blacklist, newest_only=newest_only, **kwargs)\n\n                if result or not self._skip_empty:\n                    plugins[key] = result\n\n        if filtered_name:\n            return plugins.get(filtered_name, None)\n        return plugins"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sorted_keys(self):\n\n        try:\n            keys = self._cache['sorted_keys']\n        except KeyError:\n            keys = self._cache['sorted_keys'] = sorted(self.keys(), key=parse_version)\n\n        return keys", "response": "Return list of keys sorted by version"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_blacklist(self, blacklist):\n\n        # Assume blacklist is correct format since it is checked by PluginLoader\n\n        blacklist_cache = {}\n        blacklist_cache_old = self._cache.get('blacklist', {})\n\n        for entry in blacklist:\n\n            blackkey = (entry.version, entry.operator)\n\n            if blackkey in blacklist_cache:\n                continue\n            elif blackkey in blacklist_cache_old:\n                blacklist_cache[blackkey] = blacklist_cache_old[blackkey]\n            else:\n                entry_cache = blacklist_cache[blackkey] = set()\n                blackversion = parse_version(entry.version or '0')\n                blackop = OPERATORS[entry.operator]\n\n                for key in self:\n                    if blackop(parse_version(key), blackversion):\n                        entry_cache.add(key)\n\n        self._cache['blacklist'] = blacklist_cache\n        return set().union(*blacklist_cache.values())", "response": "Process blacklist into set of excluded versions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _filter(self, blacklist=None, newest_only=False, **kwargs):\n\n        version = kwargs.get('version', None)\n        rtn = None\n\n        if self:  # Dict is not empty\n\n            if blacklist:\n\n                blacklist = self._process_blacklist(blacklist)\n\n                if version:\n                    if version not in blacklist:\n                        rtn = self.get(version, None)\n\n                elif newest_only:\n                    for key in reversed(self._sorted_keys()):\n                        if key not in blacklist:\n                            rtn = self[key]\n                            break\n                    # If no keys are left, None will be returned\n                else:\n                    rtn = dict((key, val) for key, val in self.items() if key not in blacklist) \\\n                          or None\n\n            elif version:\n                rtn = self.get(version, None)\n\n            elif newest_only:\n                rtn = self[self._sorted_keys()[-1]]\n\n            else:\n                rtn = dict(self)\n\n        return rtn", "response": "Returns a dictionary of plugins that are not in the blacklist"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the latitude and longitude coordinates of the OSGB36 in WGS84.", "response": "def OSGB36toWGS84(E, N):\n    \"\"\" Accept The Ordnance Survey National Grid eastings and northings.\n    Return latitude and longitude coordinates.\n\n    Usage:\n    >>> from bng_to_latlon import OSGB36toWGS84\n    >>> OSGB36toWGS84(538890, 177320)\n    (51.47779538331092, -0.0014016837826672265)\n    >>> OSGB36toWGS84(352500.2, 401400)\n    (53.507129843104195, -2.7176599627343263)\n    \"\"\"\n    # The Airy 1830 semi-major and semi-minor axes used for OSGB36 (m)\n    a, b = 6377563.396, 6356256.909\n    F0 = 0.9996012717  # scale factor on the central meridian\n\n    # Latitude and longtitude of true origin (radians)\n    lat0 = 49*pi/180\n    lon0 = -2*pi/180  # longtitude of central meridian\n\n    # Northing & easting of true origin (m)\n    N0, E0 = -100000, 400000\n    e2 = 1 - (b*b)/(a*a)  # eccentricity squared\n    n = (a-b)/(a+b)\n\n    # Initialise the iterative variables\n    lat, M = lat0, 0\n\n    while N-N0-M >= 0.00001:  # Accurate to 0.01mm\n        lat = (N-N0-M)/(a*F0) + lat\n        M1 = (1 + n + (5./4)*n**2 + (5./4)*n**3) * (lat-lat0)\n        M2 = (3*n + 3*n**2 + (21./8)*n**3) * sin(lat-lat0) * cos(lat+lat0)\n        M3 = ((15./8)*n**2 + (15./8)*n**3) * sin(2*(lat-lat0)) * cos(2*(lat+lat0))\n        M4 = (35./24)*n**3 * sin(3*(lat-lat0)) * cos(3*(lat+lat0))\n        # meridional arc\n        M = b * F0 * (M1 - M2 + M3 - M4)\n\n    # transverse radius of curvature\n    nu = a*F0/sqrt(1-e2*sin(lat)**2)\n\n    # meridional radius of curvature\n    rho = a*F0*(1-e2)*(1-e2*sin(lat)**2)**(-1.5)\n    eta2 = nu/rho-1\n\n    sec_lat = 1./cos(lat)\n    VII = tan(lat)/(2*rho*nu)\n    VIII = tan(lat)/(24*rho*nu**3)*(5+3*tan(lat)**2+eta2-9*tan(lat)**2*eta2)\n    IX = tan(lat)/(720*rho*nu**5)*(61+90*tan(lat)**2+45*tan(lat)**4)\n    X = sec_lat/nu\n    XI = sec_lat/(6*nu**3)*(nu/rho+2*tan(lat)**2)\n    XII = sec_lat/(120*nu**5)*(5+28*tan(lat)**2+24*tan(lat)**4)\n    XIIA = sec_lat/(5040*nu**7)*(61+662*tan(lat)**2+1320*tan(lat)**4+720*tan(lat)**6)\n    dE = E-E0\n\n    # These are on the wrong ellipsoid currently: Airy 1830 (denoted by _1)\n    lat_1 = lat - VII*dE**2 + VIII*dE**4 - IX*dE**6\n    lon_1 = lon0 + X*dE - XI*dE**3 + XII*dE**5 - XIIA*dE**7\n\n    # Want to convert to the GRS80 ellipsoid.\n    # First convert to cartesian from spherical polar coordinates\n    H = 0  # Third spherical coord.\n    x_1 = (nu/F0 + H)*cos(lat_1)*cos(lon_1)\n    y_1 = (nu/F0 + H)*cos(lat_1)*sin(lon_1)\n    z_1 = ((1-e2)*nu/F0 + H)*sin(lat_1)\n\n    # Perform Helmut transform (to go between Airy 1830 (_1) and GRS80 (_2))\n    s = -20.4894*10**-6  # The scale factor -1\n    # The translations along x, y, z axes respectively\n    tx, ty, tz = 446.448, -125.157, + 542.060\n    # The rotations along x, y, z respectively (in seconds)\n    rxs, rys, rzs = 0.1502, 0.2470, 0.8421\n\n    # convert seconds to radians\n    def sec_to_rad(x): return x*pi/(180*3600.)\n\n    rx, ry, rz = [sec_to_rad(x) for x in (rxs, rys, rzs)]  # (in radians)\n    x_2 = tx + (1+s)*x_1 + (-rz)*y_1 + (ry)*z_1\n    y_2 = ty + (rz)*x_1 + (1+s)*y_1 + (-rx)*z_1\n    z_2 = tz + (-ry)*x_1 + (rx)*y_1 + (1+s)*z_1\n\n    # Back to spherical polar coordinates from cartesian\n    # Need some of the characteristics of the new ellipsoid\n\n    # The GSR80 semi-major and semi-minor axes used for WGS84(m)\n    a_2, b_2 = 6378137.000, 6356752.3141\n    e2_2 = 1 - (b_2*b_2)/(a_2*a_2)  # The eccentricity of the GRS80 ellipsoid\n    p = sqrt(x_2**2 + y_2**2)\n\n    # Lat is obtained by an iterative proceedure:\n    lat = atan2(z_2, (p*(1-e2_2)))  # Initial value\n    latold = 2*pi\n    while abs(lat - latold) > 10**-16:\n        lat, latold = latold, lat\n        nu_2 = a_2/sqrt(1-e2_2*sin(latold)**2)\n        lat = atan2(z_2+e2_2*nu_2*sin(latold), p)\n\n    # Lon and height are then pretty easy\n    lon = atan2(y_2, x_2)\n    H = p/cos(lat) - nu_2\n\n    # Uncomment this line if you want to print the results\n    # print([(lat-lat_1)*180/pi, (lon - lon_1)*180/pi])\n\n    # Convert to degrees\n    lat = lat*180/pi\n    lon = lon*180/pi\n\n    # Job's a good'n.\n    return lat, lon"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the first element in items for which pred returns True", "response": "def find(pred, items):\n\t\"\"\"\n\tFind the index of the first element in items for which pred returns\n\tTrue\n\n\t>>> find(lambda x: x > 3, range(100))\n\t4\n\t>>> find(lambda x: x < -3, range(100)) is None\n\tTrue\n\t\"\"\"\n\tfor i, item in enumerate(items):\n\t\tif pred(item):\n\t\t\treturn i"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_less_significant(self, significant_version):\n\t\tdef nonzero(x):\n\t\t\treturn x != 0\n\t\tversion_len = 3  # strict versions are always a tuple of 3\n\t\tsignificant_pos = rfind(nonzero, significant_version.version)\n\t\tsignificant_pos = version_len + significant_pos + 1\n\t\tself.version = (\n\t\t\tself.version[:significant_pos]\n\t\t\t+ (0,) * (version_len - significant_pos))", "response": "reset all version info less significant than the passed significant version."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the version as a number.", "response": "def as_number(self):\n\t\t\"\"\"\n\t\t>>> round(SummableVersion('1.9.3').as_number(), 12)\n\t\t1.93\n\t\t\"\"\"\n\t\tdef combine(subver, ver):\n\t\t\treturn subver / 10 + ver\n\t\treturn reduce(combine, reversed(self.version))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the version of the local working set as a StrictVersion or None if no viable tag exists.", "response": "def get_tagged_version(self):\n\t\t\"\"\"\n\t\tGet the version of the local working set as a StrictVersion or\n\t\tNone if no viable tag exists. If the local working set is itself\n\t\tthe tagged commit and the tip and there are no local\n\t\tmodifications, use the tag on the parent changeset.\n\t\t\"\"\"\n\t\ttags = list(self.get_tags())\n\t\tif 'tip' in tags and not self.is_modified():\n\t\t\ttags = self.get_parent_tags('tip')\n\t\tversions = self.__versions_from_tags(tags)\n\t\treturn self.__best_version(versions)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_version(self, increment=None):\n\t\tver = (\n\t\t\tself.get_tagged_version()\n\t\t\tor str(self.get_next_version(increment)) + '.dev0'\n\t\t)\n\t\treturn str(ver)", "response": "get_current_version returns as a string the current version of the current state of the the\n\trepository"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the next version based on prior tagged releases.", "response": "def get_next_version(self, increment=None):\n\t\t\"\"\"\n\t\tReturn the next version based on prior tagged releases.\n\t\t\"\"\"\n\t\tincrement = increment or self.increment\n\t\treturn self.infer_next_version(self.get_latest_version(), increment)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninfers the next version of the application.", "response": "def infer_next_version(last_version, increment):\n\t\t\"\"\"\n\t\tGiven a simple application version (as a StrictVersion),\n\t\tand an increment (1.0, 0.1, or 0.0.1), guess the next version.\n\n\t\tSet up a shorthand for examples\n\n\t\t>>> def VM_infer(*params):\n\t\t...     return str(VersionManagement.infer_next_version(*params))\n\n\t\t>>> VM_infer('3.2', '0.0.1')\n\t\t'3.2.1'\n\t\t>>> VM_infer(StrictVersion('3.2'), '0.0.1')\n\t\t'3.2.1'\n\t\t>>> VM_infer('3.2.3', '0.1')\n\t\t'3.3'\n\t\t>>> VM_infer('3.1.2', '1.0')\n\t\t'4.0'\n\n\t\tSubversions never increment parent versions\n\n\t\t>>> VM_infer('3.0.9', '0.0.1')\n\t\t'3.0.10'\n\n\t\tIf it's a prerelease version, just remove the prerelease.\n\n\t\t>>> VM_infer('3.1a1', '0.0.1')\n\t\t'3.1'\n\n\t\tIf there is no last version, use the increment itself\n\n\t\t>>> VM_infer(None, '0.1')\n\t\t'0.1'\n\t\t\"\"\"\n\t\tif last_version is None:\n\t\t\treturn increment\n\t\tlast_version = SummableVersion(str(last_version))\n\t\tif last_version.prerelease:\n\t\t\tlast_version.prerelease = None\n\t\t\treturn str(last_version)\n\t\tincrement = SummableVersion(increment)\n\t\tsum = last_version + increment\n\t\tsum.reset_less_significant(increment)\n\t\treturn sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_global_notification(self, account_id, account_notification_end_at, account_notification_subject, account_notification_message, account_notification_start_at, account_notification_icon=None, account_notification_roles=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - account_notification[subject]\r\n        \"\"\"The subject of the notification.\"\"\"\r\n        data[\"account_notification[subject]\"] = account_notification_subject\r\n\r\n        # REQUIRED - account_notification[message]\r\n        \"\"\"The message body of the notification.\"\"\"\r\n        data[\"account_notification[message]\"] = account_notification_message\r\n\r\n        # REQUIRED - account_notification[start_at]\r\n        \"\"\"The start date and time of the notification in ISO8601 format.\r\n        e.g. 2014-01-01T01:00Z\"\"\"\r\n        data[\"account_notification[start_at]\"] = account_notification_start_at\r\n\r\n        # REQUIRED - account_notification[end_at]\r\n        \"\"\"The end date and time of the notification in ISO8601 format.\r\n        e.g. 2014-01-01T01:00Z\"\"\"\r\n        data[\"account_notification[end_at]\"] = account_notification_end_at\r\n\r\n        # OPTIONAL - account_notification[icon]\r\n        \"\"\"The icon to display with the notification.\r\n        Note: Defaults to warning.\"\"\"\r\n        if account_notification_icon is not None:\r\n            self._validate_enum(account_notification_icon, [\"warning\", \"information\", \"question\", \"error\", \"calendar\"])\r\n            data[\"account_notification[icon]\"] = account_notification_icon\r\n\r\n        # OPTIONAL - account_notification_roles\r\n        \"\"\"The role(s) to send global notification to.  Note:  ommitting this field will send to everyone\r\n        Example:\r\n          account_notification_roles: [\"StudentEnrollment\", \"TeacherEnrollment\"]\"\"\"\r\n        if account_notification_roles is not None:\r\n            data[\"account_notification_roles\"] = account_notification_roles\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/account_notifications with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/account_notifications\".format(**path), data=data, params=params, no_data=True)", "response": "Create a new global notification for an account. Returns a new global notification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadapt a persistent instance to a REST model.", "response": "def adapt_persistent_instance(persistent_object, target_rest_class=None, attribute_filter=None):\n    \"\"\"\n    Adapts a single persistent instance to a REST model; at present this is a\n    common method for all persistent backends.\n\n    Refer to: https://groups.google.com/forum/#!topic/prestans-discuss/dO1yx8f60as\n    for discussion on this feature\n    \"\"\"\n\n    # try and get the adapter and the REST class for the persistent object\n    if target_rest_class is None:\n        adapter_instance = registry.get_adapter_for_persistent_model(persistent_object)\n    else:\n        if inspect.isclass(target_rest_class):\n            target_rest_class = target_rest_class()\n\n        adapter_instance = registry.get_adapter_for_persistent_model(persistent_object, target_rest_class)\n\n    # would raise an exception if the attribute_filter differs from the target_rest_class\n    if attribute_filter is not None and isinstance(attribute_filter, parser.AttributeFilter):\n        parser.AttributeFilter.from_model(target_rest_class).conforms_to_template_filter(attribute_filter)\n\n    # convert filter to immutable if it isn't already\n    if isinstance(attribute_filter, parser.AttributeFilter):\n        attribute_filter = attribute_filter.as_immutable()\n\n    return adapter_instance.adapt_persistent_to_rest(persistent_object, attribute_filter)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adapt_persistent_to_rest(self, persistent_object, attribute_filter=None):\n        # convert filter to immutable if it isn't already\n        if isinstance(attribute_filter, parser.AttributeFilter):\n            attribute_filter = attribute_filter.as_immutable()\n\n        rest_model_instance = self.rest_model_class()\n\n        for attribute_key in rest_model_instance.get_attribute_keys():\n\n            # attribute is not visible don't bother processing\n            if isinstance(attribute_filter, (parser.AttributeFilter, parser.AttributeFilterImmutable)) and \\\n               not attribute_filter.is_attribute_visible(attribute_key):\n                continue\n\n            rest_attr = getattr(self.rest_model_class, attribute_key)\n\n            # don't bother processing if the persistent model doesn't have this attribute\n            if not hasattr(persistent_object, attribute_key):\n\n                if isinstance(rest_attr, types.Model):\n                    #: If the attribute is a Model, then we set it to None otherwise we get a model\n                    #: with default values, which is invalid when constructing responses\n                    try:\n                        setattr(rest_model_instance, attribute_key, None)\n                    # catch any exception thrown from setattr to give a usable error message\n                    except TypeError as exp:\n                        raise TypeError('Attribute %s, %s' % (attribute_key, str(exp)))\n\n                continue\n            # ignore class methods\n            elif inspect.ismethod(getattr(persistent_object, attribute_key)):\n                import logging\n                logging.error(\"ignoring method: \"+attribute_key)\n                continue\n\n            # handles prestans array population from SQLAlchemy relationships\n            elif isinstance(rest_attr, types.Array):\n\n                persistent_attr_value = getattr(persistent_object, attribute_key)\n                rest_model_array_handle = getattr(rest_model_instance, attribute_key)\n\n                # iterator uses the .append method exposed by prestans arrays to validate\n                # and populate the collection in the instance.\n                for collection_element in persistent_attr_value:\n                    if rest_attr.is_scalar:\n                        rest_model_array_handle.append(collection_element)\n                    else:\n                        element_adapter = registry.get_adapter_for_rest_model(rest_attr.element_template)\n\n                        # check if there is a sub model filter\n                        sub_attribute_filter = None\n                        if attribute_filter and attribute_key in attribute_filter:\n                            sub_attribute_filter = getattr(attribute_filter, attribute_key)\n\n                        adapted_rest_model = element_adapter.adapt_persistent_to_rest(\n                            collection_element,\n                            sub_attribute_filter\n                        )\n                        rest_model_array_handle.append(adapted_rest_model)\n\n            elif isinstance(rest_attr, types.Model):\n\n                try:\n                    persistent_attr_value = getattr(persistent_object, attribute_key)\n\n                    if persistent_attr_value is None:\n                        adapted_rest_model = None\n                    else:\n                        model_adapter = registry.get_adapter_for_rest_model(rest_attr)\n\n                        # check if there is a sub model filter\n                        sub_attribute_filter = None\n                        if isinstance(attribute_filter, (parser.AttributeFilter, parser.AttributeFilterImmutable)) and \\\n                                attribute_key in attribute_filter:\n                            sub_attribute_filter = getattr(attribute_filter, attribute_key)\n\n                        adapted_rest_model = model_adapter.adapt_persistent_to_rest(\n                            persistent_attr_value,\n                            sub_attribute_filter\n                        )\n\n                    setattr(rest_model_instance, attribute_key, adapted_rest_model)\n\n                except TypeError as exp:\n                    raise TypeError('Attribute %s, %s' % (attribute_key, str(exp)))\n                except exception.DataValidationException as exp:\n                    raise exception.InconsistentPersistentDataError(attribute_key, str(exp))\n\n            else:\n\n                # otherwise copy the value to the rest model\n                try:\n                    persistent_attr_value = getattr(persistent_object, attribute_key)\n                    setattr(rest_model_instance, attribute_key, persistent_attr_value)\n                except TypeError as exp:\n                    raise TypeError('Attribute %s, %s' % (attribute_key, str(exp)))\n                except exception.ValidationError as exp:\n                    raise exception.InconsistentPersistentDataError(attribute_key, str(exp))\n\n        return rest_model_instance", "response": "Adapts a persistent model to a rest model by inspecting it and converting it to immutable and then converting it to immutable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_persistent_rest_pair(self, persistent_model_class, rest_model_class):\n        self.register_adapter(ModelAdapter(\n            rest_model_class=rest_model_class,\n            persistent_model_class=persistent_model_class\n        ))", "response": "Register a persistent and rest pair of models."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the ModelAdapter for the given persistent model and rest model.", "response": "def get_adapter_for_persistent_model(self, persistent_model, rest_model=None):\n        \"\"\"\n        :param persistent_model: instance of persistent model\n        :param rest_model: specific REST model\n        :return: the matching model adapter\n        :rtype: ModelAdapter\n        \"\"\"\n        persistent_signature = self.generate_signature(persistent_model)\n        \n        if persistent_signature in self._persistent_map:\n            sub_map = self._persistent_map[persistent_signature]\n\n            # return the first match if REST model was not specified\n            if rest_model is None:\n                return self._persistent_map[persistent_signature][self.DEFAULT_REST_ADAPTER]\n            else:\n                rest_sig = self.generate_signature(rest_model)\n                if rest_sig in sub_map:\n                    return self._persistent_map[persistent_signature][rest_sig]\n\n        raise TypeError(\"No registered Data Adapter for class %s\" % persistent_signature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the corresponding ModelAdapter for the given REST model", "response": "def get_adapter_for_rest_model(self, rest_model):\n        \"\"\"\n        :param rest_model: instance of REST model\n        :return: the matching model adapter\n        :rtype: ModelAdapter\n        \"\"\"\n        class_signature = self.generate_signature(rest_model)\n        \n        if class_signature not in self._rest_map:\n            raise TypeError(\"No registered Data Adapter for class %s\" % class_signature)\n\n        return self._rest_map[class_signature]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a queryset of popular content objects.", "response": "def popular_content(**kwargs):\n    \"\"\"\n    Use the get_popular_ids() to retrieve trending content objects.\n    Return recent content on failure.\n    \"\"\"\n    limit = kwargs.get(\"limit\", DEFAULT_LIMIT)\n    popular_ids = get_popular_ids(limit=limit)\n    if not popular_ids:\n        # Return most recent content\n        return Content.search_objects.search().extra(size=limit)\n    return Content.search_objects.search().filter(es_filter.Ids(values=popular_ids))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a JSON string to Solr instance", "response": "def _send_solr_command(self, core_url, json_command):\n        \"\"\"\n        Sends JSON string to Solr instance\n        \"\"\"\n\n        # Check document language and dispatch to correct core\n        url = _get_url(core_url, \"update\")\n        try:\n            response = self.req_session.post(url, data=json_command, headers={'Content-Type': 'application/json'})\n            response.raise_for_status()\n        except requests.RequestException as e:\n            logger.error(\"Failed to send update to Solr endpoint [%s]: %s\", core_url, e, exc_info=True)\n            raise SolrException(\"Failed to send command to Solr [%s]: %s\" % (core_url, e,))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, documents, boost=None):\n\n        if not isinstance(documents, list):\n            documents = [documents]\n        documents = [{'doc': d} for d in documents]\n        if boost:\n            for d in documents:\n                d['boost'] = boost\n\n        self._add_batch.extend(documents)\n\n        if len(self._add_batch) > SOLR_ADD_BATCH:\n            self._addFlushBatch()", "response": "Adds documents to Solr index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending all waiting documents to Solr", "response": "def _addFlushBatch(self):\n        \"\"\"\n        Sends all waiting documents to Solr\n        \"\"\"\n\n        if len(self._add_batch) > 0:\n            language_batches = {}\n            # Create command JSONs for each of language endpoints\n            for lang in self.endpoints:\n                # Append documents with languages without endpoint to default endpoint\n                document_jsons = [\"\\\"add\\\":\" + json.dumps(data) for data in self._add_batch\n                                  if data['doc'].get(\"language\", self.default_endpoint) == lang or (lang == self.default_endpoint and not self.endpoints.has_key(data['doc'].get(\"language\", None)))]\n                command_json = \"{\" + \",\".join(document_jsons) + \"}\"\n                language_batches[lang] = command_json\n            # Solr requires for documents to be sent in { \"add\" : { \"doc\" : {...} }, \"add\": { \"doc\" : { ... }, ... }\n            # format which isn't possible with python dictionaries\n            for lang in language_batches:\n                self._send_solr_command(self.endpoints[lang], language_batches[lang])\n                self._add_batch = []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting whole Solr index. Use with care.", "response": "def deleteAll(self):\n        \"\"\"\n        Deletes whole Solr index. Use with care.\n        \"\"\"\n        for core in self.endpoints:\n            self._send_solr_command(self.endpoints[core], \"{\\\"delete\\\": { \\\"query\\\" : \\\"*:*\\\"}}\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a document with the given ID on all Solr cores", "response": "def delete(self, id):\n        \"\"\"\n        Deletes document with ID on all Solr cores\n        \"\"\"\n        for core in self.endpoints:\n            self._send_solr_command(self.endpoints[core], \"{\\\"delete\\\" : { \\\"id\\\" : \\\"%s\\\"}}\" % (id,))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommitting all pending changes and commits Solr changes", "response": "def commit(self):\n        \"\"\"\n        Flushes all pending changes and commits Solr changes\n        \"\"\"\n        self._addFlushBatch()\n        for core in self.endpoints:\n            self._send_solr_command(self.endpoints[core], \"{ \\\"commit\\\":{} }\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns comma separated list of configured Solr cores", "response": "def _get_shards(self):\n        \"\"\"\n        Returns comma separated list of configured Solr cores\n        \"\"\"\n        if self._shards is None:\n            endpoints = []\n            for endpoint in self.endpoints:\n                # We need to remove and http:// prefixes from URLs\n                url = urlparse.urlparse(self.endpoints[endpoint])\n                endpoints.append(\"/\".join([url.netloc, url.path]))\n            self._shards = \",\".join(endpoints)\n        return self._shards"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the response dictionary into a SolrResults object.", "response": "def _parse_response(self, results):\n        \"\"\"\n        Parses result dictionary into a SolrResults object\n        \"\"\"\n\n        dict_response = results.get(\"response\")\n        result_obj = SolrResults()\n        result_obj.query_time = results.get(\"responseHeader\").get(\"QTime\", None)\n        result_obj.results_count = dict_response.get(\"numFound\", 0)\n        result_obj.start_index = dict_response.get(\"start\", 0)\n\n        for doc in dict_response.get(\"docs\", []):\n            result_obj.documents.append(doc)\n\n        # Process facets\n        if \"facet_counts\" in results:\n            facet_types = [\"facet_fields\", \"facet_dates\", \"facet_ranges\", \"facet_queries\"]\n            for type in facet_types:\n                assert type in results.get(\"facet_counts\")\n                items = results.get(\"facet_counts\").get(type)\n                for field, values in items.items():\n                    result_obj.facets[field] = []\n\n                    # Range facets have results in \"counts\" subkey and \"between/after\" on top level. Flatten this.\n                    if type == \"facet_ranges\":\n                        if not \"counts\" in values:\n                            continue\n\n                        for facet, value in values[\"counts\"].items():\n                            result_obj.facets[field].append((facet, value))\n\n                        if \"before\" in values:\n                            result_obj.facets[field].append((\"before\", values[\"before\"]))\n\n                        if \"after\" in values:\n                            result_obj.facets[field].append((\"after\", values[\"after\"]))\n                    else:\n                        for facet, value in values.items():\n                            # Date facets have metadata fields between the results, skip the params, keep \"before\" and \"after\" fields for other\n                            if type == \"facet_dates\" and \\\n                            (facet == \"gap\" or facet == \"between\" or facet == \"start\" or facet == \"end\"):\n                                continue\n                            result_obj.facets[field].append((facet, value))\n\n        # Process highlights\n        if \"highlighting\" in results:\n            for key, value in results.get(\"highlighting\").items():\n                result_obj.highlights[key] = value\n\n        return result_obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery Solr and returns results for a specific entry in the cache.", "response": "def query(self, query, filters=None, columns=None, sort=None, start=0, rows=30):\n        \"\"\"\n        Queries Solr and returns results\n\n        query - Text query to search for\n        filters - dictionary of filters to apply when searching in form of { \"field\":\"filter_value\" }\n        columns - columns to return, list of strings\n        sort - list of fields to sort on in format of [\"field asc\", \"field desc\", ... ]\n        start - start number of first result (used in pagination)\n        rows - number of rows to return (used for pagination, defaults to 30)\n        \"\"\"\n\n        if not columns:\n            columns = [\"*\", \"score\"]\n\n        fields = {\"q\": query,\n                 \"json.nl\" :\"map\",           # Return facets as JSON objects\n                 \"fl\": \",\".join(columns),    # Return score along with results\n                 \"start\": str(start),\n                 \"rows\": str(rows),\n                 \"wt\": \"json\"}\n\n        # Use shards parameter only if there are several cores active\n        if len(self.endpoints) > 1:\n            fields[\"shards\"] = self._get_shards()\n\n        # Prepare filters\n        if not filters is None:\n            filter_list = []\n            for filter_field, value in filters.items():\n                filter_list.append(\"%s:%s\" % (filter_field, value))\n            fields[\"fq\"] = \" AND \".join(filter_list)\n\n        # Append sorting parameters\n        if not sort is None:\n            fields[\"sort\"] = \",\".join(sort)\n\n        # Do request to Solr server to default endpoint (other cores will be queried with shard functionality)\n        assert self.default_endpoint in self.endpoints\n        request_url = _get_url(self.endpoints[self.default_endpoint], \"select\")\n        results = self._send_solr_query(request_url, fields)\n        if not results:\n            return None\n\n        assert \"responseHeader\" in results\n        # Check for response status\n        if not results.get(\"responseHeader\").get(\"status\") == 0:\n            logger.error(\"Server error while retrieving results: %s\", results)\n            return None\n\n        assert \"response\" in results\n\n        result_obj = self._parse_response(results)\n        return result_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve more like this results for a passed query document", "response": "def more_like_this(self, query, fields, columns=None, start=0, rows=30):\n        \"\"\"\n        Retrieves \"more like this\" results for a passed query document\n\n        query - query for a document on which to base similar documents\n        fields - fields on which to base similarity estimation (either comma delimited string or a list)\n        columns - columns to return (list of strings)\n        start - start number for first result (used in pagination)\n        rows - number of rows to return (used for pagination, defaults to 30)\n        \"\"\"\n        if isinstance(fields, basestring):\n            mlt_fields = fields\n        else:\n            mlt_fields = \",\".join(fields)\n\n        if columns is None:\n            columns = [\"*\", \"score\"]\n\n        fields = {'q' : query,\n                  'json.nl': 'map',\n                  'mlt.fl': mlt_fields,\n                  'fl': \",\".join(columns),\n                  'start': str(start),\n                  'rows': str(rows),\n                  'wt': \"json\"}\n\n        if len(self.endpoints) > 1:\n            fields[\"shards\"] = self._get_shards()\n\n        assert self.default_endpoint in self.endpoints\n        request_url = _get_url(self.endpoints[self.default_endpoint], \"mlt\")\n        results = self._send_solr_query(request_url, fields)\n        if not results:\n            return None\n\n        assert \"responseHeader\" in results\n        # Check for response status\n        if not results.get(\"responseHeader\").get(\"status\") == 0:\n            logger.error(\"Server error while retrieving results: %s\", results)\n            return None\n\n        assert \"response\" in results\n\n        result_obj = self._parse_response(results)\n        return result_obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_suite(case, config, summary):\n    m = importlib.import_module(config['module'])\n    m.set_up()\n    config[\"name\"] = case\n    analysis_data = {}\n    bundle = livvkit.numerics_model_module\n    model_dir = os.path.join(livvkit.model_dir, config['data_dir'], case)\n    bench_dir = os.path.join(livvkit.bench_dir, config['data_dir'], case)\n    plot_dir = os.path.join(livvkit.output_dir, \"numerics\", \"imgs\")\n    config[\"plot_dir\"] = plot_dir\n    functions.mkdir_p(plot_dir)\n    model_cases = functions.collect_cases(model_dir)\n    bench_cases = functions.collect_cases(bench_dir)\n\n    for mscale in sorted(model_cases):\n        bscale = bench_cases[mscale] if mscale in bench_cases else []\n        for mproc in model_cases[mscale]:\n            full_name = '-'.join([mscale, mproc])\n            bpath = (os.path.join(bench_dir, mscale, mproc.replace(\"-\", os.path.sep))\n                     if mproc in bscale else \"\")\n            mpath = os.path.join(model_dir, mscale, mproc.replace(\"-\", os.path.sep))\n            model_data = functions.find_file(mpath, \"*\" + config[\"output_ext\"])\n            bench_data = functions.find_file(bpath, \"*\" + config[\"output_ext\"])\n            analysis_data[full_name] = bundle.get_plot_data(model_data,\n                                                            bench_data,\n                                                            m.setup[case],\n                                                            config)\n    try:\n        el = m.run(config, analysis_data)\n    except KeyError:\n        el = elements.error(\"Numerics Plots\", \"Missing data\")\n    result = elements.page(case, config['description'], element_list=el)\n    summary[case] = _summarize_result(m, analysis_data, config)\n    _print_summary(m, case, summary[case])\n    functions.create_page_from_template(\"numerics.html\",\n                                        os.path.join(livvkit.index_dir, \"numerics\", case + \".html\"))\n    functions.write_json(result, os.path.join(livvkit.output_dir, \"numerics\"), case + \".json\")", "response": "Run the full suite of numerics tests"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the particle system for the specified time frame at the specified framerate.", "response": "def run_ahead(self, time, framerate):\n        \"\"\"Run the particle system for the specified time frame at the\n        specified framerate to move time forward as quickly as possible.\n        Useful for \"warming up\" the particle system to reach a steady-state\n        before anything is drawn or to simply \"skip ahead\" in time.\n\n        time -- The amount of simulation time to skip over.\n\n        framerate -- The framerate of the simulation in updates per unit\n        time. Higher values will increase simulation accuracy,\n        but will take longer to compute.\n        \"\"\"\n        if time:\n            td = 1.0 / framerate\n            update = self.update\n            for i in range(int(time / td)):\n                update(td)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of HTML column for this panel.", "response": "def get_html_column(self):\n        \"\"\" Get a HTML column for this panel. \"\"\"\n\n        panel_id = \"panel_{}\".format(self.name)\n        return [\"<h2>{}</h2>\".format(self.title) + '<a href=\"{}\">Download data</a>'.format(self.tar_fn())] + [\n            # list of links\n            (\" <br />\" + os.linesep).join(\n                [\n                    \"\"\"\n\t\t\t\t\t\t   <strong>{bam_name}:</strong>\n\t\t\t\t\t\t   <a onclick=\"document.getElementById('{panel_id}').src='{bam_svg}';document.getElementById('{panel_id}_').href='{bam_html}';return false;\" href=\"#\">display graph</a>,\n\t\t\t\t\t\t   <a href=\"{bam_html}\">detailed report</a>\n\t\t\t\t\t\t   \"\"\".format(\n                        bam_name=bam.get_name(),\n                        bam_html=bam.html_fn(),\n                        bam_svg=bam.svg_fn(),\n                        panel_id=panel_id,\n                    ) for bam in self.bams\n                ]\n            ) + '<br /> '.format(self.tar_fn()),\n\n            # main graph\n            \"\"\"\n\t\t\t\t   <div class=\"formats\">\n\t\t\t\t   <a href=\"{html}\" id=\"{panel_id}_\">\n\t\t\t\t   <img src=\"{svg}\" id=\"{panel_id}\" />\n\t\t\t\t   </a>\n\t\t\t\t   </div>\n\t\t\t\t   \"\"\".format(\n                html=self.bams[0]._html_fn,\n                svg=self.bams[0]._svg_fn,\n                panel_id=panel_id,\n            ),\n        ] + [\n            # overall graphs\n            \"\"\"\n\t\t\t\t   <div class=\"formats\">\n\t\t\t\t   <img src=\"{svg}\" />\n\t\t\t\t   <br />\n\t\t\t\t   <a href=\"{svg}\">SVG version</a>\n\t\t\t\t   |\n\t\t\t\t   <a href=\"{gp}\" type=\"text/plain\">GP file</a>\n\t\t\t\t   </div>\n\t\t\t\t   \n\t\t\t\t   \"\"\".format(\n                svg=svg,\n                gp=self._gp_fn,\n            ) for svg in self._svg_fns\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating images related to this panel.", "response": "def create_graphics(self):\n        \"\"\"Create images related to this panel.\"\"\"\n\n        if len(self._svg_fns) > 0:\n            rnftools.utils.shell('\"{}\" \"{}\"'.format(\"gnuplot\", self._gp_fn))\n\n            if self.render_pdf_method is not None:\n                for svg_fn in self._svg_fns:\n                    pdf_fn = re.sub(r'\\.svg$', r'.pdf', svg_fn)\n                    svg42pdf(svg_fn, pdf_fn, method=self.render_pdf_method)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tar(self):\n\n        def add_file_to_tar(tar, orig_fn, new_fn, func=None):\n            tf = tarfile.TarInfo(name=new_fn)\n            with open(orig_fn) as f:\n                tfs = f.read()\n\n            if func is not None:\n                tfs = func(tfs)\n            tf.size = len(tfs)\n            tfs = io.BytesIO(tfs.encode('utf8'))\n            tar.addfile(tarinfo=tf, fileobj=tfs)\n\n        def add_text_to_tar(tar, new_fn, text, func=None):\n            tf = tarfile.TarInfo(name=new_fn)\n            if func is not None:\n                text = func(text)\n            tf.size = len(text)\n            tfs = io.BytesIO(text.encode('utf8'))\n            tar.addfile(tarinfo=tf, fileobj=tfs)\n\n        def strip_lines(text):\n            text = text.replace(\"\\t\", \" \")\n            while text.find(\"  \") != -1:\n                text = text.replace(\"  \", \" \")\n            lines = [x.strip() for x in text.strip().split(\"\\n\")]\n            return \"\\n\".join(lines) + \"\\n\"\n\n        tar = tarfile.TarFile(self._tar_fn, \"w\")\n        for i in range(len(self.bams)):\n            roc_fn = self.bams[i].roc_fn()\n            t_roc_fn = os.path.basename(roc_fn)\n\n            gp_fn = self.bams[i].gp_fn()\n            t_gp_fn = os.path.basename(gp_fn)\n\n            svg_fn = self.bams[i].svg_fn()\n            t_svg_fn = os.path.basename(svg_fn)\n\n            add_file_to_tar(tar, roc_fn, t_roc_fn)\n            add_file_to_tar(\n                tar, gp_fn, t_gp_fn, lambda x: strip_lines(x.replace(roc_fn, t_roc_fn).replace(svg_fn, t_svg_fn))\n            )\n\n        gp_fn = self._gp_fn\n        t_gp_fn = os.path.basename(gp_fn)\n        svg_dir = os.path.join(self.panel_dir, \"graphics\") + \"/\"\n        roc_dir = os.path.join(self.panel_dir, \"roc\") + \"/\"\n        add_file_to_tar(tar, gp_fn, t_gp_fn, lambda x: strip_lines(x.replace(svg_dir, \"\").replace(roc_dir, \"\")))\n\n        makefile = [\n            \".PHONY: all\",\n            \"all:\",\n            \"\\tgnuplot *.gp\",\n            \"clean:\",\n            \"\\trm -f *.svg\",\n            \"\",\n        ]\n        add_text_to_tar(tar, \"Makefile\", \"\\n\".join(makefile))", "response": "Create a tar file with all the files."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges two dictionaries and return the result", "response": "def merge_dicts(dict1, dict2):\n    \"\"\" Merge two dictionaries and return the result \"\"\"\n    tmp = dict1.copy()\n    tmp.update(dict2)\n    return tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a GPTL timing file and extract some data.", "response": "def parse_gptl(file_path, var_list):\n    \"\"\"\n    Read a GPTL timing file and extract some data.\n\n    Args:\n        file_path: the path to the GPTL timing file\n        var_list: a list of strings to look for in the file\n\n    Returns:\n        A dict containing key-value pairs of the livvkit\n        and the times associated with them\n    \"\"\"\n    timing_result = dict()\n    if os.path.isfile(file_path):\n        with open(file_path, 'r') as f:\n            for var in var_list:\n                for line in f:\n                    if var in line:\n                        timing_result[var] = float(line.split()[4])/int(line.split()[2])\n                        break\n    return timing_result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for a file in a directory and return the first match.", "response": "def find_file(search_dir, file_pattern):\n    \"\"\"\n    Search for a file in a directory, and return the first match.\n    If the file is not found return an empty string\n\n    Args:\n        search_dir: The root directory to search in\n        file_pattern: A unix-style wildcard pattern representing\n            the file to find\n\n    Returns:\n        The path to the file if it was found, otherwise an empty string\n    \"\"\"\n    for root, dirnames, fnames in os.walk(search_dir):\n            for fname in fnames:\n                if fnmatch.fnmatch(fname, file_pattern):\n                    return os.path.join(root, fname)\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy the correct html template file to the output directory", "response": "def create_page_from_template(template_file, output_path):\n    \"\"\" Copy the correct html template file to the output directory \"\"\"\n    mkdir_p(os.path.dirname(output_path))\n    shutil.copy(os.path.join(livvkit.resource_dir, template_file), output_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_json(file_path):\n    try:\n        with open(file_path, 'r') as f:\n            config = json_tricks.load(f)\n    except ValueError:\n        print('    '+'!'*58)\n        print('    Woops! Looks the JSON syntax is not valid in:')\n        print('        {}'.format(file_path))\n        print('    Note: commonly this is a result of having a trailing comma \\n    in the file')\n        print('    '+'!'*58)\n        raise\n\n    return config", "response": "Read in a json file and return a dictionary representation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_json(data, path, file_name):\n    if os.path.exists(path) and not os.path.isdir(path):\n        return\n    elif not os.path.exists(path):\n        mkdir_p(path)\n    with open(os.path.join(path, file_name), 'w') as f:\n        json_tricks.dump(data, f, indent=4, primitives=True, allow_nan=True)", "response": "Write out data to a json file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds all cases and subcases of a particular run type", "response": "def collect_cases(data_dir):\n    \"\"\" Find all cases and subcases of a particular run type \"\"\"\n    cases = {}\n    for root, dirs, files in os.walk(data_dir):\n        if not dirs:\n            split_case = os.path.relpath(root, data_dir).split(os.path.sep)\n            if split_case[0] not in cases:\n                cases[split_case[0]] = []\n            cases[split_case[0]].append(\"-\".join(split_case[1:]))\n    return cases"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_output(cssd=None, jsd=None, imgd=None):\n    # Check if we need to back up an old run\n    if os.path.isdir(livvkit.index_dir):\n        print(\"-------------------------------------------------------------------\")\n        print('  Previous output data found in output directory!')\n        try:\n            f = open(os.path.join(livvkit.index_dir, \"data.txt\"), \"r\")\n            prev_time = f.readline().replace(\":\", \"\").replace(\"-\", \"\").replace(\" \", \"_\").rstrip()\n            f.close()\n        except IOError:\n            prev_time = \"bkd_\"+datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        print('   Backing up data to:')\n        print('   ' + livvkit.index_dir + \"_\" + prev_time)\n        print(\"-------------------------------------------------------------------\")\n        shutil.move(livvkit.index_dir, livvkit.index_dir + \"_\" + prev_time)\n    else:\n        print(\"-------------------------------------------------------------------\")\n\n    # Copy over js, css, & imgs directories from source\n    if cssd:\n        shutil.copytree(cssd, os.path.join(livvkit.index_dir, \"css\"))\n    else:\n        shutil.copytree(os.path.join(livvkit.resource_dir, \"css\"),\n                        os.path.join(livvkit.index_dir, \"css\"))\n    if jsd:\n        shutil.copytree(jsd, os.path.join(livvkit.index_dir, \"js\"))\n    else:\n        shutil.copytree(os.path.join(livvkit.resource_dir, \"js\"),\n                        os.path.join(livvkit.index_dir, \"js\"))\n    if imgd:\n        shutil.copytree(imgd, os.path.join(livvkit.index_dir, \"js\"))\n    else:\n        shutil.copytree(os.path.join(livvkit.resource_dir, \"imgs\"),\n                        os.path.join(livvkit.index_dir, \"imgs\"))\n\n    # Get the index template from the resource directory\n    shutil.copy(os.path.join(livvkit.resource_dir, \"index.html\"),\n                os.path.join(livvkit.index_dir, \"index.html\"))\n    # Record when this data was recorded so we can make nice backups\n    with open(os.path.join(livvkit.index_dir, \"data.txt\"), \"w\") as f:\n        f.write(livvkit.timestamp + \"\\n\")\n        f.write(livvkit.comment)", "response": "Sets up the directory structure for the run\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the parameters to be used in querystring.", "response": "def prepare_query_params(**kwargs):\n    \"\"\"\n    Prepares given parameters to be used in querystring.\n    \"\"\"\n    return [\n        (sub_key, sub_value)\n        for key, value in kwargs.items()\n        for sub_key, sub_value in expand(value, key)\n        if sub_value is not None\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when the canvas is drawn.", "response": "def on_draw():\n\tglobal yrot\n\twin.clear()\n\tglLoadIdentity()\n\tglTranslatef(0, 0, -100)\n\tglRotatef(yrot, 0.0, 1.0, 0.0)\n\tdefault_system.draw()\n\t'''\n\tglBindTexture(GL_TEXTURE_2D, 1)\n\tglEnable(GL_TEXTURE_2D)\n\tglEnable(GL_POINT_SPRITE)\n\tglPointSize(100);\n\tglBegin(GL_POINTS)\n\tglVertex2f(0,0)\n\tglEnd()\n\tglBindTexture(GL_TEXTURE_2D, 2)\n\tglEnable(GL_TEXTURE_2D)\n\tglEnable(GL_POINT_SPRITE)\n\tglPointSize(100);\n\tglBegin(GL_POINTS)\n\tglVertex2f(50,0)\n\tglEnd()\n\tglBindTexture(GL_TEXTURE_2D, 0)\n\t'''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup_callbackredirect(max_age=300):\n    max_age = timezone.now() - timedelta(seconds=max_age)\n    logger.debug(\"Deleting all callback redirects created before {0}\".format(max_age.strftime(\"%b %d %Y %H:%M:%S\")))\n    CallbackRedirect.objects.filter(created__lte=max_age).delete()", "response": "Delete all callback redirects created before max_age."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_token_email(self, request, queryset):\n        for token in queryset:\n            if not token.expired: forward_token(token)", "response": "Sends email for the selected users."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the number of objects in the cache for a given slug", "response": "def count(cls, slug):\n        \"\"\"get the number of objects in the cache for a given slug\n\n        :param slug: cache key\n        :return: `int`\n        \"\"\"\n        from .models import Content\n        # Gets the count for a tag, hopefully form an in-memory cache.\n        cnt = cls._cache.get(slug)\n        if cnt is None:\n            cnt = Content.search_objects.search(tags=[slug]).count()\n            cls._cache[slug] = cnt\n        return cnt"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_varchar(self):\n        dt = DATA_TYPES['varchar']\n        if type(self.data) is dt['type'] and len(self.data) < dt['max']:\n            self.type = 'VARCHAR'\n            self.len = len(self.data)\n            return True", "response": "Determine if a data record is of the type VARCHAR."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _is_text_data(self, data_type):\n        dt = DATA_TYPES[data_type]\n        if type(self.data) is dt['type'] and len(self.data) < dt['max'] and all(type(char) == str for char in self.data):\n            self.type = data_type.upper()\n            self.len = len(self.data)\n            return True", "response": "Private method for testing text data types."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_key_name(self, function, object_name):\r\n        for funcname, name in self.name_map.items():\r\n            if funcname == function:\r\n                self.name_map[\r\n                    funcname] = object_name", "response": "Bind a key to an object name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring name map for a list of objects", "response": "def bind_keys(self, objects):\r\n        \"\"\"Configure name map: My goal here is to associate a named object\r\n        with a specific function\"\"\"\r\n        for object in objects:\r\n            if object.keys != None:\r\n                for key in object.keys:\r\n                    if key != None:\r\n                        self.bind_key_name(key, object.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the key map", "response": "def configure_keys(self):\r\n        \"\"\"Configure key map\"\"\"\r\n        self.active_functions = set()\r\n        self.key2func = {}\r\n        for funcname, key in self.key_map.items():\r\n            self.key2func[key] = getattr(self, funcname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_module_list(module_list):\n    '''Loop through all the modules and parse them.'''\n    for module_meta in module_list:\n        name = module_meta['module']\n\n        # Import & parse module\n        module = import_module(name)\n        output = parse_module(module)\n\n        # Assign to meta.content\n        module_meta['content'] = output", "response": "Loop through all the modules and parse them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_module_list(source_module, index_filename, ignore_modules):\n    '''Builds a list of python modules in the current directory.'''\n    out = []\n    dirs_with_init = set()\n    module_prefix = '' if source_module == '.' else source_module\n\n    for root, _, filenames in walk('.'):\n        root = root[2:]\n        module_root = root.replace('/', '.')\n        file_names = [filename[:-3] for filename in filenames if filename.endswith('.py')]\n\n        for filename in file_names:\n            if filename == '__init__':\n                dirs_with_init.add(root)\n                module_name = '.'.join([module_prefix, module_root]) if module_root else source_module\n            elif not root:\n                module_name = '.'.join([module_prefix, filename])\n            else:\n                module_name = '.'.join([module_prefix, root.replace('/', '.'), filename])\n\n            if module_name.startswith('.'):\n                module_name = module_name[1:]\n\n            if module_name in ignore_modules:\n                print 'Ignored file: {}{}.py'.format('{}/'.format(root), filename)\n                continue\n\n            if root and root not in dirs_with_init:\n                print 'No __init__.py, skipping: {}{}.py'.format('{}/'.format(root), filename)\n                continue\n\n            source_name = '{}.py'.format(filename)\n            if root:\n                source_name = '{}/{}'.format(root, source_name)\n\n            if filename == '__init__':\n                output_name = '{}.md'.format(index_filename)\n            else:\n                output_name = '{}.md'.format(filename)\n            if root:\n                output_name = '{}/{}'.format(root, output_name)\n\n            out.append({\n                'directory': root,\n                'file': filename,\n                'module': module_name,\n                'output': output_name,\n                'source': source_name\n            })\n\n    return out", "response": "Builds a list of python modules in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_docs(module_list, output_dir):\n    '''Write the document meta to our output location.'''\n    for module_meta in module_list:\n        directory = module_meta['directory']\n        # Ensure target directory\n        if directory and not path.isdir(directory):\n            makedirs(directory)\n\n        # Write the file\n        file = open(module_meta['output'], 'w')\n        file.write(module_meta['content'])\n        file.close()", "response": "Write the document meta to our output location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a markdown documentation from a directory and python module.", "response": "def build(\n    root, source_module, output_dir,\n    json_dump=False, ignore_modules=None, index_filename='index'\n):\n    '''\n    Build markdown documentation from a directory and/or python module.\n\n    # ignore_modules: takes a list of module names to ignore\n    # index_filename: __init__.py output (default index.md), use README.md for github indexes\n    '''\n    if root.endswith('/'):\n        root = root[:-1]\n\n    if ignore_modules is None:\n        ignore_modules = []\n    elif isinstance(ignore_modules, str):\n        ignore_modules = ignore_modules.split(',')\n\n    # Ensure output_dir format (no / at start, / at end)\n    if output_dir.startswith('/'):\n        output_dir = output_dir[1:]\n\n    if not output_dir.endswith('/'):\n        output_dir = '{}/'.format(output_dir)\n\n    # Apply root to it, make the directory if not exists\n    output_dir = '{}/{}'.format(root, output_dir)\n    if not path.isdir(output_dir):\n            makedirs(output_dir)\n\n    if source_module == '.':\n        source_dir = '{}/'.format(root)\n    else:\n        source_dir = '{}/{}/'.format(root, source_module.replace('.', os.sep))\n\n    # Cd into the source directory\n    chdir(source_dir)\n    # And build the module list\n    module_list = _build_module_list(\n        source_module,\n        index_filename=index_filename,\n        ignore_modules=ignore_modules\n    )\n\n    # Cd back to old directory\n    chdir(root)\n    # And parse all the modules\n    _parse_module_list(module_list)\n\n    # Cd inot the target directory\n    chdir(output_dir)\n    # Finally, write the module list to our output dir\n    _write_docs(module_list, output_dir)\n\n    if json_dump:\n        print json.dumps(module_list, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    '''Main in a function in case you place a build.py for pydocs inside the root directory.'''\n\n    options = '''\n        pydocs\n\n        Usage:\n            pydocs SOURCE OUTPUT_DIR\n            pydocs SOURCE OUTPUT_DIR [--json] [--index NAME] [--ignore FILE,NAMES]\n            pydocs --help\n\n        Options:\n            SOURCE                  Source module, or . for current directory.\n            OUTPUT_DIR              The location to output the generated markdown.\n            --json                  Dump meta in JSON format upon completion.\n            --index NAME            Name of the index file (default index.md) to generate.\n            --ignore FILE,NAMES     Comma separated modules to ignore/skip.\n            -h --help               Show this screen.\n            --version               Show version.\n    '''\n    args = docopt(options)\n    build(\n        getcwd(), args['SOURCE'], args['OUTPUT_DIR'],\n        json_dump=args['--json'], ignore_modules=args['--ignore'], index_filename=args['--index'] or 'index'\n    )", "response": "Main function in case you place a build. py for pydocs inside the root directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the statistics view from IXN and saves it in statistics dictionary.", "response": "def read_stats(self):\n        \"\"\" Reads the statistics view from IXN and saves it in statistics dictionary. \"\"\"\n\n        captions, rows = self._get_pages()\n        name_caption_index = captions.index(self.name_caption)\n        captions.pop(name_caption_index)\n        self.captions = captions\n        self.statistics = OrderedDict()\n        for row in rows:\n            name = row.pop(name_caption_index)\n            self.statistics[name] = row"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all_stats(self):\n\n        all_stats = OrderedDict()\n        for obj_name in self.statistics:\n            all_stats[obj_name] = dict(zip(self.captions, self.statistics[obj_name]))\n        return all_stats", "response": "returns all statistics values for all objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all captions and statistics values for the object", "response": "def get_object_stats(self, obj_name):\n        \"\"\"\n        :param obj_name: requested object name\n        :returns: all statistics values for the requested object.\n        \"\"\"\n\n        return dict(zip(self.captions, self.statistics[obj_name]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_stats(self, stat_name):\n\n        return [self.get_stat(r, stat_name) for r in self.statistics.keys()]", "response": "returns a list of all values of the requested statistic"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_stat(self, obj_name, stat_name):\n\n        return self.statistics[obj_name][self.captions.index(stat_name)]", "response": "Get the value of the requested stat for the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_cmake_exists(cmake_command):\n    from subprocess import Popen, PIPE\n\n    p = Popen(\n        '{0} --version'.format(cmake_command),\n        shell=True,\n        stdin=PIPE,\n        stdout=PIPE)\n    if not ('cmake version' in p.communicate()[0].decode('UTF-8')):\n        sys.stderr.write('   This code is built using CMake\\n\\n')\n        sys.stderr.write('   CMake is not found\\n')\n        sys.stderr.write('   get CMake at http://www.cmake.org/\\n')\n        sys.stderr.write('   on many clusters CMake is installed\\n')\n        sys.stderr.write('   but you have to load it first:\\n')\n        sys.stderr.write('   $ module load cmake\\n')\n        sys.exit(1)", "response": "Check whether CMake is installed and if not print informative error message and quits."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate build directory if it does not exist.", "response": "def setup_build_path(build_path):\n    \"\"\"\n    Create build directory. If this already exists, print informative\n    error message and quit.\n    \"\"\"\n    if os.path.isdir(build_path):\n        fname = os.path.join(build_path, 'CMakeCache.txt')\n        if os.path.exists(fname):\n            sys.stderr.write('aborting setup\\n')\n            sys.stderr.write(\n                'build directory {0} which contains CMakeCache.txt already exists\\n'.\n                format(build_path))\n            sys.stderr.write(\n                'remove the build directory and then rerun setup\\n')\n            sys.exit(1)\n    else:\n        os.makedirs(build_path, 0o755)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_cmake(command, build_path, default_build_path):\n    from subprocess import Popen, PIPE\n    from shutil import rmtree\n\n    topdir = os.getcwd()\n    p = Popen(command, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n    stdout_coded, stderr_coded = p.communicate()\n    stdout = stdout_coded.decode('UTF-8')\n    stderr = stderr_coded.decode('UTF-8')\n\n    # print cmake output to screen\n    print(stdout)\n\n    if stderr:\n        # we write out stderr but we do not stop yet\n        # this is because CMake warnings are sent to stderr\n        # and they might be benign\n        sys.stderr.write(stderr)\n\n    # write cmake output to file\n    with open(os.path.join(build_path, 'cmake_output'), 'w') as f:\n        f.write(stdout)\n\n    # change directory and return\n    os.chdir(topdir)\n\n    # to figure out whether configuration was a success\n    # we check for 3 sentences that should be part of stdout\n    configuring_done = '-- Configuring done' in stdout\n    generating_done = '-- Generating done' in stdout\n    build_files_written = '-- Build files have been written to' in stdout\n    configuration_successful = configuring_done and generating_done and build_files_written\n\n    if configuration_successful:\n        save_setup_command(sys.argv, build_path)\n        print_build_help(build_path, default_build_path)\n    else:\n        if (build_path == default_build_path):\n            # remove build_path iff not set by the user\n            # otherwise removal can be dangerous\n            rmtree(default_build_path)", "response": "Execute CMake command and return a new version of the CMake object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_build_help(build_path, default_build_path):\n    print('   configure step is done')\n    print('   now you need to compile the sources:')\n    if (build_path == default_build_path):\n        print('   $ cd build')\n    else:\n        print('   $ cd ' + build_path)\n    print('   $ make')", "response": "Print help text after configuration step is done."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_setup_command(argv, build_path):\n    file_name = os.path.join(build_path, 'setup_command')\n    with open(file_name, 'w') as f:\n        f.write(' '.join(argv[:]) + '\\n')", "response": "Save setup command to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a SHA token for the current object", "response": "def generate_hash(self):\n        \"\"\"\n        Create a unique SHA token/hash using the project SECRET_KEY, URL,\n        email address and current datetime.\n        \"\"\"\n        from django.utils.hashcompat import sha_constructor\n        hash = sha_constructor(settings.SECRET_KEY + self.url + self.email + unicode(datetime.now()) ).hexdigest()\n        return hash[::2]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_single_poll_session(self, poll_id, poll_sessions_course_id, poll_sessions_course_section_id=None, poll_sessions_has_public_results=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - poll_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_id\"] = poll_id\r\n\r\n        # REQUIRED - poll_sessions[course_id]\r\n        \"\"\"The id of the course this session is associated with.\"\"\"\r\n        data[\"poll_sessions[course_id]\"] = poll_sessions_course_id\r\n\r\n        # OPTIONAL - poll_sessions[course_section_id]\r\n        \"\"\"The id of the course section this session is associated with.\"\"\"\r\n        if poll_sessions_course_section_id is not None:\r\n            data[\"poll_sessions[course_section_id]\"] = poll_sessions_course_section_id\r\n\r\n        # OPTIONAL - poll_sessions[has_public_results]\r\n        \"\"\"Whether or not results are viewable by students.\"\"\"\r\n        if poll_sessions_has_public_results is not None:\r\n            data[\"poll_sessions[has_public_results]\"] = poll_sessions_has_public_results\r\n\r\n        self.logger.debug(\"POST /api/v1/polls/{poll_id}/poll_sessions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/polls/{poll_id}/poll_sessions\".format(**path), data=data, params=params, no_data=True)", "response": "Create a single poll session. Creates a new poll session for this poll."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninvokes the command in - process with the supplied params.", "response": "def _invoke(self, *params):\n\t\t\"\"\"\n\t\tRun the self.exe command in-process with the supplied params.\n\t\t\"\"\"\n\t\tcmd = [self.exe, '-R', self.location] + list(params)\n\t\twith reentry.in_process_context(cmd) as result:\n\t\t\tsys.modules['mercurial.dispatch'].run()\n\t\tstdout = result.stdio.stdout.getvalue()\n\t\tstderr = result.stdio.stderr.getvalue()\n\t\tif not result.returncode == 0:\n\t\t\traise RuntimeError(stderr.strip() or stdout.strip())\n\t\treturn stdout.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef removeFromRegistery(obj) :\n\t\n\tif isRabaObject(obj) :\n\t\t_unregisterRabaObjectInstance(obj)\n\telif isRabaList(obj) :\n\t\t_unregisterRabaListInstance(obj)", "response": "Removes an object from the registery."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dict describing the object", "response": "def getDctDescription(self) :\n\t\t\"returns a dict describing the object\"\n\t\treturn  {'type' : RabaFields.RABA_FIELD_TYPE_IS_RABA_OBJECT, 'className' : self._rabaClass.__name__, 'raba_id' : self.raba_id, 'raba_namespace' : self._raba_namespace}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ensureIndex(cls, fields, where = '', whereValues = []) :\n\t\tcon = RabaConnection(cls._raba_namespace)\n\t\trlf, ff = cls._parseIndex(fields)\n\t\tww = []\n\t\tfor i in range(len(whereValues)) :\n\t\t\tif isRabaObject(whereValues[i]) :\n\t\t\t\tww.append(whereValues[i].getJsonEncoding())\n\n\t\tfor name in rlf :\n\t\t\tcon.createIndex(name, 'anchor_raba_id')\n\t\t\n\t\tif len(ff) > 0 :\n\t\t\tcon.createIndex(cls.__name__, ff, where = where, whereValues = ww)\n\t\tcon.commit()", "response": "Add an index for a field."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove an index created with ensureIndex", "response": "def dropIndex(cls, fields) :\n\t\t\"removes an index created with ensureIndex \"\n\t\tcon = RabaConnection(cls._raba_namespace)\n\t\trlf, ff = cls._parseIndex(fields)\n\t\t\n\t\tfor name in rlf :\n\t\t\tcon.dropIndex(name, 'anchor_raba_id')\n\t\t\n\t\tcon.dropIndex(cls.__name__, ff)\n\t\tcon.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getIndexes(cls) :\n\t\t\"returns a list of the indexes of a class\"\n\t\tcon = RabaConnection(cls._raba_namespace)\n\t\tidxs = []\n\t\tfor idx in con.getIndexes(rabaOnly = True) :\n\t\t\tif idx[2] == cls.__name__ :\n\t\t\t\tidxs.append(idx)\n\t\t\telse :\n\t\t\t\tfor k in cls.columns :\n\t\t\t\t\tif RabaFields.isRabaListField(getattr(cls, k)) and idx[2] == con.makeRabaListTableName(cls.__name__, k) :\n\t\t\t\t\t\tidxs.append(idx)\n\t\treturn idxs", "response": "returns a list of the indexes of a class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flushIndexes(cls) :\n\t\t\"drops all indexes for a class\"\n\t\tcon = RabaConnection(cls._raba_namespace)\n\t\tfor idx in cls.getIndexes() :\n\t\t\tcon.dropIndexByName(idx[1])", "response": "drops all indexes for a class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting multiple values quickly ex : name = woopy", "response": "def set(self, **args) :\n\t\t\"set multiple values quickly, ex : name = woopy\"\n\t\tfor k, v in args.items() :\n\t\t\tsetattr(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getFields(cls) :\n\t\ts = set(cls.columns.keys())\n\t\ts.remove('json')\n\t\ts.remove('raba_id')\n\t\treturn s", "response": "returns a set of the available fields"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pupatizeElements(self) :\n\t\tfor i in range(len(self)) :\n\t\t\tself[i] = self[i].pupa()", "response": "Transform all raba objects into pupas"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the RabaList into it s own table. This private function that should be called directly by the object s save method. This private function that should be called directly by the object s save method.", "response": "def _save(self) :\n\t\t\"\"\"saves the RabaList into it's own table. This a private function that should be called directly\n\t\tBefore saving the entire list corresponding to the anchorObj is wiped out before being rewritten. The\n\t\talternative would be to keep the sync between the list and the table in real time (remove in both).\n\t\tIf the current solution proves to be to slow, i'll consider the alternative\"\"\"\n\n\t\tif self.connection.registerSave(self) :\n\t\t\tif len(self) == 0 :\n\t\t\t\tself.connection.updateRabaListLength(self.raba_id, len(self))\n\t\t\t\treturn True\n\t\t\telse :\n\t\t\t\tif self.relationName == None or self.anchorObj == None :\n\t\t\t\t\traise ValueError('%s has not been attached to any object, impossible to save it' % s)\n\n\t\t\t\t#if self.raba_id == None :\n\t\t\t\t#\tself.raba_id, self.tableName = self.connection.registerRabalist(self.anchorObj._rabaClass.__name__, self.anchorObj.raba_id, self.relationName)\n\n\t\t\t\tif self._saved :\n\t\t\t\t\tself.empty()\n\n\t\t\t\tvalues = []\n\t\t\t\tfor e in self.data :\n\t\t\t\t\tif isRabaObject(e) :\n\t\t\t\t\t\te.save()\n\t\t\t\t\t\tobjDct = e.getDctDescription()\n\t\t\t\t\t\tvalues.append((self.anchorObj.raba_id, None, RabaFields.RABA_FIELD_TYPE_IS_RABA_OBJECT, e._rabaClass.__name__, e.raba_id, e._raba_namespace))\n\t\t\t\t\telif isPythonPrimitive(e) :\n\t\t\t\t\t\tvalues.append((self.anchorObj.raba_id, e, RabaFields.RABA_FIELD_TYPE_IS_PRIMITIVE, None, None, None))\n\t\t\t\t\telse :\n\t\t\t\t\t\tvalues.append((self.anchorObj.raba_id, buffer(cPickle.dumps(e)), RabaFields.RABA_FIELD_TYPE_IS_PRIMITIVE, None, None, None))\n\n\t\t\t\tself.connection.executeMany('INSERT INTO %s (anchor_raba_id, value, type, obj_raba_class_name, obj_raba_id, obj_raba_namespace) VALUES (?, ?, ?, ?, ?, ?)' % self.tableName, values)\n\n\t\t\t\t#self.connection.updateRabaListLength(self.raba_id, len(self))\n\t\t\t\tself._saved = True\n\t\t\t\tself._mutated = False\n\t\t\t\treturn True\n\t\telse :\n\t\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nattach the rabalist to a raba object. Only attached rabalists can be saved", "response": "def _attachToObject(self, anchorObj, relationName) :\n\t\t\"Attaches the rabalist to a raba object. Only attached rabalists can  be saved\"\n\t\tif self.anchorObj == None :\n\t\t\tself.relationName = relationName\n\t\t\tself.anchorObj = anchorObj\n\t\t\tself._setNamespaceConAndConf(anchorObj._rabaClass._raba_namespace)\n\t\t\tself.tableName = self.connection.makeRabaListTableName(self.anchorObj._rabaClass.__name__, self.relationName)\n\t\t\tfaultyElmt = self._checkSelf()\n\t\t\tif faultyElmt != None :\n\t\t\t\traise ValueError(\"Element %s violates specified list or relation constraints\" % faultyElmt)\n\t\telif self.anchorObj is not anchorObj :\n\t\t\traise ValueError(\"Ouch: attempt to steal rabalist, use RabaLict.copy() instead.\\nthief: %s\\nvictim: %s\\nlist: %s\" % (anchorObj, self.anchorObj, self))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_files_courses(self, course_id, content_types=None, include=None, only=None, order=None, search_term=None, sort=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - content_types\r\n        \"\"\"Filter results by content-type. You can specify type/subtype pairs (e.g.,\r\n        'image/jpeg'), or simply types (e.g., 'image', which will match\r\n        'image/gif', 'image/jpeg', etc.).\"\"\"\r\n        if content_types is not None:\r\n            params[\"content_types\"] = content_types\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name of the files to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Array of additional information to include.\r\n        \r\n        \"user\":: the user who uploaded the file or last edited its content\r\n        \"usage_rights\":: copyright and license information for the file (see UsageRights)\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"user\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - only\r\n        \"\"\"Array of information to restrict to. Overrides include[]\r\n        \r\n        \"names\":: only returns file name information\"\"\"\r\n        if only is not None:\r\n            params[\"only\"] = only\r\n\r\n        # OPTIONAL - sort\r\n        \"\"\"Sort results by this field. Defaults to 'name'. Note that `sort=user` implies `include[]=user`.\"\"\"\r\n        if sort is not None:\r\n            self._validate_enum(sort, [\"name\", \"size\", \"created_at\", \"updated_at\", \"content_type\", \"user\"])\r\n            params[\"sort\"] = sort\r\n\r\n        # OPTIONAL - order\r\n        \"\"\"The sorting order. Defaults to 'asc'.\"\"\"\r\n        if order is not None:\r\n            self._validate_enum(order, [\"asc\", \"desc\"])\r\n            params[\"order\"] = order\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/files with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/files\".format(**path), data=data, params=params, all_pages=True)", "response": "Returns a list of files in a course."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting public inline preview url. Returns the URL that should be used for inline preview of the file.", "response": "def get_public_inline_preview_url(self, id, submission_id=None):\r\n        \"\"\"\r\n        Get public inline preview url.\r\n\r\n        Determine the URL that should be used for inline preview of the file.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - submission_id\r\n        \"\"\"The id of the submission the file is associated with.  Provide this argument to gain access to a file\r\n        that has been submitted to an assignment (Canvas will verify that the file belongs to the submission\r\n        and the calling user has rights to view the submission).\"\"\"\r\n        if submission_id is not None:\r\n            params[\"submission_id\"] = submission_id\r\n\r\n        self.logger.debug(\"GET /api/v1/files/{id}/public_url with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/files/{id}/public_url\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a file. Returns the standard attachment json object for the file.", "response": "def get_file_courses(self, id, course_id, include=None):\r\n        \"\"\"\r\n        Get file.\r\n\r\n        Returns the standard attachment json object\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Array of additional information to include.\r\n        \r\n        \"user\":: the user who uploaded the file or last edited its content\r\n        \"usage_rights\":: copyright and license information for the file (see UsageRights)\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"user\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/files/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/files/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the properties of a file in a folder containing a new display name.", "response": "def update_file(self, id, hidden=None, lock_at=None, locked=None, name=None, on_duplicate=None, parent_folder_id=None, unlock_at=None):\r\n        \"\"\"\r\n        Update file.\r\n\r\n        Update some settings on the specified file\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"The new display name of the file\"\"\"\r\n        if name is not None:\r\n            data[\"name\"] = name\r\n\r\n        # OPTIONAL - parent_folder_id\r\n        \"\"\"The id of the folder to move this file into.\r\n        The new folder must be in the same context as the original parent folder.\r\n        If the file is in a context without folders this does not apply.\"\"\"\r\n        if parent_folder_id is not None:\r\n            data[\"parent_folder_id\"] = parent_folder_id\r\n\r\n        # OPTIONAL - on_duplicate\r\n        \"\"\"If the file is moved to a folder containing a file with the same name,\r\n        or renamed to a name matching an existing file, the API call will fail\r\n        unless this parameter is supplied.\r\n        \r\n        \"overwrite\":: Replace the existing file with the same name\r\n        \"rename\":: Add a qualifier to make the new filename unique\"\"\"\r\n        if on_duplicate is not None:\r\n            self._validate_enum(on_duplicate, [\"overwrite\", \"rename\"])\r\n            data[\"on_duplicate\"] = on_duplicate\r\n\r\n        # OPTIONAL - lock_at\r\n        \"\"\"The datetime to lock the file at\"\"\"\r\n        if lock_at is not None:\r\n            data[\"lock_at\"] = lock_at\r\n\r\n        # OPTIONAL - unlock_at\r\n        \"\"\"The datetime to unlock the file at\"\"\"\r\n        if unlock_at is not None:\r\n            data[\"unlock_at\"] = unlock_at\r\n\r\n        # OPTIONAL - locked\r\n        \"\"\"Flag the file as locked\"\"\"\r\n        if locked is not None:\r\n            data[\"locked\"] = locked\r\n\r\n        # OPTIONAL - hidden\r\n        \"\"\"Flag the file as hidden\"\"\"\r\n        if hidden is not None:\r\n            data[\"hidden\"] = hidden\r\n\r\n        self.logger.debug(\"PUT /api/v1/files/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/files/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a file. Delete the specified file.", "response": "def delete_file(self, id):\r\n        \"\"\"\r\n        Delete file.\r\n\r\n        Remove the specified file\r\n        \r\n          curl -XDELETE 'https://<canvas>/api/v1/files/<file_id>' \\\r\n               -H 'Authorization: Bearer <token>'\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/files/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/files/{id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets folder details. Returns the details for a folder", "response": "def get_folder_groups(self, id, group_id):\r\n        \"\"\"\r\n        Get folder.\r\n\r\n        Returns the details for a folder\r\n        \r\n        You can get the root folder from a context by using 'root' as the :id.\r\n        For example, you could get the root folder for a course like:\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/folders/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/folders/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_folder(self, id, hidden=None, lock_at=None, locked=None, name=None, parent_folder_id=None, position=None, unlock_at=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"The new name of the folder\"\"\"\r\n        if name is not None:\r\n            data[\"name\"] = name\r\n\r\n        # OPTIONAL - parent_folder_id\r\n        \"\"\"The id of the folder to move this folder into. The new folder must be in the same context as the original parent folder.\"\"\"\r\n        if parent_folder_id is not None:\r\n            data[\"parent_folder_id\"] = parent_folder_id\r\n\r\n        # OPTIONAL - lock_at\r\n        \"\"\"The datetime to lock the folder at\"\"\"\r\n        if lock_at is not None:\r\n            data[\"lock_at\"] = lock_at\r\n\r\n        # OPTIONAL - unlock_at\r\n        \"\"\"The datetime to unlock the folder at\"\"\"\r\n        if unlock_at is not None:\r\n            data[\"unlock_at\"] = unlock_at\r\n\r\n        # OPTIONAL - locked\r\n        \"\"\"Flag the folder as locked\"\"\"\r\n        if locked is not None:\r\n            data[\"locked\"] = locked\r\n\r\n        # OPTIONAL - hidden\r\n        \"\"\"Flag the folder as hidden\"\"\"\r\n        if hidden is not None:\r\n            data[\"hidden\"] = hidden\r\n\r\n        # OPTIONAL - position\r\n        \"\"\"Set an explicit sort position for the folder\"\"\"\r\n        if position is not None:\r\n            data[\"position\"] = position\r\n\r\n        self.logger.debug(\"PUT /api/v1/folders/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/folders/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Updates a folder. Updates the properties of a folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_folder_courses(self, name, course_id, hidden=None, lock_at=None, locked=None, parent_folder_id=None, parent_folder_path=None, position=None, unlock_at=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - name\r\n        \"\"\"The name of the folder\"\"\"\r\n        data[\"name\"] = name\r\n\r\n        # OPTIONAL - parent_folder_id\r\n        \"\"\"The id of the folder to store the file in. If this and parent_folder_path are sent an error will be returned. If neither is given, a default folder will be used.\"\"\"\r\n        if parent_folder_id is not None:\r\n            data[\"parent_folder_id\"] = parent_folder_id\r\n\r\n        # OPTIONAL - parent_folder_path\r\n        \"\"\"The path of the folder to store the new folder in. The path separator is the forward slash `/`, never a back slash. The parent folder will be created if it does not already exist. This parameter only applies to new folders in a context that has folders, such as a user, a course, or a group. If this and parent_folder_id are sent an error will be returned. If neither is given, a default folder will be used.\"\"\"\r\n        if parent_folder_path is not None:\r\n            data[\"parent_folder_path\"] = parent_folder_path\r\n\r\n        # OPTIONAL - lock_at\r\n        \"\"\"The datetime to lock the folder at\"\"\"\r\n        if lock_at is not None:\r\n            data[\"lock_at\"] = lock_at\r\n\r\n        # OPTIONAL - unlock_at\r\n        \"\"\"The datetime to unlock the folder at\"\"\"\r\n        if unlock_at is not None:\r\n            data[\"unlock_at\"] = unlock_at\r\n\r\n        # OPTIONAL - locked\r\n        \"\"\"Flag the folder as locked\"\"\"\r\n        if locked is not None:\r\n            data[\"locked\"] = locked\r\n\r\n        # OPTIONAL - hidden\r\n        \"\"\"Flag the folder as hidden\"\"\"\r\n        if hidden is not None:\r\n            data[\"hidden\"] = hidden\r\n\r\n        # OPTIONAL - position\r\n        \"\"\"Set an explicit sort position for the folder\"\"\"\r\n        if position is not None:\r\n            data[\"position\"] = position\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/folders with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/folders\".format(**path), data=data, params=params, single_item=True)", "response": "Creates a new folder in the specified context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a folder. Delete a folder.", "response": "def delete_folder(self, id, force=None):\r\n        \"\"\"\r\n        Delete folder.\r\n\r\n        Remove the specified folder. You can only delete empty folders unless you\r\n        set the 'force' flag\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - force\r\n        \"\"\"Set to 'true' to allow deleting a non-empty folder\"\"\"\r\n        if force is not None:\r\n            params[\"force\"] = force\r\n\r\n        self.logger.debug(\"DELETE /api/v1/folders/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/folders/{id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy a file from another folder into another folder. Returns the new folder ID.", "response": "def copy_file(self, dest_folder_id, source_file_id, on_duplicate=None):\r\n        \"\"\"\r\n        Copy a file.\r\n\r\n        Copy a file from elsewhere in Canvas into a folder.\r\n        \r\n        Copying a file across contexts (between courses and users) is permitted,\r\n        but the source and destination must belong to the same institution.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - dest_folder_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"dest_folder_id\"] = dest_folder_id\r\n\r\n        # REQUIRED - source_file_id\r\n        \"\"\"The id of the source file\"\"\"\r\n        data[\"source_file_id\"] = source_file_id\r\n\r\n        # OPTIONAL - on_duplicate\r\n        \"\"\"What to do if a file with the same name already exists at the destination.\r\n        If such a file exists and this parameter is not given, the call will fail.\r\n        \r\n        \"overwrite\":: Replace an existing file with the same name\r\n        \"rename\":: Add a qualifier to make the new filename unique\"\"\"\r\n        if on_duplicate is not None:\r\n            self._validate_enum(on_duplicate, [\"overwrite\", \"rename\"])\r\n            data[\"on_duplicate\"] = on_duplicate\r\n\r\n        self.logger.debug(\"POST /api/v1/folders/{dest_folder_id}/copy_file with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/folders/{dest_folder_id}/copy_file\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_folder(self, dest_folder_id, source_folder_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - dest_folder_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"dest_folder_id\"] = dest_folder_id\r\n\r\n        # REQUIRED - source_folder_id\r\n        \"\"\"The id of the source folder\"\"\"\r\n        data[\"source_folder_id\"] = source_folder_id\r\n\r\n        self.logger.debug(\"POST /api/v1/folders/{dest_folder_id}/copy_folder with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/folders/{dest_folder_id}/copy_folder\".format(**path), data=data, params=params, single_item=True)", "response": "Copies a folder and its contents into another folder. Returns the new folder with the new name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the usage rights for one or more files.", "response": "def set_usage_rights_courses(self, file_ids, course_id, usage_rights_use_justification, folder_ids=None, publish=None, usage_rights_legal_copyright=None, usage_rights_license=None):\r\n        \"\"\"\r\n        Set usage rights.\r\n\r\n        Sets copyright and license information for one or more files\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - file_ids\r\n        \"\"\"List of ids of files to set usage rights for.\"\"\"\r\n        data[\"file_ids\"] = file_ids\r\n\r\n        # OPTIONAL - folder_ids\r\n        \"\"\"List of ids of folders to search for files to set usage rights for.\r\n        Note that new files uploaded to these folders do not automatically inherit these rights.\"\"\"\r\n        if folder_ids is not None:\r\n            data[\"folder_ids\"] = folder_ids\r\n\r\n        # OPTIONAL - publish\r\n        \"\"\"Whether the file(s) or folder(s) should be published on save, provided that usage rights have been specified (set to `true` to publish on save).\"\"\"\r\n        if publish is not None:\r\n            data[\"publish\"] = publish\r\n\r\n        # REQUIRED - usage_rights[use_justification]\r\n        \"\"\"The intellectual property justification for using the files in Canvas\"\"\"\r\n        self._validate_enum(usage_rights_use_justification, [\"own_copyright\", \"used_by_permission\", \"fair_use\", \"public_domain\", \"creative_commons\"])\r\n        data[\"usage_rights[use_justification]\"] = usage_rights_use_justification\r\n\r\n        # OPTIONAL - usage_rights[legal_copyright]\r\n        \"\"\"The legal copyright line for the files\"\"\"\r\n        if usage_rights_legal_copyright is not None:\r\n            data[\"usage_rights[legal_copyright]\"] = usage_rights_legal_copyright\r\n\r\n        # OPTIONAL - usage_rights[license]\r\n        \"\"\"The license that applies to the files. See the {api:UsageRightsController#licenses List licenses endpoint} for the supported license types.\"\"\"\r\n        if usage_rights_license is not None:\r\n            data[\"usage_rights[license]\"] = usage_rights_license\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/usage_rights with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/usage_rights\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_usage_rights_courses(self, file_ids, course_id, folder_ids=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - file_ids\r\n        \"\"\"List of ids of files to remove associated usage rights from.\"\"\"\r\n        params[\"file_ids\"] = file_ids\r\n\r\n        # OPTIONAL - folder_ids\r\n        \"\"\"List of ids of folders. Usage rights will be removed from all files in these folders.\"\"\"\r\n        if folder_ids is not None:\r\n            params[\"folder_ids\"] = folder_ids\r\n\r\n        self.logger.debug(\"DELETE /api/v1/courses/{course_id}/usage_rights with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/courses/{course_id}/usage_rights\".format(**path), data=data, params=params, no_data=True)", "response": "Remove usage rights. Removes copyright and license information associated with one or more files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves usage rights. Removes copyright and license information associated with one or more files.", "response": "def remove_usage_rights_groups(self, group_id, file_ids, folder_ids=None):\r\n        \"\"\"\r\n        Remove usage rights.\r\n\r\n        Removes copyright and license information associated with one or more files\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - file_ids\r\n        \"\"\"List of ids of files to remove associated usage rights from.\"\"\"\r\n        params[\"file_ids\"] = file_ids\r\n\r\n        # OPTIONAL - folder_ids\r\n        \"\"\"List of ids of folders. Usage rights will be removed from all files in these folders.\"\"\"\r\n        if folder_ids is not None:\r\n            params[\"folder_ids\"] = folder_ids\r\n\r\n        self.logger.debug(\"DELETE /api/v1/groups/{group_id}/usage_rights with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/groups/{group_id}/usage_rights\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_usage_rights_users(self, user_id, file_ids, folder_ids=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - file_ids\r\n        \"\"\"List of ids of files to remove associated usage rights from.\"\"\"\r\n        params[\"file_ids\"] = file_ids\r\n\r\n        # OPTIONAL - folder_ids\r\n        \"\"\"List of ids of folders. Usage rights will be removed from all files in these folders.\"\"\"\r\n        if folder_ids is not None:\r\n            params[\"folder_ids\"] = folder_ids\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/{user_id}/usage_rights with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/{user_id}/usage_rights\".format(**path), data=data, params=params, no_data=True)", "response": "Remove usage rights. Removes copyright and license information associated with one or more files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_class(name):\n\n    module, _, klass = name.rpartition('.')\n    mod = import_module(module)\n    return getattr(mod, klass)", "response": "Load class from fully - qualified python module name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the valid RepoManagers for this location.", "response": "def get_valid_managers(cls, location):\n\t\t\"\"\"\n\t\tGet the valid RepoManagers for this location.\n\t\t\"\"\"\n\t\tdef by_priority_attr(c):\n\t\t\treturn getattr(c, 'priority', 0)\n\t\tclasses = sorted(\n\t\t\titer_subclasses(cls), key=by_priority_attr,\n\t\t\treverse=True)\n\t\tall_managers = (c(location) for c in classes)\n\t\treturn (mgr for mgr in all_managers if mgr.is_valid())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the tags for the parent revision.", "response": "def get_parent_tags(self, rev=None):\n\t\t\"\"\"\n\t\tReturn the tags for the parent revision (or None if no single\n\t\t\tparent can be identified).\n\t\t\"\"\"\n\t\ttry:\n\t\t\tparent_rev = one(self.get_parent_revs(rev))\n\t\texcept Exception:\n\t\t\treturn None\n\t\treturn self.get_tags(parent_rev)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_all_files(self):\n\t\tfiles = self.find_files()\n\t\tsubrepo_files = (\n\t\t\tposixpath.join(subrepo.location, filename)\n\t\t\tfor subrepo in self.subrepos()\n\t\t\tfor filename in subrepo.find_files()\n\t\t)\n\t\treturn itertools.chain(files, subrepo_files)", "response": "Find all files including those in subrepositories."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the output of a command.", "response": "def get_cmd_out(command):\n\t'''Get the output of a command.\n\n\tGets a nice Unicode no-extra-whitespace string of the ``stdout`` of a given command.\n\n\tArgs:\n\t\t\tcommand (str or list): A string of the command, or a list of the arguments (as would be used in :class:`subprocess.Popen`).\n\n\tNote:\n\t\t\tIf ``command`` is a ``str``, it will be evaluated with ``shell=True`` i.e. in the default shell (for example, bash).\n\n\tReturns:\n\t\t\tstr: The ``stdout`` of the command.'''\n\n\tif isinstance(command, list):\n\t\tresult = sp.check_output(command)\n\telse:\n\t\tresult = sp.check_output(command, shell=True)\n\n\treturn result.decode('utf-8').rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_name():\n\t'''Get desktop environment or OS.\n\n\tGet the OS name or desktop environment.\n\n\t**List of Possible Values**\n\n\t+-------------------------+---------------+\n\t| Windows\t\t\t\t | windows\t   |\n\t+-------------------------+---------------+\n\t| Mac OS X\t\t\t\t| mac\t\t   |\n\t+-------------------------+---------------+\n\t| GNOME 3+\t\t\t\t| gnome\t\t |\n\t+-------------------------+---------------+\n\t| GNOME 2\t\t\t\t | gnome2\t\t|\n\t+-------------------------+---------------+\n\t| XFCE\t\t\t\t\t| xfce4\t\t |\n\t+-------------------------+---------------+\n\t| KDE\t\t\t\t\t | kde\t\t   |\n\t+-------------------------+---------------+\n\t| Unity\t\t\t\t   | unity\t\t |\n\t+-------------------------+---------------+\n\t| LXDE\t\t\t\t\t| lxde\t\t  |\n\t+-------------------------+---------------+\n\t| i3wm\t\t\t\t\t| i3\t\t\t|\n\t+-------------------------+---------------+\n\t| \\*box\t\t\t\t   | \\*box\t\t |\n\t+-------------------------+---------------+\n\t| Trinity (KDE 3 fork)\t| trinity\t   |\n\t+-------------------------+---------------+\n\t| MATE\t\t\t\t\t| mate\t\t  |\n\t+-------------------------+---------------+\n\t| IceWM\t\t\t\t   | icewm\t\t |\n\t+-------------------------+---------------+\n\t| Pantheon (elementaryOS) | pantheon\t  |\n\t+-------------------------+---------------+\n\t| LXQt\t\t\t\t\t| lxqt\t\t  |\n\t+-------------------------+---------------+\n\t| Awesome WM\t\t\t  | awesome\t   |\n\t+-------------------------+---------------+\n\t| Enlightenment\t\t   | enlightenment |\n\t+-------------------------+---------------+\n\t| AfterStep\t\t\t   | afterstep\t |\n\t+-------------------------+---------------+\n\t| WindowMaker\t\t\t | windowmaker   |\n\t+-------------------------+---------------+\n\t| [Other]\t\t\t\t | unknown\t   |\n\t+-------------------------+---------------+\n\n\tReturns:\n\t\t\tstr: The name of the desktop environment or OS.\n\t'''\n\n\tif sys.platform in ['win32', 'cygwin']:\n\t\treturn 'windows'\n\n\telif sys.platform == 'darwin':\n\t\treturn 'mac'\n\n\telse:\n\t\tdesktop_session = os.environ.get(\n\t\t\t'XDG_CURRENT_DESKTOP') or os.environ.get('DESKTOP_SESSION')\n\n\t\tif desktop_session is not None:\n\t\t\tdesktop_session = desktop_session.lower()\n\n\t\t\t# Fix for X-Cinnamon etc\n\t\t\tif desktop_session.startswith('x-'):\n\t\t\t\tdesktop_session = desktop_session.replace('x-', '')\n\n\t\t\tif desktop_session in ['gnome', 'unity', 'cinnamon', 'mate',\n\t\t\t\t\t\t\t\t   'xfce4', 'lxde', 'fluxbox',\n\t\t\t\t\t\t\t\t   'blackbox', 'openbox', 'icewm', 'jwm',\n\t\t\t\t\t\t\t\t   'afterstep', 'trinity', 'kde', 'pantheon',\n\t\t\t\t\t\t\t\t   'i3', 'lxqt', 'awesome', 'enlightenment']:\n\n\t\t\t\treturn desktop_session\n\n\t\t\t#-- Special cases --#\n\n\t\t\t# Canonical sets environment var to Lubuntu rather than\n\t\t\t# LXDE if using LXDE.\n\t\t\t# There is no guarantee that they will not do the same\n\t\t\t# with the other desktop environments.\n\n\t\t\telif 'xfce' in desktop_session:\n\t\t\t\treturn 'xfce4'\n\n\t\t\telif desktop_session.startswith('ubuntu'):\n\t\t\t\treturn 'unity'\n\n\t\t\telif desktop_session.startswith('xubuntu'):\n\t\t\t\treturn 'xfce4'\n\n\t\t\telif desktop_session.startswith('lubuntu'):\n\t\t\t\treturn 'lxde'\n\n\t\t\telif desktop_session.startswith('kubuntu'):\n\t\t\t\treturn 'kde'\n\n\t\t\telif desktop_session.startswith('razor'):\n\t\t\t\treturn 'razor-qt'\n\n\t\t\telif desktop_session.startswith('wmaker'):\n\t\t\t\treturn 'windowmaker'\n\n\t\tif os.environ.get('KDE_FULL_SESSION') == 'true':\n\t\t\treturn 'kde'\n\n\t\telif os.environ.get('GNOME_DESKTOP_SESSION_ID'):\n\t\t\tif not 'deprecated' in os.environ.get('GNOME_DESKTOP_SESSION_ID'):\n\t\t\t\treturn 'gnome2'\n\n\t\telif is_running('xfce-mcs-manage'):\n\t\t\treturn 'xfce4'\n\t\telif is_running('ksmserver'):\n\t\t\treturn 'kde'\n\n\t\treturn 'unknown'", "response": "Get desktop environment or OS name or desktop environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_in_path(program):\n\t'''\n\tCheck if a program is in the system ``PATH``.\n\n\tChecks if a given program is in the user's ``PATH`` or not.\n\n\tArgs:\n\t\t\tprogram (str): The program to try to find in ``PATH``.\n\n\tReturns:\n\t\t\tbool: Is the program in ``PATH``?\n\t'''\n\n\tif sys.version_info.major == 2:\n\t\tpath = os.getenv('PATH')\n\t\tif os.name == 'nt':\n\t\t\tpath = path.split(';')\n\t\telse:\n\t\t\tpath = path.split(':')\n\telse:\n\t\tpath = os.get_exec_path()\n\n\tfor i in path:\n\t\tif os.path.isdir(i):\n\t\t\tif program in os.listdir(i):\n\t\t\t\treturn True", "response": "Check if a given program is in the system s PATH or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if a process is running.", "response": "def is_running(process):\n\t'''\n\tCheck if process is running.\n\n\tCheck if the given process name is running or not.\n\n\tNote:\n\t\t\tOn a Linux system, kernel threads (like\t``kthreadd`` etc.)\n\t\t\tare excluded.\n\n\tArgs:\n\t\t\tprocess (str): The name of the process.\n\n\tReturns:\n\t\t\tbool: Is the process running?\n\t'''\n\n\tif os.name == 'nt':\n\t\tprocess_list = get_cmd_out(['tasklist', '/v'])\n\t\treturn process in process_list\n\n\telse:\n\t\tprocess_list = get_cmd_out('ps axw | awk \\'{print $5}\\'')\n\n\t\tfor i in process_list.split('\\n'):\n\t\t\t# 'COMMAND' is the column heading\n\t\t\t# [*] indicates kernel-level processes like \\\n\t\t\t# kthreadd, which manages threads in the Linux kernel\n\t\t\tif not i == 'COMMAND' or i.startswith('['):\n\t\t\t\tif i == process:\n\t\t\t\t\treturn True\n\n\t\t\t\telif os.path.basename(i) == process:\n\t\t\t\t\t# check i without executable path\n\t\t\t\t\t# for example, if 'process' arguments is 'sshd'\n\t\t\t\t\t# and '/usr/bin/sshd' is listed in ps, return True\n\t\t\t\t\treturn True\n\n\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_datetime(value):\n\n    if isinstance(value, (string_types, text_type, binary_type)):\n        value = dateutil.parser.parse(value)\n        value.replace(tzinfo=dateutil.tz.tzutc())\n        return value\n    elif isinstance(value, datetime.datetime):\n        value.replace(tzinfo=dateutil.tz.tzutc())\n        return value\n    elif isinstance(value, datetime.date):\n        value = datetime.datetime(value.year, value.month, value.day)\n        value.replace(tzinfo=dateutil.tz.tzutc())\n        return value\n    else:\n        raise ValueError('Value must be parsable to datetime object. Got `{}`'.format(type(value)))", "response": "Returns a datetime object for a given argument\n    This helps to convert strings dates and datetimes to proper tz - enabled\n    datetime objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef NegateQueryFilter(es_query):  # noqa\n    query = es_query.to_dict().get(\"query\", {})\n    filtered = query.get(\"filtered\", {})\n    negated_filter = filtered.get(\"filter\", {})\n    return Not(**negated_filter)", "response": "Returns a filter that removes the contents of the provided query."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the serializer by mime type.", "response": "def set_deserializer_by_mime_type(self, mime_type):\n        \"\"\"\n        :param mime_type:\n        :return:\n\n        Used by content_type_set to set get a reference to the serializer object\n        \"\"\"\n\n        for deserializer in self._deserializers:\n            if deserializer.content_type() == mime_type:\n                self._selected_deserializer = deserializer\n                return\n\n        raise exception.UnsupportedContentTypeError(mime_type, self.supported_mime_types_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the _body_template attribute of the internal object.", "response": "def body_template(self, value):\n        \"\"\"\n        Must be an instance of a prestans.types.DataCollection subclass; this is\n        generally set during the RequestHandler lifecycle. Setting this spwans the\n        parsing process of the body. If the HTTP verb is GET an AssertionError is\n        thrown. Use with extreme caution.\n        \"\"\"\n\n        if self.method == VERB.GET:\n            raise AssertionError(\"body_template cannot be set for GET requests\")\n\n        if value is None:\n            self.logger.warning(\"body_template is None, parsing will be ignored\")\n            return\n\n        if not isinstance(value, DataCollection):\n            msg = \"body_template must be an instance of %s.%s\" % (\n                DataCollection.__module__,\n                DataCollection.__name__\n            )\n            raise AssertionError(msg)\n\n        self._body_template = value\n\n        # get a deserializer based on the Content-Type header\n        # do this here so the handler gets a chance to setup extra serializers\n        self.set_deserializer_by_mime_type(self.content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the underlying version", "response": "def version(self):\n\t\t\"\"\"\n\t\tReturn the underlying version\n\t\t\"\"\"\n\t\tlines = iter(self._invoke('version').splitlines())\n\t\tversion = next(lines).strip()\n\t\treturn self._parse_version(version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_files(self):\n\t\tall_files = self._invoke('locate', '-I', '.').splitlines()\n\t\t# now we have a list of all files in self.location relative to\n\t\t#  self.find_root()\n\t\t# Remove the parent dirs from them.\n\t\tfrom_root = os.path.relpath(self.location, self.find_root())\n\t\tloc_rel_paths = [\n\t\t\tos.path.relpath(path, from_root)\n\t\t\tfor path in all_files]\n\t\treturn loc_rel_paths", "response": "Find versioned files in self. location"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the tags for the given revision specifier.", "response": "def get_tags(self, rev=None):\n\t\t\"\"\"\n\t\tGet the tags for the given revision specifier (or the\n\t\tcurrent revision if not specified).\n\t\t\"\"\"\n\t\trev_num = self._get_rev_num(rev)\n\t\t# rev_num might end with '+', indicating local modifications.\n\t\treturn (\n\t\t\tset(self._read_tags_for_rev(rev_num))\n\t\t\tif not rev_num.endswith('+')\n\t\t\telse set([])\n\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_tags_for_revset(self, spec):\n\t\tcmd = [\n\t\t\t'log', '--style', 'default', '--config', 'defaults.log=',\n\t\t\t'-r', spec]\n\t\tres = self._invoke(*cmd)\n\t\theader_pattern = re.compile(r'(?P<header>\\w+?):\\s+(?P<value>.*)')\n\t\tmatch_res = map(header_pattern.match, res.splitlines())\n\t\tmatched_lines = filter(None, match_res)\n\t\tmatches = (match.groupdict() for match in matched_lines)\n\t\tfor match in matches:\n\t\t\tif match['header'] == 'changeset':\n\t\t\t\tid, sep, rev = match['value'].partition(':')\n\t\t\tif match['header'] == 'tag':\n\t\t\t\ttag = match['value']\n\t\t\t\tyield TaggedRevision(tag, rev)", "response": "Return a generator that yields TaggedRevision for each tag and rev combination in the revset spec\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the revision number for a given revision specifier.", "response": "def _get_rev_num(self, rev=None):\n\t\t\"\"\"\n\t\tDetermine the revision number for a given revision specifier.\n\t\t\"\"\"\n\t\t# first, determine the numeric ID\n\t\tcmd = ['identify', '--num']\n\t\t# workaround for #4\n\t\tcmd.extend(['--config', 'defaults.identify='])\n\t\tif rev:\n\t\t\tcmd.extend(['--rev', rev])\n\t\tres = self._invoke(*cmd)\n\t\treturn res.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary mapping revision number to tags for that number.", "response": "def _get_tags_by_num(self):\n\t\t\"\"\"\n\t\tReturn a dictionary mapping revision number to tags for that number.\n\t\t\"\"\"\n\t\tby_revision = operator.attrgetter('revision')\n\t\ttags = sorted(self.get_tags(), key=by_revision)\n\t\trevision_tags = itertools.groupby(tags, key=by_revision)\n\n\t\tdef get_id(rev):\n\t\t\treturn rev.split(':', 1)[0]\n\t\treturn dict(\n\t\t\t(get_id(rev), [tr.tag for tr in tr_list])\n\t\t\tfor rev, tr_list in revision_tags\n\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the tags for the current revision as a set", "response": "def get_tags(self, rev=None):\n\t\t\"\"\"\n\t\tReturn the tags for the current revision as a set\n\t\t\"\"\"\n\t\trev = rev or 'HEAD'\n\t\treturn set(self._invoke('tag', '--points-at', rev).splitlines())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_template_name(self, key, value):\n        if value not in dict(current_app.config['PAGES_TEMPLATES']):\n            raise ValueError(\n                'Template \"{0}\" does not exist.'.format(value))\n        return value", "response": "Validate the template name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclassify the logical network and returns a list of logical behaviors for the list of logical networks in the attribute networks.", "response": "def classify(self, n_jobs=-1, configure=None):\n        \"\"\"\n        Returns input-output behaviors for the list of logical networks in the attribute :attr:`networks`\n\n        Example::\n\n            >>> from caspo import core, classify\n\n            >>> networks = core.LogicalNetworkList.from_csv('networks.csv')\n            >>> setup = core.Setup.from_json('setup.json')\n\n            >>> classifier = classify.Classifier(networks, setup)\n            >>> behaviors = classifier.classify()\n\n            >>> behaviors.to_csv('behaviors.csv', networks=True)\n\n        n_jobs : int\n            Number of jobs to run in parallel. Default to -1 (all cores available)\n\n        configure : callable\n            Callable object responsible of setting clingo configuration\n\n\n        Returns\n        -------\n        caspo.core.logicalnetwork.LogicalNetworkList\n            The list of networks with one representative for each behavior\n        \"\"\"\n        start = timeit.default_timer()\n        networks = self.networks\n\n        n = len(networks)\n        cpu = n_jobs if n_jobs > -1 else mp.cpu_count()\n\n        if cpu > 1:\n            lpart = int(np.ceil(n / float(cpu))) if n > cpu else 1\n            parts = networks.split(np.arange(lpart, n, lpart))\n\n            behaviors_parts = Parallel(n_jobs=n_jobs)(delayed(__learn_io__)(part, self.setup, configure) for part in parts)\n            networks = core.LogicalNetworkList.from_hypergraph(networks.hg)\n            for behavior in behaviors_parts:\n                networks = networks.concat(behavior)\n\n        behaviors = __learn_io__(networks, self.setup, configure)\n        self.stats['time_io'] = timeit.default_timer() - start\n\n        self._logger.info(\"%s input-output logical behaviors found in %.4fs\", len(behaviors), self.stats['time_io'])\n\n        return behaviors"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_observee_with_credentials(self, user_id, access_token=None, observee_password=None, observee_unique_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - observee[unique_id]\r\n        \"\"\"The login id for the user to observe.  Required if access_token is omitted.\"\"\"\r\n        if observee_unique_id is not None:\r\n            data[\"observee[unique_id]\"] = observee_unique_id\r\n\r\n        # OPTIONAL - observee[password]\r\n        \"\"\"The password for the user to observe. Required if access_token is omitted.\"\"\"\r\n        if observee_password is not None:\r\n            data[\"observee[password]\"] = observee_password\r\n\r\n        # OPTIONAL - access_token\r\n        \"\"\"The access token for the user to observe.  Required if <tt>observee[unique_id]</tt> or <tt>observee[password]</tt> are omitted.\"\"\"\r\n        if access_token is not None:\r\n            data[\"access_token\"] = access_token\r\n\r\n        self.logger.debug(\"POST /api/v1/users/{user_id}/observees with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/users/{user_id}/observees\".format(**path), data=data, params=params, single_item=True)", "response": "Adds an observee with credentials. Add an observee with credentials given the user s access token and the user s unique id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_observee(self, user_id, observee_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - observee_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"observee_id\"] = observee_id\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/observees/{observee_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/observees/{observee_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Show an observed user. Shows information about an observed user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_item(name, command, system_wide=False):\n\n\t'''Adds a program to startup.\n\n\tAdds a program to user startup.\n\n\tArgs:\n\t\tname        (str) : The name of the startup entry.\n\t\tcommand     (str) : The command to run.\n\t\tsystem_wide (bool): Add to system-wide startup.\n\n\tNote:\n\t\t``system_wide`` requires superuser/admin privileges.\n\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif os.path.isfile(command):\n\t\tcommand_is_file = True\n\n\t\tif not desktop_env == 'windows':\n\t\t\t# Will not exit program if insufficient permissions\n\t\t\tsp.Popen(['chmod +x %s' % command], shell=True)\n\n\tif desktop_env == 'windows':\n\t\timport winreg\n\t\tif system_wide:\n\t\t\tstartup_dir = os.path.join(winreg.ExpandEnvironmentStrings('%PROGRAMDATA%'), 'Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\n\t\telse:\n\t\t\tstartup_dir = os.path.join(get_config_dir()[0], 'Roaming\\\\Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\n\t\tif not command_is_file:\n\t\t\twith open(os.path.join(startup_dir, name + '.bat'), 'w') as f:\n\t\t\t\tf.write(command)\n\t\telse:\n\t\t\tshutil.copy(command, startup_dir)\n\n\telif desktop_env == 'mac':\n\t\tsp.Popen(['launchctl submit -l %s -- %s'] % (name, command), shell=True)\n\t\t# system-wide will be handled by running the above as root\n\t\t# which will auto-happen if current process is root.\n\n\telse:\n\t\t# Linux/Unix\n\n\t\tif desktop_env == 'unknown':\n\t\t\t# CLI\n\t\t\tif system_wide:\n\t\t\t\tlogin_file = '/etc/profile'\n\t\t\telse:\n\t\t\t\tlogin_file = os.path.expanduser('~/.profile')\n\n\t\t\twith open(login_file, 'a') as f:\n\t\t\t\tf.write(command)\n\n\t\telse:\n\t\t\ttry:\n\t\t\t\tdesktop_file_name = name + '.desktop'\n\n\t\t\t\tstartup_file = os.path.join(get_config_dir('autostart', system_wide=system_wide)[0], desktop_file_name)\n\n\t\t\t\t# .desktop files' Terminal option uses an independent method to find terminal emulator\n\t\t\t\tdesktop_str = desktopfile.construct(name=name, exec_=command, additional_opts={'X-GNOME-Autostart-enabled': 'true'})\n\n\t\t\t\twith open(startup_file, 'w') as f:\n\t\t\t\t\tf.write(desktop_str)\n\t\t\texcept:\n\t\t\t\tpass", "response": "Adds a program to startup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_items(system_wide=False):\n\n\t'''List startup programs.\n\n\tList the programs set to run at startup.\n\n\tArgs:\n\t\tsystem_wide (bool): Gets the programs that run at system-wide startup.\n\n\tReturns:\n\t\tlist: A list of dictionaries in this format:\n\n\t\t\t.. code-block:: python\n\n\t\t\t\t{\n\t\t\t\t  'name': 'The name of the entry.',\n\t\t\t\t  'command': 'The command used to run it.'\n\t\t\t\t}\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tresult = []\n\n\tif desktop_env == 'windows':\n\t\tsys_startup_dir = os.path.join(winreg.ExpandEnvironmentStrings('%PROGRAMDATA%'), 'Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\t\tuser_startup_dir = os.path.join(get_config_dir()[0], 'Roaming\\\\Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\n\t\tstartup_dir = sys_startup_dir if system_wide else user_startup_dir\n\n\t\tfor file in os.listdir(startup_dir):\n\t\t\tfile_path = os.path.join(startup_dir, file)\n\n\t\t\tresult.append({ 'name': file, 'command': os.path.join(startup_dir, file) })\n\n\telif desktop_env == 'mac':\n\t\titems_list = system.get_cmd_out('launchtl list | awk \\'{print $3}\\'')\n\t\tfor item in items_list.split('\\n'):\n\t\t\t# launchd stores each job as a .plist file (pseudo-xml)\n\t\t\tlaunchd_plist_paths = ['~/Library/LaunchAgents',\n\t\t\t\t\t\t\t\t\t'/Library/LaunchAgents',\n\t\t\t\t\t\t\t\t\t'/Library/LaunchDaemons',\n\t\t\t\t\t\t\t\t\t'/System/Library/LaunchAgents',\n\t\t\t\t\t\t\t\t\t'/System/Library/LaunchDaemons']\n\n\t\t\tfor path in launchd_plist_paths:\n\t\t\t\tif item + '.plist' in os.listdir(path):\n\t\t\t\t\tplist_file = os.path.join(path, item + '.plist')\n\n\t\t\t# Parse the plist\n\t\t\tif sys.version_info.major == 2:\n\t\t\t\tplist_parsed = plistlib.readPlist(plist_file)\n\t\t\telse:\n\t\t\t\twith open(plist_file) as f:\n\t\t\t\t\tplist_parsed = plistlib.load(f)\n\n\t\t\tif 'Program' in plist_parsed:\n\t\t\t\tcmd = plist_parsed['Program']\n\n\t\t\t\tif 'ProgramArguments' in plist_parsed:\n\t\t\t\t\tcmd += ' '.join(plist_parsed['ProgramArguments'])\n\n\t\t\telif 'ProgramArguments' in plist_parsed:\n\t\t\t\tcmd = ' '.join(plist_parsed['ProgramArguments'])\n\n\t\t\telse:\n\t\t\t\tcmd = ''\n\n\t\t\tresult.append({ 'name': item, 'command': cmd })\n\n\t\t# system-wide will be handled by running the above as root\n\t\t# which will auto-happen if current process is root.\n\n\telse:\n\t\t# Linux/Unix\n\n\t\t# CLI\n\t\tprofile = os.path.expanduser('~/.profile')\n\n\t\tif os.path.isfile(profile):\n\t\t\twith open(profile) as f:\n\t\t\t\tfor line in f:\n\t\t\t\t\tif system.is_in_path(line.lstrip().split(' ')[0]):\n\t\t\t\t\t\tcmd_name = line.lstrip().split(' ')[0]\n\n\t\t\t\t\t\tresult.append({ 'name': cmd_name, 'command': line.strip() })\n\n\t\t# /etc/profile.d\n\t\tif system_wide:\n\t\t\tif os.path.isdir('/etc/profile.d'):\n\t\t\t\tfor file in os.listdir('/etc/profile.d'):\n\t\t\t\t\tfile_path = os.path.join('/etc/profile.d', file)\n\t\t\t\t\tresult.append({ 'name': file, 'command': 'sh %s' % file_path })\n\n\t\t# GUI\n\n\t\ttry:\n\t\t\tstartup_dir = directories.get_config_dir('autostart', system_wide=system_wide)[0]\n\n\t\t\tfor file in os.listdir(startup_dir):\n\t\t\t\tfile_parsed = desktopfile.parse(os.path.join(startup_dir, file))\n\n\t\t\t\tif 'Name' in file_parsed:\n\t\t\t\t\tname = file_parsed['Name']\n\n\t\t\t\telse:\n\t\t\t\t\tname = file.replace('.desktop', '')\n\n\t\t\t\tif 'Exec' in file_parsed:\n\t\t\t\t\tif file_parsed['Terminal']:\n\t\t\t\t\t\tcmd = applications.terminal(exec_=file_parsed['Exec'],\n\t\t\t\t\t\t\t\t\t\t\t\t\t\treturn_cmd=True)\n\t\t\t\t\telse:\n\t\t\t\t\t\tcmd = file_parsed['Exec']\n\n\t\t\t\telse:\n\t\t\t\t\tcmd = ''\n\n\t\t\t\tif not file_parsed.get('Hidden', False):\n\t\t\t\t\tresult.append({ 'name': name, 'command': cmd })\n\n\t\texcept IndexError:\n\t\t\tpass\n\n\treturn result", "response": "List the items of the current environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_item(name, system_wide=False):\n\n\t'''Removes a program from startup.\n\n\tRemoves a program from startup.\n\n\tArgs:\n\t\tname        (str) : The name of the program (as known to the system) to remove. See :func:``list_items``.\n\t\tsystem_wide (bool): Remove it from system-wide startup.\n\n\tNote:\n\t\t``system_wide`` requires superuser/admin privileges.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif desktop_env == 'windows':\n\t\timport winreg\n\t\tif system_wide:\n\t\t\tstartup_dir = os.path.join(winreg.ExpandEnvironmentStrings('%PROGRAMDATA%'), 'Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\n\t\telse:\n\t\t\tstartup_dir = os.path.join(directories.get_config_dir()[0], 'Roaming\\\\Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Startup')\n\n\t\tfor startup_file in os.path.listdir(start_dir):\n\t\t\tif startup_file == name or startup_file.split('.')[0] == name:\n\t\t\t\tos.remove(os.path.join(startup_dir, startup_file))\n\n\telif desktop_env == 'mac':\n\t\tsp.Popen(['launchctl', 'remove', name])\n\t\t# system-wide will be handled by running the above as root\n\t\t# which will auto-happen if current process is root.\n\n\telse:\n\t\t# Linux/Unix\n\n\t\tif desktop_env == 'unknown':\n\t\t\t# CLI\n\t\t\tif system_wide:\n\t\t\t\tlogin_file = '/etc/profile'\n\t\t\telse:\n\t\t\t\tlogin_file = os.path.expanduser('~/.profile')\n\n\t\t\twith open(login_file) as f:\n\t\t\t\tlogin_file_contents = f.read()\n\n\t\t\tfinal_login_file_contents = ''\n\n\t\t\tfor line in login_file_contents.split('\\n'):\n\t\t\t\tif line.split(' ')[0] != name:\n\t\t\t\t\tfinal_login_file_contents += line\n\n\t\t\twith open(login_file, 'w') as f:\n\t\t\t\tf.write(final_login_file_contents)\n\n\t\telse:\n\t\t\ttry:\n\t\t\t\tdesktop_file_name = name + '.desktop'\n\n\t\t\t\tstartup_file = os.path.join(directories.get_config_dir('autostart', system_wide=system_wide)[0], desktop_file_name)\n\n\t\t\t\tif not os.path.isfile(startup_file):\n\t\t\t\t\tfor possible_startup_file in os.listdir(directories.get_config_dir('autostart', system_wide=system_wide)[0]):\n\t\t\t\t\t\tpossible_startup_file_parsed = desktopfile.parse(possible_startup_file)\n\n\t\t\t\t\t\tif possible_startup_file_parsed['Name'] == name:\n\t\t\t\t\t\t\tstartup_file = possible_startup_file\n\n\t\t\t\tos.remove(startup_file)\n\n\t\t\texcept IndexError:\n\t\t\t\tpass", "response": "Removes a program from startup."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_current_user(self):\n        from google.appengine.api import users\n\n        if _IS_DEVELOPMENT_SERVER:\n            return users.get_current_user()\n        else:\n            from google.appengine.api import oauth\n\n            try:\n                user = oauth.get_current_user()\n            except oauth.OAuthRequestError:\n                user = users.get_current_user()\n            return user", "response": "Override get_current_user for Google AppEngine"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a BAM file to an ES file.", "response": "def bam2es(\n        bam_fn,\n        es_fo,\n        allowed_delta,\n    ):\n        \"\"\"Convert BAM file to ES file.\n\n\t\tArgs:\n\t\t\tbam_fn (str): File name of the BAM file.\n\t\t\tbam_fo (file): File object of the ES file.\n\t\t\tallowed_delta (int): Maximal allowed coordinates difference for correct reads.\n\t\t\"\"\"\n\n        es_fo.write(\"# RN:   read name\" + os.linesep)\n        es_fo.write(\"# Q:    is mapped with quality\" + os.linesep)\n        es_fo.write(\"# Chr:  chr id\" + os.linesep)\n        es_fo.write(\"# D:    direction\" + os.linesep)\n        es_fo.write(\"# L:    leftmost nucleotide\" + os.linesep)\n        es_fo.write(\"# R:    rightmost nucleotide\" + os.linesep)\n        es_fo.write(\"# Cat:  category of alignment assigned by LAVEnder\" + os.linesep)\n        es_fo.write(\"#         M_i    i-th segment is correctly mapped\" + os.linesep)\n        es_fo.write(\"#         m      segment should be unmapped but it is mapped\" + os.linesep)\n        es_fo.write(\"#         w      segment is mapped to a wrong location\" + os.linesep)\n        es_fo.write(\"#         U      segment is unmapped and should be unmapped\" + os.linesep)\n        es_fo.write(\"#         u      segment is unmapped and should be mapped\" + os.linesep)\n        es_fo.write(\"# Segs: number of segments\" + os.linesep)\n        es_fo.write(\"# \" + os.linesep)\n        es_fo.write(\"# RN\\tQ\\tChr\\tD\\tL\\tR\\tCat\\tSegs\" + os.linesep)\n\n        with pysam.AlignmentFile(bam_fn, \"rb\") as sam:\n            references_dict = {}\n\n            for i in range(len(sam.references)):\n                references_dict[sam.references[i]] = i + 1\n\n            for read in sam:\n                rnf_read_tuple = rnftools.rnfformat.ReadTuple()\n                rnf_read_tuple.destringize(read.query_name)\n\n                left = read.reference_start + 1\n                right = read.reference_end\n                chrom_id = references_dict[sam.references[read.reference_id]]\n\n                nb_of_segments = len(rnf_read_tuple.segments)\n\n                if rnf_read_tuple.segments[0].genome_id == 1:\n                    should_be_mapped = True\n                else:\n                    should_be_mapped = False\n\n                # read is unmapped\n                if read.is_unmapped:\n                    # read should be mapped\n                    if should_be_mapped:\n                        category = \"u\"\n                    # read should be unmapped\n                    else:\n                        category = \"U\"\n                # read is mapped\n                else:\n                    # read should be mapped\n                    if should_be_mapped:\n                        exists_corresponding_segment = False\n\n                        for j in range(len(rnf_read_tuple.segments)):\n                            segment = rnf_read_tuple.segments[j]\n                            if (\n                                (segment.left == 0 or abs(segment.left - left) <= allowed_delta)\n                                and (segment.right == 0 or abs(segment.right - right) <= allowed_delta)\n                                and (segment.left != 0 or segment.right == 0)\n                                and (chrom_id == 0 or chrom_id == segment.chr_id)\n                            ):\n                                exists_corresponding_segment = True\n                                segment = str(j + 1)\n                                break\n\n                        # read was mapped to correct location\n                        if exists_corresponding_segment:  # exists ok location?\n                            category = \"M_\" + segment\n                        # read was mapped to incorrect location\n                        else:\n                            category = \"w\"\n                    # read should be unmapped\n                    else:\n                        category = \"m\"\n\n                es_fo.write(\n                    \"\\t\".join(\n                        map(\n                            str,\n                            [\n                                # read name\n                                read.query_name,\n                                # aligned?\n                                \"unmapped\" if read.is_unmapped else \"mapped_\" + str(read.mapping_quality),\n                                # reference id\n                                chrom_id,\n                                # direction\n                                \"R\" if read.is_reverse else \"F\",\n                                # left\n                                left,\n                                # right\n                                right,\n                                # assigned category\n                                category,\n                                # count of segments\n                                nb_of_segments\n                            ]\n                        )\n                    ) + os.linesep\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_es(self):\n\n        with (gzip.open(self._es_fn, \"tw+\") if self.compress_intermediate_files else open(self._es_fn, \"w+\")) as es_fo:\n            self.bam2es(\n                bam_fn=self._bam_fn,\n                es_fo=es_fo,\n                allowed_delta=self.report.allowed_delta,\n            )", "response": "Create an ES file for this BAM file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates vector of categories for given read tuple name and number of segments.", "response": "def _vector_of_categories(srs, read_tuple_name, parts):\n        \"\"\"Create vector of categories (voc[q] ... assigned category for given quality level)\n\n\t\tsrs ... single read statistics ... for every q ... dictionary\n\t\tread_tuple_name ... read name\n\t\tparts ... number of segments\n\t\t\"\"\"\n\n        # default value\n        vec = [\"x\" for i in range(rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1)]\n        assert len(srs) <= rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1, srs\n\n        should_be_mapped = bool(srs[0][\"m\"] + srs[0][\"U\"] == 0)\n\n        for q in range(len(srs)):\n\n            #####\n            # M # - all parts correctly aligned\n            #####\n            if len(srs[q][\"M\"]\n                   ) == parts and srs[q][\"w\"] == 0 and srs[q][\"m\"] == 0 and srs[q][\"U\"] == 0 and srs[q][\"u\"] == 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"M\"\n\n            #####\n            # w # - at least one segment is incorrectly aligned\n            #####\n            if srs[q][\"w\"] > 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"w\"\n\n            #####\n            # m # - at least one segment was aligned but should not be aligned\n            #####\n            if srs[q][\"w\"] == 0 and srs[q][\"m\"] > 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"m\"\n\n            #####\n            # U # - all segments should be unaligned but are unaligned\n            #####\n            if srs[q][\"U\"] > 0 and srs[q][\"u\"] == 0 and srs[q][\"m\"] == 0 and srs[q][\"w\"] == 0 and len(srs[q][\"M\"]) == 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"U\"\n\n            #####\n            # u # - at least one segment was unaligned but should be aligned\n            #####\n            if srs[q][\"w\"] == 0 and srs[q][\"u\"] > 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"u\"\n\n            #####\n            # t # - at least one segment was thresholded\n            #####\n            if len(srs[q][\"M\"]) != parts and srs[q][\"w\"] == 0 and srs[q][\"m\"] == 0 and srs[q][\"U\"] == 0 and srs[q][\n                \"u\"] == 0 and srs[q][\"t\"] > 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"t\"\n\n            #####\n            # T # - at least one segment was thresholded\n            #####\n            if len(srs[q][\"M\"]) != parts and srs[q][\"w\"] == 0 and srs[q][\"m\"] == 0 and srs[q][\"U\"] == 0 and srs[q][\n                \"u\"] == 0 and srs[q][\"T\"] > 0:\n                assert vec[q] == \"x\", str((q, srs[q]))\n                vec[q] = \"T\"\n\n            #####\n            # P # - multimapped, M + w + m > parts\n            #####\n\n            # only this one can rewrite some older assignment\n            if len(srs[q][\"M\"]) + srs[q][\"w\"] + srs[q][\"m\"] > parts and srs[q][\"U\"] == 0 and srs[q][\"u\"] == 0:\n                # assert vec[q]==\"x\",str((q,srs[q]))\n                vec[q] = \"P\"\n\n        return vec"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an ES file to an ET file.", "response": "def es2et(\n        es_fo,\n        et_fo,\n    ):\n        \"\"\"Convert ES to ET.\n\n\t\tArgs:\n\t\t\tes_fo (file): File object for the ES file.\n\t\t\tet_fo (file): File object for the ET file.\n\t\t\"\"\"\n\n        et_fo.write(\"# Mapping information for read tuples\" + os.linesep)\n        et_fo.write(\"#\" + os.linesep)\n        et_fo.write(\"# RN:   read name\" + os.linesep)\n        et_fo.write(\"# I:    intervals with asigned categories\" + os.linesep)\n        et_fo.write(\"#\" + os.linesep)\n        et_fo.write(\"# RN\tI\" + os.linesep)\n\n        last_rname = \"\"\n        for line in es_fo:\n            line = line.strip()\n            if line == \"\" or line[0] == \"#\":\n                continue\n            else:\n                (rname, mapped, ref, direction, left, right, category, nb_of_segments) = line.split(\"\\t\")\n                nb_of_segments = int(nb_of_segments)\n\n                # print(rname,last_rname,mapped)\n                # new read\n                if rname != last_rname:\n                    # update\n                    if last_rname != \"\":\n                        voc = Bam._vector_of_categories(single_reads_statistics, rname, nb_of_segments)\n                        et_fo.write(Bam._et_line(readname=rname, vector_of_categories=voc))\n                        et_fo.write(os.linesep)\n\n                    # nulling\n                    single_reads_statistics = [\n                        {\n                            \"U\": 0,\n                            \"u\": 0,\n                            \"M\": [],\n                            \"m\": 0,\n                            \"w\": 0,\n                            \"T\": 0,\n                            \"t\": 0,\n                        } for i in range(rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1)\n                    ]\n                    last_rname = rname\n\n                ####################\n                # Unmapped segment #\n                ####################\n\n                #####\n                # U #\n                #####\n                if category == \"U\":\n                    for q in range(len(single_reads_statistics)):\n                        single_reads_statistics[q][\"U\"] += 1\n\n                #####\n                # u #\n                #####\n                elif category == \"u\":\n                    for q in range(len(single_reads_statistics)):\n                        single_reads_statistics[q][\"u\"] += 1\n\n                ##################\n                # Mapped segment #\n                ##################\n\n                else:\n                    mapping_quality = int(mapped.replace(\"mapped_\", \"\"))\n                    assert 0 <= mapping_quality and mapping_quality <= rnftools.lavender.MAXIMAL_MAPPING_QUALITY, mapping_quality\n\n                    #####\n                    # m #\n                    #####\n                    if category == \"m\":\n                        for q in range(mapping_quality + 1):\n                            single_reads_statistics[q][\"m\"] += 1\n                        for q in range(mapping_quality + 1, rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1):\n                            single_reads_statistics[q][\"T\"] += 1\n\n                    #####\n                    # w #\n                    #####\n                    elif category == \"w\":\n                        for q in range(mapping_quality + 1):\n                            single_reads_statistics[q][\"w\"] += 1\n                        for q in range(mapping_quality + 1, rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1):\n                            single_reads_statistics[q][\"t\"] += 1\n\n                    #####\n                    # M #\n                    #####\n                    else:\n                        assert category[0] == \"M\", category\n                        segment_id = int(category.replace(\"M_\", \"\"))\n                        for q in range(mapping_quality + 1):\n                            single_reads_statistics[q][\"M\"].append(segment_id)\n                        for q in range(mapping_quality + 1, rnftools.lavender.MAXIMAL_MAPPING_QUALITY + 1):\n                            single_reads_statistics[q][\"t\"] += 1\n\n        # last read\n        voc = Bam._vector_of_categories(single_reads_statistics, rname, nb_of_segments)\n        et_fo.write(Bam._et_line(readname=rname, vector_of_categories=voc))\n        et_fo.write(os.linesep)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_et(self):\n\n        with (gzip.open(self._es_fn, \"tr\") if self.compress_intermediate_files else open(self._es_fn, \"r\")) as es_fo:\n            with (gzip.open(self._et_fn, \"tw+\")\n                  if self.compress_intermediate_files else open(self._et_fn, \"w+\")) as et_fo:\n                self.es2et(\n                    es_fo=es_fo,\n                    et_fo=et_fo,\n                )", "response": "Create a et file for this BAM file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a ROC file for this BAM file.", "response": "def create_roc(self):\n        \"\"\"Create a ROC file for this BAM file.\n\n\t\traises: ValueError\n\t\t\"\"\"\n\n        with (gzip.open(self._et_fn, \"tr\") if self.compress_intermediate_files else open(self._et_fn, \"r\")) as et_fo:\n            with open(self._roc_fn, \"w+\") as roc_fo:\n                self.et2roc(\n                    et_fo=et_fo,\n                    roc_fo=roc_fo,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_gp(self):\n\n        categories_order = [\n            (\"{U}\", \"#ee82ee\", 'Unmapped correctly'),\n            (\"{u}\", \"#ff0000\", 'Unmapped incorrectly'),\n            (\"{T}\", \"#00ff00\", 'Thresholded correctly'),\n            (\"{t}\", \"#008800\", 'Thresholded incorrectly'),\n            (\"{P}\", \"#ffff00\", 'Multimapped'),\n            (\"{w}+{x}\", \"#7f7f7f\", 'Mapped, should be unmapped'),\n            (\"{m}\", \"#000000\", 'Mapped to wrong position'),\n            (\"{M}\", \"#0000ff\", 'Mapped correctly'),\n        ]\n\n        plot_lines = [\n            '\"{roc_fn}\" using (( ({x}) )):({y}) lt rgb \"{color}\" with filledcurve x1 title \"{title}\", \\\\'.format(\n                roc_fn=self._roc_fn,\n                x=rnftools.lavender._format_xxx(self.default_x_axis),\n                y=rnftools.lavender._format_xxx(\n                    '({sum})*100/{{all}}'.format(sum=\"+\".join([c[0] for c in categories_order[i:]]))\n                ),\n                color=categories_order[i][1],\n                title=categories_order[i][2],\n            ) for i in range(len(categories_order))\n        ]\n\n        plot = os.linesep.join(([\"plot \\\\\"] + plot_lines + [\"\"]))\n\n        with open(self._gp_fn, \"w+\") as gp:\n            gp_content = \"\"\"\n\t\t\t\t\tset title \"{{/:Bold=16 {title}}}\"\n\t\n\t\t\t\t\tset x2lab \"{x_lab}\"\n\t\t\t\t\tset log x\n\t\t\t\t\tset log x2\n\t\n\t\t\t\t\tset format x \"10^{{%L}}\"\n\t\t\t\t\tset format x2 \"10^{{%L}}\"\n\t\t\t\t\tset xran  [{xran}]\n\t\t\t\t\tset x2ran [{xran}]\n\t\t\t\t\tset x2tics\n\t\t\t\t\tunset xtics\n\t\n\t\t\t\t\tset ylab \"Part of all reads (%)\"\n\t\n\t\t\t\t\tset format y \"%g %%\"\n\t\t\t\t\tset yran [{yran}]\n\t\t\t\t\tset y2ran [{yran}]\n\t\n\t\t\t\t\tset pointsize 1.5\n\t\n\t\t\t\t\tset grid ytics lc rgb \"#777777\" lw 1 lt 0 front\n\t\t\t\t\tset grid x2tics lc rgb \"#777777\" lw 1 lt 0 front\n\t\n\t\t\t\t\tset datafile separator \"\\\\t\"\n\t\t\t\t\tset palette negative\n\t\n\t\t\t\t\tset termin svg size {svg_size} enhanced\n\t\t\t\t\tset out \"{svg_fn}\"\n\t\t\t\t\tset key spacing 0.8 opaque width -5\n\t\t\t\t\"\"\".format(\n                svg_fn=self._svg_fn,\n                xran=\"{:.10f}:{:.10f}\".format(self.report.default_x_run[0], self.report.default_x_run[1]),\n                yran=\"{:.10f}:{:.10f}\".format(self.report.default_y_run[0], self.report.default_y_run[1]),\n                svg_size=\"{},{}\".format(self.report.default_svg_size_px[0], self.report.default_svg_size_px[1]),\n                title=os.path.basename(self._bam_fn)[:-4],\n                x_lab=self.default_x_label,\n            )\n            gp_content = textwrap.dedent(gp_content) + \"\\n\" + plot\n            # gp_lines=gp_content.split(\"\\n\")\n            # gp_lines=[x.strip() for x in gp_lines]\n            # gp_content=gp_lines.join(\"\\n\")\n            gp.write(gp_content)", "response": "Create a GnuPlot file for this BAM file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate images related to this BAM file using GnuPlot.", "response": "def create_graphics(self):\n        \"\"\"Create images related to this BAM file using GnuPlot.\"\"\"\n\n        rnftools.utils.shell('\"{}\" \"{}\"'.format(\"gnuplot\", self._gp_fn))\n\n        if self.render_pdf_method is not None:\n            svg_fn = self._svg_fn\n            pdf_fn = self._pdf_fn\n            svg42pdf(svg_fn, pdf_fn, method=self.render_pdf_method)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_html(self):\n\n        roc_dicts = []\n        with open(self._roc_fn, \"r\") as roc:\n            for line in roc:\n                line = line.strip()\n                if line != \"\" and line[0] != \"#\":\n                    (q, M, w, m, P, U, u, T, t, x, a) = map(int, line.split(\"\\t\"))\n                    roc_dict = {\n                        \"q\": q,\n                        \"M\": M,\n                        \"w\": w,\n                        \"m\": m,\n                        \"P\": P,\n                        \"U\": U,\n                        \"u\": u,\n                        \"T\": T,\n                        \"t\": t,\n                        \"x\": x,\n                        \"a\": a,\n                        \"mapped\": M + w + m + P,\n                        \"unmapped\": U + u + T + t + x,\n                    }\n                    roc_dicts.append(roc_dict)\n        tbody = os.linesep.join(\n            [\n                \"\"\"\n\t\t\t\t<tr>\n\t\t\t\t\t<td>        {quality}                   </td>\n\t\t\t\t\t<td>        {mapped}                    </td>\n\t\t\t\t\t<td><small> {mapped_proc:.2f}   </small></td>\n\t\t\t\t\t<td>        {M}                         </td>\n\t\t\t\t\t<td><small> {M_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {w}                         </td>\n\t\t\t\t\t<td><small> {w_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {m}                         </td>\n\t\t\t\t\t<td><small> {m_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {P}                         </td>\n\t\t\t\t\t<td><small> {P_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {unmapped}                  </td>\n\t\t\t\t\t<td><small> {unmapped_proc:.2f} </small></td>\n\t\t\t\t\t<td>        {U}                         </td>\n\t\t\t\t\t<td><small> {U_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {u}                         </td>\n\t\t\t\t\t<td><small> {u_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {T}                         </td>\n\t\t\t\t\t<td><small> {T_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {t}                         </td>\n\t\t\t\t\t<td><small> {t_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {x}                         </td>\n\t\t\t\t\t<td><small> {x_proc:.2f}        </small></td>\n\t\t\t\t\t<td>        {sum}                       </td>\n\t\t\t\t\t<td>        {prec_proc:.3f}              </td>\n\t\t\t\t</tr>\n\t\t\t\"\"\".format(\n                    quality=roc_dict[\"q\"],\n                    mapped=roc_dict[\"mapped\"],\n                    mapped_proc=100.0 * (roc_dict[\"mapped\"]) / roc_dict[\"a\"],\n                    M=roc_dict[\"M\"],\n                    M_proc=100.0 * (roc_dict[\"M\"]) / (roc_dict[\"mapped\"]) if (roc_dict[\"mapped\"]) != 0 else 0,\n                    w=roc_dict[\"w\"],\n                    w_proc=100.0 * (roc_dict[\"w\"]) / (roc_dict[\"mapped\"]) if (roc_dict[\"mapped\"]) != 0 else 0,\n                    m=roc_dict[\"m\"],\n                    m_proc=100.0 * (roc_dict[\"m\"]) / (roc_dict[\"mapped\"]) if (roc_dict[\"mapped\"]) != 0 else 0,\n                    P=roc_dict[\"P\"],\n                    P_proc=100.0 * (roc_dict[\"P\"]) / (roc_dict[\"mapped\"]) if (roc_dict[\"mapped\"]) != 0 else 0,\n                    unmapped=roc_dict[\"unmapped\"],\n                    unmapped_proc=100.0 * (roc_dict[\"unmapped\"]) / roc_dict[\"a\"],\n                    U=roc_dict[\"U\"],\n                    U_proc=100.0 * (roc_dict[\"U\"]) / (roc_dict[\"unmapped\"]) if (roc_dict[\"unmapped\"]) != 0 else 0,\n                    u=roc_dict[\"u\"],\n                    u_proc=100.0 * (roc_dict[\"u\"]) / (roc_dict[\"unmapped\"]) if (roc_dict[\"unmapped\"]) != 0 else 0,\n                    T=roc_dict[\"T\"],\n                    T_proc=100.0 * (roc_dict[\"T\"]) / (roc_dict[\"unmapped\"]) if (roc_dict[\"unmapped\"]) != 0 else 0,\n                    t=roc_dict[\"t\"],\n                    t_proc=100.0 * (roc_dict[\"t\"]) / (roc_dict[\"unmapped\"]) if (roc_dict[\"unmapped\"]) != 0 else 0,\n                    x=roc_dict[\"x\"],\n                    x_proc=100.0 * (roc_dict[\"x\"]) / (roc_dict[\"unmapped\"]) if (roc_dict[\"unmapped\"]) != 0 else 0,\n                    sum=roc_dict[\"a\"],\n                    prec_proc=100.0 * (roc_dict[\"M\"]) / (roc_dict[\"mapped\"]) if (roc_dict[\"mapped\"]) != 0 else 0,\n                ) for roc_dict in roc_dicts\n            ]\n        )\n\n        with open(self._html_fn, \"w+\") as html:\n            program_info = [\"No information available (PG header is essing).\"]\n            for x in rnftools.utils.shell(\n                '\"{samtools}\" view -H \"{bam}\"'.format(\n                    samtools=\"samtools\",\n                    bam=self._bam_fn,\n                ), iterable=True\n            ):\n                x = x.strip()\n\n                if x[:3] == \"@PG\":\n                    pg_header = x[4:].strip()\n                    parts = pg_header.split(\"\\t\")\n\n                    program_info = [\"<table>\"]\n                    for part in parts:\n                        (lvalue, _, rvalue) = part.partition(\":\")\n                        program_info.append(\n                            '<tr><td style=\"font-weight:bold\">{}:</td><td style=\"text-align:left\">{}</td></tr>'.format(\n                                lvalue, rvalue\n                            )\n                        )\n\n                    program_info.append(\"</table>\")\n\n            eval_info = [\"<table>\"]\n            for (lvalue, rvalue) in [\n                (\"BAM file\", self._bam_fn),\n                (\"Allowed delta\", self.report.allowed_delta),\n            ]:\n                eval_info.append(\n                    '<tr><td style=\"font-weight:bold\">{}:</td><td style=\"text-align:left\">{}</td></tr>'.format(\n                        lvalue, rvalue\n                    )\n                )\n\n            eval_info.append(\"</table>\")\n\n            css_src = textwrap.dedent(\n                \"\"\"\n\t\t\t\t\ttable            {border-collapse:collapse;}\n\t\t\t\t\ttd               {border: solid #aaaaff 1px;padding:4px;text-align:right;}\n\t\t\t\t\tcolgroup, thead  {border: solid black 2px;padding 2px;}\n\t\t\t\t\t.link_to_top     {font-size:10pt;}\n\t\t\t\t\t.desc            {color:#aaa;}\n\t\t\t\t\t.formats         {text-align:left;margin-bottom:20px;}\n\t\t\t\t\"\"\"\n            )\n\n            html_src = \"\"\"<!DOCTYPE html>\n\t\t\t\t<html>\n\t\t\t\t<head>\n\t\t\t\t\t<meta charset=\"UTF-8\" />\n\t\t\t\t\t<title>{name}</title>\n\t\t\t\t\t<style type=\"text/css\">\n\t\t\t\t\t{css}\n\t\t\t\t\t</style>\n\t\t\t\t</head>\n\t\t\t\t<body>\n\t\t\t\t\t<h1 id=\"top\">\n\t\t\t\t\t\t{name}\n\t\t\t\t\t\t<span class=\"link_to_top\">\n\t\t\t\t\t\t\t[<a href=\"{homepage}\">Back to main report</a>]\n\t\t\t\t\t\t</span>\n\t\t\t\t\t</h1>\n\t\n\t\t\t\t\t<p>\n\t\t\t\t\t\t<a href=\"#info_eval\">Information about evaluation</a> -\n\t\t\t\t\t\t<a href=\"#info_prog\">Information about program</a> -\n\t\t\t\t\t\t<a href=\"#roctable\">ROC table</a> -\n\t\t\t\t\t\t<a href=\"#graphs\">Graphs</a>\n\t\t\t\t\t</p>\n\t\n\t\t\t\t\t<h2 id=\"info_eval\">\n\t\t\t\t\t\tInformation about evaluation\n\t\t\t\t\t\t{headline_links}\n\t\t\t\t\t</h2>\n\t\n\t\t\t\t\t{eval_info}\n\t\n\t\t\t\t\t<h2 id=\"info_prog\">\n\t\t\t\t\t\tInformation about program\n\t\t\t\t\t\t{headline_links}\n\t\t\t\t\t</h2>\n\t\n\t\n\t\t\t\t\t{program_info}\n\t\n\t\t\t\t\t<h2 id=\"roctable\">\n\t\t\t\t\t\tROC table\n\t\t\t\t\t\t{headline_links}\n\t\t\t\t\t</h2>\n\t\n\t\t\t\t\t<p style=\"font-size:80%\">\n\t\t\t\t\t\t<strong>M</strong>:\n\t\t\t\t\t\t\tmapped correctly\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(all segments of tuple are mapped once and correctly),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>w</strong>:\n\t\t\t\t\t\t\tmapped to wrong position\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(at least one segment was mapped to a wrong position),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>m</strong>:\n\t\t\t\t\t\t\tmapped but should be unmapped\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(at least one segment was mapped but the read should not be mapped),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>P</strong>:\n\t\t\t\t\t\t\tmultimapped\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(read should be mapped but it at least one segment was mapped several\n\t\t\t\t\t\t\t\ttimes and all segments were mapped correctly at least once),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>U</strong>:\n\t\t\t\t\t\t\tunmapped correctly\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(all segments of the read were correctly marked as unmapped),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>u</strong>:\n\t\t\t\t\t\t\tunmapped but should be mapped\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(at least one segment was mapped but entire read should be unmapped),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>T</strong>:\n\t\t\t\t\t\t\tthresholded correctly\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(read shoud not be mapped),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>t</strong>:\n\t\t\t\t\t\t\tthresholded incorrectly\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(read should be mapped),\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<strong>x</strong>:\n\t\t\t\t\t\t\tunknown\n\t\t\t\t\t\t\t<span class=\"desc\">\n\t\t\t\t\t\t\t\t(read is probably not reported by mapper)\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t</p>\n\t\t\t\t\t<table>\n\t\t\t\t\t\t<colgroup span=\"1\" style=\"\">\n\t\t\t\t\t\t<colgroup span=\"2\" style=\"background-color:#ddd\">\n\t\t\t\t\t\t<colgroup span=\"8\" style=\"\">\n\t\t\t\t\t\t<colgroup span=\"2\" style=\"background-color:#ddd\">\n\t\t\t\t\t\t<colgroup span=\"10\" style=\"\">\n\t\t\t\t\t\t<colgroup span=\"1\" style=\"background-color:#ddd\">\n\t\t\t\t\t\t<colgroup span=\"1\" style=\"\">\n\t\t\t\t\t\t<thead style=\"font-weight:bold;background-color:#ddddff\">\n\t\t\t\t\t\t\t<tr style=\"font-weight:bold;background-color:#ddddff\">\n\t\t\t\t\t\t\t\t<td>q</td>\n\t\t\t\t\t\t\t\t<td>mapped</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>M</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>w</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>m</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>P</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>unmapped</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>U</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>u</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>T</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>t</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>x</td>\n\t\t\t\t\t\t\t\t<td>%</td>\n\t\t\t\t\t\t\t\t<td>sum</td>\n\t\t\t\t\t\t\t\t<td>prec. (%)</td>\n\t\t\t\t\t\t\t</tr>\n\t\t\t\t\t\t</thead>\n\t\t\t\t\t\t<tbody>\n\t\t\t\t\t\t\t{tbody}\n\t\t\t\t\t\t</tbody>\n\t\t\t\t\t</table>\n\t\n\t\t\t\t\t<h2 id=\"graphs\">\n\t\t\t\t\t\tGraphs\n\t\t\t\t\t\t{headline_links}\n\t\t\t\t\t</h2>\n\t\n\t\t\t\t\t<div class=\"formats\">\n\t\t\t\t\t\t<img src=\"{svg}\" />\n\t\t\t\t\t\t<br />\n\t\t\t\t\t\t<a href=\"{svg}\">SVG version</a>\n\t\t\t\t\t\t|\n\t\t\t\t\t\t<a href=\"{roc}\" type=\"text/csv\">ROC file</a>\n\t\t\t\t\t\t|\n\t\t\t\t\t\t<a href=\"{gp}\" type=\"text/plain\">GP file</a>\n\t\t\t\t\t</div>\n\t\n\t\n\t\t\t\t</body>\n\t\t\t\t</html>\n\t\t\t\t\"\"\".format(\n                name=self.name, tbody=tbody, css=css_src,\n                svg=os.path.relpath(self._svg_fn, os.path.dirname(self._html_fn)),\n                roc=os.path.relpath(self._roc_fn, os.path.dirname(self._html_fn)),\n                gp=os.path.relpath(self._gp_fn, os.path.dirname(self._html_fn)), eval_info=os.linesep.join(eval_info),\n                program_info=os.linesep.join(program_info),\n                homepage=os.path.relpath(self.report.html_fn(), os.path.dirname(self._html_fn)), headline_links='''\n\t\t\t\t\t\t\t<span class=\"link_to_top\">\n\t\t\t\t\t\t\t\t[<a href=\"#top\">Top of this page</a>]\n\t\t\t\t\t\t\t\t[<a href=\"{homepage}\">Back to main report</a>]\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t'''.format(homepage=os.path.relpath(self.report.html_fn(), os.path.dirname(self._html_fn)), )\n            )\n\n            tidy_html_src = bs4.BeautifulSoup(html_src).prettify()\n            html.write(tidy_html_src)", "response": "Create a HTML page for this BAM file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_tovot(tabdata, tabname='votable.xml', phot=False, binary=True):\n\n    # Check if input is a dictionary\n    if not isinstance(tabdata[0], dict):\n        raise TypeError('Table must be a dictionary. Call the SQL query with query_dict.execute()')\n\n    # Create an empty table to store the data\n    t = Table()\n\n    colnames = tabdata[0].keys()\n\n    # If this is a photometry table, parse it and make sure to have the full list of columns\n    if phot:\n        tabdata = photparse(tabdata)\n\n        colnames = tabdata[0].keys()\n\n        for i in range(len(tabdata)):\n            tmpcol = tabdata[i].keys()\n            for elem in tmpcol:\n                if elem not in colnames:\n                    colnames.append(elem)\n\n        # No need for band column any more\n        try:\n            colnames.remove('band')\n        except ValueError:\n            pass\n\n    # Run through all the columns and create them\n    for elem in colnames:\n        table_add(t, tabdata, elem)\n\n    # Output to a file\n    print('Creating table...')\n    votable = from_table(t)\n\n    # Required in some cases (ie, for lots of text columns)\n    if binary:\n        votable.set_all_tables_format('binary')\n\n    votable.to_xml(tabname)\n\n    print('Table created: {}'.format(tabname))", "response": "Converts a dictionary table to a VOTable with name tabname."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef photaddline(tab, sourceid):\n\n    colnames = tab[0].keys()\n    tmpdict = dict()\n    for i in range(len(tab)):\n\n        # If not working on the same source, continue\n        if tab[i]['source_id'] != sourceid:\n            continue\n\n        # Check column names and create new ones for band-specific ones\n        for elem in colnames:\n            if elem not in ['comments', 'epoch', 'instrument_id', 'magnitude', 'magnitude_unc', 'publication_id',\n                            'system', 'telescope_id']:\n                tmpdict[elem] = tab[i][elem]\n            elif elem == 'band':\n                continue\n            else:\n                tmpstr = tab[i]['band']+'.'+elem\n                tmpdict[tmpstr] = tab[i][elem]\n\n    return tmpdict", "response": "Create a line for a source in the photometry table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a photometry table to group together sources", "response": "def photparse(tab):\n    \"\"\"\n    Parse through a photometry table to group by source_id\n\n    Parameters\n    ----------\n    tab: list\n      SQL query dictionary list from running query_dict.execute()\n\n    Returns\n    -------\n    newtab: list\n      Dictionary list after parsing to group together sources\n\n    \"\"\"\n\n    # Check that source_id column is present\n    if 'source_id' not in tab[0].keys():\n        raise KeyError('phot=TRUE requires the source_id columb be included')\n\n    # Loop through the table and grab unique band names and source IDs\n    uniqueid = []\n    for i in range(len(tab)):\n        tmpid = tab[i]['source_id']\n\n        if tmpid not in uniqueid:\n            uniqueid.append(tmpid)\n\n    # Loop over unique id and create a new table for each element in it\n    newtab = []\n    for sourceid in uniqueid:\n        tmpdict = photaddline(tab, sourceid)\n        newtab.append(tmpdict)\n\n    return newtab"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table_add(tab, data, col):\n\n    x = []\n    for i in range(len(data)):\n\n        # If the particular key is not present, use a place-holder value (used for photometry tables)\n        if col not in data[i]:\n            temp = ''\n        else:\n            temp = data[i][col]\n\n        # Fix up None elements\n        if temp is None: temp = ''\n\n        x.append(temp)\n\n    print('Adding column {}'.format(col))\n    tab.add_column(Column(x, name=col))", "response": "Function to parse dictionary list data and add the data to table tab for column col"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_order_by(self, field):\n    # Get ordering model.\n    model_label = order.utils.resolve_labels('.'.join(\\\n            [self.model._meta.app_label, self.model._meta.object_name]))\n    orderitem_set = getattr(self.model, \\\n            order.utils.resolve_order_item_related_set_name(model_label))\n    order_model = orderitem_set.related.model\n\n    # Resolve ordering model table name.\n    db_table = order_model._meta.db_table\n\n    # Add ordering field as extra queryset fields.\n    pk_name = self.model._meta.pk.attname\n\n    # If we have a descending query remove '-' from field name when quering.\n    sanitized_field = field.lstrip('-')\n\n    extra_select = {\n        sanitized_field: '(SELECT %s from %s WHERE item_id=%s.%s)' % \\\n                (sanitized_field, db_table, self.model._meta.db_table, pk_name)\n    }\n\n    # Use original field name when ordering to allow for descending.\n    return self.extra(select=extra_select).all().order_by(field)", "response": "Queryset method ordering objects by user ordering field."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting enabled features. Returns a list of all enabled features on a given Account Course or User.", "response": "def list_enabled_features_accounts(self, account_id):\r\n        \"\"\"\r\n        List enabled features.\r\n\r\n        List all features that are enabled on a given Account, Course, or User.\r\n        Only the feature names are returned.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/features/enabled with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/features/enabled\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_feature_flag_courses(self, feature, course_id, state=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"\"off\":: The feature is not available for the course, user, or account and sub-accounts.\r\n        \"allowed\":: (valid only on accounts) The feature is off in the account, but may be enabled in\r\n                    sub-accounts and courses by setting a feature flag on the sub-account or course.\r\n        \"on\":: The feature is turned on unconditionally for the user, course, or account and sub-accounts.\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"off\", \"allowed\", \"on\"])\r\n            data[\"state\"] = state\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)", "response": "Sets a feature flag for a given Account Course or User."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a feature flag for a given Account Course or User.", "response": "def set_feature_flag_accounts(self, feature, account_id, state=None):\r\n        \"\"\"\r\n        Set feature flag.\r\n\r\n        Set a feature flag for a given Account, Course, or User. This call will fail if a parent account sets\r\n        a feature flag for the same feature in any state other than \"allowed\".\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"\"off\":: The feature is not available for the course, user, or account and sub-accounts.\r\n        \"allowed\":: (valid only on accounts) The feature is off in the account, but may be enabled in\r\n                    sub-accounts and courses by setting a feature flag on the sub-account or course.\r\n        \"on\":: The feature is turned on unconditionally for the user, course, or account and sub-accounts.\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"off\", \"allowed\", \"on\"])\r\n            data[\"state\"] = state\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{account_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{account_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_feature_flag_users(self, user_id, feature, state=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"\"off\":: The feature is not available for the course, user, or account and sub-accounts.\r\n        \"allowed\":: (valid only on accounts) The feature is off in the account, but may be enabled in\r\n                    sub-accounts and courses by setting a feature flag on the sub-account or course.\r\n        \"on\":: The feature is turned on unconditionally for the user, course, or account and sub-accounts.\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"off\", \"allowed\", \"on\"])\r\n            data[\"state\"] = state\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/{user_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/{user_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)", "response": "Sets a feature flag for a given User."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_feature_flag_courses(self, feature, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        self.logger.debug(\"DELETE /api/v1/courses/{course_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/courses/{course_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)", "response": "Removes a feature flag. Removes a feature flag from a given Account Course or User."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a feature flag from a given Account.", "response": "def remove_feature_flag_accounts(self, feature, account_id):\r\n        \"\"\"\r\n        Remove feature flag.\r\n\r\n        Remove feature flag for a given Account, Course, or User.  (Note that the flag must\r\n        be defined on the Account, Course, or User directly.)  The object will then inherit\r\n        the feature flags from a higher account, if any exist.  If this flag was 'on' or 'off',\r\n        then lower-level account flags that were masked by this one will apply again.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        self.logger.debug(\"DELETE /api/v1/accounts/{account_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/accounts/{account_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_feature_flag_users(self, user_id, feature):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - feature\r\n        \"\"\"ID\"\"\"\r\n        path[\"feature\"] = feature\r\n\r\n        self.logger.debug(\"DELETE /api/v1/users/{user_id}/features/flags/{feature} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/users/{user_id}/features/flags/{feature}\".format(**path), data=data, params=params, single_item=True)", "response": "Removes a feature flag for a given User. Removes the flag for a given User from the specified Feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_accuracy(data, output_dir_path='.', output_filename='accuracy.png',\n                  width=10, height=8):\n    \"\"\"Plot accuracy.\n        Args:\n            data: Panda dataframe in *the* format.\n    \"\"\"\n    output_path = os.path.join(output_dir_path, output_filename)\n\n    max_val_data = get_epoch_max_val_acc(data)\n    max_val_label = round(max_val_data['acc'].values[0], 4)\n\n    # max_val_epoch = max_val_data['epoch'].values[0]\n    max_epoch_data = data[data['epoch'] == data['epoch'].max()]\n\n    plot = ggplot(data, aes('epoch', 'acc', color='factor(data)')) + \\\n        geom_line(size=1, show_legend=False) + \\\n        geom_vline(aes(xintercept='epoch', color='data'),\n                   data=max_val_data, alpha=0.5, show_legend=False) + \\\n        geom_label(aes('epoch', 'acc'), data=max_val_data,\n                   label=max_val_label, nudge_y=-0.02, va='top', label_size=0,\n                   show_legend=False) + \\\n        geom_text(aes('epoch', 'acc', label='data'), data=max_epoch_data,\n                  nudge_x=2, ha='center', show_legend=False) + \\\n        geom_point(aes('epoch', 'acc'), data=max_val_data,\n                   show_legend=False) + \\\n        labs(y='Accuracy', x='Epochs') + \\\n        theme_bw(base_family='Arial', base_size=15) + \\\n        scale_color_manual(['#ef8a62', '#67a9cf', \"#f7f7f7\"])\n\n    plot.save(output_path, width=width, height=height)", "response": "Plot accuracy.\n        Args:\n            data: Panda dataframe in *the* format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates two plots of the accuracy loss and accuracy of the current object.", "response": "def plot(data, output_dir_path='.', width=10, height=8):\n    \"\"\"Create two plots: 1) loss 2) accuracy.\n        Args:\n            data: Panda dataframe in *the* format.\n    \"\"\"\n    if not isinstance(data, pd.DataFrame):\n        data = pd.DataFrame(data)\n    plot_accuracy(data, output_dir_path=output_dir_path,\n                  width=width, height=height)\n    plot_loss(data, output_dir_path, width=width, height=height)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self):\n        _logger.debug(\"Start connecting to broker\")\n        while True:\n            try:\n                self.client.connect(self.broker_host, self.broker_port,\n                                    self.broker_keepalive)\n                break\n            except Exception:\n                _logger.debug(\n                    \"Connect failed. wait %s sec\" % self.connect_delay)\n                sleep(self.connect_delay)\n\n        self.client.loop_forever()", "response": "Connect to the broker."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the tunnel for the specified type.", "response": "def set_tunnel(self, tunnel_type, tunnel, callback=None):\n        \"\"\"\n        set_tunnel(self, tunnel_type, tunnel, callback=None):\n        \"\"\"\n        orig_tunnel = self.tunnels.get(tunnel_type, (None, None))[0]\n        if orig_tunnel is not None:\n            _logger.debug(\"Unsubscribe: %s\", (orig_tunnel,))\n            self.client.unsubscribe(str(orig_tunnel))\n\n        self.tunnels[tunnel_type] = (tunnel, callback)\n\n        if callback is not None:\n            self.message_callback_add(tunnel, callback)\n\n        self.client.subscribe(str(tunnel))\n        _logger.debug(\"Subscribe: %s\", (tunnel,))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_tunnels(self, tunnels):\n        for tunnel_type, (tunnel, callback) in tunnels.iteritems():\n            if tunnel is None:\n                continue\n            self.set_tunnel(tunnel_type, tunnel, callback)", "response": "Set the tunnels for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npublishing a message to the broker.", "response": "def publish(self, topic=\"/controller\", qos=0, payload=None):\n        \"\"\"\n        publish(self, topic, payload=None, qos=0, retain=False)\n        Returns a tuple (result, mid), where result is MQTT_ERR_SUCCESS to\n        indicate success or MQTT_ERR_NO_CONN if the client is not currently\n        connected.  mid is the message ID for the publish request. The mid\n        value can be used to track the publish request by checking against the\n        mid argument in the on_publish() callback if it is defined.\n        \"\"\"\n        result = self.client.publish(topic,\n                                     payload=json.dumps(payload),\n                                     qos=qos)\n        if result[0] == mqtt.MQTT_ERR_NO_CONN:\n            raise RuntimeError(\"No connection\")\n        return result[1]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a simple console logger.", "response": "def get_logger(verbosity):\n    \"\"\"\n    Returns simple console logger.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    logger.setLevel({\n        0: DEFAULT_LOGGING_LEVEL,\n        1: logging.INFO,\n        2: logging.DEBUG\n    }.get(min(2, verbosity), DEFAULT_LOGGING_LEVEL))\n    logger.handlers = []\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setLevel(logging.DEBUG)\n    handler.setFormatter(logging.Formatter('%(name)s - %(levelname)s - %(message)s'))\n    logger.addHandler(handler)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the outcome results for users and outcomes in the specified context. Returns the outcome results for users and outcomes in the specified context.", "response": "def get_outcome_results(self, course_id, include=None, outcome_ids=None, user_ids=None):\r\n        \"\"\"\r\n        Get outcome results.\r\n\r\n        Gets the outcome results for users and outcomes in the specified context.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - user_ids\r\n        \"\"\"If specified, only the users whose ids are given will be included in the\r\n        results. SIS ids can be used, prefixed by \"sis_user_id:\".\r\n        It is an error to specify an id for a user who is not a student in\r\n        the context.\"\"\"\r\n        if user_ids is not None:\r\n            params[\"user_ids\"] = user_ids\r\n\r\n        # OPTIONAL - outcome_ids\r\n        \"\"\"If specified, only the outcomes whose ids are given will be included in the\r\n        results. it is an error to specify an id for an outcome which is not linked\r\n        to the context.\"\"\"\r\n        if outcome_ids is not None:\r\n            params[\"outcome_ids\"] = outcome_ids\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"[String, \"alignments\"|\"outcomes\"|\"outcomes.alignments\"|\"outcome_groups\"|\"outcome_links\"|\"outcome_paths\"|\"users\"]\r\n        Specify additional collections to be side loaded with the result.\r\n        \"alignments\" includes only the alignments referenced by the returned\r\n        results.\r\n        \"outcomes.alignments\" includes all alignments referenced by outcomes in the\r\n        context.\"\"\"\r\n        if include is not None:\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/outcome_results with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/outcome_results\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the outcome result rollups for the specified users and outcomes in the specified context.", "response": "def get_outcome_result_rollups(self, course_id, aggregate=None, include=None, outcome_ids=None, user_ids=None):\r\n        \"\"\"\r\n        Get outcome result rollups.\r\n\r\n        Gets the outcome rollups for the users and outcomes in the specified\r\n        context.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - aggregate\r\n        \"\"\"If specified, instead of returning one rollup for each user, all the user\r\n        rollups will be combined into one rollup for the course that will contain\r\n        the average rollup score for each outcome.\"\"\"\r\n        if aggregate is not None:\r\n            self._validate_enum(aggregate, [\"course\"])\r\n            params[\"aggregate\"] = aggregate\r\n\r\n        # OPTIONAL - user_ids\r\n        \"\"\"If specified, only the users whose ids are given will be included in the\r\n        results or used in an aggregate result. it is an error to specify an id\r\n        for a user who is not a student in the context\"\"\"\r\n        if user_ids is not None:\r\n            params[\"user_ids\"] = user_ids\r\n\r\n        # OPTIONAL - outcome_ids\r\n        \"\"\"If specified, only the outcomes whose ids are given will be included in the\r\n        results. it is an error to specify an id for an outcome which is not linked\r\n        to the context.\"\"\"\r\n        if outcome_ids is not None:\r\n            params[\"outcome_ids\"] = outcome_ids\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"[String, \"courses\"|\"outcomes\"|\"outcomes.alignments\"|\"outcome_groups\"|\"outcome_links\"|\"outcome_paths\"|\"users\"]\r\n        Specify additional collections to be side loaded with the result.\"\"\"\r\n        if include is not None:\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/outcome_rollups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/outcome_rollups\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, command):\n        if isinstance(command, str):\n            self.method(command.split())\n        elif isinstance(command, list):\n            self.method(command)\n        else:\n            raise TypeError(\"command should be either a string or list type\")\n\n        if self.error:\n            raise IPMIError(self.error)\n        else:\n            return self.status", "response": "Execute ipmitool commands returning the status of the chassis"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _subprocess_method(self, command):\n        p = subprocess.Popen([self._ipmitool_path] + self.args + command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        self.output, self.error = p.communicate()\n        self.status = p.returncode", "response": "Use the subprocess module to execute ipmitool commands\n        and set status"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _expect_method(self, command):\n        child = pexpect.spawn(self._ipmitool_path, self.args + command)\n        \n        i = child.expect([pexpect.TIMEOUT, 'Password: '], timeout=10)\n        if i == 0:\n            child.terminate()\n            self.error = 'ipmitool command timed out'\n            self.status = 1\n        else:\n            child.sendline(self.password)\n        \n        i = child.expect([pexpect.TIMEOUT, pexpect.EOF], timeout=10)\n        if i == 0:\n            child.terminate()\n            self.error = 'ipmitool command timed out'\n            self.status = 1\n        else:\n            if child.exitstatus:\n                self.error = child.before\n            else:\n                self.output = child.before\n\n            self.status = child.exitstatus\n            child.close()", "response": "Use the expect module to execute ipmitool commands\n            and set status\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_ipmitool_path(self, cmd='ipmitool'):\n        p = subprocess.Popen([\"which\", cmd], \n            stdout=subprocess.PIPE, stderr=subprocess.PIPE)                \n        out, err =  p.communicate()\n        return out.strip()", "response": "Get full path to the ipmitool command using the unix\n        which command"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nempty a table by deleting all of its rows.", "response": "def truncate(self, table):\n        \"\"\"Empty a table by deleting all of its rows.\"\"\"\n        if isinstance(table, (list, set, tuple)):\n            for t in table:\n                self._truncate(t)\n        else:\n            self._truncate(table)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntruncating all records from a table in MySQL", "response": "def _truncate(self, table):\n        \"\"\"\n        Remove all records from a table in MySQL\n\n        It performs the same function as a DELETE statement without a WHERE clause.\n        \"\"\"\n        statement = \"TRUNCATE TABLE {0}\".format(wrap(table))\n        self.execute(statement)\n        self._printer('\\tTruncated table {0}'.format(table))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef truncate_database(self, database=None):\n        # Change database if needed\n        if database in self.databases and database is not self.database:\n            self.change_db(database)\n\n        # Get list of tables\n        tables = self.tables if isinstance(self.tables, list) else [self.tables]\n        if len(tables) > 0:\n            self.drop(tables)\n            self._printer('\\t' + str(len(tables)), 'tables truncated from', database)\n        return tables", "response": "Drop all tables in a database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop(self, table):\n        existing_tables = self.tables\n        if isinstance(table, (list, set, tuple)):\n            for t in table:\n                self._drop(t, existing_tables)\n        else:\n            self._drop(table, existing_tables)\n        return table", "response": "Drop a table from a database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _drop(self, table, existing_tables=None):\n        # Retrieve list of existing tables for comparison\n        existing_tables = existing_tables if existing_tables else self.tables\n\n        # Only drop table if it exists\n        if table in existing_tables:\n            # Set to avoid foreign key errorrs\n            self.execute('SET FOREIGN_KEY_CHECKS = 0')\n\n            query = 'DROP TABLE {0}'.format(wrap(table))\n            self.execute(query)\n\n            # Set again\n            self.execute('SET FOREIGN_KEY_CHECKS = 1')\n            self._printer('\\tDropped table {0}'.format(table))", "response": "Private method for executing table drop commands."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop_empty_tables(self):\n        # Count number of rows in each table\n        counts = self.count_rows_all()\n        drops = []\n\n        # Loop through each table key and validate that rows count is not 0\n        for table, count in counts.items():\n            if count < 1:\n                # Drop table if it contains no rows\n                self.drop(table)\n                drops.append(table)\n        return drops", "response": "Drop all empty tables in a database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the values of a particular table columns with values where a value is met.", "response": "def update(self, table, columns, values, where):\n        \"\"\"\n        Update the values of a particular row where a value is met.\n\n        :param table: table name\n        :param columns: column(s) to update\n        :param values: updated values\n        :param where: tuple, (where_column, where_value)\n        \"\"\"\n        # Unpack WHERE clause dictionary into tuple\n        where_col, where_val = where\n\n        # Create column string from list of values\n        cols = get_col_val_str(columns, query_type='update')\n\n        # Concatenate statement\n        statement = \"UPDATE {0} SET {1} WHERE {2}='{3}'\".format(wrap(table), cols, where_col, where_val)\n\n        # Execute statement\n        self._cursor.execute(statement, values)\n        self._printer('\\tMySQL cols (' + str(len(values)) + ') successfully UPDATED')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_many(self, table, columns, values, where_col, where_index):\n        for row in values:\n            wi = row.pop(where_index)\n            self.update(table, columns, row, (where_col, wi))", "response": "Update the values of several rows."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_new_grading_standard_accounts(self, title, account_id, grading_scheme_entry_name, grading_scheme_entry_value):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - title\r\n        \"\"\"The title for the Grading Standard.\"\"\"\r\n        data[\"title\"] = title\r\n\r\n        # REQUIRED - grading_scheme_entry[name]\r\n        \"\"\"The name for an entry value within a GradingStandard that describes the range of the value\r\n        e.g. A-\"\"\"\r\n        data[\"grading_scheme_entry[name]\"] = grading_scheme_entry_name\r\n\r\n        # REQUIRED - grading_scheme_entry[value]\r\n        \"\"\"The value for the name of the entry within a GradingStandard.\r\n        The entry represents the lower bound of the range for the entry.\r\n        This range includes the value up to the next entry in the GradingStandard,\r\n        or 100 if there is no upper bound. The lowest value will have a lower bound range of 0.\r\n        e.g. 93\"\"\"\r\n        data[\"grading_scheme_entry[value]\"] = grading_scheme_entry_value\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/grading_standards with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/grading_standards\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new grading standard for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_new_grading_standard_courses(self, title, course_id, grading_scheme_entry_name, grading_scheme_entry_value):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - title\r\n        \"\"\"The title for the Grading Standard.\"\"\"\r\n        data[\"title\"] = title\r\n\r\n        # REQUIRED - grading_scheme_entry[name]\r\n        \"\"\"The name for an entry value within a GradingStandard that describes the range of the value\r\n        e.g. A-\"\"\"\r\n        data[\"grading_scheme_entry[name]\"] = grading_scheme_entry_name\r\n\r\n        # REQUIRED - grading_scheme_entry[value]\r\n        \"\"\"The value for the name of the entry within a GradingStandard.\r\n        The entry represents the lower bound of the range for the entry.\r\n        This range includes the value up to the next entry in the GradingStandard,\r\n        or 100 if there is no upper bound. The lowest value will have a lower bound range of 0.\r\n        e.g. 93\"\"\"\r\n        data[\"grading_scheme_entry[value]\"] = grading_scheme_entry_value\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/grading_standards with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/grading_standards\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new grading standard."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting the groups available in a context. Returns the list of active groups in the given context.", "response": "def list_groups_available_in_context_accounts(self, account_id, include=None, only_own_groups=None):\r\n        \"\"\"\r\n        List the groups available in a context.\r\n\r\n        Returns the list of active groups in the given context that are visible to user.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - only_own_groups\r\n        \"\"\"Will only include groups that the user belongs to if this is set\"\"\"\r\n        if only_own_groups is not None:\r\n            params[\"only_own_groups\"] = only_own_groups\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"tabs\": Include the list of tabs configured for each group.  See the\r\n          {api:TabsController#index List available tabs API} for more information.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"tabs\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/groups\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new group.", "response": "def create_group_groups(self, description=None, is_public=None, join_level=None, name=None, storage_quota_mb=None):\r\n        \"\"\"\r\n        Create a group.\r\n\r\n        Creates a new group. Groups created using the \"/api/v1/groups/\"\r\n        endpoint will be community groups.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"The name of the group\"\"\"\r\n        if name is not None:\r\n            data[\"name\"] = name\r\n\r\n        # OPTIONAL - description\r\n        \"\"\"A description of the group\"\"\"\r\n        if description is not None:\r\n            data[\"description\"] = description\r\n\r\n        # OPTIONAL - is_public\r\n        \"\"\"whether the group is public (applies only to community groups)\"\"\"\r\n        if is_public is not None:\r\n            data[\"is_public\"] = is_public\r\n\r\n        # OPTIONAL - join_level\r\n        \"\"\"no description\"\"\"\r\n        if join_level is not None:\r\n            self._validate_enum(join_level, [\"parent_context_auto_join\", \"parent_context_request\", \"invitation_only\"])\r\n            data[\"join_level\"] = join_level\r\n\r\n        # OPTIONAL - storage_quota_mb\r\n        \"\"\"The allowed file storage for the group, in megabytes. This parameter is\r\n        ignored if the caller does not have the manage_storage_quotas permission.\"\"\"\r\n        if storage_quota_mb is not None:\r\n            data[\"storage_quota_mb\"] = storage_quota_mb\r\n\r\n        self.logger.debug(\"POST /api/v1/groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef edit_group(self, group_id, avatar_id=None, description=None, is_public=None, join_level=None, members=None, name=None, storage_quota_mb=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - name\r\n        \"\"\"The name of the group\"\"\"\r\n        if name is not None:\r\n            data[\"name\"] = name\r\n\r\n        # OPTIONAL - description\r\n        \"\"\"A description of the group\"\"\"\r\n        if description is not None:\r\n            data[\"description\"] = description\r\n\r\n        # OPTIONAL - is_public\r\n        \"\"\"Whether the group is public (applies only to community groups). Currently\r\n        you cannot set a group back to private once it has been made public.\"\"\"\r\n        if is_public is not None:\r\n            data[\"is_public\"] = is_public\r\n\r\n        # OPTIONAL - join_level\r\n        \"\"\"no description\"\"\"\r\n        if join_level is not None:\r\n            self._validate_enum(join_level, [\"parent_context_auto_join\", \"parent_context_request\", \"invitation_only\"])\r\n            data[\"join_level\"] = join_level\r\n\r\n        # OPTIONAL - avatar_id\r\n        \"\"\"The id of the attachment previously uploaded to the group that you would\r\n        like to use as the avatar image for this group.\"\"\"\r\n        if avatar_id is not None:\r\n            data[\"avatar_id\"] = avatar_id\r\n\r\n        # OPTIONAL - storage_quota_mb\r\n        \"\"\"The allowed file storage for the group, in megabytes. This parameter is\r\n        ignored if the caller does not have the manage_storage_quotas permission.\"\"\"\r\n        if storage_quota_mb is not None:\r\n            data[\"storage_quota_mb\"] = storage_quota_mb\r\n\r\n        # OPTIONAL - members\r\n        \"\"\"An array of user ids for users you would like in the group.\r\n        Users not in the group will be sent invitations. Existing group\r\n        members who aren't in the list will be removed from the group.\"\"\"\r\n        if members is not None:\r\n            data[\"members\"] = members\r\n\r\n        self.logger.debug(\"PUT /api/v1/groups/{group_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/groups/{group_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Updates the attributes of a group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef invite_others_to_group(self, group_id, invitees):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - invitees\r\n        \"\"\"An array of email addresses to be sent invitations.\"\"\"\r\n        data[\"invitees\"] = invitees\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/invite with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/invite\".format(**path), data=data, params=params, no_data=True)", "response": "Invites others to a group. Sends an invitation to all supplied email addresses which will allow the others to join the group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_group_s_users(self, group_id, include=None, search_term=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name or full ID of the users to match and return in the\r\n        results list. Must be at least 3 characters.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"avatar_url\": Include users' avatar_urls.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"avatar_url\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/users\".format(**path), data=data, params=params, all_pages=True)", "response": "List group s users. Returns a list of users in the group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npreview processed html. Preview processed html content processed for this group.", "response": "def preview_processed_html(self, group_id, html=None):\r\n        \"\"\"\r\n        Preview processed html.\r\n\r\n        Preview html content processed for this group\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - html\r\n        \"\"\"The html content to process\"\"\"\r\n        if html is not None:\r\n            data[\"html\"] = html\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/preview_html with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/preview_html\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting the members of a group. Returns the list of members of the group.", "response": "def list_group_memberships(self, group_id, filter_states=None):\r\n        \"\"\"\r\n        List group memberships.\r\n\r\n        List the members of a group.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - filter_states\r\n        \"\"\"Only list memberships with the given workflow_states. By default it will\r\n        return all memberships.\"\"\"\r\n        if filter_states is not None:\r\n            self._validate_enum(filter_states, [\"accepted\", \"invited\", \"requested\"])\r\n            params[\"filter_states\"] = filter_states\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/memberships with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/memberships\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a single group membership. Returns the single group membership with the given membership id or user id.", "response": "def get_single_group_membership_memberships(self, group_id, membership_id):\r\n        \"\"\"\r\n        Get a single group membership.\r\n\r\n        Returns the group membership with the given membership id or user id.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - membership_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"membership_id\"] = membership_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/memberships/{membership_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/memberships/{membership_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_single_group_membership_users(self, user_id, group_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/users/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/users/{user_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Get a single group membership. Returns the single group membership with the given id or user id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a membership. Update a membership.", "response": "def update_membership_memberships(self, group_id, membership_id, moderator=None, workflow_state=None):\r\n        \"\"\"\r\n        Update a membership.\r\n\r\n        Accept a membership request, or add/remove moderator rights.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - membership_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"membership_id\"] = membership_id\r\n\r\n        # OPTIONAL - workflow_state\r\n        \"\"\"Currently, the only allowed value is \"accepted\"\"\"\"\r\n        if workflow_state is not None:\r\n            self._validate_enum(workflow_state, [\"accepted\"])\r\n            data[\"workflow_state\"] = workflow_state\r\n\r\n        # OPTIONAL - moderator\r\n        \"\"\"no description\"\"\"\r\n        if moderator is not None:\r\n            data[\"moderator\"] = moderator\r\n\r\n        self.logger.debug(\"PUT /api/v1/groups/{group_id}/memberships/{membership_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/groups/{group_id}/memberships/{membership_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a membership user. Update a membership request or add or remove moderator rights.", "response": "def update_membership_users(self, user_id, group_id, moderator=None, workflow_state=None):\r\n        \"\"\"\r\n        Update a membership.\r\n\r\n        Accept a membership request, or add/remove moderator rights.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - workflow_state\r\n        \"\"\"Currently, the only allowed value is \"accepted\"\"\"\"\r\n        if workflow_state is not None:\r\n            self._validate_enum(workflow_state, [\"accepted\"])\r\n            data[\"workflow_state\"] = workflow_state\r\n\r\n        # OPTIONAL - moderator\r\n        \"\"\"no description\"\"\"\r\n        if moderator is not None:\r\n            data[\"moderator\"] = moderator\r\n\r\n        self.logger.debug(\"PUT /api/v1/groups/{group_id}/users/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/groups/{group_id}/users/{user_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef leave_group_memberships(self, group_id, membership_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - membership_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"membership_id\"] = membership_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/groups/{group_id}/memberships/{membership_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/groups/{group_id}/memberships/{membership_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Leave a group. Leave a group if you are allowed to leave."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nleave a group. Leave a user.", "response": "def leave_group_users(self, user_id, group_id):\r\n        \"\"\"\r\n        Leave a group.\r\n\r\n        Leave a group if you are allowed to leave (some groups, such as sets of\r\n        course groups created by teachers, cannot be left). You may also use 'self'\r\n        in place of a membership_id.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/groups/{group_id}/users/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/groups/{group_id}/users/{user_id}\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_str(cls, string):\n        return cls([Literal.from_str(lit) for lit in string.split('+')])", "response": "Creates a clause from a given string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the Boolean evaluation of the clause with respect to a given state or assignment", "response": "def bool(self, state):\n        \"\"\"\n        Returns the Boolean evaluation of the clause with respect to a given state\n\n        Parameters\n        ----------\n        state : dict\n            Key-value mapping describing a Boolean state or assignment\n\n        Returns\n        -------\n        boolean\n            The evaluation of the clause with respect to the given state or assignment\n        \"\"\"\n        value = 1\n        for source, sign in self:\n            value = value and (state[source] if sign == 1 else not state[source])\n            if not value:\n                break\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare_dbs(self, db_x, db_y, show=True):\n        # TODO: Improve method\n        self._printer(\"\\tComparing database's {0} and {1}\".format(db_x, db_y))\n\n        # Run compare_dbs_getter to get row counts\n        x = self._compare_dbs_getter(db_x)\n        y = self._compare_dbs_getter(db_y)\n        x_tbl_count = len(list(x.keys()))\n        y_tbl_count = len(list(y.keys()))\n\n        # Check that database does not have zero tables\n        if x_tbl_count == 0:\n            self._printer('\\tThe database {0} has no tables'.format(db_x))\n            self._printer('\\tDatabase differencing was not run')\n            return None\n        elif y_tbl_count == 0:\n            self._printer('\\tThe database {0} has no tables'.format(db_y))\n            self._printer('\\tDatabase differencing was not run')\n            return None\n\n        # Print comparisons\n        if show:\n            uniques_x = diff(x, y, x_only=True)\n            if len(uniques_x) > 0:\n                self._printer('\\nUnique keys from {0} ({1} of {2}):'.format(db_x, len(uniques_x), x_tbl_count))\n                self._printer('------------------------------')\n                # print(uniques)\n                for k, v in sorted(uniques_x):\n                    self._printer('{0:25} {1}'.format(k, v))\n                self._printer('\\n')\n\n            uniques_y = diff(x, y, y_only=True)\n            if len(uniques_y) > 0:\n                self._printer('Unique keys from {0} ({1} of {2}):'.format(db_y, len(uniques_y), y_tbl_count))\n                self._printer('------------------------------')\n                for k, v in sorted(uniques_y):\n                    self._printer('{0:25} {1}'.format(k, v))\n                self._printer('\\n')\n\n            if len(uniques_y) == 0 and len(uniques_y) == 0:\n                self._printer(\"Databases's {0} and {1} are identical:\".format(db_x, db_y))\n                self._printer('------------------------------')\n\n        return diff(x, y)", "response": "Compare the tables and row counts of two databases."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a dictionary of table_name row count key value pairs for a DB.", "response": "def _compare_dbs_getter(self, db):\n        \"\"\"Retrieve a dictionary of table_name, row count key value pairs for a DB.\"\"\"\n        # Change DB connection if needed\n        if self.database != db:\n            self.change_db(db)\n        return self.count_rows_all()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare_schemas(self, db_x, db_y, show=True):\n        # TODO: Improve method\n        self._printer(\"\\tComparing database schema's {0} and {1}\".format(db_x, db_y))\n\n        # Run compare_dbs_getter to get row counts\n        x = self._schema_getter(db_x)\n        y = self._schema_getter(db_y)\n        x_count = len(x)\n        y_count = len(y)\n\n        # Check that database does not have zero tables\n        if x_count == 0:\n            self._printer('\\tThe database {0} has no tables'.format(db_x))\n            self._printer('\\tDatabase differencing was not run')\n            return None\n        elif y_count == 0:\n            self._printer('\\tThe database {0} has no tables'.format(db_y))\n            self._printer('\\tDatabase differencing was not run')\n            return None\n\n        # Print comparisons\n        if show:\n            uniques_x = diff(x, y, x_only=True)\n            if len(uniques_x) > 0:\n                self._printer('\\nUnique keys from {0} ({1} of {2}):'.format(db_x, len(uniques_x), x_count))\n                self._printer('------------------------------')\n                # print(uniques)\n                for k, v in sorted(uniques_x):\n                    self._printer('{0:25} {1}'.format(k, v))\n                self._printer('\\n')\n\n            uniques_y = diff(x, y, y_only=True)\n            if len(uniques_y) > 0:\n                self._printer('Unique keys from {0} ({1} of {2}):'.format(db_y, len(uniques_y), y_count))\n                self._printer('------------------------------')\n                for k, v in sorted(uniques_y):\n                    self._printer('{0:25} {1}'.format(k, v))\n                self._printer('\\n')\n\n            if len(uniques_y) == 0 and len(uniques_y) == 0:\n                self._printer(\"Databases's {0} and {1} are identical:\".format(db_x, db_y))\n                self._printer('------------------------------')\n\n        return diff(x, y)", "response": "Compare the structures of two databases and compares the column definitions of each table\n            in each database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _schema_getter(self, db):\n        # Change DB connection if needed\n        if self.database != db:\n            self.change_db(db)\n        schema_dict = {tbl: self.get_schema(tbl) for tbl in self.tables}\n\n        schema_lst = []\n        for table, schema in schema_dict.items():\n            for col in schema:\n                col.insert(0, table)\n                schema_lst.append(col)\n        return schema_lst", "response": "Retrieve a dictionary representing a database s data schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nputting function results into cache.", "response": "def put_cache_results(self, key, func_akw, set_cache_cb):\n        \"\"\"Put function results into cache.\"\"\"\n        args, kwargs = func_akw\n\n        # get function results\n        func_results = self.func(*args, **kwargs)\n\n        # optionally add results to cache\n        if set_cache_cb(func_results):\n            self[key] = func_results\n        return func_results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef service_param_string(params):\r\n    p = []\r\n    k = []\r\n    for param in params:\r\n        name = fix_param_name(param['name'])\r\n        if 'required' in param and param['required'] is True:\r\n            p.append(name)\r\n        else:\r\n            if 'default' in param:\r\n                k.append('{name}={default}'.format(name=name, default=param['default']))\r\n            else:\r\n                k.append('{name}=None'.format(name=name))\r\n    p.sort(lambda a, b: len(a) - len(b))\r\n    k.sort()\r\n    a = p + k\r\n    return ', '.join(a)", "response": "Takes a param section from a metadata class and returns a param string for the service method"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_metadata_class(specfile):\r\n    with open(specfile) as f:\r\n        spec = json.load(f)\r\n        name = os.path.basename(specfile).split('.')[0]\r\n        spec['name'] = name\r\n\r\n        env = get_jinja_env()\r\n\r\n        metadata_template = env.get_template('metadata.py.jinja2')\r\n        with open('pycanvas/meta/{}.py'.format(name), 'w') as t:\r\n            t.write(metadata_template.render(spec=spec))", "response": "Generate a metadata class for the specified specfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_model_classes(metadata):\r\n    i = importlib.import_module(metadata)\r\n    env = get_jinja_env()\r\n    model_template = env.get_template('model.py.jinja2')\r\n    for model in i.models:\r\n        with open(model_path(model.name.lower()), 'w') as t:\r\n            t.write(model_template.render(model_md=model))", "response": "Generate a model class for any models contained in the specified spec file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_service_class(metadata):\r\n    i = importlib.import_module(metadata)\r\n    service = i.service\r\n    env = get_jinja_env()\r\n    service_template = env.get_template('service.py.jinja2')\r\n    with open(api_path(service.name.lower()), 'w') as t:\r\n        t.write(service_template.render(service_md=service))", "response": "Generate a service class for the service contained in the specified metadata class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a Report. Returns the report instance for the account.", "response": "def start_report(self, report, account_id, _parameters=None):\r\n        \"\"\"\r\n        Start a Report.\r\n\r\n        Generates a report instance for the account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - report\r\n        \"\"\"ID\"\"\"\r\n        path[\"report\"] = report\r\n\r\n        # OPTIONAL - [parameters]\r\n        \"\"\"The parameters will vary for each report\"\"\"\r\n        if _parameters is not None:\r\n            data[\"[parameters]\"] = _parameters\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/reports/{report} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/reports/{report}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the index of all reports in the specified account.", "response": "def index_of_reports(self, report, account_id):\r\n        \"\"\"\r\n        Index of Reports.\r\n\r\n        Shows all reports that have been run for the account of a specific type.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - report\r\n        \"\"\"ID\"\"\"\r\n        path[\"report\"] = report\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/reports/{report} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/reports/{report}\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove any None value from an elasticsearch query.", "response": "def clean_query(self):\n        \"\"\"\n        Removes any `None` value from an elasticsearch query.\n        \"\"\"\n        if self.query:\n            for key, value in self.query.items():\n                if isinstance(value, list) and None in value:\n                    self.query[key] = [v for v in value if v is not None]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the first 3 content objects in the included_ids", "response": "def get_recirc_content(self, published=True, count=3):\n        \"\"\"gets the first 3 content objects in the `included_ids`\n        \"\"\"\n        query = self.get_query()\n\n        # check if query has included_ids & if there are any ids in it,\n        # in case the ids have been removed from the array\n        if not query.get('included_ids'):\n            qs = Content.search_objects.search()\n            qs = qs.query(\n                TagBoost(slugs=self.tags.values_list(\"slug\", flat=True))\n            ).filter(\n                ~Ids(values=[self.id])\n            ).sort(\n                \"_score\"\n            )\n            return qs[:count]\n\n        # NOTE: set included_ids to just be the first 3 ids,\n        # otherwise search will return last 3 items\n        query['included_ids'] = query['included_ids'][:count]\n        search = custom_search_model(Content, query, published=published, field_map={\n            \"feature_type\": \"feature_type.slug\",\n            \"tag\": \"tags.slug\",\n            \"content-type\": \"_type\"\n        })\n        return search"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_full_recirc_content(self, published=True):\n        q = self.get_query()\n        search = custom_search_model(Content, q, published=published, field_map={\n            \"feature_type\": \"feature_type.slug\",\n            \"tag\": \"tags.slug\",\n            \"content-type\": \"_type\"\n        })\n        return search", "response": "performs es search and gets all content objects\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the object has pinned content", "response": "def has_pinned_content(self):\n        \"\"\"determines if the there is a pinned object in the search\n        \"\"\"\n        q = self.get_query()\n        if \"pinned_ids\" in q:\n            return bool(len(q.get(\"pinned_ids\", [])))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_later(self, callable_, timeout, *args, **kwargs):\n\n        self.lock.acquire()\n        try:\n            if self.die:\n                raise RuntimeError('This timer has been shut down and '\n                                   'does not accept new jobs.')\n\n            job = TimerTask(callable_, *args, **kwargs)\n            self._jobs.append((job, time.time() + timeout))\n            self._jobs.sort(key=lambda j: j[1])  # sort on time\n            self.lock.notify()\n\n            return job\n        finally:\n            self.lock.release()", "response": "Schedules the specified callable for delayed execution. Returns a TimerTask instance that can be used to cancel pending jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_front_page_groups(self, group_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/front_page with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/front_page\".format(**path), data=data, params=params, single_item=True)", "response": "Show front page. Show front page. Returns the front page content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_create_front_page_courses(self, course_id, wiki_page_body=None, wiki_page_editing_roles=None, wiki_page_notify_of_update=None, wiki_page_published=None, wiki_page_title=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - wiki_page[title]\r\n        \"\"\"The title for the new page. NOTE: changing a page's title will change its\r\n        url. The updated url will be returned in the result.\"\"\"\r\n        if wiki_page_title is not None:\r\n            data[\"wiki_page[title]\"] = wiki_page_title\r\n\r\n        # OPTIONAL - wiki_page[body]\r\n        \"\"\"The content for the new page.\"\"\"\r\n        if wiki_page_body is not None:\r\n            data[\"wiki_page[body]\"] = wiki_page_body\r\n\r\n        # OPTIONAL - wiki_page[editing_roles]\r\n        \"\"\"Which user roles are allowed to edit this page. Any combination\r\n        of these roles is allowed (separated by commas).\r\n        \r\n        \"teachers\":: Allows editing by teachers in the course.\r\n        \"students\":: Allows editing by students in the course.\r\n        \"members\":: For group wikis, allows editing by members of the group.\r\n        \"public\":: Allows editing by any user.\"\"\"\r\n        if wiki_page_editing_roles is not None:\r\n            self._validate_enum(wiki_page_editing_roles, [\"teachers\", \"students\", \"members\", \"public\"])\r\n            data[\"wiki_page[editing_roles]\"] = wiki_page_editing_roles\r\n\r\n        # OPTIONAL - wiki_page[notify_of_update]\r\n        \"\"\"Whether participants should be notified when this page changes.\"\"\"\r\n        if wiki_page_notify_of_update is not None:\r\n            data[\"wiki_page[notify_of_update]\"] = wiki_page_notify_of_update\r\n\r\n        # OPTIONAL - wiki_page[published]\r\n        \"\"\"Whether the page is published (true) or draft state (false).\"\"\"\r\n        if wiki_page_published is not None:\r\n            data[\"wiki_page[published]\"] = wiki_page_published\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/front_page with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/front_page\".format(**path), data=data, params=params, single_item=True)", "response": "Updates the wiki page with the given attributes and returns the updated url."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the pages associated with a course or group. Returns a list of pages associated with a course or group.", "response": "def list_pages_courses(self, course_id, order=None, published=None, search_term=None, sort=None):\r\n        \"\"\"\r\n        List pages.\r\n\r\n        List the wiki pages associated with a course or group\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - sort\r\n        \"\"\"Sort results by this field.\"\"\"\r\n        if sort is not None:\r\n            self._validate_enum(sort, [\"title\", \"created_at\", \"updated_at\"])\r\n            params[\"sort\"] = sort\r\n\r\n        # OPTIONAL - order\r\n        \"\"\"The sorting order. Defaults to 'asc'.\"\"\"\r\n        if order is not None:\r\n            self._validate_enum(order, [\"asc\", \"desc\"])\r\n            params[\"order\"] = order\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial title of the pages to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - published\r\n        \"\"\"If true, include only published paqes. If false, exclude published\r\n        pages. If not present, do not filter on published status.\"\"\"\r\n        if published is not None:\r\n            params[\"published\"] = published\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/pages with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/pages\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists pages associated with a course or group. Returns a list of pages associated with a course or group.", "response": "def list_pages_groups(self, group_id, order=None, published=None, search_term=None, sort=None):\r\n        \"\"\"\r\n        List pages.\r\n\r\n        List the wiki pages associated with a course or group\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - sort\r\n        \"\"\"Sort results by this field.\"\"\"\r\n        if sort is not None:\r\n            self._validate_enum(sort, [\"title\", \"created_at\", \"updated_at\"])\r\n            params[\"sort\"] = sort\r\n\r\n        # OPTIONAL - order\r\n        \"\"\"The sorting order. Defaults to 'asc'.\"\"\"\r\n        if order is not None:\r\n            self._validate_enum(order, [\"asc\", \"desc\"])\r\n            params[\"order\"] = order\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial title of the pages to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - published\r\n        \"\"\"If true, include only published paqes. If false, exclude published\r\n        pages. If not present, do not filter on published status.\"\"\"\r\n        if published is not None:\r\n            params[\"published\"] = published\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/pages with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/pages\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_page_courses(self, url, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - url\r\n        \"\"\"ID\"\"\"\r\n        path[\"url\"] = url\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/pages/{url} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/pages/{url}\".format(**path), data=data, params=params, single_item=True)", "response": "Show page. Show page. Retrieve the content of a wiki page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow page. Show page. Retrieve the content of a wiki page.", "response": "def show_page_groups(self, url, group_id):\r\n        \"\"\"\r\n        Show page.\r\n\r\n        Retrieve the content of a wiki page\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - url\r\n        \"\"\"ID\"\"\"\r\n        path[\"url\"] = url\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/pages/{url} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/pages/{url}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_revisions_courses(self, url, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - url\r\n        \"\"\"ID\"\"\"\r\n        path[\"url\"] = url\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/pages/{url}/revisions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/pages/{url}/revisions\".format(**path), data=data, params=params, all_pages=True)", "response": "List the revisions of a page. Returns a list of the revisions of a page."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists the revisions of a group. Returns a list of the revisions of a group.", "response": "def list_revisions_groups(self, url, group_id):\r\n        \"\"\"\r\n        List revisions.\r\n\r\n        List the revisions of a page. Callers must have update rights on the page in order to see page history.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - url\r\n        \"\"\"ID\"\"\"\r\n        path[\"url\"] = url\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/pages/{url}/revisions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/pages/{url}/revisions\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert to natural key.", "response": "def to_representation(self, value):\n        \"\"\"Convert to natural key.\"\"\"\n        content_type = ContentType.objects.get_for_id(value)\n        return \"_\".join(content_type.natural_key())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_internal_value(self, value):\n        natural_key = value.split(\"_\")\n        content_type = ContentType.objects.get_by_natural_key(*natural_key)\n        return content_type.id", "response": "Convert to integer id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_internal_value(self, value):\n        if value == \"\":\n            return None\n\n        if isinstance(value, string_types):\n            slug = slugify(value)\n            feature_type, created = FeatureType.objects.get_or_create(\n                slug=slug,\n                defaults={\"name\": value}\n            )\n        else:\n            if \"id\" in value:\n                feature_type = FeatureType.objects.get(id=value[\"id\"])\n            elif \"slug\" in value:\n                feature_type = FeatureType.objects.get(slug=value[\"slug\"])\n            else:\n                raise ValidationError(\"Invalid feature type data\")\n        return feature_type", "response": "Basically it s a simple dict with id name and slug and returns a FeatureType object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef watch(directory=None, auto_clear=False, extensions=[]):\n    if directory and not os.path.isdir(directory):\n        raise ValueError('Directory not found: ' + directory)\n    directory = os.path.abspath(directory)\n\n    # Initial run\n    event_handler = ChangeHandler(directory, auto_clear, extensions)\n    event_handler.run()\n\n    # Setup watchdog\n    observer = Observer()\n    observer.schedule(event_handler, path=directory, recursive=True)\n    observer.start()\n\n    # Watch and run tests until interrupted by user\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()", "response": "Starts a server to render the specified file or directory containing a README."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when a file is changed to re - run the tests with nose.", "response": "def run(self):\n        \"\"\"Called when a file is changed to re-run the tests with nose.\"\"\"\n        if self.auto_clear:\n            os.system('cls' if os.name == 'nt' else 'auto_clear')\n        else:\n            print\n        print 'Running unit tests...'\n        if self.auto_clear:\n            print\n        subprocess.call('nosetests', cwd=self.directory)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting all of the output data files in the current directory to. tex", "response": "def write_tex():\n    \"\"\"\n    Finds all of the output data files, and writes them out to .tex\n    \"\"\"\n    datadir = livvkit.index_dir\n    outdir = os.path.join(datadir, \"tex\")\n    print(outdir)\n    # functions.mkdir_p(outdir)\n\n    data_files = glob.glob(datadir + \"/**/*.json\", recursive=True)\n\n    for each in data_files:\n        data = functions.read_json(each)\n        tex = translate_page(data)\n        outfile = os.path.join(outdir, os.path.basename(each).replace('json', 'tex'))\n        with open(outfile, 'w') as f:\n            f.write(tex)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef translate_page(data):\n    if \"Page\" != data[\"Type\"]:\n        return \"\"\n\n    tex_str = ('\\\\documentclass{article}\\\\n' +\n               '\\\\usepackage{placeins}\\\\n' +\n               '\\\\title{LIVVkit}\\\\n' +\n               '\\\\author{$USER}\\\\n' +\n               '\\\\usepackage[parfill]{parskip}\\\\n' +\n               '\\\\begin{document}\\\\n' +\n               '\\\\maketitle\\\\n'\n               ).replace('$USER', livvkit.user)\n\n    content = data[\"Data\"]\n    for tag_name in [\"Elements\", \"Tabs\"]:\n        for tag in content.get(tag_name, []):\n                print(\"Translating \" + tag[\"Type\"])\n                tex_str += translate_map[tag[\"Type\"]](tag)\n\n    tex_str += '\\n\\\\end{document}'\n    return tex_str", "response": "Translate a page element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef translate_section(data):\n    sect_str = \"\"\n    elements = data.get(\"Elements\", [])\n    for elem in elements:\n            print(\"    Translating \" + elem[\"Type\"])\n            sect_str += translate_map[elem[\"Type\"]](elem)\n    return sect_str", "response": "Translate a section into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef translate_tab(data):\n    tab_str = \"\"\n    sections = data.get(\"Sections\", [])\n    for section in sections:\n            print(\"  Translating \" + section[\"Type\"])\n            tab_str += translate_map[section[\"Type\"]](section)\n    return tab_str", "response": "Translate a tab data structure into a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef translate_summary(data):\n    headers = sorted(data.get(\"Headers\", []))\n    summary = '\\\\FloatBarrier \\n \\\\section{$NAME} \\n'.replace('$NAME', data.get(\"Title\", \"table\"))\n    summary += ' \\\\begin{table}[!ht] \\n \\\\begin{center}'\n\n    # Set the number of columns\n    n_cols = len(headers)\n    col_str = \"l\" + \"c\" * n_cols\n    summary += '\\n \\\\begin{tabular}{$NCOLS} \\n'.replace(\"$NCOLS\", col_str)\n    spacer = ' &' * n_cols + r'\\\\[.5em]'\n\n    for header in headers:\n        summary += '& $HEADER '.replace('$HEADER', header).replace('%', '\\%')\n    summary += ' \\\\\\\\ \\hline \\n'\n\n    names = sorted(six.iterkeys(data.get(\"Data\", [])))\n    for name in names:\n        summary += '\\n\\n \\\\textbf{{{}}} {} \\n'.format(name, spacer)\n        cases = data.get(\"Data\", []).get(name, {})\n        for case, c_data in cases.items():\n            summary += ' $CASE & '.replace('$CASE', str(case))\n            for header in headers:\n                h_data = c_data.get(header, \"\")\n                if list is type(h_data) and len(h_data) == 2:\n                    summary += (' $H_DATA_0 of $H_DATA_1 &'\n                                .replace('$H_DATA_0', str(h_data[0]))\n                                .replace('$H_DATA_1', str(h_data[1]))\n                                .replace('%', '\\%'))\n                else:\n                    summary += ' $H_DATA &'.replace('$H_DATA', str(h_data)).replace('%', '\\%')\n\n            # This takes care of the trailing & that comes from processing the headers.\n            summary = summary[:-1] + r' \\\\'\n\n    summary += '\\n \\end{tabular} \\n \\end{center} \\n \\end{table}\\n'\n    return summary", "response": "Translate a Summary data into a single string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate a table into a single string.", "response": "def translate_table(data):\n    \"\"\" Translates data where data[\"Type\"]==\"Table\" \"\"\"\n    headers = sorted(data.get(\"Headers\", []))\n    table = '\\\\FloatBarrier \\n \\\\section{$NAME} \\n'.replace('$NAME', data.get(\"Title\", \"table\"))\n    table += '\\\\begin{table}[!ht] \\n \\\\begin{center}'\n\n    # Set the number of columns\n    n_cols = \"c\"*(len(headers)+1)\n    table += '\\n \\\\begin{tabular}{$NCOLS} \\n'.replace(\"$NCOLS\", n_cols)\n\n    # Put in the headers\n    for header in headers:\n        table += ' $HEADER &'.replace('$HEADER', header).replace('%', '\\%')\n    table = table[:-1] + ' \\\\\\\\ \\n \\hline \\n'\n\n    # Put in the data\n    for header in headers:\n        table += ' $VAL &'.replace(\"$VAL\", str(data[\"Data\"][header]))\n    table = table[:-1] + ' \\\\\\\\ \\n \\hline'\n    table += '\\n \\end{tabular} \\n \\end{center} \\n \\end{table}\\n'\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_bit_for_bit(data):\n    headers = sorted(data.get(\"Headers\", []))\n    table = '\\\\FloatBarrier \\n \\\\section{$NAME} \\n'.replace('$NAME', data.get(\"Title\", \"table\"))\n    table += '\\\\begin{table}[!ht] \\n \\\\begin{center}'\n    # Set the number of columns\n    n_cols = \"c\"*(len(headers)+1)\n    table += '\\n \\\\begin{tabular}{$NCOLS} \\n'.replace(\"$NCOLS\", n_cols)\n\n    # Put in the headers\n    table += \" Variable &\"\n    for header in headers:\n        table += ' $HEADER &'.replace('$HEADER', header).replace('%', '\\%')\n    table = table[:-1] + ' \\\\\\\\ \\n \\hline \\n'\n\n    # Put in the data\n    for k, v in data.get(\"Data\", []).items():\n        table += \"\\n \\\\textbf{$VAR} & \".replace(\"$VAR\", k)\n        for header in headers:\n            table += ' $VAL &'.replace(\"$VAL\", str(v[header]))\n        table = table[:-1] + ' \\\\\\\\'\n    table += '\\n \\hline \\n \\end{tabular} \\n \\end{center} \\n \\end{table}\\n'\n    return table", "response": "Translates a bit for bit data into a single table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntranslating file diff data into a diff file", "response": "def translate_file_diff(data):\n    \"\"\" Translates data where data[\"Type\"]==\"Diff\" \"\"\"\n    diff = '\\\\FloatBarrier \\section{Configuration}'\n    sections = data.get('Data')\n    for title, config in sections.items():\n        title = title.replace('_', '\\_')\n        diff += ' \\n \\\\subsection{$NAME}'.replace('$NAME', title)\n        for opt, vals in config.items():\n            opt = opt.replace('_', '\\_')\n            diff += '\\n\\n \\\\texttt{$NAME} : '.replace('$NAME', opt)\n            if vals[0]:\n                diff += '$NAME'.replace('$NAME', vals[-1])\n            else:\n                diff += ('{} \\\\textit{{{}}}'.format(vals[1], vals[-1]))\n    diff += '\\n\\n'\n    return diff"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke the command in a subprocess and return the output.", "response": "def _invoke(self, *params):\n\t\t\"\"\"\n\t\tInvoke self.exe as a subprocess\n\t\t\"\"\"\n\t\tcmd = [self.exe] + list(params)\n\t\tproc = subprocess.Popen(\n\t\t\tcmd, stdout=subprocess.PIPE,\n\t\t\tstderr=subprocess.PIPE, cwd=self.location, env=self.env)\n\t\tstdout, stderr = proc.communicate()\n\t\tif not proc.returncode == 0:\n\t\t\traise RuntimeError(stderr.strip() or stdout.strip())\n\t\treturn stdout.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping for a class decorator which allows for bare decorator and argument syntax", "response": "def allow_bare_decorator(cls):\n    \"\"\"\n    Wrapper for a class decorator which allows for bare decorator and argument syntax\n    \"\"\"\n\n    @wraps(cls)\n    def wrapper(*args, **kwargs):\n        \"\"\"\"Wrapper for real decorator\"\"\"\n\n        # If we weren't only passed a bare class, return class instance\n        if kwargs or len(args) != 1 or not isclass(args[0]):  # pylint: disable=no-else-return\n            return cls(*args, **kwargs)\n        # Otherwise, pass call to instance with default values\n        else:\n            return cls()(args[0])\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef warp_image_by_corner_points_projection(corner_points, image):\n    # Clarify by storing in named variables.\n    top_left, top_right, bottom_left, bottom_right = np.array(corner_points)\n\n    top_edge = np.linalg.norm(top_right - top_left)\n    bottom_edge = np.linalg.norm(bottom_right - bottom_left)\n    left_edge = np.linalg.norm(top_left - bottom_left)\n    right_edge = np.linalg.norm(top_right - bottom_right)\n\n    L = int(np.ceil(max([top_edge, bottom_edge, left_edge, right_edge])))\n    src = np.array([top_left, top_right, bottom_left, bottom_right])\n    dst = np.array([[0, 0], [L - 1, 0], [0, L - 1], [L - 1, L - 1]])\n\n    tr = ProjectiveTransform()\n    tr.estimate(dst, src)\n    warped_image = warp(image, tr, output_shape=(L, L))\n    out = resize(warped_image, (500, 500))\n\n    return out", "response": "This function warps original selection to a square image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncache the spec dict for the given version", "response": "def cache_spec(name, spec):\n    \"\"\"\n    Cache the spec dict\n    :param name: Version name\n    :param spec: Spec dict\n    :return: True if cached\n    \"\"\"\n    return cache.set(build_cache_name(name), spec, app_settings.ESI_SPEC_CACHE_DURATION)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a single Spec object from the cache.", "response": "def get_spec(name, http_client=None, config=None):\n    \"\"\"\n    :param name: Name of the revision of spec, eg latest or v4\n    :param http_client: Requests client used for retrieving specs\n    :param config: Spec configuration - see Spec.CONFIG_DEFAULTS\n    :return: :class:`bravado_core.spec.Spec`\n    \"\"\"\n    http_client = http_client or requests_client.RequestsClient()\n\n    def load_spec():\n        loader = Loader(http_client)\n        return loader.load_spec(build_spec_url(name))\n\n    spec_dict = cache.get_or_set(build_cache_name(name), load_spec, app_settings.ESI_SPEC_CACHE_DURATION)\n    config = dict(CONFIG_DEFAULTS, **(config or {}))\n    return Spec.from_dict(spec_dict, build_spec_url(name), http_client, config)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a base_spec with the specified base_version and returns it.", "response": "def build_spec(base_version, http_client=None, **kwargs):\n    \"\"\"\n    Generates the Spec used to initialize a SwaggerClient, supporting mixed resource versions\n    :param http_client: :class:`bravado.requests_client.RequestsClient`\n    :param base_version: Version to base the spec on. Any resource without an explicit version will be this.\n    :param kwargs: Explicit resource versions, by name (eg Character='v4')\n    :return: :class:`bravado_core.spec.Spec`\n    \"\"\"\n    base_spec = get_spec(base_version, http_client=http_client, config=SPEC_CONFIG)\n    if kwargs:\n        for resource, resource_version in kwargs.items():\n            versioned_spec = get_spec(resource_version, http_client=http_client, config=SPEC_CONFIG)\n            try:\n                spec_resource = versioned_spec.resources[resource.capitalize()]\n            except KeyError:\n                raise AttributeError(\n                    'Resource {0} not found on API revision {1}'.format(resource, resource_version))\n            base_spec.resources[resource.capitalize()] = spec_resource\n    return base_spec"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_spec(path, http_client=None):\n    with open(path, 'r') as f:\n        spec_dict = json.loads(f.read())\n\n    return SwaggerClient.from_spec(spec_dict, http_client=http_client, config=SPEC_CONFIG)", "response": "Reads in a swagger spec file used to initialize a SwaggerClient"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate an ESI client.", "response": "def esi_client_factory(token=None, datasource=None, spec_file=None, version=None, **kwargs):\n    \"\"\"\n    Generates an ESI client.\n    :param token: :class:`esi.Token` used to access authenticated endpoints.\n    :param datasource: Name of the ESI datasource to access.\n    :param spec_file: Absolute path to a swagger spec file to load.\n    :param version: Base ESI API version. Accepted values are 'legacy', 'latest', 'dev', or 'vX' where X is a number.\n    :param kwargs: Explicit resource versions to build, in the form Character='v4'. Same values accepted as version.\n    :return: :class:`bravado.client.SwaggerClient`\n\n    If a spec_file is specified, specific versioning is not available. Meaning the version and resource version kwargs\n    are ignored in favour of the versions available in the spec_file.\n    \"\"\"\n\n    client = requests_client.RequestsClient()\n    if token or datasource:\n        client.authenticator = TokenAuthenticator(token=token, datasource=datasource)\n\n    api_version = version or app_settings.ESI_API_VERSION\n\n    if spec_file:\n        return read_spec(spec_file, http_client=client)\n    else:\n        spec = build_spec(api_version, http_client=client, **kwargs)\n        return SwaggerClient(spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntrims down a source spec dict to only the operations or resources indicated.", "response": "def minimize_spec(spec_dict, operations=None, resources=None):\n    \"\"\"\n    Trims down a source spec dict to only the operations or resources indicated.\n    :param spec_dict: The source spec dict to minimize.\n    :type spec_dict: dict\n    :param operations: A list of opertion IDs to retain.\n    :type operations: list of str\n    :param resources: A list of resource names to retain.\n    :type resources: list of str\n    :return: Minimized swagger spec dict\n    :rtype: dict\n    \"\"\"\n    operations = operations or []\n    resources = resources or []\n\n    # keep the ugly overhead for now but only add paths we need\n    minimized = {key: value for key, value in spec_dict.items() if key != 'paths'}\n    minimized['paths'] = {}\n\n    for path_name, path in spec_dict['paths'].items():\n        for method, data in path.items():\n            if data['operationId'] in operations or any(tag in resources for tag in data['tags']):\n                if path_name not in minimized['paths']:\n                    minimized['paths'][path_name] = {}\n                minimized['paths'][path_name][method] = data\n\n    return minimized"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the cache key used to cache responses from the API.", "response": "def _build_cache_key(request):\n        \"\"\"\n        Generated the key name used to cache responses\n        :param request: request used to retrieve API response\n        :return: formatted cache name\n        \"\"\"\n        str_hash = md5(\n            (request.method + request.url + str(request.params) + str(request.data) + str(request.json)).encode(\n                'utf-8')).hexdigest()\n        return 'esi_%s' % str_hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _time_to_expiry(expires):\n        try:\n            expires_dt = datetime.strptime(str(expires), '%a, %d %b %Y %H:%M:%S %Z')\n            delta = expires_dt - datetime.utcnow()\n            return delta.seconds\n        except ValueError:\n            return 0", "response": "Determines the seconds until a HTTP response header is expired"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_get_path(data, path, default=None):\n\n    keys = path.split(\".\")\n    for k in keys:\n        if type(data) == list:\n            found = False\n            for item in data:\n                name = item.get(\"name\", item.get(\"type\"))\n                if name == k:\n                    found = True\n                    data = item\n                    break\n            if not found:\n                return default\n        elif type(data) == dict:\n            if k in data:\n                data = data[k]\n            else:\n                return default\n        else:\n            return default\n    return data", "response": "Returns the value inside nested structure of data located at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a hypergraph from a base interaction graph.", "response": "def from_graph(cls, graph, length=0):\n        \"\"\"\n        Creates a hypergraph (expanded graph) from a :class:`caspo.core.graph.Graph` object instance\n\n        Parameters\n        ----------\n        graph : :class:`caspo.core.graph.Graph`\n            The base interaction graph to be expanded\n\n        length : int\n            Maximum length for hyperedges source sets. If 0, use maximum possible in each case.\n\n        Returns\n        -------\n        caspo.core.hypergraph.HyperGraph\n            Created object instance\n        \"\"\"\n        nodes = []\n        hyper = []\n        edges = defaultdict(list)\n        j = 0\n\n        for i, node in enumerate(graph.nodes_iter()):\n            nodes.append(node)\n\n            preds = graph.in_edges(node, data=True)\n            l = len(preds)\n            if length > 0:\n                l = min(length, l)\n\n            for literals in it.chain.from_iterable(it.combinations(preds, r+1) for r in xrange(l)):\n                valid = defaultdict(int)\n                for source, _, _ in literals:\n                    valid[source] += 1\n\n                if all(it.imap(lambda c: c == 1, valid.values())):\n                    hyper.append(i)\n                    for source, _, data in literals:\n                        edges['hyper_idx'].append(j)\n                        edges['name'].append(source)\n                        edges['sign'].append(data['sign'])\n\n                    j += 1\n\n        nodes = pd.Series(nodes, name='name')\n        hyper = pd.Series(hyper, name='node_idx')\n        edges = pd.DataFrame(edges)\n\n        return cls(nodes, hyper, edges)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_funset(self):\n        fs = set()\n        for i, n in self.nodes.iteritems():\n            fs.add(gringo.Fun('node', [n, i]))\n\n        for j, i in self.hyper.iteritems():\n            fs.add(gringo.Fun('hyper', [i, j, len(self.edges[self.edges.hyper_idx == j])]))\n\n        for j, v, s in self.edges.itertuples(index=False):\n            fs.add(gringo.Fun('edge', [j, v, s]))\n\n        return fs", "response": "Converts the hypergraph to a set of gringo. Fun functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating calls from call_queue and places the results in result_queue. This worker is run in a seperate process. Args: call_queue: A multiprocessing.Queue of _CallItems that will be read and evaluated by the worker. result_queue: A multiprocessing.Queue of _ResultItems that will written to by the worker. shutdown: A multiprocessing.Event that will be set as a signal to the worker that it should exit when call_queue is empty.", "response": "def _process_worker(call_queue, result_queue, shutdown):\n    \"\"\"Evaluates calls from call_queue and places the results in result_queue.\n\n    This worker is run in a seperate process.\n\n    Args:\n        call_queue: A multiprocessing.Queue of _CallItems that will be read and\n            evaluated by the worker.\n        result_queue: A multiprocessing.Queue of _ResultItems that will written\n            to by the worker.\n        shutdown: A multiprocessing.Event that will be set as a signal to the\n            worker that it should exit when call_queue is empty.\n    \"\"\"\n    while True:\n        try:\n            call_item = call_queue.get(block=True, timeout=0.1)\n        except queue.Empty:\n            if shutdown.is_set():\n                return\n        else:\n            try:\n                r = call_item()\n            except BaseException as e:\n                result_queue.put(_ResultItem(call_item.work_id, exception=e))\n            else:\n                result_queue.put(_ResultItem(call_item.work_id, result=r))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmanaging the communication between this process and the worker processes. This function is run in a local thread. Args: executor_reference: A weakref.ref to the ProcessPoolExecutor that owns this thread. Used to determine if the ProcessPoolExecutor has been garbage collected and that this function can exit. process: A list of the multiprocessing.Process instances used as workers. pending_work_items: A dict mapping work ids to _WorkItems e.g. {5: <_WorkItem...>, 6: <_WorkItem...>, ...} work_ids_queue: A queue.Queue of work ids e.g. Queue([5, 6, ...]). call_queue: A multiprocessing.Queue that will be filled with _CallItems derived from _WorkItems for processing by the process workers. result_queue: A multiprocessing.Queue of _ResultItems generated by the process workers. shutdown_process_event: A multiprocessing.Event used to signal the process workers that they should exit when their work queue is empty.", "response": "def _queue_manangement_worker(executor_reference,\n                              processes,\n                              pending_work_items,\n                              work_ids_queue,\n                              call_queue,\n                              result_queue,\n                              shutdown_process_event):\n    \"\"\"Manages the communication between this process and the worker processes.\n\n    This function is run in a local thread.\n\n    Args:\n        executor_reference: A weakref.ref to the ProcessPoolExecutor that owns\n            this thread. Used to determine if the ProcessPoolExecutor has been\n            garbage collected and that this function can exit.\n        process: A list of the multiprocessing.Process instances used as\n            workers.\n        pending_work_items: A dict mapping work ids to _WorkItems e.g.\n            {5: <_WorkItem...>, 6: <_WorkItem...>, ...}\n        work_ids_queue: A queue.Queue of work ids e.g. Queue([5, 6, ...]).\n        call_queue: A multiprocessing.Queue that will be filled with _CallItems\n            derived from _WorkItems for processing by the process workers.\n        result_queue: A multiprocessing.Queue of _ResultItems generated by the\n            process workers.\n        shutdown_process_event: A multiprocessing.Event used to signal the\n            process workers that they should exit when their work queue is\n            empty.\n    \"\"\"\n    while True:\n        _add_call_item_to_queue(pending_work_items,\n                                work_ids_queue,\n                                call_queue)\n\n        try:\n            result_item = result_queue.get(block=True, timeout=0.1)\n        except queue.Empty:\n            executor = executor_reference()\n            # No more work items can be added if:\n            #   - The interpreter is shutting down OR\n            #   - The executor that owns this worker has been collected OR\n            #   - The executor that owns this worker has been shutdown.\n            if _shutdown or executor is None or executor._shutdown_thread:\n                # Since no new work items can be added, it is safe to shutdown\n                # this thread if there are no pending work items.\n                if not pending_work_items:\n                    shutdown_process_event.set()\n\n                    # If .join() is not called on the created processes then\n                    # some multiprocessing.Queue methods may deadlock on Mac OSX.\n                    for p in processes:\n                        p.join()\n                    return\n            del executor\n        else:\n            work_item = pending_work_items.pop(result_item.work_id)\n            loop = work_item.loop\n            loop.call_from_thread(_set_work_result, work_item, result_item)\n            del result_item, work_item, loop"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshare options used by all bartender commands", "response": "def options(f):\n    \"\"\"\n    Shared options, used by all bartender commands\n    \"\"\"\n\n    f = click.option('--config', envvar='VODKA_HOME', default=click.get_app_dir('vodka'), help=\"location of config file\")(f)\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck and validate configuration attributes", "response": "def check_config(config):\n    \"\"\"\n    Check and validate configuration attributes, to help administrators\n    quickly spot missing required configurations and invalid configuration\n    values in general\n    \"\"\"\n\n\n    cfg = vodka.config.Config(read=config)\n\n    vodka.log.set_loggers(cfg.get(\"logging\"))\n    vodka.app.load_all(cfg)\n\n    click.echo(\"Checking config at %s for errors ...\" % config)\n\n    num_crit, num_warn = vodka.config.InstanceHandler.validate(cfg)\n\n    click.echo(\"%d config ERRORS, %d config WARNINGS\" % (num_crit, num_warn))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config(config, skip_defaults):\n\n    configurator = ClickConfigurator(\n        vodka.plugin,\n        skip_defaults=skip_defaults\n    )\n\n    configurator.configure(vodka.config.instance, vodka.config.InstanceHandler)\n\n    try:\n        dst = munge_config.parse_url(config)\n    except ValueError:\n        config = os.path.join(config, \"config.yaml\")\n        dst = munge_config.parse_url(config)\n\n    config_dir = os.path.dirname(config)\n    if not os.path.exists(config_dir) and config_dir:\n        os.makedirs(config_dir)\n\n    dst.cls().dumpu(vodka.config.instance, dst.url.path)\n\n    if configurator.action_required:\n        click.echo(\"\")\n        click.echo(\"not all required values could be set by this script, please manually edit the config and set the following values\")\n        click.echo(\"\")\n        for item in configurator.action_required:\n            click.echo(\"- %s\" % item)\n        click.echo(\"\")\n\n    click.echo(\"Config written to %s\" % dst.url.path)", "response": "Generates configuration file from config specifications"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef newapp(path):\n\n    app_path = os.path.join(VODKA_INSTALL_DIR, \"resources\", \"blank_app\")\n    if not os.path.exists(path):\n        os.makedirs(path)\n    elif os.path.exists(os.path.join(path, \"application.py\")):\n        click.error(\"There already exists a vodka app at %s, please specify a different path\" % path)\n    os.makedirs(os.path.join(path, \"plugins\"))\n    shutil.copy(os.path.join(app_path, \"application.py\"), os.path.join(path, \"application.py\"))\n    shutil.copy(os.path.join(app_path, \"__init__.py\"), os.path.join(path, \"__init__.py\"))\n    shutil.copy(os.path.join(app_path, \"plugins\", \"example.py\"), os.path.join(path, \"plugins\", \"example.py\"))\n    shutil.copy(os.path.join(app_path, \"plugins\", \"__init__.py\"), os.path.join(path, \"plugins\", \"__init__.py\"))", "response": "Generate all files for a new vodka app at the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serve(config):\n\n    cfg = vodka.config.Config(read=config)\n    vodka.run(cfg, cfg)", "response": "Serves the vodka application"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Email(msg=None):\n    '''\n    Valida endere\u00e7os de email\n    '''\n    def f(v):\n        if re.match(\"[\\w\\.\\-]*@[\\w\\.\\-]*\\.\\w+\", str(v)):\n            return str(v)\n        else:\n            raise Invalid(msg or (\"Endereco de email invalido\"))\n    return f", "response": "Valida endere\u00e7os de email."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if bcrypt should be used.", "response": "def is_enabled():\n    \"\"\"Returns ``True`` if bcrypt should be used.\"\"\"\n    enabled = getattr(settings, \"BCRYPT_ENABLED\", True)\n    if not enabled:\n        return False\n    # Are we under a test?\n    if hasattr(mail, 'outbox'):\n        return getattr(settings, \"BCRYPT_ENABLED_UNDER_TEST\", False)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bcrypt_check_password(self, raw_password):\n    pwd_ok = False\n    should_change = False\n    if self.password.startswith('bc$'):\n        salt_and_hash = self.password[3:]\n        pwd_ok = bcrypt.hashpw(smart_str(raw_password), salt_and_hash) == salt_and_hash\n        if pwd_ok:\n            rounds = int(salt_and_hash.split('$')[2])\n            should_change = rounds != get_rounds()\n    elif _check_password(self, raw_password):\n        pwd_ok = True\n        should_change = True\n\n    if pwd_ok and should_change and is_enabled() and migrate_to_bcrypt():\n        self.set_password(raw_password)\n        salt_and_hash = self.password[3:]\n        assert bcrypt.hashpw(raw_password, salt_and_hash) == salt_and_hash\n        self.save()\n\n    return pwd_ok", "response": "Checks the password against the bcrypt hash of the user and saves the changes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the user s password to raw_password hashed with bcrypt.", "response": "def bcrypt_set_password(self, raw_password):\n    \"\"\"\n    Sets the user's password to *raw_password*, hashed with bcrypt.\n    \"\"\"\n    if not is_enabled() or raw_password is None:\n        _set_password(self, raw_password)\n    else:\n        salt = bcrypt.gensalt(get_rounds())\n        self.password = 'bc$' + bcrypt.hashpw(smart_str(raw_password), salt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the given application is installed on this OS X system.", "response": "def mac_app_exists(app):\n\t'''Check if 'app' is installed (OS X).\n\n\tCheck if the given applications is installed on this OS X system.\n\n\tArgs:\n\t\t\tapp (str): The application name.\n\n\tReturns:\n\t\t\tbool: Is the app installed or not?\n\t'''\n\n\tAPP_CHECK_APPLESCRIPT = '''try\n\ttell application \"Finder\"\n\t\tset appname to name of application file id \"%s\"\n\t\treturn 0\n\tend tell\n\ton error err_msg number err_num\n\t\treturn 1\n\tend try'''\n\n\twith open('/tmp/app_check.AppleScript', 'w') as f:\n\t\tf.write(APP_CHECK_APPLESCRIPT % app)\n\n\tapp_check_proc = sp.Popen(\n\t\t['osascript', '-e', '/tmp/app_check.AppleScript'])\n\n\tif app_check_proc.wait() != 0:\n\t\treturn False\n\n\telse:\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a file with the default program for that type.", "response": "def open_file_with_default_program(file_path,\n\t\t\t\t\t\t\t\t   background=False, return_cmd=False):\n\t'''Opens a file with the default program for that type.\n\n\tOpen the file with the user's preferred application.\n\n\tArgs:\n\t\t\tfile_path  (str) : Path to the file to be opened.\n\t\t\tbackground (bool): Run the program in the background, instead of waiting for completion. Defaults to ``False``.\n\t\t\treturn_cmd (bool): Returns the command to run the program (str) instead of running it. Defaults to ``False``.\n\n\tReturns:\n\t\t\tstr: Only if ``return_cmd``, the command to run the program is returned instead of running it. Else returns nothing.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif desktop_env == 'windows':\n\t\topen_file_cmd = 'explorer.exe ' + \"'%s'\" % file_path\n\n\telif desktop_env == 'mac':\n\t\topen_file_cmd = 'open ' + \"'%s'\" % file_path\n\n\telse:\n\t\tfile_mime_type = system.get_cmd_out(\n\t\t\t['xdg-mime', 'query', 'filetype', file_path])\n\t\tdesktop_file = system.get_cmd_out(\n\t\t\t['xdg-mime', 'query', 'default', file_mime_type])\n\t\topen_file_cmd = desktopfile.execute(desktopfile.locate(\n\t\t\tdesktop_file)[0], files=[file_path], return_cmd=True)\n\n\tif return_cmd:\n\t\treturn open_file_cmd\n\n\telse:\n\t\tdef_program_proc = sp.Popen(open_file_cmd, shell=True)\n\n\t\tif not background:\n\t\t\tdef_program_proc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the default terminal emulator.", "response": "def terminal(exec_='', background=False, shell_after_cmd_exec=False,\n\t\t\t keep_open_after_cmd_exec=False, return_cmd=False):\n\t'''Start the default terminal emulator.\n\n\tStart the user's preferred terminal emulator, optionally running a command in it.\n\n\t**Order of starting**\n\t\t\tWindows:\n\t\t\t\t\tPowershell\n\n\t\t\tMac:\n\t\t\t\t\t- iTerm2\n\t\t\t\t\t- Terminal.app\n\n\t\t\tLinux/Unix:\n\t\t\t\t\t- ``$TERMINAL``\n\t\t\t\t\t- ``x-terminal-emulator``\n\t\t\t\t\t- Terminator\n\t\t\t\t\t- Desktop environment's terminal\n\t\t\t\t\t- gnome-terminal\n\t\t\t\t\t- urxvt\n\t\t\t\t\t- rxvt\n\t\t\t\t\t- xterm\n\n\tArgs:\n\t\t\texec\\_\t\t\t   (str) : An optional command to run in the opened terminal emulator. Defaults to empty (no command).\n\t\t\tbackground\t\t   (bool): Run the terminal in the background, instead of waiting for completion. Defaults to ``False``.\n\t\t\tshell_after_cmd_exec (bool): Start the user's shell after running the command (see exec_). Defaults to `False`.\n\t\t\treturn_cmd\t\t   (bool): Returns the command used to start the terminal (str) instead of running it. Defaults to ``False``.\n\tReturns:\n\t\t\tstr: Only if ``return_cmd``, returns the command to run the terminal instead of running it. Else returns nothing.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif not exec_:\n\t\tshell_after_cmd_exec = True\n\n\tif desktop_env == 'windows':\n\t\tterminal_cmd_str = 'start powershell.exe'\n\n\tif desktop_env == 'mac':\n\t\t# Try iTerm2 first, apparently most popular Mac Terminal\n\t\tif mac_app_exists('iTerm2'):\n\t\t\tterminal_cmd_str = 'open -a iTerm2'\n\n\t\telse:\n\t\t\tterminal_cmd_str = 'open -a Terminal'\n\n\telse:\n\n\t\t# sensible-terminal\n\n\t\tif os.getenv('TERMINAL'):\n\t\t\t# Not everywhere, but if user *really* has a preference, they will\n\t\t\t# set this\n\n\t\t\tterminal_cmd_str = os.getenv('TERMINAL')\n\n\t\telif system.is_in_path('x-terminal-emulator'):\n\t\t\t# This is a convenience script that launches terminal based on\n\t\t\t# user preferences.\n\t\t\t# This is not available on some distros (but most have it)\n\t\t\t# so try this first\n\t\t\tterminal_cmd_str = 'x-terminal-emulator'\n\n\t\telif system.is_in_path('terminator'):\n\t\t\tterminal_cmd_str = 'terminator'\n\n\t\telif desktop_env in ['gnome', 'unity', 'cinnamon', 'gnome2']:\n\t\t\tterminal_cmd_str = 'gnome-terminal'\n\n\t\telif desktop_env == 'xfce4':\n\t\t\tterminal_cmd_str = 'xfce4-terminal'\n\n\t\telif desktop_env == 'kde' or desktop_env == 'trinity':\n\t\t\tterminal_cmd_str = 'konsole'\n\n\t\telif desktop_env == 'mate':\n\t\t\tterminal_cmd_str = 'mate-terminal'\n\n\t\telif desktop_env == 'i3':\n\t\t\tterminal_cmd_str = 'i3-sensible-terminal'\n\n\t\telif desktop_env == 'pantheon':\n\t\t\tterminal_cmd_str = 'pantheon-terminal'\n\n\t\telif desktop_env == 'enlightenment':\n\t\t\tterminal_cmd_str = 'terminology'\n\n\t\telif desktop_env == 'lxde' or desktop_env == 'lxqt':\n\t\t\tterminal_cmd_str = 'lxterminal'\n\n\t\telse:\n\t\t\tif system.is_in_path('gnome-terminal'):\n\t\t\t\tterminal_cmd_str = 'gnome-terminal'\n\n\t\t\telif system.is_in_path('urxvt'):\n\t\t\t\tterminal_cmd_str = 'urxvt'\n\n\t\t\telif system.is_in_path('rxvt'):\n\t\t\t\tterminal_cmd_str = 'rxvt'\n\n\t\t\telif system.is_in_path('xterm'):\n\t\t\t\tterminal_cmd_str = 'xterm'\n\n\tif exec_:\n\t\tif desktop_env == 'windows':\n\t\t\tif keep_open_after_cmd_exec and not shell_after_cmd_exec:\n\t\t\t\texec_ += '; pause'\n\n\t\t\tif os.path.isfile(exec_):\n\t\t\t\tterminal_cmd_str += exec_\n\n\t\t\telse:\n\t\t\t\tterminal_cmd_str += ' -Command ' + '\"' + exec_ + '\"'\n\n\t\t\tif shell_after_cmd_exec:\n\t\t\t\tterminal_cmd_str += ' -NoExit'\n\n\t\telse:\n\t\t\tif keep_open_after_cmd_exec and not shell_after_cmd_exec:\n\t\t\t\texec_ += '; read'\n\n\t\t\tif shell_after_cmd_exec:\n\t\t\t\texec_ += '; ' + os.getenv('SHELL')\n\n\t\t\tif desktop_env == 'mac':\n\t\t\t\tterminal_cmd_str += ' sh -c {}'.format(shlex.quote(exec_))\n\n\t\t\telse:\n\t\t\t\tterminal_cmd_str += ' -e {}'.format(\n\t\t\t\t\tshlex.quote('sh -c {}'.format(shlex.quote(exec_))))\n\n\tif return_cmd:\n\t\treturn terminal_cmd_str\n\n\tterminal_proc = sp.Popen([terminal_cmd_str], shell=True, stdout=sp.PIPE)\n\n\tif not background:\n\t\t# Wait for process to complete\n\t\tterminal_proc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the default graphical text editor.", "response": "def text_editor(file='', background=False, return_cmd=False):\n\t'''Starts the default graphical text editor.\n\n\tStart the user's preferred graphical text editor, optionally with a file.\n\n\tArgs:\n\t\t\tfile\t   (str) : The file to be opened with the editor. Defaults to an empty string (i.e. no file).\n\t\t\tbackground (bool): Runs the editor in the background, instead of waiting for completion. Defaults to ``False``.\n\t\t\treturn_cmd (bool): Returns the command (str) to run the editor instead of running it. Defaults to ``False``.\n\n\tReturns:\n\t\t\tstr: Only if ``return_cmd``, the command to run the editor is returned. Else returns nothing.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif desktop_env == 'windows':\n\t\teditor_cmd_str = system.get_cmd_out(\n\t\t\t['ftype', 'textfile']).split('=', 1)[1]\n\n\telif desktop_env == 'mac':\n\t\teditor_cmd_str = 'open -a' + system.get_cmd_out(\n\t\t\t\t['def',\n\t\t\t\t 'read',\n\t\t\t\t 'com.apple.LaunchServices',\n\t\t\t\t 'LSHandlers'\n\t\t\t\t '-array'\n\t\t\t\t '{LSHandlerContentType=public.plain-text;}']\n\t\t\t\t)\n\n\telse:\n\t\t# Use def handler for MIME-type text/plain\n\t\teditor_cmd_str = system.get_cmd_out(\n\t\t\t['xdg-mime', 'query', 'default', 'text/plain'])\n\n\t\tif '\\n' in editor_cmd_str:\n\t\t\t# Sometimes locate returns multiple results\n\t\t\t# use first one\n\n\t\t\teditor_cmd_str = editor_cmd_str.split('\\n')[0]\n\n\tif editor_cmd_str.endswith('.desktop'):\n\t\t# We don't use desktopfile.execute() in order to have working\n\t\t# return_cmd and background\n\n\t\teditor_cmd_str = desktopfile.parse(\n\t\t\tdesktopfile.locate(editor_cmd_str)[0])['Exec']\n\n\t\tfor i in editor_cmd_str.split():\n\t\t\tif i.startswith('%'):\n\t\t\t\t# %-style formatters\n\t\t\t\teditor_cmd_str = editor_cmd_str.replace(i, '')\n\n\t\t\tif i == '--new-document':\n\t\t\t\t# Gedit\n\t\t\t\teditor_cmd_str = editor_cmd_str.replace(i, '')\n\n\tif file:\n\t\teditor_cmd_str += ' {}'.format(shlex.quote(file))\n\n\tif return_cmd:\n\t\treturn editor_cmd_str\n\n\ttext_editor_proc = sp.Popen([editor_cmd_str], shell=True)\n\n\tif not background:\n\t\ttext_editor_proc.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncollects the analyses cases to be run and launches processes for each of them. Args: run_type: A string representation of the run type (eg. verification) module: The module corresponding to the run. Must have a run_suite function config: The configuration for the module", "response": "def run(run_type, module, config):\n    \"\"\"\n    Collects the analyses cases to be run and launches processes for each of\n    them.\n\n    Args:\n        run_type: A string representation of the run type (eg. verification)\n        module: The module corresponding to the run.  Must have a run_suite function\n        config: The configuration for the module\n    \"\"\"\n    print(\" -----------------------------------------------------------------\")\n    print(\"   Beginning \" + run_type.lower() + \" test suite \")\n    print(\" -----------------------------------------------------------------\")\n    print(\"\")\n    summary = run_quiet(module, config)\n    print(\" -----------------------------------------------------------------\")\n    print(\"   \" + run_type.capitalize() + \" test suite complete \")\n    print(\" -----------------------------------------------------------------\")\n    print(\"\")\n    return summary"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef launch_processes(tests, run_module, group=True, **config):\n    manager = multiprocessing.Manager()\n    test_summaries = manager.dict()\n    process_handles = [multiprocessing.Process(target=run_module.run_suite,\n                       args=(test, config[test], test_summaries)) for test in tests]\n    for p in process_handles:\n        p.start()\n    for p in process_handles:\n        p.join()\n\n    if group:\n        summary = run_module.populate_metadata(tests[0], config[tests[0]])\n        summary[\"Data\"] = dict(test_summaries)\n        return summary\n    else:\n        test_summaries = dict(test_summaries)\n        summary = []\n        for ii, test in enumerate(tests):\n            summary.append(run_module.populate_metadata(test, config[test]))\n            if summary[ii]:\n                summary[ii]['Data'] = {test: test_summaries[test]}\n        return summary", "response": "Helper method to launch processes and sync output"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Route(resource=None, methods=[\"get\", \"post\", \"put\", \"delete\"],\n          schema=None):\n    \"\"\"\n    route\n    \"\"\"\n    def _route(func):\n        def wrapper(self, *args, **kwargs):\n            # \"test\" argument means no wrap func this time,\n            # return original func immediately.\n            if kwargs.get(\"test\", False):\n                kwargs.pop(\"test\")\n                func(self, *args, **kwargs)\n\n            _methods = methods\n            if isinstance(methods, str):\n                _methods = [methods]\n            route = self.router.route(resource)\n            for method in _methods:\n                getattr(route, method)(func, schema)\n        # Ordered by declare sequence\n        # http://stackoverflow.com/questions/4459531/how-to-read-class-attributes-in-the-same-order-as-declared\n        f_locals = sys._getframe(1).f_locals\n        _order = len([v for v in f_locals.itervalues()\n                     if hasattr(v, '__call__') and\n                     hasattr(v, '__name__') and\n                     v.__name__ == \"wrapper\"])\n        wrapper.__dict__[\"_order\"] = _order\n        return wrapper\n    return _route", "response": "Route a function to a resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the current bundle.", "response": "def start(self):\n        \"\"\"\n        start\n        \"\"\"\n        def main_thread():\n            # create resp, req thread pool\n            self._create_thread_pool()\n            # start connection, this will block until stop()\n            self.conn_thread = Thread(target=self._conn.connect)\n            self.conn_thread.daemon = True\n            self.conn_thread.start()\n\n            # register model to controller...\n            self.is_ready.wait()\n\n            if hasattr(self, 'run'):\n                _logger.debug(\"Start running...\")\n                self.run()\n\n        # start main_thread\n        self.main_thread = Thread(target=main_thread)\n        self.main_thread.daemon = True\n        self.main_thread.start()\n\n        if threading.current_thread().__class__.__name__ == '_MainThread':\n            # control this bundle stop or not\n            while not self.stop_event.wait(1):\n                sleep(1)\n        else:\n            self.stop_event.wait()\n\n        self.stop()\n        _logger.debug(\"Shutdown successfully\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop the current instance of the current instance of the current class.", "response": "def stop(self, *args, **kwargs):\n        \"\"\"\n        exit\n        \"\"\"\n        _logger.debug(\"Bundle [%s] has been shutting down\" %\n                      self.bundle.profile[\"name\"])\n\n        if hasattr(self, 'before_stop') and \\\n           hasattr(self.before_stop, '__call__'):\n            _logger.debug(\"Invoking before_stop...\")\n            self.before_stop()\n\n        self._conn.disconnect()\n        self._session.stop()\n        self.stop_event.set()\n\n        # TODO: shutdown all threads\n        for thread, stop in self.thread_list:\n            stop()\n        for thread, stop in self.thread_list:\n            thread.join()\n        self.is_ready.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef on_connect(self, client, userdata, flags, rc):\n        _logger.debug(\"Connection established with result code %s\" % rc)\n\n        if self.reg_thread is not None and self.reg_thread.is_alive():\n            _logger.debug(\"Joining previous reg_thread\")\n            self.reg_thread.join()\n\n        def reg():\n            delay = None\n            if hasattr(self.reg_delay, '__call__'):\n                delay = self.reg_delay()\n            else:\n                delay = self.reg_delay\n\n            sleep(delay)\n            self._conn.set_tunnels(self._conn.tunnels)\n            model_profile = self.get_profile(\"model\")\n            view_profile = self.get_profile(\"view\")\n            self.deregister(model_profile)\n            self.deregister(view_profile)\n            self.register(model_profile)\n            self.register(view_profile)\n            self.is_ready.set()\n\n        self.reg_thread = Thread(target=reg)\n        self.reg_thread.daemon = True\n        self.reg_thread.start()", "response": "Called when a connection is established."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a new resource in the controller.", "response": "def register(self, reg_data, retry=True, interval=1, timeout=3):\n        \"\"\"\n        register function\n        retry\n            True, infinity retries\n            False, no retries\n            Number, retries times\n        interval\n            time period for retry\n        return\n            False if no success\n            Tunnel if success\n        \"\"\"\n        if len(reg_data[\"resources\"]) == 0:\n            _logger.debug(\"%s no need to register due to no resources\" %\n                          (reg_data[\"name\"]))\n            return\n\n        def _register():\n            try:\n                resp = self.publish.direct.post(\n                    \"/controller/registration\", reg_data)\n                if resp.code == 200:\n                    return resp\n            except TimeoutError:\n                _logger.debug(\"Register message is timeout\")\n\n            return False\n\n        resp = _register()\n        while resp is False:\n            _logger.debug(\"Register failed.\")\n            self.deregister(reg_data)\n            resp = _register()\n\n        if resp is None:\n            _logger.error(\"Can\\'t not register to controller\")\n            self.stop()\n            return False\n\n        self._conn.set_tunnel(\n            reg_data[\"role\"], resp.data[\"tunnel\"], self.on_sanji_message)\n        self.bundle.profile[\"currentTunnels\"] = [\n            tunnel for tunnel, callback in self._conn.tunnels.items()]\n        self.bundle.profile[\"regCount\"] = \\\n            self.bundle.profile.get(\"reg_count\", 0) + 1\n\n        _logger.debug(\"Register successfully %s tunnel: %s\"\n                      % (reg_data[\"name\"], resp.data[\"tunnel\"],))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deregister(self, reg_data, retry=True, interval=1, timeout=3):\n        Retry(target=self.publish.direct.delete,\n              args=(\"/controller/registration\", reg_data,),\n              kwargs={\"timeout\": timeout},\n              options={\"retry\": retry, \"interval\": interval})\n        _logger.debug(\"Deregister successfully %s tunnel: %s\" %\n                      (reg_data[\"name\"],\n                       self._conn.tunnels[reg_data[\"role\"]][0],))", "response": "Deregister a tunnel from the bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds mails to the context", "response": "def get_context(self):\n        \"\"\"Add mails to the context\n\n        \"\"\"\n        context = super(MailListView, self).get_context()\n        mail_list = registered_mails_names()\n\n        context['mail_map'] = mail_list\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_split(s3_url):\n\n    assert isinstance(s3_url, str)\n\n    match = re_s3_url.match(s3_url)\n    if not match:\n        raise UrlParseError('Error parsing S3 URL: \"%s\"' % s3_url)\n\n    parts = match.groupdict()\n    return (parts['bucket'], parts['key'])", "response": "Split S3 URL and return a tuple of bucket and key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening an S3 url and return a File Object.", "response": "def open(s3_url, mode='r', s3_connection=None, **kwargs):\n    \"\"\"Open S3 url, returning a File Object.\n\n    S3 connection:\n        1. Can be specified directly by `s3_connection`.\n        2. `boto.connect_s3` will be used supplying all `kwargs`.\n           - `aws_access_key_id` and `aws_secret_access_key`.\n           - `profile_name` - recommended.\n              See:\n              http://boto.readthedocs.org/en/latest/boto_config_tut.html\n    \"\"\"\n\n    connection = s3_connection or boto.connect_s3(**kwargs)\n\n    bucket_name, key_name = url_split(s3_url)\n\n    try:\n        bucket = connection.get_bucket(bucket_name)\n    except boto.exception.S3ResponseError:\n        raise BucketNotFoundError('Bucket \"%s\" was not found.' % bucket_name)\n\n    f = NamedTemporaryFile()\n    try:\n        if 'w' in mode.lower():\n            s3_key = bucket.new_key(key_name)\n\n            yield f\n            f.seek(0)\n            s3_key.set_contents_from_file(f)\n        else:\n            s3_key = bucket.get_key(key_name)\n\n            if not s3_key:\n                raise KeyNotFoundError('Key \"%s\" was not found.' % s3_url)\n\n            s3_key.get_file(f)\n            f.seek(0)\n            yield f\n    finally:\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_decimal(self):\n        dt = DATA_TYPES['decimal']\n        if type(self.data) in dt['type']:\n            self.type = 'DECIMAL'\n            num_split = str(self.data).split('.', 1)\n            self.len = len(num_split[0])\n            self.len_decimal = len(num_split[1])\n            return True", "response": "Determine if a data record is of the type decimal."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _is_numeric_data(self, data_type):\n        dt = DATA_TYPES[data_type]\n        if dt['min'] and dt['max']:\n            if type(self.data) is dt['type'] and dt['min'] < self.data < dt['max']:\n                self.type = data_type.upper()\n                self.len = len(str(self.data))\n                return True", "response": "Private method for testing numeric data types."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_enrollment_term(self, account_id, enrollment_term_end_at=None, enrollment_term_name=None, enrollment_term_sis_term_id=None, enrollment_term_start_at=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - enrollment_term[name]\r\n        \"\"\"The name of the term.\"\"\"\r\n        if enrollment_term_name is not None:\r\n            data[\"enrollment_term[name]\"] = enrollment_term_name\r\n\r\n        # OPTIONAL - enrollment_term[start_at]\r\n        \"\"\"The day/time the term starts.\r\n        Accepts times in ISO 8601 format, e.g. 2015-01-10T18:48:00Z.\"\"\"\r\n        if enrollment_term_start_at is not None:\r\n            data[\"enrollment_term[start_at]\"] = enrollment_term_start_at\r\n\r\n        # OPTIONAL - enrollment_term[end_at]\r\n        \"\"\"The day/time the term ends.\r\n        Accepts times in ISO 8601 format, e.g. 2015-01-10T18:48:00Z.\"\"\"\r\n        if enrollment_term_end_at is not None:\r\n            data[\"enrollment_term[end_at]\"] = enrollment_term_end_at\r\n\r\n        # OPTIONAL - enrollment_term[sis_term_id]\r\n        \"\"\"The unique SIS identifier for the term.\"\"\"\r\n        if enrollment_term_sis_term_id is not None:\r\n            data[\"enrollment_term[sis_term_id]\"] = enrollment_term_sis_term_id\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/terms with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/terms\".format(**path), data=data, params=params, single_item=True)", "response": "Create an enrollment term. Creates a new enrollment term for the specified account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_enrollment_terms(self, account_id, workflow_state=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - workflow_state\r\n        \"\"\"If set, only returns terms that are in the given state.\r\n        Defaults to 'active'.\"\"\"\r\n        if workflow_state is not None:\r\n            self._validate_enum(workflow_state, [\"active\", \"deleted\", \"all\"])\r\n            params[\"workflow_state\"] = workflow_state\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/terms with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/terms\".format(**path), data=data, params=params, data_key='enrollment_terms', all_pages=True)", "response": "List enrollment terms. Returns all of the terms in the account."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps for Model s get_attribute_filter", "response": "def from_model(cls, model_instance, default_value=False, **kwargs):\n        \"\"\"\n        wrapper for Model's get_attribute_filter\n        \"\"\"\n\n        if not isinstance(model_instance, DataCollection):\n            raise TypeError(\"model_instance must be a subclass of \\\n                prestans.types.DataCollection, %s given\" % (model_instance.__class__.__name__))\n        elif isinstance(model_instance, Array) and model_instance.is_scalar:\n            return AttributeFilter(is_array_scalar=True)\n        attribute_filter_instance = model_instance.get_attribute_filter(default_value)\n\n        # kwargs support\n        for name, value in iter(kwargs.items()):\n            if name in attribute_filter_instance:\n                setattr(attribute_filter_instance, name, value)\n            else:\n                raise KeyError(name)\n\n        return attribute_filter_instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef blueprint(self):\n        blueprint = dict()\n        for key in self.keys():\n            blueprint[key] = self.is_attribute_visible(key)\n\n        return blueprint", "response": "Returns a dictionary that associates the keys of the object with the values of the attributes that are visible."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if this object conforms to the rules set by the template filter", "response": "def conforms_to_template_filter(self, template_filter):\n        \"\"\"\n        Check AttributeFilter conforms to the rules set by the template\n\n         - If self, has attributes that template_filter does not contain, throw Exception\n         - If sub list found, perform the first check\n         - If self has a value for an attribute, assign to final AttributeFilter\n         - If not found, assign value from template\n\n         todo: rename as current name is mis-leading\n        \"\"\"\n\n        if not isinstance(template_filter, self.__class__):\n            raise TypeError(\"AttributeFilter can only check conformance against \\\n                another template filter, %s provided\" % template_filter.__class__.__name__)\n\n        # keys from the template\n        template_filter_keys = template_filter.keys()\n        # Keys from the object itself\n        this_filter_keys = self.keys()\n\n        # 1. Check to see if the client has provided unwanted keys\n        unwanted_keys = set(this_filter_keys) - set(template_filter_keys)\n        if len(unwanted_keys) > 0:\n            raise exception.AttributeFilterDiffers(list(unwanted_keys))\n\n        # 2. Make a attribute_filter that we send back\n        evaluated_attribute_filter = AttributeFilter()\n\n        # 3. Evaluate the differences between the two, with template_filter as the standard\n        for template_key in template_filter_keys:\n\n            if template_key in this_filter_keys:\n\n                value = getattr(self, template_key)\n\n                # if sub filter and boolean provided with of true, create default filter with value of true\n                if isinstance(value, bool) and \\\n                   value is True and \\\n                   isinstance(getattr(template_filter, template_key), AttributeFilter):\n                    setattr(evaluated_attribute_filter, template_key, getattr(template_filter, template_key))\n                elif isinstance(value, bool):\n                    setattr(evaluated_attribute_filter, template_key, value)\n                elif isinstance(value, self.__class__):\n                    # Attribute lists sort themselves out, to produce sub Attribute Filters\n                    template_sub_list = getattr(template_filter, template_key)\n                    this_sub_list = getattr(self, template_key)\n                    setattr(\n                        evaluated_attribute_filter, template_key,\n                        this_sub_list.conforms_to_template_filter(template_sub_list)\n                    )\n            else:\n                setattr(evaluated_attribute_filter, template_key, getattr(template_filter, template_key))\n\n        return evaluated_attribute_filter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of usable keys", "response": "def keys(self):\n        \"\"\"\n        :returns: a list of usable keys\n        :rtype: list\n\n        \"\"\"\n\n        keys = list()\n\n        for attribute_name, type_instance in inspect.getmembers(self):\n\n            # ignore parameters with __ and if they are methods\n            if attribute_name.startswith('__') or inspect.ismethod(type_instance):\n\n                continue\n\n            keys.append(attribute_name)\n\n        return keys"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_filter_at_key(self, key):\n\n        if key in self:\n            attribute_status = getattr(self, key)\n            if isinstance(attribute_status, self.__class__):\n                return True\n\n        return False", "response": "Return True if the attribute is a sub filter at the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if an attribute is visible.", "response": "def is_attribute_visible(self, key):\n        \"\"\"\n        Returns True if an attribute is visible\n        If attribute is an instance of AttributeFilter, it returns True if all attributes\n        of the sub filter are visible.\n\n        :param key: name of attribute to check\n        :type key: str\n        :return: whether attribute is visible\n        :rtype: bool\n        \"\"\"\n        if key in self:\n            attribute_status = getattr(self, key)\n            if isinstance(attribute_status, bool) and attribute_status is True:\n                return True\n            elif isinstance(attribute_status, self.__class__) and attribute_status.are_any_attributes_visible():\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef are_any_attributes_visible(self):\n\n        for attribute_name, type_instance in inspect.getmembers(self):\n\n            if attribute_name.startswith('__') or inspect.ismethod(type_instance):\n                continue\n\n            if isinstance(type_instance, bool) and type_instance is True:\n                return True\n            elif isinstance(type_instance, self.__class__) and type_instance.are_all_attributes_visible() is True:\n                return True\n\n        return False", "response": "checks to see if any attributes are set to true\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_all_attribute_values(self, value):\n\n        for attribute_name, type_instance in inspect.getmembers(self):\n\n            if attribute_name.startswith('__') or inspect.ismethod(type_instance):\n                # Ignore parameters with __ and if they are methods\n                continue\n\n            if isinstance(type_instance, bool):\n                self.__dict__[attribute_name] = value\n            elif isinstance(type_instance, self.__class__):\n                type_instance.set_all_attribute_values(value)", "response": "Sets all the attribute values to the value and propagate to any children of this class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nturning the attribute filter object into python dictionary", "response": "def as_dict(self):\n        \"\"\"\n        turns attribute filter object into python dictionary\n        \"\"\"\n\n        output_dictionary = dict()\n\n        for attribute_name, type_instance in inspect.getmembers(self):\n\n            if attribute_name.startswith('__') or inspect.ismethod(type_instance):\n                continue\n\n            if isinstance(type_instance, bool):\n                output_dictionary[attribute_name] = type_instance\n            elif isinstance(type_instance, self.__class__):\n                output_dictionary[attribute_name] = type_instance.as_dict()\n\n        return output_dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_from_dictionary(self, from_dictionary, template_model=None):\n\n        if not isinstance(from_dictionary, dict):\n            raise TypeError(\"from_dictionary must be of type dict, %s \\\n                provided\" % from_dictionary.__class__.__name__)\n\n        rewrite_map = None\n        if template_model is not None:\n\n            if not isinstance(template_model, DataCollection):\n                msg = \"template_model should be a prestans model %s provided\" % template_model.__class__.__name__\n                raise TypeError(msg)\n\n            rewrite_map = template_model.attribute_rewrite_reverse_map()\n\n        for key, value in iter(from_dictionary.items()):\n\n            target_key = key\n\n            # minify support\n            if rewrite_map is not None:\n                target_key = rewrite_map[key]\n\n            # ensure that the key exists in the template model\n            if template_model is not None and target_key not in template_model:\n\n                unwanted_keys = list()\n                unwanted_keys.append(target_key)\n                raise exception.AttributeFilterDiffers(unwanted_keys)\n\n            # check to see we can work with the value\n            if not isinstance(value, (bool, dict)):\n                raise TypeError(\"AttributeFilter input for key %s must be \\\n                    boolean or dict, %s provided\" % (key, value.__class__.__name__))\n\n            # Either keep the value of wrap it up with AttributeFilter\n            if isinstance(value, bool):\n                setattr(self, target_key, value)\n            elif isinstance(value, dict):\n\n                sub_map = None\n                if template_model is not None:\n\n                    sub_map = getattr(template_model, target_key)\n\n                    # prestans Array support\n                    if isinstance(sub_map, Array):\n                        sub_map = sub_map.element_template\n\n                setattr(self, target_key, AttributeFilter(from_dictionary=value, template_model=sub_map))", "response": "Private helper to initialize the internal state of the object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predict(self):\n        self._logger.info(\"Computing all predictions and their variance for %s logical networks...\", len(self.networks))\n\n        return self.networks.predictions(self.setup.filter(self.networks))", "response": "Computes all possible weighted average predictions and their variance of all possible clamping logical networks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_traffic_items(self):\n\n        traffic = self.get_child_static('traffic')\n        return {o.obj_name(): o for o in traffic.get_objects_or_children_by_type('trafficItem')}", "response": "Returns a dictionary of all traffic items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef content(self):\n        raw_content = self._manager.api.session.get(self.download_link).content\n        data = BytesIO(raw_content)\n        archive = ZipFile(data)\n        filename = archive.filelist[0]  # Always 1 file in the archive\n        return archive.read(filename)", "response": "Returns the raw CSV content of the log file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck validity of a read tuple.", "response": "def validate(self, read_tuple_name):\n        \"\"\"Check RNF validity of a read tuple.\n\n\t\tArgs:\n\t\t\tread_tuple_name (str): Read tuple name to be checked.s\n\t\t\"\"\"\n        if reg_lrn.match(read_tuple_name) is None:\n            self.report_error(\n                read_tuple_name=read_tuple_name,\n                error_name=\"wrong_read_tuple_name_structure\",\n                message=\"'{}' is not matched\".format(reg_lrn),\n            )\n        else:\n            parts = read_tuple_name.split(\"__\")\n\n            if reg_prefix_part.match(parts[0]) is None:\n                self.report_error(\n                    read_tuple_name=read_tuple_name,\n                    error_name=\"wrong_prefix_part\",\n                    message=\"'{}' is not matched\".format(reg_prefix_part),\n                )\n\n            if reg_id_part.match(parts[1]) is None:\n                self.report_error(\n                    read_tuple_name=read_tuple_name,\n                    error_name=\"wrong_id_part\",\n                    message=\"'{}' is not matched\".format(reg_id_part),\n                )\n\n            if reg_segmental_part.match(parts[2]) is None:\n                self.report_error(\n                    read_tuple_name=read_tuple_name,\n                    error_name=\"wrong_segmental_part\",\n                    message=\"'{}' is not matched\".format(reg_segmental_part),\n                )\n\n            if reg_suffix_part.match(parts[3]) is None:\n                self.report_error(\n                    read_tuple_name=read_tuple_name,\n                    error_name=\"wrong_suffix_part\",\n                    message=\"'{}' is not matched\".format(reg_suffix_part),\n                )\n\n            if not self.rnf_profile.check(read_tuple_name):\n                self.report_error(\n                    read_tuple_name=read_tuple_name,\n                    error_name=\"wrong_profile\",\n                    message=\"Read has a wrong profile (wrong widths). It should be: {} but it is: {}.\".format(\n                        self.rnf_profile,\n                        rnftools.rnfformat.RnfProfile(read_tuple_name=read_tuple_name),\n                    ),\n                    warning=True,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef report_error(self, read_tuple_name, error_name, wrong=\"\", message=\"\", warning=False):\n        if (not self.report_only_first) or (error_name not in self.reported_errors):\n            print(\"\\t\".join([\"error\" if warning == False else \"warning\", read_tuple_name, error_name, wrong, message]))\n        self.reported_errors.add(error_name)\n        if warning:\n            self.warning_has_been_reported = True\n        else:\n            self.error_has_been_reported = True", "response": "Report an error.\n\n\t\tArgs:\n\t\t\tread_tuple_name (): Name of the read tuple.\n\t\t\terror_name (): Name of the error.\n\t\t\twrong (str): What is wrong. \n\t\t\tmessage (str): Additional msessage to be printed.\n\t\t\twarning (bool): Warning (not an error)."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if this request s URL starts with one of the excluded paths.", "response": "def _is_exempt(self, environ):\n        \"\"\"\n        Returns True if this request's URL starts with one of the\n        excluded paths.\n        \"\"\"\n        exemptions = self.exclude_paths\n\n        if exemptions:\n            path = environ.get('PATH_INFO')\n            for excluded_p in self.exclude_paths:\n                if path.startswith(excluded_p):\n                    return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads metabolic network models in metabolitics.", "response": "def load_network_model(model):\n    '''\n    Loads metabolic network models in metabolitics.\n\n    :param str model: model name\n    '''\n    if type(model) == str:\n        if model in ['ecoli', 'textbook', 'salmonella']:\n            return cb.test.create_test_model(model)\n        elif model == 'recon2':\n            return cb.io.load_json_model('%s/network_models/%s.json' %\n                                         (DATASET_PATH, model))\n    if type(model) == cb.Model:\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_expired(self):\n        max_age = timezone.now() - timedelta(seconds=app_settings.ESI_TOKEN_VALID_DURATION)\n        return self.filter(created__lte=max_age)", "response": "Get all tokens which have expired."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh all refreshable tokens in the queryset.", "response": "def bulk_refresh(self):\n        \"\"\"\n        Refreshes all refreshable tokens in the queryset.\n        Deletes any tokens which fail to refresh.\n        Deletes any tokens which are expired and cannot refresh.\n        Excludes tokens for which the refresh was incomplete for other reasons.\n        \"\"\"\n        session = OAuth2Session(app_settings.ESI_SSO_CLIENT_ID)\n        auth = requests.auth.HTTPBasicAuth(app_settings.ESI_SSO_CLIENT_ID, app_settings.ESI_SSO_CLIENT_SECRET)\n        incomplete = []\n        for model in self.filter(refresh_token__isnull=False):\n            try:\n                model.refresh(session=session, auth=auth)\n                logging.debug(\"Successfully refreshed {0}\".format(repr(model)))\n            except TokenError:\n                logger.info(\"Refresh failed for {0}. Deleting.\".format(repr(model)))\n                model.delete()\n            except IncompleteResponseError:\n                incomplete.append(model.pk)\n        self.filter(refresh_token__isnull=True).get_expired().delete()\n        return self.exclude(pk__in=incomplete)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure all tokens are still valid.", "response": "def require_valid(self):\n        \"\"\"\n        Ensures all tokens are still valid. If expired, attempts to refresh.\n        Deletes those which fail to refresh or cannot be refreshed.\n        :return: All tokens which are still valid.\n        :rtype: :class:`esi.managers.TokenQueryset`\n        \"\"\"\n        expired = self.get_expired()\n        valid = self.exclude(pk__in=expired)\n        valid_expired = expired.bulk_refresh()\n        return valid_expired | valid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef require_scopes(self, scope_string):\n        scopes = _process_scopes(scope_string)\n        if not scopes:\n            # asking for tokens with no scopes\n            return self.filter(scopes__isnull=True)\n        from .models import Scope\n        scope_pks = Scope.objects.filter(name__in=scopes).values_list('pk', flat=True)\n        if not len(scopes) == len(scope_pks):\n            # there's a scope we don't recognize, so we can't have any tokens for it\n            return self.none()\n        tokens = self.all()\n        for pk in scope_pks:\n            tokens = tokens.filter(scopes__pk=pk)\n        return tokens", "response": "Returns a Queryset of all tokens with the specified scopes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef require_scopes_exact(self, scope_string):\n        num_scopes = len(_process_scopes(scope_string))\n        pks = [v['pk'] for v in self.annotate(models.Count('scopes')).require_scopes(scope_string).filter(\n            scopes__count=num_scopes).values('pk', 'scopes__id')]\n        return self.filter(pk__in=pks)", "response": "Returns a Queryset of tokens with only the requested scopes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all tokens which match the character and scopes of a reference token", "response": "def equivalent_to(self, token):\n        \"\"\"\n        Gets all tokens which match the character and scopes of a reference token\n        :param token: :class:`esi.models.Token`\n        :return: :class:`esi.managers.TokenQueryset`\n        \"\"\"\n        return self.filter(character_id=token.character_id).require_scopes_exact(token.scopes.all()).filter(\n            models.Q(user=token.user) | models.Q(user__isnull=True)).exclude(pk=token.pk)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new token from a code.", "response": "def create_from_code(self, code, user=None):\n        \"\"\"\n        Perform OAuth code exchange to retrieve a token.\n        :param code: OAuth grant code.\n        :param user: User who will own token.\n        :return: :class:`esi.models.Token`\n        \"\"\"\n\n        # perform code exchange\n        logger.debug(\"Creating new token from code {0}\".format(code[:-5]))\n        oauth = OAuth2Session(app_settings.ESI_SSO_CLIENT_ID, redirect_uri=app_settings.ESI_SSO_CALLBACK_URL)\n        token = oauth.fetch_token(app_settings.ESI_TOKEN_URL, client_secret=app_settings.ESI_SSO_CLIENT_SECRET,\n                                  code=code)\n        r = oauth.request('get', app_settings.ESI_TOKEN_VERIFY_URL)\n        r.raise_for_status()\n        token_data = r.json()\n        logger.debug(token_data)\n\n        # translate returned data to a model\n        model = self.create(\n            character_id=token_data['CharacterID'],\n            character_name=token_data['CharacterName'],\n            character_owner_hash=token_data['CharacterOwnerHash'],\n            access_token=token['access_token'],\n            refresh_token=token['refresh_token'],\n            token_type=token_data['TokenType'],\n            user=user,\n        )\n\n        # parse scopes\n        if 'Scopes' in token_data:\n            from esi.models import Scope\n            for s in token_data['Scopes'].split():\n                try:\n                    scope = Scope.objects.get(name=s)\n                    model.scopes.add(scope)\n                except Scope.DoesNotExist:\n                    # This scope isn't included in a data migration. Create a placeholder until it updates.\n                    try:\n                        help_text = s.split('.')[1].replace('_', ' ').capitalize()\n                    except IndexError:\n                        # Unusual scope name, missing periods.\n                        help_text = s.replace('_', ' ').capitalize()\n                    scope = Scope.objects.create(name=s, help_text=help_text)\n                    model.scopes.add(scope)\n            logger.debug(\"Added {0} scopes to new token.\".format(model.scopes.all().count()))\n\n        if not app_settings.ESI_ALWAYS_CREATE_TOKEN:\n            # see if we already have a token for this character and scope combination\n            # if so, we don't need a new one\n            queryset = self.get_queryset().equivalent_to(model)\n            if queryset.exists():\n                logger.debug(\n                    \"Identified {0} tokens equivalent to new token. Updating access and refresh tokens.\".format(\n                        queryset.count()))\n                queryset.update(\n                    access_token=model.access_token,\n                    refresh_token=model.refresh_token,\n                    created=model.created,\n                )\n                if queryset.filter(user=model.user).exists():\n                    logger.debug(\"Equivalent token with same user exists. Deleting new token.\")\n                    model.delete()\n                    model = queryset.filter(user=model.user)[0]  # pick one at random\n\n        logger.debug(\"Successfully created {0} for user {1}\".format(repr(model), user))\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_from_request(self, request):\n        logger.debug(\"Creating new token for {0} session {1}\".format(request.user, request.session.session_key[:5]))\n        code = request.GET.get('code')\n        # attach a user during creation for some functionality in a post_save created receiver I'm working on elsewhere\n        model = self.create_from_code(code, user=request.user if request.user.is_authenticated else None)\n        return model", "response": "Generate a new token from the OAuth callback request. Must contain code in GET."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nyields a series of batches from iterable each size elements long.", "response": "def ibatch(iterable, size):\n    \"\"\"Yield a series of batches from iterable, each size elements long.\"\"\"\n    source = iter(iterable)\n    while True:\n        batch = itertools.islice(source, size)\n        yield itertools.chain([next(batch)], batch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put_many(self, items):  # pragma: no cover\n        for key, value in items:\n            self.put(key, value)", "response": "Put many key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prefix_items(self, prefix, strip_prefix=False):\n        items = self.items(key_from=prefix)\n\n        start = 0\n        if strip_prefix:\n            start = len(prefix)\n\n        for key, value in items:\n            if not key.startswith(prefix):\n                break\n            yield key[start:], value", "response": "Get all items that begin with the given prefix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all keys that begin with prefix.", "response": "def prefix_keys(self, prefix, strip_prefix=False):\n        \"\"\"Get all keys that begin with ``prefix``.\n\n        :param prefix: Lexical prefix for keys to search.\n        :type prefix: bytes\n\n        :param strip_prefix: True to strip the prefix from yielded items.\n        :type strip_prefix: bool\n\n        :yields: All keys in the store that begin with ``prefix``.\n\n        \"\"\"\n        keys = self.keys(key_from=prefix)\n\n        start = 0\n        if strip_prefix:\n            start = len(prefix)\n\n        for key in keys:\n            if not key.startswith(prefix):\n                break\n            yield key[start:]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the submissions for a given date and grader and assignment. Returns a nested list of submissions versions", "response": "def lists_submissions(self, date, course_id, grader_id, assignment_id):\r\n        \"\"\"\r\n        Lists submissions.\r\n\r\n        Gives a nested list of submission versions\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"The id of the contextual course for this API call\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - date\r\n        \"\"\"The date for which you would like to see submissions\"\"\"\r\n        path[\"date\"] = date\r\n\r\n        # REQUIRED - PATH - grader_id\r\n        \"\"\"The ID of the grader for which you want to see submissions\"\"\"\r\n        path[\"grader_id\"] = grader_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"The ID of the assignment for which you want to see submissions\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/gradebook_history/{date}/graders/{grader_id}/assignments/{assignment_id}/submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/gradebook_history/{date}/graders/{grader_id}/assignments/{assignment_id}/submissions\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting uncollated submission versions. Returns a paginated list of submissions in the context with the same grade and previous grade.", "response": "def list_uncollated_submission_versions(self, course_id, ascending=None, assignment_id=None, user_id=None):\r\n        \"\"\"\r\n        List uncollated submission versions.\r\n\r\n        Gives a paginated, uncollated list of submission versions for all matching\r\n        submissions in the context. This SubmissionVersion objects will not include\r\n        the +new_grade+ or +previous_grade+ keys, only the +grade+; same for\r\n        +graded_at+ and +grader+.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"The id of the contextual course for this API call\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - assignment_id\r\n        \"\"\"The ID of the assignment for which you want to see submissions. If\r\n        absent, versions of submissions from any assignment in the course are\r\n        included.\"\"\"\r\n        if assignment_id is not None:\r\n            params[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - user_id\r\n        \"\"\"The ID of the user for which you want to see submissions. If absent,\r\n        versions of submissions from any user in the course are included.\"\"\"\r\n        if user_id is not None:\r\n            params[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - ascending\r\n        \"\"\"Returns submission versions in ascending date order (oldest first). If\r\n        absent, returns submission versions in descending date order (newest\r\n        first).\"\"\"\r\n        if ascending is not None:\r\n            params[\"ascending\"] = ascending\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/gradebook_history/feed with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/gradebook_history/feed\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current object.", "response": "def save(self, *args, **kwargs):\n        \"\"\"Saving ensures that the slug, if not set, is set to the slugified name.\"\"\"\n\n        if not self.slug:\n            self.slug = slugify(self.name)\n\n        section = super(Section, self).save(*args, **kwargs)\n\n        if self.query and self.query != {}:\n            self._save_percolator()\n\n        return section"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the query field as an elasticsearch percolator", "response": "def _save_percolator(self):\n        \"\"\"saves the query field as an elasticsearch percolator\n        \"\"\"\n        index = Content.search_objects.mapping.index\n        query_filter = self.get_content().to_dict()\n\n        q = {}\n\n        if \"query\" in query_filter:\n            q = {\"query\": query_filter.get(\"query\", {})}\n        else:\n            return\n\n        es.index(\n            index=index,\n            doc_type=\".percolator\",\n            body=q,\n            id=self.es_id\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_content(self):\n        if \"query\" in self.query:\n            q = self.query[\"query\"]\n        else:\n            q = self.query\n        search = custom_search_model(Content, q, field_map={\n            \"feature-type\": \"feature_type.slug\",\n            \"tag\": \"tags.slug\",\n            \"content-type\": \"_type\",\n        })\n        return search", "response": "performs es search and gets content objects\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new sample.", "response": "def sample(name, reads_in_tuple):\n    \"\"\"\tCreate a new sample.\n\t\"\"\"\n    if name in [sample_x.get_name() for sample_x in __SAMPLES__]:\n        rnftools.utils.error(\n            \"Multiple samples have the same name. Each sample must have a unique name.\",\n            program=\"RNFtools\",\n            subprogram=\"MIShmash\",\n            exception=ValueError,\n        )\n\n    Sample(\n        name=name,\n        reads_in_tuple=reads_in_tuple,\n    )\n    add_input(current_sample().fq_fns())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the schema model that is active in this project.", "response": "def get_schema_model():\n    \"\"\"\n    Returns the schema model that is active in this project.\n    \"\"\"\n    try:\n        return django_apps.get_model(settings.POSTGRES_SCHEMA_MODEL, require_ready=False)\n    except ValueError:\n        raise ImproperlyConfigured(\"POSTGRES_SCHEMA_MODEL must be of the form 'app_label.model_name'\")\n    except LookupError:\n        raise ImproperlyConfigured(\n            \"POSTGRES_SCHEMA_MODEL refers to model '%s' that has not been installed\" % settings.POSTGRES_SCHEMA_MODEL\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, len=1024):\n        while True:\n            try:\n                return self._sslobj.read(len)\n            except SSLError:\n                ex = sys.exc_info()[1]\n                if ex.args[0] == SSL_ERROR_EOF and self.suppress_ragged_eofs:\n                    return b''\n                elif ex.args[0] == SSL_ERROR_WANT_READ:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_read(timeout=self.timeout, timeout_exc=_SSLErrorReadTimeout)\n                elif ex.args[0] == SSL_ERROR_WANT_WRITE:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_write(timeout=self.timeout, timeout_exc=_SSLErrorReadTimeout)\n                else:\n                    raise", "response": "Read up to LEN bytes and return them."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting DATA to the underlying SSL channel. Returns the number of bytes of DATA actually transmitted.", "response": "def write(self, data):\n        \"\"\"Write DATA to the underlying SSL channel.  Returns\n        number of bytes of DATA actually transmitted.\"\"\"\n        while True:\n            try:\n                return self._sslobj.write(data)\n            except SSLError:\n                ex = sys.exc_info()[1]\n                if ex.args[0] == SSL_ERROR_WANT_READ:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_read(timeout=self.timeout, timeout_exc=_SSLErrorWriteTimeout)\n                elif ex.args[0] == SSL_ERROR_WANT_WRITE:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_write(timeout=self.timeout, timeout_exc=_SSLErrorWriteTimeout)\n                else:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_handshake(self):\n        while True:\n            try:\n                return self._sslobj.do_handshake()\n            except SSLError:\n                ex = sys.exc_info()[1]\n                if ex.args[0] == SSL_ERROR_WANT_READ:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_read(timeout=self.timeout, timeout_exc=_SSLErrorHandshakeTimeout)\n                elif ex.args[0] == SSL_ERROR_WANT_WRITE:\n                    if self.timeout == 0.0:\n                        raise\n                    six.exc_clear()\n                    self._io.wait_write(timeout=self.timeout, timeout_exc=_SSLErrorHandshakeTimeout)\n                else:\n                    raise", "response": "Perform a TLS or SSL handshake."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, addr):\n        # Here we assume that the socket is client-side, and not\n        # connected at the time of the call.  We connect it, then wrap it.\n        if self._sslobj:\n            raise ValueError(\"attempt to connect already-connected SSLSocket!\")\n        socket.connect(self, addr)\n        if six.PY3:\n            self._sslobj = self.context._wrap_socket(self._sock, False, self.server_hostname)\n        else:\n            if self.ciphers is None:\n                self._sslobj = _ssl.sslwrap(self._sock, False, self.keyfile, self.certfile,\n                                            self.cert_reqs, self.ssl_version,\n                                            self.ca_certs)\n            else:\n                self._sslobj = _ssl.sslwrap(self._sock, False, self.keyfile, self.certfile,\n                                            self.cert_reqs, self.ssl_version,\n                                            self.ca_certs, self.ciphers)\n        if self.do_handshake_on_connect:\n            self.do_handshake()", "response": "Connects to the remote ADDR and then wraps the connection in\n            an SSL channel."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\naccept a new connection from a remote client and returns a server - side SSL channel and the address of the remote client.", "response": "def accept(self):\n        \"\"\"Accepts a new connection from a remote client, and returns\n        a tuple containing that new connection wrapped with a server-side\n        SSL channel, and the address of the remote client.\"\"\"\n        newsock, addr = socket.accept(self)\n        ssl_sock = SSLSocket(newsock._sock,\n                             keyfile=self.keyfile,\n                             certfile=self.certfile,\n                             server_side=True,\n                             cert_reqs=self.cert_reqs,\n                             ssl_version=self.ssl_version,\n                             ca_certs=self.ca_certs,\n                             do_handshake_on_connect=self.do_handshake_on_connect,\n                             suppress_ragged_eofs=self.suppress_ragged_eofs,\n                             ciphers=self.ciphers)\n        return ssl_sock, addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request to given url.", "response": "def send_request(self, url):\n        \"\"\" Send a request to given url. \"\"\"\n        while True:\n            try:\n                return urllib.request.urlopen(url)\n            except urllib.error.HTTPError as e:\n                raise serror(\n                    \"Request `%s` failed (%s:%s).\" %\n                    (url, e.__class__.__name__, e.code))\n            except Exception as e:\n                choice = input(serror(\n                    \"Error occured: %s - Retry? [yN]\" % type(e)))\n                if choice.strip().lower() != \"y\":\n                    raise serror(e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a request to the given uri.", "response": "def get(self, uri):\n        \"\"\" Send a request to given uri. \"\"\"\n        return self.send_request(\n            \"{0}://{1}:{2}{3}{4}\".format(\n                self.get_protocol(),\n                self.host,\n                self.port,\n                uri,\n                self.client_id\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattempts to get client_id from soundcloud homepage.", "response": "def get_client_id(self):\n        \"\"\" Attempt to get client_id from soundcloud homepage. \"\"\"\n        # FIXME: This method doesn't works\n        id = re.search(\n            \"\\\"clientID\\\":\\\"([a-z0-9]*)\\\"\",\n            self.send_request(self.SC_HOME).read().decode(\"utf-8\"))\n\n        if not id:\n            raise serror(\"Cannot retrieve client_id.\")\n\n        return id.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle and log RPC errors.", "response": "def error_handler(task):\n    \"\"\"Handle and log RPC errors.\"\"\"\n    @wraps(task)\n    def wrapper(self, *args, **kwargs):\n        try:\n            return task(self, *args, **kwargs)\n        except Exception as e:\n            self.connected = False\n            if not self.testing:\n                exc_type, exc_obj, exc_tb = sys.exc_info()\n                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n                error_message = (\n                    \"[\" + str(datetime.now()) + \"] Error in task \\\"\" +\n                    task.__name__ + \"\\\" (\" +\n                    fname + \"/\" + str(exc_tb.tb_lineno) +\n                    \")\" + e.message\n                )\n                self.logger.error(\"%s: RPC instruction failed\" % error_message)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrecord a transaction in the database.", "response": "def record_tx(self, origin, destination, amount,\n                  outcome, destination_id=None):\n        \"\"\"Records a transaction in the database.\n\n        Args:\n          origin (str): user_id of the sender\n          destination (str): coin address or user_id of the recipient\n          amount (str, Decimal, number): amount to send\n          outcome (str, bool): the transaction hash if this is a \"sendfrom\"\n                               transaction; for \"move\", True if successful,\n                               False otherwise\n          destination_id (str): the destination account label (\"move\" only)\n\n        Returns:\n          str or bool: the outcome (input) argument\n\n        \"\"\"\n        # \"move\" commands\n        if destination_id:\n            tx = db.Transaction(\n                txtype=\"move\",\n                from_user_id=origin,\n                to_user_id=destination_id,\n                txdate=datetime.now(),\n                amount=amount,\n                currency=COINS[self.coin][\"ticker\"],\n                to_coin_address=destination,\n            )\n\n        # \"sendfrom\" commands\n        else:\n            self.logger.debug(self.gettransaction(outcome))\n            confirmations = self.gettransaction(outcome)[\"confirmations\"]\n            last_confirmation = datetime.now() if confirmations else None\n            tx = db.Transaction(\n                txtype=\"sendfrom\",\n                from_user_id=origin,\n                txhash=outcome,\n                txdate=datetime.now(),\n                amount=amount,\n                currency=COINS[self.coin][\"ticker\"],\n                to_coin_address=destination,\n                confirmations=confirmations,\n                last_confirmation=last_confirmation\n            )\n        db.session.add(tx)\n        db.session.commit()\n        return outcome"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconnecting to a coin daemon s JSON RPC interface.", "response": "def rpc_connect(self):\n        \"\"\"Connect to a coin daemon's JSON RPC interface.\n\n        Returns:\n          bool: True if successfully connected, False otherwise.\n\n        \"\"\"\n        if self.coin in COINS:\n            rpc_url = COINS[self.coin][\"rpc-url\"] + \":\"\n            if self.testnet:\n                rpc_url += COINS[self.coin][\"rpc-port-testnet\"]\n            else:\n                rpc_url += COINS[self.coin][\"rpc-port\"]\n            self.rpc = pyjsonrpc.HttpClient(\n                url=rpc_url,\n                username=COINS[self.coin][\"rpc-user\"],\n                password=COINS[self.coin][\"rpc-password\"]\n            )\n            self.logger.debug(self.coin, \"RPC connection ok\")\n            self.connected = True\n        else:\n            self.logger.debug(self.coin, \"bridge not found\")\n        return self.connected"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getaccountaddress(self, user_id=\"\"):\n        address = self.rpc.call(\"getaccountaddress\", user_id)\n        self.logger.debug(\"Your\", self.coin, \"address is\", address)\n        return address", "response": "Get the coin address associated with a user id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the total balance in all addresses belonging to this user.", "response": "def getbalance(self, user_id=\"\", as_decimal=True):\n        \"\"\"Calculate the total balance in all addresses belonging to this user.\n\n        Args:\n          user_id (str): this user's unique identifier\n          as_decimal (bool): balance is returned as a Decimal if True (default)\n                             or a string if False\n\n        Returns:\n          str or Decimal: this account's total coin balance\n\n        \"\"\"\n        balance = unicode(self.rpc.call(\"getbalance\", user_id))\n        self.logger.debug(\"\\\"\" + user_id + \"\\\"\", self.coin, \"balance:\", balance)\n        if as_decimal:\n            return Decimal(balance)\n        else:\n            return balance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all transactions associated with this user.", "response": "def listtransactions(self, user_id=\"\", count=10, start_at=0):\n        \"\"\"List all transactions associated with this account.\n\n        Args:\n          user_id (str): this user's unique identifier\n          count (int): number of transactions to return (default=10)\n          start_at (int): start the list at this transaction (default=0)\n\n        Returns:\n          list [dict]: transactions associated with this user's account\n\n        \"\"\"\n        txlist = self.rpc.call(\"listtransactions\", user_id, count, start_at)\n        self.logger.debug(\"Got transaction list for \" + str(user_id))\n        return txlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends coins between accounts in the same wallet.", "response": "def move(self, fromaccount, toaccount, amount, minconf=1):\n        \"\"\"Send coins between accounts in the same wallet.\n\n        If the receiving account does not exist, it is automatically\n        created (but not automatically assigned an address).\n\n        Args:\n          fromaccount (str): origin account\n          toaccount (str): destination account\n          amount (str or Decimal): amount to send (8 decimal points)\n          minconf (int): ensure the account has a valid balance using this\n                         many confirmations (default=1) \n\n        Returns:\n          bool: True if the coins are moved successfully, False otherwise\n\n        \"\"\"\n        amount = Decimal(amount).quantize(self.quantum, rounding=ROUND_HALF_EVEN)\n        return self.rpc.call(\"move\",\n            fromaccount, toaccount, float(str(amount)), minconf\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending coins from user s account to dest_address.", "response": "def sendfrom(self, user_id, dest_address, amount, minconf=1):\n        \"\"\"\n        Send coins from user's account.\n\n        Args:\n          user_id (str): this user's unique identifier\n          dest_address (str): address which is to receive coins\n          amount (str or Decimal): amount to send (eight decimal points)\n          minconf (int): ensure the account has a valid balance using this\n                         many confirmations (default=1)\n\n        Returns:\n          str: transaction ID\n\n        \"\"\"\n        amount = Decimal(amount).quantize(self.quantum, rounding=ROUND_HALF_EVEN)\n        txhash = self.rpc.call(\"sendfrom\",\n            user_id, dest_address, float(str(amount)), minconf\n        )\n        self.logger.debug(\"Send %s %s from %s to %s\" % (str(amount), self.coin,\n                                                        str(user_id), dest_address))\n        self.logger.debug(\"Transaction hash: %s\" % txhash)\n        return txhash"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef signmessage(self, address, message):\n        signature = self.rpc.call(\"signmessage\", address, message)\n        self.logger.debug(\"Signature: %s\" % signature)\n        return signature", "response": "Sign a message with the private key of an address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verifymessage(self, address, signature, message):\n        verified = self.rpc.call(\"verifymessage\", address, signature, message)\n        self.logger.debug(\"Signature verified: %s\" % str(verified))\n        return verified", "response": "Verifies that a message has been signed by an address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call(self, command, *args):\n        return self.rpc.call(str(command), *args)", "response": "Send a command to the daemon."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_feature_type_rates(sender, instance, created, *args, **kwargs):\n    if created:\n        for role in ContributorRole.objects.all():\n            FeatureTypeRate.objects.create(role=role, feature_type=instance, rate=0)", "response": "Create a default FeatureTypeRate for each role after the creation of a FeatureTypeRate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_contributions(sender, instance, action, model, pk_set, **kwargs):\n    if action != 'pre_add':\n        return\n    else:\n        for author in model.objects.filter(pk__in=pk_set):\n            update_content_contributions(instance, author)", "response": "Creates a contribution for each author added to an article."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_calendar_events(self, all_events=None, context_codes=None, end_date=None, excludes=None, start_date=None, type=None, undated=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - type\r\n        \"\"\"Defaults to \"event\"\"\"\"\r\n        if type is not None:\r\n            self._validate_enum(type, [\"event\", \"assignment\"])\r\n            params[\"type\"] = type\r\n\r\n        # OPTIONAL - start_date\r\n        \"\"\"Only return events since the start_date (inclusive).\r\n        Defaults to today. The value should be formatted as: yyyy-mm-dd or ISO 8601 YYYY-MM-DDTHH:MM:SSZ.\"\"\"\r\n        if start_date is not None:\r\n            params[\"start_date\"] = start_date\r\n\r\n        # OPTIONAL - end_date\r\n        \"\"\"Only return events before the end_date (inclusive).\r\n        Defaults to start_date. The value should be formatted as: yyyy-mm-dd or ISO 8601 YYYY-MM-DDTHH:MM:SSZ.\r\n        If end_date is the same as start_date, then only events on that day are\r\n        returned.\"\"\"\r\n        if end_date is not None:\r\n            params[\"end_date\"] = end_date\r\n\r\n        # OPTIONAL - undated\r\n        \"\"\"Defaults to false (dated events only).\r\n        If true, only return undated events and ignore start_date and end_date.\"\"\"\r\n        if undated is not None:\r\n            params[\"undated\"] = undated\r\n\r\n        # OPTIONAL - all_events\r\n        \"\"\"Defaults to false (uses start_date, end_date, and undated criteria).\r\n        If true, all events are returned, ignoring start_date, end_date, and undated criteria.\"\"\"\r\n        if all_events is not None:\r\n            params[\"all_events\"] = all_events\r\n\r\n        # OPTIONAL - context_codes\r\n        \"\"\"List of context codes of courses/groups/users whose events you want to see.\r\n        If not specified, defaults to the current user (i.e personal calendar,\r\n        no course/group events). Limited to 10 context codes, additional ones are\r\n        ignored. The format of this field is the context type, followed by an\r\n        underscore, followed by the context id. For example: course_42\"\"\"\r\n        if context_codes is not None:\r\n            params[\"context_codes\"] = context_codes\r\n\r\n        # OPTIONAL - excludes\r\n        \"\"\"Array of attributes to exclude. Possible values are \"description\", \"child_events\" and \"assignment\"\"\"\"\r\n        if excludes is not None:\r\n            params[\"excludes\"] = excludes\r\n\r\n        self.logger.debug(\"GET /api/v1/calendar_events with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/calendar_events\".format(**path), data=data, params=params, all_pages=True)", "response": "Returns a list of calendar events or assignments for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_calendar_event(self, calendar_event_context_code, calendar_event_child_event_data_X_context_code=None, calendar_event_child_event_data_X_end_at=None, calendar_event_child_event_data_X_start_at=None, calendar_event_description=None, calendar_event_duplicate_append_iterator=None, calendar_event_duplicate_count=None, calendar_event_duplicate_frequency=None, calendar_event_duplicate_interval=None, calendar_event_end_at=None, calendar_event_location_address=None, calendar_event_location_name=None, calendar_event_start_at=None, calendar_event_time_zone_edited=None, calendar_event_title=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - calendar_event[context_code]\r\n        \"\"\"Context code of the course/group/user whose calendar this event should be\r\n        added to.\"\"\"\r\n        data[\"calendar_event[context_code]\"] = calendar_event_context_code\r\n\r\n        # OPTIONAL - calendar_event[title]\r\n        \"\"\"Short title for the calendar event.\"\"\"\r\n        if calendar_event_title is not None:\r\n            data[\"calendar_event[title]\"] = calendar_event_title\r\n\r\n        # OPTIONAL - calendar_event[description]\r\n        \"\"\"Longer HTML description of the event.\"\"\"\r\n        if calendar_event_description is not None:\r\n            data[\"calendar_event[description]\"] = calendar_event_description\r\n\r\n        # OPTIONAL - calendar_event[start_at]\r\n        \"\"\"Start date/time of the event.\"\"\"\r\n        if calendar_event_start_at is not None:\r\n            data[\"calendar_event[start_at]\"] = calendar_event_start_at\r\n\r\n        # OPTIONAL - calendar_event[end_at]\r\n        \"\"\"End date/time of the event.\"\"\"\r\n        if calendar_event_end_at is not None:\r\n            data[\"calendar_event[end_at]\"] = calendar_event_end_at\r\n\r\n        # OPTIONAL - calendar_event[location_name]\r\n        \"\"\"Location name of the event.\"\"\"\r\n        if calendar_event_location_name is not None:\r\n            data[\"calendar_event[location_name]\"] = calendar_event_location_name\r\n\r\n        # OPTIONAL - calendar_event[location_address]\r\n        \"\"\"Location address\"\"\"\r\n        if calendar_event_location_address is not None:\r\n            data[\"calendar_event[location_address]\"] = calendar_event_location_address\r\n\r\n        # OPTIONAL - calendar_event[time_zone_edited]\r\n        \"\"\"Time zone of the user editing the event. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if calendar_event_time_zone_edited is not None:\r\n            data[\"calendar_event[time_zone_edited]\"] = calendar_event_time_zone_edited\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][start_at]\r\n        \"\"\"Section-level start time(s) if this is a course event. X can be any\r\n        identifier, provided that it is consistent across the start_at, end_at\r\n        and context_code\"\"\"\r\n        if calendar_event_child_event_data_X_start_at is not None:\r\n            data[\"calendar_event[child_event_data][X][start_at]\"] = calendar_event_child_event_data_X_start_at\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][end_at]\r\n        \"\"\"Section-level end time(s) if this is a course event.\"\"\"\r\n        if calendar_event_child_event_data_X_end_at is not None:\r\n            data[\"calendar_event[child_event_data][X][end_at]\"] = calendar_event_child_event_data_X_end_at\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][context_code]\r\n        \"\"\"Context code(s) corresponding to the section-level start and end time(s).\"\"\"\r\n        if calendar_event_child_event_data_X_context_code is not None:\r\n            data[\"calendar_event[child_event_data][X][context_code]\"] = calendar_event_child_event_data_X_context_code\r\n\r\n        # OPTIONAL - calendar_event[duplicate][count]\r\n        \"\"\"Number of times to copy/duplicate the event.\"\"\"\r\n        if calendar_event_duplicate_count is not None:\r\n            data[\"calendar_event[duplicate][count]\"] = calendar_event_duplicate_count\r\n\r\n        # OPTIONAL - calendar_event[duplicate][interval]\r\n        \"\"\"Defaults to 1 if duplicate `count` is set.  The interval between the duplicated events.\"\"\"\r\n        if calendar_event_duplicate_interval is not None:\r\n            data[\"calendar_event[duplicate][interval]\"] = calendar_event_duplicate_interval\r\n\r\n        # OPTIONAL - calendar_event[duplicate][frequency]\r\n        \"\"\"Defaults to \"weekly\".  The frequency at which to duplicate the event\"\"\"\r\n        if calendar_event_duplicate_frequency is not None:\r\n            self._validate_enum(calendar_event_duplicate_frequency, [\"daily\", \"weekly\", \"monthly\"])\r\n            data[\"calendar_event[duplicate][frequency]\"] = calendar_event_duplicate_frequency\r\n\r\n        # OPTIONAL - calendar_event[duplicate][append_iterator]\r\n        \"\"\"Defaults to false.  If set to `true`, an increasing counter number will be appended to the event title\r\n        when the event is duplicated.  (e.g. Event 1, Event 2, Event 3, etc)\"\"\"\r\n        if calendar_event_duplicate_append_iterator is not None:\r\n            data[\"calendar_event[duplicate][append_iterator]\"] = calendar_event_duplicate_append_iterator\r\n\r\n        self.logger.debug(\"POST /api/v1/calendar_events with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/calendar_events\".format(**path), data=data, params=params, no_data=True)", "response": "Create a calendar event. Returns the calendar event with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reserve_time_slot(self, id, cancel_existing=None, comments=None, participant_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - participant_id\r\n        \"\"\"User or group id for whom you are making the reservation (depends on the\r\n        participant type). Defaults to the current user (or user's candidate group).\"\"\"\r\n        if participant_id is not None:\r\n            data[\"participant_id\"] = participant_id\r\n\r\n        # OPTIONAL - comments\r\n        \"\"\"Comments to associate with this reservation\"\"\"\r\n        if comments is not None:\r\n            data[\"comments\"] = comments\r\n\r\n        # OPTIONAL - cancel_existing\r\n        \"\"\"Defaults to false. If true, cancel any previous reservation(s) for this\r\n        participant and appointment group.\"\"\"\r\n        if cancel_existing is not None:\r\n            data[\"cancel_existing\"] = cancel_existing\r\n\r\n        self.logger.debug(\"POST /api/v1/calendar_events/{id}/reservations with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/calendar_events/{id}/reservations\".format(**path), data=data, params=params, no_data=True)", "response": "Reserves a particular time slot and returns the new reservation. Returns the new reservation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_calendar_event(self, id, calendar_event_child_event_data_X_context_code=None, calendar_event_child_event_data_X_end_at=None, calendar_event_child_event_data_X_start_at=None, calendar_event_context_code=None, calendar_event_description=None, calendar_event_end_at=None, calendar_event_location_address=None, calendar_event_location_name=None, calendar_event_start_at=None, calendar_event_time_zone_edited=None, calendar_event_title=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - calendar_event[context_code]\r\n        \"\"\"Context code of the course/group/user to move this event to.\r\n        Scheduler appointments and events with section-specific times cannot be moved between calendars.\"\"\"\r\n        if calendar_event_context_code is not None:\r\n            data[\"calendar_event[context_code]\"] = calendar_event_context_code\r\n\r\n        # OPTIONAL - calendar_event[title]\r\n        \"\"\"Short title for the calendar event.\"\"\"\r\n        if calendar_event_title is not None:\r\n            data[\"calendar_event[title]\"] = calendar_event_title\r\n\r\n        # OPTIONAL - calendar_event[description]\r\n        \"\"\"Longer HTML description of the event.\"\"\"\r\n        if calendar_event_description is not None:\r\n            data[\"calendar_event[description]\"] = calendar_event_description\r\n\r\n        # OPTIONAL - calendar_event[start_at]\r\n        \"\"\"Start date/time of the event.\"\"\"\r\n        if calendar_event_start_at is not None:\r\n            data[\"calendar_event[start_at]\"] = calendar_event_start_at\r\n\r\n        # OPTIONAL - calendar_event[end_at]\r\n        \"\"\"End date/time of the event.\"\"\"\r\n        if calendar_event_end_at is not None:\r\n            data[\"calendar_event[end_at]\"] = calendar_event_end_at\r\n\r\n        # OPTIONAL - calendar_event[location_name]\r\n        \"\"\"Location name of the event.\"\"\"\r\n        if calendar_event_location_name is not None:\r\n            data[\"calendar_event[location_name]\"] = calendar_event_location_name\r\n\r\n        # OPTIONAL - calendar_event[location_address]\r\n        \"\"\"Location address\"\"\"\r\n        if calendar_event_location_address is not None:\r\n            data[\"calendar_event[location_address]\"] = calendar_event_location_address\r\n\r\n        # OPTIONAL - calendar_event[time_zone_edited]\r\n        \"\"\"Time zone of the user editing the event. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if calendar_event_time_zone_edited is not None:\r\n            data[\"calendar_event[time_zone_edited]\"] = calendar_event_time_zone_edited\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][start_at]\r\n        \"\"\"Section-level start time(s) if this is a course event. X can be any\r\n        identifier, provided that it is consistent across the start_at, end_at\r\n        and context_code\"\"\"\r\n        if calendar_event_child_event_data_X_start_at is not None:\r\n            data[\"calendar_event[child_event_data][X][start_at]\"] = calendar_event_child_event_data_X_start_at\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][end_at]\r\n        \"\"\"Section-level end time(s) if this is a course event.\"\"\"\r\n        if calendar_event_child_event_data_X_end_at is not None:\r\n            data[\"calendar_event[child_event_data][X][end_at]\"] = calendar_event_child_event_data_X_end_at\r\n\r\n        # OPTIONAL - calendar_event[child_event_data][X][context_code]\r\n        \"\"\"Context code(s) corresponding to the section-level start and end time(s).\"\"\"\r\n        if calendar_event_child_event_data_X_context_code is not None:\r\n            data[\"calendar_event[child_event_data][X][context_code]\"] = calendar_event_child_event_data_X_context_code\r\n\r\n        self.logger.debug(\"PUT /api/v1/calendar_events/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/calendar_events/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Updates a calendar event. Updates the calendar event with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_calendar_event(self, id, cancel_reason=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - cancel_reason\r\n        \"\"\"Reason for deleting/canceling the event.\"\"\"\r\n        if cancel_reason is not None:\r\n            params[\"cancel_reason\"] = cancel_reason\r\n\r\n        self.logger.debug(\"DELETE /api/v1/calendar_events/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/calendar_events/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Delete a calendar event. Delete a calendar event from the calendar and return the deleted event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a course timetable. Returns the new timetable object.", "response": "def set_course_timetable(self, course_id, timetables_course_section_id=None, timetables_course_section_id_end_time=None, timetables_course_section_id_location_name=None, timetables_course_section_id_start_time=None, timetables_course_section_id_weekdays=None):\r\n        \"\"\"\r\n        Set a course timetable.\r\n\r\n        Creates and updates \"timetable\" events for a course.\r\n        Can automaticaly generate a series of calendar events based on simple schedules\r\n        (e.g. \"Monday and Wednesday at 2:00pm\" )\r\n        \r\n        Existing timetable events for the course and course sections\r\n        will be updated if they still are part of the timetable.\r\n        Otherwise, they will be deleted.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - timetables[course_section_id]\r\n        \"\"\"An array of timetable objects for the course section specified by course_section_id.\r\n        If course_section_id is set to \"all\", events will be created for the entire course.\"\"\"\r\n        if timetables_course_section_id is not None:\r\n            data[\"timetables[course_section_id]\"] = timetables_course_section_id\r\n\r\n        # OPTIONAL - timetables[course_section_id][weekdays]\r\n        \"\"\"A comma-separated list of abbreviated weekdays\r\n        (Mon-Monday, Tue-Tuesday, Wed-Wednesday, Thu-Thursday, Fri-Friday, Sat-Saturday, Sun-Sunday)\"\"\"\r\n        if timetables_course_section_id_weekdays is not None:\r\n            data[\"timetables[course_section_id][weekdays]\"] = timetables_course_section_id_weekdays\r\n\r\n        # OPTIONAL - timetables[course_section_id][start_time]\r\n        \"\"\"Time to start each event at (e.g. \"9:00 am\")\"\"\"\r\n        if timetables_course_section_id_start_time is not None:\r\n            data[\"timetables[course_section_id][start_time]\"] = timetables_course_section_id_start_time\r\n\r\n        # OPTIONAL - timetables[course_section_id][end_time]\r\n        \"\"\"Time to end each event at (e.g. \"9:00 am\")\"\"\"\r\n        if timetables_course_section_id_end_time is not None:\r\n            data[\"timetables[course_section_id][end_time]\"] = timetables_course_section_id_end_time\r\n\r\n        # OPTIONAL - timetables[course_section_id][location_name]\r\n        \"\"\"A location name to set for each event\"\"\"\r\n        if timetables_course_section_id_location_name is not None:\r\n            data[\"timetables[course_section_id][location_name]\"] = timetables_course_section_id_location_name\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/calendar_events/timetable with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/calendar_events/timetable\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_or_update_events_directly_for_course_timetable(self, course_id, course_section_id=None, events=None, events_code=None, events_end_at=None, events_location_name=None, events_start_at=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - course_section_id\r\n        \"\"\"Events will be created for the course section specified by course_section_id.\r\n        If not present, events will be created for the entire course.\"\"\"\r\n        if course_section_id is not None:\r\n            data[\"course_section_id\"] = course_section_id\r\n\r\n        # OPTIONAL - events\r\n        \"\"\"An array of event objects to use.\"\"\"\r\n        if events is not None:\r\n            data[\"events\"] = events\r\n\r\n        # OPTIONAL - events[start_at]\r\n        \"\"\"Start time for the event\"\"\"\r\n        if events_start_at is not None:\r\n            data[\"events[start_at]\"] = events_start_at\r\n\r\n        # OPTIONAL - events[end_at]\r\n        \"\"\"End time for the event\"\"\"\r\n        if events_end_at is not None:\r\n            data[\"events[end_at]\"] = events_end_at\r\n\r\n        # OPTIONAL - events[location_name]\r\n        \"\"\"Location name for the event\"\"\"\r\n        if events_location_name is not None:\r\n            data[\"events[location_name]\"] = events_location_name\r\n\r\n        # OPTIONAL - events[code]\r\n        \"\"\"A unique identifier that can be used to update the event at a later time\r\n        If one is not specified, an identifier will be generated based on the start and end times\"\"\"\r\n        if events_code is not None:\r\n            data[\"events[code]\"] = events_code\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/calendar_events/timetable_events with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/calendar_events/timetable_events\".format(**path), data=data, params=params, no_data=True)", "response": "This method creates or updates events directly for a course timetable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef token_required(scopes='', new=False):\n\n    def decorator(view_func):\n        @wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n\n            # if we're coming back from SSO for a new token, return it\n            token = _check_callback(request)\n            if token and new:\n                logger.debug(\"Got new token from {0} session {1}. Returning to view.\".format(request.user, request.session.session_key[:5]))\n                return view_func(request, token, *args, **kwargs)\n\n            # if we're selecting a token, return it\n            if request.method == 'POST':\n                if request.POST.get(\"_add\", False):\n                    logger.debug(\"{0} has selected to add new token. Redirecting to SSO.\".format(request.user))\n                    # user has selected to add a new token\n                    from esi.views import sso_redirect\n                    return sso_redirect(request, scopes=scopes)\n\n                token_pk = request.POST.get('_token', None)\n                if token_pk:\n                    logger.debug(\"{0} has selected token {1}\".format(request.user, token_pk))\n                    try:\n                        token = Token.objects.get(pk=token_pk)\n                        # ensure token belongs to this user and has required scopes\n                        if ((token.user and token.user == request.user) or not token.user) and Token.objects.filter(\n                                pk=token_pk).require_scopes(scopes).require_valid().exists():\n                            logger.debug(\"Selected token fulfills requirements of view. Returning.\")\n                            return view_func(request, token, *args, **kwargs)\n                    except Token.DoesNotExist:\n                        logger.debug(\"Token {0} not found.\".format(token_pk))\n                        pass\n\n            if not new:\n                # present the user with token choices\n                tokens = Token.objects.filter(user__pk=request.user.pk).require_scopes(scopes).require_valid()\n                if tokens.exists():\n                    logger.debug(\"Returning list of available tokens for {0}.\".format(request.user))\n                    from esi.views import select_token\n                    return select_token(request, scopes=scopes, new=new)\n                else:\n                    logger.debug(\"No tokens found for {0} session {1} with scopes {2}\".format(request.user, request.session.session_key[:5], scopes))\n\n            # prompt the user to add a new token\n            logger.debug(\"Redirecting {0} session {1} to SSO.\".format(request.user, request.session.session_key[:5]))\n            from esi.views import sso_redirect\n            return sso_redirect(request, scopes=scopes)\n\n        return _wrapped_view\n\n    return decorator", "response": "Decorator for views which supplies a single user - selected token for the view to process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the abuse contact for a given IP address.", "response": "def find(self, ip):\n        '''\n        Find the abuse contact for a IP address\n\n        :param ip: IPv4 or IPv6 address to check\n        :type ip: string\n\n        :returns: emails associated with IP\n        :rtype: list\n        :returns: none if no contact could be found\n        :rtype: None\n\n        :raises: :py:class:`ValueError`: if ip is not properly formatted\n        '''\n        ip = ipaddr.IPAddress(ip)\n        rev = reversename(ip.exploded)\n        revip, _ = rev.split(3)\n        lookup = revip.concatenate(self.provider).to_text()\n\n        contacts = self._get_txt_record(lookup)\n        if contacts:\n            return contacts.split(',')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nforming validation that selected template exists.", "response": "def template_exists(form, field):\n    \"\"\"Form validation: check that selected template exists.\"\"\"\n    try:\n        current_app.jinja_env.get_template(field.data)\n    except TemplateNotFound:\n        raise ValidationError(_(\"Template selected does not exist\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that we are not trying to assign list page itself as a child.", "response": "def same_page_choosen(form, field):\n    \"\"\"Check that we are not trying to assign list page itself as a child.\"\"\"\n    if form._obj is not None:\n        if field.data.id == form._obj.list_id:\n            raise ValidationError(\n                _('You cannot assign list page itself as a child.'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconcatenates list of columns into a string.", "response": "def cols_str(columns):\n    \"\"\"Concatenate list of columns into a string.\"\"\"\n    cols = \"\"\n    for c in columns:\n        cols = cols + wrap(c) + ', '\n    return cols[:-2]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\njoining list of columns into a string for a SQL query", "response": "def join_cols(cols):\n    \"\"\"Join list of columns into a string for a SQL query\"\"\"\n    return \", \".join([i for i in cols]) if isinstance(cols, (list, tuple, set)) else cols"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_order_classes(model_label, order_field_names):\n    # Seperate model_label into parts.\n    labels = resolve_labels(model_label)\n    # Get model class for model_label string.\n    model = get_model(labels['app'], labels['model'])\n\n    # Dynamic Classes\n    class OrderItemBase(models.Model):\n        \"\"\"\n        Dynamic order class base.\n        \"\"\"\n        item = models.ForeignKey(model_label)\n        timestamp = models.DateTimeField(auto_now=True)\n\n        class Meta:\n            abstract = True\n            app_label = 'order'\n\n    class Admin(admin.ModelAdmin):\n        \"\"\"\n        Dynamic order admin class.\n        \"\"\"\n        list_display = ('item_link',) + tuple(order_field_names)\n        list_editable = order_field_names\n\n        def get_model_perms(self, request):\n            \"\"\"\n            Return empty perms dict thus hiding the model from admin index.\n            \"\"\"\n            return {}\n\n        @csrf_protect_m\n        def changelist_view(self, request, extra_context=None):\n            list_url = reverse('admin:%s_%s_changelist' % (labels['app'], \\\n                    labels['model'].lower()))\n            add_url = reverse('admin:%s_%s_add' % (labels['app'], \\\n                    labels['model'].lower()))\n\n            result = super(Admin, self).changelist_view(\n                request,\n                extra_context={\n                    'add_url': add_url,\n                    'list_url': list_url,\n                    'related_opts': model._meta,\n                }\n            )\n\n            # XXX: Sanitize order on list save.\n            # if (request.method == \"POST\" and self.list_editable and \\\n            #        '_save' in request.POST):\n            #    sanitize_order(self.model)\n            return result\n\n        def item_link(self, obj):\n            url = reverse('admin:%s_%s_change' % (labels['app'], \\\n                    labels['model'].lower()), args=(obj.item.id,))\n            return '<a href=\"%s\">%s</a>' % (url, str(obj.item))\n        item_link.allow_tags = True\n        item_link.short_description = 'Item'\n\n    # Set up a dictionary to simulate declarations within a class.\n    attrs = {\n        '__module__': 'order.models',\n    }\n\n    # Create provided order fields and add to attrs.\n    fields = {}\n    for field in order_field_names:\n        fields[field] = models.IntegerField()\n    attrs.update(fields)\n\n    # Create the class which automatically triggers Django model processing.\n    order_item_class_name = resolve_order_item_class_name(labels)\n    order_model = type(order_item_class_name, (OrderItemBase, ), attrs)\n\n    # Register admin model.\n    admin.site.register(order_model, Admin)\n\n    # Add user_order_by method to base QuerySet.\n    from order import managers\n    setattr(QuerySet, 'user_order_by', managers.user_order_by)\n\n    # Return created model class.\n    return order_model", "response": "Create order classes for model_label."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_order_objects(model, order_fields):\n    for rel in model._meta.get_all_related_objects():\n        rel_model = rel.model\n        if rel_model.__module__ == 'order.models':\n\n            objs = model.objects.all()\n            values = {}\n            for order_field in order_fields:\n                order_objs = rel_model.objects.all().order_by('-%s' \\\n                        % order_field)\n                try:\n                    values[order_field] = getattr(order_objs[0], \\\n                            order_field) + 1\n                except IndexError:\n                    values[order_field] = 1\n            for obj in objs:\n                try:\n                    rel_model.objects.get(item=obj)\n                except rel_model.DoesNotExist:\n                    rel_model.objects.create(item=obj, **values)\n                    for key in values:\n                        values[key] += 1", "response": "Create order items for objects already present in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_orderable(cls):\n    if not getattr(settings, 'ORDERABLE_MODELS', None):\n        return False\n\n    labels = resolve_labels(cls)\n    if labels['app_model'] in settings.ORDERABLE_MODELS:\n        return settings.ORDERABLE_MODELS[labels['app_model']]\n    return False", "response": "Checks if the provided class is specified as an orderable in\n    settings. ORDERABLE_MODELS. Returns the class s settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving app model and app_model labels into parts.", "response": "def resolve_labels(model_label):\n    \"\"\"\n    Seperate model_label into parts.\n    Returns dictionary with app, model and app_model strings.\n    \"\"\"\n    labels = {}\n\n    # Resolve app label.\n    labels['app'] = model_label.split('.')[0]\n\n    # Resolve model label\n    labels['model'] = model_label.split('.')[-1]\n\n    # Resolve module_app_model label.\n    labels['app_model'] = '%s.%s' % (labels['app'], labels['model'])\n\n    return labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsanitizing order values so eliminate conflicts and gaps.", "response": "def sanitize_order(model):\n    \"\"\"\n    Sanitize order values so eliminate conflicts and gaps.\n    XXX: Early start, very ugly, needs work.\n    \"\"\"\n    to_order_dict = {}\n\n    order_field_names = []\n    for field in model._meta.fields:\n        if isinstance(field, models.IntegerField):\n            order_field_names.append(field.name)\n\n    for field_name in order_field_names:\n        to_order_dict[field_name] = list(model.objects.all().order_by(\\\n                field_name, '-timestamp'))\n\n    updates = {}\n    for field_name, object_list in to_order_dict.items():\n        for i, obj in enumerate(object_list):\n            position = i + 1\n            if getattr(obj, field_name) != position:\n                if obj in updates:\n                    updates[obj][field_name] = position\n                else:\n                    updates[obj] = {field_name: position}\n\n    for obj, fields in updates.items():\n        for field, value in fields.items():\n            setattr(obj, field, value)\n        obj.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the class type of the serializer", "response": "def get_serializer_class(self):\n        \"\"\"gets the class type of the serializer\n\n        :return: `rest_framework.Serializer`\n        \"\"\"\n        klass = None\n\n        lookup_url_kwarg = self.lookup_url_kwarg or self.lookup_field\n        if lookup_url_kwarg in self.kwargs:\n            # Looks like this is a detail...\n            klass = self.get_object().__class__\n        elif \"doctype\" in self.request.REQUEST:\n            base = self.model.get_base_class()\n            doctypes = indexable_registry.families[base]\n            try:\n                klass = doctypes[self.request.REQUEST[\"doctype\"]]\n            except KeyError:\n                raise Http404\n\n        if hasattr(klass, \"get_serializer_class\"):\n            return klass.get_serializer_class()\n\n        # TODO: fix deprecation warning here -- `get_serializer_class` is going away soon!\n        return super(ContentViewSet, self).get_serializer_class()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post_save(self, obj, created=False):\n        from bulbs.content.tasks import index\n\n        index.delay(obj.polymorphic_ctype_id, obj.pk)\n\n        message = \"Created\" if created else \"Saved\"\n        LogEntry.objects.log(self.request.user, obj, message)\n        return super(ContentViewSet, self).post_save(obj, created=created)", "response": "indexes the object to ElasticSearch after any save function ( POST / PUT"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies list view to driving listing from ES", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"Modified list view to driving listing from ES\"\"\"\n        search_kwargs = {\"published\": False}\n\n        for field_name in (\"before\", \"after\", \"status\", \"published\"):\n\n            if field_name in get_query_params(self.request):\n                search_kwargs[field_name] = get_query_params(self.request).get(field_name)\n\n        for field_name in (\"tags\", \"types\", \"feature_types\"):\n\n            if field_name in get_query_params(self.request):\n                search_kwargs[field_name] = get_query_params(self.request).getlist(field_name)\n\n        if \"search\" in get_query_params(self.request):\n            search_kwargs[\"query\"] = get_query_params(self.request).get(\"search\")\n\n        queryset = self.model.search_objects.search(**search_kwargs)\n\n        if \"authors\" in get_query_params(self.request):\n            authors = get_query_params(self.request).getlist(\"authors\")\n            queryset = queryset.filter(Authors(authors))\n\n        if \"exclude\" in get_query_params(self.request):\n            exclude = get_query_params(self.request).get(\"exclude\")\n            queryset = queryset.filter(\n                es_filter.Not(es_filter.Type(**{'value': exclude}))\n            )\n\n        # always filter out Super Features from listing page\n        queryset = queryset.filter(\n            es_filter.Not(filter=es_filter.Type(\n                value=get_superfeature_model().search_objects.mapping.doc_type))\n        )\n\n        page = self.paginate_queryset(queryset)\n        if page is not None:\n            serializer = self.get_serializer(page, many=True)\n            return self.get_paginated_response(serializer.data)\n\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the published value of the Content object", "response": "def publish(self, request, **kwargs):\n        \"\"\"sets the `published` value of the `Content`\n\n        :param request: a WSGI request object\n        :param kwargs: keyword arguments (optional)\n        :return: `rest_framework.response.Response`\n        \"\"\"\n        content = self.get_object()\n\n        if \"published\" in get_request_data(request):\n            if not get_request_data(request)[\"published\"]:\n                content.published = None\n            else:\n                publish_dt = parse_datetime(get_request_data(request)[\"published\"])\n                if publish_dt:\n                    publish_dt = publish_dt.astimezone(timezone.utc)\n                else:\n                    publish_dt = None\n                content.published = publish_dt\n        else:\n            content.published = timezone.now()\n\n        content.save()\n        LogEntry.objects.log(request.user, content, content.get_status())\n        return Response({\"status\": content.get_status(), \"published\": content.published})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a content instance and removes it from the Elastic Search index.", "response": "def trash(self, request, **kwargs):\n        \"\"\"Psuedo-deletes a `Content` instance and removes it from the ElasticSearch index\n\n        Content is not actually deleted, merely hidden by deleted from ES index.import\n\n        :param request: a WSGI request object\n        :param kwargs: keyword arguments (optional)\n        :return: `rest_framework.response.Response`\n        \"\"\"\n        content = self.get_object()\n\n        content.indexed = False\n        content.save()\n\n        LogEntry.objects.log(request.user, content, \"Trashed\")\n        return Response({\"status\": \"Trashed\"})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef status(self, request, **kwargs):\n        content = self.get_object()\n        return Response({\"status\": content.get_status()})", "response": "This endpoint returns a status text of the currently published item in the editor queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contributions(self, request, **kwargs):\n        # Check if the contribution app is installed\n        if Contribution not in get_models():\n            return Response([])\n\n        if request.method == \"POST\":\n            serializer = ContributionSerializer(data=get_request_data(request), many=True)\n            if not serializer.is_valid():\n                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n            serializer.save()\n            return Response(serializer.data)\n        else:\n            content_pk = kwargs.get('pk', None)\n            if content_pk is None:\n                return Response([], status=status.HTTP_404_NOT_FOUND)\n            queryset = Contribution.search_objects.search().filter(\n                es_filter.Term(**{'content.id': content_pk})\n            )\n            serializer = ContributionSerializer(queryset[:queryset.count()].sort('id'), many=True)\n            return Response(serializer.data)", "response": "Gets or adds contributions for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_token(self, request, **kwargs):\n\n        data = {\n            \"content\": self.get_object().id,\n            \"create_date\": get_request_data(request)[\"create_date\"],\n            \"expire_date\": get_request_data(request)[\"expire_date\"]\n        }\n        serializer = ObfuscatedUrlInfoSerializer(data=data)\n        if not serializer.is_valid():\n            return Response(\n                serializer.errors,\n                status=status.HTTP_400_BAD_REQUEST,\n                content_type=\"application/json\",\n            )\n        serializer.save()\n\n        return Response(serializer.data, status=status.HTTP_200_OK, content_type=\"application/json\")", "response": "Create a new obfuscated url info to use for accessing unpublished content."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting all tokens for this content instance.", "response": "def list_tokens(self, request, **kwargs):\n        \"\"\"List all tokens for this content instance.\n\n        :param request: a WSGI request object\n        :param kwargs: keyword arguments (optional)\n        :return: `rest_framework.response.Response`\n        \"\"\"\n\n        # no date checking is done here to make it more obvious if there's an issue with the\n        # number of records. Date filtering will be done on the frontend.\n        infos = [ObfuscatedUrlInfoSerializer(info).data\n                 for info in ObfuscatedUrlInfo.objects.filter(content=self.get_object())]\n        return Response(infos, status=status.HTTP_200_OK, content_type=\"application/json\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the base queryset object for the serializer", "response": "def get_queryset(self):\n        \"\"\"creates the base queryset object for the serializer\n\n        :return: an instance of `django.db.models.QuerySet`\n        \"\"\"\n        qs = LogEntry.objects.all()\n        content_id = get_query_params(self.request).get(\"content\", None)\n        if content_id:\n            qs = qs.filter(object_id=content_id)\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new record in the database.", "response": "def create(self, request, *args, **kwargs):\n        \"\"\"\n        Grabbing the user from request.user, and the rest of the method\n        is the same as ModelViewSet.create().\n\n        :param request: a WSGI request object\n        :param args: inline arguments (optional)\n        :param kwargs: keyword arguments (optional)\n        :return: `rest_framework.response.Response`\n        :raise: 400\n        \"\"\"\n        data = get_request_data(request).copy()\n        data[\"user\"] = request.user.id\n        serializer = self.get_serializer(data=data, files=request.FILES)\n\n        if serializer.is_valid():\n            self.pre_save(serializer.object)\n            self.object = serializer.save(force_insert=True)\n            self.post_save(self.object, created=True)\n            headers = self.get_success_headers(serializer.data)\n            return Response(\n                serializer.data,\n                status=status.HTTP_201_CREATED,\n                headers=headers\n            )\n\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the base queryset object for the serializer limited to users within the authors groups and having is_staff flag", "response": "def get_queryset(self):\n        \"\"\"created the base queryset object for the serializer limited to users within the authors\n        groups and having `is_staff`\n\n        :return: `django.db.models.QuerySet`\n        \"\"\"\n        author_filter = getattr(settings, \"BULBS_AUTHOR_FILTER\", {\"is_staff\": True})\n        queryset = self.model.objects.filter(**author_filter).distinct()\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting basic information about the user", "response": "def retrieve(self, request, *args, **kwargs):\n        \"\"\"gets basic information about the user\n\n        :param request: a WSGI request object\n        :param args: inline arguments (optional)\n        :param kwargs: keyword arguments (optional)\n        :return: `rest_framework.response.Response`\n        \"\"\"\n        data = UserSerializer().to_representation(request.user)\n\n        # add superuser flag only if user is a superuser, putting it here so users can only\n        # tell if they are themselves superusers\n        if request.user.is_superuser:\n            data['is_superuser'] = True\n\n        # attempt to add a firebase token if we have a firebase secret\n        secret = getattr(settings, 'FIREBASE_SECRET', None)\n        if secret:\n            # use firebase auth to provide auth variables to firebase security api\n            firebase_auth_payload = {\n                'id': request.user.pk,\n                'username': request.user.username,\n                'email': request.user.email,\n                'is_staff': request.user.is_staff\n            }\n            data['firebase_token'] = create_token(secret, firebase_auth_payload)\n\n        return Response(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, request):\n        query = get_query_params(request).get(\"search\", \"\")\n        results = []\n        base = self.model.get_base_class()\n        doctypes = indexable_registry.families[base]\n        for doctype, klass in doctypes.items():\n            name = klass._meta.verbose_name.title()\n            if query.lower() in name.lower():\n                results.append(dict(\n                    name=name,\n                    doctype=doctype\n                ))\n                results.sort(key=lambda x: x[\"name\"])\n        return Response(dict(results=results))", "response": "Search the doctypes for this model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, request, *args, **kwargs):\n\n        queryset = self.get_filtered_queryset(get_request_data(request))\n        # Switch between paginated or standard style responses\n        page = self.paginate_queryset(queryset)\n        if page is not None:\n            serializer = self.get_serializer(page, many=True)\n            return self.get_paginated_response(serializer.data)\n\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)", "response": "Return a list of all the items in the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhacks couldn't get POST to the list endpoint without messing up POST for the other list_routes so I'm doing this. Maybe something to do with the router?", "response": "def create(self, request, *args, **kwargs):\n        \"\"\"HACK: couldn't get POST to the list endpoint without\n        messing up POST for the other list_routes so I'm doing this.\n        Maybe something to do with the router?\n        \"\"\"\n        return self.list(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_by_course(self, course_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/course/courses/{course_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/course/courses/{course_id}\".format(**path), data=data, params=params, all_pages=True)", "response": "Query by course. Returns the list of course change events for a given course."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vary_radius(dt):\n\tglobal time\n\ttime += dt\n\tdisc.inner_radius = disc.outer_radius = 2.5 + math.sin(time / 2.0) * 1.5", "response": "Vary the disc radius over time"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _aggregate(self):\n        '''\n        The function aggreagtes all pre_stream, layout and post_stream and\n        components, and yields them one by one.\n        '''\n        # Yielding everything under pre_stream\n        for x in self._yield_all(self.pre_stream): yield x\n\n        # Yielding layout\n        for x in self._yield_all(self.layout): yield x\n\n        # Yield LayoutSR Specific Content\n        yield \"\"\"\n        <div id=\"%s\">\n        <script>\n            var MyFlaskSRMutationObserver = (function () {\n                var prefixes = ['WebKit', 'Moz', 'O', 'Ms', '']\n                for(var i=0; i < prefixes.length; i++) {\n                    if(prefixes[i] + 'MutationObserver' in window) {\n                        return window[prefixes[i] + 'MutationObserver'];\n                    }\n                }\n                return false;\n            }());\n\n            if(MyFlaskSRMutationObserver) {\n                var target = document.getElementById('%s');\n                var observerFlaskSR = new MyFlaskSRMutationObserver(function(mutations) {\n                    mutations.forEach(function(mutation) {\n                        var obj = mutation.addedNodes[0];\n                        if(obj instanceof HTMLElement) {\n                            var referenceId = obj.getAttribute('sr-id');\n                            if(referenceId) {\n                                document.getElementById('%s').querySelectorAll(\"*[ref-sr-id='\"+referenceId+\"']\")[0].innerHTML = obj.innerHTML;\n                                obj.innerHTML = '';\n                            }\n                        }\n                    });\n                });\n                var config = {\n                    childList: true\n                }\n                observerFlaskSR.observe(target, config);\n                document.addEventListener(\"DOMContentLoaded\", function(event) {\n                    observerFlaskSR.disconnect();\n                });\n            }\n            else {\n                console.log(\"MutationObserver not found!\");\n            }\n        </script>\"\"\" % (\n            self.stream_div_id,\n            self.stream_div_id,\n            self.stream_div_layout_id\n        )\n\n        # Yielding components\n        for x in self._yield_all(self.components): yield x\n\n        # Yield LayoutSR Specific Content\n        yield \"\"\"</div>\"\"\"\n\n        # Yielding everything under post_stream\n        for x in self._yield_all(self.post_stream): yield x", "response": "Yields all the components under the stream and layout and post_stream and their associated pre_stream and layout and post_stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a duration string into a datetime. timedelta object", "response": "def from_str(duration):\n    \"\"\"Parse a duration string to a datetime.timedelta\"\"\"\n\n    if duration in (\"0\", \"+0\", \"-0\"):\n        return datetime.timedelta()\n\n    pattern = re.compile('([\\d\\.]+)([a-z\u00b5\u03bc]+)')\n    total = 0\n    sign = -1 if duration[0] == '-' else 1\n    matches = pattern.findall(duration)\n\n    if not len(matches):\n        raise Exception(\"Invalid duration {}\".format(duration))\n\n    for (value, unit) in matches:\n        if unit not in units:\n            raise Exception(\n                \"Unknown unit {} in duration {}\".format(unit, duration))\n        try:\n            total += float(value) * units[unit]\n        except:\n            raise Exception(\n                \"Invalid value {} in duration {}\".format(value, duration))\n\n    microseconds = total / _microsecond_size\n    return datetime.timedelta(microseconds=sign * microseconds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat a datetime. timedelta to a duration string", "response": "def to_str(delta, extended=False):\n    \"\"\"Format a datetime.timedelta to a duration string\"\"\"\n\n    total_seconds = delta.total_seconds()\n    sign = \"-\" if total_seconds < 0 else \"\"\n    nanoseconds = abs(total_seconds * _second_size)\n\n    if total_seconds < 1:\n        result_str = _to_str_small(nanoseconds, extended)\n    else:\n        result_str = _to_str_large(nanoseconds, extended)\n\n    return \"{}{}\".format(sign, result_str)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename(self, old_table, new_table):\n        try:\n            command = 'RENAME TABLE {0} TO {1}'.format(wrap(old_table), wrap(new_table))\n        except:\n            command = 'ALTER TABLE {0} RENAME {1}'.format(wrap(old_table), wrap(new_table))\n        self.execute(command)\n        self._printer('Renamed {0} to {1}'.format(wrap(old_table), wrap(new_table)))\n        return old_table, new_table", "response": "Rename a table.\n\n        You must have ALTER and DROP privileges for the original table,\n        and CREATE and INSERT privileges for the new table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new database.", "response": "def create_database(self, name):\n        \"\"\"Create a new database.\"\"\"\n        statement = \"CREATE DATABASE {0} DEFAULT CHARACTER SET latin1 COLLATE latin1_swedish_ci\".format(wrap(name))\n        return self.execute(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_table(self, name, data, columns=None, add_pk=True):\n        # TODO: Issue occurs when bool values exist in data\n        # Remove if the table exists\n        if name in self.tables:\n            self.drop(name)\n\n        # Set headers list\n        if not columns:\n            columns = data[0]\n\n        # Validate data shape\n        for row in data:\n            assert len(row) == len(columns)\n\n        # Create dictionary of column types\n        col_types = {columns[i]: sql_column_type([d[i] for d in data], prefer_int=True, prefer_varchar=True)\n                     for i in range(0, len(columns))}\n\n        # Join column types into SQL string\n        cols = ''.join(['\\t{0} {1},\\n'.format(name, type_) for name, type_ in col_types.items()])[:-2] + '\\n'\n        statement = 'CREATE TABLE {0} ({1}{2})'.format(name, '\\n', cols)\n        self.execute(statement)\n        if add_pk:\n            self.set_primary_key_auto()\n        return True", "response": "Create a new table in the database by parsing a 2D dataset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconsult o status do pagamento", "response": "def _get_notification(self, email, token):\n        ''' Consulta o status do pagamento '''        \n        url = u'{notification_url}{notification_code}?email={email}&token={token}'.format(\n            notification_url=self.notification_url,\n            notification_code=self.notification_code,\n            email=email,\n            token=token)\n        req = requests.get(url)\n        if req.status_code == 200:\n            self.xml = req.text\n            logger.debug( u'XML com informacoes da transacao recebido: {0}'.format(self.xml) )\n            transaction_dict = xmltodict.parse(self.xml)\n            # Validar informa\u00e7\u00f5es recebidas\n            transaction_schema(transaction_dict)\n            self.transaction = transaction_dict.get('transaction')\n        else:\n            raise PagSeguroApiException(\n                        u'Erro ao fazer request para a API de notificacao:' + \n                        ' HTTP Status=%s - Response: %s' % (req.status_code, req.text))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef items(self):\n        ''' Lista dos items do pagamento\n        '''\n        if type(self.transaction['items']['item']) == list:\n            return self.transaction['items']['item']\n        else:\n            return [self.transaction['items']['item'],]", "response": "Lista dos items do pagamento"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a single poll. Create a new poll for the current user.", "response": "def create_single_poll(self, polls_question, polls_description=None):\r\n        \"\"\"\r\n        Create a single poll.\r\n\r\n        Create a new poll for the current user\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - polls[question]\r\n        \"\"\"The title of the poll.\"\"\"\r\n        data[\"polls[question]\"] = polls_question\r\n\r\n        # OPTIONAL - polls[description]\r\n        \"\"\"A brief description or instructions for the poll.\"\"\"\r\n        if polls_description is not None:\r\n            data[\"polls[description]\"] = polls_description\r\n\r\n        self.logger.debug(\"POST /api/v1/polls with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/polls\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_connection(address, timeout=_GLOBAL_DEFAULT_TIMEOUT, source_address=None):\n\n    host, port = address\n    err = None\n    for res in getaddrinfo(host, port, 0 if has_ipv6 else AF_INET, SOCK_STREAM):\n        af, socktype, proto, _canonname, sa = res\n        sock = None\n        try:\n            sock = socket(af, socktype, proto)\n            if timeout is not _GLOBAL_DEFAULT_TIMEOUT:\n                sock.settimeout(timeout)\n            if source_address:\n                sock.bind(source_address)\n            sock.connect(sa)\n            return sock\n        except error:\n            err = sys.exc_info()[1]\n            six.exc_clear()\n            if sock is not None:\n                sock.close()\n    if err is not None:\n        raise err\n    else:\n        raise error(\"getaddrinfo returns an empty list\")", "response": "Connect to a specific address and return the socket object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving content from the ES index when deleted from DB", "response": "def content_deleted(sender, instance=None, **kwargs):\n    \"\"\"removes content from the ES index when deleted from DB\n    \"\"\"\n    if getattr(instance, \"_index\", True):\n        cls = instance.get_real_instance_class()\n        index = cls.search_objects.mapping.index\n        doc_type = cls.search_objects.mapping.doc_type\n\n        cls.search_objects.client.delete(index, doc_type, instance.id, ignore=[404])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the slug to the name of the tag", "response": "def save(self, *args, **kwargs):\n        \"\"\"sets the `slug` values as the name\n\n        :param args: inline arguments (optional)\n        :param kwargs: keyword arguments (optional)\n        :return: `super.save()`\n        \"\"\"\n        self.slug = slugify(self.name)[:50]\n        return super(Tag, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, *args, **kwargs):\n        if self.slug is None or self.slug == \"\":\n            self.slug = slugify(self.name)\n\n        feature_type = super(FeatureType, self).save(*args, **kwargs)\n\n        if self.instant_article_is_dirty:\n            index_feature_type_content.delay(self.pk)\n\n        self._db_instant_article = self.instant_article\n\n        # Run all behaviors for `create`\n        if self.is_new:\n            update_feature_type_rates.delay(self.pk)\n\n        return feature_type", "response": "sets the slug values as the name\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef thumbnail(self):\n        # check if there is a valid thumbnail override\n        if self.thumbnail_override.id is not None:\n            return self.thumbnail_override\n\n        # otherwise, just try to grab the first image\n        first_image = self.first_image\n        if first_image is not None:\n            return first_image\n\n        # no override for thumbnail and no non-none image field, just return override,\n        # which is a blank image field\n        return self.thumbnail_override", "response": "Read - only attribute that provides the value of the thumbnail to display."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreadying - only attribute that provides the value of the first non - none image that s not the thumbnail override field.", "response": "def first_image(self):\n        \"\"\"Ready-only attribute that provides the value of the first non-none image that's\n        not the thumbnail override field.\n        \"\"\"\n        # loop through image fields and grab the first non-none one\n        for model_field in self._meta.fields:\n            if isinstance(model_field, ImageField):\n                if model_field.name is not 'thumbnail_override':\n                    field_value = getattr(self, model_field.name)\n                    if field_value.id is not None:\n                        return field_value\n\n        # no non-none images, return None\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_absolute_url(self):\n        try:\n            url = reverse(\"content-detail-view\", kwargs={\"pk\": self.pk, \"slug\": self.slug})\n        except NoReverseMatch:\n            url = None\n        return url", "response": "produces a url to link directly to this instance given the URL config\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_published(self):\n        if self.published:\n            now = timezone.now()\n            if now >= self.published:\n                return True\n        return False", "response": "determines if the content is live"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the related tags", "response": "def ordered_tags(self):\n        \"\"\"gets the related tags\n\n        :return: `list` of `Tag` instances\n        \"\"\"\n        tags = list(self.tags.all())\n        return sorted(\n            tags,\n            key=lambda tag: ((type(tag) != Tag) * 100000) + tag.count(),\n            reverse=True\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the slug queues up for indexing and saves the instance", "response": "def save(self, *args, **kwargs):\n        \"\"\"creates the slug, queues up for indexing and saves the instance\n\n        :param args: inline arguments (optional)\n        :param kwargs: keyword arguments\n        :return: `bulbs.content.Content`\n        \"\"\"\n        if not self.slug:\n            self.slug = slugify(self.build_slug())[:self._meta.get_field(\"slug\").max_length]\n\n        if not self.is_indexed:\n            if kwargs is None:\n                kwargs = {}\n            kwargs[\"index\"] = False\n        content = super(Content, self).save(*args, **kwargs)\n        index_content_contributions.delay(self.id)\n        index_content_report_content_proxy.delay(self.id)\n        post_to_instant_articles_api.delay(self.id)\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef percolate_special_coverage(self, max_size=10, sponsored_only=False):\n\n        # Elasticsearch v1.4 percolator range query does not support DateTime range queries\n        # (PercolateContext.nowInMillisImpl is not implemented). Once using\n        # v1.6+ we can instead compare \"start_date/end_date\" to python DateTime\n        now_epoch = datetime_to_epoch_seconds(timezone.now())\n\n        MANUALLY_ADDED_BOOST = 10\n        SPONSORED_BOOST = 100  # Must be order of magnitude higher than \"Manual\" boost\n\n        # Unsponsored boosting to either lower priority or exclude\n        if sponsored_only:\n            # Omit unsponsored\n            unsponsored_boost = 0\n        else:\n            # Below sponsored (inverse boost, since we're filtering on \"sponsored=False\"\n            unsponsored_boost = (1.0 / SPONSORED_BOOST)\n\n        # ES v1.4 has more limited percolator capabilities than later\n        # implementations. As such, in order to get this to work, we need to\n        # sort via scoring_functions, and then manually filter out zero scores.\n        sponsored_filter = {\n            \"query\": {\n                \"function_score\": {\n                    \"functions\": [\n\n                        # Boost Recent Special Coverage\n                        # Base score is start time\n                        # Note: ES 1.4 sorting granularity is poor for times\n                        # within 1 hour of each other.\n                        {\n\n                            # v1.4 \"field_value_factor\" does not yet support\n                            # \"missing\" param, and so must filter on whether\n                            # \"start_date\" field exists.\n                            \"filter\": {\n                                \"exists\": {\n                                    \"field\": \"start_date\",\n                                },\n                            },\n                            \"field_value_factor\": {\n                                \"field\": \"start_date\",\n                            }\n                        },\n                        {\n                            # Related to above, if \"start_date\" not found, omit\n                            # via zero score.\n                            \"filter\": {\n                                \"not\": {\n                                    \"exists\": {\n                                        \"field\": \"start_date\",\n                                    },\n                                },\n                            },\n                            \"weight\": 0,\n                        },\n\n\n                        # Ignore non-special-coverage percolator entries\n                        {\n                            \"filter\": {\n                                \"not\": {\n                                    \"prefix\": {\"_id\": \"specialcoverage\"},\n                                },\n                            },\n                            \"weight\": 0,\n                        },\n\n                        # Boost Manually Added Content\n                        {\n                            \"filter\": {\n                                \"terms\": {\n                                    \"included_ids\": [self.id],\n                                }\n                            },\n                            \"weight\": MANUALLY_ADDED_BOOST,\n                        },\n                        # Penalize Inactive (Zero Score Will be Omitted)\n                        {\n                            \"filter\": {\n                                \"or\": [\n                                    {\n                                        \"range\": {\n                                            \"start_date_epoch\": {\n                                                \"gt\": now_epoch,\n                                            },\n                                        }\n                                    },\n                                    {\n                                        \"range\": {\n                                            \"end_date_epoch\": {\n                                                \"lte\": now_epoch,\n                                            },\n                                        }\n                                    },\n                                ],\n                            },\n                            \"weight\": 0,\n                        },\n                        # Penalize Unsponsored (will either exclude or lower\n                        # based on \"sponsored_only\" flag)\n                        {\n                            \"filter\": {\n                                \"term\": {\n                                    \"sponsored\": False,\n                                }\n                            },\n                            \"weight\": unsponsored_boost,\n                        },\n                    ],\n                },\n            },\n\n            \"sort\": \"_score\",  # The only sort method supported by ES v1.4 percolator\n            \"size\": max_size,  # Required for sort\n        }\n\n        results = _percolate(index=self.mapping.index,\n                             doc_type=self.mapping.doc_type,\n                             content_id=self.id,\n                             body=sponsored_filter)\n\n        return [r[\"_id\"] for r in results\n                # Zero score used to omit results via scoring function (ex: inactive)\n                if r['_score'] > 0]", "response": "gets list of active sponsored special coverages containing this content via Elasticsearch Percolator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log(self, user, content, message):\n        return self.create(\n            user=user,\n            content_type=ContentType.objects.get_for_model(content),\n            object_id=content.pk,\n            change_message=message\n        )", "response": "creates a new log record with the given user content and message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, *args, **kwargs):\n        if not self.id:  # this is a totally new instance, create uuid value\n            self.url_uuid = str(uuid.uuid4()).replace(\"-\", \"\")\n        super(ObfuscatedUrlInfo, self).save(*args, **kwargs)", "response": "sets uuid for url\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_playlist_file(self, localdir):\n        path = \"{0}/playlists\".format(localdir)\n        if not os.path.exists(path):\n            os.makedirs(path)\n\n        filepath = \"{0}/{1}\".format(path, self.gen_filename())\n        playlist = open(filepath, \"w\")\n        for track in self.get_tracks():\n            playlist.write(\"{0}/{1}.mp3\\n\".format(\n                os.path.abspath(track.gen_localdir(localdir)),\n                track.gen_filename()))\n        playlist.close()", "response": "Write the playlist file to local directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of members as name type tuples", "response": "def getmembers(self):\n        \"\"\"\n        :return: list of members as name, type tuples\n        :rtype: list\n        \"\"\"\n        return filter(\n            lambda m: not m[0].startswith(\"__\") and not inspect.isfunction(m[1]) and not inspect.ismethod(m[1]),\n            inspect.getmembers(self.__class__)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_instance_attributes(self, arguments):\n        for attribute_name, type_instance in self.getmembers():\n            if isinstance(type_instance, DataType):\n                self._templates[attribute_name] = type_instance\n\n                value = None\n                if attribute_name in arguments:\n                    value = arguments[attribute_name]\n\n                try:\n                    self._attributes[attribute_name] = type_instance.validate(value)\n                # we can safely ignore required warnings during initialization\n                except exception.RequiredAttributeError:\n                    self._attributes[attribute_name] = None", "response": "Creates instance attributes for the class level attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of managed attributes for the Model class", "response": "def get_attribute_keys(self):\n        \"\"\"\n        Returns a list of managed attributes for the Model class\n\n        Implemented for use with data adapters, can be used to quickly make a list of the\n        attribute names in a prestans model\n        \"\"\"\n\n        _attribute_keys = list()\n\n        for attribute_name, type_instance in self.getmembers():\n\n            if isinstance(type_instance, DataType):\n                _attribute_keys.append(attribute_name)\n\n        return _attribute_keys"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the value of the current object.", "response": "def validate(self, value, attribute_filter=None, minified=False):\n        \"\"\"\n        :param value: serializable input to validate\n        :type value: dict | None\n        :param attribute_filter:\n        :type: prestans.parser.AttributeFilter | None\n        :param minified: whether or not the input is minified\n        :type minified: bool\n        :return: the validated model\n        :rtype: Model\n        \"\"\"\n\n        if self._required and (value is None or not isinstance(value, dict)):\n            \"\"\"\n            Model level validation requires a parsed dictionary\n            this is done by the serializer\n            \"\"\"\n            raise exception.RequiredAttributeError()\n\n        if not self._required and not value:\n            \"\"\"\n            Value was not provided by caller, but require a template\n            \"\"\"\n            return None\n\n        _model_instance = self.__class__()\n\n        rewrite_map = self.attribute_rewrite_map()\n\n        from prestans.parser import AttributeFilter\n        from prestans.parser import AttributeFilterImmutable\n\n        for attribute_name, type_instance in self.getmembers():\n            if not isinstance(type_instance, DataType):\n                raise TypeError(\"%s must be a DataType subclass\" % attribute_name)\n\n            if isinstance(attribute_filter, (AttributeFilter, AttributeFilterImmutable)) and \\\n               not attribute_filter.is_attribute_visible(attribute_name):\n                _model_instance._attributes[attribute_name] = None\n                continue\n\n            validation_input = None\n\n            input_value_key = attribute_name\n\n            # minification support\n            if minified is True:\n                input_value_key = rewrite_map[attribute_name]\n\n            if input_value_key in value:\n                validation_input = value[input_value_key]\n\n            try:\n\n                if isinstance(type_instance, DataCollection):\n                    sub_attribute_filter = None\n                    if attribute_filter and attribute_name in attribute_filter:\n                        sub_attribute_filter = getattr(attribute_filter, attribute_name)\n\n                    validated_object = type_instance.validate(\n                        validation_input,\n                        sub_attribute_filter,\n                        minified\n                    )\n                else:\n                    validated_object = type_instance.validate(validation_input)\n\n                _model_instance._attributes[attribute_name] = validated_object\n\n            except exception.DataValidationException as exp:\n                raise exception.ValidationError(\n                    message=str(exp),\n                    attribute_name=attribute_name,\n                    value=validation_input,\n                    blueprint=type_instance.blueprint()\n                )\n\n        return _model_instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attribute_rewrite_map(self):\n\n        rewrite_map = dict()\n        token_rewrite_map = self.generate_attribute_token_rewrite_map()\n\n        for attribute_name, type_instance in self.getmembers():\n\n            if isinstance(type_instance, DataType):\n                attribute_tokens = attribute_name.split('_')\n\n                rewritten_attribute_name = ''\n                for token in attribute_tokens:\n                    rewritten_attribute_name += token_rewrite_map[token] + \"_\"\n                # remove the trailing underscore\n                rewritten_attribute_name = rewritten_attribute_name[:-1]\n\n                rewrite_map[attribute_name] = rewritten_attribute_name\n\n        return rewrite_map", "response": "Generate a dictionary mapping long_name to attribute name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_serializable(self, attribute_filter=None, minified=False):\n        from prestans.parser import AttributeFilter\n        from prestans.parser import AttributeFilterImmutable\n        from prestans.types import Array\n\n        model_dictionary = dict()\n\n        rewrite_map = self.attribute_rewrite_map()\n\n        # convert filter to immutable if it isn't already\n        if isinstance(attribute_filter, AttributeFilter):\n            attribute_filter = attribute_filter.as_immutable()\n\n        for attribute_name, type_instance in self.getmembers():\n\n            if isinstance(attribute_filter, (AttributeFilter, AttributeFilterImmutable)) and \\\n               not attribute_filter.is_attribute_visible(attribute_name):\n                continue\n\n            # support minification\n            serialized_attribute_name = attribute_name\n            if minified is True:\n                serialized_attribute_name = rewrite_map[attribute_name]\n\n            if attribute_name not in self._attributes or self._attributes[attribute_name] is None:\n                if isinstance(type_instance, Array):\n                    model_dictionary[serialized_attribute_name] = []\n                else:\n                    model_dictionary[serialized_attribute_name] = None\n                continue\n\n            if isinstance(type_instance, DataCollection):\n\n                sub_attribute_filter = None\n                if isinstance(attribute_filter, (AttributeFilter, AttributeFilterImmutable)) and attribute_name in attribute_filter:\n                    sub_attribute_filter = getattr(attribute_filter, attribute_name)\n\n                model_dictionary[serialized_attribute_name] = self._attributes[attribute_name].as_serializable(sub_attribute_filter, minified)\n\n            elif isinstance(type_instance, DataStructure):\n                python_value = self._attributes[attribute_name]\n                serializable_value = type_instance.as_serializable(python_value)\n                model_dictionary[serialized_attribute_name] = serializable_value\n\n            elif isinstance(type_instance, DataType):\n                model_dictionary[serialized_attribute_name] = self._attributes[attribute_name]\n\n        return model_dictionary", "response": "Returns a dictionary with attributes and pure python representation of the data instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the enrollments in a course.", "response": "def list_enrollments_courses(self, course_id, grading_period_id=None, include=None, role=None, sis_account_id=None, sis_course_id=None, sis_section_id=None, sis_user_id=None, state=None, type=None, user_id=None):\r\n        \"\"\"\r\n        List enrollments.\r\n\r\n        Depending on the URL given, return either (1) all of the enrollments in\r\n        a course, (2) all of the enrollments in a section or (3) all of a user's\r\n        enrollments. This includes student, teacher, TA, and observer enrollments.\r\n        \r\n        If a user has multiple enrollments in a context (e.g. as a teacher\r\n        and a student or in multiple course sections), each enrollment will be\r\n        listed separately.\r\n        \r\n        note: Currently, only an admin user can return other users' enrollments. A\r\n        user can, however, return his/her own enrollments.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - type\r\n        \"\"\"A list of enrollment types to return. Accepted values are\r\n        'StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment',\r\n        'DesignerEnrollment', and 'ObserverEnrollment.' If omitted, all enrollment\r\n        types are returned. This argument is ignored if `role` is given.\"\"\"\r\n        if type is not None:\r\n            params[\"type\"] = type\r\n\r\n        # OPTIONAL - role\r\n        \"\"\"A list of enrollment roles to return. Accepted values include course-level\r\n        roles created by the {api:RoleOverridesController#add_role Add Role API}\r\n        as well as the base enrollment types accepted by the `type` argument above.\"\"\"\r\n        if role is not None:\r\n            params[\"role\"] = role\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"Filter by enrollment state. If omitted, 'active' and 'invited' enrollments\r\n        are returned. When querying a user's enrollments (either via user_id\r\n        argument or via user enrollments endpoint), the following additional\r\n        synthetic states are supported: \"current_and_invited\"|\"current_and_future\"|\"current_and_concluded\"\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"active\", \"invited\", \"creation_pending\", \"deleted\", \"rejected\", \"completed\", \"inactive\"])\r\n            params[\"state\"] = state\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Array of additional information to include on the enrollment or user records.\r\n        \"avatar_url\" and \"group_ids\" will be returned on the user record.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"avatar_url\", \"group_ids\", \"locked\", \"observed_users\", \"can_be_removed\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - user_id\r\n        \"\"\"Filter by user_id (only valid for course or section enrollment\r\n        queries). If set to the current user's id, this is a way to\r\n        determine if the user has any enrollments in the course or section,\r\n        independent of whether the user has permission to view other people\r\n        on the roster.\"\"\"\r\n        if user_id is not None:\r\n            params[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - grading_period_id\r\n        \"\"\"Return grades for the given grading_period.  If this parameter is not\r\n        specified, the returned grades will be for the whole course.\"\"\"\r\n        if grading_period_id is not None:\r\n            params[\"grading_period_id\"] = grading_period_id\r\n\r\n        # OPTIONAL - sis_account_id\r\n        \"\"\"Returns only enrollments for the specified SIS account ID(s). Does not\r\n        look into subaccounts. May pass in array or string.\"\"\"\r\n        if sis_account_id is not None:\r\n            params[\"sis_account_id\"] = sis_account_id\r\n\r\n        # OPTIONAL - sis_course_id\r\n        \"\"\"Returns only enrollments matching the specified SIS course ID(s).\r\n        May pass in array or string.\"\"\"\r\n        if sis_course_id is not None:\r\n            params[\"sis_course_id\"] = sis_course_id\r\n\r\n        # OPTIONAL - sis_section_id\r\n        \"\"\"Returns only section enrollments matching the specified SIS section ID(s).\r\n        May pass in array or string.\"\"\"\r\n        if sis_section_id is not None:\r\n            params[\"sis_section_id\"] = sis_section_id\r\n\r\n        # OPTIONAL - sis_user_id\r\n        \"\"\"Returns only enrollments for the specified SIS user ID(s). May pass in\r\n        array or string.\"\"\"\r\n        if sis_user_id is not None:\r\n            params[\"sis_user_id\"] = sis_user_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/enrollments with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/enrollments\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenrolling a user in a course or section.", "response": "def enroll_user_courses(self, course_id, enrollment_type, enrollment_user_id, enrollment_associated_user_id=None, enrollment_course_section_id=None, enrollment_enrollment_state=None, enrollment_limit_privileges_to_course_section=None, enrollment_notify=None, enrollment_role=None, enrollment_role_id=None, enrollment_self_enrolled=None, enrollment_self_enrollment_code=None):\r\n        \"\"\"\r\n        Enroll a user.\r\n\r\n        Create a new user enrollment for a course or section.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - enrollment[user_id]\r\n        \"\"\"The ID of the user to be enrolled in the course.\"\"\"\r\n        data[\"enrollment[user_id]\"] = enrollment_user_id\r\n\r\n        # REQUIRED - enrollment[type]\r\n        \"\"\"Enroll the user as a student, teacher, TA, observer, or designer. If no\r\n        value is given, the type will be inferred by enrollment[role] if supplied,\r\n        otherwise 'StudentEnrollment' will be used.\"\"\"\r\n        self._validate_enum(enrollment_type, [\"StudentEnrollment\", \"TeacherEnrollment\", \"TaEnrollment\", \"ObserverEnrollment\", \"DesignerEnrollment\"])\r\n        data[\"enrollment[type]\"] = enrollment_type\r\n\r\n        # OPTIONAL - enrollment[role]\r\n        \"\"\"Assigns a custom course-level role to the user.\"\"\"\r\n        if enrollment_role is not None:\r\n            data[\"enrollment[role]\"] = enrollment_role\r\n\r\n        # OPTIONAL - enrollment[role_id]\r\n        \"\"\"Assigns a custom course-level role to the user.\"\"\"\r\n        if enrollment_role_id is not None:\r\n            data[\"enrollment[role_id]\"] = enrollment_role_id\r\n\r\n        # OPTIONAL - enrollment[enrollment_state]\r\n        \"\"\"If set to 'active,' student will be immediately enrolled in the course.\r\n        Otherwise they will be required to accept a course invitation. Default is\r\n        'invited.'.\r\n        \r\n        If set to 'inactive', student will be listed in the course roster for\r\n        teachers, but will not be able to participate in the course until\r\n        their enrollment is activated.\"\"\"\r\n        if enrollment_enrollment_state is not None:\r\n            self._validate_enum(enrollment_enrollment_state, [\"active\", \"invited\", \"inactive\"])\r\n            data[\"enrollment[enrollment_state]\"] = enrollment_enrollment_state\r\n\r\n        # OPTIONAL - enrollment[course_section_id]\r\n        \"\"\"The ID of the course section to enroll the student in. If the\r\n        section-specific URL is used, this argument is redundant and will be\r\n        ignored.\"\"\"\r\n        if enrollment_course_section_id is not None:\r\n            data[\"enrollment[course_section_id]\"] = enrollment_course_section_id\r\n\r\n        # OPTIONAL - enrollment[limit_privileges_to_course_section]\r\n        \"\"\"If set, the enrollment will only allow the user to see and interact with\r\n        users enrolled in the section given by course_section_id.\r\n        * For teachers and TAs, this includes grading privileges.\r\n        * Section-limited students will not see any users (including teachers\r\n          and TAs) not enrolled in their sections.\r\n        * Users may have other enrollments that grant privileges to\r\n          multiple sections in the same course.\"\"\"\r\n        if enrollment_limit_privileges_to_course_section is not None:\r\n            data[\"enrollment[limit_privileges_to_course_section]\"] = enrollment_limit_privileges_to_course_section\r\n\r\n        # OPTIONAL - enrollment[notify]\r\n        \"\"\"If true, a notification will be sent to the enrolled user.\r\n        Notifications are not sent by default.\"\"\"\r\n        if enrollment_notify is not None:\r\n            data[\"enrollment[notify]\"] = enrollment_notify\r\n\r\n        # OPTIONAL - enrollment[self_enrollment_code]\r\n        \"\"\"If the current user is not allowed to manage enrollments in this\r\n        course, but the course allows self-enrollment, the user can self-\r\n        enroll as a student in the default section by passing in a valid\r\n        code. When self-enrolling, the user_id must be 'self'. The\r\n        enrollment_state will be set to 'active' and all other arguments\r\n        will be ignored.\"\"\"\r\n        if enrollment_self_enrollment_code is not None:\r\n            data[\"enrollment[self_enrollment_code]\"] = enrollment_self_enrollment_code\r\n\r\n        # OPTIONAL - enrollment[self_enrolled]\r\n        \"\"\"If true, marks the enrollment as a self-enrollment, which gives\r\n        students the ability to drop the course if desired. Defaults to false.\"\"\"\r\n        if enrollment_self_enrolled is not None:\r\n            data[\"enrollment[self_enrolled]\"] = enrollment_self_enrolled\r\n\r\n        # OPTIONAL - enrollment[associated_user_id]\r\n        \"\"\"For an observer enrollment, the ID of a student to observe. The\r\n        caller must have +manage_students+ permission in the course.\r\n        This is a one-off operation; to automatically observe all a\r\n        student's enrollments (for example, as a parent), please use\r\n        the {api:UserObserveesController#create User Observees API}.\"\"\"\r\n        if enrollment_associated_user_id is not None:\r\n            data[\"enrollment[associated_user_id]\"] = enrollment_associated_user_id\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/enrollments with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/enrollments\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conclude_deactivate_or_delete_enrollment(self, id, course_id, task=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - task\r\n        \"\"\"The action to take on the enrollment.\r\n        When inactive, a user will still appear in the course roster to admins, but be unable to participate.\r\n        (\"inactivate\" and \"deactivate\" are equivalent tasks)\"\"\"\r\n        if task is not None:\r\n            self._validate_enum(task, [\"conclude\", \"delete\", \"inactivate\", \"deactivate\"])\r\n            params[\"task\"] = task\r\n\r\n        self.logger.debug(\"DELETE /api/v1/courses/{course_id}/enrollments/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/courses/{course_id}/enrollments/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Conclude deactivate or delete an enrollment. Conclude deactivate or delete an enrollment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_ints_based_on_vlan(interfaces, vlan, count=1):\n\n    filtered_interfaces = []\n    for interface in interfaces:\n        if interface.obj_type() == 'interface':\n            ixn_vlan = interface.get_object_by_type('vlan')\n            vlanEnable = is_true(ixn_vlan.get_attribute('vlanEnable'))\n            vlanCount = int(ixn_vlan.get_attribute('vlanCount'))\n        elif interface.obj_type() == 'range':\n            ixn_vlan = interface.get_object_by_type('vlanRange')\n            vlanEnable = is_true(ixn_vlan.get_attribute('enabled'))\n            vlanCount = len(ixn_vlan.get_objects_by_type('vlanIdInfo'))\n        else:\n            ixn_vlan = interface.get_object_by_type('ethernet')\n            vlanEnable = is_true(ixn_vlan.get_attribute('useVlans'))\n            vlanCount = int(ixn_vlan.get_attribute('vlanCount'))\n        if not (vlanEnable ^ vlan) and vlanCount == count:\n            filtered_interfaces.append(interface)\n    return filtered_interfaces", "response": "Filter list of interfaces based on VLAN presence or absence criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate new interface on IxNetwork.", "response": "def _create(self, **attributes):\n        \"\"\" Create new interface on IxNetwork.\n\n        Set enabled and description (==name).\n\n        :return: interface object reference.\n        \"\"\"\n\n        attributes['enabled'] = True\n        if 'name' in self._data:\n            attributes['description'] = self._data['name']\n        obj_ref = self.api.add(self.obj_parent(), self.obj_type(), **attributes)\n        self.api.commit()\n        return self.api.remapIds(obj_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of constraint names matching the columns and conditions.", "response": "def _constraint_names(self, model, column_names=None, unique=None,\n                          primary_key=None, index=None, foreign_key=None,\n                          check=None):\n        \"\"\"\n        Returns all constraint names matching the columns and conditions\n        \"\"\"\n        column_names = list(column_names) if column_names else None\n        with self.connection.cursor() as cursor:\n            constraints = get_constraints(cursor, model._meta.db_table)\n        result = []\n        for name, infodict in constraints.items():\n            if column_names is None or column_names == infodict['columns']:\n                if unique is not None and infodict['unique'] != unique:\n                    continue\n                if primary_key is not None and infodict['primary_key'] != primary_key:\n                    continue\n                if index is not None and infodict['index'] != index:\n                    continue\n                if check is not None and infodict['check'] != check:\n                    continue\n                if foreign_key is not None and not infodict['foreign_key']:\n                    continue\n                result.append(name)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the log entry is a scalar.", "response": "def is_scalar(self):\n        \"\"\"\n        :return:\n        :rtype: bool\n        \"\"\"\n        return \\\n            isinstance(self._element_template, Boolean) or \\\n            isinstance(self._element_template, Float) or  \\\n            isinstance(self._element_template, Integer) or \\\n            isinstance(self._element_template, String)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate(self, value, attribute_filter=None, minified=False):\n\n        if not self._required and value is None:\n            return None\n        elif self._required and value is None:\n            raise exception.RequiredAttributeError()\n\n        _validated_value = self.__class__(\n            element_template=self._element_template,\n            min_length=self._min_length,\n            max_length=self._max_length\n        )\n\n        if not isinstance(value, (list, tuple)):\n            raise TypeError(value)\n\n        for array_element in value:\n\n            if isinstance(self._element_template, DataCollection):\n                validated_array_element = self._element_template.validate(array_element, attribute_filter, minified)\n            else:\n                validated_array_element = self._element_template.validate(array_element)\n\n            _validated_value.append(validated_array_element)\n\n        if self._min_length is not None and len(_validated_value) < self._min_length:\n            raise exception.LessThanMinimumError(value, self._min_length)\n\n        if self._max_length is not None and len(_validated_value) > self._max_length:\n            raise exception.MoreThanMaximumError(value, self._max_length)\n\n        return _validated_value", "response": "Validate the value of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nproviding a decorator for RESTRequestHandler methods to check for authenticated users RESTRequestHandler subclass must have a auth_context instance, refer to prestans.auth for the parent class definition. If decorator is used and no auth_context is provided the client will be denied access. Handler will return a 401 Unauthorized if the user is not logged in, the service does not redirect to login handler page, this is the client's responsibility. auth_context_handler instance provides a message called get_current_user, use this to obtain a reference to an authenticated user profile. If all goes well, the original handler definition is executed.", "response": "def login_required(http_method_handler):\n    \"\"\"\n    provides a decorator for RESTRequestHandler methods to check for authenticated users\n\n    RESTRequestHandler subclass must have a auth_context instance, refer to prestans.auth\n    for the parent class definition.\n\n    If decorator is used and no auth_context is provided the client will be denied access.\n\n    Handler will return a 401 Unauthorized if the user is not logged in, the service does\n    not redirect to login handler page, this is the client's responsibility.\n\n    auth_context_handler instance provides a message called get_current_user, use this\n    to obtain a reference to an authenticated user profile.\n\n    If all goes well, the original handler definition is executed.\n    \"\"\"\n\n    @wraps(http_method_handler)\n    def secure_http_method_handler(self, *args, **kwargs):\n\n        if not self.__provider_config__.authentication:\n            _message = \"Service available to authenticated users only, no auth context provider set in handler\"\n            authentication_error = prestans.exception.AuthenticationError(_message)\n            authentication_error.request = self.request\n            raise authentication_error\n\n        if not self.__provider_config__.authentication.is_authenticated_user():\n            authentication_error = prestans.exception.AuthenticationError()\n            authentication_error.request = self.request\n            raise authentication_error\n\n        http_method_handler(self, *args, **kwargs)\n\n    return secure_http_method_handler"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nauthenticate a HTTP method handler based on a provided role With a little help from Peter Cole's Blog http://mrcoles.com/blog/3-decorator-examples-and-awesome-python/", "response": "def role_required(role_name=None):\n    \"\"\"\n    Authenticates a HTTP method handler based on a provided role\n\n    With a little help from Peter Cole's Blog\n    http://mrcoles.com/blog/3-decorator-examples-and-awesome-python/\n    \"\"\"\n\n    def _role_required(http_method_handler):\n\n        @wraps(http_method_handler)\n        def secure_http_method_handler(self, *args, **kwargs):\n\n            # role name must be provided\n            if role_name is None:\n                _message = \"Role name must be provided\"\n                authorization_error = prestans.exception.AuthorizationError(_message)\n                authorization_error.request = self.request\n                raise authorization_error\n\n            # authentication context must be set\n            if not self.__provider_config__.authentication:\n                _message = \"Service available to authenticated users only, no auth context provider set in handler\"\n                authentication_error = prestans.exception.AuthenticationError(_message)\n                authentication_error.request = self.request\n                raise authentication_error\n\n            # check for the role by calling current_user_has_role\n            if not self.__provider_config__.authentication.current_user_has_role(role_name):\n                authorization_error = prestans.exception.AuthorizationError(role_name)\n                authorization_error.request = self.request\n                raise authorization_error\n\n            http_method_handler(self, *args, **kwargs)\n\n        return wraps(http_method_handler)(secure_http_method_handler)\n\n    return _role_required"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef access_required(config=None):\n\n    def _access_required(http_method_handler):\n\n        def secure_http_method_handler(self, *args, **kwargs):\n\n            # authentication context must be set\n            if not self.__provider_config__.authentication:\n                _message = \"Service available to authenticated users only, no auth context provider set in handler\"\n                authentication_error = prestans.exception.AuthenticationError(_message)\n                authentication_error.request = self.request\n                raise authentication_error\n\n            # check for access by calling is_authorized_user\n            if not self.__provider_config__.authentication.is_authorized_user(config):\n                _message = \"Service available to authorized users only\"\n                authorization_error = prestans.exception.AuthorizationError(_message)\n                authorization_error.request = self.request\n                raise authorization_error\n\n            http_method_handler(self, *args, **kwargs)\n\n        return wraps(http_method_handler)(secure_http_method_handler)\n\n    return _access_required", "response": "Decorator that checks if a user is authorized to access the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn the attribute filter object into python dictionary", "response": "def as_dict(self):\n        \"\"\"\n        turns attribute filter object into python dictionary\n        \"\"\"\n        output_dictionary = dict()\n\n        for key, value in iter(self._key_map.items()):\n            if isinstance(value, bool):\n                output_dictionary[key] = value\n            elif isinstance(value, self.__class__):\n                output_dictionary[key] = value.as_dict()\n\n        return output_dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the setup script.", "response": "def gen_setup(config, default_build_type, relative_path, setup_script_name):\n    \"\"\"\n    Generate setup script.\n    \"\"\"\n    from autocmake.extract import extract_list\n\n    s = []\n    s.append('#!/usr/bin/env python')\n    s.append('\\n{0}'.format(autogenerated_notice()))\n    s.append('\\nimport os')\n    s.append('import sys')\n    s.append('assert sys.version_info >= (2, 6), \\'Python >= 2.6 is required\\'')\n\n    s.append(\"\\nsys.path.insert(0, '{0}')\".format(relative_path))\n\n    s.append('from autocmake import configure')\n    s.append('from autocmake.external import docopt')\n\n    s.append('\\n\\noptions = \"\"\"')\n    s.append('Usage:')\n    s.append('  ./{0} [options] [<builddir>]'.format(setup_script_name))\n    s.append('  ./{0} (-h | --help)'.format(setup_script_name))\n    s.append('\\nOptions:')\n\n    options = []\n\n    for opt in config['docopt']:\n        first = opt.split()[0].strip()\n        rest = ' '.join(opt.split()[1:]).strip()\n        options.append([first, rest])\n\n    options.append(['--type=<TYPE>', 'Set the CMake build type (debug, release, relwithdebinfo, minsizerel) [default: {0}].'.format(default_build_type)])\n    options.append(['--generator=<STRING>', 'Set the CMake build system generator [default: Unix Makefiles].'])\n    options.append(['--show', 'Show CMake command and exit.'])\n    options.append(['--cmake-executable=<CMAKE_EXECUTABLE>', 'Set the CMake executable [default: cmake].'])\n    options.append(['--cmake-options=<STRING>', \"Define options to CMake [default: ''].\"])\n    options.append(['--prefix=<PATH>', 'Set the install path for make install.'])\n    options.append(['<builddir>', 'Build directory.'])\n    options.append(['-h --help', 'Show this screen.'])\n\n    s.append(align_options(options))\n\n    s.append('\"\"\"')\n\n    s.append(gen_cmake_command(config))\n\n    s.append(\"\\n\")\n    s.append(\"# parse command line args\")\n    s.append(\"try:\")\n    s.append(\"    arguments = docopt.docopt(options, argv=None)\")\n    s.append(\"except docopt.DocoptExit:\")\n    s.append(r\"    sys.stderr.write('ERROR: bad input to {0}\\n'.format(sys.argv[0]))\")\n    s.append(\"    sys.stderr.write(options)\")\n    s.append(\"    sys.exit(-1)\")\n    s.append(\"\\n\")\n    s.append(\"# use extensions to validate/post-process args\")\n    s.append(\"if configure.module_exists('extensions'):\")\n    s.append(\"    import extensions\")\n    s.append(\"    arguments = extensions.postprocess_args(sys.argv, arguments)\")\n    s.append(\"\\n\")\n    s.append(\"root_directory = os.path.dirname(os.path.realpath(__file__))\")\n    s.append(\"\\n\")\n    s.append(\"build_path = arguments['<builddir>']\")\n    s.append(\"\\n\")\n    s.append(\"# create cmake command\")\n    s.append(\"cmake_command = '{0} -H{1}'.format(gen_cmake_command(options, arguments), root_directory)\")\n    s.append(\"\\n\")\n    s.append(\"# run cmake\")\n    s.append(\"configure.configure(root_directory, build_path, cmake_command, arguments['--show'])\")\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nalign the options to the length of the main help text.", "response": "def align_options(options):\n    \"\"\"\n    Indents flags and aligns help texts.\n    \"\"\"\n    l = 0\n    for opt in options:\n        if len(opt[0]) > l:\n            l = len(opt[0])\n    s = []\n    for opt in options:\n        s.append('  {0}{1}  {2}'.format(opt[0], ' ' * (l - len(opt[0])), opt[1]))\n    return '\\n'.join(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of formatted tracebacks for the given exception type and value.", "response": "def format_exception(etype, value, tback, limit=None):\n    \"\"\"\n    Python 2 compatible version of traceback.format_exception\n    Accepts negative limits like the Python 3 version\n    \"\"\"\n\n    rtn = ['Traceback (most recent call last):\\n']\n\n    if limit is None or limit >= 0:\n        rtn.extend(traceback.format_tb(tback, limit))\n    else:\n        rtn.extend(traceback.format_list(traceback.extract_tb(tback)[limit:]))\n\n    rtn.extend(traceback.format_exception_only(etype, value))\n\n    return rtn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting a module and returns the object that can be used to adb - related information.", "response": "def _import_module(name, path=None):\n    \"\"\"\n    Args:\n        name(str):\n            * Full name of object\n            * name can also be an EntryPoint object, name and path will be determined dynamically\n        path(str): Module directory\n\n    Returns:\n        object: module object or advertised object for EntryPoint\n\n    Loads a module using importlib catching exceptions\n    If path is given, the traceback will be formatted to give more friendly and direct information\n    \"\"\"\n\n    # If name is an entry point, try to parse it\n    epoint = None\n    if isinstance(name, EntryPoint):\n        epoint = name\n        name = epoint.module_name\n\n    if path is None:\n        try:\n            loader = pkgutil.get_loader(name)\n        except ImportError:\n            pass\n        else:\n            if loader:\n                path = os.path.dirname(loader.get_filename(name))\n\n    LOGGER.debug('Attempting to load module %s from %s', name, path)\n    try:\n        if epoint:\n            mod = epoint.load()\n        else:\n            mod = importlib.import_module(name)\n\n    except Exception as e:  # pylint: disable=broad-except\n\n        etype = e.__class__\n        tback = getattr(e, '__traceback__', sys.exc_info()[2])\n\n        # Create traceback starting at module for friendly output\n        start = 0\n        here = 0\n        tb_list = traceback.extract_tb(tback)\n\n        if path:\n            for idx, entry in enumerate(tb_list):\n                # Find index for traceback starting with module we tried to load\n                if os.path.dirname(entry[0]) == path:\n                    start = idx\n                    break\n                # Find index for traceback starting with this file\n                elif os.path.splitext(entry[0])[0] == os.path.splitext(__file__)[0]:\n                    here = idx\n\n        if start == 0 and isinstance(e, SyntaxError):\n            limit = 0\n        else:\n            limit = 0 - len(tb_list) + max(start, here)\n\n        # pylint: disable=wrong-spelling-in-comment\n        # friendly = ''.join(traceback.format_exception(etype, e, tback, limit))\n        friendly = ''.join(format_exception(etype, e, tback, limit))\n\n        # Format exception\n        msg = 'Error while importing candidate plugin module %s from %s' % (name, path)\n        exception = PluginImportError('%s: %s' % (msg, repr(e)), friendly=friendly)\n\n        raise_with_traceback(exception, tback)\n\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading modules from locations specified during initialization.", "response": "def load_modules(self):\n        \"\"\"\n        Locate and import modules from locations specified during initialization.\n\n        Locations include:\n            - Program's standard library (``library``)\n            - `Entry points <Entry point_>`_ (``entry_point``)\n            - Specified modules (``modules``)\n            - Specified paths (``paths``)\n\n        If a malformed child plugin class is imported, a :py:exc:`PluginWarning` will be issued,\n        the class is skipped, and loading operations continue.\n\n        If an invalid `entry point <Entry point_>`_ is specified, an :py:exc:`EntryPointWarning`\n        is issued and loading operations continue.\n        \"\"\"\n\n        # Start with standard library\n        if self.library:\n            LOGGER.info('Loading plugins from standard library')\n            libmod = _import_module(self.library)\n            _recursive_import(libmod)\n\n        # Get entry points\n        if self.entry_point:\n            LOGGER.info('Loading plugins from entry points group %s', self.entry_point)\n            for epoint in iter_entry_points(group=self.entry_point):\n                try:\n                    mod = _import_module(epoint)\n                except PluginImportError as e:\n                    warnings.warn(\"Module %s can not be loaded for entry point %s: %s\" %\n                                  (epoint.module_name, epoint.name, e), EntryPointWarning)\n                    continue\n\n                # If we have a package, walk it\n                if ismodule(mod):\n                    _recursive_import(mod)\n                else:\n                    warnings.warn(\"Entry point '%s' is not a module or package\" % epoint.name,\n                                  EntryPointWarning)\n\n        # Load auxiliary modules\n        if self.modules:\n            for mod in self.modules:\n                LOGGER.info('Loading plugins from %s', mod)\n                _recursive_import(_import_module(mod))\n\n        # Load auxiliary paths\n        if self.paths:\n            auth_paths_mod = importlib.import_module(self.prefix_package)\n            initial_path = auth_paths_mod.__path__[:]\n\n            # Append each path to module path\n            for path in self.paths:\n\n                modpath = os.path.realpath(path)\n                if os.path.isdir(modpath):\n                    LOGGER.info('Adding %s as a plugin search path', path)\n                    if modpath not in auth_paths_mod.__path__:\n                        auth_paths_mod.__path__.append(modpath)\n\n                else:\n                    LOGGER.info(\"Configured plugin path '%s' is not a valid directory\", path)\n\n            # Walk packages\n            try:\n                _recursive_import(auth_paths_mod)\n\n            finally:\n                # Restore Path\n                auth_paths_mod.__path__[:] = initial_path\n\n        self.loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plugins(self):\n\n        if not self.loaded:\n            self.load_modules()\n\n        # pylint: disable=protected-access\n        return get_plugins()[self.group]._filter(blacklist=self.blacklist, newest_only=True,\n                                                 type_filter=self.type_filter)", "response": "Return a nested dictionary of all plugins in the group filtered by blacklist"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a nested dictionary of all plugins in the group filtered by blacklist", "response": "def plugins_all(self):\n        \"\"\"\n        All resulting versions of all plugins in the group filtered by ``blacklist``\n\n        Returns:\n            dict: Nested dictionary of plugins accessible through dot-notation.\n\n        Similar to :py:attr:`plugins`, but lowest level is a regular dictionary of\n        all unfiltered plugin versions for the given plugin type and name.\n\n        Parent types are always included.\n        Child plugins will only be included if at least one valid, non-blacklisted plugin\n        is available.\n        \"\"\"\n\n        if not self.loaded:\n            self.load_modules()\n\n        # pylint: disable=protected-access\n        return get_plugins()[self.group]._filter(blacklist=self.blacklist,\n                                                 type_filter=self.type_filter)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plugin(self, plugin_type, name, version=None):\n\n        if not self.loaded:\n            self.load_modules()\n\n        # pylint: disable=protected-access\n        return get_plugins()[self.group]._filter(blacklist=self.blacklist,\n                                                 newest_only=True,\n                                                 type_filter=self.type_filter,\n                                                 type=plugin_type,\n                                                 name=name,\n                                                 version=version)", "response": "Returns a specific plugin from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert multiple rows into a table that do not already exist.", "response": "def insert_uniques(self, table, columns, values):\n        \"\"\"\n        Insert multiple rows into a table that do not already exist.\n\n        If the rows primary key already exists, the rows values will be updated.\n        If the rows primary key does not exists, a new row will be inserted\n        \"\"\"\n        # Rows that exist in the table\n        existing_rows = self.select(table, columns)\n\n        # Rows that DO NOT exist in the table\n        unique = diff(existing_rows, values, y_only=True)  # Get values that are not in existing_rows\n\n        # Keys that exist in the table\n        keys = self.get_primary_key_vals(table)\n\n        # Primary key's column index\n        pk_col = self.get_primary_key(table)\n        pk_index = columns.index(pk_col)\n\n        # Split list of unique rows into list of rows to update and rows to insert\n        to_insert, to_update = [], []\n        for index, row in enumerate(unique):\n            # Primary key is not in list of pk values, insert new row\n            if row[pk_index] not in keys:\n                to_insert.append(unique[index])\n\n            # Primary key exists, update row rather than insert\n            elif row[pk_index] in keys:\n                to_update.append(unique[index])\n\n        # Insert new rows\n        if len(to_insert) > 0:\n            self.insert_many(table, columns, to_insert)\n\n        # Update existing rows\n        if len(to_update) > 0:\n            self.update_many(table, columns, to_update, pk_col, 0)\n\n        # No inserted or updated rows\n        if len(to_insert) < 1 and len(to_update) < 0:\n            self._printer('No rows added to', table)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, table, columns, values, execute=True):\n        # TODO: Cant accept lists?\n        # Concatenate statement\n        cols, vals = get_col_val_str(columns)\n        statement = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(wrap(table), cols, vals)\n\n        # Execute statement\n        if execute:\n            self._cursor.execute(statement, values)\n            self._commit()\n            self._printer('\\tMySQL row successfully inserted into {0}'.format(table))\n\n        # Only return statement\n        else:\n            return statement", "response": "Insert a single row into a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_many(self, table, columns, values, limit=MAX_ROWS_PER_QUERY, execute=True):\n        # Make values a list of lists if it is a flat list\n        if not isinstance(values[0], (list, set, tuple)):\n            values = []\n            for v in values:\n                if v is not None and len(v) > 0:\n                    values.append([v])\n                else:\n                    values.append([None])\n\n        # Concatenate statement\n        cols, vals = get_col_val_str(columns)\n        statement = 'INSERT INTO {0} ({1}) VALUES ({2})'.format(wrap(table), cols, vals)\n\n        if execute and len(values) > limit:\n            while len(values) > 0:\n                vals = [values.pop(0) for i in range(0, min(limit, len(values)))]\n                self._cursor.executemany(statement, vals)\n                self._commit()\n\n        elif execute:\n            # Execute statement\n            self._cursor.executemany(statement, values)\n            self._commit()\n            self._printer('\\tMySQL rows (' + str(len(values)) + ') successfully INSERTED')\n\n        # Only return statement\n        else:\n            return statement", "response": "Insert multiple rows into a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist quizzes in a course. Returns the list of Quizzes in this course.", "response": "def list_quizzes_in_course(self, course_id, search_term=None):\r\n        \"\"\"\r\n        List quizzes in a course.\r\n\r\n        Returns the list of Quizzes in this course.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial title of the quizzes to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/quizzes with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/quizzes\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new quiz for this course.", "response": "def create_quiz(self, course_id, quiz_title, quiz_access_code=None, quiz_allowed_attempts=None, quiz_assignment_group_id=None, quiz_cant_go_back=None, quiz_description=None, quiz_due_at=None, quiz_hide_correct_answers_at=None, quiz_hide_results=None, quiz_ip_filter=None, quiz_lock_at=None, quiz_one_question_at_a_time=None, quiz_one_time_results=None, quiz_only_visible_to_overrides=None, quiz_published=None, quiz_quiz_type=None, quiz_scoring_policy=None, quiz_show_correct_answers=None, quiz_show_correct_answers_at=None, quiz_show_correct_answers_last_attempt=None, quiz_shuffle_answers=None, quiz_time_limit=None, quiz_unlock_at=None):\r\n        \"\"\"\r\n        Create a quiz.\r\n\r\n        Create a new quiz for this course.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - quiz[title]\r\n        \"\"\"The quiz title.\"\"\"\r\n        data[\"quiz[title]\"] = quiz_title\r\n\r\n        # OPTIONAL - quiz[description]\r\n        \"\"\"A description of the quiz.\"\"\"\r\n        if quiz_description is not None:\r\n            data[\"quiz[description]\"] = quiz_description\r\n\r\n        # OPTIONAL - quiz[quiz_type]\r\n        \"\"\"The type of quiz.\"\"\"\r\n        if quiz_quiz_type is not None:\r\n            self._validate_enum(quiz_quiz_type, [\"practice_quiz\", \"assignment\", \"graded_survey\", \"survey\"])\r\n            data[\"quiz[quiz_type]\"] = quiz_quiz_type\r\n\r\n        # OPTIONAL - quiz[assignment_group_id]\r\n        \"\"\"The assignment group id to put the assignment in. Defaults to the top\r\n        assignment group in the course. Only valid if the quiz is graded, i.e. if\r\n        quiz_type is \"assignment\" or \"graded_survey\".\"\"\"\r\n        if quiz_assignment_group_id is not None:\r\n            data[\"quiz[assignment_group_id]\"] = quiz_assignment_group_id\r\n\r\n        # OPTIONAL - quiz[time_limit]\r\n        \"\"\"Time limit to take this quiz, in minutes. Set to null for no time limit.\r\n        Defaults to null.\"\"\"\r\n        if quiz_time_limit is not None:\r\n            data[\"quiz[time_limit]\"] = quiz_time_limit\r\n\r\n        # OPTIONAL - quiz[shuffle_answers]\r\n        \"\"\"If true, quiz answers for multiple choice questions will be randomized for\r\n        each student. Defaults to false.\"\"\"\r\n        if quiz_shuffle_answers is not None:\r\n            data[\"quiz[shuffle_answers]\"] = quiz_shuffle_answers\r\n\r\n        # OPTIONAL - quiz[hide_results]\r\n        \"\"\"Dictates whether or not quiz results are hidden from students.\r\n        If null, students can see their results after any attempt.\r\n        If \"always\", students can never see their results.\r\n        If \"until_after_last_attempt\", students can only see results after their\r\n        last attempt. (Only valid if allowed_attempts > 1). Defaults to null.\"\"\"\r\n        if quiz_hide_results is not None:\r\n            self._validate_enum(quiz_hide_results, [\"always\", \"until_after_last_attempt\"])\r\n            data[\"quiz[hide_results]\"] = quiz_hide_results\r\n\r\n        # OPTIONAL - quiz[show_correct_answers]\r\n        \"\"\"Only valid if hide_results=null\r\n        If false, hides correct answers from students when quiz results are viewed.\r\n        Defaults to true.\"\"\"\r\n        if quiz_show_correct_answers is not None:\r\n            data[\"quiz[show_correct_answers]\"] = quiz_show_correct_answers\r\n\r\n        # OPTIONAL - quiz[show_correct_answers_last_attempt]\r\n        \"\"\"Only valid if show_correct_answers=true and allowed_attempts > 1\r\n        If true, hides correct answers from students when quiz results are viewed\r\n        until they submit the last attempt for the quiz.\r\n        Defaults to false.\"\"\"\r\n        if quiz_show_correct_answers_last_attempt is not None:\r\n            data[\"quiz[show_correct_answers_last_attempt]\"] = quiz_show_correct_answers_last_attempt\r\n\r\n        # OPTIONAL - quiz[show_correct_answers_at]\r\n        \"\"\"Only valid if show_correct_answers=true\r\n        If set, the correct answers will be visible by students only after this\r\n        date, otherwise the correct answers are visible once the student hands in\r\n        their quiz submission.\"\"\"\r\n        if quiz_show_correct_answers_at is not None:\r\n            data[\"quiz[show_correct_answers_at]\"] = quiz_show_correct_answers_at\r\n\r\n        # OPTIONAL - quiz[hide_correct_answers_at]\r\n        \"\"\"Only valid if show_correct_answers=true\r\n        If set, the correct answers will stop being visible once this date has\r\n        passed. Otherwise, the correct answers will be visible indefinitely.\"\"\"\r\n        if quiz_hide_correct_answers_at is not None:\r\n            data[\"quiz[hide_correct_answers_at]\"] = quiz_hide_correct_answers_at\r\n\r\n        # OPTIONAL - quiz[allowed_attempts]\r\n        \"\"\"Number of times a student is allowed to take a quiz.\r\n        Set to -1 for unlimited attempts.\r\n        Defaults to 1.\"\"\"\r\n        if quiz_allowed_attempts is not None:\r\n            data[\"quiz[allowed_attempts]\"] = quiz_allowed_attempts\r\n\r\n        # OPTIONAL - quiz[scoring_policy]\r\n        \"\"\"Required and only valid if allowed_attempts > 1.\r\n        Scoring policy for a quiz that students can take multiple times.\r\n        Defaults to \"keep_highest\".\"\"\"\r\n        if quiz_scoring_policy is not None:\r\n            self._validate_enum(quiz_scoring_policy, [\"keep_highest\", \"keep_latest\"])\r\n            data[\"quiz[scoring_policy]\"] = quiz_scoring_policy\r\n\r\n        # OPTIONAL - quiz[one_question_at_a_time]\r\n        \"\"\"If true, shows quiz to student one question at a time.\r\n        Defaults to false.\"\"\"\r\n        if quiz_one_question_at_a_time is not None:\r\n            data[\"quiz[one_question_at_a_time]\"] = quiz_one_question_at_a_time\r\n\r\n        # OPTIONAL - quiz[cant_go_back]\r\n        \"\"\"Only valid if one_question_at_a_time=true\r\n        If true, questions are locked after answering.\r\n        Defaults to false.\"\"\"\r\n        if quiz_cant_go_back is not None:\r\n            data[\"quiz[cant_go_back]\"] = quiz_cant_go_back\r\n\r\n        # OPTIONAL - quiz[access_code]\r\n        \"\"\"Restricts access to the quiz with a password.\r\n        For no access code restriction, set to null.\r\n        Defaults to null.\"\"\"\r\n        if quiz_access_code is not None:\r\n            data[\"quiz[access_code]\"] = quiz_access_code\r\n\r\n        # OPTIONAL - quiz[ip_filter]\r\n        \"\"\"Restricts access to the quiz to computers in a specified IP range.\r\n        Filters can be a comma-separated list of addresses, or an address followed by a mask\r\n        \r\n        Examples:\r\n          \"192.168.217.1\"\r\n          \"192.168.217.1/24\"\r\n          \"192.168.217.1/255.255.255.0\"\r\n        \r\n        For no IP filter restriction, set to null.\r\n        Defaults to null.\"\"\"\r\n        if quiz_ip_filter is not None:\r\n            data[\"quiz[ip_filter]\"] = quiz_ip_filter\r\n\r\n        # OPTIONAL - quiz[due_at]\r\n        \"\"\"The day/time the quiz is due.\r\n        Accepts times in ISO 8601 format, e.g. 2011-10-21T18:48Z.\"\"\"\r\n        if quiz_due_at is not None:\r\n            data[\"quiz[due_at]\"] = quiz_due_at\r\n\r\n        # OPTIONAL - quiz[lock_at]\r\n        \"\"\"The day/time the quiz is locked for students.\r\n        Accepts times in ISO 8601 format, e.g. 2011-10-21T18:48Z.\"\"\"\r\n        if quiz_lock_at is not None:\r\n            data[\"quiz[lock_at]\"] = quiz_lock_at\r\n\r\n        # OPTIONAL - quiz[unlock_at]\r\n        \"\"\"The day/time the quiz is unlocked for students.\r\n        Accepts times in ISO 8601 format, e.g. 2011-10-21T18:48Z.\"\"\"\r\n        if quiz_unlock_at is not None:\r\n            data[\"quiz[unlock_at]\"] = quiz_unlock_at\r\n\r\n        # OPTIONAL - quiz[published]\r\n        \"\"\"Whether the quiz should have a draft state of published or unpublished.\r\n        NOTE: If students have started taking the quiz, or there are any\r\n        submissions for the quiz, you may not unpublish a quiz and will recieve\r\n        an error.\"\"\"\r\n        if quiz_published is not None:\r\n            data[\"quiz[published]\"] = quiz_published\r\n\r\n        # OPTIONAL - quiz[one_time_results]\r\n        \"\"\"Whether students should be prevented from viewing their quiz results past\r\n        the first time (right after they turn the quiz in.)\r\n        Only valid if \"hide_results\" is not set to \"always\".\r\n        Defaults to false.\"\"\"\r\n        if quiz_one_time_results is not None:\r\n            data[\"quiz[one_time_results]\"] = quiz_one_time_results\r\n\r\n        # OPTIONAL - quiz[only_visible_to_overrides]\r\n        \"\"\"Whether this quiz is only visible to overrides (Only useful if\r\n        'differentiated assignments' account setting is on)\r\n        Defaults to false.\"\"\"\r\n        if quiz_only_visible_to_overrides is not None:\r\n            data[\"quiz[only_visible_to_overrides]\"] = quiz_only_visible_to_overrides\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_quiz_access_code(self, id, course_id, access_code):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - access_code\r\n        \"\"\"The access code being validated\"\"\"\r\n        data[\"access_code\"] = access_code\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{id}/validate_access_code with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{id}/validate_access_code\".format(**path), data=data, params=params)", "response": "Validate a quiz access code. Returns a boolean indicating whether the code is correct."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, block=True, timeout=None):\n        self.not_empty.acquire()\n        try:\n            if not block:\n                if not self._qsize():\n                    raise Empty\n            elif timeout is None:\n                while not self._qsize():\n                    self.not_empty.wait()\n            elif timeout < 0:\n                raise ValueError(\"'timeout' must be a positive number\")\n            else:\n                if not self._qsize():\n                    self.not_empty.wait(timeout)\n                    if not self._qsize():\n                        raise Empty\n            item = self._get()\n            self.not_full.notify()\n            return item\n        finally:\n            self.not_empty.release()", "response": "Remove and return an item from the queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the full suite of validation tests.", "response": "def run_suite(case, config, summary):\n    \"\"\" Run the full suite of validation tests \"\"\"\n    m = _load_case_module(case, config)\n\n    result = m.run(case, config)\n    summary[case] = _summarize_result(m, result)\n    _print_summary(m, case, summary)\n   \n    if result['Type'] == 'Book':\n        for name, page in six.iteritems(result['Data']):\n            functions.create_page_from_template(\"validation.html\",\n                                                os.path.join(livvkit.index_dir, \"validation\", name + \".html\"))\n            functions.write_json(page, os.path.join(livvkit.output_dir, \"validation\"), name + \".json\")\n    else:\n        functions.create_page_from_template(\"validation.html\",\n                                            os.path.join(livvkit.index_dir, \"validation\", case + \".html\"))\n        functions.write_json(result, os.path.join(livvkit.output_dir, \"validation\"), case + \".json\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef artifact_already_exists(cli, meta, owner):\n    distro_name = '{}/{}.tar.bz2'.format(conda.config.subdir, meta.dist())\n\n    try:\n        dist_info = cli.distribution(owner, meta.name(), meta.version(), distro_name)\n    except binstar_client.errors.NotFound:\n        dist_info = {}\n\n    return bool(dist_info)", "response": "Checks to see if the recipe already exists on the owner s binstar account."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_generate_sub_commands(self):\n\n        gen_parser = self._subparsers_handle.add_parser(\n            name=\"gen\",\n            help=\"generate client side model stubs, filters\"\n            )\n\n        gen_parser.add_argument(\n            \"-t\",\n            \"--template\",\n            choices=['closure.model', 'closure.filter'],\n            default='closure.model',\n            required=True,\n            dest=\"template\",\n            help=\"template to use for client side code generation\"\n            )\n\n        gen_parser.add_argument(\n            \"-m\",\n            \"--model\",\n            required=True,\n            dest=\"models_definition\",\n            help=\"path to models definition file or package\"\n            )\n\n        gen_parser.add_argument(\n            \"-o\",\n            \"--output\",\n            default=\".\",\n            dest=\"output\",\n            help=\"output path for generated code\"\n            )\n\n        gen_parser.add_argument(\n            \"-n\",\n            \"--namespace\",\n            required=True,\n            dest=\"namespace\",\n            help=\"namespace to use with template e.g prestans.data.model\"\n            )\n\n        gen_parser.add_argument(\n            \"-fn\",\n            \"--filter-namespace\",\n            required=False,\n            default=None,\n            dest=\"filter_namespace\",\n            help=\"filter namespace to use with template e.g prestans.data.filter\"\n            )", "response": "Add the command line options for generating models for usage by clients."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the generate subset of commands.", "response": "def _dispatch_gen(self):\n        \"\"\"\n        Process the generate subset of commands.\n        \"\"\"\n\n        if not os.path.isdir(self._args.output):\n            raise exception.Base(\"%s is not a writeable directory\" % self._args.output)\n\n        if not os.path.isfile(self._args.models_definition):\n            if not self.check_package_exists(self._args.models_definition):\n                raise exception.Base(\"failed to locate package or models definitions file at: %s\" % self._args.models_definition)\n\n        from prestans.devel.gen import Preplate\n        preplate = Preplate(\n            template_type=self._args.template,\n            models_definition=self._args.models_definition,\n            namespace=self._args.namespace,\n            filter_namespace=self._args.filter_namespace,\n            output_directory=self._args.output)\n\n        preplate.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self):\n        # Retrieve all Or filters pertinent to the special coverage query.\n        should_filters = [\n            es_filter.Terms(pk=self.query.get(\"included_ids\", [])),\n            es_filter.Terms(pk=self.query.get(\"pinned_ids\", []))\n        ]\n        should_filters += self.get_group_filters()\n\n        # Compile list of all Must filters.\n        must_filters = [\n            es_filter.Bool(should=should_filters),\n            ~es_filter.Terms(pk=self.query.get(\"excluded_ids\", []))\n        ]\n\n        return Content.search_objects.search().filter(es_filter.Bool(must=must_filters))", "response": "Return a search using the combined query of all associated special coverage objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_group_filters(self):\n        group_filters = []\n        field_map = {\n            \"feature-type\": \"feature_type.slug\",\n            \"tag\": \"tags.slug\",\n            \"content-type\": \"_type\"\n        }\n        for group_set in self.query.get(\"groups\", []):\n            for group in group_set:\n                group_filter = es_filter.MatchAll()\n                for condition in group.get(\"conditions\", []):\n                    group_filter &= get_condition_filter(condition, field_map=field_map)\n                group_filters.append(group_filter)\n        return group_filters", "response": "Return es OR filters to include all special coverage group conditions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngroup the self. special_coverages queries and memoize them.", "response": "def query(self):\n        \"\"\"Group the self.special_coverages queries and memoize them.\"\"\"\n        if not self._query:\n            self._query.update({\n                \"excluded_ids\": [],\n                \"included_ids\": [],\n                \"pinned_ids\": [],\n                \"groups\": [],\n            })\n            for special_coverage in self._special_coverages:\n                # Access query at dict level.\n                query = getattr(special_coverage, \"query\", {})\n                if \"query\" in query:\n                    query = query.get(\"query\")\n                self._query[\"excluded_ids\"] += query.get(\"excluded_ids\", [])\n                self._query[\"included_ids\"] += query.get(\"included_ids\", [])\n                self._query[\"pinned_ids\"] += query.get(\"pinned_ids\", [])\n                self._query[\"groups\"] += [query.get(\"groups\", [])]\n        return self._query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_extensions_for_student_quiz_submissions(self, user_id, course_id, extend_from_end_at=None, extend_from_now=None, extra_attempts=None, extra_time=None, manually_unlocked=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - user_id\r\n        \"\"\"The ID of the user we want to add quiz extensions for.\"\"\"\r\n        data[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - extra_attempts\r\n        \"\"\"Number of times the student is allowed to re-take the quiz over the\r\n        multiple-attempt limit. This is limited to 1000 attempts or less.\"\"\"\r\n        if extra_attempts is not None:\r\n            data[\"extra_attempts\"] = extra_attempts\r\n\r\n        # OPTIONAL - extra_time\r\n        \"\"\"The number of extra minutes to allow for all attempts. This will\r\n        add to the existing time limit on the submission. This is limited to\r\n        10080 minutes (1 week)\"\"\"\r\n        if extra_time is not None:\r\n            data[\"extra_time\"] = extra_time\r\n\r\n        # OPTIONAL - manually_unlocked\r\n        \"\"\"Allow the student to take the quiz even if it's locked for\r\n        everyone else.\"\"\"\r\n        if manually_unlocked is not None:\r\n            data[\"manually_unlocked\"] = manually_unlocked\r\n\r\n        # OPTIONAL - extend_from_now\r\n        \"\"\"The number of minutes to extend the quiz from the current time. This is\r\n        mutually exclusive to extend_from_end_at. This is limited to 1440\r\n        minutes (24 hours)\"\"\"\r\n        if extend_from_now is not None:\r\n            data[\"extend_from_now\"] = extend_from_now\r\n\r\n        # OPTIONAL - extend_from_end_at\r\n        \"\"\"The number of minutes to extend the quiz beyond the quiz's current\r\n        ending time. This is mutually exclusive to extend_from_now. This is\r\n        limited to 1440 minutes (24 hours)\"\"\"\r\n        if extend_from_end_at is not None:\r\n            data[\"extend_from_end_at\"] = extend_from_end_at\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quiz_extensions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quiz_extensions\".format(**path), data=data, params=params, no_data=True)", "response": "Updates the extensions for student quiz submissions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting SAM to RNF - based FASTQ with respect to argparse parameters.", "response": "def sam2rnf(args):\n    \"\"\"Convert SAM to RNF-based FASTQ with respect to argparse parameters.\n\n\tArgs:\n\t\targs (...): Arguments parsed by argparse\n\t\"\"\"\n\n    rnftools.mishmash.Source.recode_sam_reads(\n        sam_fn=args.sam_fn,\n        fastq_rnf_fo=args.fq_fo,\n        fai_fo=args.fai_fo,\n        genome_id=args.genome_id,\n        number_of_read_tuples=10**9,\n        simulator_name=args.simulator_name,\n        allow_unmapped=args.allow_unmapped,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_sam2rnf_parser(subparsers, subcommand, help, description, simulator_name=None):\n\n    parser_sam2rnf = subparsers.add_parser(subcommand, help=help, description=description)\n\n    parser_sam2rnf.set_defaults(func=sam2rnf)\n\n    parser_sam2rnf.add_argument(\n        '-s', '--sam', type=str, metavar='file', dest='sam_fn', required=True,\n        help='Input SAM/BAM with true (expected) alignments of the reads  (- for standard input).'\n    )\n\n    _add_shared_params(parser_sam2rnf, unmapped_switcher=True)\n\n    parser_sam2rnf.add_argument(\n        '-n',\n        '--simulator-name',\n        type=str,\n        metavar='str',\n        dest='simulator_name',\n        default=simulator_name,\n        help='Name of the simulator (for RNF).' if simulator_name is not None else argparse.SUPPRESS,\n    )", "response": "Adds a parser for a SAM2RNF - like command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_with_user(self, user_params, **kwargs):\n        affiliate = self.create(**kwargs)\n        self.api.affiliate_users.create(affiliate_id=affiliate.id, **user_params)\n        return affiliate", "response": "Creates an affiliate and corresponding affiliate user"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the roles available to an account. Returns a list of the roles available to an account.", "response": "def list_roles(self, account_id, show_inherited=None, state=None):\r\n        \"\"\"\r\n        List roles.\r\n\r\n        List the roles available to an account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"The id of the account to retrieve roles for.\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"Filter by role state. If this argument is omitted, only 'active' roles are\r\n        returned.\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"active\", \"inactive\"])\r\n            params[\"state\"] = state\r\n\r\n        # OPTIONAL - show_inherited\r\n        \"\"\"If this argument is true, all roles inherited from parent accounts will\r\n        be included.\"\"\"\r\n        if show_inherited is not None:\r\n            params[\"show_inherited\"] = show_inherited\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/roles with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/roles\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_single_role(self, id, role_id, account_id, role=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"The id of the account containing the role\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - role_id\r\n        \"\"\"The unique identifier for the role\"\"\"\r\n        params[\"role_id\"] = role_id\r\n\r\n        # OPTIONAL - role\r\n        \"\"\"The name for the role\"\"\"\r\n        if role is not None:\r\n            params[\"role\"] = role\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/roles/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/roles/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Get a single role. Returns the full information about the role."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap method for SQLScript class.", "response": "def execute_script(self, sql_script=None, commands=None, split_algo='sql_split', prep_statements=False,\n                       dump_fails=True, execute_fails=True, ignored_commands=('DROP', 'UNLOCK', 'LOCK')):\n        \"\"\"Wrapper method for SQLScript class.\"\"\"\n        ss = Execute(sql_script, split_algo, prep_statements, dump_fails, self)\n        ss.execute(commands, ignored_commands=ignored_commands, execute_fails=execute_fails)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef script(self, sql_script, split_algo='sql_split', prep_statements=True, dump_fails=True):\n        return Execute(sql_script, split_algo, prep_statements, dump_fails, self)", "response": "Wrapper method providing access to the SQLScript class s methods and properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the URL to which the user can be redirected to.", "response": "def authorize_url(self, scope: list, state: str = None) -> tuple:\n        \"\"\"\n        Returns the URL to which the user can be redirected to authorize your application to access his/her account. It\n        will also return the state which can be used for CSRF protection. A state is generated if not passed to this\n        method.\n\n        Example:\n            >>> auth = OAuthAuthentication('https://example.com/oauth/moneybird/', 'your_id', 'your_secret')\n            >>> auth.authorize_url()\n            ('https://moneybird.com/oauth/authorize?client_id=your_id&redirect_uri=https%3A%2F%2Fexample.com%2Flogin%2F\n            moneybird&state=random_string', 'random_string')\n\n        :param scope: The requested scope.\n        :param state: Optional state, when omitted a random value is generated.\n        :return: 2-tuple containing the URL to redirect the user to and the randomly generated state.\n        \"\"\"\n        url = urljoin(self.base_url, self.auth_url)\n        params = {\n            'response_type': 'code',\n            'client_id': self.client_id,\n            'redirect_uri': self.redirect_url,\n            'scope': ' '.join(scope),\n            'state': state if state is not None else self._generate_state(),\n        }\n\n        return \"%s?%s\" % (url, urlencode(params)), params['state']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nobtains an authorization token from the provided URL.", "response": "def obtain_token(self, redirect_url: str, state: str) -> str:\n        \"\"\"\n        Exchange the code that was obtained using `authorize_url` for an authorization token. The code is extracted\n        from the URL that redirected the user back to your site.\n\n        Example:\n            >>> auth = OAuthAuthentication('https://example.com/oauth/moneybird/', 'your_id', 'your_secret')\n            >>> auth.obtain_token('https://example.com/oauth/moneybird/?code=any&state=random_string', 'random_string')\n            'token_for_auth'\n            >>> auth.is_ready()\n            True\n\n        :param redirect_url: The full URL the user was redirected to.\n        :param state: The state used in the authorize url.\n        :return: The authorization token.\n        \"\"\"\n        url_data = parse_qs(redirect_url.split('?', 1)[1])\n\n        if 'error' in url_data:\n            logger.warning(\"Error received in OAuth authentication response: %s\" % url_data.get('error'))\n            raise OAuthAuthentication.OAuthError(url_data['error'], url_data.get('error_description', None))\n\n        if 'code' not in url_data:\n            logger.error(\"The provided URL is not a valid OAuth authentication response: no code\")\n            raise ValueError(\"The provided URL is not a valid OAuth authentication response: no code\")\n\n        if state and [state] != url_data['state']:\n            logger.warning(\"OAuth CSRF attack detected: the state in the provided URL does not equal the given state\")\n            raise ValueError(\"CSRF attack detected: the state in the provided URL does not equal the given state\")\n\n        try:\n            response = requests.post(\n                url=urljoin(self.base_url, self.token_url),\n                data={\n                    'grant_type': 'authorization_code',\n                    'code': url_data['code'][0],\n                    'redirect_uri': self.redirect_url,\n                    'client_id': self.client_id,\n                    'client_secret': self.client_secret,\n                },\n            ).json()\n        except ValueError:\n            logger.error(\"The OAuth server returned an invalid response when obtaining a token: JSON error\")\n            raise ValueError(\"The OAuth server returned an invalid response when obtaining a token: JSON error\")\n\n        if 'error' in response:\n            logger.warning(\"Error while obtaining OAuth authorization token: %s\" % response['error'])\n            raise OAuthAuthentication.OAuthError(response['error'], response.get('error', ''))\n\n        if 'access_token' not in response:\n            logger.error(\"The OAuth server returned an invalid response when obtaining a token: no access token\")\n            raise ValueError(\"The remote server returned an invalid response when obtaining a token: no access token\")\n\n        self.real_auth.set_token(response['access_token'])\n        logger.debug(\"Obtained authentication token for state %s: %s\" % (state, self.real_auth.auth_token))\n\n        return response['access_token']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_state() -> str:\n        state = str(uuid.uuid4()).replace('-', '')\n        logger.debug(\"Generated OAuth state: %s\" % state)\n        return state", "response": "Generates a random string to be used as OAuth state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the best fit data type for a column of a MySQL table.", "response": "def sql_column_type(column_data, prefer_varchar=False, prefer_int=False):\n    \"\"\"\n    Retrieve the best fit data type for a column of a MySQL table.\n\n    Accepts a iterable of values ONLY for the column whose data type\n    is in question.\n\n    :param column_data: Iterable of values from a MySQL table column\n    :param prefer_varchar: Use type VARCHAR if valid\n    :param prefer_int: Use type INT if valid\n    :return: data type\n    \"\"\"\n    # Collect list of type, length tuples\n    type_len_pairs = [ValueType(record).get_type_len for record in column_data]\n\n    # Retrieve frequency counts of each type\n    types_count = {t: type_len_pairs.count(t) for t in set([type_ for type_, len_, len_dec in type_len_pairs])}\n\n    # Most frequently occurring datatype\n    most_frequent = max(types_count.items(), key=itemgetter(1))[0]\n\n    # Get max length of all rows to determine suitable limit\n    len_lst, len_decimals_lst = [], []\n    for type_, len_, len_dec in type_len_pairs:\n        if type_ == most_frequent:\n            if type(len_) is int:\n                len_lst.append(len_)\n            if type(len_dec) is int:\n                len_decimals_lst.append(len_dec)\n\n    # Catch errors if current type has no len\n    try:\n        max_len = max(len_lst)\n    except ValueError:\n        max_len = None\n    try:\n        max_len_decimal = max(len_decimals_lst)\n    except ValueError:\n        max_len_decimal = None\n\n    # Return VARCHAR or INT type if flag is on\n    if prefer_varchar and most_frequent != 'VARCHAR' and 'text' in most_frequent.lower():\n        most_frequent = 'VARCHAR'\n    elif prefer_int and most_frequent != 'INT' and 'int' in most_frequent.lower():\n        most_frequent = 'INT'\n\n    # Return MySQL datatype in proper format, only include length if it is set\n    if max_len and max_len_decimal:\n        return '{0} ({1}, {2})'.format(most_frequent, max_len, max_len_decimal)\n    elif max_len:\n        return '{0} ({1})'.format(most_frequent, max_len)\n    else:\n        return most_frequent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sql(self):\n        test_method = [\n            self.is_time,\n            self.is_date,\n            self.is_datetime,\n            self.is_decimal,\n            self.is_year,\n            self.is_tinyint,\n            self.is_smallint,\n            self.is_mediumint,\n            self.is_int,\n            self.is_bigint,\n            self.is_tinytext,\n            self.is_varchar,\n            self.is_mediumtext,\n            self.is_longtext,\n        ]\n        # Loop through test methods until a test returns True\n        for method in test_method:\n            if method():\n                return self.sql", "response": "Retrieve the data type for a data record."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_type_len(self):\n        # Check types and set type/len\n        self.get_sql()\n        return self.type, self.len, self.len_decimal", "response": "Retrieve the type and length for a data record."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_course_section(self, course_id, course_section_end_at=None, course_section_name=None, course_section_restrict_enrollments_to_section_dates=None, course_section_sis_section_id=None, course_section_start_at=None, enable_sis_reactivation=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - course_section[name]\r\n        \"\"\"The name of the section\"\"\"\r\n        if course_section_name is not None:\r\n            data[\"course_section[name]\"] = course_section_name\r\n\r\n        # OPTIONAL - course_section[sis_section_id]\r\n        \"\"\"The sis ID of the section\"\"\"\r\n        if course_section_sis_section_id is not None:\r\n            data[\"course_section[sis_section_id]\"] = course_section_sis_section_id\r\n\r\n        # OPTIONAL - course_section[start_at]\r\n        \"\"\"Section start date in ISO8601 format, e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_section_start_at is not None:\r\n            data[\"course_section[start_at]\"] = course_section_start_at\r\n\r\n        # OPTIONAL - course_section[end_at]\r\n        \"\"\"Section end date in ISO8601 format. e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_section_end_at is not None:\r\n            data[\"course_section[end_at]\"] = course_section_end_at\r\n\r\n        # OPTIONAL - course_section[restrict_enrollments_to_section_dates]\r\n        \"\"\"Set to true to restrict user enrollments to the start and end dates of the section.\"\"\"\r\n        if course_section_restrict_enrollments_to_section_dates is not None:\r\n            data[\"course_section[restrict_enrollments_to_section_dates]\"] = course_section_restrict_enrollments_to_section_dates\r\n\r\n        # OPTIONAL - enable_sis_reactivation\r\n        \"\"\"When true, will first try to re-activate a deleted section with matching sis_section_id if possible.\"\"\"\r\n        if enable_sis_reactivation is not None:\r\n            data[\"enable_sis_reactivation\"] = enable_sis_reactivation\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/sections with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/sections\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new course section. Returns the course section object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove a Section to another course. Cross - list a Section.", "response": "def cross_list_section(self, id, new_course_id):\r\n        \"\"\"\r\n        Cross-list a Section.\r\n\r\n        Move the Section to another course.  The new course may be in a different account (department),\r\n        but must belong to the same root account (institution).\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - new_course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"new_course_id\"] = new_course_id\r\n\r\n        self.logger.debug(\"POST /api/v1/sections/{id}/crosslist/{new_course_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/sections/{id}/crosslist/{new_course_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nedit a section. Modify an existing section.", "response": "def edit_section(self, id, course_section_end_at=None, course_section_name=None, course_section_restrict_enrollments_to_section_dates=None, course_section_sis_section_id=None, course_section_start_at=None):\r\n        \"\"\"\r\n        Edit a section.\r\n\r\n        Modify an existing section.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - course_section[name]\r\n        \"\"\"The name of the section\"\"\"\r\n        if course_section_name is not None:\r\n            data[\"course_section[name]\"] = course_section_name\r\n\r\n        # OPTIONAL - course_section[sis_section_id]\r\n        \"\"\"The sis ID of the section\"\"\"\r\n        if course_section_sis_section_id is not None:\r\n            data[\"course_section[sis_section_id]\"] = course_section_sis_section_id\r\n\r\n        # OPTIONAL - course_section[start_at]\r\n        \"\"\"Section start date in ISO8601 format, e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_section_start_at is not None:\r\n            data[\"course_section[start_at]\"] = course_section_start_at\r\n\r\n        # OPTIONAL - course_section[end_at]\r\n        \"\"\"Section end date in ISO8601 format. e.g. 2011-01-01T01:00Z\"\"\"\r\n        if course_section_end_at is not None:\r\n            data[\"course_section[end_at]\"] = course_section_end_at\r\n\r\n        # OPTIONAL - course_section[restrict_enrollments_to_section_dates]\r\n        \"\"\"Set to true to restrict user enrollments to the start and end dates of the section.\"\"\"\r\n        if course_section_restrict_enrollments_to_section_dates is not None:\r\n            data[\"course_section[restrict_enrollments_to_section_dates]\"] = course_section_restrict_enrollments_to_section_dates\r\n\r\n        self.logger.debug(\"PUT /api/v1/sections/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/sections/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting a single SQL query without returning a result.", "response": "def execute(self, command):\n        \"\"\"Execute a single SQL query without returning a result.\"\"\"\n        self._cursor.execute(command)\n        self._commit()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef executemany(self, command, params=None, max_attempts=5):\n        attempts = 0\n        while attempts < max_attempts:\n            try:\n                # Execute statement\n                self._cursor.executemany(command, params)\n                self._commit()\n                return True\n            except Exception as e:\n                attempts += 1\n                self.reconnect()\n                continue", "response": "Execute multiple SQL queries without returning a result."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _connect(self, config):\n        if 'connection_timeout' not in self._config:\n            self._config['connection_timeout'] = 480\n        try:\n            self._cnx = connect(**config)\n            self._cursor = self._cnx.cursor()\n            self._printer('\\tMySQL DB connection established with db', config['database'])\n        except Error as err:\n            if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n                print(\"Something is wrong with your user name or password\")\n            elif err.errno == errorcode.ER_BAD_DB_ERROR:\n                print(\"Database does not exist\")\n            raise err", "response": "Establish a connection with a MySQL database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fetch(self, statement, commit, max_attempts=5):\n        if self._auto_reconnect:\n            attempts = 0\n            while attempts < max_attempts:\n                try:\n                    # Execute statement\n                    self._cursor.execute(statement)\n                    fetch = self._cursor.fetchall()\n                    rows = self._fetch_rows(fetch)\n                    if commit:\n                        self._commit()\n\n                    # Return a single item if the list only has one item\n                    return rows[0] if len(rows) == 1 else rows\n                except Exception as e:\n                    if attempts >= max_attempts:\n                        raise e\n                    else:\n                        attempts += 1\n                        self.reconnect()\n                        continue\n        else:\n            # Execute statement\n            self._cursor.execute(statement)\n            fetch = self._cursor.fetchall()\n            rows = self._fetch_rows(fetch)\n            if commit:\n                self._commit()\n\n            # Return a single item if the list only has one item\n            return rows[0] if len(rows) == 1 else rows", "response": "Execute a SQL query and return a result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitialing settings for the OpenGL state machine, clear color, window size, etc", "response": "def resize(widthWindow, heightWindow):\n\t\"\"\"Initial settings for the OpenGL state machine, clear color, window size, etc\"\"\"\n\tglEnable(GL_BLEND)\n\tglEnable(GL_POINT_SMOOTH)\n\tglShadeModel(GL_SMOOTH)# Enables Smooth Shading\n\tglBlendFunc(GL_SRC_ALPHA,GL_ONE)#Type Of Blending To Perform\n\tglHint(GL_PERSPECTIVE_CORRECTION_HINT,GL_NICEST);#Really Nice Perspective Calculations\n\tglHint(GL_POINT_SMOOTH_HINT,GL_NICEST);#Really Nice Point Smoothing\n\tglDisable(GL_DEPTH_TEST)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_bumper_color(self, particle, group, bumper, collision_point, collision_normal):\n\t\tself.color = tuple(particle.color)[:3]", "response": "Set bumper color to the color of the particle that collided with it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset the internal state of the object to the default state", "response": "def reset(self, rabaClass, namespace = None) :\n\t\t\"\"\"rabaClass can either be a raba class of a string of a raba class name. In the latter case you must provide the namespace argument.\n\t\tIf it's a Raba Class the argument is ignored. If you fear cicular imports use strings\"\"\"\n\n\t\tif type(rabaClass) is types.StringType :\n\t\t\tself._raba_namespace = namespace\n\t\t\tself.con = stp.RabaConnection(self._raba_namespace)\n\t\t\tself.rabaClass = self.con.getClass(rabaClass)\n\t\telse :\n\t\t\tself.rabaClass = rabaClass\n\t\t\tself._raba_namespace = self.rabaClass._raba_namespace\n\n\t\tself.con = stp.RabaConnection(self._raba_namespace)\n\t\tself.filters = []\n\t\tself.tables = set()\n\n\t\t#self.fctPattern = re.compile(\"\\s*([^\\s]+)\\s*\\(\\s*([^\\s]+)\\s*\\)\\s*([=><])\\s*([^\\s]+)\\s*\")\n\t\tself.fieldPattern = re.compile(\"\\s*([^\\s\\(\\)]+)\\s*([=><]|([L|l][I|i][K|k][E|e]))\\s*(.+)\")\n\t\tself.operators = set(['LIKE', '=', '<', '>', '=', '>=', '<=', '<>', '!=', 'IS'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new filter to the query", "response": "def addFilter(self, *lstFilters, **dctFilters) :\n\t\t\"add a new filter to the query\"\n\n\t\tdstF = {}\n\t\tif len(lstFilters) > 0 :\n\t\t\tif type(lstFilters[0]) is types.DictType :\n\t\t\t\tdstF = lstFilters[0]\n\t\t\t\tlstFilters = lstFilters[1:]\n\n\t\tif len(dctFilters) > 0 :\n\t\t\tdstF = dict(dstF, **dctFilters)\n\n\t\tfilts = {}\n\t\tfor k, v in dstF.iteritems() :\n\t\t\tsk = k.split(' ')\n\t\t\tif len(sk) == 2 :\n\t\t\t\toperator = sk[-1].strip().upper()\n\t\t\t\tif operator not in self.operators :\n\t\t\t\t\traise ValueError('Unrecognized operator \"%s\"' % operator)\n\t\t\t\tkk = '%s.%s'% (self.rabaClass.__name__, k)\n\t\t\telif len(sk) == 1 :\n\t\t\t\toperator = \"=\"\n\t\t\t\tkk = '%s.%s ='% (self.rabaClass.__name__, k)\n\t\t\telse :\n\t\t\t\traise ValueError('Invalid field %s' % k)\n\n\t\t\tif isRabaObject(v) :\n\t\t\t\tvv = v.getJsonEncoding()\n\t\t\telse :\n\t\t\t\tvv = v\n\n\t\t\tif sk[0].find('.') > -1 :\n\t\t\t\tkk = self._parseJoint(sk[0], operator)\n\t\t\t\n\t\t\tfilts[kk] = vv\n\t\t\t\t\n\t\tfor lt in lstFilters :\n\t\t\tfor l in lt :\n\t\t\t\tmatch = self.fieldPattern.match(l)\n\t\t\t\tif match == None :\n\t\t\t\t\traise ValueError(\"RabaQuery Error: Invalid filter '%s'\" % l)\n\n\t\t\t\tfield = match.group(1)\n\t\t\t\toperator = match.group(2)\n\t\t\t\tvalue = match.group(4)\n\n\t\t\t\tif field.find('.') > -1 :\n\t\t\t\t\tjoink = self._parseJoint(field, operator, value)\n\t\t\t\t\tfilts[joink] = value\n\t\t\t\telse :\n\t\t\t\t\tfilts['%s.%s %s' %(self.rabaClass.__name__, field, operator)] = value\n\n\t\tself.filters.append(filts)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSQLQuery(self, count = False) :\n\t\t\"Returns the query without performing it. If count, the query returned will be a SELECT COUNT() instead of a SELECT\"\n\t\tsqlFilters = []\n\t\tsqlValues = []\n\t\t# print self.filters\n\t\tfor f in self.filters :\n\t\t\tfilt = []\n\t\t\tfor k, vv in f.iteritems() :\n\t\t\t\tif type(vv) is types.ListType or type(vv) is types.TupleType :\n\t\t\t\t\tsqlValues.extend(vv)\n\t\t\t\t\tkk = 'OR %s ? '%k * len(vv)\n\t\t\t\t\tkk = \"(%s)\" % kk[3:]\n\t\t\t\telse :\n\t\t\t\t\tkk = k\n\t\t\t\tsqlValues.append(vv)\n\t\t\t\tfilt.append(kk)\t\n\t\t\t\n\t\t\tsqlFilters.append('(%s ?)' % ' ? AND '.join(filt))\n\t\t\n\t\tif len(sqlValues) > stp.SQLITE_LIMIT_VARIABLE_NUMBER :\n\t\t\traise ValueError(\"\"\"The limit number of parameters imposed by sqlite is %s.\nYou will have to break your query into several smaller one. Sorry about that. (actual number of parameters is: %s)\"\"\" % (stp.SQLITE_LIMIT_VARIABLE_NUMBER, len(sqlValues)))\n\t\t\n\t\tsqlFilters =' OR '.join(sqlFilters)\n\t\t\n\t\tif len(self.tables) < 2 :\n\t\t\ttablesStr = self.rabaClass.__name__\n\t\telse :\n\t\t\ttablesStr =  ', '.join(self.tables)\n\t\t\n\t\tif len(sqlFilters) == 0 :\n\t\t\tsqlFilters = '1'\n\t\tif count :\n\t\t\tsql = 'SELECT COUNT(*) FROM %s WHERE %s' % (tablesStr, sqlFilters)\n\t\telse :\n\t\t\tsql = 'SELECT %s.raba_id FROM %s WHERE %s' % (self.rabaClass.__name__, tablesStr, sqlFilters)\n\t\t\n\t\treturn (sql, sqlValues)", "response": "Returns the query without performing it. If count is True the query returned will be a SELECT COUNT instead of a SELECT"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iterRun(self, sqlTail = '', raw = False) :\n\n\t\tsql, sqlValues = self.getSQLQuery()\n\t\tcur = self.con.execute('%s %s'% (sql, sqlTail), sqlValues)\n\t\tfor v in cur :\n\t\t\tif not raw :\n\t\t\t\tyield RabaPupa(self.rabaClass, v[0])\n\t\t\telse :\n\t\t\t\tyield v", "response": "Compile filters and run the query and return an iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles filters and run the query and return the entire result.", "response": "def run(self, sqlTail = '', raw = False) :\n\t\t\"\"\"Compile filters and run the query and returns the entire result. You can use sqlTail to add things such as order by. If raw, returns the raw tuple data (not wrapped into a raba object)\"\"\"\n\t\tsql, sqlValues = self.getSQLQuery()\n\t\tcur = self.con.execute('%s %s'% (sql, sqlTail), sqlValues)\n\n\t\tres = []\n\t\tfor v in cur :\n\t\t\tif not raw :\n\t\t\t\tres.append(RabaPupa(self.rabaClass, v[0]))\n\t\t\telse :\n\t\t\t\treturn v\n\t\t\n\t\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef count(self, sqlTail = '') :\n\t\t\"Compile filters and counts the number of results. You can use sqlTail to add things such as order by\"\n\t\tsql, sqlValues = self.getSQLQuery(count = True)\n\t\treturn int(self.con.execute('%s %s'% (sql, sqlTail), sqlValues).fetchone()[0])", "response": "Compile filters and counts the number of results. You can use sqlTail to add things such as order by"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_schema_dict(self, table):\n        # Retrieve schema in list form\n        schema = self.get_schema(table, with_headers=True)\n\n        # Pop headers from first item in list\n        headers = schema.pop(0)\n\n        # Create dictionary by zipping headers with each row\n        return {values[0]: dict(zip(headers, values[0:])) for values in schema}", "response": "Retrieve the database schema in key value pairs for easier\n        references and comparisons."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_schema(self, table, with_headers=False):\n        f = self.fetch('desc ' + wrap(table))\n        if not isinstance(f[0], list):\n            f = [f]\n\n        # Replace None with ''\n        schema = [['' if col is None else col for col in row] for row in f]\n\n        # If with_headers is True, insert headers to first row before returning\n        if with_headers:\n            schema.insert(0, ['Column', 'Type', 'Null', 'Key', 'Default', 'Extra'])\n        return schema", "response": "Retrieve the database schema for a particular table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a column to an existing table.", "response": "def add_column(self, table, name='ID', data_type='int(11)', after_col=None, null=False, primary_key=False):\n        \"\"\"Add a column to an existing table.\"\"\"\n        location = 'AFTER {0}'.format(after_col) if after_col else 'FIRST'\n        null_ = 'NULL' if null else 'NOT NULL'\n        comment = \"COMMENT 'Column auto created by mysql-toolkit'\"\n        pk = 'AUTO_INCREMENT PRIMARY KEY {0}'.format(comment) if primary_key else ''\n        query = 'ALTER TABLE {0} ADD COLUMN {1} {2} {3} {4} {5}'.format(wrap(table), name, data_type, null_, pk,\n                                                                        location)\n        self.execute(query)\n        self._printer(\"\\tAdded column '{0}' to '{1}' {2}\".format(name, table, '(Primary Key)' if primary_key else ''))\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop_column(self, table, name):\n        try:\n            self.execute('ALTER TABLE {0} DROP COLUMN {1}'.format(wrap(table), name))\n            self._printer('\\tDropped column {0} from {1}'.format(name, table))\n        except ProgrammingError:\n            self._printer(\"\\tCan't DROP '{0}'; check that column/key exists in '{1}'\".format(name, table))\n        return name", "response": "Remove a column from an existing table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndrop an index from a table.", "response": "def drop_index(self, table, column):\n        \"\"\"Drop an index from a table.\"\"\"\n        self.execute('ALTER TABLE {0} DROP INDEX {1}'.format(wrap(table), column))\n        self._printer('\\tDropped index from column {0}'.format(column))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a comment to an existing column in a table.", "response": "def add_comment(self, table, column, comment):\n        \"\"\"Add a comment to an existing column in a table.\"\"\"\n        col_def = self.get_column_definition(table, column)\n        query = \"ALTER TABLE {0} MODIFY COLUMN {1} {2} COMMENT '{3}'\".format(table, column, col_def, comment)\n        self.execute(query)\n        self._printer('\\tAdded comment to column {0}'.format(column))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_auto_increment(self, table, name):\n        # Get current column definition and add auto_incrementing\n        definition = self.get_column_definition(table, name) + ' AUTO_INCREMENT'\n\n        # Concatenate and execute modify statement\n        self.execute(\"ALTER TABLE {0} MODIFY {1}\".format(table, definition))\n        self._printer('\\tAdded AUTO_INCREMENT to column {0}'.format(name))\n        return True", "response": "Modify an existing column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmodifying an existing column.", "response": "def modify_column(self, table, name, new_name=None, data_type=None, null=None, default=None):\n        \"\"\"Modify an existing column.\"\"\"\n        existing_def = self.get_schema_dict(table)[name]\n\n        # Set column name\n        new_name = new_name if new_name is not None else name\n\n        # Set data type\n        if not data_type:\n            data_type = existing_def['Type']\n\n        # Set NULL\n        if null is None:\n            null_ = 'NULL' if existing_def['Null'].lower() == 'yes' else 'NOT NULL'\n        else:\n            null_ = 'NULL' if null else 'NOT NULL'\n\n        default = 'DEFAULT {0}'.format(default if default else null_)\n\n        query = 'ALTER TABLE {0} CHANGE {1} {2} {3} {4} {5}'.format(wrap(table), wrap(name), wrap(new_name), data_type,\n                                                                           null_, default)\n        self.execute(query)\n        self._printer('\\tModified column {0}'.format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist the modules in a course. Returns a list of modules in a course with the specified id.", "response": "def list_modules(self, course_id, include=None, search_term=None, student_id=None):\r\n        \"\"\"\r\n        List modules.\r\n\r\n        List the modules in a course\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"items\": Return module items inline if possible.\r\n          This parameter suggests that Canvas return module items directly\r\n          in the Module object JSON, to avoid having to make separate API\r\n          requests for each module when enumerating modules and items. Canvas\r\n          is free to omit 'items' for any particular module if it deems them\r\n          too numerous to return inline. Callers must be prepared to use the\r\n          {api:ContextModuleItemsApiController#index List Module Items API}\r\n          if items are not returned.\r\n        - \"content_details\": Requires include['items']. Returns additional\r\n          details with module items specific to their associated content items.\r\n          Includes standard lock information for each item.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"items\", \"content_details\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name of the modules (and module items, if include['items'] is\r\n        specified) to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - student_id\r\n        \"\"\"Returns module completion information for the student with this id.\"\"\"\r\n        if student_id is not None:\r\n            params[\"student_id\"] = student_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/modules with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/modules\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new module in the specified course. Returns a new module with the specified name and optionally a grade.", "response": "def create_module(self, course_id, module_name, module_position=None, module_prerequisite_module_ids=None, module_publish_final_grade=None, module_require_sequential_progress=None, module_unlock_at=None):\r\n        \"\"\"\r\n        Create a module.\r\n\r\n        Create and return a new module\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - module[name]\r\n        \"\"\"The name of the module\"\"\"\r\n        data[\"module[name]\"] = module_name\r\n\r\n        # OPTIONAL - module[unlock_at]\r\n        \"\"\"The date the module will unlock\"\"\"\r\n        if module_unlock_at is not None:\r\n            data[\"module[unlock_at]\"] = module_unlock_at\r\n\r\n        # OPTIONAL - module[position]\r\n        \"\"\"The position of this module in the course (1-based)\"\"\"\r\n        if module_position is not None:\r\n            data[\"module[position]\"] = module_position\r\n\r\n        # OPTIONAL - module[require_sequential_progress]\r\n        \"\"\"Whether module items must be unlocked in order\"\"\"\r\n        if module_require_sequential_progress is not None:\r\n            data[\"module[require_sequential_progress]\"] = module_require_sequential_progress\r\n\r\n        # OPTIONAL - module[prerequisite_module_ids]\r\n        \"\"\"IDs of Modules that must be completed before this one is unlocked.\r\n        Prerequisite modules must precede this module (i.e. have a lower position\r\n        value), otherwise they will be ignored\"\"\"\r\n        if module_prerequisite_module_ids is not None:\r\n            data[\"module[prerequisite_module_ids]\"] = module_prerequisite_module_ids\r\n\r\n        # OPTIONAL - module[publish_final_grade]\r\n        \"\"\"Whether to publish the student's final grade for the course upon\r\n        completion of this module.\"\"\"\r\n        if module_publish_final_grade is not None:\r\n            data[\"module[publish_final_grade]\"] = module_publish_final_grade\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/modules with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/modules\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_module_item(self, course_id, module_id, module_item_type, module_item_content_id, module_item_completion_requirement_min_score=None, module_item_completion_requirement_type=None, module_item_external_url=None, module_item_indent=None, module_item_new_tab=None, module_item_page_url=None, module_item_position=None, module_item_title=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - module_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"module_id\"] = module_id\r\n\r\n        # OPTIONAL - module_item[title]\r\n        \"\"\"The name of the module item and associated content\"\"\"\r\n        if module_item_title is not None:\r\n            data[\"module_item[title]\"] = module_item_title\r\n\r\n        # REQUIRED - module_item[type]\r\n        \"\"\"The type of content linked to the item\"\"\"\r\n        self._validate_enum(module_item_type, [\"File\", \"Page\", \"Discussion\", \"Assignment\", \"Quiz\", \"SubHeader\", \"ExternalUrl\", \"ExternalTool\"])\r\n        data[\"module_item[type]\"] = module_item_type\r\n\r\n        # REQUIRED - module_item[content_id]\r\n        \"\"\"The id of the content to link to the module item. Required, except for\r\n        'ExternalUrl', 'Page', and 'SubHeader' types.\"\"\"\r\n        data[\"module_item[content_id]\"] = module_item_content_id\r\n\r\n        # OPTIONAL - module_item[position]\r\n        \"\"\"The position of this item in the module (1-based).\"\"\"\r\n        if module_item_position is not None:\r\n            data[\"module_item[position]\"] = module_item_position\r\n\r\n        # OPTIONAL - module_item[indent]\r\n        \"\"\"0-based indent level; module items may be indented to show a hierarchy\"\"\"\r\n        if module_item_indent is not None:\r\n            data[\"module_item[indent]\"] = module_item_indent\r\n\r\n        # OPTIONAL - module_item[page_url]\r\n        \"\"\"Suffix for the linked wiki page (e.g. 'front-page'). Required for 'Page'\r\n        type.\"\"\"\r\n        if module_item_page_url is not None:\r\n            data[\"module_item[page_url]\"] = module_item_page_url\r\n\r\n        # OPTIONAL - module_item[external_url]\r\n        \"\"\"External url that the item points to. [Required for 'ExternalUrl' and\r\n        'ExternalTool' types.\"\"\"\r\n        if module_item_external_url is not None:\r\n            data[\"module_item[external_url]\"] = module_item_external_url\r\n\r\n        # OPTIONAL - module_item[new_tab]\r\n        \"\"\"Whether the external tool opens in a new tab. Only applies to\r\n        'ExternalTool' type.\"\"\"\r\n        if module_item_new_tab is not None:\r\n            data[\"module_item[new_tab]\"] = module_item_new_tab\r\n\r\n        # OPTIONAL - module_item[completion_requirement][type]\r\n        \"\"\"Completion requirement for this module item.\r\n        \"must_view\": Applies to all item types\r\n        \"must_contribute\": Only applies to \"Assignment\", \"Discussion\", and \"Page\" types\r\n        \"must_submit\", \"min_score\": Only apply to \"Assignment\" and \"Quiz\" types\r\n        Inapplicable types will be ignored\"\"\"\r\n        if module_item_completion_requirement_type is not None:\r\n            self._validate_enum(module_item_completion_requirement_type, [\"must_view\", \"must_contribute\", \"must_submit\"])\r\n            data[\"module_item[completion_requirement][type]\"] = module_item_completion_requirement_type\r\n\r\n        # OPTIONAL - module_item[completion_requirement][min_score]\r\n        \"\"\"Minimum score required to complete. Required for completion_requirement\r\n        type 'min_score'.\"\"\"\r\n        if module_item_completion_requirement_min_score is not None:\r\n            data[\"module_item[completion_requirement][min_score]\"] = module_item_completion_requirement_min_score\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/modules/{module_id}/items with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/modules/{module_id}/items\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new module item. Returns the newly created module item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a module item. Returns the updated module item.", "response": "def update_module_item(self, id, course_id, module_id, module_item_completion_requirement_min_score=None, module_item_completion_requirement_type=None, module_item_external_url=None, module_item_indent=None, module_item_module_id=None, module_item_new_tab=None, module_item_position=None, module_item_published=None, module_item_title=None):\r\n        \"\"\"\r\n        Update a module item.\r\n\r\n        Update and return an existing module item\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - module_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"module_id\"] = module_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - module_item[title]\r\n        \"\"\"The name of the module item\"\"\"\r\n        if module_item_title is not None:\r\n            data[\"module_item[title]\"] = module_item_title\r\n\r\n        # OPTIONAL - module_item[position]\r\n        \"\"\"The position of this item in the module (1-based)\"\"\"\r\n        if module_item_position is not None:\r\n            data[\"module_item[position]\"] = module_item_position\r\n\r\n        # OPTIONAL - module_item[indent]\r\n        \"\"\"0-based indent level; module items may be indented to show a hierarchy\"\"\"\r\n        if module_item_indent is not None:\r\n            data[\"module_item[indent]\"] = module_item_indent\r\n\r\n        # OPTIONAL - module_item[external_url]\r\n        \"\"\"External url that the item points to. Only applies to 'ExternalUrl' type.\"\"\"\r\n        if module_item_external_url is not None:\r\n            data[\"module_item[external_url]\"] = module_item_external_url\r\n\r\n        # OPTIONAL - module_item[new_tab]\r\n        \"\"\"Whether the external tool opens in a new tab. Only applies to\r\n        'ExternalTool' type.\"\"\"\r\n        if module_item_new_tab is not None:\r\n            data[\"module_item[new_tab]\"] = module_item_new_tab\r\n\r\n        # OPTIONAL - module_item[completion_requirement][type]\r\n        \"\"\"Completion requirement for this module item.\r\n        \"must_view\": Applies to all item types\r\n        \"must_contribute\": Only applies to \"Assignment\", \"Discussion\", and \"Page\" types\r\n        \"must_submit\", \"min_score\": Only apply to \"Assignment\" and \"Quiz\" types\r\n        Inapplicable types will be ignored\"\"\"\r\n        if module_item_completion_requirement_type is not None:\r\n            self._validate_enum(module_item_completion_requirement_type, [\"must_view\", \"must_contribute\", \"must_submit\"])\r\n            data[\"module_item[completion_requirement][type]\"] = module_item_completion_requirement_type\r\n\r\n        # OPTIONAL - module_item[completion_requirement][min_score]\r\n        \"\"\"Minimum score required to complete, Required for completion_requirement\r\n        type 'min_score'.\"\"\"\r\n        if module_item_completion_requirement_min_score is not None:\r\n            data[\"module_item[completion_requirement][min_score]\"] = module_item_completion_requirement_min_score\r\n\r\n        # OPTIONAL - module_item[published]\r\n        \"\"\"Whether the module item is published and visible to students.\"\"\"\r\n        if module_item_published is not None:\r\n            data[\"module_item[published]\"] = module_item_published\r\n\r\n        # OPTIONAL - module_item[module_id]\r\n        \"\"\"Move this item to another module by specifying the target module id here.\r\n        The target module must be in the same course.\"\"\"\r\n        if module_item_module_id is not None:\r\n            data[\"module_item[module_id]\"] = module_item_module_id\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/modules/{module_id}/items/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/modules/{module_id}/items/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef select_mastery_path(self, id, course_id, module_id, assignment_set_id=None, student_id=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - module_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"module_id\"] = module_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - assignment_set_id\r\n        \"\"\"Assignment set chosen, as specified in the mastery_paths portion of the\r\n        context module item response\"\"\"\r\n        if assignment_set_id is not None:\r\n            data[\"assignment_set_id\"] = assignment_set_id\r\n\r\n        # OPTIONAL - student_id\r\n        \"\"\"Which student the selection applies to.  If not specified, current user is\r\n        implied.\"\"\"\r\n        if student_id is not None:\r\n            data[\"student_id\"] = student_id\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/modules/{module_id}/items/{id}/select_mastery_path with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/modules/{module_id}/items/{id}/select_mastery_path\".format(**path), data=data, params=params, no_data=True)", "response": "Select a mastery path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_module_item_sequence(self, course_id, asset_id=None, asset_type=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - asset_type\r\n        \"\"\"The type of asset to find module sequence information for. Use the ModuleItem if it is known\r\n        (e.g., the user navigated from a module item), since this will avoid ambiguity if the asset\r\n        appears more than once in the module sequence.\"\"\"\r\n        if asset_type is not None:\r\n            self._validate_enum(asset_type, [\"ModuleItem\", \"File\", \"Page\", \"Discussion\", \"Assignment\", \"Quiz\", \"ExternalTool\"])\r\n            params[\"asset_type\"] = asset_type\r\n\r\n        # OPTIONAL - asset_id\r\n        \"\"\"The id of the asset (or the url in the case of a Page)\"\"\"\r\n        if asset_id is not None:\r\n            params[\"asset_id\"] = asset_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/module_item_sequence with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/module_item_sequence\".format(**path), data=data, params=params, single_item=True)", "response": "Get the module item sequence. Returns the module item sequence for the given asset in a course and the previous and next Module Items for the given asset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_data_from_response(self, response, data_key=None):\r\n        response_json_data = response.json()\r\n        # Seems to be two types of response, a dict with keys and then lists of data or a flat list data with no key.\r\n        if type(response_json_data) == list:\r\n            # Return the data\r\n            return response_json_data\r\n        elif type(response_json_data) == dict:\r\n            if data_key is None:\r\n                return response_json_data\r\n            else:\r\n                return response_json_data[data_key]\r\n        else:\r\n            raise CanvasAPIError(response)", "response": "Given a response and an optional data_key should return a dictionary of data returned as part of the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a wrapped response from a Canvas API endpoint extract the pagination links from the response headers and return a dictionary of the pagination links.", "response": "def extract_pagination_links(self, response):\r\n        '''Given a wrapped_response from a Canvas API endpoint,\r\n        extract the pagination links from the response headers'''\r\n        try:\r\n            link_header = response.headers['Link']\r\n        except KeyError:\r\n            logger.warn('Unable to find the Link header. Unable to continue with pagination.')\r\n            return None\r\n\r\n        split_header = link_header.split(',')\r\n        exploded_split_header = [i.split(';') for i in split_header]\r\n\r\n        pagination_links = {}\r\n        for h in exploded_split_header:\r\n            link = h[0]\r\n            rel = h[1]\r\n            # Check that the link format is what we expect\r\n            if link.startswith('<') and link.endswith('>'):\r\n                link = link[1:-1]\r\n            else:\r\n                continue\r\n            # Extract the rel argument\r\n            m = self.rel_matcher.match(rel)\r\n            try:\r\n                rel = m.groups()[0]\r\n            except AttributeError:\r\n                # Match returned None, just skip.\r\n                continue\r\n            except IndexError:\r\n                # Matched but no groups returned\r\n                continue\r\n\r\n            pagination_links[rel] = link\r\n        return pagination_links"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value or raise a ValueError if it is not a string in ISO8601 format.", "response": "def _validate_iso8601_string(self, value):\r\n        \"\"\"Return the value or raise a ValueError if it is not a string in ISO8601 format.\"\"\"\r\n        ISO8601_REGEX = r'(\\d{4})-(\\d{2})-(\\d{2})T(\\d{2})\\:(\\d{2})\\:(\\d{2})([+-](\\d{2})\\:(\\d{2})|Z)'\r\n        if re.match(ISO8601_REGEX, value):\r\n            return value\r\n        else:\r\n            raise ValueError('{} must be in ISO8601 format.'.format(value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new database at the given dbpath.", "response": "def create_database(dbpath, schema='', overwrite=True):\n    \"\"\"\n    Create a new database at the given dbpath\n\n    Parameters\n    ----------\n    dbpath: str\n        The full path for the new database, including the filename and .db file extension.\n    schema: str\n        The path to the .sql schema for the database\n    overwrite: bool\n        Overwrite dbpath if it already exists\n    \"\"\"\n    if dbpath.endswith('.db'):\n        \n        if os.path.isfile(dbpath) and overwrite:\n            os.system('rm {}'.format(dbpath))\n        \n        # Load the schema if given\n        if schema:\n            os.system(\"cat {} | sqlite3 {}\".format(schema,dbpath))\n            \n        # Otherwise just make an empty SOURCES table\n        else:\n            sources_table = \"CREATE TABLE sources (id INTEGER PRIMARY KEY, ra REAL, dec REAL, designation TEXT, \" \\\n                            \"publication_id INTEGER, shortname TEXT, names TEXT, comments TEXT)\"\n            os.system(\"sqlite3 {} '{}'\".format(dbpath, sources_table))\n            \n        if os.path.isfile(dbpath):\n            print(\n                \"\\nDatabase created! To load, run\\n\\ndb = astrodb.Database('{}')\"\n                \"\\n\\nThen run db.modify_table() method to create tables.\".format(dbpath))\n    else:\n        print(\"Please provide a path and file name with a .db file extension, e.g. /Users/<username>/Desktop/test.db\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadapt a Numpy array into an ARRAY string to put into the database. Parameters ---------- arr: array The Numpy array to be adapted into an ARRAY type that can be inserted into a SQL file. Returns ------- ARRAY The adapted array object", "response": "def adapt_array(arr):\n    \"\"\"\n    Adapts a Numpy array into an ARRAY string to put into the database.\n\n    Parameters\n    ----------\n    arr: array\n        The Numpy array to be adapted into an ARRAY type that can be inserted into a SQL file.\n\n    Returns\n    -------\n    ARRAY\n            The adapted array object\n\n    \"\"\"\n    out = io.BytesIO()\n    np.save(out, arr), out.seek(0)\n    return buffer(out.read())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the angular separation between two coordinates.", "response": "def ang_sep(row, ra1, dec1):\n    \"\"\"\n    Calculate angular separation between two coordinates\n    Uses Vicenty Formula (http://en.wikipedia.org/wiki/Great-circle_distance) and adapts from astropy's SkyCoord\n    Written to be used within the Database.search() method\n\n    Parameters\n    ----------\n    row: dict, pandas Row\n        Coordinate structure containing ra and dec keys in decimal degrees\n    ra1: float\n        RA to compare with, in decimal degrees\n    dec1: float\n        Dec to compare with, in decimal degrees\n\n    Returns\n    -------\n        Angular distance, in degrees, between the coordinates\n    \"\"\"\n\n    factor = math.pi / 180\n    sdlon = math.sin((row['ra'] - ra1) * factor)  # RA is longitude\n    cdlon = math.cos((row['ra'] - ra1) * factor)\n    slat1 = math.sin(dec1 * factor)  # Dec is latitude\n    slat2 = math.sin(row['dec'] * factor)\n    clat1 = math.cos(dec1 * factor)\n    clat2 = math.cos(row['dec'] * factor)\n\n    num1 = clat2 * sdlon\n    num2 = clat1 * slat2 - slat1 * clat2 * cdlon\n    numerator = math.sqrt(num1 ** 2 + num2 ** 2)\n    denominator = slat1 * slat2 + clat1 * clat2 * cdlon\n\n    return np.arctan2(numerator, denominator) / factor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_array(array):\n    out = io.BytesIO(array)\n    out.seek(0)\n    return np.load(out)", "response": "Converts an ARRAY object stored in the database back into a Numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_image(File, verbose=False):\n    image, header = '', ''\n    if isinstance(File, type(b'')):  # Decode if needed (ie, for Python 3)\n        File = File.decode('utf-8')\n        \n    if isinstance(File, (str, type(u''))):\n        \n        # Convert variable path to absolute path\n        if File.startswith('$'):\n            abspath = os.popen('echo {}'.format(File.split('/')[0])).read()[:-1]\n            if abspath:\n                File = File.replace(File.split('/')[0], abspath)\n                \n        if File.startswith('http'):\n            if verbose:\n                print('Downloading {}'.format(File))\n            \n            # Download only once\n            downloaded_file = download_file(File, cache=True)\n        else:\n            downloaded_file = File\n            \n        try: \n            # Get the data\n            image, header = pf.getdata(downloaded_file, cache=True, header=True)\n            \n            # If no data, then clear out all retrieved info for object\n            if not isinstance(image, np.ndarray):\n                image = None\n                \n            if verbose:\n                print('Read as FITS...')\n            \n        except (IOError, KeyError):\n            # Check if the FITS file is just Numpy arrays\n            try:\n                image, header = pf.getdata(downloaded_file, cache=True, header=True)\n                if verbose:\n                    print('Read as FITS Numpy array...')\n                    \n            except (IOError, KeyError):\n                try:  # Try ascii\n                    image = ii.read(downloaded_file)\n                    image = np.array([np.asarray(image.columns[n]) for n in range(len(image.columns))])\n                    if verbose:\n                        print('Read as ascii...')\n                        \n                    txt, header = open(downloaded_file), []\n                    for i in txt:\n                        if any([i.startswith(char) for char in ['#', '|', '\\\\']]):\n                            header.append(i.replace('\\n', ''))\n                    txt.close()\n                    \n                except:\n                    pass\n                    \n    if image == '':\n        print('Could not retrieve image at {}.'.format(File))\n        return File\n        \n    else:\n        image = Image(image, header, File)\n        return image", "response": "Converts a IMAGE file to a data cube."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_spectrum(File, verbose=False):\n    spectrum, header = '', ''\n    if isinstance(File, type(b'')):  # Decode if needed (ie, for Python 3)\n        File = File.decode('utf-8')\n\n    if isinstance(File, (str, type(u''))):\n\n        # Convert variable path to absolute path\n        if File.startswith('$'):\n            abspath = os.popen('echo {}'.format(File.split('/')[0])).read()[:-1]\n            if abspath: File = File.replace(File.split('/')[0], abspath)\n\n        if File.startswith('http'):\n            if verbose: print('Downloading {}'.format(File))\n            downloaded_file = download_file(File, cache=True)  # download only once\n        else:\n            downloaded_file = File\n\n        try:  # Try FITS files first\n            # Get the data\n            # try:\n            spectrum, header = pf.getdata(downloaded_file, cache=True, header=True)\n            # except:\n            #     spectrum, header = pf.getdata(File, cache=False, header=True)\n\n            # Check the key type\n            KEY_TYPE = ['CTYPE1']\n            setType = set(KEY_TYPE).intersection(set(header.keys()))\n            if len(setType) == 0:\n                isLinear = True\n            else:\n                valType = header[setType.pop()]\n                isLinear = valType.strip().upper() == 'LINEAR'\n\n            # Get wl, flux & error data from fits file\n            spectrum = __get_spec(spectrum, header, File)\n\n            # Generate wl axis when needed\n            if not isinstance(spectrum[0], np.ndarray):\n                tempwav = __create_waxis(header, len(spectrum[1]), File)\n\n                # Check to see if it's a FIRE spectrum with CDELT1, if so needs wlog=True\n                if 'INSTRUME' in header.keys():\n                    if header['INSTRUME'].strip() == 'FIRE' and 'CDELT1' in header.keys():\n                        tempwav = __create_waxis(header, len(spectrum[1]), File, wlog=True)\n\n                spectrum[0] = tempwav\n\n            # If no wl axis generated, then clear out all retrieved data for object\n            if not isinstance(spectrum[0], np.ndarray):\n                spectrum = None\n\n            if verbose: print('Read as FITS...')\n        except (IOError, KeyError):\n            # Check if the FITS file is just Numpy arrays\n            try:\n                spectrum, header = pf.getdata(downloaded_file, cache=True, header=True)\n                if verbose: print('Read as FITS Numpy array...')\n            except (IOError, KeyError):\n                try:  # Try ascii\n                    spectrum = ii.read(downloaded_file)\n                    spectrum = np.array([np.asarray(spectrum.columns[n]) for n in range(len(spectrum.columns))])\n                    if verbose: print('Read as ascii...')\n\n                    txt, header = open(downloaded_file), []\n                    for i in txt:\n                        if any([i.startswith(char) for char in ['#', '|', '\\\\']]):\n                            header.append(i.replace('\\n', ''))\n                    txt.close()\n                except:\n                    pass\n\n    if spectrum == '':\n        print('Could not retrieve spectrum at {}.'.format(File))\n        return File\n    else:\n        spectrum = Spectrum(spectrum, header, File)\n        return spectrum", "response": "Converts a SPECTRUM file into a sequence of arrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pprint(data, names='', title='', formats={}):\n    # Make the data into a table if it isn't already\n    if type(data) != at.Table:\n        data = at.Table(data, names=names)\n\n    # Make a copy\n    pdata = data.copy()\n\n    # Put the title in the metadata\n    try:\n        title = title or pdata.meta['name']\n    except:\n        pass\n\n    # Shorten the column names for slimmer data\n    for old, new in zip(*[pdata.colnames, [\n        i.replace('wavelength', 'wav').replace('publication', 'pub').replace('instrument', 'inst')\\\n        .replace('telescope','scope') for i in pdata.colnames]]):\n        pdata.rename_column(old, new) if new != old else None\n\n    # Format the columns\n    formats.update({'comments': '%.15s', 'obs_date': '%.10s', 'names': '%.30s', 'description': '%.50s'})\n\n    # print it!\n    if title: print('\\n' + title)\n    try:\n        ii.write(pdata, sys.stdout, Writer=ii.FixedWidthTwoLine, formats=formats, fill_values=[('None', '-')])\n    except UnicodeDecodeError:  # Fix for Unicode characters. Print out in close approximation to ii.write()\n        max_length = 50\n        str_lengths = dict()\n        for key in pdata.keys():\n            lengths = map(lambda x: len(str(x).decode('utf-8')), pdata[key].data)\n            lengths.append(len(key))\n            str_lengths[key] = min(max(lengths), max_length)\n        print(' '.join(key.rjust(str_lengths[key]) for key in pdata.keys()))\n        print(' '.join('-' * str_lengths[key] for key in pdata.keys()))\n        for i in pdata:\n            print(' '.join([str(i[key]).decode('utf-8')[:max_length].rjust(str_lengths[key])\n                           if i[key] else '-'.rjust(str_lengths[key]) for key in pdata.keys()]))", "response": "Print the data in a table with a bit of formatting"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scrub(data, units=False):\n    units = [i.unit if hasattr(i, 'unit') else 1 for i in data]\n    data = [np.asarray(i.value if hasattr(i, 'unit') else i, dtype=np.float32) for i in data if\n            isinstance(i, np.ndarray)]\n    data = [i[np.where(~np.isinf(data[1]))] for i in data]\n    data = [i[np.where(np.logical_and(data[1] > 0, ~np.isnan(data[1])))] for i in data]\n    data = [i[np.unique(data[0], return_index=True)[1]] for i in data]\n    return [i[np.lexsort([data[0]])] * Q for i, Q in zip(data, units)] if units else [i[np.lexsort([data[0]])] for i in\n                                                                                      data]", "response": "Scrubs the input data into a list of wavelengths and errors."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an astropy table with columns auto-filled from FITS header Parameters ---------- record: astropy.io.fits.table.table.Row The spectrum table row to scrape Returns ------- record: astropy.io.fits.table.table.Row The spectrum table row with possible new rows inserted", "response": "def _autofill_spec_record(record):\n    \"\"\"\n    Returns an astropy table with columns auto-filled from FITS header\n\n    Parameters\n    ----------\n    record: astropy.io.fits.table.table.Row\n        The spectrum table row to scrape\n\n    Returns\n    -------\n    record: astropy.io.fits.table.table.Row\n        The spectrum table row with possible new rows inserted\n    \"\"\"\n    try:\n        record['filename'] = os.path.basename(record['spectrum'])\n\n        if record['spectrum'].endswith('.fits'):\n            header = pf.getheader(record['spectrum'])\n\n            # Wavelength units\n            if not record['wavelength_units']:\n                try:\n                    record['wavelength_units'] = header['XUNITS']\n                except KeyError:\n                    try:\n                        if header['BUNIT']: record['wavelength_units'] = 'um'\n                    except KeyError:\n                        pass\n            if 'microns' in record['wavelength_units'] or 'Microns' in record['wavelength_units'] or 'um' in record[\n                'wavelength_units']:\n                record['wavelength_units'] = 'um'\n\n            # Flux units\n            if not record['flux_units']:\n                try:\n                    record['flux_units'] = header['YUNITS'].replace(' ', '')\n                except KeyError:\n                    try:\n                        record['flux_units'] = header['BUNIT'].replace(' ', '')\n                    except KeyError:\n                        pass\n            if 'erg' in record['flux_units'] and 'A' in record['flux_units']:\n                record['flux_units'] = 'ergs-1cm-2A-1' if 'erg' in record['flux_units'] and 'A' in record['flux_units'] \\\n                    else 'ergs-1cm-2um-1' if 'erg' in record['flux_units'] and 'um' in record['flux_units'] \\\n                    else 'Wm-2um-1' if 'W' in record['flux_units'] and 'um' in record['flux_units'] \\\n                    else 'Wm-2A-1' if 'W' in record['flux_units'] and 'A' in record['flux_units'] \\\n                    else ''\n\n            # Observation date\n            if not record['obs_date']:\n                try:\n                    record['obs_date'] = header['DATE_OBS']\n                except KeyError:\n                    try:\n                        record['obs_date'] = header['DATE-OBS']\n                    except KeyError:\n                        try:\n                            record['obs_date'] = header['DATE']\n                        except KeyError:\n                            pass\n\n            # Telescope id\n            if not record['telescope_id']:\n                try:\n                    n = header['TELESCOP'].lower() if isinstance(header['TELESCOP'], str) else ''\n                    record['telescope_id'] = 5 if 'hst' in n \\\n                        else 6 if 'spitzer' in n \\\n                        else 7 if 'irtf' in n \\\n                        else 9 if 'keck' in n and 'ii' in n \\\n                        else 8 if 'keck' in n and 'i' in n \\\n                        else 10 if 'kp' in n and '4' in n \\\n                        else 11 if 'kp' in n and '2' in n \\\n                        else 12 if 'bok' in n \\\n                        else 13 if 'mmt' in n \\\n                        else 14 if 'ctio' in n and '1' in n \\\n                        else 15 if 'ctio' in n and '4' in n \\\n                        else 16 if 'gemini' in n and 'north' in n \\\n                        else 17 if 'gemini' in n and 'south' in n \\\n                        else 18 if ('vlt' in n and 'U2' in n) \\\n                        else 19 if '3.5m' in n \\\n                        else 20 if 'subaru' in n \\\n                        else 21 if ('mag' in n and 'ii' in n) or ('clay' in n) \\\n                        else 22 if ('mag' in n and 'i' in n) or ('baade' in n) \\\n                        else 23 if ('eso' in n and '1m' in n) \\\n                        else 24 if 'cfht' in n \\\n                        else 25 if 'ntt' in n \\\n                        else 26 if ('palomar' in n and '200-inch' in n) \\\n                        else 27 if 'pan-starrs' in n \\\n                        else 28 if ('palomar' in n and '60-inch' in n) \\\n                        else 29 if ('ctio' in n and '0.9m' in n) \\\n                        else 30 if 'soar' in n \\\n                        else 31 if ('vlt' in n and 'U3' in n) \\\n                        else 32 if ('vlt' in n and 'U4' in n) \\\n                        else 33 if 'gtc' in n \\\n                        else None\n                except KeyError:\n                    pass\n\n            # Instrument id\n            if not record['instrument_id']:\n                try:\n                    i = header['INSTRUME'].lower()\n                    record[\n                        'instrument_id'] = 1 if 'r-c spec' in i or 'test' in i or 'nod' in i else 2 if 'gmos-n' in i else 3 if 'gmos-s' in i else 4 if 'fors' in i else 5 if 'lris' in i else 6 if 'spex' in i else 7 if 'ldss3' in i else 8 if 'focas' in i else 9 if 'nirspec' in i else 10 if 'irs' in i else 11 if 'fire' in i else 12 if 'mage' in i else 13 if 'goldcam' in i else 14 if 'sinfoni' in i else 15 if 'osiris' in i else 16 if 'triplespec' in i else 17 if 'x-shooter' in i else 18 if 'gnirs' in i else 19 if 'wircam' in i else 20 if 'cormass' in i else 21 if 'isaac' in i else 22 if 'irac' in i else 23 if 'dis' in i else 24 if 'susi2' in i else 25 if 'ircs' in i else 26 if 'nirc' in i else 29 if 'stis' in i else 0\n                except KeyError:\n                    pass\n\n    except:\n        pass\n\n    return record"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_changelog(self, user=\"\", mod_tables=\"\", user_desc=\"\"):\n        import datetime\n        import socket\n        \n        # Spit out warning messages if the user does not provide the needed information\n        if user == \"\" or mod_tables == \"\" or user_desc == \"\":\n            print(\"You must supply your name, the name(s) of table(s) edited, \"\n                  \"and a description for add_changelog() to work.\")\n            raise InputError('Did not supply the required input, see help(db.add_changelog) for more information.\\n'\n                             'Your inputs: \\n\\t user = {}\\n\\t mod_tables = {}\\n\\t user_desc = {}'.format(user, mod_tables, user_desc))\n                             \n        # Making tables all uppercase for consistency\n        mod_tables = mod_tables.upper()\n        \n        data = list()\n        data.append(['date', 'user', 'machine_name', 'modified_tables', 'user_description'])\n        datestr = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        machine = socket.gethostname()\n        data.append([datestr, user, machine, mod_tables, user_desc])\n        self.add_data(data, 'changelog')", "response": "Add an entry to the changelog table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd data to the specified table.", "response": "def add_data(self, data, table, delimiter='|', bands='', clean_up=True, rename_columns={}, column_fill={}, verbose=False):\n        \"\"\"\n        Adds data to the specified database table. Column names must match table fields to insert,\n        however order and completeness don't matter.\n        \n        Parameters\n        ----------\n        data: str, array-like, astropy.table.Table\n            The path to an ascii file, array-like object, or table. The first row or element must\n            be the list of column names\n        table: str\n            The name of the table into which the data should be inserted\n        delimiter: str\n            The string to use as the delimiter when parsing the ascii file\n        bands: sequence\n            Sequence of band to look for in the data header when digesting columns of\n            multiple photometric measurements (e.g. ['MKO_J','MKO_H','MKO_K']) into individual\n            rows of data for database insertion\n        clean_up: bool\n            Run self.clean_up()\n        rename_columns: dict\n            A dictionary of the {input_col_name:desired_col_name} for table columns,\n            e.g. {'e_Jmag':'J_unc', 'RAJ2000':'ra'}\n        column_fill: dict\n            A dictionary of the column name and value to fill, e.g. {'instrument_id':2, 'band':'2MASS.J'}\n        verbose: bool\n          Print diagnostic messages\n        \"\"\"\n        # Store raw entry\n        entry, del_records = data, []\n\n        # Digest the ascii file into table\n        if isinstance(data, str) and os.path.isfile(data):\n            data = ii.read(data, delimiter=delimiter)\n\n        # Or read the sequence of data elements into a table\n        elif isinstance(data, (list, tuple, np.ndarray)):\n            data = ii.read(['|'.join(map(str, row)) for row in data], data_start=1, delimiter='|')\n            \n        # Or convert pandas dataframe to astropy table\n        elif isinstance(data, pd.core.frame.DataFrame):\n            data = at.Table.from_pandas(data)\n            \n        # Or if it's already an astropy table\n        elif isinstance(data, at.Table):\n            pass\n            \n        else:\n            data = None\n            \n        if data:\n            \n            # Rename columns\n            if isinstance(rename_columns,str):\n                rename_columns = astrocat.default_rename_columns(rename_columns)\n            for input_name,new_name in rename_columns.items():\n                data.rename_column(input_name,new_name)\n                \n            # Add column fills\n            if isinstance(column_fill,str):\n                column_fill = astrocat.default_column_fill(column_fill)\n            for colname,fill_value in column_fill.items():\n                data[colname] = [fill_value]*len(data)\n                \n            # Get list of all columns and make an empty table for new records\n            metadata = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n            columns, types, required = [np.array(metadata[n]) for n in ['name', 'type', 'notnull']]\n            new_records = at.Table(names=columns, dtype=[type_dict[t] for t in types])\n            \n            # Fix column dtypes and blanks\n            for col in data.colnames:\n                \n                # Convert data dtypes to those of the existing table\n                try:\n                    temp = data[col].astype(new_records[col].dtype)\n                    data.replace_column(col, temp)\n                except KeyError:\n                    continue\n                    \n            # If a row contains photometry for multiple bands, use the *multiband argument and execute this\n            if bands and table.lower() == 'photometry':\n                \n                # Pull out columns that are band names\n                for b in list(set(bands) & set(data.colnames)):\n                    \n                    try:\n                        # Get the repeated data plus the band data and rename the columns\n                        band = data[list(set(columns) & set(data.colnames)) + [b, b + '_unc']]\n                        for suf in ['', '_unc']:\n                            band.rename_column(b+suf, 'magnitude'+suf)\n                            temp = band['magnitude'+suf].astype(new_records['magnitude'+suf].dtype)\n                            band.replace_column('magnitude'+suf, temp)\n                        band.add_column(at.Column([b] * len(band), name='band', dtype='O'))\n                        \n                        # Add the band data to the list of new_records\n                        new_records = at.vstack([new_records, band])\n                        \n                    except IOError:\n                        pass\n                        \n            else:\n                # Inject data into full database table format\n                new_records = at.vstack([new_records, data])[new_records.colnames]\n                \n            # Reject rows that fail column requirements, e.g. NOT NULL fields like 'source_id'\n            for r in columns[np.where(np.logical_and(required, columns != 'id'))]:\n                # Null values...\n                new_records = new_records[np.where(new_records[r])]\n                \n                # Masked values...\n                try:\n                    new_records = new_records[~new_records[r].mask]\n                except:\n                    pass\n                \n                # NaN values...\n                if new_records.dtype[r] in (int, float):\n                    new_records = new_records[~np.isnan(new_records[r])]\n                    \n            # For spectra, try to populate the table by reading the FITS header\n            if table.lower() == 'spectra':\n                for n, new_rec in enumerate(new_records):\n                    \n                    # Convert relative path to absolute path\n                    relpath = new_rec['spectrum']\n                    if relpath.startswith('$'):\n                        abspath = os.popen('echo {}'.format(relpath.split('/')[0])).read()[:-1]\n                        if abspath:\n                            new_rec['spectrum'] = relpath.replace(relpath.split('/')[0], abspath)\n                            \n                    # Test if the file exists and try to pull metadata from the FITS header\n                    if os.path.isfile(new_rec['spectrum']):\n                        new_records[n]['spectrum'] = relpath\n                        new_records[n] = _autofill_spec_record(new_rec)\n                    else:\n                        print('Error adding the spectrum at {}'.format(new_rec['spectrum']))\n                        del_records.append(n)\n                        \n                # Remove bad records from the table\n                new_records.remove_rows(del_records)\n                \n            # For images, try to populate the table by reading the FITS header\n            if table.lower() == 'images':\n                for n, new_rec in enumerate(new_records):\n                    \n                    # Convert relative path to absolute path\n                    relpath = new_rec['image']\n                    if relpath.startswith('$'):\n                        abspath = os.popen('echo {}'.format(relpath.split('/')[0])).read()[:-1]\n                        if abspath:\n                            new_rec['image'] = relpath.replace(relpath.split('/')[0], abspath)\n\n                    # Test if the file exists and try to pull metadata from the FITS header\n                    if os.path.isfile(new_rec['image']):\n                        new_records[n]['image'] = relpath\n                        new_records[n] = _autofill_spec_record(new_rec)\n                    else:\n                        print('Error adding the image at {}'.format(new_rec['image']))\n                        del_records.append(n)\n                        \n                # Remove bad records from the table\n                new_records.remove_rows(del_records)\n                \n            # Get some new row ids for the good records\n            rowids = self._lowest_rowids(table, len(new_records))\n            \n            # Add the new records\n            keepers, rejects = [], []\n            for N, new_rec in enumerate(new_records):\n                new_rec = list(new_rec)\n                new_rec[0] = rowids[N]\n                for n, col in enumerate(new_rec):\n                    if type(col) == np.int64 and sys.version_info[0] >= 3:\n                        # Fix for Py3 and sqlite3 issue with numpy types\n                        new_rec[n] = col.item()\n                    if type(col) == np.ma.core.MaskedConstant:\n                        new_rec[n] = None\n                        \n                try:\n                    self.modify(\"INSERT INTO {} VALUES({})\".format(table, ','.join('?'*len(columns))), new_rec, verbose=verbose)\n                    keepers.append(N)\n                except IOError:\n                    rejects.append(N)\n                    \n                new_records[N]['id'] = rowids[N]\n                \n            # Make tables of keepers and rejects\n            rejected = new_records[rejects]\n            new_records = new_records[keepers]\n            \n            # Print a table of the new records or bad news\n            if new_records:\n                print(\"\\033[1;32m{} new records added to the {} table.\\033[1;m\".format(len(new_records), table.upper()))\n                new_records.pprint()\n                \n            if rejected:\n                print(\"\\033[1;31m{} records rejected from the {} table.\\033[1;m\".format(len(rejected), table.upper()))\n                rejected.pprint()\n                \n            # Run table clean up\n            if clean_up:\n                self.clean_up(table, verbose)\n\n        else:\n            print('Please check your input: {}'.format(entry))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_foreign_key(self, table, parent, key_child, key_parent, verbose=True):\n\n        # Temporarily turn off foreign keys\n        self.list('PRAGMA foreign_keys=OFF')\n\n        metadata = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n        columns, types, required, pk = [np.array(metadata[n]) for n in ['name', 'type', 'notnull', 'pk']]\n\n        # Set constraints\n        constraints = []\n        for elem in required:\n            if elem > 0:\n                constraints.append('NOT NULL')\n            else:\n                constraints.append('')\n\n        # Set PRIMARY KEY columns\n        ind, = np.where(pk >= 1)\n        for i in ind:\n            constraints[i] += ' UNIQUE'  # Add UNIQUE constraint to primary keys\n        pk_names = columns[ind]\n\n        try:\n            # Rename the old table and create a new one\n            self.list(\"DROP TABLE IF EXISTS TempOldTable_foreign\")\n            self.list(\"ALTER TABLE {0} RENAME TO TempOldTable_foreign\".format(table))\n\n            # Re-create the table specifying the FOREIGN KEY\n            sqltxt = \"CREATE TABLE {0} (\\n\\t{1}\".format(table, ', \\n\\t'.join(['{} {} {}'.format(c, t, r)\n                                                                      for c, t, r in zip(columns, types, constraints)]))\n            sqltxt += ', \\n\\tPRIMARY KEY({})'.format(', '.join([elem for elem in pk_names]))\n            if isinstance(key_child, type(list())):\n                for kc, p, kp in zip(key_child, parent, key_parent):\n                    sqltxt += ', \\n\\tFOREIGN KEY ({0}) REFERENCES {1} ({2}) ON UPDATE CASCADE'.format(kc, p, kp)\n            else:\n                sqltxt += ', \\n\\tFOREIGN KEY ({0}) REFERENCES {1} ({2}) ON UPDATE CASCADE'.format(key_child, parent, key_parent)\n            sqltxt += ' \\n)'\n\n            self.list(sqltxt)\n\n            # Populate the new table and drop the old one\n            tempdata = self.query(\"PRAGMA table_info(TempOldTable_foreign)\", fmt='table')\n            old_columns = [c for c in tempdata['name'] if c in columns]\n            self.list(\"INSERT INTO {0} ({1}) SELECT {1} FROM TempOldTable_foreign\".format(table, ','.join(old_columns)))\n            self.list(\"DROP TABLE TempOldTable_foreign\")\n\n            if verbose:\n                # print('Successfully added foreign key.')\n                t = self.query('SELECT name, sql FROM sqlite_master', fmt='table')\n                # print(t[t['name'] == table]['sql'][0].replace(',', ',\\n'))\n                print(t[t['name'] == table]['sql'][0])\n\n        except:\n            print('Error attempting to add foreign key.')\n            self.list(\"DROP TABLE IF EXISTS {0}\".format(table))\n            self.list(\"ALTER TABLE TempOldTable_foreign RENAME TO {0}\".format(table))\n            raise sqlite3.IntegrityError('Failed to add foreign key')\n\n        # Reactivate foreign keys\n        self.list('PRAGMA foreign_keys=ON')", "response": "Adds a foreign key to the table column key_child from parent."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all possible duplicate entries from the specified table.", "response": "def clean_up(self, table, verbose=False):\n        \"\"\"\n        Removes exact duplicates, blank records or data without a *source_id* from the specified **table**.\n        Then finds possible duplicates and prompts for conflict resolution.\n\n        Parameters\n        ----------\n        table: str\n            The name of the table to remove duplicates, blanks, and data without source attributions.\n        verbose: bool\n            Print out some diagnostic messages\n\n        \"\"\"\n        # Get the table info and all the records\n        metadata = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n        columns, types, required = [np.array(metadata[n]) for n in ['name', 'type', 'notnull']]\n        # records = self.query(\"SELECT * FROM {}\".format(table), fmt='table', use_converters=False)\n        ignore = self.query(\"SELECT * FROM ignore WHERE tablename LIKE ?\", (table,))\n        duplicate, command = [1], ''\n\n        # Remove records with missing required values\n        req_keys = columns[np.where(required)]\n        try:\n            self.modify(\"DELETE FROM {} WHERE {}\".format(table, ' OR '.join([i + ' IS NULL' for i in req_keys])),\n                        verbose=False)\n            self.modify(\n                \"DELETE FROM {} WHERE {}\".format(table, ' OR '.join([i + \" IN ('null','None','')\" for i in req_keys])),\n                verbose=False)\n        except:\n            pass\n\n        # Remove exact duplicates\n        self.modify(\"DELETE FROM {0} WHERE id NOT IN (SELECT min(id) FROM {0} GROUP BY {1})\".format(table, ', '.join(\n                columns[1:])), verbose=False)\n\n        # Check for records with identical required values but different ids.\n        if table.lower() != 'sources': req_keys = columns[np.where(np.logical_and(required, columns != 'id'))]\n\n        # List of old and new pairs to ignore\n        if not type(ignore) == np.ndarray: ignore = np.array([])\n        new_ignore = []\n\n        while any(duplicate):\n            # Pull out duplicates one by one\n            if 'source_id' not in columns:  # Check if there is a source_id in the columns\n                SQL = \"SELECT t1.id, t2.id FROM {0} t1 JOIN {0} t2 ON t1.id=t2.id WHERE \".format(table)\n            else:\n                SQL = \"SELECT t1.id, t2.id FROM {0} t1 JOIN {0} t2 ON t1.source_id=t2.source_id \" \\\n                      \"WHERE t1.id!=t2.id AND \".format(table)\n\n            if any(req_keys):\n                SQL += ' AND '.join(['t1.{0}=t2.{0}'.format(i) for i in req_keys]) + ' AND '\n\n            if any(ignore):\n                SQL += ' AND '.join(\n                    [\"(t1.id NOT IN ({0}) AND t2.id NOT IN ({0}))\".format(','.join(map(str, [id1, id2])))\n                        for id1, id2 in zip(ignore['id1'], ignore['id2'])]\n                    if any(ignore) else '') + ' AND '\n\n            if any(new_ignore):\n                SQL += ' AND '.join(\n                    [\"(t1.id NOT IN ({0}) AND t2.id NOT IN ({0}))\".format(','.join(map(str, ni)))\n                     for ni in new_ignore] if new_ignore else '') + ' AND '\n\n            # Clean up empty WHERE at end if it's present (eg, for empty req_keys, ignore, and new_ignore)\n            if SQL[-6:] == 'WHERE ':\n                SQL = SQL[:-6]\n\n            # Clean up hanging AND if present\n            if SQL[-5:] == ' AND ':\n                SQL = SQL[:-5]\n\n            if verbose:\n                print('\\nSearching for duplicates with: {}\\n'.format(SQL))\n\n            duplicate = self.query(SQL, fetch='one')\n\n            # Compare potential duplicates and prompt user for action on each\n            try:\n                # Run record matches through comparison and return the command\n                command = self._compare_records(table, duplicate)\n\n                # Add acceptable duplicates to ignore list or abort\n                if command == 'keep':\n                    new_ignore.append([duplicate[0], duplicate[1]])\n                    self.list(\"INSERT INTO ignore VALUES(?,?,?,?)\", (None, duplicate[0], duplicate[1], table.lower()))\n                elif command == 'undo':\n                    pass  # TODO: Add this functionality!\n                elif command == 'abort':\n                    break\n                else:\n                    pass\n            except:\n                break\n\n        # Finish or abort table clean up\n        if command == 'abort':\n            print('\\nAborted clean up of {} table.'.format(table.upper()))\n            return 'abort'\n        else:\n            print('\\nFinished clean up on {} table.'.format(table.upper()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the database and ask to save and delete the file", "response": "def close(self, silent=False):\n        \"\"\"\n        Close the database and ask to save and delete the file\n\n        Parameters\n        ----------\n        silent: bool\n            Close quietly without saving or deleting (Default: False).\n        \"\"\"\n        if not silent:\n            saveme = get_input(\"Save database contents to '{}/'? (y, [n]) \\n\"\n                               \"To save elsewhere, run db.save() before closing. \".format(self.directory))\n            if saveme.lower() == 'y':\n                self.save()\n\n            delete = get_input(\"Do you want to delete {0}? (y,[n]) \\n\"\n                               \"Don't worry, a new one will be generated if you run astrodb.Database('{1}') \"\n                               .format(self.dbpath, self.sqlpath))\n            if delete.lower() == 'y':\n                print(\"Deleting {}\".format(self.dbpath))\n                os.system(\"rm {}\".format(self.dbpath))\n\n        print('Closing connection')\n        self.conn.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompares similar records and prompts the user to make decisions about keeping updating or modifying records in question.", "response": "def _compare_records(self, table, duplicate, options=['r', 'c', 'k', 'sql']):\n        \"\"\"\n        Compares similar records and prompts the user to make decisions about keeping, updating, or modifying records in question.\n\n        Parameters\n        ----------\n        table: str\n            The name of the table whose records are being compared.\n        duplicate: sequence\n            The ids of the potentially duplicate records\n        options: list\n            The allowed options: 'r' for replace, 'c' for complete, 'k' for keep, 'sql' for raw SQL input.\n\n        \"\"\"\n        # print the old and new records suspected of being duplicates\n        verbose = True\n        if duplicate[0] == duplicate[1]:  # No need to display if no duplicates were found\n            verbose = False\n\n        data = self.query(\"SELECT * FROM {} WHERE id IN ({})\".format(table, ','.join(map(str, duplicate))), \\\n                          fmt='table', verbose=verbose, use_converters=False)\n        columns = data.colnames[1:]\n        old, new = [[data[n][k] for k in columns[1:]] for n in [0, 1]]\n\n        # Prompt the user for action\n        replace = get_input(\n            \"\\nKeep both records [k]? Or replace [r], complete [c], or keep only [Press *Enter*] record {}? (Type column name to inspect or 'help' for options): \".format(\n                    duplicate[0])).lower()\n        replace = replace.strip()\n\n        while replace in columns or replace == 'help':\n            if replace in columns:\n                pprint(np.asarray([[i for idx, i in enumerate(old) if idx in [0, columns.index(replace)]], \\\n                                   [i for idx, i in enumerate(new) if idx in [0, columns.index(replace)]]]), \\\n                       names=['id', replace])\n\n            elif replace == 'help':\n                _help()\n\n            replace = get_input(\n                \"\\nKeep both records [k]? Or replace [r], complete [c], or keep only [Press *Enter*] record {}? (Type column name to inspect or 'help' for options): \".format(\n                        duplicate[0])).lower()\n\n        if replace and replace.split()[0] in options:\n\n            # Replace the entire old record with the new record\n            if replace == 'r':\n                sure = get_input(\n                    'Are you sure you want to replace record {} with record {}? [y/n] : '.format(*duplicate))\n                if sure.lower() == 'y':\n                    self.modify(\"DELETE FROM {} WHERE id={}\".format(table, duplicate[0]), verbose=False)\n                    self.modify(\"UPDATE {} SET id={} WHERE id={}\".format(table, duplicate[0], duplicate[1]),\n                                verbose=False)\n\n            # Replace specific columns\n            elif replace.startswith('r'):\n                replace_cols = replace.split()[1:]\n                if all([i in columns for i in replace_cols]):\n                    empty_cols, new_vals = zip(\n                        *[['{}=?'.format(e), n] for e, n in zip(columns, new) if e in replace_cols])\n                    if empty_cols:\n                        self.modify(\"DELETE FROM {} WHERE id={}\".format(table, duplicate[1]), verbose=False)\n                        self.modify(\"UPDATE {} SET {} WHERE id={}\".format(table, ','.join(empty_cols), duplicate[0]),\n                                    tuple(new_vals), verbose=False)\n                else:\n                    badcols = ','.join([i for i in replace_cols if i not in columns])\n                    print(\"\\nInvalid column names for {} table: {}\".format(table, badcols))\n\n            # Complete the old record with any missing data provided in the new record, then delete the new record\n            elif replace == 'c':\n                try:\n                    empty_cols, new_vals = zip(\n                        *[['{}=?'.format(e), n] for e, o, n in zip(columns[1:], old, new) if n and not o])\n                    self.modify(\"DELETE FROM {} WHERE id={}\".format(table, duplicate[1]), verbose=False)\n                    self.modify(\"UPDATE {} SET {} WHERE id={}\".format(table, ','.join(empty_cols), duplicate[0]),\n                                tuple(new_vals), verbose=False)\n                except:\n                    pass\n\n            # Keep both records\n            elif replace == 'k':\n                return 'keep'\n\n            # Execute raw SQL\n            elif replace.startswith('sql') and 'sql' in options:\n                self.modify(replace[4:], verbose=False)\n\n        # Abort the current database clean up\n        elif replace == 'abort':\n            return 'abort'\n\n        # Delete the higher id record\n        elif not replace:\n            self.modify(\"DELETE FROM {} WHERE id={}\".format(table, max(duplicate)), verbose=False)\n\n        # Prompt again\n        else:\n            print(\"\\nInvalid command: {}\\nTry again or type 'help' or 'abort'.\\n\".format(replace))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _explicit_query(self, SQL, use_converters=True):\n        try:\n            # If field names are given, sort so that they come out in the same order they are fetched\n            if 'select' in SQL.lower() and 'from' in SQL.lower():\n\n                # Make a dictionary of the table aliases\n                tdict = {}\n                from_clause = SQL.lower().split('from ')[-1].split(' where')[0]\n                tables = [j for k in [i.split(' on ') for i in from_clause.split(' join ')] for j in k if '=' not in j]\n\n                for t in tables:\n                    t = t.replace('as', '')\n                    try:\n                        name, alias = t.split()\n                        tdict[alias] = name\n                    except:\n                        tdict[t] = t\n\n                # Get all the column names and dtype placeholders\n                columns = \\\n                SQL.replace(' ', '').lower().split('distinct' if 'distinct' in SQL.lower() else 'select')[1].split(\n                    'from')[0].split(',')\n\n                # Replace * with the field names\n                for n, col in enumerate(columns):\n                    if '.' in col:\n                        t, col = col.split('.')\n                    else:\n                        t = tables[0]\n\n                    if '*' in col:\n                        col = np.array(self.list(\"PRAGMA table_info({})\".format(tdict.get(t))).fetchall()).T[1]\n                    else:\n                        col = [col]\n\n                    columns[n] = [\"{}.{}\".format(t, c) if len(tables) > 1 else c for c in col]\n\n                # Flatten the list of columns and dtypes\n                columns = [j for k in columns for j in k]\n\n                # Get the dtypes\n                dSQL = \"SELECT \" \\\n                       + ','.join([\"typeof({})\".format(col) for col in columns]) \\\n                       + ' FROM ' + SQL.replace('from', 'FROM').split('FROM')[-1]\n                if use_converters:\n                    dtypes = [None] * len(columns)\n                else:\n                    dtypes = self.list(dSQL).fetchone()\n\n                # Reconstruct SQL query\n                SQL = \"SELECT {}\".format('DISTINCT ' if 'distinct' in SQL.lower() else '') \\\n                      + (','.join([\"{0} AS '{0}'\".format(col) for col in columns]) \\\n                             if use_converters else ','.join([\"{1}{0}{2} AS '{0}'\".format(col,\n                                                                                          'CAST(' if dt != 'null' else '',\n                                                                                          ' AS {})'.format(\n                                                                                              dt) if dt != 'null' else '') \\\n                                                              for dt, col in zip(dtypes, columns)])) \\\n                      + ' FROM ' \\\n                      + SQL.replace('from', 'FROM').split('FROM')[-1]\n\n            elif 'pragma' in SQL.lower():\n                columns = ['cid', 'name', 'type', 'notnull', 'dflt_value', 'pk']\n\n            return SQL, columns\n\n        except:\n            return SQL, ''", "response": "This method is used to parse the SQL query and return the column names and types of the tables in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the bibtex entry for a specific id or shortname from the Publications table.", "response": "def get_bibtex(self, id, fetch=False, table='publications'):\n        \"\"\"\n        Grab bibtex entry from NASA ADS\n\n        Parameters\n        ----------\n        id: int or str\n            The id or shortname from the PUBLICATIONS table to search\n        fetch: bool\n            Whether or not to return the bibtex string in addition to printing (default: False)\n        table: str\n            Table name, defaults to publications\n\n        Returns\n        -------\n        bibtex: str\n            If fetch=True, return the bibtex string\n        \"\"\"\n\n        import requests\n        bibcode_name = 'bibcode'\n\n        if isinstance(id, type(1)):\n            bibcode = self.query(\"SELECT {} FROM {} WHERE id={}\".format(bibcode_name, table, id),\n                                 fetch='one')\n        else:\n            bibcode = self.query(\"SELECT {} FROM {} WHERE shortname='{}'\".format(bibcode_name, table, id),\n                                 fetch='one')\n\n        # Check for empty bibcodes\n        if isinstance(bibcode, type(None)):\n            print('No bibcode for {}'.format(id))\n            return\n        bibcode = bibcode[0]\n        if bibcode == '':\n            print('No bibcode for {}'.format(id))\n            return\n\n        # Construct URL and grab data\n        url = 'http://adsabs.harvard.edu/cgi-bin/nph-bib_query?bibcode={}&data_type=BIBTEX&db_key=AST&nocookieset=1'.\\\n            format(bibcode)\n        try:\n            r = requests.get(url)\n        except Exception as ex:\n            print('Error accessing url {}'.format(url))\n            print(ex.message)\n            return\n\n        # Check status and display results\n        if r.status_code == 200:\n            ind = r.content.find(b'@')\n            print(r.content[ind:].strip().decode('utf-8'))\n            if fetch:\n                return r.content[ind:].strip()\n        else:\n            print('Error getting bibtex')\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting out information about the loaded database and the number of entries for each table.", "response": "def info(self):\n        \"\"\"\n        Prints out information for the loaded database, namely the available tables and the number of entries for each.\n        \"\"\"\n        t = self.query(\"SELECT * FROM sqlite_master WHERE type='table'\", fmt='table')\n        all_tables = t['name'].tolist()\n        print('\\nDatabase path: {} \\nSQL path: {}\\n'.format(self.dbpath, self.sqlpath))\n        print('Database Inventory')\n        print('==================')\n        for table in ['sources'] + [t for t in all_tables if\n                                    t not in ['sources', 'sqlite_sequence']]:\n            x = self.query('select count() from {}'.format(table), fmt='array', fetch='one')\n            if x is None: continue\n            print('{}: {}'.format(table.upper(), x[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a summary of all objects in the SOURCES table.", "response": "def inventory(self, source_id, fetch=False, fmt='table'):\n        \"\"\"\n        Prints a summary of all objects in the database. Input string or list of strings in **ID** or **unum**\n        for specific objects.\n\n        Parameters\n        ----------\n        source_id: int\n            The id from the SOURCES table whose data across all tables is to be printed.\n        fetch: bool\n            Return the results.\n        fmt: str\n            Returns the data as a dictionary, array, or astropy.table given 'dict', 'array', or 'table'\n\n        Returns\n        -------\n        data_tables: dict\n            Returns a dictionary of astropy tables with the table name as the keys.\n\n        \"\"\"\n        data_tables = {}\n\n        t = self.query(\"SELECT * FROM sqlite_master WHERE type='table'\", fmt='table')\n        all_tables = t['name'].tolist()\n        for table in ['sources'] + [t for t in all_tables if\n                                    t not in ['sources', 'sqlite_sequence']]:\n\n            try:\n\n                # Get the columns, pull out redundant ones, and query the table for this source's data\n                t = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n                columns = np.array(t['name'])\n                types = np.array(t['type'])\n\n                if table == 'sources' or 'source_id' in columns:\n\n                    # If printing, only get simple data types and exclude redundant 'source_id' for nicer printing\n                    if not fetch:\n                        columns = columns[\n                            ((types == 'REAL') | (types == 'INTEGER') | (types == 'TEXT')) & (columns != 'source_id')]\n\n                    # Query the table\n                    try:\n                        id = 'id' if table.lower() == 'sources' else 'source_id'\n                        data = self.query(\n                            \"SELECT {} FROM {} WHERE {}={}\".format(','.join(columns), table, id, source_id),\n                            fmt='table')\n\n                        if not data and table.lower() == 'sources':\n                            print(\n                            'No source with id {}. Try db.search() to search the database for a source_id.'.format(\n                                source_id))\n\n                    except:\n                        data = None\n\n                    # If there's data for this table, save it\n                    if data:\n                        if fetch:\n                            data_tables[table] = self.query(\n                                \"SELECT {} FROM {} WHERE {}={}\".format(','.join(columns), table, id, source_id), \\\n                                fetch=True, fmt=fmt)\n                        else:\n                            data = data[[c.lower() for c in columns]]\n                            pprint(data, title=table.upper())\n\n                else:\n                    pass\n\n            except:\n                print('Could not retrieve data from {} table.'.format(table.upper()))\n\n        if fetch: return data_tables"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup(self, criteria, table, columns=''):\n        results, colmasks = [], []\n        \n        # Iterate through the list, trying to match objects\n        for n,criterion in enumerate(criteria):\n            records = self.search(criterion, table, columns=columns, fetch=True)\n                \n            # If multiple matches, take the first but notify the user of the other matches\n            if len(records)>1:\n                print(\"'{}' matched to {} other record{}.\".format(criterion, len(records)-1, \\\n                      's' if len(records)-1>1 else ''))\n            \n            # If no matches, make an empty row\n            if len(records)==0:\n                records.add_row(np.asarray(np.zeros(len(records.colnames))).T)\n                colmasks.append([True]*len(records.colnames))\n            else:\n                colmasks.append([False]*len(records.colnames))\n            \n            # Grab the first row\n            results.append(records[0])\n        \n        # Add all the rows to the results table\n        table = at.Table(rows=results, names=results[0].colnames, masked=True)\n        \n        # Mask the rows with no matches\n        for col,msk in zip(records.colnames,np.asarray(colmasks).T): \n            table[col].mask = msk\n        \n        return table", "response": "Returns a table of records from the specified table that correspond to each element in the specified columns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the lowest available row ids for table insertion. Keeps things tidy!", "response": "def _lowest_rowids(self, table, limit):\n        \"\"\"\n        Gets the lowest available row ids for table insertion. Keeps things tidy!\n\n        Parameters\n        ----------\n        table: str\n            The name of the table being modified\n        limit: int\n            The number of row ids needed\n\n        Returns\n            -------\n        available: sequence\n            An array of all available row ids\n\n        \"\"\"\n        try:\n            t = self.query(\"SELECT id FROM {}\".format(table), unpack=True, fmt='table')\n            ids = t['id']\n            all_ids = np.array(range(1, max(ids)))\n        except TypeError:\n            ids = None\n            all_ids = np.array(range(1, limit+1))\n\n        available = all_ids[np.in1d(all_ids, ids, assume_unique=True, invert=True)][:limit]\n\n        # If there aren't enough empty row ids, start using the new ones\n        if len(available) < limit:\n            diff = limit - len(available)\n            available = np.concatenate((available, np.array(range(max(ids) + 1, max(ids) + 1 + diff))))\n\n        return available"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge the tables of the specified tables into the master database.", "response": "def merge(self, conflicted, tables=[], diff_only=True):\n        \"\"\"\n        Merges specific **tables** or all tables of **conflicted** database into the master database.\n\n        Parameters\n        ----------\n        conflicted: str\n            The path of the SQL database to be merged into the master.\n        tables: list (optional)\n            The list of tables to merge. If None, all tables are merged.\n        diff_only: bool\n                If True, only prints the differences of each table and doesn't actually merge anything.\n\n        \"\"\"\n        if os.path.isfile(conflicted):\n            # Load and attach master and conflicted databases\n            con, master, reassign = Database(conflicted), self.list(\"PRAGMA database_list\").fetchall()[0][2], {}\n            con.modify(\"ATTACH DATABASE '{}' AS m\".format(master), verbose=False)\n            self.modify(\"ATTACH DATABASE '{}' AS c\".format(conflicted), verbose=False)\n            con.modify(\"ATTACH DATABASE '{}' AS c\".format(conflicted), verbose=False)\n            self.modify(\"ATTACH DATABASE '{}' AS m\".format(master), verbose=False)\n\n            # Drop any backup tables from failed merges\n            for table in tables: self.modify(\"DROP TABLE IF EXISTS Backup_{0}\".format(table), verbose=False)\n\n            # Gather user data to add to CHANGELOG table\n            import socket, datetime\n            if not diff_only: user = get_input('Please enter your name : ')\n            machine_name = socket.gethostname()\n            date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n            modified_tables = []\n\n            # Merge table by table, starting with SOURCES\n            if not isinstance(tables, type(list())):\n                tables = [tables]\n\n            tables = tables or ['sources'] + [t for t in zip(*self.list(\n                \"SELECT * FROM sqlite_master WHERE name NOT LIKE '%Backup%' AND name!='sqlite_sequence' AND type='table'{}\".format(\n                    \" AND name IN ({})\".format(\"'\" + \"','\".join(tables) + \"'\") if tables else '')))[1] if\n                                              t != 'sources']\n            for table in tables:\n                # Get column names and data types from master table and column names from conflicted table\n                metadata = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n                columns, types, constraints = [np.array(metadata[n]) for n in ['name', 'type', 'notnull']]\n                # columns, types, constraints = self.query(\"PRAGMA table_info({})\".format(table), unpack=True)[1:4]\n                conflicted_cols = con.query(\"PRAGMA table_info({})\".format(table), unpack=True)[1]\n\n                if any([i not in columns for i in conflicted_cols]):\n                    # Abort table merge if conflicted has new columns not present in master. New columns must be added to the master database first via db.edit_columns().\n                    print(\n                    \"\\nMerge of {0} table aborted since conflicted copy has columns {1} not present in master.\\nAdd new columns to master with astrodb.table() method and try again.\\n\".format(\n                        table.upper(), [i for i in conflicted_cols if i not in columns]))\n\n                else:\n                    # Add new columns from master table to conflicted table if necessary\n                    if any([i not in conflicted_cols for i in columns]):\n                        con.modify(\"DROP TABLE IF EXISTS Conflicted_{0}\".format(table))\n                        con.modify(\"ALTER TABLE {0} RENAME TO Conflicted_{0}\".format(table))\n                        # TODO: Update to allow multiple primary and foreign keys\n                        con.modify(\"CREATE TABLE {0} ({1})\".format(table, ', '.join( \\\n                                ['{} {} {}{}'.format(c, t, r, ' UNIQUE PRIMARY KEY' if c == 'id' else '') \\\n                                 for c, t, r in zip(columns, types, constraints * ['NOT NULL'])])))\n                        con.modify(\"INSERT INTO {0} ({1}) SELECT {1} FROM Conflicted_{0}\".format(table, ','.join(\n                            conflicted_cols)))\n                        con.modify(\"DROP TABLE Conflicted_{0}\".format(table))\n\n                    # Pull unique records from conflicted table\n                    data = map(list, con.list(\n                        \"SELECT * FROM (SELECT 1 AS db, {0} FROM m.{2} UNION ALL SELECT 2 AS db, {0} FROM c.{2}) GROUP BY {1} HAVING COUNT(*)=1 AND db=2\".format(\n                            ','.join(columns), ','.join(columns[1:]), table)).fetchall())\n\n                    if data:\n\n                        # Just print the table differences\n                        if diff_only:\n                            pprint(zip(*data)[1:], names=columns, title='New {} records'.format(table.upper()))\n\n                        # Add new records to the master and then clean up tables\n                        else:\n                            # Make temporary table copy so changes can be undone at any time\n                            self.modify(\"DROP TABLE IF EXISTS Backup_{0}\".format(table), verbose=False)\n                            self.modify(\"ALTER TABLE {0} RENAME TO Backup_{0}\".format(table), verbose=False)\n                            self.modify(\"CREATE TABLE {0} ({1})\".format(table, ', '.join( \\\n                                    ['{} {} {}{}'.format(c, t, r, ' UNIQUE PRIMARY KEY' if c == 'id' else '') \\\n                                     for c, t, r in zip(columns, types, constraints * ['NOT NULL'])])), verbose=False)\n                            self.modify(\n                                \"INSERT INTO {0} ({1}) SELECT {1} FROM Backup_{0}\".format(table, ','.join(columns)),\n                                verbose=False)\n\n                            # Create a dictionary of any reassigned ids from merged SOURCES tables and replace applicable source_ids in other tables.\n                            print(\"\\nMerging {} tables.\\n\".format(table.upper()))\n                            try:\n                                count = self.query(\"SELECT MAX(id) FROM {}\".format(table), fetch='one')[0] + 1\n                            except TypeError:\n                                count = 1\n                            for n, i in enumerate([d[1:] for d in data]):\n                                if table == 'sources':\n                                    reassign[i[0]] = count\n                                elif 'source_id' in columns and i[1] in reassign.keys():\n                                    i[1] = reassign[i[1]]\n                                else:\n                                    pass\n                                i[0] = count\n                                data[n] = i\n                                count += 1\n\n                            # Insert unique records into master\n                            for d in data: self.modify(\n                                \"INSERT INTO {} VALUES({})\".format(table, ','.join(['?' for c in columns])), d,\n                                verbose=False)\n                            pprint(zip(*data), names=columns,\n                                   title=\"{} records added to {} table at '{}':\".format(len(data), table, master))\n\n                            # Run clean_up on the table to check for conflicts\n                            abort = self.clean_up(table)\n\n                            # Undo all changes to table if merge is aborted. Otherwise, push table changes to master.\n                            if abort:\n                                self.modify(\"DROP TABLE {0}\".format(table), verbose=False)\n                                self.modify(\"ALTER TABLE Backup_{0} RENAME TO {0}\".format(table), verbose=False)\n                            else:\n                                self.modify(\"DROP TABLE Backup_{0}\".format(table), verbose=False)\n                                modified_tables.append(table.upper())\n\n                    else:\n                        print(\"\\n{} tables identical.\".format(table.upper()))\n\n            # Add data to CHANGELOG table\n            if not diff_only:\n                user_description = get_input('\\nPlease describe the changes made in this merge: ')\n                self.list(\"INSERT INTO changelog VALUES(?, ?, ?, ?, ?, ?, ?)\", \\\n                          (None, date, str(user), machine_name, ', '.join(modified_tables), user_description,\n                           os.path.basename(conflicted)))\n\n            # Finish up and detach\n            if diff_only:\n                print(\"\\nDiff complete. No changes made to either database. Set `diff_only=False' to apply merge.\")\n            else:\n                print(\"\\nMerge complete!\")\n\n            con.modify(\"DETACH DATABASE c\", verbose=False)\n            self.modify(\"DETACH DATABASE c\", verbose=False)\n            con.modify(\"DETACH DATABASE m\", verbose=False)\n            self.modify(\"DETACH DATABASE m\", verbose=False)\n        else:\n            print(\"File '{}' not found!\".format(conflicted))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify(self, SQL, params='', verbose=True):\n        # Make sure the database isn't locked\n        self.conn.commit()\n\n        if SQL.lower().startswith('select'):\n            print('Use self.query method for queries.')\n        else:\n            self.list(SQL, params)\n            self.conn.commit()\n            if verbose:\n                print('Number of records modified: {}'.format(self.list(\"SELECT changes()\").fetchone()[0] or '0'))", "response": "Wrapper for SQL modify method for CRUD operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_spectrum(self, spectrum, filepath, header={}):\n        # If an integer is supplied, get the spectrum from the SPECTRA table\n        if isinstance(spectrum, int):\n            data = self.query(\"SELECT * FROM spectra WHERE id={}\".format(spectrum), fetch='one', fmt='dict')\n            try:\n                data['header'] = list(map(list, data['spectrum'].header.cards)) + [[k, v, ''] for k, v in\n                                                                                   header.items()]\n            except:\n                data['header'] = ''\n\n        # If a [w,f,e] sequence is supplied, make it into a Spectrum object\n        elif isinstance(spectrum, (list, tuple, np.ndarray)):\n            data = {'spectrum': Spectrum(spectrum, header=header), 'wavelength_units': '', 'flux_units': ''}\n            try:\n                data['header'] = list(map(list, data['spectrum'].header.cards))\n            except:\n                data['header'] = ''\n\n        if data:\n            fn = filepath if filepath.endswith('.txt') else filepath + 'spectrum.txt'\n\n            # Write the header\n            if data['header']:\n                for n, line in enumerate(data['header']):\n                    data['header'][n] = ['# {}'.format(str(line[0])).ljust(10)[:10],\n                                         '{:50s} / {}'.format(*map(str, line[1:]))]\n                try:\n                    ii.write([np.asarray(i) for i in np.asarray(data['header']).T], fn, delimiter='\\t',\n                             format='no_header')\n                except IOError:\n                    pass\n\n            # Write the data\n            names = ['# wavelength [{}]'.format(data['wavelength_units']), 'flux [{}]'.format(data['flux_units'])]\n            if len(data['spectrum'].data) == 3:\n                if type(data['spectrum'].data[2]) in [np.ndarray, list]:\n                    names += ['unc [{}]'.format(data['flux_units'])]\n                else:\n                    data['spectrum'].data = data['spectrum'].data[:2]\n\n            with open(fn, mode='a') as f:\n                ii.write([np.asarray(i, dtype=np.float64) for i in data['spectrum'].data], f, names=names,\n                         delimiter='\\t')\n\n        else:\n            print(\"Could not output spectrum: {}\".format(spectrum))", "response": "Prints a file of the given spectrum to an ascii file with specified filepath."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a spectrum from the given column and table.", "response": "def show_image(self, image_id, table='images', column='image', overplot=False, cmap='hot', log=False):\n        \"\"\"\n        Plots a spectrum from the given column and table\n\n        Parameters\n        ----------\n        image_id: int\n            The id from the table of the images to plot.\n        overplot: bool\n            Overplot the image\n        table: str\n            The table from which the plot is being made\n        column: str\n            The column with IMAGE data type to plot\n        cmap: str\n            The colormap used for the data\n        \"\"\"\n        # TODO: Look into axes number formats. As is it will sometimes not display any numbers for wavelength\n\n        i = self.query(\"SELECT * FROM {} WHERE id={}\".format(table, image_id), fetch='one', fmt='dict')\n        if i:\n            try:\n                img = i['image'].data\n                \n                # Draw the axes and add the metadata\n                if not overplot:\n                    fig, ax = plt.subplots()\n                    plt.rc('text', usetex=False)\n                    plt.figtext(0.15, 0.88, '\\n'.join(['{}: {}'.format(k, v) for k, v in i.items() if k != column]), \\\n                                verticalalignment='top')\n                    ax.legend(loc=8, frameon=False)\n                else:\n                    ax = plt.gca()\n                    \n                # Plot the data\n                cmap = plt.get_cmap(cmap)\n                cmap.set_under(color='white')\n                vmin = 0.0000001\n                vmax = np.nanmax(img)\n                if log:\n                    from matplotlib.colors import LogNorm\n                    ax.imshow(img, cmap=cmap, norm=LogNorm(vmin=vmin,vmax=vmax), interpolation='none')\n                else:\n                    ax.imshow(img, cmap=cmap, interpolation='none', vmin=0.0000001)\n                X, Y = plt.xlim(), plt.ylim()\n                plt.ion()\n                \n            except IOError:\n                print(\"Could not plot image {}\".format(image_id))\n                plt.close()\n                \n        else:\n            print(\"No image {} in the {} table.\".format(image_id, table.upper()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_spectrum(self, spectrum_id, table='spectra', column='spectrum', overplot=False, color='b', norm=False):\n        # TODO: Look into axes number formats. As is it will sometimes not display any numbers for wavelength\n\n        i = self.query(\"SELECT * FROM {} WHERE id={}\".format(table, spectrum_id), fetch='one', fmt='dict')\n        if i:\n            try:\n                spec = scrub(i[column].data, units=False)\n                w, f = spec[:2]\n                try:\n                    e = spec[2]\n                except:\n                    e = ''\n\n                # Draw the axes and add the metadata\n                if not overplot:\n                    fig, ax = plt.subplots()\n                    plt.rc('text', usetex=False)\n                    ax.set_yscale('log', nonposy='clip')\n                    plt.figtext(0.15, 0.88, '\\n'.join(['{}: {}'.format(k, v) for k, v in i.items() if k != column]), \\\n                                verticalalignment='top')\n                    try:\n                        ax.set_xlabel(r'$\\lambda$ [{}]'.format(i.get('wavelength_units')))\n                        ax.set_ylabel(r'$F_\\lambda$ [{}]'.format(i.get('flux_units')))\n                    except:\n                        pass\n                    ax.legend(loc=8, frameon=False)\n                else:\n                    ax = plt.gca()\n\n                # Normalize the data\n                if norm:\n                    try:\n                        if isinstance(norm, bool): norm = (min(w), max(w))\n\n                        # Normalize to the specified window\n                        norm_mask = np.logical_and(w >= norm[0], w <= norm[1])\n                        C = 1. / np.trapz(f[norm_mask], x=w[norm_mask])\n                        f *= C\n                        try:\n                            e *= C\n                        except:\n                            pass\n\n                    except:\n                        print('Could not normalize.')\n\n                # Plot the data\n                ax.loglog(w, f, c=color, label='spec_id: {}'.format(i['id']))\n                X, Y = plt.xlim(), plt.ylim()\n                try:\n                    ax.fill_between(w, f - e, f + e, color=color, alpha=0.3), ax.set_xlim(X), ax.set_ylim(Y)\n                except:\n                    print('No uncertainty array for spectrum {}'.format(spectrum_id))\n                plt.ion()\n\n            except IOError:\n                print(\"Could not plot spectrum {}\".format(spectrum_id))\n                plt.close()\n\n        else:\n            print(\"No spectrum {} in the {} table.\".format(spectrum_id, table.upper()))", "response": "Plots a spectrum from the given column and table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a SQL query and return the result as a dictionary.", "response": "def query(self, SQL, params='', fmt='array', fetch='all', unpack=False, export='', \\\n              verbose=False, use_converters=True):\n        \"\"\"\n        Returns data satisfying the provided **SQL** script. Only SELECT or PRAGMA statements are allowed.\n        Results can be returned in a variety of formats.\n        For example, to extract the ra and dec of all entries in SOURCES in astropy.Table format one can write:\n            data = db.query('SELECT ra, dec FROM sources', fmt='table')\n\n        For more general SQL statements, see the modify() method.\n\n        Parameters\n        ----------\n        SQL: str\n            The SQL query to execute\n        params: sequence\n            Mimics the native parameter substitution of sqlite3\n        fmt: str\n            Returns the data as a dictionary, array, astropy.table, or pandas.Dataframe\n            given 'dict', 'array', 'table', or 'pandas'\n        fetch: str\n            String indicating whether to return **all** results or just **one**\n        unpack: bool\n            Returns the transpose of the data\n        export: str\n            The file path of the ascii file to which the data should be exported\n        verbose: bool\n            print the data as well\n        use_converters: bool\n            Apply converters to columns with custom data types\n\n        Returns\n        -------\n        result: (array,dict,table)\n            The result of the database query\n        \"\"\"\n        try:\n            # Restrict queries to SELECT and PRAGMA statements\n            if SQL.lower().startswith('select') or SQL.lower().startswith('pragma'):\n                \n                # Make the query explicit so that column and table names are preserved\n                # Then, get the data as a dictionary\n                origSQL = SQL\n                try:\n                    SQL, columns = self._explicit_query(SQL, use_converters=use_converters)\n                    dictionary = self.dict(SQL, params).fetchall()\n                except:\n                    print('WARNING: Unable to use converters')\n                    dictionary = self.dict(origSQL, params).fetchall()\n                    \n                if any(dictionary):\n                    \n                    # Fetch one\n                    if fetch == 'one':\n                        dictionary = [dictionary.pop(0)]\n                        \n                    # Make an Astropy table\n                    table = at.Table(dictionary)\n                    \n                    # Reorder the columns\n                    try:\n                        table = table[columns]\n                    except:\n                        pass\n                        \n                    # Make an array\n                    array = np.asarray(table)\n                    \n                    # Unpack the results if necessary (data types are not preserved)\n                    if unpack: \n                        array = np.array(zip(*array))\n                        \n                    # print on screen\n                    if verbose:\n                        pprint(table)\n                        \n                    # print the results to file\n                    if export:\n                        # If .vot or .xml, assume VOTable export with votools\n                        if export.lower().endswith('.xml') or export.lower().endswith('.vot'):\n                            votools.dict_tovot(dictionary, export)\n                            \n                        # Otherwise print as ascii\n                        else:\n                            ii.write(table, export, Writer=ii.FixedWidthTwoLine, fill_values=[('None', '-')])\n                            \n                    # Or return the results\n                    else:\n                        if fetch == 'one':\n                            dictionary, array = dictionary[0], array if unpack else np.array(list(array[0]))\n                            \n                        if fmt == 'table':\n                            return table\n                        elif fmt == 'dict':\n                            return dictionary\n                        elif fmt == 'pandas':\n                            return table.to_pandas()\n                        else:\n                            return array\n                            \n                else:\n                    return\n                    \n            else:\n                print(\n                'Queries must begin with a SELECT or PRAGMA statement. For database modifications use self.modify() method.')\n                \n        except IOError:\n            print('Could not execute: ' + SQL)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes a reverse lookup on the publications table and return every entry that matches that reference.", "response": "def references(self, criteria, publications='publications', column_name='publication_shortname', fetch=False):\n        \"\"\"\n        Do a reverse lookup on the **publications** table. Will return every entry that matches that reference.\n\n        Parameters\n        ----------\n        criteria: int or str\n            The id from the PUBLICATIONS table whose data across all tables is to be printed.\n        publications: str\n            Name of the publications table\n        column_name: str\n            Name of the reference column in other tables\n        fetch: bool\n            Return the results.\n\n        Returns\n        -------\n        data_tables: dict\n             Returns a dictionary of astropy tables with the table name as the keys.\n\n        \"\"\"\n\n        data_tables = dict()\n\n        # If an ID is provided but the column name is publication shortname, grab the shortname\n        if isinstance(criteria, type(1)) and column_name == 'publication_shortname':\n            t = self.query(\"SELECT * FROM {} WHERE id={}\".format(publications, criteria), fmt='table')\n            if len(t) > 0:\n                criteria = t['shortname'][0]\n            else:\n                print('No match found for {}'.format(criteria))\n                return\n\n        t = self.query(\"SELECT * FROM sqlite_master WHERE type='table'\", fmt='table')\n        all_tables = t['name'].tolist()\n        for table in ['sources'] + [t for t in all_tables if\n                                    t not in ['publications', 'sqlite_sequence', 'sources']]:\n\n            # Get the columns, pull out redundant ones, and query the table for this source's data\n            t = self.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n            columns = np.array(t['name'])\n            types = np.array(t['type'])\n\n            # Only get simple data types and exclude redundant ones for nicer printing\n            columns = columns[\n                ((types == 'REAL') | (types == 'INTEGER') | (types == 'TEXT')) & (columns != column_name)]\n\n            # Query the table\n            try:\n                data = self.query(\"SELECT {} FROM {} WHERE {}='{}'\".format(','.join(columns), table,\n                                                                         column_name, criteria), fmt='table')\n            except:\n                data = None\n\n            # If there's data for this table, save it\n            if data:\n                if fetch:\n                    data_tables[table] = self.query(\n                        \"SELECT {} FROM {} WHERE {}='{}'\".format(\n                            ','.join(columns), table, column_name, criteria), fmt='table', fetch=True)\n                else:\n                    data = data[[c.lower() for c in columns]]  # force lowercase since astropy.Tables have all lowercase\n                    pprint(data, title=table.upper())\n\n        if fetch: return data_tables"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the contents of the database into the tabledata directory as ascii files", "response": "def save(self, directory=None):\n        \"\"\"\n        Dump the entire contents of the database into the tabledata directory as ascii files\n        \"\"\"\n        from subprocess import call\n\n        # If user did not supply a new directory, use the one loaded (default: tabledata)\n        if isinstance(directory, type(None)):\n            directory = self.directory\n\n        # Create the .sql file is it doesn't exist, i.e. if the Database class called a .db file initially\n        if not os.path.isfile(self.sqlpath):\n            self.sqlpath = self.dbpath.replace('.db', '.sql')\n            os.system('touch {}'.format(self.sqlpath))\n\n        # # Write the data to the .sql file\n        # with open(self.sqlpath, 'w') as f:\n        #     for line in self.conn.iterdump():\n        #         f.write('%s\\n' % line)\n\n        # Alternatively...\n        # Write the schema\n        os.system(\"echo '.output {}\\n.schema' | sqlite3 {}\".format(self.sqlpath, self.dbpath))\n\n        # Write the table files to the tabledata directory\n        os.system(\"mkdir -p {}\".format(directory))\n        tables = self.query(\"select tbl_name from sqlite_master where type='table'\")['tbl_name']\n        tablepaths = [self.sqlpath]\n        for table in tables:\n            print('Generating {}...'.format(table))\n            tablepath = '{0}/{1}.sql'.format(directory, table)\n            tablepaths.append(tablepath)\n            with open(tablepath, 'w') as f:\n                for line in self.conn.iterdump():\n                    line = line.strip()\n                    if line.startswith('INSERT INTO \"{}\"'.format(table)):\n                        if sys.version_info.major == 2:\n                            f.write(u'{}\\n'.format(line).encode('utf-8'))\n                        else:\n                            f.write(u'{}\\n'.format(line))\n\n        print(\"Tables saved to directory {}/\".format(directory))\n        print(\"\"\"=======================================================================================\nYou can now run git to commit and push these changes, if needed.\nFor example, if on the master branch you can do the following:\n  git add {0} {1}/*.sql\n  git commit -m \"COMMIT MESSAGE HERE\"\n  git push origin master\nYou can then issue a pull request on GitHub to have these changes reviewed and accepted\n=======================================================================================\"\"\"\n              .format(self.sqlpath, directory))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the table schema", "response": "def schema(self, table):\n        \"\"\"\n        Print the table schema\n\n        Parameters\n        ----------\n        table: str\n          The table name\n\n        \"\"\"\n        try:\n            pprint(self.query(\"PRAGMA table_info({})\".format(table), fmt='table'))\n        except ValueError:\n            print('Table {} not found'.format(table))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to generate a snapshot of the database by version number.", "response": "def snapshot(self, name_db='export.db', version=1.0):\n        \"\"\"\n        Function to generate a snapshot of the database by version number.\n\n        Parameters\n        ----------\n        name_db: string\n            Name of the new database (Default: export.db)\n        version: float\n            Version number to export (Default: 1.0)\n        \"\"\"\n\n        # Check if file exists\n        if os.path.isfile(name_db):\n            import datetime\n            date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n            print(\"Renaming existing file {} to {}\".format(name_db, name_db.replace('.db', date + '.db')))\n            os.system(\"mv {} {}\".format(name_db, name_db.replace('.db', date + '.db')))\n\n        # Create a new database from existing database schema\n        t, = self.query(\"select sql from sqlite_master where type = 'table'\", unpack=True)\n        schema = ';\\n'.join(t) + ';'\n        os.system(\"sqlite3 {} '{}'\".format(name_db, schema))\n\n        # Attach database to newly created database\n        db = Database(name_db)\n        db.list('PRAGMA foreign_keys=OFF')  # Temporarily deactivate foreign keys for the snapshot\n        db.list(\"ATTACH DATABASE '{}' AS orig\".format(self.dbpath))\n\n        # For each table in database, insert records if they match version number\n        t = db.query(\"SELECT * FROM sqlite_master WHERE type='table'\", fmt='table')\n        all_tables = t['name'].tolist()\n        for table in [t for t in all_tables if t not in ['sqlite_sequence', 'changelog']]:\n            # Check if this is table with version column\n            metadata = db.query(\"PRAGMA table_info({})\".format(table), fmt='table')\n            columns, types, required, pk = [np.array(metadata[n]) for n in ['name', 'type', 'notnull', 'pk']]\n            print(table, columns)\n            if 'version' not in columns:\n                db.modify(\"INSERT INTO {0} SELECT * FROM orig.{0}\".format(table))\n            else:\n                db.modify(\"INSERT INTO {0} SELECT * FROM orig.{0} WHERE orig.{0}.version<={1}\".format(table, version))\n\n        # Detach original database\n        db.list('DETACH DATABASE orig')\n        db.list('PRAGMA foreign_keys=ON')\n        db.close(silent=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef table(self, table, columns, types, constraints='', pk='', new_table=False):\n        goodtogo = True\n\n        # Make sure there is an integer primary key, unique, not null 'id' column\n        # and the appropriate number of elements in each sequence\n        if columns[0] != 'id':\n            print(\"Column 1 must be called 'id'\")\n            goodtogo = False\n\n        if constraints:\n            if 'UNIQUE' not in constraints[0].upper() and 'NOT NULL' not in constraints[0].upper():\n                print(\"'id' column constraints must be 'UNIQUE NOT NULL'\")\n                goodtogo = False\n        else:\n            constraints = ['UNIQUE NOT NULL'] + ([''] * (len(columns) - 1))\n\n        # Set UNIQUE NOT NULL constraints for the primary keys, except ID which is already has them\n        if pk:\n            if not isinstance(pk, type(list())):\n                pk = list(pk)\n\n            for elem in pk:\n                if elem == 'id':\n                    continue\n                else:\n                    ind, = np.where(columns == elem)\n                    constraints[ind] = 'UNIQUE NOT NULL'\n        else:\n            pk = ['id']\n\n        if not len(columns) == len(types) == len(constraints):\n            print(\"Must provide equal length *columns ({}), *types ({}), and *constraints ({}) sequences.\" \\\n                  .format(len(columns), len(types), len(constraints)))\n            goodtogo = False\n\n        if goodtogo:\n            t = self.query(\"SELECT name FROM sqlite_master\", unpack=True, fmt='table')\n            tables = t['name'].tolist()\n\n            # If the table exists, modify the columns\n            if table in tables and not new_table:\n\n                # Rename the old table and create a new one\n                self.list(\"DROP TABLE IF EXISTS TempOldTable\")\n                self.list(\"ALTER TABLE {0} RENAME TO TempOldTable\".format(table))\n                create_txt = \"CREATE TABLE {0} (\\n\\t{1}\".format(table, ', \\n\\t'.join(\n                        ['{} {} {}'.format(c, t, r) for c, t, r in zip(columns, types, constraints)]))\n                create_txt += ', \\n\\tPRIMARY KEY({})\\n)'.format(', '.join([elem for elem in pk]))\n                # print(create_txt.replace(',', ',\\n'))\n                self.list(create_txt)\n\n                # Populate the new table and drop the old one\n                old_columns = [c for c in self.query(\"PRAGMA table_info(TempOldTable)\", unpack=True)[1] if c in columns]\n                self.list(\"INSERT INTO {0} ({1}) SELECT {1} FROM TempOldTable\".format(table, ','.join(old_columns)))\n\n                # Check for and add any foreign key constraints\n                t = self.query('PRAGMA foreign_key_list(TempOldTable)', fmt='table')\n                if not isinstance(t, type(None)):\n                    self.list(\"DROP TABLE TempOldTable\")\n                    self.add_foreign_key(table, t['table'].tolist(), t['from'].tolist(), t['to'].tolist())\n                else:\n                    self.list(\"DROP TABLE TempOldTable\")\n\n            # If the table does not exist and new_table is True, create it\n            elif table not in tables and new_table:\n                create_txt = \"CREATE TABLE {0} (\\n\\t{1}\".format(table, ', \\n\\t'.join(\n                    ['{} {} {}'.format(c, t, r) for c, t, r in zip(columns, types, constraints)]))\n                create_txt += ', \\n\\tPRIMARY KEY({})\\n)'.format(', '.join([elem for elem in pk]))\n                # print(create_txt.replace(',', ',\\n'))\n                print(create_txt)\n                self.list(create_txt)\n\n            # Otherwise the table to be modified doesn't exist or the new table to add already exists, so do nothing\n            else:\n                if new_table:\n                    print('Table {} already exists. Set *new_table=False to modify.'.format(table.upper()))\n                else:\n                    print('Table {} does not exist. Could not modify. Set *new_table=True to add a new table.'.format(\n                        table.upper()))\n\n        else:\n            print('The {} table has not been {}. Please make sure your table columns, \\\n             types, and constraints are formatted properly.'.format(table.upper(), \\\n                                                                    'created' if new_table else 'modified'))", "response": "Rearrange add or delete columns from database with desired ordered list of columns and corresponding data types and constraints."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(path):\n    url = '{}/{}/{}'.format(settings.VAULT_BASE_URL.rstrip('/'),\n                            settings.VAULT_BASE_SECRET_PATH.strip('/'),\n                            path.lstrip('/'))\n\n    headers = {'X-Vault-Token': settings.VAULT_ACCESS_TOKEN}\n    resp = requests.get(url, headers=headers)\n    if resp.ok:\n        return resp.json()['data']\n    else:\n        log.error('Failed VAULT GET request: %s %s', resp.status_code, resp.text)\n        raise Exception('Failed Vault GET request: {} {}'.format(resp.status_code, resp.text))", "response": "Read a secret from Vault REST endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all indexes in the sql database. rabaOnly returns only the indexes created by raba", "response": "def getIndexes(self, rabaOnly = True) :\n\t\t\"returns a list of all indexes in the sql database. rabaOnly returns only the indexes created by raba\"\n\t\tsql = \"SELECT * FROM sqlite_master WHERE type='index'\"\n\t\tcur = self.execute(sql)\n\t\tl = []\n\t\tfor n in cur :\n\t\t\tif rabaOnly :\n\t\t\t\tif n[1].lower().find('raba') == 0 :\n\t\t\t\t\tl.append(n)\n\t\t\telse :\n\t\t\t\tl.append(n)\n\t\treturn l"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndrop all indexes created by Raba", "response": "def flushIndexes(self) :\n\t\t\"drops all indexes created by Raba\"\n\t\tfor n in self.getIndexes(rabaOnly = True) :\n\t\t\tself.dropIndexByName(n[1])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an index for Raba Class.", "response": "def createIndex(self, table, fields, where = '', whereValues = []) :\n\t\t\"\"\"Creates indexes for Raba Class a fields resulting in significantly faster SELECTs but potentially slower UPADTES/INSERTS and a bigger DBs\n\t\tFields can be a list of fields for Multi-Column Indices, or siply the name of one single field.\n\t\tWith the where close you can create a partial index by adding conditions\n\t\t-----\n\t\tonly for sqlite 3.8.0+\n\t\twhere : optional ex: name = ? AND hair_color = ?\n\t\twhereValues : optional, ex: [\"britney\", 'black']\n\t\t\"\"\"\n\t\tversioTest = sq.sqlite_version_info[0] >= 3 and sq.sqlite_version_info[1] >= 8\n\t\tif len(where) > 0 and not versioTest :\n\t\t\t\t#raise FutureWarning(\"Partial joints (with the WHERE clause) where only implemented in sqlite 3.8.0+, your version is: %s. Sorry about that.\" % sq.sqlite_version)\n\t\t\t\tsys.stderr.write(\"WARNING: IGNORING THE \\\"WHERE\\\" CLAUSE in INDEX. Partial indexes where only implemented in sqlite 3.8.0+, your version is: %s. Sorry about that.\\n\" % sq.sqlite_version)\n\t\t\t\tindexTable = self.makeIndexTableName(table, fields)\n\t\telse :\n\t\t\tindexTable = self.makeIndexTableName(table, fields, where, whereValues)\n\n\t\tif type(fields) is types.ListType :\n\t\t\tsql = \"CREATE INDEX IF NOT EXISTS %s on %s(%s)\" %(indexTable, table, ', '.join(fields))\n\t\telse :\n\t\t\tsql = \"CREATE INDEX IF NOT EXISTS %s on %s(%s)\" %(indexTable, table, fields)\n\n\t\tif len(where) > 0 and versioTest:\n\t\t\tsql = \"%s WHERE %s;\" % (sql, where)\n\t\t\tself.execute(sql, whereValues)\n\t\telse :\n\t\t\tself.execute(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndrop an index created by RabaDb see createIndexes", "response": "def dropIndex(self, table, fields, where = '') :\n\t\t\"DROPs an index created by RabaDb see createIndexes()\"\n\t\tindexTable = self.makeIndexTableName(table, fields, where)\n\t\tself.dropIndexByName(indexTable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enableStats(self, bol, logQueries = False) :\n\t\t\"If bol == True, Raba will keep a count of every query time performed, logQueries == True it will also keep a record of all the queries \"\n\t\tself._enableStats = bol\n\t\tself._logQueries = logQueries\n\t\tif bol :\n\t\t\tself._enableStats = True\n\t\t\tself.eraseStats()\n\t\t\tself.startTime = time.time()", "response": "Raba will keep a count of every query time performed logQueries == True Raba will also keep a record of all the queries"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, sql, values = ()) :\n\t\t\"executes an sql command for you or appends it to the current transacations. returns a cursor\"\n\t\tsql = sql.strip()\n\t\tself._debugActions(sql, values)\n\t\tcur = self.connection.cursor()\n\t\tcur.execute(sql, values)\n\t\treturn cur", "response": "executes an sql command for you or appends it to the current transacations. returns a cursor"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to initiates a save session.", "response": "def initateSave(self, obj) :\n\t\t\"\"\"Tries to initiates a save sessions. Each object can only be saved once during a session.\n\t\tThe session begins when a raba object initates it and ends when this object and all it's dependencies have been saved\"\"\"\n\t\tif self.saveIniator != None :\n\t\t\treturn False\n\t\tself.saveIniator = obj\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef freeSave(self, obj) :\n\t\tif self.saveIniator is obj and not self.inTransaction :\n\t\t\tself.saveIniator = None\n\t\t\tself.savedObject = set()\n\t\t\tself.connection.commit()\n\t\t\treturn True\n\t\treturn False", "response": "Frees the save state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a save object. Returns False if the object has already been saved. True otherwise.", "response": "def registerSave(self, obj) :\n\t\t\"\"\"Each object can only be save donce during a session, returns False if the object has already been saved. True otherwise\"\"\"\n\t\tif obj._runtimeId in self.savedObject :\n\t\t\treturn False\n\n\t\tself.savedObject.add(obj._runtimeId)\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, table, where, values = ()) :\n\t\tsql = 'DELETE FROM %s WHERE %s' % (table, where)\n\t\treturn self.execute(sql, values)", "response": "Delete all rows from a table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkeeping track all loaded raba classes", "response": "def getLastRabaId(self, cls) :\n\t\t\"\"\"keep track all loaded raba classes\"\"\"\n\t\tself.loadedRabaClasses[cls.__name__] = cls\n\t\tsql = 'SELECT MAX(raba_id) from %s LIMIT 1' % (cls.__name__)\n\t\tcur = self.execute(sql)\n\t\tres = cur.fetchone()\n\t\ttry :\n\t\t\treturn int(res[0])+1\n\t\texcept TypeError:\n\t\t\treturn  0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a table and resturns the ursor returns None", "response": "def createTable(self, tableName, strFields) :\n\t\t'creates a table and resturns the ursor, if the table already exists returns None'\n\t\tif not self.tableExits(tableName) :\n\t\t\tsql = 'CREATE TABLE %s ( %s)' % (tableName, strFields)\n\t\t\tself.execute(sql)\n\t\t\tself.tables.add(tableName)\n\t\t\treturn True\n\t\treturn False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves columns from a RabaObj table. lstFieldsToKeep should not contain raba_id or json fileds", "response": "def dropColumnsFromRabaObjTable(self, name, lstFieldsToKeep) :\n\t\t\"Removes columns from a RabaObj table. lstFieldsToKeep should not contain raba_id or json fileds\"\n\t\tif len(lstFieldsToKeep) == 0 :\n\t\t\traise ValueError(\"There are no fields to keep\")\n\n\t\tcpy = name+'_copy'\n\t\tsqlFiledsStr = ', '.join(lstFieldsToKeep)\n\t\tself.createTable(cpy, 'raba_id INTEGER PRIMARY KEY AUTOINCREMENT, json, %s' % (sqlFiledsStr))\n\t\tsql = \"INSERT INTO %s SELECT %s FROM %s;\" % (cpy, 'raba_id, json, %s' % sqlFiledsStr, name)\n\t\tself.execute(sql)\n\t\tself.dropTable(name)\n\t\tself.renameTable(cpy, name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting user s likes.", "response": "def get_likes(self, offset=0, limit=50):\n        \"\"\" Get user's likes. \"\"\"\n        response = self.client.get(\n            self.client.USER_LIKES % (self.name, offset, limit))\n        return self._parse_response(response, strack)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget user s tracks.", "response": "def get_tracks(self, offset=0, limit=50):\n        \"\"\" Get user's tracks. \"\"\"\n        response = self.client.get(\n            self.client.USER_TRACKS % (self.name, offset, limit))\n        return self._parse_response(response, strack)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_playlists(self, offset=0, limit=50):\n        response = self.client.get(\n            self.client.USER_PLAYLISTS % (self.name, offset, limit))\n        return self._parse_response(response, splaylist)\n\n        return playlists", "response": "Get user s playlists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_external_feed_courses(self, url, course_id, header_match=None, verbosity=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - url\r\n        \"\"\"The url to the external rss or atom feed\"\"\"\r\n        data[\"url\"] = url\r\n\r\n        # OPTIONAL - header_match\r\n        \"\"\"If given, only feed entries that contain this string in their title will be imported\"\"\"\r\n        if header_match is not None:\r\n            data[\"header_match\"] = header_match\r\n\r\n        # OPTIONAL - verbosity\r\n        \"\"\"Defaults to \"full\"\"\"\"\r\n        if verbosity is not None:\r\n            self._validate_enum(verbosity, [\"full\", \"truncate\", \"link_only\"])\r\n            data[\"verbosity\"] = verbosity\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/external_feeds with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/external_feeds\".format(**path), data=data, params=params, single_item=True)", "response": "Create an external feed for the given course. Returns the new external feed entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_external_feed_groups(self, url, group_id, header_match=None, verbosity=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - url\r\n        \"\"\"The url to the external rss or atom feed\"\"\"\r\n        data[\"url\"] = url\r\n\r\n        # OPTIONAL - header_match\r\n        \"\"\"If given, only feed entries that contain this string in their title will be imported\"\"\"\r\n        if header_match is not None:\r\n            data[\"header_match\"] = header_match\r\n\r\n        # OPTIONAL - verbosity\r\n        \"\"\"Defaults to \"full\"\"\"\"\r\n        if verbosity is not None:\r\n            self._validate_enum(verbosity, [\"full\", \"truncate\", \"link_only\"])\r\n            data[\"verbosity\"] = verbosity\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/external_feeds with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/external_feeds\".format(**path), data=data, params=params, single_item=True)", "response": "Create an external feed for the course or group. Create a new external feed for the course or group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an external feed. Delete an external feed.", "response": "def delete_external_feed_courses(self, course_id, external_feed_id):\r\n        \"\"\"\r\n        Delete an external feed.\r\n\r\n        Deletes the external feed.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - external_feed_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"external_feed_id\"] = external_feed_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/courses/{course_id}/external_feeds/{external_feed_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/courses/{course_id}/external_feeds/{external_feed_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_external_feed_groups(self, group_id, external_feed_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - external_feed_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"external_feed_id\"] = external_feed_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/groups/{group_id}/external_feeds/{external_feed_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/groups/{group_id}/external_feeds/{external_feed_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Delete an external feed. Deletes the external feed with the given ID. Returns the updated entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_token_occurrences(cls, words):\n        counts = {}\n        for word in words:\n            if word in counts:\n                counts[word] += 1\n            else:\n                counts[word] = 1\n        return counts", "response": "Counts the number of occurrences of words in a given list of words."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_category_probability(self):\n        total_tally = 0.0\n        probs = {}\n        for category, bayes_category in \\\n                self.categories.get_categories().items():\n            count = bayes_category.get_tally()\n            total_tally += count\n            probs[category] = count\n\n        # Calculating the probability\n        for category, count in probs.items():\n            if total_tally > 0:\n                probs[category] = float(count)/float(total_tally)\n            else:\n                probs[category] = 0.0\n\n        for category, probability in probs.items():\n            self.probabilities[category] = {\n                # Probability that any given token is of this category\n                'prc': probability,\n                # Probability that any given token is not of this category\n                'prnc': sum(probs.values()) - probability\n            }", "response": "Calculates the probability that any given token is of this category and the total number of tallyed items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef train(self, category, text):\n        try:\n            bayes_category = self.categories.get_category(category)\n        except KeyError:\n            bayes_category = self.categories.add_category(category)\n\n        tokens = self.tokenizer(str(text))\n        occurrence_counts = self.count_token_occurrences(tokens)\n\n        for word, count in occurrence_counts.items():\n            bayes_category.train_token(word, count)\n\n        # Updating our per-category overall probabilities\n        self.calculate_category_probability()", "response": "Train a category with a sample of text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef classify(self, text):\n        score = self.score(text)\n        if not score:\n            return None\n        return sorted(score.items(), key=lambda v: v[1])[-1][0]", "response": "Return the winning category for a sample of text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the score of a sample of text with the number of occurances of the words in the text.", "response": "def score(self, text):\n        \"\"\"\n        Scores a sample of text\n\n        :param text: sample text to score\n        :type text: str\n        :return: dict of scores per category\n        :rtype: dict\n        \"\"\"\n        occurs = self.count_token_occurrences(self.tokenizer(text))\n        scores = {}\n        for category in self.categories.get_categories().keys():\n            scores[category] = 0\n\n        categories = self.categories.get_categories().items()\n\n        for word, count in occurs.items():\n            token_scores = {}\n\n            # Adding up individual token scores\n            for category, bayes_category in categories:\n                token_scores[category] = \\\n                    float(bayes_category.get_token_count(word))\n\n            # We use this to get token-in-category probabilities\n            token_tally = sum(token_scores.values())\n\n            # If this token isn't found anywhere its probability is 0\n            if token_tally == 0.0:\n                continue\n\n            # Calculating bayes probabiltity for this token\n            # http://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering\n            for category, token_score in token_scores.items():\n                # Bayes probability * the number of occurances of this token\n                scores[category] += count * \\\n                    self.calculate_bayesian_probability(\n                        category,\n                        token_score,\n                        token_tally\n                    )\n\n        # Removing empty categories from the results\n        final_scores = {}\n        for category, score in scores.items():\n            if score > 0:\n                final_scores[category] = score\n\n        return final_scores"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_bayesian_probability(self, cat, token_score, token_tally):\n        # P that any given token IS in this category\n        prc = self.probabilities[cat]['prc']\n        # P that any given token is NOT in this category\n        prnc = self.probabilities[cat]['prnc']\n        # P that this token is NOT of this category\n        prtnc = (token_tally - token_score) / token_tally\n        # P that this token IS of this category\n        prtc = token_score / token_tally\n\n        # Assembling the parts of the bayes equation\n        numerator = (prtc * prc)\n        denominator = (numerator + (prtnc * prnc))\n\n        # Returning the calculated bayes probability unless the denom. is 0\n        return numerator / denominator if denominator != 0.0 else 0.0", "response": "Calculates the bayesian probability for a given token and category."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tally(self, category):\n        try:\n            bayes_category = self.categories.get_category(category)\n        except KeyError:\n            return 0\n\n        return bayes_category.get_tally()", "response": "Gets the tally for a given category"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cache_location(self):\n        filename = self.cache_path if \\\n            self.cache_path[-1:] == '/' else \\\n            self.cache_path + '/'\n        filename += self.cache_file\n        return filename", "response": "Gets the location of the cache file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the current trained data to the cache.", "response": "def cache_persist(self):\n        \"\"\"\n        Saves the current trained data to the cache.\n        This is initiated by the program using this module\n        \"\"\"\n        filename = self.get_cache_location()\n        pickle.dump(self.categories, open(filename, 'wb'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cache_train(self):\n        filename = self.get_cache_location()\n\n        if not os.path.exists(filename):\n            return False\n\n        categories = pickle.load(open(filename, 'rb'))\n\n        assert isinstance(categories, BayesCategories), \\\n            \"Cache data is either corrupt or invalid\"\n\n        self.categories = categories\n\n        # Updating our per-category overall probabilities\n        self.calculate_category_probability()\n\n        return True", "response": "Loads the data for this classifier from a cache file and updates the categories attribute with the data from that file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_feature_type_rates(self, created=False):\n        if created:\n            for feature_type in FeatureType.objects.all():\n                FeatureTypeRate.objects.create(role=self, feature_type=feature_type, rate=0)", "response": "Create the feature type rates for all existing feature types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd this Handler s exported methods to an RPC Service instance.", "response": "def addToService(self, service, namespace=None, seperator='.'):\n        \"\"\"\n        Add this Handler's exported methods to an RPC Service instance.\n        \"\"\"\n        if namespace is None:\n            namespace = []\n        if isinstance(namespace, basestring):\n            namespace = [namespace]\n\n        for n, m in inspect.getmembers(self, inspect.ismethod):\n            if hasattr(m, 'export_rpc'):\n                try:\n                    name = seperator.join(namespace + m.export_rpc)\n                except TypeError:\n                    name = seperator.join(namespace + [m.export_rpc])\n                service.add(m, name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint a progress bar.", "response": "def print_progress_bar(text, done, total, width):\n    \"\"\"\n    Print progress bar.\n    \"\"\"\n    if total > 0:\n        n = int(float(width) * float(done) / float(total))\n        sys.stdout.write(\"\\r{0} [{1}{2}] ({3}/{4})\".format(text, '#' * n, ' ' * (width - n), done, total))\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_modules(config, relative_path, download_directory):\n    from collections import Iterable, namedtuple, defaultdict\n    from autocmake.extract import extract_list, to_d, to_l\n    from autocmake.parse_rst import parse_cmake_module\n\n    cleaned_config = defaultdict(lambda: [])\n\n    modules = []\n    Module = namedtuple('Module', 'path name')\n\n    num_sources = len(extract_list(config, 'source'))\n\n    print_progress_bar(text='- assembling modules:',\n                       done=0,\n                       total=num_sources,\n                       width=30)\n\n    if 'modules' in config:\n        i = 0\n        for t in config['modules']:\n            for k, v in t.items():\n\n                d = to_d(v)\n                for _k, _v in to_d(v).items():\n                    cleaned_config[_k] = flat_add(cleaned_config[_k], _v)\n\n                # fetch sources and parse them\n                if 'source' in d:\n                    for src in to_l(d['source']):\n                        i += 1\n\n                        # we download the file\n                        module_name = os.path.basename(src)\n                        if 'http' in src:\n                            path = download_directory\n                            name = 'autocmake_{0}'.format(module_name)\n                            dst = os.path.join(download_directory, 'autocmake_{0}'.format(module_name))\n                            fetch_url(src, dst)\n                            file_name = dst\n                            fetch_dst_directory = download_directory\n                        else:\n                            if os.path.exists(src):\n                                path = os.path.dirname(src)\n                                name = module_name\n                                file_name = src\n                                fetch_dst_directory = path\n                            else:\n                                sys.stderr.write(\"ERROR: {0} does not exist\\n\".format(src))\n                                sys.exit(-1)\n\n                        # we infer config from the module documentation\n                        # dictionary d overrides the configuration in the module documentation\n                        # this allows to override interpolation inside the module\n                        with open(file_name, 'r') as f:\n                            parsed_config = parse_cmake_module(f.read(), d)\n                            for _k2, _v2 in parsed_config.items():\n                                if _k2 not in to_d(v):\n                                    # we add to clean_config only if the entry does not exist\n                                    # in parent autocmake.yml already\n                                    # this allows to override\n                                    cleaned_config[_k2] = flat_add(cleaned_config[_k2], _v2)\n\n                        modules.append(Module(path=path, name=name))\n                        print_progress_bar(text='- assembling modules:',\n                                           done=i,\n                                           total=num_sources,\n                                           width=30)\n        print('')\n\n    return modules, cleaned_config", "response": "Assemble modules which will be included in CMakeLists. txt."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_url(src, dst):\n    # we do not use the nicer sys.version_info.major\n    # for compatibility with Python < 2.7\n    if sys.version_info[0] > 2:\n        import urllib.request\n\n        class URLopener(urllib.request.FancyURLopener):\n            def http_error_default(self, url, fp, errcode, errmsg, headers):\n                sys.stderr.write(\"ERROR: could not fetch {0}\\n\".format(url))\n                sys.exit(-1)\n    else:\n        import urllib\n\n        class URLopener(urllib.FancyURLopener):\n            def http_error_default(self, url, fp, errcode, errmsg, headers):\n                sys.stderr.write(\"ERROR: could not fetch {0}\\n\".format(url))\n                sys.exit(-1)\n\n    dirname = os.path.dirname(dst)\n    if dirname != '':\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n\n    opener = URLopener()\n    opener.retrieve(src, dst)", "response": "Fetch file from URL src and save it to dst."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_single_poll_submission(self, id, poll_id, poll_session_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - poll_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_id\"] = poll_id\r\n\r\n        # REQUIRED - PATH - poll_session_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_session_id\"] = poll_session_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"GET /api/v1/polls/{poll_id}/poll_sessions/{poll_session_id}/poll_submissions/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/polls/{poll_id}/poll_sessions/{poll_session_id}/poll_submissions/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Get a single poll submission. Returns the poll submission with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_single_poll_submission(self, poll_id, poll_session_id, poll_submissions_poll_choice_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - poll_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_id\"] = poll_id\r\n\r\n        # REQUIRED - PATH - poll_session_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"poll_session_id\"] = poll_session_id\r\n\r\n        # REQUIRED - poll_submissions[poll_choice_id]\r\n        \"\"\"The chosen poll choice for this submission.\"\"\"\r\n        data[\"poll_submissions[poll_choice_id]\"] = poll_submissions_poll_choice_id\r\n\r\n        self.logger.debug(\"POST /api/v1/polls/{poll_id}/poll_sessions/{poll_session_id}/poll_submissions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/polls/{poll_id}/poll_sessions/{poll_session_id}/poll_submissions\".format(**path), data=data, params=params, no_data=True)", "response": "Create a single poll submission. Create a new poll submission for this poll session."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodifies list view to driving listing from ES", "response": "def list(self, request, *args, **kwargs):\n        \"\"\"Modified list view to driving listing from ES\"\"\"\n        search_kwargs = {\"published\": False}\n\n        query_params = get_query_params(self.request)\n\n        for field_name in (\"status\"):\n            if field_name in query_params:\n                search_kwargs[field_name] = query_params.get(field_name)\n\n        if \"search\" in query_params:\n            search_kwargs[\"query\"] = query_params.get(\"search\")\n\n        # active/closed are semantics of the Poll model\n        # active is analagous to 'published' in Content\n        # closed is in relation to the end_date of a Poll\n        if \"active\" in query_params:\n            del search_kwargs[\"published\"]\n            search_kwargs[\"active\"] = True\n\n        if \"closed\" in query_params:\n            del search_kwargs[\"published\"]\n            search_kwargs[\"closed\"] = True\n\n        queryset = self.model.search_objects.search(**search_kwargs)\n\n        page = self.paginate_queryset(queryset)\n        if page is not None:\n            serializer = self.get_serializer(page, many=True)\n            return self.get_paginated_response(serializer.data)\n\n        serializer = self.get_serializer(queryset, many=True)\n        return Response(serializer.data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recode_wgsim_reads(\n        rnf_fastq_fo,\n        fai_fo,\n        genome_id,\n        wgsim_fastq_1_fn,\n        wgsim_fastq_2_fn=None,\n        number_of_read_tuples=10**9,\n    ):\n        \"\"\"Convert WgSim FASTQ files to RNF FASTQ files.\n\n\t\tArgs:\n\t\t\trnf_fastq_fo (file): File object of the target RNF file.\n\t\t\tfai_fo (file): File object of FAI index of the reference genome.\n\t\t\tgenome_id (int): RNF genome ID.\n\t\t\twgsim_fastq_1_fn (str): File name of the first WgSim FASTQ file.\n\t\t\twgsim_fastq_2_fn (str): File name of the second WgSim FASTQ file.\n\t\t\tnumber_of_read_tuples (int): Expected number of read tuples (to estimate widths).\n\t\t\"\"\"\n\n        wgsim_pattern = re.compile(\n            '@(.*)_([0-9]+)_([0-9]+)_([0-9]+):([0-9]+):([0-9]+)_([0-9]+):([0-9]+):([0-9]+)_([0-9a-f]+)/([12])'\n        )\n        \"\"\"\n\t\t\tWGSIM read name format\n\n\t\t1)  contig name (chromsome name)\n\t\t2)  start end 1 (one-based)\n\t\t3)  end end 2 (one-based)\n\t\t4)  number of errors end 1\n\t\t5)  number of substitutions end 1\n\t\t6)  number of indels end 1\n\t\t5)  number of errors end 2\n\t\t6)  number of substitutions end 2\n\t\t7)  number of indels end 2\n\t\t10) id\n\t\t11) pair\n\t\t\"\"\"\n\n        fai_index = rnftools.utils.FaIdx(fai_fo)\n        read_tuple_id_width = len(format(number_of_read_tuples, 'x'))\n\n        last_read_tuple_name = None\n\n        fq_creator = rnftools.rnfformat.FqCreator(\n            fastq_fo=rnf_fastq_fo,\n            read_tuple_id_width=read_tuple_id_width,\n            genome_id_width=2,\n            chr_id_width=fai_index.chr_id_width,\n            coor_width=fai_index.coor_width,\n            info_reads_in_tuple=True,\n            info_simulator=\"wgsim\",\n        )\n\n        reads_in_tuple = 2\n        if wgsim_fastq_2_fn is None:\n            reads_in_tuple = 1\n\n        i = 0\n        with open(wgsim_fastq_1_fn, \"r+\") as f_inp_1:\n            if reads_in_tuple == 2:\n                # todo: close file\n                f_inp_2 = open(wgsim_fastq_2_fn)\n\n            for line_a in f_inp_1:\n                lines = [line_a.strip()]\n                if reads_in_tuple == 2:\n                    lines.append(f_inp_2.readline().strip())\n\n                if i % 4 == 0:\n                    segments = []\n                    # bases=[]\n                    # qualities=[]\n\n                    m = wgsim_pattern.search(lines[0])\n                    if m is None:\n                        rnftools.utils.error(\n                            \"Read tuple '{}' was not generated by WgSim.\".format(lines[0][1:]), program=\"RNFtools\",\n                            subprogram=\"MIShmash\", exception=ValueError\n                        )\n\n                    contig_name = m.group(1)\n                    start_1 = int(m.group(2))\n                    end_2 = int(m.group(3))\n                    errors_1 = int(m.group(4))\n                    substitutions_1 = int(m.group(5))\n                    indels_1 = int(m.group(6))\n                    errors_2 = int(m.group(7))\n                    substitutions_2 = int(m.group(8))\n                    indels_2 = int(m.group(9))\n                    read_tuple_id_w = int(m.group(10), 16)\n                    pair = int(m.group(11))\n\n                    chr_id = fai_index.dict_chr_ids[contig_name] if fai_index.dict_chr_ids != {} else \"0\"\n\n                    if start_1 < end_2:\n                        direction_1 = \"F\"\n                        direction_2 = \"R\"\n                    else:\n                        direction_1 = \"R\"\n                        direction_2 = \"F\"\n\n                    segment1 = rnftools.rnfformat.Segment(\n                        genome_id=genome_id,\n                        chr_id=chr_id,\n                        direction=direction_1,\n                        left=start_1,\n                        right=0,\n                    )\n\n                    segment2 = rnftools.rnfformat.Segment(\n                        genome_id=genome_id,\n                        chr_id=chr_id,\n                        direction=direction_2,\n                        left=0,\n                        right=end_2,\n                    )\n\n                elif i % 4 == 1:\n                    bases = lines[0]\n                    if reads_in_tuple == 2:\n                        bases2 = lines[1]\n\n                elif i % 4 == 2:\n                    pass\n\n                elif i % 4 == 3:\n                    qualities = lines[0]\n                    if reads_in_tuple == 2:\n                        qualities2 = lines[1]\n\n                    if reads_in_tuple == 1:\n                        fq_creator.add_read(\n                            read_tuple_id=i // 4 + 1,\n                            bases=bases,\n                            qualities=qualities,\n                            segments=[segment1, segment2],\n                        )\n                    else:\n                        fq_creator.add_read(\n                            read_tuple_id=i // 4 + 1,\n                            bases=bases,\n                            qualities=qualities,\n                            segments=[segment1],\n                        )\n                        fq_creator.add_read(\n                            read_tuple_id=i // 4 + 1,\n                            bases=bases2,\n                            qualities=qualities2,\n                            segments=[segment2],\n                        )\n\n                i += 1\n\n        fq_creator.flush_read_tuple()", "response": "Convert WgSim FASTQ files to RNF FASTQ files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if requesting user has permission for the object in question", "response": "def has_object_permission(self, request, view, obj):\n        \"\"\"determines if requesting user has permissions for the object\n\n        :param request: WSGI request object - where we get the user from\n        :param view: the view calling for permission\n        :param obj: the object in question\n        :return: `bool`\n        \"\"\"\n        # Give permission if we're not protecting this method\n        if self.protected_methods and request.method not in self.protected_methods:\n            return True\n\n        user = getattr(request, \"user\", None)\n\n        if not user or user.is_anonymous():\n            return False\n\n        if self.require_staff and not user.is_staff:\n            return False\n\n        # if they have higher-level privileges we can return true right now\n        if user.has_perms(self.permissions):\n            return True\n\n        # no? ok maybe they're the author and have appropriate author permissions.\n        authors_field = getattr(obj, self.authors_field, None)\n\n        if not authors_field:\n            return False\n\n        if self.author_permissions and not user.has_perms(self.author_permissions):\n            return False\n\n        return user in authors_field.all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_permission(self, request, view):\n        has_permission = False\n        if request.method == \"GET\" \\\n                or request.method in [\"PUT\", \"POST\", \"DELETE\"] \\\n                and request.user and request.user.is_superuser:\n            has_permission = True\n        return has_permission", "response": "Check if user can access the resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind(self, app):\n        self.parent = app\n        app.add_subapp(self.prefix, self.app)", "response": "Bind API to Muffin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister handler to the API.", "response": "def register(self, *paths, methods=None, name=None):\n        \"\"\"Register handler to the API.\"\"\"\n        if isinstance(methods, str):\n            methods = [methods]\n\n        def wrapper(handler):\n\n            if isinstance(handler, (FunctionType, MethodType)):\n                handler = RESTHandler.from_view(handler, *(methods or ['GET']))\n\n            if handler.name in self.handlers:\n                raise muffin.MuffinException('Handler is already registered: %s' % handler.name)\n\n            self.handlers[tuple(paths or [\"/{0}/{{{0}}}\".format(handler.name)])] = handler\n\n            handler.bind(self.app, *paths, methods=methods, name=name or handler.name)\n            return handler\n\n        # Support for @app.register(func)\n        if len(paths) == 1 and callable(paths[0]):\n            view = paths[0]\n            paths = []\n            return wrapper(view)\n\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_pzone(**kwargs):\n\n    pzone = PZone.objects.get(**kwargs)\n\n    # get the data and loop through operate_on, applying them if necessary\n    when = timezone.now()\n    data = pzone.data\n    for operation in pzone.operations.filter(when__lte=when, applied=False):\n        data = operation.apply(data)\n        operation.applied = True\n        operation.save()\n    pzone.data = data\n\n    # create a history entry\n    pzone.history.create(data=pzone.data)\n\n    # save modified pzone, making transactions permanent\n    pzone.save()", "response": "Update the data of a pzone in the DB"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo something with operate_on.", "response": "def operate_on(self, when=None, apply=False, **kwargs):\n        \"\"\"Do something with operate_on. If apply is True, all transactions will\n        be applied and saved via celery task.\"\"\"\n\n        # get pzone based on id\n        pzone = self.get(**kwargs)\n\n        # cache the current time\n        now = timezone.now()\n\n        # ensure we have some value for when\n        if when is None:\n            when = now\n\n        if when < now:\n            histories = pzone.history.filter(date__lte=when)\n            if histories.exists():\n                # we have some history, use its data\n                pzone.data = histories[0].data\n\n        else:\n            # only apply operations if cache is expired or empty, or we're looking at the future\n            data = pzone.data\n\n            # Get the cached time of the next expiration\n            next_operation_time = cache.get('pzone-operation-expiry-' + pzone.name)\n            if next_operation_time is None or next_operation_time < when:\n\n                # start applying operations\n                pending_operations = pzone.operations.filter(when__lte=when, applied=False)\n                for operation in pending_operations:\n                    data = operation.apply(data)\n\n                # reassign data\n                pzone.data = data\n\n                if apply and pending_operations.exists():\n                    # there are operations to apply, do celery task\n                    update_pzone.delay(**kwargs)\n\n        # return pzone, modified if apply was True\n        return pzone"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npreview transactions but don t actually save changes to list.", "response": "def preview(self, when=timezone.now(), **kwargs):\n        \"\"\"Preview transactions, but don't actually save changes to list.\"\"\"\n\n        return self.operate_on(when=when, apply=False, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget direct download link with soudcloud s redirect system.", "response": "def get_download_link(self):\n        \"\"\" Get direct download link with soudcloud's redirect system. \"\"\"\n        url = None\n        if not self.get(\"downloadable\"):\n            try:\n                url = self.client.get_location(\n                    self.client.STREAM_URL % self.get(\"id\"))\n            except serror as e:\n                print(e)\n\n        if not url:\n            try:\n                url = self.client.get_location(\n                    self.client.DOWNLOAD_URL % self.get(\"id\"))\n            except serror as e:\n                print(e)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_file_extension(self, filepath):\n        mtype = magic.from_file(filepath, mime=True)\n        if type(mtype) == bytes:\n            mtype = mtype.decode(\"utf-8\")\n\n        if mtype == \"audio/mpeg\":\n            ext = \".mp3\"\n        elif mtype == \"audio/x-wav\":\n            ext = \".wav\"\n        else:\n            ext = \".\" + self.get(\"original-format\")\n        return ext", "response": "This method returns the file extension."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gen_localdir(self, localdir):\n        directory = \"{0}/{1}/\".format(localdir, self.get(\"username\"))\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        return directory", "response": "Generate local directory where track will be saved."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a track exists in local directory.", "response": "def track_exists(self, localdir):\n        \"\"\" Check if track exists in local directory. \"\"\"\n        path = glob.glob(self.gen_localdir(localdir) +\n                         self.gen_filename() + \"*\")\n        if len(path) > 0 and os.path.getsize(path[0]) > 0:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_ignored_tracks(self, localdir):\n        ignore_file = \"%s/.ignore\" % localdir\n        list = []\n        if os.path.exists(ignore_file):\n            f = open(ignore_file)\n            ignored = f.readlines()\n            f.close()\n\n            for i in ignored:\n                list.append(\"%s/%s\" % (localdir, i.rstrip()))\n\n        return list", "response": "Get the list of ignored tracks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload a track in local directory.", "response": "def download(self, localdir, max_retry):\n        \"\"\" Download a track in local directory. \"\"\"\n        local_file = self.gen_localdir(localdir) + self.gen_filename()\n\n        if self.track_exists(localdir):\n            print(\"Track {0} already downloaded, skipping!\".format(\n                self.get(\"id\")))\n            return False\n\n        if local_file in self.get_ignored_tracks(localdir):\n            print(\"\\033[93mTrack {0} ignored, skipping!!\\033[0m\".format(\n                self.get(\"id\")))\n            return False\n\n        dlurl = self.get_download_link()\n\n        if not dlurl:\n            raise serror(\"Can't download track_id:%d|%s\" % (\n                self.get(\"id\"),\n                self.get(\"title\")))\n\n        retry = max_retry\n        print(\"\\nDownloading %s (%d)..\" % (self.get(\"title\"), self.get(\"id\")))\n\n        while True:\n            try:\n                urllib.request.urlretrieve(dlurl, local_file,\n                                           self._progress_hook)\n                break\n            except Exception as e:\n                if os.path.isfile(local_file):\n                    os.unlink(local_file)\n                retry -= 1\n\n                if retry < 0:\n                    raise serror(\"Can't download track-id %s, max retry \"\n                                 \"reached (%d). Error occured: %s\" % (\n                                     self.get(\"id\"), max_retry, type(e)))\n                else:\n                    print(\"\\033[93mError occured for track-id %s (%s). \"\n                          \"Retrying.. (%d/%d) \\033[0m\" % (\n                              self.get(\"id\"),\n                              type(e),\n                              max_retry - retry,\n                              max_retry))\n            except KeyboardInterrupt:\n                if os.path.isfile(local_file):\n                    os.unlink(local_file)\n                raise serror(\"KeyBoard Interrupt: Incomplete file removed.\")\n\n        self.filepath = local_file + self.get_file_extension(local_file)\n        os.rename(local_file, self.filepath)\n        print(\"Downloaded => %s\" % self.filepath)\n\n        self.downloaded = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses ID3 Tags for mp3 files.", "response": "def process_tags(self, tag=None):\n        \"\"\"Process ID3 Tags for mp3 files.\"\"\"\n        if self.downloaded is False:\n            raise serror(\"Track not downloaded, can't process tags..\")\n        filetype = magic.from_file(self.filepath, mime=True)\n        if filetype != \"audio/mpeg\":\n            raise serror(\"Cannot process tags for file type %s.\" % filetype)\n\n        print(\"Processing tags for %s..\" % self.filepath)\n        if tag is None:\n            tag = stag()\n        tag.load_id3(self)\n        tag.write_id3(self.filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert file in mp3 format.", "response": "def convert(self):\n        \"\"\"Convert file in mp3 format.\"\"\"\n        if self.downloaded is False:\n            raise serror(\"Track not downloaded, can't convert file..\")\n        filetype = magic.from_file(self.filepath, mime=True)\n        if filetype == \"audio/mpeg\":\n            print(\"File is already in mp3 format. Skipping convert.\")\n            return False\n\n        rootpath = os.path.dirname(os.path.dirname(self.filepath))\n        backupdir = rootpath + \"/backups/\" + self.get(\"username\")\n        if not os.path.exists(backupdir):\n            os.makedirs(backupdir)\n\n        backupfile = \"%s/%s%s\" % (\n            backupdir,\n            self.gen_filename(),\n            self.get_file_extension(self.filepath))\n        newfile = \"%s.mp3\" % self.filename_without_extension()\n\n        os.rename(self.filepath, backupfile)\n        self.filepath = newfile\n\n        print(\"Converting to %s..\" % newfile)\n        song = AudioSegment.from_file(backupfile)\n        return song.export(newfile, format=\"mp3\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload track s artwork and return file path.", "response": "def download_artwork(self, localdir, max_retry):\n        \"\"\"\n        Download track's artwork and return file path.\n        Artwork's path is saved in track's metadata as 'artwork-path' key.\n        \"\"\"\n        if self.get(\"artwork-url\") == \"None\":\n            self.metadata[\"artwork-path\"] = None\n            return None\n\n        artwork_dir = localdir + \"/artworks\"\n        if not os.path.isdir(artwork_dir):\n            if os.path.isfile(artwork_dir):\n                os.unlink(artwork_dir)\n            os.mkdir(artwork_dir)\n\n        artwork_filepath = artwork_dir + \"/\" + self.gen_artwork_filename()\n\n        retry = max_retry\n        while True:\n            try:\n                res = urllib.request.urlopen(self.get(\"artwork-url\"))\n                with open(artwork_filepath, \"wb\") as file:\n                    file.write(res.read())\n                break\n            except Exception as e:\n                retry -= 1\n                if retry < 0:\n                    print(serror(\"Can't download track's artwork, max retry \"\n                                 \"reached (%d). Error occured: %s\" % (\n                                     max_retry, type(e))))\n                    return False\n                else:\n                    print(\"\\033[93mTrack's artwork download failed (%s). \"\n                          \"Retrying.. (%d/%d) \\033[0m\" % (\n                              type(e),\n                              max_retry - retry,\n                              max_retry))\n\n        self.metadata[\"artwork-path\"] = artwork_filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprogresses hook for urlretrieve.", "response": "def _progress_hook(self, blocknum, blocksize, totalsize):\n        \"\"\" Progress hook for urlretrieve. \"\"\"\n        read = blocknum * blocksize\n        if totalsize > 0:\n            percent = read * 1e2 / totalsize\n            s = \"\\r%d%% %*d / %d\" % (\n                percent, len(str(totalsize)), read, totalsize)\n            sys.stdout.write(s)\n\n            if read >= totalsize:\n                sys.stdout.write(\"\\n\")\n        else:\n            sys.stdout.write(\"read %d\\n\" % read)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_id3(self, track):\n        if not isinstance(track, strack):\n            raise TypeError('strack object required')\n\n        timestamp = calendar.timegm(parse(track.get(\"created-at\")).timetuple())\n\n        self.mapper[TIT1] = TIT1(text=track.get(\"description\"))\n        self.mapper[TIT2] = TIT2(text=track.get(\"title\"))\n        self.mapper[TIT3] = TIT3(text=track.get(\"tags-list\"))\n        self.mapper[TDOR] = TDOR(text=str(timestamp))\n        self.mapper[TLEN] = TLEN(text=track.get(\"duration\"))\n        self.mapper[TOFN] = TOFN(text=track.get(\"permalink\"))\n        self.mapper[TCON] = TCON(text=track.get(\"genre\"))\n        self.mapper[TCOP] = TCOP(text=track.get(\"license\"))\n        self.mapper[WOAS] = WOAS(url=track.get(\"permalink-url\"))\n        self.mapper[WOAF] = WOAF(url=track.get(\"uri\"))\n        self.mapper[TPUB] = TPUB(text=track.get(\"username\"))\n        self.mapper[WOAR] = WOAR(url=track.get(\"user-url\"))\n        self.mapper[TPE1] = TPE1(text=track.get(\"artist\"))\n        self.mapper[TALB] = TALB(text=\"%s Soundcloud tracks\"\n                                 % track.get(\"artist\"))\n\n        if track.get(\"artwork-path\") is not None:\n            self.mapper[APIC] = APIC(value=track.get(\"artwork-path\"))", "response": "Load id3 tags from strack metadata"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite id3 tags to file.", "response": "def write_id3(self, filename):\n        \"\"\" Write id3 tags \"\"\"\n        if not os.path.exists(filename):\n            raise ValueError(\"File doesn't exists.\")\n\n        self.mapper.write(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _atlas_from_images(images):\n\timport pyglet\n\twidest = max(img.width for img in images)\n\theight = sum(img.height for img in images)\n\n\tatlas = pyglet.image.atlas.TextureAtlas(\n\t\twidth=_nearest_pow2(widest), height=_nearest_pow2(height))\n\ttextures = [atlas.add(image) for image in images]\n\treturn atlas, textures", "response": "Create a pyglet texture atlas from a sequence of images.\nReturn a tuple of atlas and textures"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a point texture.", "response": "def create_point_texture(size, feather=0):\n\t\"\"\"Create and load a circular grayscale image centered in a square texture\n\twith a width and height of size. The radius of the circle is size / 2.\n\tSince size is used as the texture width and height, it should typically\n\tbe a power of two.\n\n\tFeather determines the softness of the edge of the circle. The default,\n\tzero, creates a hard edged circle. Larger feather values create softer\n\tedges for blending. The point at the center of the texture is always\n\twhite.\n\n\tReturn the OpenGL texture name (id) for the resulting texture. This\n\tvalue can be passed directy to a texturizer or glBindTexture\n\t\"\"\"\n\tfrom pyglet import gl\n\n\tassert feather >= 0, 'Expected feather value >= 0'\n\tcoords = range(size)\n\ttexel = (gl.GLfloat * size**2)()\n\tr = size / 2.0\n\tc = feather + 1.0\n\n\tfor y in coords:\n\t\tcol = y * size\n\t\tfor x in coords:\n\t\t\td = math.sqrt((x - r)**2 + (y - r)**2)\n\t\t\tif d < r and (1.0 - 1.0 / (d / r - 1.0)) < 100:\n\t\t\t\ttexel[x + col] = c**2 / c**(1.0 - 1.0 / (d / r - 1.0))\n\t\t\telse:\n\t\t\t\ttexel[x + col] = 0\n\tid = gl.GLuint()\n\tgl.glGenTextures(1, ctypes.byref(id))\n\tgl.glBindTexture(gl.GL_TEXTURE_2D, id.value)\n\tgl.glPixelStorei(gl.GL_UNPACK_ALIGNMENT, 4)\n\tgl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_LUMINANCE, size, size, 0,\n\t\tgl.GL_LUMINANCE, gl.GL_FLOAT, ctypes.byref(texel))\n\tgl.glFlush()\n\treturn id.value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a SpriteTexturizer from a sequence of Pyglet images.", "response": "def from_images(cls, images, weights=None, filter=None, wrap=None,\n\t\taspect_adjust_width=False, aspect_adjust_height=False):\n\t\t\"\"\"Create a SpriteTexturizer from a sequence of Pyglet images.\n\n\t\tNote all the images must be able to fit into a single OpenGL texture, so\n\t\ttheir combined size should typically be less than 1024x1024\n\t\t\"\"\"\n\t\timport pyglet\n\t\tatlas, textures = _atlas_from_images(images)\n\t\ttexturizer = cls(\n\t\t\tatlas.texture.id, [tex.tex_coords for tex in textures],\n\t\t\tweights, filter or pyglet.gl.GL_LINEAR, wrap or pyglet.gl.GL_CLAMP,\n\t\t\taspect_adjust_width, aspect_adjust_height)\n\t\ttexturizer.atlas = atlas\n\t\ttexturizer.textures = textures\n\t\treturn texturizer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_querystring(querystring):\n    if querystring is None or len(querystring) == 0:\n        return {}\n\n    qs_dict = parse.parse_qs(querystring, keep_blank_values=True)\n    for key in qs_dict:\n        if len(qs_dict[key]) != 1:\n            continue\n        qs_dict[key] = qs_dict[key][0]\n        if qs_dict[key] == '':\n            qs_dict[key] = True\n\n    return dict((key, qs_dict[key]) for key in qs_dict if len(key) != 0)", "response": "Parse a querystring into a dict of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the object to a dictionary.", "response": "def to_dict(self):\n        \"\"\"\n        to_dict will clean all protected and private properties\n        \"\"\"\n        return dict(\n            (k, self.__dict__[k]) for k in self.__dict__ if k.find(\"_\") != 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmatch input route and return new Message instance with parsed content", "response": "def match(self, route):\n        \"\"\"\n        Match input route and return new Message instance\n        with parsed content\n        \"\"\"\n        _resource = trim_resource(self.resource)\n        self.method = self.method.lower()\n        resource_match = route.resource_regex.search(_resource)\n        if resource_match is None:\n            return None\n\n        # build params and querystring\n        params = resource_match.groupdict()\n        querystring = params.pop(\"querystring\", \"\")\n        setattr(self, \"param\", params)\n        setattr(self, \"query\", parse_querystring(querystring))\n\n        return copy.deepcopy(self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_response(self, sign, code=200, data=None):\n        msg = copy.deepcopy(self)\n        msg.data = data\n\n        setattr(msg, 'code', code)\n        for _ in [\"query\", \"param\", \"tunnel\"]:\n            if not hasattr(msg, _):\n                continue\n            delattr(msg, _)\n\n        if hasattr(msg, 'sign') and isinstance(msg.sign, list):\n            msg.sign.append(sign)\n        else:\n            msg.sign = [sign]\n\n        msg._type = Message.get_message_type(msg.__dict__)\n\n        return msg", "response": "transform message to response message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_event(self):\n        msg = copy.deepcopy(self)\n        for _ in [\"id\", \"sign\", \"tunnel\", \"query\", \"param\"]:\n            if not hasattr(msg, _):\n                continue\n            delattr(msg, _)\n\n        msg._type = Message.get_message_type(msg.__dict__)\n\n        return msg", "response": "converts the message to an event"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_message_type(message):\n        for msg_type in MessageType.FIELDS:\n            if Message.is_type(msg_type, message):\n                return msg_type\n\n        return MessageType.UNKNOWN", "response": "Return the message s type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_type(msg_type, msg):\n        for prop in MessageType.FIELDS[msg_type][\"must\"]:\n            if msg.get(prop, False) is False:\n                return False\n        for prop in MessageType.FIELDS[msg_type][\"prohibit\"]:\n            if msg.get(prop, False) is not False:\n                return False\n\n        return True", "response": "Return whether the message s type is or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, f, name=None, types=None, required=None):\n        if name is None:\n            fname = f.__name__  # Register the function using its own name.\n        else:\n            fname = name\n\n        self.method_data[fname] = {'method': f}\n\n        if types is not None:\n            self.method_data[fname]['types'] = types\n\n            if required is not None:\n                self.method_data[fname]['required'] = required", "response": "Adds a new method to the jsonrpc service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stopServing(self, exception=None):\n        if exception is None:\n            exception = ServiceUnavailableError\n        self.serve_exception = exception\n        if self.pending:\n            d = self.out_of_service_deferred = defer.Deferred()\n            return d\n        return defer.succeed(None)", "response": "Stop serving the current set of items from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall jsonrpc service s method and returns its return value in a JSON string", "response": "def call(self, jsondata):\n        \"\"\"\n        Calls jsonrpc service's method and returns its return value in a JSON\n        string or None if there is none.\n\n        Arguments:\n        jsondata -- remote method call in jsonrpc format\n        \"\"\"\n        result = yield self.call_py(jsondata)\n        if result is None:\n            defer.returnValue(None)\n        else:\n            defer.returnValue(json.dumps(result))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call_py(self, jsondata):\n        try:\n            try:\n                rdata = json.loads(jsondata)\n            except ValueError:\n                raise ParseError\n        except ParseError, e:\n            defer.returnValue(self._get_err(e))\n            return\n\n        # set some default values for error handling\n        request = self._get_default_vals()\n\n        try:\n            if isinstance(rdata, dict) and rdata:\n                # It's a single request.\n                self._fill_request(request, rdata)\n                respond = yield self._handle_request(request)\n\n                # Don't respond to notifications\n                if respond is None:\n                    defer.returnValue(None)\n                else:\n                    defer.returnValue(respond)\n                return\n            elif isinstance(rdata, list) and rdata:\n                # It's a batch.\n                requests = []\n                responds = []\n\n                for rdata_ in rdata:\n                    # set some default values for error handling\n                    request_ = self._get_default_vals()\n                    try:\n                        self._fill_request(request_, rdata_)\n                    except InvalidRequestError, e:\n                        err = self._get_err(e, request_['id'])\n                        if err:\n                            responds.append(err)\n                        continue\n                    except JSONRPCError, e:\n                        err = self._get_err(e, request_['id'])\n                        if err:\n                            responds.append(err)\n                        continue\n\n                    requests.append(request_)\n\n                for request_ in requests:\n                    try:\n                        # TODO: We should use a deferred list so requests\n                        #       are processed in parallel\n                        respond = yield self._handle_request(request_)\n                    except JSONRPCError, e:\n                        respond = self._get_err(e,\n                                                request_['id'],\n                                                request_['jsonrpc'])\n\n                    # Don't respond to notifications\n                    if respond is not None:\n                        responds.append(respond)\n\n                if responds:\n                    defer.returnValue(responds)\n                    return\n\n                # Nothing to respond.\n                defer.returnValue(None)\n                return\n            else:\n                # empty dict, list or wrong type\n                raise InvalidRequestError\n        except InvalidRequestError, e:\n            defer.returnValue(self._get_err(e, request['id']))\n        except JSONRPCError, e:\n            defer.returnValue(self._get_err(e,\n                                            request['id'],\n                                            request['jsonrpc']))", "response": "Calls jsonrpc service s method and returns its return value in python\n        object format or None if there is none."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn jsonrpc error message.", "response": "def _get_err(self, e, id=None, jsonrpc=DEFAULT_JSONRPC):\n        \"\"\"\n        Returns jsonrpc error message.\n        \"\"\"\n        # Do not respond to notifications when the request is valid.\n        if not id \\\n                and not isinstance(e, ParseError) \\\n                and not isinstance(e, InvalidRequestError):\n            return None\n\n        respond = {'id': id}\n\n        if isinstance(jsonrpc, int):\n            # v1.0 requires result to exist always.\n            # No error codes are defined in v1.0 so only use the message.\n            if jsonrpc == 10:\n                respond['result'] = None\n                respond['error'] = e.dumps()['message']\n            else:\n                self._fill_ver(jsonrpc, respond)\n                respond['error'] = e.dumps()\n        else:\n            respond['jsonrpc'] = jsonrpc\n            respond['error'] = e.dumps()\n\n        return respond"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _man_args(self, f):\n        argcount = f.func_code.co_argcount\n\n        # account for \"self\" getting passed to class instance methods\n        if isinstance(f, types.MethodType):\n            argcount -= 1\n\n        if f.func_defaults is None:\n            return argcount\n\n        return argcount - len(f.func_defaults)", "response": "Returns the number of mandatory arguments required by given function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _max_args(self, f):\n        if f.func_defaults is None:\n            return f.func_code.co_argcount\n\n        return f.func_code.co_argcount + len(f.func_defaults)", "response": "Returns the maximum number of arguments accepted by given function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn jsonrpc request s id value or None if there is none.", "response": "def _get_id(self, rdata):\n        \"\"\"\n        Returns jsonrpc request's id value or None if there is none.\n\n        InvalidRequestError will be raised if the id value has invalid type.\n        \"\"\"\n        if 'id' in rdata:\n            if isinstance(rdata['id'], basestring) or \\\n                    isinstance(rdata['id'], int) or \\\n                    isinstance(rdata['id'], long) or \\\n                    isinstance(rdata['id'], float) or \\\n                    rdata['id'] is None:\n                return rdata['id']\n            else:\n                # invalid type\n                raise InvalidRequestError\n        else:\n            # It's a notification.\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_method(self, rdata):\n        if 'method' in rdata:\n            if not isinstance(rdata['method'], basestring):\n                raise InvalidRequestError\n        else:\n            raise InvalidRequestError\n\n        if rdata['method'] not in self.method_data.keys():\n            raise MethodNotFoundError\n\n        return rdata['method']", "response": "Returns jsonrpc request s method value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of jsonrpc request s method parameters.", "response": "def _get_params(self, rdata):\n        \"\"\"\n        Returns a list of jsonrpc request's method parameters.\n        \"\"\"\n        if 'params' in rdata:\n            if isinstance(rdata['params'], dict) \\\n                    or isinstance(rdata['params'], list) \\\n                    or rdata['params'] is None:\n                return rdata['params']\n            else:\n                # wrong type\n                raise InvalidRequestError\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfilling request with data from the jsonrpc call.", "response": "def _fill_request(self, request, rdata):\n        \"\"\"Fills request with data from the jsonrpc call.\"\"\"\n        if not isinstance(rdata, dict):\n            raise InvalidRequestError\n\n        request['jsonrpc'] = self._get_jsonrpc(rdata)\n        request['id'] = self._get_id(rdata)\n        request['method'] = self._get_method(rdata)\n        request['params'] = self._get_params(rdata)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call_method(self, request):\n        method = self.method_data[request['method']]['method']\n        params = request['params']\n        result = None\n        try:\n            if isinstance(params, list):\n                # Does it have enough arguments?\n                if len(params) < self._man_args(method):\n                    raise InvalidParamsError('not enough arguments')\n                # Does it have too many arguments?\n                if not self._vargs(method) \\\n                        and len(params) > self._max_args(method):\n                    raise InvalidParamsError('too many arguments')\n\n                result = yield defer.maybeDeferred(method, *params)\n            elif isinstance(params, dict):\n                # Do not accept keyword arguments if the jsonrpc version is\n                # not >=1.1.\n                if request['jsonrpc'] < 11:\n                    raise KeywordError\n\n                result = yield defer.maybeDeferred(method, **params)\n            else:  # No params\n                result = yield defer.maybeDeferred(method)\n        except JSONRPCError:\n            raise\n        except Exception:\n            # Exception was raised inside the method.\n            log.msg('Exception raised while invoking RPC method \"{}\".'.format(\n                    request['method']))\n            log.err()\n            raise ServerError\n\n        defer.returnValue(result)", "response": "Calls given method with given params and returns it value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle given request and returns its response.", "response": "def _handle_request(self, request):\n        \"\"\"Handles given request and returns its response.\"\"\"\n        if 'types' in self.method_data[request['method']]:\n            self._validate_params_types(request['method'], request['params'])\n\n        if self.serve_exception:\n            raise self.serve_exception()\n        d = self._call_method(request)\n        self.pending.add(d)\n        if self.timeout:\n            timeout_deferred = self.reactor.callLater(self.timeout, d.cancel)\n\n            def completed(result):\n                if timeout_deferred.active():\n                    # cancel the timeout_deferred if it has not been fired yet\n                    # this is to prevent d's deferred chain from firing twice\n                    # (and raising an exception).\n                    timeout_deferred.cancel()\n                return result\n            d.addBoth(completed)\n        try:\n            result = yield d\n        except defer.CancelledError:\n            # The request was cancelled due to a timeout or by cancelPending\n            # having been called. We return a TimeoutError to the client.\n            self._remove_pending(d)\n            raise TimeoutError()\n        except Exception as e:\n            self._remove_pending(d)\n            raise e\n        self._remove_pending(d)\n        # Do not respond to notifications.\n        if request['id'] is None:\n            defer.returnValue(None)\n\n        respond = {}\n        self._fill_ver(request['jsonrpc'], respond)\n        respond['result'] = result\n        respond['id'] = request['id']\n\n        defer.returnValue(respond)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate request s parameter types.", "response": "def _validate_params_types(self, method, params):\n        \"\"\"\n        Validates request's parameter types.\n        \"\"\"\n        if isinstance(params, list):\n            if not isinstance(self.method_data[method]['types'], list):\n                raise InvalidParamsError(\n                    'expected keyword params, not positional')\n\n            for param, type, posnum in zip(params,\n                                           self.method_data[method]['types'],\n                                           range(1, len(params)+1)):\n                if not (isinstance(param, type) or param is None):\n                    raise InvalidParamsError(\n                        'positional arg #{} is the wrong type'.format(posnum))\n\n        elif isinstance(params, dict):\n            if not isinstance(self.method_data[method]['types'], dict):\n                raise InvalidParamsError(\n                    'expected positional params, not keyword')\n\n            if 'required' in self.method_data[method]:\n                for key in self.method_data[method]['required']:\n                    if key not in params:\n                        raise InvalidParamsError('missing key: %s' % key)\n\n            for key in params.keys():\n                if key not in self.method_data[method]['types'] or \\\n                    not (isinstance(params[key],\n                                    self.method_data[method]['types'][key])\n                         or params[key] is None):\n                    raise InvalidParamsError(\n                        'arg \"{}\" is the wrong type'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef startService(self):\n        self.clientFactory.connect().addErrback(\n            log.err, 'error starting the JSON-RPC client service %r' % (self,))\n        service.Service.startService(self)", "response": "Start the JSON - RPC service and connect the JSONRPCClientFactory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef callRemote(self, *a, **kw):\n        if not self.running:\n            return defer.fail(ServiceStopped())\n        return self.clientFactory.callRemote(*a, **kw)", "response": "Make a callRemote request of the JSONRPCClientFactory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dumps(self):\n\n        error = {'code': self.code,\n                 'message': str(self.message)}\n\n        if self.data is not None:\n            error['data'] = self.data\n\n        return error", "response": "Return the exception data in a format for JSON - RPC."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, parent, obj_type, **attributes):\n\n        response = self.post(self.server_url + parent.ref + '/' + obj_type, attributes)\n        return self._get_href(response.json())", "response": "IXN API add command - adds object to parent object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a string representation of this read.", "response": "def stringize(\n        self,\n        rnf_profile=RnfProfile(),\n    ):\n        \"\"\"Create RNF representation of this read.\n\n\t\tArgs:\n\t\t\tread_tuple_id_width (int): Maximal expected string length of read tuple ID.\n\t\t\tgenome_id_width (int): Maximal expected string length of genome ID.\n\t\t\tchr_id_width (int): Maximal expected string length of chromosome ID.\n\t\t\tcoor_width (int): Maximal expected string length of a coordinate.\n\t\t\"\"\"\n\n        sorted_segments = sorted(self.segments,\n         key=lambda x: (\n          x.genome_id * (10 ** 23) +\n          x.chr_id * (10 ** 21) +\n          (x.left + (int(x.left == 0) * x.right - 1)) * (10 ** 11) +\n          x.right * (10 ** 1) +\n          int(x.direction == \"F\")\n         )\n        )\n\n        segments_strings = [x.stringize(rnf_profile) for x in sorted_segments]\n\n        read_tuple_name = \"__\".join(\n            [\n                self.prefix,\n                format(self.read_tuple_id, 'x').zfill(rnf_profile.read_tuple_id_width),\n                \",\".join(segments_strings),\n                self.suffix,\n            ]\n        )\n\n        return read_tuple_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef destringize(self, string):\n\n        # todo: assert -- starting with (, ending with )\n        # (prefix,read_tuple_id,segments_t,suffix)=(text).split(\"__\")\n        # segments=segments_t.split(\"),(\")\n        m = read_tuple_destr_pattern.match(string)\n        if not m:\n            smbl.messages.error(\n                \"'{}' is not a valid read name with respect to the RNF specification\".format(string),\n                program=\"RNFtools\", subprogram=\"RNF format\", exception=ValueError\n            )\n        groups = m.groups()\n        # todo: check number of groups\n        self.prefix = groups[0]\n        read_tuple_id = groups[1]\n        self.read_tuple_id = int(read_tuple_id, 16)\n        self.segments = []\n        segments_str = groups[2:-1]\n        for b_str in segments_str:\n            if b_str is not None:\n                if b_str[0] == \",\":\n                    b_str = b_str[1:]\n                b = rnftools.rnfformat.Segment()\n                b.destringize(b_str)\n                self.segments.append(b)\n        self.suffix = groups[-1]", "response": "This function will take a textual representation of a read and save them into this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct(name, exec_, terminal=False, additional_opts={}):\n\t'''Construct a .desktop file and return it as a string.\n\tCreate a standards-compliant .desktop file, returning it as a string.\n\tArgs:\n\t\t\tname\t\t\t(str) : The program's name.\n\t\t\texec\\_\t\t  (str) : The command.\n\t\t\tterminal\t\t(bool): Determine if program should be run in a terminal emulator or not. Defaults to ``False``.\n\t\t\tadditional_opts (dict): Any additional fields.\n\tReturns:\n\t\t\tstr: The constructed .desktop file.\n\t'''\n\n\tdesktop_file = '[Desktop Entry]\\n'\n\n\tdesktop_file_dict = {\n\t\t'Name': name,\n\t\t'Exec': exec_,\n\t\t'Terminal': 'true' if terminal else 'false',\n\t\t'Comment': additional_opts.get('Comment', name)\n\t}\n\n\tdesktop_file = ('[Desktop Entry]\\nName={name}\\nExec={exec_}\\n'\n\t\t\t\t\t'Terminal={terminal}\\nComment={comment}\\n')\n\n\tdesktop_file = desktop_file.format(name=desktop_file_dict['Name'],\n\t\t\t\t\t\t\t\t\t   exec_=desktop_file_dict['Exec'],\n\t\t\t\t\t\t\t\t\t   terminal=desktop_file_dict['Terminal'],\n\t\t\t\t\t\t\t\t\t   comment=desktop_file_dict['Comment'])\n\n\tif additional_opts is None:\n\t\tadditional_opts = {}\n\n\tfor option in additional_opts:\n\t\tif not option in desktop_file_dict:\n\t\t\tdesktop_file += '%s=%s\\n' % (option, additional_opts[option])\n\n\treturn desktop_file", "response": "Construct a. desktop file and return it as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(desktop_file, files=None, return_cmd=False, background=False):\n\t'''Execute a .desktop file.\n\tExecutes a given .desktop file path properly.\n\tArgs:\n\t\t\tdesktop_file (str) : The path to the .desktop file.\n\t\t\tfiles\t\t(list): Any files to be launched by the .desktop. Defaults to empty list.\n\t\t\treturn_cmd   (bool): Return the command (as ``str``) instead of executing. Defaults to ``False``.\n\t\t\tbackground   (bool): Run command in background. Defaults to ``False``.\n\tReturns:\n\t\t\tstr: Only if ``return_cmd``. Returns command instead of running it. Else returns nothing.\n\t'''\n\n\t# Attempt to manually parse and execute\n\n\tdesktop_file_exec = parse(desktop_file)['Exec']\n\n\tfor i in desktop_file_exec.split():\n\t\tif i.startswith('%'):\n\t\t\tdesktop_file_exec = desktop_file_exec.replace(i, '')\n\n\tdesktop_file_exec = desktop_file_exec.replace(r'%F', '')\n\tdesktop_file_exec = desktop_file_exec.replace(r'%f', '')\n\n\tif files:\n\t\tfor i in files:\n\t\t\tdesktop_file_exec += ' ' + i\n\n\tif parse(desktop_file)['Terminal']:\n\t\t# Use eval and __import__ to bypass a circular dependency\n\t\tdesktop_file_exec = eval(\n\t\t\t\t('__import__(\"libdesktop\").applications.terminal(exec_=\"%s\",'\n\t\t\t\t ' keep_open_after_cmd_exec=True, return_cmd=True)') %\n\t\t\tdesktop_file_exec)\n\n\tif return_cmd:\n\t\treturn desktop_file_exec\n\n\tdesktop_file_proc = sp.Popen([desktop_file_exec], shell=True)\n\n\tif not background:\n\t\tdesktop_file_proc.wait()", "response": "Execute a. desktop file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef locate(desktop_filename_or_name):\n\t'''Locate a .desktop from the standard locations.\n\tFind the path to the .desktop file of a given .desktop filename or application name.\n\tStandard locations:\n\t\t\t- ``~/.local/share/applications/``\n\t\t\t- ``/usr/share/applications``\n\tArgs:\n\t\t\tdesktop_filename_or_name (str): Either the filename of a .desktop file or the name of an application.\n\tReturns:\n\t\t\tlist: A list of all matching .desktop files found.\n\t'''\n\n\tpaths = [\n\t\tos.path.expanduser('~/.local/share/applications'),\n\t\t'/usr/share/applications']\n\n\tresult = []\n\n\tfor path in paths:\n\t\tfor file in os.listdir(path):\n\t\t\tif desktop_filename_or_name in file.split(\n\t\t\t\t\t'.') or desktop_filename_or_name == file:\n\t\t\t\t# Example: org.gnome.gedit\n\t\t\t\tresult.append(os.path.join(path, file))\n\n\t\t\telse:\n\t\t\t\tfile_parsed = parse(os.path.join(path, file))\n\n\t\t\t\ttry:\n\t\t\t\t\tif desktop_filename_or_name.lower() == file_parsed[\n\t\t\t\t\t\t\t'Name'].lower():\n\t\t\t\t\t\tresult.append(file)\n\t\t\t\t\telif desktop_filename_or_name.lower() == file_parsed[\n\t\t\t\t\t\t\t'Exec'].split(' ')[0]:\n\t\t\t\t\t\tresult.append(file)\n\t\t\t\texcept KeyError:\n\t\t\t\t\tpass\n\n\tfor res in result:\n\t\tif not res.endswith('.desktop'):\n\t\t\tresult.remove(res)\n\n\tif not result and not result.endswith('.desktop'):\n\t\tresult.extend(locate(desktop_filename_or_name + '.desktop'))\n\n\treturn result", "response": "Locate a. desktop from the standard locations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a. desktop file or a string with its contents into an easy - to - use dict with standard values present even if not defined in file.", "response": "def parse(desktop_file_or_string):\n\t'''Parse a .desktop file.\n\tParse a .desktop file or a string with its contents into an easy-to-use dict, with standard values present even if not defined in file.\n\tArgs:\n\t\t\tdesktop_file_or_string (str): Either the path to a .desktop file or a string with a .desktop file as its contents.\n\tReturns:\n\t\t\tdict: A dictionary of the parsed file.'''\n\n\tif os.path.isfile(desktop_file_or_string):\n\t\twith open(desktop_file_or_string) as f:\n\t\t\tdesktop_file = f.read()\n\n\telse:\n\t\tdesktop_file = desktop_file_or_string\n\n\tresult = {}\n\n\tfor line in desktop_file.split('\\n'):\n\t\tif '=' in line:\n\t\t\tresult[line.split('=')[0]] = line.split('=')[1]\n\n\tfor key, value in result.items():\n\t\tif value == 'false':\n\t\t\tresult[key] = False\n\t\telif value == 'true':\n\t\t\tresult[key] = True\n\n\tif not 'Terminal' in result:\n\t\tresult['Terminal'] = False\n\n\tif not 'Hidden' in result:\n\t\tresult['Hidden'] = False\n\n\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_completed(fs, timeout=None):\n    with _AcquireFutures(fs):\n        finished = set(f for f in fs if f._state in [CANCELLED_AND_NOTIFIED, FINISHED])\n        pending = set(fs) - finished\n        waiter = _create_and_install_waiters(fs, _AS_COMPLETED)\n\n    timer = Timeout(timeout)\n    timer.start()\n    try:\n        for future in finished:\n            yield future\n        while pending:\n            waiter.event.wait()\n            with waiter.lock:\n                finished = waiter.finished_futures\n                waiter.finished_futures = []\n                waiter.event.clear()\n            for future in finished:\n                yield future\n                pending.remove(future)\n    except Timeout as e:\n        if timer is not e:\n            raise\n        raise TimeoutError('%d (of %d) futures unfinished' % (len(pending), len(fs)))\n    finally:\n        timer.cancel()\n        for f in fs:\n            f._waiters.remove(waiter)", "response": "An iterator over the given Futures that yields each as it completes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterator equivalent to map ( fn iter ).", "response": "def map(self, fn, *iterables, **kwargs):\n        \"\"\"Returns a iterator equivalent to map(fn, iter).\n\n        Args:\n            fn: A callable that will take take as many arguments as there are\n                passed iterables.\n            timeout: The maximum number of seconds to wait. If None, then there\n                is no limit on the wait time.\n\n        Returns:\n            An iterator equivalent to: map(func, *iterables) but the calls may\n            be evaluated out-of-order.\n\n        Raises:\n            TimeoutError: If the entire result iterator could not be generated\n                before the given timeout.\n            Exception: If fn(*args) raises for any values.\n        \"\"\"\n        loop = evergreen.current.loop\n\n        timeout = kwargs.get('timeout')\n        if timeout is not None:\n            end_time = timeout + loop.time()\n\n        fs = [self.submit(fn, *args) for args in zip(*iterables)]\n\n        # Yield must be hidden in closure so that the futures are submitted\n        # before the first iterator value is required.\n        def result_iterator():\n            try:\n                for future in fs:\n                    if timeout is None:\n                        yield future.get()\n                    else:\n                        yield future.get(end_time - loop.time())\n            finally:\n                for future in fs:\n                    future.cancel()\n        return result_iterator()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up the server for the current instance of the class.", "response": "def set_server(self, wsgi_app, fnc_serve=None):\n        \"\"\"\n        figures out how the wsgi application is to be served\n        according to config\n        \"\"\"\n\n        self.set_wsgi_app(wsgi_app)\n\n        ssl_config = self.get_config(\"ssl\")\n        ssl_context = {}\n\n        if self.get_config(\"server\") == \"gevent\":\n\n            if ssl_config.get(\"enabled\"):\n                ssl_context[\"certfile\"] = ssl_config.get(\"cert\")\n                ssl_context[\"keyfile\"] = ssl_config.get(\"key\")\n\n            from gevent.pywsgi import WSGIServer\n\n            http_server = WSGIServer(\n                (self.host, self.port),\n                wsgi_app,\n                **ssl_context\n            )\n\n            self.log.debug(\"Serving WSGI via gevent.pywsgi.WSGIServer\")\n\n            fnc_serve = http_server.serve_forever\n\n        elif self.get_config(\"server\") == \"uwsgi\":\n            self.pluginmgr_config[\"start_manual\"] = True\n\n        elif self.get_config(\"server\") == \"gunicorn\":\n            self.pluginmgr_config[\"start_manual\"] = True\n\n        elif self.get_config(\"server\") == \"self\":\n            fnc_serve = self.run\n\n        # figure out async handler\n\n        if self.get_config(\"async\") == \"gevent\":\n\n            # handle async via gevent\n            import gevent\n\n            self.log.debug(\"Handling wsgi on gevent\")\n\n            self.worker = gevent.spawn(fnc_serve)\n\n        elif self.get_config(\"async\") == \"thread\":\n\n            self.worker = fnc_serve\n\n        else:\n\n            self.worker = fnc_serve"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pre_save(self, instance, add):\n        # get currently entered slug\n        value = self.value_from_object(instance)\n        slug = None\n\n        # auto populate (if the form didn't do that already).\n        # If you want unique_with logic, use django-autoslug instead.\n        # This model field only allows parameters which can be passed to the form widget too.\n        if self.populate_from and (self.always_update or not value):\n            value = getattr(instance, self.populate_from)\n\n        # Make sure the slugify logic is applied,\n        # even on manually entered input.\n        if value:\n            value = force_text(value)\n            slug = self.slugify(value)\n            if self.max_length < len(slug):\n                slug = slug[:self.max_length]\n\n        # make the updated slug available as instance attribute\n        setattr(instance, self.name, slug)\n        return slug", "response": "Auto - generate the slug if needed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a search list that contains only the first object from a queryset into the first position of a reading list.", "response": "def FirstSlotSlicer(primary_query, secondary_query, limit=30):  # noqa\n    \"\"\"\n    Inject the first object from a queryset into the first position of a reading list.\n\n    :param primary_queryset: djes.LazySearch object. Default queryset for reading list.\n    :param secondary_queryset: djes.LazySearch object. first result leads the reading_list.\n    :return list: mixed reading list.\n    \"\"\"\n    reading_list = SearchSlicer(limit=limit)\n    reading_list.register_queryset(primary_query)\n    reading_list.register_queryset(secondary_query, validator=lambda x: bool(x == 0))\n    return reading_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a given queryset to the iterator with custom logic for iteration.", "response": "def register_queryset(self, queryset, validator=None, default=False):\n        \"\"\"\n        Add a given queryset to the iterator with custom logic for iteration.\n\n        :param queryset: List of objects included in the reading list.\n        :param validator: Custom logic to determine a queryset's position in a reading_list.\n            Validators must accept an index as an argument and return a truthy value.\n        :param default: Sets the given queryset as the primary queryset when no validator applies.\n        \"\"\"\n        if default or self.default_queryset is None:\n            self.default_queryset = queryset\n            return\n        if validator:\n            self.querysets[validator] = queryset\n        else:\n            raise ValueError(\n                \"\"\"Querysets require validation logic to integrate with reading lists.\"\"\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first day of the current month", "response": "def get_month_start_date(self):\n        \"\"\"Returns the first day of the current month\"\"\"\n        now = timezone.now()\n        return timezone.datetime(day=1, month=now.month, year=now.year, tzinfo=now.tzinfo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding all items from the given iterable like list or tuple.", "response": "def _yield_all(self, l):\n        '''\n        Given a iterable like list or tuple the function yields each of its\n        items with _yield\n        '''\n        if l is not None:\n            if type(l) in [list, tuple]:\n                for f in l:\n                    for x in self._yield(f): yield x\n            else:\n                for x in self._yield(l): yield x"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a POST request to the endpoint identified by the resource path. POST requests are usually used to add new data. Example: >>> from moneybird import MoneyBird, TokenAuthentication >>> moneybird = MoneyBird(TokenAuthentication('access_token')) >>> data = {'url': 'http://www.mocky.io/v2/5185415ba171ea3a00704eed'} >>> moneybird.post('webhooks', data, 123) {'id': '143274315994891267', 'url': 'http://www.mocky.io/v2/5185415ba171ea3a00704eed', ... :param resource_path: The resource path. :param data: The data to send to the server. :param administration_id: The administration id (optional, depending on the resource path). :return: The decoded JSON response for the request.", "response": "def post(self, resource_path: str, data: dict, administration_id: int = None):\n        \"\"\"\n        Performs a POST request to the endpoint identified by the resource path. POST requests are usually used to add\n        new data.\n\n        Example:\n            >>> from moneybird import MoneyBird, TokenAuthentication\n            >>> moneybird = MoneyBird(TokenAuthentication('access_token'))\n            >>> data = {'url': 'http://www.mocky.io/v2/5185415ba171ea3a00704eed'}\n            >>> moneybird.post('webhooks', data, 123)\n            {'id': '143274315994891267', 'url': 'http://www.mocky.io/v2/5185415ba171ea3a00704eed', ...\n\n        :param resource_path: The resource path.\n        :param data: The data to send to the server.\n        :param administration_id: The administration id (optional, depending on the resource path).\n        :return: The decoded JSON response for the request.\n        \"\"\"\n        response = self.session.post(\n            url=self._get_url(administration_id, resource_path),\n            json=data,\n        )\n        return self._process_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete the resource identified by the resource path.", "response": "def delete(self, resource_path: str, administration_id: int = None):\n        \"\"\"\n        Performs a DELETE request to the endpoint identified by the resource path. DELETE requests are usually used to\n        (permanently) delete existing data. USE THIS METHOD WITH CAUTION.\n\n        From a client perspective, DELETE requests behave similarly to GET requests.\n\n        :param resource_path: The resource path.\n        :param administration_id: The administration id (optional, depending on the resource path).\n        :return: The decoded JSON response for the request.\n        \"\"\"\n        response = self.session.delete(\n            url=self._get_url(administration_id, resource_path),\n        )\n        return self._process_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenews all session data and starts a new session.", "response": "def renew_session(self):\n        \"\"\"\n        Clears all session data and starts a new session using the same settings as before.\n\n        This method can be used to clear session data, e.g., cookies. Future requests will use a new session initiated\n        with the same settings and authentication method.\n        \"\"\"\n        logger.debug(\"API session renewed\")\n        self.session = self.authentication.get_session()\n        self.session.headers.update({\n            'User-Agent': 'MoneyBird for Python %s' % VERSION,\n            'Accept': 'application/json',\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the URL to the API endpoint specified by the given parameters.", "response": "def _get_url(cls, administration_id: int, resource_path: str):\n        \"\"\"\n        Builds the URL to the API endpoint specified by the given parameters.\n\n        :param administration_id: The ID of the administration (may be None).\n        :param resource_path: The path to the resource.\n        :return: The absolute URL to the endpoint.\n        \"\"\"\n        url = urljoin(cls.base_url, '%s/' % cls.version)\n\n        if administration_id is not None:\n            url = urljoin(url, '%s/' % administration_id)\n\n        url = urljoin(url, '%s.json' % resource_path)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_response(response: requests.Response, expected: list = []) -> dict:\n        responses = {\n            200: None,\n            201: None,\n            204: None,\n            400: MoneyBird.Unauthorized,\n            401: MoneyBird.Unauthorized,\n            403: MoneyBird.Throttled,\n            404: MoneyBird.NotFound,\n            406: MoneyBird.NotFound,\n            422: MoneyBird.InvalidData,\n            429: MoneyBird.Throttled,\n            500: MoneyBird.ServerError,\n        }\n\n        logger.debug(\"API request: %s %s\\n\" % (response.request.method, response.request.url) +\n                     \"Response: %s %s\" % (response.status_code, response.text))\n\n        if response.status_code not in expected:\n            if response.status_code not in responses:\n                logger.error(\"API response contained unknown status code\")\n                raise MoneyBird.APIError(response, \"API response contained unknown status code\")\n            elif responses[response.status_code] is not None:\n                try:\n                    description = response.json()['error']\n                except (AttributeError, TypeError, KeyError, ValueError):\n                    description = None\n                raise responses[response.status_code](response, description)\n\n        try:\n            data = response.json()\n        except ValueError:\n            logger.error(\"API response is not JSON decodable\")\n            data = None\n\n        return data", "response": "Processes an API response and returns a dict of the relevant data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_videohub(cls, query, filters=None, status=None, sort=None, size=None, page=None):\n        # construct url\n        url = getattr(settings, \"VIDEOHUB_API_SEARCH_URL\", cls.DEFAULT_VIDEOHUB_API_SEARCH_URL)\n        # construct auth headers\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": settings.VIDEOHUB_API_TOKEN,\n        }\n        # construct payload\n        payload = {\n            \"query\": query,\n        }\n        if filters:\n            assert isinstance(filters, dict)\n            payload[\"filters\"] = filters\n        if status:\n            assert isinstance(status, six.string_types)\n            payload.setdefault(\"filters\", {})\n            payload[\"filters\"][\"status\"] = status\n        if sort:\n            assert isinstance(sort, dict)\n            payload[\"sort\"] = sort\n        if size:\n            assert isinstance(size, (six.string_types, int))\n            payload[\"size\"] = size\n        if page:\n            assert isinstance(page, (six.string_types, int))\n            payload[\"page\"] = page\n        # send request\n        res = requests.post(url, data=json.dumps(payload), headers=headers)\n        # raise if not 200\n        if res.status_code != 200:\n            res.raise_for_status()\n        # parse and return response\n        return json.loads(res.content)", "response": "searches the videohub given a query and applies given filters and other bits\n        returns a dictionary of results and meta information"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_hub_url(self):\n        url = getattr(settings, \"VIDEOHUB_VIDEO_URL\", self.DEFAULT_VIDEOHUB_VIDEO_URL)\n\n        # slugify needs ascii\n        ascii_title = \"\"\n        if isinstance(self.title, str):\n            ascii_title = self.title\n        elif six.PY2 and isinstance(self.title, six.text_type):\n            # Legacy unicode conversion\n            ascii_title = self.title.encode('ascii', 'replace')\n\n        path = slugify(\"{}-{}\".format(ascii_title, self.id))\n\n        return url.format(path)", "response": "gets a canonical path to the detail page of the video on the hub"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a canonical path to an embedded iframe of the video from the hub", "response": "def get_embed_url(self, targeting=None, recirc=None):\n        \"\"\"gets a canonical path to an embedded iframe of the video from the hub\n\n        :return: the path to create an embedded iframe of the video\n        :rtype: str\n        \"\"\"\n        url = getattr(settings, \"VIDEOHUB_EMBED_URL\", self.DEFAULT_VIDEOHUB_EMBED_URL)\n        url = url.format(self.id)\n        if targeting is not None:\n            for k, v in sorted(targeting.items()):\n                url += '&{0}={1}'.format(k, v)\n        if recirc is not None:\n            url += '&recirc={0}'.format(recirc)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_api_url(self):\n        url = getattr(settings, 'VIDEOHUB_API_URL', None)\n        # Support alternate setting (used by most client projects)\n        if not url:\n            url = getattr(settings, 'VIDEOHUB_API_BASE_URL', None)\n            if url:\n                url = url.rstrip('/') + '/videos/{}'\n        if not url:\n            url = self.DEFAULT_VIDEOHUB_API_URL\n        return url.format(self.id)", "response": "gets a canonical path to the api detail url of the video on the hub"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self, node):\n        if node is None or node._prev == -1:\n            return\n        if node._next is None:\n            self._last = node._prev  # last node\n        else:\n            node._next._prev = node._prev\n        if node._prev is None:\n            self._first = node._next  # first node\n        else:\n            node._prev._next = node._next\n        node._prev = node._next = -1\n        self._size -= 1", "response": "Removes a node from the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_outcome_links_for_context_accounts(self, account_id, outcome_group_style=None, outcome_style=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - outcome_style\r\n        \"\"\"The detail level of the outcomes. Defaults to \"abbrev\".\r\n        Specify \"full\" for more information.\"\"\"\r\n        if outcome_style is not None:\r\n            params[\"outcome_style\"] = outcome_style\r\n\r\n        # OPTIONAL - outcome_group_style\r\n        \"\"\"The detail level of the outcome groups. Defaults to \"abbrev\".\r\n        Specify \"full\" for more information.\"\"\"\r\n        if outcome_group_style is not None:\r\n            params[\"outcome_group_style\"] = outcome_group_style\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/outcome_group_links with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/outcome_group_links\".format(**path), data=data, params=params, all_pages=True)", "response": "Get all outcome links for a context. Returns a list of outcome links for the given context and account."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets all outcome links for a context. Returns a list of outcome links for the context.", "response": "def get_all_outcome_links_for_context_courses(self, course_id, outcome_group_style=None, outcome_style=None):\r\n        \"\"\"\r\n        Get all outcome links for context.\r\n\r\n        \r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - outcome_style\r\n        \"\"\"The detail level of the outcomes. Defaults to \"abbrev\".\r\n        Specify \"full\" for more information.\"\"\"\r\n        if outcome_style is not None:\r\n            params[\"outcome_style\"] = outcome_style\r\n\r\n        # OPTIONAL - outcome_group_style\r\n        \"\"\"The detail level of the outcome groups. Defaults to \"abbrev\".\r\n        Specify \"full\" for more information.\"\"\"\r\n        if outcome_group_style is not None:\r\n            params[\"outcome_group_style\"] = outcome_group_style\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/outcome_group_links with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/outcome_group_links\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_link_outcome_global_outcome_id(self, id, outcome_id, calculation_int=None, calculation_method=None, description=None, display_name=None, mastery_points=None, ratings_description=None, ratings_points=None, title=None, vendor_guid=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - outcome_id\r\n        \"\"\"The ID of the existing outcome to link.\"\"\"\r\n        path[\"outcome_id\"] = outcome_id\r\n\r\n        # OPTIONAL - title\r\n        \"\"\"The title of the new outcome. Required if outcome_id is absent.\"\"\"\r\n        if title is not None:\r\n            data[\"title\"] = title\r\n\r\n        # OPTIONAL - display_name\r\n        \"\"\"A friendly name shown in reports for outcomes with cryptic titles,\r\n        such as common core standards names.\"\"\"\r\n        if display_name is not None:\r\n            data[\"display_name\"] = display_name\r\n\r\n        # OPTIONAL - description\r\n        \"\"\"The description of the new outcome.\"\"\"\r\n        if description is not None:\r\n            data[\"description\"] = description\r\n\r\n        # OPTIONAL - vendor_guid\r\n        \"\"\"A custom GUID for the learning standard.\"\"\"\r\n        if vendor_guid is not None:\r\n            data[\"vendor_guid\"] = vendor_guid\r\n\r\n        # OPTIONAL - mastery_points\r\n        \"\"\"The mastery threshold for the embedded rubric criterion.\"\"\"\r\n        if mastery_points is not None:\r\n            data[\"mastery_points\"] = mastery_points\r\n\r\n        # OPTIONAL - ratings[description]\r\n        \"\"\"The description of a rating level for the embedded rubric criterion.\"\"\"\r\n        if ratings_description is not None:\r\n            data[\"ratings[description]\"] = ratings_description\r\n\r\n        # OPTIONAL - ratings[points]\r\n        \"\"\"The points corresponding to a rating level for the embedded rubric criterion.\"\"\"\r\n        if ratings_points is not None:\r\n            data[\"ratings[points]\"] = ratings_points\r\n\r\n        # OPTIONAL - calculation_method\r\n        \"\"\"The new calculation method.  Defaults to \"highest\"\"\"\"\r\n        if calculation_method is not None:\r\n            self._validate_enum(calculation_method, [\"decaying_average\", \"n_mastery\", \"latest\", \"highest\"])\r\n            data[\"calculation_method\"] = calculation_method\r\n\r\n        # OPTIONAL - calculation_int\r\n        \"\"\"The new calculation int.  Only applies if the calculation_method is \"decaying_average\" or \"n_mastery\"\"\"\"\r\n        if calculation_int is not None:\r\n            data[\"calculation_int\"] = calculation_int\r\n\r\n        self.logger.debug(\"PUT /api/v1/global/outcome_groups/{id}/outcomes/{outcome_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/global/outcome_groups/{id}/outcomes/{outcome_id}\".format(**path), data=data, params=params, single_item=True)", "response": "Creates a new global outcome in the outcome group."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_subgroups_global(self, id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"GET /api/v1/global/outcome_groups/{id}/subgroups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/global/outcome_groups/{id}/subgroups\".format(**path), data=data, params=params, all_pages=True)", "response": "List the immediate OutcomeGroup children of the outcome group. Returns a list of all the subgroups that are in the global outcome group."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists the immediate OutcomeGroup children of the outcome group. Returns a list of all the subgroups in the outcome group.", "response": "def list_subgroups_accounts(self, id, account_id):\r\n        \"\"\"\r\n        List subgroups.\r\n\r\n        List the immediate OutcomeGroup children of the outcome group. Paginated.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/outcome_groups/{id}/subgroups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/outcome_groups/{id}/subgroups\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_subgroup_global(self, id, title, description=None, vendor_guid=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - title\r\n        \"\"\"The title of the new outcome group.\"\"\"\r\n        data[\"title\"] = title\r\n\r\n        # OPTIONAL - description\r\n        \"\"\"The description of the new outcome group.\"\"\"\r\n        if description is not None:\r\n            data[\"description\"] = description\r\n\r\n        # OPTIONAL - vendor_guid\r\n        \"\"\"A custom GUID for the learning standard\"\"\"\r\n        if vendor_guid is not None:\r\n            data[\"vendor_guid\"] = vendor_guid\r\n\r\n        self.logger.debug(\"POST /api/v1/global/outcome_groups/{id}/subgroups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/global/outcome_groups/{id}/subgroups\".format(**path), data=data, params=params, single_item=True)", "response": "Create a new empty subgroup under the given outcome group. Returns the new subgroup with the given title and description."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_single_grading_period(self, id, course_id, grading_periods_end_date, grading_periods_start_date, grading_periods_weight=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - grading_periods[start_date]\r\n        \"\"\"The date the grading period starts.\"\"\"\r\n        data[\"grading_periods[start_date]\"] = grading_periods_start_date\r\n\r\n        # REQUIRED - grading_periods[end_date]\r\n        \"\"\"no description\"\"\"\r\n        data[\"grading_periods[end_date]\"] = grading_periods_end_date\r\n\r\n        # OPTIONAL - grading_periods[weight]\r\n        \"\"\"A weight value that contributes to the overall weight of a grading period set which is used to calculate how much assignments in this period contribute to the total grade\"\"\"\r\n        if grading_periods_weight is not None:\r\n            data[\"grading_periods[weight]\"] = grading_periods_weight\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/grading_periods/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/grading_periods/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Update a single grading period. Updates a single grading period."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_grading_period_accounts(self, id, account_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/accounts/{account_id}/grading_periods/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/accounts/{account_id}/grading_periods/{id}\".format(**path), data=data, params=params, no_data=True)", "response": "Delete a grading period. Delete a grading period."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_appointment_groups(self, context_codes=None, include=None, include_past_appointments=None, scope=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"Defaults to \"reservable\"\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"reservable\", \"manageable\"])\r\n            params[\"scope\"] = scope\r\n\r\n        # OPTIONAL - context_codes\r\n        \"\"\"Array of context codes used to limit returned results.\"\"\"\r\n        if context_codes is not None:\r\n            params[\"context_codes\"] = context_codes\r\n\r\n        # OPTIONAL - include_past_appointments\r\n        \"\"\"Defaults to false. If true, includes past appointment groups\"\"\"\r\n        if include_past_appointments is not None:\r\n            params[\"include_past_appointments\"] = include_past_appointments\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Array of additional information to include.\r\n        \r\n        \"appointments\":: calendar event time slots for this appointment group\r\n        \"child_events\":: reservations of those time slots\r\n        \"participant_count\":: number of reservations\r\n        \"reserved_times\":: the event id, start time and end time of reservations\r\n                           the current user has made)\r\n        \"all_context_codes\":: all context codes associated with this appointment group\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"appointments\", \"child_events\", \"participant_count\", \"reserved_times\", \"all_context_codes\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/appointment_groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/appointment_groups\".format(**path), data=data, params=params, no_data=True)", "response": "List appointment groups. Returns a list of appointment groups that can be reserved or managed by the current user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_appointment_group(self, appointment_group_title, appointment_group_context_codes, appointment_group_description=None, appointment_group_location_address=None, appointment_group_location_name=None, appointment_group_max_appointments_per_participant=None, appointment_group_min_appointments_per_participant=None, appointment_group_new_appointments_X=None, appointment_group_participant_visibility=None, appointment_group_participants_per_appointment=None, appointment_group_publish=None, appointment_group_sub_context_codes=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - appointment_group[context_codes]\r\n        \"\"\"Array of context codes (courses, e.g. course_1) this group should be\r\n        linked to (1 or more). Users in the course(s) with appropriate permissions\r\n        will be able to sign up for this appointment group.\"\"\"\r\n        data[\"appointment_group[context_codes]\"] = appointment_group_context_codes\r\n\r\n        # OPTIONAL - appointment_group[sub_context_codes]\r\n        \"\"\"Array of sub context codes (course sections or a single group category)\r\n        this group should be linked to. Used to limit the appointment group to\r\n        particular sections. If a group category is specified, students will sign\r\n        up in groups and the participant_type will be \"Group\" instead of \"User\".\"\"\"\r\n        if appointment_group_sub_context_codes is not None:\r\n            data[\"appointment_group[sub_context_codes]\"] = appointment_group_sub_context_codes\r\n\r\n        # REQUIRED - appointment_group[title]\r\n        \"\"\"Short title for the appointment group.\"\"\"\r\n        data[\"appointment_group[title]\"] = appointment_group_title\r\n\r\n        # OPTIONAL - appointment_group[description]\r\n        \"\"\"Longer text description of the appointment group.\"\"\"\r\n        if appointment_group_description is not None:\r\n            data[\"appointment_group[description]\"] = appointment_group_description\r\n\r\n        # OPTIONAL - appointment_group[location_name]\r\n        \"\"\"Location name of the appointment group.\"\"\"\r\n        if appointment_group_location_name is not None:\r\n            data[\"appointment_group[location_name]\"] = appointment_group_location_name\r\n\r\n        # OPTIONAL - appointment_group[location_address]\r\n        \"\"\"Location address.\"\"\"\r\n        if appointment_group_location_address is not None:\r\n            data[\"appointment_group[location_address]\"] = appointment_group_location_address\r\n\r\n        # OPTIONAL - appointment_group[publish]\r\n        \"\"\"Indicates whether this appointment group should be published (i.e. made\r\n        available for signup). Once published, an appointment group cannot be\r\n        unpublished. Defaults to false.\"\"\"\r\n        if appointment_group_publish is not None:\r\n            data[\"appointment_group[publish]\"] = appointment_group_publish\r\n\r\n        # OPTIONAL - appointment_group[participants_per_appointment]\r\n        \"\"\"Maximum number of participants that may register for each time slot.\r\n        Defaults to null (no limit).\"\"\"\r\n        if appointment_group_participants_per_appointment is not None:\r\n            data[\"appointment_group[participants_per_appointment]\"] = appointment_group_participants_per_appointment\r\n\r\n        # OPTIONAL - appointment_group[min_appointments_per_participant]\r\n        \"\"\"Minimum number of time slots a user must register for. If not set, users\r\n        do not need to sign up for any time slots.\"\"\"\r\n        if appointment_group_min_appointments_per_participant is not None:\r\n            data[\"appointment_group[min_appointments_per_participant]\"] = appointment_group_min_appointments_per_participant\r\n\r\n        # OPTIONAL - appointment_group[max_appointments_per_participant]\r\n        \"\"\"Maximum number of time slots a user may register for.\"\"\"\r\n        if appointment_group_max_appointments_per_participant is not None:\r\n            data[\"appointment_group[max_appointments_per_participant]\"] = appointment_group_max_appointments_per_participant\r\n\r\n        # OPTIONAL - appointment_group[new_appointments][X]\r\n        \"\"\"Nested array of start time/end time pairs indicating time slots for this\r\n        appointment group. Refer to the example request.\"\"\"\r\n        if appointment_group_new_appointments_X is not None:\r\n            data[\"appointment_group[new_appointments][X]\"] = appointment_group_new_appointments_X\r\n\r\n        # OPTIONAL - appointment_group[participant_visibility]\r\n        \"\"\"\"private\":: participants cannot see who has signed up for a particular\r\n                    time slot\r\n        \"protected\":: participants can see who has signed up.  Defaults to\r\n                      \"private\".\"\"\"\r\n        if appointment_group_participant_visibility is not None:\r\n            self._validate_enum(appointment_group_participant_visibility, [\"private\", \"protected\"])\r\n            data[\"appointment_group[participant_visibility]\"] = appointment_group_participant_visibility\r\n\r\n        self.logger.debug(\"POST /api/v1/appointment_groups with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/appointment_groups\".format(**path), data=data, params=params, no_data=True)", "response": "Create an appointment group. Returns a new appointment group with the specified title description max_appointments_per_participant min_appointments_per_participant and appointment_group_participants_per_participant."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting the user participants in this appointment group. Returns a list of the user participants that are participating in this appointment group.", "response": "def list_user_participants(self, id, registration_status=None):\r\n        \"\"\"\r\n        List user participants.\r\n\r\n        List users that are (or may be) participating in this appointment group.\r\n        Refer to the Users API for the response fields. Returns no results for\r\n        appointment groups with the \"Group\" participant_type.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - registration_status\r\n        \"\"\"Limits results to the a given participation status, defaults to \"all\"\"\"\"\r\n        if registration_status is not None:\r\n            self._validate_enum(registration_status, [\"all\", \"registered\", \"registered\"])\r\n            params[\"registration_status\"] = registration_status\r\n\r\n        self.logger.debug(\"GET /api/v1/appointment_groups/{id}/users with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/appointment_groups/{id}/users\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget next appointment. Returns the next available appointment.", "response": "def get_next_appointment(self, appointment_group_ids=None):\r\n        \"\"\"\r\n        Get next appointment.\r\n\r\n        Return the next appointment available to sign up for. The appointment\r\n        is returned in a one-element array. If no future appointments are\r\n        available, an empty array is returned.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # OPTIONAL - appointment_group_ids\r\n        \"\"\"List of ids of appointment groups to search.\"\"\"\r\n        if appointment_group_ids is not None:\r\n            params[\"appointment_group_ids\"] = appointment_group_ids\r\n\r\n        self.logger.debug(\"GET /api/v1/appointment_groups/next_appointment with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/appointment_groups/next_appointment\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_funset(self, discrete):\n        fs = self.clampings.to_funset(\"exp\")\n        fs = fs.union(self.setup.to_funset())\n\n        for i, row in self.readouts.iterrows():\n            for var, val in row.iteritems():\n                if not np.isnan(val):\n                    fs.add(gringo.Fun('obs', [i, var, discrete(val)]))\n\n        return fs", "response": "Converts the dataset to a set of gringo. Fun_ instances."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the system native file dialog for opening a file.", "response": "def open_file(default_dir='~', extensions=None,\n\t\t\t  title='Choose a file', multiple_files=False, directory=False):\n\t'''Start the native file dialog for opening file(s).\n\n\tStarts the system native file dialog in order to open a file (or multiple files).\n\n\tThe toolkit used for each platform:\n\n\t+-------------------------------------+------------------------------+\n\t| Windows\t\t\t\t\t\t\t | Windows API (Win32)\t\t  |\n\t+-------------------------------------+------------------------------+\n\t| Mac OS X\t\t\t\t\t\t\t| Cocoa\t\t\t\t\t\t|\n\t+-------------------------------------+------------------------------+\n\t| GNOME, Unity, Cinnamon, Pantheon\t| GTK+ 3\t\t\t\t\t   |\n\t+-------------------------------------+------------------------------+\n\t| KDE, LXQt\t\t\t\t\t\t   | Qt 5 (fallback: Qt 4/GTK+ 3) |\n\t+-------------------------------------+------------------------------+\n\t| Other desktops (Xfce, WMs etc)\t  | GTK+ 2 (fallback: GTK+ 3)\t|\n\t+-------------------------------------+------------------------------+\n\n\t**Note on Dependencies**\n\n\tIt depends on pywin32 for Windows (installed by default in Python for Windows)\n\tIt depends on `PyQt <https://riverbankcomputing.com/software/pyqt>`_ for KDE and LxQt (usually installed by default on these).\n\tIt depends on `PyGObject <https://wiki.gnome.org/Projects/PyGObject>`_ for GNOME etc. (virtually every Linux desktop has this).\n\tIt depends on `PyGTK <https://pygtk.org>`_ for other desktops (not usually installed, so has a GTK+ 3 fallback).\n\n\tArgs:\n\t\t\tdefault_dir (str)   : The directory to start the dialog in. Default: User home directory.\n\t\t\textensions  (dict)  : The extensions to filter by. Format:\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t.. code-block:: python\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  'Filter Name (example: Image Files)': ['*.png', '*.whatever', '*']\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\n\t\t\ttitle\t\t  (str) : The title of the dialog. Default: `Choose a file`\n\t\t\tmultiple_files (bool): Whether to choose multiple files or single files only. Default: `False`\n\t\t\tdirectory\t  (bool): Whether to choose directories. Default: `False`\n\n\tReturns:\n\t\t\tlist: `list` of `str` s (each `str` being a selected file). If nothing is selected/dialog is cancelled, it is `None`.\n\t'''\n\n\tdefault_dir = os.path.expanduser(default_dir)\n\n\tif not extensions:\n\t\textensions = {}\n\n\tif system.get_name() == 'windows':\n\t\tpass  # TODO: Implement Win32 file dialog\n\n\telif system.get_name() == 'mac':\n\t\tpass  # TODO: Implement Cocoa file dialog\n\n\telse:\n\n\t\tdef gtk3_dialog():\n\n\t\t\t# GTK+ 3\n\n\t\t\timport gi\n\t\t\tgi.require_version('Gtk', '3.0')\n\n\t\t\tfrom gi.repository import Gtk\n\n\t\t\tclass FileChooserWindow(Gtk.Window):\n\n\t\t\t\tdef __init__(self):\n\n\t\t\t\t\tself.path = ''\n\n\t\t\t\t\tGtk.Window.__init__(self, title='')\n\n\t\t\t\t\tdialog = Gtk.FileChooserDialog(title, None,\n\t\t\t\t\t\t\t\t\t\t\t\t   Gtk.FileChooserAction.OPEN,\n\t\t\t\t\t\t\t\t\t\t\t\t   (Gtk.STOCK_CANCEL,\n\t\t\t\t\t\t\t\t\t\t\t\t\tGtk.ResponseType.CANCEL,\n\t\t\t\t\t\t\t\t\t\t\t\t\tGtk.STOCK_OPEN,\n\t\t\t\t\t\t\t\t\t\t\t\t\tGtk.ResponseType.OK)\n\t\t\t\t\t\t\t\t\t\t\t\t   )\n\n\t\t\t\t\tif extensions:\n\t\t\t\t\t\tfor entry in extensions:\n\t\t\t\t\t\t\tfile_filter = Gtk.FileFilter()\n\t\t\t\t\t\t\tfile_filter.set_name(entry)\n\n\t\t\t\t\t\t\tfor pattern in extensions[entry]:\n\t\t\t\t\t\t\t\tfile_filter.add_pattern(pattern)\n\n\t\t\t\t\t\t\tdialog.add_filter(file_filter)\n\n\t\t\t\t\tdialog.set_select_multiple(multiple_files)\n\n\t\t\t\t\tdialog.set_current_folder(default_dir)\n\n\t\t\t\t\tresponse = dialog.run()\n\n\t\t\t\t\tif response == Gtk.ResponseType.OK:\n\t\t\t\t\t\tself.path = dialog.get_filenames()\n\t\t\t\t\t\tdialog.destroy()\n\n\t\t\t\t\telif response == Gtk.ResponseType.CANCEL:\n\t\t\t\t\t\tself.path = None\n\t\t\t\t\t\tdialog.destroy()\n\n\t\t\twin = FileChooserWindow()\n\t\t\twin.connect('destroy', Gtk.main_quit)\n\t\t\twin.connect('delete-event', Gtk.main_quit)\n\t\t\twin.show_all()\n\t\t\twin.destroy()\n\t\t\twin.close()\n\n\t\t\treturn win.path\n\n\t\tdef qt5_dialog():\n\n\t\t\t# Qt 5\n\n\t\t\ttry:\n\t\t\t\tfrom PyQt5 import Qt\n\n\t\t\texcept ImportError:\n\t\t\t\t# The API is the same for what this uses\n\t\t\t\tfrom PyQt4 import Qt\n\n\t\t\tclass FileChooserWindow(Qt.QWidget):\n\n\t\t\t\tdef __init__(self):\n\t\t\t\t\tsuper().__init__()\n\n\t\t\t\t\textensions_string = ''\n\n\t\t\t\t\tif extensions:\n\t\t\t\t\t\tfor entry in extensions:\n\t\t\t\t\t\t\t# entry \u2192 Filter name (i.e. 'Image Files' etc)\n\t\t\t\t\t\t\t# value \u2192 Filter expression (i.e. '*.png, *.jpg'\n\t\t\t\t\t\t\t# etc)\n\t\t\t\t\t\t\textensions_string += '%s (%s);;' % (entry,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t' '.join(extensions[entry]))\n\n\t\t\t\t\telse:\n\t\t\t\t\t\textensions_string = 'All Files (*)'\n\n\t\t\t\t\tdialog = Qt.QFileDialog()\n\n\t\t\t\t\tif multiple_files:\n\t\t\t\t\t\tdialog.setFileMode(Qt.QFileDialog.ExistingFiles)\n\n\t\t\t\t\tif directory:\n\t\t\t\t\t\tdialog.setFileMode(Qt.QFileDialog.Directory)\n\n\t\t\t\t\tdialog.setWindowTitle(title)\n\t\t\t\t\tdialog.setDirectory(default_dir)\n\n\t\t\t\t\tdialog.setNameFilter(extensions_string)\n\n\t\t\t\t\tif dialog.exec_():\n\t\t\t\t\t\tself.path = dialog.selectedFiles()\n\n\t\t\t\t\telse:\n\t\t\t\t\t\tself.path = None\n\n\t\t\tapp = Qt.QApplication(sys.argv)\n\n\t\t\twin = FileChooserWindow()\n\t\t\twin.close()\n\n\t\t\tif win.path:\n\t\t\t\treturn win.path\n\n\t\t\telse:\n\t\t\t\treturn None\n\n\t\t\tapp.exec_()\n\n\t\tdef gtk2_dialog():\n\n\t\t\t# GTK+ 2\n\n\t\t\timport pygtk\n\t\t\tpygtk.require('2.0')\n\n\t\t\tdialog = gtk.FileChooserDialog(title, None,\n\t\t\t\t\t\t\t\t\t\t   gtk.FILE_CHOOSER_ACTION_OPEN,\n\t\t\t\t\t\t\t\t\t\t   (gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n\t\t\t\t\t\t\t\t\t\t\tgtk.STOCK_OPEN, gtk.RESPONSE_OK))\n\n\t\t\tdialog.set_default_response(gtk.RESPONSE_OK)\n\n\t\t\tif extensions:\n\t\t\t\tfor entry in extensions:\n\t\t\t\t\tfile_filter = gtk.FileFilter()\n\t\t\t\t\tfile_filter.set_name(entry)\n\n\t\t\t\t\tfor pattern in extensions[entry]:\n\t\t\t\t\t\tfile_filter.add_pattern(pattern)\n\n\t\t\t\t\tdialog.add_filter(file_filter)\n\n\t\t\tdialog.set_select_multiple(multiple_files)\n\n\t\t\tresponse = dialog.run()\n\n\t\t\tif response == gtk.RESPONSE_OK:\n\t\t\t\treturn dialog.get_filenames()\n\n\t\t\telif response == gtk.RESPONSE_CANCEL:\n\t\t\t\treturn None\n\n\t\t\tdialog.destroy()\n\n\t\tif system.get_name() in ['gnome', 'unity', 'cinnamon', 'pantheon']:\n\t\t\treturn gtk3_dialog()\n\n\t\telif system.get_name() in ['kde', 'lxqt']:\n\t\t\ttry:\n\t\t\t\treturn qt5_dialog()\n\n\t\t\texcept ImportError:\n\t\t\t\treturn gtk3_dialog()\n\n\t\telse:\n\t\t\ttry:\n\t\t\t\treturn gtk2_dialog()\n\n\t\t\texcept ImportError:\n\t\t\t\treturn gtk3_dialog()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a directory for dumping SQL commands.", "response": "def set_dump_directory(base=None, sub_dir=None):\n    \"\"\"Create directory for dumping SQL commands.\"\"\"\n    # Set current timestamp\n    timestamp = datetime.fromtimestamp(time()).strftime('%Y-%m-%d %H-%M-%S')\n\n    # Clean sub_dir\n    if sub_dir and '.' in sub_dir:\n        sub_dir = sub_dir.rsplit('.', 1)[0]\n\n    # Create a directory to save fail SQL scripts\n    # TODO: Replace with function that recursively creates directories until path exists\n    if not os.path.exists(base):\n        os.mkdir(base)\n    dump_dir = os.path.join(base, sub_dir) if sub_dir else base\n    if not os.path.exists(dump_dir):\n        os.mkdir(dump_dir)\n    dump_dir = os.path.join(dump_dir, timestamp)\n    if not os.path.exists(dump_dir):\n        os.mkdir(dump_dir)\n        return dump_dir"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_commands(commands, directory=None, sub_dir=None):\n    print('\\t' + str(len(commands)), 'failed commands')\n\n    # Create dump_dir directory\n    if directory and os.path.isfile(directory):\n        dump_dir = set_dump_directory(os.path.dirname(directory), sub_dir)\n        return_dir = dump_dir\n    elif directory:\n        dump_dir = set_dump_directory(directory, sub_dir)\n        return_dir = dump_dir\n    else:\n        dump_dir = TemporaryDirectory().name\n        return_dir = TemporaryDirectory()\n\n    # Create list of (path, content) tuples\n    command_filepath = [(fail, os.path.join(dump_dir, str(count) + '.sql')) for count, fail in enumerate(commands)]\n\n    # Dump failed commands to text file in the same directory as the commands\n    # Utilize's multiprocessing module if it is available\n    timer = Timer()\n    if MULTIPROCESS:\n        pool = Pool(cpu_count())\n        pool.map(write_text_tup, command_filepath)\n        pool.close()\n        print('\\tDumped ', len(command_filepath), 'commands\\n\\t\\tTime      : {0}'.format(timer.end),\n              '\\n\\t\\tMethod    : (multiprocessing)\\n\\t\\tDirectory : {0}'.format(dump_dir))\n    else:\n        for tup in command_filepath:\n            write_text_tup(tup)\n        print('\\tDumped ', len(command_filepath), 'commands\\n\\t\\tTime      : {0}'.format(timer.end),\n              '\\n\\t\\tMethod    : (sequential)\\n\\t\\tDirectory : {0}'.format(dump_dir))\n\n    # Return base directory of dumped commands\n    return return_dir", "response": "Dump failed commands to. sql files."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_text(_command, txt_file):\n    command = _command.strip()\n    with open(txt_file, 'w') as txt:\n        txt.writelines(command)", "response": "Dump SQL command to a text file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_commands_from_dir(directory, zip_backup=True, remove_dir=True):\n    # Get SQL commands file paths\n    failed_scripts = sorted([os.path.join(directory, fn) for fn in os.listdir(directory) if fn.endswith('.sql')])\n\n    # Read each failed SQL file and append contents to a list\n    print('\\tReading SQL scripts from files')\n    commands = []\n    for sql_file in failed_scripts:\n        with open(sql_file, 'r') as txt:\n            sql_command = txt.read()\n        commands.append(sql_command)\n\n    # Remove most recent failures folder after reading\n    if zip_backup:\n        ZipBackup(directory).backup()\n    if remove_dir:\n        shutil.rmtree(directory)\n    return commands", "response": "Traverse a directory and read contained SQL files and return a list of SQL commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary that contains the blueprint support for this object", "response": "def blueprint(self):\n        \"\"\"\n        blueprint support, returns a partial dictionary\n        \"\"\"\n\n        blueprint = dict()\n        blueprint['type'] = \"%s.%s\" % (self.__module__, self.__class__.__name__)\n\n        # Fields\n        fields = dict()\n\n        # inspects the attributes of a parameter set and tries to validate the input\n        for attribute_name, type_instance in self.getmembers():\n\n            # must be one of the following types\n            if not isinstance(type_instance, String) and \\\n               not isinstance(type_instance, Float) and \\\n               not isinstance(type_instance, Integer) and \\\n               not isinstance(type_instance, Date) and \\\n               not isinstance(type_instance, DateTime) and \\\n               not isinstance(type_instance, Array):\n                raise TypeError(\"%s should be instance of\\\n                 prestans.types.String/Integer/Float/Date/DateTime/Array\" % attribute_name)\n\n            if isinstance(type_instance, Array):\n                if not isinstance(type_instance.element_template, String) and \\\n                   not isinstance(type_instance.element_template, Float) and \\\n                   not isinstance(type_instance.element_template, Integer):\n                    raise TypeError(\"%s should be instance of \\\n                        prestans.types.String/Integer/Float/Array\" % attribute_name)\n\n            fields[attribute_name] = type_instance.blueprint()\n\n        blueprint['fields'] = fields\n        return blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate(self, request):\n\n        validated_parameter_set = self.__class__()\n\n        # Inspects the attributes of a parameter set and tries to validate the input\n        for attribute_name, type_instance in self.getmembers():\n\n            #: Must be one of the following types\n            if not isinstance(type_instance, String) and \\\n               not isinstance(type_instance, Float) and \\\n               not isinstance(type_instance, Integer) and \\\n               not isinstance(type_instance, Date) and \\\n               not isinstance(type_instance, DateTime) and \\\n               not isinstance(type_instance, Array):\n                raise TypeError(\"%s should be of type \\\n                    prestans.types.String/Integer/Float/Date/DateTime/Array\" % attribute_name)\n\n            if issubclass(type_instance.__class__, Array):\n\n                if not isinstance(type_instance.element_template, String) and \\\n                   not isinstance(type_instance.element_template, Float) and \\\n                   not isinstance(type_instance.element_template, Integer):\n                    raise TypeError(\"%s elements should be of \\\n                        type prestans.types.String/Integer/Float\" % attribute_name)\n\n            try:\n\n                #: Get input from parameters\n                #: Empty list returned if key is missing for getall\n                if issubclass(type_instance.__class__, Array):\n                    validation_input = request.params.getall(attribute_name)\n                #: Key error thrown if key is missing for getone\n                else:\n                    try:\n                        validation_input = request.params.getone(attribute_name)\n                    except KeyError:\n                        validation_input = None\n\n                #: Validate input based on data type rules,\n                #: raises DataTypeValidationException if validation fails\n                validation_result = type_instance.validate(validation_input)\n\n                setattr(validated_parameter_set, attribute_name, validation_result)\n\n            except exception.DataValidationException as exp:\n                raise exception.ValidationError(\n                    message=str(exp),\n                    attribute_name=attribute_name,\n                    value=validation_input,\n                    blueprint=type_instance.blueprint())\n\n        return validated_parameter_set", "response": "Validate the input parameter set for the current request object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_methods(cls, subclass):  # pylint: disable=too-many-branches\n\n    for meth, methobj in cls.__abstractmethods__.items():\n\n        # Need to get attribute from dictionary for instance tests to work\n        for base in subclass.__mro__:  # pragma: no branch\n            if meth in base.__dict__:\n                submethobj = base.__dict__[meth]\n                break\n\n        # If we found our abstract method, we didn't find anything\n        if submethobj is methobj:\n            submethobj = UNDEFINED\n\n        # Determine if we have the right method type\n        result = None\n        bad_arg_spec = 'Argument spec does not match parent for method %s'\n\n        # pylint: disable=deprecated-method\n        if isinstance(methobj, property):\n            if submethobj is UNDEFINED or not isinstance(submethobj, property):\n                result = Result(False, 'Does not contain required property (%s)' % meth, 210)\n\n        elif isinstance(methobj, staticmethod):\n            if submethobj is UNDEFINED or not isinstance(submethobj, staticmethod):\n                result = Result(False, 'Does not contain required static method (%s)' % meth, 211)\n            elif PY26:  # pragma: no cover\n                if getfullargspec(methobj.__get__(True)) != \\\n                   getfullargspec(submethobj.__get__(True)):\n                    result = Result(False, bad_arg_spec % meth, 220)\n            elif getfullargspec(methobj.__func__) != getfullargspec(submethobj.__func__):\n                result = Result(False, bad_arg_spec % meth, 220)\n\n        elif isinstance(methobj, classmethod):\n            if submethobj is UNDEFINED or not isinstance(submethobj, classmethod):\n                result = Result(False, 'Does not contain required class method (%s)' % meth, 212)\n            elif PY26:  # pragma: no cover\n                if getfullargspec(methobj.__get__(True).__func__) != \\\n                   getfullargspec(submethobj.__get__(True).__func__):\n                    result = Result(False, bad_arg_spec % meth, 220)\n            elif getfullargspec(methobj.__func__) != getfullargspec(submethobj.__func__):\n                result = Result(False, bad_arg_spec % meth, 220)\n\n        elif isfunction(methobj):\n            if submethobj is UNDEFINED or not isfunction(submethobj):\n                result = Result(False, 'Does not contain required method (%s)' % meth, 213)\n            elif getfullargspec(methobj) != getfullargspec(submethobj):\n                result = Result(False, bad_arg_spec % meth, 220)\n\n        # If it's not a type we're specifically checking, just check for existence\n        elif submethobj is UNDEFINED:\n            result = Result(False, 'Does not contain required attribute (%s)' % meth, 214)\n\n        if result:\n            return result\n\n    return Result(True, None, 0)", "response": "Checks if the class has all abstract methods defined in subclass."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _inspect_class(cls, subclass):\n\n    if callable(subclass._skipload_):\n\n        result = subclass._skipload_()\n\n        if isinstance(result, tuple):\n            skip, msg = result\n        else:\n            skip, msg = result, None\n\n        if skip:\n            return Result(False, msg, 156)\n\n    elif subclass._skipload_:\n        return Result(False, 'Skipload flag is True', 50)\n\n    return _check_methods(cls, subclass)", "response": "Inspects a class for inclusion of a sequence of objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the version of the current object.", "response": "def version(cls):  # noqa: N805  # pylint: disable=no-self-argument\n        \"\"\"\n        :py:class:Returns `str` -- Returns :attr:`_version_` if set,\n        otherwise falls back to module `__version__` or None\n        \"\"\"\n        return cls._version_ or getattr(sys.modules.get(cls.__module__, None),\n                                        '__version__', None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering all pages before the first application request.", "response": "def preload_pages():\n    \"\"\"Register all pages before the first application request.\"\"\"\n    try:\n        _add_url_rule([page.url for page in Page.query.all()])\n    except Exception:  # pragma: no cover\n        current_app.logger.warn('Pages were not loaded.')\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_page(path):\n    try:\n        page = Page.get_by_url(request.path)\n    except NoResultFound:\n        abort(404)\n\n    return render_template(\n        [page.template_name, current_app.config['PAGES_DEFAULT_TEMPLATE']],\n        page=page)", "response": "Internal interface to the page view."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_not_found(exception, **extra):\n    assert isinstance(exception, NotFound)\n\n    page = Page.query.filter(db.or_(Page.url == request.path,\n                                    Page.url == request.path + \"/\")).first()\n\n    if page:\n        _add_url_rule(page.url)\n        return render_template(\n            [\n                page.template_name,\n                current_app.config['PAGES_DEFAULT_TEMPLATE']\n            ],\n            page=page\n        )\n    elif 'wrapped' in extra:\n        return extra['wrapped'](exception)\n    else:\n        return exception", "response": "Custom blueprint exception handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_url_rule(url_or_urls):\n    old = current_app._got_first_request\n    # This is bit of cheating to overcome @flask.app.setupmethod decorator.\n    current_app._got_first_request = False\n    if isinstance(url_or_urls, six.string_types):\n        url_or_urls = [url_or_urls]\n    map(lambda url: current_app.add_url_rule(url, 'invenio_pages.view', view),\n        url_or_urls)\n    current_app._got_first_request = old", "response": "Register URL rule to application URL map."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting members of a given collaboration. Returns a list of members of a given collaboration.", "response": "def list_members_of_collaboration(self, id, include=None):\r\n        \"\"\"\r\n        List members of a collaboration.\r\n\r\n        List the collaborators of a given collaboration\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- \"collaborator_lti_id\": Optional information to include with each member.\r\n          Represents an identifier to be used for the member in an LTI context.\r\n        - \"avatar_image_url\": Optional information to include with each member.\r\n          The url for the avatar of a collaborator with type 'user'.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"collaborator_lti_id\", \"avatar_image_url\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/collaborations/{id}/members with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/collaborations/{id}/members\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of discussion topics for the given course or group.", "response": "def list_discussion_topics_courses(self, course_id, exclude_context_module_locked_topics=None, include=None, only_announcements=None, order_by=None, scope=None, search_term=None):\r\n        \"\"\"\r\n        List discussion topics.\r\n\r\n        Returns the paginated list of discussion topics for this course or group.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"If \"all_dates\" is passed, all dates associated with graded discussions'\r\n        assignments will be included.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"all_dates\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - order_by\r\n        \"\"\"Determines the order of the discussion topic list. Defaults to \"position\".\"\"\"\r\n        if order_by is not None:\r\n            self._validate_enum(order_by, [\"position\", \"recent_activity\"])\r\n            params[\"order_by\"] = order_by\r\n\r\n        # OPTIONAL - scope\r\n        \"\"\"Only return discussion topics in the given state(s). Defaults to including\r\n        all topics. Filtering is done after pagination, so pages\r\n        may be smaller than requested if topics are filtered.\r\n        Can pass multiple states as comma separated string.\"\"\"\r\n        if scope is not None:\r\n            self._validate_enum(scope, [\"locked\", \"unlocked\", \"pinned\", \"unpinned\"])\r\n            params[\"scope\"] = scope\r\n\r\n        # OPTIONAL - only_announcements\r\n        \"\"\"Return announcements instead of discussion topics. Defaults to false\"\"\"\r\n        if only_announcements is not None:\r\n            params[\"only_announcements\"] = only_announcements\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial title of the discussion topics to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - exclude_context_module_locked_topics\r\n        \"\"\"For students, exclude topics that are locked by module progression.\r\n        Defaults to false.\"\"\"\r\n        if exclude_context_module_locked_topics is not None:\r\n            params[\"exclude_context_module_locked_topics\"] = exclude_context_module_locked_topics\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/discussion_topics with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/discussion_topics\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_new_discussion_topic_courses(self, course_id, allow_rating=None, assignment=None, attachment=None, delayed_post_at=None, discussion_type=None, group_category_id=None, is_announcement=None, lock_at=None, message=None, only_graders_can_rate=None, pinned=None, podcast_enabled=None, podcast_has_student_posts=None, position_after=None, published=None, require_initial_post=None, sort_by_rating=None, title=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - title\r\n        \"\"\"no description\"\"\"\r\n        if title is not None:\r\n            data[\"title\"] = title\r\n\r\n        # OPTIONAL - message\r\n        \"\"\"no description\"\"\"\r\n        if message is not None:\r\n            data[\"message\"] = message\r\n\r\n        # OPTIONAL - discussion_type\r\n        \"\"\"The type of discussion. Defaults to side_comment if not value is given. Accepted values are 'side_comment', for discussions that only allow one level of nested comments, and 'threaded' for fully threaded discussions.\"\"\"\r\n        if discussion_type is not None:\r\n            self._validate_enum(discussion_type, [\"side_comment\", \"threaded\"])\r\n            data[\"discussion_type\"] = discussion_type\r\n\r\n        # OPTIONAL - published\r\n        \"\"\"Whether this topic is published (true) or draft state (false). Only\r\n        teachers and TAs have the ability to create draft state topics.\"\"\"\r\n        if published is not None:\r\n            data[\"published\"] = published\r\n\r\n        # OPTIONAL - delayed_post_at\r\n        \"\"\"If a timestamp is given, the topic will not be published until that time.\"\"\"\r\n        if delayed_post_at is not None:\r\n            data[\"delayed_post_at\"] = delayed_post_at\r\n\r\n        # OPTIONAL - lock_at\r\n        \"\"\"If a timestamp is given, the topic will be scheduled to lock at the\r\n        provided timestamp. If the timestamp is in the past, the topic will be\r\n        locked.\"\"\"\r\n        if lock_at is not None:\r\n            data[\"lock_at\"] = lock_at\r\n\r\n        # OPTIONAL - podcast_enabled\r\n        \"\"\"If true, the topic will have an associated podcast feed.\"\"\"\r\n        if podcast_enabled is not None:\r\n            data[\"podcast_enabled\"] = podcast_enabled\r\n\r\n        # OPTIONAL - podcast_has_student_posts\r\n        \"\"\"If true, the podcast will include posts from students as well. Implies\r\n        podcast_enabled.\"\"\"\r\n        if podcast_has_student_posts is not None:\r\n            data[\"podcast_has_student_posts\"] = podcast_has_student_posts\r\n\r\n        # OPTIONAL - require_initial_post\r\n        \"\"\"If true then a user may not respond to other replies until that user has\r\n        made an initial reply. Defaults to false.\"\"\"\r\n        if require_initial_post is not None:\r\n            data[\"require_initial_post\"] = require_initial_post\r\n\r\n        # OPTIONAL - assignment\r\n        \"\"\"To create an assignment discussion, pass the assignment parameters as a\r\n        sub-object. See the {api:AssignmentsApiController#create Create an Assignment API}\r\n        for the available parameters. The name parameter will be ignored, as it's\r\n        taken from the discussion title. If you want to make a discussion that was\r\n        an assignment NOT an assignment, pass set_assignment = false as part of\r\n        the assignment object\"\"\"\r\n        if assignment is not None:\r\n            data[\"assignment\"] = assignment\r\n\r\n        # OPTIONAL - is_announcement\r\n        \"\"\"If true, this topic is an announcement. It will appear in the\r\n        announcement's section rather than the discussions section. This requires\r\n        announcment-posting permissions.\"\"\"\r\n        if is_announcement is not None:\r\n            data[\"is_announcement\"] = is_announcement\r\n\r\n        # OPTIONAL - pinned\r\n        \"\"\"If true, this topic will be listed in the \"Pinned Discussion\" section\"\"\"\r\n        if pinned is not None:\r\n            data[\"pinned\"] = pinned\r\n\r\n        # OPTIONAL - position_after\r\n        \"\"\"By default, discussions are sorted chronologically by creation date, you\r\n        can pass the id of another topic to have this one show up after the other\r\n        when they are listed.\"\"\"\r\n        if position_after is not None:\r\n            data[\"position_after\"] = position_after\r\n\r\n        # OPTIONAL - group_category_id\r\n        \"\"\"If present, the topic will become a group discussion assigned\r\n        to the group.\"\"\"\r\n        if group_category_id is not None:\r\n            data[\"group_category_id\"] = group_category_id\r\n\r\n        # OPTIONAL - allow_rating\r\n        \"\"\"If true, users will be allowed to rate entries.\"\"\"\r\n        if allow_rating is not None:\r\n            data[\"allow_rating\"] = allow_rating\r\n\r\n        # OPTIONAL - only_graders_can_rate\r\n        \"\"\"If true, only graders will be allowed to rate entries.\"\"\"\r\n        if only_graders_can_rate is not None:\r\n            data[\"only_graders_can_rate\"] = only_graders_can_rate\r\n\r\n        # OPTIONAL - sort_by_rating\r\n        \"\"\"If true, entries will be sorted by rating.\"\"\"\r\n        if sort_by_rating is not None:\r\n            data[\"sort_by_rating\"] = sort_by_rating\r\n\r\n        # OPTIONAL - attachment\r\n        \"\"\"A multipart/form-data form-field-style attachment.\r\n        Attachments larger than 1 kilobyte are subject to quota restrictions.\"\"\"\r\n        if attachment is not None:\r\n            data[\"attachment\"] = attachment\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/discussion_topics with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/discussion_topics\".format(**path), data=data, params=params, no_data=True)", "response": "Creates a new discussion topic for the given course."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_topic_groups(self, group_id, topic_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - topic_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"topic_id\"] = topic_id\r\n\r\n        self.logger.debug(\"DELETE /api/v1/groups/{group_id}/discussion_topics/{topic_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"DELETE\", \"/api/v1/groups/{group_id}/discussion_topics/{topic_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Delete a topic group. Deletes the discussion topic and assignment. This will also delete the assignment discussion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reorder_pinned_topics_courses(self, order, course_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - order\r\n        \"\"\"The ids of the pinned discussion topics in the desired order.\r\n        (For example, \"order=104,102,103\".)\"\"\"\r\n        data[\"order\"] = order\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/discussion_topics/reorder with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/discussion_topics/reorder\".format(**path), data=data, params=params, no_data=True)", "response": "Reorder pinned topics. Reorder pinned discussion topics in the specified order."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reorder_pinned_topics_groups(self, order, group_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - order\r\n        \"\"\"The ids of the pinned discussion topics in the desired order.\r\n        (For example, \"order=104,102,103\".)\"\"\"\r\n        data[\"order\"] = order\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/discussion_topics/reorder with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/discussion_topics/reorder\".format(**path), data=data, params=params, no_data=True)", "response": "Reorder pinned topics in a group. Reorders the pinned discussion topics in the specified order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef post_entry_courses(self, topic_id, course_id, attachment=None, message=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - topic_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"topic_id\"] = topic_id\r\n\r\n        # OPTIONAL - message\r\n        \"\"\"The body of the entry.\"\"\"\r\n        if message is not None:\r\n            data[\"message\"] = message\r\n\r\n        # OPTIONAL - attachment\r\n        \"\"\"a multipart/form-data form-field-style\r\n        attachment. Attachments larger than 1 kilobyte are subject to quota\r\n        restrictions.\"\"\"\r\n        if attachment is not None:\r\n            data[\"attachment\"] = attachment\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/discussion_topics/{topic_id}/entries with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/discussion_topics/{topic_id}/entries\".format(**path), data=data, params=params, no_data=True)", "response": "Post an entry in a discussion topic. Returns a json representation of the created entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post_reply_groups(self, group_id, topic_id, entry_id, attachment=None, message=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - topic_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"topic_id\"] = topic_id\r\n\r\n        # REQUIRED - PATH - entry_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"entry_id\"] = entry_id\r\n\r\n        # OPTIONAL - message\r\n        \"\"\"The body of the entry.\"\"\"\r\n        if message is not None:\r\n            data[\"message\"] = message\r\n\r\n        # OPTIONAL - attachment\r\n        \"\"\"a multipart/form-data form-field-style\r\n        attachment. Attachments larger than 1 kilobyte are subject to quota\r\n        restrictions.\"\"\"\r\n        if attachment is not None:\r\n            data[\"attachment\"] = attachment\r\n\r\n        self.logger.debug(\"POST /api/v1/groups/{group_id}/discussion_topics/{topic_id}/entries/{entry_id}/replies with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/groups/{group_id}/discussion_topics/{topic_id}/entries/{entry_id}/replies\".format(**path), data=data, params=params, no_data=True)", "response": "Post a reply to an entry in a discussion topic. Returns a json object containing the created reply."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrate a discussion entry. Rate a discussion entry.", "response": "def rate_entry_courses(self, topic_id, entry_id, course_id, rating=None):\r\n        \"\"\"\r\n        Rate entry.\r\n\r\n        Rate a discussion entry.\r\n        \r\n        On success, the response will be 204 No Content with an empty body.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - topic_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"topic_id\"] = topic_id\r\n\r\n        # REQUIRED - PATH - entry_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"entry_id\"] = entry_id\r\n\r\n        # OPTIONAL - rating\r\n        \"\"\"A rating to set on this entry. Only 0 and 1 are accepted.\"\"\"\r\n        if rating is not None:\r\n            data[\"rating\"] = rating\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/discussion_topics/{topic_id}/entries/{entry_id}/rating with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/discussion_topics/{topic_id}/entries/{entry_id}/rating\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlaunches command using supervisor or screen / tmux", "response": "def cli(**settings):\n    \"\"\"Notify about new reviews in AppStore and Google Play in slack.\n\n       Launch command using supervisor or using screen/tmux/etc.\n       Reviews are fetched for multiple apps and languages in --beat=300 interval.\n    \"\"\"\n    setup_logging(settings)\n    settings = setup_languages(settings)\n    channels = setup_channel_map(settings)\n    app = CriticApp(**dict(settings, channels=channels))\n    if settings['sentry_dsn']:\n        app.sentry_client = Client(settings['sentry_dsn'])\n        logger.debug('Errors are reported to %s' % settings['sentry_dsn'])\n    else:\n        app.sentry_client = None\n\n    if settings['version']:\n        click.echo('Version %s' % critics.__version__)\n        return\n    if not (settings['ios'] or settings['android']):\n        click.echo('Please choose either --ios or --android')\n        return\n\n    loop = tornado.ioloop.IOLoop.instance()\n\n    if app.load_model():\n        logger.debug('Model loaded OK, not skipping notify on first run')\n        notify = True\n    else:\n        notify = False\n\n    if settings['ios']:\n        logger.info('Tracking IOS apps: %s', ', '.join(settings['ios']))\n        itunes = tornado.ioloop.PeriodicCallback(partial(app.poll_store, 'ios'),\n                                                 1000 * settings['beat'], loop)\n        itunes.start()\n    if settings['android']:\n        logger.info('Tracking Android apps: %s', ', '.join(settings['android']))\n        google_play = tornado.ioloop.PeriodicCallback(partial(app.poll_store, 'android'),\n                                                      1000 * settings['beat'], loop)\n        google_play.start()\n\n    echo_channel_map(channels)\n\n    if settings['ios']:\n        app.poll_store('ios', notify=notify)\n    if settings['android']:\n        app.poll_store('android', notify=notify)\n\n    if settings['stats']:\n        port = int(settings['stats'])\n        logger.debug('Serving metrics server on port %s' % port)\n        start_http_server(port)\n\n    if settings['daemonize']:\n        loop.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_fa(self):\n\n        if self._seqs is None:\n            os.symlink(self._fa0_fn, self._fa_fn)\n        else:\n            in_seqs = pyfaidx.Fasta(self._fa0_fn)\n\n            with open(self._fa_fn, \"w+\") as g:\n                for seq_desc in self._seqs:\n                    x = in_seqs[seq_desc]\n                    name, seq = x.name, str(x)\n                    g.write(\">\" + name + \"\\n\")\n                    n = 80\n                    seq_split = \"\\n\".join([seq[i:i + n] for i in range(0, len(seq), n)])\n                    g.write(seq_split + \"\\n\")", "response": "Create a FASTA file with extracted sequences."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recode_sam_reads(\n        sam_fn,\n        fastq_rnf_fo,\n        fai_fo,\n        genome_id,\n        number_of_read_tuples=10**9,\n        simulator_name=None,\n        allow_unmapped=False,\n    ):\n        \"\"\"Transform a SAM file to RNF-compatible FASTQ.\n\n\t\tArgs:\n\t\t\tsam_fn (str): SAM/BAM file - file name.\n\t\t\tfastq_rnf_fo (str): Output FASTQ file - file object.\n\t\t\tfai_fo (str): FAI index of the reference genome - file object.\n\t\t\tgenome_id (int): Genome ID for RNF.\n\t\t\tnumber_of_read_tuples (int): Expected number of read tuples (to set width of read tuple id).\n\t\t\tsimulator_name (str): Name of the simulator. Used for comment in read tuple name.\n\t\t\tallow_unmapped (bool): Allow unmapped reads.\n\n\t\tRaises:\n\t\t\tNotImplementedError\n\t\t\"\"\"\n\n        fai_index = rnftools.utils.FaIdx(fai_fo)\n        # last_read_tuple_name=[]\n        read_tuple_id_width = len(format(number_of_read_tuples, 'x'))\n        fq_creator = rnftools.rnfformat.FqCreator(\n            fastq_fo=fastq_rnf_fo,\n            read_tuple_id_width=read_tuple_id_width,\n            genome_id_width=2,\n            chr_id_width=fai_index.chr_id_width,\n            coor_width=fai_index.coor_width,\n            info_reads_in_tuple=True,\n            info_simulator=simulator_name,\n        )\n\n        # todo: check if clipping corrections is well implemented\n        cigar_reg_shift = re.compile(\"([0-9]+)([MDNP=X])\")\n\n        # todo: other upac codes\n        reverse_complement_dict = {\n            \"A\": \"T\",\n            \"T\": \"A\",\n            \"C\": \"G\",\n            \"G\": \"C\",\n            \"N\": \"N\",\n        }\n\n        read_tuple_id = 0\n        last_read_tuple_name = None\n        with pysam.AlignmentFile(\n            sam_fn,\n            check_header=False,\n        ) as samfile:\n            for alignment in samfile:\n                if alignment.query_name != last_read_tuple_name and last_read_tuple_name is not None:\n                    read_tuple_id += 1\n                last_read_tuple_name = alignment.query_name\n\n                if alignment.is_unmapped:\n                    rnftools.utils.error(\n                        \"SAM files used for conversion should not contain unaligned segments. \"\n                        \"This condition is broken by read tuple \"\n                        \"'{}' in file '{}'.\".format(alignment.query_name, sam_fn),\n                        program=\"RNFtools\",\n                        subprogram=\"MIShmash\",\n                        exception=NotImplementedError,\n                    )\n\n                if alignment.is_reverse:\n                    direction = \"R\"\n                    bases = \"\".join([reverse_complement_dict[nucl] for nucl in alignment.seq[::-1]])\n                    qualities = str(alignment.qual[::-1])\n                else:\n                    direction = \"F\"\n                    bases = alignment.seq[:]\n                    qualities = str(alignment.qual[:])\n\n                # todo: are chromosomes in bam sorted correctly (the same order as in FASTA)?\n                if fai_index.dict_chr_ids != {}:\n                    chr_id = fai_index.dict_chr_ids[samfile.getrname(alignment.reference_id)]\n                else:\n                    chr_id = \"0\"\n\n                left = int(alignment.reference_start) + 1\n                right = left - 1\n                for (steps, operation) in cigar_reg_shift.findall(alignment.cigarstring):\n                    right += int(steps)\n\n                segment = rnftools.rnfformat.Segment(\n                    genome_id=genome_id,\n                    chr_id=chr_id,\n                    direction=direction,\n                    left=left,\n                    right=right,\n                )\n\n                fq_creator.add_read(\n                    read_tuple_id=read_tuple_id,\n                    bases=bases,\n                    qualities=qualities,\n                    segments=[segment],\n                )\n        fq_creator.flush_read_tuple()", "response": "Transform a SAM file to RNF - compatible FASTQ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncompiles a regex for a resource.", "response": "def compile_resource(resource):\n    \"\"\"\n    Return compiled regex for resource matching\n    \"\"\"\n    return re.compile(\"^\" + trim_resource(re.sub(r\":(\\w+)\", r\"(?P<\\1>[\\w-]+?)\",\n                      resource)) + r\"(\\?(?P<querystring>.*))?$\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dispatch(self, message):\n        handlers = []\n        for handler in self.handlers:\n            if handler[\"method\"] != message.method:\n                continue\n\n            handlers.append(handler)\n        return handlers", "response": "Dispatches a message to the list of handlers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef route(self, resource):\n        route = self.routes.get(resource, Route(resource))\n        self.routes.update({resource: route})\n        return route", "response": "Returns the route for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_route_func(self, method):\n        def _route(resource, handler, schema=None):\n            \"\"\"\n            _route\n            \"\"\"\n            route = self.routes.get(resource, Route(resource))\n            route.__getattribute__(method)(handler, schema)\n            self.routes.update({resource: route})\n            return self\n\n        return _route", "response": "create_route_func returns a function that will update the route with the given method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndispatches a message to all routes and return a list of the result.", "response": "def dispatch(self, message):\n        \"\"\"\n        dispatch\n        \"\"\"\n        results = []\n        # match routes\n        for resource, route in self.routes.items():\n            __message = message.match(route)\n            if __message is None:\n                continue\n\n            route_result = route.dispatch(__message)\n            if len(route_result) == 0:\n                continue\n\n            results.append({\n                \"handlers\": route_result,\n                \"message\": __message\n            })\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting all data handlers for the specified data type and return the result of the handlers", "response": "def handle(data_type, data, data_id=None, caller=None):\n    \"\"\"\n    execute all data handlers on the specified data according to data type\n\n    Args:\n        data_type (str): data type handle\n        data (dict or list): data\n\n    Kwargs:\n        data_id (str): can be used to differentiate between different data\n            sets of the same data type. If not specified will default to\n            the data type\n        caller (object): if specified, holds the object or function that\n            is trying to handle data\n\n    Returns:\n        dict or list - data after handlers have been executed on it\n    \"\"\"\n\n    if not data_id:\n        data_id = data_type\n\n    # instantiate handlers for data type if they havent been yet\n    if data_id not in _handlers:\n        _handlers[data_id] = dict(\n            [(h.handle, h) for h in handlers.instantiate_for_data_type(data_type, data_id=data_id)])\n\n    for handler in list(_handlers[data_id].values()):\n        try:\n            data = handler(data, caller=caller)\n        except Exception as inst:\n            vodka.log.error(\"Data handler '%s' failed with error\" % handler)\n            vodka.log.error(traceback.format_exc())\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfirming query exists given common filters.", "response": "def validate_query(self, query):\n        \"\"\"Confirm query exists given common filters.\"\"\"\n        if query is None:\n            return query\n        query = self.update_reading_list(query)\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_validated_augment_query(self, augment_query=None):\n        augment_query = self.validate_query(augment_query)\n\n        # Given an invalid query, reach for a Sponsored query.\n        if not augment_query:\n            augment_query = self.validate_query(Content.search_objects.sponsored())\n\n        # Given an invalid Sponsored query, reach for a Video query.\n        if not augment_query:\n            reading_list_config = getattr(settings, \"READING_LIST_CONFIG\", {})\n            excluded_channel_ids = reading_list_config.get(\"excluded_channel_ids\", [])\n            augment_query = self.validate_query(Content.search_objects.evergreen_video(\n                excluded_channel_ids=excluded_channel_ids\n            ))\n\n        return augment_query", "response": "Validate an augment query."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply injected logic for slicing reading lists with additional content.", "response": "def augment_reading_list(self, primary_query, augment_query=None, reverse_negate=False):\n        \"\"\"Apply injected logic for slicing reading lists with additional content.\"\"\"\n        primary_query = self.validate_query(primary_query)\n        augment_query = self.get_validated_augment_query(augment_query=augment_query)\n\n        try:\n            # We use this for cases like recent where queries are vague.\n            if reverse_negate:\n                primary_query = primary_query.filter(NegateQueryFilter(augment_query))\n            else:\n                augment_query = augment_query.filter(NegateQueryFilter(primary_query))\n            augment_query = randomize_es(augment_query)\n            return FirstSlotSlicer(primary_query, augment_query)\n        except TransportError:\n            return primary_query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_reading_list_context(self, **kwargs):\n        reading_list = None\n        context = {\n            \"name\": \"\",\n            \"content\": reading_list,\n            \"targeting\": {},\n            \"videos\": []\n        }\n\n        if self.reading_list_identifier == \"popular\":\n            reading_list = popular_content()\n            context.update({\"name\": self.reading_list_identifier})\n\n            # Popular is augmented.\n            reading_list = self.augment_reading_list(reading_list)\n            context.update({\"content\": reading_list})\n            return context\n\n        if self.reading_list_identifier.startswith(\"specialcoverage\"):\n            special_coverage = SpecialCoverage.objects.get_by_identifier(\n                self.reading_list_identifier\n            )\n            reading_list = special_coverage.get_content().query(\n                SponsoredBoost(field_name=\"tunic_campaign_id\")\n            ).sort(\"_score\", \"-published\")\n            context[\"targeting\"][\"dfp_specialcoverage\"] = special_coverage.slug\n            if special_coverage.tunic_campaign_id:\n                context[\"tunic_campaign_id\"] = special_coverage.tunic_campaign_id\n                context[\"targeting\"].update({\n                    \"dfp_campaign_id\": special_coverage.tunic_campaign_id\n                })\n                # We do not augment sponsored special coverage lists.\n                reading_list = self.update_reading_list(reading_list)\n            else:\n                reading_list = self.augment_reading_list(reading_list)\n            context.update({\n                \"name\": special_coverage.name,\n                \"videos\": special_coverage.videos,\n                \"content\": reading_list\n            })\n            return context\n\n        if self.reading_list_identifier.startswith(\"section\"):\n            section = Section.objects.get_by_identifier(self.reading_list_identifier)\n            reading_list = section.get_content()\n            reading_list = self.augment_reading_list(reading_list)\n            context.update({\n                \"name\": section.name,\n                \"content\": reading_list\n            })\n            return context\n\n        reading_list = Content.search_objects.search()\n        reading_list = self.augment_reading_list(reading_list, reverse_negate=True)\n        context.update({\n            \"name\": \"Recent News\",\n            \"content\": reading_list\n        })\n        return context", "response": "Returns the context dictionary for a given reading list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading file at path and returns dict with separated frontmatter.", "response": "def read_file(cls, path):\n        \"\"\"Reads file at path and returns dict with separated frontmatter.\n        See read() for more info on dict return value.\n        \"\"\"\n        with open(path, encoding=\"utf-8\") as file:\n            file_contents = file.read()\n            return cls.read(file_contents)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(cls, string):\n        fmatter = \"\"\n        body = \"\"\n        result = cls._regex.search(string)\n\n        if result:\n            fmatter = result.group(1)\n            body = result.group(2)\n        return {\n            \"attributes\": yaml.load(fmatter),\n            \"body\": body,\n            \"frontmatter\": fmatter,\n        }", "response": "Returns dict with separated frontmatter from string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_suite(case, config, summary):\n    config[\"name\"] = case\n    timing_data = dict()\n    model_dir = os.path.join(livvkit.model_dir, config['data_dir'], case)\n    bench_dir = os.path.join(livvkit.bench_dir, config['data_dir'], case)\n    plot_dir = os.path.join(livvkit.output_dir, \"performance\", \"imgs\")\n    model_cases = functions.collect_cases(model_dir)\n    bench_cases = functions.collect_cases(bench_dir)\n    functions.mkdir_p(plot_dir)\n\n    # Generate all of the timing data\n    for subcase in sorted(model_cases):\n        bench_subcases = bench_cases[subcase] if subcase in bench_cases else []\n        timing_data[subcase] = dict()\n        for mcase in model_cases[subcase]:\n            config[\"case\"] = \"-\".join([subcase, mcase])\n            bpath = (os.path.join(bench_dir, subcase, mcase.replace(\"-\", os.path.sep))\n                     if mcase in bench_subcases else None)\n            mpath = os.path.join(model_dir, subcase, mcase.replace(\"-\", os.path.sep))\n            timing_data[subcase][mcase] = _analyze_case(mpath, bpath, config)\n\n    # Create scaling and timing breakdown plots\n    weak_data = weak_scaling(timing_data, config['scaling_var'],\n                             config['weak_scaling_points'])\n    strong_data = strong_scaling(timing_data, config['scaling_var'],\n                                 config['strong_scaling_points'])\n\n    timing_plots = [\n        generate_scaling_plot(weak_data,\n                              \"Weak scaling for \" + case.capitalize(),\n                              \"runtime (s)\", \"\",\n                              os.path.join(plot_dir, case + \"_weak_scaling.png\")\n                              ),\n        weak_scaling_efficiency_plot(weak_data,\n                                     \"Weak scaling efficiency for \" + case.capitalize(),\n                                     \"Parallel efficiency (% of linear)\", \"\",\n                                     os.path.join(plot_dir, case + \"_weak_scaling_efficiency.png\")\n                                     ),\n        generate_scaling_plot(strong_data,\n                              \"Strong scaling for \" + case.capitalize(),\n                              \"Runtime (s)\", \"\",\n                              os.path.join(plot_dir, case + \"_strong_scaling.png\")\n                              ),\n        strong_scaling_efficiency_plot(strong_data,\n                                       \"Strong scaling efficiency for \" + case.capitalize(),\n                                       \"Parallel efficiency (% of linear)\", \"\",\n                                       os.path.join(plot_dir,\n                                                    case + \"_strong_scaling_efficiency.png\")\n                                       ),\n        ]\n\n    timing_plots = timing_plots + \\\n        [generate_timing_breakdown_plot(timing_data[s],\n                                        config['scaling_var'],\n                                        \"Timing breakdown for \" + case.capitalize()+\" \"+s,\n                                        \"\",\n                                        os.path.join(plot_dir, case+\"_\"+s+\"_timing_breakdown.png\")\n                                        )\n         for s in sorted(six.iterkeys(timing_data), key=functions.sort_scale)]\n\n    # Build an image gallery and write the results\n    el = [\n            elements.gallery(\"Performance Plots\", timing_plots)\n         ]\n    result = elements.page(case, config[\"description\"], element_list=el)\n    summary[case] = _summarize_result(timing_data, config)\n    _print_result(case, summary)\n    functions.create_page_from_template(\"performance.html\",\n                                        os.path.join(livvkit.index_dir, \"performance\",\n                                                     case + \".html\"))\n    functions.write_json(result, os.path.join(livvkit.output_dir, \"performance\"),\n                         case + \".json\")", "response": "Run the full suite of performance tests."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _analyze_case(model_dir, bench_dir, config):\n    model_timings = set(glob.glob(os.path.join(model_dir, \"*\" + config[\"timing_ext\"])))\n    if bench_dir is not None:\n        bench_timings = set(glob.glob(os.path.join(bench_dir, \"*\" + config[\"timing_ext\"])))\n    else:\n        bench_timings = set()\n    if not len(model_timings):\n        return dict()\n    model_stats = generate_timing_stats(model_timings, config['timing_vars'])\n    bench_stats = generate_timing_stats(bench_timings, config['timing_vars'])\n    return dict(model=model_stats, bench=bench_stats)", "response": "Generates statistics from the timing summaries"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint some statistics from the run", "response": "def _print_result(case, summary):\n    \"\"\" Show some statistics from the run \"\"\"\n    for case, case_data in summary.items():\n        for dof, data in case_data.items():\n            print(\"    \" + case + \" \" + dof)\n            print(\"    -------------------\")\n            for header, val in data.items():\n                print(\"    \" + header + \" : \" + str(val))\n            print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _summarize_result(result, config):\n    timing_var = config['scaling_var']\n    summary = LIVVDict()\n    for size, res in result.items():\n        proc_counts = []\n        bench_times = []\n        model_times = []\n        for proc, data in res.items():\n            proc_counts.append(int(proc[1:]))\n            try:\n                bench_times.append(data['bench'][timing_var]['mean'])\n            except KeyError:\n                pass\n            try:\n                model_times.append(data['model'][timing_var]['mean'])\n            except KeyError:\n                pass\n        if model_times != [] and bench_times != []:\n            time_diff = np.mean(model_times)/np.mean(bench_times)\n        else:\n            time_diff = 'NA'\n        summary[size]['Proc. Counts'] = \", \".join([str(x) for x in sorted(proc_counts)])\n        summary[size]['Mean Time Diff (% of benchmark)'] = time_diff\n    return summary", "response": "Return a LIVVDict with the data from the result of the index page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_timing_stats(file_list, var_list):\n    timing_result = dict()\n    timing_summary = dict()\n    for file in file_list:\n        timing_result[file] = functions.parse_gptl(file, var_list)\n    for var in var_list:\n        var_time = []\n        for f, data in timing_result.items():\n            try:\n                var_time.append(data[var])\n            except:\n                continue\n        if len(var_time):\n            timing_summary[var] = {'mean': np.mean(var_time),\n                                   'max': np.max(var_time),\n                                   'min': np.min(var_time),\n                                   'std': np.std(var_time)}\n    return timing_summary", "response": "Parse all of the timing files and generate some statistics about the run."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates data for plotting weak scaling of the data points in a new language.", "response": "def weak_scaling(timing_stats, scaling_var, data_points):\n    \"\"\"\n    Generate data for plotting weak scaling.  The data points keep\n    a constant amount of work per processor for each data point.\n\n    Args:\n        timing_stats: the result of the generate_timing_stats function\n        scaling_var: the variable to select from the timing_stats dictionary\n                     (can be provided in configurations via the 'scaling_var' key)\n        data_points: the list of size and processor counts to use as data\n                     (can be provided in configurations via the 'weak_scaling_points' key)\n\n    Returns:\n         A dict of the form:\n            {'bench' : {'mins' : [], 'means' : [], 'maxs' : []},\n             'model' : {'mins' : [], 'means' : [], 'maxs' : []},\n             'proc_counts' : []}\n    \"\"\"\n    timing_data = dict()\n    proc_counts = []\n    bench_means = []\n    bench_mins = []\n    bench_maxs = []\n    model_means = []\n    model_mins = []\n    model_maxs = []\n    for point in data_points:\n        size = point[0]\n        proc = point[1]\n        try:\n            model_data = timing_stats[size][proc]['model'][scaling_var]\n            bench_data = timing_stats[size][proc]['bench'][scaling_var]\n        except KeyError:\n            continue\n        proc_counts.append(proc)\n        model_means.append(model_data['mean'])\n        model_mins.append(model_data['min'])\n        model_maxs.append(model_data['max'])\n        bench_means.append(bench_data['mean'])\n        bench_mins.append(bench_data['min'])\n        bench_maxs.append(bench_data['max'])\n    timing_data['bench'] = dict(mins=bench_mins, means=bench_means, maxs=bench_maxs)\n    timing_data['model'] = dict(mins=model_mins, means=model_means, maxs=model_maxs)\n    timing_data['proc_counts'] = [int(pc[1:]) for pc in proc_counts]\n    return timing_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_scaling_plot(timing_data, title, ylabel, description, plot_file):\n    proc_counts = timing_data['proc_counts']\n    if len(proc_counts) > 2:\n        plt.figure(figsize=(10, 8), dpi=150)\n        plt.title(title)\n        plt.xlabel(\"Number of processors\")\n        plt.ylabel(ylabel)\n\n        for case, case_color in zip(['bench', 'model'], ['#91bfdb', '#fc8d59']):\n            case_data = timing_data[case]\n            means = case_data['means']\n            mins = case_data['mins']\n            maxs = case_data['maxs']\n            plt.fill_between(proc_counts, mins, maxs, facecolor=case_color, alpha=0.5)\n            plt.plot(proc_counts, means, 'o-', color=case_color, label=case)\n\n        plt.legend(loc='best')\n    else:\n        plt.figure(figsize=(5, 3))\n        plt.axis('off')\n        plt.text(0.4, 0.8, \"ERROR:\")\n        plt.text(0.0, 0.6, \"Not enough data points to draw scaling plot\")\n        plt.text(0.0, 0.44, \"To generate this data rerun BATS with the\")\n        plt.text(0.0, 0.36, \"performance option enabled.\")\n\n    if livvkit.publish:\n        plt.savefig(os.path.splitext(plot_file)[0]+'.eps', dpi=600)\n    plt.savefig(plot_file)\n    plt.close()\n    return elements.image(title, description, os.path.basename(plot_file))", "response": "Generates a scaling plot for the current process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a timing breakdown plot for the given set of timing stats.", "response": "def generate_timing_breakdown_plot(timing_stats, scaling_var, title, description, plot_file):\n    \"\"\"\n    Description\n\n    Args:\n        timing_stats: a dictionary of the form\n            {proc_count : {model||bench : { var : { stat : val }}}}\n        scaling_var: the variable that accounts for the total runtime\n        title: the title of the plot\n        description: the description of the plot\n        plot_file: the file to write the plot out to\n    Returns:\n        an image element containing the plot file and metadata\n    \"\"\"\n    # noinspection PyProtectedMember\n    cmap_data = colormaps._viridis_data\n    n_subplots = len(six.viewkeys(timing_stats))\n    fig, ax = plt.subplots(1, n_subplots+1, figsize=(3*(n_subplots+2), 5))\n    for plot_num, p_count in enumerate(\n            sorted(six.iterkeys(timing_stats), key=functions.sort_processor_counts)):\n\n        case_data = timing_stats[p_count]\n        all_timers = set(six.iterkeys(case_data['model'])) | set(six.iterkeys(case_data['bench']))\n        all_timers = sorted(list(all_timers), reverse=True)\n        cmap_stride = int(len(cmap_data)/(len(all_timers)+1))\n        colors = {all_timers[i]: cmap_data[i*cmap_stride] for i in range(len(all_timers))}\n\n        sub_ax = plt.subplot(1, n_subplots+1, plot_num+1)\n        sub_ax.set_title(p_count)\n        sub_ax.set_ylabel('Runtime (s)')\n        for case, var_data in case_data.items():\n            if case == 'bench':\n                bar_num = 2\n            else:\n                bar_num = 1\n\n            offset = 0\n            if var_data != {}:\n                for var in sorted(six.iterkeys(var_data), reverse=True):\n                    if var != scaling_var:\n                        plt.bar(bar_num, var_data[var]['mean'], 0.8, bottom=offset,\n                                color=colors[var], label=(var if bar_num == 1 else '_none'))\n                        offset += var_data[var]['mean']\n\n                plt.bar(bar_num, var_data[scaling_var]['mean']-offset, 0.8, bottom=offset,\n                        color=colors[scaling_var], label=(scaling_var if bar_num == 1 else '_none'))\n\n                sub_ax.set_xticks([1.4, 2.4])\n                sub_ax.set_xticklabels(('test', 'bench'))\n\n    plt.legend(loc=6, bbox_to_anchor=(1.05, 0.5))\n    plt.tight_layout()\n\n    sub_ax = plt.subplot(1, n_subplots+1, n_subplots+1)\n    hid_bar = plt.bar(1, 100)\n    for group in hid_bar:\n            group.set_visible(False)\n    sub_ax.set_visible(False)\n\n    if livvkit.publish:\n        plt.savefig(os.path.splitext(plot_file)[0]+'.eps', dpi=600)\n    plt.savefig(plot_file)\n    plt.close()\n    return elements.image(title, description, os.path.basename(plot_file))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_source(self, ra, dec, flag='', radius=10*q.arcsec):\n        # Get the id\n        id = int(len(self.catalog)+1)\n        \n        # Check the coordinates\n        ra = ra.to(q.deg)\n        dec = dec.to(q.deg)\n        datasets = 0\n        \n        # Search the catalogs for this source\n        for cat_name,params in self.catalogs.items():\n            self.Vizier_query(params['cat_loc'], cat_name, ra, dec, radius, ra_col=params['ra_col'], dec_col=params['dec_col'], append=True, group=False)\n            \n        # Add the source to the catalog\n        self.catalog = self.catalog.append([id, ra.value, dec.value, flag, datasets], ignore_index=True)", "response": "Add a source to the catalog manually and find data in existing catalogs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_source(self, id):\n        # Set the index\n        self.catalog.set_index('id')\n        \n        # Exclude the unwanted source\n        self.catalog = self.catalog[self.catalog.id!=id]\n        \n        # Remove the records from the catalogs\n        for cat_name in self.catalogs:\n            new_cat = getattr(self, cat_name)[getattr(self, cat_name).source_id!=id]\n            print('{} records removed from {} catalog'.format(int(len(getattr(self, cat_name))-len(new_cat)), cat_name))\n            setattr(self, cat_name, new_cat)", "response": "Delete a source from the catalog."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ingest_data(self, data, cat_name, id_col, ra_col='_RAJ2000', dec_col='_DEJ2000', cat_loc='', append=False, count=-1):\n        # Check if the catalog is already ingested\n        if not append and cat_name in self.catalogs:\n            \n            print('Catalog {} already ingested.'.format(cat_name))\n            \n        else:\n            \n            if isinstance(data, str):\n                cat_loc = cat_loc or data\n                data = pd.read_csv(data, sep='\\t', comment='#', engine='python')[:count]\n                \n            elif isinstance(data, pd.core.frame.DataFrame):\n                cat_loc = cat_loc or type(data)\n                \n            elif isinstance(data, (at.QTable, at.Table)):\n                cat_loc = cat_loc or type(data)\n                data = pd.DataFrame(list(data), columns=data.colnames)\n                \n            else:\n                print(\"Sorry, but I cannot read that data. Try an ascii file cat_loc, astropy table, or pandas data frame.\")\n                return\n                \n            # Make sure ra and dec are decimal degrees\n            if isinstance(data[ra_col][0], str):\n                \n                crds = coord.SkyCoord(ra=data[ra_col], dec=data[dec_col], unit=(q.hour, q.deg), frame='icrs')\n                data.insert(0,'dec', crds.dec)\n                data.insert(0,'ra', crds.ra)\n                \n            elif isinstance(data[ra_col][0], float):\n                \n                data.rename(columns={ra_col:'ra', dec_col:'dec'}, inplace=True)\n            \n            else:\n                print(\"I can't read the RA and DEC of the input data. Please try again.\")\n                return\n                \n            # Change some names\n            try:\n                last = len(getattr(self, cat_name)) if append else 0\n                data.insert(0,'catID', ['{}_{}'.format(cat_name,n+1) for n in range(last,last+len(data))])\n                data.insert(0,'dec_corr', data['dec'])\n                data.insert(0,'ra_corr', data['ra'])\n                data.insert(0,'source_id', np.nan)\n            \n                print('Ingesting {} rows from {} catalog...'.format(len(data),cat_name))\n            \n                # Save the raw data as an attribute\n                if append:\n                    setattr(self, cat_name, getattr(self, cat_name).append(data, ignore_index=True))\n                \n                else:\n                    setattr(self, cat_name, data)\n                \n                # Update the history\n                self.history += \"\\n{}: Catalog {} ingested.\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),cat_name)\n                self.catalogs.update({cat_name:{'cat_loc':cat_loc, 'id_col':id_col, 'ra_col':ra_col, 'dec_col':dec_col}})\n                \n            except AttributeError:\n                print(\"No catalog named '{}'. Set 'append=False' to create it.\".format(cat_name))", "response": "Ingest a data file and regroup sources of the VizieR."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the inventory for a given source", "response": "def inventory(self, source_id):\n        \"\"\"\n        Look at the inventory for a given source\n        \n        Parameters\n        ----------\n        source_id: int\n            The id of the source to inspect\n        \"\"\"\n        if self.n_sources==0:\n            print('Please run group_sources() to create the catalog first.')\n        \n        else:\n            \n            if source_id>self.n_sources or source_id<1 or not isinstance(source_id, int):\n                print('Please enter an integer between 1 and',self.n_sources)\n            \n            else:\n            \n                print('Source:')\n                print(at.Table.from_pandas(self.catalog[self.catalog['id']==source_id]).pprint())\n                for cat_name in self.catalogs:\n                    cat = getattr(self, cat_name)\n                    rows = cat[cat['source_id']==source_id]\n                    if not rows.empty:\n                        print('\\n{}:'.format(cat_name))\n                        at.Table.from_pandas(rows).pprint()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _catalog_check(self, cat_name, append=False):\n        good = True\n        \n        # Make sure the attribute name is good\n        if cat_name[0].isdigit():\n            print(\"No names beginning with numbers please!\")\n            good = False\n            \n        # Make sure catalog is unique\n        if not append and cat_name in self.catalogs:\n            print(\"Catalog {} already ingested. Set 'append=True' to add more records.\".format(cat_name))\n            good = False\n        \n        return good", "response": "Check to see if the name of the ingested catalog is valid and if not append is True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch SDSS for sources within a given radius of a given catalog.", "response": "def SDSS_spectra_query(self, cat_name, ra, dec, radius, group=True, **kwargs):\n        \"\"\"\n        Use astroquery to search SDSS for sources within a search cone\n        \n        Parameters\n        ----------\n        cat_name: str\n            A name for the imported catalog (e.g. '2MASS')\n        ra: astropy.units.quantity.Quantity\n            The RA of the center of the cone search\n        dec: astropy.units.quantity.Quantity\n            The Dec of the center of the cone search\n        radius: astropy.units.quantity.Quantity\n            The radius of the cone search\n        \"\"\"\n        # Verify the cat_name\n        if self._catalog_check(cat_name):\n            \n            # Prep the current catalog as an astropy.QTable\n            tab = at.Table.from_pandas(self.catalog)\n            \n            # Cone search Vizier\n            print(\"Searching SDSS for sources within {} of ({}, {}). Please be patient...\".format(viz_cat, radius, ra, dec))\n            crds = coord.SkyCoord(ra=ra, dec=dec, frame='icrs')\n            try:\n                data = SDSS.query_region(crds, spectro=True, radius=radius)\n            except:\n                print(\"No data found in SDSS within {} of ({}, {}).\".format(viz_cat, radius, ra, dec))\n                return\n            \n            # Ingest the data\n            self.ingest_data(data, cat_name, 'id', ra_col=ra_col, dec_col=dec_col)\n            \n            # Regroup\n            if len(self.catalogs)>1 and group:\n                self.group_sources(self.xmatch_radius)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Vizier_query(self, viz_cat, cat_name, ra, dec, radius, ra_col='RAJ2000', dec_col='DEJ2000', columns=[\"**\"], append=False, group=True, **kwargs):\n        # Verify the cat_name\n        if self._catalog_check(cat_name, append=append):\n            \n            # Cone search Vizier\n            print(\"Searching {} for sources within {} of ({}, {}). Please be patient...\".format(viz_cat, radius, ra, dec))\n            crds = coord.SkyCoord(ra=ra, dec=dec, frame='icrs')\n            V = Vizier(columns=columns, **kwargs)\n            V.ROW_LIMIT = -1\n            \n            try:\n                data = V.query_region(crds, radius=radius, catalog=viz_cat)[0]\n            except:\n                print(\"No data found in {} within {} of ({}, {}).\".format(viz_cat, radius, ra, dec))\n                return\n            \n            # Ingest the data\n            self.ingest_data(data, cat_name, 'id', ra_col=ra_col, dec_col=dec_col, cat_loc=viz_cat, append=append)\n            \n            # Regroup\n            if len(self.catalogs)>1 and group:\n                self.group_sources(self.xmatch_radius)", "response": "Search a Vizier for sources within a given radius."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Vizier_xmatch(self, viz_cat, cat_name, ra_col='_RAJ2000', dec_col='_DEJ2000', radius='', group=True):\n        # Make sure sources have been grouped\n        if self.catalog.empty:\n            print('Please run group_sources() before cross matching.')\n            return\n            \n        if self._catalog_check(cat_name):\n            \n            # Verify the cat_name\n            viz_cat = \"vizier:{}\".format(viz_cat)\n            \n            # Prep the current catalog as an astropy.QTable\n            tab = at.Table.from_pandas(self.catalog)\n            \n            # Crossmatch with Vizier\n            print(\"Cross matching {} sources with {} catalog. Please be patient...\".format(len(tab), viz_cat))\n            data = XMatch.query(cat1=tab, cat2=viz_cat, max_distance=radius or self.xmatch_radius*q.deg, colRA1='ra', colDec1='dec', colRA2=ra_col, colDec2=dec_col)\n            \n            # Ingest the data\n            self.ingest_data(data, cat_name, 'id', ra_col=ra_col, dec_col=dec_col)\n            \n            # Regroup\n            if group:\n                self.group_sources(self.xmatch_radius)", "response": "Cross - match a Vizier object with sources in self. catalog."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_sources(self, radius='', plot=False):\n        if len(self.catalogs)==0:\n            print(\"No catalogs to start grouping! Add one with the ingest_data() method first.\")\n            \n        else:\n            \n            # Gather the catalogs\n            print('Grouping sources from the following catalogs:',list(self.catalogs.keys()))\n            cats = pd.concat([getattr(self, cat_name) for cat_name in self.catalogs])\n            \n            # Clear the source grouping\n            cats['oncID'] = np.nan\n            cats['oncflag'] = ''\n            self.xmatch_radius = radius if isinstance(radius,(float,int)) else self.xmatch_radius\n            \n            # Make a list of the coordinates of each catalog row\n            coords = cats[['ra_corr','dec_corr']].values\n            \n            # Perform DBSCAN to find clusters\n            db = DBSCAN(eps=self.xmatch_radius, min_samples=1, n_jobs=-1).fit(coords)\n            \n            # Group the sources\n            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n            core_samples_mask[db.core_sample_indices_] = True\n            source_ids = db.labels_+1\n            unique_source_ids = list(set(source_ids))\n            self.n_sources = len(unique_source_ids)\n            \n            # Get the average coordinates of all clusters\n            unique_coords = np.asarray([np.mean(coords[source_ids==id], axis=0) for id in list(set(source_ids))])\n            \n            # Generate a source catalog\n            self.catalog = pd.DataFrame(columns=('id','ra','dec','flag','datasets'))\n            self.catalog['id'] = unique_source_ids\n            self.catalog[['ra','dec']] = unique_coords\n            self.catalog['flag'] = [None]*len(unique_source_ids)\n            # self.catalog['flag'] = ['d{}'.format(i) if i>1 else '' for i in Counter(source_ids).values()]\n            self.catalog['datasets'] = Counter(source_ids).values()\n            \n            # Update history\n            self.history += \"\\n{}: Catalog grouped with radius {} arcsec.\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), self.xmatch_radius)\n            \n            # Update the source_ids in each catalog\n            cats['source_id'] = source_ids\n            for cat_name in self.catalogs:\n                \n                # Get the source_ids for the catalog\n                cat_source_ids = cats.loc[cats['catID'].str.startswith(cat_name)]['source_id']\n                \n                # Get the catalog\n                cat = getattr(self, cat_name)\n                \n                # Update the source_ids and put it back\n                cat['source_id'] = cat_source_ids\n                setattr(self, cat_name, cat)\n                \n                del cat, cat_source_ids\n                \n            del cats\n            \n            # Plot it\n            if plot:\n                plt.figure()\n                plt.title('{} clusters for {} sources'.format(self.n_sources,len(coords)))\n                \n                colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, self.n_sources)]\n                for k, col in zip(unique_source_ids, colors):\n                    \n                    class_member_mask = (source_ids == k)\n                    xy = coords[class_member_mask & core_samples_mask]\n                    \n                    marker = 'o'\n                    if len(xy)==1:\n                        col = [0,0,0,1]\n                        marker = '+'\n                        \n                    plt.plot(xy[:, 0], xy[:, 1], color=tuple(col), marker=marker, markerfacecolor=tuple(col))", "response": "Group the sources of the cluster by the number of points in each source."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_catalog(self, cat_name):\n        # Delete the name and data\n        self.catalogs.pop(cat_name)\n        delattr(self, cat_name)\n        \n        # Update history\n        print(\"Deleted {} catalog.\".format(cat_name))\n        self.history += \"\\n{}: Deleted {} catalog.\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), cat_name)", "response": "Drop an imported catalog from the Dataset object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, path):\n        # Get the object\n        DB = joblib.load(path)\n        \n        # Load the attributes\n        self.catalog   = DB.catalog\n        self.n_sources = DB.n_sources\n        self.name      = DB.name\n        self.history   = DB.history\n        \n        del DB", "response": "Loads the catalog from file and sets the attributes of the object to the attributes of the object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef correct_offsets(self, cat_name, truth='ACS'):\n        # Must be grouped!\n        if not self.xmatch_radius:\n            \n            print(\"Please run group_sources() before running correct_offsets().\")\n            \n        else:\n            \n            # First, remove any previous catalog correction\n            self.catalog.loc[self.catalog['cat_name']==cat_name, 'ra_corr'] = self.catalog.loc[self.catalog['cat_name']==cat_name, '_RAJ2000']\n            self.catalog.loc[self.catalog['cat_name']==cat_name, 'dec_corr'] = self.catalog.loc[self.catalog['cat_name']==cat_name, '_DEJ2000']\n            \n            # Copy the catalog\n            onc_gr = self.catalog.copy()\n            \n            # restrict to one-to-one matches, sort by oncID so that matches are paired\n            o2o_new = onc_gr.loc[(onc_gr['oncflag'].str.contains('o')) & (onc_gr['cat_name'] == cat_name) ,:].sort_values('oncID')\n            o2o_old = onc_gr.loc[(onc_gr['oncID'].isin(o2o_new['oncID']) & (onc_gr['cat_name'] == truth)), :].sort_values('oncID')\n            \n            # get coords\n            c_o2o_new = SkyCoord(o2o_new.loc[o2o_new['cat_name'] == cat_name, 'ra_corr'],\\\n                                 o2o_new.loc[o2o_new['cat_name'] == cat_name, 'dec_corr'], unit='degree')\n            c_o2o_old = SkyCoord(o2o_old.loc[o2o_old['cat_name'] == truth, 'ra_corr'],\\\n                                 o2o_old.loc[o2o_old['cat_name'] == truth, 'dec_corr'], unit='degree')\n                             \n            print(len(c_o2o_old), 'one-to-one matches found!')\n            \n            if len(c_o2o_old)>0:\n                \n                delta_ra = []\n                delta_dec = []\n                \n                for i in range(len(c_o2o_old)):\n                    # offsets FROM ACS TO new catalog\n                    ri, di = c_o2o_old[i].spherical_offsets_to(c_o2o_new[i])\n                    \n                    delta_ra.append(ri.arcsecond)\n                    delta_dec.append(di.arcsecond)\n                    \n                    progress_meter((i+1)*100./len(c_o2o_old))\n                    \n                delta_ra = np.array(delta_ra)\n                delta_dec = np.array(delta_dec)\n                \n                print('\\n')\n                \n                # fit a gaussian\n                mu_ra, std_ra = norm.fit(delta_ra)\n                mu_dec, std_dec = norm.fit(delta_dec)\n                \n                # Fix precision\n                mu_ra = round(mu_ra, 6)\n                mu_dec = round(mu_dec, 6)\n                \n                # Update the coordinates of the appropriate sources\n                print('Shifting {} sources by {}\" in RA and {}\" in Dec...'.format(cat_name,mu_ra,mu_dec))\n                self.catalog.loc[self.catalog['cat_name']==cat_name, 'ra_corr'] += mu_ra\n                self.catalog.loc[self.catalog['cat_name']==cat_name, 'dec_corr'] += mu_dec\n                \n                # Update history\n                now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n                self.history += \"\\n{}: {} sources shifted by {} deg in RA and {} deg in Declination.\".format(now, cat_name, mu_ra, mu_dec)\n                \n                # Regroup the sources since many have moved\n                self.group_sources(self.xmatch_radius)\n                \n            else:\n                \n                print('Cannot correct offsets in {} sources.'.format(cat_name))", "response": "This function is used to determine systematic linear offsets between the two catalogs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jinja_env(self):\n        if self._jinja_env is None:\n            self._jinja_env = SandboxedEnvironment(\n                extensions=[\n                    'jinja2.ext.autoescape', 'jinja2.ext.with_', ],\n                autoescape=True,\n            )\n            self._jinja_env.globals['url_for'] = url_for\n            # Load whitelisted configuration variables.\n            for var in self.app.config['PAGES_WHITELIST_CONFIG_KEYS']:\n                self._jinja_env.globals[var] = self.app.config.get(var)\n        return self._jinja_env", "response": "Create a sandboxed Jinja environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_template(self, source, **kwargs_context):\n        return self.jinja_env.from_string(source).render(kwargs_context)", "response": "r Render a template string using sandboxed environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap error handler. :param app: The Flask application.", "response": "def wrap_errorhandler(app):\n        \"\"\"Wrap error handler.\n\n        :param app: The Flask application.\n        \"\"\"\n        try:\n            existing_handler = app.error_handler_spec[None][404][NotFound]\n        except (KeyError, TypeError):\n            existing_handler = None\n\n        if existing_handler:\n            app.error_handler_spec[None][404][NotFound] = \\\n                lambda error: handle_not_found(error, wrapped=existing_handler)\n        else:\n            app.error_handler_spec.setdefault(None, {}).setdefault(404, {})\n            app.error_handler_spec[None][404][NotFound] = handle_not_found"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init_app(self, app):\n        self.init_config(app)\n\n        self.wrap_errorhandler(app)\n        app.extensions['invenio-pages'] = _InvenioPagesState(app)\n\n        return app.extensions['invenio-pages']", "response": "Initializes the Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_conferences_groups(self, group_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/conferences with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/conferences\".format(**path), data=data, params=params, all_pages=True)", "response": "List conferences for a group"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_assignment_overridden_dates_for_quizzes(self, course_id, quiz_assignment_overrides_0_quiz_ids=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - quiz_assignment_overrides[0][quiz_ids]\r\n        \"\"\"An array of quiz IDs. If omitted, overrides for all quizzes available to\r\n        the operating user will be returned.\"\"\"\r\n        if quiz_assignment_overrides_0_quiz_ids is not None:\r\n            params[\"quiz_assignment_overrides[0][quiz_ids]\"] = quiz_assignment_overrides_0_quiz_ids\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/quizzes/assignment_overrides with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/quizzes/assignment_overrides\".format(**path), data=data, params=params, single_item=True)", "response": "Retrieve assignment - overridden dates for quizzes. Returns the actual due - at unlock - at and available - at dates for quizzes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the model using X as training data and y as target values", "response": "def fit(self, X, y):\n        \"\"\"Fit the model using X as training data and y as target values\"\"\"\n\n        self._data = X\n        self._classes = np.unique(y)\n        self._labels = y\n        self._is_fitted = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predict(self, X):\n        # TODO: Make classification of multiple samples a bit more effective...\n        if X.ndim > 1 and X.shape[1] != 1:\n            out = []\n            for x in X:\n                out += self.predict(x)\n            return out\n        X = X.flatten()\n\n        if self.metric == 'minkowski':\n            dists = np.sum(np.abs(self._data - X) ** self.p, axis=1)\n        else:\n            # TODO: Implement other metrics.\n            raise ValueError(\"Only Minkowski distance metric implemented...\")\n\n        argument = np.argsort(dists)\n        labels = self._labels[argument[:self.n_neighbors]]\n\n        if self.weights == 'distance':\n            weights = 1 / dists[argument[:self.n_neighbors]]\n            out = np.zeros((len(self._classes), ), 'float')\n            for i, c in enumerate(self._classes):\n               out[i] = np.sum(weights[labels == c])\n            out /= np.sum(out)\n            y_pred = self._labels[np.argmax(out)]\n        else:\n            y_pred, _ = mode(labels)\n\n        return y_pred.tolist()", "response": "Predict the class labels for the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replaced_url_for(endpoint, filename=None, **values):\n    lookup_result = overlay_url_for(endpoint, filename, **values)\n\n    if lookup_result is not None:\n        return lookup_result\n\n    return url_for(endpoint, filename=filename, **values)", "response": "This function is used to replace the default url_for function and intercepts if the file is not available in bower assets\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_url_error(error, endpoint, values):\n    url = overlay_url_for(endpoint, **values)\n    if url is None:\n        exc_type, exc_value, tb = sys.exc_info()\n        if exc_value is error:\n            reraise(exc_type, exc_value, tb)\n        else:\n            raise error\n    # url_for will use this result, instead of raising BuildError.\n    return url", "response": "Handle BuildErrors of url_for."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverlaying a URL for a given endpoint.", "response": "def overlay_url_for(endpoint, filename=None, **values):\n    \"\"\"\n    Replace flasks url_for() function to allow usage without template changes\n\n    If the requested endpoint is static or ending in .static, it tries to serve a bower asset, otherwise it will pass\n    the arguments to flask.url_for()\n\n    See http://flask.pocoo.org/docs/0.10/api/#flask.url_for\n    \"\"\"\n    default_url_for_args = values.copy()\n    if filename:\n        default_url_for_args['filename'] = filename\n\n    if endpoint == 'static' or endpoint.endswith('.static'):\n\n        if os.path.sep in filename:\n            filename_parts = filename.split(os.path.sep)\n            component = filename_parts[0]\n            # Using * magic here to expand list\n            filename = os.path.join(*filename_parts[1:])\n\n            returned_url = build_url(component, filename, **values)\n\n            if returned_url is not None:\n                return returned_url\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding url for a given component and filename", "response": "def build_url(component, filename, **values):\n    \"\"\"\n    search bower asset and build url\n\n    :param component: bower component (package)\n    :type component: str\n    :param filename: filename in bower component - can contain directories (like dist/jquery.js)\n    :type filename: str\n    :param values: additional url parameters\n    :type values: dict[str, str]\n    :return: url\n    :rtype: str | None\n    \"\"\"\n    root = current_app.config['BOWER_COMPONENTS_ROOT']\n    bower_data = None\n    package_data = None\n\n    # check if component exists in bower_components directory\n    if not os.path.isdir(os.path.join(current_app.root_path, root, component)):\n        # FallBack to default url_for flask\n        return None\n\n    # load bower.json of specified component\n    bower_file_path = os.path.join(current_app.root_path, root, component, 'bower.json')\n    if os.path.exists(bower_file_path):\n        with open(bower_file_path, 'r') as bower_file:\n            bower_data = json.load(bower_file)\n\n    # check if package.json exists and load package.json data\n    package_file_path = os.path.join(current_app.root_path, root, component, 'package.json')\n    if os.path.exists(package_file_path):\n        with open(package_file_path, 'r') as package_file:\n            package_data = json.load(package_file)\n\n    # check if specified file actually exists\n    if not os.path.exists(os.path.join(current_app.root_path, root, component, filename)):\n        return None\n\n    # check if minified file exists (by pattern <filename>.min.<ext>\n    # returns filename if successful\n    if current_app.config['BOWER_TRY_MINIFIED']:\n        if '.min.' not in filename:\n            minified_filename = '%s.min.%s' % tuple(filename.rsplit('.', 1))\n            minified_path = os.path.join(root, component, minified_filename)\n\n            if os.path.exists(os.path.join(current_app.root_path, minified_path)):\n                filename = minified_filename\n\n    # determine version of component and append as ?version= parameter to allow cache busting\n    if current_app.config['BOWER_QUERYSTRING_REVVING']:\n        if bower_data is not None and 'version' in bower_data:\n            values['version'] = bower_data['version']\n        elif package_data is not None and 'version' in package_data:\n            values['version'] = package_data['version']\n        else:\n            values['version'] = os.path.getmtime(os.path.join(current_app.root_path, root, component, filename))\n\n    return url_for('bower.serve', component=component, filename=filename, **values)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_ixn(api, logger, install_dir=None):\n\n    if api == ApiType.tcl:\n        api_wrapper = IxnTclWrapper(logger, install_dir)\n    elif api == ApiType.python:\n        api_wrapper = IxnPythonWrapper(logger, install_dir)\n    elif api == ApiType.rest:\n        api_wrapper = IxnRestWrapper(logger)\n    else:\n        raise TgnError('{} API not supported - use Tcl, python or REST'.format(api))\n    return IxnApp(logger, api_wrapper)", "response": "Create IXN object.\n\n    :param api: tcl/python/rest\n    :type api: trafficgenerator.tgn_utils.ApiType\n    :param logger: logger object\n    :param install_dir: IXN installation directory\n    :return: IXN object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disconnect(self):\n        if self.root.ref is not None:\n            self.api.disconnect()\n        self.root = None", "response": "Disconnect from chassis and server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreserves ports and optionally wait for up.", "response": "def reserve(self, ports, force=False, wait_for_up=True, timeout=80):\n        \"\"\" Reserve port and optionally wait for port to come up.\n\n        :param ports: dict of <port, ip/module/port'>.\n        :param force: whether to revoke existing reservation (True) or not (False).\n        :param wait_for_up: True - wait for port to come up, False - return immediately.\n        :param timeout: how long (seconds) to wait for port to come up.\n        \"\"\"\n\n        if force:\n            for port in ports:\n                port.release()\n\n        for port, location in ports.items():\n            port.reserve(location, False, wait_for_up, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n        assert not self._timer, '%r is already started; to restart it, cancel it first' % self\n        loop = evergreen.current.loop\n        current = evergreen.current.task\n        if self.seconds is None or self.seconds < 0:\n            # \"fake\" timeout (never expires)\n            self._timer = None\n        elif self.exception is None or isinstance(self.exception, bool):\n            # timeout that raises self\n            self._timer = loop.call_later(self.seconds, self._timer_cb, current.throw, self)\n        else:\n            # regular timeout with user-provided exception\n            self._timer = loop.call_later(self.seconds, self._timer_cb, current.throw, self.exception)", "response": "Schedule the timeout.  This is called on construction, so\n        it should not be called explicitly, unless the timer has been\n        canceled."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush_read_tuple(self):\n        if not self.is_empty():\n            suffix_comment_buffer = []\n            if self._info_simulator is not None:\n                suffix_comment_buffer.append(self._info_simulator)\n            if self._info_reads_in_tuple:\n                # todo: orientation (FF, FR, etc.)\n                # orientation=\"\".join([])\n                suffix_comment_buffer.append(\"reads-in-tuple:{}\".format(len(self.seqs_bases)))\n            if len(suffix_comment_buffer) != 0:\n                suffix_comment = \"[{}]\".format(\",\".join(suffix_comment_buffer))\n            else:\n                suffix_comment = \"\"\n\n            rnf_name = self._rnf_profile.get_rnf_name(\n                rnftools.rnfformat.ReadTuple(\n                    segments=self.segments,\n                    read_tuple_id=self.current_read_tuple_id,\n                    suffix=suffix_comment,\n                )\n            )\n            fq_reads = [\n                os.linesep.join(\n                    [\n                        \"@{rnf_name}{read_suffix}\".format(\n                            rnf_name=rnf_name,\n                            read_suffix=\"/{}\".format(str(i + 1)) if len(self.seqs_bases) > 1 else \"\",\n                        ),\n                        self.seqs_bases[i],\n                        \"+\",\n                        self.seqs_qualities[i],\n                    ]\n                ) for i in range(len(self.seqs_bases))\n            ]\n            self._fq_file.write(os.linesep.join(fq_reads))\n            self._fq_file.write(os.linesep)\n            self.empty()", "response": "Flush the internal buffer of reads."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new read to the current buffer.", "response": "def add_read(\n        self,\n        read_tuple_id,\n        bases,\n        qualities,\n        segments,\n    ):\n        \"\"\"Add a new read to the current buffer. If it is a new read tuple (detected from ID), the buffer will be flushed.\n\n\t\tArgs:\n\t\t\tread_tuple_id (int): ID of the read tuple.\n\t\t\tbases (str): Sequence of bases.\n\t\t\tqualities (str): Sequence of FASTQ qualities.\n\t\t\tsegments (list of rnftools.rnfformat.segment): List of segments constituting the read.\n\t\t\"\"\"\n\n        assert type(bases) is str, \"Wrong type of bases: '{}'\".format(bases)\n        assert type(qualities) is str, \"Wrong type of qualities: '{}'\".format(qualities)\n        assert type(segments) is tuple or type(segments) is list\n\n        if self.current_read_tuple_id != read_tuple_id:\n            self.flush_read_tuple()\n        self.current_read_tuple_id = read_tuple_id\n\n        self.seqs_bases.append(bases)\n        self.seqs_qualities.append(qualities)\n        self.segments.extend(segments)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_category(self, name):\n        category = BayesCategory(name)\n        self.categories[name] = category\n        return category", "response": "Adds a bayes category to the set of available categories."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if line is interesting.", "response": "def line_is_interesting(self, line):\n        \"\"\"Return True, False, or None.\n\n        True means always output, False means never output, None means output\n        only if there are interesting lines.\n\n        \"\"\"\n        if line.startswith('Name'):\n            return None\n        if line.startswith('--------'):\n            return None\n        if line.startswith('TOTAL'):\n            return None\n        if '100%' in line:\n            return False\n        if line == '\\n':\n            return None if self._last_line_was_printable else False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_tuples(cls, tuples):\n        return cls(it.imap(lambda (source, target, sign): (source, target, {'sign': sign}), tuples))", "response": "Creates a new graph from an iterable of tuples describing signed and directed edges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_sif(cls, path):\n        df = pd.read_csv(path, delim_whitespace=True, names=['source', 'sign', 'target']).drop_duplicates()\n        edges = [(source, target, {'sign': sign}) for _, source, sign, target in df.itertuples()]\n        return cls(data=edges)", "response": "Reads a simple interaction format SIF file and returns a new instance of this class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of predecessors of a given node.", "response": "def predecessors(self, node, exclude_compressed=True):\n        \"\"\"\n        Returns the list of predecessors of a given node\n\n        Parameters\n        ----------\n        node : str\n            The target node\n\n        exclude_compressed : boolean\n            If true, compressed nodes are excluded from the predecessors list\n\n        Returns\n        -------\n        list\n            List of predecessors nodes\n        \"\"\"\n        preds = super(Graph, self).predecessors(node)\n        if exclude_compressed:\n            return [n for n in preds if not self.node[n].get('compressed', False)]\n        else:\n            return preds"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef successors(self, node, exclude_compressed=True):\n        succs = super(Graph, self).successors(node)\n        if exclude_compressed:\n            return [n for n in succs if not self.node[n].get('compressed', False)]\n        else:\n            return succs", "response": "Returns the list of successors of a given node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compress(self, setup):\n        designated = set(setup.nodes)\n        zipped = self.copy()\n\n        marked = [(n, d) for n, d in self.nodes(data=True) if n not in designated and not d.get('compressed', False)]\n        while marked:\n            for node, _ in sorted(marked):\n                backward = zipped.predecessors(node)\n                forward = zipped.successors(node)\n\n                if not backward or (len(backward) == 1 and not backward[0] in forward):\n                    self.__merge_source_targets(node, zipped)\n\n                elif not forward or (len(forward) == 1 and not forward[0] in backward):\n                    self.__merge_target_sources(node, zipped)\n\n                else:\n                    designated.add(node)\n\n            marked = [(n, d) for n, d in self.nodes(data=True) if n not in designated and not d.get('compressed', False)]\n\n        not_compressed = [(n, d) for n, d in zipped.nodes(data=True) if not d.get('compressed', False)]\n        return zipped.subgraph([n for n, _ in not_compressed])", "response": "Returns the compressed graph according to the given experimental setup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef combine(*rnf_profiles):\n\n        for rnf_profile in rnf_profiles:\n            self.prefix_width = max(self.prefix_width, rnf_profile.prefix_width)\n            self.read_tuple_id_width = max(self.read_tuple_id_width, rnf_profile.read_tuple_id_width)\n            self.genome_id_width = max(self.genome_id_width, rnf_profile.genome_id_width)\n            self.chr_id_width = max(self.chr_id_width, rnf_profile.chr_id_width)\n            self.coor_width = max(self.coor_width, rnf_profile.coor_width)", "response": "Combine more profiles and set their maximal values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, read_tuple_name):\n        self.prefix_width = 0\n        self.read_tuple_id_width = 0\n        self.genome_id_width = 0\n        self.chr_id_width = 0\n        self.coor_width = 0\n\n        parts = read_tuple_name.split(\"__\")\n        self.prefix_width = len(parts[0])\n        self.read_tuple_id_width = len(parts[1])\n\n        segments = parts[2][1:-1].split(\"),(\")\n        for segment in segments:\n            int_widths = list(map(len, segment.split(\",\")))\n            self.genome_id_width = max(self.genome_id_width, int_widths[0])\n            self.chr_id_width = max(self.chr_id_width, int_widths[1])\n            self.coor_width = max(self.coor_width, int_widths[2], int_widths[3])", "response": "Load the values from a read tuple name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply(self, read_tuple_name, read_tuple_id=None, synchronize_widths=True):\n        parts = read_tuple_name.split(\"__\")\n        parts[0] = self._fill_right(parts[0], \"-\", self.prefix_width)\n        if read_tuple_id is not None:\n            parts[1] = \"{:x}\".format(read_tuple_id)\n        parts[1] = self._fill_left(parts[1], \"0\", self.read_tuple_id_width)\n\n        if synchronize_widths:\n            new_segments = []\n            segments = parts[2][1:-1].split(\"),(\")\n            for segment in segments:\n                values = segment.split(\",\")\n                values[0] = values[0].zfill(self.genome_id_width)\n                values[1] = values[1].zfill(self.chr_id_width)\n                values[3] = values[3].zfill(self.coor_width)\n                values[4] = values[4].zfill(self.coor_width)\n                new_segments.append(\"(\" + \",\".join(values) + \")\")\n            parts[2] = \",\".join(new_segments)\n\n        return \"__\".join(parts)", "response": "Applies the profile on a read tuple name and update read tuple ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(self, read_tuple_name):\n\n        parts = read_tuple_name.split(\"__\")\n\n        if len(parts[0]) != self.prefix_width or len(parts[1]) != self.read_tuple_id_width:\n            return False\n\n        segments = parts[2][1:-1].split(\"),(\")\n        for segment in segments:\n            int_widths = list(map(len, segment.split(\",\")))\n            if self.genome_id_width != int_widths[0]:\n                return False\n            if self.chr_id_width != int_widths[1]:\n                return False\n            if self.coor_width != int_widths[3] or self.coor_width != int_widths[4]:\n                return False\n\n        return True", "response": "Check if the given read tuple name satisfies this profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_column_definition_all(self, table):\n        # Get complete table definition\n        col_defs = self.get_table_definition(table).split('\\n')\n\n        # Return only column definitions\n        return [i[0:-1].strip().replace(',', ', ') for i in col_defs if i.strip().startswith('`')]", "response": "Retrieve the column definition statement for all columns in a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the column definition statement for a column from a table.", "response": "def get_column_definition(self, table, column):\n        \"\"\"Retrieve the column definition statement for a column from a table.\"\"\"\n        # Parse column definitions for match\n        for col in self.get_column_definition_all(table):\n            if col.strip('`').startswith(column):\n                return col.strip(',')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef original(modname):\n    # note that it's not necessary to temporarily install unpatched\n    # versions of all patchable modules during the import of the\n    # module; this is because none of them import each other, except\n    # for threading which imports thread\n    original_name = '__original_module_' + modname\n    if original_name in sys.modules:\n        return sys.modules.get(original_name)\n\n    # re-import the \"pure\" module and store it in the global _originals\n    # dict; be sure to restore whatever module had that name already\n    saver = SysModulesSaver((modname,))\n    sys.modules.pop(modname, None)\n    try:\n        real_mod = __import__(modname, {}, {}, modname.split('.')[:-1])\n        # save a reference to the unpatched module so it doesn't get lost\n        sys.modules[original_name] = real_mod\n    finally:\n        saver.restore()\n\n    return sys.modules[original_name]", "response": "This returns an unpatched version of a module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef patch(**on):\n    accepted_args = set(('select', 'socket', 'time'))\n    default_on = on.pop(\"all\", None)\n    for k in on.keys():\n        if k not in accepted_args:\n            raise TypeError(\"patch() got an unexpected keyword argument %r\" % k)\n    if default_on is None:\n        default_on = not (True in list(on.values()))\n    for modname in accepted_args:\n        on.setdefault(modname, default_on)\n\n    modules_to_patch = []\n    if on['select'] and not already_patched.get('select'):\n        modules_to_patch += _select_modules()\n        already_patched['select'] = True\n    if on['socket'] and not already_patched.get('socket'):\n        modules_to_patch += _socket_modules()\n        already_patched['socket'] = True\n    if on['time'] and not already_patched.get('time'):\n        modules_to_patch += _time_modules()\n        already_patched['time'] = True\n\n    imp.acquire_lock()\n    try:\n        for name, mod in modules_to_patch:\n            orig_mod = sys.modules.get(name)\n            if orig_mod is None:\n                orig_mod = __import__(name)\n            for attr_name in mod.__patched__:\n                patched_attr = getattr(mod, attr_name, None)\n                if patched_attr is not None:\n                    setattr(orig_mod, attr_name, patched_attr)\n    finally:\n        imp.release_lock()", "response": "Globally patches certain system modules to be cooperaive."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninject greened modules into a new module.", "response": "def inject(module_name, new_globals, *additional_modules):\n    \"\"\"Base method for \"injecting\" greened modules into an imported module.  It\n    imports the module specified in *module_name*, arranging things so\n    that the already-imported modules in *additional_modules* are used when\n    *module_name* makes its imports.\n\n    *new_globals* is either None or a globals dictionary that gets populated\n    with the contents of the *module_name* module.  This is useful when creating\n    a \"green\" version of some other module.\n\n    *additional_modules* should be a collection of two-element tuples, of the\n    form (<name>, <module>).  If it's not specified, a default selection of\n    name/module pairs is used, which should cover all use cases but may be\n    slower because there are inevitably redundant or unnecessary imports.\n    \"\"\"\n    patched_name = '__patched_module_' + module_name\n    if patched_name in sys.modules:\n        # returning already-patched module so as not to destroy existing\n        # references to patched modules\n        return sys.modules[patched_name]\n\n    if not additional_modules:\n        # supply some defaults\n        additional_modules = (_select_modules() +\n                              _socket_modules() +\n                              _time_modules())\n\n    # after this we are gonna screw with sys.modules, so capture the\n    # state of all the modules we're going to mess with, and lock\n    saver = SysModulesSaver([name for name, m in additional_modules])\n    saver.save(module_name)\n\n    # Cover the target modules so that when you import the module it\n    # sees only the patched versions\n    for name, mod in additional_modules:\n        sys.modules[name] = mod\n\n    ## Remove the old module from sys.modules and reimport it while\n    ## the specified modules are in place\n    sys.modules.pop(module_name, None)\n    try:\n        module = __import__(module_name, {}, {}, module_name.split('.')[:-1])\n\n        if new_globals is not None:\n            ## Update the given globals dictionary with everything from this new module\n            for name in dir(module):\n                if name not in __exclude:\n                    new_globals[name] = getattr(module, name)\n\n        ## Keep a reference to the new module to prevent it from dying\n        sys.modules[patched_name] = module\n    finally:\n        saver.restore()  # Put the original modules back\n\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies properties from source to destination.", "response": "def slurp_properties(source, destination, ignore=[], srckeys=None):\n    \"\"\"Copy properties from *source* (assumed to be a module) to\n    *destination* (assumed to be a dict).\n\n    *ignore* lists properties that should not be thusly copied.\n    *srckeys* is a list of keys to copy, if the source's __all__ is\n    untrustworthy.\n    \"\"\"\n    if srckeys is None:\n        srckeys = source.__all__\n    destination.update(dict([(name, getattr(source, name))\n                              for name in srckeys\n                                if not (name.startswith('__') or name in ignore)\n                            ]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the named modules to the object.", "response": "def save(self, *module_names):\n        \"\"\"Saves the named modules to the object.\"\"\"\n        for modname in module_names:\n            self._saved[modname] = sys.modules.get(modname, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring the modules that the saver knows about into", "response": "def restore(self):\n        \"\"\"Restores the modules that the saver knows about into\n        sys.modules.\n        \"\"\"\n        try:\n            for modname, mod in self._saved.items():\n                if mod is not None:\n                    sys.modules[modname] = mod\n                else:\n                    try:\n                        del sys.modules[modname]\n                    except KeyError:\n                        pass\n        finally:\n            imp.release_lock()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a series of nested LIVVDicts given a list", "response": "def nested_insert(self, item_list):\n        \"\"\" Create a series of nested LIVVDicts given a list \"\"\"\n        if len(item_list) == 1:\n            self[item_list[0]] = LIVVDict()\n        elif len(item_list) > 1:\n            if item_list[0] not in self:\n                self[item_list[0]] = LIVVDict()\n            self[item_list[0]].nested_insert(item_list[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nested_assign(self, key_list, value):\n        if len(key_list) == 1:\n            self[key_list[0]] = value\n        elif len(key_list) > 1:\n            if key_list[0] not in self:\n                self[key_list[0]] = LIVVDict()\n            self[key_list[0]].nested_assign(key_list[1:], value)", "response": "Assign a value to a nested LIVVDict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_children(parent):\n\n    components = []\n    for tag in parent.children:\n        matched = parse_tag(tag)\n        if matched:\n            components.append(matched)\n        elif hasattr(tag, 'contents'):\n            components += parse_children(tag)\n    return components", "response": "Recursively parse child tags until match is found"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the contents of the current object to a particular location.", "response": "def save(self, path):\n        \"\"\"\n        Writes file to a particular location\n\n        This won't work for cloud environments like Google's App Engine, use with caution\n        ensure to catch exceptions so you can provide informed feedback.\n\n        prestans does not mask File IO exceptions so your handler can respond better.\n        \"\"\"\n\n        file_handle = open(path, 'wb')\n        file_handle.write(self._file_contents)\n        file_handle.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_by_assignment(self, assignment_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/grade_change/assignments/{assignment_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/grade_change/assignments/{assignment_id}\".format(**path), data=data, params=params, all_pages=True)", "response": "Query by assignment. Returns a list of grade change events for a given assignment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_by_student(self, student_id, end_time=None, start_time=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - student_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"student_id\"] = student_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/grade_change/students/{student_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/grade_change/students/{student_id}\".format(**path), data=data, params=params, all_pages=True)", "response": "Query by student. Returns a list of grade change events for a given student."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries by grader. Returns a list of grade change events for a given grader.", "response": "def query_by_grader(self, grader_id, end_time=None, start_time=None):\r\n        \"\"\"\r\n        Query by grader.\r\n\r\n        List grade change events for a given grader.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - grader_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"grader_id\"] = grader_id\r\n\r\n        # OPTIONAL - start_time\r\n        \"\"\"The beginning of the time range from which you want events.\"\"\"\r\n        if start_time is not None:\r\n            params[\"start_time\"] = start_time\r\n\r\n        # OPTIONAL - end_time\r\n        \"\"\"The end of the time range from which you want events.\"\"\"\r\n        if end_time is not None:\r\n            params[\"end_time\"] = end_time\r\n\r\n        self.logger.debug(\"GET /api/v1/audit/grade_change/graders/{grader_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/audit/grade_change/graders/{grader_id}\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the serializer by mime type", "response": "def _set_serializer_by_mime_type(self, mime_type):\n        \"\"\"\n        :param mime_type:\n        :return:\n\n        used by content_type_set to set get a reference to the appropriate serializer\n        \"\"\"\n\n        # ignore if binary response\n        if isinstance(self._app_iter, BinaryResponse):\n            self.logger.info(\"ignoring setting serializer for binary response\")\n            return\n\n        for available_serializer in self._serializers:\n            if available_serializer.content_type() == mime_type:\n                self._selected_serializer = available_serializer\n                self.logger.info(\"set serializer for mime type: %s\" % mime_type)\n                return\n\n        self.logger.info(\"could not find serializer for mime type: %s\" % mime_type)\n        raise exception.UnsupportedVocabularyError(mime_type, self.supported_mime_types_str)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_serializers(self, serializers):\n        for new_serializer in serializers:\n\n            if not isinstance(new_serializer, serializer.Base):\n                msg = \"registered serializer %s.%s does not inherit from prestans.serializer.Serializer\" % (\n                    new_serializer.__module__,\n                    new_serializer.__class__.__name__\n                )\n                raise TypeError(msg)\n\n        self._serializers = self._serializers + serializers", "response": "Adds extra serializers to the internal list of serializers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid(self):\n        if not self.total:\n            return False\n        if not self.contributor.freelanceprofile.is_freelance:\n            return False\n        return True", "response": "returns True if the report should be sent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a datetime filter against the contributor s contribution queryset.", "response": "def contributions(self):\n        \"\"\"Apply a datetime filter against the contributor's contribution queryset.\"\"\"\n        if self._contributions is None:\n            self._contributions = self.contributor.contributions.filter(\n                content__published__gte=self.start,\n                content__published__lt=self.end\n            )\n        return self._contributions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a datetime filter against the contributors s line item queryset.", "response": "def line_items(self):\n        \"\"\"Apply a datetime filter against the contributors's line item queryset.\"\"\"\n        if self._line_items is None:\n            self._line_items = self.contributor.line_items.filter(\n                payment_date__range=(self.start, self.end)\n            )\n        return self._line_items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deadline(self):\n        if not self._deadline:\n            self._deadline = self.now + timezone.timedelta(days=1)\n        return self._deadline", "response": "Return next day as deadline if no deadline provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_contributor_email(self, contributor):\n        ContributorReport(\n            contributor,\n            month=self.month,\n            year=self.year,\n            deadline=self._deadline,\n            start=self._start,\n            end=self._end\n        ).send()", "response": "Send an EmailMessage object for a given contributor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends report email to all relevant contributors.", "response": "def send_mass_contributor_emails(self):\n        \"\"\"Send report email to all relevant contributors.\"\"\"\n        # If the report configuration is not active we only send to the debugging user.\n        for contributor in self.contributors:\n            if contributor.email not in EMAIL_SETTINGS.get(\"EXCLUDED\", []):\n                self.send_contributor_email(contributor)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of contributors with contributions between the start and end dates.", "response": "def get_contributors(self):\n        \"\"\"Return a list of contributors with contributions between the start/end dates.\"\"\"\n        return User.objects.filter(\n            freelanceprofile__is_freelance=True\n        ).filter(\n            contributions__content__published__gte=self.start,\n            contributions__content__published__lt=self.end\n        ).distinct()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contributors(self):\n        if not self._contributors:\n            self._contributors = self.get_contributors()\n        return self._contributors", "response": "Property to retrieve or access the list of contributors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef control(self, size=0, configure=None):\n        self._strategies = []\n\n        clingo = gringo.Control(['-c maxsize=%s' % size])\n\n        clingo.conf.solve.models = '0'\n        if configure:\n            def overwrite(args, proxy):\n                for i in xrange(args.threads):\n                    proxy.solver[i].no_lookback = 'false'\n                    proxy.solver[i].heuristic = 'domain'\n                    proxy.solver[i].dom_mod = '5,16'\n\n            configure(clingo.conf, overwrite)\n        else:\n            clingo.conf.solver.no_lookback = 'false'\n            clingo.conf.solver.heuristic = 'domain'\n            clingo.conf.solver.dom_mod = '5,16'\n\n        clingo.conf.solve.enum_mode = 'domRec'\n\n        clingo.add(\"base\", [], self.instance)\n        clingo.load(self.encodings['control'])\n\n        clingo.ground([(\"base\", [])])\n        clingo.solve(on_model=self.__save__)\n\n        self.stats['time_optimum'] = clingo.stats['time_solve']\n        self.stats['time_enumeration'] = clingo.stats['time_total']\n\n        self._logger.info(\"%s optimal intervention strategies found in %.4fs\", len(self._strategies), self.stats['time_enumeration'])\n\n        self.strategies = core.ClampingList(self._strategies)", "response": "Finds all inclusion - minimal intervention strategies up to the given size."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a URL and return the content of the resource as a string.", "response": "def open_url(self, url, stale_after, parse_as_html = True, **kwargs):\r\n\t\t\"\"\"\r\n\t\tDownload or retrieve from cache.\r\n\r\n\t\turl -- The URL to be downloaded, as a string.\r\n\r\n\t\tstale_after -- A network request for the url will be performed if the\r\n\t\tcached copy does not exist or if it exists but its age (in days) is\r\n\t\tlarger or equal to the stale_after value. A non-positive value will\r\n\t\tforce re-download.\r\n\r\n\t\tparse_as_html -- Parse the resource downloaded as HTML. This uses the\r\n\t\tlxml.html package to parse the resource leniently, thus it will not\r\n\t\tfail even for reasonably invalid HTML. This argument also decides the\r\n\t\treturn type of this method; if True, then the return type is an\r\n\t\tElementTree.Element root object; if False, the content of the resource\r\n\t\tis returned as a bytestring.\r\n\r\n\t\tExceptions raised:\r\n\r\n\t\tBannedException -- If does_show_ban returns True.\r\n\r\n\t\tHTTPCodeNotOKError -- If the returned HTTP status code \r\n\t\t\t\t\t\t\t  is not equal to 200.\r\n\r\n\t\t\"\"\"\r\n\t\t_LOGGER.info('open_url() received url: %s', url)\r\n\t\ttoday = datetime.date.today()\r\n\t\tthreshold_date = today - datetime.timedelta(stale_after)\r\n\t\tdownloaded = False\r\n\r\n\t\twith self._get_conn() as conn:\r\n\t\t\trs = conn.execute('''\r\n\t\t\t\tselect content\r\n\t\t\t\tfrom cache\r\n\t\t\t\twhere url = ?\r\n\t\t\t\tand date > ?\r\n\t\t\t\t''',\r\n\t\t\t\t(url, _date_to_sqlite_str(threshold_date))\r\n\t\t\t)\r\n\r\n\t\trow = rs.fetchone()\r\n\r\n\t\tretry_run = kwargs.get('retry_run', False)\r\n\t\tassert (not retry_run) or (retry_run and row is None)\r\n\t\tif row is None:\r\n\t\t\tfile_obj = self._download(url).get_file_obj()\r\n\t\t\tdownloaded = True\r\n\t\telse:\r\n\t\t\tfile_obj = cStringIO.StringIO(zlib.decompress(row[0]))\r\n\r\n\t\tif parse_as_html:\r\n\t\t\ttree = lxml.html.parse(file_obj)\r\n\t\t\ttree.getroot().url = url\r\n\t\t\tappears_to_be_banned = False\r\n\t\t\tif self.does_show_ban(tree.getroot()):\r\n\t\t\t\tappears_to_be_banned = True\r\n\t\t\t\tif downloaded:\r\n\t\t\t\t\tmessage = ('Function {f} claims we have been banned, '\r\n\t\t\t\t\t\t\t   'it was called with an element parsed from url '\r\n\t\t\t\t\t\t\t   '(downloaded, not from cache): {u}'\r\n\t\t\t\t\t\t\t   .format(f = self.does_show_ban, u = url))\r\n\t\t\t\t\t_LOGGER.error(message)\r\n\t\t\t\t_LOGGER.info('Deleting url %s from the cache (if it exists) '\r\n\t\t\t\t\t\t\t'because it triggered ban page cache poisoning '\r\n\t\t\t\t\t\t\t'exception', url)\r\n\t\t\t\twith self._get_conn() as conn:\r\n\t\t\t\t\tconn.execute('delete from cache where url = ?', [str(url)])\r\n\t\t\t\tif downloaded:\r\n\t\t\t\t\traise BannedException(message)\r\n\t\t\t\telse:\r\n\t\t\t\t\treturn self.open_url(url, stale_after, retry_run = True)\r\n\t\telse:\r\n\t\t\ttree = file_obj.read()\r\n\r\n\t\tif downloaded:\r\n# make_links_absolute should only be called when the document has a base_url\r\n# attribute, which it has not when it has been loaded from the database. So,\r\n# this \"if\" is needed:\r\n\t\t\tif parse_as_html:\r\n\t\t\t\ttree.getroot().make_links_absolute(tree.getroot().base_url)\r\n\t\t\t\tto_store = lxml.html.tostring(\r\n\t\t\t\t\t\t\t\ttree,\r\n\t\t\t\t\t\t\t\tpretty_print = True,\r\n\t\t\t\t\t\t\t\tencoding = 'utf-8'\r\n\t\t\t\t)\r\n\t\t\telse:\r\n\t\t\t\tto_store = tree\r\n\t\t\tto_store = zlib.compress(to_store, 8)\r\n\r\n\t\t\twith self._get_conn() as conn:\r\n\t\t\t\tconn.execute('''\r\n\t\t\t\t\tinsert or replace \r\n\t\t\t\t\tinto cache\r\n\t\t\t\t\t(url, date, content)\r\n\t\t\t\t\tvalues\r\n\t\t\t\t\t(?, ?, ?)\r\n\t\t\t\t\t''',\r\n\t\t\t\t\t(\r\n\t\t\t\t\t\tstr(url),\r\n\t\t\t\t\t\t_date_to_sqlite_str(today),\r\n\t\t\t\t\t\tsqlite3.Binary(to_store)\r\n\t\t\t\t\t)\r\n\r\n\t\t\t\t)\r\n\t\treturn tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries each of the xpaths successively until one element is found.", "response": "def xpath_pick_one(self, xpaths):\r\n\t\t\"\"\"\r\n\t\tTry each of the xpaths successively until\r\n\t\ta single element is found. If no xpath succeeds\r\n\t\tthen raise the last UnexpectedContentException caught.\r\n\t\t\"\"\"\r\n\t\tfor xpathi, xpath in enumerate(xpaths):\r\n\t\t\ttry:\r\n\t\t\t\treturn self.xpath(xpath, [1, 1])[0]\r\n\t\t\texcept UnexpectedContentException as e:\r\n\t\t\t\tif xpathi == len(xpaths) - 1:\r\n\t\t\t\t\traise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets content s title.", "response": "def get_content_title(self, obj):\n        \"\"\"Get content's title.\"\"\"\n        return Content.objects.get(id=obj.content.id).title"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_date(self):\n        dt = DATA_TYPES['date']\n        if type(self.data) is dt['type'] and '-' in str(self.data) and str(self.data).count('-') == 2:\n            # Separate year, month and day\n            date_split = str(self.data).split('-')\n            y, m, d = date_split[0], date_split[1], date_split[2]\n\n            # Validate values\n            valid_year, valid_months, valid_days = int(y) in YEARS, int(m) in MONTHS, int(d) in DAYS\n\n            # Check that all validations are True\n            if all(i is True for i in (valid_year, valid_months, valid_days)):\n                self.type = 'date'.upper()\n                self.len = None\n                return True", "response": "Determine if a data record is of type DATE."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_time(self):\n        dt = DATA_TYPES['time']\n        if type(self.data) is dt['type'] and ':' in str(self.data) and str(self.data).count(':') == 2:\n            # Separate hour, month, second\n            date_split = str(self.data).split(':')\n            h, m, s = date_split[0], date_split[1], date_split[2]\n\n            # Validate values\n            valid_hour, valid_min, valid_sec = int(h) in HOURS, int(m) in MINUTES, int(float(s)) in SECONDS\n\n            if all(i is True for i in (valid_hour, valid_min, valid_sec)):\n                self.type = 'time'.upper()\n                self.len = None\n                return True", "response": "Determine if a data record is of type TIME."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine if a data record is of type YEAR.", "response": "def is_year(self):\n        \"\"\"Determine if a data record is of type YEAR.\"\"\"\n        dt = DATA_TYPES['year']\n        if dt['min'] and dt['max']:\n            if type(self.data) is dt['type'] and dt['min'] < self.data < dt['max']:\n                self.type = 'year'.upper()\n                self.len = None\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_date_data(self, data_type):\n        dt = DATA_TYPES[data_type]\n        if isinstance(self.data, dt['type']):\n            self.type = data_type.upper()\n            self.len = None\n            return True", "response": "Private method to determine if a data record is of type DATE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait(self, timeout=None):\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter()    # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()", "response": "Wait for the barrier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, request, *args, **kwargs):\n\n        self.object = self.get_object()\n\n        allow_anonymous = kwargs.get(\"allow_anonymous\", False)\n\n        # We only want to redirect is that setting is true, and we're not allowing anonymous users\n        if self.redirect_correct_path and not allow_anonymous:\n\n            # Also we obviously only want to redirect if the URL is wrong\n            if self.request.path != self.object.get_absolute_url():\n                return HttpResponsePermanentRedirect(self.object.get_absolute_url())\n\n        context = self.get_context_data(object=self.object)\n        response = self.render_to_response(context)\n\n        # If we have an unpublished article....\n        if self.object.published is None or self.object.published > timezone.now():\n\n            # And the user doesn't have permission to view this\n            if not request.user.is_staff and not allow_anonymous:\n                response = redirect_unpublished_to_login_or_404(\n                    request=request,\n                    next_url=self.object.get_absolute_url(),\n                    next_params=request.GET)\n\n            # Never cache unpublished articles\n            add_never_cache_headers(response)\n        else:\n            response[\"Vary\"] = \"Accept-Encoding\"\n\n        return response", "response": "Override default get function to use token if there is one to retrieve object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that the value is a valid network location", "response": "def host(value):\n    \"\"\" Validates that the value is a valid network location \"\"\"\n    if not value:\n        return (True, \"\")\n    try:\n        host,port = value.split(\":\")\n    except ValueError as _:\n        return (False, \"value needs to be <host>:<port>\")\n\n    try:\n        int(port)\n    except ValueError as _:\n        return (False, \"port component of the host address needs to be a number\")\n\n    return (True, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_wallpaper():\n\t'''Get the desktop wallpaper.\n\n\tGet the current desktop wallpaper.\n\n\tReturns:\n\t\t\tstr: The path to the current wallpaper.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif desktop_env in ['gnome', 'unity', 'cinnamon', 'pantheon', 'mate']:\n\t\tSCHEMA = 'org.gnome.desktop.background'\n\t\tKEY = 'picture-uri'\n\n\t\tif desktop_env == 'mate':\n\t\t\tSCHEMA = 'org.mate.background'\n\t\t\tKEY = 'picture-filename'\n\n\t\ttry:\n\t\t\tfrom gi.repository import Gio\n\n\t\t\tgsettings = Gio.Settings.new(SCHEMA)\n\t\t\treturn gsettings.get_string(KEY).replace('file://', '')\n\t\texcept ImportError:\n\t\t\ttry:\n\t\t\t\treturn system.get_cmd_out(\n\t\t\t\t\t['gsettings', 'get', SCHEMA, KEY]).replace('file://', '')\n\t\t\texcept:  # MATE < 1.6\n\t\t\t\treturn system.get_cmd_out(\n\t\t\t\t\t\t['mateconftool-2', '-t', 'string', '--get',\n\t\t\t\t\t\t '/desktop/mate/background/picture_filename']\n\t\t\t\t\t\t).replace('file://', '')\n\n\telif desktop_env == 'gnome2':\n\t\targs = ['gconftool-2', '-t', 'string', '--get',\n\t\t\t\t'/desktop/gnome/background/picture_filename']\n\t\treturn system.get_cmd_out(args).replace('file://', '')\n\n\telif desktop_env == 'kde':\n\t\tconf_file = directories.get_config_file(\n\t\t\t\t'plasma-org.kde.plasma.desktop-appletsrc')[0]\n\t\twith open(conf_file) as f:\n\t\t\tcontents = f.read()\n\n\t\tcontents = contents.splitlines()\n\n\t\tcontents = contents[\n\t\t\tcontents.index(\n\t\t\t'[Containments][8][Wallpaper][org.kde.image][General]') +\n\t\t\t1].split(\n\t\t\t'=',\n\t\t\t1\n\t\t\t)\n\n\t\treturn contents[len(contents) - 1].strip().replace('file://', '')\n\n\telif desktop_env == 'xfce4':\n\t\t# XFCE4's image property is not image-path but last-image (What?)\n\n\t\tlist_of_properties = system.get_cmd_out(\n\t\t\t['xfconf-query', '-R', '-l', '-c', 'xfce4-desktop', '-p',\n\t\t\t '/backdrop'])\n\n\t\tfor i in list_of_properties.split('\\n'):\n\t\t\tif i.endswith('last-image') and 'workspace' in i:\n\t\t\t\t# The property given is a background property\n\t\t\t\treturn system.get_cmd_out(\n\t\t\t\t\t['xfconf-query', '-c', 'xfce4-desktop', '-p', i])\n\n\telif desktop_env == 'razor-qt':\n\t\tdesktop_conf = configparser.ConfigParser()\n\t\t# Development version\n\n\t\tdesktop_conf_file = os.path.join(\n\t\t\tget_config_dir('razor')[0], 'desktop.conf')\n\n\t\tif os.path.isfile(desktop_conf_file):\n\t\t\tconfig_option = r'screens\\1\\desktops\\1\\wallpaper'\n\n\t\telse:\n\t\t\tdesktop_conf_file = os.path.join(\n\t\t\t\tos.path.expanduser('~'), '.razor/desktop.conf')\n\t\t\tconfig_option = r'desktops\\1\\wallpaper'\n\n\t\tdesktop_conf.read(os.path.join(desktop_conf_file))\n\t\ttry:\n\t\t\tif desktop_conf.has_option('razor', config_option):\n\t\t\t\treturn desktop_conf.get('razor', config_option)\n\t\texcept:\n\t\t\tpass\n\n\telif desktop_env in ['fluxbox', 'jwm', 'openbox', 'afterstep', 'i3']:\n\t\t# feh stores last feh command in '~/.fehbg'\n\t\t# parse it\n\t\twith open(os.path.expanduser('~/.fehbg')) as f:\n\t\t\tfehbg = f.read()\n\n\t\tfehbg = fehbg.split('\\n')\n\n\t\tfor line in fehbg:\n\t\t\tif '#!' in line:\n\t\t\t\tfehbg.remove(line)\n\n\t\tfehbg = fehbg[0]\n\n\t\tfor i in fehbg.split(' '):\n\t\t\tif not i.startswith(\"-\"):\n\t\t\t\tif not i.startswith('feh'):\n\t\t\t\t\tif not i in ['', ' ', '  ', '\\n']:\n\t\t\t\t\t\treturn(i.replace(\"'\", ''))\n\n\t# TODO: way to get wallpaper for desktops which are commented-out below\n\telif desktop_env == 'icewm':\n\t\twith open(os.path.expanduser('~/.icewm/preferences')) as f:\n\t\t\tfor line in f:\n\t\t\t\tif line.startswith('DesktopBackgroundImage'):\n\t\t\t\t\treturn os.path.expanduser(line.strip().split(\n\t\t\t\t\t\t'=', 1)[1].strip().replace('\"', '').replace(\"'\", ''))\n\n\telif desktop_env == 'awesome':\n\t\tconf_file = os.path.join(\n\t\t\t\tdirectories.get_config_dir('awesome')[0],\n\t\t\t\t'rc.lua')\n\n\t\twith open(conf_file) as f:\n\t\t\tfor line in f:\n\t\t\t\tif line.startswith('theme_path'):\n\t\t\t\t\tawesome_theme = line.strip().split('=', 1)\n\t\t\t\t\tawesome_theme = awesome_theme[\n\t\t\t\t\t\tlen(awesome_theme) -\n\t\t\t\t\t\t1].strip().replace(\n\t\t\t\t\t\t'\"',\n\t\t\t\t\t\t'').replace(\n\t\t\t\t\t\t\"'\",\n\t\t\t\t\t\t'')\n\n\t\twith open(os.path.expanduser(awesome_theme)) as f:\n\t\t\tfor line in f:\n\t\t\t\tif line.startswith('theme.wallpaper'):\n\t\t\t\t\tawesome_wallpaper = line.strip().split('=', 1)\n\t\t\t\t\tawesome_wallpaper = awesome_wallpaper[\n\t\t\t\t\t\tlen(awesome_wallpaper) -\n\t\t\t\t\t\t1].strip().replace(\n\t\t\t\t\t\t'\"',\n\t\t\t\t\t\t'').replace(\n\t\t\t\t\t\t\"'\",\n\t\t\t\t\t\t'')\n\n\t\t\t\t\treturn os.path.expanduser(awesome_wallpaper)\n\n\t# elif desktop_env == 'blackbox':\n\t# \targs = ['bsetbg', '-full', image]\n\t# \tsp.Popen(args)\n\t#\n\t# elif desktop_env == 'lxde':\n\t# \targs = 'pcmanfm --set-wallpaper %s --wallpaper-mode=scaled' % image\n\t# \tsp.Popen(args, shell=True)\n\t#\n\t# elif desktop_env == 'lxqt':\n\t# \targs = 'pcmanfm-qt --set-wallpaper %s --wallpaper-mode=scaled' % image\n\t# \tsp.Popen(args, shell=True)\n\t#\n\t# elif desktop_env == 'windowmaker':\n\t# \targs = 'wmsetbg -s -u %s' % image\n\t# \tsp.Popen(args, shell=True)\n\t#\n\t# elif desktop_env == 'enlightenment':\n\t#\targs = 'enlightenment_remote -desktop-bg-add 0 0 0 0 %s' % image\n\t#\tsp.Popen(args, shell=True)\n\t#\n\t# elif desktop_env == 'awesome':\n\t# \twith sp.Popen(\"awesome-client\", stdin=sp.PIPE) as awesome_client:\n\t# \t\tcommand = 'local gears = require(\"gears\"); for s = 1, screen.count()\n\t#       do gears.wallpaper.maximized(\"%s\", s, true); end;' % image\n\t# \t\tawesome_client.communicate(input=bytes(command, 'UTF-8'))\n\n\telif desktop_env == 'windows':\n\t\tWINDOWS_SCRIPT = ('reg query \"HKEY_CURRENT_USER\\Control'\n\t\t\t\t\t\t  ' Panel\\Desktop\\Desktop\"')\n\n\t\treturn system.get_cmd_out(WINDOWS_SCRIPT)\n\n\telif desktop_env == 'mac':\n\t\ttry:\n\t\t\tfrom appscript import app\n\t\t\tapp('Finder').desktop_picture.get()\n\t\texcept ImportError:\n\t\t\tOSX_SCRIPT = ('tell app \"finder\" to get posix path'\n\t\t\t\t\t\t  ' of (get desktop picture as alias)')\n\n\t\t\treturn system.get_cmd_out(['osascript', OSX_SCRIPT])", "response": "Get the desktop wallpaper."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_wallpaper(image):\n\t'''Set the desktop wallpaper.\n\n\tSets the desktop wallpaper to an image.\n\n\tArgs:\n\t\t\timage (str): The path to the image to be set as wallpaper.\n\t'''\n\n\tdesktop_env = system.get_name()\n\n\tif desktop_env in ['gnome', 'unity', 'cinnamon', 'pantheon', 'mate']:\n\t\turi = 'file://%s' % image\n\n\t\tSCHEMA = 'org.gnome.desktop.background'\n\t\tKEY = 'picture-uri'\n\n\t\tif desktop_env == 'mate':\n\t\t\turi = image\n\n\t\t\tSCHEMA = 'org.mate.background'\n\t\t\tKEY = 'picture-filename'\n\n\t\ttry:\n\t\t\tfrom gi.repository import Gio\n\n\t\t\tgsettings = Gio.Settings.new(SCHEMA)\n\t\t\tgsettings.set_string(KEY, uri)\n\t\texcept ImportError:\n\t\t\ttry:\n\t\t\t\tgsettings_proc = sp.Popen(\n\t\t\t\t\t['gsettings', 'set', SCHEMA, KEY, uri])\n\t\t\texcept:  # MATE < 1.6\n\t\t\t\tsp.Popen(['mateconftool-2',\n\t\t\t\t\t\t  '-t',\n\t\t\t\t\t\t  'string',\n\t\t\t\t\t\t  '--set',\n\t\t\t\t\t\t  '/desktop/mate/background/picture_filename',\n\t\t\t\t\t\t  '%s' % image],\n\t\t\t\t\t\t stdout=sp.PIPE)\n\t\t\tfinally:\n\t\t\t\tgsettings_proc.communicate()\n\n\t\t\t\tif gsettings_proc.returncode != 0:\n\t\t\t\t\tsp.Popen(['mateconftool-2',\n\t\t\t\t\t\t\t  '-t',\n\t\t\t\t\t\t\t  'string',\n\t\t\t\t\t\t\t  '--set',\n\t\t\t\t\t\t\t  '/desktop/mate/background/picture_filename',\n\t\t\t\t\t\t\t  '%s' % image])\n\n\telif desktop_env == 'gnome2':\n\t\tsp.Popen(\n\t\t\t['gconftool-2',\n\t\t\t '-t',\n\t\t\t 'string',\n\t\t\t '--set',\n\t\t\t '/desktop/gnome/background/picture_filename',\n\t\t\t image]\n\t\t)\n\n\telif desktop_env == 'kde':\n\t\t# This probably only works in Plasma 5+\n\n\t\tkde_script = dedent(\n\t\t'''\\\n\t\tvar Desktops = desktops();\n\t\tfor (i=0;i<Desktops.length;i++) {{\n\t\t\td = Desktops[i];\n\t\t\td.wallpaperPlugin = \"org.kde.image\";\n\t\t\td.currentConfigGroup = Array(\"Wallpaper\",\n\t\t\t\t\t\t\t\t\t\t\"org.kde.image\",\n\t\t\t\t\t\t\t\t\t\t\"General\");\n\t\t\td.writeConfig(\"Image\", \"file://{}\")\n\t\t}}\n\t\t''').format(image)\n\n\t\tsp.Popen(\n\t\t\t\t['dbus-send',\n\t\t\t\t '--session',\n\t\t\t\t '--dest=org.kde.plasmashell',\n\t\t\t\t '--type=method_call',\n\t\t\t\t '/PlasmaShell',\n\t\t\t\t 'org.kde.PlasmaShell.evaluateScript',\n\t\t\t\t 'string:{}'.format(kde_script)]\n\t\t)\n\n\telif desktop_env in ['kde3', 'trinity']:\n\t\targs = 'dcop kdesktop KBackgroundIface setWallpaper 0 \"%s\" 6' % image\n\t\tsp.Popen(args, shell=True)\n\n\telif desktop_env == 'xfce4':\n\t\t# XFCE4's image property is not image-path but last-image (What?)\n\n\t\tlist_of_properties = system.get_cmd_out(\n\t\t\t\t['xfconf-query',\n\t\t\t\t '-R',\n\t\t\t\t '-l',\n\t\t\t\t '-c',\n\t\t\t\t 'xfce4-desktop',\n\t\t\t\t '-p',\n\t\t\t\t '/backdrop']\n\t\t)\n\n\t\tfor i in list_of_properties.split('\\n'):\n\t\t\tif i.endswith('last-image'):\n\t\t\t\t# The property given is a background property\n\t\t\t\tsp.Popen(\n\t\t\t\t\t['xfconf-query -c xfce4-desktop -p %s -s \"%s\"' %\n\t\t\t\t\t\t(i, image)],\n\t\t\t\t\tshell=True)\n\n\t\t\t\tsp.Popen(['xfdesktop --reload'], shell=True)\n\n\telif desktop_env == 'razor-qt':\n\t\tdesktop_conf = configparser.ConfigParser()\n\t\t# Development version\n\n\t\tdesktop_conf_file = os.path.join(\n\t\t\tget_config_dir('razor')[0], 'desktop.conf')\n\n\t\tif os.path.isfile(desktop_conf_file):\n\t\t\tconfig_option = r'screens\\1\\desktops\\1\\wallpaper'\n\n\t\telse:\n\t\t\tdesktop_conf_file = os.path.join(\n\t\t\t\tos.path.expanduser('~'), '.razor/desktop.conf')\n\t\t\tconfig_option = r'desktops\\1\\wallpaper'\n\n\t\tdesktop_conf.read(os.path.join(desktop_conf_file))\n\t\ttry:\n\t\t\tif desktop_conf.has_option('razor', config_option):\n\t\t\t\tdesktop_conf.set('razor', config_option, image)\n\t\t\t\twith codecs.open(desktop_conf_file, 'w', encoding='utf-8', errors='replace') as f:\n\t\t\t\t\tdesktop_conf.write(f)\n\t\texcept:\n\t\t\tpass\n\n\telif desktop_env in ['fluxbox', 'jwm', 'openbox', 'afterstep', 'i3']:\n\t\ttry:\n\t\t\targs = ['feh', '--bg-scale', image]\n\t\t\tsp.Popen(args)\n\t\texcept:\n\t\t\tsys.stderr.write('Error: Failed to set wallpaper with feh!')\n\t\t\tsys.stderr.write('Please make sre that You have feh installed.')\n\n\telif desktop_env == 'icewm':\n\t\targs = ['icewmbg', image]\n\t\tsp.Popen(args)\n\n\telif desktop_env == 'blackbox':\n\t\targs = ['bsetbg', '-full', image]\n\t\tsp.Popen(args)\n\n\telif desktop_env == 'lxde':\n\t\targs = 'pcmanfm --set-wallpaper %s --wallpaper-mode=scaled' % image\n\t\tsp.Popen(args, shell=True)\n\n\telif desktop_env == 'lxqt':\n\t\targs = 'pcmanfm-qt --set-wallpaper %s --wallpaper-mode=scaled' % image\n\t\tsp.Popen(args, shell=True)\n\n\telif desktop_env == 'windowmaker':\n\t\targs = 'wmsetbg -s -u %s' % image\n\t\tsp.Popen(args, shell=True)\n\n\telif desktop_env == 'enlightenment':\n\t\targs = 'enlightenment_remote -desktop-bg-add 0 0 0 0 %s' % image\n\t\tsp.Popen(args, shell=True)\n\n\telif desktop_env == 'awesome':\n\t\twith sp.Popen(\"awesome-client\", stdin=sp.PIPE) as awesome_client:\n\t\t\tcommand = ('local gears = require(\"gears\"); for s = 1,'\n\t\t\t\t\t\t' screen.count() do gears.wallpaper.maximized'\n\t\t\t\t\t\t'(\"%s\", s, true); end;') % image\n\t\t\tawesome_client.communicate(input=bytes(command, 'UTF-8'))\n\n\telif desktop_env == 'windows':\n\t\tWINDOWS_SCRIPT = dedent('''\n\t\t\treg add \"HKEY_CURRENT_USER\\Control Panel\\Desktop\" \\\n\t\t\t/v Wallpaper /t REG_SZ /d  %s /f\n\n\t\t\trundll32.exe user32.dll,UpdatePerUserSystemParameters\n\t\t\t''') % image\n\n\t\twindows_script_file = os.path.join(\n\t\t\ttempfile.gettempdir(), 'wallscript.bat')\n\n\t\twith open(windows_script_file, 'w') as f:\n\t\t\tf.write(WINDOWS_SCRIPT)\n\n\t\tsp.Popen([windows_script_file], shell=True)\n\n\t\t# Sometimes the method above works\n\t\t# and sometimes the one below\n\n\t\tSPI_SETDESKWALLPAPER = 20\n\t\tctypes.windll.user32.SystemParametersInfoA(\n\t\t\tSPI_SETDESKWALLPAPER, 0, image, 0)\n\n\telif desktop_env == 'mac':\n\t\ttry:\n\t\t\tfrom appscript import app, mactypes\n\t\t\tapp('Finder').desktop_picture.set(mactypes.File(image))\n\t\texcept ImportError:\n\t\t\tOSX_SCRIPT = dedent(\n\t\t\t\t'''tell application \"System Events\"\n\t\t\t\t\t   set desktopCount to count of desktops\n\t\t\t\t\t\t\t repeat with desktopNumber from 1 to desktopCount\n\t\t\t\t\t\t\t   tell desktop desktopNumber\n\t\t\t\t\t\t\t\t set picture to POSIX file \"%s\"\n\t\t\t\t\t\t\t   end tell\n\t\t\t\t\t\t\t end repeat\n\t\t\t\t end tell''') % image\n\n\t\t\tsp.Popen(['osascript', OSX_SCRIPT])\n\telse:\n\t\ttry:\n\t\t\tsp.Popen(['feh', '--bg-scale', image])\n\t\t\t# feh is nearly a catch-all for Linux WMs\n\t\texcept:\n\t\t\tpass", "response": "Sets the desktop wallpaper to an image."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve all quiz reports. Returns a list of all available reports.", "response": "def retrieve_all_quiz_reports(self, quiz_id, course_id, includes_all_versions=None):\r\n        \"\"\"\r\n        Retrieve all quiz reports.\r\n\r\n        Returns a list of all available reports.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # OPTIONAL - includes_all_versions\r\n        \"\"\"Whether to retrieve reports that consider all the submissions or only\r\n        the most recent. Defaults to false, ignored for item_analysis reports.\"\"\"\r\n        if includes_all_versions is not None:\r\n            params[\"includes_all_versions\"] = includes_all_versions\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/quizzes/{quiz_id}/reports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/reports\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new quiz report. Returns a new quiz report.", "response": "def create_quiz_report(self, quiz_id, course_id, quiz_report_report_type, include=None, quiz_report_includes_all_versions=None):\r\n        \"\"\"\r\n        Create a quiz report.\r\n\r\n        Create and return a new report for this quiz. If a previously\r\n        generated report matches the arguments and is still current (i.e.\r\n        there have been no new submissions), it will be returned.\r\n        \r\n        *Responses*\r\n        \r\n        * <code>400 Bad Request</code> if the specified report type is invalid\r\n        * <code>409 Conflict</code> if a quiz report of the specified type is already being\r\n          generated\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - quiz_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_id\"] = quiz_id\r\n\r\n        # REQUIRED - quiz_report[report_type]\r\n        \"\"\"The type of report to be generated.\"\"\"\r\n        self._validate_enum(quiz_report_report_type, [\"student_analysis\", \"item_analysis\"])\r\n        data[\"quiz_report[report_type]\"] = quiz_report_report_type\r\n\r\n        # OPTIONAL - quiz_report[includes_all_versions]\r\n        \"\"\"Whether the report should consider all submissions or only the most\r\n        recent. Defaults to false, ignored for item_analysis.\"\"\"\r\n        if quiz_report_includes_all_versions is not None:\r\n            data[\"quiz_report[includes_all_versions]\"] = quiz_report_includes_all_versions\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Whether the output should include documents for the file and/or progress\r\n        objects associated with this report. (Note: JSON-API only)\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"file\", \"progress\"])\r\n            data[\"include\"] = include\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/quizzes/{quiz_id}/reports with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/quizzes/{quiz_id}/reports\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clampings_iter(self, cues=None):\n        s = cues or list(self.stimuli + self.inhibitors)\n        clampings = it.chain.from_iterable(it.combinations(s, r) for r in xrange(len(s) + 1))\n\n        literals_tpl = {}\n        for stimulus in self.stimuli:\n            literals_tpl[stimulus] = -1\n\n        for c in clampings:\n            literals = literals_tpl.copy()\n            for cues in c:\n                if cues in self.stimuli:\n                    literals[cues] = 1\n                else:\n                    literals[cues] = -1\n\n            yield Clamping(literals.iteritems())", "response": "Iterate over all possible clampings of this experimental setup."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_funset(self):\n        fs = set((gringo.Fun('stimulus', [str(var)]) for var in self.stimuli))\n        fs = fs.union((gringo.Fun('inhibitor', [str(var)]) for var in self.inhibitors))\n        fs = fs.union((gringo.Fun('readout', [str(var)]) for var in self.readouts))\n\n        return fs", "response": "Converts the experimental setup to a set of gringo. Fun objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an experimental setup from a JSON file.", "response": "def from_json(cls, filename):\n        \"\"\"\n        Creates an experimental setup from a JSON file\n\n        Parameters\n        ----------\n        filename : str\n            Absolute path to JSON file\n\n        Returns\n        -------\n        caspo.core.setup.Setup\n            Created object instance\n        \"\"\"\n        with open(filename) as fp:\n            raw = json.load(fp)\n\n        return cls(raw['stimuli'], raw['inhibitors'], raw['readouts'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_json(self, filename):\n        with open(filename, 'w') as fp:\n            json.dump(dict(stimuli=self.stimuli, inhibitors=self.inhibitors, readouts=self.readouts), fp)", "response": "Writes the experimental setup to a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new experimental setup restricted to species present in the given list of networks.", "response": "def filter(self, networks):\n        \"\"\"\n        Returns a new experimental setup restricted to species present in the given list of networks\n\n        Parameters\n        ----------\n        networks : :class:`caspo.core.logicalnetwork.LogicalNetworkList`\n            List of logical networks\n\n        Returns\n        -------\n        caspo.core.setup.Setup\n            The restricted experimental setup\n        \"\"\"\n        cues = self.stimuli + self.inhibitors\n        active_cues = set()\n        active_readouts = set()\n        for clause, var in networks.mappings:\n            active_cues = active_cues.union((l for (l, s) in clause if l in cues))\n            if var in self.readouts:\n                active_readouts.add(var)\n\n        return Setup(active_cues.intersection(self.stimuli), active_cues.intersection(self.inhibitors), active_readouts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cues(self, rename_inhibitors=False):\n        if rename_inhibitors:\n            return self.stimuli + [i+'i' for i in self.inhibitors]\n        else:\n            return self.stimuli + self.inhibitors", "response": "Returns the stimuli and inhibitors species of this experimental setup."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_external_tools_courses(self, course_id, include_parents=None, search_term=None, selectable=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name of the tools to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - selectable\r\n        \"\"\"If true, then only tools that are meant to be selectable are returned\"\"\"\r\n        if selectable is not None:\r\n            params[\"selectable\"] = selectable\r\n\r\n        # OPTIONAL - include_parents\r\n        \"\"\"If true, then include tools installed in all accounts above the current context\"\"\"\r\n        if include_parents is not None:\r\n            params[\"include_parents\"] = include_parents\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/external_tools with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/external_tools\".format(**path), data=data, params=params, no_data=True)", "response": "List external tools. Returns the paginated list of external tools for the current context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting external tools for the given account. Returns a paginated list of external tools for the current context.", "response": "def list_external_tools_accounts(self, account_id, include_parents=None, search_term=None, selectable=None):\r\n        \"\"\"\r\n        List external tools.\r\n\r\n        Returns the paginated list of external tools for the current context.\r\n        See the get request docs for a single tool for a list of properties on an external tool.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name of the tools to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - selectable\r\n        \"\"\"If true, then only tools that are meant to be selectable are returned\"\"\"\r\n        if selectable is not None:\r\n            params[\"selectable\"] = selectable\r\n\r\n        # OPTIONAL - include_parents\r\n        \"\"\"If true, then include tools installed in all accounts above the current context\"\"\"\r\n        if include_parents is not None:\r\n            params[\"include_parents\"] = include_parents\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/external_tools with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/external_tools\".format(**path), data=data, params=params, no_data=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_external_tools_groups(self, group_id, include_parents=None, search_term=None, selectable=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial name of the tools to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - selectable\r\n        \"\"\"If true, then only tools that are meant to be selectable are returned\"\"\"\r\n        if selectable is not None:\r\n            params[\"selectable\"] = selectable\r\n\r\n        # OPTIONAL - include_parents\r\n        \"\"\"If true, then include tools installed in all accounts above the current context\"\"\"\r\n        if include_parents is not None:\r\n            params[\"include_parents\"] = include_parents\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/external_tools with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/external_tools\".format(**path), data=data, params=params, no_data=True)", "response": "List external tools for a group. Returns the paginated list of external tools for the current context."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_sessionless_launch_url_for_external_tool_courses(self, course_id, assignment_id=None, id=None, launch_type=None, module_item_id=None, url=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - id\r\n        \"\"\"The external id of the tool to launch.\"\"\"\r\n        if id is not None:\r\n            params[\"id\"] = id\r\n\r\n        # OPTIONAL - url\r\n        \"\"\"The LTI launch url for the external tool.\"\"\"\r\n        if url is not None:\r\n            params[\"url\"] = url\r\n\r\n        # OPTIONAL - assignment_id\r\n        \"\"\"The assignment id for an assignment launch. Required if launch_type is set to \"assessment\".\"\"\"\r\n        if assignment_id is not None:\r\n            params[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - module_item_id\r\n        \"\"\"The assignment id for a module item launch. Required if launch_type is set to \"module_item\".\"\"\"\r\n        if module_item_id is not None:\r\n            params[\"module_item_id\"] = module_item_id\r\n\r\n        # OPTIONAL - launch_type\r\n        \"\"\"The type of launch to perform on the external tool. Placement names (eg. \"course_navigation\")\r\n        can also be specified to use the custom launch url for that placement; if done, the tool id\r\n        must be provided.\"\"\"\r\n        if launch_type is not None:\r\n            self._validate_enum(launch_type, [\"assessment\", \"module_item\"])\r\n            params[\"launch_type\"] = launch_type\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/external_tools/sessionless_launch with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/external_tools/sessionless_launch\".format(**path), data=data, params=params, no_data=True)", "response": "Returns the URL that the LTI launch url for the specified external tool."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_single_external_tool_courses(self, course_id, external_tool_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - external_tool_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"external_tool_id\"] = external_tool_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/external_tools/{external_tool_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/external_tools/{external_tool_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Get a single external tool. Returns the single external tool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_single_external_tool_accounts(self, account_id, external_tool_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - external_tool_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"external_tool_id\"] = external_tool_id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/external_tools/{external_tool_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/external_tools/{external_tool_id}\".format(**path), data=data, params=params, no_data=True)", "response": "Get a single external tool. Returns the single external tool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_external_tool_courses(self, name, course_id, consumer_key, privacy_level, shared_secret, account_navigation_enabled=None, account_navigation_selection_height=None, account_navigation_selection_width=None, account_navigation_text=None, account_navigation_url=None, config_type=None, config_url=None, config_xml=None, course_home_sub_navigation_enabled=None, course_home_sub_navigation_icon_url=None, course_home_sub_navigation_text=None, course_home_sub_navigation_url=None, course_navigation_default=None, course_navigation_enabled=None, course_navigation_text=None, course_navigation_visibility=None, course_navigation_windowTarget=None, custom_fields_field_name=None, description=None, domain=None, editor_button_enabled=None, editor_button_icon_url=None, editor_button_message_type=None, editor_button_selection_height=None, editor_button_selection_width=None, editor_button_url=None, homework_submission_enabled=None, homework_submission_message_type=None, homework_submission_text=None, homework_submission_url=None, icon_url=None, link_selection_enabled=None, link_selection_message_type=None, link_selection_text=None, link_selection_url=None, migration_selection_enabled=None, migration_selection_message_type=None, migration_selection_url=None, not_selectable=None, oauth_compliant=None, resource_selection_enabled=None, resource_selection_icon_url=None, resource_selection_selection_height=None, resource_selection_selection_width=None, resource_selection_url=None, text=None, tool_configuration_enabled=None, tool_configuration_message_type=None, tool_configuration_url=None, url=None, user_navigation_enabled=None, user_navigation_text=None, user_navigation_url=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - name\r\n        \"\"\"The name of the tool\"\"\"\r\n        data[\"name\"] = name\r\n\r\n        # REQUIRED - privacy_level\r\n        \"\"\"What information to send to the external tool.\"\"\"\r\n        self._validate_enum(privacy_level, [\"anonymous\", \"name_only\", \"public\"])\r\n        data[\"privacy_level\"] = privacy_level\r\n\r\n        # REQUIRED - consumer_key\r\n        \"\"\"The consumer key for the external tool\"\"\"\r\n        data[\"consumer_key\"] = consumer_key\r\n\r\n        # REQUIRED - shared_secret\r\n        \"\"\"The shared secret with the external tool\"\"\"\r\n        data[\"shared_secret\"] = shared_secret\r\n\r\n        # OPTIONAL - description\r\n        \"\"\"A description of the tool\"\"\"\r\n        if description is not None:\r\n            data[\"description\"] = description\r\n\r\n        # OPTIONAL - url\r\n        \"\"\"The url to match links against. Either \"url\" or \"domain\" should be set,\r\n        not both.\"\"\"\r\n        if url is not None:\r\n            data[\"url\"] = url\r\n\r\n        # OPTIONAL - domain\r\n        \"\"\"The domain to match links against. Either \"url\" or \"domain\" should be\r\n        set, not both.\"\"\"\r\n        if domain is not None:\r\n            data[\"domain\"] = domain\r\n\r\n        # OPTIONAL - icon_url\r\n        \"\"\"The url of the icon to show for this tool\"\"\"\r\n        if icon_url is not None:\r\n            data[\"icon_url\"] = icon_url\r\n\r\n        # OPTIONAL - text\r\n        \"\"\"The default text to show for this tool\"\"\"\r\n        if text is not None:\r\n            data[\"text\"] = text\r\n\r\n        # OPTIONAL - custom_fields[field_name]\r\n        \"\"\"Custom fields that will be sent to the tool consumer; can be used\r\n        multiple times\"\"\"\r\n        if custom_fields_field_name is not None:\r\n            data[\"custom_fields[field_name]\"] = custom_fields_field_name\r\n\r\n        # OPTIONAL - account_navigation[url]\r\n        \"\"\"The url of the external tool for account navigation\"\"\"\r\n        if account_navigation_url is not None:\r\n            data[\"account_navigation[url]\"] = account_navigation_url\r\n\r\n        # OPTIONAL - account_navigation[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if account_navigation_enabled is not None:\r\n            data[\"account_navigation[enabled]\"] = account_navigation_enabled\r\n\r\n        # OPTIONAL - account_navigation[text]\r\n        \"\"\"The text that will show on the left-tab in the account navigation\"\"\"\r\n        if account_navigation_text is not None:\r\n            data[\"account_navigation[text]\"] = account_navigation_text\r\n\r\n        # OPTIONAL - account_navigation[selection_width]\r\n        \"\"\"The width of the dialog the tool is launched in\"\"\"\r\n        if account_navigation_selection_width is not None:\r\n            data[\"account_navigation[selection_width]\"] = account_navigation_selection_width\r\n\r\n        # OPTIONAL - account_navigation[selection_height]\r\n        \"\"\"The height of the dialog the tool is launched in\"\"\"\r\n        if account_navigation_selection_height is not None:\r\n            data[\"account_navigation[selection_height]\"] = account_navigation_selection_height\r\n\r\n        # OPTIONAL - user_navigation[url]\r\n        \"\"\"The url of the external tool for user navigation\"\"\"\r\n        if user_navigation_url is not None:\r\n            data[\"user_navigation[url]\"] = user_navigation_url\r\n\r\n        # OPTIONAL - user_navigation[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if user_navigation_enabled is not None:\r\n            data[\"user_navigation[enabled]\"] = user_navigation_enabled\r\n\r\n        # OPTIONAL - user_navigation[text]\r\n        \"\"\"The text that will show on the left-tab in the user navigation\"\"\"\r\n        if user_navigation_text is not None:\r\n            data[\"user_navigation[text]\"] = user_navigation_text\r\n\r\n        # OPTIONAL - course_home_sub_navigation[url]\r\n        \"\"\"The url of the external tool for right-side course home navigation menu\"\"\"\r\n        if course_home_sub_navigation_url is not None:\r\n            data[\"course_home_sub_navigation[url]\"] = course_home_sub_navigation_url\r\n\r\n        # OPTIONAL - course_home_sub_navigation[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if course_home_sub_navigation_enabled is not None:\r\n            data[\"course_home_sub_navigation[enabled]\"] = course_home_sub_navigation_enabled\r\n\r\n        # OPTIONAL - course_home_sub_navigation[text]\r\n        \"\"\"The text that will show on the right-side course home navigation menu\"\"\"\r\n        if course_home_sub_navigation_text is not None:\r\n            data[\"course_home_sub_navigation[text]\"] = course_home_sub_navigation_text\r\n\r\n        # OPTIONAL - course_home_sub_navigation[icon_url]\r\n        \"\"\"The url of the icon to show in the right-side course home navigation menu\"\"\"\r\n        if course_home_sub_navigation_icon_url is not None:\r\n            data[\"course_home_sub_navigation[icon_url]\"] = course_home_sub_navigation_icon_url\r\n\r\n        # OPTIONAL - course_navigation[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if course_navigation_enabled is not None:\r\n            data[\"course_navigation[enabled]\"] = course_navigation_enabled\r\n\r\n        # OPTIONAL - course_navigation[text]\r\n        \"\"\"The text that will show on the left-tab in the course navigation\"\"\"\r\n        if course_navigation_text is not None:\r\n            data[\"course_navigation[text]\"] = course_navigation_text\r\n\r\n        # OPTIONAL - course_navigation[visibility]\r\n        \"\"\"Who will see the navigation tab. \"admins\" for course admins, \"members\" for\r\n        students, null for everyone\"\"\"\r\n        if course_navigation_visibility is not None:\r\n            self._validate_enum(course_navigation_visibility, [\"admins\", \"members\"])\r\n            data[\"course_navigation[visibility]\"] = course_navigation_visibility\r\n\r\n        # OPTIONAL - course_navigation[windowTarget]\r\n        \"\"\"Determines how the navigation tab will be opened.\r\n        \"_blank\"\tLaunches the external tool in a new window or tab.\r\n        \"_self\"\t(Default) Launches the external tool in an iframe inside of Canvas.\"\"\"\r\n        if course_navigation_windowTarget is not None:\r\n            self._validate_enum(course_navigation_windowTarget, [\"_blank\", \"_self\"])\r\n            data[\"course_navigation[windowTarget]\"] = course_navigation_windowTarget\r\n\r\n        # OPTIONAL - course_navigation[default]\r\n        \"\"\"Whether the navigation option will show in the course by default or\r\n        whether the teacher will have to explicitly enable it\"\"\"\r\n        if course_navigation_default is not None:\r\n            data[\"course_navigation[default]\"] = course_navigation_default\r\n\r\n        # OPTIONAL - editor_button[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if editor_button_url is not None:\r\n            data[\"editor_button[url]\"] = editor_button_url\r\n\r\n        # OPTIONAL - editor_button[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if editor_button_enabled is not None:\r\n            data[\"editor_button[enabled]\"] = editor_button_enabled\r\n\r\n        # OPTIONAL - editor_button[icon_url]\r\n        \"\"\"The url of the icon to show in the WYSIWYG editor\"\"\"\r\n        if editor_button_icon_url is not None:\r\n            data[\"editor_button[icon_url]\"] = editor_button_icon_url\r\n\r\n        # OPTIONAL - editor_button[selection_width]\r\n        \"\"\"The width of the dialog the tool is launched in\"\"\"\r\n        if editor_button_selection_width is not None:\r\n            data[\"editor_button[selection_width]\"] = editor_button_selection_width\r\n\r\n        # OPTIONAL - editor_button[selection_height]\r\n        \"\"\"The height of the dialog the tool is launched in\"\"\"\r\n        if editor_button_selection_height is not None:\r\n            data[\"editor_button[selection_height]\"] = editor_button_selection_height\r\n\r\n        # OPTIONAL - editor_button[message_type]\r\n        \"\"\"Set this to ContentItemSelectionRequest to tell the tool to use\r\n        content-item; otherwise, omit\"\"\"\r\n        if editor_button_message_type is not None:\r\n            data[\"editor_button[message_type]\"] = editor_button_message_type\r\n\r\n        # OPTIONAL - homework_submission[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if homework_submission_url is not None:\r\n            data[\"homework_submission[url]\"] = homework_submission_url\r\n\r\n        # OPTIONAL - homework_submission[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if homework_submission_enabled is not None:\r\n            data[\"homework_submission[enabled]\"] = homework_submission_enabled\r\n\r\n        # OPTIONAL - homework_submission[text]\r\n        \"\"\"The text that will show on the homework submission tab\"\"\"\r\n        if homework_submission_text is not None:\r\n            data[\"homework_submission[text]\"] = homework_submission_text\r\n\r\n        # OPTIONAL - homework_submission[message_type]\r\n        \"\"\"Set this to ContentItemSelectionRequest to tell the tool to use\r\n        content-item; otherwise, omit\"\"\"\r\n        if homework_submission_message_type is not None:\r\n            data[\"homework_submission[message_type]\"] = homework_submission_message_type\r\n\r\n        # OPTIONAL - link_selection[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if link_selection_url is not None:\r\n            data[\"link_selection[url]\"] = link_selection_url\r\n\r\n        # OPTIONAL - link_selection[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if link_selection_enabled is not None:\r\n            data[\"link_selection[enabled]\"] = link_selection_enabled\r\n\r\n        # OPTIONAL - link_selection[text]\r\n        \"\"\"The text that will show for the link selection text\"\"\"\r\n        if link_selection_text is not None:\r\n            data[\"link_selection[text]\"] = link_selection_text\r\n\r\n        # OPTIONAL - link_selection[message_type]\r\n        \"\"\"Set this to ContentItemSelectionRequest to tell the tool to use\r\n        content-item; otherwise, omit\"\"\"\r\n        if link_selection_message_type is not None:\r\n            data[\"link_selection[message_type]\"] = link_selection_message_type\r\n\r\n        # OPTIONAL - migration_selection[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if migration_selection_url is not None:\r\n            data[\"migration_selection[url]\"] = migration_selection_url\r\n\r\n        # OPTIONAL - migration_selection[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if migration_selection_enabled is not None:\r\n            data[\"migration_selection[enabled]\"] = migration_selection_enabled\r\n\r\n        # OPTIONAL - migration_selection[message_type]\r\n        \"\"\"Set this to ContentItemSelectionRequest to tell the tool to use\r\n        content-item; otherwise, omit\"\"\"\r\n        if migration_selection_message_type is not None:\r\n            data[\"migration_selection[message_type]\"] = migration_selection_message_type\r\n\r\n        # OPTIONAL - tool_configuration[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if tool_configuration_url is not None:\r\n            data[\"tool_configuration[url]\"] = tool_configuration_url\r\n\r\n        # OPTIONAL - tool_configuration[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if tool_configuration_enabled is not None:\r\n            data[\"tool_configuration[enabled]\"] = tool_configuration_enabled\r\n\r\n        # OPTIONAL - tool_configuration[message_type]\r\n        \"\"\"Set this to ContentItemSelectionRequest to tell the tool to use\r\n        content-item; otherwise, omit\"\"\"\r\n        if tool_configuration_message_type is not None:\r\n            data[\"tool_configuration[message_type]\"] = tool_configuration_message_type\r\n\r\n        # OPTIONAL - resource_selection[url]\r\n        \"\"\"The url of the external tool\"\"\"\r\n        if resource_selection_url is not None:\r\n            data[\"resource_selection[url]\"] = resource_selection_url\r\n\r\n        # OPTIONAL - resource_selection[enabled]\r\n        \"\"\"Set this to enable this feature\"\"\"\r\n        if resource_selection_enabled is not None:\r\n            data[\"resource_selection[enabled]\"] = resource_selection_enabled\r\n\r\n        # OPTIONAL - resource_selection[icon_url]\r\n        \"\"\"The url of the icon to show in the module external tool list\"\"\"\r\n        if resource_selection_icon_url is not None:\r\n            data[\"resource_selection[icon_url]\"] = resource_selection_icon_url\r\n\r\n        # OPTIONAL - resource_selection[selection_width]\r\n        \"\"\"The width of the dialog the tool is launched in\"\"\"\r\n        if resource_selection_selection_width is not None:\r\n            data[\"resource_selection[selection_width]\"] = resource_selection_selection_width\r\n\r\n        # OPTIONAL - resource_selection[selection_height]\r\n        \"\"\"The height of the dialog the tool is launched in\"\"\"\r\n        if resource_selection_selection_height is not None:\r\n            data[\"resource_selection[selection_height]\"] = resource_selection_selection_height\r\n\r\n        # OPTIONAL - config_type\r\n        \"\"\"Configuration can be passed in as CC xml instead of using query\r\n        parameters. If this value is \"by_url\" or \"by_xml\" then an xml\r\n        configuration will be expected in either the \"config_xml\" or \"config_url\"\r\n        parameter. Note that the name parameter overrides the tool name provided\r\n        in the xml\"\"\"\r\n        if config_type is not None:\r\n            data[\"config_type\"] = config_type\r\n\r\n        # OPTIONAL - config_xml\r\n        \"\"\"XML tool configuration, as specified in the CC xml specification. This is\r\n        required if \"config_type\" is set to \"by_xml\"\"\"\"\r\n        if config_xml is not None:\r\n            data[\"config_xml\"] = config_xml\r\n\r\n        # OPTIONAL - config_url\r\n        \"\"\"URL where the server can retrieve an XML tool configuration, as specified\r\n        in the CC xml specification. This is required if \"config_type\" is set to\r\n        \"by_url\"\"\"\"\r\n        if config_url is not None:\r\n            data[\"config_url\"] = config_url\r\n\r\n        # OPTIONAL - not_selectable\r\n        \"\"\"Default: false, if set to true the tool won't show up in the external tool\r\n        selection UI in modules and assignments\"\"\"\r\n        if not_selectable is not None:\r\n            data[\"not_selectable\"] = not_selectable\r\n\r\n        # OPTIONAL - oauth_compliant\r\n        \"\"\"Default: false, if set to true LTI query params will not be copied to the\r\n        post body.\"\"\"\r\n        if oauth_compliant is not None:\r\n            data[\"oauth_compliant\"] = oauth_compliant\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/external_tools with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/external_tools\".format(**path), data=data, params=params, no_data=True)", "response": "Create an external tool in the specified course."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert(self, key, value):\n        self._find_lte(key)\n        node = self._create_node(key, value)\n        self._insert(node)", "response": "Insert a key - value pair into the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace the value of the first key - value pair with key *key*.", "response": "def replace(self, key, value):\n        \"\"\"Replace the value of the first key-value pair with key *key*.\n\n        If the key was not found, the pair is inserted.\n        \"\"\"\n        self._find_lt(key)\n        node = self._path[0][2]\n        if node is self._tail or key < node[0]:\n            node = self._create_node(key, value)\n            self._insert(node)\n        else:\n            node[1] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n        for i in range(self.maxlevel):\n            self._head[2+i] = self._tail\n            self._tail[-1] = 0\n        self._level = 1", "response": "Remove all key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an iterator yielding the key - value pairs in the list.", "response": "def items(self, start=None, stop=None):\n        \"\"\"Return an iterator yielding pairs.\n\n        If *start* is specified, iteration starts at the first pair with a key\n        that is larger than or equal to *start*. If not specified, iteration\n        starts at the first pair in the list.\n\n        If *stop* is specified, iteration stops at the last pair that is\n        smaller than *stop*. If not specified, iteration end with the last pair\n        in the list.\n        \"\"\"\n        if start is None:\n            node = self._head[2]\n        else:\n            self._find_lt(start)\n            node = self._path[0][2]\n        while node is not self._tail and (stop is None or node[0] < stop):\n            yield (node[0], node[1])\n            node = node[2]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes items but returns only the keys.", "response": "def keys(self, start=None, stop=None):\n        \"\"\"Like :meth:`items` but returns only the keys.\"\"\"\n        return (item[0] for item in self.items(start, stop))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlikes items but returns only the values.", "response": "def values(self, start=None, stop=None):\n        \"\"\"Like :meth:`items` but returns only the values.\"\"\"\n        return (item[1] for item in self.items(start, stop))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef popitem(self):\n        node = self._head[2]\n        if node is self._tail:\n            raise KeyError('list is empty')\n        self._find_lt(node[0])\n        self._remove(node)\n        return (node[0], node[1])", "response": "Removes the first key - value pair and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches the key - value pair with key and return its value.", "response": "def search(self, key, default=None):\n        \"\"\"Find the first key-value pair with key *key* and return its value.\n\n        If the key was not found, return *default*. If no default was provided,\n        return ``None``. This method never raises a ``KeyError``.\n        \"\"\"\n        self._find_lt(key)\n        node = self._path[0][2]\n        if node is self._tail or key < node[0]:\n            return default\n        return node[1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, key):\n        self._find_lt(key)\n        node = self._path[0][2]\n        if node is self._tail or key < node[0]:\n            raise KeyError('{!r} is not in list'.format(key))\n        self._remove(node)", "response": "Removes the first key - value pair with key *key*."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pop(self, key, default=UNSET):\n        self._find_lt(key)\n        node = self._path[0][2]\n        if node is self._tail or key < node[0]:\n            if default is self.UNSET:\n                raise KeyError('key {!r} not in list')\n            return default\n        self._remove(node)\n        return node[1]", "response": "Removes the first key - value pair with key *key*. If no key - value pair was found raise KeyError. If default is not provided raise KeyError."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the index of the first key - value pair with key and return its distance.", "response": "def index(self, key, default=UNSET):\n        \"\"\"Find the first key-value pair with key *key* and return its position.\n\n        If the key is not found, return *default*. If default was not provided,\n        raise a ``KeyError``\n        \"\"\"\n        self._find_lt(key)\n        node = self._path[0][2]\n        if node is self._tail or key < node[0]:\n            if default is self.UNSET:\n                raise KeyError('key {!r} not in list'.format(key))\n            return default\n        return self._distance[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of pairs with key key.", "response": "def count(self, key):\n        \"\"\"Return the number of pairs with key *key*.\"\"\"\n        count = 0\n        pos = self.index(key, -1)\n        if pos == -1:\n            return count\n        count += 1\n        for i in range(pos+1, len(self)):\n            if self[i][0] != key:\n                break\n            count += 1\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a single tab for a course. Returns the updated tab.", "response": "def update_tab_for_course(self, tab_id, course_id, hidden=None, position=None):\r\n        \"\"\"\r\n        Update a tab for a course.\r\n\r\n        Home and Settings tabs are not manageable, and can't be hidden or moved\r\n        \r\n        Returns a tab object\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - tab_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"tab_id\"] = tab_id\r\n\r\n        # OPTIONAL - position\r\n        \"\"\"The new position of the tab, 1-based\"\"\"\r\n        if position is not None:\r\n            data[\"position\"] = position\r\n\r\n        # OPTIONAL - hidden\r\n        \"\"\"no description\"\"\"\r\n        if hidden is not None:\r\n            data[\"hidden\"] = hidden\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/tabs/{tab_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/tabs/{tab_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying all rows and columns from a table.", "response": "def select_all(self, table, limit=MAX_ROWS_PER_QUERY, execute=True):\n        \"\"\"Query all rows and columns from a table.\"\"\"\n        # Determine if a row per query limit should be set\n        num_rows = self.count_rows(table)\n        if num_rows > limit:\n            return self._select_batched(table, '*', num_rows, limit, execute=execute)\n        else:\n            return self.select(table, '*', execute=execute)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries distinct values from a table.", "response": "def select_distinct(self, table, cols='*', execute=True):\n        \"\"\"Query distinct values from a table.\"\"\"\n        return self.select(table, cols, execute, select_type='SELECT DISTINCT')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select(self, table, cols, execute=True, select_type='SELECT', return_type=list):\n        # Validate query type\n        select_type = select_type.upper()\n        assert select_type in SELECT_QUERY_TYPES\n\n        # Concatenate statement\n        statement = '{0} {1} FROM {2}'.format(select_type, join_cols(cols), wrap(table))\n        if not execute:\n            # Return command\n            return statement\n\n        # Retrieve values\n        values = self.fetch(statement)\n        return self._return_rows(table, cols, values, return_type)", "response": "Query every row and only certain columns from a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects all rows and columns from two tables where a common value is shared.", "response": "def select_join(self, table1, table2, cols, table1_col, table2_col=None, join_type=None):\n        \"\"\"\n        Left join all rows and columns from two tables where a common value is shared.\n\n        :param table1: Name of table #1\n        :param table2: Name of table #2\n        :param cols: List of columns or column tuples\n            String or flat list: Assumes column(s) are from table #1 if not specified\n            List of tuples: Each tuple in list of columns represents (table_name, column_name)\n        :param table1_col: Column from table #1 to use as key\n        :param table2_col: Column from table #2 to use as key\n        :param join_type: Type of join query\n        :return: Queried rows\n        \"\"\"\n        # Check if cols is a list of tuples\n        if isinstance(cols[0], tuple):\n            cols = join_cols(['{0}.{1}'.format(tbl, col) for tbl, col in cols])\n        else:\n            cols = join_cols(['{0}.{1}'.format(table1, col) for col in cols])\n\n        # Validate join_type and table2_col\n        join_type = join_type.lower().split(' ', 1)[0].upper() + ' JOIN' if join_type else 'LEFT JOIN'\n        assert join_type in JOIN_QUERY_TYPES\n        table2_col = table2_col if table2_col else table1_col\n\n        # Concatenate and return statement\n        statement = '''\n        SELECT {columns}\n        FROM {table1}\n        {join_type} {table2} ON {table1}.{table1_col} = {table2}.{table2_col}\n        '''.format(table1=wrap(table1), table2=wrap(table2), columns=cols, table1_col=table1_col, table2_col=table2_col,\n                   join_type=join_type)\n        return self.fetch(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select_limit(self, table, cols='*', offset=0, limit=MAX_ROWS_PER_QUERY):\n        return self.fetch(self._select_limit_statement(table, cols, offset, limit))", "response": "Run a select query with an offset and limit parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef select_where(self, table, cols, where, return_type=list):\n        # Unpack WHERE clause dictionary into tuple\n        if isinstance(where, (list, set)):\n            # Multiple WHERE clause's (separate with AND)\n            clauses = [self._where_clause(clause) for clause in where]\n            where_statement = ' AND '.join(clauses)\n        else:\n            where_statement = self._where_clause(where)\n\n        # Concatenate full statement and execute\n        statement = \"SELECT {0} FROM {1} WHERE {2}\".format(join_cols(cols), wrap(table), where_statement)\n        values = self.fetch(statement)\n        return self._return_rows(table, cols, values, return_type)", "response": "Query certain rows from a table where a particular value is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries rows from a table where a columns value is found between two values.", "response": "def select_where_between(self, table, cols, where_col, between):\n        \"\"\"\n        Query rows from a table where a columns value is found between two values.\n\n        :param table: Name of the table\n        :param cols: List, tuple or set of columns or string with single column name\n        :param where_col: Column to check values against\n        :param between: Tuple with min and max values for comparison\n        :return: Queried rows\n        \"\"\"\n        # Unpack WHERE clause dictionary into tuple\n        min_val, max_val = between\n\n        # Concatenate full statement and execute\n        statement = \"SELECT {0} FROM {1} WHERE {2} BETWEEN {3} AND {4}\".format(join_cols(cols), wrap(table), where_col,\n                                                                               min_val, max_val)\n        return self.fetch(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery rows from a table where a specific pattern is found in a column.", "response": "def select_where_like(self, table, cols, where_col, start=None, end=None, anywhere=None,\n                          index=(None, None), length=None):\n        \"\"\"\n        Query rows from a table where a specific pattern is found in a column.\n\n        MySQL syntax assumptions:\n            (%) The percent sign represents zero, one, or multiple characters.\n            (_) The underscore represents a single character.\n\n        :param table: Name of the table\n        :param cols: List, tuple or set of columns or string with single column name\n        :param where_col: Column to check pattern against\n        :param start: Value to be found at the start\n        :param end: Value to be found at the end\n        :param anywhere: Value to be found anywhere\n        :param index: Value to be found at a certain index\n        :param length: Minimum character length\n        :return: Queried rows\n        \"\"\"\n        # Retrieve search pattern\n        pattern = self._like_pattern(start, end, anywhere, index, length)\n\n        # Concatenate full statement and execute\n        statement = \"SELECT {0} FROM {1} WHERE {2} LIKE '{3}'\".format(join_cols(cols), wrap(table), where_col, pattern)\n        return self.fetch(statement)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a where clause tuple and concatenate a MySQL WHERE statement.", "response": "def _where_clause(where):\n        \"\"\"\n        Unpack a where clause tuple and concatenate a MySQL WHERE statement.\n\n        :param where: 2 or 3 part tuple containing a where_column and a where_value (optional operator)\n        :return: WHERE clause statement\n        \"\"\"\n        assert isinstance(where, tuple)\n        if len(where) == 3:\n            where_col, operator, where_val = where\n        else:\n            where_col, where_val = where\n            operator = '='\n        assert operator in SELECT_WHERE_OPERATORS\n\n        # Concatenate WHERE clause (ex: **first_name='John'**)\n        return \"{0}{1}'{2}'\".format(where_col, operator, where_val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _return_rows(self, table, cols, values, return_type):\n        if return_type is dict:\n            # Pack each row into a dictionary\n            cols = self.get_columns(table) if cols is '*' else cols\n            if len(values) > 0 and isinstance(values[0], (set, list, tuple)):\n                return [dict(zip(cols, row)) for row in values]\n            else:\n                return dict(zip(cols, values))\n        elif return_type is tuple:\n            return [tuple(row) for row in values]\n        else:\n            return values", "response": "Return fetched rows in the desired type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting select queries in small batches and return joined resutls.", "response": "def _select_batched(self, table, cols, num_rows, limit, queries_per_batch=3, execute=True):\n        \"\"\"Run select queries in small batches and return joined resutls.\"\"\"\n        # Execute select queries in small batches to avoid connection timeout\n        commands, offset = [], 0\n        while num_rows > 0:\n            # Use number of rows as limit if num_rows < limit\n            _limit = min(limit, num_rows)\n\n            # Execute select_limit query\n            commands.append(self._select_limit_statement(table, cols=cols, offset=offset, limit=limit))\n            offset += _limit\n            num_rows += -_limit\n\n        # Execute commands\n        if execute:\n            rows = []\n            til_reconnect = queries_per_batch\n            for c in commands:\n                if til_reconnect == 0:\n                    self.disconnect()\n                    self.reconnect()\n                    til_reconnect = queries_per_batch\n                rows.extend(self.fetch(c, False))\n                til_reconnect += -1\n            del commands\n            return rows\n        # Return commands\n        else:\n            return commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconcatenates a select with offset and limit statement.", "response": "def _select_limit_statement(table, cols='*', offset=0, limit=MAX_ROWS_PER_QUERY):\n        \"\"\"Concatenate a select with offset and limit statement.\"\"\"\n        return 'SELECT {0} FROM {1} LIMIT {2}, {3}'.format(join_cols(cols), wrap(table), offset, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a LIKE pattern for a specific set of values.", "response": "def _like_pattern(start, end, anywhere, index, length):\n        \"\"\"\n        Create a LIKE pattern to use as a search parameter for a WHERE clause.\n\n        :param start: Value to be found at the start\n        :param end: Value to be found at the end\n        :param anywhere: Value to be found anywhere\n        :param index: Value to be found at a certain index\n        :param length: Minimum character length\n        :return: WHERE pattern\n        \"\"\"\n        # Unpack index tuple\n        index_num, index_char = index\n        index = None\n\n        # Start, end, anywhere\n        if all(i for i in [start, end, anywhere]) and not any(i for i in [index, length]):\n            return '{start}%{anywhere}%{end}'.format(start=start, end=end, anywhere=anywhere)\n\n        # Start, end\n        elif all(i for i in [start, end]) and not any(i for i in [anywhere, index, length]):\n            return '{start}%{end}'.format(start=start, end=end)\n\n        # Start, anywhere\n        elif all(i for i in [start, anywhere]) and not any(i for i in [end, index, length]):\n            return '{start}%{anywhere}%'.format(start=start, anywhere=anywhere)\n\n        # End, anywhere\n        elif all(i for i in [end, anywhere]) and not any(i for i in [start, index, length]):\n            return '%{anywhere}%{end}'.format(end=end, anywhere=anywhere)\n\n        # Start\n        elif start and not any(i for i in [end, anywhere, index, length]):\n            return '{start}%'.format(start=start)\n\n        # End\n        elif end and not any(i for i in [start, anywhere, index, length]):\n            return '%{end}'.format(end=end)\n\n        # Anywhere\n        elif anywhere and not any(i for i in [start, end, index, length]):\n            return '%{anywhere}%'.format(anywhere=anywhere)\n\n        # Index\n        elif index_num and index_char and not any(i for i in [start, end, anywhere, length]):\n            return '{index_num}{index_char}%'.format(index_num='_' * (index_num + 1), index_char=index_char)\n\n        # Length\n        elif length and not any(i for i in [start, end, anywhere, index]):\n            return '{length}'.format(length='_%' * length)\n\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an insert statement string for dumping to text file or MySQL execution.", "response": "def insert_statement(table, columns, values):\n    \"\"\"Generate an insert statement string for dumping to text file or MySQL execution.\"\"\"\n    if not all(isinstance(r, (list, set, tuple)) for r in values):\n        values = [[r] for r in values]\n    rows = []\n    for row in values:\n        new_row = []\n        for col in row:\n            if col is None:\n                new_col = 'NULL'\n            elif isinstance(col, (int, float, Decimal)):\n                new_col = str(MySQLConverterBase().to_mysql(col))\n            else:\n                string = str(MySQLConverterBase().to_mysql(col))\n                if \"'\" in string:\n                    new_col = '\"' + string + '\"'\n                else:\n                    new_col = \"'\" + string + \"'\"\n            new_row.append(new_col)\n        rows.append(', '.join(new_row))\n    vals = '(' + '),\\n\\t('.join(rows) + ')'\n    statement = \"INSERT INTO\\n\\t{0} ({1}) \\nVALUES\\n\\t{2}\".format(wrap(table), cols_str(columns), vals)\n    return statement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexporting a table structure and data to SQL file for backup or later import.", "response": "def dump_table(self, table, drop_statement=True):\n        \"\"\"Export a table structure and data to SQL file for backup or later import.\"\"\"\n        create_statement = self.get_table_definition(table)\n        data = self.select_all(table)\n        statements = ['\\n', sql_file_comment(''),\n                      sql_file_comment('Table structure and data dump for {0}'.format(table)), sql_file_comment('')]\n        if drop_statement:\n            statements.append('\\nDROP TABLE IF EXISTS {0};'.format(wrap(table)))\n        statements.append('{0};\\n'.format(create_statement))\n        if len(data) > 0:\n            statements.append('{0};'.format(insert_statement(table, self.get_columns(table), data)))\n        return '\\n'.join(statements)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_database(self, file_path, database=None, tables=None):\n        # Change database if needed\n        if database:\n            self.change_db(database)\n\n        # Set table\n        if not tables:\n            tables = self.tables\n\n        # Retrieve and join dump statements\n        statements = [self.dump_table(table) for table in tqdm(tables, total=len(tables), desc='Generating dump files')]\n        dump = 'SET FOREIGN_KEY_CHECKS=0;' + '\\n'.join(statements) + '\\nSET FOREIGN_KEY_CHECKS=1;'\n\n        # Write dump statements to sql file\n        file_path = file_path if file_path.endswith('.sql') else file_path + '.sql'\n        write_text(dump, file_path)\n        return file_path", "response": "Export the table structure and data for tables in a database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nallows to retry method execution few times.", "response": "def retry(method):\n    \"\"\"\n    Allows to retry method execution few times.\n    \"\"\"\n\n    def inner(self, *args, **kwargs):\n        attempt_number = 1\n        while attempt_number < self.retries:\n            try:\n                return method(self, *args, **kwargs)\n            except HasOffersException as exc:\n                if 'API usage exceeded rate limit' not in str(exc):\n                    raise exc\n                self.logger.debug('Retrying due: %s', exc)\n                time.sleep(self.retry_timeout)\n            except requests.exceptions.ConnectionError:\n                # This happens when the session gets expired\n                self.logger.debug('Recreating session due to ConnectionError')\n                self._session = requests.Session()\n            attempt_number += 1\n        raise MaxRetriesExceeded\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_managers(self):\n        self._managers = {}\n        for manager_class in MODEL_MANAGERS:\n            instance = manager_class(self)\n            if not instance.forbid_registration \\\n                    and not isinstance(instance, ApplicationManager) or instance.__class__ is ApplicationManager:\n                # Descendants of ``ApplicationManager`` shouldn't be present in API instance.  They are controlled by\n                # Application controller. The manager itself, on the other hand, should.\n                setattr(self, instance.name, instance)\n            if instance.model:\n                self._managers[instance.model.__name__] = instance\n            if instance.model_aliases:\n                for alias in instance.model_aliases:\n                    self._managers[alias] = instance", "response": "Sets up the managers for this API instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _call(self, target, method, target_class=None, single_result=True, raw=False, files=None, **kwargs):\n        if target_class is None:\n            target_class = target\n        params = prepare_query_params(\n            NetworkToken=self.network_token,\n            NetworkId=self.network_id,\n            Target=target,\n            Method=method,\n            **kwargs\n        )\n        kwargs = {'url': self.endpoint, 'params': params, 'verify': self.verify, 'method': 'GET'}\n        if files:\n            kwargs.update({'method': 'POST', 'files': files})\n\n        self.logger.debug('Request parameters: %s', params)\n        response = self.session.request(**kwargs)\n\n        self.logger.debug('Response [%s]: %s', response.status_code, response.text)\n        response.raise_for_status()\n        data = response.json(object_pairs_hook=OrderedDict)\n        return self.handle_response(data, target=target_class, single_result=single_result, raw=raw)", "response": "Internal method to make a call to HasOffers API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_response(self, content, target=None, single_result=True, raw=False):\n        response = content['response']\n\n        self.check_errors(response)\n\n        data = response.get('data')\n\n        if is_empty(data):\n            return data\n        elif is_paginated(data):\n            if 'count' in data and not data['count']:\n                # Response is paginated, but is empty\n                return data['data']\n            data = data['data']\n\n        if raw:\n            return data\n        return self.init_all_objects(data, target=target, single_result=single_result)", "response": "Handles the response from the server and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing all model instances from given data.", "response": "def init_all_objects(self, data, target=None, single_result=True):\n        \"\"\"\n        Initializes model instances from given data.\n        Returns single instance if single_result=True.\n        \"\"\"\n        if single_result:\n            return self.init_target_object(target, data)\n        return list(self.expand_models(target, data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_target_object(self, target, data):\n        target_object = self.init_single_object(target, data.pop(target, data))\n        for key, item in data.items():\n            key_alias = MANAGER_ALIASES.get(key, key)\n            if item:\n                # Item is an OrderedDict with 4 possible structure patterns:\n                #   - Just an OrderedDict with (key - value)'s\n                #   - OrderedDict with single (key - OrderedDict)\n                #   - OrderedDict with multiple (key - OrderedDict)'s\n                #   - String (like CreativeCode model)\n                if isinstance(item, str):\n                    children = item\n                else:\n                    first_key = list(item.keys())[0]\n                    if isinstance(item[first_key], OrderedDict):\n                        instances = item.values()\n                        if len(instances) > 1:\n                            children = [self.init_single_object(key_alias, instance) for instance in instances]\n                        else:\n                            children = self.init_single_object(key_alias, list(instances)[0])\n                    else:\n                        children = self.init_single_object(key_alias, item)\n                setattr(target_object, key.lower(), children)\n            else:\n                setattr(target_object, key.lower(), None)\n        return target_object", "response": "Initializes target object and assign extra objects to target object and assign extra objects to target object as attributes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expand_models(self, target, data):\n        if isinstance(data, dict):\n            data = data.values()\n        for chunk in data:\n            if target in chunk:\n                yield self.init_target_object(target, chunk)\n            else:\n                for key, item in chunk.items():\n                    yield self.init_single_object(key, item)", "response": "Generates all objects from given data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_roles(dominant_name, deprecated_name):\n    dominant_qs = ContributorRole.objects.filter(name=dominant_name)\n    if not dominant_qs.exists() or dominant_qs.count() != 1:\n        return\n    dominant = dominant_qs.first()\n    deprecated_qs = ContributorRole.objects.filter(name=deprecated_name)\n    if not deprecated_qs.exists() or deprecated_qs.count() != 1:\n        return\n    deprecated = deprecated_qs.first()\n\n    # Update Rates\n    if not dominant.flat_rates.exists() and deprecated.flat_rates.exists():\n        flat_rate = deprecated.flat_rates.first()\n        flat_rate.role = dominant\n        flat_rate.save()\n\n    if not dominant.hourly_rates.exists() and deprecated.hourly_rates.exists():\n        hourly_rate = deprecated.hourly_rates.first()\n        hourly_rate.role = dominant\n        hourly_rate.save()\n\n    for ft_rate in deprecated.feature_type_rates.all():\n        dom_ft_rate = dominant.feature_type_rates.filter(feature_type=ft_rate.feature_type)\n\n        if dom_ft_rate.exists() and dom_ft_rate.first().rate == 0:\n            dom_ft_rate.first().delete()\n\n        if not dom_ft_rate.exists():\n            ft_rate.role = dominant\n            ft_rate.save()\n\n    # Update contributions\n    for contribution in deprecated.contribution_set.all():\n        contribution.role = dominant\n        contribution.save()\n\n    # Update overrides\n    for override in deprecated.overrides.all():\n        dom_override_qs = dominant.overrides.filter(contributor=override.contributor)\n        if not dom_override_qs.exists():\n            override.role = dominant\n            override.save()\n        else:\n            dom_override = dom_override_qs.first()\n            for flat_override in override.override_flatrate.all():\n                flat_override.profile = dom_override\n                flat_override.save()\n            for hourly_override in override.override_hourly.all():\n                hourly_override.profile = dom_override\n                hourly_override.save()\n            for feature_type_override in override.override_feature_type.all():\n                feature_type_override.profile = dom_override\n                feature_type_override.save()", "response": "Merges a deprecated role into a dominant role."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap for search_bugs for simple string searches", "response": "def quick_search(self, terms):\n        '''Wrapper for search_bugs, for simple string searches'''\n        assert type(terms) is str\n        p = [{'quicksearch': terms}]\n        return self.search_bugs(p)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_bugs(self, terms):\n        '''http://bugzilla.readthedocs.org/en/latest/api/core/v1/bug.html#search-bugs\n        terms = [{'product': 'Infrastructure & Operations'}, {'status': 'NEW'}]'''\n        params = ''\n        for i in terms:\n            k = i.popitem()\n            params = '{p}&{new}={value}'.format(p=params, new=quote_url(k[0]),\n                        value=quote_url(k[1]))\n        return DotDict(self._get('bug', params=params))", "response": "Search for bugs by a list of terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nposts an attachment to Bugzilla", "response": "def post_attachment(self, bugid, attachment):\n        '''http://bugzilla.readthedocs.org/en/latest/api/core/v1/attachment.html#create-attachment'''\n        assert type(attachment) is DotDict\n        assert 'data' in attachment\n        assert 'file_name' in attachment\n        assert 'summary' in attachment\n        if (not 'content_type' in attachment): attachment.content_type = 'text/plain'\n        attachment.ids = bugid\n        attachment.data = base64.standard_b64encode(bytearray(attachment.data, 'ascii')).decode('ascii')\n\n        return self._post('bug/{bugid}/attachment'.format(bugid=bugid), json.dumps(attachment))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nposting a bug to Bugzilla.", "response": "def post_bug(self, bug):\n        '''http://bugzilla.readthedocs.org/en/latest/api/core/v1/bug.html#create-bug'''\n        assert type(bug) is DotDict\n        assert 'product' in bug\n        assert 'component' in bug\n        assert 'summary' in bug\n        if (not 'version' in bug): bug.version = 'other'\n        if (not 'op_sys' in bug): bug.op_sys = 'All'\n        if (not 'platform' in bug): bug.platform = 'All'\n\n        return self._post('bug', json.dumps(bug))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef post_comment(self, bugid, comment):\n        '''http://bugzilla.readthedocs.org/en/latest/api/core/v1/comment.html#create-comments'''\n        data = {'id': bugid, \"comment\": comment}\n        return self._post('bug/{bugid}/comment'.format(bugid=bugid), json.dumps(data))", "response": "Post a comment to a bugzilla."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _post(self, q, payload='', params=''):\n        '''Generic POST wrapper including the api_key'''\n        if (q[-1] == '/'): q = q[:-1]\n        headers = {'Content-Type': 'application/json'}\n        r = requests.post('{url}{q}?api_key={key}{params}'.format(url=self.url, q=q, key=self.api_key, params=params),\n                        headers=headers, data=payload)\n        ret = DotDict(r.json())\n        if (not r.ok or ('error' in ret and ret.error == True)):\n            raise Exception(r.url, r.reason, r.status_code, r.json())\n        return DotDict(r.json())", "response": "Generic POST wrapper including the api_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding one or more objects to the control", "response": "def bind_objects(self, *objects):\r\n        \"\"\"Bind one or more objects\"\"\"\r\n        self.control.bind_keys(objects)\r\n        self.objects += objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, time_delta):\r\n        self.control.update(self, time_delta)\r\n        for object in self.objects:\r\n            object.update(time_delta)\r\n            # object.sprite.last_position = object.sprite.position\r\n            # object.sprite.last_velocity = object.sprite.velocity\r\n\r\n        # for group in self:\r\n        for controller in self.controllers:\r\n            controller(time_delta, self)", "response": "Update all objects and controllers in the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws all the sprites in the system using their renderers.", "response": "def draw(self):\r\n        \"\"\"Draw all the sprites in the system using their renderers.\r\n\r\n        This method is convenient to call from you Pyglet window's\r\n        on_draw handler to redraw particles when needed.\r\n        \"\"\"\r\n        glPushAttrib(GL_ALL_ATTRIB_BITS)\r\n        self.draw_score()\r\n        for sprite in self:\r\n            sprite.draw()\r\n        glPopAttrib()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets ball to set location on the screen", "response": "def reset_ball(self, x, y):\r\n        \"\"\"reset ball to set location on the screen\"\"\"\r\n        self.sprite.position.x = x\r\n        self.sprite.position.y = y"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, td):\r\n        self.sprite.last_position = self.sprite.position\r\n        self.sprite.last_velocity = self.sprite.velocity\r\n        if self.particle_group != None:\r\n            self.update_particle_group(td)", "response": "Update state of ball"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random point inside the box", "response": "def generate(self):\r\n        \"\"\"Return a random point inside the box\"\"\"\r\n        x, y, z = self.point1\r\n        return (x + self.size_x * random(),\r\n                y + self.size_y * random(),\r\n                z + self.size_z * random())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intersect(self, start_point, end_point):\r\n        sx, sy, sz = start_point\r\n        ex, ey, ez = end_point\r\n        p1x, p1y, p1z = self.point1\r\n        p2x, p2y, p2z = self.point2\r\n        start_inside = start_point in self\r\n        end_inside = end_point in self\r\n        if start_inside != end_inside:\r\n            if (end_inside and sy > p2y) or (start_inside and ey >= p2y) and (ey != sy):\r\n                # Test for itersection with bottom face\r\n                t = (sy - p2y) / (ey - sy)\r\n                ix = (ex - sx) * t + sx\r\n                iy = p2y\r\n                iz = (ez - sz) * t + sz\r\n                if p1x <= ix <= p2x and p1z <= iz <= p2z:\r\n                    return (ix, iy, iz), (0.0, (sy > p2y) * 2.0 - 1.0, 0.0)\r\n            if (end_inside and sx < p1x) or (start_inside and ex <= p1x) and (ex != sx):\r\n                # Test for itersection with left face\r\n                t = (sx - p1x) / (ex - sx)\r\n                ix = p1x\r\n                iy = (ey - sy) * t + sy\r\n                iz = (ez - sz) * t + sz\r\n                if p1y <= iy <= p2y and p1z <= iz <= p2z:\r\n                    return (ix, iy, iz), ((sx > p1x) * 2.0 - 1.0, 0.0, 0.0)\r\n            if (end_inside and sy < p1y) or (start_inside and ey <= p1y) and (ey != sy):\r\n                # Test for itersection with top face\r\n                t = (sy - p1y) / (ey - sy)\r\n                ix = (ex - sx) * t + sx\r\n                iy = p1y\r\n                iz = (ez - sz) * t + sz\r\n                if p1x <= ix <= p2x and p1z <= iz <= p2z:\r\n                    return (ix, iy, iz), (0.0, (sy > p1y) * 2.0 - 1.0, 0.0)\r\n            if (end_inside and sx > p2x) or (start_inside and ex >= p2x) and (ex != sx):\r\n                # Test for itersection with right face\r\n                t = (sx - p2x) / (ex - sx)\r\n                ix = p2x\r\n                iy = (ey - sy) * t + sy\r\n                iz = (ez - sz) * t + sz\r\n                if p1y <= iy <= p2y and p1z <= iz <= p2z:\r\n                    return (ix, iy, iz), ((sx > p2x) * 2.0 - 1.0, 0.0, 0.0)\r\n            if (end_inside and sz > p2z) or (start_inside and ez >= p2z) and (ez != sz):\r\n                # Test for itersection with far face\r\n                t = (sz - p2z) / (ez - sz)\r\n                ix = (ex - sx) * t + sx\r\n                iy = (ey - sy) * t + sy\r\n                iz = p2z\r\n                if p1y <= iy <= p2y and p1x <= ix <= p2x:\r\n                    return (ix, iy, iz), (0.0, 0.0, (sz > p2z) * 2.0 - 1.0)\r\n            if (end_inside and sz < p1z) or (start_inside and ez <= p1z) and (ez != sz):\r\n                # Test for itersection with near face\r\n                t = (sz - p1z) / (ez - sz)\r\n                ix = (ex - sx) * t + sx\r\n                iy = (ey - sy) * t + sy\r\n                iz = p1z\r\n                if p1y <= iy <= p2y and p1x <= ix <= p2x:\r\n                    return (ix, iy, iz), (0.0, 0.0, (sz > p1z) * 2.0 - 1.0)\r\n        return None, None", "response": "Intersect the line segment with the box return the first intersection point and normal vector pointing into space from\r\n            the box side intersected."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef custom_search_model(model, query, preview=False, published=False,\n                        id_field=\"id\", sort_pinned=True, field_map={}):\n    \"\"\"Filter a model with the given filter.\n\n    `field_map` translates incoming field names to the appropriate ES names.\n    \"\"\"\n    if preview:\n        func = preview_filter_from_query\n    else:\n        func = filter_from_query\n    f = func(query, id_field=id_field, field_map=field_map)\n    # filter by published\n    if published:\n        if f:\n            f &= Range(published={\"lte\": timezone.now()})\n        else:\n            f = Range(published={\"lte\": timezone.now()})\n\n    qs = model.search_objects.search(published=False)\n    if f:\n        qs = qs.filter(f)\n\n    # possibly include a text query\n    if query.get(\"query\"):\n        qs = qs.query(\"match\", _all=query[\"query\"])\n    # set up pinned ids\n    pinned_ids = query.get(\"pinned_ids\")\n    if pinned_ids and sort_pinned:\n\n        pinned_query = es_query.FunctionScore(\n            boost_mode=\"multiply\",\n            functions=[{\n                \"filter\": Terms(id=pinned_ids),\n                \"weight\": 2\n            }]\n        )\n\n        qs = qs.query(pinned_query)\n        qs = qs.sort(\"_score\", \"-published\")\n    else:\n        qs = qs.sort(\"-published\")\n    return qs", "response": "Filter a model with the given filter.\n\n    `field_map` translates incoming field names to the appropriate ES names."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef preview_filter_from_query(query, id_field=\"id\", field_map={}):\n    f = groups_filter_from_query(query, field_map=field_map)\n    # NOTE: we don't exclude the excluded ids here so they show up in the editor\n    # include these, please\n    included_ids = query.get(\"included_ids\")\n    if included_ids:\n        if f:\n            f |= Terms(pk=included_ids)\n        else:\n            f = Terms(pk=included_ids)\n    return f", "response": "This filter includes the excluded_ids so they still show up in the editor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_from_query(query, id_field=\"id\", field_map={}):\n    f = groups_filter_from_query(query, field_map=field_map)\n    excluded_ids = query.get(\"excluded_ids\")\n    included_ids = query.get(\"included_ids\")\n\n    if included_ids:  # include these, please\n        if f is None:\n            f = Terms(pk=included_ids)\n        else:\n            f |= Terms(pk=included_ids)\n\n    if excluded_ids:  # exclude these\n        if f is None:\n            f = MatchAll()\n\n        f &= ~Terms(pk=excluded_ids)\n    return f", "response": "This returns a filter which actually filters out everything unlike the\n    preview filter which includes excluded_ids for UI purposes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the appropriate filter for a given group condition.", "response": "def get_condition_filter(condition, field_map={}):\n    \"\"\"\n    Return the appropriate filter for a given group condition.\n\n    #  TODO: integrate this into groups_filter_from_query function.\n    \"\"\"\n    field_name = condition.get(\"field\")\n    field_name = field_map.get(field_name, field_name)\n    operation = condition[\"type\"]\n    values = condition[\"values\"]\n\n    condition_filter = MatchAll()\n\n    if values:\n        values = [v[\"value\"] for v in values]\n        if operation == \"all\":\n            for value in values:\n                if \".\" in field_name:\n                    path = field_name.split(\".\")[0]\n                    condition_filter &= Nested(path=path, filter=Term(**{field_name: value}))\n                else:\n                    condition_filter &= Term(**{field_name: value})\n        elif operation == \"any\":\n            if \".\" in field_name:\n                path = field_name.split(\".\")[0]\n                condition_filter &= Nested(path=path, filter=Terms(**{field_name: values}))\n            else:\n                condition_filter &= Terms(**{field_name: values})\n        elif operation == \"none\":\n            if \".\" in field_name:\n                path = field_name.split(\".\")[0]\n                condition_filter &= ~Nested(path=path, filter=Terms(**{field_name: values}))\n            else:\n                condition_filter &= ~Terms(**{field_name: values})\n        else:\n            raise ValueError(\n                \"\"\"ES conditions must be one of the following values: ['all', 'any', 'none']\"\"\"\n            )\n    return condition_filter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef groups_filter_from_query(query, field_map={}):\n    f = None\n    # filter groups\n    for group in query.get(\"groups\", []):\n        group_f = MatchAll()\n        for condition in group.get(\"conditions\", []):\n            field_name = condition[\"field\"]\n            field_name = field_map.get(field_name, field_name)\n            operation = condition[\"type\"]\n            values = condition[\"values\"]\n            if values:\n                values = [v[\"value\"] for v in values]\n                if operation == \"all\":\n                    # NOTE: is there a better way to express this?\n                    for value in values:\n                        if \".\" in field_name:\n                            path = field_name.split(\".\")[0]\n                            group_f &= Nested(path=path, filter=Term(**{field_name: value}))\n                        else:\n                            group_f &= Term(**{field_name: value})\n                elif operation == \"any\":\n                    if \".\" in field_name:\n                        path = field_name.split(\".\")[0]\n                        group_f &= Nested(path=path, filter=Terms(**{field_name: values}))\n                    else:\n                        group_f &= Terms(**{field_name: values})\n                elif operation == \"none\":\n                    if \".\" in field_name:\n                        path = field_name.split(\".\")[0]\n                        group_f &= ~Nested(path=path, filter=Terms(**{field_name: values}))\n                    else:\n                        group_f &= ~Terms(**{field_name: values})\n\n        date_range = group.get(\"time\")\n        if date_range:\n            group_f &= date_range_filter(date_range)\n        if f:\n            f |= group_f\n        else:\n            f = group_f\n    return f", "response": "Creates an F object for the groups of a search query."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a filter from a named date range.", "response": "def date_range_filter(range_name):\n    \"\"\"Create a filter from a named date range.\"\"\"\n\n    filter_days = list(filter(\n        lambda time: time[\"label\"] == range_name,\n        settings.CUSTOM_SEARCH_TIME_PERIODS))\n    num_days = filter_days[0][\"days\"] if len(filter_days) else None\n\n    if num_days:\n        dt = timedelta(num_days)\n        start_time = timezone.now() - dt\n        return Range(published={\"gte\": start_time})\n    return MatchAll()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self, action, data={}, headers={}, method='GET'):\n        headers = {\n            \"Authorization\": \"Bearer \" + self.token,\n            \"Content-Type\": \"application/json\",\n            \"X-Version\": \"1\",\n            \"Accept\": \"application/json\"\n        }\n\n        return Transport.request(self, action, data, headers, method)", "response": "This method is called by the REST API to send the request to every resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a message to the specified user.", "response": "def sendMessage(self, to, message, extra={}):\n        \"\"\"\n        If the 'to' parameter is a single entry, we will parse it into a list.\n        We will merge default values into the request data and the extra parameters\n        provided by the user.\n        \"\"\"\n        to = to if isinstance(to, list) else [to]\n        to = [str(num) for num in to]\n        data = {'to': to, 'text': message}\n        data = self.merge(data, {'callback': 7, 'mo': 1}, extra)\n\n        content = self.parseRest(self.request('rest/message', data, {}, 'POST'));\n        result = []\n\n        # Messages in the REST response will contain errors on the message entry itself.\n        for entry in content['message']:\n            entry = self.merge({'apiMessageId': False, 'to': data['to'][0], 'error': False, 'errorCode': False}, entry)\n            result.append({\n                'id': entry['apiMessageId'].encode('utf-8'),\n                'destination': entry['to'].encode('utf-8'),\n                'error': entry['error']['description'].encode('utf-8') if entry['error'] != False else False,\n                'errorCode': entry['error']['code'].encode('utf-8') if entry['error'] != False else False\n            });\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stopMessage(self, apiMsgId):\n        content =  self.parseRest(self.request('rest/message/' + apiMsgId, {}, {}, 'DELETE'))\n\n        return {\n            'id': content['apiMessageId'].encode('utf-8'),\n            'status': content['messageStatus'].encode('utf-8'),\n            'description': self.getStatus(content['messageStatus'])\n        }", "response": "Stop a message from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the charge of a message", "response": "def getMessageCharge(self, apiMsgId):\n        \"\"\"\n        See parent method for documentation\n        \"\"\"\n        content = self.parseRest(self.request('rest/message/' + apiMsgId))\n\n        return {\n            'id': apiMsgId,\n            'status': content['messageStatus'].encode('utf-8'),\n            'description': self.getStatus(content['messageStatus']),\n            'charge': float(content['charge'])\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of the route coverage information for a given msisdn.", "response": "def routeCoverage(self, msisdn):\n        \"\"\"\n        If the route coverage lookup encounters an error, we will treat it as \"not covered\".\n        \"\"\"\n        content = self.parseRest(self.request('rest/coverage/' + str(msisdn)))\n\n        return {\n            'routable': content['routable'],\n            'destination': content['destination'].encode('utf-8'),\n            'charge': float(content['minimumCharge'])\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_account_admin(self, user_id, account_id, role=None, role_id=None, send_confirmation=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - user_id\r\n        \"\"\"The id of the user to promote.\"\"\"\r\n        data[\"user_id\"] = user_id\r\n\r\n        # OPTIONAL - role\r\n        \"\"\"(deprecated)\r\n        The user's admin relationship with the account will be created with the\r\n        given role. Defaults to 'AccountAdmin'.\"\"\"\r\n        if role is not None:\r\n            data[\"role\"] = role\r\n\r\n        # OPTIONAL - role_id\r\n        \"\"\"The user's admin relationship with the account will be created with the\r\n        given role. Defaults to the built-in role for 'AccountAdmin'.\"\"\"\r\n        if role_id is not None:\r\n            data[\"role_id\"] = role_id\r\n\r\n        # OPTIONAL - send_confirmation\r\n        \"\"\"Send a notification email to\r\n        the new admin if true. Default is true.\"\"\"\r\n        if send_confirmation is not None:\r\n            data[\"send_confirmation\"] = send_confirmation\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/admins with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/admins\".format(**path), data=data, params=params, single_item=True)", "response": "Make an account admin. Creates an account admin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting the admins in the account. Returns the list of admins in the account.", "response": "def list_account_admins(self, account_id, user_id=None):\r\n        \"\"\"\r\n        List account admins.\r\n\r\n        List the admins in the account\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - user_id\r\n        \"\"\"Scope the results to those with user IDs equal to any of the IDs specified here.\"\"\"\r\n        if user_id is not None:\r\n            params[\"user_id\"] = user_id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/admins with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/admins\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting hex code to rgb.", "response": "def _hex_to_rgb(hex_code):\n    \"\"\"\n    >>> _hex_to_rgb(\"007fff\")\n    (0, 127, 255)\n    \"\"\"\n    if len(hex_code) != 6:\n        raise ValueError(hex_code + \" is not a string of length 6, cannot convert to rgb.\")\n    return tuple(map(ord, hex_code.decode(\"hex\")))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd color definitions from a file or a file - like object pointing to a color definition.", "response": "def add_colors_from_file(self, system, f_or_filename):\n        \"\"\"Add color definition to a given color system.\n\n        You may pass either a file-like object or a filename string pointing\n        to a color definition csv file. Each line in that input file should\n        look like this::\n\n            caf\u00e9 au lait,a67b5b\n\n        i.e. a color name and a sRGB hex code, separated by by comma (``,``). Note that\n        this is standard excel-style csv format without headers.\n\n        You may add to already existing color system. Previously existing color\n        definitions of the same (normalized) name will be overwritten,\n        regardless of the color system.\n\n        Args:\n          system (string): The color system the colors should be added to\n            (e.g. ``\"en\"``).\n          color_definitions (filename, or file-like object): Either\n            a filename, or a file-like object pointing to a color definition\n            csv file (excel style).\n\n        \"\"\"\n        if hasattr(f_or_filename, \"read\"):\n            colors = (row for row in csv.reader(f_or_filename) if row)\n        else:\n            with open(f_or_filename, \"rb\") as f:\n                colors = [row for row in csv.reader(f) if row]\n\n        self.add_colors(system, colors)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_colors(self, system, colors):\n\n        if system not in self._colors_by_system_hex:\n            self._colors_by_system_hex[system] = {}\n            self._colors_by_system_lab[system] = []\n\n        for color_name, hex_code in colors:\n            hex_code = hex_code.lower().strip().strip(\"#\")\n            color_name = color_name.lower().strip()\n            if not isinstance(color_name, unicode):\n                color_name = unicode(color_name, \"utf-8\")\n\n            self._colors_by_system_hex[system][hex_code] = color_name\n            self._colors_by_system_lab[system].append((_hex_to_lab(hex_code), color_name))\n            self._hex_by_color[_normalize(color_name)] = hex_code", "response": "Add color definitions to a given color system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_name(self, in_string, fuzzy=False):\n        in_string = _normalize(in_string)\n        if in_string in self._hex_by_color:\n            return MatchResult(self._hex_by_color[in_string], 100)\n\n        if not fuzzy:\n            raise ValueError(\"No match for %r found.\" % in_string)\n\n        # We want the standard scorer *plus* the set scorer, because colors are often\n        # (but not always) related by sub-strings\n        color_names = self._hex_by_color.keys()\n        set_match = dict(fuzzywuzzy.process.extract(\n            in_string,\n            color_names,\n            scorer=fuzzywuzzy.fuzz.token_set_ratio\n        ))\n        standard_match = dict(fuzzywuzzy.process.extract(in_string, color_names))\n\n        # This would be much easier with a collections.Counter, but alas! it's a 2.7 feature.\n        key_union = set(set_match) | set(standard_match)\n        counter = ((n, set_match.get(n, 0) + standard_match.get(n, 0)) for n in key_union)\n        color_name, score = sorted(counter, key=operator.itemgetter(1))[-1]\n\n        return MatchResult(self._hex_by_color[color_name], score / 2)", "response": "Match a color name to a sRGB value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a color name that s most similar to a given sRGB hex code.", "response": "def find_nearest(self, hex_code, system, filter_set=None):\n        \"\"\"Find a color name that's most similar to a given sRGB hex code.\n\n        In normalization terms, this method implements \"normalize an arbitrary sRGB value\n        to a well-defined color name\".\n\n        Args:\n          system (string): The color system. Currently, `\"en\"`` is the only default\n            system.\n          filter_set (iterable of string, optional): Limits the output choices\n            to fewer color names. The names (e.g. ``[\"black\", \"white\"]``) must be\n            present in the given system.\n            If omitted, all color names of the system are considered. Defaults to None.\n\n        Returns:\n          A named tuple with the members `color_name` and `distance`.\n\n        Raises:\n          ValueError: If argument `system` is not a registered color system.\n\n        Examples:\n          >>> tint_registry = TintRegistry()\n          >>> tint_registry.find_nearest(\"54e6e4\", system=\"en\")\n          FindResult(color_name=u'bright turquoise', distance=3.730288645055483)\n          >>> tint_registry.find_nearest(\"54e6e4\", \"en\", filter_set=(\"white\", \"black\"))\n          FindResult(color_name=u'white', distance=25.709952192116894)\n\n        \"\"\"\n\n        if system not in self._colors_by_system_hex:\n            raise ValueError(\n                \"%r is not a registered color system. Try one of %r\"\n                % (system, self._colors_by_system_hex.keys())\n            )\n        hex_code = hex_code.lower().strip()\n\n        # Try direct hit (fast path)\n        if hex_code in self._colors_by_system_hex[system]:\n            color_name = self._colors_by_system_hex[system][hex_code]\n            if filter_set is None or color_name in filter_set:\n                return FindResult(color_name, 0)\n\n        # No direct hit, assemble list of lab_color/color_name pairs\n        colors = self._colors_by_system_lab[system]\n        if filter_set is not None:\n            colors = (pair for pair in colors if pair[1] in set(filter_set))\n\n        # find minimal distance\n        lab_color = _hex_to_lab(hex_code)\n        min_distance = sys.float_info.max\n        min_color_name = None\n        for current_lab_color, current_color_name in colors:\n            distance = colormath.color_diff.delta_e_cie2000(lab_color, current_lab_color)\n            if distance < min_distance:\n                min_distance = distance\n                min_color_name = current_color_name\n\n        return FindResult(min_color_name, min_distance)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SessionAuthSourceInitializer(\n    value_key='sanity.'\n):\n    \"\"\" An authentication source that uses the current session \"\"\"\n\n    value_key = value_key + 'value'\n\n    @implementer(IAuthSourceService)\n    class SessionAuthSource(object):\n        vary = []\n\n        def __init__(self, context, request):\n            self.request = request\n            self.session = request.session\n            self.cur_val = None\n\n        def get_value(self):\n            if self.cur_val is None:\n                self.cur_val = self.session.get(value_key, [None, None])\n\n            return self.cur_val\n\n        def headers_remember(self, value):\n            if self.cur_val is None:\n                self.cur_val = self.session.get(value_key, [None, None])\n\n            self.session[value_key] = value\n            return []\n\n        def headers_forget(self):\n            if self.cur_val is None:\n                self.cur_val = self.session.get(value_key, [None, None])\n\n            if value_key in self.session:\n                del self.session[value_key]\n            return []\n\n    return SessionAuthSource", "response": "A factory for the authentication source that uses the current session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an authentication source that uses a unique cookie.", "response": "def CookieAuthSourceInitializer(\n    secret,\n    cookie_name='auth',\n    secure=False,\n    max_age=None,\n    httponly=False,\n    path=\"/\",\n    domains=None,\n    debug=False,\n    hashalg='sha512',\n):\n    \"\"\" An authentication source that uses a unique cookie. \"\"\"\n\n    @implementer(IAuthSourceService)\n    class CookieAuthSource(object):\n        vary = ['Cookie']\n\n        def __init__(self, context, request):\n            self.domains = domains\n\n            if self.domains is None:\n                self.domains = []\n                self.domains.append(request.domain)\n\n            self.cookie = SignedCookieProfile(\n                secret,\n                'authsanity',\n                cookie_name,\n                secure=secure,\n                max_age=max_age,\n                httponly=httponly,\n                path=path,\n                domains=domains,\n                hashalg=hashalg,\n                )\n            # Bind the cookie to the current request\n            self.cookie = self.cookie.bind(request)\n\n        def get_value(self):\n            val = self.cookie.get_value()\n\n            if val is None:\n                return [None, None]\n\n            return val\n\n        def headers_remember(self, value):\n            return self.cookie.get_headers(value, domains=self.domains)\n\n        def headers_forget(self):\n            return self.cookie.get_headers(None, max_age=0)\n\n    return CookieAuthSource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an authentication source that uses the Authorization header.", "response": "def HeaderAuthSourceInitializer(\n    secret,\n    salt='sanity.header.'\n):\n    \"\"\" An authentication source that uses the Authorization header. \"\"\"\n\n    @implementer(IAuthSourceService)\n    class HeaderAuthSource(object):\n        vary = ['Authorization']\n\n        def __init__(self, context, request):\n            self.request = request\n            self.cur_val = None\n\n            serializer = JSONSerializer()\n            self.serializer = SignedSerializer(\n                secret,\n                salt,\n                serializer=serializer,\n                )\n\n        def _get_authorization(self):\n            try:\n                type, token = self.request.authorization\n\n                return self.serializer.loads(token)\n            except Exception:\n                return None\n\n        def _create_authorization(self, value):\n            try:\n                return self.serializer.dumps(value)\n            except Exception:\n                return ''\n\n        def get_value(self):\n            if self.cur_val is None:\n                self.cur_val = self._get_authorization() or [None, None]\n\n            return self.cur_val\n\n        def headers_remember(self, value):\n            if self.cur_val is None:\n                self.cur_val = None\n\n            token = self._create_authorization(value)\n            auth_info = native_(b'Bearer ' + token, 'latin-1', 'strict')\n            return [('Authorization', auth_info)]\n\n        def headers_forget(self):\n            if self.cur_val is None:\n                self.cur_val = None\n\n            return []\n\n    return HeaderAuthSource"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(self, collection, ops, resource=None, **kwargs):\n        mfield = self.mfield or resource.meta.model._meta.fields.get(self.field.attribute)\n        if mfield:\n            collection = collection.where(*[op(mfield, val) for op, val in ops])\n        return collection", "response": "Filter given collection by given operations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def delete(self, request, resource=None, **kwargs):\n        if resource:\n            resources = [resource]\n        else:\n            data = await self.parse(request)\n            if data:\n                resources = list(self.collection.where(self.meta.model_pk << data))\n\n        if not resources:\n            raise RESTNotFound(reason='Resource not found')\n\n        for resource in resources:\n            resource.delete_instance()", "response": "Delete a resource. Supports batch delete."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the sub - accounts of the given account.", "response": "def get_sub_accounts_of_account(self, account_id, recursive=None):\r\n        \"\"\"\r\n        Get the sub-accounts of an account.\r\n\r\n        List accounts that are sub-accounts of the given account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - recursive\r\n        \"\"\"If true, the entire account tree underneath\r\n        this account will be returned (though still paginated). If false, only\r\n        direct sub-accounts of this account will be returned. Defaults to false.\"\"\"\r\n        if recursive is not None:\r\n            params[\"recursive\"] = recursive\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/sub_accounts with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/sub_accounts\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_active_courses_in_account(self, account_id, by_subaccounts=None, by_teachers=None, completed=None, enrollment_term_id=None, enrollment_type=None, hide_enrollmentless_courses=None, include=None, published=None, search_term=None, state=None, with_enrollments=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # OPTIONAL - with_enrollments\r\n        \"\"\"If true, include only courses with at least one enrollment.  If false,\r\n        include only courses with no enrollments.  If not present, do not filter\r\n        on course enrollment status.\"\"\"\r\n        if with_enrollments is not None:\r\n            params[\"with_enrollments\"] = with_enrollments\r\n\r\n        # OPTIONAL - enrollment_type\r\n        \"\"\"If set, only return courses that have at least one user enrolled in\r\n        in the course with one of the specified enrollment types.\"\"\"\r\n        if enrollment_type is not None:\r\n            self._validate_enum(enrollment_type, [\"teacher\", \"student\", \"ta\", \"observer\", \"designer\"])\r\n            params[\"enrollment_type\"] = enrollment_type\r\n\r\n        # OPTIONAL - published\r\n        \"\"\"If true, include only published courses.  If false, exclude published\r\n        courses.  If not present, do not filter on published status.\"\"\"\r\n        if published is not None:\r\n            params[\"published\"] = published\r\n\r\n        # OPTIONAL - completed\r\n        \"\"\"If true, include only completed courses (these may be in state\r\n        'completed', or their enrollment term may have ended).  If false, exclude\r\n        completed courses.  If not present, do not filter on completed status.\"\"\"\r\n        if completed is not None:\r\n            params[\"completed\"] = completed\r\n\r\n        # OPTIONAL - by_teachers\r\n        \"\"\"List of User IDs of teachers; if supplied, include only courses taught by\r\n        one of the referenced users.\"\"\"\r\n        if by_teachers is not None:\r\n            params[\"by_teachers\"] = by_teachers\r\n\r\n        # OPTIONAL - by_subaccounts\r\n        \"\"\"List of Account IDs; if supplied, include only courses associated with one\r\n        of the referenced subaccounts.\"\"\"\r\n        if by_subaccounts is not None:\r\n            params[\"by_subaccounts\"] = by_subaccounts\r\n\r\n        # OPTIONAL - hide_enrollmentless_courses\r\n        \"\"\"If present, only return courses that have at least one enrollment.\r\n        Equivalent to 'with_enrollments=true'; retained for compatibility.\"\"\"\r\n        if hide_enrollmentless_courses is not None:\r\n            params[\"hide_enrollmentless_courses\"] = hide_enrollmentless_courses\r\n\r\n        # OPTIONAL - state\r\n        \"\"\"If set, only return courses that are in the given state(s). By default,\r\n        all states but \"deleted\" are returned.\"\"\"\r\n        if state is not None:\r\n            self._validate_enum(state, [\"created\", \"claimed\", \"available\", \"completed\", \"deleted\", \"all\"])\r\n            params[\"state\"] = state\r\n\r\n        # OPTIONAL - enrollment_term_id\r\n        \"\"\"If set, only includes courses from the specified term.\"\"\"\r\n        if enrollment_term_id is not None:\r\n            params[\"enrollment_term_id\"] = enrollment_term_id\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial course name, code, or full ID to match and return in the results list. Must be at least 3 characters.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"- All explanations can be seen in the {api:CoursesController#index Course API index documentation}\r\n        - \"sections\", \"needs_grading_count\" and \"total_scores\" are not valid options at the account level\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"syllabus_body\", \"term\", \"course_progress\", \"storage_quota_used_mb\", \"total_students\", \"teachers\"])\r\n            params[\"include\"] = include\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/courses with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/courses\".format(**path), data=data, params=params, all_pages=True)", "response": "Returns a list of active courses in an account."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate an existing account. Updates the attributes of an existing account.", "response": "def update_account(self, id, account_default_group_storage_quota_mb=None, account_default_storage_quota_mb=None, account_default_time_zone=None, account_default_user_storage_quota_mb=None, account_name=None, account_services=None, account_settings_lock_all_announcements_locked=None, account_settings_lock_all_announcements_value=None, account_settings_restrict_student_future_listing_locked=None, account_settings_restrict_student_future_listing_value=None, account_settings_restrict_student_future_view_locked=None, account_settings_restrict_student_future_view_value=None, account_settings_restrict_student_past_view_locked=None, account_settings_restrict_student_past_view_value=None):\r\n        \"\"\"\r\n        Update an account.\r\n\r\n        Update an existing account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - account[name]\r\n        \"\"\"Updates the account name\"\"\"\r\n        if account_name is not None:\r\n            data[\"account[name]\"] = account_name\r\n\r\n        # OPTIONAL - account[default_time_zone]\r\n        \"\"\"The default time zone of the account. Allowed time zones are\r\n        {http://www.iana.org/time-zones IANA time zones} or friendlier\r\n        {http://api.rubyonrails.org/classes/ActiveSupport/TimeZone.html Ruby on Rails time zones}.\"\"\"\r\n        if account_default_time_zone is not None:\r\n            data[\"account[default_time_zone]\"] = account_default_time_zone\r\n\r\n        # OPTIONAL - account[default_storage_quota_mb]\r\n        \"\"\"The default course storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_storage_quota_mb is not None:\r\n            data[\"account[default_storage_quota_mb]\"] = account_default_storage_quota_mb\r\n\r\n        # OPTIONAL - account[default_user_storage_quota_mb]\r\n        \"\"\"The default user storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_user_storage_quota_mb is not None:\r\n            data[\"account[default_user_storage_quota_mb]\"] = account_default_user_storage_quota_mb\r\n\r\n        # OPTIONAL - account[default_group_storage_quota_mb]\r\n        \"\"\"The default group storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_group_storage_quota_mb is not None:\r\n            data[\"account[default_group_storage_quota_mb]\"] = account_default_group_storage_quota_mb\r\n\r\n        # OPTIONAL - account[settings][restrict_student_past_view][value]\r\n        \"\"\"Restrict students from viewing courses after end date\"\"\"\r\n        if account_settings_restrict_student_past_view_value is not None:\r\n            data[\"account[settings][restrict_student_past_view][value]\"] = account_settings_restrict_student_past_view_value\r\n\r\n        # OPTIONAL - account[settings][restrict_student_past_view][locked]\r\n        \"\"\"Lock this setting for sub-accounts and courses\"\"\"\r\n        if account_settings_restrict_student_past_view_locked is not None:\r\n            data[\"account[settings][restrict_student_past_view][locked]\"] = account_settings_restrict_student_past_view_locked\r\n\r\n        # OPTIONAL - account[settings][restrict_student_future_view][value]\r\n        \"\"\"Restrict students from viewing courses before start date\"\"\"\r\n        if account_settings_restrict_student_future_view_value is not None:\r\n            data[\"account[settings][restrict_student_future_view][value]\"] = account_settings_restrict_student_future_view_value\r\n\r\n        # OPTIONAL - account[settings][restrict_student_future_view][locked]\r\n        \"\"\"Lock this setting for sub-accounts and courses\"\"\"\r\n        if account_settings_restrict_student_future_view_locked is not None:\r\n            data[\"account[settings][restrict_student_future_view][locked]\"] = account_settings_restrict_student_future_view_locked\r\n\r\n        # OPTIONAL - account[settings][lock_all_announcements][value]\r\n        \"\"\"Disable comments on announcements\"\"\"\r\n        if account_settings_lock_all_announcements_value is not None:\r\n            data[\"account[settings][lock_all_announcements][value]\"] = account_settings_lock_all_announcements_value\r\n\r\n        # OPTIONAL - account[settings][lock_all_announcements][locked]\r\n        \"\"\"Lock this setting for sub-accounts and courses\"\"\"\r\n        if account_settings_lock_all_announcements_locked is not None:\r\n            data[\"account[settings][lock_all_announcements][locked]\"] = account_settings_lock_all_announcements_locked\r\n\r\n        # OPTIONAL - account[settings][restrict_student_future_listing][value]\r\n        \"\"\"Restrict students from viewing future enrollments in course list\"\"\"\r\n        if account_settings_restrict_student_future_listing_value is not None:\r\n            data[\"account[settings][restrict_student_future_listing][value]\"] = account_settings_restrict_student_future_listing_value\r\n\r\n        # OPTIONAL - account[settings][restrict_student_future_listing][locked]\r\n        \"\"\"Lock this setting for sub-accounts and courses\"\"\"\r\n        if account_settings_restrict_student_future_listing_locked is not None:\r\n            data[\"account[settings][restrict_student_future_listing][locked]\"] = account_settings_restrict_student_future_listing_locked\r\n\r\n        # OPTIONAL - account[services]\r\n        \"\"\"Give this a set of keys and boolean values to enable or disable services matching the keys\"\"\"\r\n        if account_services is not None:\r\n            data[\"account[services]\"] = account_services\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new sub - account. Create a new sub - account.", "response": "def create_new_sub_account(self, account_id, account_name, account_default_group_storage_quota_mb=None, account_default_storage_quota_mb=None, account_default_user_storage_quota_mb=None, account_sis_account_id=None):\r\n        \"\"\"\r\n        Create a new sub-account.\r\n\r\n        Add a new sub-account to a given account.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - account[name]\r\n        \"\"\"The name of the new sub-account.\"\"\"\r\n        data[\"account[name]\"] = account_name\r\n\r\n        # OPTIONAL - account[sis_account_id]\r\n        \"\"\"The account's identifier in the Student Information System.\"\"\"\r\n        if account_sis_account_id is not None:\r\n            data[\"account[sis_account_id]\"] = account_sis_account_id\r\n\r\n        # OPTIONAL - account[default_storage_quota_mb]\r\n        \"\"\"The default course storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_storage_quota_mb is not None:\r\n            data[\"account[default_storage_quota_mb]\"] = account_default_storage_quota_mb\r\n\r\n        # OPTIONAL - account[default_user_storage_quota_mb]\r\n        \"\"\"The default user storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_user_storage_quota_mb is not None:\r\n            data[\"account[default_user_storage_quota_mb]\"] = account_default_user_storage_quota_mb\r\n\r\n        # OPTIONAL - account[default_group_storage_quota_mb]\r\n        \"\"\"The default group storage quota to be used, if not otherwise specified.\"\"\"\r\n        if account_default_group_storage_quota_mb is not None:\r\n            data[\"account[default_group_storage_quota_mb]\"] = account_default_group_storage_quota_mb\r\n\r\n        self.logger.debug(\"POST /api/v1/accounts/{account_id}/sub_accounts with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/accounts/{account_id}/sub_accounts\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, table, where=None):\n        if where:\n            where_key, where_val = where\n            query = \"DELETE FROM {0} WHERE {1}='{2}'\".format(wrap(table), where_key, where_val)\n        else:\n            query = 'DELETE FROM {0}'.format(wrap(table))\n        self.execute(query)\n        return True", "response": "Delete existing rows from a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef coloured_network(network, setup, filename):\n    NODES_ATTR = {\n        'DEFAULT':   {'color': 'black', 'fillcolor': 'white', 'style': 'filled, bold', 'fontname': 'Helvetica', 'fontsize': 18, 'shape': 'ellipse'},\n        'STIMULI':   {'color': 'olivedrab3', 'fillcolor': 'olivedrab3'},\n        'INHIBITOR': {'color': 'orangered', 'fillcolor': 'orangered'},\n        'READOUT':   {'color': 'lightblue', 'fillcolor': 'lightblue'},\n        'INHOUT':    {'color': 'orangered', 'fillcolor': 'SkyBlue2', 'style': 'filled, bold, diagonals'},\n        'GATE' :     {'fillcolor': 'black', 'fixedsize': True, 'width': 0.2, 'height': 0.2, 'label': '.'}\n    }\n\n    EDGES_ATTR = {\n        'DEFAULT': {'dir': 'forward', 'penwidth': 2.5},\n        1 : {'color': 'forestgreen', 'arrowhead': 'normal'},\n        -1 : {'color': 'red', 'arrowhead': 'tee'}\n    }\n\n    graph = network.__plot__()\n\n    for node in graph.nodes():\n        _type = 'DEFAULT'\n        for attr, value in NODES_ATTR[_type].items():\n            graph.node[node][attr] = value\n\n        if 'gate' in graph.node[node]:\n            _type = 'GATE'\n        elif node in setup.stimuli:\n            _type = 'STIMULI'\n        elif node in setup.readouts and node in setup.inhibitors:\n            _type = 'INHOUT'\n        elif node in setup.readouts:\n            _type = 'READOUT'\n        elif node in setup.inhibitors:\n            _type = 'INHIBITOR'\n\n        if _type != 'DEFAULT':\n            for attr, value in NODES_ATTR[_type].items():\n                graph.node[node][attr] = value\n\n    for source, target in graph.edges():\n        for k in graph.edge[source][target]:\n            for attr, value in EDGES_ATTR['DEFAULT'].items():\n                graph.edge[source][target][k][attr] = value\n\n            for attr, value in EDGES_ATTR[graph.edge[source][target][k]['sign']].items():\n                graph.edge[source][target][k][attr] = value\n\n            if 'weight' in graph.edge[source][target][k]:\n                graph.edge[source][target][k]['penwidth'] = 5 * graph.edge[source][target][k]['weight']\n\n    write_dot(graph, filename)", "response": "Plots a coloured network into a dot file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating two alternative plots describing the distribution of the logical networks of the current set of logical networks.", "response": "def networks_distribution(df, filepath=None):\n    \"\"\"\n    Generates two alternative plots describing the distribution of\n    variables `mse` and `size`. It is intended to be used over a list\n    of logical networks.\n\n\n    Parameters\n    ----------\n    df: `pandas.DataFrame`_\n        DataFrame with columns `mse` and `size`\n\n    filepath: str\n        Absolute path to a folder where to write the plots\n\n\n    Returns\n    -------\n    tuple\n        Generated plots\n\n\n    .. _pandas.DataFrame: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n    \"\"\"\n\n    df.mse = df.mse.map(lambda f: \"%.4f\" % f)\n\n    g = sns.JointGrid(x=\"mse\", y=\"size\", data=df)\n\n    g.plot_joint(sns.violinplot, scale='count')\n    g.ax_joint.set_yticks(range(df['size'].min(), df['size'].max() + 1))\n    g.ax_joint.set_yticklabels(range(df['size'].min(), df['size'].max() + 1))\n\n    for tick in g.ax_joint.get_xticklabels():\n        tick.set_rotation(90)\n\n    g.ax_joint.set_xlabel(\"MSE\")\n    g.ax_joint.set_ylabel(\"Size\")\n\n    for i, t in enumerate(g.ax_joint.get_xticklabels()):\n        c = df[df['mse'] == t.get_text()].shape[0]\n        g.ax_marg_x.annotate(c, xy=(i, 0.5), va=\"center\", ha=\"center\", size=20, rotation=90)\n\n    for i, t in enumerate(g.ax_joint.get_yticklabels()):\n        s = int(t.get_text())\n        c = df[df['size'] == s].shape[0]\n        g.ax_marg_y.annotate(c, xy=(0.5, s), va=\"center\", ha=\"center\", size=20)\n\n    if filepath:\n        g.savefig(os.path.join(filepath, 'networks-distribution.pdf'))\n\n    plt.figure()\n    counts = df[[\"size\", \"mse\"]].reset_index(level=0).groupby([\"size\", \"mse\"], as_index=False).count()\n    cp = counts.pivot(\"size\", \"mse\", \"index\").sort_index()\n\n    ax = sns.heatmap(cp, annot=True, fmt=\".0f\", linewidths=.5)\n    ax.set_xlabel(\"MSE\")\n    ax.set_ylabel(\"Size\")\n\n    if filepath:\n        plt.savefig(os.path.join(filepath, 'networks-heatmap.pdf'))\n\n    return g, ax"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mappings_frequency(df, filepath=None):\n\n    df = df.sort_values('frequency')\n    df['conf'] = df.frequency.map(lambda f: 0 if f < 0.2 else 1 if f < 0.8 else 2)\n\n    g = sns.factorplot(x=\"mapping\", y=\"frequency\", data=df, aspect=3, hue='conf', legend=False)\n    for tick in g.ax.get_xticklabels():\n        tick.set_rotation(90)\n\n    g.ax.set_ylim([-.05, 1.05])\n\n    g.ax.set_xlabel(\"Logical mapping\")\n    g.ax.set_ylabel(\"Frequency\")\n\n    if filepath:\n        g.savefig(os.path.join(filepath, 'mappings-frequency.pdf'))\n\n    return g", "response": "Plots the frequency of logical conjunction mappings in a single plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef behaviors_distribution(df, filepath=None):\n\n    cols = [\"networks\", \"index\"]\n    rcols = [\"Logical networks\", \"Input-Output behaviors\"]\n    sort_cols = [\"networks\"]\n\n    if \"mse\" in df.columns:\n        cols.append(\"mse\")\n        rcols.append(\"MSE\")\n        sort_cols = [\"mse\"] + sort_cols\n\n        df.mse = df.mse.map(lambda f: \"%.4f\" % f)\n\n    df = df.sort_values(sort_cols).reset_index(drop=True).reset_index(level=0)[cols]\n    df.columns = rcols\n\n    if \"MSE\" in df.columns:\n        g = sns.factorplot(x='Input-Output behaviors', y='Logical networks', hue='MSE', data=df, aspect=3, kind='bar', legend_out=False)\n    else:\n        g = sns.factorplot(x='Input-Output behaviors', y='Logical networks', data=df, aspect=3, kind='bar', legend_out=False)\n\n    g.ax.set_xticks([])\n    if filepath:\n        g.savefig(os.path.join(filepath, 'behaviors-distribution.pdf'))\n\n    return g", "response": "Plots the distribution of logical networks across input - output behaviors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplotting all the corresponding experimental designs in a different plot.", "response": "def experimental_designs(df, filepath=None):\n    \"\"\"\n    For each experimental design it plot all the corresponding\n    experimental conditions in a different plot\n\n    Parameters\n    ----------\n    df: `pandas.DataFrame`_\n        DataFrame with columns `id` and starting with `TR:`\n\n    filepath: str\n        Absolute path to a folder where to write the plot\n\n\n    Returns\n    -------\n    list\n        Generated plots\n\n\n    .. _pandas.DataFrame: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n    \"\"\"\n\n    axes = []\n    bw = matplotlib.colors.ListedColormap(['white', 'black'])\n    cols = df.columns\n    for i, dd in df.groupby(\"id\"):\n        cues = dd.drop([c for c in cols if not c.startswith(\"TR:\")] + [\"id\"], axis=1).reset_index(drop=True)\n        cues.columns = [c[3:] for c in cues.columns]\n\n        plt.figure(figsize=(max((len(cues.columns)-1) * .5, 4), max(len(cues)*0.6, 2.5)))\n\n        ax = sns.heatmap(cues, linewidths=.5, cbar=False, cmap=bw, linecolor='gray')\n        _ = [t.set_color('r') if t.get_text().endswith('i') else t.set_color('g') for t in ax.xaxis.get_ticklabels()]\n\n        ax.set_xlabel(\"Stimuli (green) and Inhibitors (red)\")\n        ax.set_ylabel(\"Experimental condition\")\n\n        plt.tight_layout()\n        axes.append(ax)\n\n        if filepath:\n            plt.savefig(os.path.join(filepath, 'design-%s.pdf' % i))\n\n    return axes"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef differences_distribution(df, filepath=None):\n\n    axes = []\n    cols = df.columns\n    for i, dd in df.groupby(\"id\"):\n        palette = sns.color_palette(\"Set1\", len(dd))\n        plt.figure()\n\n        readouts = dd.drop([c for c in cols if not c.startswith(\"DIF:\")] + [\"id\"], axis=1).reset_index(drop=True)\n        readouts.columns = [c[4:] for c in readouts.columns]\n\n        ax1 = readouts.T.plot(kind='bar', stacked=True, color=palette)\n\n        ax1.set_xlabel(\"Readout\")\n        ax1.set_ylabel(\"Pairwise differences\")\n        plt.tight_layout()\n\n        if filepath:\n            plt.savefig(os.path.join(filepath, 'design-%s-readouts.pdf' % i))\n\n        plt.figure()\n        behaviors = dd[[\"pairs\"]].reset_index(drop=True)\n        ax2 = behaviors.plot.bar(color=palette, legend=False)\n\n        ax2.set_xlabel(\"Experimental condition\")\n        ax2.set_ylabel(\"Pairs of input-output behaviors\")\n        plt.tight_layout()\n\n        if filepath:\n            plt.savefig(os.path.join(filepath, 'design-%s-behaviors.pdf' % i))\n\n        axes.append((ax1, ax2))\n\n    return axes", "response": "Plots all the corresponding generated differences in different plots for each experimental design it plot all the corresponding\n    generated differences in different plots"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predictions_variance(df, filepath=None):\n\n    df = df.filter(regex=\"^VAR:\")\n\n    by_readout = df.mean(axis=0).reset_index(level=0)\n    by_readout.columns = ['Readout', 'Prediction variance (mean)']\n\n    by_readout['Readout'] = by_readout.Readout.map(lambda n: n[4:])\n\n    g1 = sns.factorplot(x='Readout', y='Prediction variance (mean)', data=by_readout, kind='bar', aspect=2)\n\n    for tick in g1.ax.get_xticklabels():\n        tick.set_rotation(90)\n\n    if filepath:\n        g1.savefig(os.path.join(filepath, 'predictions-variance.pdf'))\n\n    return g1", "response": "Plots the mean variance prediction for each readout and returns a plot of the mean variance for each readout."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef intervention_strategies(df, filepath=None):\n    logger = logging.getLogger(\"caspo\")\n\n    LIMIT = 50\n    if len(df) > LIMIT:\n        msg = \"Too many intervention strategies to visualize. A sample of %s strategies will be considered.\" % LIMIT\n        logger.warning(msg)\n        df = df.sample(LIMIT)\n\n    values = np.unique(df.values.flatten())\n    if len(values) == 3:\n        rwg = matplotlib.colors.ListedColormap(['red', 'white', 'green'])\n    elif 1 in values:\n        rwg = matplotlib.colors.ListedColormap(['white', 'green'])\n    else:\n        rwg = matplotlib.colors.ListedColormap(['red', 'white'])\n\n    plt.figure(figsize=(max((len(df.columns)-1) * .5, 4), max(len(df)*0.6, 2.5)))\n\n    df.columns = [c[3:] for c in df.columns]\n    ax = sns.heatmap(df, linewidths=.5, cbar=False, cmap=rwg, linecolor='gray')\n\n    ax.set_xlabel(\"Species\")\n    ax.set_ylabel(\"Intervention strategy\")\n\n    for tick in ax.get_xticklabels():\n        tick.set_rotation(90)\n\n    plt.tight_layout()\n\n    if filepath:\n        plt.savefig(os.path.join(filepath, 'strategies.pdf'))\n\n    return ax", "response": "Plots all intervention strategies in a single plot."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interventions_frequency(df, filepath=None):\n\n    df = df.sort_values('frequency')\n    df['conf'] = df.frequency.map(lambda f: 0 if f < 0.2 else 1 if f < 0.8 else 2)\n\n    g = sns.factorplot(x=\"intervention\", y=\"frequency\", data=df, aspect=3, hue='conf', legend=False)\n    for tick in g.ax.get_xticklabels():\n        tick.set_rotation(90)\n\n    _ = [t.set_color('r') if t.get_text().endswith('-1') else t.set_color('g') for t in g.ax.xaxis.get_ticklabels()]\n\n    g.ax.set_ylim([-.05, 1.05])\n\n    g.ax.set_xlabel(\"Intervention\")\n    g.ax.set_ylabel(\"Frequency\")\n\n    if filepath:\n        g.savefig(os.path.join(filepath, 'interventions-frequency.pdf'))\n\n    return g", "response": "Plots the frequency of occurrence for each intervention."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new graph to the overlap report. Args: y (str): Value plotted on y-axis. x_label (str): Label on x-axis. y_label (str): Label on y-axis. title (str): Title of the plot. x_run ((float,float)): x-range. y_run ((int,int)): y-rang. svg_size_px ((int,int): Size of SVG image in pixels. key_position (str): GnuPlot position of the legend.", "response": "def add_graph(\n        self,\n        y,\n        x_label=None,\n        y_label=\"\",\n        title=\"\",\n        x_run=None,\n        y_run=None,\n        svg_size_px=None,\n        key_position=\"bottom right\",\n    ):\n        \"\"\"\n\t\tAdd a new graph to the overlap report.\n\n\t\tArgs:\n\t\t\ty (str): Value plotted on y-axis.\n\t\t\tx_label (str): Label on x-axis.\n\t\t\ty_label (str): Label on y-axis.\n\t\t\ttitle (str): Title of the plot.\n\t\t\tx_run ((float,float)): x-range.\n\t\t\ty_run ((int,int)): y-rang.\n\t\t\tsvg_size_px ((int,int): Size of SVG image in pixels.\n\t\t\tkey_position (str): GnuPlot position of the legend.\n\t\t\"\"\"\n\n        if x_run is None:\n            x_run = self.default_x_run\n        if y_run is None:\n            y_run = self.default_y_run\n        if svg_size_px is None:\n            svg_size_px = self.default_svg_size_px\n\n        for panel in self.panels:\n            x_run = self._load_x_run(x_run)\n            y_run = self._load_y_run(y_run)\n            svg_size_px = self._load_svg_size_px(svg_size_px)\n            panel.add_graph(\n                y=y,\n                x_run=x_run,\n                y_run=y_run,\n                svg_size_px=svg_size_px,\n                y_label=y_label,\n                x_label=x_label if x_label is not None else self.default_x_label,\n                title=title,\n                key_position=key_position,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all temporary files.", "response": "def clean(self):\n        \"\"\"Remove all temporary files.\"\"\"\n\n        rnftools.utils.shell('rm -fR \"{}\" \"{}\"'.format(self.report_dir, self._html_fn))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current traceback as Traceback object.", "response": "def get_current_traceback(show_hidden_frames=False, skip=0, context=None, exc_info=None):\n    \"\"\"Get the current exception info as `Traceback` object.  Per default\n    calling this method will reraise system exceptions such as generator exit,\n    system exit or others.  This behavior can be disabled by passing `False`\n    to the function as first parameter.\n    \"\"\"\n    if exc_info is None:\n        exc_info = sys.exc_info()\n\n    exc_type, exc_value, tb = exc_info\n    for x in range(skip):\n        if tb.tb_next is None:\n            break\n        tb = tb.tb_next\n    tb = Traceback(exc_type, exc_value, tb, context=context)\n    if not show_hidden_frames:\n        tb.filter_hidden_frames()\n    return tb"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog the ASCII traceback into a file object.", "response": "def log(self, logfile=None):\n        \"\"\"Log the ASCII traceback into a file object.\"\"\"\n        if logfile is None:\n            logfile = sys.stderr\n        tb = self.plaintext.rstrip() + '\\n'\n\n        file_mode = getattr(logfile, 'mode', None)\n        if file_mode is not None:\n            if 'b' in file_mode:\n                tb = tb.encode('utf-8')\n            logfile.write(tb)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a paste and return the paste id.", "response": "def paste(self):\n        \"\"\"Create a paste and return the paste id.\"\"\"\n        data = json.dumps({\n            'description': 'Backlash Internal Server Error',\n            'public': False,\n            'files': {\n                'traceback.txt': {\n                    'content': self.plaintext\n                }\n            }\n        }).encode('utf-8')\n\n        rv = urlopen('https://api.github.com/gists', data=data)\n        resp = json.loads(rv.read().decode('utf-8'))\n        rv.close()\n        return {\n            'url': resp['html_url'],\n            'id': resp['id']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_summary(self, include_title=True):\n        title = ''\n        description = ''\n        frames = []\n        classes = ['traceback']\n        if not self.frames:\n            classes.append('noframe-traceback')\n\n        if include_title:\n            if self.is_syntax_error:\n                title = text_('Syntax Error')\n            else:\n                title = text_('Traceback <em>(most recent call last)</em>:')\n\n        for frame in self.frames:\n            frames.append(text_('<li%s>%s') % (\n                frame.info and text_(' title=\"%s\"') % escape(frame.info) or text_(''),\n                frame.render()\n                ))\n\n        if self.is_syntax_error:\n            description_wrapper = text_('<pre class=syntaxerror>%s</pre>')\n        else:\n            description_wrapper = text_('<blockquote>%s</blockquote>')\n\n        return SUMMARY_HTML % {\n            'classes':      text_(' '.join(classes)),\n            'title':        title and text_('<h3>%s</h3>' % title) or text_(''),\n            'frames':       text_('\\n'.join(frames)),\n            'description':  description_wrapper % escape(self.exception)\n        }", "response": "Render the traceback for the interactive console."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_plaintext_traceback(self):\n        yield text_('Traceback (most recent call last):')\n        for frame in self.frames:\n            yield text_('  File \"%s\", line %s, in %s' % (\n                frame.filename,\n                frame.lineno,\n                frame.function_name\n                ))\n            yield text_('    ' + frame.current_line.strip())\n        yield text_(self.exception)", "response": "Like the plaintext attribute but returns a generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts DWGSIM FASTQ file to RNF file.", "response": "def recode_dwgsim_reads(\n        dwgsim_prefix,\n        fastq_rnf_fo,\n        fai_fo,\n        genome_id,\n        estimate_unknown_values,\n        number_of_read_tuples=10**9,\n    ):\n        \"\"\"Convert DwgSim FASTQ file to RNF FASTQ file.\n\n\t\tArgs:\n\t\t\tdwgsim_prefix (str): DwgSim prefix of the simulation (see its commandline parameters).\n\t\t\tfastq_rnf_fo (file): File object of RNF FASTQ.\n\t\t\tfai_fo (file): File object for FAI file of the reference genome.\n\t\t\tgenome_id (int): RNF genome ID to be used.\n\t\t\testimate_unknown_values (bool): Estimate unknown values (right coordinate of each end).\n\t\t\tnumber_of_read_tuples (int): Estimate of number of simulated read tuples (to set width).\n\t\t\"\"\"\n\n        dwgsim_pattern = re.compile(\n            '@(.*)_([0-9]+)_([0-9]+)_([01])_([01])_([01])_([01])_([0-9]+):([0-9]+):([0-9]+)_([0-9]+):([0-9]+):([0-9]+)_(([0-9abcdef])+)'\n        )\n\n        ###\n        # DWGSIM read name format\n        #\n        # 1)  contig name (chromsome name)\n        # 2)  start end 1 (one-based)\n        # 3)  start end 2 (one-based)\n        # 4)  strand end 1 (0 - forward, 1 - reverse)\n        # 5)  strand end 2 (0 - forward, 1 - reverse)\n        # 6)  random read end 1 (0 - from the mutated reference, 1 - random)\n        # 7)  random read end 2 (0 - from the mutated reference, 1 - random)\n        # 8)  number of sequencing errors end 1 (color errors for colorspace)\n        # 9)  number of SNPs end 1\n        # 10) number of indels end 1\n        # 11) number of sequencing errors end 2 (color errors for colorspace)\n        # 12) number of SNPs end 2\n        # 13) number of indels end 2\n        # 14) read number (unique within a given contig/chromosome)\n        ###\n\n        fai_index = rnftools.utils.FaIdx(fai_fo=fai_fo)\n        read_tuple_id_width = len(format(number_of_read_tuples, 'x'))\n\n        # parsing FQ file\n        read_tuple_id = 0\n        last_read_tuple_name = None\n        old_fq = \"{}.bfast.fastq\".format(dwgsim_prefix)\n\n        fq_creator = rnftools.rnfformat.FqCreator(\n            fastq_fo=fastq_rnf_fo,\n            read_tuple_id_width=read_tuple_id_width,\n            genome_id_width=2,\n            chr_id_width=fai_index.chr_id_width,\n            coor_width=fai_index.coor_width,\n            info_reads_in_tuple=True,\n            info_simulator=\"dwgsim\",\n        )\n\n        i = 0\n        with open(old_fq, \"r+\") as f1:\n            for line in f1:\n                if i % 4 == 0:\n                    read_tuple_name = line[1:].strip()\n                    if read_tuple_name != last_read_tuple_name:\n                        new_tuple = True\n                        if last_read_tuple_name is not None:\n                            read_tuple_id += 1\n                    else:\n                        new_tuple = False\n\n                    last_read_tuple_name = read_tuple_name\n                    m = dwgsim_pattern.search(line)\n                    if m is None:\n                        rnftools.utils.error(\n                            \"Read tuple '{}' was not created by DwgSim.\".format(line[1:]),\n                            program=\"RNFtools\",\n                            subprogram=\"MIShmash\",\n                            exception=ValueError,\n                        )\n\n                    contig_name = m.group(1)\n                    start_1 = int(m.group(2))\n                    start_2 = int(m.group(3))\n                    direction_1 = \"F\" if int(m.group(4)) == 0 else \"R\"\n                    direction_2 = \"F\" if int(m.group(5)) == 0 else \"R\"\n                    # random_1 = bool(m.group(6))\n                    # random_2 = bool(m.group(7))\n                    # seq_err_1 = int(m.group(8))\n                    # snp_1 = int(m.group(9))\n                    # indels_1 = int(m.group(10))\n                    # seq_err_2 = int(m.group(11))\n                    # snp_2 = int(m.group(12))\n                    # indels_2 = int(m.group(13))\n                    # read_tuple_id_dwg = int(m.group(14), 16)\n\n                    chr_id = fai_index.dict_chr_ids[contig_name] if fai_index.dict_chr_ids != {} else \"0\"\n\n                elif i % 4 == 1:\n                    bases = line.strip()\n\n                    if new_tuple:\n\n                        segment = rnftools.rnfformat.Segment(\n                            genome_id=genome_id,\n                            chr_id=chr_id,\n                            direction=direction_1,\n                            left=start_1,\n                            right=start_1 + len(bases) - 1 if estimate_unknown_values else 0,\n                        )\n\n                    else:\n\n                        segment = rnftools.rnfformat.Segment(\n                            genome_id=genome_id,\n                            chr_id=chr_id,\n                            direction=direction_2,\n                            left=start_2,\n                            right=start_2 + len(bases) - 1 if estimate_unknown_values else 0,\n                        )\n\n                elif i % 4 == 2:\n                    pass\n\n                elif i % 4 == 3:\n                    qualities = line.strip()\n                    fq_creator.add_read(\n                        read_tuple_id=read_tuple_id,\n                        bases=bases,\n                        qualities=qualities,\n                        segments=[segment],\n                    )\n\n                i += 1\n\n        fq_creator.flush_read_tuple()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield control to another eligible coroutine until at least * seconds * have elapsed.", "response": "def sleep(seconds=0):\n    \"\"\"Yield control to another eligible coroutine until at least *seconds* have\n    elapsed.\n\n    *seconds* may be specified as an integer, or a float if fractional seconds\n    are desired.\n    \"\"\"\n    loop = evergreen.current.loop\n    current = Fiber.current()\n    assert loop.task is not current\n    timer = loop.call_later(seconds, current.switch)\n    try:\n        loop.switch()\n    finally:\n        timer.cancel()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns a task to run func with args and kwargs.", "response": "def spawn(func, *args, **kwargs):\n    \"\"\"Create a task to run ``func(*args, **kwargs)``.  Returns a\n    :class:`Task` objec.\n\n    Execution control returns immediately to the caller; the created task\n    is merely scheduled to be run at the next available opportunity.\n    Use :func:`spawn_later` to  arrange for tasks to be spawned\n    after a finite delay.\n    \"\"\"\n    t = Task(target=func, args=args, kwargs=kwargs)\n    t.start()\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait for this Task to end.", "response": "def join(self, timeout=None):\n        \"\"\"Wait for this Task to end. If a timeout is given, after the time expires the function\n        will return anyway.\"\"\"\n        if not self._started:\n            raise RuntimeError('cannot join task before it is started')\n        return self._exit_event.wait(timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nterminating the current task by raising an exception into it.", "response": "def kill(self, typ=TaskExit, value=None, tb=None):\n        \"\"\"Terminates the current task by raising an exception into it.\n        Whatever that task might be doing; be it waiting for I/O or another\n        primitive, it sees an exception as soon as it yields control.\n\n        By default, this exception is TaskExit, but a specific exception\n        may be specified.\n        \"\"\"\n        if not self.is_alive():\n            return\n        if not value:\n            value = typ()\n        if not self._running:\n            # task hasn't started yet and therefore throw won't work\n            def just_raise():\n                six.reraise(typ, value, tb)\n            self.run = just_raise\n            return\n        evergreen.current.loop.call_soon(self.throw, typ, value, tb)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_csv(cls, filename):\n        df = pd.read_csv(filename)\n\n        edges = set()\n        mappings = []\n        cols = []\n        for m in df.columns:\n            try:\n                ct = Mapping.from_str(m)\n                mappings.append(ct)\n                cols.append(m)\n                for source, sign in ct.clause:\n                    edges.add((source, ct.target, sign))\n            except ValueError:\n                #current column isn't a mapping\n                pass\n\n        graph = Graph.from_tuples(edges)\n        hypergraph = HyperGraph.from_graph(graph)\n        hypergraph.mappings = mappings\n\n        if 'networks' in df.columns:\n            nnet = df['networks'].values.astype(int)\n        else:\n            nnet = None\n\n        return cls(hypergraph, matrix=df[cols].values, networks=nnet)", "response": "Creates a list of logical networks from a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_hypergraph(cls, hypergraph, networks=None):\n        matrix = None\n        nnet = None\n        if networks:\n            matrix = np.array([networks[0].to_array(hypergraph.mappings)])\n            nnet = [networks[0].networks]\n            for network in networks[1:]:\n                matrix = np.append(matrix, [network.to_array(hypergraph.mappings)], axis=0)\n                nnet.append(network.networks)\n\n        return cls(hypergraph, matrix, nnet)", "response": "Creates a list of logical networks from a given hypergraph and an optional list of logical networks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list of mappings present in at least one logical network in this list", "response": "def mappings(self):\n        \"\"\"\n        :class:`caspo.core.mapping.MappingList`: the list of mappings present in at least one logical network in this list\n        \"\"\"\n        return self.hg.mappings[np.unique(np.where(self.__matrix == 1)[1])]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset the internal state of the object.", "response": "def reset(self):\n        \"\"\"\n        Drop all networks in the list\n        \"\"\"\n        self.__matrix = np.array([])\n        self.__networks = np.array([])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split(self, indices):\n        return [LogicalNetworkList(self.hg, part) for part in np.split(self.__matrix, indices)]", "response": "Splits the logical networks according to given indices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef concat(self, other):\n        if len(other) == 0:\n            return self\n        elif len(self) == 0:\n            return other\n        else:\n            return LogicalNetworkList(self.hg, np.append(self.__matrix, other.__matrix, axis=0), np.concatenate([self.__networks, other.__networks]))", "response": "Returns the concatenation of self and other."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nappending a logical network to the list of logical entries.", "response": "def append(self, network):\n        \"\"\"\n        Append a :class:`caspo.core.logicalnetwork.LogicalNetwork` to the list\n\n        Parameters\n        ----------\n        network : :class:`caspo.core.logicalnetwork.LogicalNetwork`\n            The network to append\n        \"\"\"\n        arr = network.to_array(self.hg.mappings)\n        if len(self.__matrix):\n            self.__matrix = np.append(self.__matrix, [arr], axis=0)\n            self.__networks = np.append(self.__networks, network.networks)\n        else:\n            self.__matrix = np.array([arr])\n            self.__networks = np.array([network.networks])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_funset(self):\n        fs = set((gringo.Fun(\"variable\", [var]) for var in self.hg.nodes))\n\n        formulas = set()\n        for network in self:\n            formulas = formulas.union(it.imap(lambda (_, f): f, network.formulas_iter()))\n\n        formulas = pd.Series(list(formulas))\n\n        for i, network in enumerate(self):\n            for v, f in network.formulas_iter():\n                fs.add(gringo.Fun(\"formula\", [i, v, formulas[formulas == f].index[0]]))\n\n        for formula_idx, formula in formulas.iteritems():\n            for clause in formula:\n                clause_idx = self.hg.clauses_idx[clause]\n                fs.add(gringo.Fun(\"dnf\", [formula_idx, clause_idx]))\n                for variable, sign in clause:\n                    fs.add(gringo.Fun(\"clause\", [clause_idx, variable, sign]))\n\n        return fs", "response": "Converts the list of logical networks to a set of gringo. Fun_ instances"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dataframe(self, networks=False, dataset=None, size=False, n_jobs=-1):\n        length = len(self)\n        df = pd.DataFrame(self.__matrix, columns=map(str, self.hg.mappings))\n\n        if networks:\n            df = pd.concat([df, pd.DataFrame({'networks': self.__networks})], axis=1)\n\n        if dataset is not None:\n            clampings = dataset.clampings\n            readouts = dataset.readouts.columns\n            observations = dataset.readouts.values\n            pos = ~np.isnan(observations)\n\n            mse = Parallel(n_jobs=n_jobs)(delayed(__parallel_mse__)(n, clampings, readouts, observations[pos], pos) for n in self)\n            df = pd.concat([df, pd.DataFrame({'mse': mse})], axis=1)\n\n        if size:\n            df = pd.concat([df, pd.DataFrame({'size': np.fromiter((n.size for n in self), int, length)})], axis=1)\n\n        return df", "response": "Converts the list of logical networks to a pandas. DataFrame instance instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_csv(self, filename, networks=False, dataset=None, size=False, n_jobs=-1):\n        self.to_dataframe(networks, dataset, size, n_jobs).to_csv(filename, index=False)", "response": "Writes the list of logical networks to a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frequencies_iter(self):\n        f = self.__matrix.mean(axis=0)\n        for i, m in self.mappings.iteritems():\n            yield m, f[i]", "response": "Iterates over all non - zero frequencies of logical conjunction mappings in this list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef frequency(self, mapping):\n        return self.__matrix[:, self.hg.mappings[mapping]].mean()", "response": "Returns the frequency of a given mapping over all logical networks."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef combinatorics(self):\n        f = self.__matrix.mean(axis=0)\n        candidates = np.where((f < 1) & (f > 0))[0]\n        exclusive, inclusive = defaultdict(set), defaultdict(set)\n        for i, j in it.combinations(candidates, 2):\n            xor = np.logical_xor(self.__matrix[:, i], self.__matrix[:, j])\n            if xor.all():\n                exclusive[self.hg.mappings[i]].add(self.hg.mappings[j])\n                exclusive[self.hg.mappings[j]].add(self.hg.mappings[i])\n\n            if (~xor).all():\n                inclusive[self.hg.mappings[i]].add(self.hg.mappings[j])\n                inclusive[self.hg.mappings[j]].add(self.hg.mappings[i])\n\n        return exclusive, inclusive", "response": "Returns the set of mutually exclusive and inclusive mappings for the current hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predictions(self, setup, n_jobs=-1):\n        stimuli, inhibitors, readouts = setup.stimuli, setup.inhibitors, setup.readouts\n        nc = len(setup.cues())\n        predictions = np.zeros((len(self), 2**nc, len(setup)))\n        predictions[:, :, :] = Parallel(n_jobs=n_jobs)(delayed(__parallel_predictions__)(n, list(setup.clampings_iter(setup.cues())), readouts, stimuli, inhibitors) for n in self)\n\n        avg = np.average(predictions[:, :, nc:], axis=0, weights=self.__networks)\n        var = np.average((predictions[:, :, nc:]-avg)**2, axis=0, weights=self.__networks)\n\n        rcues = [\"TR:%s\" % c for c in setup.cues(True)]\n        cols = np.concatenate([rcues, [\"AVG:%s\" % r for r in readouts], [\"VAR:%s\" % r for r in readouts]])\n\n        #use the first network predictions to extract all clampings\n        df = pd.DataFrame(np.concatenate([predictions[0, :, :nc], avg, var], axis=1), columns=cols)\n        df[rcues] = df[rcues].astype(int)\n\n        return df", "response": "Returns a pandas. DataFrame_ with weighted average predictions and variance of all possible clampings for each logical network."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef weighted_mse(self, dataset, n_jobs=-1):\n        predictions = np.zeros((len(self), len(dataset.clampings), len(dataset.setup.readouts)))\n        predictions[:, :, :] = Parallel(n_jobs=n_jobs)(delayed(__parallel_predictions__)(n, dataset.clampings, dataset.setup.readouts) for n in self)\n        for i, _ in enumerate(self):\n            predictions[i, :, :] *= self.__networks[i]\n\n        readouts = dataset.readouts.values\n        pos = ~np.isnan(readouts)\n\n        return mean_squared_error(readouts[pos], (np.sum(predictions, axis=0) / np.sum(self.__networks))[pos])", "response": "Computes the weighted MSE over all logical networks with respect to the given dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a logical network from an iterable of integer tuples matching mappings in the given hypergraph.", "response": "def from_hypertuples(cls, hg, tuples):\n        \"\"\"\n        Creates a logical network from an iterable of integer tuples matching mappings in the given\n        :class:`caspo.core.hypergraph.HyperGraph`\n\n        Parameters\n        ----------\n        hg : :class:`caspo.core.hypergraph.HyperGraph`\n            Underlying hypergraph\n\n        tuples : (int,int)\n            tuples matching mappings in the given hypergraph\n\n        Returns\n        -------\n        caspo.core.logicalnetwork.LogicalNetwork\n            Created object instance\n        \"\"\"\n        return cls([(hg.clauses[j], hg.variable(i)) for i, j in tuples], networks=1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the logical network to its underlying interaction graph", "response": "def to_graph(self):\n        \"\"\"\n        Converts the logical network to its underlying interaction graph\n\n        Returns\n        -------\n        caspo.core.graph.Graph\n            The underlying interaction graph\n        \"\"\"\n        edges = set()\n        for clause, target in self.edges_iter():\n            for source, signature in clause:\n                edges.add((source, target, signature))\n\n        return Graph.from_tuples(edges)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform a simulation step from the given state and with respect to the given clamping", "response": "def step(self, state, clamping):\n        \"\"\"\n        Performs a simulation step from the given state and with respect to the given clamping\n\n        Parameters\n        ----------\n        state : dict\n            The key-value mapping describing the current state of the logical network\n\n        clamping : caspo.core.clamping.Clamping\n            A clamping over variables in the logical network\n\n        Returns\n        -------\n        dict\n            The key-value mapping describing the next state of the logical network\n        \"\"\"\n        ns = state.copy()\n        for var in state:\n            if clamping.has_variable(var):\n                ns[var] = int(clamping.bool(var))\n            else:\n                or_value = 0\n                for clause, _ in self.in_edges_iter(var):\n                    or_value = or_value or clause.bool(state)\n                    if or_value:\n                        break\n\n                ns[var] = int(or_value)\n\n        return ns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fixpoint(self, clamping, steps=0):\n        current = dict.fromkeys(self.variables(), 0)\n        updated = self.step(current, clamping)\n        steps -= 1\n        while current != updated and steps != 0:\n            current = updated\n            updated = self.step(current, clamping)\n\n        return current", "response": "Computes the fixpoint with respect to a given clamping."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the network predictions for the given iterable of clampings and readouts.", "response": "def predictions(self, clampings, readouts, stimuli=None, inhibitors=None, nclampings=-1):\n        \"\"\"\n        Computes network predictions for the given iterable of clampings\n\n        Parameters\n        ----------\n        clampings : iterable\n            Iterable over clampings\n\n        readouts : list[str]\n            List of readouts names\n\n        stimuli : Optional[list[str]]\n            List of stimuli names\n\n        inhibitors : Optional[list[str]]\n            List of inhibitors names\n\n        nclampings : Optional[int]\n            If greater than zero, it must be the number of clampings in the iterable. Otherwise,\n            clampings must implement the special method :func:`__len__`\n\n\n        Returns\n        -------\n        `pandas.DataFrame`_\n            DataFrame with network predictions for each clamping. If stimuli and inhibitors are given,\n            columns are included describing each clamping. Otherwise, columns correspond to readouts only.\n\n\n        .. _pandas.DataFrame: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n        \"\"\"\n        stimuli, inhibitors = stimuli or [], inhibitors or []\n        cues = stimuli + inhibitors\n        nc = len(cues)\n        ns = len(stimuli)\n        predictions = np.zeros((nclampings if nclampings > 0 else len(clampings), nc+len(readouts)), dtype=np.int8)\n        for i, clamping in enumerate(clampings):\n            if nc > 0:\n                arr = clamping.to_array(cues)\n                arr[np.where(arr[:ns] == -1)[0]] = 0\n                arr[ns + np.where(arr[ns:] == -1)[0]] = 1\n                predictions[i, :nc] = arr\n\n            fixpoint = self.fixpoint(clamping)\n            for j, readout in enumerate(readouts):\n                predictions[i, nc+j] = fixpoint.get(readout, 0)\n\n        return pd.DataFrame(predictions, columns=np.concatenate([stimuli, [i+'i' for i in inhibitors], readouts]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the mean squared error with respect to the given dataset object.", "response": "def mse(self, dataset):\n        \"\"\"\n        Returns the Mean Squared Error with respect to the given :class:`caspo.core.dataset.Dataset` object\n\n        Parameters\n        ----------\n        dataset : :class:`caspo.core.dataset.Dataset`\n            Dataset to compute MSE\n\n        Returns\n        -------\n        float\n            Computed mean squared error\n        \"\"\"\n        clampings = dataset.clampings\n        readouts = dataset.readouts.columns\n        observations = dataset.readouts.values\n        pos = ~np.isnan(observations)\n\n        return mean_squared_error(observations, (self.predictions(clampings, readouts).values)[pos])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef variables(self):\n        variables = set()\n        for v in self.nodes_iter():\n            if isinstance(v, Clause):\n                for l in v:\n                    variables.add(l.variable)\n            else:\n                variables.add(v)\n        return variables", "response": "Returns the set of variables in the logical network"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formulas_iter(self):\n        for var in it.ifilter(self.has_node, self.variables()):\n            yield var, frozenset(self.predecessors(var))", "response": "Iterates over all variable - clauses in the logical network and yields the next tuple of the form of the variables in the logical network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_array(self, mappings):\n        arr = np.zeros(len(mappings), np.int8)\n        for i, (clause, target) in enumerate(mappings):\n            if self.has_edge(clause, target):\n                arr[i] = 1\n\n        return arr", "response": "Converts the logical network to a binary array with respect to the given mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanswers questions. Provide or update an answer to one or more QuizQuestions.", "response": "def answering_questions(self, attempt, validation_token, quiz_submission_id, access_code=None, quiz_questions=None):\r\n        \"\"\"\r\n        Answering questions.\r\n\r\n        Provide or update an answer to one or more QuizQuestions.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - quiz_submission_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"quiz_submission_id\"] = quiz_submission_id\r\n\r\n        # REQUIRED - attempt\r\n        \"\"\"The attempt number of the quiz submission being taken. Note that this\r\n        must be the latest attempt index, as questions for earlier attempts can\r\n        not be modified.\"\"\"\r\n        data[\"attempt\"] = attempt\r\n\r\n        # REQUIRED - validation_token\r\n        \"\"\"The unique validation token you received when the Quiz Submission was\r\n        created.\"\"\"\r\n        data[\"validation_token\"] = validation_token\r\n\r\n        # OPTIONAL - access_code\r\n        \"\"\"Access code for the Quiz, if any.\"\"\"\r\n        if access_code is not None:\r\n            data[\"access_code\"] = access_code\r\n\r\n        # OPTIONAL - quiz_questions\r\n        \"\"\"Set of question IDs and the answer value.\r\n        \r\n        See {Appendix: Question Answer Formats} for the accepted answer formats\r\n        for each question type.\"\"\"\r\n        if quiz_questions is not None:\r\n            data[\"quiz_questions\"] = quiz_questions\r\n\r\n        self.logger.debug(\"POST /api/v1/quiz_submissions/{quiz_submission_id}/questions with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/quiz_submissions/{quiz_submission_id}/questions\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the list of clampings to a set of gringo. Fun s.", "response": "def to_funset(self, lname=\"clamping\", cname=\"clamped\"):\n        \"\"\"\n        Converts the list of clampings to a set of `gringo.Fun`_ instances\n\n        Parameters\n        ----------\n        lname : str\n            Predicate name for the clamping id\n\n        cname : str\n            Predicate name for the clamped variable\n\n        Returns\n        -------\n        set\n            Representation of all clampings as a set of `gringo.Fun`_ instances\n\n\n        .. _gringo.Fun: http://potassco.sourceforge.net/gringo.html#Fun\n        \"\"\"\n        fs = set()\n        for i, clamping in enumerate(self):\n            fs.add(gringo.Fun(lname, [i]))\n            fs = fs.union(clamping.to_funset(i, cname))\n\n        return fs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the list of clampings to a pandas. DataFrame instance instance.", "response": "def to_dataframe(self, stimuli=None, inhibitors=None, prepend=\"\"):\n        \"\"\"\n        Converts the list of clampigns to a `pandas.DataFrame`_ object instance\n\n        Parameters\n        ----------\n        stimuli : Optional[list[str]]\n            List of stimuli names. If given, stimuli are converted to {0,1} instead of {-1,1}.\n\n        inhibitors : Optional[list[str]]\n            List of inhibitors names. If given, inhibitors are renamed and converted to {0,1} instead of {-1,1}.\n\n        prepend : str\n            Columns are renamed using the given string at the beginning\n\n        Returns\n        -------\n        `pandas.DataFrame`_\n            DataFrame representation of the list of clampings\n\n\n        .. _pandas.DataFrame: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n        \"\"\"\n        stimuli, inhibitors = stimuli or [], inhibitors or []\n        cues = stimuli + inhibitors\n        nc = len(cues)\n        ns = len(stimuli)\n\n        variables = cues or np.array(list(set((v for (v, s) in it.chain.from_iterable(self)))))\n\n        matrix = np.array([])\n        for clamping in self:\n            arr = clamping.to_array(variables)\n            if nc > 0:\n                arr[np.where(arr[:ns] == -1)[0]] = 0\n                arr[ns + np.where(arr[ns:] == -1)[0]] = 1\n\n            if len(matrix):\n                matrix = np.append(matrix, [arr], axis=0)\n            else:\n                matrix = np.array([arr])\n\n        return pd.DataFrame(matrix, columns=[prepend + \"%s\" % c for c in (stimuli + [i+'i' for i in inhibitors] if nc > 0 else variables)])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the list of clampings to a CSV file.", "response": "def to_csv(self, filename, stimuli=None, inhibitors=None, prepend=\"\"):\n        \"\"\"\n        Writes the list of clampings to a CSV file\n\n        Parameters\n        ----------\n        filename : str\n            Absolute path where to write the CSV file\n\n        stimuli : Optional[list[str]]\n            List of stimuli names. If given, stimuli are converted to {0,1} instead of {-1,1}.\n\n        inhibitors : Optional[list[str]]\n            List of inhibitors names. If given, inhibitors are renamed and converted to {0,1} instead of {-1,1}.\n\n        prepend : str\n            Columns are renamed using the given string at the beginning\n        \"\"\"\n        self.to_dataframe(stimuli, inhibitors, prepend).to_csv(filename, index=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a list of clampings from a pandas. DataFrame instance.", "response": "def from_dataframe(cls, df, inhibitors=None):\n        \"\"\"\n        Creates a list of clampings from a `pandas.DataFrame`_ object instance.\n        Column names are expected to be of the form `TR:species_name`\n\n        Parameters\n        ----------\n        df : `pandas.DataFrame`_\n            Columns and rows correspond to species names and individual clampings, respectively.\n\n        inhibitors : Optional[list[str]]\n            If given, species names ending with `i` and found in the list (without the `i`)\n            will be interpreted as inhibitors. That is, if they are set to 1, the corresponding species is inhibited\n            and therefore its negatively clamped. Apart from that, all 1s (resp. 0s) are interpreted as positively\n            (resp. negatively) clamped.\n\n            Otherwise (if inhibitors=[]), all 1s (resp. -1s) are interpreted as positively (resp. negatively) clamped.\n\n\n        Returns\n        -------\n        caspo.core.ClampingList\n            Created object instance\n\n\n        .. _pandas.DataFrame: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n        \"\"\"\n        inhibitors = inhibitors or []\n        clampings = []\n        ni = len(inhibitors)\n        for _, row in df.iterrows():\n            if ni > 0:\n                literals = []\n                for v, s in row.iteritems():\n                    if v.endswith('i') and v[3:-1] in inhibitors:\n                        if s == 1:\n                            literals.append(Literal(v[3:-1], -1))\n                    else:\n                        literals.append(Literal(v[3:], 1 if s == 1 else -1))\n                clampings.append(Clamping(literals))\n            else:\n\n                clampings.append(Clamping([Literal(v[3:], s) for v, s in row[row != 0].iteritems()]))\n\n        return cls(clampings)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a list of clampings from a CSV file.", "response": "def from_csv(cls, filename, inhibitors=None):\n        \"\"\"\n        Creates a list of clampings from a CSV file. Column names are expected to be of the form `TR:species_name`\n\n        Parameters\n        ----------\n        filename : str\n            Absolute path to a CSV file to be loaded with `pandas.read_csv`_. The resulting DataFrame is passed to :func:`from_dataframe`.\n\n        inhibitors : Optional[list[str]]\n            If given, species names ending with `i` and found in the list (without the `i`)\n            will be interpreted as inhibitors. That is, if they are set to 1, the corresponding species is inhibited\n            and therefore its negatively clamped. Apart from that, all 1s (resp. 0s) are interpreted as positively\n            (resp. negatively) clamped.\n\n            Otherwise (if inhibitors=[]), all 1s (resp. -1s) are interpreted as positively (resp. negatively) clamped.\n\n\n        Returns\n        -------\n        caspo.core.clamping.ClampingList\n            Created object instance\n\n\n        .. _pandas.read_csv: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv\n        \"\"\"\n        df = pd.read_csv(filename)\n        return cls.from_dataframe(df, inhibitors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over the frequencies of all clamped variables", "response": "def frequencies_iter(self):\n        \"\"\"\n        Iterates over the frequencies of all clamped variables\n\n        Yields\n        ------\n        tuple[ caspo.core.literal.Literal, float ]\n            The next tuple of the form (literal, frequency)\n        \"\"\"\n        df = self.to_dataframe()\n        n = float(len(self))\n        for var, sign in it.product(df.columns, [-1, 1]):\n            f = len(df[df[var] == sign]) / n\n            if f > 0:\n                yield Literal(var, sign), f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the frequency of a clamped variable", "response": "def frequency(self, literal):\n        \"\"\"\n        Returns the frequency of a clamped variable\n\n        Parameters\n        ----------\n        literal : :class:`caspo.core.literal.Literal`\n            The clamped variable\n\n        Returns\n        -------\n        float\n            The frequency of the given literal\n\n        Raises\n        ------\n        ValueError\n            If the variable is not present in any of the clampings\n        \"\"\"\n        df = self.to_dataframe()\n        if literal.variable in df.columns:\n            return len(df[df[literal.variable] == literal.signature]) / float(len(self))\n        else:\n            raise ValueError(\"Variable not found: %s\" % literal.variable)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a tuple of two dictionaries containing the set of mutually exclusive and inclusive clampings.", "response": "def combinatorics(self):\n        \"\"\"\n        Returns mutually exclusive/inclusive clampings\n\n        Returns\n        -------\n        (dict,dict)\n            A tuple of 2 dictionaries.\n            For each literal key, the first dict has as value the set of mutually exclusive clampings while\n            the second dict has as value the set of mutually inclusive clampings.\n        \"\"\"\n        df = self.to_dataframe()\n        literals = set((l for l in it.chain.from_iterable(self)))\n        exclusive, inclusive = defaultdict(set), defaultdict(set)\n\n        for l1, l2 in it.combinations(it.ifilter(lambda l: self.frequency(l) < 1., literals), 2):\n            a1, a2 = df[l1.variable] == l1.signature, df[l2.variable] == l2.signature\n            if (a1 != a2).all():\n                exclusive[l1].add(l2)\n                exclusive[l2].add(l1)\n\n            if (a1 == a2).all():\n                inclusive[l1].add(l2)\n                inclusive[l2].add(l1)\n\n        return exclusive, inclusive"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef differences(self, networks, readouts, prepend=\"\"):\n        z, p = np.zeros((len(self), len(readouts)), dtype=int), np.zeros(len(self), dtype=int)\n        for n1, n2 in it.combinations(networks, 2):\n            r, c = np.where(n1.predictions(self, readouts) != n2.predictions(self, readouts))\n            z[r, c] += 1\n            p[r] += 1\n\n        df = pd.DataFrame(z, columns=[prepend + \"%s\" % c for c in readouts])\n        return pd.concat([df, pd.Series(p, name='pairs')], axis=1)", "response": "Returns the total number of pairwise differences over the given readouts for each logical network in the given networks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_literals(self, literals):\n        clampings = []\n        for clamping in self:\n            c = clamping.drop_literals(literals)\n            if len(c) > 0:\n                clampings.append(c)\n\n        return ClampingList(clampings)", "response": "Returns a new list of clampings with the given literals removed from each clamping."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_tuples(cls, tuples):\n        return cls(it.imap(lambda (v, s): Literal(v, s), tuples))", "response": "Creates a clamping object from a set of tuples describing clamped variables and signs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_funset(self, index, name=\"clamped\"):\n        fs = set()\n        for var, sign in self:\n            fs.add(gringo.Fun(name, [index, var, sign]))\n\n        return fs", "response": "Converts the clamping to a set of gringo. Fun_ objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_array(self, variables):\n        arr = np.zeros(len(variables), np.int8)\n        dc = dict(self)\n\n        for i, var in enumerate(variables):\n            arr[i] = dc.get(var, arr[i])\n\n        return arr", "response": "Converts the clamping to a 1 - D array with respect to the given variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_custom_gradebook_column(self, course_id, column_title, column_hidden=None, column_position=None, column_teacher_notes=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - column[title]\r\n        \"\"\"no description\"\"\"\r\n        data[\"column[title]\"] = column_title\r\n\r\n        # OPTIONAL - column[position]\r\n        \"\"\"The position of the column relative to other custom columns\"\"\"\r\n        if column_position is not None:\r\n            data[\"column[position]\"] = column_position\r\n\r\n        # OPTIONAL - column[hidden]\r\n        \"\"\"Hidden columns are not displayed in the gradebook\"\"\"\r\n        if column_hidden is not None:\r\n            data[\"column[hidden]\"] = column_hidden\r\n\r\n        # OPTIONAL - column[teacher_notes]\r\n        \"\"\"Set this if the column is created by a teacher.  The gradebook only\r\n        supports one teacher_notes column.\"\"\"\r\n        if column_teacher_notes is not None:\r\n            data[\"column[teacher_notes]\"] = column_teacher_notes\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/custom_gradebook_columns with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/custom_gradebook_columns\".format(**path), data=data, params=params, single_item=True)", "response": "Create a custom gradebook column. Create a custom column."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a custom column data. Updates the content of a custom column.", "response": "def update_column_data(self, id, user_id, course_id, column_data_content):\r\n        \"\"\"\r\n        Update column data.\r\n\r\n        Set the content of a custom column\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - column_data[content]\r\n        \"\"\"Column content.  Setting this to blank will delete the datum object.\"\"\"\r\n        data[\"column_data[content]\"] = column_data_content\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/custom_gradebook_columns/{id}/data/{user_id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/custom_gradebook_columns/{id}/data/{user_id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_log(file_path):\n    if not os.path.isfile(file_path):\n        return elements.error(\"Output Log\", \"Could not open file: \" + file_path.split(os.sep)[-1])\n\n    headers = [\"Converged Iterations\",\n               \"Avg. Iterations to Converge\",\n               \"Processor Count\",\n               \"Dycore Type\"]\n\n    with open(file_path, 'r') as f:\n        dycore_types = {\"0\": \"Glide\",\n                        \"1\": \"Glam\",\n                        \"2\": \"Glissade\",\n                        \"3\": \"Albany_felix\",\n                        \"4\": \"BISICLES\"}\n        curr_step = 0\n        proc_count = 0\n        iter_number = 0\n        converged_iters = []\n        iters_to_converge = []\n        for line in f:\n            split = line.split()\n            if ('CISM dycore type' in line):\n                if line.split()[-1] == '=':\n                    dycore_type = dycore_types[next(f).strip()]\n                else:\n                    dycore_type = dycore_types[line.split()[-1]]\n            elif ('total procs' in line):\n                proc_count += int(line.split()[-1])\n            elif ('Nonlinear Solver Step' in line):\n                curr_step = int(line.split()[4])\n            elif ('Compute ice velocities, time = ' in line):\n                converged_iters.append(curr_step)\n                curr_step = float(line.split()[-1])\n            elif ('\"SOLVE_STATUS_CONVERGED\"' in line):\n                split = line.split()\n                iters_to_converge.append(int(split[split.index('\"SOLVE_STATUS_CONVERGED\"') + 2]))\n            elif (\"Compute dH/dt\" in line):\n                iters_to_converge.append(int(iter_number))\n            elif len(split) > 0 and split[0].isdigit():\n                iter_number = split[0]\n        if iters_to_converge == []:\n            iters_to_converge.append(int(iter_number))\n    data = {\n        \"Dycore Type\": dycore_type,\n        \"Processor Count\": proc_count,\n        \"Converged Iterations\": len(converged_iters),\n        \"Avg. Iterations to Converge\": np.mean(iters_to_converge)\n    }\n    return elements.table(\"Output Log\", headers, data)", "response": "Parse a CISM output log file and extract some information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_config(file_path):\n    if not os.path.isfile(file_path):\n        return {}\n    parser = ConfigParser()\n    parser.read(file_path)\n    # Strip out inline comments\n    for s in parser._sections:\n        for v in six.iterkeys(parser._sections[s]):\n            parser._sections[s][v] = parser._sections[s][v].split(\"#\")[0].strip()\n    return parser._sections", "response": "Convert the CISM configuration file to a dictionary representation of the given file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _selectedRepoRow(self):\n        # TODO - figure out what happens if no repo is selected\n        selectedModelIndexes = \\\n            self.reposTableWidget.selectionModel().selectedRows()\n        for index in selectedModelIndexes:\n            return index.row()", "response": "Return the currently selected repo row"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating objective function for given measured metabolites.", "response": "def set_objective(self, measured_metabolites):\n        '''\n        Updates objective function for given measured metabolites.\n\n        :param dict measured_metabolites: dict in which keys are metabolite names \n            and values are float numbers represent fold changes in metabolites. \n        '''\n        self.clean_objective()\n        for k, v in measured_metabolites.items():\n\n            m = self.model.metabolites.get_by_id(k)\n            total_stoichiometry = m.total_stoichiometry(\n                self.without_transports)\n\n            for r in m.producers(self.without_transports):\n                update_rate = v * r.metabolites[m] / total_stoichiometry\n                r.objective_coefficient += update_rate"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a class that can be used to create a new router for a given type.", "response": "def Routers(typ, share, handler=RoutersHandler):\n    \"\"\"\n    Pass the result of this function to the handler argument\n    in your attribute declaration\n    \"\"\"\n    _sharing_id, _mode = tuple(share.split(\":\"))\n    _router_cls = ROUTERS.get(typ)\n    class _Handler(handler):\n        mode=_mode\n        sharing_id=_sharing_id\n        router_cls=_router_cls\n    return _Handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist migration issues. Returns a list of all issues in a given account.", "response": "def list_migration_issues_accounts(self, account_id, content_migration_id):\r\n        \"\"\"\r\n        List migration issues.\r\n\r\n        Returns paginated migration issues\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        self.logger.debug(\"GET /api/v1/accounts/{account_id}/content_migrations/{content_migration_id}/migration_issues with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/accounts/{account_id}/content_migrations/{content_migration_id}/migration_issues\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist migration issues. Returns a paginated list of migration issues.", "response": "def list_migration_issues_courses(self, course_id, content_migration_id):\r\n        \"\"\"\r\n        List migration issues.\r\n\r\n        Returns paginated migration issues\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/content_migrations/{content_migration_id}/migration_issues with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/content_migrations/{content_migration_id}/migration_issues\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_migration_issues_groups(self, group_id, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/content_migrations/{content_migration_id}/migration_issues with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/content_migrations/{content_migration_id}/migration_issues\".format(**path), data=data, params=params, all_pages=True)", "response": "List migration issues. Returns a list of all issues in a group."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_migration_issues_users(self, user_id, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        self.logger.debug(\"GET /api/v1/users/{user_id}/content_migrations/{content_migration_id}/migration_issues with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/users/{user_id}/content_migrations/{content_migration_id}/migration_issues\".format(**path), data=data, params=params, all_pages=True)", "response": "List migration issues. Returns a paginated list of migration issues for a given user and content migration."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_migration_issue_accounts(self, id, account_id, workflow_state, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - account_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"account_id\"] = account_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - workflow_state\r\n        \"\"\"Set the workflow_state of the issue.\"\"\"\r\n        self._validate_enum(workflow_state, [\"active\", \"resolved\"])\r\n        data[\"workflow_state\"] = workflow_state\r\n\r\n        self.logger.debug(\"PUT /api/v1/accounts/{account_id}/content_migrations/{content_migration_id}/migration_issues/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/accounts/{account_id}/content_migrations/{content_migration_id}/migration_issues/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Update a migration issue. Updates the workflow_state of a migration issue. Updates the workflow_state of a migration issue."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_migration_issue_courses(self, id, course_id, workflow_state, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - workflow_state\r\n        \"\"\"Set the workflow_state of the issue.\"\"\"\r\n        self._validate_enum(workflow_state, [\"active\", \"resolved\"])\r\n        data[\"workflow_state\"] = workflow_state\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/content_migrations/{content_migration_id}/migration_issues/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/content_migrations/{content_migration_id}/migration_issues/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Update a migration issue. Updates the workflow_state of a migration issue. Updates the workflow_state of a migration issue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_migration_issue_groups(self, id, group_id, workflow_state, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - workflow_state\r\n        \"\"\"Set the workflow_state of the issue.\"\"\"\r\n        self._validate_enum(workflow_state, [\"active\", \"resolved\"])\r\n        data[\"workflow_state\"] = workflow_state\r\n\r\n        self.logger.debug(\"PUT /api/v1/groups/{group_id}/content_migrations/{content_migration_id}/migration_issues/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/groups/{group_id}/content_migrations/{content_migration_id}/migration_issues/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Update a migration issue. Updates the workflow_state of a migration issue. Updates the workflow_state of a migration issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_migration_issue_users(self, id, user_id, workflow_state, content_migration_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - user_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"user_id\"] = user_id\r\n\r\n        # REQUIRED - PATH - content_migration_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"content_migration_id\"] = content_migration_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # REQUIRED - workflow_state\r\n        \"\"\"Set the workflow_state of the issue.\"\"\"\r\n        self._validate_enum(workflow_state, [\"active\", \"resolved\"])\r\n        data[\"workflow_state\"] = workflow_state\r\n\r\n        self.logger.debug(\"PUT /api/v1/users/{user_id}/content_migrations/{content_migration_id}/migration_issues/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/users/{user_id}/content_migrations/{content_migration_id}/migration_issues/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Update a migration issue. Updates the workflow_state of a migration issue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string representation of the current region.", "response": "def stringize(\n        self,\n        rnf_profile,\n    ):\n        \"\"\"Create RNF representation of this segment.\n\n\t\tArgs:\n\t\t\trnf_profile (rnftools.rnfformat.RnfProfile): RNF profile (with widths).\n\t\t\"\"\"\n\n        coor_width = max(rnf_profile.coor_width, len(str(self.left)), len(str(self.right)))\n        return \"({},{},{},{},{})\".format(\n            str(self.genome_id).zfill(rnf_profile.genome_id_width),\n            str(self.chr_id).zfill(rnf_profile.chr_id_width), self.direction,\n            str(self.left).zfill(coor_width),\n            str(self.right).zfill(coor_width)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting RNF values for this segment from its textual representation and save them into this object.", "response": "def destringize(self, string):\n        \"\"\"Get RNF values for this segment from its textual representation and\n\t\tsave them into this object.\n\n\t\tArgs:\n\t\t\tstring (str): Textual representation of a segment.\n\t\t\"\"\"\n\n        m = segment_destr_pattern.match(string)\n        self.genome_id = int(m.group(1))\n        self.chr_id = int(m.group(2))\n        self.direction = m.group(3)\n        self.left = int(m.group(4))\n        self.right = int(m.group(5))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of assignments for the current context.", "response": "def list_assignments(self, course_id, assignment_ids=None, bucket=None, include=None, needs_grading_count_by_section=None, override_assignment_dates=None, search_term=None):\r\n        \"\"\"\r\n        List assignments.\r\n\r\n        Returns the list of assignments for the current context.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the assignment. The \"assignment_visibility\" option\r\n        requires that the Differentiated Assignments course feature be turned on. If\r\n        \"observed_users\" is passed, submissions for observed users will also be included as an array.\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission\", \"assignment_visibility\", \"all_dates\", \"overrides\", \"observed_users\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - search_term\r\n        \"\"\"The partial title of the assignments to match and return.\"\"\"\r\n        if search_term is not None:\r\n            params[\"search_term\"] = search_term\r\n\r\n        # OPTIONAL - override_assignment_dates\r\n        \"\"\"Apply assignment overrides for each assignment, defaults to true.\"\"\"\r\n        if override_assignment_dates is not None:\r\n            params[\"override_assignment_dates\"] = override_assignment_dates\r\n\r\n        # OPTIONAL - needs_grading_count_by_section\r\n        \"\"\"Split up \"needs_grading_count\" by sections into the \"needs_grading_count_by_section\" key, defaults to false\"\"\"\r\n        if needs_grading_count_by_section is not None:\r\n            params[\"needs_grading_count_by_section\"] = needs_grading_count_by_section\r\n\r\n        # OPTIONAL - bucket\r\n        \"\"\"If included, only return certain assignments depending on due date and submission status.\"\"\"\r\n        if bucket is not None:\r\n            self._validate_enum(bucket, [\"past\", \"overdue\", \"undated\", \"ungraded\", \"unsubmitted\", \"upcoming\", \"future\"])\r\n            params[\"bucket\"] = bucket\r\n\r\n        # OPTIONAL - assignment_ids\r\n        \"\"\"if set, return only assignments specified\"\"\"\r\n        if assignment_ids is not None:\r\n            params[\"assignment_ids\"] = assignment_ids\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignments with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignments\".format(**path), data=data, params=params, all_pages=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a single assignment. Returns the single assignment with the given id.", "response": "def get_single_assignment(self, id, course_id, all_dates=None, include=None, needs_grading_count_by_section=None, override_assignment_dates=None):\r\n        \"\"\"\r\n        Get a single assignment.\r\n\r\n        Returns the assignment with the given id.\r\n         \"observed_users\" is passed, submissions for observed users will also be included.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - include\r\n        \"\"\"Associations to include with the assignment. The \"assignment_visibility\" option\r\n        requires that the Differentiated Assignments course feature be turned on. If\"\"\"\r\n        if include is not None:\r\n            self._validate_enum(include, [\"submission\", \"assignment_visibility\", \"overrides\", \"observed_users\"])\r\n            params[\"include\"] = include\r\n\r\n        # OPTIONAL - override_assignment_dates\r\n        \"\"\"Apply assignment overrides to the assignment, defaults to true.\"\"\"\r\n        if override_assignment_dates is not None:\r\n            params[\"override_assignment_dates\"] = override_assignment_dates\r\n\r\n        # OPTIONAL - needs_grading_count_by_section\r\n        \"\"\"Split up \"needs_grading_count\" by sections into the \"needs_grading_count_by_section\" key, defaults to false\"\"\"\r\n        if needs_grading_count_by_section is not None:\r\n            params[\"needs_grading_count_by_section\"] = needs_grading_count_by_section\r\n\r\n        # OPTIONAL - all_dates\r\n        \"\"\"All dates associated with the assignment, if applicable\"\"\"\r\n        if all_dates is not None:\r\n            params[\"all_dates\"] = all_dates\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignments/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignments/{id}\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an assignment for this course. Returns the full assignment record", "response": "def create_assignment(self, course_id, assignment_name, assignment_allowed_extensions=None, assignment_assignment_group_id=None, assignment_assignment_overrides=None, assignment_automatic_peer_reviews=None, assignment_description=None, assignment_due_at=None, assignment_external_tool_tag_attributes=None, assignment_grade_group_students_individually=None, assignment_grading_standard_id=None, assignment_grading_type=None, assignment_group_category_id=None, assignment_integration_data=None, assignment_integration_id=None, assignment_lock_at=None, assignment_muted=None, assignment_notify_of_update=None, assignment_omit_from_final_grade=None, assignment_only_visible_to_overrides=None, assignment_peer_reviews=None, assignment_points_possible=None, assignment_position=None, assignment_published=None, assignment_submission_types=None, assignment_turnitin_enabled=None, assignment_turnitin_settings=None, assignment_unlock_at=None, assignment_vericite_enabled=None):\r\n        \"\"\"\r\n        Create an assignment.\r\n\r\n        Create a new assignment for this course. The assignment is created in the\r\n        active state.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - assignment[name]\r\n        \"\"\"The assignment name.\"\"\"\r\n        data[\"assignment[name]\"] = assignment_name\r\n\r\n        # OPTIONAL - assignment[position]\r\n        \"\"\"The position of this assignment in the group when displaying\r\n        assignment lists.\"\"\"\r\n        if assignment_position is not None:\r\n            data[\"assignment[position]\"] = assignment_position\r\n\r\n        # OPTIONAL - assignment[submission_types]\r\n        \"\"\"List of supported submission types for the assignment.\r\n        Unless the assignment is allowing online submissions, the array should\r\n        only have one element.\r\n        \r\n        If not allowing online submissions, your options are:\r\n          \"online_quiz\"\r\n          \"none\"\r\n          \"on_paper\"\r\n          \"online_quiz\"\r\n          \"discussion_topic\"\r\n          \"external_tool\"\r\n        \r\n        If you are allowing online submissions, you can have one or many\r\n        allowed submission types:\r\n        \r\n          \"online_upload\"\r\n          \"online_text_entry\"\r\n          \"online_url\"\r\n          \"media_recording\" (Only valid when the Kaltura plugin is enabled)\"\"\"\r\n        if assignment_submission_types is not None:\r\n            self._validate_enum(assignment_submission_types, [\"online_quiz\", \"none\", \"on_paper\", \"online_quiz\", \"discussion_topic\", \"external_tool\", \"online_upload\", \"online_text_entry\", \"online_url\", \"media_recording\"])\r\n            data[\"assignment[submission_types]\"] = assignment_submission_types\r\n\r\n        # OPTIONAL - assignment[allowed_extensions]\r\n        \"\"\"Allowed extensions if submission_types includes \"online_upload\"\r\n        \r\n        Example:\r\n          allowed_extensions: [\"docx\",\"ppt\"]\"\"\"\r\n        if assignment_allowed_extensions is not None:\r\n            data[\"assignment[allowed_extensions]\"] = assignment_allowed_extensions\r\n\r\n        # OPTIONAL - assignment[turnitin_enabled]\r\n        \"\"\"Only applies when the Turnitin plugin is enabled for a course and\r\n        the submission_types array includes \"online_upload\".\r\n        Toggles Turnitin submissions for the assignment.\r\n        Will be ignored if Turnitin is not available for the course.\"\"\"\r\n        if assignment_turnitin_enabled is not None:\r\n            data[\"assignment[turnitin_enabled]\"] = assignment_turnitin_enabled\r\n\r\n        # OPTIONAL - assignment[vericite_enabled]\r\n        \"\"\"Only applies when the VeriCite plugin is enabled for a course and\r\n        the submission_types array includes \"online_upload\".\r\n        Toggles VeriCite submissions for the assignment.\r\n        Will be ignored if VeriCite is not available for the course.\"\"\"\r\n        if assignment_vericite_enabled is not None:\r\n            data[\"assignment[vericite_enabled]\"] = assignment_vericite_enabled\r\n\r\n        # OPTIONAL - assignment[turnitin_settings]\r\n        \"\"\"Settings to send along to turnitin. See Assignment object definition for\r\n        format.\"\"\"\r\n        if assignment_turnitin_settings is not None:\r\n            data[\"assignment[turnitin_settings]\"] = assignment_turnitin_settings\r\n\r\n        # OPTIONAL - assignment[integration_data]\r\n        \"\"\"Data related to third party integrations, JSON string required.\"\"\"\r\n        if assignment_integration_data is not None:\r\n            data[\"assignment[integration_data]\"] = assignment_integration_data\r\n\r\n        # OPTIONAL - assignment[integration_id]\r\n        \"\"\"Unique ID from third party integrations\"\"\"\r\n        if assignment_integration_id is not None:\r\n            data[\"assignment[integration_id]\"] = assignment_integration_id\r\n\r\n        # OPTIONAL - assignment[peer_reviews]\r\n        \"\"\"If submission_types does not include external_tool,discussion_topic,\r\n        online_quiz, or on_paper, determines whether or not peer reviews\r\n        will be turned on for the assignment.\"\"\"\r\n        if assignment_peer_reviews is not None:\r\n            data[\"assignment[peer_reviews]\"] = assignment_peer_reviews\r\n\r\n        # OPTIONAL - assignment[automatic_peer_reviews]\r\n        \"\"\"Whether peer reviews will be assigned automatically by Canvas or if\r\n        teachers must manually assign peer reviews. Does not apply if peer reviews\r\n        are not enabled.\"\"\"\r\n        if assignment_automatic_peer_reviews is not None:\r\n            data[\"assignment[automatic_peer_reviews]\"] = assignment_automatic_peer_reviews\r\n\r\n        # OPTIONAL - assignment[notify_of_update]\r\n        \"\"\"If true, Canvas will send a notification to students in the class\r\n        notifying them that the content has changed.\"\"\"\r\n        if assignment_notify_of_update is not None:\r\n            data[\"assignment[notify_of_update]\"] = assignment_notify_of_update\r\n\r\n        # OPTIONAL - assignment[group_category_id]\r\n        \"\"\"If present, the assignment will become a group assignment assigned\r\n        to the group.\"\"\"\r\n        if assignment_group_category_id is not None:\r\n            data[\"assignment[group_category_id]\"] = assignment_group_category_id\r\n\r\n        # OPTIONAL - assignment[grade_group_students_individually]\r\n        \"\"\"If this is a group assignment, teachers have the options to grade\r\n        students individually. If false, Canvas will apply the assignment's\r\n        score to each member of the group. If true, the teacher can manually\r\n        assign scores to each member of the group.\"\"\"\r\n        if assignment_grade_group_students_individually is not None:\r\n            data[\"assignment[grade_group_students_individually]\"] = assignment_grade_group_students_individually\r\n\r\n        # OPTIONAL - assignment[external_tool_tag_attributes]\r\n        \"\"\"Hash of external tool parameters if submission_types is [\"external_tool\"].\r\n        See Assignment object definition for format.\"\"\"\r\n        if assignment_external_tool_tag_attributes is not None:\r\n            data[\"assignment[external_tool_tag_attributes]\"] = assignment_external_tool_tag_attributes\r\n\r\n        # OPTIONAL - assignment[points_possible]\r\n        \"\"\"The maximum points possible on the assignment.\"\"\"\r\n        if assignment_points_possible is not None:\r\n            data[\"assignment[points_possible]\"] = assignment_points_possible\r\n\r\n        # OPTIONAL - assignment[grading_type]\r\n        \"\"\"The strategy used for grading the assignment.\r\n        The assignment defaults to \"points\" if this field is omitted.\"\"\"\r\n        if assignment_grading_type is not None:\r\n            self._validate_enum(assignment_grading_type, [\"pass_fail\", \"percent\", \"letter_grade\", \"gpa_scale\", \"points\"])\r\n            data[\"assignment[grading_type]\"] = assignment_grading_type\r\n\r\n        # OPTIONAL - assignment[due_at]\r\n        \"\"\"The day/time the assignment is due.\r\n        Accepts times in ISO 8601 format, e.g. 2014-10-21T18:48:00Z.\"\"\"\r\n        if assignment_due_at is not None:\r\n            data[\"assignment[due_at]\"] = assignment_due_at\r\n\r\n        # OPTIONAL - assignment[lock_at]\r\n        \"\"\"The day/time the assignment is locked after.\r\n        Accepts times in ISO 8601 format, e.g. 2014-10-21T18:48:00Z.\"\"\"\r\n        if assignment_lock_at is not None:\r\n            data[\"assignment[lock_at]\"] = assignment_lock_at\r\n\r\n        # OPTIONAL - assignment[unlock_at]\r\n        \"\"\"The day/time the assignment is unlocked.\r\n        Accepts times in ISO 8601 format, e.g. 2014-10-21T18:48:00Z.\"\"\"\r\n        if assignment_unlock_at is not None:\r\n            data[\"assignment[unlock_at]\"] = assignment_unlock_at\r\n\r\n        # OPTIONAL - assignment[description]\r\n        \"\"\"The assignment's description, supports HTML.\"\"\"\r\n        if assignment_description is not None:\r\n            data[\"assignment[description]\"] = assignment_description\r\n\r\n        # OPTIONAL - assignment[assignment_group_id]\r\n        \"\"\"The assignment group id to put the assignment in.\r\n        Defaults to the top assignment group in the course.\"\"\"\r\n        if assignment_assignment_group_id is not None:\r\n            data[\"assignment[assignment_group_id]\"] = assignment_assignment_group_id\r\n\r\n        # OPTIONAL - assignment[muted]\r\n        \"\"\"Whether this assignment is muted.\r\n        A muted assignment does not send change notifications\r\n        and hides grades from students.\r\n        Defaults to false.\"\"\"\r\n        if assignment_muted is not None:\r\n            data[\"assignment[muted]\"] = assignment_muted\r\n\r\n        # OPTIONAL - assignment[assignment_overrides]\r\n        \"\"\"List of overrides for the assignment.\r\n        NOTE: The assignment overrides feature is in beta.\"\"\"\r\n        if assignment_assignment_overrides is not None:\r\n            data[\"assignment[assignment_overrides]\"] = assignment_assignment_overrides\r\n\r\n        # OPTIONAL - assignment[only_visible_to_overrides]\r\n        \"\"\"Whether this assignment is only visible to overrides\r\n        (Only useful if 'differentiated assignments' account setting is on)\"\"\"\r\n        if assignment_only_visible_to_overrides is not None:\r\n            data[\"assignment[only_visible_to_overrides]\"] = assignment_only_visible_to_overrides\r\n\r\n        # OPTIONAL - assignment[published]\r\n        \"\"\"Whether this assignment is published.\r\n        (Only useful if 'draft state' account setting is on)\r\n        Unpublished assignments are not visible to students.\"\"\"\r\n        if assignment_published is not None:\r\n            data[\"assignment[published]\"] = assignment_published\r\n\r\n        # OPTIONAL - assignment[grading_standard_id]\r\n        \"\"\"The grading standard id to set for the course.  If no value is provided for this argument the current grading_standard will be un-set from this course.\r\n        This will update the grading_type for the course to 'letter_grade' unless it is already 'gpa_scale'.\"\"\"\r\n        if assignment_grading_standard_id is not None:\r\n            data[\"assignment[grading_standard_id]\"] = assignment_grading_standard_id\r\n\r\n        # OPTIONAL - assignment[omit_from_final_grade]\r\n        \"\"\"Whether this assignment is counted towards a student's final grade.\"\"\"\r\n        if assignment_omit_from_final_grade is not None:\r\n            data[\"assignment[omit_from_final_grade]\"] = assignment_omit_from_final_grade\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/assignments with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/assignments\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_assignment_overrides(self, course_id, assignment_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        self.logger.debug(\"GET /api/v1/courses/{course_id}/assignments/{assignment_id}/overrides with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/overrides\".format(**path), data=data, params=params, all_pages=True)", "response": "List assignment overrides. Returns the list of overrides for this assignment that target\r\n        sections / groups / students visible to the current user. Returns the list of overrides for this assignment that target\r\n        sections / groups / students visible to the current user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef redirect_to_assignment_override_for_group(self, group_id, assignment_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - group_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"group_id\"] = group_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        self.logger.debug(\"GET /api/v1/groups/{group_id}/assignments/{assignment_id}/override with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/groups/{group_id}/assignments/{assignment_id}/override\".format(**path), data=data, params=params, no_data=True)", "response": "Redirect to the assignment override for a given group. Returns a 201 Created with the new assignment override."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef redirect_to_assignment_override_for_section(self, assignment_id, course_section_id):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_section_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_section_id\"] = course_section_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        self.logger.debug(\"GET /api/v1/sections/{course_section_id}/assignments/{assignment_id}/override with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"GET\", \"/api/v1/sections/{course_section_id}/assignments/{assignment_id}/override\".format(**path), data=data, params=params, no_data=True)", "response": "Redirect to the assignment override for a given section. Returns a 201 Created with the new assignment override."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an assignment override.", "response": "def create_assignment_override(self, course_id, assignment_id, assignment_override_course_section_id=None, assignment_override_due_at=None, assignment_override_group_id=None, assignment_override_lock_at=None, assignment_override_student_ids=None, assignment_override_title=None, assignment_override_unlock_at=None):\r\n        \"\"\"\r\n        Create an assignment override.\r\n\r\n        One of student_ids, group_id, or course_section_id must be present. At most\r\n        one should be present; if multiple are present only the most specific\r\n        (student_ids first, then group_id, then course_section_id) is used and any\r\n        others are ignored.\r\n        \"\"\"\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # OPTIONAL - assignment_override[student_ids]\r\n        \"\"\"The IDs of\r\n        the override's target students. If present, the IDs must each identify a\r\n        user with an active student enrollment in the course that is not already\r\n        targetted by a different adhoc override.\"\"\"\r\n        if assignment_override_student_ids is not None:\r\n            data[\"assignment_override[student_ids]\"] = assignment_override_student_ids\r\n\r\n        # OPTIONAL - assignment_override[title]\r\n        \"\"\"The title of the adhoc\r\n        assignment override. Required if student_ids is present, ignored\r\n        otherwise (the title is set to the name of the targetted group or section\r\n        instead).\"\"\"\r\n        if assignment_override_title is not None:\r\n            data[\"assignment_override[title]\"] = assignment_override_title\r\n\r\n        # OPTIONAL - assignment_override[group_id]\r\n        \"\"\"The ID of the\r\n        override's target group. If present, the following conditions must be met\r\n        for the override to be successful:\r\n        \r\n        1. the assignment MUST be a group assignment (a group_category_id is assigned to it)\r\n        2. the ID must identify an active group in the group set the assignment is in\r\n        3. the ID must not be targetted by a different override\r\n        \r\n        See {Appendix: Group assignments} for more info.\"\"\"\r\n        if assignment_override_group_id is not None:\r\n            data[\"assignment_override[group_id]\"] = assignment_override_group_id\r\n\r\n        # OPTIONAL - assignment_override[course_section_id]\r\n        \"\"\"The ID\r\n        of the override's target section. If present, must identify an active\r\n        section of the assignment's course not already targetted by a different\r\n        override.\"\"\"\r\n        if assignment_override_course_section_id is not None:\r\n            data[\"assignment_override[course_section_id]\"] = assignment_override_course_section_id\r\n\r\n        # OPTIONAL - assignment_override[due_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment is due. Accepts times in ISO 8601 format, e.g.\r\n        2014-10-21T18:48:00Z. If absent, this override will not affect due date.\r\n        May be present but null to indicate the override removes any previous due\r\n        date.\"\"\"\r\n        if assignment_override_due_at is not None:\r\n            data[\"assignment_override[due_at]\"] = assignment_override_due_at\r\n\r\n        # OPTIONAL - assignment_override[unlock_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment becomes unlocked. Accepts times in ISO 8601\r\n        format, e.g. 2014-10-21T18:48:00Z. If absent, this override will not\r\n        affect the unlock date. May be present but null to indicate the override\r\n        removes any previous unlock date.\"\"\"\r\n        if assignment_override_unlock_at is not None:\r\n            data[\"assignment_override[unlock_at]\"] = assignment_override_unlock_at\r\n\r\n        # OPTIONAL - assignment_override[lock_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment becomes locked. Accepts times in ISO 8601\r\n        format, e.g. 2014-10-21T18:48:00Z. If absent, this override will not\r\n        affect the lock date. May be present but null to indicate the override\r\n        removes any previous lock date.\"\"\"\r\n        if assignment_override_lock_at is not None:\r\n            data[\"assignment_override[lock_at]\"] = assignment_override_lock_at\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/assignments/{assignment_id}/overrides with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/overrides\".format(**path), data=data, params=params, single_item=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_assignment_override(self, id, course_id, assignment_id, assignment_override_due_at=None, assignment_override_lock_at=None, assignment_override_student_ids=None, assignment_override_title=None, assignment_override_unlock_at=None):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - PATH - assignment_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"assignment_id\"] = assignment_id\r\n\r\n        # REQUIRED - PATH - id\r\n        \"\"\"ID\"\"\"\r\n        path[\"id\"] = id\r\n\r\n        # OPTIONAL - assignment_override[student_ids]\r\n        \"\"\"The IDs of the\r\n        override's target students. If present, the IDs must each identify a\r\n        user with an active student enrollment in the course that is not already\r\n        targetted by a different adhoc override. Ignored unless the override\r\n        being updated is adhoc.\"\"\"\r\n        if assignment_override_student_ids is not None:\r\n            data[\"assignment_override[student_ids]\"] = assignment_override_student_ids\r\n\r\n        # OPTIONAL - assignment_override[title]\r\n        \"\"\"The title of an adhoc\r\n        assignment override. Ignored unless the override being updated is adhoc.\"\"\"\r\n        if assignment_override_title is not None:\r\n            data[\"assignment_override[title]\"] = assignment_override_title\r\n\r\n        # OPTIONAL - assignment_override[due_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment is due. Accepts times in ISO 8601 format, e.g.\r\n        2014-10-21T18:48:00Z. If absent, this override will not affect due date.\r\n        May be present but null to indicate the override removes any previous due\r\n        date.\"\"\"\r\n        if assignment_override_due_at is not None:\r\n            data[\"assignment_override[due_at]\"] = assignment_override_due_at\r\n\r\n        # OPTIONAL - assignment_override[unlock_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment becomes unlocked. Accepts times in ISO 8601\r\n        format, e.g. 2014-10-21T18:48:00Z. If absent, this override will not\r\n        affect the unlock date. May be present but null to indicate the override\r\n        removes any previous unlock date.\"\"\"\r\n        if assignment_override_unlock_at is not None:\r\n            data[\"assignment_override[unlock_at]\"] = assignment_override_unlock_at\r\n\r\n        # OPTIONAL - assignment_override[lock_at]\r\n        \"\"\"The day/time\r\n        the overridden assignment becomes locked. Accepts times in ISO 8601\r\n        format, e.g. 2014-10-21T18:48:00Z. If absent, this override will not\r\n        affect the lock date. May be present but null to indicate the override\r\n        removes any previous lock date.\"\"\"\r\n        if assignment_override_lock_at is not None:\r\n            data[\"assignment_override[lock_at]\"] = assignment_override_lock_at\r\n\r\n        self.logger.debug(\"PUT /api/v1/courses/{course_id}/assignments/{assignment_id}/overrides/{id} with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"PUT\", \"/api/v1/courses/{course_id}/assignments/{assignment_id}/overrides/{id}\".format(**path), data=data, params=params, single_item=True)", "response": "Updates an assignment override. Updates the existing assignment override."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef batch_create_overrides_in_course(self, course_id, assignment_overrides):\r\n        path = {}\r\n        data = {}\r\n        params = {}\r\n\r\n        # REQUIRED - PATH - course_id\r\n        \"\"\"ID\"\"\"\r\n        path[\"course_id\"] = course_id\r\n\r\n        # REQUIRED - assignment_overrides\r\n        \"\"\"Attributes for the new assignment overrides.\r\n        See {api:AssignmentOverridesController#create Create an assignment override} for available\r\n        attributes\"\"\"\r\n        data[\"assignment_overrides\"] = assignment_overrides\r\n\r\n        self.logger.debug(\"POST /api/v1/courses/{course_id}/assignments/overrides with query params: {params} and form data: {data}\".format(params=params, data=data, **path))\r\n        return self.generic_request(\"POST\", \"/api/v1/courses/{course_id}/assignments/overrides\".format(**path), data=data, params=params, all_pages=True)", "response": "Create the specified overrides for each assignment in a course. Returns the new overrides for each assignment in the course."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrandomizes an elasticsearch queryset.", "response": "def randomize_es(es_queryset):\n    \"\"\"Randomize an elasticsearch queryset.\"\"\"\n    return es_queryset.query(\n        query.FunctionScore(\n            functions=[function.RandomScore()]\n        )\n    ).sort(\"-_score\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform a list of metabolic measurements into a single object.", "response": "def transform(self, X, y=None):\n        '''\n        :param X: list of dict which contains metabolic measurements.\n        '''\n        return Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(x)\n                                            for x in X)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlearn all nearly optimal logical networks with give fitness and size tolerance.", "response": "def learn(self, fit=0, size=0, configure=None):\n        \"\"\"\n        Learns all (nearly) optimal logical networks with give fitness and size tolerance.\n        The first optimum logical network found is saved in the attribute :attr:`optimum` while\n        all enumerated logical networks are saved in the attribute :attr:`networks`.\n\n        Example::\n\n            >>> from caspo import core, learn\n\n            >>> graph = core.Graph.read_sif('pkn.sif')\n            >>> dataset = core.Dataset('dataset.csv', 30)\n            >>> zipped = graph.compress(dataset.setup)\n\n            >>> learner = learn.Learner(zipped, dataset, 2, 'round', 100)\n            >>> learner.learn(0.02, 1)\n\n            >>> learner.networks.to_csv('networks.csv')\n\n        Parameters\n        ----------\n        fit : float\n            Fitness tolerance, e.g., use 0.1 for 10% tolerance with respect to the optimum\n\n        size : int\n            Size tolerance with respect to the optimum\n\n        configure : callable\n            Callable object responsible of setting a custom clingo configuration\n        \"\"\"\n        encodings = ['guess', 'fixpoint', 'rss']\n        if self.optimum is None:\n            clingo = self.__get_clingo__(encodings + ['opt'])\n            if configure is not None:\n                configure(clingo.conf)\n\n            clingo.ground([(\"base\", [])])\n            clingo.solve(on_model=self.__keep_last__)\n\n            self.stats['time_optimum'] = clingo.stats['time_total']\n            self._logger.info(\"Optimum logical network learned in %.4fs\", self.stats['time_optimum'])\n\n            tuples = (f.args() for f in self._last)\n            self.optimum = core.LogicalNetwork.from_hypertuples(self.hypergraph, tuples)\n\n        predictions = self.optimum.predictions(self.dataset.clampings, self.dataset.readouts.columns).values\n\n        readouts = self.dataset.readouts.values\n        pos = ~np.isnan(readouts)\n\n        rss = np.sum((np.vectorize(self.discrete)(readouts[pos]) - predictions[pos]*self.factor)**2)\n\n\n        self.stats['optimum_mse'] = mean_squared_error(readouts[pos], predictions[pos])\n        self.stats['optimum_size'] = self.optimum.size\n\n        self._logger.info(\"Optimum logical networks has MSE %.4f and size %s\", self.stats['optimum_mse'], self.stats['optimum_size'])\n\n        self.networks.reset()\n\n        args = ['-c maxrss=%s' % int(rss + rss*fit), '-c maxsize=%s' % (self.optimum.size + size)]\n\n        clingo = self.__get_clingo__(encodings + ['enum'], args)\n        clingo.conf.solve.models = '0'\n        if configure is not None:\n            configure(clingo.conf)\n\n        clingo.ground([(\"base\", [])])\n        clingo.solve(on_model=self.__save__)\n\n        self.stats['time_enumeration'] = clingo.stats['time_total']\n        self._logger.info(\"%s (nearly) optimal logical networks learned in %.4fs\", len(self.networks), self.stats['time_enumeration'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates n random logical networks with given size range number of AND gates and maximum_in input signals for AND gates.", "response": "def random(self, size, n_and, max_in, n=1):\n        \"\"\"\n        Generates `n` random logical networks with given size range, number of AND gates and maximum\n        input signals for AND gates. Logical networks are saved in the attribute :attr:`networks`.\n\n        Parameters\n        ----------\n        n : int\n            Number of random logical networks to be generated\n\n        size : (int,int)\n            Minimum and maximum sizes\n\n        n_and : (int,int)\n            Minimum and maximum AND gates\n\n        max_in : int\n            Maximum input signals for AND gates\n        \"\"\"\n        args = ['-c minsize=%s' % size[0], '-c maxsize=%s' % size[1],\n                '-c minnand=%s' % n_and[0], '-c maxnand=%s' % n_and[1], '-c maxin=%s' % max_in]\n        encodings = ['guess', 'random']\n\n        self.networks.reset()\n\n        clingo = self.__get_clingo__(args, encodings)\n        clingo.conf.solve.models = str(n)\n        clingo.conf.solver.seed = str(randint(0, 32767))\n        clingo.conf.solver.sign_def = '3'\n\n        clingo.ground([(\"base\", [])])\n        clingo.solve(on_model=self.__save__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configure(self, cfg, handler, path=\"\"):\n\n        \"\"\"\n        Start configuration process for the provided handler\n\n        Args:\n            cfg (dict): config container\n            handler (config.Handler class): config handler to use\n            path (str): current path in the configuration progress\n        \"\"\"\n\n        # configure simple value attributes (str, int etc.)\n        for name, attr in handler.attributes():\n            if cfg.get(name) is not None:\n                continue\n            if attr.expected_type not in [list, dict]:\n                cfg[name] = self.set(handler, attr, name, path, cfg)\n            elif attr.default is None and not hasattr(handler, \"configure_%s\" % name):\n                self.action_required.append((\"%s.%s: %s\" % (path, name, attr.help_text)).strip(\".\"))\n\n        # configure attributes that have complex handlers defined\n        # on the config Handler class (class methods prefixed by\n        # configure_ prefix\n        for name, attr in handler.attributes():\n            if cfg.get(name) is not None:\n                continue\n            if hasattr(handler, \"configure_%s\" % name):\n                fn = getattr(handler, \"configure_%s\" % name)\n                fn(self, cfg, \"%s.%s\"% (path, name))\n                if attr.expected_type in [list, dict] and not cfg.get(name):\n                    try:\n                        del cfg[name]\n                    except KeyError:\n                        pass", "response": "Configure the configuration for the provided config container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nobtain value for a user config variable by prompting the user for input and validating the user input until the user input is valid.", "response": "def set(self, handler, attr, name, path, cfg):\n\n        \"\"\"\n        Obtain value for config variable, by prompting the user\n        for input and substituting a default value if needed.\n\n        Also does validation on user input\n        \"\"\"\n\n        full_name = (\"%s.%s\" % (path, name)).strip(\".\")\n\n        # obtain default value\n        if attr.default is None:\n            default = None\n        else:\n            try:\n                comp = vodka.component.Component(cfg)\n                default = handler.default(name, inst=comp)\n                if self.skip_defaults:\n                    self.echo(\"%s: %s [default]\" % (full_name, default))\n                    return default\n            except Exception:\n                raise\n\n        # render explanation\n        self.echo(\"\")\n        self.echo(attr.help_text)\n        if attr.choices:\n            self.echo(\"choices: %s\" % \", \".join([str(c) for c in attr.choices]))\n\n\n        # obtain user input and validate until input is valid\n        b = False\n        while not b:\n            try:\n                if type(attr.expected_type) == type:\n                    r = self.prompt(full_name, default=default, type=attr.expected_type)\n                    r = attr.expected_type(r)\n                else:\n                    r = self.prompt(full_name, default=default, type=str)\n            except ValueError:\n                self.echo(\"Value expected to be of type %s\"% attr.expected_type)\n            try:\n                b = handler.check({name:r}, name, path)\n            except Exception as inst:\n                if hasattr(inst, \"explanation\"):\n                    self.echo(inst.explanation)\n                else:\n                    raise\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting accuracy and loss from a panda s dataframe.", "response": "def _from_keras_log_format(data, **kwargs):\n    \"\"\"Plot accuracy and loss from a panda's dataframe.\n\n    Args:\n        data: Panda dataframe in the format of the Keras CSV log.\n        output_dir_path: The path to the directory where the resultings plots\n            should end up.\n    \"\"\"\n    data_val = pd.DataFrame(data[['epoch']])\n\n    data_val['acc'] = data['val_acc']\n    data_val['loss'] = data['val_loss']\n    data_val['data'] = 'validation'\n\n    data_training = pd.DataFrame(data[['acc', 'loss', 'epoch']])\n    data_training['data'] = 'training'\n\n    result = pd.concat([data_training, data_val], sort=False)\n    plot(result, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_keras_log(csv_path, output_dir_path, **kwargs):\n    # automatically get seperator by using Python's CSV parser\n    data = pd.read_csv(csv_path, sep=None, engine='python')\n    _from_keras_log_format(data, output_dir_path=output_dir_path, **kwargs)", "response": "Plot accuracy and loss from a Keras CSV log."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_config(self, key_name):\n        if key_name in self.config:\n            return self.config.get(key_name)\n        return self.Configuration.default(key_name, inst=self)", "response": "Returns the value for the specified configuration key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn Link Hypermedia Header.", "response": "def make_pagination_headers(request, limit, curpage, total, links=False):\n    \"\"\"Return Link Hypermedia Header.\"\"\"\n    lastpage = math.ceil(total / limit) - 1\n    headers = {'X-Total-Count': str(total), 'X-Limit': str(limit),\n               'X-Page-Last': str(lastpage), 'X-Page': str(curpage)}\n    if links:\n        base = \"{}?%s\".format(request.path)\n        links = {}\n        links['first'] = base % urlencode(dict(request.query, **{VAR_PAGE: 0}))\n        links['last'] = base % urlencode(dict(request.query, **{VAR_PAGE: lastpage}))\n        if curpage:\n            links['prev'] = base % urlencode(dict(request.query, **{VAR_PAGE: curpage - 1}))\n        if curpage < lastpage:\n            links['next'] = base % urlencode(dict(request.query, **{VAR_PAGE: curpage + 1}))\n        headers['Link'] = \",\".join(['<%s>; rel=\"%s\"' % (v, n) for n, v in links.items()])\n    return headers"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind to the application.", "response": "def bind(cls, app, *paths, methods=None, name=None, **kwargs):\n        \"\"\"Bind to the application.\n\n        Generate URL, name if it's not provided.\n        \"\"\"\n        paths = paths or ['/%s(/{%s})?/?' % (cls.name, cls.name)]\n        name = name or \"api.%s\" % cls.name\n        return super(RESTHandler, cls).bind(app, *paths, methods=methods, name=name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a handler result to web response.", "response": "async def make_response(self, request, response, **response_kwargs):\n        \"\"\"Convert a handler result to web response.\"\"\"\n        while iscoroutine(response):\n            response = await response\n\n        if isinstance(response, StreamResponse):\n            return response\n\n        response_kwargs.setdefault('content_type', 'application/json')\n\n        return Response(text=dumps(response), **response_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget resource or collection of resources.", "response": "async def get(self, request, resource=None, **kwargs):\n        \"\"\"Get resource or collection of resources.\n\n        ---\n        parameters:\n            - name: resource\n              in: path\n              type: string\n\n        \"\"\"\n        if resource is not None and resource != '':\n            return self.to_simple(request, resource, **kwargs)\n\n        return self.to_simple(request, self.collection, many=True, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_simple(self, request, data, many=False, **kwargs):\n        schema = self.get_schema(request, **kwargs)\n        return schema.dump(data, many=many).data if schema else data", "response": "Serialize response to simple object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads resource from given data.", "response": "async def load(self, request, resource=None, **kwargs):\n        \"\"\"Load resource from given data.\"\"\"\n        schema = self.get_schema(request, resource=resource, **kwargs)\n        data = await self.parse(request)\n        resource, errors = schema.load(\n            data, partial=resource is not None, many=isinstance(data, list))\n        if errors:\n            raise RESTBadRequest(reason='Bad request', json={'errors': errors})\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def put(self, request, resource=None, **kwargs):\n        if resource is None:\n            raise RESTNotFound(reason='Resource not found')\n\n        return await self.post(request, resource=resource, **kwargs)", "response": "Update a resource.\n+(\\ s + resource + \\ s + n"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_to_response(self, context, **response_kwargs):\n        serializer = PollPublicSerializer(self.object)\n        response = HttpResponse(\n            json.dumps(serializer.data),\n            content_type=\"application/json\"\n        )\n        if \"HTTP_ORIGIN\" in self.request.META:\n            response[\"Access-Control-Allow-Origin\"] = self.request.META[\"HTTP_ORIGIN\"]\n            response[\"Access-Control-Allow-Credentials\"] = 'true'\n\n        return response", "response": "Render the poll public data to a response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, **kwargs):\n        validated_data = [\n            dict(list(attrs.items()) + list(kwargs.items()))\n            for attrs in self.validated_data\n        ]\n\n        if \"id\" in validated_data:\n            ModelClass = self.Meta.model\n\n            try:\n                self.instance = ModelClass.objects.get(id=validated_data[\"id\"])\n            except ModelClass.DoesNotExist:\n                pass\n\n        return super(VideohubVideoSerializer, self).save(**kwargs)", "response": "Save and return a list of object instances."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_d(l):\n    _d = {}\n    for x in l:\n        for k, v in x.items():\n            _d[k] = v\n    return _d", "response": "Converts list of dicts to dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tailor(pattern_or_root, dimensions=None, distributed_dim='time',\n           read_only=False):\n    \"\"\"\n    Return a TileManager to wrap the root descriptor and tailor all the\n    dimensions to a specified window.\n\n    Keyword arguments:\n    root -- a NCObject descriptor.\n    pattern -- a filename string to open a NCObject descriptor.\n    dimensions -- a dictionary to configurate the dimensions limits.\n    \"\"\"\n    return TileManager(pattern_or_root, dimensions=dimensions,\n                       distributed_dim=distributed_dim, read_only=read_only)", "response": "Returns a TileManager to wrap the root descriptor and tailor all the dimensions to a specified window."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef command_dependants(options):\n    dependants = sorted(\n        get_dependants(options.package.project_name),\n        key=lambda n: n.lower()\n    )\n\n    if dependants:\n        print(*dependants, sep='\\n')", "response": "Command launched by CLI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding dependants of project_name.", "response": "def get_dependants(project_name):\n    \"\"\"Yield dependants of `project_name`.\"\"\"\n    for package in get_installed_distributions(user_only=ENABLE_USER_SITE):\n        if is_dependant(package, project_name):\n            yield package.project_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine whether a package is a dependant of project_name.", "response": "def is_dependant(package, project_name):\n    \"\"\"Determine whether `package` is a dependant of `project_name`.\"\"\"\n    for requirement in package.requires():\n        # perform case-insensitive matching\n        if requirement.project_name.lower() == project_name.lower():\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the global rate limit per client.", "response": "def get_global_rate_limit(self):\n        \"\"\"Get the global rate limit per client.\n\n        :rtype: int\n        :returns: The global rate limit for each client.\n        \"\"\"\n        r = urllib.request.urlopen('https://archive.org/metadata/iamine-rate-limiter')\n        j = json.loads(r.read().decode('utf-8'))\n        return int(j.get('metadata', {}).get('rate_per_second', 300))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmining metadata from Archive. org items.", "response": "def mine_items(self, identifiers, params=None, callback=None):\n        \"\"\"Mine metadata from Archive.org items.\n\n        :param identifiers: Archive.org identifiers to be mined.\n        :type identifiers: iterable\n\n        :param params: URL parameters to send with each metadata\n                       request.\n        :type params: dict\n\n        :param callback: A callback function to be called on each\n                         :py:class:`aiohttp.client.ClientResponse`.\n        :type callback: func\n        \"\"\"\n        # By default, don't cache item metadata in redis.\n        params = {'dontcache': 1} if not params else {}\n        requests = metadata_requests(identifiers, params, callback, self)\n        yield from self.mine(requests)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmines Archive. org search requests.", "response": "def search_requests(self, query=None, params=None, callback=None, mine_ids=None):\n        \"\"\"Mine Archive.org search results.\n\n        :param query: The Archive.org search query to yield results for.\n                      Refer to https://archive.org/advancedsearch.php#raw\n                      for help formatting your query.\n        :type query: str\n\n        :param params: The URL parameters to send with each request sent\n                       to the Archive.org Advancedsearch Api.\n        :type params: dict\n        \"\"\"\n        # If mining ids, devote half the workers to search and half to item mining.\n        if mine_ids:\n            self.max_tasks = self.max_tasks/2\n        # When mining id's, the only field we need returned is \"identifier\".\n        if mine_ids and params:\n            params = dict((k, v) for k, v in params.items() if 'fl' not in k)\n            params['fl[]'] = 'identifier'\n\n        # Make sure \"identifier\" is always returned in search results.\n        fields = [k for k in params if 'fl' in k]\n        if (len(fields) == 1) and (not any('identifier' == params[k] for k in params)):\n            # Make sure to not overwrite the existing fl[] key.\n            i = 0\n            while params.get('fl[{}]'.format(i)):\n                i += 1\n            params['fl[{}]'.format(i)] = 'identifier'\n\n        search_params = self.get_search_params(query, params)\n        url = make_url('/advancedsearch.php', self.protocol, self.hosts)\n\n        search_info = self.get_search_info(search_params)\n        total_results = search_info.get('response', {}).get('numFound', 0)\n        total_pages = (int(total_results/search_params['rows']) + 1)\n\n        for page in range(1, (total_pages + 1)):\n            params = deepcopy(search_params)\n            params['page'] = page\n            if not callback and mine_ids:\n                callback = self._handle_search_results\n            req = MineRequest('GET', url, self.access,\n                              callback=callback,\n                              max_retries=self.max_retries,\n                              debug=self.debug,\n                              params=params,\n                              connector=self.connector)\n            yield req"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef analyze(self, text):\n        logger.debug('Sending %r to LUIS app %s', text, self._url)\n        r = requests.get(self._url, {'q': text})\n        logger.debug('Request sent to LUIS URL: %s', r.url)\n        logger.debug(\n            'LUIS returned status %s with text: %s', r.status_code, r.text)\n        r.raise_for_status()\n        json_response = r.json()\n        result = LuisResult._from_json(json_response)\n        logger.debug('Returning %s', result)\n        return result", "response": "Sends a text to LUIS for analysis. Returns a LuisResult."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enum(**enums):\n    # Enum values must be hashable to support reverse lookup.\n    if not all(isinstance(val, collections.Hashable) for val in _values(enums)):\n        raise EnumConstructionException('All enum values must be hashable.')\n\n    # Cheating by maintaining a copy of original dict for iteration b/c iterators are hard.\n    # It must be a deepcopy because new.classobj() modifies the original.\n    en = copy.deepcopy(enums)\n    e = type('Enum', (_EnumMethods,), dict((k, v) for k, v in _items(en)))\n\n    try:\n        e.choices = [(v, k) for k, v in sorted(_items(enums), key=itemgetter(1))]  # DEPRECATED\n    except TypeError:\n        pass\n    e.get_id_by_label = e.__dict__.get\n    e.get_label_by_id = dict((v, k) for (k, v) in _items(enums)).get\n\n    return e", "response": "A basic enum implementation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeprecating use Django Field. choices", "response": "def choices(cls, value_field='canonical_name', display_field='display_name'):\n        \"\"\"\n        DEPRECATED\n\n        Returns a list of 2-tuples to be used as an argument to Django Field.choices\n\n        Implementation note: choices() can't be a property\n        See:\n            http://www.no-ack.org/2011/03/strange-behavior-with-properties-on.html\n            http://utcc.utoronto.ca/~cks/space/blog/python/UsingMetaclass03\n        \"\"\"\n        return [m.choicify(value_field=value_field, display_field=display_field) for m in cls.members()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the translations tasks from the instance and its translatable children", "response": "def create_translation_tasks(self, instance):\n        \"\"\"\n        Creates the translations tasks from the instance and its translatable children\n\n        :param instance:\n        :return:\n        \"\"\"\n\n        langs = self.get_languages()\n\n        result = []\n        # get the previous and actual values\n        # in case it's and \"add\" operation previous values will be empty\n        previous_values, actual_values = self.get_previous_and_current_values(instance)\n\n        # extract the differences\n        differences = self.extract_diferences(previous_values, actual_values)\n        self.log('\\nprev: {}\\nactu:{}\\ndiff:{}'.format(previous_values, actual_values, differences))\n        if len(differences) > 0:\n            # there are differences in the main model, so we create the tasks for it\n            result += self.create_from_item(langs, instance.master, differences, trans_instance=self.instance)\n        else:\n            # no differences so we do nothing to the main model\n            self.log('No differences we do nothing CREATE {}:{}'.format(self.master_class, instance.language_code))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_task(self, differences):\n\n        self.log('differences UPDATING: {}'.format(differences))\n\n        object_name = '{} - {}'.format(self.app_label, self.instance.master._meta.verbose_name)\n        lang = self.instance.language_code\n        object_pk = self.instance.master.pk\n\n        for field in differences:\n            value = getattr(self.instance, field)\n            if value is None or value == '':\n                continue\n            try:\n                TransTask.objects.filter(\n                    language__code=lang, object_field=field, object_name=object_name, object_pk=object_pk\n                ).update(done=True, date_modification=datetime.now(), object_field_value_translation=value)\n                self.log('MARKED TASK AS DONE')\n            except TransTask.DoesNotExist:\n                self.log('error MARKING TASK AS DONE: {} - {} - {} - {}'.format(lang, field, object_name, object_pk))", "response": "Updates a task as done if we have a new value for this alternative language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_previous_and_current_values(self, instance):\n        translated_field_names = self._get_translated_field_names(instance.master)\n        if instance.pk:\n            try:\n                previous_obj = instance._meta.model.objects.get(pk=instance.pk)\n                previous_values = self.get_obj_values(previous_obj, translated_field_names)\n            except ObjectDoesNotExist:\n                previous_values = {}\n        else:\n            previous_values = {}\n        current_values = self.get_obj_values(instance, translated_field_names)\n        return previous_values, current_values", "response": "Get the previous and actual values and compares them\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the translated field values of an object", "response": "def get_obj_values(obj, translated_field_names):\n        \"\"\"\n        get the translated field values from translatable fields of an object\n\n        :param obj:\n        :param translated_field_names:\n        :return:\n        \"\"\"\n        # set of translated fields to list\n        fields = list(translated_field_names)\n        values = {field: getattr(obj, field) for field in fields}\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_translated_field_names(model_instance):\n        hvad_internal_fields = ['id', 'language_code', 'master', 'master_id', 'master_id']\n        translated_field_names = set(model_instance._translated_field_names) - set(hvad_internal_fields)\n        return translated_field_names", "response": "Get the instance translatable fields\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_languages(self, include_main=False):\n\n        if not self.master:\n            raise Exception('TransManager - No master set')\n\n        item_languages = self.get_languages_from_item(self.ct_master, self.master)\n\n        languages = self.get_languages_from_model(self.ct_master.app_label, self.ct_master.model)\n        if not languages:\n            languages = self.get_languages_from_application(self.ct_master.app_label)\n            # if not languages:\n            #     languages = self.get_languages_default()\n\n        if not include_main:\n            main_language = self.get_main_language()\n            if main_language in languages:\n                languages.remove(main_language)\n\n        return list(set(item_languages + languages))", "response": "Get all the languages except the main."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_users_indexed_by_lang():\n        result = {}\n        users = TransUser.objects.filter(active=True).select_related('user')\n        for user in users:\n            for lang in user.languages.all():\n                if lang.code not in result:\n                    result[lang.code] = set()\n                result[lang.code].add(user)\n        return result", "response": "Return all the translator users indexed by lang"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the languages configured for the current item", "response": "def get_languages_from_item(ct_item, item):\n        \"\"\"\n        Get the languages configured for the current item\n        :param ct_item:\n        :param item:\n        :return:\n        \"\"\"\n        try:\n            item_lan = TransItemLanguage.objects.filter(content_type__pk=ct_item.id, object_id=item.id).get()\n            languages = [lang.code for lang in item_lan.languages.all()]\n            return languages\n        except TransItemLanguage.DoesNotExist:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the languages configured for the current model", "response": "def get_languages_from_model(app_label, model_label):\n        \"\"\"\n        Get the languages configured for the current model\n\n        :param model_label:\n        :param app_label:\n        :return:\n        \"\"\"\n        try:\n            mod_lan = TransModelLanguage.objects.filter(model='{} - {}'.format(app_label, model_label)).get()\n            languages = [lang.code for lang in mod_lan.languages.all()]\n            return languages\n        except TransModelLanguage.DoesNotExist:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the languages configured for the current application.", "response": "def get_languages_from_application(app_label):\n        \"\"\"\n        Get the languages configured for the current application\n\n        :param app_label:\n        :return:\n        \"\"\"\n        try:\n            mod_lan = TransApplicationLanguage.objects.filter(application=app_label).get()\n            languages = [lang.code for lang in mod_lan.languages.all()]\n            return languages\n        except TransApplicationLanguage.DoesNotExist:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the main language of the national product.", "response": "def get_main_language():\n        \"\"\"\n        returns the main language\n        :return:\n        \"\"\"\n        try:\n            main_language = TransLanguage.objects.filter(main_language=True).get()\n            return main_language.code\n        except TransLanguage.DoesNotExist:\n            return TM_DEFAULT_LANGUAGE_CODE"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log(self, msg):\n        if self.master_class and self.instance_class:\n            logger.info('{0} - {1} - {2} - {3} - lang: {4} msg: {5}'.format(\n                self.ct_master.app_label, self.ct_master.model,\n                self.instance_class, self.instance.language_code, self.instance.pk, msg)\n            )\n        elif self.instance_class:\n            logger.info('{} - {}: {}'.format(self.instance_class, self.instance.pk, msg))\n        else:\n            logger.info('{}'.format(msg))", "response": "Log a message about the master_class and instance_class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_item(self, languages, item, fields, trans_instance=None):\n        if not isinstance(item, TranslatableModel):\n            return\n\n        self.log('gonna parse fields: {}'.format(fields))\n\n        with self.lock:\n            result = []\n\n            if trans_instance:\n                # get the values from the instance that is being saved, values not saved yet\n                trans = trans_instance\n            else:\n                # get the values from the db instance\n                trans = self.get_translation_from_instance(item, self.main_language)\n\n            if not trans:\n                return\n\n            for field in fields:\n\n                self.log('parsing field: {}'.format(field))\n\n                # for every field\n                object_field_label = self.get_field_label(trans, field)\n                object_field_value = getattr(trans, field)\n                # if object_field_value is None or object_field_value == '':\n                #     object_field_value = getattr(self.instance, field, '')\n\n                self.log('object_field_value for {} - .{}.'.format(object_field_label, object_field_value))\n\n                if object_field_value == '' or object_field_value is None:\n                    continue\n\n                for lang in languages:\n                    # for every language\n                    self.log('parsing lang: {}'.format(lang))\n\n                    language = TransLanguage.objects.filter(code=lang).get()\n                    users = self.translators.get(lang, [])\n\n                    self.log('gonna parse users')\n\n                    for user in users:\n                        # for every user we create a task\n\n                        # check if there is already a value for the destinatation lang\n                        # when we are in bulk mode, when we are in signal mode\n                        # we update the destination task if it exists\n                        if self.bulk_mode and self.exists_destination_lang_value(item, field, lang):\n                            continue\n\n                        ob_class_name = item.__class__.__name__\n\n                        self.log('creating or updating object_class: {} | object_pk:{} | object_field: {}'.format(\n                            ob_class_name,\n                            item.pk,\n                            field\n                        ))\n\n                        app_label = item._meta.app_label\n                        model = ob_class_name.lower()\n                        ct = ContentType.objects.get_by_natural_key(app_label, model)\n\n                        try:\n                            task, created = TransTask.objects.get_or_create(\n                                content_type=ct,\n                                object_class=ob_class_name,\n                                object_pk=item.pk,\n                                object_field=field,\n                                language=language,\n                                user=user,\n                                defaults={\n                                    'object_name': '{} - {}'.format(app_label, item._meta.verbose_name),\n                                    'object_field_label': object_field_label,\n                                    'object_field_value': object_field_value,\n                                    'done': False\n                                }\n                            )\n                            if not created:\n                                self.log('updating')\n                                task.date_modification = datetime.now()\n                                task.object_field_value = object_field_value\n                                task.done = False\n                                task.save()\n                            result.append(task)\n                        except TransTask.MultipleObjectsReturned:\n                            # theorically it should not occur but if so delete the repeated tasks\n                            tasks = TransTask.objects.filter(\n                                content_type=ct,\n                                object_class=ob_class_name,\n                                object_pk=item.pk,\n                                object_field=field,\n                                language=language,\n                                user=user\n                            )\n                            for i, task in enumerate(tasks):\n                                if i == 0:\n                                    task.date_modification = datetime.now()\n                                    task.object_field_value = object_field_value\n                                    task.done = False\n                                    task.save()\n                                else:\n                                    task.delete()\n\n        # we return every task (created or modified)\n        return result", "response": "Create a list of tasks from a model instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field_label(self, trans, field):\n        try:\n            # get from the instance\n            object_field_label = trans._meta.get_field_by_name(field)[0].verbose_name\n        except Exception:\n            try:\n                # get from the class\n                object_field_label = self.sender._meta.get_field_by_name(field)[0].verbose_name\n            except Exception:\n                # in the worst case we set the field name as field label\n                object_field_label = field\n        return object_field_label", "response": "Get the field label from the _meta api of the model\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all the translatable children from obj.", "response": "def get_translatable_children(self, obj):\n        \"\"\"\n        Obtain all the translatable children from \"obj\"\n\n        :param obj:\n        :return:\n        \"\"\"\n        collector = NestedObjects(using='default')\n        collector.collect([obj])\n        object_list = collector.nested()\n        items = self.get_elements(object_list)\n        # avoid first object because it's the main object\n        return items[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the TransModelLanguages model with the selected languages.", "response": "def update_model_languages(self, model_class, languages):\n        \"\"\"\n        Update the TransModelLanguages model with the selected languages\n\n        :param model_class:\n        :param languages:\n        :return:\n        \"\"\"\n        # get the langs we have to add to the TransModelLanguage\n        qs = TransLanguage.objects.filter(code__in=languages)\n        new_langs = [lang for lang in qs]\n        if not new_langs:\n            return\n        mod_lan, created = TransModelLanguage.objects.get_or_create(\n            model='{} - {}'.format(model_class._meta.app_label, model_class._meta.model.__name__.lower()),\n        )\n\n        exist_langs_codes = [lang.code for lang in mod_lan.languages.all()]\n        for lang in new_langs:\n            if lang.code not in exist_langs_codes:\n                try:\n                    mod_lan.languages.add(lang)\n                except IntegrityError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_item_languages(self, item, languages):\n        # get the langs we have to add to the TransModelLanguage\n        qs = TransLanguage.objects.filter(code__in=languages)\n        new_langs = [lang for lang in qs]\n        if not new_langs:\n            return\n\n        ct_item = ContentType.objects.get_for_model(item)\n        item_lan, created = TransItemLanguage.objects.get_or_create(content_type_id=ct_item.id, object_id=item.id)\n        item_lan.languages.add(*new_langs)", "response": "Update the TransItemLanguage model with the selected languages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the selected languages from the TransItemLanguage model", "response": "def remove_item_languages(self, item, languages):\n        \"\"\"\n        delete the selected languages from the TransItemLanguage model\n\n        :param item:\n        :param languages:\n        :return:\n        \"\"\"\n        # get the langs we have to add to the TransModelLanguage\n        qs = TransLanguage.objects.filter(code__in=languages)\n        remove_langs = [lang for lang in qs]\n        if not remove_langs:\n            return\n\n        ct_item = ContentType.objects.get_for_model(item)\n        item_lan, created = TransItemLanguage.objects.get_or_create(content_type_id=ct_item.id, object_id=item.id)\n        for lang in remove_langs:\n            item_lan.languages.remove(lang)\n        if item_lan.languages.count() == 0:\n            item_lan.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_translation_from_instance(instance, lang):\n        try:\n            translation = get_translation(instance, lang)\n        except (AttributeError, ObjectDoesNotExist):\n            translation = None\n        return translation", "response": "Get the translation from the instance in a specific language"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_translations_for_item_and_its_children(self, item, languages=None):\n\n        if not self.master:\n            self.set_master(item)\n\n        if not languages:\n            languages = self.get_languages()\n\n        result_ids = []\n\n        # first process main object\n        fields = self._get_translated_field_names(item)\n        tasks = self.create_from_item(languages, item, fields)\n        if tasks:\n            result_ids += [task.pk for task in tasks]\n\n        # then process child objects from main\n        children = self.get_translatable_children(item)\n        for child in children:\n            fields = self._get_translated_field_names(child)\n            tasks = self.create_from_item(languages, child, fields)\n            if tasks:\n                result_ids += [task.pk for task in tasks]\n\n        return result_ids", "response": "Creates the translations for an item and returns the id s of the created tasks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_translations_for_item_and_its_children(self, item, languages=None):\n\n        self.log('--- Deleting translations ---')\n\n        if not self.master:\n            self.set_master(item)\n\n        object_name = '{} - {}'.format(item._meta.app_label.lower(), item._meta.verbose_name)\n        object_class = item.__class__.__name__\n        object_pk = item.pk\n\n        filter_by = {\n            'object_class': object_class,\n            'object_name': object_name,\n            'object_pk': object_pk,\n            'done': False\n        }\n        if languages:\n            filter_by.update({'language__code__in': languages})\n        TransTask.objects.filter(**filter_by).delete()\n\n        # then process child objects from main\n        children = self.get_translatable_children(item)\n        for child in children:\n            self.delete_translations_for_item_and_its_children(child, languages)", "response": "Deletes the translations task of an item and its children"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses blastn query or set up initial blast form.", "response": "def blast(request, blast_form, template_init, template_result, blast_commandline, sample_fasta_path,\n          extra_context=None):\n    \"\"\"\n    Process blastn/tblastn (blast+) query or set up initial blast form.\n    \"\"\"\n\n    if request.method == 'POST':\n\n        form = blast_form(request.POST)\n\n        if form.is_valid():\n\n            query_file_object_tmp = form.cleaned_data['sequence_in_form']\n            evalue = float(form.cleaned_data['evalue_in_form'])\n            word_size = int(form.cleaned_data['word_size_in_form'])\n            database_path = str(form.cleaned_data['blast_db_in_form'])\n\n            standard_opt_dic = {'query': query_file_object_tmp, 'evalue': evalue, 'outfmt': 5, 'db': database_path,\n                                'word_size': word_size}\n            annotated = utils.get_annotation(database_path, BLAST_DB_NUCL_LIST)\n\n            # none standard options:\n            try:\n                matrix = str(form.cleaned_data['matrix_in_form'])\n                standard_opt_dic[\"matrix\"] = matrix\n            except:\n                pass\n\n            sensitivity_opt_dic = ast.literal_eval(str(form.cleaned_data['search_sensitivity_in_form']))\n\n            blast_records__file_xml = None\n            try:\n\n                # blast search, parse results from temp file, put them into template for rendering.\n                blast_records__file_xml, blast_error = utils.run_blast_commands(blast_commandline,\n                                                                                **dict(standard_opt_dic,\n                                                                                       **sensitivity_opt_dic))\n\n                if len(blast_error) > 0:\n                    return render(request=request, template_name=template_result,\n                                  context={\"blast_record\": '', blast_error: BLAST_CORRECT_PARAMS})\n\n                else:\n\n                    # converts blast results into objects and pack into list\n                    blast_records_in_object_and_list = utils.blast_records_to_object(\n                        list(NCBIXML.parse(blast_records__file_xml)))\n\n                    # user defined function to modify blast results\n                    # e.g. join blast results with external database in template\n                    if extra_context is not None:\n                        blast_records_in_object_and_list = extra_context(blast_records_in_object_and_list)\n\n                    return render(request=request, template_name=template_result,\n                                  context={'application': blast_records_in_object_and_list[0].application,\n                                           'version': blast_records_in_object_and_list[0].version,\n                                           'blast_records': blast_records_in_object_and_list,\n                                           'annotated': annotated})\n\n            finally:\n                # remove result - temporary file\n                if blast_records__file_xml is not None:\n                    os.remove(blast_records__file_xml.name)\n\n    else:\n        form = blast_form(initial={'sequence_in_form': '', 'evalue_in_form': EVALUE_BLAST_DEFAULT})\n\n    return render(request=request, template_name=template_init,\n                  context={'form': form, 'sequence_sample_in_fasta': utils.get_sample_data(sample_fasta_path),\n                           \"blast_max_number_seq_in_input\": BLAST_MAX_NUMBER_SEQ_IN_INPUT, })"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the hive s keys.", "response": "def keys(self):\n        \"\"\"Iterates over the hive's keys.\n\n        Yields WinRegKey namedtuples containing:\n\n            path: path of the key \"RootKey\\\\Key\\\\...\"\n            timestamp: date and time of last modification\n            values: list of values ((\"ValueKey\", \"ValueType\", ValueValue), ... )\n\n        \"\"\"\n        for node in self.node_children(self.root()):\n            yield from self._visit_registry(node, self._rootkey)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing binary and unidentified values.", "response": "def _value_data(self, value):\n        \"\"\"Parses binary and unidentified values.\"\"\"\n        return codecs.decode(\n            codecs.encode(self.value_value(value)[1], 'base64'), 'utf8')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intersection(*args):\n    if not args:\n        return []\n\n    # remove duplicates from first list whilst preserving order\n    base = list(OrderedDict.fromkeys(args[0]))\n\n    if len(args) == 1:\n        return base\n    else:\n        others = set(args[1]).intersection(*args[2:])\n        return [e for e in base if e in others]", "response": "Returns the intersection of lists using the first list to determine item order\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef union(*args):\n    if not args:\n        return []\n\n    base = args[0]\n    for other in args[1:]:\n        base.extend(other)\n\n    return list(OrderedDict.fromkeys(base))", "response": "Returns the union of lists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_string(length):\n    # avoid things that could be mistaken ex: 'I' and '1'\n    letters = \"23456789ABCDEFGHJKLMNPQRSTUVWXYZ\"\n    return \"\".join([random.choice(letters) for _ in range(length)])", "response": "Generates a random alphanumeric string"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new dict that only has the given keys", "response": "def filter_dict(d, keys):\n    \"\"\"\n    Creates a new dict from an existing dict that only has the given keys\n    \"\"\"\n    return {k: v for k, v in d.items() if k in keys}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the result of a method call using the given key and TTL as a cache", "response": "def get_cacheable(cache_key, cache_ttl, calculate, recalculate=False):\n    \"\"\"\n    Gets the result of a method call, using the given key and TTL as a cache\n    \"\"\"\n    if not recalculate:\n        cached = cache.get(cache_key)\n        if cached is not None:\n            return json.loads(cached)\n\n    calculated = calculate()\n    cache.set(cache_key, json.dumps(calculated), cache_ttl)\n\n    return calculated"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_obj_cacheable(obj, attr_name, calculate, recalculate=False):\n    if not recalculate and hasattr(obj, attr_name):\n        return getattr(obj, attr_name)\n\n    calculated = calculate()\n    setattr(obj, attr_name, calculated)\n\n    return calculated", "response": "Gets the result of a method call using the given object and attribute name\n    as a cache\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a datetime to a millisecond accuracy timestamp", "response": "def datetime_to_ms(dt):\n    \"\"\"\n    Converts a datetime to a millisecond accuracy timestamp\n    \"\"\"\n    seconds = calendar.timegm(dt.utctimetuple())\n    return seconds * 1000 + int(dt.microsecond / 1000)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a millisecond accuracy timestamp to a datetime object", "response": "def ms_to_datetime(ms):\n    \"\"\"\n    Converts a millisecond accuracy timestamp to a datetime\n    \"\"\"\n    dt = datetime.datetime.utcfromtimestamp(ms / 1000)\n    return dt.replace(microsecond=(ms % 1000) * 1000).replace(tzinfo=pytz.utc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the start and end datetimes of the current month.", "response": "def get_month_range(d=None):\n    \"\"\"\n    Gets the start (inclusive) and end (exclusive) datetimes of the current\n    month in the same timezone as the given date\n    \"\"\"\n    if not d:\n        d = timezone.now()\n\n    start = d.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n    end = start + relativedelta(months=1)\n    return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chunks(iterable, size):\n    it = iter(iterable)\n    item = list(islice(it, size))\n    while item:\n        yield item\n        item = list(islice(it, size))", "response": "Splits a very large list into evenly sized chunks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing two dictionaries to see if they are equal.", "response": "def is_dict_equal(d1, d2, keys=None, ignore_none_values=True):\n    \"\"\"\n    Compares two dictionaries to see if they are equal\n    :param d1: the first dictionary\n    :param d2: the second dictionary\n    :param keys: the keys to limit the comparison to (optional)\n    :param ignore_none_values: whether to ignore none values\n    :return: true if the dictionaries are equal, else false\n    \"\"\"\n    if keys or ignore_none_values:\n        d1 = {k: v for k, v in d1.items() if (keys is None or k in keys) and (v is not None or not ignore_none_values)}\n        d2 = {k: v for k, v in d2.items() if (keys is None or k in keys) and (v is not None or not ignore_none_values)}\n\n    return d1 == d2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef command_locate(options):\n    matches = find_owners(options.file.name)\n\n    if matches:\n        print(*matches, sep='\\n')", "response": "Command launched by CLI."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the package names that file belongs to.", "response": "def find_owners(path):\n    \"\"\"Return the package(s) that file belongs to.\"\"\"\n    abspath = os.path.abspath(path)\n\n    packages = search_packages_info(\n        sorted((d.project_name for d in\n                get_installed_distributions(user_only=ENABLE_USER_SITE)),\n               key=lambda d: d.lower()))\n\n    return [p['name'] for p in packages if is_owner(p, abspath)]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine whether abspath belongs to package.", "response": "def is_owner(package, abspath):\n    \"\"\"Determine whether `abspath` belongs to `package`.\"\"\"\n    try:\n        files = package['files']\n        location = package['location']\n    except KeyError:\n        return False\n\n    paths = (os.path.abspath(os.path.join(location, f))\n             for f in files)\n\n    return abspath in paths"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_subfolder(self, foldername, returntype,\n                       params=None, file_data=None):\n        \"\"\"Return an object of the requested type with the path relative\n           to the current object's URL. Optionally, query parameters\n           may be set.\"\"\"\n        newurl = compat.urljoin(self.url, compat.quote(foldername), False)\n\n        params = params or {}\n        file_data = file_data or {}\n\n        # Add the key-value pairs sent in params to query string if they\n        # are so defined.\n        query_dict = {}\n        url_tuple = compat.urlsplit(newurl)\n        urllist = list(url_tuple)\n\n        if params:\n            # As above, pull out first element from parse_qs' values\n            query_dict = dict((k, v[0]) for k, v in \n                               cgi.parse_qs(urllist[3]).items())\n            for key, val in params.items():\n                # Lowercase bool string\n                if isinstance(val, bool):\n                    query_dict[key] = str(val).lower()\n                # Special case: convert an envelope to .bbox in the bb\n                # parameter\n                elif isinstance(val, geometry.Envelope):\n                    query_dict[key] = val.bbox\n                # Another special case: strings can't be quoted/escaped at the\n                # top level\n                elif isinstance(val, gptypes.GPString):\n                    query_dict[key] = val.value\n                # Just use the wkid of SpatialReferences\n                elif isinstance(val, geometry.SpatialReference): \n                    query_dict[key] = val.wkid\n                # If it's a list, make it a comma-separated string\n                elif isinstance(val, (list, tuple, set)):\n                    val = \",\".join([str(v.id) \n                                    if isinstance(v, Layer)\n                                    else str(v) for v in val])\n                # If it's a dictionary, dump as JSON\n                elif isinstance(val, dict):\n                    val = json.dumps(val)\n                # Ignore null values, and coerce string values (hopefully\n                # everything sent in to a query has a sane __str__)\n                elif val is not None:\n                    query_dict[key] = str(val)\n        if self.__token__ is not None:\n            query_dict['token'] = self.__token__\n        query_dict[REQUEST_REFERER_MAGIC_NAME] = self._referer or self.url\n        # Replace URL query component with newly altered component\n        urllist[3] = compat.urlencode(query_dict)\n        newurl = urllist\n        # Instantiate new RestURL or subclass\n        rt = returntype(newurl, file_data)\n        # Remind the resource where it came from\n        try:\n            rt.parent = self\n        except:\n            rt._parent = self\n        return rt", "response": "Return an object of the requested type with the path relative\n           to the current object s URL. Optionally a query parameters can be set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets this object s parent", "response": "def parent(self):\n        \"Get this object's parent\"\n        if self._parent:\n            return self._parent\n        # auto-compute parent if needed\n        elif getattr(self, '__parent_type__', None):\n            return self._get_subfolder('..' if self._url[2].endswith('/')\n                                            else '.', self.__parent_type__)\n        else:\n            raise AttributeError(\"%r has no parent attribute\" % type(self))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering subclass handlers of various service - type - specific service implementations. Look for classes decorated with . _register_service_type for hints on how this works.", "response": "def _register_service_type(cls, subclass):\n        \"\"\"Registers subclass handlers of various service-type-specific service\n           implementations. Look for classes decorated with\n           @Folder._register_service_type for hints on how this works.\"\"\"\n        if hasattr(subclass, '__service_type__'):\n            cls._service_type_mapping[subclass.__service_type__] = subclass\n            if subclass.__service_type__:\n                setattr(subclass,\n                        subclass.__service_type__,\n                        property(lambda x: x))\n        return subclass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives the list of services available in this folder.", "response": "def servicenames(self):\n        \"Give the list of services available in this folder.\"\n        return set([service['name'].rstrip('/').split('/')[-1] \n                        for service in self._json_struct.get('services', [])])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef services(self):\n        \"Returns a list of Service objects available in this folder\"\n        return [self._get_subfolder(\"%s/%s/\" % \n                (s['name'].rstrip('/').split('/')[-1], s['type']), \n                self._service_type_mapping.get(s['type'], Service)) for s\n                in self._json_struct.get('services', [])]", "response": "Returns a list of Service objects available in this folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the image data to a file or file - like object", "response": "def save(self, outfile):\n        \"\"\"Save the image data to a file or file-like object\"\"\"\n        if isinstance(outfile, compat.string_type):\n            outfile = open(outfile, 'wb')\n        outfile.write(self._contents)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef QueryLayer(self, text=None, Geometry=None, inSR=None, \n                   spatialRel='esriSpatialRelIntersects', where=None,\n                   outFields=None, returnGeometry=None, outSR=None,\n                   objectIds=None, time=None, maxAllowableOffset=None,\n                   returnIdsOnly=None):\n        \"\"\"The query operation is performed on a layer resource. The result\n           of this operation is a resultset resource. This resource provides\n           information about query results including the values for the fields\n           requested by the user. If you request geometry information, the\n           geometry of each result is also returned in the resultset.\n\n           B{Spatial Relation Options:}\n             - esriSpatialRelIntersects\n             - esriSpatialRelContains\n             - esriSpatialRelCrosses\n             - esriSpatialRelEnvelopeIntersects\n             - esriSpatialRelIndexIntersects\n             - esriSpatialRelOverlaps\n             - esriSpatialRelTouches\n             - esriSpatialRelWithin\"\"\"\n        if not inSR:\n            if Geometry:\n                inSR = Geometry.spatialReference\n        out = self._get_subfolder(\"./query\", JsonResult, {\n                                               'text': text,\n                                               'geometry': geometry,\n                                               'inSR': inSR,\n                                               'spatialRel': spatialRel,\n                                               'where': where,\n                                               'outFields': outFields,\n                                               'returnGeometry': \n                                                    returnGeometry,\n                                               'outSR': outSR,\n                                               'objectIds': objectIds,\n                                               'time': \n                                                    utils.pythonvaluetotime(\n                                                        time),\n                                               'maxAllowableOffset':\n                                                    maxAllowableOffset,\n                                               'returnIdsOnly':\n                                                    returnIdsOnly\n                                                })\n        return gptypes.GPFeatureRecordSetLayer.fromJson(out._json_struct)", "response": "This method queries the layer resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the time info for this Map Service", "response": "def timeInfo(self):\n        \"\"\"Return the time info for this Map Service\"\"\"\n        time_info = self._json_struct.get('timeInfo', {})\n        if not time_info:\n            return None\n        time_info = time_info.copy()\n        if 'timeExtent' in time_info:\n            time_info['timeExtent'] = utils.timetopythonvalue(\n                                                    time_info['timeExtent'])\n        return time_info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the image data to a file or file - like object", "response": "def save(self, outfile):\n        \"\"\"Save the image data to a file or file-like object\"\"\"\n        if isinstance(outfile, compat.string_type):\n            outfile = open(outfile, 'wb')\n        assert hasattr(outfile, 'write') and callable(outfile.write), \\\n            \"Expect a file or file-like object with a .write() method\"\n        outfile.write(self.data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict of outputs from the GPTask execution.", "response": "def results(self):\n        \"Returns a dict of outputs from the GPTask execution.\"\n        if self._results is None:\n            results = self._json_struct['results']\n            def result_iterator():\n                for result in results:\n                    datatype = None\n                    conversion = None\n                    for param in self.parent.parameters:\n                        if param['name'] == result['paramName']:\n                            datatype = param['datatype']\n                    if datatype is None:\n                        conversion = str\n                    else:\n                        conversion = datatype.fromJson\n                    dt = result['paramName']\n                    val = conversion(result['value'])\n                    yield (dt, val)\n            self._results = dict(res for res in result_iterator())\n        return self._results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Execute(self, *params, **kw):\n        fp = self.__expandparamstodict(params, kw)\n        return self._get_subfolder('execute/', GPExecutionResult, fp)", "response": "Synchronously execute the specified GP task. Parameters are passed in either in order of either as keywords. Returns a GPExecutionResult object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the image data to a file or file - like object", "response": "def save(self, outfile):\n        \"\"\"Save the image data to a file or file-like object\"\"\"\n        if isinstance(outfile, compat.string_type):\n            outfile = open(outfile, 'wb')\n        outfile.write(compat.urllib2.urlopen(self.href).read())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsolving the closest facility of a resource.", "response": "def SolveClosestFacility(self, facilities=None, \n                             incidents=None, \n                             barriers=None,\n                             polylineBarriers=None,\n                             polygonBarriers=None, \n                             attributeParameterValues=None,\n                             returnDirections=None,\n                             directionsLanguage=None,\n                             directionsStyleName=None,\n                             directionsLengthUnits=None,\n                             directionsTimeAttributeName=None,\n                             returnCFRoutes=None,\n                             returnFacilities=None,\n                             returnIncidents=None,\n                             returnBarriers=None,\n                             returnPolylineBarriers=None,\n                             returnPolygonBarriers=None,\n                             facilityReturnType=None,\n                             outputLines=None,\n                             defaultCutoff=None,\n                             defaultTargetFacilityCount=None,\n                             travelDirection=None,\n                             outSR=None,\n                             impedanceAttributeName=None,\n                             restrictionAttributeNames=None,\n                             restrictUTurns=None,\n                             useHierarchy=None,\n                             outputGeometryPrecision=None,\n                             outputGeometryPrecisionUnits=None):\n        \"\"\"The solve operation is performed on a network layer resource of type\n           closest facility.\"\"\"\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsolve a service area.", "response": "def SolveServiceArea(self, facilities=None,\n                         barriers=None,\n                         polylineBarriers=None,\n                         polygonBarriers=None,\n                         attributeParameterValues=None,\n                         defaultBreaks=None,\n                         excludeSourcesFromPolygons=None,\n                         mergeSimilarPolygonRanges=None,\n                         outputLines=None,\n                         outputPolygons=None,\n                         overlapLines=None,\n                         overlapPolygons=None,\n                         splitLinesAtBreaks=None,\n                         splitPolygonsAtBreaks=None,\n                         travelDirection=None,\n                         trimOuterPolygon=None,\n                         trimPolygonDistance=None,\n                         trimPolygonDistanceUnits=None,\n                         accumulateAttributeNames=None,\n                         impedanceAttributeName=None,\n                         restrictionAttributeNames=None,\n                         restrictUTurns=None,\n                         outputGeometryPrecision=None,\n                         outputGeometryPrecisionUnits=None):\n        \"\"\"The solve operation is performed on a network layer resource of type\n           service area (layerType is esriNAServerServiceArea).\"\"\"\n        raise NotImplementedError()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving a network layer.", "response": "def Solve(self, stops=None, barriers=None, returnDirections=None,\n              returnRoutes=None, returnStops=None, returnBarriers=None,\n              outSR=None, ignoreInvalidLocations=None, outputLines=None,\n              findBestSequence=None, preserveFirstStop=None,\n              preserveLastStop=None, useTimeWindows=None, startTime=None, \n              accumulateAttributeNames=None, impedanceAttributeName=None,\n              restrictionAttributeNames=None, restrictUTurns=None,\n              useHierarchy=None, directionsLanguage=None,\n              outputGeometryPrecision=None, directionsLengthUnits=None,\n              directionsTimeAttributeName=None, attributeParameterValues=None,\n              polylineBarriers=None, polygonBarriers=None):\n        \"\"\"The solve operation is performed on a network layer resource.\n\n           At 9.3.1, the solve operation is supported only on the route layer.\n           Or specifically, on a network layer whose layerType is\n           esriNAServerRouteLayer.\n\n           You can provide arguments to the solve route operation as query\n           parameters defined in the parameters table below.\n        \"\"\"\n        def ptlist_as_semilist(lst):\n            if isinstance(lst, geometry.Point):\n                lst = [lst]\n            if isinstance(lst, (list, tuple)):\n                return \";\".join(','.join(str(x) for x in pt) for pt in lst)\n            return lst\n        if self.layerType != \"esriNAServerRouteLayer\":\n            raise TypeError(\"Layer is of type %s; Solve is not available.\"\n                            % self.layerType)\n        return self._get_subfolder('solve/', NetworkSolveResult,\n                       {'stops': ptlist_as_semilist(stops),\n                        'barriers': ptlist_as_semilist(barriers),\n                        'returnDirections': returnDirections,\n                        'returnRoutes': returnRoutes,\n                        'returnStops': returnStops,\n                        'returnBarriers': returnBarriers,\n                        'outSR': outSR,\n                        'ignoreInvalidLocations': ignoreInvalidLocations,\n                        'outputLines': outputLines,\n                        'findBestSequence': findBestSequence,\n                        'preserveFirstStop': preserveFirstStop,\n                        'preserveLastStop': preserveLastStop,\n                        'useTimeWindows': useTimeWindows,\n                        'startTime': startTime,\n                        'accumulateAttributeNames': accumulateAttributeNames,\n                        'impedanceAttributeName': impedanceAttributeName,\n                        'restrictionAttributeNames': restrictionAttributeNames,\n                        'restrictUTurns': restrictUTurns,\n                        'useHierarchy': useHierarchy,\n                        'directionsLanguage': directionsLanguage,\n                        'outputGeometryPrecision': outputGeometryPrecision,\n                        'directionsLengthUnits': directionsLengthUnits,\n                        'directionsTimeAttributeName':\n                                                  directionsTimeAttributeName,\n                        'attributeParameterValues': attributeParameterValues,\n                        'polylineBarriers': polylineBarriers,\n                        'polygonBarriers': polygonBarriers})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef QueryRelatedRecords(self, objectIds=None, relationshipId=None,\n                            outFields=None, definitionExpression=None,\n                            returnGeometry=None, outSR=None):\n        \"\"\"The query operation is performed on a feature service layer\n           resource. The result of this operation are featuresets grouped by\n           source layer / table object IDs. Each featureset contains Feature\n           objects including the values for the fields requested by the user.\n           For related layers, if you request geometry information, the\n           geometry of each feature is also returned in the featureset. For\n           related tables, the featureset does not include geometries.\"\"\"\n\n        out = self._get_subfolder(\"./queryRelatedRecords\", JsonResult, {\n                                                        'objectIds':\n                                                            objectIds,\n                                                        'relationshipId':\n                                                            relationshipId,\n                                                        'outFields':\n                                                            outFields,\n                                                        'definitionExpression':\n                                                          definitionExpression,\n                                                        'returnGeometry':\n                                                            returnGeometry,\n                                                        'outSR': outSR\n                                                })\n        return out._json_struct", "response": "This operation returns a JSON object containing the values for each object in the objectIds and the values for each relationshipId in the objectIds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DeleteFeatures(self, objectIds=None, where=None, geometry=None,\n                       inSR=None, spatialRel=None):\n        \"\"\"This operation deletes features in a feature layer or table (POST\n           only). The delete features operation is performed on a feature\n           service layer resource. The result of this operation is an array\n           of edit results. Each edit result identifies a single feature and\n           indicates if the edit were successful or not. If not, it also\n           includes an error code and an error description.\"\"\"\n        gt = geometry.__geometry_type__\n        if sr is None:\n            sr = geometry.spatialReference.wkid\n        geo_json = json.dumps(Geometry._json_struct_without_sr)\n        return self._get_subfolder(\"./deleteFeatures\", JsonPostResult, {\n                                                    'objectIds': objectIds,\n                                                    'where': where,\n                                                    'geometry': geo_json,\n                                                    'geometryType':\n                                                            geometryType,\n                                                    'inSR': inSR,\n                                                    'spatialRel': spatialRel\n                                    })", "response": "This operation deletes features in a feature layer or table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, **kwargs):\n        try:\n            # result_ids = []\n            manager = Manager()\n            for item in self.model_class.objects.language(manager.get_main_language()).filter(pk__in=self.ids).all():\n                create_translations_for_item_and_its_children.delay(self.model_class, item.pk, self.languages,\n                                                                    update_item_languages=True)\n            # return TransTaskSerializer(TransTask.objects.filter(pk__in=result_ids), many=True).data\n            return {'status': 'ok'}\n        except Exception as e:\n            raise serializers.ValidationError(detail=str(e))", "response": "Method that creates the translations tasks for every selected instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_version():\n\tversion_py = os.path.join(os.path.dirname(__file__), 'deepgram', 'version.py')\n\twith open(version_py, 'r') as fh:\n\t\tfor line in fh:\n\t\t\tif line.startswith('__version__'):\n\t\t\t\treturn line.split('=')[-1].strip().replace('\"', '')\n\traise ValueError('Failed to parse version from: {}'.format(version_py))", "response": "Gets the current version of the package.\n\t"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef config(env=DEFAULT_ENV, default=None, **overrides):\n\n    config = {}\n\n    s = os.environ.get(env, default)\n\n    if s:\n        config = parse(s)\n\n    overrides = dict([(k.upper(), v) for k, v in overrides.items()])\n\n    config.update(overrides)\n\n    return config", "response": "Returns configured REDIS dictionary from REDIS_URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a database URL and returns a dictionary of environment variables.", "response": "def parse(url):\n    \"\"\"Parses a database URL.\"\"\"\n\n    config = {}\n\n    url = urlparse.urlparse(url)\n\n    # Remove query strings.\n    path = url.path[1:]\n    path = path.split('?', 2)[0]\n\n    # Update with environment configuration.\n    config.update({\n        \"DB\": int(path or 0),\n        \"PASSWORD\": url.password or None,\n        \"HOST\": url.hostname or \"localhost\",\n        \"PORT\": int(url.port or 6379),\n    })\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash_filesystem(filesystem, hashtype='sha1'):\n    try:\n        return dict(filesystem.checksums('/'))\n    except RuntimeError:\n        results = {}\n\n        logging.warning(\"Error hashing disk %s contents, iterating over files.\",\n                        filesystem.disk_path)\n\n        for path in filesystem.nodes('/'):\n            try:\n                regular = stat.S_ISREG(filesystem.stat(path)['mode'])\n            except RuntimeError:\n                continue  # unaccessible node\n\n            if regular:\n                try:\n                    results[path] = filesystem.checksum(path, hashtype=hashtype)\n                except RuntimeError:\n                    logging.debug(\"Unable to hash %s.\", path)\n\n        return results", "response": "Utility function for running the files iterator at once."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the file system root.", "response": "def fsroot(self):\n        \"\"\"Returns the file system root.\"\"\"\n        if self.osname == 'windows':\n            return '{}:\\\\'.format(\n                self._handler.inspect_get_drive_mappings(self._root)[0][0])\n        else:\n            return self._handler.inspect_get_mountpoints(self._root)[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmounts the given disk.", "response": "def mount(self, readonly=True):\n        \"\"\"Mounts the given disk.\n        It must be called before any other method.\n\n        \"\"\"\n        self._handler.add_drive_opts(self.disk_path, readonly=True)\n        self._handler.launch()\n\n        for mountpoint, device in self._inspect_disk():\n            if readonly:\n                self._handler.mount_ro(device, mountpoint)\n            else:\n                self._handler.mount(device, mountpoint)\n\n        if self._handler.inspect_get_type(self._root) == 'windows':\n            self.path = self._windows_path\n        else:\n            self.path = posix_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _inspect_disk(self):\n        roots = self._handler.inspect_os()\n\n        if roots:\n            self._root = roots[0]\n            return sorted(self._handler.inspect_get_mountpoints(self._root),\n                          key=lambda m: len(m[0]))\n        else:\n            raise RuntimeError(\"No OS found on the given disk image.\")", "response": "Inspects the disk and returns the mountpoints mapping\n        as a list which is the supposed one for correct mounting."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download(self, source, destination):\n        self._handler.download(posix_path(source), destination)", "response": "Downloads the file on the disk at source into destination."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over the files and directories contained within the disk starting from the given path.", "response": "def nodes(self, path):\n        \"\"\"Iterates over the files and directories contained within the disk\n        starting from the given path.\n\n        Yields the path of the nodes.\n\n        \"\"\"\n        path = posix_path(path)\n\n        yield from (self.path(path, e) for e in self._handler.find(path))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the checksum of the given path.", "response": "def checksum(self, path, hashtype='sha1'):\n        \"\"\"Returns the checksum of the given path.\"\"\"\n        return self._handler.checksum(hashtype, posix_path(path))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checksums(self, path, hashtype='sha1'):\n        with NamedTemporaryFile(buffering=0) as tempfile:\n            self._handler.checksums_out(hashtype, posix_path(path),\n                                        tempfile.name)\n\n            yield from ((self.path(f[1].lstrip('.')), f[0])\n                        for f in (l.decode('utf8').strip().split(None, 1)\n                                  for l in tempfile))", "response": "Iterates over the files hashes contained within the disk\n            starting from the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlistens to message service loop to start receiving messages.", "response": "def listen(self):\n        \"\"\"\n        Listen/Connect to message service loop to start receiving messages.\n        Do not include in constructor, in this way it can be included in tasks\n        \"\"\"\n        self.listening = True\n        try:\n            self.service_backend.listen()\n        except AuthenticationError:\n            self.listening = False\n            raise\n        else:\n            self.listening = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking all chats created with no agent assigned yet.", "response": "def attend_pendings(self):\n        \"\"\"\n        Check all chats created with no agent assigned yet.\n        Schedule a timer timeout to call it.\n        \"\"\"\n        chats_attended = []\n        pending_chats = Chat.pending.all()\n        for pending_chat in pending_chats:\n            free_agent = self.strategy.free_agent() \n            if free_agent:\n                pending_chat.attend_pending(free_agent, self)\n                pending_chat.save()\n                chats_attended.append(pending_chat)\n            else:\n                break\n        return chats_attended"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef terminate_obsolete(self):\n        chats_terminated = []\n        live_chats = Chat.live.all()\n        for live_chat in live_chats:\n            if live_chat.is_obsolete(self.time_obsolete_offset):\n                live_chat.terminate()\n                live_chat.save()\n                chats_terminated.append(live_chat)\n        return chats_terminated", "response": "Check chats can be considered as obsolete to terminate them"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_message(self, message_id_service, contact_id_service, content):\n        try:\n            live_chat = Chat.live.get(\n                Q(agent__id_service=contact_id_service) | Q(asker__id_service=contact_id_service))            \n        except ObjectDoesNotExist:\n            self._new_chat_processing(message_id_service, contact_id_service, content)\n        else:\n            live_chat.handle_message(message_id_service, contact_id_service, content, self)", "response": "Called when a message is received from the chat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef decode_path(file_path):\n    if file_path is None:\n        return\n    if isinstance(file_path, six.binary_type):\n        file_path = file_path.decode(sys.getfilesystemencoding())\n    return file_path", "response": "Turn a path name into unicode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_command(self):\n        # Do a non-blocking read here so the demo can keep running if there is no data\n        comm = self.reader.byte(blocking=False)\n        if comm is None:\n            return False\n\n        cmds = {\n            SET_KEY: self.handle_set_key,\n            DELETE_KEY: self.handle_delete_key,\n            SET_ROW: self.handle_set_row,\n            PAUSE: self.handle_pause,\n            SAVE_TRACKS: self.handle_save_tracks\n        }\n\n        func = cmds.get(comm)\n\n        if func:\n            func()\n        else:\n            logger.error(\"Unknown command: %s\", comm)\n\n        return True", "response": "Attempt to read the next command from the editor or server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_set_key(self):\n        track_id = self.reader.int()\n        row = self.reader.int()\n        value = self.reader.float()\n        kind = self.reader.byte()\n        logger.info(\" -> track=%s, row=%s, value=%s, type=%s\", track_id, row, value, kind)\n\n        # Add or update track value\n        track = self.tracks.get_by_id(track_id)\n        track.add_or_update(row, value, kind)", "response": "Read incoming key from server and update the track value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads incoming delete key event from server and delete the record", "response": "def handle_delete_key(self):\n        \"\"\"Read incoming delete key event from server\"\"\"\n        track_id = self.reader.int()\n        row = self.reader.int()\n        logger.info(\" -> track=%s, row=%s\", track_id, row)\n\n        # Delete the actual track value\n        track = self.tracks.get_by_id(track_id)\n        track.delete(row)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading incoming row change from server", "response": "def handle_set_row(self):\n        \"\"\"Read incoming row change from server\"\"\"\n        row = self.reader.int()\n        logger.info(\" -> row: %s\", row)\n        self.controller.row = row"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread pause signal from server", "response": "def handle_pause(self):\n        \"\"\"Read pause signal from server\"\"\"\n        flag = self.reader.byte()\n        if flag > 0:\n            logger.info(\" -> pause: on\")\n            self.controller.playing = False\n        else:\n            logger.info(\" -> pause: off\")\n            self.controller.playing = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the select choices for models in optgroup mode", "response": "def get_choices_for_models():\n        \"\"\"\n        Get the select choices for models in optgroup mode\n        :return:\n        \"\"\"\n        result = {}\n\n        apps = [item.model.split(' - ')[0] for item in TransModelLanguage.objects.all()]\n        qs = ContentType.objects.exclude(model__contains='translation').filter(app_label__in=apps).order_by(\n            'app_label', 'model'\n        )\n        for ct in qs:\n            if not issubclass(ct.model_class(), TranslatableModel):\n                continue\n            if ct.app_label not in result:\n                result[ct.app_label] = []\n            result[ct.app_label].append((\n                ct.id, str(ct.model_class()._meta.verbose_name_plural)\n            ))\n        choices = [(str(_('Todas las clases')), (('', _('Todas las clases')),))]\n        for key, value in result.items():\n            choices.append((key, tuple([it for it in sorted(value, key=lambda el: el[1])])))\n        return choices"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch the Wigle wifi database for matching entries.", "response": "def search(self, lat_range=None, long_range=None, variance=None,\n               bssid=None, ssid=None,\n               last_update=None,\n               address=None, state=None, zipcode=None,\n               on_new_page=None, max_results=100):\n        \"\"\"\n        Search the Wigle wifi database for matching entries. The following\n        criteria are supported:\n\n        Args:\n            lat_range ((float, float)): latitude range\n            long_range ((float, float)): longitude range\n            variance (float): radius tolerance in degrees\n            bssid (str): BSSID/MAC of AP\n            ssid (str): SSID of network\n            last_update (datetime): when was the AP last seen\n            address (str): location, address\n            state (str): location, state\n            zipcode (str): location, zip code\n            on_new_page (func(int)): callback to notify when requesting new\n                page of results\n\n        Returns:\n            [dict]: list of dicts describing matching wifis\n        \"\"\"\n\n        params = {\n            'latrange1': lat_range[0] if lat_range else \"\",\n            'latrange2': lat_range[1] if lat_range else \"\",\n            'longrange1': long_range[0] if long_range else \"\",\n            'longrange2': long_range[1] if long_range else \"\",\n            'variance': str(variance) if variance else \"0.01\",\n            'netid': bssid or \"\",\n            'ssid': ssid or \"\",\n            'lastupdt': last_update.strftime(\"%Y%m%d%H%M%S\") if last_update else \"\",\n            'addresscode': address or \"\",\n            'statecode': state or \"\",\n            'zipcode': zipcode or \"\",\n            'Query': \"Query\",\n        }\n\n        wifis = []\n        while True:\n            if on_new_page:\n                on_new_page(params.get('first', 1))\n            resp = self._authenticated_request('jsonSearch', params=params)\n            data = resp.json()\n            if not data['success']:\n                raise_wigle_error(data)\n\n            for result in data['results'][:max_results-len(wifis)]:\n                normalise_entry(result)\n                wifis.append(result)\n\n            if data['resultCount'] < WIGLE_PAGESIZE or len(wifis) >= max_results:\n                break\n\n            params['first'] = data['last'] + 1\n\n        return wifis"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, force_insert=False, force_update=False, using=None, update_fields=None):\n        super().save(force_insert, force_update, using, update_fields)\n        if self.main_language:\n            TransLanguage.objects.exclude(pk=self.pk).update(main_language=False)", "response": "Save the current language in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trigger_org_task(task_name, queue=\"celery\"):\n    active_orgs = apps.get_model(\"orgs\", \"Org\").objects.filter(is_active=True)\n    for org in active_orgs:\n        sig = signature(task_name, args=[org.pk])\n        sig.apply_async(queue=queue)\n\n    logger.info(\"Requested task '%s' for %d active orgs\" % (task_name, len(active_orgs)))", "response": "Triggers the given org task to be run for all active orgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef org_task(task_key, lock_timeout=None):\n\n    def _org_task(task_func):\n        def _decorator(org_id):\n            org = apps.get_model(\"orgs\", \"Org\").objects.get(pk=org_id)\n            maybe_run_for_org(org, task_func, task_key, lock_timeout)\n\n        return shared_task(wraps(task_func)(_decorator))\n\n    return _org_task", "response": "Decorator to create an org task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef maybe_run_for_org(org, task_func, task_key, lock_timeout):\n    r = get_redis_connection()\n\n    key = TaskState.get_lock_key(org, task_key)\n\n    if r.get(key):\n        logger.warning(\"Skipping task %s for org #%d as it is still running\" % (task_key, org.id))\n    else:\n        with r.lock(key, timeout=lock_timeout):\n            state = org.get_task_state(task_key)\n            if state.is_disabled:\n                logger.info(\"Skipping task %s for org #%d as is marked disabled\" % (task_key, org.id))\n                return\n\n            logger.info(\"Started task %s for org #%d...\" % (task_key, org.id))\n\n            prev_started_on = state.last_successfully_started_on\n            this_started_on = timezone.now()\n\n            state.started_on = this_started_on\n            state.ended_on = None\n            state.save(update_fields=(\"started_on\", \"ended_on\"))\n\n            num_task_args = len(inspect.getargspec(task_func).args)\n\n            try:\n                if num_task_args == 3:\n                    results = task_func(org, prev_started_on, this_started_on)\n                elif num_task_args == 1:\n                    results = task_func(org)\n                else:\n                    raise ValueError(\"Task signature must be foo(org) or foo(org, since, until)\")  # pragma: no cover\n\n                state.ended_on = timezone.now()\n                state.last_successfully_started_on = this_started_on\n                state.last_results = json.dumps(results)\n                state.is_failing = False\n                state.save(update_fields=(\"ended_on\", \"last_successfully_started_on\", \"last_results\", \"is_failing\"))\n\n                logger.info(\"Finished task %s for org #%d with result: %s\" % (task_key, org.id, json.dumps(results)))\n\n            except Exception as e:\n                state.ended_on = timezone.now()\n                state.last_results = None\n                state.is_failing = True\n                state.save(update_fields=(\"ended_on\", \"last_results\", \"is_failing\"))\n\n                logger.exception(\"Task %s for org #%d failed\" % (task_key, org.id))\n                raise e", "response": "Runs the given task function for the specified org if it s not already running."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_data_type(self):\n        metadata_type = self.column_metadata.get('type')\n        if self.type != metadata_type and metadata_type not in self.type:\n            raise ValueError('Types of transformer don\\'t match')", "response": "Check the type of the transformer and column match."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the transformer to convert data.", "response": "def fit(self, col):\n        \"\"\"Prepare the transformer to convert data.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            None\n        \"\"\"\n        dates = self.safe_datetime_cast(col)\n        self.default_val = dates.groupby(dates).count().index[0].timestamp() * 1e9"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare the transformer to convert data and return the processed table.", "response": "def transform(self, col):\n        \"\"\"Prepare the transformer to convert data and return the processed table.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n        out = pd.DataFrame()\n        out[self.col_name] = self.safe_datetime_cast(col)\n        out[self.col_name] = self.to_timestamp(out)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts data back into original format.", "response": "def reverse_transform(self, col):\n        \"\"\"Converts data back into original format.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n        if isinstance(col, pd.Series):\n            col = col.to_frame()\n\n        output = pd.DataFrame(index=col.index)\n        output[self.col_name] = col.apply(self.safe_date, axis=1)\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_datetime_cast(self, col):\n        casted_dates = pd.to_datetime(col[self.col_name], format=self.date_format, errors='coerce')\n\n        if len(casted_dates[casted_dates.isnull()]):\n            # This will raise an error for bad formatted data\n            # but not for out of bonds or missing dates.\n            slice_ = casted_dates.isnull() & ~col[self.col_name].isnull()\n            col[slice_][self.col_name].apply(self.strptime_format)\n\n        return casted_dates", "response": "Parses string values into datetime."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms a datetime series into linux epoch.", "response": "def to_timestamp(self, data):\n        \"\"\"Transform a datetime series into linux epoch.\n\n        Args:\n            data(pandas.DataFrame): DataFrame containins a column named as `self.col_name`.\n\n        Returns:\n            pandas.Series\n        \"\"\"\n        result = pd.Series(index=data.index)\n        _slice = ~data[self.col_name].isnull()\n\n        result[_slice] = data[_slice][self.col_name].astype('int64')\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef safe_date(self, x):\n\n        t = x[self.col_name]\n        if np.isnan(t):\n            return t\n\n        elif np.isposinf(t):\n            t = sys.maxsize\n\n        elif np.isneginf(t):\n            t = -sys.maxsize\n\n        tmp = time.localtime(float(t) / 1e9)\n        return time.strftime(self.date_format, tmp)", "response": "Transform x into a date string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef long_description():\n    # use re.compile() for flags support in Python 2.6\n    pattern = re.compile(r'\\n^\\.\\. start-badges.*^\\.\\. end-badges\\n',\n                         flags=re.M | re.S)\n    return pattern.sub('', read('README.rst'))", "response": "Return the contents of README. rst with badging removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites all messages to the stream in a thread - safe way.", "response": "def send_message(self, id_service, content):\n        \"\"\"Write all messages to the stream in a thread-safe way.\"\"\"\n        if not content:\n            return\n        with self._lock:\n            try:\n                message = \"Message: %s to %s\" % (content, id_service)\n                self.write_message(message)\n                self.stream.flush()  # flush after each message\n                return \"message_id\"\n            except Exception:\n                if not self.fail_silently:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef chop_sequence(sequence, limit_length):\n        return [sequence[i:i + limit_length] for i in range(0, len(sequence), limit_length)]", "response": "Input sequence is divided on smaller non - overlapping sequences with set length."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a string from the fields of the object.", "response": "def get_tabular_str(self):\n        \"\"\"Creates table-like string from fields. \"\"\"\n        hsp_string = \"\"\n\n        try:\n            hsp_list = [\n                {\"length\": self.align_length},\n                {\"e-value\": self.expect},\n                {\"score\": self.score},\n                {\"identities\": self.identities},\n                {\"positives\": self.positives},\n                {\"bits\": self.bits},\n                {\"query start\": self.query_start},\n                {\"query end\": self.query_end},\n                {\"subject start\": self.sbjct_start},\n                {\"subject end\": self.sbjct_end},\n            ]\n\n            for h in hsp_list:\n                for k, v in h.items():\n                    hsp_string += \"{}\\t{}\\n\".format(k, v)\n        except:\n            pass\n\n        return hsp_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of identities of the best HSP in alignment.", "response": "def best_identities(self):\n        \"\"\"Returns identities of the best HSP in alignment.  \"\"\"\n        if len(self.hsp_list) > 0:\n            return round(float(self.hsp_list[0].identities) / float(self.hsp_list[0].align_length) * 100, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_id(self):\n        return hash(str(self.title) + str(self.best_score()) + str(self.hit_def))", "response": "Returns unique id of an alignment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_template(template, **context):\n    parts = template.split('/')\n    renderer = _get_renderer(parts[:-1])\n    return renderer.render(renderer.load_template(parts[-1:][0]), context)", "response": "Renders a given template and context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(pattern, read_only=False):\n    root = NCObject.open(pattern, read_only=read_only)\n    return root, root.is_new", "response": "Returns a root descriptor to work with one or multiple NetCDF files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a variable from a NCFile or NCPackage instance.", "response": "def getvar(root, name, vtype='', dimensions=(), digits=0, fill_value=None,\n           source=None):\n    \"\"\"\n    Return a variable from a NCFile or NCPackage instance. If the variable\n    doesn't exists create it.\n\n    Keyword arguments:\n    root -- the root descriptor returned by the 'open' function\n    name -- the name of the variable\n    vtype -- the type of each value, ex ['f4', 'i4', 'i1', 'S1'] (default '')\n    dimensions -- the tuple with dimensions name of the variables (default ())\n    digits -- the precision required when using a 'f4' vtype (default 0)\n    fill_value -- the initial value used in the creation time (default None)\n    source -- the source variable to be copied (default None)\n    \"\"\"\n    return root.getvar(name, vtype, dimensions, digits, fill_value, source)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loader(pattern, dimensions=None, distributed_dim='time', read_only=False):\n    if dimensions:\n        root = tailor(pattern, dimensions, distributed_dim, read_only=read_only)\n    else:\n        root, _ = open(pattern, read_only=read_only)\n    yield root\n    root.close()", "response": "A context manager that opens and closes a root descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies dict args to avoid modifying caller s copy", "response": "def dict_copy(func):\n    \"copy dict args, to avoid modifying caller's copy\"\n    def proxy(*args, **kwargs):\n        new_args = []\n        new_kwargs = {}\n        for var in kwargs:\n            if isinstance(kwargs[var], dict):\n                new_kwargs[var] = dict(kwargs[var])\n            else:\n                new_kwargs[var] = kwargs[var]\n        for arg in args:\n            if isinstance(arg, dict):\n                new_args.append(dict(arg))\n            else:\n                new_args.append(arg)\n        return func(*new_args, **new_kwargs)\n    return proxy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_listish(obj):\n    if isinstance(obj, (list, tuple, set)):\n        return True\n    return is_sequence(obj)", "response": "Check if something quacks like a list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a list unique retaining order of initial appearance.", "response": "def unique_list(lst):\n    \"\"\"Make a list unique, retaining order of initial appearance.\"\"\"\n    uniq = []\n    for item in lst:\n        if item not in uniq:\n            uniq.append(item)\n    return uniq"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the main language of the national accesse.", "response": "def _get_main_language():\n        \"\"\"\n        returns the main language\n        :return:\n        \"\"\"\n        try:\n            main_language = TransLanguage.objects.filter(main_language=True).get()\n            return main_language.code\n        except TransLanguage.DoesNotExist:\n            return 'es'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fields_need_translation(self, elem, destination_lang):\n\n        fields = self._get_translated_field_names(elem)\n        elem_langs = elem.get_available_languages()\n        # if we don't have a translation for the destination lang we have to include the tuple\n        if destination_lang not in elem_langs:\n            return fields\n\n        # we have the translation, we decide which fields we need to translate. we have to get the translation first\n        translation = get_translation(elem, destination_lang)\n        result = []\n        for field in fields:\n            value = getattr(translation, field, '')\n            if not value or value.strip() == '':\n                result.append(field)\n\n        return result", "response": "Detects if the tuple needs translation and which fields need to be translated and which fields need to be translated"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the given MLdataset instances are compatible with the training set.", "response": "def check_compatibility(datasets, reqd_num_features=None):\n    \"\"\"\n    Checks whether the given MLdataset instances are compatible\n\n    i.e. with same set of subjects, each beloning to the same class in all instances.\n\n    Checks the first dataset in the list against the rest, and returns a boolean array.\n\n    Parameters\n    ----------\n    datasets : Iterable\n        A list of n datasets\n\n    reqd_num_features : int\n        The required number of features in each dataset.\n        Helpful to ensure test sets are compatible with training set,\n            as well as within themselves.\n\n    Returns\n    -------\n    all_are_compatible : bool\n        Boolean flag indicating whether all datasets are compatible or not\n\n    compatibility : list\n        List indicating whether first dataset is compatible with the rest individually.\n        This could be useful to select a subset of mutually compatible datasets.\n        Length : n-1\n\n    dim_mismatch : bool\n        Boolean flag indicating mismatch in dimensionality from that specified\n\n    size_descriptor : tuple\n        A tuple with values for (num_samples, reqd_num_features)\n        - num_samples must be common for all datasets that are evaluated for compatibility\n        - reqd_num_features is None (when no check on dimensionality is perfomed), or\n            list of corresponding dimensionalities for each input dataset\n\n    \"\"\"\n\n    from collections import Iterable\n    if not isinstance(datasets, Iterable):\n        raise TypeError('Input must be an iterable '\n                        'i.e. (list/tuple) of MLdataset/similar instances')\n\n    datasets = list(datasets)  # to make it indexable if coming from a set\n    num_datasets = len(datasets)\n\n    check_dimensionality = False\n    dim_mismatch = False\n    if reqd_num_features is not None:\n        if isinstance(reqd_num_features, Iterable):\n            if len(reqd_num_features) != num_datasets:\n                raise ValueError('Specify dimensionality for exactly {} datasets.'\n                                 ' Given for a different number {}'\n                                 ''.format(num_datasets, len(reqd_num_features)))\n            reqd_num_features = list(map(int, reqd_num_features))\n        else:  # same dimensionality for all\n            reqd_num_features = [int(reqd_num_features)] * num_datasets\n\n        check_dimensionality = True\n    else:\n        # to enable iteration\n        reqd_num_features = [None,] * num_datasets\n\n    pivot = datasets[0]\n    if not isinstance(pivot, MLDataset):\n        pivot = MLDataset(pivot)\n\n    if check_dimensionality and pivot.num_features != reqd_num_features[0]:\n        warnings.warn('Dimensionality mismatch! Expected {} whereas current {}.'\n                      ''.format(reqd_num_features[0], pivot.num_features))\n        dim_mismatch = True\n\n    compatible = list()\n    for ds, reqd_dim in zip(datasets[1:], reqd_num_features[1:]):\n        if not isinstance(ds, MLDataset):\n            ds = MLDataset(ds)\n\n        is_compatible = True\n        # compound bool will short-circuit, not optim required\n        if pivot.num_samples != ds.num_samples \\\n                or pivot.keys != ds.keys \\\n                or pivot.classes != ds.classes:\n            is_compatible = False\n\n        if check_dimensionality and reqd_dim != ds.num_features:\n            warnings.warn('Dimensionality mismatch! Expected {} whereas current {}.'\n                          ''.format(reqd_dim, ds.num_features))\n            dim_mismatch = True\n\n        compatible.append(is_compatible)\n\n    return all(compatible), compatible, dim_mismatch, \\\n           (pivot.num_samples, reqd_num_features)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncommand line interface This interface saves you coding effort to: - display basic info (classes, sizes etc) about datasets - display meta data (class membership) for samples - perform basic arithmetic (add multiple classes or feature sets)", "response": "def cli_run():\n    \"\"\"\n    Command line interface\n\n    This interface saves you coding effort to:\n\n        - display basic info (classes, sizes etc) about datasets\n        - display meta data (class membership) for samples\n        - perform basic arithmetic (add multiple classes or feature sets)\n\n\n    \"\"\"\n\n    path_list, meta_requested, summary_requested, add_path_list, out_path = parse_args()\n\n    # printing info if requested\n    if path_list:\n        for ds_path in path_list:\n            ds = MLDataset(ds_path)\n            if summary_requested:\n                print_info(ds, ds_path)\n            if meta_requested:\n                print_meta(ds, ds_path)\n\n    # combining datasets\n    if add_path_list:\n        combine_and_save(add_path_list, out_path)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint basic summary of a given dataset.", "response": "def print_info(ds, ds_path=None):\n    \"Prints basic summary of a given dataset.\"\n\n    if ds_path is None:\n        bname = ''\n    else:\n        bname = basename(ds_path)\n\n    dashes = '-' * len(bname)\n    print('\\n{}\\n{}\\n{:full}'.format(dashes, bname, ds))\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_meta(ds, ds_path=None):\n    \"Prints meta data for subjects in given dataset.\"\n\n    print('\\n#' + ds_path)\n    for sub, cls in ds.classes.items():\n        print('{},{}'.format(sub, cls))\n\n    return", "response": "Prints meta data for subjects in given dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines the datasets that can be combined and save the bigger dataset to a given location.", "response": "def combine_and_save(add_path_list, out_path):\n    \"\"\"\n    Combines whatever datasets that can be combined,\n    and save the bigger dataset to a given location.\n    \"\"\"\n\n    add_path_list = list(add_path_list)\n    # first one!\n    first_ds_path = add_path_list[0]\n    print('Starting with {}'.format(first_ds_path))\n    combined = MLDataset(first_ds_path)\n    for ds_path in add_path_list[1:]:\n        try:\n            combined = combined + MLDataset(ds_path)\n        except:\n            print('      Failed to add {}'.format(ds_path))\n            traceback.print_exc()\n        else:\n            print('Successfully added {}'.format(ds_path))\n\n    combined.save(out_path)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_args():\n\n    parser = get_parser()\n\n    if len(sys.argv) < 2:\n        parser.print_help()\n        logging.warning('Too few arguments!')\n        parser.exit(1)\n\n    # parsing\n    try:\n        params = parser.parse_args()\n    except Exception as exc:\n        print(exc)\n        raise ValueError('Unable to parse command-line arguments.')\n\n    path_list = list()\n    if params.path_list is not None:\n        for dpath in params.path_list:\n            if pexists(dpath):\n                path_list.append(realpath(dpath))\n            else:\n                print('Below dataset does not exist. Ignoring it.\\n{}'.format(dpath))\n\n    add_path_list = list()\n    out_path = None\n    if params.add_path_list is not None:\n        for dpath in params.add_path_list:\n            if pexists(dpath):\n                add_path_list.append(realpath(dpath))\n            else:\n                print('Below dataset does not exist. Ignoring it.\\n{}'.format(dpath))\n\n        if params.out_path is None:\n            raise ValueError(\n                'Output path must be specified to save the combined dataset to')\n\n        out_path = realpath(params.out_path)\n        parent_dir = dirname(out_path)\n        if not pexists(parent_dir):\n            os.mkdir(parent_dir)\n\n        if len(add_path_list) < 2:\n            raise ValueError('Need a minimum of datasets to combine!!')\n\n    # removing duplicates (from regex etc)\n    path_list = set(path_list)\n    add_path_list = set(add_path_list)\n\n    return path_list, params.meta_requested, params.summary_requested, \\\n           add_path_list, out_path", "response": "Arg parser. parse_args returns a tuple of path_list meta_requested summary_requested and out_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the data matrix and labels for the current node.", "response": "def data_and_labels(self):\n        \"\"\"\n        Dataset features and labels in a matrix form for learning.\n\n        Also returns sample_ids in the same order.\n\n        Returns\n        -------\n        data_matrix : ndarray\n            2D array of shape [num_samples, num_features]\n            with features corresponding row-wise to sample_ids\n        labels : ndarray\n            Array of numeric labels for each sample corresponding row-wise to sample_ids\n        sample_ids : list\n            List of sample ids\n\n        \"\"\"\n\n        sample_ids = np.array(self.keys)\n        label_dict = self.labels\n        matrix = np.full([self.num_samples, self.num_features], np.nan)\n        labels = np.full([self.num_samples, 1], np.nan)\n        for ix, sample in enumerate(sample_ids):\n            matrix[ix, :] = self.__data[sample]\n            labels[ix] = label_dict[sample]\n\n        return matrix, np.ravel(labels), sample_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self, values, feature_names=None):\n        if isinstance(values, dict):\n            if self.__labels is not None and len(self.__labels) != len(values):\n                raise ValueError(\n                    'number of samples do not match the previously assigned labels')\n            elif len(values) < 1:\n                raise ValueError('There must be at least 1 sample in the dataset!')\n            else:\n                self.__data = values\n                # update dimensionality\n                # assuming all keys in dict have same len arrays\n                self.__num_features = len(values[self.keys[0]])\n\n            if feature_names is None:\n                self.__feature_names = self.__str_names(self.num_features)\n            else:\n                self.feature_names = feature_names\n        else:\n            raise ValueError('data input must be a dictionary!')", "response": "Populates this dataset with the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the class labels for each sample in the dataset.", "response": "def labels(self, values):\n        \"\"\"Class labels (such as 1, 2, -1, 'A', 'B' etc.) for each sample in the dataset.\"\"\"\n        if isinstance(values, dict):\n            if self.__data is not None and len(self.__data) != len(values):\n                raise ValueError(\n                    'number of samples do not match the previously assigned data')\n            elif set(self.keys) != set(list(values)):\n                raise ValueError('sample ids do not match the previously assigned ids.')\n            else:\n                self.__labels = values\n        else:\n            raise ValueError('labels input must be a dictionary!')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the classes of the current object.", "response": "def classes(self, values):\n        \"\"\"Classes setter.\"\"\"\n        if isinstance(values, dict):\n            if self.__data is not None and len(self.__data) != len(values):\n                raise ValueError(\n                    'number of samples do not match the previously assigned data')\n            elif set(self.keys) != set(list(values)):\n                raise ValueError('sample ids do not match the previously assigned ids.')\n            else:\n                self.__classes = values\n        else:\n            raise ValueError('classes input must be a dictionary!')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the text labels for features", "response": "def feature_names(self, names):\n        \"Stores the text labels for features\"\n\n        if len(names) != self.num_features:\n            raise ValueError(\"Number of names do not match the number of features!\")\n        if not isinstance(names, (Sequence, np.ndarray, np.generic)):\n            raise ValueError(\"Input is not a sequence. \"\n                             \"Ensure names are in the same order \"\n                             \"and length as features.\")\n\n        self.__feature_names = np.array(names)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef glance(self, nitems=5):\n        nitems = max([1, min([nitems, self.num_samples - 1])])\n        return self.__take(nitems, iter(self.__data.items()))", "response": "Quick and partial glance of the data matrix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef summarize_classes(self):\n\n        class_sizes = np.zeros(len(self.class_set))\n        for idx, cls in enumerate(self.class_set):\n            class_sizes[idx] = self.class_sizes[cls]\n\n        # TODO consider returning numeric label set e.g. for use in scikit-learn\n        return self.class_set, self.label_set, class_sizes", "response": "Summary of classes and labels of all the classes in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_features(self, features):\n\n        if not isinstance(features, np.ndarray):\n            features = np.asarray(features)\n\n        if features.size <= 0:\n            raise ValueError('provided features are empty.')\n\n        if features.ndim > 1:\n            features = np.ravel(features)\n\n        return features", "response": "Method to ensure data to be added is not empty and vectorized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_sample(self, sample_id, features, label,\n                   class_id=None,\n                   overwrite=False,\n                   feature_names=None):\n        \"\"\"Adds a new sample to the dataset with its features, label and class ID.\n\n        This is the preferred way to construct the dataset.\n\n        Parameters\n        ----------\n\n        sample_id : str, int\n            The identifier that uniquely identifies this sample.\n        features : list, ndarray\n            The features for this sample\n        label : int, str\n            The label for this sample\n        class_id : int, str\n            The class for this sample.\n            If not provided, label converted to a string becomes its ID.\n        overwrite : bool\n            If True, allows the overwite of features for an existing subject ID.\n            Default : False.\n        feature_names : list\n            The names for each feature. Assumed to be in the same order as `features`\n\n        Raises\n        ------\n        ValueError\n            If `sample_id` is already in the MLDataset (and overwrite=False), or\n            If dimensionality of the current sample does not match the current, or\n            If `feature_names` do not match existing names\n        TypeError\n            If sample to be added is of different data type compared to existing samples.\n\n        \"\"\"\n\n        if sample_id in self.__data and not overwrite:\n            raise ValueError('{} already exists in this dataset!'.format(sample_id))\n\n        # ensuring there is always a class name, even when not provided by the user.\n        # this is needed, in order for __str__ method to work.\n        # TODO consider enforcing label to be numeric and class_id to be string\n        #  so portability with other packages is more uniform e.g. for use in scikit-learn\n        if class_id is None:\n            class_id = str(label)\n\n        features = self.check_features(features)\n        if self.num_samples <= 0:\n            self.__data[sample_id] = features\n            self.__labels[sample_id] = label\n            self.__classes[sample_id] = class_id\n            self.__dtype = type(features)\n            self.__num_features = features.size if isinstance(features,\n                                                              np.ndarray) else len(\n                features)\n            if feature_names is None:\n                self.__feature_names = self.__str_names(self.num_features)\n        else:\n            if self.__num_features != features.size:\n                raise ValueError('dimensionality of this sample ({}) '\n                                 'does not match existing samples ({})'\n                                 ''.format(features.size, self.__num_features))\n            if not isinstance(features, self.__dtype):\n                raise TypeError(\"Mismatched dtype. Provide {}\".format(self.__dtype))\n\n            self.__data[sample_id] = features\n            self.__labels[sample_id] = label\n            self.__classes[sample_id] = class_id\n            if feature_names is not None:\n                # if it was never set, allow it\n                # class gets here when adding the first sample,\n                #   after dataset was initialized with empty constructor\n                if self.__feature_names is None:\n                    self.__feature_names = np.array(feature_names)\n                else:  # if set already, ensure a match\n                    if not np.array_equal(self.feature_names, np.array(feature_names)):\n                        raise ValueError(\n                            \"supplied feature names do not match the existing names!\")", "response": "Adds a new sample to the dataset with its features label and class ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef del_sample(self, sample_id):\n        if sample_id not in self.__data:\n            warnings.warn('Sample to delete not found in the dataset - nothing to do.')\n        else:\n            self.__data.pop(sample_id)\n            self.__classes.pop(sample_id)\n            self.__labels.pop(sample_id)\n            print('{} removed.'.format(sample_id))", "response": "Removes a sample from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the subset of features indexed numerically.", "response": "def get_feature_subset(self, subset_idx):\n        \"\"\"\n        Returns the subset of features indexed numerically.\n\n        Parameters\n        ----------\n        subset_idx : list, ndarray\n            List of indices to features to be returned\n\n        Returns\n        -------\n        MLDataset : MLDataset\n            with subset of features requested.\n\n        Raises\n        ------\n        UnboundLocalError\n            If input indices are out of bounds for the dataset.\n\n        \"\"\"\n\n        subset_idx = np.asarray(subset_idx)\n        if not (max(subset_idx) < self.__num_features) and (min(subset_idx) >= 0):\n            raise UnboundLocalError('indices out of range for the dataset. '\n                                    'Max index: {} Min index : 0'.format(\n                self.__num_features))\n\n        sub_data = {sample: features[subset_idx] for sample, features in\n                    self.__data.items()}\n        new_descr = 'Subset features derived from: \\n ' + self.__description\n        subdataset = MLDataset(data=sub_data,\n                               labels=self.__labels, classes=self.__classes,\n                               description=new_descr,\n                               feature_names=self.__feature_names[subset_idx])\n\n        return subdataset"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keys_with_value(dictionary, value):\n        \"Returns a subset of keys from the dict with the value supplied.\"\n\n        subset = [key for key in dictionary if dictionary[key] == value]\n\n        return subset", "response": "Returns a subset of keys from the dict with the value supplied."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a smaller dataset with the specified class.", "response": "def get_class(self, class_id):\n        \"\"\"\n        Returns a smaller dataset belonging to the requested classes.\n\n        Parameters\n        ----------\n        class_id : str or list\n            identifier(s) of the class(es) to be returned.\n\n        Returns\n        -------\n        MLDataset\n            With subset of samples belonging to the given class(es).\n\n        Raises\n        ------\n        ValueError\n            If one or more of the requested classes do not exist in this dataset.\n            If the specified id is empty or None\n\n        \"\"\"\n        if class_id in [None, '']:\n            raise ValueError(\"class id can not be empty or None.\")\n\n        if isinstance(class_id, str):\n            class_ids = [class_id, ]\n        else:\n            class_ids = class_id\n\n        non_existent = set(self.class_set).intersection(set(class_ids))\n        if len(non_existent) < 1:\n            raise ValueError(\n                'These classes {} do not exist in this dataset.'.format(non_existent))\n\n        subsets = list()\n        for class_id in class_ids:\n            subsets_this_class = self.keys_with_value(self.__classes, class_id)\n            subsets.extend(subsets_this_class)\n\n        return self.get_subset(subsets)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies a given function to the features of each subject and returns a new dataset with other info unchanged.", "response": "def transform(self, func, func_description=None):\n        \"\"\"\n        Applies a given a function to the features of each subject\n            and returns a new dataset with other info unchanged.\n\n        Parameters\n        ----------\n        func : callable\n            A valid callable that takes in a single ndarray and returns a single ndarray.\n            Ensure the transformed dimensionality must be the same for all subjects.\n\n            If your function requires more than one argument,\n            use `functools.partial` to freeze all the arguments\n            except the features for the subject.\n\n        func_description : str, optional\n            Human readable description of the given function.\n\n        Returns\n        -------\n        xfm_ds : MLDataset\n            with features obtained from subject-wise transform\n\n        Raises\n        ------\n        TypeError\n            If given func is not a callable\n        ValueError\n            If transformation of any of the subjects features raises an exception.\n\n        Examples\n        --------\n        Simple:\n\n        .. code-block:: python\n\n            from pyradigm import MLDataset\n\n            thickness = MLDataset(in_path='ADNI_thickness.csv')\n            pcg_thickness = thickness.apply_xfm(func=get_pcg, description = 'applying ROI mask for PCG')\n            pcg_median = pcg_thickness.apply_xfm(func=np.median, description='median per subject')\n\n\n        Complex example with function taking more than one argument:\n\n        .. code-block:: python\n\n            from pyradigm import MLDataset\n            from functools import partial\n            import hiwenet\n\n            thickness = MLDataset(in_path='ADNI_thickness.csv')\n            roi_membership = read_roi_membership()\n            hw = partial(hiwenet, groups = roi_membership)\n\n            thickness_hiwenet = thickness.transform(func=hw, description = 'histogram weighted networks')\n            median_thk_hiwenet = thickness_hiwenet.transform(func=np.median, description='median per subject')\n\n        \"\"\"\n\n        if not callable(func):\n            raise TypeError('Given function {} is not a callable'.format(func))\n\n        xfm_ds = MLDataset()\n        for sample, data in self.__data.items():\n            try:\n                xfm_data = func(data)\n            except:\n                print('Unable to transform features for {}. Quitting.'.format(sample))\n                raise\n\n            xfm_ds.add_sample(sample, xfm_data,\n                              label=self.__labels[sample],\n                              class_id=self.__classes[sample])\n\n        xfm_ds.description = \"{}\\n{}\".format(func_description, self.__description)\n\n        return xfm_ds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_subset_ids_by_count(self, count_per_class=1):\n\n        class_sizes = self.class_sizes\n        subsets = list()\n\n        if count_per_class < 1:\n            warnings.warn('Atleast one sample must be selected from each class')\n            return list()\n        elif count_per_class >= self.num_samples:\n            warnings.warn('All samples requested - returning a copy!')\n            return self.keys\n\n        # seeding the random number generator\n        # random.seed(random_seed)\n\n        for class_id, class_size in class_sizes.items():\n            # samples belonging to the class\n            this_class = self.keys_with_value(self.classes, class_id)\n            # shuffling the sample order; shuffling works in-place!\n            random.shuffle(this_class)\n\n            # clipping the range to [0, class_size]\n            subset_size_this_class = max(0, min(class_size, count_per_class))\n            if subset_size_this_class < 1 or this_class is None:\n                # warning if none were selected\n                warnings.warn('No subjects from class {} were selected.'.format(class_id))\n            else:\n                subsets_this_class = this_class[0:count_per_class]\n                subsets.extend(subsets_this_class)\n\n        if len(subsets) > 0:\n            return subsets\n        else:\n            warnings.warn('Zero samples were selected. Returning an empty list!')\n            return list()", "response": "Returns a random subset of sample ids of specified size by count."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a random subset of sample ids within each class.", "response": "def random_subset_ids(self, perc_per_class=0.5):\n        \"\"\"\n        Returns a random subset of sample ids (size in percentage) within each class.\n\n        Parameters\n        ----------\n        perc_per_class : float\n            Fraction of samples per class\n\n        Returns\n        -------\n        subset : list\n            Combined list of sample ids from all classes.\n\n        Raises\n        ------\n        ValueError\n            If no subjects from one or more classes were selected.\n        UserWarning\n            If an empty or full dataset is requested.\n\n        \"\"\"\n\n        class_sizes = self.class_sizes\n        subsets = list()\n\n        if perc_per_class <= 0.0:\n            warnings.warn('Zero percentage requested - returning an empty dataset!')\n            return list()\n        elif perc_per_class >= 1.0:\n            warnings.warn('Full or a larger dataset requested - returning a copy!')\n            return self.keys\n\n        # seeding the random number generator\n        # random.seed(random_seed)\n\n        for class_id, class_size in class_sizes.items():\n            # samples belonging to the class\n            this_class = self.keys_with_value(self.classes, class_id)\n            # shuffling the sample order; shuffling works in-place!\n            random.shuffle(this_class)\n            # calculating the requested number of samples\n            subset_size_this_class = np.int64(np.floor(class_size * perc_per_class))\n            # clipping the range to [1, n]\n            subset_size_this_class = max(1, min(class_size, subset_size_this_class))\n            if subset_size_this_class < 1 or len(this_class) < 1 or this_class is None:\n                # warning if none were selected\n                raise ValueError(\n                    'No subjects from class {} were selected.'.format(class_id))\n            else:\n                subsets_this_class = this_class[0:subset_size_this_class]\n                subsets.extend(subsets_this_class)\n\n        if len(subsets) > 0:\n            return subsets\n        else:\n            warnings.warn('Zero samples were selected. Returning an empty list!')\n            return list()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef random_subset(self, perc_in_class=0.5):\n\n        subsets = self.random_subset_ids(perc_in_class)\n        if len(subsets) > 0:\n            return self.get_subset(subsets)\n        else:\n            warnings.warn('Zero samples were selected. Returning an empty dataset!')\n            return MLDataset()", "response": "Returns a random subset of the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample_ids_in_class(self, class_id):\n\n        # subset_ids = [sid for sid in self.keys if self.classes[sid] == class_id]\n        subset_ids = self.keys_with_value(self.classes, class_id)\n        return subset_ids", "response": "Returns a list of sample ids belonging to a given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subset(self, subset_ids):\n\n        num_existing_keys = sum([1 for key in subset_ids if key in self.__data])\n        if subset_ids is not None and num_existing_keys > 0:\n            # ensure items are added to data, labels etc in the same order of sample IDs\n            # TODO come up with a way to do this even when not using OrderedDict()\n            # putting the access of data, labels and classes in the same loop  would\n            # ensure there is correspondence across the three attributes of the class\n            data = self.__get_subset_from_dict(self.__data, subset_ids)\n            labels = self.__get_subset_from_dict(self.__labels, subset_ids)\n            if self.__classes is not None:\n                classes = self.__get_subset_from_dict(self.__classes, subset_ids)\n            else:\n                classes = None\n            subdataset = MLDataset(data=data, labels=labels, classes=classes)\n            # Appending the history\n            subdataset.description += '\\n Subset derived from: ' + self.description\n            subdataset.feature_names = self.__feature_names\n            subdataset.__dtype = self.dtype\n            return subdataset\n        else:\n            warnings.warn('subset of IDs requested do not exist in the dataset!')\n            return MLDataset()", "response": "Returns a smaller dataset identified by their keys and sample IDs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data_matrix_in_order(self, subset_ids):\n\n        if len(subset_ids) < 1:\n            warnings.warn('subset must have atleast one ID - returning empty matrix!')\n            return np.empty((0, 0))\n\n        if isinstance(subset_ids, set):\n            raise TypeError('Input set is not ordered, hence can not guarantee order! '\n                            'Must provide a list or tuple.')\n\n        if isinstance(subset_ids, str):\n            subset_ids = [subset_ids, ]\n\n        num_existing_keys = sum([1 for key in subset_ids if key in self.__data])\n        if num_existing_keys < len(subset_ids):\n            raise ValueError('One or more IDs from  subset do not exist in the dataset!')\n\n        matrix = np.full((num_existing_keys, self.num_features), np.nan)\n        for idx, sid in enumerate(subset_ids):\n            matrix[idx, :] = self.__data[sid]\n\n        return matrix", "response": "Returns a numpy array of features rows in the same order as subset_ids."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of labels in the dataset corresponding to class_set.", "response": "def label_set(self):\n        \"\"\"Set of labels in the dataset corresponding to class_set.\"\"\"\n        label_set = list()\n        for class_ in self.class_set:\n            samples_in_class = self.sample_ids_in_class(class_)\n            label_set.append(self.labels[samples_in_class[0]])\n\n        return label_set"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the classes to the internal class table.", "response": "def add_classes(self, classes):\n        \"\"\"\n        Helper to rename the classes, if provided by a dict keyed in by the orignal keys\n\n        Parameters\n        ----------\n        classes : dict\n            Dict of class named keyed in by sample IDs.\n\n        Raises\n        ------\n        TypeError\n            If classes is not a dict.\n        ValueError\n            If all samples in dataset are not present in input dict,\n            or one of they samples in input is not recognized.\n\n        \"\"\"\n        if not isinstance(classes, dict):\n            raise TypeError('Input classes is not a dict!')\n        if not len(classes) == self.num_samples:\n            raise ValueError('Too few items - need {} keys'.format(self.num_samples))\n        if not all([key in self.keys for key in classes]):\n            raise ValueError('One or more unrecognized keys!')\n        self.__classes = classes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy the contents of another object.", "response": "def __copy(self, other):\n        \"\"\"Copy constructor.\"\"\"\n        self.__data = copy.deepcopy(other.data)\n        self.__classes = copy.deepcopy(other.classes)\n        self.__labels = copy.deepcopy(other.labels)\n        self.__dtype = copy.deepcopy(other.dtype)\n        self.__description = copy.deepcopy(other.description)\n        self.__feature_names = copy.deepcopy(other.feature_names)\n        self.__num_features = copy.deepcopy(other.num_features)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __load(self, path):\n        try:\n            path = os.path.abspath(path)\n            with open(path, 'rb') as df:\n                # loaded_dataset = pickle.load(df)\n                self.__data, self.__classes, self.__labels, \\\n                self.__dtype, self.__description, \\\n                self.__num_features, self.__feature_names = pickle.load(df)\n\n            # ensure the loaded dataset is valid\n            self.__validate(self.__data, self.__classes, self.__labels)\n\n        except IOError as ioe:\n            raise IOError('Unable to read the dataset from file: {}', format(ioe))\n        except:\n            raise", "response": "Method to load the serialized dataset from disk."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __load_arff(self, arff_path, encode_nonnumeric=False):\n        try:\n            from scipy.io.arff import loadarff\n            arff_data, arff_meta = loadarff(arff_path)\n        except:\n            raise ValueError('Error loading the ARFF dataset!')\n\n        attr_names = arff_meta.names()[:-1]  # last column is class\n        attr_types = arff_meta.types()[:-1]\n        if not encode_nonnumeric:\n            # ensure all the attributes are numeric\n            uniq_types = set(attr_types)\n            if 'numeric' not in uniq_types:\n                raise ValueError(\n                    'Currently only numeric attributes in ARFF are supported!')\n\n            non_numeric = uniq_types.difference({'numeric'})\n            if len(non_numeric) > 0:\n                raise ValueError('Non-numeric features provided ({}), '\n                                 'without requesting encoding to numeric. '\n                                 'Try setting encode_nonnumeric=True '\n                                 'or encode features to numeric!'.format(non_numeric))\n        else:\n            raise NotImplementedError(\n                'encoding non-numeric features to numeric is not implemented yet! '\n                'Encode features beforing to ARFF.')\n\n        self.__description = arff_meta.name  # to enable it as a label e.g. in neuropredict\n\n        # initializing the key containers, before calling self.add_sample\n        self.__data = OrderedDict()\n        self.__labels = OrderedDict()\n        self.__classes = OrderedDict()\n\n        num_samples = len(arff_data)\n        num_digits = len(str(num_samples))\n        make_id = lambda index: 'row{index:0{nd}d}'.format(index=index, nd=num_digits)\n        sample_classes = [cls.decode('utf-8') for cls in arff_data['class']]\n        class_set = set(sample_classes)\n        label_dict = dict()\n        # encoding class names to labels 1 to n\n        for ix, cls in enumerate(class_set):\n            label_dict[cls] = ix + 1\n\n        for index in range(num_samples):\n            sample = arff_data.take([index])[0].tolist()\n            sample_attrs = sample[:-1]\n            sample_class = sample[-1].decode('utf-8')\n            self.add_sample(sample_id=make_id(index),  # ARFF rows do not have an ID\n                            features=sample_attrs,\n                            label=label_dict[sample_class],\n                            class_id=sample_class)\n            # not necessary to set feature_names=attr_names for each sample,\n            # as we do it globally after loop\n\n        self.__feature_names = attr_names\n\n        return", "response": "Loads a given dataset saved in Weka s ARFF format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, file_path):\n\n        # TODO need a file format that is flexible and efficient to allow the following:\n        #   1) being able to read just meta info without having to load the ENTIRE dataset\n        #       i.e. use case: compatibility check with #subjects, ids and their classes\n        #   2) random access layout: being able to read features for a single subject!\n\n        try:\n            file_path = os.path.abspath(file_path)\n            with open(file_path, 'wb') as df:\n                # pickle.dump(self, df)\n                pickle.dump((self.__data, self.__classes, self.__labels,\n                             self.__dtype, self.__description, self.__num_features,\n                             self.__feature_names),\n                            df)\n            return\n        except IOError as ioe:\n            raise IOError('Unable to save the dataset to file: {}', format(ioe))\n        except:\n            raise", "response": "Save the current dataset to disk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extend(self, other):\n\n        if not isinstance(other, MLDataset):\n            raise TypeError('Incorrect type of dataset provided!')\n        # assert self.__dtype==other.dtype, TypeError('Incorrect data type of features!')\n        for sample in other.keys:\n            self.add_sample(sample, other.data[sample], other.labels[sample],\n                            other.classes[sample])", "response": "Extend the current dataset vertically with the samples from another dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating word size in blast form.", "response": "def validate_word_size(word_size, BLAST_SETS):\n    \"\"\"Validate word size in blast/tblastn form.  \"\"\"\n\n    blast_min_int_word_size = BLAST_SETS.min_word_size\n    blast_max_int_word_size = BLAST_SETS.max_word_size\n    blast_word_size_error = BLAST_SETS.get_word_size_error()\n\n    try:\n        if len(word_size) <= 0:\n            raise forms.ValidationError(blast_word_size_error)\n\n        int_word_size = int(word_size)\n\n        if int_word_size < blast_min_int_word_size:\n            raise forms.ValidationError(blast_word_size_error)\n\n        if int_word_size >= blast_max_int_word_size:\n            raise forms.ValidationError(blast_word_size_error)\n\n    except:\n        raise forms.ValidationError(blast_word_size_error)\n\n    return int_word_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_sequence(sequence: str, sequence_is_as_nucleotide=True):\n\n    tmp_seq = tempfile.NamedTemporaryFile(mode=\"wb+\", delete=False)\n\n    if len(str(sequence).strip()) == 0:\n        raise forms.ValidationError(blast_settings.BLAST_CORRECT_SEQ_ERROR_MSG)\n\n    if str(sequence).strip()[0] != \">\":\n        tmp_seq.write(\">seq1\\n\".encode())\n\n    tmp_seq.write(sequence.encode())\n    tmp_seq.close()\n\n    records = SeqIO.index(tmp_seq.name, \"fasta\")\n    record_count = len(records)\n\n    if record_count == 0:\n        raise forms.ValidationError(blast_settings.BLAST_CORRECT_SEQ_ERROR_MSG)\n\n    if record_count > blast_settings.BLAST_MAX_NUMBER_SEQ_IN_INPUT:\n        raise forms.ValidationError(blast_settings.BLAST_CORRECT_SEQ_MAX_SEQ_NUMB_ERROR_MSG)\n\n    # read query sequence from temporary file\n    first_sequence_list_in_file = SeqIO.parse(tmp_seq.name, \"fasta\")\n\n    for sequence in first_sequence_list_in_file:\n\n        if len(sequence.seq) <= 10:\n            raise forms.ValidationError(blast_settings.BLAST_CORRECT_SEQ_TOO_SHORT_ERROR_MSG)\n\n        if sequence_is_as_nucleotide:\n            check_allowed_letters(str(sequence.seq), ALLOWED_NUCL)\n        else:\n            check_allowed_letters(str(sequence.seq), ALLOWED_AMINOACIDS)\n\n    return tmp_seq", "response": "Validate sequence in blast format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_allowed_letters(seq, allowed_letters_as_set):\n\n    # set of unique letters in sequence\n    seq_set = set(seq)\n\n    not_allowed_letters_in_seq = [x for x in seq_set if str(x).upper() not in allowed_letters_as_set]\n\n    if len(not_allowed_letters_in_seq) > 0:\n        raise forms.ValidationError(\n            \"This sequence type cannot contain letters: \" + \", \".join(not_allowed_letters_in_seq))", "response": "Rise an error if sequence contains undesirable letters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _repeat(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        \"\"\"Repeats the call until True is returned.\"\"\"\n        ret = None\n        while ret is None:\n            ret = func(*args, **kwargs)\n        return ret\n    return wrapper", "response": "Decorator to repeat a function until something other than None is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(pandocversion=None, doc=None):\n\n    # This requires some care because we can't be sure that a call to 'pandoc'\n    # will work.  It could be 'pandoc-1.17.0.2' or some other name.  Try\n    # checking the parent process first, and only make a call to 'pandoc' as\n    # a last resort.\n\n    global _PANDOCVERSION  # pylint: disable=global-statement\n\n    pattern = re.compile(r'^[1-2]\\.[0-9]+(?:\\.[0-9]+)?(?:\\.[0-9]+)?$')\n\n    if 'PANDOC_VERSION' in os.environ:  # Available for pandoc >= 1.19.1\n        pandocversion = str(os.environ['PANDOC_VERSION'])\n\n    if not pandocversion is None:\n        # Test the result and if it is OK then store it in _PANDOCVERSION\n        if pattern.match(pandocversion):\n            _PANDOCVERSION = pandocversion\n            return _PANDOCVERSION\n        else:\n            msg = 'Cannot understand pandocversion=%s'%pandocversion\n            raise RuntimeError(msg)\n\n    if not doc is None:\n        if 'pandoc-api-version' in doc:\n            # This could be either 1.18 or 1.19; there is no way to\n            # distinguish them (but there isn't a use case in pandoc-fignos\n            # and friends where it matters)\n            _PANDOCVERSION = '1.18'\n            return _PANDOCVERSION\n\n    # Get the command\n    try:  # Get the path for the parent process\n        if os.name == 'nt':\n            # psutil appears to work differently for windows\n            command = psutil.Process(os.getpid()).parent().parent().exe()\n        else:\n            command = psutil.Process(os.getpid()).parent().exe()\n        if not os.path.basename(command).startswith('pandoc'):\n            raise RuntimeError('pandoc not found')\n    except:  # pylint: disable=bare-except\n        # Call whatever pandoc is available and hope for the best\n        command = 'pandoc'\n\n    # Make the call\n    try:\n        # Get the version number and confirm it conforms to expectations\n        output = subprocess.check_output([command, '-v'])\n        line = output.decode('utf-8').split('\\n')[0]\n        pandocversion = line.split(' ')[-1].strip()\n    except: # pylint: disable=bare-except\n        pandocversion = ''\n\n    # Test the result and if it is OK then store it in _PANDOCVERSION\n    if pattern.match(pandocversion):\n        _PANDOCVERSION = pandocversion\n\n    if _PANDOCVERSION is None:\n        msg = \"\"\"Cannot determine pandoc version.  Please file an issue at\n              https://github.com/tomduck/pandocfiltering/issues\"\"\"\n        raise RuntimeError(textwrap.dedent(msg))\n\n    return _PANDOCVERSION", "response": "Sets or determines the pandoc version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_meta(meta, name):\n    assert name in meta\n    data = meta[name]\n\n    if data['t'] in ['MetaString', 'MetaBool']:\n        return data['c']\n    elif data['t'] == 'MetaInlines':\n        # Handle bug in pandoc 2.2.3 and 2.2.3.1: Return boolean value rather\n        # than strings, as appropriate.\n        if len(data['c']) == 1 and data['c'][0]['t'] == 'Str':\n            if data['c'][0]['c'] in ['true', 'True', 'TRUE']:\n                return True\n            elif data['c'][0]['c'] in ['false', 'False', 'FALSE']:\n                return False\n        return stringify(data['c'])\n    elif data['t'] == 'MetaList':\n        return [stringify(v['c']) for v in data['c']]\n    else:\n        raise RuntimeError(\"Could not understand metadata variable '%s'.\" %\n                           name)", "response": "Retrieves the metadata variable name from the meta dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef elt(eltType, numargs):  # pylint: disable=invalid-name\n    def Element(*value):  # pylint: disable=invalid-name\n        \"\"\"Creates an element.\"\"\"\n        el = _elt(eltType, numargs)(*value)\n        if isinstance(el['c'], tuple):\n            el['c'] = list(el['c'])  # The content should be a list, not tuple\n        return el\n    return Element", "response": "Returns an element of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an element given a key and value.", "response": "def _getel(key, value):\n    \"\"\"Returns an element given a key and value.\"\"\"\n    if key in ['HorizontalRule', 'Null']:\n        return elt(key, 0)()\n    elif key in ['Plain', 'Para', 'BlockQuote', 'BulletList',\n                 'DefinitionList', 'HorizontalRule', 'Null']:\n        return elt(key, 1)(value)\n    return elt(key, len(value))(*value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quotify(x):\n\n    def _quotify(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Replaced Quoted elements with quoted strings.\"\"\"\n        if key == 'Quoted':\n            ret = []\n            quote = '\"' if value[0]['t'] == 'DoubleQuote' else \"'\"\n            if value[1][0]['t'] == 'Str':\n                value[1][0]['c'] = quote + value[1][0]['c']\n            else:\n                ret.append(Str(quote))\n\n            if value[1][-1]['t'] == 'Str':\n                value[1][-1]['c'] = value[1][-1]['c'] + quote\n                ret += value[1]\n            else:\n                ret += value[1] + [Str(quote)]\n            return ret\n        return None\n\n    return walk(walk(x, _quotify, '', {}), join_strings, '', {})", "response": "Replaces Quoted elements in element list x with quoted strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dollarfy(x):\n\n    def _dollarfy(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Replaces Math elements\"\"\"\n        if key == 'Math':\n            return Str('$' + value[1] + '$')\n        return None\n\n    return walk(x, _dollarfy, '', {})", "response": "Replaces Math elements in element list x with a $ - enclosed string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_attrs(x, n):\n\n    # Check for the start of the attributes string\n    if not (x[n]['t'] == 'Str' and x[n]['c'].startswith('{')):\n        raise ValueError('Attributes not found.')\n\n    # It starts with {, so this *may* be an attributes list.  Search for where\n    # the attributes end.  Do not consider } in quoted elements.\n\n    seq = []          # A sequence of saved values\n    quotechar = None  # Used to keep track of quotes in strings\n    flag = False      # Flags that an attributes list was found\n    i = 0             # Initialization\n\n    for i, v in enumerate(x[n:]):  # Scan through the list\n        if v and v['t'] == 'Str':\n            # Scan for } outside of a quote\n            for j, c in enumerate(v['c']):\n                if c == quotechar:  # This is an end quote\n                    quotechar = None\n                elif c in ['\"', \"'\"]:  # This is an open quote\n                    quotechar = c\n                elif c == '}' and quotechar is None:  # The attributes end here\n                    # Split the string at the } and save the pieces\n                    head, tail = v['c'][:j+1], v['c'][j+1:]\n                    x[n+i] = copy.deepcopy(v)\n                    x[n+i]['c'] = tail\n                    v['c'] = head\n                    flag = True\n                    break\n        seq.append(v)\n        if flag:\n            break\n\n    if flag:  # Attributes string was found, so process it\n\n        # Delete empty and extracted elements\n        if x[n+i]['t'] == 'Str' and not x[n+i]['c']:\n            del x[n+i]\n        del x[n:n+i]\n\n        # Process the attrs\n        attrstr = stringify(dollarfy(quotify(seq))).strip()\n        attrs = PandocAttributes(attrstr, 'markdown').to_pandoc()\n\n        # Remove extranneous quotes from kvs\n        for i, (k, v) in enumerate(attrs[2]):  # pylint: disable=unused-variable\n            if v[0] == v[-1] == '\"' or v[0] == \"'\" == v[-1] == \"'\":\n                attrs[2][i][1] = attrs[2][i][1][1:-1]\n\n        # We're done\n        return attrs\n\n    # Attributes not found\n    raise ValueError('Attributes not found.')", "response": "Extracts the attributes from element list x beginning at index n."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _join_strings(x):\n    for i in range(len(x)-1):  # Process successive pairs of elements\n        if x[i]['t'] == 'Str' and x[i+1]['t'] == 'Str':\n            x[i]['c'] += x[i+1]['c']\n            del x[i+1]  # In-place deletion of element from list\n            return None  # Forces processing to repeat\n    return True", "response": "Joins adjacent Str elements found in the element list x."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\njoin adjacent Str elements in the value list.", "response": "def join_strings(key, value, fmt, meta):  # pylint: disable=unused-argument\n    \"\"\"Joins adjacent Str elements in the 'value' list.\"\"\"\n    if key in ['Para', 'Plain']:\n        _join_strings(value)\n    elif key == 'Image':\n        _join_strings(value[-2])\n    elif key == 'Table':\n        _join_strings(value[-5])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if this is a broken reference ; False otherwise.", "response": "def _is_broken_ref(key1, value1, key2, value2):\n    \"\"\"True if this is a broken reference; False otherwise.\"\"\"\n    # A link followed by a string may represent a broken reference\n    if key1 != 'Link' or key2 != 'Str':\n        return False\n    # Assemble the parts\n    n = 0 if _PANDOCVERSION < '1.16' else 1\n\n    if isinstance(value1[n][0]['c'], list):\n        # Occurs when there is quoted text in an actual link.  This is not\n        # a broken link.  See Issue #1.\n        return False\n\n    s = value1[n][0]['c'] + value2\n    # Return True if this matches the reference regex\n    return True if _REF.match(s) else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms the repair on the element list x.", "response": "def _repair_refs(x):\n    \"\"\"Performs the repair on the element list 'x'.\"\"\"\n\n    if _PANDOCVERSION is None:\n        raise RuntimeError('Module uninitialized.  Please call init().')\n\n    # Scan the element list x\n    for i in range(len(x)-1):\n\n        # Check for broken references\n        if _is_broken_ref(x[i]['t'], x[i]['c'] if 'c' in x[i] else [],\n                          x[i+1]['t'], x[i+1]['c'] if 'c' in x[i+1] else []):\n\n            # Get the reference string\n            n = 0 if _PANDOCVERSION < '1.16' else 1\n            s = x[i]['c'][n][0]['c'] + x[i+1]['c']\n\n            # Chop it into pieces.  Note that the prefix and suffix may be\n            # parts of other broken references.\n            prefix, label, suffix = _REF.match(s).groups()\n\n            # Insert the suffix, label and prefix back into x.  Do it in this\n            # order so that the indexing works.\n            if suffix:\n                x.insert(i+2, Str(suffix))\n            x[i+1] = Cite(\n                [{\"citationId\":label,\n                  \"citationPrefix\":[],\n                  \"citationSuffix\":[],\n                  \"citationNoteNum\":0,\n                  \"citationMode\":{\"t\":\"AuthorInText\", \"c\":[]},\n                  \"citationHash\":0}],\n                [Str('@' + label)])\n            if prefix:\n                if i > 0 and x[i-1]['t'] == 'Str':\n                    x[i-1]['c'] = x[i-1]['c'] + prefix\n                    del x[i]\n                else:\n                    x[i] = Str(prefix)\n            else:\n                del x[i]\n\n            return None  # Forces processing to repeat\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing \"-f markdown+autolink_bare_uris\" with pandoc < 1.18 splits a reference like \"{@fig:one}\" into email Link and Str elements. This function replaces the mess with the Cite and Str elements we normally get. Call this before any reference processing.", "response": "def repair_refs(key, value, fmt, meta):  # pylint: disable=unused-argument\n    \"\"\"Using \"-f markdown+autolink_bare_uris\" with pandoc < 1.18 splits a\n    reference like \"{@fig:one}\" into email Link and Str elements.  This\n    function replaces the mess with the Cite and Str elements we normally\n    get.  Call this before any reference processing.\"\"\"\n\n    if _PANDOCVERSION >= '1.18':\n        return\n\n    # The problem spans multiple elements, and so can only be identified in\n    # element lists.  Element lists are encapsulated in different ways.  We\n    # must process them all.\n\n    if key in ('Para', 'Plain'):\n        _repair_refs(value)\n    elif key == 'Image':\n        _repair_refs(value[-2])\n    elif key == 'Table':\n        _repair_refs(value[-5])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the modifier in front of the Cite at index i in the element list x. The modifier is stored in attrs. Returns the updated index i.", "response": "def _extract_modifier(x, i, attrs):\n    \"\"\"Extracts the */+/! modifier in front of the Cite at index 'i' of the\n    element list 'x'.  The modifier is stored in 'attrs'.  Returns the updated\n    index 'i'.\"\"\"\n\n    global _cleveref_tex_flag  # pylint: disable=global-statement\n\n    assert x[i]['t'] == 'Cite'\n    assert i > 0\n\n    # Check the previous element for a modifier in the last character\n    if x[i-1]['t'] == 'Str':\n        modifier = x[i-1]['c'][-1]\n        if not _cleveref_tex_flag and modifier in ['*', '+']:\n            _cleveref_tex_flag = True\n        if modifier in ['*', '+', '!']:\n            attrs[2].append(['modifier', modifier])\n            if len(x[i-1]['c']) > 1:  # Lop the modifier off of the string\n                x[i-1]['c'] = x[i-1]['c'][:-1]\n            else:  # The element contains only the modifier; delete it\n                del x[i-1]\n                i -= 1\n\n    return i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving curly brackets surrounding the Cite element at index i in the element list x.", "response": "def _remove_brackets(x, i):\n    \"\"\"Removes curly brackets surrounding the Cite element at index 'i' in\n    the element list 'x'.  It is assumed that the modifier has been\n    extracted.  Empty strings are deleted from 'x'.\"\"\"\n\n    assert x[i]['t'] == 'Cite'\n    assert i > 0 and i < len(x) - 1\n\n    # Check if the surrounding elements are strings\n    if not x[i-1]['t'] == x[i+1]['t'] == 'Str':\n        return\n\n    # Trim off curly brackets\n    if x[i-1]['c'].endswith('{') and x[i+1]['c'].startswith('}'):\n        if len(x[i+1]['c']) > 1:\n            x[i+1]['c'] = x[i+1]['c'][1:]\n        else:\n            del x[i+1]\n\n        if len(x[i-1]['c']) > 1:\n            x[i-1]['c'] = x[i-1]['c'][:-1]\n        else:\n            del x[i-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _process_refs(x, labels):\n\n    # Scan the element list x for Cite elements with known labels\n    for i, v in enumerate(x):\n        if v['t'] == 'Cite' and len(v['c']) == 2 and \\\n          _get_label(v['t'], v['c']) in labels:\n\n            # A new reference was found; create some empty attributes for it\n            attrs = ['', [], []]\n\n            # Extract the modifiers.  'attrs' is updated in place.  Element\n            # deletion could change the index of the Cite being processed.\n            if i > 0:\n                i = _extract_modifier(x, i, attrs)\n\n            # Attach the attributes\n            v['c'].insert(0, attrs)\n\n            # Remove surrounding brackets\n            if i > 0 and i < len(x)-1:\n                _remove_brackets(x, i)\n\n            # The element list may be changed\n            return None  # Forces processing to repeat via _repeat decorator\n\n    return True", "response": "Processes the element list x for Cite elements with the given labels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_refs_factory(labels):\n\n    # pylint: disable=unused-argument\n    def process_refs(key, value, fmt, meta):\n        \"\"\"Instates Ref elements.\"\"\"\n        # References may occur in a variety of places; we must process them\n        # all.\n\n        if key in ['Para', 'Plain']:\n            _process_refs(value, labels)\n        elif key == 'Image':\n            _process_refs(value[-2], labels)\n        elif key == 'Table':\n            _process_refs(value[-5], labels)\n        elif key == 'Span':\n            _process_refs(value[-1], labels)\n        elif key == 'Emph':\n            _process_refs(value, labels)\n        elif key == 'Strong':\n            _process_refs(value, labels)\n\n    return process_refs", "response": "Returns a function that processes the text around a reference."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a function that replaces the references with format - specific content.", "response": "def replace_refs_factory(references, use_cleveref_default, use_eqref,\n                         plusname, starname, target):\n    \"\"\"Returns replace_refs(key, value, fmt, meta) action that replaces\n    references with format-specific content.  The content is determined using\n    the 'references' dict, which associates reference labels with numbers or\n    string tags (e.g., { 'fig:1':1, 'fig:2':2, ...}).  If 'use_cleveref_default'\n    is True, or if \"modifier\" in the reference's attributes is \"+\" or \"*\", then\n    clever referencing is used; i.e., a name is placed in front of the number\n    or string tag.  The 'plusname' and 'starname' lists give the singular\n    and plural names for \"+\" and \"*\" clever references, respectively.  The\n    'target' is the LaTeX type for clever referencing (e.g., \"figure\",\n    \"equation\", \"table\", ...).\"\"\"\n\n    global _cleveref_tex_flag  # pylint: disable=global-statement\n\n    # Update global if clever referencing is required by default\n    _cleveref_tex_flag = _cleveref_tex_flag or use_cleveref_default\n\n    def _insert_cleveref_fakery(key, value, meta):\n        r\"\"\"Inserts TeX to support clever referencing in LaTeX documents\n        if the key isn't a RawBlock.  If the key is a RawBlock, then check\n        the value to see if the TeX was already inserted.\n\n        The \\providecommand macro is used to fake the cleveref package's\n        behaviour if it is not provided in the template via\n        \\usepackage{cleveref}.\n\n        TeX is inserted into the value.  Replacement elements are returned.\n        \"\"\"\n\n        global _cleveref_tex_flag  # pylint: disable=global-statement\n\n        comment1 = '% pandoc-xnos: cleveref formatting'\n        tex1 = [comment1,\n                r'\\crefformat{%s}{%s~#2#1#3}'%(target, plusname[0]),\n                r'\\Crefformat{%s}{%s~#2#1#3}'%(target, starname[0])]\n\n        if key == 'RawBlock':  # Check for existing cleveref TeX\n            if value[1].startswith(comment1):\n                # Append the new portion\n                value[1] = value[1] + '\\n' + '\\n'.join(tex1[1:])\n                _cleveref_tex_flag = False  # Cleveref fakery already installed\n\n        elif key != 'RawBlock':  # Write the cleveref TeX\n            _cleveref_tex_flag = False  # Cancels further attempts\n            ret = []\n\n            # Check first to see if fakery is turned off\n            if not 'xnos-cleveref-fake' in meta or \\\n              check_bool(get_meta(meta, 'xnos-cleveref-fake')):\n                # Cleveref fakery\n                tex2 = [\n                    r'% pandoc-xnos: cleveref fakery',\n                    r'\\newcommand{\\plusnamesingular}{}',\n                    r'\\newcommand{\\starnamesingular}{}',\n                    r'\\newcommand{\\xrefname}[1]{'\\\n                      r'\\protect\\renewcommand{\\plusnamesingular}{#1}}',\n                    r'\\newcommand{\\Xrefname}[1]{'\\\n                      r'\\protect\\renewcommand{\\starnamesingular}{#1}}',\n                    r'\\providecommand{\\cref}{\\plusnamesingular~\\ref}',\n                    r'\\providecommand{\\Cref}{\\starnamesingular~\\ref}',\n                    r'\\providecommand{\\crefformat}[2]{}',\n                    r'\\providecommand{\\Crefformat}[2]{}']\n                ret.append(RawBlock('tex', '\\n'.join(tex2)))\n            ret.append(RawBlock('tex', '\\n'.join(tex1)))\n            return ret\n        return None\n\n    def _cite_replacement(key, value, fmt, meta):\n        \"\"\"Returns context-dependent content to replace a Cite element.\"\"\"\n\n        assert key == 'Cite'\n\n        attrs, label = value[0], _get_label(key, value)\n        attrs = PandocAttributes(attrs, 'pandoc')\n\n        assert label in references\n\n        # Get the replacement value\n        text = str(references[label])\n\n        # Choose between \\Cref, \\cref and \\ref\n        use_cleveref = attrs['modifier'] in ['*', '+'] \\\n          if 'modifier' in attrs.kvs else use_cleveref_default\n        plus = attrs['modifier'] == '+' if 'modifier' in attrs.kvs \\\n          else use_cleveref_default\n        name = plusname[0] if plus else starname[0]  # Name used by cref\n\n        # The replacement depends on the output format\n        if fmt == 'latex':\n            if use_cleveref:\n                # Renew commands needed for cleveref fakery\n                if not 'xnos-cleveref-fake' in meta or \\\n                  check_bool(get_meta(meta, 'xnos-cleveref-fake')):\n                    faketex = (r'\\xrefname' if plus else r'\\Xrefname') + \\\n                      '{%s}' % name\n                else:\n                    faketex = ''\n                macro = r'\\cref' if plus else r'\\Cref'\n                ret = RawInline('tex', r'%s%s{%s}'%(faketex, macro, label))\n            elif use_eqref:\n                ret = RawInline('tex', r'\\eqref{%s}'%label)\n            else:\n                ret = RawInline('tex', r'\\ref{%s}'%label)\n        else:\n            if use_eqref:\n                text = '(' + text + ')'\n\n            linktext = [Math({\"t\":\"InlineMath\", \"c\":[]}, text[1:-1]) \\\n               if text.startswith('$') and text.endswith('$') \\\n               else Str(text)]\n\n            link = elt('Link', 2)(linktext, ['#%s' % label, '']) \\\n              if _PANDOCVERSION < '1.16' else \\\n              Link(['', [], []], linktext, ['#%s' % label, ''])\n            ret = ([Str(name), Space()] if use_cleveref else []) + [link]\n\n        return ret\n\n    def replace_refs(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Replaces references with format-specific content.\"\"\"\n\n        if fmt == 'latex' and _cleveref_tex_flag:\n\n            # Put the cleveref TeX fakery in front of the first block element\n            # that isn't a RawBlock.\n\n            if not key in ['Plain', 'Para', 'CodeBlock', 'RawBlock',\n                           'BlockQuote', 'OrderedList', 'BulletList',\n                           'DefinitionList', 'Header', 'HorizontalRule',\n                           'Table', 'Div', 'Null']:\n                return None\n\n            # Reconstruct the block element\n            el = _getel(key, value)\n\n            # Insert cleveref TeX in front of the block element\n            tex = _insert_cleveref_fakery(key, value, meta)\n            if tex:\n                return  tex + [el]\n\n        elif key == 'Cite' and len(value) == 3:  # Replace the reference\n\n            return _cite_replacement(key, value, fmt, meta)\n\n        return None\n\n    return replace_refs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attach_attrs_factory(f, extract_attrs=extract_attrs, allow_space=False):\n\n    # Get the name\n    name = f.__closure__[0].cell_contents\n\n    def _attach_attrs(x):\n        \"\"\"Extracts and attaches the attributes.\"\"\"\n        for i, v in enumerate(x):\n            if v and v['t'] == name:  # Find where the attributes start\n                n = i+1\n                if allow_space and n < len(x) and x[n]['t'] == 'Space':\n                    n += 1\n                try:  # Extract the attributes\n                    attrs = extract_attrs(x, n)\n                    x[i]['c'].insert(0, attrs)\n                except (ValueError, IndexError):\n                    pass\n\n    def attach_attrs(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Attaches attributes to an element.\"\"\"\n        if key in ['Para', 'Plain']:\n            _attach_attrs(value)\n\n            # Image: Add pandoc's figure marker if warranted\n            if len(value) == 1 and value[0]['t'] == 'Image':\n                value[0]['c'][-1][1] = 'fig:'\n\n    return attach_attrs", "response": "Returns an action that reads and attaches attributes to unattributed elements generated by the pandocfilters function f."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function that detaches the attributes attached to elements of type f.", "response": "def detach_attrs_factory(f):\n    \"\"\"Returns detach_attrs(key, value, fmt, meta) action that detaches\n    attributes attached to elements of type f (e.g. pandocfilters.Math, etc).\n    Attributes provided natively by pandoc will be left as is.\"\"\"\n\n    # Get the name and standard length\n    name = f.__closure__[0].cell_contents\n    n = f.__closure__[1].cell_contents\n\n    def detach_attrs(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Detaches the attributes.\"\"\"\n        if key == name:\n            assert len(value) <= n+1\n            if len(value) == n+1:\n                # Make sure value[0] represents attributes then delete\n                assert len(value[0]) == 3\n                assert isinstance(value[0][0], STRTYPES)\n                assert isinstance(value[0][1], list)\n                assert isinstance(value[0][2], list)\n                del value[0]\n\n    return detach_attrs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a function that inserts section numbers into the attributes of elements of type f.", "response": "def insert_secnos_factory(f):\n    \"\"\"Returns insert_secnos(key, value, fmt, meta) action that inserts\n    section numbers into the attributes of elements of type f.\n    \"\"\"\n\n    # Get the name and standard length\n    name = f.__closure__[0].cell_contents\n    n = f.__closure__[1].cell_contents\n\n    def insert_secnos(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Inserts section numbers into elements attributes.\"\"\"\n\n        global sec  # pylint: disable=global-statement\n\n        if 'xnos-number-sections' in meta and \\\n          check_bool(get_meta(meta, 'xnos-number-sections')) and \\\n              fmt in ['html', 'html5']:\n            if key == 'Header':\n                if 'unnumbered' in value[1][1]:\n                    return\n                level = value[0]\n                m = level - len(sec)\n                if m > 0:\n                    sec.extend([0]*m)\n                sec[level-1] += 1\n                sec = sec[:MAXLEVEL]\n            if key == name:\n\n                # Only insert if attributes are attached.  Images always have\n                # attributes.\n                assert len(value) <= n+1\n                if name == 'Image' or len(value) == n+1:\n\n                    # Make sure value[0] represents attributes\n                    assert len(value[0]) == 3\n                    assert isinstance(value[0][0], STRTYPES)\n                    assert isinstance(value[0][1], list)\n                    assert isinstance(value[0][2], list)\n\n                    # Insert the section number into the attributes\n                    s = '.'.join([str(m) for m in sec])\n                    value[0][2].insert(0, ['secno', s])\n\n    return insert_secnos"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_secnos_factory(f):\n\n    # Get the name and standard length\n    name = f.__closure__[0].cell_contents\n    n = f.__closure__[1].cell_contents\n\n    def delete_secnos(key, value, fmt, meta):  # pylint: disable=unused-argument\n        \"\"\"Deletes section numbers from elements attributes.\"\"\"\n        if 'xnos-number-sections' in meta and \\\n          check_bool(get_meta(meta, 'xnos-number-sections')) and \\\n              fmt in ['html', 'html5']:\n\n            # Only delete if attributes are attached.   Images always have\n            # attributes.\n            if key == name:\n                assert len(value) <= n+1\n                if name == 'Image' or len(value) == n+1:\n\n                    # Make sure value[0] represents attributes\n                    assert len(value[0]) == 3\n                    assert isinstance(value[0][0], STRTYPES)\n                    assert isinstance(value[0][1], list)\n                    assert isinstance(value[0][2], list)\n\n                    # Remove the secno attribute\n                    if value[0][2] and value[0][2][0][0] == 'secno':\n                        del value[0][2][0]\n\n    return delete_secnos", "response": "Returns a delete_secnos action that deletes section numbers from the attributes of elements of type f."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_rawblocks_factory(rawblocks):\n\n    # pylint: disable=unused-argument\n    def insert_rawblocks(key, value, fmt, meta):\n        \"\"\"Inserts non-duplicate RawBlock elements.\"\"\"\n\n        if not rawblocks:\n            return None\n\n        # Put the RawBlock elements in front of the first block element that\n        # isn't also a RawBlock.\n\n        if not key in ['Plain', 'Para', 'CodeBlock', 'RawBlock',\n                       'BlockQuote', 'OrderedList', 'BulletList',\n                       'DefinitionList', 'Header', 'HorizontalRule',\n                       'Table', 'Div', 'Null']:\n            return None\n\n        if key == 'RawBlock':  # Remove duplicates\n            rawblock = RawBlock(*value)\n            if rawblock in rawblocks:\n                rawblocks.remove(rawblock)\n                return None\n\n        if rawblocks:  # Insert blocks\n            el = _getel(key, value)\n            return [rawblocks.pop(0) for i in range(len(rawblocks))] + [el]\n\n        return None\n\n    return insert_rawblocks", "response": "r Returns insert_rawblocks action that inserts non - duplicate RawBlock elements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting movies that match the search query string from the API.", "response": "def search(self, **kwargs):\n        \"\"\"Get movies that match the search query string from the API.\n\n        Args:\n          q (optional): plain text search query; remember to URI encode\n          page_limit (optional): number of search results to show per page, \n                                 default=30\n          page (optional): results page number, default=1\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('search')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the cast for a movie specified by id from the API.", "response": "def cast(self, **kwargs):\n        \"\"\"Get the cast for a movie specified by id from the API.\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_id_path('cast')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clips(self, **kwargs):\n        path = self._get_id_path('clips')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Get related clips and trailers for a movie."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sample_data(sample_file):\n\n    sequence_sample_in_fasta = None\n    with open(sample_file) as handle:\n        sequence_sample_in_fasta = handle.read()\n\n    return sequence_sample_in_fasta", "response": "Read and returns sample data to fill form with default sample sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform biopython s blast record into a list of BlastRecord objects.", "response": "def blast_records_to_object(blast_records):\n    \"\"\"Transforms biopython's blast record into blast object defined in django-blastplus app.  \"\"\"\n\n    # container for transformed objects\n    blast_objects_list = []\n\n    for blast_record in blast_records:\n\n        br = BlastRecord(**{'query': blast_record.query,\n                            'version': blast_record.version,\n                            'expect': blast_record.expect,\n                            'application': blast_record.application,\n                            'reference': blast_record.reference})\n\n        for alignment in blast_record.alignments:\n\n            al = Alignment(**{\n                'hit_def': alignment.hit_def,\n                'title': alignment.title,\n                'length': alignment.length,\n            })\n\n            for hsp in alignment.hsps:\n                h = Hsp(**{\n                    'align_length': hsp.align_length,\n                    'bits': hsp.bits,\n                    'expect': hsp.expect,\n                    'frame': hsp.frame,\n                    'gaps': hsp.gaps,\n                    'identities': hsp.identities,\n                    'match': hsp.match,\n                    'num_alignments': hsp.num_alignments,\n                    'positives': hsp.positives,\n                    'query': hsp.query,\n                    'query_end': hsp.query_end,\n                    'query_start': hsp.query_start,\n                    'sbjct': hsp.sbjct,\n                    'sbjct_end': hsp.sbjct_end,\n                    'sbjct_start': hsp.sbjct_start,\n                    'score': hsp.score,\n                    'strand': hsp.strand,\n                    'str': str(hsp),\n                })\n\n                al.hsp_list.append(h)\n            br.alignments.append(al)\n        blast_objects_list.append(br)\n    return blast_objects_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning blastplus and tblastn search and returns the output and error string.", "response": "def run_blast_commands(ncbicommandline_method, **keywords):\n    \"\"\"Runs blastplus/tblastn search, collects result and pass as a xml temporary file.  \"\"\"\n\n    # temporary files for output\n    blast_out_tmp = tempfile.NamedTemporaryFile(mode=\"w+\",delete=False)\n    keywords['out'] = blast_out_tmp.name\n\n    # unpack query temp file object\n    query_file_object_tmp = keywords['query']\n    keywords['query'] = query_file_object_tmp.name\n\n    stderr = ''\n    error_string = ''\n    try:\n        # formating blastplus command\n        blastplusx_cline = ncbicommandline_method(**keywords)\n        stdout, stderr = blastplusx_cline()\n\n    except ApplicationError as e:\n        error_string = \"Runtime error: \" + stderr + \"\\n\" + e.cmd\n\n    # remove query temp file\n    os.unlink(query_file_object_tmp.name)\n    # os.remove(query_file_object_tmp.name)\n\n    return blast_out_tmp, error_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if database is set as annotated.", "response": "def get_annotation(db_path, db_list):\n    \"\"\" Checks if database is set as annotated. \"\"\"\n\n    annotated = False\n    for db in db_list:\n        if db[\"path\"] == db_path:\n            annotated = db[\"annotated\"]\n            break\n\n    return annotated"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the tty device for a given usbserial devices identifiers.", "response": "def find_usbserial(vendor, product):\n  \"\"\"Find the tty device for a given usbserial devices identifiers.\n\n  Args:\n     vendor: (int) something like 0x0000\n     product: (int) something like 0x0000\n\n  Returns:\n     String, like /dev/ttyACM0 or /dev/tty.usb...\n  \"\"\"\n  if platform.system() == 'Linux':\n    vendor, product = [('%04x' % (x)).strip() for x in (vendor, product)]\n    return linux_find_usbserial(vendor, product)\n  elif platform.system() == 'Darwin':\n    return osx_find_usbserial(vendor, product)\n  else:\n    raise NotImplementedError('Cannot find serial ports on %s'\n                              % platform.system())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_manager(self, base_manager=models.Manager):\n\n        _builder = self\n\n        class CustomManager(base_manager):\n            def search(self, search_data, custom_args={}):\n                \"\"\"\n                Search inside the custom fields for this model for any match\n                 of search_data and returns existing model instances\n\n                :param search_data:\n                :param custom_args:\n                :return:\n                \"\"\"\n                query = None\n                lookups = (\n                    '%s__%s' % ('value_text', 'icontains'),\n                )\n                content_type = ContentType.objects.get_for_model(self.model)\n                custom_args = dict({ 'content_type': content_type, 'searchable': True }, **custom_args)\n                custom_fields = dict((f.name, f) for f in _builder.fields_model_class.objects.filter(**custom_args))\n                for value_lookup in lookups:\n                    for key, f in custom_fields.items():\n                        found = _builder.values_model_class.objects.filter(**{ 'custom_field': f,\n                                                                               'content_type': content_type,\n                                                                               value_lookup: search_data })\n                        if found.count() > 0:\n                            if query is None:\n                                query = Q()\n                            query = query & Q(**{ str('%s__in' % self.model._meta.pk.name):\n                                                  [obj.object_id for obj in found] })\n                if query is None:\n                    return self.get_queryset().none()\n                return self.get_queryset().filter(query)\n\n        return CustomManager", "response": "Create a custom manager that will use the fields_model and values_model\n        respectively."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a custom ModelMixin that will attach to your custom field.", "response": "def create_mixin(self):\n        \"\"\"\n        This will create the custom Model Mixin to attach to your custom field\n        enabled model.\n\n        :return:\n        \"\"\"\n\n        _builder = self\n\n        class CustomModelMixin(object):\n            @cached_property\n            def _content_type(self):\n                return ContentType.objects.get_for_model(self)\n\n            @classmethod\n            def get_model_custom_fields(cls):\n                \"\"\" Return a list of custom fields for this model, callable at model level \"\"\"\n                return _builder.fields_model_class.objects.filter(content_type=ContentType.objects.get_for_model(cls))\n\n            def get_custom_fields(self):\n                \"\"\" Return a list of custom fields for this model \"\"\"\n                return _builder.fields_model_class.objects.filter(content_type=self._content_type)\n\n            def get_custom_value(self, field):\n                \"\"\" Get a value for a specified custom field \"\"\"\n                return _builder.values_model_class.objects.get(custom_field=field,\n                                                               content_type=self._content_type,\n                                                               object_id=self.pk)\n\n            def set_custom_value(self, field, value):\n                \"\"\" Set a value for a specified custom field \"\"\"\n                custom_value, created = \\\n                    _builder.values_model_class.objects.get_or_create(custom_field=field,\n                                                                      content_type=self._content_type,\n                                                                      object_id=self.pk)\n                custom_value.value = value\n                custom_value.full_clean()\n                custom_value.save()\n                return custom_value\n\n            #def __getattr__(self, name):\n            #    \"\"\" Get a value for a specified custom field \"\"\"\n            #    try:\n            #        obj = _builder.values_model_class.objects.get(custom_field__name=name,\n            #                                                      content_type=self._content_type,\n            #                                                      object_id=self.pk)\n            #        return obj.value\n            #    except ObjectDoesNotExist:\n            #        pass\n            #    return super(CustomModelMixin, self).__getattr__(name)\n\n        return CustomModelMixin"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_modelform(self, base_form=forms.ModelForm,\n                         field_types=settings.CUSTOM_FIELD_TYPES,\n                         widget_types=settings.CUSTOM_WIDGET_TYPES):\n        \"\"\"\n        This creates the class that implements a ModelForm that knows about\n        the custom fields\n\n        :param base_form:\n        :param field_types:\n        :param widget_types:\n        :return:\n        \"\"\"\n\n        _builder = self\n\n        class CustomFieldModelBaseForm(base_form):\n            def __init__(self, *args, **kwargs):\n                \"\"\"\n                Constructor\n                \"\"\"\n                # additional form variables\n                self.custom_classes = None\n                self.is_custom_form = True\n                self.instance = None\n\n                # construct the form\n                super(CustomFieldModelBaseForm, self).__init__(*args, **kwargs)\n\n                # init custom fields from model in the form\n                self.init_custom_fields()\n\n            def clean(self):\n                \"\"\"\n                Clean the form\n                \"\"\"\n                cleaned_data = super(CustomFieldModelBaseForm, self).clean()\n                return cleaned_data\n\n            def save(self, commit=True):\n                \"\"\"\n                Save the form\n                \"\"\"\n                self.instance = super(CustomFieldModelBaseForm, self).save(commit=commit)\n                if self.instance and commit:\n                    self.instance.save()\n                    self.save_custom_fields()\n                return self.instance\n\n            def init_custom_fields(self):\n                \"\"\"\n                Populate the ``form.fields[]`` with the additional fields coming from\n                the custom fields models.\n                \"\"\"\n                content_type = self.get_content_type()\n                fields = self.get_fields_for_content_type(content_type)\n                for f in fields:\n                    name = str(f.name)\n                    initial = f.initial\n                    self.fields[name] = self.get_formfield_for_field(f)\n                    self.fields[name].is_custom = True\n                    self.fields[name].label = f.label\n                    self.fields[name].required = f.required\n                    self.fields[name].widget = self.get_widget_for_field(f)\n                    if self.instance and self.instance.pk:\n                        value = self.search_value_for_field(f,\n                                                            content_type,\n                                                            self.instance.pk)\n                        if len(value) > 0:\n                            initial = value[0].value\n                    self.fields[name].initial = self.initial[name] = initial\n\n            def save_custom_fields(self):\n                \"\"\" Perform save and validation over the custom fields \"\"\"\n                if not self.instance.pk:\n                    raise Exception(\"The model instance has not been saved. Have you called instance.save() ?\")\n\n                content_type = self.get_content_type()\n                fields = self.get_fields_for_content_type(content_type)\n                for f in fields:\n                    name = str(f.name)\n                    fv = self.search_value_for_field(f,\n                                                     content_type,\n                                                     self.instance.pk)\n                    if len(fv) > 0:\n                        value = fv[0]\n                        value.value = self.cleaned_data[name]\n                    else:\n                        value = self.create_value_for_field(f,\n                                                            self.instance.pk,\n                                                            self.cleaned_data[name])\n                    value.save()\n\n            def get_model(self):\n                \"\"\"\n                Returns the actual model this ``ModelForm`` is referring to\n                \"\"\"\n                return self._meta.model\n\n            def get_content_type(self):\n                \"\"\"\n                Returns the content type instance of the model this ``ModelForm`` is\n                referring to\n                \"\"\"\n                return ContentType.objects.get_for_model(self.get_model())\n\n            def get_formfield_for_field(self, field):\n                \"\"\"\n                Returns the defined formfield instance built from the type of the field\n\n                :param field: custom field instance\n                :return: the formfield instance\n                \"\"\"\n                field_attrs = {\n                    'label': field.label,\n                    'help_text': field.help_text,\n                    'required': field.required,\n                }\n                if field.data_type == CUSTOM_TYPE_TEXT:\n                    #widget_attrs = {}\n                    if field.min_length:\n                        field_attrs['min_length'] = field.min_length\n                    if field.max_length:\n                        field_attrs['max_length'] = field.max_length\n                    #    widget_attrs['maxlength'] = field.max_length\n                    #field_attrs['widget'] = widgets.AdminTextInputWidget(attrs=widget_attrs)\n                elif field.data_type == CUSTOM_TYPE_INTEGER:\n                    if field.min_value: field_attrs['min_value'] = int(float(field.min_value))\n                    if field.max_value: field_attrs['max_value'] = int(float(field.max_value))\n                    #field_attrs['widget'] = spinner.IntegerSpinnerWidget(attrs=field_attrs)\n                elif field.data_type == CUSTOM_TYPE_FLOAT:\n                    if field.min_value: field_attrs['min_value'] = float(field.min_value)\n                    if field.max_value: field_attrs['max_value'] = float(field.max_value)\n                    #field_attrs['widget'] = spinner.SpinnerWidget(attrs=field_attrs)\n                elif field.data_type == CUSTOM_TYPE_TIME:\n                    #field_attrs['widget'] = date.TimePickerWidget()\n                    pass\n                elif field.data_type == CUSTOM_TYPE_DATE:\n                    #field_attrs['widget'] = date.DatePickerWidget()\n                    pass\n                elif field.data_type == CUSTOM_TYPE_DATETIME:\n                    #field_attrs['widget'] = date.DateTimePickerWidget()\n                    pass\n                elif field.data_type == CUSTOM_TYPE_BOOLEAN:\n                    pass\n                field_type = import_class(field_types[field.data_type])\n                return field_type(**field_attrs)\n\n            def get_widget_for_field(self, field, attrs={}):\n                \"\"\"\n                Returns the defined widget type instance built from the type of the field\n\n                :param field: custom field instance\n                :param attrs: attributes of widgets\n                :return: the widget instance\n                \"\"\"\n                return import_class(widget_types[field.data_type])(**attrs)\n\n            def get_fields_for_content_type(self, content_type):\n                \"\"\"\n                Returns all fields for a given content type\n\n                Example implementation:\n\n                  return MyCustomField.objects.filter(content_type=content_type)\n\n                :param content_type: content type to search\n                :return: the custom field instances\n                \"\"\"\n\n                return _builder.fields_model_class.objects.filter(content_type=content_type)\n\n            def search_value_for_field(self, field, content_type, object_id):\n                \"\"\"\n                This function will return the CustomFieldValue instance for a given\n                field of an object that has the given content_type\n\n                Example implementation:\n\n                  return MyCustomFieldValue.objects.filter(custom_field=field,\n                                                           content_type=content_type,\n                                                           object_id=object_id)\n\n                :param field: the custom field instance\n                :param content_type: the content type instance\n                :param object_id: the object id this value is referring to\n                :return: CustomFieldValue queryset\n                \"\"\"\n                return _builder.values_model_class.objects.filter(custom_field=field,\n                                                                  content_type=content_type,\n                                                                  object_id=object_id)\n\n            def create_value_for_field(self, field, object_id, value):\n                \"\"\"\n                Create a value for a given field of an object\n\n                Example implementation:\n\n                  return MyCustomFieldValue(custom_field=field,\n                                            object_id=object_id,\n                                            value=value)\n\n                :param field: the custom field instance\n                :param object_id: the object id this value is referring to\n                :param value: the value to set\n                :return: the value instance (not saved!)\n                \"\"\"\n                return _builder.values_model_class(custom_field=field,\n                                                   object_id=object_id,\n                                                   value=value)\n\n        return CustomFieldModelBaseForm", "response": "Creates a new base form that knows about the custom fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_modeladmin(self, base_admin=admin.ModelAdmin):\n\n        _builder = self\n\n        class CustomFieldModelBaseAdmin(base_admin):\n            def __init__(self, *args, **kwargs):\n                super(CustomFieldModelBaseAdmin, self).__init__(*args, **kwargs)\n\n            def save_model(self, request, obj, form, change):\n                obj.save()\n                if hasattr(form, 'save_custom_fields'):\n                    form.save_custom_fields()\n\n        return CustomFieldModelBaseAdmin", "response": "Creates a new base admin that knows about the custom fields of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning a complex object into an iterator of byte strings.", "response": "def bytes_iter(obj):\n    \"\"\"Turn a complex object into an iterator of byte strings.\n    The resulting iterator can be used for caching.\n    \"\"\"\n    if obj is None:\n        return\n    elif isinstance(obj, six.binary_type):\n        yield obj\n    elif isinstance(obj, six.string_types):\n        yield obj\n    elif isinstance(obj, (date, datetime)):\n        yield obj.isoformat()\n    elif is_mapping(obj):\n        for key in sorted(obj.keys()):\n            for out in chain(bytes_iter(key), bytes_iter(obj[key])):\n                yield out\n    elif is_sequence(obj):\n        if isinstance(obj, (list, set)):\n            try:\n                obj = sorted(obj)\n            except Exception:\n                pass\n        for item in obj:\n            for out in bytes_iter(item):\n                yield out\n    elif isinstance(obj, (types.FunctionType, types.BuiltinFunctionType,\n                          types.MethodType, types.BuiltinMethodType)):\n        yield getattr(obj, 'func_name', '')\n    else:\n        yield six.text_type(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hash_data(obj):\n    collect = sha1()\n    for text in bytes_iter(obj):\n        if isinstance(text, six.text_type):\n            text = text.encode('utf-8')\n        collect.update(text)\n    return collect.hexdigest()", "response": "Generate a SHA1 from a complex object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef triples(self, words):\n\n        if len(words) < 3:\n            return\n\n        for i in range(len(words) - 2):\n            yield (words[i], words[i+1], words[i+2])", "response": "Generates triples from the given data string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget list of import from python module", "response": "def ast_imports(file_path):\n    \"\"\"get list of import from python module\n    :return: (list - tuple) (module, name, asname, level)\n    \"\"\"\n    with open(file_path, 'r') as fp:\n        text = fp.read()\n    mod_ast = ast.parse(text, file_path)\n    finder = _ImportsFinder()\n    finder.visit(mod_ast)\n    return finder.imports"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_fqn(cls, path):\n        name_list = [path.stem]\n        current_path = path\n        # move to parent path until parent path is a python package\n        while cls.is_pkg(current_path.parent):\n            name_list.append(current_path.parent.name)\n            current_path = current_path.parent\n        return list(reversed(name_list))", "response": "get full qualified name as list of strings"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to get imported module reference by its name", "response": "def _get_imported_module(self, module_name):\n        \"\"\"try to get imported module reference by its name\"\"\"\n        # if imported module on module_set add to list\n        imp_mod = self.by_name.get(module_name)\n        if imp_mod:\n            return imp_mod\n\n        # last part of import section might not be a module\n        # remove last section\n        no_obj = module_name.rsplit('.', 1)[0]\n        imp_mod2 = self.by_name.get(no_obj)\n        if imp_mod2:\n            return imp_mod2\n\n        # special case for __init__\n        if module_name in self.pkgs:\n            pkg_name = module_name  + \".__init__\"\n            return self.by_name[pkg_name]\n\n        if no_obj in self.pkgs:\n            pkg_name = no_obj +  \".__init__\"\n            return self.by_name[pkg_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_imports(self, module, return_fqn=False):\n        # print('####', module.fqn)\n        # print(self.by_name.keys(), '\\n\\n')\n        imports = set()\n        raw_imports = ast_imports(module.path)\n        for import_entry in raw_imports:\n            # join 'from' and 'import' part of import statement\n            full = \".\".join(s for s in import_entry[:2] if s)\n\n            import_level = import_entry[3]\n            if import_level:\n                # intra package imports\n                intra = '.'.join(module.fqn[:-import_level] + [full])\n                imported = self._get_imported_module(intra)\n            else:\n                imported = self._get_imported_module(full)\n\n            if imported:\n                if return_fqn:\n                    imports.add('.'.join(imported.fqn))\n                else:\n                    imports.add(imported.path)\n        return imports", "response": "return set of imported modules that are in self\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_random_string(cls, length):\n        # avoid things that could be mistaken ex: 'I' and '1'\n        letters = \"23456789ABCDEFGHJKLMNPQRSTUVWXYZ\"\n        return \"\".join([random.choice(letters) for _ in range(length)])", "response": "Generates a random string of the specified length"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_airbnb_demo(data_dir):\n\n    # Setup\n    meta_file = os.path.join(data_dir, 'Airbnb_demo_meta.json')\n    transformer_list = ['NumberTransformer', 'DTTransformer', 'CatTransformer']\n    ht = HyperTransformer(meta_file)\n\n    # Run\n    transformed = ht.fit_transform(transformer_list=transformer_list)\n    result = ht.reverse_transform(tables=transformed)\n\n    # Check\n    assert result.keys() == ht.table_dict.keys()\n\n    for name, table in result.items():\n        assert not result[name].isnull().all().all()", "response": "HyperTransfomer will transform back and forth data airbnb data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eventlog(self, path):\n        self.logger.debug(\"Parsing Event log file %s.\", path)\n\n        with NamedTemporaryFile(buffering=0) as tempfile:\n            self._filesystem.download(path, tempfile.name)\n\n            file_header = FileHeader(tempfile.read(), 0)\n\n            for xml_string, _ in evtx_file_xml_view(file_header):\n                yield xml_string", "response": "Iterates over the Events contained within the log at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef publish_message_to_centrifugo(sender, instance, created, **kwargs):\n    if created is True:\n        client = Client(\"{0}api/\".format(getattr(settings, \"CENTRIFUGE_ADDRESS\")), getattr(settings, \"CENTRIFUGE_SECRET\"))\n        # we ensure the client is still in the thread (he may have left or have been removed)\n        active_participants = [participation.participant.id for participation in Participation.objects.filter(thread=instance.thread, date_left__isnull=True).select_related('participant')]\n        client.publish(\n            build_channel(settings.CENTRIFUGO_MESSAGE_NAMESPACE, instance.thread.id, active_participants),\n            {\n                \"id\": instance.id,\n                \"body\": instance.body,\n                \"sender\": instance.sender.id,\n                \"thread\": instance.thread.id,\n                \"sent_at\": str(instance.sent_at),\n                \"is_notification\": True,  # ATTENTION: check against sender too to be sure to not notify him his message\n            }\n        )", "response": "Publishes each saved message to Centrifugo."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npublishing participation to a thread.", "response": "def publish_participation_to_thread(sender, instance, created, **kwargs):\n    \"\"\" Warns users everytime a thread including them is published. This is done via channel subscription.  \"\"\"\n    if kwargs.get('created_and_add_participants') is True:\n        request_participant_id = kwargs.get('request_participant_id')\n        if request_participant_id is not None:\n            client = Client(\"{0}api/\".format(getattr(settings, \"CENTRIFUGE_ADDRESS\")), getattr(settings, \"CENTRIFUGE_SECRET\"))\n            active_participants = [participation.participant for participation in Participation.objects.filter(thread=instance, date_left__isnull=True).select_related('participant')]\n            for participant in active_participants:\n                client.publish(\n                    build_channel(settings.CENTRIFUGO_THREAD_NAMESPACE, participant.id, [participant.id]),\n                    {\n                        \"message_channel_to_connect_to\": build_channel(settings.CENTRIFUGO_MESSAGE_NAMESPACE, instance.id, [p.id for p in active_participants])\n                    }\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getFileAndName(self, *args, **kwargs):\n\t\t'''\n\t\tGive a requested page (note: the arguments for this call are forwarded to getpage()),\n\t\treturn the content at the target URL and the filename for the target content as a\n\t\t2-tuple (pgctnt, hName) for the content at the target URL.\n\n\t\tThe filename specified in the content-disposition header is used, if present. Otherwise,\n\t\tthe last section of the url path segment is treated as the filename.\n\t\t'''\n\n\t\tpgctnt, hName, mime = self.getFileNameMime(*args, **kwargs)\n\t\treturn pgctnt, hName", "response": "This method returns the filename of the requested file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a requested page (note: the arguments for this call are forwarded to getpage()), return the content at the target URL, the filename for the target content, and the mimetype for the content at the target URL, as a 3-tuple (pgctnt, hName, mime). The filename specified in the content-disposition header is used, if present. Otherwise, the last section of the url path segment is treated as the filename.", "response": "def getFileNameMime(self, requestedUrl, *args, **kwargs):\n\t\t'''\n\t\tGive a requested page (note: the arguments for this call are forwarded to getpage()),\n\t\treturn the content at the target URL, the filename for the target content, and\n\t\tthe mimetype for the content at the target URL, as a 3-tuple (pgctnt, hName, mime).\n\n\t\tThe filename specified in the content-disposition header is used, if present. Otherwise,\n\t\tthe last section of the url path segment is treated as the filename.\n\t\t'''\n\n\n\n\t\tif 'returnMultiple' in kwargs:\n\t\t\traise Exceptions.ArgumentError(\"getFileAndName cannot be called with 'returnMultiple'\", requestedUrl)\n\n\t\tif 'soup' in kwargs and kwargs['soup']:\n\t\t\traise Exceptions.ArgumentError(\"getFileAndName contradicts the 'soup' directive!\", requestedUrl)\n\n\t\tkwargs[\"returnMultiple\"] = True\n\n\t\tpgctnt, pghandle = self.getpage(requestedUrl, *args, **kwargs)\n\n\t\tinfo = pghandle.info()\n\t\tif not 'Content-Disposition' in info:\n\t\t\thName = ''\n\t\telif not 'filename=' in info['Content-Disposition']:\n\t\t\thName = ''\n\t\telse:\n\t\t\thName = info['Content-Disposition'].split('filename=')[1]\n\t\t\t# Unquote filename if it's quoted.\n\t\t\tif ((hName.startswith(\"'\") and hName.endswith(\"'\")) or hName.startswith('\"') and hName.endswith('\"')) and len(hName) >= 2:\n\t\t\t\thName = hName[1:-1]\n\n\t\tmime = info.get_content_type()\n\n\t\tif not hName.strip():\n\t\t\trequestedUrl = pghandle.geturl()\n\t\t\thName = urllib.parse.urlsplit(requestedUrl).path.split(\"/\")[-1].strip()\n\n\t\tif \"/\" in hName:\n\t\t\thName = hName.split(\"/\")[-1]\n\n\t\treturn pgctnt, hName, mime"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that we have a sucuri - protected cloudproxy cookie.", "response": "def __check_suc_cookie(self, components):\n\t\t'''\n\t\tThis is only called if we're on a known sucuri-\"protected\" site.\n\t\tAs such, if we do *not* have a sucuri cloudproxy cookie, we can assume we need to\n\t\tdo the normal WAF step-through.\n\t\t'''\n\t\tnetloc = components.netloc.lower()\n\n\t\tfor cookie in self.cj:\n\t\t\tif cookie.domain_specified and (cookie.domain.lower().endswith(netloc)\n\t\t\t\tor (cookie.domain.lower().endswith(\"127.0.0.1\") and (\n\t\t\t\tcomponents.path == \"/sucuri_shit_3\" or components.path == \"/sucuri_shit_2\" ))):   # Allow testing\n\t\t\t\tif \"sucuri_cloudproxy_uuid_\" in cookie.name:\n\t\t\t\t\treturn\n\t\tself.log.info(\"Missing cloudproxy cookie for known sucuri wrapped site. Doing a pre-emptive chromium fetch.\")\n\t\traise Exceptions.SucuriWrapper(\"WAF Shit\", str(components))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __pre_check(self, requestedUrl):\n\t\t'''\n\t\tAllow the pre-emptive fetching of sites with a full browser if they're known\n\t\tto be dick hosters.\n\t\t'''\n\t\tcomponents = urllib.parse.urlsplit(requestedUrl)\n\n\t\tnetloc_l = components.netloc.lower()\n\t\tif netloc_l in Domain_Constants.SUCURI_GARBAGE_SITE_NETLOCS:\n\t\t\tself.__check_suc_cookie(components)\n\t\telif netloc_l in Domain_Constants.CF_GARBAGE_SITE_NETLOCS:\n\t\t\tself.__check_cf_cookie(components)\n\t\telif components.path == '/sucuri_shit_2':\n\t\t\tself.__check_suc_cookie(components)\n\t\telif components.path == '/sucuri_shit_3':\n\t\t\tself.__check_suc_cookie(components)\n\t\telif components.path == '/cloudflare_under_attack_shit_2':\n\t\t\tself.__check_cf_cookie(components)\n\t\telif components.path == '/cloudflare_under_attack_shit_3':\n\t\t\tself.__check_cf_cookie(components)", "response": "Check the pre -emptive fetching of sites with a full browser."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __decompressContent(self, coding, pgctnt):\n\t\t#preLen = len(pgctnt)\n\t\tif coding == 'deflate':\n\t\t\tcompType = \"deflate\"\n\t\t\tbits_opts = [\n\t\t\t\t-zlib.MAX_WBITS,       # deflate\n\t\t\t\t zlib.MAX_WBITS,       # zlib\n\t\t\t\t zlib.MAX_WBITS | 16,  # gzip\n\t\t\t\t zlib.MAX_WBITS | 32,  # \"automatic header detection\"\n\n\t\t\t\t 0,  # Try to guess from header\n\n\t\t\t\t # Try all the raw window options.\n\t\t\t\t -8, -9, -10, -11, -12, -13, -14, -15,\n\n\t\t\t\t # Stream with zlib headers\n\t\t\t\t  8,  9,  10,  11,  12,  13,  14,  15,\n\n\t\t\t\t # With gzip header+trailer\n\t\t\t\t  8+16,  9+16,  10+16,  11+16,  12+16,  13+16,  14+16,  15+16,\n\t\t\t\t # Automatic detection\n\t\t\t\t  8+32,  9+32,  10+32,  11+32,  12+32,  13+32,  14+32,  15+32,\n\n\t\t\t]\n\n\t\t\terr = None\n\n\t\t\tfor wbits_val in bits_opts:\n\t\t\t\ttry:\n\t\t\t\t\tpgctnt = zlib.decompress(pgctnt, wbits_val)\n\t\t\t\t\treturn compType, pgctnt\n\t\t\t\texcept zlib.error as e:\n\t\t\t\t\terr = e\n\n\t\t\t# We can't get here without err having thrown.\n\t\t\traise err\n\n\t\telif coding == 'gzip':\n\t\t\tcompType = \"gzip\"\n\n\t\t\tbuf = io.BytesIO(pgctnt)\n\t\t\tf = gzip.GzipFile(fileobj=buf)\n\t\t\tpgctnt = f.read()\n\n\t\telif coding == \"sdch\":\n\t\t\traise Exceptions.ContentTypeError(\"Wait, someone other then google actually supports SDCH compression (%s)?\" % pgreq)\n\n\t\telse:\n\t\t\tcompType = \"none\"\n\n\t\treturn compType, pgctnt", "response": "Decompress the content of the pgctnt."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a selenium cookie into the active opener", "response": "def addSeleniumCookie(self, cookieDict):\n\t\t'''\n\t\tInstall a cookie exported from a selenium webdriver into\n\t\tthe active opener\n\t\t'''\n\t\t# print cookieDict\n\t\tcookie = http.cookiejar.Cookie(\n\t\t\t\tversion            = 0,\n\t\t\t\tname               = cookieDict['name'],\n\t\t\t\tvalue              = cookieDict['value'],\n\t\t\t\tport               = None,\n\t\t\t\tport_specified     = False,\n\t\t\t\tdomain             = cookieDict['domain'],\n\t\t\t\tdomain_specified   = True,\n\t\t\t\tdomain_initial_dot = False,\n\t\t\t\tpath               = cookieDict['path'],\n\t\t\t\tpath_specified     = False,\n\t\t\t\tsecure             = cookieDict['secure'],\n\t\t\t\texpires            = cookieDict['expiry'] if 'expiry' in cookieDict else None,\n\t\t\t\tdiscard            = False,\n\t\t\t\tcomment            = None,\n\t\t\t\tcomment_url        = None,\n\t\t\t\trest               = {\"httponly\":\"%s\" % cookieDict['httponly'] if 'httponly' in cookieDict else False},\n\t\t\t\trfc2109            = False\n\t\t\t)\n\n\t\tself.addCookie(cookie)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mail_on_500(app, recipients, sender='noreply@localhost'):\n    '''Main function for setting up Flask-ErrorMail to send e-mails when 500 \n    errors occur.\n\n    :param app: Flask Application Object\n    :type app: flask.Flask\n    :param recipients: List of recipient email addresses.\n    :type recipients: list or tuple\n    :param sender: Email address that should be listed as the sender. Defaults \n        to 'noreply@localhost'\n    :type sender: string\n\n    '''\n\n    #importing locally, so that the dependencies are only required if \n    # mail_on_500 is used.\n    from flask import request as __request\n    from flask_mail import Mail as __Mail\n    from flask_mail import Message as __Message\n\n    mail = __Mail(app)\n\n    # create a closure to track the sender and recipients\n    def email_exception(exception):\n        '''Handles the exception message from Flask by sending an email to the\n        recipients defined in the call to mail_on_500.\n\n        '''\n\n        msg = __Message(\"[Flask|ErrorMail] Exception Detected\",\n                        sender=sender,\n                        recipients=recipients)\n        msg_contents = [\n            'Traceback:',\n            '='*80,\n            traceback.format_exc(),\n        ]\n        msg_contents.append('\\n')\n        msg_contents.append('Request Information:')\n        msg_contents.append('='*80)\n        environ = __request.environ\n        environkeys = sorted(environ.keys())\n        for key in environkeys:\n            msg_contents.append('%s: %s' % (key, environ.get(key)))\n\n        msg.body = '\\n'.join(msg_contents) + '\\n'\n\n        mail.send(msg)\n\n    app.register_error_handler(500, email_exception)", "response": "This function is used to set up Flask - ErrorMail to send e - mails when 500 error occurs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef command_dependents(options):\n    dependents = dependencies(options.package, options.recursive, options.info)\n\n    if dependents:\n        print(*dependents, sep='\\n')", "response": "Command launched by CLI."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dependencies(dist, recursive=False, info=False):\n\n    def case_sorted(items):\n        \"\"\"Return unique list sorted in case-insensitive order.\"\"\"\n        return sorted(set(items), key=lambda i: i.lower())\n\n    def requires(distribution):\n        \"\"\"Return the requirements for a distribution.\"\"\"\n        if recursive:\n            req = set(pkg_resources.require(distribution.project_name))\n            req.remove(distribution)\n            return {r.as_requirement() for r in req}\n        return distribution.requires()\n\n    def modifier(distribution):\n        \"\"\"Return project's name or full requirement string.\"\"\"\n        return str(distribution) if info else distribution.project_name\n\n    return case_sorted(modifier(r) for r in requires(dist))", "response": "Yields a list of all dependencies of a distribution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user_group_perms_processor(request):\n    org = None\n    group = None\n\n    if hasattr(request, \"user\"):\n        if request.user.is_anonymous:\n            group = None\n        else:\n            group = request.user.get_org_group()\n            org = request.user.get_org()\n\n    if group:\n        context = dict(org_perms=GroupPermWrapper(group))\n    else:\n        context = dict()\n\n    # make sure user_org is set on our request based on their session\n    context[\"user_org\"] = org\n\n    return context", "response": "Return context variables with org permissions to the user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getresult(self, captcha_id, timeout=None):\n\t\ttimeout = timeout\n\n\t\tif not timeout:\n\t\t\ttimeout = self.waittime\n\n\t\tpoll_interval = 8\n\n\t\tstart = time.time()\n\n\t\tfor x in range(int(timeout / poll_interval)+1):\n\t\t\tself.log.info(\"Sleeping %s seconds (poll %s of %s, elapsed %0.2fs of %0.2f).\",\n\t\t\t\t\tpoll_interval,\n\t\t\t\t\tx,\n\t\t\t\t\tint(timeout / poll_interval)+1,\n\t\t\t\t\t(time.time() - start),\n\t\t\t\t\ttimeout,\n\t\t\t\t)\n\t\t\ttime.sleep(poll_interval)\n\n\t\t\ttry:\n\t\t\t\tresp = self.doGet('result', {\n\t\t\t\t\t\t'action' : 'get',\n\t\t\t\t\t\t'key'    : self.api_key,\n\t\t\t\t\t\t'json'   : True,\n\t\t\t\t\t\t'id'     : captcha_id,\n\t\t\t\t\t}\n\t\t\t\t)\n\n\t\t\t\tself.log.info(\"Call returned success!\")\n\t\t\t\treturn resp\n\n\t\t\texcept exc.CaptchaNotReady:\n\t\t\t\tself.log.info(\"Captcha not ready. Waiting longer.\")\n\n\t\traise exc.CaptchaSolverFailure(\"Solving captcha timed out after %s seconds!\" % (time.time() - start, ))", "response": "Get the result of a captcha."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubmit a file to the solver service and return the request ID associated with the new captcha task.", "response": "def _submit(self, pathfile, filedata, filename):\n\t\t'''\n\t\tSubmit either a file from disk, or a in-memory file to the solver service, and\n\t\treturn the request ID associated with the new captcha task.\n\t\t'''\n\t\tif pathfile and os.path.exists(pathfile):\n\t\t\tfiles = {'file': open(pathfile, 'rb')}\n\t\telif filedata:\n\t\t\tassert filename\n\t\t\tfiles = {'file' : (filename, io.BytesIO(filedata))}\n\t\telse:\n\t\t\traise ValueError(\"You must pass either a valid file path, or a bytes array containing the captcha image!\")\n\n\t\tpayload = {\n\t\t\t'key'    : self.api_key,\n\t\t\t'method' : 'post',\n\t\t\t'json'   : True,\n\t\t\t}\n\n\t\tself.log.info(\"Uploading to 2Captcha.com.\")\n\n\t\turl = self.getUrlFor('input', {})\n\n\t\trequest = requests.post(url, files=files, data=payload)\n\n\t\tif not request.ok:\n\t\t\traise exc.CaptchaSolverFailure(\"Posting captcha to solve failed!\")\n\n\t\tresp_json = json.loads(request.text)\n\t\treturn self._process_response(resp_json)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solve_simple_captcha(self, pathfile=None, filedata=None, filename=None):\n\n\t\tcaptcha_id = self._submit(pathfile, filedata, filename)\n\t\treturn self._getresult(captcha_id=captcha_id)", "response": "Solve a simple captcha."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves a recaptcha on a page with the input value google_key.", "response": "def solve_recaptcha(self, google_key, page_url, timeout = 15 * 60):\n\t\t'''\n\t\tSolve a recaptcha on page `page_url` with the input value `google_key`.\n\t\tTimeout is `timeout` seconds, defaulting to 60 seconds.\n\n\t\tReturn value is either the `g-recaptcha-response` value, or an exceptionj is raised\n\t\t(generally `CaptchaSolverFailure`)\n\t\t'''\n\n\t\tproxy = SocksProxy.ProxyLauncher([TWOCAPTCHA_IP])\n\n\t\ttry:\n\t\t\tcaptcha_id = self.doGet('input', {\n\t\t\t\t\t\t'key'         : self.api_key,\n\t\t\t\t\t\t'method'      : \"userrecaptcha\",\n\t\t\t\t\t\t'googlekey'   : google_key,\n\t\t\t\t\t\t'pageurl'     : page_url,\n\n\t\t\t\t\t\t'proxy'       : proxy.get_wan_address(),\n\t\t\t\t\t\t'proxytype'   : \"SOCKS5\",\n\n\t\t\t\t\t\t'json'        : True,\n\t\t\t\t\t}\n\t\t\t\t)\n\n\t\t\t# Allow 15 minutes for the solution\n\t\t\t# I've been seeing times up to 160+ seconds in testing.\n\t\t\treturn self._getresult(captcha_id=captcha_id, timeout=timeout)\n\t\tfinally:\n\t\t\tproxy.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(query=None, params=None, callback=None, mine_ids=None, info_only=None,\n           **kwargs):\n    \"\"\"Mine Archive.org search results.\n\n    :param query: (optional) The Archive.org search query to yield\n                  results for. Refer to https://archive.org/advancedsearch.php#raw\n                  for help formatting your query. If no query is given,\n                  all indexed items will be mined!\n    :type query: str\n\n    :param params: (optional) The URL parameters to send with each\n                   request sent to the Archive.org Advancedsearch Api.\n    :type params: dict\n\n    :param callback: (optional) A callback function to be called on each\n                     :py:class:`aiohttp.client.ClientResponse`.\n\n    :param mine_ids: (optional) By default, ``search`` mines through\n                     search results. To mine through the item metadata\n                     for each item returned by your query instead, set\n                     ``mine_ids`` to ``True``.\n    :type mine_ids: bool\n\n    :param info_only: (optional) Set to ``True`` to return information\n                      about your query rather than mining any metadata\n                      or search results.\n    :type info_only: bool\n\n    :param \\*\\*kwargs: (optional) Arguments that ``get_miner`` takes.\n    \"\"\"\n    query = '(*:*)' if not query else query\n    params = params if params else {}\n    mine_ids = True if mine_ids else False\n    info_only = True if info_only else False\n    miner = SearchMiner(**kwargs)\n\n    if info_only:\n        params = miner.get_search_params(query, params)\n        r = miner.get_search_info(params)\n        search_info = r.get('responseHeader')\n        search_info['numFound'] = r.get('response', {}).get('numFound', 0)\n        return search_info\n\n    try:\n        miner.loop.add_signal_handler(signal.SIGINT, miner.close)\n        miner.loop.run_until_complete(\n                miner.search(query, params=params, callback=callback, mine_ids=mine_ids))\n    except RuntimeError:\n        pass", "response": "Mine Archive. org search results."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mine_urls(urls, params=None, callback=None, **kwargs):\n    miner = Miner(**kwargs)\n    try:\n        miner.loop.add_signal_handler(signal.SIGINT, miner.close)\n        miner.loop.run_until_complete(miner.mine_urls(urls, params, callback))\n    except RuntimeError:\n        pass", "response": "Concurrently retrieve URLs.\n\n    :param urls: A set of URLs to concurrently retrieve.\n    :type urls: iterable\n\n    :param params: (optional) The URL parameters to send with each\n                   request.\n    :type params: dict\n\n    :param callback: (optional) A callback function to be called on each\n                     :py:class:`aiohttp.client.ClientResponse`.\n\n    :param \\*\\*kwargs: (optional) Arguments that ``get_miner`` takes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mine_items(identifiers, params=None, callback=None, **kwargs):\n    miner = ItemMiner(**kwargs)\n    try:\n        miner.loop.run_until_complete(miner.mine_items(identifiers, params, callback))\n    except RuntimeError:\n        miner.loop.close()", "response": "Concurrently retrieve metadata from Archive. org items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configure(username=None, password=None, overwrite=None, config_file=None):\n    username = input('Email address: ') if not username else username\n    password = getpass('Password: ') if not password else password\n    _config_file = write_config_file(username, password, overwrite, config_file)\n    print('\\nConfig saved to: {}'.format(_config_file))", "response": "Configure IA Mine with your Archive. org credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets news feed for a given symbol", "response": "def get_news_feed(self, symbol):\n        \"\"\"get_news_feed() uses the rss data table to get rss feeds under the Headlines and Financial Blogs headings on a typical stock page.\n        \"\"\"\n        rss_url='http://finance.yahoo.com/rss/headline?s={0}'.format(symbol)\n        response = self.select('rss',['title','link','description'],limit=2).where(['url','=',rss_url])\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_options_info(self, symbol, items=None, expiration=''):\n        response = self.select('yahoo.finance.options',items).where(['symbol','=',symbol],[] if not expiration else ['expiration','=',expiration])\n        return response", "response": "get_options_data uses the yahoo. finance. options table to retrieve call and put options from the options page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_industry_index(self, index_id,items=None):\n        response = self.select('yahoo.finance.industry',items).where(['id','=',index_id])\n        return response", "response": "retrieves all symbols that belong to an industry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves currency exchange rate data for given pair ( s ). Accepts both where pair = eurusd gbpusd and where pair = usdaud", "response": "def get_xchange_rate(self, pairs, items=None):\n        \"\"\"Retrieves currency exchange rate data for given pair(s). \n        Accepts both where pair='eurusd, gbpusd' and where pair in ('eurusd', 'gpbusd, usdaud')\n        \"\"\"\n        response = self.select('yahoo.finance.xchange', items).where(['pair', 'in', pairs])\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dividendhistory(self, symbol, startDate, endDate, items=None):\n        startDate, endDate = self.__get_time_range(startDate, endDate)\n        response = self.select('yahoo.finance.dividendhistory', items).where(['symbol', '=', symbol], ['startDate', '=', startDate], ['endDate', '=', endDate])\n        return response", "response": "Retrieves divident history for a given symbol start and end dates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_symbols(self, name):\n        url = \"http://autoc.finance.yahoo.com/autoc?query={0}&callback=YAHOO.Finance.SymbolSuggest.ssCallback\".format(name)\n\n        response = requests.get(url)\n\n        json_data = re.match(\"YAHOO\\.Finance\\.SymbolSuggest.ssCallback\\((.*)\\)\", response.text)\n        try:\n            json_data = json_data.groups()[0]\n        except (Exception,) as e:\n            print(e)\n            json_data = '{\"results\": \"Webservice seems to be down\"}'\n\n        return type('response', (requests.Response,),{\n            'text' : json_data,\n            'content': json_data.encode(),\n            'status_code': response.status_code,\n            'reason': response.reason,\n            'encoding': response.encoding,\n            'apparent_encoding': response.apparent_encoding,\n            'cookies': response.cookies,\n            'headers': response.headers,\n            'json': lambda : json.loads(json_data),\n            'url': response.url\n        })", "response": "Retrieves all symbols belonging to a company"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pip(filename):\n    '''Parse pip requirement file and transform it to setuptools requirements'''\n    requirements = []\n    for line in open(os.path.join('requirements', filename)).readlines():\n        match = RE_REQUIREMENT.match(line)\n        if match:\n            requirements.extend(pip(match.group('filename')))\n        else:\n            requirements.append(line)\n    return requirements", "response": "Parse pip requirement file and transform it to setuptools requirements"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pointlist(points, sr):\n    assert all(isinstance(pt, Point) or len(pt) == 2 \n               for pt in points), \"Point(s) not in [x, y] form\"\n    return [coord if isinstance(coord, Point) \n                  else Point(coord[0], coord[1], sr)\n            for coord in points]", "response": "Convert a list of the form [[ x y ]... ] to a list of Point instances\nATTRIBS with the given x y coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a JSON struct to a Geometry based on its structure", "response": "def fromJson(struct, attributes=None):\n    \"Convert a JSON struct to a Geometry based on its structure\"\n    if isinstance(struct, basestring):\n        struct = json.loads(struct)\n    indicative_attributes = {\n        'x': Point,\n        'wkid': SpatialReference,\n        'paths': Polyline,\n        'rings': Polygon,\n        'points': Multipoint,\n        'xmin': Envelope\n    }\n    # bbox string\n    if isinstance(struct, basestring) and len(struct.split(',')) == 4:\n        return Envelope(*map(float, struct.split(',')))\n    # Look for telltale attributes in the dict\n    if isinstance(struct, dict):\n        for key, cls in indicative_attributes.iteritems():\n            if key in struct:\n                ret = cls.fromJson(dict((str(key), value)\n                                   for (key, value) in struct.iteritems()))\n                if attributes:\n                    ret.attributes = dict((str(key.lower()), val) \n                                           for (key, val)\n                                           in attributes.iteritems())\n                return ret\n    raise ValueError(\"Unconvertible to geometry\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a GeoJSON - like struct to a Geometry based on its structure", "response": "def fromGeoJson(struct, attributes=None):\n    \"Convert a GeoJSON-like struct to a Geometry based on its structure\"\n    if isinstance(struct, basestring):\n        struct = json.loads(struct)\n    type_map = {\n        'Point': Point,\n        'MultiLineString': Polyline,\n        'LineString': Polyline,\n        'Polygon': Polygon,\n        'MultiPolygon': Polygon,\n        'MultiPoint': Multipoint,\n        'Box': Envelope\n    }\n    if struct['type'] == \"Feature\":\n        return fromGeoJson(struct, struct.get('properties', None))\n    elif struct['type'] == \"FeatureCollection\":\n        sr = None\n        if 'crs' in struct:\n            sr = SpatialReference(struct['crs']['properties']['code'])\n            members = map(fromGeoJson, struct['members'])\n            for member in members:\n                member.spatialReference = sr\n            return members\n        else:\n            return map(fromGeoJson, struct['members'])\n    elif struct['type'] in type_map and hasattr(type_map[struct['type']], \n                                              'fromGeoJson'):\n        instances = type_map[struct['type']].fromGeoJson(struct)\n        i = []\n        assert instances is not None, \"GeoJson conversion returned a Null geom\"\n        for instance in instances:\n            if 'properties' in struct:\n                instance.attributes = struct['properties'].copy()\n                if '@esri.sr' in instance.attributes:\n                    instance.spatialReference = SpatialReference.fromJson(\n                                               instance.attributes['@esri.sr'])\n                    del instance.attributes['@esri.sr']\n            if attributes:\n                if not hasattr(instance, 'attributes'):\n                    instance.attributes = {}\n                for k, v in attributes.iteritems():\n                    instance.attributes[k] = v\n            i.append(instance)\n        if i:\n            if len(i) > 1:\n                return i\n            return i[0]\n    raise ValueError(\"Unconvertible to geometry\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef name():\n        \"Get/view the name for the well known ID of a Projection\"\n        if self.wkid in projected:\n            return projected[self.wkid]\n        elif self.wkid in geographic:\n            return geographic[self.wkid]\n        else:\n            raise KeyError(\"Not a known WKID.\")", "response": "Get / view the name for the well known ID of a Projection"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests if the provided point is in the polygon.", "response": "def contains(self, pt):\n        \"Tests if the provided point is in the polygon.\"\n        if isinstance(pt, Point):\n            ptx, pty = pt.x, pt.y\n            assert (self.spatialReference is None or \\\n                    self.spatialReference.wkid is None) or \\\n                    (pt.spatialReference is None or \\\n                     pt.spatialReference.wkid is None) or \\\n                   self.spatialReference == pt.spatialReference, \\\n                   \"Spatial references do not match.\"\n        else:\n            ptx, pty = pt\n        in_shape = False\n        # Ported nearly line-for-line from the Javascript API\n        for ring in self._json_rings:\n            for idx in range(len(ring)):\n                idxp1 = idx + 1\n                if idxp1 >= len(ring):\n                    idxp1 -= len(ring)\n                pi, pj = ring[idx], ring[idxp1]\n                # Divide-by-zero checks\n                if (pi[1] == pj[1]) and pty >= min((pi[1], pj[1])):\n                    if ptx >= max((pi[0], pj[0])):\n                        in_shape = not in_shape\n                elif (pi[0] == pj[0]) and pty >= min((pi[0], pj[0])):\n                    if ptx >= max((pi[1], pj[1])):\n                        in_shape = not in_shape\n                elif (((pi[1] < pty and pj[1] >= pty) or \n                     (pj[1] < pty and pi[1] >= pty)) and \n                    (pi[0] + (pty - pi[1]) / \n                     (pj[1] - pi[1]) * (pj[0] - pi[0]) < ptx)):\n                    in_shape = not in_shape\n        return in_shape"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the envelope as a Bound Box string compatible with ( bb ) params", "response": "def bbox(self):\n        \"Return the envelope as a Bound Box string compatible with (bb) params\"\n        return \",\".join(str(attr) for attr in \n                            (self.xmin, self.ymin, self.xmax, self.ymax))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing to require that a function will run only of the blockchain is recently updated. If the chain is old, raise a StaleBlockchain exception Define how stale the chain can be with keyword arguments from datetime.timedelta, like stalecheck(web3, days=2) Turn off the staleness check at runtime with: wrapped_func(..., assertfresh=False)", "response": "def stalecheck(web3, **kwargs):\n    '''\n    Use to require that a function will run only of the blockchain is recently updated.\n\n    If the chain is old, raise a StaleBlockchain exception\n\n    Define how stale the chain can be with keyword arguments from datetime.timedelta,\n    like stalecheck(web3, days=2)\n\n    Turn off the staleness check at runtime with:\n    wrapped_func(..., assertfresh=False)\n    '''\n    allowable_delay = datetime.timedelta(**kwargs).total_seconds()\n\n    def decorator(func):\n        def wrapper(*args, assertfresh=True, **kwargs):\n            if assertfresh:\n                last_block = web3.eth.getBlock('latest')\n                if not isfresh(last_block, allowable_delay):\n                    raise StaleBlockchain(last_block, allowable_delay)\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scan(self, concurrency=1):\n        self.logger.debug(\"Scanning FS content.\")\n\n        with ThreadPoolExecutor(max_workers=concurrency) as executor:\n            results = executor.map(self.query_vulnerabilities,\n                                   self.applications())\n\n        for report in results:\n            application, vulnerabilities = report\n            vulnerabilities = list(lookup_vulnerabilities(application.version,\n                                                          vulnerabilities))\n\n            if vulnerabilities:\n                yield VulnApp(application.name,\n                              application.version,\n                              vulnerabilities)", "response": "Iterates over the files installed within the disk and returns a list of namedtuples each containing the name version and vulnerabilities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_ping(host_list, remote_user, remote_pass,\n                 sudo=False, sudo_user=None, sudo_pass=None):\n    '''\n    Execute ls on some hosts\n    '''\n    runner = spam.ansirunner.AnsibleRunner()\n    result, failed_hosts = runner.ansible_perform_operation(\n        host_list=host_list,\n        remote_user=remote_user,\n        remote_pass=remote_pass,\n        sudo=sudo,\n        sudo_pass=sudo_pass,\n        sudo_user=sudo_user,\n        module=\"ping\")\n\n    print result, failed_hosts\n    dark_hosts = runner.ansible_get_dark_hosts(result)\n    print \"dark hosts: \", dark_hosts", "response": "Execute ping on some hosts\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute_ls(host_list, remote_user, remote_pass):\n    '''\n    Execute any adhoc command on the hosts.\n    '''\n    runner = spam.ansirunner.AnsibleRunner()\n    result, failed_hosts = runner.ansible_perform_operation(\n        host_list=host_list,\n        remote_user=remote_user,\n        remote_pass=remote_pass,\n        module=\"command\",\n        module_args=\"ls -1\")\n\n    print \"Result: \", result", "response": "Execute any adhoc command on the hosts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compiler_preprocessor_verbose(compiler, extraflags):\n    lines = []\n    with open(os.devnull, 'r') as devnull:\n        cmd = [compiler, '-E'] \n        cmd += extraflags\n        cmd += ['-', '-v']\n        p = Popen(cmd, stdin=devnull, stdout=PIPE, stderr=PIPE)\n        p.wait()\n        p.stdout.close()\n        lines = p.stderr.read()\n        lines = lines.decode('utf-8')\n        lines = lines.splitlines()\n    return lines", "response": "Capture the compiler preprocessor stage in verbose mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform(self, col):\n\n        out = pd.DataFrame(index=col.index)\n        out[self.col_name] = col.apply(self.get_val, axis=1)\n\n        if self.subtype == 'int':\n            out[self.col_name] = out[self.col_name].astype(int)\n\n        return out", "response": "Prepare the transformer to convert data and return the processed table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse_transform(self, col):\n\n        output = pd.DataFrame(index=col.index)\n        output[self.col_name] = col.apply(self.safe_round, axis=1)\n\n        if self.subtype == 'int':\n            output[self.col_name] = output[self.col_name].astype(int)\n\n        return output", "response": "Converts data back into original format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a converter that takes in a value and turns it into an integer if necessary.", "response": "def safe_round(self, x):\n        \"\"\"Returns a converter that takes in a value and turns it into an integer, if necessary.\n\n        Args:\n            col_name(str): Name of the column.\n            subtype(str): Numeric subtype of the values.\n\n        Returns:\n            function\n        \"\"\"\n        val = x[self.col_name]\n\n        if np.isposinf(val):\n            val = sys.maxsize\n\n        elif np.isneginf(val):\n            val = -sys.maxsize\n\n        if np.isnan(val):\n            val = self.default_val\n\n        if self.subtype == 'integer':\n            return int(round(val))\n\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninvoking the rados df command and return output to user", "response": "def rados_df(self,\n                 host_list=None,\n                 remote_user=None,\n                 remote_pass=None):\n        '''\n        Invoked the rados df command and return output to user\n        '''\n        result, failed_hosts = self.runner.ansible_perform_operation(\n            host_list=host_list,\n            remote_user=remote_user,\n            remote_pass=remote_pass,\n            module=\"command\",\n            module_args=\"rados df\")\n\n        parsed_result = self.rados_parse_df(result)\n\n        return parsed_result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the result from ansirunner module and save it as a json object.", "response": "def rados_parse_df(self,\n                       result):\n        '''\n        Parse the result from ansirunner module and save it as a json\n        object\n        '''\n        parsed_results = []\n        HEADING = r\".*(pool name) *(category) *(KB) *(objects) *(clones)\" + \\\n            \" *(degraded) *(unfound) *(rd) *(rd KB) *(wr) *(wr KB)\"\n\n        HEADING_RE = re.compile(HEADING,\n                                re.IGNORECASE)\n\n        dict_keys = [\"pool_name\", \"category\", \"size_kb\", \"objects\",\n                     \"clones\", \"degraded\", \"unfound\", \"rd\", \"rd_kb\",\n                     \"wr\", \"wr_kb\"]\n\n        if result['contacted'].keys():\n            for node in result['contacted'].keys():\n                df_result = {}\n                nodeobj = result['contacted'][node]\n                df_output = nodeobj['stdout']\n                for line in df_output.splitlines():\n                    print \"Line: \", line\n                    # Skip the heading line.\n                    reobj = HEADING_RE.match(line)\n                    if not reobj:\n                        row = line.split()\n                        if len(row) != len(dict_keys):\n                            print \"line not match: \", line\n                            continue\n\n                        key_count = 0\n                        for column in row:\n                            df_result[dict_keys[key_count]] = column\n                            key_count += 1\n                        print \"df_result: \", df_result\n                        parsed_results.append(df_result)\n\n                    nodeobj['parsed_results'] = parsed_results\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_roles_gce(use_cache=True, cache_expiration=86400, cache_path=\"~/.gcetools/instances\", group_name=None, region=None, zone=None):\n    data = _get_data(use_cache, cache_expiration, group_name=group_name, region=region, zone=zone)\n    roles = _get_roles(data)\n    env.roledefs.update(roles)\n\n    _data_loaded = True\n    return INSTANCES_CACHE", "response": "Dynamically update the roles of each instance in the GCE environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eventsource_connect(url, io_loop=None, callback=None, connect_timeout=None):\n    if io_loop is None:\n        io_loop = IOLoop.current()\n    if isinstance(url, httpclient.HTTPRequest):\n        assert connect_timeout is None\n        request = url\n        # Copy and convert the headers dict/object (see comments in\n        # AsyncHTTPClient.fetch)\n        request.headers = httputil.HTTPHeaders(request.headers)\n    else:\n        request = httpclient.HTTPRequest(\n            url,\n            connect_timeout=connect_timeout,\n            headers=httputil.HTTPHeaders({\n                \"Accept-Encoding\": \"identity\"\n            })\n        )\n    request = httpclient._RequestProxy(\n        request, httpclient.HTTPRequest._DEFAULTS)\n    conn = EventSourceClient(io_loop, request)\n    if callback is not None:\n        io_loop.add_future(conn.connect_future, callback)\n    return conn.connect_future", "response": "Client - side eventsource support. Takes a url and returns a Future whose result is a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nact on message reception :param message: string of an incoming message parse all the fields and builds an Event object that is passed to the callback function", "response": "def handle_stream(self, message):\n        \"\"\"\n        Acts on message reception\n        :param message: string of an incoming message\n\n        parse all the fields and builds an Event object that is passed to the callback function\n        \"\"\"\n        logging.debug(\"handle_stream(...)\")\n\n        event = Event()\n        for line in message.strip().splitlines():\n            (field, value) = line.split(\":\", 1)\n            field = field.strip()\n\n            if field == \"event\":\n                event.name = value.lstrip()\n            elif field == \"data\":\n                value = value.lstrip()\n                if event.data is None:\n                    event.data = value\n                else:\n                    event.data = \"%s\\n%s\" % (event.data, value)\n            elif field == \"id\":\n                event.id = value.lstrip()\n                self.last_event_id = event.id\n            elif field == \"retry\":\n                try:\n                    self.retry_timeout = int(value)\n                    event.retry = self.retry_timeout\n                    logging.info(\"timeout reset: %s\" % (value,))\n                except ValueError:\n                    pass\n            elif field == \"\":\n                logging.debug(\"received comment: %s\" % (value,))\n            else:\n                raise Exception(\"Unknown field !\")\n        self.events.append(event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints out the given arguments.", "response": "def printout(*args, **kwargs):\n    \"\"\"\n    Print function with extra options for formating text in terminals.\n    \"\"\"\n\n    # TODO(Lukas): conflicts with function names\n    color = kwargs.pop('color', {})\n    style = kwargs.pop('style', {})\n    prefx = kwargs.pop('prefix', '')\n    suffx = kwargs.pop('suffix', '')\n    ind = kwargs.pop('indent', 0)\n\n    print_args = []\n    for arg in args:\n        arg = str(arg)\n        arg = colorize(arg, **color)\n        arg = stylize(arg, **style)\n        arg = prefix(arg, prefx)\n        arg = indent(arg, ind)\n        arg += str(suffx)\n        print_args.append(arg)\n\n    print(*print_args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint escape codes to set the terminal color. fg and bg are indices into the color palette for the foreground and background colors.", "response": "def colorize(txt, fg=None, bg=None):\n    \"\"\"\n    Print escape codes to set the terminal color.\n\n    fg and bg are indices into the color palette for the foreground and\n    background colors.\n    \"\"\"\n\n    setting = ''\n    setting += _SET_FG.format(fg) if fg else ''\n    setting += _SET_BG.format(bg) if bg else ''\n    return setting + str(txt) + _STYLE_RESET"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stylize(txt, bold=False, underline=False):\n\n    setting = ''\n    setting += _SET_BOLD if bold is True else ''\n    setting += _SET_UNDERLINE if underline is True else ''\n    return setting + str(txt) + _STYLE_RESET", "response": "Changes style of the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef indent(txt, spacing=4):\n    return prefix(str(txt), ''.join([' ' for _ in range(spacing)]))", "response": "Indent given text using custom spacing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rgb(red, green, blue):\n    for value in (red, green, blue):\n        if value not in range(6):\n            raise ColorError('Value must be within 0-5, was {}.'.format(value))\n    return 16 + (red * 36) + (green * 6) + blue", "response": "Calculate the palette index of a color in the 6x6x6 color cube."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isUTF8Strict(data):     # pragma: no cover - Only used when cchardet is missing.\n\t'''\n\tCheck if all characters in a bytearray are decodable\n\tusing UTF-8.\n\t'''\n\ttry:\n\t\tdecoded = data.decode('UTF-8')\n\texcept UnicodeDecodeError:\n\t\treturn False\n\telse:\n\t\tfor ch in decoded:\n\t\t\tif 0xD800 <= ord(ch) <= 0xDFFF:\n\t\t\t\treturn False\n\t\treturn True", "response": "Check if a bytearray is UTF - 8 strict."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode_headers(header_list):\n\t'''\n\tDecode a list of headers.\n\n\tTakes a list of bytestrings, returns a list of unicode strings.\n\tThe character set for each bytestring is individually decoded.\n\t'''\n\n\tdecoded_headers = []\n\tfor header in header_list:\n\t\tif cchardet:\n\t\t\tinferred = cchardet.detect(header)\n\t\t\tif inferred and inferred['confidence'] > 0.8:\n\t\t\t\t# print(\"Parsing headers!\", header)\n\t\t\t\tdecoded_headers.append(header.decode(inferred['encoding']))\n\t\t\telse:\n\t\t\t\tdecoded_headers.append(header.decode('iso-8859-1'))\n\t\telse:    # pragma: no cover\n\t\t\t# All bytes are < 127 (e.g. ASCII)\n\t\t\tif all([char & 0x80 == 0 for char in header]):\n\t\t\t\tdecoded_headers.append(header.decode(\"us-ascii\"))\n\t\t\telif isUTF8Strict(header):\n\t\t\t\tdecoded_headers.append(header.decode(\"utf-8\"))\n\t\t\telse:\n\t\t\t\tdecoded_headers.append(header.decode('iso-8859-1'))\n\n\treturn decoded_headers", "response": "Decode a list of headers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_headers(fp, _class=http.client.HTTPMessage):\n\theaders = []\n\twhile True:\n\t\tline = fp.readline(http.client._MAXLINE + 1)\n\t\tif len(line) > http.client._MAXLINE:\n\t\t\traise http.client.LineTooLong(\"header line\")\n\t\theaders.append(line)\n\t\tif len(headers) > http.client._MAXHEADERS:\n\t\t\traise HTTPException(\"got more than %d headers\" % http.client._MAXHEADERS)\n\t\tif line in (b'\\r\\n', b'\\n', b''):\n\t\t\tbreak\n\n\tdecoded_headers = decode_headers(headers)\n\n\thstring = ''.join(decoded_headers)\n\n\treturn email.parser.Parser(_class=_class).parsestr(hstring)", "response": "Parses only RFC2822 headers from a file pointer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush to github. com", "response": "def push(tool, slug, config_loader, prompt=lambda included, excluded: True):\n    \"\"\"\n    Push to github.com/org/repo=username/slug if tool exists.\n    Returns username, commit hash\n    \"\"\"\n    check_dependencies()\n\n    org, (included, excluded) = connect(slug, config_loader)\n\n    with authenticate(org) as user, prepare(tool, slug, user, included):\n        if prompt(included, excluded):\n            return upload(slug, user, tool)\n        else:\n            raise Error(_(\"No files were submitted.\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate local copy of github. com. org. repo branch.", "response": "def local(tool, slug, config_loader, offline=False):\n    \"\"\"\n    Create/update local copy of github.com/org/repo/branch.\n    Returns path to local copy\n    \"\"\"\n    # Parse slug\n    slug = Slug(slug, offline=offline)\n\n    local_path = Path(LOCAL_PATH).expanduser() / slug.org / slug.repo\n\n    git = Git(f\"-C {shlex.quote(str(local_path))}\")\n    if not local_path.exists():\n        _run(Git()(f\"init {shlex.quote(str(local_path))}\"))\n        _run(git(f\"remote add origin https://github.com/{slug.org}/{slug.repo}\"))\n\n    if not offline:\n        # Get latest version of checks\n        _run(git(f\"fetch origin {slug.branch}\"))\n\n    # Ensure that local copy of the repo is identical to remote copy\n    _run(git(f\"checkout -f -B {slug.branch} origin/{slug.branch}\"))\n    _run(git(f\"reset --hard HEAD\"))\n\n    problem_path = (local_path / slug.problem).absolute()\n\n    if not problem_path.exists():\n        raise InvalidSlugError(_(\"{} does not exist at {}/{}\").format(slug.problem, slug.org, slug.repo))\n\n    # Get config\n    try:\n        with open(problem_path / \".cs50.yaml\") as f:\n            try:\n                config = config_loader.load(f.read())\n            except InvalidConfigError:\n                raise InvalidSlugError(\n                    _(\"Invalid slug for {}. Did you mean something else?\").format(tool))\n    except FileNotFoundError:\n        raise InvalidSlugError(_(\"Invalid slug. Did you mean something else?\"))\n\n    return problem_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield a temporary directory containing all files in files.", "response": "def working_area(files, name=\"\"):\n    \"\"\"\n    Copy all files to a temporary directory (the working area)\n    Optionally names the working area name\n    Returns path to the working area\n    \"\"\"\n    with tempfile.TemporaryDirectory() as dir:\n        dir = Path(Path(dir) / name)\n        dir.mkdir(exist_ok=True)\n\n        for f in files:\n            dest = (dir / f).absolute()\n            dest.parent.mkdir(parents=True, exist_ok=True)\n            shutil.copy(f, dest)\n        yield dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cd(dest):\n    origin = os.getcwd()\n    try:\n        os.chdir(dest)\n        yield dest\n    finally:\n        os.chdir(origin)", "response": "Temporarily cd into a directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef files(patterns,\n          require_tags=(\"require\",),\n          include_tags=(\"include\",),\n          exclude_tags=(\"exclude\",),\n          root=\".\",\n          always_exclude=(\"**/.git*\", \"**/.lfs*\", \"**/.c9*\", \"**/.~c9*\")):\n    \"\"\"\n    Takes a list of lib50._config.TaggedValue returns which files should be included and excluded from `root`.\n    Any pattern tagged with a tag\n        from include_tags will be included\n        from require_tags can only be a file, that will then be included. MissingFilesError is raised if missing\n        from exclude_tags will be excluded\n    Any pattern in always_exclude will always be excluded.\n    \"\"\"\n    require_tags = list(require_tags)\n    include_tags = list(include_tags)\n    exclude_tags = list(exclude_tags)\n\n    # Ensure every tag starts with !\n    for tags in [require_tags, include_tags, exclude_tags]:\n        for i, tag in enumerate(tags):\n            tags[i] = tag if tag.startswith(\"!\") else \"!\" + tag\n\n    with cd(root):\n        # Include everything by default\n        included = _glob(\"*\")\n        excluded = set()\n\n        if patterns:\n            missing_files = []\n\n            # Per line in files\n            for pattern in patterns:\n                # Include all files that are tagged with !require\n                if pattern.tag in require_tags:\n                    file = str(Path(pattern.value))\n                    if not Path(file).exists():\n                        missing_files.append(file)\n                    else:\n                        try:\n                            excluded.remove(file)\n                        except KeyError:\n                            pass\n                        else:\n                            included.add(file)\n                # Include all files that are tagged with !include\n                elif pattern.tag in include_tags:\n                    new_included = _glob(pattern.value)\n                    excluded -= new_included\n                    included.update(new_included)\n                # Exclude all files that are tagged with !exclude\n                elif pattern.tag in exclude_tags:\n                    new_excluded = _glob(pattern.value)\n                    included -= new_excluded\n                    excluded.update(new_excluded)\n\n            if missing_files:\n                raise MissingFilesError(missing_files)\n\n    # Exclude all files that match a pattern from always_exclude\n    for line in always_exclude:\n        included -= _glob(line)\n\n    # Exclude any files that are not valid utf8\n    invalid = set()\n    for file in included:\n        try:\n            file.encode(\"utf8\")\n        except UnicodeEncodeError:\n            excluded.add(file.encode(\"utf8\", \"replace\").decode())\n            invalid.add(file)\n    included -= invalid\n\n    return included, excluded", "response": "Takes a list of lib50. _config. TaggedValue returns which files should be included and excluded from root."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to a specific version of a single. cs50. yaml file.", "response": "def connect(slug, config_loader):\n    \"\"\"\n    Ensure .cs50.yaml and tool key exists, raises Error otherwise\n    Check that all required files as per .cs50.yaml are present\n    Returns tool specific portion of .cs50.yaml\n    \"\"\"\n    with ProgressBar(_(\"Connecting\")):\n        # Parse slug\n        slug = Slug(slug)\n\n        # Get .cs50.yaml\n        try:\n            config = config_loader.load(_get_content(slug.org, slug.repo,\n                                              slug.branch, slug.problem / \".cs50.yaml\"))\n        except InvalidConfigError:\n            raise InvalidSlugError(_(\"Invalid slug for {}. Did you mean something else?\").format(config_loader.tool))\n\n        print(\"WTF!!!!\", config)\n\n        if not config:\n            raise InvalidSlugError(_(\"Invalid slug for {}. Did you mean something else?\").format(config_loader.tool))\n\n        # If config of tool is just a truthy value, config should be empty\n        if not isinstance(config, dict):\n            config = {}\n\n        org = config.get(\"org\", config_loader.tool)\n        included, excluded = files(config.get(\"files\"))\n\n        # Check that at least 1 file is staged\n        if not included:\n            raise Error(_(\"No files in this directory are expected for submission.\"))\n\n        return org, (included, excluded)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nauthenticate with GitHub if possible Otherwise authenticate via HTTPS if possible", "response": "def authenticate(org):\n    \"\"\"\n    Authenticate with GitHub via SSH if possible\n    Otherwise authenticate via HTTPS\n    Returns an authenticated User\n    \"\"\"\n    with ProgressBar(_(\"Authenticating\")) as progress_bar:\n        user = _authenticate_ssh(org)\n        progress_bar.stop()\n        if user is None:\n            # SSH auth failed, fallback to HTTPS\n            with _authenticate_https(org) as user:\n                yield user\n        else:\n            yield user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprepare git for pushing a necessities file to a branch", "response": "def prepare(tool, branch, user, included):\n    \"\"\"\n    Prepare git for pushing\n    Check that there are no permission errors\n    Add necessities to git config\n    Stage files\n    Stage files via lfs if necessary\n    Check that atleast one file is staged\n    \"\"\"\n    with ProgressBar(_(\"Preparing\")) as progress_bar, working_area(included) as area:\n        Git.working_area = f\"-C {area}\"\n        git = Git(Git.working_area)\n        # Clone just .git folder\n        try:\n            _run(git.set(Git.cache)(f\"clone --bare {user.repo} .git\"))\n        except Error:\n            raise Error(_(\"Looks like {} isn't enabled for your account yet. \"\n                          \"Go to https://cs50.me/authorize and make sure you accept any pending invitations!\".format(tool)))\n\n        _run(git(\"config --bool core.bare false\"))\n        _run(git(f\"config --path core.worktree {area}\"))\n\n        try:\n            _run(git(\"checkout --force {} .gitattributes\".format(branch)))\n        except Error:\n            pass\n\n        # Set user name/email in repo config\n        _run(git(f\"config user.email {shlex.quote(user.email)}\"))\n        _run(git(f\"config user.name {shlex.quote(user.name)}\"))\n\n        # Switch to branch without checkout\n        _run(git(f\"symbolic-ref HEAD refs/heads/{branch}\"))\n\n        # Git add all included files\n        for f in included:\n            _run(git(f\"add {f}\"))\n\n        # Remove gitattributes from included\n        if Path(\".gitattributes\").exists() and \".gitattributes\" in included:\n            included.remove(\".gitattributes\")\n\n        # Add any oversized files through git-lfs\n        _lfs_add(included, git)\n\n        progress_bar.stop()\n        yield"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upload(branch, user, tool):\n    with ProgressBar(_(\"Uploading\")):\n        language = os.environ.get(\"LANGUAGE\")\n        commit_message = [_(\"automated commit by {}\").format(tool)]\n\n        # If LANGUAGE environment variable is set, we need to communicate\n        # this to any remote tool via the commit message.\n        if language:\n            commit_message.append(f\"[{language}]\")\n\n        commit_message = \" \".join(commit_message)\n\n        # Commit + push\n        git = Git(Git.working_area)\n        _run(git(f\"commit -m {shlex.quote(commit_message)} --allow-empty\"))\n        _run(git.set(Git.cache)(f\"push origin {branch}\"))\n        commit_hash = _run(git(\"rev-parse HEAD\"))\n        return user.name, commit_hash", "response": "Upload a new branch to the remote tool"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the dependencies are installed and that git is installed and that credential - cache - daemon ignores SIGHUP", "response": "def check_dependencies():\n    \"\"\"\n    Check that dependencies are installed:\n    - require git 2.7+, so that credential-cache--daemon ignores SIGHUP\n        https://github.com/git/git/blob/v2.7.0/credential-cache--daemon.c\n    \"\"\"\n\n    # Check that git is installed\n    if not shutil.which(\"git\"):\n        raise Error(_(\"You don't have git. Install git, then re-run!\"))\n\n    # Check that git --version > 2.7\n    version = subprocess.check_output([\"git\", \"--version\"]).decode(\"utf-8\")\n    matches = re.search(r\"^git version (\\d+\\.\\d+\\.\\d+).*$\", version)\n    if not matches or pkg_resources.parse_version(matches.group(1)) < pkg_resources.parse_version(\"2.7.0\"):\n        raise Error(_(\"You have an old version of git. Install version 2.7 or later, then re-run!\"))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _run(command, quiet=False, timeout=None):\n    try:\n        with _spawn(command, quiet, timeout) as child:\n            command_output = child.read().strip().replace(\"\\r\\n\", \"\\n\")\n    except pexpect.TIMEOUT:\n        logger.info(f\"command {command} timed out\")\n        raise Error()\n\n    return command_output", "response": "Run a command returns command output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _glob(pattern, skip_dirs=False):\n    # Implicit recursive iff no / in pattern and starts with *\n    if \"/\" not in pattern and pattern.startswith(\"*\"):\n        files = glob.glob(f\"**/{pattern}\", recursive=True)\n    else:\n        files = glob.glob(pattern, recursive=True)\n\n    # Expand dirs\n    all_files = set()\n    for file in files:\n        if os.path.isdir(file) and not skip_dirs:\n            all_files.update(set(f for f in _glob(f\"{file}/**/*\", skip_dirs=True) if not os.path.isdir(f)))\n        else:\n            all_files.add(file)\n\n    # Normalize all files\n    return {str(Path(f)) for f in all_files}", "response": "Glob pattern expand directories return all files that matched."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_content(org, repo, branch, filepath):\n    url = \"https://github.com/{}/{}/raw/{}/{}\".format(org, repo, branch, filepath)\n    r = requests.get(url)\n    if not r.ok:\n        if r.status_code == 404:\n            raise InvalidSlugError(_(\"Invalid slug. Did you mean to submit something else?\"))\n        else:\n            raise Error(_(\"Could not connect to GitHub.\"))\n    return r.content", "response": "Get all content from org / repo branch / filepath at GitHub."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _lfs_add(files, git):\n    # Check for large files > 100 MB (and huge files > 2 GB)\n    # https://help.github.com/articles/conditions-for-large-files/\n    # https://help.github.com/articles/about-git-large-file-storage/\n    larges, huges = [], []\n    for file in files:\n        size = os.path.getsize(file)\n        if size > (100 * 1024 * 1024):\n            larges.append(file)\n        elif size > (2 * 1024 * 1024 * 1024):\n            huges.append(file)\n\n    # Raise Error if a file is >2GB\n    if huges:\n        raise Error(_(\"These files are too large to be submitted:\\n{}\\n\"\n                      \"Remove these files from your directory \"\n                      \"and then re-run {}!\").format(\"\\n\".join(huges), org))\n\n    # Add large files (>100MB) with git-lfs\n    if larges:\n        # Raise Error if git-lfs not installed\n        if not shutil.which(\"git-lfs\"):\n            raise Error(_(\"These files are too large to be submitted:\\n{}\\n\"\n                          \"Install git-lfs (or remove these files from your directory) \"\n                          \"and then re-run!\").format(\"\\n\".join(larges)))\n\n        # Install git-lfs for this repo\n        _run(git(\"lfs install --local\"))\n\n        # For pre-push hook\n        _run(git(\"config credential.helper cache\"))\n\n        # Rm previously added file, have lfs track file, add file again\n        for large in larges:\n            _run(git(\"rm --cached {}\".format(shlex.quote(large))))\n            _run(git(\"lfs track {}\".format(shlex.quote(large))))\n            _run(git(\"add {}\".format(shlex.quote(large))))\n        _run(git(\"add --force .gitattributes\"))", "response": "Add any oversized files with lfs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _authenticate_ssh(org):\n    # Try to get username from git config\n    username = os.environ.get(f\"{org.upper()}_USERNAME\")\n    # Require ssh-agent\n    child = pexpect.spawn(\"ssh -T git@github.com\", encoding=\"utf8\")\n    # GitHub prints 'Hi {username}!...' when attempting to get shell access\n    i = child.expect([\"Hi (.+)! You've successfully authenticated\",\n                      \"Enter passphrase for key\",\n                      \"Permission denied\",\n                      \"Are you sure you want to continue connecting\"])\n    child.close()\n\n    if i == 0:\n        if username is None:\n            username = child.match.groups()[0]\n    else:\n        return None\n\n    return User(name=username,\n                repo=f\"git@github.com:{org}/{username}\")", "response": "Try authenticating via ssh if succesful yields a User otherwise raises Error"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _authenticate_https(org):\n    _CREDENTIAL_SOCKET.parent.mkdir(mode=0o700, exist_ok=True)\n    try:\n        Git.cache = f\"-c credential.helper= -c credential.helper='cache --socket {_CREDENTIAL_SOCKET}'\"\n        git = Git(Git.cache)\n\n        # Get credentials from cache if possible\n        with _spawn(git(\"credential fill\"), quiet=True) as child:\n            child.sendline(\"protocol=https\")\n            child.sendline(\"host=github.com\")\n            child.sendline(\"\")\n            i = child.expect([\"Username for '.+'\", \"Password for '.+'\",\n                              \"username=([^\\r]+)\\r\\npassword=([^\\r]+)\\r\\n\"])\n            if i == 2:\n                username, password = child.match.groups()\n            else:\n                username = password = None\n                child.close()\n                child.exitstatus = 0\n\n        # No credentials found, need to ask user\n        if password is None:\n            username = _prompt_username(_(\"GitHub username: \"))\n            password = _prompt_password(_(\"GitHub password: \"))\n\n        # Check if credentials are correct\n        res = requests.get(\"https://api.github.com/user\", auth=(username, password))\n\n        # Check for 2-factor authentication https://developer.github.com/v3/auth/#working-with-two-factor-authentication\n        if \"X-GitHub-OTP\" in res.headers:\n            raise Error(\"Looks like you have two-factor authentication enabled!\"\n                        \" Please generate a personal access token and use it as your password.\"\n                        \" See https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line for more info.\")\n\n        if res.status_code != 200:\n            logger.info(res.headers)\n            logger.info(res.text)\n            raise Error(_(\"Invalid username and/or password.\") if res.status_code ==\n                        401 else _(\"Could not authenticate user.\"))\n\n        # Canonicalize (capitalization of) username,\n        # Especially if user logged in via email address\n        username = res.json()[\"login\"]\n\n        # Credentials are correct, best cache them\n        with _spawn(git(\"-c credentialcache.ignoresighup=true credential approve\"), quiet=True) as child:\n            child.sendline(\"protocol=https\")\n            child.sendline(\"host=github.com\")\n            child.sendline(f\"path={org}/{username}\")\n            child.sendline(f\"username={username}\")\n            child.sendline(f\"password={password}\")\n            child.sendline(\"\")\n\n        yield User(name=username,\n                   repo=f\"https://{username}@github.com/{org}/{username}\")\n    except BaseException:\n        # Some error occured while this context manager is active, best forget credentials.\n        logout()\n        raise", "response": "Try authenticating via HTTPS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprompt the user for username.", "response": "def _prompt_username(prompt=\"Username: \", prefill=None):\n    \"\"\"Prompt the user for username.\"\"\"\n    if prefill:\n        readline.set_startup_hook(lambda: readline.insert_text(prefill))\n\n    try:\n        return input(prompt).strip()\n    except EOFError:\n        print()\n    finally:\n        readline.set_startup_hook()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprompts the user for password", "response": "def _prompt_password(prompt=\"Password: \"):\n    \"\"\"Prompt the user for password, printing asterisks for each character\"\"\"\n    fd = sys.stdin.fileno()\n    old_settings = termios.tcgetattr(fd)\n    tty.setraw(fd)\n\n    print(prompt, end=\"\", flush=True)\n    password = []\n    try:\n        while True:\n            ch = sys.stdin.buffer.read(1)[0]\n            if ch in (ord(\"\\r\"), ord(\"\\n\"), 4):  # If user presses Enter or ctrl-d\n                print(\"\\r\")\n                break\n            elif ch == 127:  # DEL\n                try:\n                    password.pop()\n                except IndexError:\n                    pass\n                else:\n                    print(\"\\b \\b\", end=\"\", flush=True)\n            elif ch == 3:  # ctrl-c\n                print(\"^C\", end=\"\", flush=True)\n                raise KeyboardInterrupt\n            else:\n                password.append(ch)\n                print(\"*\", end=\"\", flush=True)\n    finally:\n        termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n\n    return bytes(password).decode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_endings(self):\n        if self.slug.startswith(\"/\") and self.slug.endswith(\"/\"):\n            raise InvalidSlugError(\n                _(\"Invalid slug. Did you mean {}, without the leading and trailing slashes?\".format(self.slug.strip(\"/\"))))\n        elif self.slug.startswith(\"/\"):\n            raise InvalidSlugError(\n                _(\"Invalid slug. Did you mean {}, without the leading slash?\".format(self.slug.strip(\"/\"))))\n        elif self.slug.endswith(\"/\"):\n            raise InvalidSlugError(\n                _(\"Invalid slug. Did you mean {}, without the trailing slash?\".format(self.slug.strip(\"/\"))))", "response": "Check begin and end of slug raises Error if malformed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_branches(self):\n        if self.offline:\n            local_path = Path(LOCAL_PATH).expanduser() / self.org / self.repo\n            get_refs = f\"git -C {shlex.quote(str(local_path))} show-ref --heads\"\n        else:\n            get_refs = f\"git ls-remote --heads https://github.com/{self.org}/{self.repo}\"\n        try:\n            # Parse get_refs output for the actual branch names\n            return (line.split()[1].replace(\"refs/heads/\", \"\") for line in _run(get_refs, timeout=3).split(\"\\n\"))\n        except Error:\n            return []", "response": "Get branches from org or repo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n        if self._progressing:\n            self._progressing = False\n            self._thread.join()", "response": "Stop the progress bar."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a URL given a path and optionally a protocol and set of hosts to select from randomly.", "response": "def make_url(path, protocol=None, hosts=None):\n    \"\"\"Make an URL given a path, and optionally, a protocol and set of\n    hosts to select from randomly.\n\n    :param path: The Archive.org path.\n    :type path: str\n\n    :param protocol: (optional) The HTTP protocol to use. \"https://\" is\n                     used by default.\n    :type protocol: str\n\n    :param hosts: (optional) A set of hosts. A host will be chosen at\n                  random. The default host is \"archive.org\".\n    :type hosts: iterable\n\n    :rtype: str\n    :returns: An Absolute URI.\n    \"\"\"\n    protocol = 'https://' if not protocol else protocol\n    host = hosts[random.randrange(len(hosts))] if hosts else 'archive.org'\n    return protocol + host + path.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the URLs for the archive. org metadata files.", "response": "def metadata_urls(identifiers, protocol=None, hosts=None):\n    \"\"\"An Archive.org metadata URL generator.\n\n    :param identifiers: A set of Archive.org identifiers for which to\n                        make metadata URLs.\n    :type identifiers: iterable\n\n    :param protocol: (optional) The HTTP protocol to use. \"https://\" is\n                     used by default.\n    :type protocol: str\n\n    :param hosts: (optional) A set of hosts. A host will be chosen at\n                  random. The default host is \"archive.org\".\n    :type hosts: iterable\n\n    :returns: A generator yielding Archive.org metadata URLs.\n    \"\"\"\n    for identifier in identifiers:\n        path = '/metadata/{}'.format(identifier)\n        url = make_url(path, protocol, hosts)\n        yield url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lang_direction(request):\n    if lang_direction.rtl_langs is None:\n        lang_direction.rtl_langs = getattr(settings, \"RTL_LANGUAGES\", set())\n\n    return {\"lang_direction\": \"rtl\" if request.LANGUAGE_CODE in lang_direction.rtl_langs else \"ltr\"}", "response": "Returns a dictionary of context variables that maps the language code to the language direction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the top - level lists available from the API.", "response": "def lists(self, **kwargs):\n        \"\"\"Gets the top-level lists available from the API.\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('lists')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the movie lists available from the API.", "response": "def movie_lists(self, **kwargs):\n        \"\"\"Gets the movie lists available from the API.\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('movie_lists')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef movies_box_office(self, **kwargs):\n        path = self._get_path('movies_box_office')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the top box office earning movies from the API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef movies_in_theaters(self, **kwargs):\n        path = self._get_path('movies_in_theaters')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the movies currently in theaters from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current opening movies from the API.", "response": "def movies_opening(self, **kwargs):\n        \"\"\"Gets the current opening movies from the API.\n\n        Args:\n          limit (optional): limits the number of movies returned, default=10\n          country (optional): localized data for selected country, default=\"us\"\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('movies_opening')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef movies_upcoming(self, **kwargs):\n        path = self._get_path('movies_upcoming')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the upcoming movies from the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the dvd lists available from the API.", "response": "def dvd_lists(self, **kwargs):\n        \"\"\"Gets the dvd lists available from the API.\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('dvd_lists')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dvds_top_rentals(self, **kwargs):\n        path = self._get_path('dvds_top_rentals')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the current opening movies from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the upcoming movies from the API.", "response": "def dvds_current_releases(self, **kwargs):\n        \"\"\"Gets the upcoming movies from the API.\n\n        Args:\n          page_limit (optional): number of movies to show per page, default=16\n          page (optional): results page number, default=1\n          country (optional): localized data for selected country, default=\"us\"\n\n        Returns:\n          A dict respresentation of the JSON returned from the API.\n        \"\"\"\n        path = self._get_path('dvds_current_releases')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dvds_new_releases(self, **kwargs):\n        path = self._get_path('dvds_new_releases')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the upcoming movies from the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dvds_upcoming(self, **kwargs):\n        path = self._get_path('dvds_upcoming')\n\n        response = self._GET(path, kwargs)\n        self._set_attrs_to_values(response)\n        return response", "response": "Gets the upcoming movies from the API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef code_to_unicode(code):\n    def utf32chr(n):\n        \"\"\"utf32char for narrow build python\"\"\"\n        return eval(\"u\\'\\\\U%08X\\'\" % n)\n    def lazy_unichr(n):\n        try:\n            return unichr(n)\n        except ValueError:\n            warnings.warn(\"Your python it built as narrow python. Make with \"\n                \"'--enable-unicode=ucs4' configure option to build wide python\")\n            return utf32chr(n)\n    if code and isinstance(code, basestring):\n        clean_code = code.replace('>', '')\n        if clean_code:\n            return u''.join([lazy_unichr(int(code_char, 16)) for code_char in clean_code.split('+') if code_char])\n    return None", "response": "Convert character code to unicode"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_regex_patterns(symbols):\n    pattern_unicode = []\n    pattern_google = []\n    pattern_docomo = []\n    pattern_kddi = []\n    pattern_softbank = []\n    for x in symbols:\n        if x.unicode.code: pattern_unicode.append(re.escape(unicode(x.unicode)))\n        if x.google.code: pattern_google.append(re.escape(unicode(x.google)))\n        if x.docomo.code: pattern_docomo.append(re.escape(unicode(x.docomo)))\n        if x.kddi.code: pattern_kddi.append(re.escape(unicode(x.kddi)))\n        if x.softbank.code: pattern_softbank.append(re.escape(unicode(x.softbank)))\n#    pattern_unicode = re.compile(u\"[%s]\" % u''.join(pattern_unicode))\n#    pattern_google = re.compile(u\"[%s]\" % u''.join(pattern_google))\n#    pattern_docomo = re.compile(u\"[%s]\" % u''.join(pattern_docomo))\n#    pattern_kddi = re.compile(u\"[%s]\" % u''.join(pattern_kddi))\n#    pattern_softbank = re.compile(u\"[%s]\" % u''.join(pattern_softbank))\n    pattern_unicode = re.compile(u\"%s\" % u'|'.join(pattern_unicode))\n    pattern_google = re.compile(u\"%s\" % u'|'.join(pattern_google))\n    pattern_docomo = re.compile(u\"%s\" % u'|'.join(pattern_docomo))\n    pattern_kddi = re.compile(u\"%s\" % u'|'.join(pattern_kddi))\n    pattern_softbank = re.compile(u\"%s\" % u'|'.join(pattern_softbank))\n    return {\n        #                forward            reverse\n        'text':         (None,              pattern_unicode),\n        'docomo_img':   (None,              pattern_unicode),\n        'kddi_img':     (None,              pattern_unicode),\n        'softbank_img': (None,              pattern_unicode),\n        'google':       (pattern_google,    pattern_unicode),\n        'docomo':       (pattern_docomo,    pattern_unicode),\n        'kddi':         (pattern_kddi,      pattern_unicode),\n        'softbank':     (pattern_softbank,  pattern_unicode),\n    }", "response": "u create regex patterns for text google docomo kddi and softbank via symbols"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a query dealing with errors and throttling requests.", "response": "def vtquery(apikey, checksums):\n    \"\"\"Performs the query dealing with errors and throttling requests.\"\"\"\n    data = {'apikey': apikey,\n            'resource': isinstance(checksums, str) and checksums\n                        or ', '.join(checksums)}\n\n    while 1:\n        response = requests.post(VT_REPORT_URL, data=data)\n        response.raise_for_status()\n\n        if response.status_code == 200:\n            return response.json()\n        elif response.status_code == 204:\n            logging.debug(\"API key request rate limit reached, throttling.\")\n            time.sleep(VT_THROTTLE)\n        else:\n            raise RuntimeError(\"Response status code %s\" % response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits iterator into chunks.", "response": "def chunks(iterable, size=1):\n    \"\"\"Splits iterator in chunks.\"\"\"\n    iterator = iter(iterable)\n\n    for element in iterator:\n        yield chain([element], islice(iterator, size - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over the content of the filesystem and queries VirusTotal to determine whether it s malicious or not.", "response": "def scan(self, filetypes=None):\n        \"\"\"Iterates over the content of the disk and queries VirusTotal\n        to determine whether it's malicious or not.\n\n        filetypes is a list containing regular expression patterns.\n        If given, only the files which type will match with one or more of\n        the given patterns will be queried against VirusTotal.\n\n        For each file which is unknown by VT or positive to any of its engines,\n        the method yields a namedtuple:\n\n        VTReport(path        -> C:\\\\Windows\\\\System32\\\\infected.dll\n                 hash        -> ab231...\n                 detections) -> dictionary engine -> detection\n\n        Files unknown by VirusTotal will contain the string 'unknown'\n        in the detection field.\n\n        \"\"\"\n        self.logger.debug(\"Scanning FS content.\")\n        checksums = self.filetype_filter(self._filesystem.checksums('/'),\n                                         filetypes=filetypes)\n\n        self.logger.debug(\"Querying %d objects to VTotal.\", len(checksums))\n\n        for files in chunks(checksums, size=self.batchsize):\n            files = dict((reversed(e) for e in files))\n            response = vtquery(self._apikey, files.keys())\n\n            yield from self.parse_response(files, response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the maximum training size that the smallest class can provide.", "response": "def compute_training_sizes(train_perc, class_sizes, stratified=True):\n    \"\"\"Computes the maximum training size that the smallest class can provide \"\"\"\n\n    size_per_class = np.int64(np.around(train_perc * class_sizes))\n\n    if stratified:\n        print(\"Different classes in training set are stratified to match smallest class!\")\n\n        # per-class\n        size_per_class = np.minimum(np.min(size_per_class), size_per_class)\n\n        # single number\n        reduced_sizes = np.unique(size_per_class)\n        if len(reduced_sizes) != 1:  # they must all be the same\n            raise ValueError(\"Error in stratification of training set based on \"\n                             \"smallest class!\")\n\n    total_test_samples = np.int64(np.sum(class_sizes) - sum(size_per_class))\n\n    return size_per_class, total_test_samples"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load(self, dataset_spec):\n\n        for idx, ds in enumerate(dataset_spec):\n            self.append(ds, idx)", "response": "Load the datasets from a list of datasets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, dataset, identifier):\n\n        dataset = dataset if isinstance(dataset, MLDataset) else MLDataset(dataset)\n\n        if not self._is_init:\n            self._ids = set(dataset.keys)\n            self._classes = dataset.classes\n            self._class_sizes = dataset.class_sizes\n\n            self._num_samples = len(self._ids)\n            self._modalities[identifier] = dataset.data\n            self._num_features.append(dataset.num_features)\n\n            # maintaining a no-data MLDataset internally for reuse its methods\n            self._dataset = copy(dataset)\n            # replacing its data with zeros\n            self._dataset.data = {id_: np.zeros(1) for id_ in self._ids}\n\n            self._is_init = True\n        else:\n            # this also checks for the size (num_samples)\n            if set(dataset.keys) != self._ids:\n                raise ValueError('Differing set of IDs in two datasets.'\n                                 'Unable to add this dataset to the MultiDataset.')\n\n            if dataset.classes != self._classes:\n                raise ValueError('Classes for IDs differ in the two datasets.')\n\n            if identifier not in self._modalities:\n                self._modalities[identifier] = dataset.data\n                self._num_features.append(dataset.num_features)\n            else:\n                raise KeyError('{} already exists in MultiDataset'.format(identifier))\n\n        # each addition should be counted, if successful\n        self._modality_count += 1", "response": "Adds a dataset to the MultiDataset if compatible with the existing ones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef holdout(self,\n                train_perc=0.7,\n                num_rep=50,\n                stratified=True,\n                return_ids_only=False,\n                format='MLDataset'):\n        \"\"\"\n        Builds a generator for train and test sets for cross-validation.\n\n        \"\"\"\n\n        ids_in_class = {cid: self._dataset.sample_ids_in_class(cid)\n                        for cid in self._class_sizes.keys()}\n\n        sizes_numeric = np.array([len(ids_in_class[cid]) for cid in ids_in_class.keys()])\n        size_per_class, total_test_count = compute_training_sizes(\n                train_perc, sizes_numeric, stratified=stratified)\n\n        if len(self._class_sizes) != len(size_per_class):\n            raise ValueError('size spec differs in num elements with class sizes!')\n\n        for rep in range(num_rep):\n            print('rep {}'.format(rep))\n\n            train_set = list()\n            for index, (cls_id, class_size) in enumerate(self._class_sizes.items()):\n                # shuffling the IDs each time\n                random.shuffle(ids_in_class[cls_id])\n\n                subset_size = max(0, min(class_size, size_per_class[index]))\n                if subset_size < 1 or class_size < 1:\n                    warnings.warn('No subjects from class {} were selected.'\n                                  ''.format(cls_id))\n                else:\n                    subsets_this_class = ids_in_class[cls_id][0:size_per_class[index]]\n                    train_set.extend(subsets_this_class)\n\n            # this ensures both are mutually exclusive!\n            test_set = list(self._ids - set(train_set))\n\n            if return_ids_only:\n                # when only IDs are required, without associated features\n                # returning tuples to prevent accidental changes\n                yield tuple(train_set), tuple(test_set)\n            else:\n                yield self._get_data(train_set, format), self._get_data(test_set, format)", "response": "Generates a generator for training and test sets for cross - validation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_data(self, id_list, format='MLDataset'):\n\n        format = format.lower()\n\n        features = list()  # returning a dict would be better if AutoMKL() can handle it\n        for modality, data in self._modalities.items():\n            if format in ('ndarray', 'data_matrix'):\n                # turning dict of arrays into a data matrix\n                # this is arguably worse, as labels are difficult to pass\n                subset = np.array(itemgetter(*id_list)(data))\n            elif format in ('mldataset', 'pyradigm'):\n                # getting container with fake data\n                subset = self._dataset.get_subset(id_list)\n                # injecting actual features\n                subset.data = { id_: data[id_] for id_ in id_list }\n            else:\n                raise ValueError('Invalid output format - choose only one of '\n                                 'MLDataset or data_matrix')\n\n            features.append(subset)\n\n        return features", "response": "Returns the data for all modalities for a given list of IDs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_package_finder(options, index_urls, session):\n        return PackageFinder(\n            find_links=options.get('find_links'),\n            index_urls=index_urls,\n            allow_all_prereleases=options.get('pre'),\n            trusted_hosts=options.get('trusted_hosts'),\n            session=session,\n        )", "response": "Build a package finder appropriate to this list command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining whether the package can be updated or not.", "response": "def can_be_updated(cls, dist, latest_version):\n        \"\"\"Determine whether package can be updated or not.\"\"\"\n        scheme = get_scheme('default')\n        name = dist.project_name\n        dependants = cls.get_dependants(name)\n        for dependant in dependants:\n            requires = dependant.requires()\n            for requirement in cls.get_requirement(name, requires):\n                req = parse_requirement(requirement)\n                # Ignore error if version in requirement spec can't be parsed\n                try:\n                    matcher = scheme.matcher(req.requirement)\n                except UnsupportedVersionError:\n                    continue\n                if not matcher.match(str(latest_version)):\n                    return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dependants(cls, dist):\n        for package in cls.installed_distributions:\n            for requirement_package in package.requires():\n                requirement_name = requirement_package.project_name\n                # perform case-insensitive matching\n                if requirement_name.lower() == dist.lower():\n                    yield package", "response": "Yields all dependant user packages for a given package name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_requirement(name, requires):\n        for require in requires:\n            if name.lower() == require.project_name.lower() and require.specs:\n                safe_name = require.project_name.replace('-', '_')\n                yield '%s (%s)' % (safe_name, require.specifier)", "response": "Yields a list of strings that represent the names of the modules that require the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_package(dist):\n        if dist_is_editable(dist):\n            return '%s (%s, %s)' % (\n                dist.project_name,\n                dist.version,\n                dist.location,\n            )\n        return '%s (%s)' % (dist.project_name, dist.version)", "response": "Return string displaying package information."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints outdated user packages.", "response": "def run_outdated(cls, options):\n        \"\"\"Print outdated user packages.\"\"\"\n        latest_versions = sorted(\n            cls.find_packages_latest_versions(cls.options),\n            key=lambda p: p[0].project_name.lower())\n\n        for dist, latest_version, typ in latest_versions:\n            if latest_version > dist.parsed_version:\n                if options.all:\n                    pass\n                elif options.pinned:\n                    if cls.can_be_updated(dist, latest_version):\n                        continue\n                elif not options.pinned:\n                    if not cls.can_be_updated(dist, latest_version):\n                        continue\n                    elif options.update:\n                        print(dist.project_name if options.brief else\n                              'Updating %s to Latest: %s [%s]' %\n                              (cls.output_package(dist), latest_version, typ))\n                        main(['install', '--upgrade'] + ([\n                            '--user'\n                        ] if ENABLE_USER_SITE else []) + [dist.key])\n                        continue\n\n                print(dist.project_name if options.brief else\n                      '%s - Latest: %s [%s]' %\n                      (cls.output_package(dist), latest_version, typ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, X, y, eval_set=None):\n        # Verify the input parameters\n        base_estimator = self.base_estimator\n        base_estimator_is_tree = self.base_estimator_is_tree\n        if base_estimator is None:\n            base_estimator = tree.DecisionTreeRegressor(max_depth=1, random_state=self.random_state)\n            base_estimator_is_tree = True\n\n        if not isinstance(base_estimator, base.RegressorMixin):\n            raise ValueError('base_estimator must be a RegressorMixin')\n\n        loss = self.loss or self._default_loss\n\n        self.init_estimator_ = base.clone(self.init_estimator or loss.default_init_estimator)\n\n        eval_metric = self.eval_metric or loss\n\n        line_searcher = self.line_searcher\n        if line_searcher is None and base_estimator_is_tree:\n            line_searcher = loss.tree_line_searcher\n\n        self._rng = utils.check_random_state(self.random_state)\n\n        # At this point we assume the input data has been checked\n        if y.ndim == 1:\n            y = y.reshape(-1, 1)\n\n        # Instantiate some training variables\n        self.estimators_ = []\n        self.line_searchers_ = []\n        self.columns_ = []\n        self.eval_scores_ = [] if eval_set else None\n\n        # Use init_estimator for the first fit\n        self.init_estimator_.fit(X, y)\n        y_pred = self.init_estimator_.predict(X)\n\n        # We keep training weak learners until we reach n_estimators or early stopping occurs\n        for _ in range(self.n_estimators):\n\n            # If row_sampling is lower than 1 then we're doing stochastic gradient descent\n            rows = None\n            if self.row_sampling < 1:\n                n_rows = int(X.shape[0] * self.row_sampling)\n                rows = self._rng.choice(X.shape[0], n_rows, replace=False)\n\n            # If col_sampling is lower than 1 then we only use a subset of the features\n            cols = None\n            if self.col_sampling < 1:\n                n_cols = int(X.shape[1] * self.col_sampling)\n                cols = self._rng.choice(X.shape[1], n_cols, replace=False)\n\n            # Subset X\n            X_fit = X\n            if rows is not None:\n                X_fit = X_fit[rows, :]\n            if cols is not None:\n                X_fit = X_fit[:, cols]\n\n            # Compute the gradients of the loss for the current prediction\n            gradients = loss.gradient(y, self._transform_y_pred(y_pred))\n\n            # We will train one weak model per column in y\n            estimators = []\n            line_searchers = []\n\n            for i, gradient in enumerate(gradients.T):\n\n                # Fit a weak learner to the negative gradient of the loss function\n                estimator = base.clone(base_estimator)\n                estimator = estimator.fit(X_fit, -gradient if rows is None else -gradient[rows])\n                estimators.append(estimator)\n\n                # Estimate the descent direction using the weak learner\n                direction = estimator.predict(X if cols is None else X[:, cols])\n\n                # Apply line search if a line searcher has been provided\n                if line_searcher:\n                    ls = copy.copy(line_searcher)\n                    ls = ls.fit(y[:, i], y_pred[:, i], gradient, direction)\n                    line_searchers.append(ls)\n                    direction = ls.update(direction)\n\n                # Move the predictions along the estimated descent direction\n                y_pred[:, i] += self.learning_rate * direction\n\n            # Store the estimator and the step\n            self.estimators_.append(estimators)\n            if line_searchers:\n                self.line_searchers_.append(line_searchers)\n            self.columns_.append(cols)\n\n            # We're now at the end of a round so we can evaluate the model on the validation set\n            if not eval_set:\n                continue\n            X_val, y_val = eval_set\n            self.eval_scores_.append(eval_metric(y_val, self.predict(X_val)))\n\n            # Check for early stopping\n            if self.early_stopping_rounds and len(self.eval_scores_) > self.early_stopping_rounds:\n                if self.eval_scores_[-1] > self.eval_scores_[-(self.early_stopping_rounds + 1)]:\n                    break\n\n        return self", "response": "Fit a gradient boosting procedure to a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the predictions for X at every stage of boosting procedure.", "response": "def iter_predict(self, X, include_init=False):\n        \"\"\"Returns the predictions for ``X`` at every stage of the boosting procedure.\n\n        Args:\n            X (array-like or sparse matrix of shape (n_samples, n_features): The input samples.\n                Sparse matrices are accepted only if they are supported by the weak model.\n            include_init (bool, default=False): If ``True`` then the prediction from\n                ``init_estimator`` will also be returned.\n        Returns:\n            iterator of arrays of shape (n_samples,) containing the predicted values at each stage\n        \"\"\"\n        utils.validation.check_is_fitted(self, 'init_estimator_')\n        X = utils.check_array(X, accept_sparse=['csr', 'csc'], dtype=None, force_all_finite=False)\n\n        y_pred = self.init_estimator_.predict(X)\n\n        # The user decides if the initial prediction should be included or not\n        if include_init:\n            yield y_pred\n\n        for estimators, line_searchers, cols in itertools.zip_longest(self.estimators_,\n                                                                      self.line_searchers_,\n                                                                      self.columns_):\n\n            for i, (estimator, line_searcher) in enumerate(itertools.zip_longest(estimators,\n                                                                                 line_searchers or [])):\n\n                # If we used column sampling then we have to make sure the columns of X are arranged\n                # in the correct order\n                if cols is None:\n                    direction = estimator.predict(X)\n                else:\n                    direction = estimator.predict(X[:, cols])\n\n                if line_searcher:\n                    direction = line_searcher.update(direction)\n\n                y_pred[:, i] += self.learning_rate * direction\n\n            yield y_pred"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, X):\n        return collections.deque(self.iter_predict(X), maxlen=1).pop()", "response": "Returns the predictions for X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the predicted probabilities for X at every stage of boosting procedure.", "response": "def iter_predict_proba(self, X, include_init=False):\n        \"\"\"Returns the predicted probabilities for ``X`` at every stage of the boosting procedure.\n\n        Arguments:\n            X (array-like or sparse matrix of shape (n_samples, n_features)): The input samples.\n                Sparse matrices are accepted only if they are supported by the weak model.\n            include_init (bool, default=False): If ``True`` then the prediction from\n                ``init_estimator`` will also be returned.\n\n        Returns:\n            iterator of arrays of shape (n_samples, n_classes) containing the predicted\n            probabilities at each stage\n        \"\"\"\n        utils.validation.check_is_fitted(self, 'init_estimator_')\n        X = utils.check_array(X, accept_sparse=['csr', 'csc'], dtype=None, force_all_finite=False)\n\n        probas = np.empty(shape=(len(X), len(self.classes_)), dtype=np.float64)\n\n        for y_pred in super().iter_predict(X, include_init=include_init):\n            if len(self.classes_) == 2:\n                probas[:, 1] = sigmoid(y_pred[:, 0])\n                probas[:, 0] = 1. - probas[:, 1]\n            else:\n                probas[:] = softmax(y_pred)\n            yield probas"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_predict(self, X, include_init=False):\n        for probas in self.iter_predict_proba(X, include_init=include_init):\n            yield self.encoder_.inverse_transform(np.argmax(probas, axis=1))", "response": "Returns the predicted classes at every stage of boosting procedure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef predict_proba(self, X):\n        return collections.deque(self.iter_predict_proba(X), maxlen=1).pop()", "response": "Returns the predicted probabilities for X."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_html(self, attr_string):\n        splitter = re.compile(self.split_regex(separator=self.spnl))\n        attrs = splitter.split(attr_string)[1::2]\n\n        idre = re.compile(r'''id=[\"']?([\\w ]*)['\"]?''')\n        clsre = re.compile(r'''class=[\"']?([\\w ]*)['\"]?''')\n\n        id_matches = [idre.search(a) for a in attrs]\n        cls_matches = [clsre.search(a) for a in attrs]\n\n        try:\n            id = [m.groups()[0] for m in id_matches if m][0]\n        except IndexError:\n            id = ''\n\n        classes = [m.groups()[0] for m in cls_matches if m][0].split()\n\n        special = ['unnumbered' for a in attrs if '-' in a]\n        classes.extend(special)\n\n        kvs = [a.split('=', 1) for a in attrs if '=' in a]\n        kvs = OrderedDict((k, v) for k, v in kvs if k not in ('id', 'class'))\n\n        return id, classes, kvs", "response": "Read a html string to attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_dict(self, attrs):\n        attrs = attrs or {}\n        ident = attrs.get(\"id\", \"\")\n        classes = attrs.get(\"classes\", [])\n        kvs = OrderedDict((k, v) for k, v in attrs.items()\n                          if k not in (\"classes\", \"id\"))\n\n        return ident, classes, kvs", "response": "Read a dict to attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns attributes formatted as markdown with optional format argument to determine order of attribute contents.", "response": "def to_markdown(self, format='{id} {classes} {kvs}', surround=True):\n        \"\"\"Returns attributes formatted as markdown with optional\n        format argument to determine order of attribute contents.\n        \"\"\"\n        id = '#' + self.id if self.id else ''\n        classes = ' '.join('.' + cls for cls in self.classes)\n        kvs = ' '.join('{}={}'.format(k, v) for k, v in self.kvs.items())\n\n        attrs = format.format(id=id, classes=classes, kvs=kvs).strip()\n\n        if surround:\n            return '{' + attrs + '}'\n        elif not surround:\n            return attrs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn attributes formatted as html.", "response": "def to_html(self):\n        \"\"\"Returns attributes formatted as html.\"\"\"\n        id, classes, kvs = self.id, self.classes, self.kvs\n        id_str = 'id=\"{}\"'.format(id) if id else ''\n        class_str = 'class=\"{}\"'.format(' '.join(classes)) if classes else ''\n        key_str = ' '.join('{}={}'.format(k, v) for k, v in kvs.items())\n        return ' '.join((id_str, class_str, key_str)).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_dict(self):\n        d = {'id': self.id, 'classes': self.classes}\n        d.update(self.kvs)\n        return d", "response": "Returns attributes formatted as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef watch_pending_transactions(self, callback):\n        '''\n        Callback will receive one argument: the transaction object just observed\n\n        This is equivalent to `eth.filter('pending')`\n        '''\n        self.pending_tx_watchers.append(callback)\n        if len(self.pending_tx_watchers) == 1:\n            eth.filter('pending').watch(self._new_pending_tx)", "response": "Add a callback to be called when a pending transaction is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_files(controller, track_path, log_level=logging.ERROR):\n        rocket = Rocket(controller, track_path=track_path, log_level=log_level)\n        rocket.connector = FilesConnector(track_path,\n                                          controller=controller,\n                                          tracks=rocket.tracks)\n        return rocket", "response": "Create a new rocket instance using a project file connector"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new rocket instance using a project file connector", "response": "def from_project_file(controller, project_file, track_path=None, log_level=logging.ERROR):\n        \"\"\"Create rocket instance using project file connector\"\"\"\n        rocket = Rocket(controller, track_path=track_path, log_level=log_level)\n        rocket.connector = ProjectFileConnector(project_file,\n                                                controller=controller,\n                                                tracks=rocket.tracks)\n        return rocket"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_socket(controller, host=None, port=None, track_path=None, log_level=logging.ERROR):\n        rocket = Rocket(controller, track_path=track_path, log_level=log_level)\n        rocket.connector = SocketConnector(controller=controller,\n                                           tracks=rocket.tracks,\n                                           host=host,\n                                           port=port)\n        return rocket", "response": "Create a new rocket instance using a socket connector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget value of a track at the current time", "response": "def value(self, name):\n        \"\"\"get value of a track at the current time\"\"\"\n        return self.tracks.get(name).row_value(self.controller.row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompare the two given GuestFS instances and returns a dictionary containing the files created removed and modified.", "response": "def compare_filesystems(fs0, fs1, concurrent=False):\n    \"\"\"Compares the two given filesystems.\n\n    fs0 and fs1 are two mounted GuestFS instances\n    containing the two disks to be compared.\n\n    If the concurrent flag is True,\n    two processes will be used speeding up the comparison on multiple CPUs.\n\n    Returns a dictionary containing files created, removed and modified.\n\n        {'created_files': [<files in fs1 and not in fs0>],\n         'deleted_files': [<files in fs0 and not in fs1>],\n         'modified_files': [<files in both fs0 and fs1 but different>]}\n\n    \"\"\"\n    if concurrent:\n        future0 = concurrent_hash_filesystem(fs0)\n        future1 = concurrent_hash_filesystem(fs1)\n\n        files0 = future0.result()\n        files1 = future1.result()\n    else:\n        files0 = hash_filesystem(fs0)\n        files1 = hash_filesystem(fs1)\n\n    return file_comparison(files0, files1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare two dictionaries of files returning their difference.", "response": "def file_comparison(files0, files1):\n    \"\"\"Compares two dictionaries of files returning their difference.\n\n        {'created_files': [<files in files1 and not in files0>],\n         'deleted_files': [<files in files0 and not in files1>],\n         'modified_files': [<files in both files0 and files1 but different>]}\n\n    \"\"\"\n    comparison = {'created_files': [],\n                  'deleted_files': [],\n                  'modified_files': []}\n\n    for path, sha1 in files1.items():\n        if path in files0:\n            if sha1 != files0[path]:\n                comparison['modified_files'].append(\n                    {'path': path,\n                     'original_sha1': files0[path],\n                     'sha1': sha1})\n        else:\n            comparison['created_files'].append({'path': path,\n                                                'sha1': sha1})\n    for path, sha1 in files0.items():\n        if path not in files1:\n            comparison['deleted_files'].append({'path': path,\n                                                'original_sha1': files0[path]})\n\n    return comparison"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_files(filesystem, files, path):\n    extracted_files = {}\n    failed_extractions = {}\n\n    for file_to_extract in files:\n        source = file_to_extract['path']\n        destination = Path(path, file_to_extract['sha1'])\n\n        if not destination.exists():\n            destination = str(destination)\n\n            try:\n                filesystem.download(source, destination)\n                extracted_files[file_to_extract['sha1']] = destination\n            except RuntimeError:\n                failed_extractions[file_to_extract['sha1']] = source\n        else:\n            extracted_files[file_to_extract['sha1']] = destination\n\n    return extracted_files, failed_extractions", "response": "Extracts the requested files into the path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compare_registries(fs0, fs1, concurrent=False):\n    hives = compare_hives(fs0, fs1)\n\n    if concurrent:\n        future0 = concurrent_parse_registries(fs0, hives)\n        future1 = concurrent_parse_registries(fs1, hives)\n\n        registry0 = future0.result()\n        registry1 = future1.result()\n    else:\n        registry0 = parse_registries(fs0, hives)\n        registry1 = parse_registries(fs1, hives)\n\n    return registry_comparison(registry0, registry1)", "response": "Compares the Windows Registry contained within the two File Systems."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomparing two dictionaries of registry keys returning their difference.", "response": "def registry_comparison(registry0, registry1):\n    \"\"\"Compares two dictionaries of registry keys returning their difference.\"\"\"\n    comparison = {'created_keys': {},\n                  'deleted_keys': [],\n                  'created_values': {},\n                  'deleted_values': {},\n                  'modified_values': {}}\n\n    for key, info in registry1.items():\n        if key in registry0:\n            if info[1] != registry0[key][1]:\n                created, deleted, modified = compare_values(\n                    registry0[key][1], info[1])\n\n                if created:\n                    comparison['created_values'][key] = (info[0], created)\n                if deleted:\n                    comparison['deleted_values'][key] = (info[0], deleted)\n                if modified:\n                    comparison['modified_values'][key] = (info[0], modified)\n        else:\n            comparison['created_keys'][key] = info\n\n    for key in registry0.keys():\n        if key not in registry1:\n            comparison['deleted_keys'].append(key)\n\n    return comparison"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compare_values(values0, values1):\n    values0 = {v[0]: v[1:] for v in values0}\n    values1 = {v[0]: v[1:] for v in values1}\n\n    created = [(k, v[0], v[1]) for k, v in values1.items() if k not in values0]\n    deleted = [(k, v[0], v[1]) for k, v in values0.items() if k not in values1]\n    modified = [(k, v[0], v[1]) for k, v in values0.items()\n                if v != values1.get(k, None)]\n\n    return created, deleted, modified", "response": "Compares all the values of a single registry key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare_hives(fs0, fs1):\n    registries = []\n\n    for path in chain(registries_path(fs0.fsroot), user_registries(fs0, fs1)):\n        if fs0.checksum(path) != fs1.checksum(path):\n            registries.append(path)\n\n    return registries", "response": "Compares all the windows registry hive files\n    returns those which differ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the list of user registries present on both FileSystems.", "response": "def user_registries(fs0, fs1):\n    \"\"\"Returns the list of user registries present on both FileSystems.\"\"\"\n    for user in fs0.ls('{}Users'.format(fs0.fsroot)):\n        for path in user_registries_path(fs0.fsroot, user):\n            if fs1.exists(path):\n                yield path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninspect the file type of the given files.", "response": "def files_type(fs0, fs1, files):\n    \"\"\"Inspects the file type of the given files.\"\"\"\n    for file_meta in files['deleted_files']:\n        file_meta['type'] = fs0.file(file_meta['path'])\n    for file_meta in files['created_files'] + files['modified_files']:\n        file_meta['type'] = fs1.file(file_meta['path'])\n\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the file size of the given files.", "response": "def files_size(fs0, fs1, files):\n    \"\"\"Gets the file size of the given files.\"\"\"\n    for file_meta in files['deleted_files']:\n        file_meta['size'] = fs0.stat(file_meta['path'])['size']\n    for file_meta in files['created_files'] + files['modified_files']:\n        file_meta['size'] = fs1.stat(file_meta['path'])['size']\n\n    return files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary with the content of the given registry hives.", "response": "def parse_registries(filesystem, registries):\n    \"\"\"Returns a dictionary with the content of the given registry hives.\n\n    {\"\\\\Registry\\\\Key\\\\\", ((\"ValueKey\", \"ValueType\", ValueValue))}\n\n    \"\"\"\n    results = {}\n\n    for path in registries:\n        with NamedTemporaryFile(buffering=0) as tempfile:\n            filesystem.download(path, tempfile.name)\n\n            registry = RegistryHive(tempfile.name)\n            registry.rootkey = registry_root(path)\n\n            results.update({k.path: (k.timestamp, k.values)\n                            for k in registry.keys()})\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the directory tree if non existing.", "response": "def makedirs(path):\n    \"\"\"Creates the directory tree if non existing.\"\"\"\n    path = Path(path)\n\n    if not path.exists():\n        path.mkdir(parents=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare the two disks according to flags.", "response": "def compare(self, concurrent=False, identify=False, size=False):\n        \"\"\"Compares the two disks according to flags.\n\n        Generates the following report:\n\n        ::\n\n            {'created_files': [{'path': '/file/in/disk1/not/in/disk0',\n                                'sha1': 'sha1_of_the_file'}],\n             'deleted_files': [{'path': '/file/in/disk0/not/in/disk1',\n                                'original_sha1': 'sha1_of_the_file'}],\n             'modified_files': [{'path': '/file/both/disks/but/different',\n                                 'sha1': 'sha1_of_the_file_on_disk0',\n                                 'original_sha1': 'sha1_of_the_file_on_disk0'}]}\n\n        If concurrent is set to True, the logic will use multiple CPUs to\n        speed up the process.\n\n        The identify and size keywords will add respectively the type\n        and the size of the files to the results.\n\n        \"\"\"\n        self.logger.debug(\"Comparing FS contents.\")\n        results = compare_filesystems(self.filesystems[0], self.filesystems[1],\n                                      concurrent=concurrent)\n\n        if identify:\n            self.logger.debug(\"Gatering file types.\")\n            results = files_type(self.filesystems[0], self.filesystems[1],\n                                 results)\n\n        if size:\n            self.logger.debug(\"Gatering file sizes.\")\n            results = files_size(self.filesystems[0], self.filesystems[1],\n                                 results)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract(self, disk, files, path='.'):\n        self.logger.debug(\"Extracting files.\")\n        extracted_files, failed = self._extract_files(disk, files, path)\n\n        return {'extracted_files': [f for f in extracted_files.keys()],\n                'extraction_errors': [f for f in failed.keys()]}", "response": "Extracts the given files from the given disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compare_registry(self, concurrent=False):\n        self.logger.debug(\"Comparing Windows registries.\")\n\n        self._assert_windows()\n\n        return compare_registries(self.filesystems[0], self.filesystems[1],\n                                  concurrent=concurrent)", "response": "Compares the Windows Registry contained within the two File Systems."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_error(self, status_code):\n\n        return jsend.error(message=ComodoCA.status_code[status_code], code=status_code)", "response": "Create an error message in jsend format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cert_types(self):\n        result = self.client.service.getCustomerCertTypes(authData=self.auth)\n\n        if result.statusCode == 0:\n            return jsend.success({'cert_types': result.types})\n        else:\n            return self._create_error(result.statusCode)", "response": "Collect the certificate types that are available to the customer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect(self, cert_id, format_type):\n\n        result = self.client.service.collect(authData=self.auth, id=cert_id,\n                                             formatType=ComodoCA.format_type[format_type])\n\n        # The certificate is ready for collection\n        if result.statusCode == 2:\n            return jsend.success({'certificate': result.SSL.certificate, 'certificate_status': 'issued',\n                                  'certificate_id': cert_id})\n        # The certificate is not ready for collection yet\n        elif result.statusCode == 0:\n            return jsend.fail({'certificate_id': cert_id, 'certificate': '', 'certificate_status': 'pending'})\n        # Some error occurred\n        else:\n            return self._create_error(result.statusCode)", "response": "Poll for certificate availability after submission."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrevoking a certificate. :param int cert_id: The certificate ID :param str reason: Reason for revocation (up to 256 characters), can be blank: '' :return: The result of the operation, 'Successful' on success :rtype: dict", "response": "def revoke(self, cert_id, reason=''):\n        \"\"\"\n        Revoke a certificate.\n\n        :param int cert_id: The certificate ID\n        :param str reason: Reason for revocation (up to 256 characters), can be blank: ''\n        :return: The result of the operation, 'Successful' on success\n        :rtype: dict\n        \"\"\"\n        result = self.client.service.revoke(authData=self.auth, id=cert_id, reason=reason)\n\n        if result == 0:\n            return jsend.success()\n        else:\n            return self._create_error(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubmit a certificate request to Comodo.", "response": "def submit(self, cert_type_name, csr, revoke_password, term, subject_alt_names='',\n               server_type='OTHER'):\n        \"\"\"\n        Submit a certificate request to Comodo.\n\n        :param string cert_type_name: The full cert type name (Example: 'PlatinumSSL Certificate') the supported\n                                      certificate types for your account can be obtained with the\n                                      get_cert_types() method.\n        :param string csr: The Certificate Signing Request (CSR)\n        :param string revoke_password: A password for certificate revocation\n        :param int term: The length, in years, for the certificate to be issued\n        :param string subject_alt_names: Subject Alternative Names separated by a \",\".\n        :param string server_type: The type of server for the TLS certificate e.g 'Apache/ModSSL' full list available in\n                                   ComodoCA.server_type (Default: OTHER)\n        :return: The certificate_id and the normal status messages for errors.\n        :rtype: dict\n        \"\"\"\n        cert_types = self.get_cert_types()\n\n        # If collection of cert types fails we simply pass the error back.\n        if cert_types['status'] == 'error':\n            return cert_types\n\n        # We do this because we need to pass the entire cert type definition back to Comodo\n        # not just the name.\n        for cert_type in cert_types['data']['cert_types']:\n            if cert_type.name == cert_type_name:\n                cert_type_def = cert_type\n\n        result = self.client.service.enroll(authData=self.auth, orgId=self.org_id, secretKey=self.secret_key,\n                                            csr=csr, phrase=revoke_password, subjAltNames=subject_alt_names,\n                                            certType=cert_type_def, numberServers=1,\n                                            serverType=ComodoCA.formats[server_type], term=term, comments='')\n\n        # Anything greater than 0 is the certificate ID\n        if result > 0:\n            return jsend.success({'certificate_id': result})\n        # Anything else is an error\n        else:\n            return self._create_error(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_from_source(version, **kwargs):\n        mvn = os.path.join(Spark.svm_version_path(version), 'build', 'mvn')\n        Spark.chmod_add_excute(mvn)\n        p = subprocess.Popen([mvn, '-DskipTests', 'clean', 'package'], cwd=Spark.svm_version_path(version))\n        p.wait()\n        return p.returncode", "response": "Builds specified Spark version from source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chmod_add_excute(filename):\n        st = os.stat(filename)\n        os.chmod(filename, st.st_mode | stat.S_IEXEC)", "response": "Adds execute permission to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload Spark version. Uses same name as release tag without the leading v.", "response": "def download_source(version):\n        \"\"\"\n        Download Spark version. Uses same name as release tag without the leading 'v'.\n        :param version: Version number to download.\n        :return: None\n        \"\"\"\n        local_filename = 'v{}.zip'.format(Spark.svm_version_path(version))\n        Spark.download(Spark.spark_versions()['v{}'.format(version)], local_filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef svm_version_path(version):\n        return os.path.join(Spark.HOME_DIR, Spark.SVM_DIR, 'v{}'.format(version))", "response": "Returns the path to the Spark version numbering directory. Accepts semantic version numbering."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunzips specified file into ~. svm AttributeNames", "response": "def unzip(filename):\n        \"\"\"\n        Unzips specified file into ~/.svm\n        :param filename:\n        :return:\n        \"\"\"\n        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n            zip_ref.extractall(Spark.svm_path())\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename_unzipped_folder(version):\n\n        for filename in os.listdir(Spark.svm_path()):\n            if fnmatch.fnmatch(filename, 'apache-spark-*'):\n                return os.rename(os.path.join(Spark.svm_path(), filename), Spark.svm_version_path(version))\n\n        raise SparkInstallationError(\"Unable to find unzipped Spark folder in {}\".format(Spark.svm_path()))", "response": "Renames unzipped Spark version folder to the release tag."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a MultiValue type from a specific GP Value type.", "response": "def fromType(datatype):\n        \"\"\"Use this method to create a MultiValue type from a specific GP Value\n           type.\n           \n              >>> gpmultistr = arcrest.GPMultiValue.fromType(arcrest.GPString)\n              >>> gpvalue = gpmultistr([\"a\", \"b\", \"c\"])\n        \"\"\"\n        if issubclass(datatype, GPBaseType):\n            return GPBaseType._get_type_by_name(\"GPMultiValue:%s\" % \n                                                datatype.__name__)\n        else:\n            return GPBaseType._get_type_by_name(\"GPMultiValue:%s\" % \n                                                str(datatype))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the gradient of the L1 loss with respect to each prediction.", "response": "def gradient(self, y_true, y_pred):\n        \"\"\"Returns the gradient of the L1 loss with respect to each prediction.\n\n        Example:\n            >>> import starboost as sb\n            >>> y_true = [0, 0, 1]\n            >>> y_pred = [0.3, 0, 0.8]\n            >>> sb.losses.L1Loss().gradient(y_true, y_pred)\n            array([ 1.,  0., -1.])\n        \"\"\"\n        return np.sign(np.subtract(y_pred, y_true))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn sorted list of names of packages without dependants.", "response": "def get_parents():\n    \"\"\"Return sorted list of names of packages without dependants.\"\"\"\n    distributions = get_installed_distributions(user_only=ENABLE_USER_SITE)\n    remaining = {d.project_name.lower() for d in distributions}\n    requirements = {r.project_name.lower() for d in distributions for\n                    r in d.requires()}\n\n    return get_realnames(remaining - requirements)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning list of unique case - correct package names.", "response": "def get_realnames(packages):\n    \"\"\"\n    Return list of unique case-correct package names.\n\n    Packages are listed in a case-insensitive sorted order.\n    \"\"\"\n    return sorted({get_distribution(p).project_name for p in packages},\n                  key=lambda n: n.lower())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a redirect to the authentication URL for this service. After authentication, the service will redirect back to the given callback URI. We request the given attributes for the authenticated user by default (name, email, language, and username). If you don't need all those attributes for your app, you can request fewer with the |ask_for| keyword argument.", "response": "def authenticate_redirect(self, callback_uri=None,\n                              ask_for=[\"name\", \"email\", \"language\", \"username\"]):\n        \"\"\"\n        Performs a redirect to the authentication URL for this service.\n\n        After authentication, the service will redirect back to the given\n        callback URI.\n\n        We request the given attributes for the authenticated user by\n        default (name, email, language, and username). If you don't need\n        all those attributes for your app, you can request fewer with\n        the |ask_for| keyword argument.\n        \"\"\"\n        callback_uri = callback_uri or request.url\n        args = self._openid_args(callback_uri, ax_attrs=ask_for)\n        return redirect(self._OPENID_ENDPOINT +\n                        (\"&\" if \"?\" in self._OPENID_ENDPOINT else \"?\") +\n                        urllib.urlencode(args))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch the authenticated user data upon redirect.", "response": "def get_authenticated_user(self, callback):\n        \"\"\"Fetches the authenticated user data upon redirect.\n\n        This method should be called by the handler that receives the\n        redirect from the authenticate_redirect() or authorize_redirect()\n        methods.\n        \"\"\"\n        # Verify the OpenID response via direct request to the OP\n        args = dict((k, v) for k, v in request.args.items())\n        args[\"openid.mode\"] = u\"check_authentication\"\n\n        r = requests.post(self._OPENID_ENDPOINT, data=args)\n        return self._on_authentication_verified(callback, r)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _on_auth(self, user):\n        app = current_app._get_current_object()\n        if not user:\n            # Google auth failed.\n            login_error.send(app, user=None)\n            abort(403)\n        session[\"openid\"] = user\n        login.send(app, user=user)\n        return redirect(request.args.get(\"next\", None) or request.referrer or \"/\")", "response": "Called when OpenID authentication is complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests decorator. Forces authentication.", "response": "def required(self, fn):\n        \"\"\"Request decorator. Forces authentication.\"\"\"\n        @functools.wraps(fn)\n        def decorated(*args, **kwargs):\n            if (not self._check_auth()\n               # Don't try to force authentication if the request is part\n               # of the authentication process - otherwise we end up in a\n               # loop.\n               and request.blueprint != self.blueprint.name):\n                return redirect(url_for(\"%s.login\" % self.blueprint.name,\n                                        next=request.url))\n            return fn(*args, **kwargs)\n        return decorated"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over the journal s file taking care of paddings.", "response": "def parse_journal_file(journal_file):\n    \"\"\"Iterates over the journal's file taking care of paddings.\"\"\"\n    counter = count()\n\n    for block in read_next_block(journal_file):\n        block = remove_nullchars(block)\n\n        while len(block) > MIN_RECORD_SIZE:\n            header = RECORD_HEADER.unpack_from(block)\n            size = header[0]\n\n            try:\n                yield parse_record(header, block[:size])\n\n                next(counter)\n            except RuntimeError:\n                yield CorruptedUsnRecord(next(counter))\n            finally:\n                block = remove_nullchars(block[size:])\n\n        journal_file.seek(- len(block), 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a USN record according to its version.", "response": "def parse_record(header, record):\n    \"\"\"Parses a record according to its version.\"\"\"\n    major_version = header[1]\n\n    try:\n        return RECORD_PARSER[major_version](header, record)\n    except (KeyError, struct.error) as error:\n        raise RuntimeError(\"Corrupted USN Record\") from error"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract USN V2 record information.", "response": "def usn_v2_record(header, record):\n    \"\"\"Extracts USN V2 record information.\"\"\"\n    length, major_version, minor_version = header\n    fields = V2_RECORD.unpack_from(record, RECORD_HEADER.size)\n\n    return UsnRecord(length,\n                     float('{}.{}'.format(major_version, minor_version)),\n                     fields[0] | fields[1] << 16,  # 6 bytes little endian mft\n                     fields[2],  # 2 bytes little endian mft sequence\n                     fields[3] | fields[4] << 16,  # 6 bytes little endian mft\n                     fields[5],  # 2 bytes little endian mft sequence\n                     fields[6],\n                     (datetime(1601, 1, 1) +\n                      timedelta(microseconds=(fields[7] / 10))).isoformat(' '),\n                     unpack_flags(fields[8], REASONS),\n                     unpack_flags(fields[9], SOURCEINFO),\n                     fields[10],\n                     unpack_flags(fields[11], ATTRIBUTES),\n                     str(struct.unpack_from('{}s'.format(fields[12]).encode(),\n                                            record, fields[13])[0], 'utf16'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef usn_v4_record(header, record):\n    length, major_version, minor_version = header\n    fields = V4_RECORD.unpack_from(record, RECORD_HEADER.size)\n\n    raise NotImplementedError('Not implemented')", "response": "Extracts USN V4 record information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nunpacking a single flags field into a list of lists.", "response": "def unpack_flags(value, flags):\n    \"\"\"Multiple flags might be packed in the same field.\"\"\"\n    try:\n        return [flags[value]]\n    except KeyError:\n        return [flags[k] for k in sorted(flags.keys()) if k & value > 0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_next_block(infile, block_size=io.DEFAULT_BUFFER_SIZE):\n    chunk = infile.read(block_size)\n\n    while chunk:\n        yield chunk\n\n        chunk = infile.read(block_size)", "response": "Iterates over the file in blocks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_nullchars(block):\n    data = block.lstrip(b'\\00')\n\n    padding = b'\\00' * ((len(block) - len(data)) % 8)\n\n    return padding + data", "response": "Strips NULL chars taking care of bytes alignment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a time or time range from ArcGIS REST server format to Python", "response": "def timetopythonvalue(time_val):\n    \"Convert a time or time range from ArcGIS REST server format to Python\"\n    if isinstance(time_val, sequence):\n        return map(timetopythonvalue, time_val)\n    elif isinstance(time_val, numeric):\n        return datetime.datetime(*(time.gmtime(time_val))[:6])\n    elif isinstance(time_val, numeric):\n        values = []\n        try:\n            values = map(long, time_val.split(\",\"))\n        except:\n            pass\n        if values:\n            return map(timetopythonvalue, values)\n    raise ValueError(repr(time_val))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pythonvaluetotime(time_val):\n    \"Convert a time or time range from Python datetime to ArcGIS REST server\"\n    if time_val is None:\n        return None\n    elif isinstance(time_val, numeric):\n        return str(long(time_val * 1000.0))\n    elif isinstance(time_val, date):\n        dtlist = [time_val.year, time_val.month, time_val.day]\n        if isinstance(time_val, datetime.datetime):\n            dtlist += [time_val.hour, time_val.minute, time_val.second]\n        else:\n            dtlist += [0, 0, 0]\n        return long(calendar.timegm(dtlist) * 1000.0)\n    elif (isinstance(time_val, sequence)\n                    and len(time_val) == 2):\n        if all(isinstance(x, numeric) \n               for x in time_val):\n            return \",\".join(pythonvaluetotime(x) \n                            for x in time_val)\n        elif all(isinstance(x, date) \n               for x in time_val):\n            return \",\".join(pythonvaluetotime(x) \n                            for x in time_val)\n    raise ValueError(repr(time_val))", "response": "Convert a time or time range from Python datetime to ArcGIS REST server"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_hosts(self, group=None):\n        '''\n        Get the hosts\n        '''\n        hostlist = []\n\n        if group:\n            groupobj = self.inventory.groups.get(group)\n            if not groupobj:\n                print \"Group [%s] not found in inventory\" % group\n                return None\n\n            groupdict = {}\n            groupdict['hostlist'] = []\n            for host in groupobj.get_hosts():\n                groupdict['hostlist'].append(host.name)\n            hostlist.append(groupdict)\n        else:\n            for group in self.inventory.groups:\n                groupdict = {}\n                groupdict['group'] = group\n                groupdict['hostlist'] = []\n                groupobj = self.inventory.groups.get(group)\n                for host in groupobj.get_hosts():\n                    groupdict['hostlist'].append(host.name)\n                hostlist.append(groupdict)\n\n        return hostlist", "response": "Get the hosts of the group or all hosts"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random MLDataset for use in testing.", "response": "def make_random_MLdataset(max_num_classes = 20,\n                          min_class_size = 20,\n                          max_class_size = 50,\n                          max_dim = 100,\n                          stratified = True):\n    \"Generates a random MLDataset for use in testing.\"\n\n    smallest = min(min_class_size, max_class_size)\n    max_class_size = max(min_class_size, max_class_size)\n    largest = max(50, max_class_size)\n    largest = max(smallest+3,largest)\n\n    if max_num_classes != 2:\n        num_classes = np.random.randint(2, max_num_classes, 1)\n    else:\n        num_classes = 2\n\n    if type(num_classes) == np.ndarray:\n        num_classes = num_classes[0]\n    if not stratified:\n        class_sizes = np.random.random_integers(smallest, largest, num_classes)\n    else:\n        class_sizes = np.repeat(np.random.randint(smallest, largest), num_classes)\n\n    num_features = np.random.randint(min(3, max_dim), max(3, max_dim), 1)[0]\n    # feat_names = [ str(x) for x in range(num_features)]\n\n    class_ids = list()\n    labels = list()\n    for cl in range(num_classes):\n        class_ids.append('class-{}'.format(cl))\n        labels.append(int(cl))\n\n    ds = MLDataset()\n    for cc, class_ in enumerate(class_ids):\n        subids = [ 's{}-c{}'.format(ix,cc) for ix in range(class_sizes[cc]) ]\n        for sid in subids:\n            ds.add_sample(sid, feat_generator(num_features), int(cc), class_)\n\n    return ds"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef forProperty(instance,propertyName,useGetter=False):\n        assert isinstance(propertyName,str)\n\n        if propertyName.startswith(\"get\") or propertyName.startswith(\"set\"):\n            #property is a getter function or a setter function, assume a corresponding setter/getter function exists\n            getterName = \"get\" + propertyName[3:]\n            setterName = \"set\" + propertyName[3:]\n            if len(propertyName[3:]) > 1:\n                signalName = propertyName[3].lower() + propertyName[4:] + \"Changed\"\n            else:\n                signalName = propertyName.lower() + \"Changed\"\n\n            assert hasattr(instance,getterName)\n            assert hasattr(instance,setterName)\n            assert hasattr(instance,signalName)\n            getter = getattr(instance,getterName)\n            setter = getattr(instance,setterName)\n            signal = getattr(instance,signalName)\n\n        elif hasattr(instance, propertyName) and callable(getattr(instance,propertyName)):\n            #property is a getter function without the \"get\" prefix. Assume a corresponding setter method exists\n            getterName = propertyName\n            setterName = \"set\" + propertyName.capitalize()\n            signalName = propertyName + \"Changed\"\n\n            assert hasattr(instance,setterName)\n            assert hasattr(instance,signalName)\n            getter = getattr(instance,getterName)\n            setter = getattr(instance,setterName)\n            signal = getattr(instance,signalName)\n\n\n        elif hasattr(instance, propertyName):\n            #property is real property. Assume it is not readonly\n            signalName = propertyName + \"Changed\"\n            assert hasattr(instance,signalName)\n\n            getter = lambda: getattr(instance,propertyName)\n            setter = lambda value: setattr(instance,propertyName,value)\n            signal = getattr(instance,signalName)\n\n        else:\n            #property is a virtual property. There should be getPropertyName and setPropertyName methods\n            if len(propertyName) > 1:\n                getterName = \"get\" + propertyName[0].upper() + propertyName[1:]\n                setterName = \"set\" + propertyName[0].upper() + propertyName[1:]\n                signalName = propertyName + \"Changed\"\n            else:\n                getterName = \"get\" + propertyName.upper()\n                setterName = \"set\" + propertyName.upper()\n                signalName = propertyName.lower() + \"Changed\"\n\n            assert hasattr(instance,getterName)\n            assert hasattr(instance,setterName)\n            assert hasattr(instance,signalName)\n\n            getter = getattr(instance,getterName)\n            setter = getattr(instance,setterName)\n            signal = getattr(instance,signalName)\n\n        return BindingEndpoint(instance, setter, signal, getter = getter if useGetter else None)", "response": "Binds a property to an instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbinds an object to the related object.", "response": "def bind(self,instance,setter,valueChangedSignal,getter = None):\n        \"\"\"\n        Creates an endpoint and call bindToEndpoint(endpoint). This is a convenience method.\n\n        Parameters:\n            instance -- the object instance to which the getter, setter and changedSignal belong\n            setter -- the value setter method\n            valueChangedSignal -- the pyqtSignal that is emitted with the value changes\n            getter -- the value getter method (default None)\n                      If None, the signal argument(s) are passed to the setter method\n        \"\"\"\n\n        endpoint = BindingEndpoint(instance,setter,valueChangedSignal,getter=getter)\n        self.bindToEndPoint(endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bindToEndPoint(self,bindingEndpoint):\n        self.bindings[bindingEndpoint.instanceId] = bindingEndpoint\n        bindingEndpoint.valueChangedSignal.connect(self._updateEndpoints)", "response": "Binds the target endpoint to all other endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbinding to an instance property.", "response": "def bindToProperty(self,instance,propertyName,useGetter=False):\n        \"\"\"\n        2-way binds to an instance property.\n\n        Parameters:\n        - instance -- the object instance\n        - propertyName -- the name of the property to bind to\n        - useGetter: when True, calls the getter method to obtain the value. When False, the signal argument is used as input for the target setter. (default False)\n\n        Notes:\n        2-way binds to an instance property according to one of the following naming conventions:\n\n        @property, propertyName.setter and pyqtSignal\n        - getter: propertyName\n        - setter: propertyName\n        - changedSignal: propertyNameChanged\n\n        getter, setter and pyqtSignal (this is used when binding to standard QWidgets like QSpinBox)\n        - getter: propertyName()\n        - setter: setPropertyName()\n        - changedSignal: propertyNameChanged\n        \"\"\"\n        endpoint = BindingEndpoint.forProperty(instance,propertyName,useGetter = useGetter)\n\n        self.bindToEndPoint(endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _updateEndpoints(self,*args,**kwargs):\n\n        sender = self.sender()\n        if not self.ignoreEvents:\n            self.ignoreEvents = True\n\n            for binding in self.bindings.values():\n                if binding.instanceId == id(sender):\n                    continue\n                \n                if args: \n                    binding.setter(*args,**kwargs)\n                else:\n                    binding.setter(self.bindings[id(sender)].getter())\n\n            self.ignoreEvents = False", "response": "Updates all the endpoints except the one from which this slot was called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _anonymize_table(cls, table_data, pii_fields):\n        for pii_field in pii_fields:\n            field_name = pii_field['name']\n            transformer = cls.get_class(TRANSFORMERS['categorical'])(pii_field)\n            table_data[field_name] = transformer.anonymize_column(table_data)\n\n        return table_data", "response": "Anonymize in table_data the fields in pii_fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the contents of meta_file and the corresponding data.", "response": "def _get_tables(self, base_dir):\n        \"\"\"Load the contents of meta_file and the corresponding data.\n\n        If fields containing Personally Identifiable Information are detected in the metadata\n        they are anonymized before asign them into `table_dict`.\n\n        Args:\n            base_dir(str): Root folder of the dataset files.\n\n        Returns:\n            dict: Mapping str -> tuple(pandas.DataFrame, dict)\n        \"\"\"\n        table_dict = {}\n\n        for table in self.metadata['tables']:\n            if table['use']:\n                relative_path = os.path.join(base_dir, self.metadata['path'], table['path'])\n                data_table = pd.read_csv(relative_path)\n                pii_fields = self._get_pii_fields(table)\n                data_table = self._anonymize_table(data_table, pii_fields)\n\n                table_dict[table['name']] = (data_table, table)\n\n        return table_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_transformers(self):\n        transformer_dict = {}\n\n        for table in self.metadata['tables']:\n            table_name = table['name']\n\n            for field in table['fields']:\n                transformer_type = field.get('type')\n                if transformer_type:\n                    col_name = field['name']\n                    transformer_dict[(table_name, col_name)] = transformer_type\n\n        return transformer_dict", "response": "Load the contents of meta_file and extract information about the transformers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfitting a column from table using transformer and given parameters.", "response": "def _fit_transform_column(self, table, metadata, transformer_name, table_name):\n        \"\"\"Transform a column from table using transformer and given parameters.\n\n        Args:\n            table (pandas.DataFrame): Dataframe containing column to transform.\n            metadata (dict): Metadata for given column.\n            transformer_name (str): Name of transformer to use on column.\n            table_name (str): Name of table in original dataset.\n\n        Returns:\n            pandas.DataFrame: Dataframe containing the transformed column. If self.missing=True,\n                              it will contain a second column containing 0 and 1 marking if that\n                              value was originally null or not.\n        \"\"\"\n\n        column_name = metadata['name']\n        content = {}\n        columns = []\n\n        if self.missing and table[column_name].isnull().any():\n            null_transformer = transformers.NullTransformer(metadata)\n            clean_column = null_transformer.fit_transform(table[column_name])\n            null_name = '?' + column_name\n            columns.append(null_name)\n            content[null_name] = clean_column[null_name].values\n            table[column_name] = clean_column[column_name]\n\n        transformer_class = self.get_class(transformer_name)\n        transformer = transformer_class(metadata)\n\n        self.transformers[(table_name, column_name)] = transformer\n        content[column_name] = transformer.fit_transform(table)[column_name].values\n\n        columns = [column_name] + columns\n        return pd.DataFrame(content, columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reverse_transform_column(self, table, metadata, table_name):\n\n        column_name = metadata['name']\n\n        if column_name not in table:\n            return\n\n        null_name = '?' + column_name\n        content = pd.DataFrame(columns=[column_name], index=table.index)\n        transformer = self.transformers[(table_name, column_name)]\n        content[column_name] = transformer.reverse_transform(table[column_name].to_frame())\n\n        if self.missing and null_name in table[column_name]:\n            content[null_name] = table.pop(null_name)\n            null_transformer = transformers.NullTransformer(metadata)\n            content[column_name] = null_transformer.reverse_transform(content)\n\n        return content", "response": "Reverses the transformtion on a column from table using the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_transform_table(\n            self, table, table_meta, transformer_dict=None, transformer_list=None, missing=None):\n        \"\"\"Create, apply and store the specified transformers for `table`.\n\n        Args:\n            table(pandas.DataFrame):    Contents of the table to be transformed.\n\n            table_meta(dict):   Metadata for the given table.\n\n            transformer_dict(dict):     Mapping  `tuple(str, str)` -> `str` where the tuple in the\n                                        keys represent the (table_name, column_name) and the value\n                                        the name of the assigned transformer.\n\n            transformer_list(list):     List of transformers to use. Overrides the transformers in\n                                        the meta_file.\n\n            missing(bool):      Wheter or not use NullTransformer to handle missing values.\n\n        Returns:\n            pandas.DataFrame: Transformed table.\n        \"\"\"\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(DEPRECATION_MESSAGE.format('fit_transform_table'), DeprecationWarning)\n\n        result = pd.DataFrame()\n        table_name = table_meta['name']\n\n        for field in table_meta['fields']:\n            col_name = field['name']\n\n            if transformer_list:\n                for transformer_name in transformer_list:\n                    if field['type'] == self.get_class(transformer_name).type:\n                        transformed = self._fit_transform_column(\n                            table, field, transformer_name, table_name)\n\n                        result = pd.concat([result, transformed], axis=1)\n\n            elif (table_name, col_name) in transformer_dict:\n                transformer_name = TRANSFORMERS[transformer_dict[(table_name, col_name)]]\n                transformed = self._fit_transform_column(\n                    table, field, transformer_name, table_name)\n\n                result = pd.concat([result, transformed], axis=1)\n\n        return result", "response": "Create apply and store the specified transformers for the given table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies the stored transformers to the given table.", "response": "def transform_table(self, table, table_meta, missing=None):\n        \"\"\"Apply the stored transformers to `table`.\n\n        Args:\n            table(pandas.DataFrame):     Contents of the table to be transformed.\n\n            table_meta(dict):   Metadata for the given table.\n\n            missing(bool):      Wheter or not use NullTransformer to handle missing values.\n\n        Returns:\n            pandas.DataFrame: Transformed table.\n        \"\"\"\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(DEPRECATION_MESSAGE.format('transform_table'), DeprecationWarning)\n\n        content = {}\n        columns = []\n        table_name = table_meta['name']\n\n        for field in table_meta['fields']:\n            column_name = field['name']\n\n            if missing and table[column_name].isnull().any():\n                null_transformer = transformers.NullTransformer(field)\n                clean_column = null_transformer.fit_transform(table[column_name])\n                null_name = '?' + column_name\n                columns.append(null_name)\n                content[null_name] = clean_column[null_name].values\n                column = clean_column[column_name]\n\n            else:\n                column = table[column_name].to_frame()\n\n            transformer = self.transformers[(table_name, column_name)]\n            content[column_name] = transformer.transform(column)[column_name].values\n            columns.append(column_name)\n\n        return pd.DataFrame(content, columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reverse_transform_table(self, table, table_meta, missing=None):\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(\n                DEPRECATION_MESSAGE.format('reverse_transform_table'), DeprecationWarning)\n\n        result = pd.DataFrame(index=table.index)\n        table_name = table_meta['name']\n\n        for field in table_meta['fields']:\n            new_column = self._reverse_transform_column(table, field, table_name)\n            if new_column is not None:\n                result[field['name']] = new_column\n\n        return result", "response": "Transform a table back to its original format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates apply and store the specified transformers for the given tables.", "response": "def fit_transform(\n            self, tables=None, transformer_dict=None, transformer_list=None, missing=None):\n        \"\"\"Create, apply and store the specified transformers for the given tables.\n\n        Args:\n            tables(dict):   Mapping of table names to `tuple` where each tuple is on the form\n                            (`pandas.DataFrame`, `dict`). The `DataFrame` contains the table data\n                            and the `dict` the corresponding meta information.\n                            If not specified, the tables will be retrieved using the meta_file.\n\n            transformer_dict(dict):     Mapping  `tuple(str, str)` -> `str` where the tuple is\n                                        (table_name, column_name).\n\n            transformer_list(list):     List of transformers to use. Overrides the transformers in\n                                        the meta_file.\n\n            missing(bool):      Wheter or not use NullTransformer to handle missing values.\n\n        Returns:\n            dict: Map from `str` (table_names) to `pandas.DataFrame` (transformed data).\n        \"\"\"\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(DEPRECATION_MESSAGE.format('fit_transform'), DeprecationWarning)\n\n        transformed = {}\n\n        if tables is None:\n            tables = self.table_dict\n\n        if transformer_dict is None and transformer_list is None:\n            transformer_dict = self.transformer_dict\n\n        for table_name in tables:\n            table, table_meta = tables[table_name]\n            transformed_table = self.fit_transform_table(\n                table, table_meta, transformer_dict, transformer_list)\n\n            transformed[table_name] = transformed_table\n\n        return transformed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform(self, tables, table_metas=None, missing=None):\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(DEPRECATION_MESSAGE.format('transform'), DeprecationWarning)\n\n        transformed = {}\n\n        for table_name in tables:\n            table = tables[table_name]\n\n            if table_metas is None:\n                table_meta = self.table_dict[table_name][1]\n            else:\n                table_meta = table_metas[table_name]\n\n            transformed[table_name] = self.transform_table(table, table_meta)\n\n        return transformed", "response": "Apply all the saved transformers to tables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming data back to its original format.", "response": "def reverse_transform(self, tables, table_metas=None, missing=None):\n        \"\"\"Transform data back to its original format.\n\n        Args:\n            tables(dict):   mapping of table names to `tuple` where each tuple is on the form\n                            (`pandas.DataFrame`, `dict`). The `DataFrame` contains the transformed\n                            data and the `dict` the corresponding meta information.\n                            If not specified, the tables will be retrieved using the meta_file.\n\n            table_metas(dict):  Full metadata file for the dataset.\n\n            missing(bool):      Wheter or not use NullTransformer to handle missing values.\n\n        Returns:\n            dict: Map from `str` (table_names) to `pandas.DataFrame` (transformed data).\n        \"\"\"\n\n        if missing is None:\n            missing = self.missing\n\n        else:\n            self.missing = missing\n            warnings.warn(DEPRECATION_MESSAGE.format('reverse_transform'), DeprecationWarning)\n\n        reverse = {}\n\n        for table_name in tables:\n            table = tables[table_name]\n            if table_metas is None:\n                table_meta = self.table_dict[table_name][1]\n            else:\n                table_meta = table_metas[table_name]\n\n            reverse[table_name] = self.reverse_transform_table(table, table_meta)\n\n        return reverse"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef echo(msg, *args, **kwargs):\n    '''Wraps click.echo, handles formatting and check encoding'''\n    file = kwargs.pop('file', None)\n    nl = kwargs.pop('nl', True)\n    err = kwargs.pop('err', False)\n    color = kwargs.pop('color', None)\n    msg = safe_unicode(msg).format(*args, **kwargs)\n    click.echo(msg, file=file, nl=nl, err=err, color=color)", "response": "Wraps click. echo and handles formatting and check encoding"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisplays a success message", "response": "def success(msg, *args, **kwargs):\n    '''Display a success message'''\n    echo('{0} {1}'.format(green(OK), white(msg)), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef warning(msg, *args, **kwargs):\n    '''Display a warning message'''\n    msg = '{0} {1}'.format(yellow(WARNING), msg)\n    echo(msg, *args, **kwargs)", "response": "Display a warning message"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays an error message with optionnal details", "response": "def error(msg, details=None, *args, **kwargs):\n    '''Display an error message with optionnal details'''\n    msg = '{0} {1}'.format(red(KO), white(msg))\n    if details:\n        msg = '\\n'.join((msg, safe_unicode(details)))\n    echo(format_multiline(msg), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads one or more CADA CSV files matching patterns", "response": "def load(patterns, full_reindex):\n    '''\n    Load one or more CADA CSV files matching patterns\n    '''\n    header('Loading CSV files')\n    for pattern in patterns:\n        for filename in iglob(pattern):\n            echo('Loading {}'.format(white(filename)))\n            with open(filename) as f:\n                reader = csv.reader(f)\n                # Skip header\n                reader.next()\n                for idx, row in enumerate(reader, 1):\n                    try:\n                        advice = csv.from_row(row)\n                        skipped = False\n                        if not full_reindex:\n                            index(advice)\n                        echo('.' if idx % 50 else white(idx), nl=False)\n                    except Exception:\n                        echo(cyan('s') if idx % 50 else white('{0}(s)'.format(idx)), nl=False)\n                        skipped = True\n                if skipped:\n                    echo(white('{}(s)'.format(idx)) if idx % 50 else '')\n                else:\n                    echo(white(idx) if idx % 50 else '')\n                success('Processed {0} rows'.format(idx))\n    if full_reindex:\n        reindex()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile and collect static files into path", "response": "def static(path, no_input):\n    '''Compile and collect static files into path'''\n    log = logging.getLogger('webassets')\n    log.addHandler(logging.StreamHandler())\n    log.setLevel(logging.DEBUG)\n\n    cmdenv = CommandLineEnvironment(assets, log)\n    cmdenv.build()\n\n    if exists(path):\n        warning('{0} directory already exists and will be {1}', white(path), white('erased'))\n        if not no_input and not click.confirm('Are you sure'):\n            exit_with_error()\n        shutil.rmtree(path)\n\n    echo('Copying assets into {0}', white(path))\n    shutil.copytree(assets.directory, path)\n\n    success('Done')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef anon():\n    '''Check for candidates to anonymization'''\n    header(anon.__doc__)\n    filename = 'urls_to_check.csv'\n\n    candidates = Advice.objects(__raw__={\n        '$or': [\n            {'subject': {\n                '$regex': '(Monsieur|Madame|Docteur|Mademoiselle)\\s+[^X\\s\\.]{3}',\n                '$options': 'imx',\n            }},\n            {'content': {\n                '$regex': '(Monsieur|Madame|Docteur|Mademoiselle)\\s+[^X\\s\\.]{3}',\n                '$options': 'imx',\n            }}\n        ]\n    })\n\n    with open(filename, 'wb') as csvfile:\n        writer = csv.writer(csvfile)\n        # Generate header\n        writer.writerow(csv.ANON_HEADER)\n\n        for idx, advice in enumerate(candidates, 1):\n            writer.writerow(csv.to_anon_row(advice))\n            echo('.' if idx % 50 else white(idx), nl=False)\n        echo(white(idx) if idx % 50 else '')\n\n    success('Total: {0} candidates', len(candidates))", "response": "Check for candidates to anonymization"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying a fix to a single file.", "response": "def fix(csvfile):\n    '''Apply a fix (ie. remove plain names)'''\n    header('Apply fixes from {}', csvfile.name)\n    bads = []\n    reader = csv.reader(csvfile)\n    reader.next()  # Skip header\n    for id, _, sources, dests in reader:\n        advice = Advice.objects.get(id=id)\n        sources = [s.strip() for s in sources.split(',') if s.strip()]\n        dests = [d.strip() for d in dests.split(',') if d.strip()]\n        if not len(sources) == len(dests):\n            bads.append(id)\n            continue\n        for source, dest in zip(sources, dests):\n            echo('{0}: Replace {1} with {2}', white(id), white(source), white(dest))\n            advice.subject = advice.subject.replace(source, dest)\n            advice.content = advice.content.replace(source, dest)\n        advice.save()\n        index(advice)\n    for id in bads:\n        echo('{0}: Replacements length not matching', white(id))\n    success('Done')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_channel(namespace, name, user_ids):\n    ids = ','.join(map(str, user_ids))\n    return \"{0}:{1}#{2}\".format(namespace, name, ids)", "response": "Builds a channel name from the given namespace name and user_ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login(self, **kwargs):\n    if 'signed_username' in kwargs:\n      apiToken = kwargs['signed_username']\n      if kwargs.get('authenticate', False):\n        self._checkReturn(requests.get(\"{}/users?signed_username={}\".format(self.url, apiToken)))\n      self.signedUsername = apiToken\n    else:\n      auth = (kwargs['user_id'], kwargs['token'])\n      self.signedUsername = self._checkReturn(requests.get(\"{}/users/login\".format(self.url), auth=auth))[\n        'signed_username']", "response": "Logs the current user into the server with the passed in credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads an asset to the server.", "response": "def uploadAsset(self, data, async=False, metadata=None, callback=None):\n    \"\"\"Takes an array of bytes or a BufferedReader and uploads it. If async=false a json with the result is returned otherwise a json with an asset_id is returned.\n    :param data: array of bytes or BufferedReader\n    :param metadata: arbitrary additional description information for the asset\n    :param async:\n    :param callback: Callback URL\n    :return:\n    \"\"\"\n    #todo: has atter read would be better here\n    if isinstance(data, io.BufferedReader):\n      data = data.read()\n    assert isinstance(data, bytes)\n    data = base64.b64encode(data)\n    audio = {'content': data.decode(\"utf-8\")}\n    config = {'async': async}\n    if callback is not None:\n      config['callback'] = callback\n\n    if metadata is not None:\n      body = {'audio': audio, 'config': config, 'metadata': metadata}\n    else:\n      body = {'audio': audio, 'config': config}\n\n    return self._checkReturn(\n      requests.post(\"{}/speech:recognize?signed_username={}\".format(self.url, self.signedUsername), json=body))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(filename=None,\n        url=r\"https://raw.githubusercontent.com/googlei18n/emoji4unicode/master/data/emoji4unicode.xml\",\n        loader_class=None):\n    u\"\"\"load google's `emoji4unicode` project's xml file. must call this method first to use `e4u` library. this method never work twice if you want to reload, use `e4u.reload()` insted.\"\"\"\n    if not has_loaded():\n        reload(filename, url, loader_class)", "response": "u load google s emoji4unicode project s xml file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reload(filename=None,\n        url=r\"https://raw.githubusercontent.com/googlei18n/emoji4unicode/master/data/emoji4unicode.xml\",\n        loader_class=None):\n    u\"\"\"reload google's `emoji4unicode` project's xml file. must call this method first to use `e4u` library.\"\"\"\n    if loader_class is None:\n        loader_class = loader.Loader\n    global _loader\n    _loader = loader_class()\n    _loader.load(filename, url)", "response": "u reload google s emoji4unicode project s xml file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef translate(source, carrier, reverse=False, encoding=None):\n    if not isinstance(source, unicode) and encoding:\n        source = source.decode(encoding, 'replace')\n    elif not isinstance(source, unicode):\n        raise AttributeError(u\"`source` must be decoded to `unicode` or set `encoding` attribute to decode `source`\")\n    regex_pattern = _loader.regex_patterns[carrier]\n    translate_dictionary = _loader.translate_dictionaries[carrier]\n    if not reverse:\n        regex_pattern = regex_pattern[0]\n        translate_dictionary = translate_dictionary[0]\n    else:\n        regex_pattern = regex_pattern[1]\n        translate_dictionary = translate_dictionary[1]\n    if not regex_pattern or not translate_dictionary:\n        return source\n    return regex_pattern.sub(lambda m: translate_dictionary[m.group()], source)", "response": "u translate unicode text to carrier text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_file_encrypted(self, filename):\n        '''\n        Given a file. Check if it is already encrypted.\n        '''\n        if not os.path.exists(filename):\n            print \"Invalid filename %s. Does not exist\" % filename\n            return False\n\n        fhandle = open(filename, \"rb\")\n        data = fhandle.read()\n        fhandle.close()\n\n        if data.startswith(AnsiVault.HEADER):\n            return True\n        else:\n            return False", "response": "Check if a file is already encrypted."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencrypts File Args: filename: Pass the filename to encrypt. Returns: No return.", "response": "def encrpyt_file(self, filename):\n        '''\n        Encrypt File\n        Args:\n            filename: Pass the filename to encrypt.\n        Returns:\n            No return.\n        '''\n        if not os.path.exists(filename):\n            print \"Invalid filename %s. Does not exist\" % filename\n            return\n\n        if self.vault_password is None:\n            print \"ENV Variable PYANSI_VAULT_PASSWORD not set\"\n            return\n\n        if self.is_file_encrypted(filename):\n            # No need to do anything.\n            return\n\n        cipher = 'AES256'\n        vaulteditor = VaultEditor(cipher, self.vault_password, filename)\n        vaulteditor.encrypt_file()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decrypt_file(self, filename):\n        '''\n        Decrypt File\n        Args:\n            filename: Pass the filename to encrypt.\n        Returns:\n            No return.\n        '''\n        if not os.path.exists(filename):\n            print \"Invalid filename %s. Does not exist\" % filename\n            return\n\n        if self.vault_password is None:\n            print \"ENV Variable PYANSI_VAULT_PASSWORD not set\"\n            return\n\n        if not self.is_file_encrypted(filename):\n            # No need to do anything.\n            return\n\n        cipher = 'AES256'\n        vaulteditor = VaultEditor(cipher, self.vault_password, filename)\n        vaulteditor.decrypt_file()", "response": "Decrypt a file and return the ID of the decrypted file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef common_start(*args):\n    def _iter():\n        for s in zip(*args):\n            if len(set(s)) < len(args):\n                yield s[0]\n            else:\n                return\n\n    out = \"\".join(_iter()).strip()\n    result = [s for s in args if not s.startswith(out)]\n    result.insert(0, out)\n    return ', '.join(result)", "response": "returns the longest common substring from the beginning of sa and sb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef determine_json_encoding(json_bytes):\n\t'''\n\tGiven the fact that the first 2 characters in json are guaranteed to be ASCII, we can use\n\tthese to determine the encoding.\n\tSee: http://tools.ietf.org/html/rfc4627#section-3\n\n\tCopied here:\n\t   Since the first two characters of a JSON text will always be ASCII\n\t   characters [RFC0020], it is possible to determine whether an octet\n\t   stream is UTF-8, UTF-16 (BE or LE), or UTF-32 (BE or LE) by looking\n\t   at the pattern of nulls in the first four octets.\n\n\t\t\t   00 00 00 xx  UTF-32BE\n\t\t\t   00 xx 00 xx  UTF-16BE\n\t\t\t   xx 00 00 00  UTF-32LE\n\t\t\t   xx 00 xx 00  UTF-16LE\n\t\t\t   xx xx xx xx  UTF-8\n\t'''\n\n\tassert isinstance(json_bytes, bytes), \"`determine_json_encoding()` can only operate on bytestring inputs\"\n\n\tif len(json_bytes) > 4:\n\t\tb1, b2, b3, b4 = json_bytes[0], json_bytes[1], json_bytes[2], json_bytes[3]\n\t\tif   b1 == 0 and b2 == 0 and b3 == 0 and b4 != 0:\n\t\t\treturn \"UTF-32BE\"\n\t\telif b1 == 0 and b2 != 0 and b3 == 0 and b4 != 0:\n\t\t\treturn \"UTF-16BE\"\n\t\telif b1 != 0 and b2 == 0 and b3 == 0 and b4 == 0:\n\t\t\treturn \"UTF-32LE\"\n\t\telif b1 != 0 and b2 == 0 and b3 != 0 and b4 == 0:\n\t\t\treturn \"UTF-16LE\"\n\t\telif b1 != 0 and b2 != 0 and b3 != 0 and b4 != 0:\n\t\t\treturn \"UTF-8\"\n\t\telse:\n\t\t\traise Exceptions.ContentTypeError(\"Unknown encoding!\")\n\n\telif len(json_bytes) > 2:\n\t\tb1, b2 = json_bytes[0], json_bytes[1]\n\t\tif   b1 == 0 and b2 == 0:\n\t\t\treturn \"UTF-32BE\"\n\t\telif b1 == 0 and b2 != 0:\n\t\t\treturn \"UTF-16BE\"\n\t\telif b1 != 0 and b2 == 0:\n\t\t\traise Exceptions.ContentTypeError(\"Json string too short to definitively infer encoding.\")\n\t\telif b1 != 0 and b2 != 0:\n\t\t\treturn \"UTF-8\"\n\t\telse:\n\t\t\traise Exceptions.ContentTypeError(\"Unknown encoding!\")\n\n\traise Exceptions.ContentTypeError(\"Input string too short to guess encoding!\")", "response": "This function determines the encoding of the given JSON bytestring."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a random string from the available language.", "response": "def passgen(length=12, punctuation=False, digits=True, letters=True,\n            case=\"both\", **kwargs):\n    \"\"\"Generate random password.\n\n    Args:\n        length (int): The length of the password.  Must be greater than\n            zero. Defaults to 12.\n        punctuation (bool): Whether to use punctuation or not.  Defaults\n            to False.\n        limit_punctuation (str): Limits the allowed puncturation to defined \n            characters.\n        digits (bool): Whether to use digits or not.  Defaults to True.\n            One of *digits* and *letters* must be True.\n        letters (bool): Whether to use letters or not.  Defaults to\n            True. One of *digits* and *letters* must be True.\n        case (str): Letter case to use.  Accepts 'upper' for upper case,\n            'lower' for lower case, and 'both' for both.  Defaults to\n            'both'.\n        \n    Returns:\n        str. The generated password.\n\n    Raises:\n        ValueError\n\n    Below are some basic examples.\n\n    >>> passgen()\n    z7GlutdEEbnk\n\n    >>> passgen(case='upper')\n    Q81J9DOAMBRN\n\n    >>> passgen(length=6)\n    EzJMRX\n    \"\"\"\n\n    p_min = punctuation\n    p_max = 0 if punctuation is False else length\n    d_min = digits\n    d_max = 0 if digits is False else length\n    a_min = letters\n    a_max = 0 if letters is False else length\n\n    if d_min + p_min + a_min > length:\n        raise ValueError(\"Minimum punctuation and digits number cannot be greater than length\")    \n    if not digits and not letters:\n        raise ValueError(\"digits and letters cannot be False at the same time\")\n    if length < 1:\n        raise ValueError(\"length must be greater than zero\")\n\n    if letters:\n        if case == \"both\":\n            alpha = string.ascii_uppercase + string.ascii_lowercase\n        elif case == \"upper\":\n            alpha = string.ascii_uppercase\n        elif case == \"lower\":\n            alpha = string.ascii_lowercase\n        else:\n            raise ValueError(\"case can only be 'both', 'upper' or 'lower'\")\n    else:\n        alpha = string.ascii_uppercase + string.ascii_lowercase\n    if punctuation:\n        limit_punctuation = kwargs.get('limit_punctuation', '')\n        if limit_punctuation == '':\n            punctuation_set = string.punctuation\n        else:\n            # In case limit_punctuation contains non-punctuation characters\n            punctuation_set = ''.join([p for p in limit_punctuation\n                                   if p in string.punctuation])\n    else:\n        punctuation_set = string.punctuation\n\n    srandom = random.SystemRandom()\n    p_generator = Generator(punctuation_set, srandom, p_min, p_max)\n    d_generator = Generator(string.digits, srandom, d_min, d_max)\n    a_generator = Generator(alpha, srandom, a_min, a_max)\n\n    main_generator = SuperGenerator(srandom, length, length)\n    main_generator.add(p_generator)\n    main_generator.add(a_generator)\n    main_generator.add(d_generator)\n    chars = []\n    for i in main_generator:\n        chars.append(i)\n    try:\n        srandom.shuffle(chars, srandom)\n    except:\n        random.shuffle(chars)\n    return \"\".join(chars)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning converter. Args: language: (unicode) language code.", "response": "def convert(self, language, *args, **kwargs):\n        \"\"\"\n        Run converter.\n        Args:\n            language: (unicode) language code.\n        \"\"\"\n\n        for f in find_pos(language):\n            PoToXls(src=f, **kwargs).convert()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_language(self, request, org):\n        if org:\n            lang = org.language or settings.DEFAULT_LANGUAGE\n            translation.activate(lang)", "response": "Set the current language from the org configuration."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_timezone(self, request, org):\n        if org and org.timezone:\n            timezone.activate(org.timezone)", "response": "Set the current timezone from the org configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the transformer to convert data and return the processed table.", "response": "def transform(self, col):\n        \"\"\"Prepare the transformer to convert data and return the processed table.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n        out = pd.DataFrame(index=col.index)\n        out[self.col_name] = col.fillna(self.default_value)\n        out[self.new_name] = (pd.notnull(col) * 1).astype(int)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reverse_transform(self, col):\n        output = pd.DataFrame()\n        new_name = '?' + self.col_name\n\n        col.loc[col[new_name] == 0, self.col_name] = np.nan\n        output[self.col_name] = col[self.col_name]\n        return output", "response": "Converts data back into original format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_private_ip(ip):\n\tnetworks = [\n\t\t\"0.0.0.0/8\",\n\t\t\"10.0.0.0/8\",\n\t\t\"100.64.0.0/10\",\n\t\t\"127.0.0.0/8\",\n\t\t\"169.254.0.0/16\",\n\t\t\"172.16.0.0/12\",\n\t\t\"192.0.0.0/24\",\n\t\t\"192.0.2.0/24\",\n\t\t\"192.88.99.0/24\",\n\t\t\"192.168.0.0/16\",\n\t\t\"198.18.0.0/15\",\n\t\t\"198.51.100.0/24\",\n\t\t\"203.0.113.0/24\",\n\t\t\"240.0.0.0/4\",\n\t\t\"255.255.255.255/32\",\n\t\t\"224.0.0.0/4\",\n\t]\n\n\tfor network in networks:\n\t\ttry:\n\t\t\tipaddr = struct.unpack(\">I\", socket.inet_aton(ip))[0]\n\n\t\t\tnetaddr, bits = network.split(\"/\")\n\n\t\t\tnetwork_low = struct.unpack(\">I\", socket.inet_aton(netaddr))[0]\n\t\t\tnetwork_high = network_low | 1 << (32 - int(bits)) - 1\n\n\t\t\tif ipaddr <= network_high and ipaddr >= network_low:\n\t\t\t\treturn True\n\t\texcept Exception:\n\t\t\tcontinue\n\n\treturn False", "response": "Checks if the given IP address belongs to private network blocks."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new object to the list of tracks.", "response": "def add(self, obj):\n        \"\"\"\n        Add pre-created tracks.\n        If the tracks are already created, we hijack the data.\n        This way the pointer to the pre-created tracks are still valid.\n        \"\"\"\n        obj.controller = self.controller\n        # Is the track already loaded or created?\n        track = self.tracks.get(obj.name)\n        if track:\n            if track == obj:\n                return\n            # hijack the track data\n            obj.keys = track.keys\n            obj.controller = track.controller\n            self.tracks[track.name] = obj\n            self.track_index[self.track_index.index(track)] = obj\n        else:\n            # Add a new track\n            obj.controller = self.controller\n            self.tracks[obj.name] = obj\n            self.track_index.append(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the value at a given row", "response": "def row_value(self, row):\n        \"\"\"Get the tracks value at row\"\"\"\n        irow = int(row)\n        i = self._get_key_index(irow)\n        if i == -1:\n            return 0.0\n\n        # Are we dealing with the last key?\n        if i == len(self.keys) - 1:\n            return self.keys[-1].value\n\n        return TrackKey.interpolate(self.keys[i], self.keys[i + 1], row)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds or update a track value", "response": "def add_or_update(self, row, value, kind):\n        \"\"\"Add or update a track value\"\"\"\n        i = bisect.bisect_left(self.keys, row)\n\n        # Are we simply replacing a key?\n        if i < len(self.keys) and self.keys[i].row == row:\n            self.keys[i].update(value, kind)\n        else:\n            self.keys.insert(i, TrackKey(row, value, kind))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a track value", "response": "def delete(self, row):\n        \"\"\"Delete a track value\"\"\"\n        i = self._get_key_index(row)\n        del self.keys[i]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_key_index(self, row):\n        # Don't bother with empty tracks\n        if len(self.keys) == 0:\n            return -1\n\n        # No track values are defined yet\n        if row < self.keys[0].row:\n            return -1\n\n        # Get the insertion index\n        index = bisect.bisect_left(self.keys, row)\n        # Index is within the array size?\n        if index < len(self.keys):\n            # Are we inside an interval?\n            if row < self.keys[index].row:\n                return index - 1\n            return index\n\n        # Return the last index\n        return len(self.keys) - 1", "response": "Get the key that should be used as the first interpolation value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the track file", "response": "def load(self, filepath):\n        \"\"\"Load the track file\"\"\"\n        with open(filepath, 'rb') as fd:\n            num_keys = struct.unpack(\">i\", fd.read(4))[0]\n            for i in range(num_keys):\n                row, value, kind = struct.unpack('>ifb', fd.read(9))\n                self.keys.append(TrackKey(row, value, kind))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, path):\n        name = Track.filename(self.name)\n        with open(os.path.join(path, name), 'wb') as fd:\n            fd.write(struct.pack('>I', len(self.keys)))\n            for k in self.keys:\n                fd.write(struct.pack('>ifb', k.row, k.value, k.kind))", "response": "Save the track to a file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting an IRI to a URI.", "response": "def iri2uri(uri):\n\t\"\"\"Convert an IRI to a URI. Note that IRIs must be\n\tpassed in a unicode strings. That is, do not utf-8 encode\n\tthe IRI before passing it into the function.\"\"\"\n\n\tassert uri != None, 'iri2uri must be passed a non-none string!'\n\n\toriginal = uri\n\tif isinstance(uri ,str):\n\t\t(scheme, authority, path, query, fragment) = urllib.parse.urlsplit(uri)\n\t\tauthority = authority.encode('idna').decode('utf-8')\n\t\t# For each character in 'ucschar' or 'iprivate'\n\t\t#  1. encode as utf-8\n\t\t#  2. then %-encode each octet of that utf-8\n\t\t# path = urllib.parse.quote(path)\n\t\turi = urllib.parse.urlunsplit((scheme, authority, path, query, fragment))\n\t\turi = \"\".join([encode(c) for c in uri])\n\n\t# urllib.parse.urlunsplit(urllib.parse.urlsplit({something})\n\t# strips any trailing \"?\" chars. While this may be legal according to the\n\t# spec, it breaks some services. Therefore, we patch\n\t# the \"?\" back in if it has been removed.\n\tif original.endswith(\"?\") and not uri.endswith(\"?\"):\n\t\turi = uri+\"?\"\n\treturn uri"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating and set the host list and remote user parameters.", "response": "def validate_host_parameters(self, host_list, remote_user):\n        '''\n        Validate and set the host list and remote user parameters.\n        '''\n        if host_list is None:\n            host_list = self.host_list\n\n        if remote_user is None:\n            remote_user = self.remote_user\n\n        if host_list is None or remote_user is None:\n            print \"Host list [%s], remote user [%s] are required\" % \\\n                  (host_list, remote_user)\n            return (None, None)\n\n        return (host_list, remote_user)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_results(self, results, checks=None):\n        '''\n        Valdiate results from the Anisble Run.\n        '''\n        results['status'] = 'PASS'\n        failed_hosts = []\n\n        ###################################################\n        # First validation is to make sure connectivity to\n        # all the hosts was ok.\n        ###################################################\n        if results['dark']:\n            print \"Host connectivity issues on %s\",\n            results['dark'].keys()\n            failed_hosts.append(results['dark'].keys())\n            results['status'] = 'FAIL'\n\n        ##################################################\n        # Now look for status 'failed'\n        ##################################################\n        for node in results['contacted'].keys():\n            if 'failed' in results['contacted'][node]:\n                if results['contacted'][node]['failed'] is True:\n                    results['status'] = 'FAIL'\n\n        #################################################\n        # Check for the return code 'rc' for each host.\n        #################################################\n        for node in results['contacted'].keys():\n            rc = results['contacted'][node].get('rc', None)\n            if rc is not None and rc != 0:\n                print \"Operation 'return code' %s on host %s\" % \\\n                    (results['contacted'][node]['rc'], node)\n                failed_hosts.append(node)\n                results['status'] = 'FAIL'\n\n        ##################################################\n        # Additional checks. If passed is a list of key/value\n        # pairs that should be matched.\n        ##################################################\n        if checks is None:\n            #print \"No additional checks validated\"\n            return results, failed_hosts\n\n        for check in checks:\n            key = check.keys()[0]\n            value = check.values()[0]\n            for node in results['contacted'].keys():\n                if key in results['contacted'][node].keys():\n                    if results['contacted'][node][key] != value:\n                        failed_hosts.append(node)\n                        results['status'] = 'FAIL'\n\n        return (results, failed_hosts)", "response": "Validate the results of a run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ansible_perform_operation(self,\n                                  host_list=None,\n                                  remote_user=None,\n                                  remote_pass=None,\n                                  module=None,\n                                  complex_args=None,\n                                  module_args='',\n                                  environment=None,\n                                  check=False,\n                                  sudo=False,\n                                  sudo_user=None,\n                                  sudo_pass=None,\n                                  forks=20):\n        '''\n        Perform any ansible operation.\n        '''\n        (host_list, remote_user) = \\\n            self.validate_host_parameters(host_list, remote_user)\n        if (host_list, remote_user) is (None, None):\n            return None\n\n        if module is None:\n            print \"ANSIBLE Perform operation: No module specified\"\n            return None\n\n        runner = ansible.runner.Runner(\n            module_name=module,\n            host_list=host_list,\n            remote_user=remote_user,\n            remote_pass=remote_pass,\n            module_args=module_args,\n            complex_args=complex_args,\n            environment=environment,\n            check=check,\n            become=sudo,\n            become_user=sudo_user,\n            become_pass=sudo_pass,\n            forks=forks)\n\n        results = runner.run()\n\n        results, failed_hosts = self.validate_results(results)\n        if results['status'] != 'PASS':\n            print \"ANSIBLE: [%s] operation failed [%s] [hosts: %s]\" % \\\n                (module, complex_args, failed_hosts)\n\n        return results, failed_hosts", "response": "An ansible - specific method to perform an ansible operation on a set of hosts."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the header of the given name to the given xlwt. Worksheet instance.", "response": "def header(self, sheet, name):\n        \"\"\"\n        Write sheet header.\n        Args:\n            sheet: (xlwt.Worksheet.Worksheet) instance of xlwt sheet.\n            name: (unicode) name of sheet.\n        \"\"\"\n\n        header = sheet.row(0)\n        for i, column in enumerate(self.headers[name]):\n            header.write(i, self.headers[name][i])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating full path for excel file to save parsed translations strings.", "response": "def output(self):\n        \"\"\"\n        Create full path for excel file to save parsed translations strings.\n        Returns:\n            unicode: full path for excel file to save parsed translations strings.\n        \"\"\"\n\n        path, src = os.path.split(self.src)\n        src, ext = os.path.splitext(src)\n\n        return os.path.join(path, \"{src}.xls\".format(**{\"src\": src, }))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the set of strings in the result file.", "response": "def strings(self):\n        \"\"\"\n        Write strings sheet.\n        \"\"\"\n\n        sheet = self.result.add_sheet(\"strings\")\n        self.header(sheet, \"strings\")\n\n        n_row = 1  # row number\n\n        for entry in self.po:\n            row = sheet.row(n_row)\n            row.write(0, entry.msgid)\n            row.write(1, entry.msgstr)\n            n_row += 1\n            sheet.flush_row_data()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert(self, *args, **kwargs):\n\n        self.strings()\n        self.metadata()\n\n        # save file\n        self.result.save(self.output())", "response": "Convert the object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing command - line options.", "response": "def _parser():\n    \"\"\"Parse command-line options.\"\"\"\n    launcher = 'pip%s-utils' % sys.version_info.major\n\n    parser = argparse.ArgumentParser(\n        description='%s.' % __description__,\n        epilog='See `%s COMMAND --help` for help '\n               'on a specific subcommand.' % launcher,\n        prog=launcher)\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='%(prog)s ' + __version__)\n\n    subparsers = parser.add_subparsers()\n\n    # dependants\n    parser_dependants = subparsers.add_parser(\n        'dependants',\n        add_help=False,\n        help='list dependants of package')\n    parser_dependants.add_argument(\n        'package',\n        metavar='PACKAGE',\n        type=_distribution)\n    parser_dependants.add_argument(\n        '-h', '--help',\n        action='help',\n        help=argparse.SUPPRESS)\n    parser_dependants.set_defaults(\n        func=command_dependants)\n\n    # dependents\n    parser_dependents = subparsers.add_parser(\n        'dependents',\n        add_help=False,\n        help='list dependents of package')\n    parser_dependents.add_argument(\n        'package',\n        metavar='PACKAGE',\n        type=_distribution)\n    parser_dependents.add_argument(\n        '-i', '--info',\n        action='store_true',\n        help='show version requirements')\n    parser_dependents.add_argument(\n        '-r', '--recursive',\n        action='store_true',\n        help='list dependencies recursively')\n    parser_dependents.add_argument(\n        '-h', '--help',\n        action='help',\n        help=argparse.SUPPRESS)\n    parser_dependents.set_defaults(\n        func=command_dependents)\n\n    # locate\n    parser_locate = subparsers.add_parser(\n        'locate',\n        add_help=False,\n        help='identify packages that file belongs to')\n    parser_locate.add_argument(\n        'file',\n        metavar='FILE',\n        type=argparse.FileType('r'))\n    parser_locate.add_argument(\n        '-h', '--help',\n        action='help',\n        help=argparse.SUPPRESS)\n    parser_locate.set_defaults(\n        func=command_locate)\n\n    # outdated\n    parser_outdated = subparsers.add_parser(\n        'outdated',\n        add_help=False,\n        help='list outdated packages that may be updated')\n    parser_outdated.add_argument(\n        '-b', '--brief',\n        action='store_true',\n        help='show package name only')\n    group = parser_outdated.add_mutually_exclusive_group()\n    group.add_argument(\n        '-a', '--all',\n        action='store_true',\n        help='list all outdated packages')\n    group.add_argument(\n        '-p', '--pinned',\n        action='store_true',\n        help='list outdated packages unable to be updated')\n    group.add_argument(\n        '-U', '--upgrade',\n        action='store_true',\n        dest='update',\n        help='update packages that can be updated'\n    )\n    parser_outdated.add_argument(\n        '-h', '--help',\n        action='help',\n        help=argparse.SUPPRESS)\n    parser_outdated.set_defaults(\n        func=command_outdated)\n\n    # parents\n    parser_parents = subparsers.add_parser(\n        'parents',\n        add_help=False,\n        help='list packages lacking dependants')\n    parser_parents.add_argument(\n        '-h', '--help',\n        action='help',\n        help=argparse.SUPPRESS)\n    parser_parents.set_defaults(\n        func=command_parents)\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync_local_to_set(org, syncer, remote_set):\n    outcome_counts = defaultdict(int)\n\n    remote_identities = set()\n\n    for remote in remote_set:\n        outcome = sync_from_remote(org, syncer, remote)\n        outcome_counts[outcome] += 1\n\n        remote_identities.add(syncer.identify_remote(remote))\n\n    # active local objects which weren't in the remote set need to be deleted\n    active_locals = syncer.fetch_all(org).filter(is_active=True)\n    delete_locals = active_locals.exclude(**{syncer.local_id_attr + \"__in\": remote_identities})\n\n    for local in delete_locals:\n        with syncer.lock(org, syncer.identify_local(local)):\n            syncer.delete_local(local)\n            outcome_counts[SyncOutcome.deleted] += 1\n\n    return (\n        outcome_counts[SyncOutcome.created],\n        outcome_counts[SyncOutcome.updated],\n        outcome_counts[SyncOutcome.deleted],\n        outcome_counts[SyncOutcome.ignored],\n    )", "response": "Syncs an org s set of local objects to match the set of remote objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_local_to_changes(org, syncer, fetches, deleted_fetches, progress_callback=None):\n    num_synced = 0\n    outcome_counts = defaultdict(int)\n\n    for fetch in fetches:\n        for remote in fetch:\n            outcome = sync_from_remote(org, syncer, remote)\n            outcome_counts[outcome] += 1\n\n        num_synced += len(fetch)\n        if progress_callback:\n            progress_callback(num_synced)\n\n    # any item that has been deleted remotely should also be released locally\n    for deleted_fetch in deleted_fetches:\n        for deleted_remote in deleted_fetch:\n            identity = syncer.identify_remote(deleted_remote)\n            with syncer.lock(org, identity):\n                existing = syncer.fetch_local(org, identity)\n                if existing:\n                    syncer.delete_local(existing)\n                    outcome_counts[SyncOutcome.deleted] += 1\n\n        num_synced += len(deleted_fetch)\n        if progress_callback:\n            progress_callback(num_synced)\n\n    return (\n        outcome_counts[SyncOutcome.created],\n        outcome_counts[SyncOutcome.updated],\n        outcome_counts[SyncOutcome.deleted],\n        outcome_counts[SyncOutcome.ignored],\n    )", "response": "Syncs local objects against iterators which return fetches of modified and deleted remote objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch the local model instance with the given identity returning none if it doesn t exist", "response": "def fetch_local(self, org, identity):\n        \"\"\"\n        Fetches the local model instance with the given identity, returning none if it doesn't exist\n        :param org: the org\n        :param identity: the unique identity\n        :return: the instance or none\n        \"\"\"\n        qs = self.fetch_all(org=org).filter(**{self.local_id_attr: identity})\n\n        if self.select_related:\n            qs = qs.select_related(*self.select_related)\n        if self.prefetch_related:\n            qs = qs.prefetch_related(*self.prefetch_related)\n\n        return qs.first()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches all local objects in the given org", "response": "def fetch_all(self, org):\n        \"\"\"\n        Fetches all local objects\n        :param org: the org\n        :return: the queryset\n        \"\"\"\n        qs = self.model.objects.filter(org=org)\n        if self.local_backend_attr is not None:\n            qs = qs.filter(**{self.local_backend_attr: self.backend})\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves rpn expression return None if not valid.", "response": "def solve(self):\n        \"\"\"Solve rpn expression, return None if not valid.\"\"\"\n        popflag = True\n        self.tmpopslist = []\n        while True:\n            while self.opslist and popflag:\n                op = self.opslist.pop()\n                if self.is_variable(op):\n                    op = self.variables.get(op)\n                if self.is_operator(op):\n                    popflag = False\n                    break\n                self.tmpopslist.append(op)\n\n            # operations\n            tmpr = self._get_temp_result(op)\n            if tmpr == 'ERROR':\n                return None\n\n            if tmpr is not None:\n                self.opslist.append('{r:.20f}'.format(r=tmpr))\n\n            if len(self.tmpopslist) > 0 or len(self.opslist) > 1:\n                popflag = True\n            else:\n                break\n\n        return float(self.opslist[0])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds sort query paramter from kwargs", "response": "def build_sort():\n    '''Build sort query paramter from kwargs'''\n    sorts = request.args.getlist('sort')\n    sorts = [sorts] if isinstance(sorts, basestring) else sorts\n    sorts = [s.split(' ') for s in sorts]\n    return [{SORTS[s]: d} for s, d in sorts if s in SORTS]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nindexing a CADA advice", "response": "def index(advice):\n    '''Index/Reindex a CADA advice'''\n    topics = []\n    for topic in advice.topics:\n        topics.append(topic)\n        parts = topic.split('/')\n        if len(parts) > 1:\n            topics.append(parts[0])\n\n    try:\n        es.index(index=es.index_name, doc_type=DOCTYPE, id=advice.id, body={\n            'id': advice.id,\n            'administration': advice.administration,\n            'type': advice.type,\n            'session': advice.session.strftime('%Y-%m-%d'),\n            'subject': advice.subject,\n            'topics': topics,\n            'tags': advice.tags,\n            'meanings': advice.meanings,\n            'part': advice.part,\n            'content': advice.content,\n        })\n    except Exception:\n        log.exception('Unable to index advice %s', advice.id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate or update indices and mappings", "response": "def initialize(self):\n        '''Create or update indices and mappings'''\n        if es.indices.exists(self.index_name):\n            es.indices.put_mapping(index=self.index_name, doc_type=DOCTYPE, body=MAPPING)\n        else:\n            es.indices.create(self.index_name, {\n                'mappings': {'advice': MAPPING},\n                'settings': {'analysis': ANALSYS},\n            })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show_list_translations(context, item):\n    if not item:\n        return\n\n    manager = Manager()\n    manager.set_master(item)\n\n    ct_item = ContentType.objects.get_for_model(item)\n\n    item_language_codes = manager.get_languages_from_item(ct_item, item)\n    model_language_codes = manager.get_languages_from_model(ct_item.app_label, ct_item.model)\n\n    item_languages = [{'lang': lang, 'from_model': lang.code in model_language_codes}\n                      for lang in TransLanguage.objects.filter(code__in=item_language_codes).order_by('name')]\n\n    more_languages = [{'lang': lang, 'from_model': lang.code in model_language_codes}\n                      for lang in TransLanguage.objects.exclude(main_language=True).order_by('name')]\n\n    return render_to_string('languages/translation_language_selector.html', {\n        'item_languages': item_languages,\n        'more_languages': more_languages,\n        'api_url': TM_API_URL,\n        'app_label': manager.app_label,\n        'model': manager.model_label,\n        'object_pk': item.pk\n    })", "response": "Show the list of translations we want to order or delete from the item it s being edited"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a xml file of the table", "response": "def _create_table_xml_file(self, data, fname=None):\n        \"\"\"Creates a xml file of the table\n        \"\"\"\n        content = self._xml_pretty_print(data)\n        if not fname:\n            fname = self.name\n        with open(fname+\".xml\", 'w') as f:\n            f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a table element tree.", "response": "def _init_table_elementTree(self, xml=True, db_table=True):\n        \"\"\"Create a table \n        \"\"\"\n        # <table> tag object\n        t_table =  xtree.Element('table')\n        # <table xmlns='' securityLevel='' htpps=''>\n        if not self.table_attr :\n            self.table_attr = self._TAB_ATTR\n        for attr in self.table_attr.items() :\n            t_table.set(*attr)\n\n        # <meta>\n        t_meta = xtree.SubElement(t_table, 'meta')\n\n        # Loop over a sorted key,value of class attributes while ignoring table_attr and name\n        for key, value in [(k,v) for k,v in sorted(self.__dict__.items(), key=lambda x: x[0]) if k not in ('table_attr','name') ]:\n            if isinstance(value, list): # Works for element like sampleQuery\n                for elt in value:\n                    t_tag = xtree.SubElement(t_meta, key) # setting attribute name as a tag name\n                    t_tag.text = elt # Setting attribute  value as text\n            else:\n                t_tag = xtree.SubElement(t_meta,key)\n                t_tag.text = value\n      \n        ## <bindings>\n        t_bindings = xtree.SubElement(t_table, 'bindings')\n        ##\n\n        self.etree = t_table\n        return t_table"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave file as xml", "response": "def save(self, name=None, path=None):\n        \"\"\"Save file as xml\n        \"\"\"\n        if path :\n            name = os.path.join(path,name)\n\n        try:\n            self._create_table_xml_file(self.etree, name)\n        except (Exception,) as e:\n            print(e)\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addBinder(self, binder):\n        root = self.etree\n        bindings = root.find('bindings')\n        bindings.append(binder.etree)\n\n        return True", "response": "Adds a binder to the file\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a binder from a table alido", "response": "def removeBinder(self, name):\n        \"\"\"Remove a binder from a table\n        \"\"\"\n        root = self.etree\n        \n        t_bindings = root.find('bindings')\n        \n        t_binder = t_bindings.find(name)\n\n        if t_binder :\n            t_bindings.remove(t_binder)\n            return True\n        \n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the given url is in the current url False otherwise.", "response": "def if_url(context, url_name, yes, no):\n    \"\"\"\n    Example:\n        %li{ class:\"{% if_url 'contacts.contact_read' 'active' '' %}\" }\n    \"\"\"\n    current = context[\"request\"].resolver_match.url_name\n    return yes if url_name == current else no"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a JSON representation of the user s information.", "response": "def post(self, request, *args, **kwargs):\n        \"\"\"\n        Returns a token identifying the user in Centrifugo.\n        \"\"\"\n\n        current_timestamp = \"%.0f\" % time.time()\n        user_id_str = u\"{0}\".format(request.user.id)\n        token = generate_token(settings.CENTRIFUGE_SECRET, user_id_str, \"{0}\".format(current_timestamp), info=\"\")\n\n        # we get all the channels to which the user can subscribe\n        participant = Participant.objects.get(id=request.user.id)\n\n        # we use the threads as channels ids\n        channels = []\n        for thread in Thread.managers.get_threads_where_participant_is_active(participant_id=participant.id):\n            channels.append(\n                build_channel(settings.CENTRIFUGO_MESSAGE_NAMESPACE, thread.id, thread.participants.all())\n            )\n\n        # we also have a channel to alert us about new threads\n        threads_channel = build_channel(settings.CENTRIFUGO_THREAD_NAMESPACE, request.user.id, [request.user.id])  # he is the only one to have access to the channel\n        channels.append(threads_channel)\n\n        # we return the information\n        to_return = {\n            'user': user_id_str,\n            'timestamp': current_timestamp,\n            'token': token,\n            'connection_url': \"{0}connection/\".format(settings.CENTRIFUGE_ADDRESS),\n            'channels': channels,\n            'debug': settings.DEBUG,\n        }\n\n        return HttpResponse(json.dumps(to_return), content_type='application/json; charset=utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef index_queryset(self, using=None):\n        return self.get_model().objects.filter(date_creation__lte=datetime.datetime.now())", "response": "Returns a queryset of all the objects that have been indexed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds function to the xml file.", "response": "def addFunction(self, func_code, from_file=''):\n        \"\"\"Add function \n        \"\"\"\n        if from_file:\n            with open(from_file) as f:\n                func_code = f.read()\n\n        root = self.etree\n        t_execute = root.find('execute')\n\n        if not t_execute :\n            t_execute = ctree.SubElement(root, 'execute')\n\n        t_execute.text = \"\\n\\t![CDATA]{0:>5}]]\\n\\t\".format(func_code.ljust(4))\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns object into an Element Tree", "response": "def _buildElementTree(self,):\n        \"\"\"Turns object into a Element Tree\n        \"\"\"\n        t_binder = ctree.Element(self.name)\n\n        for k,v in self.__dict__.items():\n            if k not in ('name', 'urls', 'inputs', 'paging') and v :\n                t_binder.set(k,v)\n\n        self.etree = t_binder\n        return t_binder"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef addUrl(self, url):\n\n        if url not in self.urls:\n            self.urls.append(url)\n\n        root = self.etree\n        t_urls = root.find('urls')\n\n        if not t_urls:\n            t_urls = ctree.SubElement(root, 'urls')\n\n        t_url = ctree.SubElement(t_urls, 'url')\n        t_url.text = url\n\n        return True", "response": "Add url to the binder s list of urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef removeUrl(self, url):\n\n        root = self.etree\n        t_urls = root.find('urls')\n\n        if not t_urls:\n            return False\n\n        for t_url in t_urls.findall('url'):\n            if t_url.text == url.strip():\n                t_urls.remove(t_url)\n                if url in self.urls:\n                    self.urls.remove(url)\n                return True\n\n        return False", "response": "Remove passed url from a binder\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addInput(self, key):\n        if key not in self.inputs:\n            self.inputs.append(key)\n\n        root = self.etree\n        t_inputs = root.find('inputs')\n\n        if not t_inputs :\n            t_inputs = ctree.SubElement(root, 'inputs')\n\n        t_inputs.append(key.etree)\n\n        return True", "response": "Add key to input"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving input from Input", "response": "def removeInput(self, key_id, input_type='key'):\n        \"\"\"Remove key (key, value, map) from Input\n        key_id : id of the input element i.e <key id='artist' />\n        input_type : type of the input ; key, value or map\n        \"\"\"\n        root = self.etree\n        t_inputs = root.find('inputs')\n\n        if not t_inputs:\n            return False\n\n        keys = t_inputs.findall(input_type)\n\n        key = [ key for key in keys if key.get('id') == key_id ]\n\n        try:\n            t_inputs.remove(key[0])\n            return True\n        except (Exception,) as e:\n            print(e)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd paging to Binder", "response": "def addPaging(self,paging):\n        \"\"\"Add paging to Binder\n        \"\"\"\n        if not vars(self).get('paging', None):\n            self.paging = paging\n        root = self.etree\n\n        try:\n            root.append(paging.etree)\n            return True\n        except (Exception,) as e:\n            print(e)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving paging from Binder", "response": "def removePaging(self,):\n        \"\"\"Remove paging from Binder\n        \"\"\"\n        root = self.etree\n        t_paging = root.find('paging')\n\n        try:\n            root.remove(t_paging)\n            return True\n        except (Exception,) as e:\n            print(e)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _buildElementTree(self,):\n        t_elt = ctree.Element(self.name)\n\n        for k,v in [ (key,value) for key,value in self.__dict__.items() if key != 'name']: # Excluding name from list of items\n            if v and v != 'false' :\n                t_elt.set(k if k != 'like' else 'as', str(v).lower())\n\n        self._etree = t_elt\n        return t_elt", "response": "Turn object into an ElementTree\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning object into an Element Tree", "response": "def _buildElementTree(self,):\n        \"\"\"Turn object into an Element Tree\n        \"\"\"\n\n        t_paging = ctree.Element('paging')\n        t_paging.set('model', self.model)\n        for key in self.__dict__.keys():\n            if key != 'model':\n                t_tag = ctree.SubElement(t_paging, key)\n                for item in self.__dict__[key].items():\n                    t_tag.set(*item)\n\n        self.etree = t_paging\n        return  t_paging"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_application_choices():\n    result = []\n    keys = set()\n    for ct in ContentType.objects.order_by('app_label', 'model'):\n        try:\n            if issubclass(ct.model_class(), TranslatableModel) and ct.app_label not in keys:\n                result.append(('{}'.format(ct.app_label), '{}'.format(ct.app_label.capitalize())))\n                keys.add(ct.app_label)\n        except TypeError:\n            continue\n    return result", "response": "Get the select options for the application selector"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_model_choices():\n    result = []\n    for ct in ContentType.objects.order_by('app_label', 'model'):\n        try:\n            if issubclass(ct.model_class(), TranslatableModel):\n                result.append(\n                    ('{} - {}'.format(ct.app_label, ct.model.lower()),\n                     '{} - {}'.format(ct.app_label.capitalize(), ct.model_class()._meta.verbose_name_plural))\n                )\n        except TypeError:\n            continue\n    return result", "response": "Get the select options for the model selector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncount and returns the number of words found in a given text", "response": "def get_num_words(text):\n    \"\"\"\n    Counts and returns the number of words found in a given text\n\n    :param text:\n    :return:\n    \"\"\"\n    try:\n        word_regexp_pattern = re.compile(r\"[a-zA-Z\u00e1\u00e9\u00ed\u00f3\u00fa\u00f1]+\")\n        num_words = re.findall(word_regexp_pattern, text)\n        return len(num_words)\n    except TypeError:\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_field(mc, field_name):\n    try:\n        mc._meta.get_field(field_name)\n    except FieldDoesNotExist:\n        return False\n    return True", "response": "detect if a model has a given field"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reader(f):\n    '''CSV Reader factory for CADA format'''\n    return unicodecsv.reader(f, encoding='utf-8', delimiter=b',', quotechar=b'\"')", "response": "CSV Reader factory for CADA format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef writer(f):\n    '''CSV writer factory for CADA format'''\n    return unicodecsv.writer(f, encoding='utf-8', delimiter=b',', quotechar=b'\"')", "response": "CSV writer factory for CADA format"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an advice from a CSV row", "response": "def from_row(row):\n    '''Create an advice from a CSV row'''\n    subject = (row[5][0].upper() + row[5][1:]) if row[5] else row[5]\n    return Advice.objects.create(\n        id=row[0],\n        administration=cleanup(row[1]),\n        type=row[2],\n        session=datetime.strptime(row[4], '%d/%m/%Y'),\n        subject=cleanup(subject),\n        topics=[t.title() for t in cleanup(row[6]).split(', ')],\n        tags=[tag.strip() for tag in row[7].split(',') if tag.strip()],\n        meanings=cleanup(row[8]).replace(' / ', '/').split(', '),\n        part=_part(row[9]),\n        content=cleanup(row[10]),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nserializing an advice into a CSV row", "response": "def to_row(advice):\n    '''Serialize an advice into a CSV row'''\n    return [\n        advice.id,\n        advice.administration,\n        advice.type,\n        advice.session.year,\n        advice.session.strftime('%d/%m/%Y'),\n        advice.subject,\n        ', '.join(advice.topics),\n        ', '.join(advice.tags),\n        ', '.join(advice.meanings),\n        ROMAN_NUMS.get(advice.part, ''),\n        advice.content,\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean_dict(data):\n    if is_mapping(data):\n        out = {}\n        for k, v in data.items():\n            if v is not None:\n                out[k] = clean_dict(v)\n        return out\n    elif is_sequence(data):\n        return [clean_dict(d) for d in data if d is not None]\n    return data", "response": "Remove None - valued keys from a dictionary recursively."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef keys_values(data, *keys):\n    values = []\n    if is_mapping(data):\n        for key in keys:\n            if key in data:\n                values.extend(ensure_list(data[key]))\n    return values", "response": "Get an entry as a list from a dict. Provide a fallback key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef solve_simple_captcha(self, pathfile=None, filedata=None, filename=None):\n\n\t\tif pathfile and os.path.exists(pathfile):\n\t\t\tfp = open(pathfile, 'rb')\n\t\telif filedata:\n\t\t\tfp = io.BytesIO(filedata)\n\t\telse:\n\t\t\traise ValueError(\"You must pass either a valid file path, or a bytes array containing the captcha image!\")\n\n\t\ttry:\n\t\t\ttask = python_anticaptcha.ImageToTextTask(fp)\n\t\t\tjob = self.client.createTask(task)\n\n\t\t\tjob.join(maximum_time = self.waittime)\n\n\t\t\treturn job.get_captcha_text()\n\n\t\texcept python_anticaptcha.AnticaptchaException as e:\n\t\t\traise exc.CaptchaSolverFailure(\"Failure solving captcha: %s, %s, %s\" % (\n\t\t\t\t\te.error_id,\n\t\t\t\t\te.error_code,\n\t\t\t\t\te.error_description,\n\t\t\t\t))", "response": "Solve a simple captcha."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsolves a recaptcha on page page_url with the input value google_key.", "response": "def solve_recaptcha(self, google_key, page_url, timeout = 15 * 60):\n\t\t'''\n\t\tSolve a recaptcha on page `page_url` with the input value `google_key`.\n\t\tTimeout is `timeout` seconds, defaulting to 60 seconds.\n\n\t\tReturn value is either the `g-recaptcha-response` value, or an exceptionj is raised\n\t\t(generally `CaptchaSolverFailure`)\n\t\t'''\n\n\t\tproxy = SocksProxy.ProxyLauncher(ANTICAPTCHA_IPS)\n\n\t\ttry:\n\t\t\tantiprox = python_anticaptcha.Proxy(\n\t\t\t\t\tproxy_type     = \"socks5\",\n\t\t\t\t\tproxy_address  = proxy.get_wan_ip(),\n\t\t\t\t\tproxy_port     = proxy.get_wan_port(),\n\t\t\t\t\tproxy_login    = None,\n\t\t\t\t\tproxy_password = None,\n\t\t\t\t)\n\n\t\t\ttask = python_anticaptcha.NoCaptchaTask(\n\t\t\t\t\twebsite_url = page_url,\n\t\t\t\t\twebsite_key = google_key,\n\t\t\t\t\tproxy       = antiprox,\n\t\t\t\t\tuser_agent  = dict(self.wg.browserHeaders).get('User-Agent')\n\t\t\t\t)\n\t\t\tjob = self.client.createTask(task)\n\t\t\tjob.join(maximum_time = timeout)\n\n\t\t\treturn job.get_solution_response()\n\t\texcept python_anticaptcha.AnticaptchaException as e:\n\t\t\traise exc.CaptchaSolverFailure(\"Failure solving captcha: %s, %s, %s\" % (\n\t\t\t\t\te.error_id,\n\t\t\t\t\te.error_code,\n\t\t\t\t\te.error_description,\n\t\t\t\t))\n\n\t\tfinally:\n\t\t\tproxy.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef userinput(prompttext=\"\", times=1):\n\n    # If times is 1\n    if times == 1:\n        # Return the result\n        return input(str(prompttext))\n\n    # Create new empty list\n    inputlist = []\n\n    # For each time in range\n    for _ in range(times):\n        # Append the result of another input request\n        inputlist.append(input(str(prompttext)))\n\n    # Return the final result\n    return inputlist", "response": "Get the input of the user via universally secure method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shellinput(initialtext='>> ', splitpart=' '):\n\n    # Get the user's input\n    shelluserinput = input(str(initialtext))\n\n    # Return the computed result\n    return shelluserinput if splitpart in (\n        '', None) else shelluserinput.split(splitpart)", "response": "Return the user s input to enter commands."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef splitstring(string, splitcharacter=' ', part=None):\n\n    # If the part is empty\n    if part in [None, '']:\n        # Return an array of the splitted text\n        return str(string).split(splitcharacter)\n\n    # Return an array of the splitted text with a specific part\n    return str(string).split(splitcharacter)[part]", "response": "Split a string based on a character and get the parts as a list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of keywords or if a keyword exists in the Python keyword dictionary.", "response": "def pykeyword(operation='list', keywordtotest=None):\n    \"\"\"\n    Check if a keyword exists in the Python keyword dictionary.\n\n    :type operation: string\n    :param operation: Whether to list or check the keywords. Possible options are 'list' and 'in'.\n\n    :type keywordtotest: string\n    :param keywordtotest: The keyword to check.\n\n    :return: The list of keywords or if a keyword exists.\n    :rtype: list or boolean\n\n    >>> \"True\" in pykeyword(\"list\")\n    True\n\n    >>> pykeyword(\"in\", \"True\")\n    True\n\n    >>> pykeyword(\"in\", \"foo\")\n    False\n\n    >>> pykeyword(\"foo\", \"foo\")\n    Traceback (most recent call last):\n      ...\n    ValueError: Invalid operation specified.\n    \"\"\"\n\n    # If the operation was 'list'\n    if operation == 'list':\n        # Return an array of keywords\n        return str(keyword.kwlist)\n\n    # If the operation was 'in'\n    elif operation == 'in':\n        # Return a boolean for if the string was a keyword\n        return keyword.iskeyword(str(keywordtotest))\n\n    # Raise a warning\n    raise ValueError(\"Invalid operation specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts 0 1 or False to True or vice versa.", "response": "def binboolflip(item):\n    \"\"\"\n    Convert 0 or 1 to False or True (or vice versa).\n    The converter works as follows:\n\n    - 0 > False\n    - False > 0\n    - 1 > True\n    - True > 1\n\n    :type item: integer or boolean\n    :param item: The item to convert.\n\n    >>> binboolflip(0)\n    False\n\n    >>> binboolflip(False)\n    0\n\n    >>> binboolflip(1)\n    True\n\n    >>> binboolflip(True)\n    1\n\n    >>> binboolflip(\"foo\")\n    Traceback (most recent call last):\n      ...\n    ValueError: Invalid item specified.\n    \"\"\"\n\n    if item in [0, False, 1, True]:\n        return int(item) if isinstance(item, bool) else bool(item)\n\n    # Raise a warning\n    raise ValueError(\"Invalid item specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the Python warnings.", "response": "def warnconfig(action='default'):\n    \"\"\"\n    Configure the Python warnings.\n\n    :type action: string\n    :param action: The configuration to set. Options are: 'default', 'error', 'ignore', 'always', 'module' and 'once'.\n    \"\"\"\n\n    # If action is 'default'\n    if action.lower() == 'default':\n        # Change warning settings\n        warnings.filterwarnings('default')\n\n    # If action is 'error'\n    elif action.lower() == 'error':\n        # Change warning settings\n        warnings.filterwarnings('error')\n\n    # If action is 'ignore'\n    elif action.lower() == 'ignore':\n        # Change warning settings\n        warnings.filterwarnings('ignore')\n\n    # If action is 'always'\n    elif action.lower() == 'always':\n        # Change warning settings\n        warnings.filterwarnings('always')\n\n    # If action is 'module'\n    elif action.lower() == 'module':\n        # Change warning settings\n        warnings.filterwarnings('module')\n\n    # If action is 'once'\n    elif action.lower() == 'once':\n        # Change warning settings\n        warnings.filterwarnings('once')\n\n    # Raise runtime warning\n    raise ValueError(\"Invalid action specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef happybirthday(person):\n    print('Happy Birthday To You')\n    time.sleep(2)\n    print('Happy Birthday To You')\n    time.sleep(2)\n    print('Happy Birthday Dear ' + str(person[0].upper()) + str(person[1:]))\n    time.sleep(2)\n    print('Happy Birthday To You')", "response": "Happy Birthday To You"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cowsay(text='', align='centre'):\n\n    # Make align lowercase\n    align = align.lower()\n\n    # Set the cowtext\n    cowtext = str(text)\n\n    # Set top part of speech bubble to the length of the text plus 2\n    topbar = ' ' * (len(text) + 2)\n\n    # Set bottom part of speech bubble to the length of the text plus 2\n    bottombar = ' ' * (len(text) + 2)\n\n    # If align is centre\n    if align in [\"center\", \"centre\"]:\n        # Set the spacing before the cow to the length of half of the length of topbar plus 1\n        spacing = \" \" * (int(len(topbar) / 2) + 1)\n\n    # If align is left\n    elif align == 'left':\n        # Set spacing to a single space\n        spacing = ' '\n\n    # If align is right\n    elif align == 'right':\n        # Set the spacing to the length of the text plus 2\n        spacing = \" \" * (len(text) + 2)\n\n    else:\n        # Raise a runtime warning\n        raise ValueError(\"Invalid alignment provided.\")\n\n    # Print the top bar\n    print(topbar)\n\n    # Print the text\n    print('( ' + repr(str(cowtext)) + ' )')\n\n    # Print the bottom bar\n    print(bottombar)\n\n    # Print the cow with the spacing\n    print(spacing + r'o   ^__^ ')\n    print(spacing + r' o  (oO)\\_______')\n    print(spacing + r'    (__)\\       )\\/\\ ')\n    print(spacing + r'     U  ||----w | ')\n    print(spacing + r'        ||     || ')", "response": "Simulate an ASCII cow saying text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convertbinary(value, argument):\n\n    if argument == 'to':\n        return bin(value)\n    elif argument == 'from':\n        return format(value)\n    raise ValueError(\"Invalid argument specified.\")", "response": "Converts text to binary form or backwards."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reversetext(contenttoreverse, reconvert=True):\n\n    # If reconvert is specified\n    if reconvert is True:\n        # Return the evalated form\n        return eval(\n            str(type(contenttoreverse)).split(\"'\")[1] + \"('\" +\n            str(contenttoreverse)[::-1] + \"')\")\n\n    # Return the raw version\n    return contenttoreverse[::-1]", "response": "Reverse any contenttoreverse of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convertascii(value, command='to'):\n    command = command.lower()\n    if command == 'to':\n        return chr(value)\n    elif command == 'from':\n        return ord(value)\n    else:\n        raise ValueError('Invalid operation provided.')", "response": "Converts an ASCII value to a symbol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all the available characters for a specific type.", "response": "def availchars(charactertype):\n    \"\"\"\n    Get all the available characters for a specific type.\n\n    :type charactertype: string\n    :param charactertype: The characters to get. Can be 'letters', 'lowercase, 'uppercase', 'digits', 'hexdigits', 'punctuation', 'printable', 'whitespace' or 'all'.\n\n    >>> availchars(\"lowercase\")\n    'abcdefghijklmnopqrstuvwxyz'\n    \"\"\"\n\n    # If the lowercase version of the character type is 'letters'\n    if charactertype.lower() == 'letters':\n        # Return the result\n        return string.ascii_letters\n\n    # If the lowercase version of the character type is 'lowercase'\n    elif charactertype.lower() == 'lowercase':\n        # Return the result\n        return string.ascii_lowercase\n\n    # If the lowercase version of the character type is 'uppercase'\n    elif charactertype.lower() == 'uppercase':\n        # Return the result\n        return string.ascii_uppercase\n\n    # If the lowercase version of the character type is 'digits'\n    elif charactertype.lower() == 'digits':\n        # Return the result\n        return string.digits\n\n    # If the lowercase version of the character type is 'hexdigits'\n    elif charactertype.lower() == 'hexdigits':\n        # Return the result\n        return string.hexdigits\n\n    # If the lowercase version of the character type is 'punctuation'\n    elif charactertype.lower() == 'punctuation':\n        # Return the result\n        return string.punctuation\n\n    # If the lowercase version of the character type is 'printable'\n    elif charactertype.lower() == 'printable':\n        # Return the result\n        return string.printable\n\n    # If the lowercase version of the character type is 'whitespace'\n    elif charactertype.lower() == 'whitespace':\n        # Return the result\n        return string.whitespace\n\n    # If the lowercase version of the character type is 'all'\n    elif charactertype.lower() == 'all':\n        # Return the result\n        return string.ascii_letters + string.ascii_lowercase + string.ascii_uppercase + string.digits + string.hexdigits + string.punctuation + string.printable + string.whitespace\n\n    # Raise a warning\n    raise ValueError(\"Invalid character type provided.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the text between two parts of the current language.", "response": "def textbetween(variable,\n                firstnum=None,\n                secondnum=None,\n                locationoftext='regular'):\n    \"\"\"\n    Get The Text Between Two Parts\n    \"\"\"\n    if locationoftext == 'regular':\n        return variable[firstnum:secondnum]\n    elif locationoftext == 'toend':\n        return variable[firstnum:]\n    elif locationoftext == 'tostart':\n        return variable[:secondnum]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of the letternum that is part of the base64 encoded string.", "response": "def letternum(letter):\n    \"\"\"\n    Get The Number Corresponding To A Letter\n    \"\"\"\n    if not isinstance(letter, str):\n        raise TypeError(\"Invalid letter provided.\")\n    if not len(letter) == 1:\n        raise ValueError(\"Invalid letter length provided.\")\n    letter = letter.lower()\n    alphaletters = string.ascii_lowercase\n    for i in range(len(alphaletters)):\n        if letter[0] == alphaletters[i]:\n            return i + 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wordvalue(word):\n\n    # Set total to 0\n    total = 0\n\n    # For each character of word\n    for i in enumerate(word):\n        # Add it's letter value to total\n        total += letternum(word[i[0]])\n\n    # Return the final value\n    return total", "response": "Returns the value of each letter of a string s position in the alphabet added up\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spacelist(listtospace, spacechar=\" \"):\n    output = ''\n    space = ''\n    output += str(listtospace[0])\n    space += spacechar\n    for listnum in range(1, len(listtospace)):\n        output += space\n        output += str(listtospace[listnum])\n    return output", "response": "Convert a list to a string with all of the list s items spaced out."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef numlistbetween(num1, num2, option='list', listoption='string'):\n    if option == 'list':\n        if listoption == 'string':\n            output = ''\n            output += str(num1)\n            for currentnum in range(num1 + 1, num2 + 1):\n                output += ','\n                output += str(currentnum)\n        elif listoption == 'list':\n            output = []\n            for currentnum in range(num1, num2 + 1):\n                output.append(str(currentnum))\n            return output\n    elif option == 'count':\n        return num2 - num1", "response": "Returns the number of the items in the sequence num1 and num2 in a list or count list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nalign text when Given Full Length", "response": "def textalign(text, maxlength, align='left'):\n    \"\"\"\n    Align Text When Given Full Length\n    \"\"\"\n    if align == 'left':\n        return text\n    elif align == 'centre' or align == 'center':\n        spaces = ' ' * (int((maxlength - len(text)) / 2))\n    elif align == 'right':\n        spaces = (maxlength - len(text))\n    else:\n        raise ValueError(\"Invalid alignment specified.\")\n    return spaces + text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the amount of sides or the shape of a node.", "response": "def shapesides(inputtocheck, inputtype='shape'):\n    \"\"\"\n    Get the sides of a shape.\n\n    inputtocheck:\n    The amount of sides or the shape to be checked,\n    depending on the value of inputtype.\n\n    inputtype:\n    The type of input provided.\n    Can be: 'shape', 'sides'.\n    \"\"\"\n\n    # Define the array of sides to a shape\n    shapestosides = {\n        'triangle': 3,\n        'square': 4,\n        'pentagon': 5,\n        'hexagon': 6,\n        'heptagon': 7,\n        'octagon': 8,\n        'nonagon': 9,\n        'decagon': 10,\n        'hendecagon': 11,\n        'dodecagon': 12,\n        'triskaidecagon': 13,\n        'tetrakaidecagon': 14,\n        'pentadecagon': 15,\n        'hexakaidecagon': 16,\n        'heptadecagon': 17,\n        'octakaidecagon': 18,\n        'enneadecagon': 19,\n        'icosagon': 20,\n        'triacontagon': 30,\n        'tetracontagon': 40,\n        'pentacontagon': 50,\n        'hexacontagon': 60,\n        'heptacontagon': 70,\n        'octacontagon': 80,\n        'enneacontagon': 90,\n        'hectagon': 100,\n        'chiliagon': 1000,\n        'myriagon': 10000,\n        'megagon': 1000000,\n        'googolgon': pow(10, 100),\n        'ngon': 'n'\n    }\n\n    # Define an array with the flipped version of the sides to a shape\n    sidestoshapes = dictflip(shapestosides)\n\n    # If the lowercase version of the input type is 'shape'\n    if inputtype.lower() == 'shape':\n        # If the lowercase version of the shape is in the array\n        if inputtocheck.lower() in shapestosides:\n            # Return the corresponding sides\n            return shapestosides[inputtocheck.lower()]\n\n        # Return 'n'\n        return shapestosides['n']\n\n    if inputtype.lower() == 'sides':\n        # If the lowercase version of the shape is in the array\n        if inputtocheck.lower() in sidestoshapes:\n            # Return the corresponding sides\n            return sidestoshapes[inputtocheck.lower()]\n\n        # Return 'ngon'\n        return sidestoshapes['ngon']\n\n    # Raise a warning\n    raise ValueError(\"Invalid input type.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef autosolve(equation):\n\n    try:\n        # Try to set a variable to an integer\n        num1 = int(equation.split(\" \")[0])\n\n    except ValueError:\n        # Try to set a variable to a decimal\n        num1 = float(equation.split(\" \")[0])\n\n    try:\n        # Try to set a variable to an integer\n        num2 = int(equation.split(\" \")[2])\n\n    except ValueError:\n        # Try to set a variable to a decimal\n        num2 = float(equation.split(\" \")[2])\n\n    # If the lowercase version of the operator is '+', 'plus' or 'add'\n    if equation.split(\" \")[1].lower() in [\"+\", \"plus\", \"add\"]:\n\n        # Return the answer\n        return num1 + num2\n\n    # If the lowercase version of the operator is '-', 'minus' or 'subtract'\n    elif equation.split(\" \")[1].lower() in [\"-\", \"minus\", \"subtract\"]:\n\n        # Return the answer\n        return num1 - num2\n\n    # If the lowercase version of the operator is '*', 'times', 'multiply'\n    elif equation.split(\" \")[1].lower() in [\"*\", \"times\", \"multiply\"]:\n\n        # Return the answer\n        return num1 * num2\n\n    # If the lowercase version of the operator is '/', 'divide' or 'quotient'\n    elif equation.split(\" \")[1].lower() in [\"/\", \"divide\", \"quotient\"]:\n\n        # Return the answer\n        return num1 / num2\n\n    # If the lowercase version of the operator is '%, 'remainder' or 'rem'\n    elif equation.split(\" \")[1].lower() in [\"%\", \"remainder\", \"rem\"]:\n\n        # Return the answer\n        return num1 % num2\n\n    # Raise a warning\n    raise ValueError(\"Invalid operation provided.\")", "response": "Automatically solve an easy maths problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef equation(operation, firstnum, secondnum):\n    if operation == 'plus':\n        return firstnum + secondnum\n    elif operation == 'minus':\n        return firstnum - secondnum\n    elif operation == 'multiply':\n        return firstnum * secondnum\n    elif operation == 'divide':\n        if not secondnum == 0:\n            return firstnum / secondnum\n        raise ZeroDivisionError(\"Unable to divide by 0.\")\n    raise ValueError('Invalid operation provided.')", "response": "Solve a simple maths equation manually"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scientific(number, operation, number2=None, logbase=10):\n    if operation == 'log':\n        return math.log(number, logbase)\n    elif operation == 'acos':\n        return math.acos(number)\n    elif operation == 'asin':\n        return math.asin(number)\n    elif operation == 'atan':\n        return math.atan(number)\n    elif operation == 'cos':\n        return math.cos(number)\n    elif operation == 'hypot':\n        return math.hypot(number, number2)\n    elif operation == 'sin':\n        return math.sin(number)\n    elif operation == 'tan':\n        return math.tan(number)", "response": "Solve a number using a scientific operation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsimplify a fraction. :type numerator: integer :param numerator: The numerator of the fraction to simplify :type denominator: integer :param denominator: The denominator of the fraction to simplify :return: The simplified fraction :rtype: list", "response": "def fracsimplify(numerator, denominator):\n    \"\"\"\n    Simplify a fraction.\n\n    :type numerator: integer\n    :param numerator: The numerator of the fraction to simplify\n\n    :type denominator: integer\n    :param denominator: The denominator of the fraction to simplify\n\n    :return: The simplified fraction\n    :rtype: list\n    \"\"\"\n\n    # If the numerator is the same as the denominator\n    if numerator == denominator:\n        # Return the most simplified fraction\n        return '1/1'\n\n    # If the numerator is larger than the denominator\n    elif int(numerator) > int(denominator):\n        # Set the limit to half of the numerator\n        limit = int(numerator / 2)\n\n    elif int(numerator) < int(denominator):\n\n        # Set the limit to half of the denominator\n        limit = int(denominator / 2)\n\n    # For each item in range from 2 to the limit\n    for i in range(2, limit):\n        # Set the number to check as the limit minus i\n        checknum = limit - i\n        # If the number is divisible by the numerator and denominator\n        if numerator % checknum == 0 and denominator % checknum == 0:\n            # Set the numerator to half of the number\n            numerator = numerator / checknum\n            # Set the denominator to half of the number\n            denominator = denominator / checknum\n\n    # Return the integer version of the numerator and denominator\n    return [int(numerator), int(denominator)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a number in a circle measurement to a new format.", "response": "def circleconvert(amount, currentformat, newformat):\n    \"\"\"\n    Convert a circle measurement.\n\n    :type amount: number\n    :param amount: The number to convert.\n\n    :type currentformat: string\n    :param currentformat: The format of the provided value.\n\n    :type newformat: string\n    :param newformat: The intended format of the value.\n\n    >>> circleconvert(45, \"radius\", \"diameter\")\n    90\n    \"\"\"\n\n    # If the same format was provided\n    if currentformat.lower() == newformat.lower():\n        # Return the provided value\n        return amount\n\n    # If the lowercase version of the current format is 'radius'\n    if currentformat.lower() == 'radius':\n        # If the lowercase version of the new format is 'diameter'\n        if newformat.lower() == 'diameter':\n            # Return the converted value\n            return amount * 2\n\n        # If the lowercase version of the new format is 'circumference'\n        elif newformat.lower() == 'circumference':\n            # Return the converted value\n            return amount * 2 * math.pi\n\n        # Raise a warning\n        raise ValueError(\"Invalid new format provided.\")\n\n    # If the lowercase version of the current format is 'diameter'\n    elif currentformat.lower() == 'diameter':\n        # If the lowercase version of the new format is 'radius'\n        if newformat.lower() == 'radius':\n            # Return the converted value\n            return amount / 2\n\n        # If the lowercase version of the new format is 'circumference'\n        elif newformat.lower() == 'circumference':\n            # Return the converted value\n            return amount * math.pi\n\n        # Raise a warning\n        raise ValueError(\"Invalid new format provided.\")\n\n    # If the lowercase version of the current format is 'circumference'\n    elif currentformat.lower() == 'circumference':\n        # If the lowercase version of the new format is 'radius'\n        if newformat.lower() == 'radius':\n            # Return the converted value\n            return amount / math.pi / 2\n\n        # If the lowercase version of the new format is 'diameter'\n        elif newformat.lower() == 'diameter':\n            # Return the converted value\n            return amount / math.pi"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef amountdiv(number, minnum, maxnum):\n\n    # Set the amount to 0\n    amount = 0\n\n    # For each item in range of minimum and maximum\n    for i in range(minnum, maxnum + 1):\n        # If the remainder of the divided number is 0\n        if number % i == 0:\n            # Add 1 to the total amount\n            amount += 1\n\n    # Return the result\n    return amount", "response": "Returns the amount of numbers divisable by a number."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the constant of a given type", "response": "def constant(constanttype):\n    \"\"\"\n    Get A Constant\n    \"\"\"\n    constanttype = constanttype.lower()\n    if constanttype == 'pi':\n        return math.pi\n    elif constanttype == 'e':\n        return math.e\n    elif constanttype == 'tau':\n        return math.tau\n    elif constanttype == 'inf':\n        return math.inf\n    elif constanttype == 'nan':\n        return math.nan\n    elif constanttype in ['phi', 'golden']:\n        return (1 + 5**0.5) / 2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the average of a list of numbers.", "response": "def average(numbers, averagetype='mean'):\n    \"\"\"\n    Find the average of a list of numbers\n\n    :type numbers: list\n    :param numbers: The list of numbers to find the average of.\n\n    :type averagetype: string\n    :param averagetype: The type of average to find.\n\n    >>> average([1, 2, 3, 4, 5], 'median')\n    3\n    \"\"\"\n\n    try:\n        # Try to get the mean of the numbers\n        statistics.mean(numbers)\n\n    except RuntimeError:\n        # Raise a warning\n        raise ValueError('Unable to parse the list.')\n\n    # If the lowercase version of the average type is 'mean'\n    if averagetype.lower() == 'mean':\n        # Return the answer\n        return statistics.mean(numbers)\n\n    # If the lowercase version of the average type is 'mode'\n    elif averagetype.lower() == 'mode':\n        # Return the answer\n        return statistics.mode(numbers)\n\n    # If the lowercase version of the average type is 'median'\n    elif averagetype.lower() == 'median':\n        # Return the answer\n        return statistics.median(numbers)\n\n    # If the lowercase version of the average type is 'min'\n    elif averagetype.lower() == 'min':\n        # Return the answer\n        return min(numbers)\n\n    # If the lowercase version of the average type is 'max'\n    elif averagetype.lower() == 'max':\n        # Return the answer\n        return max(numbers)\n\n    # If the lowercase version of the average type is 'range'\n    elif averagetype.lower() == 'range':\n        # Return the answer\n        return max(numbers) - min(numbers)\n\n    # Raise a warning\n    raise ValueError('Invalid average type provided.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef numprop(value, propertyexpected):\n    if propertyexpected == 'triangular':\n        x = (math.sqrt(8 * value + 1) - 1) / 2\n        return bool(x - int(x) > 0)\n    elif propertyexpected == 'square':\n        return math.sqrt(value).is_integer()\n    elif propertyexpected == 'cube':\n        x = value**(1 / 3)\n        x = int(round(x))\n        return bool(x**3 == value)\n    elif propertyexpected == 'even':\n        return value % 2 == 0\n    elif propertyexpected == 'odd':\n        return not value % 2 == 0\n    elif propertyexpected == 'positive':\n        return bool(value > 0)\n    elif propertyexpected == 'negative':\n        return bool(value < 0)\n    elif propertyexpected == 'zero':\n        return bool(value == 0)", "response": "Check if A Number Is A Type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef posnegtoggle(number):\n    if bool(number > 0):\n        return number - number * 2\n    elif bool(number < 0):\n        return number + abs(number) * 2\n    elif bool(number == 0):\n        return number", "response": "This function is used to toggle a number between positive and negative."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomparing two values in the .", "response": "def compare(value1, value2, comparison):\n    \"\"\"\n    Compare 2 values\n\n    :type value1: object\n    :param value1: The first value to compare.\n\n    :type value2: object\n    :param value2: The second value to compare.\n\n    :type comparison: string\n    :param comparison: The comparison to make. Can be \"is\", \"or\", \"and\".\n\n    :return: If the value is, or, and of another value\n    :rtype: boolean\n    \"\"\"\n    if not isinstance(comparison, str):\n        raise TypeError(\"Comparison argument must be a string.\")\n    if comparison == 'is':\n        return value1 == value2\n    elif comparison == 'or':\n        return value1 or value2\n    elif comparison == 'and':\n        return value1 and value2\n    raise ValueError(\"Invalid comparison operator specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all of the factors of a number.", "response": "def factors(number):\n    \"\"\"\n    Find all of the factors of a number and return it as a list.\n\n    :type number: integer\n    :param number: The number to find the factors for.\n    \"\"\"\n\n    if not (isinstance(number, int)):\n        raise TypeError(\n            \"Incorrect number type provided. Only integers are accepted.\")\n\n    factors = []\n    for i in range(1, number + 1):\n        if number % i == 0:\n            factors.append(i)\n    return factors"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randomnum(minimum=1, maximum=2, seed=None):\n\n    if not (isnum(minimum)):\n        raise TypeError(\"Minimum number is not a number.\")\n\n    if not (isnum(maximum)):\n        raise TypeError(\"Maximum number is not a number.\")\n\n    if seed is None:\n        return random.randint(minimum, maximum)\n\n    random.seed(seed)\n    return random.randint(minimum, maximum)", "response": "Generate a random number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random string in hexadecimal", "response": "def tokhex(length=10, urlsafe=False):\n    \"\"\"\n    Return a random string in hexadecimal\n    \"\"\"\n    if urlsafe is True:\n        return secrets.token_urlsafe(length)\n    return secrets.token_hex(length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef isfib(number):\n\n    num1 = 1\n    num2 = 1\n    while True:\n        if num2 < number:\n            tempnum = num2\n            num2 += num1\n            num1 = tempnum\n        elif num2 == number:\n            return True\n        else:\n            return False", "response": "Checks if a number is in the Fibonacci sequence."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a number is a prime number", "response": "def isprime(number):\n    \"\"\"\n    Check if a number is a prime number\n\n    :type number: integer\n    :param number: The number to check\n    \"\"\"\n\n    if number == 1:\n        return False\n    for i in range(2, int(number**0.5) + 1):\n        if number % i == 0:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a number in base 10 to another base 10.", "response": "def convertbase(number, base=10):\n    \"\"\"\n    Convert a number in base 10 to another base\n\n    :type number: number\n    :param number: The number to convert\n\n    :type base: integer\n    :param base: The base to convert to.\n    \"\"\"\n\n    integer = number\n    if not integer:\n        return '0'\n    sign = 1 if integer > 0 else -1\n    alphanum = string.digits + string.ascii_lowercase\n    nums = alphanum[:base]\n    res = ''\n    integer *= sign\n    while integer:\n        integer, mod = divmod(integer, base)\n        res += nums[mod]\n    return ('' if sign == 1 else '-') + res[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the quadrant a pair of coordinates are located in", "response": "def quadrant(xcoord, ycoord):\n    \"\"\"\n    Find the quadrant a pair of coordinates are located in\n\n    :type xcoord: integer\n    :param xcoord: The x coordinate to find the quadrant for\n\n    :type ycoord: integer\n    :param ycoord: The y coordinate to find the quadrant for\n    \"\"\"\n\n    xneg = bool(xcoord < 0)\n    yneg = bool(ycoord < 0)\n    if xneg is True:\n        if yneg is False:\n            return 2\n        return 3\n    if yneg is False:\n        return 1\n    return 4"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nflipping the coordinates over a specific axis to a different quadrant.", "response": "def flipcoords(xcoord, ycoord, axis):\n    \"\"\"\n    Flip the coordinates over a specific axis, to a different quadrant\n\n    :type xcoord: integer\n    :param xcoord: The x coordinate to flip\n\n    :type ycoord: integer\n    :param ycoord: The y coordinate to flip\n\n    :type axis: string\n    :param axis: The axis to flip across. Could be 'x' or 'y'\n    \"\"\"\n\n    axis = axis.lower()\n    if axis == 'y':\n        if xcoord > 0:\n            return str(xcoord - xcoord - xcoord) + ', ' + str(ycoord)\n        elif xcoord < 0:\n            return str(xcoord + abs(xcoord) * 2) + ', ' + str(ycoord)\n        elif xcoord == 0:\n            return str(xcoord) + ', ' + str(ycoord)\n        raise ValueError(\n            \"The X coordinate is neither larger, smaller or the same as 0.\")\n\n    elif axis == 'x':\n        if ycoord > 0:\n            return str(xcoord) + ', ' + str(ycoord - ycoord - ycoord)\n        elif ycoord < 0:\n            return str(ycoord + abs(ycoord) * 2) + ', ' + str(xcoord)\n        elif ycoord == 0:\n            return str(xcoord) + ', ' + str(ycoord)\n        raise ValueError(\n            \"The Y coordinate is neither larger, smaller or the same as 0.\")\n    raise ValueError(\"Invalid axis. Neither x nor y was specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lcm(num1, num2):\n\n    if num1 > num2:\n        bigger = num1\n    else:\n        bigger = num2\n    while True:\n        if bigger % num1 == 0 and bigger % num2 == 0:\n            return bigger\n        bigger += 1", "response": "Find the lowest common multiple of 2 numbers in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the highest common factor of 2 numbers AttributeNames", "response": "def hcf(num1, num2):\n    \"\"\"\n    Find the highest common factor of 2 numbers\n\n    :type num1: number\n    :param num1: The first number to find the hcf for\n\n    :type num2: number\n    :param num2: The second number to find the hcf for\n    \"\"\"\n\n    if num1 > num2:\n        smaller = num2\n    else:\n        smaller = num1\n    for i in range(1, smaller + 1):\n        if ((num1 % i == 0) and (num2 % i == 0)):\n            return i"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef randstring(length=1):\n    charstouse = string.ascii_letters + string.digits + string.punctuation\n    newpass = ''\n    for _ in range(length):\n        newpass += str(charstouse[random.randint(0, len(charstouse) - 1)])\n    return newpass", "response": "Generates a random string consisting of letters digits and punctuation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshortens some text by replacing the last part with a placeholder.", "response": "def shortentext(text, minlength, placeholder='...'):\n    \"\"\"\n    Shorten some text by replacing the last part with a placeholder (such as '...')\n\n    :type text: string\n    :param text: The text to shorten\n\n    :type minlength: integer\n    :param minlength: The minimum length before a shortening will occur\n\n    :type placeholder: string\n    :param placeholder: The text to append after removing protruding text.\n    \"\"\"\n\n    return textwrap.shorten(text, minlength, placeholder=str(placeholder))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the casing of some text.", "response": "def case(text, casingformat='sentence'):\n    \"\"\"\n    Change the casing of some text.\n\n    :type text: string\n    :param text: The text to change the casing of.\n\n    :type casingformat: string\n    :param casingformat: The format of casing to apply to the text. Can be 'uppercase', 'lowercase', 'sentence' or 'caterpillar'.\n\n    :raises ValueError: Invalid text format specified.\n\n    >>> case(\"HELLO world\", \"uppercase\")\n    'HELLO WORLD'\n    \"\"\"\n\n    # If the lowercase version of the casing format is 'uppercase'\n    if casingformat.lower() == 'uppercase':\n        # Return the uppercase version\n        return str(text.upper())\n\n    # If the lowercase version of the casing format is 'lowercase'\n    elif casingformat.lower() == 'lowercase':\n        # Return the lowercase version\n        return str(text.lower())\n\n    # If the lowercase version of the casing format is 'sentence'\n    elif casingformat.lower() == 'sentence':\n        # Return the sentence case version\n        return str(text[0].upper()) + str(text[1:])\n\n    # If the lowercase version of the casing format is 'caterpillar'\n    elif casingformat.lower() == 'caterpillar':\n        # Return the caterpillar case version\n        return str(text.lower().replace(\" \", \"_\"))\n\n    # Raise a warning\n    raise ValueError(\"Invalid text format specified.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encryptstring(text, password):\n\n    enc = []\n    for i in enumerate(text):\n        key_c = password[i[0] % len(password)]\n        enc_c = chr((ord(i[1]) + ord(key_c)) % 256)\n        enc.append(enc_c)\n    return base64.urlsafe_b64encode(\"\".join(enc).encode()).decode()", "response": "Encrypt a string according to a specific password."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decryptstring(enc, password):\n\n    dec = []\n    enc = base64.urlsafe_b64decode(enc).decode()\n    for i in enumerate(enc):\n        key_c = password[i[0] % len(password)]\n        dec_c = chr((256 + ord(i[1]) - ord(key_c)) % 256)\n        dec.append(dec_c)\n    return \"\".join(dec)", "response": "Decrypt an encrypted string according to a specific password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninstall one or more pip packages.", "response": "def pipinstall(packages):\n    \"\"\"\n    Install one or more pip packages.\n\n    :type packages: string or list\n    :param packages: The package or list of packages to install.\n\n    :raises TypeError: Nor a string or a list was provided.\n    \"\"\"\n\n    if isinstance(packages, str):\n        if hasattr(pip, 'main'):\n            pip.main(['install', packages])\n        else:\n            pip._internal.main(['install', packages])\n    elif isinstance(packages, list):\n        for i in enumerate(packages):\n            if hasattr(pip, 'main'):\n                pip.main(['install', i[1]])\n            else:\n                pip._internal.main(['install', i[1]])\n    else:\n        raise TypeError(\"Nor a string or a list was provided.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating all currently installed pip packages", "response": "def pipupdate():\n    \"\"\"\n    Update all currently installed pip packages\n    \"\"\"\n\n    packages = [d for d in pkg_resources.working_set]\n    subprocess.call('pip install --upgrade ' + ' '.join(packages))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the directory exists and if it does not exist.", "response": "def dirtool(operation, directory):\n    \"\"\"\n    Tools For Directories (If Exists, Make And Delete)\n\n    :raises ValueError: Nor a string or a list was provided.\n    \"\"\"\n    operation = operation.lower()\n    if operation == 'exists':\n        return bool(os.path.exists(directory))\n    if operation == 'create':\n        os.makedirs(directory)\n    elif operation == 'delete':\n        os.rmdir(directory)\n    else:\n        raise ValueError('Invalid operation provided.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of strings for the specified file.", "response": "def file(operation, path):\n    \"\"\"\n    Tools For Files (If Exists, Make And Delete)\n    \"\"\"\n    operation = operation.lower()\n    if operation == 'exists':\n        return bool(os.path.isfile(path))\n    if operation == 'read':\n        with open(path, 'r') as f:\n            return [line.strip() for line in f]\n    elif operation == 'delete':\n        os.remove(path)\n    elif operation == 'create':\n        open(path, 'w').close()\n    elif operation == 'clear':\n        open(path, 'w').close()\n    else:\n        raise ValueError('Invalid operation provided.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loglevel(leveltype=None, isequal=False):\n    log = logging.getLogger(__name__)\n    leveltype = leveltype\n    loglevels = {\n        \"none\": 0,\n        \"debug\": 10,\n        \"info\": 20,\n        \"warning\": 30,\n        \"error\": 40,\n        \"critical\": 50\n    }\n    if leveltype is None and isequal is False:\n        return log.getEffectiveLevel()\n    if leveltype is not None and isequal is True:\n        if leveltype in loglevels.values():\n            return leveltype == log.getEffectiveLevel()\n        elif leveltype in loglevels:\n            return loglevels[leveltype] == log.getEffectiveLevel()\n        raise ValueError(\n            \"Incorrect input provided. It should be none, debug, info, warning, error or critical.\"\n        )\n    if leveltype in loglevels.values():\n        log.basicConfig(level=leveltype)\n    elif leveltype in loglevels:\n        log.basicConfig(level=loglevels[leveltype])\n    else:\n        raise ValueError(\n            \"Incorrect input provided. It should be none, debug, info, warning, error or critical.\"\n        )", "response": "Returns True if the logging level is equal to the leveltype."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the file for Quilt to log to.", "response": "def logfile(targetfile=\"ros.log\"):\n    \"\"\"\n    Set the file for Quilt to log to\n    targetfile:\n    Change the file to log to.\n    \"\"\"\n    log = logging.getLogger(__name__)\n    log.basicConfig(filename=str(targetfile))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform changes on text files on the file system", "response": "def text(path, operation, content):\n    \"\"\"\n    Perform changes on text files\n\n    :type path: string\n    :param path: The path to perform the action on\n\n    :type operation: string\n    :param operation: The operation to use on the file\n\n    :type content: string\n    :param content: The content to use with the operation\n    \"\"\"\n\n    # If the operation is \"write\"\n    if operation.lower() == 'write':\n        # Open the file as \"fh\"\n        with open(path, 'w') as fh:\n            # Write to the file\n            fh.write(content)\n\n    # If the operation is \"append\"\n    elif operation.lower() == 'append':\n        # Open the file as \"fh\"\n        with open(path, 'a') as fh:\n            # Write to the file\n            fh.write(content)\n\n    # Raise a warning\n    raise ValueError(\"Invalid operation provided\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getdatetime(timedateformat='complete'):\n\n    timedateformat = timedateformat.lower()\n    if timedateformat == 'day':\n        return ((str(datetime.datetime.now())).split(' ')[0]).split('-')[2]\n    elif timedateformat == 'month':\n        return ((str(datetime.datetime.now())).split(' ')[0]).split('-')[1]\n    elif timedateformat == 'year':\n        return ((str(datetime.datetime.now())).split(' ')[0]).split('-')[0]\n    elif timedateformat == 'hour':\n        return (((str(datetime.datetime.now())).split(' ')[1]).split('.')[0]\n               ).split(':')[0]\n    elif timedateformat == 'minute':\n        return (((str(datetime.datetime.now())).split(' ')[1]).split('.')[0]\n               ).split(':')[1]\n    elif timedateformat == 'second':\n        return (((str(datetime.datetime.now())).split(' ')[1]).split('.')[0]\n               ).split(':')[2]\n    elif timedateformat == 'millisecond':\n        return (str(datetime.datetime.now())).split('.')[1]\n    elif timedateformat == 'yearmonthday':\n        return (str(datetime.datetime.now())).split(' ')[0]\n    elif timedateformat == 'daymonthyear':\n        return ((str(datetime.datetime.now())).split(' ')[0]).split(\n            '-')[2] + '-' + ((str(\n                datetime.datetime.now())).split(' ')[0]).split('-')[1] + '-' + (\n                    (str(datetime.datetime.now())).split(' ')[0]).split('-')[0]\n    elif timedateformat == 'hourminutesecond':\n        return ((str(datetime.datetime.now())).split(' ')[1]).split('.')[0]\n    elif timedateformat == 'secondminutehour':\n        return (((str(datetime.datetime.now())).split(' ')[1]).split('.')[0]\n               ).split(':')[2] + ':' + (((str(datetime.datetime.now())).split(\n                   ' ')[1]).split('.')[0]).split(':')[1] + ':' + (\n                       ((str(datetime.datetime.now())).split(' ')[1]\n                       ).split('.')[0]).split(':')[0]\n    elif timedateformat == 'complete':\n        return str(datetime.datetime.now())\n    elif timedateformat == 'datetime':\n        return (str(datetime.datetime.now())).split('.')[0]\n    elif timedateformat == 'timedate':\n        return ((str(\n            datetime.datetime.now())).split('.')[0]).split(' ')[1] + ' ' + (\n                (str(datetime.datetime.now())).split('.')[0]).split(' ')[0]\n    else:\n        raise ValueError(\"Invalid time date format used.\")", "response": "Get the current date or time in a specific format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mailto(to, cc=None, bcc=None, subject=None, body=None):\n\n    mailurl = 'mailto:' + str(to)\n    if cc is None and bcc is None and subject is None and body is None:\n        return str(mailurl)\n    mailurl += '?'\n    if cc is not None:\n        mailurl += 'cc=' + str(cc)\n        added = True\n    added = False\n    if bcc is not None:\n        if added is True:\n            mailurl += '&'\n        mailurl += 'bcc=' + str(cc)\n        added = True\n    if subject is not None:\n        if added is True:\n            mailurl += '&'\n        mailurl += 'subject=' + str(subject)\n        added = True\n    if body is not None:\n        if added is True:\n            mailurl += '&'\n        mailurl += 'body=' + str(body)\n        added = True\n    return mailurl", "response": "Generate and run mailto."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute_virsh_command(self,\n                              **kwargs):\n        '''\n        common virsh execution function\n        '''\n        host_list = kwargs.get('host_list', None)\n        remote_user = kwargs.get('remote_user', None)\n        remote_pass = kwargs.get('remote_pass', None)\n        sudo = kwargs.get('sudo', False)\n        sudo_user = kwargs.get('sudo_user', None)\n        sudo_pass = kwargs.get('sudo_pass', None)\n\n        host_list, remote_user, remote_pass, \\\n            sudo, sudo_user, sudo_pass = self.get_validated_params(\n                host_list, remote_user,\n                remote_pass, sudo,\n                sudo_user, sudo_pass)\n\n        if 'cmd' not in kwargs.keys():\n            print \"Require a command to execute\"\n            return None\n        cmd = kwargs['cmd']\n\n        if 'delimiter' not in kwargs.keys():\n            delimiter = \":\"\n        else:\n            delimiter = kwargs['delimiter']\n\n        if 'output_type' not in kwargs.keys():\n            output_type = \"LRVALUE\"\n        else:\n            output_type = kwargs['output_type']\n\n        if output_type == \"TABLE\":\n            if 'fields' not in kwargs.keys():\n                print \"Require to pass fields\"\n                return None\n\n        fields = kwargs['fields']\n\n        result, failed_hosts = self.runner.ansible_perform_operation(\n            host_list=host_list,\n            remote_user=remote_user,\n            remote_pass=remote_pass,\n            module=\"command\",\n            module_args=cmd,\n            sudo=sudo,\n            sudo_user=sudo_user,\n            sudo_pass=sudo_pass)\n\n        virsh_result = None\n        if result['contacted'].keys():\n            virsh_result = {}\n            for node in result['contacted'].keys():\n                nodeobj = result['contacted'][node]\n                if output_type == \"LRVALUE\":\n                    jsonoutput = rex.parse_lrvalue_string(nodeobj['stdout'],\n                                                          delimiter)\n                elif output_type == \"TABLE\":\n                    jsonoutput = rex.parse_tabular_string(nodeobj['stdout'],\n                                                          fields)\n                else:\n                    pass\n                virsh_result[node] = {}\n                virsh_result[node]['result'] = jsonoutput\n\n        return virsh_result", "response": "Execute a virsh command and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef virsh_version(self,\n                      host_list=None,\n                      remote_user=None,\n                      remote_pass=None,\n                      sudo=False,\n                      sudo_user=None,\n                      sudo_pass=None):\n        '''\n        Get the virsh version\n        '''\n        host_list, remote_user, remote_pass, \\\n            sudo, sudo_user, sudo_pass = self.get_validated_params(\n               host_list, remote_user, remote_pass, sudo, sudo_user,\n               sudo_pass)\n\n\n        result, failed_hosts = self.runner.ansible_perform_operation(\n            host_list=host_list,\n            remote_user=remote_user,\n            remote_pass=remote_pass,\n            module=\"command\",\n            module_args=\"virsh version\",\n            sudo=sudo,\n            sudo_user=sudo_user,\n            sudo_pass=sudo_pass)\n\n        virsh_result = None\n\n        if result['contacted'].keys():\n            virsh_result = {}\n            for node in result['contacted'].keys():\n                nodeobj = result['contacted'][node]\n                jsonoutput = rex.parse_lrvalue_string(nodeobj['stdout'], \":\")\n                virsh_result[node] = {}\n                virsh_result[node]['result'] = jsonoutput\n\n        return virsh_result", "response": "Get the virsh version of the ansible - free entry point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef virsh_per_domain_info(self,\n                              **kwargs):\n        '''\n        Get per domain stats from each hosts passed as hostlist.\n        '''\n        host_list = kwargs.get('host_list', self.host_list)\n        remote_user = kwargs.get('remote_user', self.remote_user)\n        remote_pass = kwargs.get('remote_pass', self.remote_pass)\n        sudo = kwargs.get('sudo', self.sudo)\n        sudo_user = kwargs.get('sudo_user', self.sudo_user)\n        sudo_pass = kwargs.get('sudo_pass', self.sudo_pass)\n\n        result, failed_hosts = self.runner.ansible_perform_operation(\n            host_list=host_list,\n            remote_user=remote_user,\n            remote_pass=remote_pass,\n            module=\"command\",\n            module_args=\"virsh list\",\n            sudo=sudo,\n            sudo_user=sudo_user,\n            sudo_pass=sudo_pass)\n\n        virsh_result = None\n\n        fields = [\"Id\", \"Name\", \"state\"]\n\n        if result['contacted'].keys():\n            virsh_result = {}\n            for node in result['contacted'].keys():\n                nodeobj = result['contacted'][node]\n                jsonoutput = rex.parse_tabular_string(nodeobj['stdout'],\n                                                      fields)\n                virsh_result[node] = {}\n                virsh_result[node]['result'] = jsonoutput\n\n        print virsh_result\n\n\n        return virsh_result", "response": "Get per domain stats from each host passed as hostlist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a randomized user - agent.", "response": "def getUserAgent():\n\t'''\n\tGenerate a randomized user agent by permuting a large set of possible values.\n\tThe returned user agent should look like a valid, in-use brower, with a specified preferred language of english.\n\n\tReturn value is a list of tuples, where each tuple is one of the user-agent headers.\n\n\tCurrently can provide approximately 147 * 17 * 5 * 5 * 2 * 3 * 2 values, or ~749K possible\n\tunique user-agents.\n\t'''\n\n\tcoding = random.choice(ENCODINGS)\n\trandom.shuffle(coding)\n\tcoding = random.choice((\", \", \",\")).join(coding)\n\n\taccept_list = [tmp for tmp in random.choice(ACCEPT)]\n\taccept_list.append(random.choice(ACCEPT_POSTFIX))\n\taccept_str = random.choice((\", \", \",\")).join(accept_list)\n\n\tassert accept_str.count(\"*.*\") <= 1\n\n\tuser_agent = [\n\t\t\t\t('User-Agent'\t\t,\trandom.choice(USER_AGENTS)),\n\t\t\t\t('Accept-Language'\t,\trandom.choice(ACCEPT_LANGUAGE)),\n\t\t\t\t('Accept'\t\t\t,\taccept_str),\n\t\t\t\t('Accept-Encoding'\t,\tcoding)\n\t\t\t\t]\n\treturn user_agent"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_generator(self):\n\n        faker = Faker()\n\n        try:\n            return getattr(faker, self.category)\n\n        except AttributeError:\n            raise ValueError('Category {} couldn\\'t be found on faker')", "response": "Return the generator object to anonymize data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmap the values of column to new ones of the same type. It replaces the values from others generated using `faker`. It will however, keep the original distribution. That mean that the generated `probability_map` for both will have the same values, but different keys. Args: col (pandas.DataFrame): Dataframe containing the column to anonymize. Returns: pd.DataFrame: DataFrame with its values mapped to new ones, keeping the original distribution. Raises: ValueError: A `ValueError` is raised if faker is not able to provide enought different values.", "response": "def anonymize_column(self, col):\n        \"\"\"Map the values of column to new ones of the same type.\n\n        It replaces the values from others generated using `faker`. It will however,\n        keep the original distribution. That mean that the generated `probability_map` for both\n        will have the same values, but different keys.\n\n        Args:\n            col (pandas.DataFrame): Dataframe containing the column to anonymize.\n\n        Returns:\n            pd.DataFrame: DataFrame with its values mapped to new ones,\n                          keeping the original distribution.\n\n        Raises:\n            ValueError: A `ValueError` is raised if faker is not able to provide enought\n                        different values.\n        \"\"\"\n\n        column = col[self.col_name]\n\n        generator = self.get_generator()\n        original_values = column[~pd.isnull(column)].unique()\n        new_values = [generator() for x in range(len(original_values))]\n\n        if len(new_values) != len(set(new_values)):\n            raise ValueError(\n                'There are not enought different values on faker provider'\n                'for category {}'.format(self.category)\n            )\n\n        value_map = dict(zip(original_values, new_values))\n        column = column.apply(value_map.get)\n\n        return column.to_frame()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fit(self, col):\n\n        column = col[self.col_name].replace({np.nan: np.inf})\n        frequencies = column.groupby(column).count().rename({np.inf: None}).to_dict()\n        # next set probability ranges on interval [0,1]\n        start = 0\n        end = 0\n        num_vals = len(col)\n\n        for val in frequencies:\n            prob = frequencies[val] / num_vals\n            end = start + prob\n            interval = (start, end)\n            mean = np.mean(interval)\n            std = prob / 6\n            self.probability_map[val] = (interval, mean, std)\n            start = end", "response": "Create a map of the empirical probability for each category."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare the transformer to convert data and return the processed table.", "response": "def transform(self, col):\n        \"\"\"Prepare the transformer to convert data and return the processed table.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n\n        out = pd.DataFrame()\n\n        # Make sure all nans are handled the same by replacing with None\n        column = col[self.col_name].replace({np.nan: None})\n        out[self.col_name] = column.apply(self.get_val)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit the transformer and return processed data.", "response": "def fit_transform(self, col):\n        \"\"\"Prepare the transformer and return processed data.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n\n        if self.anonymize:\n            col = self.anonymize_column(col)\n\n        self._fit(col)\n        return self.transform(col)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting data back into original format.", "response": "def reverse_transform(self, col):\n        \"\"\"Converts data back into original format.\n\n        Args:\n            col(pandas.DataFrame): Data to transform.\n\n        Returns:\n            pandas.DataFrame\n        \"\"\"\n\n        output = pd.DataFrame()\n        output[self.col_name] = self.get_category(col[self.col_name])\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting cat value into num between 0 and 1.", "response": "def get_val(self, x):\n        \"\"\"Convert cat value into num between 0 and 1.\"\"\"\n        interval, mean, std = self.probability_map[x]\n        new_val = norm.rvs(mean, std)\n        return new_val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the categories for the specified numeric values.", "response": "def get_category(self, column):\n        \"\"\"Returns categories for the specified numeric values\n\n        Args:\n            column(pandas.Series): Values to transform into categories\n\n        Returns:\n            pandas.Series\n        \"\"\"\n        result = pd.Series(index=column.index)\n\n        for category, stats in self.probability_map.items():\n            start, end = stats[0]\n            result[(start < column) & (column < end)] = category\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, column):\n        self.check_data_type()\n\n        return pd.DataFrame({self.col_name: np.exp(column[self.col_name])})", "response": "Applies an exponential to values to turn them positive numbers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reverse_transform(self, column):\n        self.check_data_type()\n\n        return pd.DataFrame({self.col_name: np.log(column[self.col_name])})", "response": "Applies the natural logarithm function to turn positive values into real ranged values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a YQL query and returns a response", "response": "def raw_query(self, query, format=None, pretty=False):\n        '''Executes a YQL query and returns a response\n        >>>...\n        >>> resp = yql.raw_query('select * from weather.forecast where woeid=2502265')\n        >>>\n        '''\n        if format:\n            format = format\n        else:\n            format = self.format\n\n        payload = self._payload_builder(query, format=format)\n        response = self.execute_query(payload)\n        if pretty:\n            response = self.response_builder(response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the query and returns and response", "response": "def execute_query(self, payload):\n        '''Execute the query and returns and response'''\n        if vars(self).get('oauth'):\n            if not self.oauth.token_is_valid(): # Refresh token if token has expired\n                self.oauth.refresh_token()\n            response = self.oauth.session.get(self.PRIVATE_URL, params= payload, header_auth=True)\n        else:\n            response = requests.get(self.PUBLIC_URL, params= payload)\n\n        self._response = response # Saving last response object.\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat conditions args is a list of ['field operator value ]", "response": "def _clause_formatter(self, cond):\n        '''Formats conditions\n        args is a list of ['field', 'operator', 'value']\n        '''\n\n        if len(cond) == 2 :\n            cond = ' '.join(cond)\n            return cond\n\n        if 'in' in cond[1].lower() :\n            if not isinstance(cond[2], (tuple, list)):\n                    raise TypeError('(\"{0}\") must be of type <type tuple> or <type list>'.format(cond[2]))\n\n            if 'select' not in cond[2][0].lower() :\n                cond[2] = \"({0})\".format(','.join(map(str,[\"'{0}'\".format(e) for e in cond[2]])))\n            else:\n                cond[2] = \"({0})\".format(','.join(map(str,[\"{0}\".format(e) for e in cond[2]])))\n\n            cond = \" \".join(cond)\n        else: \n            #if isinstance(cond[2], str):\n            #    var = re.match('^@(\\w+)$', cond[2])\n            #else:\n            #    var = None\n            #if var :\n            if isinstance(cond[2], str) and cond[2].startswith('@'):\n                cond[2] = \"{0}\".format(cond[2])\n            else :\n                cond[2] = \"'{0}'\".format(cond[2])\n            cond = ' '.join(cond)\n\n        return cond"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef response_builder(self, response):\n        '''Try to return a pretty formatted response object\n        '''\n        try:\n            r = response.json()\n            result = r['query']['results']\n            response = {\n                'num_result': r['query']['count'] ,\n                'result': result\n            }\n        except (Exception,) as e:\n            print(e)\n            return response.content\n\n        return response", "response": "Try to return a pretty formatted response object\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _func_filters(self, filters):\n        '''Build post query filters\n        '''\n        if not isinstance(filters, (list,tuple)):\n            raise TypeError('func_filters must be a <type list> or <type tuple>')\n\n        for i, func in enumerate(filters) :\n            if isinstance(func, str) and func == 'reverse':\n                filters[i] = 'reverse()'\n            elif isinstance(func, tuple) and func[0] in YQL.FUNC_FILTERS:\n                filters[i] = '{:s}(count={:d})'.format(*func)\n            elif isinstance(func, dict) :\n                func_stmt = ''\n                func_name = list(func.keys())[0] # Because of Py3\n                values = [ \"{0}='{1}'\".format(v[0], v[1]) for v in func[func_name] ]\n                func_stmt = ','.join(values)\n                func_stmt = '{0}({1})'.format(func_name, func_stmt)\n                filters[i] = func_stmt\n            else:\n                raise TypeError('{0} is neither a <str>, a <tuple> or a <dict>'.format(func))\n        return '| '.join(filters)", "response": "Build post query filters\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef use(self, url, name='mytable'):\n        '''Changes the data provider\n        >>> yql.use('http://myserver.com/mytables.xml')\n        '''\n        self.yql_table_url = url\n        self.yql_table_name = name\n        return {'table url': url, 'table name': name}", "response": "Changes the data provider\n        >>> yql. use ( myserver. com"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning table description >>> yql.desc('geo.countries') >>>", "response": "def desc(self, table):\n        '''Returns table description\n        >>> yql.desc('geo.countries')\n        >>>\n        '''\n        query = \"desc {0}\".format(table)\n        response = self.raw_query(query)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, table, items=None, limit=None, offset=None, remote_filter=None, func_filters=None):\n        '''This method simulate a select on a table\n        >>> yql.select('geo.countries', limit=5) \n        >>> yql.select('social.profile', ['guid', 'givenName', 'gender'])\n        '''\n        self._table = table\n\n        if remote_filter:\n            if not isinstance(remote_filter, tuple):\n                raise TypeError(\"{0} must be of type <type tuple>\".format(remote_filter))\n\n            table = \"%s(%s)\" %(table, ','.join(map(str, remote_filter)))\n\n        if not items:\n            items = ['*']\n        self._query = \"SELECT {1} FROM {0} \".format(table, ','.join(items))\n\n        if func_filters:\n            self._func = self._func_filters(func_filters) \n\n        self._limit = limit\n        self._offset = offset\n            \n        return self", "response": "This method simulate a select on a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, table,items, values):\n        values = [\"'{0}'\".format(e) for e in values]\n        self._query = \"INSERT INTO {0} ({1}) VALUES ({2})\".format(table,','.join(items),','.join(values))\n        payload = self._payload_builder(self._query)\n        response = self.execute_query(payload)\n\n        return response", "response": "This method allows to insert data into table\n        >>> yql. insert ( bi. ly. shorten"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, table, items, values):\n        self._table = table\n        self._limit = None\n        items_values = ','.join([\"{0} = '{1}'\".format(k,v) for k,v in zip(items,values)])\n        self._query = \"UPDATE {0} SET {1}\".format(self._table, items_values)\n\n        return self", "response": "Update a YQL table with a list of items and a list of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, table):\n        self._table = table\n        self._limit = None\n        self._query = \"DELETE FROM {0}\".format(self._table)\n\n        return self", "response": "Deletes record in table"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef where(self, *args):\n        ''' This method simulates a where condition. Use as follow:\n        >>> yql.select('mytable').where(['name', '=', 'alain'], ['location', '!=', 'paris'])\n        '''\n        if not self._table:\n            raise errors.NoTableSelectedError('No Table Selected')\n\n        clause = []\n        self._query += ' WHERE '\n\n        clause = [ self._clause_formatter(x) for x in args if x ]\n\n        self._query += ' AND '.join(clause)\n\n        payload = self._payload_builder(self._query)\n        response = self.execute_query(payload)\n\n        return response", "response": "This method simulates a where condition. Use as follow."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show_tables(self, format='json'):\n        '''Return list of all available tables'''\n\n        query = 'SHOW TABLES'\n        payload = self._payload_builder(query, format) \t\n\n        response = self.execute_query(payload) \n\n        return response", "response": "Return list of all available tables"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_weather_in(self, place, unit=None, items=None):\n        unit = unit if unit else self.unit\n        response = self.select('weather.forecast', items=items).where(['woeid','IN',('SELECT woeid FROM geo.places WHERE text=\"{0}\"'.format(place),)], ['u','=',unit] if unit else [])\n        return response", "response": "Return weather info according to place"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn weather forecast accoriding to place", "response": "def get_weather_forecast(self, place, unit=None):\n        \"\"\"Return weather forecast accoriding to place\n        \"\"\"\n        unit = unit if unit else self.unit\n        response = self.get_weather_in(place, items=['item.forecast'], unit=unit)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stepThroughJsWaf_bare_chromium(self, url, titleContains='', titleNotContains='', extra_tid=None):\n\t\t'''\n\t\tUse Chromium to access a resource behind WAF protection.\n\n\t\tParams:\n\t\t\t``url`` - The URL to access that is protected by WAF\n\t\t\t``titleContains`` - A string that is in the title of the protected page, and NOT the\n\t\t\t\tWAF intermediate page. The presence of this string in the page title\n\t\t\t\tis used to determine whether the WAF protection has been successfully\n\t\t\t\tpenetrated.\n\t\t\t``titleContains`` - A string that is in the title of the WAF intermediate page\n\t\t\t\tand NOT in the target page. The presence of this string in the page title\n\t\t\t\tis used to determine whether the WAF protection has been successfully\n\t\t\t\tpenetrated.\n\n\t\tThe current WebGetRobust headers are installed into the selenium browser, which\n\t\tis then used to access the protected resource.\n\n\t\tOnce the protected page has properly loaded, the WAF access cookie is\n\t\tthen extracted from the selenium browser, and installed back into the WebGetRobust\n\t\tinstance, so it can continue to use the WAF auth in normal requests.\n\n\t\t'''\n\n\t\tif (not titleContains) and (not titleNotContains):\n\t\t\traise ValueError(\"You must pass either a string the title should contain, or a string the title shouldn't contain!\")\n\n\t\tif titleContains and titleNotContains:\n\t\t\traise ValueError(\"You can only pass a single conditional statement!\")\n\n\t\tself.log.info(\"Attempting to access page through WAF browser verification.\")\n\n\t\tcurrent_title = None\n\n\t\tif extra_tid is True:\n\t\t\textra_tid = threading.get_ident()\n\n\t\twith self._chrome_context(url, extra_tid=extra_tid) as cr:\n\t\t\tself._syncIntoChromium(cr)\n\t\t\tcr.blocking_navigate(url)\n\n\t\t\tfor _ in range(self.wrapper_step_through_timeout):\n\t\t\t\ttime.sleep(1)\n\t\t\t\tcurrent_title, _ = cr.get_page_url_title()\n\t\t\t\tif titleContains and titleContains in current_title:\n\t\t\t\t\tself._syncOutOfChromium(cr)\n\t\t\t\t\treturn True\n\t\t\t\tif titleNotContains and current_title and titleNotContains not in current_title:\n\t\t\t\t\tself._syncOutOfChromium(cr)\n\t\t\t\t\treturn True\n\n\t\t\tself._syncOutOfChromium(cr)\n\n\t\tself.log.error(\"Failed to step through. Current title: '%s'\", current_title)\n\n\t\treturn False", "response": "This method is used to step through the WAF browser verification process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a chromium context.", "response": "def chromiumContext(self, url, extra_tid=None):\n\t\t'''\n\t\tReturn a active chromium context, useable for manual operations directly against\n\t\tchromium.\n\n\t\tThe WebRequest user agent and other context is synchronized into the chromium\n\t\tinstance at startup, and changes are flushed back to the webrequest instance\n\t\tfrom chromium at completion.\n\t\t'''\n\t\tassert url is not None, \"You need to pass a URL to the contextmanager, so it can dispatch to the correct tab!\"\n\n\n\t\tif extra_tid is True:\n\t\t\textra_tid = threading.get_ident()\n\n\t\treturn self._chrome_context(url, extra_tid=extra_tid)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_data_table(table_name, meta_file, meta):\n    for table in meta['tables']:\n        if table['name'] == table_name:\n            prefix = os.path.dirname(meta_file)\n            relative_path = os.path.join(prefix, meta['path'], table['path'])\n            return pd.read_csv(relative_path), table", "response": "Load the contents and metadata of a given table."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the content and metadata of a fiven column.", "response": "def get_col_info(table_name, col_name, meta_file):\n    \"\"\"Return the content and metadata of a fiven column.\n\n    Args:\n        table_name(str): Name of the table.\n        col_name(str): Name of the column.\n        meta_file(str): Path to the meta.json file.\n\n    Returns:\n        tuple(pandas.Series, dict)\n    \"\"\"\n\n    with open(meta_file, 'r') as f:\n        meta = json.load(f)\n\n    data_table, table = load_data_table(table_name, meta_file, meta)\n\n    for field in table['fields']:\n        if field['name'] == col_name:\n            col_meta = field\n\n    col = data_table[col_name]\n\n    return (col, col_meta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the current user has permission for this view.", "response": "def has_permission(self, request, *args, **kwargs):\n        \"\"\"\n        Figures out if the current user has permissions for this view.\n        \"\"\"\n        self.kwargs = kwargs\n        self.args = args\n        self.request = request\n        self.org = self.derive_org()\n\n        if self.get_user().is_superuser:\n            return True\n\n        if self.get_user().has_perm(self.permission):\n            return True\n\n        return self.has_org_perm(self.permission)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef task_coverage():\n    cov = Coverage(\n        [PythonPackage('import_deps', 'tests')],\n        config={'branch':True,},\n    )\n    yield cov.all() # create task `coverage`\n    yield cov.src()", "response": "show coverage for all modules including tests"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_workflow(connection, domain, workflow):\n    args = get_workflow_registration_parameter(workflow)\n\n    try:\n        connection.register_workflow_type(domain=domain, **args)\n    except ClientError as err:\n        if err.response['Error']['Code'] == 'TypeAlreadyExistsFault':\n            return False  # Ignore this error\n        raise\n\n    return True", "response": "Register a workflow type. Return False if this workflow already registered Return True if this workflow already registered Return False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pretty_json(data):\n    data = json.loads(data.decode('utf-8'))\n    return json.dumps(data, indent=4, sort_keys=True)", "response": "Return a pretty formatted json\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_xml(data):\n    parsed_string = minidom.parseString(data.decode('utf-8'))\n    return parsed_string.toprettyxml(indent='\\t', encoding='utf-8')", "response": "Return a pretty formated xml\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prettyfy(response, format='json'):\n    if format == 'json':\n        return pretty_json(response.content)\n    else:\n        return pretty_xml(response.content)", "response": "A wrapper for pretty_json and pretty_xml"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the USN Journal content removing duplicates and corrupted records.", "response": "def parse_journal(journal):\n    \"\"\"Parses the USN Journal content removing duplicates\n    and corrupted records.\n\n    \"\"\"\n    events = [e for e in journal if not isinstance(e, CorruptedUsnRecord)]\n    keyfunc = lambda e: str(e.file_reference_number) + e.file_name + e.timestamp\n    event_groups = (tuple(g) for k, g in groupby(events, key=keyfunc))\n\n    if len(events) < len(list(journal)):\n        LOGGER.debug(\n            \"Corrupted records in UsnJrnl, some events might be missing.\")\n\n    return [journal_event(g) for g in event_groups]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef journal_event(events):\n    reasons = set(chain.from_iterable(e.reasons for e in events))\n    attributes = set(chain.from_iterable(e.file_attributes for e in events))\n\n    return JrnlEvent(events[0].file_reference_number,\n                     events[0].parent_file_reference_number,\n                     events[0].file_name,\n                     events[0].timestamp,\n                     list(reasons), list(attributes))", "response": "Group multiple events into a single one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_timeline(usnjrnl, filesystem_content):\n    journal_content = defaultdict(list)\n    for event in usnjrnl:\n        journal_content[event.inode].append(event)\n\n    for event in usnjrnl:\n        try:\n            dirent = lookup_dirent(event, filesystem_content, journal_content)\n\n            yield UsnJrnlEvent(\n                dirent.inode, dirent.path, dirent.size, dirent.allocated,\n                event.timestamp, event.changes, event.attributes)\n        except LookupError as error:\n            LOGGER.debug(error)", "response": "Generates the USN journal and filesystem content for the USN archive."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _visit_filesystem(self):\n        self.logger.debug(\"Parsing File System content.\")\n\n        root_partition = self._filesystem.inspect_get_roots()[0]\n\n        yield from self._root_dirent()\n\n        for entry in self._filesystem.filesystem_walk(root_partition):\n            yield Dirent(\n                entry['tsk_inode'],\n                self._filesystem.path('/' + entry['tsk_name']),\n                entry['tsk_size'], entry['tsk_type'],\n                True if entry['tsk_flags'] & TSK_ALLOC else False,\n                timestamp(entry['tsk_atime_sec'], entry['tsk_atime_nsec']),\n                timestamp(entry['tsk_mtime_sec'], entry['tsk_mtime_nsec']),\n                timestamp(entry['tsk_ctime_sec'], entry['tsk_ctime_nsec']),\n                timestamp(entry['tsk_crtime_sec'], entry['tsk_crtime_nsec']))", "response": "Walks through the filesystem content and yields Dirents."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _root_dirent(self):\n        fstat = self._filesystem.stat('/')\n\n        yield Dirent(fstat['ino'], self._filesystem.path('/'),\n                     fstat['size'], 'd', True,\n                     timestamp(fstat['atime'], 0),\n                     timestamp(fstat['mtime'], 0),\n                     timestamp(fstat['ctime'], 0),\n                     0)", "response": "Returns the root folder dirent as filesystem_walk API doesn t."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over the changes occurred within the Unix FS and generates a UsnJrnlEvent object.", "response": "def usnjrnl_timeline(self):\n        \"\"\"Iterates over the changes occurred within the filesystem.\n\n        Yields UsnJrnlEvent namedtuples containing:\n\n            file_reference_number: known in Unix FS as inode.\n            path: full path of the file.\n            size: size of the file in bytes if recoverable.\n            allocated: whether the file exists or it has been deleted.\n            timestamp: timespamp of the change.\n            changes: list of changes applied to the file.\n            attributes: list of file attributes.\n\n        \"\"\"\n        filesystem_content = defaultdict(list)\n\n        self.logger.debug(\"Extracting Update Sequence Number journal.\")\n\n        journal = self._read_journal()\n\n        for dirent in self._visit_filesystem():\n            filesystem_content[dirent.inode].append(dirent)\n\n        self.logger.debug(\"Generating timeline.\")\n        yield from generate_timeline(journal, filesystem_content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the USN journal from the disk and parses its content.", "response": "def _read_journal(self):\n        \"\"\"Extracts the USN journal from the disk and parses its content.\"\"\"\n        root = self._filesystem.inspect_get_roots()[0]\n        inode = self._filesystem.stat('C:\\\\$Extend\\\\$UsnJrnl')['ino']\n\n        with NamedTemporaryFile(buffering=0) as tempfile:\n            self._filesystem.download_inode(root, inode, tempfile.name)\n\n            journal = usn_journal(tempfile.name)\n\n            return parse_journal(journal)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nspawns a new background process", "response": "def put(self, stream, cmd):\n        \"\"\" Spawn a new background process \"\"\"\n\n        if len(self.q) < self.max_size:\n            if stream['id'] in self.q:\n                raise QueueDuplicate\n            p = self.call(stream, cmd)\n            self.q[stream['id']] = p\n        else:\n            raise QueueFull"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_finished(self):\n        indices  = []\n        for idf, v in self.q.items():\n            if v.poll() != None:\n                indices.append(idf)\n\n        for i in indices:\n            self.q.pop(i)\n        return indices", "response": "Clean up terminated processes and returns the list of their ids"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_stdouts(self):\n        souts = []\n        for v in self.q.values():\n            souts.append(v.stdout)\n        return souts", "response": "Get the list of stdout of each process"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nterminate a process by id", "response": "def terminate_process(self, idf):\n        \"\"\" Terminate a process by id \"\"\"\n        try:\n            p = self.q.pop(idf)\n            p.terminate()\n            return p\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the text interface", "response": "def init(self, s):\n        \"\"\" Initialize the text interface \"\"\"\n\n        # Hide cursor\n        curses.curs_set(0)\n\n        self.s = s\n        self.s.keypad(1)\n\n        self.set_screen_size()\n\n        self.pads = {}\n        self.offsets = {}\n\n        self.init_help()\n        self.init_streams_pad()\n        self.current_pad = 'streams'\n\n        self.set_title(TITLE_STRING)\n\n        self.got_g = False\n\n        signal.signal(28, self.resize)\n\n        if self.config.CHECK_ONLINE_ON_START:\n            self.check_online_streams()\n\n        self.set_status('Ready')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n\n        # Show stream list\n        self.show_streams()\n\n        while True:\n            self.s.refresh()\n\n            # See if any stream has ended\n            self.check_stopped_streams()\n\n            # Wait on stdin or on the streams output\n            souts = self.q.get_stdouts()\n            souts.append(sys.stdin)\n            try:\n                (r, w, x) = select.select(souts, [], [], 1)\n            except select.error:\n                continue\n            if not r:\n                if self.config.CHECK_ONLINE_INTERVAL <= 0: continue\n                cur_time = int(time())\n                time_delta = cur_time - self.last_autocheck\n                if time_delta > self.config.CHECK_ONLINE_INTERVAL:\n                    self.check_online_streams()\n                    self.set_status('Next check at {0}'.format(\n                        strftime('%H:%M:%S', localtime(time() + self.config.CHECK_ONLINE_INTERVAL))\n                        ))\n                continue\n            for fd in r:\n                if fd != sys.stdin:\n                    # Set the new status line only if non-empty\n                    msg = fd.readline()\n                    if msg:\n                        self.set_status(msg[:-1])\n                else:\n                    # Main event loop\n                    c = self.pads[self.current_pad].getch()\n                    if c == curses.KEY_UP or c == ord('k'):\n                        self.move(-1)\n                    elif c == curses.KEY_DOWN or c == ord('j'):\n                        self.move(1)\n                    elif c == ord('f'):\n                        if self.current_pad == 'streams':\n                            self.filter_streams()\n                    elif c == ord('F'):\n                        if self.current_pad == 'streams':\n                            self.clear_filter()\n                    elif c == ord('g'):\n                        if self.got_g:\n                            self.move(0, absolute=True)\n                            self.got_g = False\n                            continue\n                        self.got_g = True\n                    elif c == ord('G'):\n                        self.move(len(self.filtered_streams)-1, absolute=True)\n                    elif c == ord('q'):\n                        if self.current_pad == 'streams':\n                            self.q.terminate()\n                            return\n                        else:\n                            self.show_streams()\n                    elif c == 27: # ESC\n                        if self.current_pad != 'streams':\n                            self.show_streams()\n                    if self.current_pad == 'help':\n                        continue\n                    elif c == 10:\n                        self.play_stream()\n                    elif c == ord('s'):\n                        self.stop_stream()\n                    elif c == ord('c'):\n                        self.reset_stream()\n                    elif c == ord('n'):\n                        self.edit_stream('name')\n                    elif c == ord('r'):\n                        self.edit_stream('res')\n                    elif c == ord('u'):\n                        self.edit_stream('url')\n                    elif c == ord('l'):\n                        self.show_commandline()\n                    elif c == ord('L'):\n                        self.shift_commandline()\n                    elif c == ord('a'):\n                        self.prompt_new_stream()\n                    elif c == ord('d'):\n                        self.delete_stream()\n                    elif c == ord('o'):\n                        self.show_offline_streams ^= True\n                        self.refilter_streams()\n                    elif c == ord('O'):\n                        self.check_online_streams()\n                    elif c == ord('h') or c == ord('?'):\n                        self.show_help()", "response": "Main event loop for the internal check process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_screen_size(self):\n        height, width = self.getheightwidth()\n        curses.resizeterm(height, width)\n        self.pad_x = 0\n        self.max_y, self.max_x = (height-1, width-1)\n        self.pad_h = height-3\n        self.pad_w = width-2*self.pad_x", "response": "Setup screen size and padding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the title line text", "response": "def set_title(self, msg):\n        \"\"\" Set first header line text \"\"\"\n        self.s.move(0, 0)\n        self.overwrite_line(msg, curses.A_REVERSE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the first head line text.", "response": "def set_header(self, msg):\n        \"\"\" Set second head line text \"\"\"\n        self.s.move(1, 0)\n        self.overwrite_line(msg, attr=curses.A_NORMAL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets first footer line text", "response": "def set_footer(self, msg, reverse=True):\n        \"\"\" Set first footer line text \"\"\"\n        self.s.move(self.max_y-1, 0)\n        if reverse:\n            self.overwrite_line(msg, attr=curses.A_REVERSE)\n        else:\n            self.overwrite_line(msg, attr=curses.A_NORMAL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_help(self):\n        self.s.move(1,0)\n        self.s.clrtobot()\n        self.set_header('Help'.center(self.pad_w))\n        self.set_footer(' ESC or \\'q\\' to return to main menu')\n        self.s.refresh()\n        self.current_pad = 'help'\n        self.refresh_current_pad()", "response": "Redraw Help screen and wait for any input to leave"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_streams_pad(self, start_row=0):\n        y = 0\n        pad = curses.newpad(max(1,len(self.filtered_streams)), self.pad_w)\n        pad.keypad(1)\n        for s in self.filtered_streams:\n            pad.addstr(y, 0, self.format_stream_line(s))\n            y+=1\n        self.offsets['streams'] = 0\n        pad.move(start_row, 0)\n        if not self.no_stream_shown:\n            pad.chgat(curses.A_REVERSE)\n        self.pads['streams'] = pad", "response": "Create a curses pad and populate it with a line by stream"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, direction, absolute=False, pad_name=None, refresh=True):\n\n        # pad in this lists have the current line highlighted\n        cursor_line = [ 'streams' ]\n\n        # pads in this list will be moved screen-wise as opposed to line-wise\n        # if absolute is set, will go all the way top or all the way down depending\n        # on direction\n        scroll_only = [ 'help' ]\n\n        if not pad_name:\n            pad_name = self.current_pad\n        pad = self.pads[pad_name]\n        if pad_name == 'streams' and self.no_streams:\n            return\n        (row, col) = pad.getyx()\n        new_row    = row\n        offset = self.offsets[pad_name]\n        new_offset = offset\n        if pad_name in scroll_only:\n            if absolute:\n                if direction > 0:\n                    new_offset = pad.getmaxyx()[0] - self.pad_h + 1\n                else:\n                    new_offset = 0\n            else:\n                if direction > 0:\n                    new_offset = min(pad.getmaxyx()[0] - self.pad_h + 1, offset + self.pad_h)\n                elif offset > 0:\n                    new_offset = max(0, offset - self.pad_h)\n        else:\n            if absolute and direction >= 0 and direction < pad.getmaxyx()[0]:\n                if direction < offset:\n                    new_offset = direction\n                elif direction > offset + self.pad_h - 2:\n                    new_offset = direction - self.pad_h + 2\n                new_row = direction\n            else:\n                if direction == -1 and row > 0:\n                    if row == offset:\n                        new_offset -= 1\n                    new_row = row-1\n                elif direction == 1 and row < len(self.filtered_streams)-1:\n                    if row == offset + self.pad_h - 2:\n                        new_offset += 1\n                    new_row = row+1\n        if pad_name in cursor_line:\n            pad.move(row, 0)\n            pad.chgat(curses.A_NORMAL)\n        self.offsets[pad_name] = new_offset\n        pad.move(new_row, 0)\n        if pad_name in cursor_line:\n            pad.chgat(curses.A_REVERSE)\n        if pad_name == 'streams':\n            self.redraw_stream_footer()\n        if refresh:\n            self.refresh_current_pad()", "response": "Scroll the current pad in the given direction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nredrawing the highlighted line", "response": "def redraw_current_line(self):\n        \"\"\" Redraw the highlighted line \"\"\"\n        if self.no_streams:\n            return\n        row = self.pads[self.current_pad].getyx()[0]\n        s = self.filtered_streams[row]\n        pad = self.pads['streams']\n        pad.move(row, 0)\n        pad.clrtoeol()\n        pad.addstr(row, 0, self.format_stream_line(s), curses.A_REVERSE)\n        pad.chgat(curses.A_REVERSE)\n        pad.move(row, 0)\n        self.refresh_current_pad()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stepThroughJsWaf_selenium_chromium(self, url, titleContains='', titleNotContains=''):\n\t\t'''\n\t\tUse Selenium+SeleniumChromium to access a resource behind cloudflare protection.\n\n\t\tParams:\n\t\t\t``url`` - The URL to access that is protected by cloudflare\n\t\t\t``titleContains`` - A string that is in the title of the protected page, and NOT the\n\t\t\t\tcloudflare intermediate page. The presence of this string in the page title\n\t\t\t\tis used to determine whether the cloudflare protection has been successfully\n\t\t\t\tpenetrated.\n\n\t\tThe current WebGetRobust headers are installed into the selenium browser, which\n\t\tis then used to access the protected resource.\n\n\t\tOnce the protected page has properly loaded, the cloudflare access cookie is\n\t\tthen extracted from the selenium browser, and installed back into the WebGetRobust\n\t\tinstance, so it can continue to use the cloudflare auth in normal requests.\n\n\t\t'''\n\n\t\tif (not titleContains) and (not titleNotContains):\n\t\t\traise ValueError(\"You must pass either a string the title should contain, or a string the title shouldn't contain!\")\n\n\t\tif titleContains and titleNotContains:\n\t\t\traise ValueError(\"You can only pass a single conditional statement!\")\n\n\t\tself.log.info(\"Attempting to access page through cloudflare browser verification.\")\n\n\t\tif not self.selenium_chromium_driver:\n\t\t\tself._initSeleniumChromiumWebDriver()\n\t\tself._syncIntoSeleniumChromiumWebDriver()\n\n\n\t\tself.selenium_chromium_driver.get(url)\n\n\t\tif titleContains:\n\t\t\tcondition = EC.title_contains(titleContains)\n\t\telif titleNotContains:\n\t\t\tcondition = SeleniumCommon.title_not_contains(titleNotContains)\n\t\telse:\n\t\t\traise ValueError(\"Wat?\")\n\n\n\t\ttry:\n\t\t\tWebDriverWait(self.selenium_chromium_driver, 45).until(condition)\n\t\t\tsuccess = True\n\t\t\tself.log.info(\"Successfully accessed main page!\")\n\t\texcept TimeoutException:\n\t\t\tself.log.error(\"Could not pass through cloudflare blocking!\")\n\t\t\tsuccess = False\n\t\t# Add cookies to cookiejar\n\n\t\tself._syncOutOfSeleniumChromiumWebDriver()\n\n\t\tself._syncCookiesFromFile()\n\n\t\treturn success", "response": "This method is used to access a resource behind the cloudflare protection. It is used to access a resource behind the cloudflare protection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self, content):\n        # Try parsing the YAML with global tags\n        try:\n            config = yaml.load(content, Loader=self._loader(self._global_tags))\n        except yaml.YAMLError:\n            raise InvalidConfigError(_(\"Config is not valid yaml.\"))\n\n        # Try extracting just the tool portion\n        try:\n            config = config[self.tool]\n        except (TypeError, KeyError):\n            return None\n\n        # If no scopes, just apply global default\n        if not isinstance(config, dict):\n            config = self._apply_default(config, self._global_default)\n        else:\n            # Figure out what scopes exist\n            scoped_keys = set(key for key in self._scopes)\n\n            # For every scope\n            for key in config:\n                # If scope has custom tags, apply\n                if key in scoped_keys:\n                    # local tags, and local default\n                    tags, default = self._scopes[key]\n\n                    # Inherit global default if no local default\n                    if not default:\n                        default = self._global_default\n\n                    config[key] = self._apply_default(config[key], default)\n                    self._apply_scope(config[key], tags)\n                # Otherwise just apply global default\n                else:\n                    config[key] = self._apply_default(config[key], self._global_default)\n\n        self._validate(config)\n\n        return config", "response": "Parse the content of a YAML file and return a dictionary with the keys as keys and the values as values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a yaml Loader.", "response": "def _loader(self, tags):\n        \"\"\"Create a yaml Loader.\"\"\"\n        class ConfigLoader(SafeLoader):\n            pass\n        ConfigLoader.add_multi_constructor(\"\", lambda loader, prefix, node: TaggedValue(node.value, node.tag, *tags))\n        return ConfigLoader"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking whether every TaggedValue has a valid tag otherwise raise InvalidConfigError", "response": "def _validate(self, config):\n        \"\"\"Check whether every TaggedValue has a valid tag, otherwise raise InvalidConfigError\"\"\"\n        if isinstance(config, dict):\n            # Recursively validate each item in the config\n            for val in config.values():\n                self._validate(val)\n\n        elif isinstance(config, list):\n            # Recursively validate each item in the config\n            for item in config:\n                self._validate(item)\n\n        elif isinstance(config, TaggedValue):\n            tagged_value = config\n\n            # if tagged_value is invalid, error\n            if tagged_value.tag not in tagged_value.tags:\n                raise InvalidConfigError(_(\"{} is not a valid tag for {}\".format(tagged_value.tag, self.tool)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying default value to every TaggedValue in config.", "response": "def _apply_default(self, config, default):\n        \"\"\"\n        Apply default value to every str in config.\n        Also ensure every TaggedValue has default in .tags\n        \"\"\"\n        # No default, nothing to be done here\n        if not default:\n            return config\n\n        # If the entire config is just a string, return default TaggedValue\n        if isinstance(config, str):\n            return TaggedValue(config, default, default, *self._global_tags)\n\n        if isinstance(config, dict):\n            # Recursively apply defaults for  each item in the config\n            for key, val in config.items():\n                config[key] = self._apply_default(val, default)\n\n        elif isinstance(config, list):\n            # Recursively apply defaults for each item in the config\n            for i, val in enumerate(config):\n                config[i] = self._apply_default(val, default)\n\n        elif isinstance(config, TaggedValue):\n            # Make sure each TaggedValue knows about the default tag\n            config.tags.add(default)\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _apply_scope(self, config, tags):\n        if isinstance(config, dict):\n            # Recursively _apply_scope for each item in the config\n            for val in config.values():\n                self._apply_scope(val, tags)\n\n        elif isinstance(config, list):\n            # Recursively _apply_scope for each item in the config\n            for item in config:\n                self._apply_scope(item, tags)\n\n        elif isinstance(config, TaggedValue):\n            tagged_value = config\n\n            # add all local tags\n            tagged_value.tags |= set(tags)\n            for tag in tags:\n                if not hasattr(tagged_value, tag):\n                    setattr(tagged_value, tag, False)", "response": "Add locally scoped tags to config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_args():\n        ''' returns true if the decorator invocation\n            had arguments passed to it before being\n            sent a function to decorate '''\n        no_args_syntax = '@overload'\n        args_syntax = no_args_syntax + '('\n        args, no_args = [(-1,-1)], [(-1,-1)]\n        for i, line in enumerate(Overload.traceback_lines()):\n            if args_syntax in line:\n                args.append((i, line.find(args_syntax)))\n            if no_args_syntax in line:\n                no_args.append((i, line.find(no_args_syntax)))\n        args, no_args = max(args), max(no_args)\n        if sum(args)+sum(no_args) == -4:\n            # couldnt find invocation\n            return False\n        return args >= no_args", "response": "returns true if the decorator invocation\n            had arguments passed to it before being\n            sent a function to decorate"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nidentifying a function and return a tuple that is used to match the function to their neighbors in their resident namespaces", "response": "def identify(fn):\n        ''' returns a tuple that is used to match\n            functions to their neighbors in their\n            resident namespaces '''\n        return (\n            fn.__globals__['__name__'], # module namespace\n            getattr(fn, '__qualname__', getattr(fn, '__name__', '')) # class and function namespace\n        )\n        def __init__(self, fn):\n            self.validate_function(fn)\n            self.configured = False\n            self.has_backup_plan = False\n            if self.has_args():\n                self.backup_plan = fn\n            else:\n                self.id = self.identify(fn)\n                self.backup_plan = big.overload._cache.get(self.id, None)\n                #if self.id in overload._cache:\n                #    self.backup_plan =\n                self.configure_with(fn)\n            #wraps(fn)(self)\n\n        def __call__(self, *args, **kwargs):\n            #print(locals())\n            try:  # try running like normal\n                return self.fn(*args, **kwargs)\n            except Exception as ex:\n                if self.has_backup_plan:\n                    return self.backup_plan(*args, **kwargs) # run backup plan\n                elif self.configured:\n                    raise ex # no backup plan, abort\n                else:\n                    # complete unconfigured setup\n                    self.configure_with(*args, **kwargs)\n                    return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_attributes(klass_or_instance):\n    pairs = list()\n    for attr, value in inspect.getmembers(\n            klass_or_instance, lambda x: not inspect.isroutine(x)):\n        if not (attr.startswith(\"__\") or attr.endswith(\"__\")):\n            pairs.append((attr, value))\n    return pairs", "response": "Get all attributes of a class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getResults(self, parFound = None):\n        ''' \n            Function to obtain the Dictionarythat represents this object.\n            \n            :param parFound:    values to return.\n\n            :return:    The output format will be like:\n                [{\"type\" : \"i3visio.email\", \"value\": \"foo@bar.com\", \"attributes\": [] }, {\"type\" : \"i3visio.email\", \"value\": \"bar@foo.com\", \"attributes\": [] }]\n        '''\n        # Defining a dictionary\n        results = []\n        # Defining a dictionary inside with a couple of fields: reg_exp for the regular expression and found_exp for the expressions found.\n        #results[self.name] = {\"reg_exp\" : self.reg_exp, \"found_exp\" : parFound}\n        #results[self.name] = parFound\n        if len(parFound ) >0:\n            for found in parFound:\n                aux = {}\n                aux[\"type\"] = self.name\n                aux[\"value\"] = found\n                aux[\"attributes\"] = self.getAttributes(found)\n                results.append(aux)\n        return results", "response": "Function to obtain the Dictionary that represents this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_requirement_from_url(url):\n    link = Link(url)\n    egg_info = link.egg_fragment\n    if not egg_info:\n        egg_info = splitext(link.filename)[0]\n    return package_to_requirement(egg_info)", "response": "Get a requirement from the URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef package_to_requirement(package_name):\n    match = re.search(r'^(.*?)-(dev|\\d.*)', package_name)\n    if match:\n        name = match.group(1)\n        version = match.group(2)\n    else:\n        name = package_name\n        version = ''\n    if version:\n        return '%s==%s' % (name, version)\n    else:\n        return name", "response": "Translate a name like foo - 1. 2 to foo == 1. 3"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mirrors(hostname=None):\n    if hostname is None:\n        hostname = DEFAULT_MIRROR_URL\n\n    # return the last mirror registered on PyPI.\n    try:\n        hostname = socket.gethostbyname_ex(hostname)[0]\n    except socket.gaierror:\n        return []\n    end_letter = hostname.split(\".\", 1)\n\n    # determine the list from the last one.\n    return [\"%s.%s\" % (s, end_letter[1]) for s in string_range(end_letter[0])]", "response": "Return the list of mirrors from the last record found on the DNS\n    entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the range of string between a and last.", "response": "def string_range(last):\n    \"\"\"Compute the range of string between \"a\" and last.\n\n    This works for simple \"a to z\" lists, but also for \"a to zz\" lists.\n    \"\"\"\n    for k in range(len(last)):\n        for x in product(string.ascii_lowercase, repeat=k+1):\n            result = ''.join(x)\n            yield result\n            if result == last:\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _sort_locations(locations):\n        files = []\n        urls = []\n\n        # puts the url for the given file path into the appropriate\n        # list\n        def sort_path(path):\n            url = path_to_url2(path)\n            if mimetypes.guess_type(url, strict=False)[0] == 'text/html':\n                urls.append(url)\n            else:\n                files.append(url)\n\n        for url in locations:\n            if url.startswith('file:'):\n                path = url_to_path(url)\n                if os.path.isdir(path):\n                    path = os.path.realpath(path)\n                    for item in os.listdir(path):\n                        sort_path(os.path.join(path, item))\n                elif os.path.isfile(path):\n                    sort_path(path)\n            else:\n                urls.append(url)\n        return files, urls", "response": "Sort locations into files and urls and return a pair of lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_pages(self, locations, req):\n        pending_queue = Queue()\n        for location in locations:\n            pending_queue.put(location)\n        done = []\n        seen = set()\n        threads = []\n        for i in range(min(10, len(locations))):\n            t = threading.Thread(target=self._get_queued_page, args=(req, pending_queue, done, seen))\n            t.setDaemon(True)\n            threads.append(t)\n            t.start()\n        for t in threads:\n            t.join()\n        return done", "response": "Yields page_url for each location in locations skipping locations that have errors and adding download links."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _link_package_versions(self, link, search_name):\n        if link.egg_fragment:\n            egg_info = link.egg_fragment\n        else:\n            egg_info, ext = link.splitext()\n            if not ext:\n                if link not in self.logged_links:\n                    logger.debug('Skipping link %s; not a file' % link)\n                    self.logged_links.add(link)\n                return []\n            if egg_info.endswith('.tar'):\n                # Special double-extension case:\n                egg_info = egg_info[:-4]\n                ext = '.tar' + ext\n            if ext not in ('.tar.gz', '.tar.bz2', '.tar', '.tgz', '.zip'):\n                if link not in self.logged_links:\n                    logger.debug('Skipping link %s; unknown archive format: %s' % (link, ext))\n                    self.logged_links.add(link)\n                return []\n        version = self._egg_info_matches(egg_info, search_name, link)\n        if version is None:\n            logger.debug('Skipping link %s; wrong project name (not %s)' % (link, search_name))\n            return []\n        match = self._py_version_re.search(version)\n        if match:\n            version = version[:match.start()]\n            py_version = match.group(1)\n            if py_version != sys.version[:3]:\n                logger.debug('Skipping %s because Python version is incorrect' % link)\n                return []\n        logger.debug('Found link %s, version: %s' % (link, version))\n        return [(pkg_resources.parse_version(version),\n               link,\n               version)]", "response": "Returns an iterable of triples that can be extracted from the given link and python_version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a list of URLs from the main mirror DNS entry unless a list of mirror URLs are passed.", "response": "def _get_mirror_urls(self, mirrors=None, main_mirror_url=None):\n        \"\"\"Retrieves a list of URLs from the main mirror DNS entry\n        unless a list of mirror URLs are passed.\n        \"\"\"\n        if not mirrors:\n            mirrors = get_mirrors(main_mirror_url)\n            # Should this be made \"less random\"? E.g. netselect like?\n            random.shuffle(mirrors)\n\n        mirror_urls = set()\n        for mirror_url in mirrors:\n            # Make sure we have a valid URL\n            if not (\"http://\" or \"https://\" or \"file://\") in mirror_url:\n                mirror_url = \"http://%s\" % mirror_url\n            if not mirror_url.endswith(\"/simple\"):\n                mirror_url = \"%s/simple/\" % mirror_url\n            mirror_urls.add(mirror_url)\n\n        return list(mirror_urls)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_content_type(url):\n        scheme, netloc, path, query, fragment = urlparse.urlsplit(url)\n        if not scheme in ('http', 'https', 'ftp', 'ftps'):\n            ## FIXME: some warning or something?\n            ## assertion error?\n            return ''\n        req = Urllib2HeadRequest(url, headers={'Host': netloc})\n        resp = urlopen(req)\n        try:\n            if hasattr(resp, 'code') and resp.code != 200 and scheme not in ('ftp', 'ftps'):\n                ## FIXME: doesn't handle redirects\n                return ''\n            return resp.info().get('content-type', '')\n        finally:\n            resp.close()", "response": "Get the Content - Type of the given url using a HEAD request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef links(self):\n        for match in self._href_re.finditer(self.content):\n            url = match.group(1) or match.group(2) or match.group(3)\n            url = self.clean_link(urlparse.urljoin(self.base_url, url))\n            yield Link(url, self)", "response": "Yields all links in the page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef explicit_rel_links(self, rels=('homepage', 'download')):\n        for match in self._rel_re.finditer(self.content):\n            found_rels = match.group(1).lower().split()\n            for rel in rels:\n                if rel in found_rels:\n                    break\n            else:\n                continue\n            match = self._href_re.search(match.group(0))\n            if not match:\n                continue\n            url = match.group(1) or match.group(2) or match.group(3)\n            url = self.clean_link(urlparse.urljoin(self.base_url, url))\n            yield Link(url, self)", "response": "Yields all links with the given relations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect_outs(self):\n        # TODO: this should probably live in CacheManager.\n        for outfile in self.rule.output_files or []:\n            outfile_built = os.path.join(self.buildroot, outfile)\n            if not os.path.exists(outfile_built):\n                raise error.TargetBuildFailed(\n                    self.address, 'Output file is missing: %s' % outfile)\n\n        #git_sha = gitrepo.RepoState().GetRepo(self.address.repo).repo.commit()\n        # git_sha is insufficient, and is actually not all that useful.\n        # More factors to include in hash:\n        # - commit/state of source repo of all dependencies\n        #   (or all input files?)\n        #   - Actually I like that idea: hash all the input files!\n        # - versions of build tools used (?)\n        metahash = self._metahash()\n        log.debug('[%s]: Metahash: %s', self.address, metahash.hexdigest())\n        # TODO: record git repo state and buildoptions in cachemgr\n        # TODO: move cachemgr to outer controller(?)\n        self.cachemgr.putfile(outfile_built, self.buildroot, metahash)", "response": "Collect and store the outputs from this rule."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_cached(self):\n        # TODO: cache by target+hash, not per file.\n        try:\n            for item in self.rule.output_files:\n                log.info(item)\n                self.cachemgr.in_cache(item, self._metahash())\n        except cache.CacheMiss:\n            log.info('[%s]: Not cached.', self.address)\n            return False\n        else:\n            log.info('[%s]: found in cache.', self.address)\n            return True", "response": "Returns true if this rule is already cached."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_from_cache(self):\n        for item in self.rule.output_files:\n            dstpath = os.path.join(self.buildroot, item)\n            self.linkorcopy(\n                self.cachemgr.path_in_cache(item, self._metahash()),\n                dstpath)", "response": "See if this rule has already been built and cached."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef linkorcopy(self, src, dst):\n        if os.path.isdir(dst):\n            log.warn('linkorcopy given a directory as destination. '\n                     'Use caution.')\n            log.debug('src: %s  dst: %s', src, dst)\n        elif os.path.exists(dst):\n            os.unlink(dst)\n        elif not os.path.exists(os.path.dirname(dst)):\n            os.makedirs(os.path.dirname(dst))\n        if self.linkfiles:\n            log.debug('Linking: %s -> %s', src, dst)\n            os.link(src, dst)\n        else:\n            log.debug('Copying: %s -> %s', src, dst)\n            shutil.copy2(src, dst)", "response": "hardlink src file to dst if possible otherwise copy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the rule object for an address from our deps graph.", "response": "def rulefor(self, addr):\n        \"\"\"Return the rule object for an address from our deps graph.\"\"\"\n        return self.rule.subgraph.node[self.rule.makeaddress(addr)][\n            'target_obj']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of dependencies of this build target.", "response": "def composed_deps(self):\n        \"\"\"Dependencies of this build target.\"\"\"\n        if 'deps' in self.params:\n            param_deps = self.params['deps'] or []\n            deps = [self.makeaddress(dep) for dep in param_deps]\n            return deps\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns a label into an Address with current context.", "response": "def makeaddress(self, label):\n        \"\"\"Turn a label into an Address with current context.\n\n        Adds repo and path if given a label that only has a :target part.\n        \"\"\"\n        addr = address.new(label)\n        if not addr.repo:\n            addr.repo = self.address.repo\n            if not addr.path:\n                addr.path = self.address.path\n        return addr"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the allowed queryset for this sign or the default one.", "response": "def get_queryset(self):\n        \"\"\"Return the allowed queryset for this sign or the default one.\"\"\"\n        if 'sign' in self.request.query_params:\n            try:\n                filter_and_actions = unsign_filters_and_actions(\n                    self.request.query_params['sign'],\n                    '{}.{}'.format(\n                        self.queryset.model._meta.app_label,\n                        self.queryset.model._meta.model_name,\n                    )\n                )\n            except signing.BadSignature:\n                return super(SignedViewSetMixin, self).get_queryset()\n            else:\n                for filtered_action in filter_and_actions:\n                    try:\n                        qs = self.queryset.filter(**filtered_action['filters'])\n                    except FieldError:\n                        continue\n                    return qs\n        return super(SignedViewSetMixin, self).get_queryset()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a string to ASCII and remove spaces underscores and hyphens.", "response": "def slugify(value, allow_unicode=False):\n    \"\"\"\n    Convert to ASCII if 'allow_unicode' is False. Convert spaces to hyphens.\n    Remove characters that aren't alphanumerics, underscores, or hyphens.\n    Convert to lowercase. Also strip leading and trailing whitespace.\n    \"\"\"\n    value\n    if allow_unicode:\n        value = unicodedata.normalize('NFKC', value)\n    else:\n        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n\n    return re.sub(r'[-\\s]+', '-', value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_date(value):\n    if not is_valid_date(value):\n        return ('', '', '')\n\n    splited = value.split('-')\n\n    try:\n        year = splited[0]\n    except IndexError:\n        year = ''\n\n    try:\n        month = splited[1]\n    except IndexError:\n        month = ''\n\n    try:\n        day = splited[2]\n    except IndexError:\n        day = ''\n\n    return (year, month, day)", "response": "This method splits a date in a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef items(self):\n        return [(section, dict(self.conf.items(section, raw=True))) for \\\n            section in [section for section in self.conf.sections()]]", "response": "Returns a list of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse Jarsign to sign an apk target file using the provided keystore information.", "response": "def jarsign(storepass, keypass, keystore, source, alias, path=None):\n  \"\"\"\n  Uses Jarsign to sign an apk target file using the provided keystore information.\n\n  :param storepass(str) - keystore storepass\n  :param keypass(str) - keystore keypass\n  :param keystore(str) - keystore file path\n  :param source(str) - apk path\n  :param alias(str) - keystore alias\n  :param path(str) - basedir to run the command\n  \"\"\"\n  cmd = [\n    'jarsigner',\n    '-verbose',\n    '-storepass',\n    storepass,\n    '-keypass',\n    keypass,\n    '-keystore',\n    keystore,\n    source,\n    alias\n  ]\n  common.run_cmd(cmd, log='jarsign.log', cwd=path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing zipalign based on a provided build tool version.", "response": "def zipalign(source, dist, build_tool=None, version='4', path=None):\n  \"\"\"\n  Uses zipalign based on a provided build tool version (defaulit is 23.0.2).\n\n  :param source(str) - source apk file to be zipaligned\n  :param dist(str) - zipaligned apk file path to be created\n  :param build_tool(str) - build tool version to be used by zipalign (default is 23.0.2)\n  :param version(str) - zipalign version, default is 4\n  :param path(str) - basedir to run the command\n  \"\"\"\n  if build_tool is None:\n    build_tool = config.build_tool_version\n  android_home = os.environ.get('AG_MOBILE_SDK', os.environ.get('ANDROID_HOME'))\n  cmd_path = [\n    android_home,\n    '/build-tools',\n    '/%s' % build_tool,\n    '/zipalign'\n  ]\n  cmd = [\n    ''.join(cmd_path),\n    '-v',\n    version,\n    source,\n    dist,\n  ]\n  common.run_cmd(cmd, log='zipalign.log', cwd=path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default_keystore(prefix='AG_'):\n  path = os.environ.get('%s_KEYSTORE_PATH' % prefix, config.keystore.path)\n  storepass = os.environ.get('%s_KEYSTORE_STOREPASS' % prefix, config.keystore.storepass)\n  keypass = os.environ.get('%s_KEYSTORE_KEYPASS' % prefix, config.keystore.keypass)\n  alias = os.environ.get('%s_KEYSTORE_ALIAS' % prefix, config.keystore.alias)\n  return (path, storepass, keypass, alias)", "response": "Returns the default keystore information based on environment variables and a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the highest build tool version based on major version sdk version.", "response": "def get_highest_build_tool(sdk_version=None):\n  \"\"\"\n  Gets the highest build tool version based on major version sdk version.\n\n  :param sdk_version(int) - sdk version to be used as the marjor build tool version context.\n\n  Returns:\n    A string containg the build tool version (default is 23.0.2 if none is found)\n  \"\"\"\n  if sdk_version is None:\n    sdk_version = config.sdk_version\n  android_home = os.environ.get('AG_MOBILE_SDK', os.environ.get('ANDROID_HOME'))\n  build_tool_folder = '%s/build-tools' % android_home\n  folder_list = os.listdir(build_tool_folder)\n  versions = [folder for folder in folder_list if folder.startswith('%s.' % sdk_version)]\n  if len(versions) == 0:\n    return config.build_tool_version\n  return versions[::-1][0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename_file(self, instance, field_name):\n        file = getattr(instance, field_name)\n\n        if file:\n            new_name = get_hashed_filename(file.name, file)\n            if new_name != file.name:\n                print('    Renaming \"%s\" to \"%s\"' % (file.name, new_name))\n                file.save(os.path.basename(new_name), file, save=False)\n                return True\n\n        return False", "response": "Renames a file and updates the model field to point to the new file. Returns True if a change has been made ; otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a cusotom implementation of a served http resource.", "response": "def addServerResource(self, pluginSubPath: bytes, resource: BasicResource) -> None:\n        \"\"\" Add Server Resource\n\n        Add a cusotom implementation of a served http resource.\n\n        :param pluginSubPath: The resource path where you want to serve this resource.\n        :param resource: The resource to serve.\n        :return: None\n\n        \"\"\"\n        pluginSubPath = pluginSubPath.strip(b'/')\n        self.__rootServerResource.putChild(pluginSubPath, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the framework :param http_port: HTTP port to listen to :param peer_name: Name of the peer :param node_name: Name (also, UID) of the node hosting the peer :param app_id: Application ID", "response": "def main(http_port, peer_name, node_name, app_id):\n    \"\"\"\n    Runs the framework\n\n    :param http_port: HTTP port to listen to\n    :param peer_name: Name of the peer\n    :param node_name: Name (also, UID) of the node hosting the peer\n    :param app_id: Application ID\n    \"\"\"\n    # Create the framework\n    framework = pelix.framework.create_framework(\n        ('pelix.ipopo.core',\n         'pelix.ipopo.waiting',\n         'pelix.shell.core',\n         'pelix.shell.ipopo',\n         'pelix.shell.console',\n         'pelix.http.basic',\n\n         # Herald core\n         'herald.core',\n         'herald.directory',\n         'herald.shell',\n\n         # Herald HTTP\n         'herald.transports.http.directory',\n         'herald.transports.http.discovery_multicast',\n         'herald.transports.http.servlet',\n         'herald.transports.http.transport',\n\n         # RPC\n         'pelix.remote.dispatcher',\n         'pelix.remote.registry',\n         'herald.remote.discovery',\n         'herald.remote.herald_xmlrpc',),\n        {herald.FWPROP_NODE_UID: node_name,\n         herald.FWPROP_NODE_NAME: node_name,\n         herald.FWPROP_PEER_NAME: peer_name,\n         herald.FWPROP_APPLICATION_ID: app_id})\n\n    # Start everything\n    framework.start()\n    context = framework.get_bundle_context()\n\n    # Instantiate components\n    with use_waiting_list(context) as ipopo:\n        # ... HTTP server\n        ipopo.add(pelix.http.FACTORY_HTTP_BASIC, \"http-server\",\n                  {pelix.http.HTTP_SERVICE_PORT: http_port})\n\n        # ... HTTP reception servlet\n        ipopo.add(herald.transports.http.FACTORY_SERVLET,\n                  \"herald-http-servlet\")\n\n        # ... HTTP multicast discovery\n        ipopo.add(herald.transports.http.FACTORY_DISCOVERY_MULTICAST,\n                  \"herald-http-discovery-multicast\")\n\n    # Start the framework and wait for it to stop\n    framework.wait_for_stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the data to the underlying data stream.", "response": "def write(self, data: bytes) -> None:\n        \"\"\"\n        Write the data.\n        \"\"\"\n        if self.finished():\n            if self._exc:\n                raise self._exc\n\n            raise WriteAfterFinishedError\n\n        if not data:\n            return\n\n        try:\n            self._delegate.write_data(data, finished=False)\n\n        except BaseWriteException as e:\n            self._finished.set()\n            if self._exc is None:\n                self._exc = e\n\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflush the pending data to the internal buffer.", "response": "async def flush(self) -> None:\n        \"\"\"\n        Give the writer a chance to flush the pending data\n        out of the internal buffer.\n        \"\"\"\n        async with self._flush_lock:\n            if self.finished():\n                if self._exc:\n                    raise self._exc\n\n                return\n\n            try:\n                await self._delegate.flush_buf()\n\n            except asyncio.CancelledError:  # pragma: no cover\n                raise\n\n            except BaseWriteException as e:\n                self._finished.set()\n                if self._exc is None:\n                    self._exc = e\n\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreceives the RCON command response from the socket and return the header stripped out", "response": "def recvall(self, timeout=0.5):\n        \"\"\"\n        Receive the RCON command response\n        :param timeout: The timeout between consequent data receive\n        :return str: The RCON command response with header stripped out\n        \"\"\"\n        response = ''\n        self.socket.setblocking(False)\n        start = time.time()\n        while True:\n            if response and time.time() - start > timeout:\n                break\n            elif time.time() - start > timeout * 2:\n                break\n\n            try:\n                data = self.socket.recv(4096)\n                if data:\n                    response += data.replace(self._rconreplystring, '')\n                    start = time.time()\n                else:\n                    time.sleep(0.1)\n            except socket.error:\n                pass\n\n        return response.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a RCON command over the socket.", "response": "def send(self, data):\n        \"\"\"\n        Send a RCON command over the socket\n        :param data: The command to send\n        :raise RconError: When it's not possible to evaluate the command\n        :return str: The server response to the RCON command\n        \"\"\"\n        try:\n            if not data:\n                raise RconError('no command supplied')\n            with self.lock:\n                self.socket.send(self._rconsendstring.format(self.password, data))\n        except socket.error, e:\n            raise RconError(e.message, e)\n        else:\n            timeout = self._timeout\n            command = data.split(' ')[0]\n            if command in self._long_commands_timeout:\n                timeout = self._long_commands_timeout[command]\n            return self.recvall(timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a class into its python path.", "response": "def klass_to_pypath(klass):\n    \"\"\"when a class is defined within the module that is being executed as\n    main, the module name will be specified as '__main__' even though the\n    module actually had its own real name.  This ends up being very confusing\n    to Configman as it tries to refer to a class by its proper module name.\n    This function will convert a class into its properly qualified actual\n    pathname.  This method is used when a Socorro app is actually invoked\n    directly through the file in which the App class is defined.  This allows\n    configman to reimport the class under its proper name and treat it as if\n    it had been run through the SocorroWelcomeApp.  In turn, this allows\n    the application defaults to be fetched from the properly imported class\n    in time for configman use that information as value source.\"\"\"\n    if klass.__module__ == '__main__':\n        module_path = (\n            sys.modules['__main__']\n            .__file__[:-3]\n        )\n        module_name = ''\n        for a_python_path in sys.path:\n            tentative_pathname = module_path.replace(a_python_path, '')\n            if tentative_pathname != module_path:\n                module_name = (\n                    tentative_pathname.replace('/', '.').strip('.')\n                )\n                break\n        if module_name == '':\n            return py_obj_to_str(klass)\n    else:\n        module_name = klass.__module__\n    return \"%s.%s\" % (module_name, klass.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a build target string and return a dict of the build target and the build target and the build target.", "response": "def __parse_target(targetstr, current_repo=None):\n        \"\"\"Parse a build target string.\n\n        General form: //repo[gitref]/dir/path:target.\n\n        These are all valid:\n          //repo\n          //repo[a038fi31d9e8bc11582ef1b1b1982d8fc]\n          //repo[a039aa30853298]:foo\n          //repo/dir\n          //repo[a037928734]/dir\n          //repo/dir/path\n          //repo/dir/path:foo\n          :foo\n          dir/path\n          dir/path:foo\n          dir:foo\n\n        Returns: {'repo': '//reponame',\n                  'git_ref': 'a839a38fd...',\n                  'path': 'dir/path',\n                  'target': 'targetname}\n        \"\"\"\n        # 'blah' -> ':blah'\n        if not (':' in targetstr or '/' in targetstr):\n            targetstr = ':%s' % targetstr\n\n        match = re.match(\n            r'^(?://(?P<repo>[\\w-]+)(?:\\[(?P<git_ref>.*)\\])?)?'\n            r'(?:$|/?(?P<path>[\\w/-]+)?(?::?(?P<target>[\\w-]+)?))', targetstr)\n        try:\n            groups = match.groupdict()\n            if not groups['repo']:\n                groups['repo'] = current_repo\n            if not groups['git_ref']:\n                groups['git_ref'] = 'develop'\n            if not groups['target']:\n                groups['target'] = 'all'\n            if not groups['path']:\n                groups['path'] = ''\n        except AttributeError:\n            raise error.ButcherError('\"%s\" is not a valid build target.')\n        #log.debug('parse_target: %s -> %s', targetstr, groups)\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an authenticated Yahoo requests. Session object.", "response": "def authenticated_session(username, password):\n    \"\"\"\n    Given username and password, return an authenticated Yahoo `requests`\n    session that can be used for further scraping requests.\n\n    Throw an AuthencationError if authentication fails.\n    \"\"\"\n    session = requests.Session()\n    session.headers.update(headers())\n\n    response = session.get(url())\n    login_path = path(response.text)\n    login_url = urljoin(response.url, login_path)\n    login_post_data = post_data(response.text, username, password)\n\n    response = session.post(login_url, data=login_post_data)\n    if response.headers['connection'] == 'close':\n        raise Exception('Authencation failed')\n\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_data(page, username, password):\n    soup = BeautifulSoup(page)\n    try:\n        inputs = soup.find(id='hiddens').findAll('input')\n        post_data = {input['name']: input['value'] for input in inputs}\n        post_data['username'] = username\n        post_data['passwd'] = password\n        return post_data\n    except:\n        return None", "response": "Given username and password return the post data necessary for login\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_signed_raw(cls: Type[CertificationType], signed_raw: str) -> CertificationType:\n        n = 0\n        lines = signed_raw.splitlines(True)\n\n        version = int(Identity.parse_field(\"Version\", lines[n]))\n        n += 1\n\n        Certification.parse_field(\"Type\", lines[n])\n        n += 1\n\n        currency = Certification.parse_field(\"Currency\", lines[n])\n        n += 1\n\n        pubkey_from = Certification.parse_field(\"Issuer\", lines[n])\n        n += 1\n\n        identity_pubkey = Certification.parse_field(\"IdtyIssuer\", lines[n])\n        n += 1\n\n        identity_uid = Certification.parse_field(\"IdtyUniqueID\", lines[n])\n        n += 1\n\n        identity_timestamp = BlockUID.from_str(Certification.parse_field(\"IdtyTimestamp\", lines[n]))\n        n += 1\n\n        identity_signature = Certification.parse_field(\"IdtySignature\", lines[n])\n        n += 1\n\n        timestamp = BlockUID.from_str(Certification.parse_field(\"CertTimestamp\", lines[n]))\n        n += 1\n\n        signature = Certification.parse_field(\"Signature\", lines[n])\n\n        identity = Identity(version, currency, identity_pubkey, identity_uid, identity_timestamp, identity_signature)\n\n        return cls(version, currency, pubkey_from, identity, timestamp, signature)", "response": "Return a Certification instance from a signed raw document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_inline(cls: Type[CertificationType], version: int, currency: str, blockhash: Optional[str],\n                    inline: str) -> CertificationType:\n        \"\"\"\n        Return Certification instance from inline document\n\n        Only self.pubkey_to is populated.\n        You must populate self.identity with an Identity instance to use raw/sign/signed_raw methods\n\n        :param version: Version of document\n        :param currency: Name of the currency\n        :param blockhash: Hash of the block\n        :param inline: Inline document\n        :return:\n        \"\"\"\n        cert_data = Certification.re_inline.match(inline)\n        if cert_data is None:\n            raise MalformedDocumentError(\"Certification ({0})\".format(inline))\n        pubkey_from = cert_data.group(1)\n        pubkey_to = cert_data.group(2)\n        blockid = int(cert_data.group(3))\n        if blockid == 0 or blockhash is None:\n            timestamp = BlockUID.empty()\n        else:\n            timestamp = BlockUID(blockid, blockhash)\n\n        signature = cert_data.group(4)\n        return cls(version, currency, pubkey_from, pubkey_to, timestamp, signature)", "response": "Return a Certification instance from an inline document."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a raw document of the certification", "response": "def raw(self) -> str:\n        \"\"\"\n        Return a raw document of the certification\n        \"\"\"\n        if not isinstance(self.identity, Identity):\n            raise MalformedDocumentError(\"Can not return full certification document created from inline\")\n\n        return \"\"\"Version: {version}\nType: Certification\nCurrency: {currency}\nIssuer: {issuer}\nIdtyIssuer: {certified_pubkey}\nIdtyUniqueID: {certified_uid}\nIdtyTimestamp: {certified_ts}\nIdtySignature: {certified_signature}\nCertTimestamp: {timestamp}\n\"\"\".format(version=self.version,\n           currency=self.currency,\n           issuer=self.pubkey_from,\n           certified_pubkey=self.identity.pubkey,\n           certified_uid=self.identity.uid,\n           certified_ts=self.identity.timestamp,\n           certified_signature=self.identity.signatures[0],\n           timestamp=self.timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn inline document string", "response": "def inline(self) -> str:\n        \"\"\"\n        Return inline document string\n\n        :return:\n        \"\"\"\n        return \"{0}:{1}:{2}:{3}\".format(self.pubkey_from, self.pubkey_to,\n                                        self.timestamp.number, self.signatures[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef command(execute=None):  # noqa: E501\n    if connexion.request.is_json:\n        execute = Execute.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'", "response": "Execute a Command\n\n    Execute a command # noqa: E501\n\n    :param execute: The data needed to execute this command\n    :type execute: dict | bytes\n\n    :rtype: Response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef endpoint_catalog(catalog=None):  # noqa: E501\n    if connexion.request.is_json:\n        catalog = UserAuth.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'", "response": "Retrieve the endpoint catalog"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef queryset_iterator(queryset, chunksize=1000):\n    '''''\n    Iterate over a Django Queryset ordered by the primary key\n\n    This method loads a maximum of chunksize (default: 1000) rows in it's\n    memory at the same time while django normally would load all rows in it's\n    memory. Using the iterator() method only causes it to not preload all the\n    classes.\n\n    Note that the implementation of the iterator does not support ordered query sets.\n\n    Link: https://djangosnippets.org/snippets/1949/\n    '''\n\n    pk = 0\n\n    last_pk = queryset.order_by('-pk').values_list('pk', flat=True).first()\n    if last_pk is not None:\n        queryset = queryset.order_by('pk')\n        while pk < last_pk:\n            for row in queryset.filter(pk__gt=pk)[:chunksize]:\n                pk = row.pk\n                yield row\n            gc.collect()", "response": "Iterator over a Django Queryset ordered by the primary key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a directory from the FtpRmTree.", "response": "def remove_dir(self, destination_path):\n        \"\"\"\n        Remove folder. Based on https://gist.github.com/artlogic/2632647.\n        \"\"\"\n\n        wd = self.conn.pwd()\n\n        try:\n            names = self.conn.nlst(destination_path)\n        except ftplib.all_errors as e:\n            # some FTP servers complain when you try and list non-existent paths\n            logger.debug('FtpRmTree: Could not remove {0}: {1}'.format(\n                destination_path, e))\n            return\n\n        for name in names:\n            if os.path.split(name)[1] in ('.', '..'):\n                continue\n\n            try:\n                self.conn.cwd(name)  # if we can cwd to it, it's a folder\n                self.conn.cwd(wd)  # don't try a nuke a folder we're in\n                self.remove_dir(name)\n            except ftplib.all_errors:\n                self.conn.delete(name)\n\n        try:\n            self.conn.rmd(destination_path)\n        except ftplib.all_errors as e:\n            logger.debug('remove_dir: Could not remove {0}: {1}'.format(\n                destination_path, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the corect Response object based on the API command type.", "response": "def _handle_response(response, command, id_xpath='./id', **kwargs):\n    \"\"\" Initialize the corect Response object from the response string based on the API command type. \"\"\"\n    _response_switch = {\n        'insert': ModifyResponse,\n        'replace': ModifyResponse,\n        'partial-replace': ModifyResponse,\n        'update': ModifyResponse,\n        'delete': ModifyResponse,\n        'search-delete': SearchDeleteResponse,\n        'reindex': Response,\n        'backup': Response,\n        'restore': Response,\n        'clear': Response,\n        'status': StatusResponse,\n        'search': SearchResponse,\n        'retrieve': ListResponse,\n        'similar': ListResponse,\n        'lookup': LookupResponse,\n        'alternatives': AlternativesResponse,\n        'list-words': WordsResponse,\n        'list-first': ListResponse,\n        'list-last': ListResponse,\n        'retrieve-last': ListResponse,\n        'retrieve-first': ListResponse,\n        'show-history': None,\n        'list-paths': ListPathsResponse,\n        'list-facets': ListFacetsResponse}\n    try:\n        request_class = _response_switch[command]\n    except KeyError:\n        request_class = Response\n    return request_class(response, id_xpath, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the response tag and raise APIError or APIWarning for nonfatal errors.", "response": "def _parse_for_errors(self):\n        \"\"\" Look for an error tag and raise APIError for fatal errors or APIWarning for nonfatal ones. \"\"\"\n        error = self._response.find('{www.clusterpoint.com}error')\n        if error is not None:\n            if error.find('level').text.lower() in ('rejected', 'failed', 'error', 'fatal'):\n                raise APIError(error)\n            else:\n                warnings.warn(APIWarning(error))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_content_string(self):\n        return ''.join([ET.tostring(element, encoding=\"utf-8\", method=\"xml\")\n                        for element in list(self._content)])", "response": "Ge thet Clusterpoint response s content as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the contents of a specific subtag from Clusterpoint Storage s response s content tag.", "response": "def get_content_field(self, name):\n        \"\"\" Get the contents of a specific subtag from Clusterpoint Storage's response's content tag.\n\n            Args:\n                name -- A name string of the content's subtag to be returned.\n\n            Returns:\n                A dict representing the contents of the specified field or a list of dicts\n                if there are multiple fields with that tag name. Returns None if no field found.\n        \"\"\"\n        fields = self._content.findall(name)\n        if not fields:\n            return None\n        elif len(fields) == 1:\n            return etree_to_dict(fields[0])[name]\n        else:\n            return [etree_to_dict(field)[name] for field in fields]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of documents in the Storege XML document.", "response": "def get_documents(self, doc_format='dict'):\n        \"\"\" Get the documents returned from Storege in this response.\n\n            Keyword args:\n                doc_format -- Specifies the doc_format for the returned documents.\n                    Can be 'dict', 'etree' or 'string'. Default is 'dict'.\n\n            Returns:\n                A dict where keys are document ids and values depending of the required doc_format:\n                    A dict representations of documents (see etree_to_dict());\n                    A etree Element representing the document;\n                    A raw XML document string.\n\n            Raises:\n                ParameterError -- The doc_format value is not allowed.\n        \"\"\"\n        def get_doc_id(root, rel_path):\n            if not rel_path:\n                return root.text\n            else:\n                child = root.find(rel_path[0])\n                if child is None:\n                    return None\n                return get_doc_id(child, rel_path[1:])\n\n        if doc_format == 'dict':\n            return dict([(get_doc_id(document, self._id_xpath), etree_to_dict(document)['document']) for\n                        document in self._get_doc_list()])\n        elif doc_format == 'etree':\n            return dict([(get_doc_id(document, self._id_xpath), document) for\n                        document in self._get_doc_list()])\n        elif doc_format == 'list-etree':\n            return self._get_doc_list()\n        elif doc_format == 'list-string':\n            return list([(ET.tostring(document)) for\n                        document in self._get_doc_list()])\n        elif doc_format in ('', None, 'string'):\n            return dict([(get_doc_id(document, self._id_xpath), ET.tostring(document)) for\n                        document in self._get_doc_list()])\n        else:\n            raise ParameterError(\"doc_format=\" + doc_format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting aggregate data. Returns : A dict in with queries as keys and results as values.", "response": "def get_aggregate(self):\n        \"\"\" Get aggregate data.\n\n            Returns:\n                A dict in with queries as keys and results as values.\n        \"\"\"\n        return dict([(aggregate.find('query').text, [(ET.tostring(data).lstrip('<data xmlns:cps=\"www.clusterpoint.com\" xmlns:cpse=\"www.clusterpoint.com\">').strip().rstrip(\"</data>\")) for data in aggregate.findall('data')])\n                   for aggregate in self._content.findall('aggregate')])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_words(self):\n        return dict([(word_list.attrib['to'], dict([(word.text, word.attrib['count'])\n                                                    for word in word_list.findall('word')]))\n                     for word_list in self._content.findall('list')])", "response": "Get words matching the request search terms.\n            Returns a dict in form of tuples where the key is the ID of the item that was found in the Storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_alternatives(self):\n        return dict([(alternatives.find('to').text,\n                      {'count': int(alternatives.find('count').text),\n                       'words': dict([(word.text, word.attrib)\n                                      for word in alternatives.findall('word')])})\n                     for alternatives in\n                     self._content.find('alternatives_list').findall('alternatives')])", "response": "Get the spelling alternatives for search terms."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting facets from the response.", "response": "def get_facets(self):\n        \"\"\" Get facets from the response.\n\n            Returns:\n                A dict where requested facet paths are keys and a list of coresponding terms are values.\n        \"\"\"\n        return dict([(facet.attrib['path'], [term.text\n                                             for term in facet.findall('term')])\n                     for facet in self._content.findall('facet')])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a JSON result after an HTTP Request.", "response": "def _process_response(self):\n        \"\"\"Return a JSON result after an HTTP Request.\n\n        Process the response of an HTTP Request and make it a JSON error if\n        it failed. Otherwise return the response's content.\n\n        \"\"\"\n        response = self.conn.getresponse()\n        if response.status == 200 or response.status == 201:\n            data = response.read()\n        else:\n            data = {\n                \"error\":  {\n                    \"code\": response.status,\n                    \"reason\": response.reason,\n                    \"data\": response.read()\n                }\n            }\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a HTTP POST request to a URL and return the result.", "response": "def post(self, url, data):\n        \"\"\"Send a HTTP POST request to a URL and return the result.\n        \"\"\"\n        headers = {\n            \"Content-type\": \"application/x-www-form-urlencoded\",\n            \"Accept\": \"text/json\"\n        }\n        self.conn.request(\"POST\", url, data, headers)\n        return self._process_response()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an HTTP PUT request to a URL and return the result.", "response": "def put(self, url, data=None):\n        \"\"\"Send a HTTP PUT request to a URL and return the result.\n        \"\"\"\n        self.conn.request(\"PUT\", url, data)\n        return self._process_response()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef number_of_issues_by_year(self, issn, collection, years=0, type=None):\n\n        body = {\n            \"query\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"match\": {\n                                \"issn\": issn\n                            }\n                        },\n                        {\n                            \"match\": {\n                                \"collection\": collection\n                            }\n                        }\n                    ]\n                }\n            },\n            \"aggs\": {\n                \"issue\": {\n                    \"cardinality\": {\n                        \"field\": \"issue\"\n                    }\n                }\n            }\n\n        }\n\n        if type:\n            body['query']['bool']['must'].append({\"match\": {\"issue_type\": type}})\n\n        if years != 0:\n            body['aggs'] = {\n                \"publication_year\": {\n                    \"terms\": {\n                        \"field\": \"publication_year\",\n                        \"size\": years,\n                        \"order\": {\n                            \"_term\": 'desc'\n                        }\n                    },\n                    \"aggs\": {\n                        \"issue\": {\n                            \"cardinality\": {\n                                \"field\": \"issue\"\n                            }\n                        }\n                    }\n                }\n            }\n\n        query_parameters = [\n            ('size', '0')\n        ]\n\n        query_result = self.search(\n            'article', json.dumps(body), query_parameters\n        )\n\n        return self._compute_number_of_issues_by_year(\n            query_result, years=years)", "response": "Returns the number of issues in a given year."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _must_not_custom_query(issn):\n\n        custom_queries = set([utils.cleanup_string(i) for i in journal_titles.load(issn).get('must_not', [])])\n\n        for item in custom_queries:\n\n            query = {\n                \"match\": {\n                    \"reference_source_cleaned\": item\n                }\n            }\n\n            yield query", "response": "A generator that returns a query for the must_not field."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fuzzy_custom_query(issn, titles):\n        custom_queries = journal_titles.load(issn).get('should', [])\n        titles = [{'title': i} for i in titles if i not in [x['title'] for x in custom_queries]]\n        titles.extend(custom_queries)\n\n        for item in titles:\n\n            if len(item['title'].strip()) == 0:\n                continue\n\n            query = {\n                \"fuzzy\": {\n                    \"reference_source_cleaned\": {\n                        \"value\": utils.cleanup_string(item['title']),\n                        \"fuzziness\": item.get('fuzziness', 3),\n                        \"max_expansions\": 50\n                    }\n                }\n            }\n\n            yield query", "response": "A generator that yields a query that matches the given subject."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nginx_web_ssl_config(self):\n\n        dt = [self.nginx_web_dir, self.nginx_ssl_dir]\n        return nginx_conf_string.simple_ssl_web_conf.format(dt=dt)", "response": "Nginx web ssl config"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isValidExp(self, exp):\n        '''     \n            Method to verify if a given expression is correct just in case the used regular expression needs additional processing to verify this fact.$\n            This method will be overwritten when necessary.\n\n            :param exp:     Expression to verify.\n\n            :return:        True | False\n        '''\n        # order of the letters depending on which is the mod of the number\n        #         0    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16   17   18   19   20   21   22   23\n        order = ['T', 'R', 'W', 'A', 'G', 'M', 'Y', 'F', 'P', 'D', 'X', 'B', 'N', 'J', 'Z', 'S', 'Q', 'V', 'H', 'L', 'C', 'K', 'E', 'T']\n\n        #print exp\n        l = exp[len(exp)-1]\n\n        try:\n            # verifying if it is an 8-length number\n            number = int(exp[0:7])\n        except:\n            try:\n                # verifying if it is a 7-length number\n                number = int(exp[0:6])\n            except:\n                # not a  valid number\n                pass\n        if l == order[number%23]:\n                    return True\n        else:\n            return False", "response": "Method to verify if a given regular expression is correct just in case the used regular expression needs additional processing to verify this fact."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the feature list product spec against.", "response": "def is_valid(self):\n        \"\"\"\n        Checks the feature list product spec against.\n        Checks if all mandartory features are contained;\n        Checks that all \"never\" features are not contained\n        :return: boolean\n        \"\"\"\n        for spec in self.product_specs:\n\n            for feature in spec.get('mandatory', []):\n                if feature.replace('__', '.') not in self.feature_list:\n                    self.errors_mandatory.append(feature)\n\n            for feature in spec.get('never', []):\n                if feature.replace('__', '.') in self.feature_list:\n                    self.errors_never.append(feature)\n\n        return not self.has_errors()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read(self, spec_path, product_name):\n        matches = []\n        with codecs.open(spec_path, 'r') as f:\n            for entry in json.loads(f.read()):\n                if product_name in entry.get('products'):\n                    matches.append(entry)\n        return matches", "response": "Reads the spec files and extracts the concrete product spec."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connectivity_map(dset,prefix,x,y,z,radius=2):\n    '''Will perform connectivity analysis on ``dset`` using seed point ``(x,y,z)`` (in RAI order) with a sphere of radius ``radius``.\n    Does not perform any preprocessing of ``dset``. This should be already motion corrected, noise-regressed, residualized, etc.'''\n    seed_series = nl.sphere_average(dset,x,y,z,radius)\n    with tempfile.NamedTemporaryFile(delete=False) as temp:\n        temp.write('\\n'.join([str(x) for x in seed_series]))\n    decon = nl.Decon()\n    decon.input_dsets = dset\n    decon.stim_files = {'seed':temp.name}\n    decon.prefix = prefix\n    decon.run()\n    try:\n        os.remove(temp.name)\n    except:\n        pass", "response": "This function will perform connectivity analysis on a set of data points using a seed point x y z and radius."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef return_real_id_base(dbpath, set_object):\n    engine = create_engine('sqlite:////' + dbpath)\n    session_cl = sessionmaker(bind=engine)\n    session = session_cl()\n    return_list = []\n    for i in session.query(set_object).order_by(set_object.id):\n        return_list.append(i.real_id)\n    session.close()\n    return return_list", "response": "Generic function which returns a list of real_id values for the dataset"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef return_feature_list_base(dbpath, set_object):\n    engine = create_engine('sqlite:////' + dbpath)\n    session_cl = sessionmaker(bind=engine)\n    session = session_cl()\n    return_list = []\n    tmp_object = session.query(set_object).get(1)\n    for feature in tmp_object.features:\n        return_list.append(feature)\n    session.close()\n    return return_list", "response": "Generic function which returns a list of the names of all available features"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies features from one database to another.", "response": "def copy_features_base(dbpath_origin, dbpath_destination, set_object, force_copy=False):\n    \"\"\"\n    Generic function which copies features from one database to another (base object should be of the same type)\n\n    Parameters\n    ----------\n    dbpath_origin : string, path to SQLite database file from which the features will be copied\n    dbpath_destination : string, path to SQLite database file to which the features will be copied\n    set_object : object (either TestSet or TrainSet) which is stored in the database\n    force_copy : boolean, if True - will overwrite features with same name when copying, if False, won't;\n    default value: False\n\n    Returns\n    -------\n    None\n    \"\"\"\n    engine_origin = create_engine('sqlite:////' + dbpath_origin)\n    engine_destination = create_engine('sqlite:////' + dbpath_destination)\n    session_cl_origin = sessionmaker(bind=engine_origin)\n    session_cl_destination = sessionmaker(bind=engine_destination)\n    session_origin = session_cl_origin()\n    session_destination = session_cl_destination()\n    if force_copy is True:\n        for i in session_origin.query(set_object).order_by(set_object.id):\n            dest_obj = session_destination.query(set_object).get(i.id)\n            for feature in i.features:\n                if dest_obj.features is not None:\n                    dest_obj.features[feature] = i.features[feature]\n                else:\n                    dest_obj.features = {feature: i.features[feature]}\n    else:\n        for i in session_origin.query(set_object).order_by(set_object.id):\n            dest_obj = session_destination.query(set_object).get(i.id)\n            for feature in i.features:\n                if dest_obj.features is not None:\n                    if (feature not in dest_obj.features) or force_copy is True:\n                        dest_obj.features[feature] = i.features[feature]\n                else:\n                    dest_obj.features = {feature: i.features[feature]}\n    session_origin.close()\n    session_destination.commit()\n    session_destination.close()\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef return_single_real_id_base(dbpath, set_object, object_id):\n    engine = create_engine('sqlite:////' + dbpath)\n    session_cl = sessionmaker(bind=engine)\n    session = session_cl()\n    tmp_object = session.query(set_object).get(object_id)\n    session.close()\n    return tmp_object.real_id", "response": "Generic function which returns a real_id string of an object specified by object_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef return_single_convert_numpy_base(dbpath, folder_path, set_object, object_id, converter, add_args=None):\n    engine = create_engine('sqlite:////' + dbpath)\n    session_cl = sessionmaker(bind=engine)\n    session = session_cl()\n    tmp_object = session.query(set_object).get(object_id)\n    session.close()\n    if add_args is None:\n        return converter(join(folder_path, tmp_object.path))\n    else:\n        return converter(join(folder_path, tmp_object.path), add_args)", "response": "Generic function which converts an object specified by the object_id into a numpy array and returns the array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a database file and writes each data point s path real_id into it.", "response": "def prepopulate(self):\n        \"\"\"\n        Creates a database file (if it doesn't exist, writes each data point's path, real_id into it)\n\n        Parameters\n        ----------\n        self\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self._prepopulated is False:\n            engine = create_engine('sqlite:////' + self.dbpath)\n            self._db_base.metadata.create_all(engine)\n            self._prepopulated = True\n            session_cl = sessionmaker(bind=engine)\n            session = session_cl()\n\n            for (dirpath, dirnames, filenames) in walk(self.path_to_set):\n                for f_name in filenames:\n                    datapoint = self._set_object(real_id=cutoff_filename(self.file_prefix, self.file_suffix, f_name),\n                                                 path=f_name, features=None)\n                    session.add(datapoint)\n                    self.points_amt += 1\n            session.commit()\n            session.close()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_feature(self, extractor, force_extraction=False, verbose=0, add_args=None, custom_name=None):\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            return extract_feature_base(self.dbpath, self.path_to_set, self._set_object, extractor, force_extraction,\n                                        verbose, add_args, custom_name)", "response": "Extracts a feature from the database and stores it in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting a feature which may be dependent on other features and stores it in the database.", "response": "def extract_feature_dependent_feature(self, extractor, force_extraction=False, verbose=0, add_args=None,\n                                          custom_name=None):\n        \"\"\"\n        Extracts a feature which may be dependent on other features and stores it in the database\n\n        Parameters\n        ----------\n        extractor : function, which takes the path of a data point, a dictionary of all other features and *args as\n        parameters and returns a feature\n        force_extraction : boolean, if True - will re-extract feature even if a feature with this name already\n        exists in the database, otherwise, will only extract if the feature doesn't exist in the database.\n        default value: False\n        verbose : int, if bigger than 0, will print the current number of the file for which data is being extracted\n        add_args : optional arguments for the extractor (list/dictionary/tuple/whatever). if None, the\n        extractor should take only one input argument - the file path. default value: None\n        custom_name : string, optional name for the feature (it will be stored in the database with the custom_name\n        instead of extractor function name). if None, the extractor function name will be used. default value: None\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            return extract_feature_dependent_feature_base(self.dbpath, self.path_to_set, self._set_object, extractor,\n                                                          force_extraction, verbose, add_args, custom_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef return_features(self, names='all'):\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            return return_features_base(self.dbpath, self._set_object, names)", "response": "Returns a list of extracted features from the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef return_features_numpy(self, names='all'):\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            return return_features_numpy_base(self.dbpath, self._set_object, self.points_amt, names)", "response": "Returns a 2d numpy array of extracted features for a single datapoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of real_id values for the dataset.", "response": "def return_real_id(self):\n        \"\"\"\n        Returns a list of real_id's\n\n        Parameters\n        ----------\n\n        Returns\n        -------\n        A list of real_id values for the dataset (a real_id is the filename minus the suffix and prefix)\n        \"\"\"\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            return return_real_id_base(self.dbpath, self._set_object)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_features(self, dbpath_origin, force_copy=False):\n        copy_features_base(dbpath_origin, self.dbpath, self._set_object, force_copy)\n        return None", "response": "Copies features from one database to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an object specified by the object_id into a numpy array and returns the array, the conversion is done by the 'converter' function Parameters ---------- object_id : int, id of object in database converter : function, which takes the path of a data point and *args as parameters and returns a numpy array add_args : optional arguments for the converter (list/dictionary/tuple/whatever). if None, the converter should take only one input argument - the file path. default value: None Returns ------- result : ndarray", "response": "def return_single_convert_numpy(self, object_id, converter, add_args=None):\n        \"\"\"\n        Converts an object specified by the object_id into a numpy array and returns the array,\n        the conversion is done by the 'converter' function\n\n        Parameters\n        ----------\n        object_id : int, id of object in database\n        converter : function, which takes the path of a data point and *args as parameters and returns a numpy array\n        add_args : optional arguments for the converter (list/dictionary/tuple/whatever). if None, the\n        converter should take only one input argument - the file path. default value: None\n\n        Returns\n        -------\n        result : ndarray\n        \"\"\"\n        return return_single_convert_numpy_base(self.dbpath, self.path_to_set, self._set_object, object_id, converter,\n                                                add_args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting several objects, with ids in the range (start_id, end_id) into a 2d numpy array and returns the array, the conversion is done by the 'converter' function Parameters ---------- start_id : the id of the first object to be converted end_id : the id of the last object to be converted, if equal to -1, will convert all data points in range (start_id, <id of last element in database>) converter : function, which takes the path of a data point and *args as parameters and returns a numpy array add_args : optional arguments for the converter (list/dictionary/tuple/whatever). if None, the converter should take only one input argument - the file path. default value: None Returns ------- result : 2-dimensional ndarray", "response": "def return_multiple_convert_numpy(self, start_id, end_id, converter, add_args=None):\n        \"\"\"\n        Converts several objects, with ids in the range (start_id, end_id)\n        into a 2d numpy array and returns the array, the conversion is done by the 'converter' function\n\n        Parameters\n        ----------\n        start_id : the id of the first object to be converted\n        end_id : the id of the last object to be converted, if equal to -1, will convert all data points in range\n        (start_id, <id of last element in database>)\n        converter : function, which takes the path of a data point and *args as parameters and returns a numpy array\n        add_args : optional arguments for the converter (list/dictionary/tuple/whatever). if None, the\n        converter should take only one input argument - the file path. default value: None\n\n        Returns\n        -------\n        result : 2-dimensional ndarray\n        \"\"\"\n        if end_id == -1:\n            end_id = self.points_amt\n        return return_multiple_convert_numpy_base(self.dbpath, self.path_to_set, self._set_object, start_id, end_id,\n                                                  converter, add_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a list of lists or ndarray of features into the database.", "response": "def dump_feature(self, feature_name, feature, force_extraction=True):\n        \"\"\"\n        Dumps a list of lists or ndarray of features into database (allows to\n        copy features from a pre-existing .txt/.csv/.whatever file, for example)\n\n        Parameters\n        ----------\n        feature : list of lists or ndarray, contains the data to be written to the database\n        force_extraction : boolean, if True - will overwrite any existing feature with this name\n        default value: False\n\n        Returns\n        -------\n        None\n        \"\"\"\n        dump_feature_base(self.dbpath, self._set_object, self.points_amt, feature_name, feature, force_extraction)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the labels of the dataset", "response": "def return_labels(self, original=False):\n        \"\"\"\n        Returns the labels of the dataset\n\n        Parameters\n        ----------\n        original : if True, will return original labels, if False, will return transformed labels (as defined by\n        label_dict), default value: False\n\n        Returns\n        -------\n        A list of lists, each 'inside list' corresponds to a single data point, each element of the 'inside list' is a\n        label\n        \"\"\"\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            engine = create_engine('sqlite:////' + self.dbpath)\n            trainset.Base.metadata.create_all(engine)\n            session_cl = sessionmaker(bind=engine)\n            session = session_cl()\n            return_list = []\n            for i in session.query(trainset.TrainSet).order_by(trainset.TrainSet.id):\n                if original is True:\n                    row_list = i.labels['original']\n                else:\n                    row_list = i.labels['transformed']\n                return_list.append(row_list[:])\n            session.close()\n            return return_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a 2d numpy array of labels corresponding to a single datapoint", "response": "def return_labels_numpy(self, original=False):\n        \"\"\"\n        Returns a 2d numpy array of labels\n\n        Parameters\n        ----------\n        original : if True, will return original labels, if False, will return transformed labels (as defined by\n        label_dict), default value: False\n\n        Returns\n        -------\n        A numpy array of labels, each row corresponds to a single datapoint\n        \"\"\"\n        if self._prepopulated is False:\n            raise errors.EmptyDatabase(self.dbpath)\n        else:\n            engine = create_engine('sqlite:////' + self.dbpath)\n            trainset.Base.metadata.create_all(engine)\n            session_cl = sessionmaker(bind=engine)\n            session = session_cl()\n            tmp_object = session.query(trainset.TrainSet).get(1)\n\n            columns_amt = len(tmp_object.labels['original'])\n            return_array = np.zeros([self.points_amt, columns_amt])\n            for i in enumerate(session.query(trainset.TrainSet).order_by(trainset.TrainSet.id)):\n                if original is False:\n                    return_array[i[0], :] = i[1].labels['transformed']\n                else:\n                    return_array[i[0], :] = i[1].labels['original']\n            session.close()\n            return return_array"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef return_single_labels(self, object_id):\n        engine = create_engine('sqlite:////' + self.dbpath)\n        trainset.Base.metadata.create_all(engine)\n        session_cl = sessionmaker(bind=engine)\n        session = session_cl()\n        tmp_object = session.query(trainset.TrainSet).get(object_id)\n        return tmp_object.labels", "response": "Returns all labels for an object specified by the object_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path_in_cache(self, filename, metahash):\n        cpath = self._genpath(filename, metahash)\n        if os.path.exists(cpath):\n            return cpath\n        else:\n            raise CacheMiss", "response": "Generates the path to a file in the mh cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the path to a file in the cache.", "response": "def _genpath(self, filename, mhash):\n        \"\"\"Generate the path to a file in the cache.\n\n        Does not check to see if the file exists. Just constructs the path\n        where it should be.\n        \"\"\"\n        mhash = mhash.hexdigest()\n        return os.path.join(self.mh_cachedir, mhash[0:2], mhash[2:4],\n                            mhash, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nputs a file in the mh cache.", "response": "def putfile(self, filepath, buildroot, metahash):\n        \"\"\"Put a file in the cache.\n\n        Args:\n          filepath: Path to file on disk.\n          buildroot: Path to buildroot\n          buildrule: The rule that generated this file.\n          metahash: hash object\n        \"\"\"\n        def gen_obj_path(filename):\n            filehash = util.hash_file(filepath).hexdigest()\n            return filehash, os.path.join(self.obj_cachedir, filehash[0:2],\n                                          filehash[2:4], filehash)\n\n        filepath_relative = filepath.split(buildroot)[1][1:]  # Strip leading /\n        # Path for the metahashed reference:\n        incachepath = self._genpath(filepath_relative, metahash)\n\n        filehash, obj_path = gen_obj_path(filepath)\n        if not os.path.exists(obj_path):\n            obj_dir = os.path.dirname(obj_path)\n            if not os.path.exists(obj_dir):\n                os.makedirs(obj_dir)\n            log.debug('Adding to obj cache: %s -> %s', filepath, obj_path)\n            os.link(filepath, obj_path)\n\n        if os.path.exists(incachepath):\n            existingfile_hash = util.hash_file(incachepath).hexdigest()\n            if filehash != existingfile_hash:\n                log.warn('File found in mh cache, but checksum differs. '\n                         'Replacing with this new version. (File: %s)',\n                         filepath)\n                log.warn('Possible reasons for this:')\n                log.warn(' 1. This build is not hermetic, and something '\n                         'differs about the build environment compared to the '\n                         'previous build.')\n                log.warn(' 2. This file has a timestamp or other build-time '\n                         'related data encoded into it, which will always '\n                         'cause the checksum to differ when built.')\n                log.warn(' 3. Everything is terrible and nothing works.')\n                os.unlink(incachepath)\n\n        if not os.path.exists(incachepath):\n            log.debug('Adding to mh cache: %s -> %s', filepath, incachepath)\n            if not os.path.exists(os.path.dirname(incachepath)):\n                os.makedirs(os.path.dirname(incachepath))\n            os.link(obj_path, incachepath)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if object is in cache False otherwise.", "response": "def in_cache(self, objpath, metahash):\n        \"\"\"Returns true if object is cached.\n\n        Args:\n          objpath: Filename relative to buildroot.\n          metahash: hash object\n        \"\"\"\n        try:\n            self.path_in_cache(objpath, metahash)\n            return True\n        except CacheMiss:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting object from cache write it to dst_path.", "response": "def get_obj(self, objpath, metahash, dst_path):\n        \"\"\"Get object from cache, write it to dst_path.\n\n        Args:\n          objpath: filename relative to buildroot\n                   (example: mini-boot/blahblah/somefile.bin)\n          metahash: metahash. See targets/base.py\n          dst_path: Absolute path where the file should be written.\n        Raises:\n          CacheMiss: if the item is not in the cache\n        \"\"\"\n        incachepath = self.path_in_cache(objpath, metahash)\n        if not os.path.exists(incachepath):\n            raise CacheMiss('%s not in cache.' % incachepath)\n        else:\n            log.debug('Cache hit! %s~%s', objpath, metahash.hexdigest())\n            if not os.path.exists(os.path.dirname(dst_path)):\n                os.makedirs(os.path.dirname(dst_path))\n            os.link(incachepath, dst_path)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_link(self, peer):\n        assert isinstance(peer, beans.Peer)\n\n        # Look for a link to the peer, using routers\n        for router in self._routers:\n            link = router.get_link(peer)\n            if link:\n                return link\n\n        # Not found\n        raise ValueError(\"No link to peer {0}\".format(peer))", "response": "Returns a Link object for the given peer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef web_services_from_str(\n    list_splitter_fn=ujson.loads,\n):\n    \"\"\"\n    parameters:\n        list_splitter_fn - a function that will take the json compatible string\n            rerpesenting a list of mappings.\n    \"\"\"\n\n    # -------------------------------------------------------------------------\n    def class_list_converter(collector_services_str):\n        \"\"\"This function becomes the actual converter used by configman to\n        take a string and convert it into the nested sequence of Namespaces,\n        one for each class in the list.  It does this by creating a proxy\n        class stuffed with its own 'required_config' that's dynamically\n        generated.\"\"\"\n        if isinstance(collector_services_str, basestring):\n            all_collector_services = list_splitter_fn(collector_services_str)\n        else:\n            raise TypeError('must be derivative of a basestring')\n\n        # =====================================================================\n        class InnerClassList(RequiredConfig):\n            \"\"\"This nested class is a proxy list for the classes.  It collects\n            all the config requirements for the listed classes and places them\n            each into their own Namespace.\n            \"\"\"\n            # we're dynamically creating a class here.  The following block of\n            # code is actually adding class level attributes to this new class\n\n            # 1st requirement for configman\n            required_config = Namespace()\n\n            # to help the programmer know what Namespaces we added\n            subordinate_namespace_names = []\n\n            # for display\n            original_input = collector_services_str.replace('\\n', '\\\\n')\n\n            # for each class in the class list\n            service_list = []\n            for namespace_index, collector_service_element in enumerate(\n                all_collector_services\n            ):\n                service_name = collector_service_element['name']\n                service_uri = collector_service_element['uri']\n                service_implementation_class = class_converter(\n                    collector_service_element['service_implementation_class']\n                )\n\n                service_list.append(\n                    (\n                        service_name,\n                        service_uri,\n                        service_implementation_class,\n                    )\n                )\n                subordinate_namespace_names.append(service_name)\n                # create the new Namespace\n                required_config.namespace(service_name)\n                a_class_namespace = required_config[service_name]\n                a_class_namespace.add_option(\n                    \"service_implementation_class\",\n                    doc='fully qualified classname for a class that implements'\n                        'the action associtated with the URI',\n                    default=service_implementation_class,\n                    from_string_converter=class_converter,\n                    likely_to_be_changed=True,\n                )\n                a_class_namespace.add_option(\n                    \"uri\",\n                    doc='uri for this service',\n                    default=service_uri,\n                    likely_to_be_changed=True,\n                )\n\n            @classmethod\n            def to_str(cls):\n                \"\"\"this method takes this inner class object and turns it back\n                into the original string of classnames.  This is used\n                primarily as for the output of the 'help' option\"\"\"\n                return \"'%s'\" % cls.original_input\n\n        return InnerClassList  # result of class_list_converter\n\n    return class_list_converter", "response": "This function takes a string and converts it into a list of services and adds them to the list of services that are available in the web services."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change_default(\n    kls,\n    key,\n    new_default,\n    new_converter=None,\n    new_reference_value=None,\n):\n    \"\"\"return a new configman Option object that is a copy of an existing one,\n    giving the new one a different default value\"\"\"\n    an_option = kls.get_required_config()[key].copy()\n    an_option.default = new_default\n    if new_converter:\n        an_option.from_string_converter = new_converter\n    if new_reference_value:\n        an_option.reference_value_from = new_reference_value\n    return an_option", "response": "change the default value of an existing configman Option"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_target(self):\n    with open('%s/project.properties' % self.path) as f:\n      for line in f.readlines():\n        matches = re.findall(r'^target=(.*)', line)\n        if len(matches) == 0:\n          continue\n        return matches[0].replace('\\n', '')\n    return 'android-%s' % (config.sdk_version)", "response": "Reads the android target based on project. properties file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sign(self, storepass=None, keypass=None, keystore=None, apk=None, alias=None, name='app'):\n    target = self.get_target()\n    build_tool = android_helper.get_highest_build_tool(target.split('-')[1])\n    if keystore is None:\n      (keystore, storepass, keypass, alias) = android_helper.get_default_keystore()\n    dist = '%s/%s.apk' % ('/'.join(apk.split('/')[:-1]), name)\n    android_helper.jarsign(storepass, keypass, keystore, apk, alias, path=self.path)\n    android_helper.zipalign(apk, dist, build_tool=build_tool, path=self.path)", "response": "Signs a target apk file based on keystore information uses default debug keystore file by default."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare(self):\n    cmd = [\n      'android', 'update', 'project',\n      '-p', self.path,\n      '-t', self.get_target()\n    ]\n    self.run_cmd(cmd, 'prepare')", "response": "Prepares the android project to be built"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup(self, name, host_override=None):\n        if host_override is not None:\n            self.headers['Host'] = host_override\n        full_url = \"http://%s/%s\" % (self.addr, name)\n        request = urllib2.Request(full_url, None, self.headers)\n        try:\n            response = urllib2.urlopen(request)\n        except urllib2.HTTPError, e:\n            if e.code == 404:\n                e = DataNotFound(e, name, self.headers['Host'])\n            if e.code < 200 or e.code > 299:\n                self._log.debug(\"%s\" % (e.msg,), exc_info=True)\n                raise e\n\n        namecoin_string = response.read()\n        try:\n            data = json.loads(namecoin_string)\n        except ValueError:\n            raise MalformedJSON(\"%s\\n%s\" % (ValueError, namecoin_string))\n        return data", "response": "Look up a name from the DNSChain server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cache_function(length):\n    def decorator(func):\n        def inner_func(*args, **kwargs):\n            from django.core.cache import cache\n\n            value = cache.get(func)\n            if func in cache:\n                return value\n            else:\n                # This will set a temporary value while ``func`` is being\n                # processed. When using threads, this is vital, as otherwise\n                # the function can be called several times before it finishes\n                # and is put into the cache.\n                class MethodNotFinishedError(Exception):\n                    pass\n                cache.set(func, MethodNotFinishedError(\n                    'The function %s has not finished processing yet. This \\\nvalue will be replaced when it finishes.' % (func.__name__)\n                ), length)\n                result = func(*args, **kwargs)\n                cache.set(func, result, length)\n                return result\n        return inner_func\n    return decorator", "response": "A function decorator that caches a function in django. core. cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_formatted_feature_dependencies(data):\n    conditions = list()\n    for k, v in data.items():\n        for feature in v.get('after', list()):\n            conditions.append(dict(\n                name=k,\n                subject=feature,\n                ctype='after'\n            ))\n        if v.get('first', False):\n            conditions.append(dict(\n                name=k,\n                subject=None,\n                ctype='first'\n            ))\n        if v.get('last', False):\n            conditions.append(dict(\n                name=k,\n                subject=None,\n                ctype='last'\n            ))\n    return conditions", "response": "Takes the format of the feature_order. json in featuremodel pool. Returns a list of dictionaries containing the conditions that are added to the list of conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_condition_instances(data):\n    conditions = list()\n    for cond in data:\n        conditions.append(OrderingCondition(\n            name=cond.get('name'),\n            subject=cond.get('subject'),\n            ctype=cond.get('ctype')\n        ))\n    return conditions", "response": "Returns a list of OrderingCondition instances created from the passed data structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef join(self, path):\n\n        return self.parse_uri(urlparse(os.path.join(str(self), path)), storage_args=self.storage_args)", "response": "Similar to os. path. join but returns a storage object instead."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the object exists.", "response": "def exists(self):\n        \"\"\"Uses ``HEAD`` requests for efficiency.\"\"\"\n\n        try:\n            self.s3_object.load()\n            return True\n        except botocore.exceptions.ClientError: return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_dir(self):\n\n        bucket = self.s3_object.Bucket()\n        prefix = self.s3_object.key\n        if not prefix.endswith('/'): prefix += '/'\n\n        for obj in bucket.objects.filter(Delimiter='/', Prefix=prefix):\n            yield 's3://{}/{}'.format(obj.bucket_name, obj.key)", "response": "A generator over files in this directory for efficiency."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put_content(self, content):\n\n        self.blob.content_encoding = self.content_encoding\n        self.blob.metadata = self.metadata\n        return self.blob.upload_from_string(content, content_type=self.content_type)", "response": "Upload the content to the blob."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the object exists False otherwise.", "response": "def exists(self):\n        \"\"\"Uses ``HEAD`` requests for efficiency.\"\"\"\n\n        try:\n            self.blob.reload()\n            return True\n        except google.cloud.exceptions.NotFound: return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_dir(self):\n\n        bucket = self.blob.bucket\n        prefix = self.blob.name\n        if not prefix.endswith('/'): prefix += '/'\n\n        for blob in bucket.list_blobs(prefix=prefix, delimiter='/'):\n            yield 'gs://{}/{}'.format(blob.bucket.name, blob.name)", "response": "A generator over files in this directory for efficiency."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef put_content(self, content):\n\n        r = requests.request(self.method if self.method else 'PUT', self.url, data=content, **self.storage_args)\n        if self.raise_for_status: r.raise_for_status()", "response": "Makes a PUT request with the content in the body."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the directory exists.", "response": "def dir_exists(self):\n        \"\"\"\n        Makes a ``HEAD`` requests to the URI.\n\n        :returns: ``True`` if status code is 2xx.\n        \"\"\"\n\n        r = requests.request(self.method if self.method else 'HEAD', self.url, **self.storage_args)\n        try: r.raise_for_status()\n        except Exception: return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_content(self, content):\n        if not isinstance(content, str):\n            content = content.decode('utf-8')\n\n        self.topic.publish(Message=content, **self.storage_args)", "response": "Publishes a message straight to SNS."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _string2Duration(text):\n    if text == \"\" or text == \"zero\":\n        return ZERO\n\n    amount, interval = re.match(r\"([\\d\\.]*)(.*)\", text).groups()\n    amount = int(amount) if amount else 1\n\n    if MILLI_VALUES[interval] == None:\n        from mo_logs import Log\n        Log.error(\n            \"{{interval|quote}} in {{text|quote}} is not a recognized duration type (did you use the pural form by mistake?\",\n            interval=interval,\n            text=text\n        )\n\n    output = Duration(0)\n    if MONTH_VALUES[interval] == 0:\n        output.milli = amount * MILLI_VALUES[interval]\n    else:\n        output.milli = amount * MONTH_VALUES[interval] * MILLI_VALUES.month\n        output.month = amount * MONTH_VALUES[interval]\n\n    return output", "response": "Convert a string to a duration object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister an exit call to start the core.", "response": "def registerExitCall():\n  r\"\"\"Registers an exit call to start the core.\n\n    The core would be started after the main module is loaded. Ec would be exited from the core.\n  \"\"\"\n  if state.isExitHooked:\n    return\n\n  state.isExitHooked = True\n\n  from atexit import register\n\n  register(core.start)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a v_eq vector given R dR Prot dProt", "response": "def generate_veq(R=1.3, dR=0.1, Prot=6, dProt=0.1,nsamples=1e4,plot=False,\n                 R_samples=None,Prot_samples=None):\n    \"\"\" Returns the mean and std equatorial velocity given R,dR,Prot,dProt\n\n    Assumes all distributions are normal.  This will be used mainly for\n    testing purposes; I can use MC-generated v_eq distributions when we go for real.\n    \"\"\"\n    if R_samples is None:\n        R_samples = R*(1 + rand.normal(size=nsamples)*dR)\n    else:\n        inds = rand.randint(len(R_samples),size=nsamples)\n        R_samples = R_samples[inds]\n\n    if Prot_samples is None:\n        Prot_samples = Prot*(1 + rand.normal(size=nsamples)*dProt)\n    else:\n        inds = rand.randint(len(Prot_samples),size=nsamples)\n        Prot_samples = Prot_samples[inds]\n\n    veq_samples = 2*np.pi*R_samples*RSUN/(Prot_samples*DAY)/1e5\n    \n    if plot:\n        plt.hist(veq_samples,histtype='step',color='k',bins=50,normed=True)\n        d = stats.norm(scale=veq_samples.std(),loc=veq_samples.mean())\n        vs = np.linspace(veq_samples.min(),veq_samples.max(),1e4)\n        plt.plot(vs,d.pdf(vs),'r')\n    \n    return veq_samples.mean(),veq_samples.std()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef like_cosi(cosi,vsini_dist,veq_dist,vgrid=None):\n    sini = np.sqrt(1-cosi**2)\n    def integrand(v):\n        #return vsini_dist(v)*veq_dist(v/sini)\n        return vsini_dist(v*sini)*veq_dist(v)\n    if vgrid is None:\n        return quad(integrand,0,np.inf)[0]\n    else:\n        return np.trapz(integrand(vgrid),vgrid)", "response": "likelihood of Data given cosi"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns posterior of cosI given vsini and veq", "response": "def cosi_posterior(vsini_dist,veq_dist,vgrid=None,npts=100,vgrid_pts=1000):\n    \"\"\"returns posterior of cosI given dists for vsini and veq (incorporates unc. in vsini)\n    \"\"\"\n    if vgrid is None:\n        vgrid = np.linspace(min(veq_dist.ppf(0.001),vsini_dist.ppf(0.001)),\n                            max(veq_dist.ppf(0.999),vsini_dist.ppf(0.999)),\n                            vgrid_pts)\n        logging.debug('vgrid: {} pts, {} to {}'.format(vgrid_pts,\n                                                       vgrid[0],\n                                                       vgrid[-1]))\n        #vgrid = np.linspace(vsini_dist.ppf(0.005),vsini_dist.ppf(0.995),vgrid_pts)\n    cs = np.linspace(0,1,npts)\n    Ls = cs*0\n    for i,c in enumerate(cs):\n        Ls[i] = like_cosi(c,vsini_dist,veq_dist,vgrid=vgrid)\n    if np.isnan(Ls[-1]): #hack to prevent nan when cos=1\n        Ls[-1] = Ls[-2]\n    Ls /= np.trapz(Ls,cs)\n    return cs,Ls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning nsamples from a tabulated posterior", "response": "def sample_posterior(x,post,nsamples=1):\n    \"\"\" Returns nsamples from a tabulated posterior (not necessarily normalized)\n    \"\"\"\n    cdf = post.cumsum()\n    cdf /= cdf.max()\n    u = rand.random(size=nsamples)\n    inds = np.digitize(u,cdf)\n    return x[inds]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef v_posts_from_dataframe(df,N=1e4,alpha=0.23,l0=20,sigl=20):\n    vsini_posts = []\n    veq_posts = []\n    if 'ep_R' in df:\n        for R,dR_p,dR_m,P,dP,v,dv in zip(df['R'],df['ep_R'],df['em_R'],\n                                  df['Prot'],df['e_Prot'],\n                                  df['vsini'],df['e_vsini']):\n            vsini_posts.append(stats.norm(v,dv))\n            if dR_p==dR_m:\n                veq_posts.append(Veq_Posterior(R,dR_p,P,dP))\n            else:\n                R_dist = dists.fit_doublegauss(R,dR_m,dR_p)\n                Prot_dist = stats.norm(P,dP)\n                veq_posts.append(Veq_Posterior_General(R_dist,Prot_dist,N=N,\n                                                       l0=l0,sigl=sigl))\n    else:\n        for R,dR,P,dP,v,dv in zip(df['R'],df['e_R'],\n                                  df['Prot'],df['e_Prot'],\n                                  df['vsini'],df['e_vsini']):\n            vsini_posts.append(stats.norm(v,dv))\n            veq_posts.append(Veq_Posterior(R,dR,P,dP))\n        \n    return vsini_posts,veq_posts", "response": "returns a list of Veq_Posterior_General and Veq_Posterior_General objects for a given dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_process(self, paths, dry_run=False, **options):\n        with post_process_error_counter(self):\n            with patched_name_fn(self, 'hashed_name', 'hashed name'):\n                with patched_name_fn(self, 'url', 'url'):\n                    for result in super(LaxPostProcessorMixin,\n                                        self).post_process(paths, dry_run, **options):\n                        yield result\n            error_count = self._post_process_error_count\n            if error_count:\n                print('%s post-processing error%s.' % (error_count,\n                        '' if error_count == 1 else 's'))", "response": "Override to add post - processing to the base class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride to exclude any files that are not in the cache.", "response": "def post_process(self, paths, dry_run=False, **options):\n        \"\"\"\n        Overridden to allow some files to be excluded (using\n        ``postprocess_exclusions``)\n\n        \"\"\"\n        if self.postprocess_exclusions:\n            paths = dict((k, v) for k, v in paths.items() if not\n                    self.exclude_file(k))\n        return super(CachedFilesMixin, self).post_process(paths,\n                dry_run, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_paths(self):\n        '''\n        get list of module paths\n        '''\n\n        # guess site package dir of virtualenv (system dependent)\n        venv_site_packages = '%s/lib/site-packages' % self.venv_dir\n\n        if not os.path.isdir(venv_site_packages):\n            venv_site_packages_glob = glob.glob('%s/lib/*/site-packages' % self.venv_dir)\n\n            if len(venv_site_packages_glob):\n                venv_site_packages = venv_site_packages_glob[0]\n\n        return [\n            self.venv_dir,\n            venv_site_packages\n        ]", "response": "get list of module paths containing the current virtualenv and site - packages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_virtualenv(venv_dir, use_venv_module=True):\n\n        if not use_venv_module:\n            try:\n                check_call(['virtualenv', venv_dir, '--no-site-packages'])\n            except OSError:\n                raise Exception('You probably dont have virtualenv installed: sudo apt-get install python-virtualenv')\n        else:\n            check_call([sys.executable or 'python', '-m', 'venv', venv_dir])", "response": "Creates a new virtualenv in venv_dir."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data_dirpath(task=None, **kwargs):\n    path = _base_dir()\n    if task:\n        path = os.path.join(path, _snail_case(task))\n    for k, v in sorted(kwargs.items()):\n        subdir_name = '{}_{}'.format(_snail_case(k), _snail_case(v))\n        path = os.path.join(path, subdir_name)\n    os.makedirs(path, exist_ok=True)\n    return path", "response": "Get the path to the corresponding data directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the path to the dataset file.", "response": "def dataset_dirpath(dataset_name=None, task=None, **kwargs):\n    \"\"\"Get the path of the corresponding dataset file.\n\n    Parameters\n    ----------\n    dataset_name : str, optional\n        The name of the dataset. Used to define a sub-directory to contain all\n        instances of the dataset. If not given, a dataset-agnostic directory\n        path is returned.\n    task : str, optional\n        The task for which datasets in the desired path are used for. If not\n        given, a path for the corresponding task-agnostic directory is\n        returned.\n    **kwargs : extra keyword arguments\n        Extra keyword arguments, representing additional attributes of the\n        datasets, are used to determine additional sub-folders on the path.\n        For example, providing 'lang=en' will results in a path such as\n        '/barn_base_dir/regression/lang_en/mydataset.csv'. Hierarchy always\n        matches lexicographical order of keyword argument names, so 'lang=en'\n        and 'animal=dog' will result in a path such as\n        'barn_base_dir/task_name/animal_dof/lang_en/dset.csv'.\n\n    Returns\n    -------\n    str\n        The path to the desired dataset file.\n    \"\"\"\n    dataset_dir_path = data_dirpath(task=task, **kwargs)\n    if dataset_name:\n        dataset_dir_name = _snail_case(dataset_name)\n        dataset_dir_path = os.path.join(dataset_dir_path, dataset_dir_name)\n    os.makedirs(dataset_dir_path, exist_ok=True)\n    return dataset_dir_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dataset_filepath(filename, dataset_name=None, task=None, **kwargs):\n    dataset_dir_path = dataset_dirpath(\n        dataset_name=dataset_name, task=task, **kwargs)\n    return os.path.join(dataset_dir_path, filename)", "response": "Returns the path to the dataset file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the Model Class based on the given json schema file form schemes folder containing the resource schema file form schemes filename containing the resource schema.", "response": "def get_model_class( klass, api = None, use_request_api = True):\n    \"\"\"\n    Generates the Model Class based on the klass \n    loads automatically the corresponding json schema file form schemes folder\n    :param klass: json schema filename\n    :param use_request_api: if True autoinitializes request class if api is None\n    :param api: the transportation api\n                if none the default settings are taken an instantiated\n    \"\"\"\n    if api is None and use_request_api:\n        api = APIClient()\n    _type = klass\n    if isinstance(klass, dict):\n        _type = klass['type']\n    schema = loaders.load_schema_raw(_type)\n    model_cls = model_factory(schema, base_class = RemoteResource)\n    model_cls.__api__ = api\n    return model_cls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate(self, data):\n        try:\n            schema_path = os.path.normpath(SCHEMA_ROOT)\n            location = u'file://%s' % (schema_path)\n            fs_resolver = resolver.LocalRefResolver(location, self.schema)\n            jsonschema.Draft3Validator(self.schema, resolver=fs_resolver).validate(data)\n\n        except jsonschema.ValidationError as exc:\n            # print \"data %s\" % (data)\n            raise jsonschema.exceptions.ValidationError(str(exc))", "response": "Apply a JSON schema to an object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, *args, **kwargs):\n        self._pre_save(*args, **kwargs)\n        response = self._save(*args, **kwargs)\n        response = self._post_save(response, *args, **kwargs)\n        return response", "response": "Saves creates or updates current resource\n        returns new resource\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a remote resource by id", "response": "def load(self, id, *args, **kwargs):\n        \"\"\"\n        loads a remote resource by id\n        \"\"\"\n        self._pre_load(id, *args, **kwargs)\n        response = self._load(id, *args, **kwargs)\n        response = self._post_load(response, *args, **kwargs)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self,  *args, **kwargs):\n        self._pre_delete(*args, **kwargs)\n        response = self._delete(*args, **kwargs)\n        response = self._post_delete(response, *args, **kwargs)\n        return response", "response": "Deletes the current resource from the cache. Returns the response from the API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nputting the object to json and remove the internal stuff", "response": "def to_json(self):\n        \"\"\"\n        put the object to json and remove the internal stuff\n        salesking schema stores the type in the title\n        \"\"\"\n        data = json.dumps(self)\n\n        out = u'{\"%s\":%s}' % (self.schema['title'], data)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a response if it is a valid call otherwise the corresponding error", "response": "def _do_api_call(self, call_type=u'', id = None):\n        \"\"\"\n        returns a response if it is a valid call\n        otherwise the corresponding error\n        \n        \"\"\"\n        endpoint = None\n        url = None\n        # print \"call_type %s\" % (call_type)\n        if call_type == u'load':\n            endpoint = self.get_endpoint(\"self\")\n            if id is None:\n                raise APIException(\"LOAD_IDNOTSET\", \"could not load object\")\n        elif call_type == u'delete' or (call_type == u\"destroy\"):\n            endpoint = self.get_endpoint(\"destroy\")\n            if id is None:\n                raise APIException(\"DELETE_IDNOTSET\", \"could not delete object\")\n        elif call_type == u'update':\n            endpoint = self.get_endpoint(\"update\")\n            if id is None:\n                raise APIException(\"UPDATE_IDNOTSET\", \"could not load object\")\n        elif call_type == u'create':\n            endpoint = self.get_endpoint(\"create\")\n            url = u\"%s%s%s\" % (self.__api__.base_url, API_BASE_PATH, endpoint['href'])\n            # post?\n        elif call_type == u'schema':\n            # add schema gethering functionality \n            # hackisch\n            endpoint = self.get_endpoint(\"create\")\n            url = u\"%s%s%s/schema\" % (self.__api__.base_url, API_BASE_PATH, endpoint['href'])\n            endpoint['method'] = u'GET'    \n        if id is not None:\n            url = u\"%s%s%s\" % (self.__api__.base_url, API_BASE_PATH, endpoint['href'].replace(u\"{id}\",id))\n        ## excecute the api request\n        payload = self.to_json()\n        if u'method' in endpoint.keys():\n            method = endpoint['method']\n        else:\n            method = u'GET'\n        # request raises exceptions if something goes wrong\n        obj = None\n        try:\n            # dbg\n            msg = u\"url: %s method:%s p: %s\" % (url, method, payload)\n            #print msg\n            response = self.__api__.request(url, method, data=payload)\n            #load update create success\n            if ((response.status_code == 200 and \n                 call_type in ['load', 'update']) or\n            (response.status_code == 201 and call_type == 'create')):\n                msg = \"call_type: %s successfully completed\" % call_type\n                log.info(msg)\n                return self.to_instance(response)\n            elif (response.status_code == 200 and call_type in ['delete', 'destroy']):\n            #delete success\n                msg =\"call_type: %s successfully completed\" % call_type\n                log.info(msg)\n                return self._try_to_serialize(response)\n            elif 200 <= response.status_code <= 299:\n                return self._try_to_serialize(response)\n        except Exception as e:\n            msg = \"Exception occoured %s url: %s\" % (e, url)\n            log.error(msg)\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_instance(self, response):\n        klass = self.schema['title']\n        cls = get_model_class(klass, api=self.__api__)\n        jdict = json.loads(response.content, encoding=\"utf-8\")\n        ### check if we have a response\n        properties_dict = jdict[self.schema['title']]\n        # @todo: find a way to handle the data\n        # validation fails if the none values are not removed\n        new_dict = helpers.remove_properties_containing_None(properties_dict)\n        #jdict[self.schema['title']] = new_dict\n        obj = cls(new_dict)\n        #obj.links = jdict[self.schema['title']]['links']\n        return obj", "response": "transforms the content to a new instance of\n        object self. schema [ title ]\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming the content to a new instance of object self. schema [ title ]", "response": "def dict_to_instance(self, content):\n        \"\"\"\n        transforms the content to a new instace of\n        object self.schema['title']\n        :param content: valid response\n        :returns new instance of current class\n        \"\"\"\n        klass = self.schema['title']\n        cls = get_model_class(klass, api=self.__api__)\n        # jdict = json.loads(content, encoding=\"utf-8\")\n        ### check if we have a response\n        properties_dict = content[self.schema['title']][self.schema['title']]\n        #@todo: find a way to handle the data\n        # validation fails if the none values are not removed\n        new_dict = helpers.remove_properties_containing_None(properties_dict)\n        obj = cls(new_dict)\n        #obj.links = content[self.schema['title']]['links']\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a formatted view of the local variables in a frame", "response": "def get_locals(f):\n    ''' returns a formatted view of the local variables in a frame '''\n    return pformat({i:f.f_locals[i] for i in f.f_locals if not i.startswith('__')})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default_profiler(f, _type, _value):\n    ''' inspects an input frame and pretty prints the following:\n\n        <src-path>:<src-line> -> <function-name>\n        <source-code>\n        <local-variables>\n        ----------------------------------------\n    '''\n    try:\n        profile_print(\n            '\\n'.join([\n                get_frame_src(f),\n                get_locals(f),\n                '----------------------------------------'\n            ])\n        )\n    except:\n        pass", "response": "inspects an input frame and pretty prints the following:\n\n        <src-path>:<src-line> -> <function-name>\n        <source-code>\n        <local-variables>\n        ----------------------------------------"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens the named log file in append mode.", "response": "def open_logfile(filename, mode='a'):\n    \"\"\"Open the named log file in append mode.\n\n    If the file already exists, a separator will also be printed to\n    the file to separate past activity from current activity.\n    \"\"\"\n    filename = os.path.expanduser(filename)\n    filename = os.path.abspath(filename)\n    dirname = os.path.dirname(filename)\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n    exists = os.path.exists(filename)\n\n    log_fp = open(filename, mode)\n    if exists:\n        log_fp.write('%s\\n' % ('-'*60))\n        log_fp.write('%s run on %s\\n' % (sys.argv[0], time.strftime('%c')))\n    return log_fp"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates with the backend role", "response": "def authenticate(realm, authid, details):\n    \"\"\"\n    application_name : name of your application\n    version : version of your application\n    required_components dictionary of components required for you application\n    and their version required\n\n        {\n           \"component\" : \"1.1\",\n           \"component2\" : \"0.1\",\n           ...\n        }\n\n     when all the different component required has been register your component will\n     be allow to authenticate with a role build only for your application with\n     only the right right for it to works\n    \"\"\"\n    global _start\n    global _waiting\n    import json\n    ticket = json.loads(details['ticket']\n                        )\n    if 'application_name' not in ticket and 'version' not in ticket:\n        raise ApplicationError(\n            'could not start the authentication of an app,\\\n             field application_name or version is missing')\n    application_name = ticket['application_name']\n    version = ticket['version']\n\n    required_components = ticket[\n        'required_components'] if 'required_components' in ticket else {}\n    if not _try_to_start_app(application_name, version, required_components):\n        ready_defered = defer.Deferred()\n        ready_defered.addCallback(defer_try_start_app,\n                                  application_name=application_name,\n                                  version=version,\n                                  required_components=required_components)\n        _waiting[application_name]['defer'] = ready_defered\n        yield ready_defered\n\n    print(\"[MESTR] start app: \", _start)\n    print(\"[MESTR] waiting app: \", _waiting)\n\n    for k in _start:\n        if k in _waiting:\n            _waiting = remove_element(_waiting, k)\n    # backend role must be contains in the config.json\n    # since we can't create them dynamically for the moment\n    returnValue(\"backend\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting information on a provided resource", "response": "def info(self, resource):\n        '''\n        prints information/documentation on a provided resource\n        '''\n        service_def, resource_def, path = self._get_service_information(\n            resource)\n\n        print (resource)\n        print (\"*******************************************\")\n        print (\"Base URL: {0}\" . format (self.tld))\n        print (\"Resource path: {0}\" . format (resource_def.get(\"endpoint\")))\n        print (\"Required parameters: {0}\" . format (resource_def.get(\"required_params\")))\n        print (\"Optional parameters\" . format (resource_def.get(\"optional_params\")))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, resource, resource_id):\n        '''\n        A base function that performs a default delete DELETE request for a given object\n        '''\n\n        service_def, resource_def, path = self._get_service_information(\n            resource)\n        delete_path = \"{0}{1}/\" . format(path, resource_id)\n        return self.call(path=delete_path, method=\"delete\")", "response": "A base function that performs a default DELETE request for a given object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes API methods for the service.", "response": "def _make_api(self, service_name):\n        '''\n        not yet in use ..\n        '''\n\n        resources = [resource for resource, resource_details in\n                     service_definitions.get(service_name, {}).get(\"resources\", {}).items()]\n\n        for resource in resources:\n            setattr(self, 'list_{0}' . format(resource), self.list)\n            setattr(self, 'get_{0}' . format(resource), self.get)\n            setattr(self, 'create_{0}' . format(resource), self.create)\n            setattr(self, 'update_{0}' . format(resource), self.update)\n            setattr(self, 'delete_{0}' . format(resource), self.delete)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getSystemIps():\n        IPs = []\n        for interface in NetInfo.getSystemIfs():\n            if not interface.startswith('lo'):\n                ip = netinfo.get_ip(interface)\n                IPs.append(ip)\n        return IPs", "response": "will not return the localhost one"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a comma delimited string of all the system IPs", "response": "def getIPString():\n        \"\"\" return comma delimited string of all the system IPs\"\"\"\n        if not(NetInfo.systemip):\n            NetInfo.systemip = \",\".join(NetInfo.getSystemIps())\n        return NetInfo.systemip"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if an update is available on pypi Return False otherwise", "response": "def check_update():\n    \"\"\"\n    Return True if an update is available on pypi\n    \"\"\"\n    r = requests.get(\"https://pypi.python.org/pypi/prof/json\")\n    data = r.json()\n    if versiontuple(data['info']['version']) > versiontuple(__version__):\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts time inputs to UT1 seconds since Unix epoch", "response": "def to_ut1unix(time: Union[str, datetime, float, np.ndarray]) -> np.ndarray:\n    \"\"\"\n    converts time inputs to UT1 seconds since Unix epoch\n    \"\"\"\n    # keep this order\n    time = totime(time)\n\n    if isinstance(time, (float, int)):\n        return time\n\n    if isinstance(time, (tuple, list, np.ndarray)):\n        assert isinstance(time[0], datetime), f'expected datetime, not {type(time[0])}'\n        return np.array(list(map(dt2ut1, time)))\n    else:\n        assert isinstance(time, datetime)\n        return dt2ut1(time)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the profile of a chapman peak", "response": "def chapman_profile(Z0: float, zKM: np.ndarray, H: float):\n    \"\"\"\n    Z0: altitude [km] of intensity peak\n    zKM: altitude grid [km]\n    H: scale height [km]\n\n    example:\n    pz = chapman_profile(110,np.arange(90,200,1),20)\n    \"\"\"\n    return np.exp(.5*(1-(zKM-Z0)/H - np.exp((Z0-zKM)/H)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_editable(editable_req, default_vcs=None):\n    url = editable_req\n    if os.path.isdir(url) and os.path.exists(os.path.join(url, 'setup.py')):\n        # Treating it as code that has already been checked out\n        url = path_to_url(url)\n    if url.lower().startswith('file:'):\n        return None, url\n    for version_control in vcs:\n        if url.lower().startswith('%s:' % version_control):\n            url = '%s+%s' % (version_control, url)\n    if '+' not in url:\n        if default_vcs:\n            url = default_vcs + '+' + url\n        else:\n            raise InstallationError(\n                '--editable=%s should be formatted with svn+URL, git+URL, hg+URL or bzr+URL' % editable_req)\n    vc_type = url.split('+', 1)[0].lower()\n    if not vcs.get_backend(vc_type):\n        raise InstallationError(\n            'For --editable=%s only svn (svn+URL), Git (git+URL), Mercurial (hg+URL) and Bazaar (bzr+URL) is currently supported' % editable_req)\n    match = re.search(r'(?:#|#.*?&)egg=([^&]*)', editable_req)\n    if (not match or not match.group(1)) and vcs.get_backend(vc_type):\n        parts = [p for p in editable_req.split('#', 1)[0].split('/') if p]\n        if parts[-2] in ('tags', 'branches', 'tag', 'branch'):\n            req = parts[-3]\n        elif parts[-1] == 'trunk':\n            req = parts[-2]\n        else:\n            raise InstallationError(\n                '--editable=%s is not the right format; it must have #egg=Package'\n                % editable_req)\n    else:\n        req = match.group(1)\n    ## FIXME: use package_to_requirement?\n    match = re.search(r'^(.*?)(?:-dev|-\\d.*)$', req)\n    if match:\n        # Strip off -dev, -0.2, etc.\n        req = match.group(1)\n    return req, url", "response": "Parses an editable requirement into a requirement\n    and a URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_line(cls, name, comes_from=None):\n        url = None\n        name = name.strip()\n        req = None\n        path = os.path.normpath(os.path.abspath(name))\n        link = None\n\n        if is_url(name):\n            link = Link(name)\n        elif os.path.isdir(path) and (os.path.sep in name or name.startswith('.')):\n            if not is_installable_dir(path):\n                raise InstallationError(\"Directory %r is not installable. File 'setup.py' not found.\", name)\n            link = Link(path_to_url(name))\n        elif is_archive_file(path):\n            if not os.path.isfile(path):\n                logger.warn('Requirement %r looks like a filename, but the file does not exist', name)\n            link = Link(path_to_url(name))\n\n        # If the line has an egg= definition, but isn't editable, pull the requirement out.\n        # Otherwise, assume the name is the req for the non URL/path/archive case.\n        if link and req is None:\n          url = link.url_fragment\n          req = link.egg_fragment\n\n          # Handle relative file URLs\n          if link.scheme == 'file' and re.search(r'\\.\\./', url):\n            url = path_to_url(os.path.normpath(os.path.abspath(link.path)))\n\n        else:\n          req = name\n\n        return cls(req, comes_from, url=url)", "response": "Creates an InstallRequirement from a name which might be a\n        requirement directory containing setup. py filename or URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the source files from this requirement if they are marked for deletion", "response": "def remove_temporary_source(self):\n        \"\"\"Remove the source files from this requirement, if they are marked\n        for deletion\"\"\"\n        if self.is_bundle or os.path.exists(self.delete_marker_filename):\n            logger.info('Removing source in %s' % self.source_dir)\n            if self.source_dir:\n                rmtree(self.source_dir)\n            self.source_dir = None\n        if self._temp_build_dir and os.path.exists(self._temp_build_dir):\n            rmtree(self._temp_build_dir)\n        self._temp_build_dir = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_if_exists(self):\n        if self.req is None:\n            return False\n        try:\n            self.satisfied_by = pkg_resources.get_distribution(self.req)\n        except pkg_resources.DistributionNotFound:\n            return False\n        except pkg_resources.VersionConflict:\n            self.conflicts_with = pkg_resources.get_distribution(self.req.project_name)\n        return True", "response": "Find an installed distribution that satisfies or conflicts\n        with this requirement and set self. satisfied_by or self. conflicts_with appropriately."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef release():\n\n    with settings(warn_only=True):\n        r = local(clom.git['diff-files']('--quiet', '--ignore-submodules', '--'))\n\n    if r.return_code != 0:\n        abort('There are uncommitted changes, commit or stash them before releasing')\n\n    version = open('VERSION.txt').read().strip()\n\n    print('Releasing %s...' % version)\n    local(clom.git.flow.release.start(version))\n    local(clom.git.flow.release.finish(version, m='Release-%s' % version))\n    local(clom.git.push('origin', 'master', 'develop', tags=True))\n    local(clom.python('setup.py', 'sdist', 'upload'))", "response": "Release current version to pypi\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute(tokens):\n    if not validate_rc():\n        print('Your .vacationrc file has errors!')\n        echo_vacation_rc()\n        return\n\n    for action, value in tokens:\n        if action == 'show':\n            show()\n        elif action == 'log':\n            log_vacation_days()\n        elif action == 'echo':\n            echo_vacation_rc()\n        elif action == 'take':\n            take(value)\n        elif action == 'cancel':\n            cancel(value)\n        elif action == 'setrate':\n            setrate(value)\n        elif action == 'setdays':\n            setdays(value)", "response": "Execute the actions described by the input tokens."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving any duplicate entries.", "response": "def unique(transactions):\n    \"\"\" Remove any duplicate entries. \"\"\"\n    seen = set()\n    # TODO: Handle comments\n    return [x for x in transactions if not (x in seen or seen.add(x))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort(transactions):\n    return transactions.sort(key=lambda x: datetime.datetime.strptime(x.split(':')[0], '%Y-%m-%d'))[:]", "response": "Return a list of sorted transactions by date."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate our. vacationrc file.", "response": "def validate_rc():\n    \"\"\" Before we execute any actions, let's validate our .vacationrc. \"\"\"\n    transactions = rc.read()\n    if not transactions:\n        print('Your .vacationrc file is empty! Set days and rate.')\n        return False\n    transactions = sort(unique(transactions))\n    return validate_setup(transactions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the setup of the vacationrc file.", "response": "def validate_setup(transactions):\n    \"\"\" First two transactions must set rate & days. \"\"\"\n    if not transactions:\n        return True\n    try:\n        first, second = transactions[:2]\n    except ValueError:\n        print('Error: vacationrc file must have both initial days and rates entries')\n        return False\n\n    parts1, parts2 = first.split(), second.split()\n\n    if parts1[0] != parts2[0]:\n        print('Error: First two entries in vacationrc must have the same date')\n        return False  # Dates must match\n\n    if 'rate' not in (parts1[1], parts2[1]) or 'days' not in (parts1[1], parts2[1]):\n        print('Error: First two entries in vacationrc must set days and rate')\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_transaction_entry(entry):\n    parts = entry.split()\n\n    date_string = parts[0]\n    try:\n        date = datetime.datetime.strptime(date_string[:-1], '%Y-%m-%d').date()\n    except ValueError:\n        raise ValueError('Invalid date in vacationrc for entry: {}'.format(entry))\n\n    if len(parts) < 2:\n        raise ValueError('.vacationrc missing an action for entry: {}'.format(entry))\n    action = parts[1].lower()\n    if action not in ('days', 'rate', 'off', 'adjust', 'show'):\n        raise ValueError('Invalid action in vacationrc for entry: {}'.format(entry))\n\n    try:\n        value = float(parts[2])\n    except IndexError:\n        value = None\n    except (ValueError, TypeError):\n        raise ValueError('Invalid value in vacationrc for entry: {}'.format(entry))\n\n    return (date, action, value)", "response": "Validate & parse a transaction entry into a date action and value tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stat_holidays(province='BC', year=2015):\n    return holidays.Canada(state=province, years=year).keys()", "response": "Returns a list of holiday dates for a given province and year."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sum_transactions(transactions):\n    workdays_per_year = 250\n    previous_date = None\n    rate = 0\n    day_sum = 0\n    for transaction in transactions:\n        date, action, value = _parse_transaction_entry(transaction)\n        if previous_date is None:\n            previous_date = date\n        elapsed = workdays.networkdays(previous_date, date, stat_holidays()) - 1\n\n        if action == 'rate':\n            rate = float(value) / workdays_per_year\n        elif action == 'off':\n            elapsed -= 1  # Didn't work that day\n            day_sum -= 1  # And we used a day\n        day_sum += rate * elapsed\n\n        if action == 'days':\n            day_sum = value  # Fixed value as of this entry\n\n        previous_date = date\n\n    return day_sum", "response": "Sums transactions into a total of remaining vacation days."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the dates for any take day off transactions.", "response": "def get_days_off(transactions):\n    \"\"\" Return the dates for any 'take day off' transactions. \"\"\"\n    days_off = []\n    for trans in transactions:\n        date, action, _ = _parse_transaction_entry(trans)\n        if action == 'off':\n            days_off.append(date)\n    return days_off"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_vacation_days():\n    days_off = get_days_off(rc.read())\n    pretty_days = map(lambda day: day.strftime('%a %b %d %Y'), days_off)\n    for day in pretty_days:\n        print(day)", "response": "Sum and report taken days off."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay all our. vimationrc file.", "response": "def echo_vacation_rc():\n    \"\"\" Display all our .vacationrc file. \"\"\"\n    contents = rc.read()\n    print('.vacationrc\\n===========')\n    for line in contents:\n        print(line.rstrip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_email(email_class, email, language=None, **data):\n    if language:\n        email_class().send([email], language=language, **data)\n    else:\n        email_class().send([email], translation.get_language(), **data)", "response": "Send email to specified email address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a user to the user model", "response": "def to_user(email_class, user, **data):\n    \"\"\"\n    Email user\n    \"\"\"\n    try:\n        email_class().send([user.email], user.language, **data)\n    except AttributeError:\n        # this is a fallback in case the user model does not have the language field\n        email_class().send([user.email], translation.get_language(), **data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_staff(email_class, **data):\n    for user in get_user_model().objects.filter(is_staff=True):\n        try:\n            email_class().send([user.email], user.language, **data)\n        except AttributeError:\n            email_class().send([user.email], translation.get_language(), **data)", "response": "Send email to staff users"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend email to superuser.", "response": "def to_superuser(email_class, **data):\n    \"\"\"\n    Email superusers\n    \"\"\"\n    for user in get_user_model().objects.filter(is_superuser=True):\n        try:\n            email_class().send([user.email], user.language, **data)\n        except AttributeError:\n            email_class().send([user.email], translation.get_language(), **data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_use_declaration(p):\n    '''use_declaration : namespace_name\n                       | NS_SEPARATOR namespace_name\n                       | namespace_name AS STRING\n                       | NS_SEPARATOR namespace_name AS STRING'''\n    if len(p) == 2:\n        p[0] = ast.UseDeclaration(p[1], None, lineno=p.lineno(1))\n    elif len(p) == 3:\n        p[0] = ast.UseDeclaration(p[1] + p[2], None, lineno=p.lineno(1))\n    elif len(p) == 4:\n        p[0] = ast.UseDeclaration(p[1], p[3], lineno=p.lineno(2))\n    else:\n        p[0] = ast.UseDeclaration(p[1] + p[2], p[4], lineno=p.lineno(1))", "response": "use_declaration : namespace_name\n                       | NS_SEPARATOR namespace_name\n                       | namespace_name AS STRING\n                       | NS_SEPARATOR namespace_name AS STRING"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_constant_declaration(p):\n    'constant_declaration : STRING EQUALS static_scalar'\n    p[0] = ast.ConstantDeclaration(p[1], p[3], lineno=p.lineno(1))", "response": "isolate constant_declaration : STRING EQUALS static_scalar"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the IF statement.", "response": "def p_statement_if(p):\n    '''statement : IF LPAREN expr RPAREN statement elseif_list else_single\n                 | IF LPAREN expr RPAREN COLON inner_statement_list new_elseif_list new_else_single ENDIF SEMI'''\n    if len(p) == 8:\n        p[0] = ast.If(p[3], p[5], p[6], p[7], lineno=p.lineno(1))\n    else:\n        p[0] = ast.If(p[3], ast.Block(p[6], lineno=p.lineno(5)),\n                      p[7], p[8], lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_while(p):\n    'statement : WHILE LPAREN expr RPAREN while_statement'\n    p[0] = ast.While(p[3], p[5], lineno=p.lineno(1))", "response": "statement : WHILE LPAREN expr RPAREN while_statement"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_statement_do_while(p):\n    'statement : DO statement WHILE LPAREN expr RPAREN SEMI'\n    p[0] = ast.DoWhile(p[2], p[5], lineno=p.lineno(1))", "response": "statement : DO statement WHILE LPAREN expr RPAREN SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_statement_for(p):\n    'statement : FOR LPAREN for_expr SEMI for_expr SEMI for_expr RPAREN for_statement'\n    p[0] = ast.For(p[3], p[5], p[7], p[9], lineno=p.lineno(1))", "response": "statement : FOR LPAREN for_expr SEMI for_expr RPAREN for_statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_foreach(p):\n    'statement : FOREACH LPAREN expr AS foreach_variable foreach_optional_arg RPAREN foreach_statement'\n    if p[6] is None:\n        p[0] = ast.Foreach(p[3], None, p[5], p[8], lineno=p.lineno(1))\n    else:\n        p[0] = ast.Foreach(p[3], p[5], p[6], p[8], lineno=p.lineno(1))", "response": "statement : FOREACH LPAREN expr AS foreach_variable foreach_optional_arg RPAREN foreach_statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_break(p):\n    '''statement : BREAK SEMI\n                 | BREAK expr SEMI'''\n    if len(p) == 3:\n        p[0] = ast.Break(None, lineno=p.lineno(1))\n    else:\n        p[0] = ast.Break(p[2], lineno=p.lineno(1))", "response": "statement : BREAK SEMI\n                 | BREAK expr SEMI"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_statement_try(p):\n    'statement : TRY LBRACE inner_statement_list RBRACE CATCH LPAREN fully_qualified_class_name VARIABLE RPAREN LBRACE inner_statement_list RBRACE additional_catches'\n    p[0] = ast.Try(p[3], [ast.Catch(p[7], ast.Variable(p[8], lineno=p.lineno(8)),\n                                    p[11], lineno=p.lineno(5))] + p[13],\n                   lineno=p.lineno(1))", "response": "statement : TRY LBRACE inner_statement_list RBRACE CATCH LPAREN fully_qualified_class_name VARIABLE RPAREN RBRACE additional_catches"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_additional_catches(p):\n    '''additional_catches : additional_catches CATCH LPAREN fully_qualified_class_name VARIABLE RPAREN LBRACE inner_statement_list RBRACE\n                          | empty'''\n    if len(p) == 10:\n        p[0] = p[1] + [ast.Catch(p[4], ast.Variable(p[5], lineno=p.lineno(5)),\n                                 p[8], lineno=p.lineno(2))]\n    else:\n        p[0] = []", "response": "A helper function to add additional catches to the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_declare_list(p):\n    '''declare_list : STRING EQUALS static_scalar\n                    | declare_list COMMA STRING EQUALS static_scalar'''\n    if len(p) == 4:\n        p[0] = [ast.Directive(p[1], p[3], lineno=p.lineno(1))]\n    else:\n        p[0] = p[1] + [ast.Directive(p[3], p[5], lineno=p.lineno(2))]", "response": "declare_list : STRING EQUALS static_scalar\n                    | declare_list COMMA STRING EQUALS static_scalar"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a DECLARE statement.", "response": "def p_declare_statement(p):\n    '''declare_statement : statement\n                         | COLON inner_statement_list ENDDECLARE SEMI'''\n    if len(p) == 2:\n        p[0] = p[1]\n    else:\n        p[0] = ast.Block(p[2], lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_elseif_list(p):\n    '''elseif_list : empty\n                   | elseif_list ELSEIF LPAREN expr RPAREN statement'''\n    if len(p) == 2:\n        p[0] = []\n    else:\n        p[0] = p[1] + [ast.ElseIf(p[4], p[6], lineno=p.lineno(2))]", "response": "elseif_list : empty\n                   | elseif_list ELSEIF LPAREN expr RPAREN statement"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_else_single(p):\n    '''else_single : empty\n                   | ELSE statement'''\n    if len(p) == 3:\n        p[0] = ast.Else(p[2], lineno=p.lineno(1))", "response": "A function to handle the case where the first element is an empty item."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the new_elseif_list statement.", "response": "def p_new_elseif_list(p):\n    '''new_elseif_list : empty\n                       | new_elseif_list ELSEIF LPAREN expr RPAREN COLON inner_statement_list'''\n    if len(p) == 2:\n        p[0] = []\n    else:\n        p[0] = p[1] + [ast.ElseIf(p[4], ast.Block(p[7], lineo=p.lineno(6)),\n                                  lineno=p.lineno(2))]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_new_else_single(p):\n    '''new_else_single : empty\n                       | ELSE COLON inner_statement_list'''\n    if len(p) == 4:\n        p[0] = ast.Else(ast.Block(p[3], lineno=p.lineno(2)),\n                        lineno=p.lineno(1))", "response": "new_else_single : empty\n                       | ELSE COLON inner_statement_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a while statement.", "response": "def p_while_statement(p):\n    '''while_statement : statement\n                       | COLON inner_statement_list ENDWHILE SEMI'''\n    if len(p) == 2:\n        p[0] = p[1]\n    else:\n        p[0] = ast.Block(p[2], lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_for_statement(p):\n    '''for_statement : statement\n                     | COLON inner_statement_list ENDFOR SEMI'''\n    if len(p) == 2:\n        p[0] = p[1]\n    else:\n        p[0] = ast.Block(p[2], lineno=p.lineno(1))", "response": "for_statement : statement\n                     | COLON inner_statement_list ENDFOR SEMI"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_foreach_statement(p):\n    '''foreach_statement : statement\n                         | COLON inner_statement_list ENDFOREACH SEMI'''\n    if len(p) == 2:\n        p[0] = p[1]\n    else:\n        p[0] = ast.Block(p[2], lineno=p.lineno(1))", "response": "Parse a foreach statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_case_list(p):\n    '''case_list : empty\n                 | case_list CASE expr case_separator inner_statement_list\n                 | case_list DEFAULT case_separator inner_statement_list'''\n    if len(p) == 6:\n        p[0] = p[1] + [ast.Case(p[3], p[5], lineno=p.lineno(2))]\n    elif len(p) == 5:\n        p[0] = p[1] + [ast.Default(p[4], lineno=p.lineno(2))]\n    else:\n        p[0] = []", "response": "Pattern for case list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_global_var(p):\n    '''global_var : VARIABLE\n                  | DOLLAR variable\n                  | DOLLAR LBRACE expr RBRACE'''\n    if len(p) == 2:\n        p[0] = ast.Variable(p[1], lineno=p.lineno(1))\n    elif len(p) == 3:\n        p[0] = ast.Variable(p[2], lineno=p.lineno(1))\n    else:\n        p[0] = ast.Variable(p[3], lineno=p.lineno(1))", "response": "parse global_var | global_var | global_var | variable\n                  | variable\n                  | DOLLAR LBRACE expr RBRACE"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_static_var(p):\n    '''static_var : VARIABLE EQUALS static_scalar\n                  | VARIABLE'''\n    if len(p) == 4:\n        p[0] = ast.StaticVariable(p[1], p[3], lineno=p.lineno(1))\n    else:\n        p[0] = ast.StaticVariable(p[1], None, lineno=p.lineno(1))", "response": "static_var : VARIABLE EQUALS static_scalar\n                  | VARIABLE"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_function_declaration_statement(p):\n    'function_declaration_statement : FUNCTION is_reference STRING LPAREN parameter_list RPAREN LBRACE inner_statement_list RBRACE'\n    p[0] = ast.Function(p[3], p[5], p[8], p[2], lineno=p.lineno(1))", "response": "is_reference STRING LPAREN parameter_list RPAREN inner_statement_list RBRACE"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a class declaration statement.", "response": "def p_class_declaration_statement(p):\n    '''class_declaration_statement : class_entry_type STRING extends_from implements_list LBRACE class_statement_list RBRACE\n                                   | INTERFACE STRING interface_extends_list LBRACE class_statement_list RBRACE'''\n    if len(p) == 8:\n        p[0] = ast.Class(p[2], p[1], p[3], p[4], p[6], lineno=p.lineno(2))\n    else:\n        p[0] = ast.Interface(p[2], p[3], p[5], lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_fully_qualified_class_name(p):\n    '''fully_qualified_class_name : namespace_name\n                                  | NS_SEPARATOR namespace_name\n                                  | NAMESPACE NS_SEPARATOR namespace_name'''\n    if len(p) == 2:\n        p[0] = p[1]\n    elif len(p) == 3:\n        p[0] = p[1] + p[2]\n    else:\n        p[0] = p[1] + p[2] + p[3]", "response": "fully_qualified_class_name is a version of the fully qualified class name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a class statement.", "response": "def p_class_statement(p):\n    '''class_statement : method_modifiers FUNCTION is_reference STRING LPAREN parameter_list RPAREN method_body\n                       | comment\n                       | variable_modifiers class_variable_declaration SEMI\n                       | class_constant_declaration SEMI'''\n    if len(p) == 9:\n        p[0] = ast.Method(p[4], p[1], p[6], p[8], p[3], lineno=p.lineno(2))\n    elif len(p) == 4:\n        p[0] = ast.ClassVariables(p[1], p[2], lineno=p.lineno(3))\n    elif len(p) == 2:\n        p[0] = p[1]\n    else:\n        p[0] = ast.ClassConstants(p[1], lineno=p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_class_variable_declaration_initial(p):\n    '''class_variable_declaration : class_variable_declaration COMMA VARIABLE EQUALS static_scalar\n                                  | VARIABLE EQUALS static_scalar'''\n    if len(p) == 6:\n        p[0] = p[1] + [ast.ClassVariable(p[3], p[5], lineno=p.lineno(2))]\n    else:\n        p[0] = [ast.ClassVariable(p[1], p[3], lineno=p.lineno(1))]", "response": "Class variable declaration initial tokenization."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_class_variable_declaration_no_initial(p):\n    '''class_variable_declaration : class_variable_declaration COMMA VARIABLE\n                                  | VARIABLE'''\n    if len(p) == 4:\n        p[0] = p[1] + [ast.ClassVariable(p[3], None, lineno=p.lineno(2))]\n    else:\n        p[0] = [ast.ClassVariable(p[1], None, lineno=p.lineno(1))]", "response": "Class variable declaration with no initial value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_class_constant_declaration(p):\n    '''class_constant_declaration : class_constant_declaration COMMA STRING EQUALS static_scalar\n                                  | CONST STRING EQUALS static_scalar'''\n    if len(p) == 6:\n        p[0] = p[1] + [ast.ClassConstant(p[3], p[5], lineno=p.lineno(2))]\n    else:\n        p[0] = [ast.ClassConstant(p[2], p[4], lineno=p.lineno(1))]", "response": "class_constant_declaration : class_constant_declaration COMMA STRING EQUALS static_scalar\n                                  | CONST STRING EQUALS static_scalar"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_parameter(p):\n    '''parameter : VARIABLE\n                 | class_name VARIABLE\n                 | ARRAY VARIABLE\n                 | AND VARIABLE\n                 | class_name AND VARIABLE\n                 | ARRAY AND VARIABLE\n                 | VARIABLE EQUALS static_scalar\n                 | class_name VARIABLE EQUALS static_scalar\n                 | ARRAY VARIABLE EQUALS static_scalar\n                 | AND VARIABLE EQUALS static_scalar\n                 | class_name AND VARIABLE EQUALS static_scalar\n                 | ARRAY AND VARIABLE EQUALS static_scalar'''\n    if len(p) == 2: # VARIABLE\n        p[0] = ast.FormalParameter(p[1], None, False, None, lineno=p.lineno(1))\n    elif len(p) == 3 and p[1] == '&': # AND VARIABLE\n        p[0] = ast.FormalParameter(p[2], None, True, None, lineno=p.lineno(1))\n    elif len(p) == 3 and p[1] != '&': # STRING VARIABLE\n        p[0] = ast.FormalParameter(p[2], None, False, p[1], lineno=p.lineno(1))\n    elif len(p) == 4 and p[2] != '&': # VARIABLE EQUALS static_scalar\n        p[0] = ast.FormalParameter(p[1], p[3], False, None, lineno=p.lineno(1))\n    elif len(p) == 4 and p[2] == '&': # STRING AND VARIABLE\n        p[0] = ast.FormalParameter(p[3], None, True, p[1], lineno=p.lineno(1))\n    elif len(p) == 5 and p[1] == '&': # AND VARIABLE EQUALS static_scalar\n        p[0] = ast.FormalParameter(p[2], p[4], True, None, lineno=p.lineno(1))\n    elif len(p) == 5 and p[1] != '&': # STRING VARIABLE EQUALS static_scalar\n        p[0] = ast.FormalParameter(p[2], p[4], False, p[1], lineno=p.lineno(1))\n    else: # STRING AND VARIABLE EQUALS static_scalar\n        p[0] = ast.FormalParameter(p[3], p[5], True, p[1], lineno=p.lineno(1))", "response": "parses the parameter section of the grammar"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_expr_assign(p):\n    '''expr : variable EQUALS expr\n            | variable EQUALS AND expr'''\n    if len(p) == 5:\n        p[0] = ast.Assignment(p[1], p[4], True, lineno=p.lineno(2))\n    else:\n        p[0] = ast.Assignment(p[1], p[3], False, lineno=p.lineno(2))", "response": "expr : variable EQUALS expr\n            | variable EQUALS AND expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_expr_new(p):\n    'expr : NEW class_name_reference ctor_arguments'\n    p[0] = ast.New(p[2], p[3], lineno=p.lineno(1))", "response": "expr : NEW class_name_reference ctor_arguments"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_class_name(p):\n    '''class_name : namespace_name\n                  | NS_SEPARATOR namespace_name\n                  | NAMESPACE NS_SEPARATOR namespace_name'''\n    if len(p) == 2:\n        p[0] = p[1]\n    elif len(p) == 3:\n        p[0] = p[1] + p[2]\n    else:\n        p[0] = p[1] + p[2] + p[3]", "response": "class_name is a list of strings where each string is a namespace name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_expr_list_assign(p):\n    'expr : LIST LPAREN assignment_list RPAREN EQUALS expr'\n    p[0] = ast.ListAssignment(p[3], p[6], lineno=p.lineno(1))", "response": "expr : LIST LPAREN assignment_list RPAREN EQUALS expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_function_call(p):\n    '''function_call : namespace_name LPAREN function_call_parameter_list RPAREN\n                     | NS_SEPARATOR namespace_name LPAREN function_call_parameter_list RPAREN\n                     | NAMESPACE NS_SEPARATOR namespace_name LPAREN function_call_parameter_list RPAREN'''\n    if len(p) == 5:\n        p[0] = ast.FunctionCall(p[1], p[3], lineno=p.lineno(2))\n    elif len(p) == 6:\n        p[0] = ast.FunctionCall(p[1] + p[2], p[4], lineno=p.lineno(1))\n    else:\n        p[0] = ast.FunctionCall(p[1] + p[2] + p[3], p[5], lineno=p.lineno(1))", "response": "function_call : namespace_name LPAREN function_call_parameter_list RPAREN\n                     | NS_SEPARATOR namespace_name LPAREN function_call_parameter_list RPAREN\n                     | NAMESPACE NS_SEPARATOR namespace_name LPAREN function_call_parameter_list RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a function call in a static method.", "response": "def p_function_call_static(p):\n    '''function_call : class_name DOUBLE_COLON STRING LPAREN function_call_parameter_list RPAREN\n                     | class_name DOUBLE_COLON variable_without_objects LPAREN function_call_parameter_list RPAREN\n                     | variable_class_name DOUBLE_COLON STRING LPAREN function_call_parameter_list RPAREN\n                     | variable_class_name DOUBLE_COLON variable_without_objects LPAREN function_call_parameter_list RPAREN'''\n    p[0] = ast.StaticMethodCall(p[1], p[3], p[5], lineno=p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_function_call_variable(p):\n    'function_call : variable_without_objects LPAREN function_call_parameter_list RPAREN'\n    p[0] = ast.FunctionCall(p[1], p[3], lineno=p.lineno(2))", "response": "function_call : variable_without_objects LPAREN function_call_parameter_list RPAREN"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_static_member(p):\n    '''static_member : class_name DOUBLE_COLON variable_without_objects\n                     | variable_class_name DOUBLE_COLON variable_without_objects'''\n    p[0] = ast.StaticProperty(p[1], p[3], lineno=p.lineno(2))", "response": "static_member : class_name DOUBLE_COLON variable_without_objects\n                     | variable_class_name DOUBLE_COLON variable_without_objects"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nisolate reference_variable LBRACKET dim_offset RBRACKET", "response": "def p_reference_variable_array_offset(p):\n    'reference_variable : reference_variable LBRACKET dim_offset RBRACKET'\n    p[0] = ast.ArrayOffset(p[1], p[3], lineno=p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nisolating reference_variable LBRACE expr RBRACE", "response": "def p_reference_variable_string_offset(p):\n    'reference_variable : reference_variable LBRACE expr RBRACE'\n    p[0] = ast.StringOffset(p[1], p[3], lineno=p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_non_empty_array_pair_list_item(p):\n    '''non_empty_array_pair_list : non_empty_array_pair_list COMMA AND variable\n                                 | non_empty_array_pair_list COMMA expr\n                                 | AND variable\n                                 | expr'''\n    if len(p) == 5:\n        p[0] = p[1] + [ast.ArrayElement(None, p[4], True, lineno=p.lineno(2))]\n    elif len(p) == 4:\n        p[0] = p[1] + [ast.ArrayElement(None, p[3], False, lineno=p.lineno(2))]\n    elif len(p) == 3:\n        p[0] = [ast.ArrayElement(None, p[2], True, lineno=p.lineno(1))]\n    else:\n        p[0] = [ast.ArrayElement(None, p[1], False, lineno=p.lineno(1))]", "response": "parse non - empty array pair list item"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses non - empty array pair list pair", "response": "def p_non_empty_array_pair_list_pair(p):\n    '''non_empty_array_pair_list : non_empty_array_pair_list COMMA expr DOUBLE_ARROW AND variable\n                                 | non_empty_array_pair_list COMMA expr DOUBLE_ARROW expr\n                                 | expr DOUBLE_ARROW AND variable\n                                 | expr DOUBLE_ARROW expr'''\n    if len(p) == 7:\n        p[0] = p[1] + [ast.ArrayElement(p[3], p[6], True, lineno=p.lineno(2))]\n    elif len(p) == 6:\n        p[0] = p[1] + [ast.ArrayElement(p[3], p[5], False, lineno=p.lineno(2))]\n    elif len(p) == 5:\n        p[0] = [ast.ArrayElement(p[1], p[4], True, lineno=p.lineno(2))]\n    else:\n        p[0] = [ast.ArrayElement(p[1], p[3], False, lineno=p.lineno(2))]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_function_call_parameter(p):\n    '''function_call_parameter : expr\n                               | AND variable'''\n    if len(p) == 2:\n        p[0] = ast.Parameter(p[1], False, lineno=p.lineno(1))\n    else:\n        p[0] = ast.Parameter(p[2], True, lineno=p.lineno(1))", "response": "function_call_parameter | expr\n                               | AND variable"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an assignment operator.", "response": "def p_expr_assign_op(p):\n    '''expr : variable PLUS_EQUAL expr\n            | variable MINUS_EQUAL expr\n            | variable MUL_EQUAL expr\n            | variable DIV_EQUAL expr\n            | variable CONCAT_EQUAL expr\n            | variable MOD_EQUAL expr\n            | variable AND_EQUAL expr\n            | variable OR_EQUAL expr\n            | variable XOR_EQUAL expr\n            | variable SL_EQUAL expr\n            | variable SR_EQUAL expr'''\n    p[0] = ast.AssignOp(p[2], p[1], p[3], lineno=p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expr_binary_op(p):\n    '''expr : expr BOOLEAN_AND expr\n            | expr BOOLEAN_OR expr\n            | expr LOGICAL_AND expr\n            | expr LOGICAL_OR expr\n            | expr LOGICAL_XOR expr\n            | expr AND expr\n            | expr OR expr\n            | expr XOR expr\n            | expr CONCAT expr\n            | expr PLUS expr\n            | expr MINUS expr\n            | expr MUL expr\n            | expr DIV expr\n            | expr SL expr\n            | expr SR expr\n            | expr MOD expr\n            | expr IS_IDENTICAL expr\n            | expr IS_NOT_IDENTICAL expr\n            | expr IS_EQUAL expr\n            | expr IS_NOT_EQUAL expr\n            | expr IS_SMALLER expr\n            | expr IS_SMALLER_OR_EQUAL expr\n            | expr IS_GREATER expr\n            | expr IS_GREATER_OR_EQUAL expr\n            | expr INSTANCEOF expr'''\n    p[0] = ast.BinaryOp(p[2].lower(), p[1], p[3], lineno=p.lineno(2))", "response": "Parse expr binary operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_expr_unary_op(p):\n    '''expr : PLUS expr\n            | MINUS expr\n            | NOT expr\n            | BOOLEAN_NOT expr'''\n    p[0] = ast.UnaryOp(p[1], p[2], lineno=p.lineno(1))", "response": "expr : PLUS expr\n            | MINUS expr\n            | NOT expr\n            | BOOLEAN_NOT expr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_expr_ternary_op(p):\n    'expr : expr QUESTION expr COLON expr'\n    p[0] = ast.TernaryOp(p[1], p[3], p[5], lineno=p.lineno(2))", "response": "expr : expr QUESTION expr COLON expr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an expression exit.", "response": "def p_expr_exit(p):\n    '''expr : EXIT\n            | EXIT LPAREN RPAREN\n            | EXIT LPAREN expr RPAREN'''\n    if len(p) == 5:\n        p[0] = ast.Exit(p[3], lineno=p.lineno(1))\n    else:\n        p[0] = ast.Exit(None, lineno=p.lineno(1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_class_constant(p):\n    '''class_constant : class_name DOUBLE_COLON STRING\n                      | variable_class_name DOUBLE_COLON STRING'''\n    p[0] = ast.StaticProperty(p[1], p[3], lineno=p.lineno(2))", "response": "class_constant : class_name DOUBLE_COLON STRING\n                      | variable_class_name DOUBLE_COLON STRING"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_common_scalar_magic_dir(p):\n    'common_scalar : DIR'\n    value = getattr(p.lexer, 'filename', None)\n    if value is not None:\n        value = os.path.dirname(value)\n    p[0] = ast.MagicConstant(p[1].upper(), value, lineno=p.lineno(1))", "response": "Common scalar magic dir"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_common_scalar_magic_method(p):\n    'common_scalar : METHOD_C'\n    p[0] = ast.MagicConstant(p[1].upper(), None, lineno=p.lineno(1))", "response": "Common scalar magic method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_static_scalar(p):\n    '''static_scalar : common_scalar\n                     | QUOTE QUOTE\n                     | QUOTE ENCAPSED_AND_WHITESPACE QUOTE'''\n    if len(p) == 2:\n        p[0] = p[1]\n    elif len(p) == 3:\n        p[0] = ''\n    else:\n        p[0] = p[2].decode('string_escape')", "response": "static_scalar is a special case for the static_scalar field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_static_scalar_unary_op(p):\n    '''static_scalar : PLUS static_scalar\n                     | MINUS static_scalar'''\n    p[0] = ast.UnaryOp(p[1], p[2], lineno=p.lineno(1))", "response": "static_scalar : PLUS static_scalar\n                     | MINUS static_scalar"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_static_non_empty_array_pair_list_item(p):\n    '''static_non_empty_array_pair_list : static_non_empty_array_pair_list COMMA static_scalar\n                                        | static_scalar'''\n    if len(p) == 4:\n        p[0] = p[1] + [ast.ArrayElement(None, p[3], False, lineno=p.lineno(2))]\n    else:\n        p[0] = [ast.ArrayElement(None, p[1], False, lineno=p.lineno(1))]", "response": "static_non_empty_array_pair_list : static_non_empty_array_pair_list COMMA static_scalar\n                                        | static_scalar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the encaps_list expression.", "response": "def p_encaps_list(p):\n    '''encaps_list : encaps_list encaps_var\n                   | empty'''\n    if len(p) == 3:\n        if p[1] == '':\n            p[0] = p[2]\n        else:\n            p[0] = ast.BinaryOp('.', p[1], p[2], lineno=p.lineno(2))\n    else:\n        p[0] = ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_encaps_list_string(p):\n    'encaps_list : encaps_list ENCAPSED_AND_WHITESPACE'\n    if p[1] == '':\n        p[0] = p[2].decode('string_escape')\n    else:\n        p[0] = ast.BinaryOp('.', p[1], p[2].decode('string_escape'),\n                            lineno=p.lineno(2))", "response": "encaps_list : encaps_list ENCAPSED_AND_WHITESPACE"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_encaps_var_object_property(p):\n    'encaps_var : VARIABLE OBJECT_OPERATOR STRING'\n    p[0] = ast.ObjectProperty(ast.Variable(p[1], lineno=p.lineno(1)), p[3],\n                              lineno=p.lineno(2))", "response": "encaps_var : VARIABLE OBJECT_OPERATOR STRING"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef listify(args):\n    if args:\n        if isinstance(args, list):\n            return args\n        elif isinstance(args, (set, tuple, GeneratorType,\n                               range, past.builtins.xrange)):\n            return list(args)\n        return [args]\n    return []", "response": "Return args as a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_censor_file(input_dset,out_prefix=None,fraction=0.1,clip_to=0.1,max_exclude=0.3,motion_file=None,motion_exclude=1.0):\n    '''create a binary censor file using 3dToutcount\n\n    :input_dset:        the input dataset\n    :prefix:            output 1D file (default: ``prefix(input_dset)`` + ``.1D``)\n    :fraction:          censor a timepoint if proportional of outliers in this\n                        time point is greater than given value\n    :clip_to:           keep the number of time points censored under this proportion\n                        of total reps. If more time points would be censored,\n                        it will only pick the top ``clip_to*reps`` points\n    :max_exclude:       if more time points than the given proportion of reps are excluded for the\n                        entire run, throw an exception -- something is probably wrong\n    :motion_file:       optional filename of a \"motion\" file with multiple columns and rows corresponding to reps.\n                        It doesn't really matter what the values are, as long as they are appropriate relative to ``motion_exclude``\n    :motion_exclude:    Will exclude any reps that have a value greater than this in any column of ``motion_file``\n    '''\n    (outcount,perc_outliers) = nl.qc.outcount(input_dset,fraction)\n    info = nl.dset_info(input_dset)\n    binarize = lambda o,f: [oo<f for oo in o]\n    perc_outliers = lambda o: 1.-(sum(o)/float(info.reps))\n\n    if motion_file:\n        with open(motion_file,'Ur') as f:\n            motion = [max([float(y) for y in x.strip().split()]) for x in f.read().split('\\n') if len(x.strip())>0 and x.strip()[0]!='#']\n            motion_1D = [x for x in binarize(motion,motion_exclude)]\n            if perc_outliers(motion_1D) > max_exclude:\n                nl.notify('Error: Too many points excluded because of motion (%.2f) in dset %s' % (perc_outliers(motion_1D),input_dset),level=nl.level.error)\n                return False\n            outcount = [outcount[i] if motion_1D[i] else 1. for i in range(len(outcount))]\n\n    binary_outcount = binarize(outcount,fraction)\n\n    if max_exclude and perc_outliers(binary_outcount) > max_exclude:\n        nl.notify('Error: Found %.1f%% outliers in dset %s' % (100*perc_outliers(outcount),input_dset),level=nl.level.error)\n        return False\n    if clip_to:\n        while perc_outliers(binary_outcount) > clip_to:\n            best_outlier = min([(outcount[i],i) for i in range(len(outcount)) if not binary_outcount[i]])\n            binary_outcount[best_outlier[1]] = True\n    if not out_prefix:\n        out_prefix = nl.prefix(input_dset) + '.1D'\n    with open(out_prefix,'w') as f:\n        f.write('\\n'.join([str(int(x)) for x in binary_outcount]))\n    return True", "response": "create a binary censor file using 3dToutcount"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pkg_available(pkg_name,required=False):\n    '''tests if analysis package is available on this machine (e.g., \"afni\" or \"fsl\"), and prints an error if ``required``'''\n    if pkg_name in pkgs:\n        return True\n    if required:\n        nl.notify('Error: could not find required analysis package %s' % pkg_name,level=nl.level.error)\n    return False", "response": "tests if an analysis package is available on this machine and prints an error if required is True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef available_method(method_name):\n    '''ruturn the method for earliest package in ``pkg_preferences``, if package is available (based on :meth:`pkg_available`)'''\n    pkg_prefs_copy = list(pkg_prefs)\n    if method_name in method_prefs:\n        pkg_prefs_copy = [method_prefs[method_name]] + pkg_prefs_copy\n    for pkg in pkg_prefs_copy:\n        if pkg in pkgs:\n            if method_name in dir(pkgs[pkg]):\n                return getattr(pkgs[pkg],method_name)\n    nl.notify('Error: Could not find implementation of %s on this computer' % (method_name),level=nl.level.error)", "response": "ruturn the method for earliest package in pkg_preferences"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string that can be used to calculate a single expression in a sequence of strings.", "response": "def calc(dsets,expr,prefix=None,datum=None):\n    ''' returns a string of an inline ``3dcalc``-style expression\n\n    ``dsets`` can be a single string, or list of strings. Each string in ``dsets`` will\n    be labeled 'a','b','c', sequentially. The expression ``expr`` is used directly\n\n    If ``prefix`` is not given, will return a 3dcalc string that can be passed to another\n    AFNI program as a dataset. Otherwise, will create the dataset with the name ``prefix``'''\n    return available_method('calc')(dsets,expr,prefix,datum)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef thresh(dset,p,positive_only=False,prefix=None):\n    ''' returns a string containing an inline ``3dcalc`` command that thresholds the\n        given dataset at the specified *p*-value, or will create a new dataset if a\n        suffix or prefix is given '''\n    return available_method('thresh')(dset,p,positive_only,prefix)", "response": "returns a string that will create a new dataset at the specified p * - value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cluster(dset,min_distance,min_cluster_size,prefix=None):\n    '''clusters given ``dset`` connecting voxels ``min_distance``mm away with minimum cluster size of ``min_cluster_size``\n    default prefix is ``dset`` suffixed with ``_clust%d``'''\n    if prefix==None:\n        prefix = nl.suffix(dset,'_clust%d' % min_cluster_size)\n    return available_method('cluster')(dset,min_distance,min_cluster_size,prefix)", "response": "clusters given dset connecting voxels away with minimum cluster size of min_cluster_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nblurs dataset with given fwhm runs 3dmerge to blur dataset to given fwhm", "response": "def blur(dset,fwhm,prefix=None):\n    '''blurs ``dset`` with given ``fwhm`` runs 3dmerge to blur dataset to given ``fwhm``\n    default ``prefix`` is to suffix ``dset`` with ``_blur%.1fmm``'''\n    if prefix==None:\n        prefix = nl.suffix(dset,'_blur%.1fmm'%fwhm)\n    return available_method('blur')(dset,fwhm,prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to cleanly remove skull from dset", "response": "def skull_strip(dset,suffix='_ns',prefix=None,unifize=True):\n    '''attempts to cleanly remove skull from ``dset``'''\n    return available_method('skull_strip')(dset,suffix,prefix,unifize)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrefreshes the view of the log group", "response": "def do_refresh(self,args):\n        \"\"\"Refresh the view of the log group\"\"\"\n        print \"stackResource: {}\".format(self.stackResource)\n        \n        self.roleDetails = AwsConnectionFactory.getIamClient().get_role(RoleName=self.stackResource.physical_resource_id)\n        print \"== role details ==\"\n        pprint(self.roleDetails)\n\n        self.rolePolicies = self.loadRolePolicies()\n        print \"== attached policies ==\"\n        pprint(self.rolePolicies)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collect_manifest_dependencies(manifest_data, lockfile_data):\n    output = {}\n\n    for dependencyName, dependencyConstraint in manifest_data.items():\n        output[dependencyName] = {\n            # identifies where this dependency is installed from\n            'source': 'example-package-manager',\n            # the constraint that the user is using (i.e. \"> 1.0.0\")\n            'constraint': dependencyConstraint,\n            # all available versions above and outside of their constraint\n            # - usually you would need to use the package manager lib or API\n            #   to get this information (we just fake it here)\n            'available': [\n                {'name': '2.0.0'},\n            ],\n        }\n\n    return output", "response": "Convert the manifest format to the dependencies schema"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collect_lockfile_dependencies(lockfile_data):\n    output = {}\n\n    for dependencyName, installedVersion in lockfile_data.items():\n        output[dependencyName] = {\n            'source': 'example-package-manager',\n            'installed': {'name': installedVersion},\n        }\n\n    return output", "response": "Convert the lockfile format to the dependencies schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the most similar matching item from a list of items.", "response": "def match_similar(base, items):\n    \"\"\"Get the most similar matching item from a list of items.\n\n    @param base: base item to locate best match\n    @param items: list of items for comparison\n    @return: most similar matching item or None\n\n    \"\"\"\n    finds = list(find_similar(base, items))\n    if finds:\n        return max(finds, key=base.similarity)  # TODO: make O(n)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef duplicates(base, items):\n    for item in items:\n        if item.similarity(base) and not item.equality(base):\n            yield item", "response": "Get an iterator of items similar but not equal to the base item"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of items ranked in descending similarity.", "response": "def sort(base, items):\n    \"\"\"Get a sorted list of items ranked in descending similarity.\n\n    @param base: base item to perform comparison against\n    @param items: list of items to compare to the base\n    @return: list of items sorted by similarity to the base\n\n    \"\"\"\n    return sorted(items, key=base.similarity, reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef term(term, xpath=None, escape=True):\n    prefix = []\n    postfix = []\n    if xpath:\n        tags = xpath.split('/')\n        for tag in tags:\n            if tag:\n                prefix.append('<{0}>'.format(tag))\n                postfix.insert(0, '</{0}>'.format(tag))\n    if escape:\n        term = cgi.escape(term)\n    return ''.join(prefix + [term] + postfix)", "response": "Returns an XML string that contains the given term."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef terms_from_dict(source):\n    parsed = ''\n    for xpath, text in source.items():\n        if hasattr(text, 'keys'):\n            parsed += term(terms_from_dict(text), xpath, escape=False)\n        else:\n            parsed += term(text, xpath)\n    return parsed", "response": "Convert a dict representing a query to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef and_terms(*args):\n    args = [arg if not isinstance(arg, list) else ' '.join(arg) for arg in args]\n    return '({0})'.format(' '.join(args))", "response": "Connect given term strings or list of strings representing query terms and return a query string consisting of argument terms anded together."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef or_terms(*args):\n    args = [arg if not isinstance(arg, list) else ' '.join(arg) for arg in args]\n    return '{{{0}}}'.format(' '.join(args))", "response": "Connect given term strings or list of strings representing query terms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_format_iso8601(validator, fieldname, value, format_option):\n    try:\n        iso8601.parse_date(value)\n    except ValueError:\n        raise ValidationError(\n            \"Value %(value)r of field '%(fieldname)s' is not in \"\n            \"'iso8601 YYYY-MM-DDThh:mm:ss(+/-)hh:mm' format\" % locals())", "response": "Raises ValidationError if value is not in the format ISO - 8601 eg #\"2007 -06 - 20T12 - 34 : 40 + 03 - 03"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef json_schema_validation_format(value, schema_validation_type):\n    DEFAULT_FORMAT_VALIDATORS['date-time'] = validate_format_iso8601\n    DEFAULT_FORMAT_VALIDATORS['text'] = validate_format_text\n    validictory.validate(value, schema_validation_type, format_validators=DEFAULT_FORMAT_VALIDATORS)", "response": "Validate that value is in the format specified by schema_validation_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_signature(name, func):\n    args, varargs, keywords, defaults = inspect.getargspec(func)\n    defaults = defaults or []\n    posargslen = len(args) - len(defaults)\n    if varargs is None and keywords is None:\n        sig = name + '('\n        sigargs = []\n        for idx, arg in enumerate(args):\n            if idx < posargslen:\n                sigargs.append(arg)\n            else:\n                default = repr(defaults[idx - posargslen])\n                sigargs.append(arg + '=' + default)\n        sig += ', '.join(sigargs) + ')'\n        return sig\n    elif not args and varargs and not keywords and not defaults:\n        return name + '(*' + varargs + ')'\n    else:\n        raise InvalidTask('ape tasks may not use **kwargs')", "response": "Helper to generate a readable signature for a function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(cls, color):\n        sys.stdout.write(cls.colors.get(color, cls.colors['RESET']))", "response": "Sets the terminal to the passed color."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, func):\n\n        if hasattr(self._tasks, func.__name__):\n            raise TaskAlreadyRegistered(func.__name__)\n        setattr(self._tasks, func.__name__, func)\n        return _get_invalid_accessor(func.__name__)", "response": "Register a task. Typically used as a decorator to the task function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a function as a helper", "response": "def register_helper(self, func):\n        \"\"\"\n        A helper is a task that is not directly exposed to\n        the command line\n        :param func: registers func as a helper\n        :return: invalid accessor\n        \"\"\"\n\n        self._helper_names.add(func.__name__)\n        return self.register(func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of tuples.", "response": "def get_tasks(self):\n        \"\"\"\n        Return tasks as list of (name, function) tuples.\n        \"\"\"\n\n        def predicate(item):\n            return (inspect.isfunction(item) and\n                    item.__name__ not in self._helper_names)\n        return inspect.getmembers(self._tasks, predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_task(self, name, include_helpers=True):\n\n        if not include_helpers and name in self._helper_names:\n            raise TaskNotFound(name)\n        try:\n            return getattr(self._tasks, name)\n        except AttributeError:\n            raise TaskNotFound(name)", "response": "Get the task identified by name or raise TaskNotFound if there is no such task."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the help for the passed task with the passed name.", "response": "def print_task_help(self, task, name):\n        \"\"\"\n        Prints the help for the passed task with the passed name.\n        :param task: the task function object\n        :param name: the name of the module.\n        :return: None\n        \"\"\"\n        TerminalColor.set('GREEN')\n        print(get_signature(name, task))\n\n        # TODO: print the location does not work properly and sometimes returns None\n        # print('    => defined in: {}'.format(inspect.getsourcefile(task)))\n        help_msg = inspect.getdoc(task) or ''\n        TerminalColor.reset()\n        print('   ' + help_msg.replace('\\n', '\\n   '))\n        TerminalColor.reset()\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef help(self, taskname=None):\n\n        if not taskname:\n            print(inspect.getdoc(self._tasks))\n            print()\n            print('Available tasks:')\n            print()\n\n            for task in self.get_tasks():\n                self.print_task_help(task[1], task[0])\n        else:\n            try:\n                task = self.get_task(taskname)\n                self.print_task_help(task, task.__name__)\n\n            except TaskNotFound:\n                print('Task \"%s\" not found! Use \"ape help\" to get usage information.' % taskname)", "response": "Prints help for all available tasks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsuperimposing a task module on registered tasks''' :param module: ape tasks module that is superimposed on available ape tasks :return: None", "response": "def superimpose(self, module):\n        \"\"\"\n        superimpose a task module on registered tasks'''\n        :param module: ape tasks module that is superimposed on available ape tasks\n        :return: None\n        \"\"\"\n        featuremonkey.compose(module, self._tasks)\n        self._tasks.FEATURE_SELECTION.append(module.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclassing method that returns all defined arguments within the class.", "response": "def props(cls):\n    \"\"\"\n    Class method that returns all defined arguments within the class.\n    \n    Returns:\n      A dictionary containing all action defined arguments (if any).\n    \"\"\"\n    return {k:v for (k, v) in inspect.getmembers(cls) if type(v) is Argument}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npurges old logs from the database table", "response": "def purge_old_logs(delete_before_days=7):\n    \"\"\"\n    Purges old logs from the database table\n    \"\"\"\n    delete_before_date = timezone.now() - timedelta(days=delete_before_days)\n    logs_deleted = Log.objects.filter(\n        created_on__lte=delete_before_date).delete()\n    return logs_deleted"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npurges old event logs from the database table", "response": "def purge_old_event_logs(delete_before_days=7):\n    \"\"\"\n    Purges old event logs from the database table\n    \"\"\"\n    delete_before_date = timezone.now() - timedelta(days=delete_before_days)\n    logs_deleted = EventLog.objects.filter(\n        created_on__lte=delete_before_date).delete()\n    return logs_deleted"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef purge_old_request_logs(delete_before_days=7):\n    delete_before_date = timezone.now() - timedelta(days=delete_before_days)\n    logs_deleted = RequestLog.objects.filter(\n        created_on__lte=delete_before_date).delete()\n    return logs_deleted", "response": "Purges old request logs from the database table\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sigmafilter(data, sigmas, passes):\r\n    for n in range(passes):\r\n        meandata = np.mean(data[~np.isnan(data)])\r\n        sigma = np.std(data[~np.isnan(data)])\r\n        data[data > meandata+sigmas*sigma] = np.nan\r\n        data[data < meandata-sigmas*sigma] = np.nan\r\n    return data", "response": "Remove datapoints outside of a specified standard deviation range."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef psd(t, data, window=None, n_band_average=1):\r\n    dt = t[1] - t[0]\r\n    N = len(data)\r\n    data = data - np.mean(data)\r\n    if window == \"Hanning\":\r\n        data = data*np.hanning(N)\r\n    f = np.fft.fftfreq(N, dt)\r\n    y = np.fft.fft(data)\r\n    f = f[0:N/2]\r\n    psd = (2*dt/N)*abs(y)**2\r\n    psd = np.real(psd[0:N/2])\r\n    if n_band_average > 1:\r\n        f_raw, s_raw = f*1, psd*1\r\n        f = np.zeros(len(f_raw)//n_band_average)\r\n        psd = np.zeros(len(f_raw)//n_band_average)\r\n        for n in range(len(f_raw)//n_band_average):\r\n            f[n] = np.mean(f_raw[n*n_band_average:(n+1)*n_band_average])\r\n            psd[n] = np.mean(s_raw[n*n_band_average:(n+1)*n_band_average])\r\n    return f, psd", "response": "Compute one - sided power spectral density subtracting mean automatically."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the running standard deviation of a time series.", "response": "def runningstd(t, data, width):\r\n    \"\"\"Compute the running standard deviation of a time series.\r\n\r\n    Returns `t_new`, `std_r`.\r\n    \"\"\"\r\n    ne = len(t) - width\r\n    t_new = np.zeros(ne)\r\n    std_r = np.zeros(ne)\r\n    for i in range(ne):\r\n        t_new[i] = np.mean(t[i:i+width+1])\r\n        std_r[i] = scipy.stats.nanstd(data[i:i+width+1])\r\n    return t_new, std_r"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsmooths data with a moving average.", "response": "def smooth(data, fw):\r\n    \"\"\"Smooth data with a moving average.\"\"\"\r\n    if fw == 0:\r\n        fdata = data\r\n    else:\r\n        fdata = lfilter(np.ones(fw)/fw, 1, data)\r\n    return fdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calcstats(data, t1, t2, sr):\r\n    dataseg = data[sr*t1:sr*t2]\r\n    meandata = np.mean(dataseg[~np.isnan(dataseg)])\r\n    stddata = np.std(dataseg[~np.isnan(dataseg)])\r\n    return meandata, stddata", "response": "Calculate the mean and standard deviation of some array between t1 and t2 provided the sample rate sr."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\naverage a quantity q over a rectangular area given a 2D array and the x and y vectors for sample locations.", "response": "def average_over_area(q, x, y):\r\n    \"\"\"Averages a quantity `q` over a rectangular area given a 2D array and\r\n    the x and y vectors for sample locations, using the trapezoidal rule\"\"\"\r\n    area = (np.max(x) - np.min(x))*(np.max(y) - np.min(y))\r\n    integral = np.trapz(np.trapz(q, y, axis=0), x)\r\n    return integral/area"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a 2 - D array out of data taken in the same plane for contour plotting.", "response": "def build_plane_arrays(x, y, qlist):\r\n    \"\"\"Build a 2-D array out of data taken in the same plane, for contour\r\n    plotting.\r\n    \"\"\"\r\n    if type(qlist) is not list:\r\n        return_list = False\r\n        qlist = [qlist]\r\n    else:\r\n        return_list = True\r\n    xv = x[np.where(y==y[0])[0]]\r\n    yv = y[np.where(x==x[0])[0]]\r\n    qlistp = []\r\n    for n in range(len(qlist)):\r\n        qlistp.append(np.zeros((len(yv), len(xv))))\r\n    for j in range(len(qlist)):\r\n        for n in range(len(yv)):\r\n            i = np.where(y==yv[n])[0]\r\n            qlistp[j][n,:] = qlist[j][i]\r\n    if not return_list:\r\n        qlistp = qlistp[0]\r\n    return xv, yv, qlistp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute lagged correlation coefficient for two time series.", "response": "def corr_coeff(x1, x2, t, tau1, tau2):\r\n    \"\"\"Compute lagged correlation coefficient for two time series.\"\"\"\r\n    dt = t[1] - t[0]\r\n    tau = np.arange(tau1, tau2+dt, dt)\r\n    rho = np.zeros(len(tau))\r\n    for n in range(len(tau)):\r\n        i = np.abs(int(tau[n]/dt))\r\n        if tau[n] >= 0: # Positive lag, push x2 forward in time\r\n            seg2 = x2[0:-1-i]\r\n            seg1 = x1[i:-1]\r\n        elif tau[n] < 0: # Negative lag, push x2 back in time\r\n            seg1 = x1[0:-i-1]\r\n            seg2 = x2[i:-1]\r\n        seg1 = seg1 - seg1.mean()\r\n        seg2 = seg2 - seg2.mean()\r\n        rho[n] = np.mean(seg1*seg2)/seg1.std()/seg2.std()\r\n    return tau, rho"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autocorr_coeff(x, t, tau1, tau2):\r\n    return corr_coeff(x, x, t, tau1, tau2)", "response": "Calculate the autocorrelation coefficient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef integral_scale(u, t, tau1=0.0, tau2=1.0):\r\n    tau, rho = autocorr_coeff(u, t, tau1, tau2)\r\n    zero_cross_ind = np.where(np.diff(np.sign(rho)))[0][0]\r\n    int_scale = np.trapz(rho[:zero_cross_ind], tau[:zero_cross_ind])\r\n    return int_scale", "response": "Calculate the integral scale of a time series by integrating up to the first zero crossing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing combined standard deviation for subsets.", "response": "def combine_std(n, mean, std):\r\n    \"\"\"Compute combined standard deviation for subsets.\r\n\r\n    See https://stats.stackexchange.com/questions/43159/\\\r\n    how-to-calculate-pooled-variance-of-two-groups-given-known-group-variances-\\\r\n    mean for derivation.\r\n\r\n    Parameters\r\n    ----------\r\n    n : numpy array of sample sizes\r\n    mean : numpy array of sample means\r\n    std : numpy array of sample standard deviations\r\n    \"\"\"\r\n    # Calculate weighted mean\r\n    mean_tot = np.sum(n*mean)/np.sum(n)\r\n    var_tot = np.sum(n*(std**2 + mean**2))/np.sum(n) - mean_tot**2\r\n    return np.sqrt(var_tot)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the expanded uncertainty using values from multiple runs.", "response": "def calc_multi_exp_unc(sys_unc, n, mean, std, dof, confidence=0.95):\r\n    \"\"\"Calculate expanded uncertainty using values from multiple runs.\r\n\r\n    Note that this function assumes the statistic is a mean value, therefore\r\n    the combined standard deviation is divided by `sqrt(N)`.\r\n\r\n    Parameters\r\n    ----------\r\n    sys_unc : numpy array of systematic uncertainties\r\n    n : numpy array of numbers of samples per set\r\n    std : numpy array of sample standard deviations\r\n    dof : numpy array of degrees of freedom\r\n    confidence : Confidence interval for t-statistic\r\n    \"\"\"\r\n    sys_unc = sys_unc.mean()\r\n    std_combined = combine_std(n, mean, std)\r\n    std_combined /= np.sqrt(n.sum())\r\n    std_unc_combined = np.sqrt(std_combined**2 + sys_unc**2)\r\n    dof = dof.sum()\r\n    t_combined = scipy.stats.t.interval(alpha=confidence, df=dof)[-1]\r\n    exp_unc_combined = t_combined*std_unc_combined\r\n    return exp_unc_combined"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn Student - t statistic for given DOF and confidence interval.", "response": "def student_t(degrees_of_freedom, confidence=0.95):\r\n    \"\"\"Return Student-t statistic for given DOF and confidence interval.\"\"\"\r\n    return scipy.stats.t.interval(alpha=confidence,\r\n                                  df=degrees_of_freedom)[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the combined standard uncertainty of a quantity.", "response": "def calc_uncertainty(quantity, sys_unc, mean=True):\r\n    \"\"\"Calculate the combined standard uncertainty of a quantity.\"\"\"\r\n    n = len(quantity)\r\n    std = np.nanstd(quantity)\r\n    if mean:\r\n        std /= np.sqrt(n)\r\n    return np.sqrt(std**2 + sys_unc**2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the expanded uncertainty of a single sample.", "response": "def calc_exp_uncertainty(n, std, combined_unc, sys_unc, rel_unc=0.25,\r\n                         confidence=0.95, mean=True):\r\n    \"\"\"Calculate expanded uncertainty.\r\n\r\n    Parameters\r\n    ----------\r\n    n : Number of independent samples\r\n    std : Sample standard deviation\r\n    sys_unc : Systematic uncertainty (b in Coleman and Steele)\r\n    rel_unc : Relative uncertainty of each systematic error source (guess 0.25)\r\n    confidence : Confidence interval (0, 1)\r\n    mean : bool whether or not the quantity is a mean value\r\n\r\n    Returns\r\n    -------\r\n    exp_unc : Expanded uncertainty\r\n    nu_x : Degrees of freedom\r\n    \"\"\"\r\n    s_x = std\r\n    if mean:\r\n        s_x /= np.sqrt(n)\r\n    nu_s_x = n - 1\r\n    b = sys_unc\r\n    nu_b = 0.5*rel_unc**(-2)\r\n    nu_x = ((s_x**2 + b**2)**2)/(s_x**4/nu_s_x + b**4/nu_b)\r\n    t = scipy.stats.t.interval(alpha=0.95, df=nu_x)[-1]\r\n    exp_unc = t*combined_unc\r\n    return exp_unc, nu_x"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_amp_phase(angle, data, npeaks=3, min_amp=None, min_phase=None):\r\n    # First subtract the mean of the data\r\n    data = data - data.mean()\r\n    # Make some guesses for parameters from a subset of data starting at an\r\n    # integer multiple of periods\r\n    if angle[0] != 0.0:\r\n        angle1 = angle[0] + (2*np.pi/npeaks - (2*np.pi/npeaks) % angle[0])\r\n    else:\r\n        angle1 = angle[0]\r\n    angle1 += min_phase\r\n    angle2 = angle1 + 2*np.pi/npeaks\r\n    ind = np.logical_and(angle >= angle1, angle <= angle2)\r\n    angle_sub = angle[ind]\r\n    data_sub = data[ind]\r\n    amp_guess = (data_sub.max() - data_sub.min())/2\r\n    phase_guess = angle[np.where(data_sub == data_sub.max())[0][0]] \\\r\n            % (np.pi*2/npeaks)\r\n    # Define the function we will try to fit to\r\n    def func(angle, amp, phase, mean):\r\n        return amp*np.cos(npeaks*(angle - phase)) + mean\r\n    # Calculate fit\r\n    p0 = amp_guess, phase_guess, 0.0\r\n    popt, pcov = curve_fit(func, angle, data, p0=p0)\r\n    amp, phase, mean = popt\r\n    return amp, phase", "response": "Estimate amplitude and phase of an approximately sinusoidal quantity using scipy. optimize. curve_fit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_script(create=None):  # noqa: E501\n    if connexion.request.is_json:\n        create = Create.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'", "response": "Create a new script"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a script Delete a script # noqa: E501 :param delete: The data needed to delete this script :type delete: dict | bytes :rtype: Response", "response": "def delete_script(delete=None):  # noqa: E501\n    \"\"\"Delete a script\n\n    Delete a script # noqa: E501\n\n    :param delete: The data needed to delete this script\n    :type delete: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        delete = Delete.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrenaming a script Rename a script # noqa: E501 :param rename: The data needed to save this script :type rename: dict | bytes :rtype: Response", "response": "def rename_script(rename=None):  # noqa: E501\n    \"\"\"Rename a script\n\n    Rename a script # noqa: E501\n\n    :param rename: The data needed to save this script\n    :type rename: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        rename = Rename.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave a script Save a script # noqa: E501 :param save: The data needed to save this script :type save: dict | bytes :rtype: Response", "response": "def save_script(save=None):  # noqa: E501\n    \"\"\"Save a script\n\n    Save a script # noqa: E501\n\n    :param save: The data needed to save this script\n    :type save: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        save = Save.from_dict(connexion.request.get_json())  # noqa: E501\n    return 'do some magic!'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_numbers(s):\n\n    result = map(int, re.findall(r'[0-9]+', unicode(s)))\n    return result + [1] * (2 - len(result))", "response": "Extracts all integers from a string an return them in a list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy given string into system clipboard.", "response": "def copy(string):\n    \"\"\"Copy given string into system clipboard.\n    \"\"\"\n    win32clipboard.OpenClipboard()\n    win32clipboard.EmptyClipboard()\n    win32clipboard.SetClipboardText(string)\n    win32clipboard.CloseClipboard()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addVertex(self, _id=None):\n        node = self.neograph.nodes.create(_id=_id)\n        return Vertex(node)", "response": "Add param declared for compability with the API. Neo4j\n        creates the id automatically"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves an existing vertex from the graph", "response": "def getVertex(self, _id):\n        \"\"\"Retrieves an existing vertex from the graph\n        @params _id: Node unique identifier\n\n        @returns The requested Vertex or None\"\"\"\n        try:\n            node = self.neograph.nodes.get(_id)\n        except client.NotFoundError:\n            return None\n        return Vertex(node)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an edge to the cache.", "response": "def addEdge(self, outVertex, inVertex, label):\n        \"\"\"Creates a new edge\n        @params outVertex: Edge origin Vertex\n        @params inVertex: Edge target vertex\n        @params label: Edge label\n\n        @returns The created Edge object\"\"\"\n        n1 = outVertex.neoelement\n        n2 = inVertex.neoelement\n        edge = n1.relationships.create(label, n2)\n        return Edge(edge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getEdge(self, _id):\n        try:\n            edge = self.neograph.relationships.get(_id)\n        except client.NotFoundError:\n            return None\n        return Edge(edge)", "response": "Retrieves an existing edge from the graph\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the outgoing edges of the node.", "response": "def getOutEdges(self, label=None):\n        \"\"\"Gets all the outgoing edges of the node. If label\n        parameter is provided, it only returns the edges of\n        the given label\n        @params label: Optional parameter to filter the edges\n\n        @returns A generator function with the outgoing edges\"\"\"\n        if label:\n            for edge in self.neoelement.relationships.outgoing(types=[label]):\n                yield Edge(edge)\n        else:\n            for edge in self.neoelement.relationships.outgoing():\n                yield Edge(edge)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getInEdges(self, label=None):\n        if label:\n            for edge in self.neoelement.relationships.incoming(types=[label]):\n                yield Edge(edge)\n        else:\n            for edge in self.neoelement.relationships.incoming():\n                yield Edge(edge)", "response": "Gets all the incoming edges of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all the edges of the node.", "response": "def getBothEdges(self, label=None):\n        \"\"\"Gets all the edges of the node. If label\n        parameter is provided, it only returns the edges of\n        the given label\n        @params label: Optional parameter to filter the edges\n\n        @returns A generator function with the incoming edges\"\"\"\n        if label:\n            for edge in self.neoelement.relationships.all(types=[label]):\n                yield Edge(edge)\n        else:\n            for edge in self.neoelement.relationships.all():\n                yield Edge(edge)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nputs an element in an index under a given key - value pair", "response": "def put(self, key, value, element):\n        \"\"\"Puts an element in an index under a given\n        key-value pair\n        @params key: Index key string\n        @params value: Index value string\n        @params element: Vertex or Edge element to be indexed\"\"\"\n        self.neoindex[key][value] = element.neoelement"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an element from an index under a given key - value pair", "response": "def get(self, key, value):\n        \"\"\"Gets an element from an index under a given\n        key-value pair\n        @params key: Index key string\n        @params value: Index value string\n        @returns A generator of Vertex or Edge objects\"\"\"\n        for element in self.neoindex[key][value]:\n            if self.indexClass == \"vertex\":\n                yield Vertex(element)\n            elif self.indexClass == \"edge\":\n                yield Edge(element)\n            else:\n                raise TypeError(self.indexClass)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving an element from an index under a given key - value pair", "response": "def remove(self, key, value, element):\n        \"\"\"Removes an element from an index under a given\n        key-value pair\n        @params key: Index key string\n        @params value: Index value string\n        @params element: Vertex or Edge element to be removed\"\"\"\n        self.neoindex.delete(key, value, element.neoelement)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createManualIndex(self, indexName, indexClass):\n        indexClass = str(indexClass).lower()\n        if indexClass == \"vertex\":\n            index = self.neograph.nodes.indexes.create(indexName)\n        elif indexClass == \"edge\":\n            index = self.neograph.relationships.indexes.create(indexName)\n        else:\n            NameError(\"Unknown Index Class %s\" % indexClass)\n        return Index(indexName, indexClass, \"manual\", index)", "response": "Creates an index manually managed by this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getIndex(self, indexName, indexClass):\n        if indexClass == \"vertex\":\n            try:\n                return Index(indexName, indexClass, \"manual\",\n                        self.neograph.nodes.indexes.get(indexName))\n            except client.NotFoundError:\n                return None\n        elif indexClass == \"edge\":\n            try:\n                return Index(indexName, indexClass, \"manual\",\n                        self.neograph.relationships.indexes.get(indexName))\n            except client.NotFoundError:\n                return None\n        else:\n            raise KeyError(\"Unknown Index Class (%s). Use vertex or edge\"\\\n                    % indexClass)", "response": "Retrieves an index with a given name and class"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator function over all the existing indexes", "response": "def getIndices(self):\n        \"\"\"Returns a generator function over all the existing indexes\n\n        @returns A generator function over all rhe Index objects\"\"\"\n        for indexName in self.neograph.nodes.indexes.keys():\n            indexObject = self.neograph.nodes.indexes.get(indexName)\n            yield Index(indexName, \"vertex\", \"manual\", indexObject)\n        for indexName in self.neograph.relationships.indexes.keys():\n            indexObject = self.neograph.relationships.indexes.get(indexName)\n            yield Index(indexName, \"edge\", \"manual\", indexObject)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns ( url revision ) where both are strings", "response": "def get_info(self, location):\n        \"\"\"Returns (url, revision), where both are strings\"\"\"\n        assert not location.rstrip('/').endswith(self.dirname), 'Bad directory: %s' % location\n        output = call_subprocess(\n            [self.cmd, 'info', location], show_stdout=False, extra_environ={'LANG': 'C'})\n        match = _svn_url_re.search(output)\n        if not match:\n            logger.warn('Cannot determine URL of svn checkout %s' % display_path(location))\n            logger.info('Output that cannot be parsed: \\n%s' % output)\n            return None, None\n        url = match.group(1).strip()\n        match = _svn_revision_re.search(output)\n        if not match:\n            logger.warn('Cannot determine revision of svn checkout %s' % display_path(location))\n            logger.info('Output that cannot be parsed: \\n%s' % output)\n            return url, None\n        return url, match.group(1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export(self, location):\n        url, rev = self.get_url_rev()\n        logger.notify('Exporting svn repository %s to %s' % (url, location))\n        logger.indent += 2\n        try:\n            if os.path.exists(location):\n                # Subversion doesn't like to check out over an existing directory\n                # --force fixes this, but was only added in svn 1.5\n                rmtree(location)\n            call_subprocess(\n                [self.cmd, 'export', url, location],\n                filter_stdout=self._filter, show_stdout=False)\n        finally:\n            logger.indent -= 2", "response": "Export the svn repository at the url to the destination location"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_revision(self, location):\n        # Note: taken from setuptools.command.egg_info\n        revision = 0\n\n        for base, dirs, files in os.walk(location):\n            if self.dirname not in dirs:\n                dirs[:] = []\n                continue    # no sense walking uncontrolled subdirs\n            dirs.remove(self.dirname)\n            entries_fn = os.path.join(base, self.dirname, 'entries')\n            if not os.path.exists(entries_fn):\n                ## FIXME: should we warn?\n                continue\n            f = open(entries_fn)\n            data = f.read()\n            f.close()\n\n            if data.startswith('8') or data.startswith('9') or data.startswith('10'):\n                data = list(map(str.splitlines, data.split('\\n\\x0c\\n')))\n                del data[0][0]  # get rid of the '8'\n                dirurl = data[0][3]\n                revs = [int(d[9]) for d in data if len(d)>9 and d[9]]+[0]\n                if revs:\n                    localrev = max(revs)\n                else:\n                    localrev = 0\n            elif data.startswith('<?xml'):\n                dirurl = _svn_xml_url_re.search(data).group(1)    # get repository URL\n                revs = [int(m.group(1)) for m in _svn_rev_re.finditer(data)]+[0]\n                if revs:\n                    localrev = max(revs)\n                else:\n                    localrev = 0\n            else:\n                logger.warn(\"Unrecognized .svn/entries format; skipping %s\", base)\n                dirs[:] = []\n                continue\n            if base == location:\n                base_url = dirurl+'/'   # save the root url\n            elif not dirurl.startswith(base_url):\n                dirs[:] = []\n                continue    # not part of the same svn tree, skip it\n            revision = max(revision, localrev)\n        return revision", "response": "Get the maximum revision for all files under a given location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef word(self, value):\n\n        self._validate_word(value=value)\n\n        _word = []\n\n        # Iterate the values passed.\n        for a in value:\n            # Check the value is an int or a string.\n            if not (isinstance(a, int) or isinstance(a, str) or isinstance(a, unicode)):\n                raise ValueError('DigitWords must be made from digits (strings or ints) '\n                                 'between 0 and 9 for decimal and 0 and 15 for hex')\n\n            # This convoluted check is caused by the remove of the unicode type in Python 3+\n            # If this is Python2.x, then we need to convert unicode to string, otherwise\n            # we leave it as is.\n            if sys.version_info[0] == 2 and isinstance(a, unicode):\n                _a = str(a)\n            else:\n                _a = a\n\n            # Create the correct type of Digit based on the wordtype of the DigitWord\n            if self.wordtype == DigitWord.DIGIT:\n                _digit = Digit(_a)\n            elif self.wordtype == DigitWord.HEXDIGIT:\n                _digit = HexDigit(_a)\n            else:\n                raise TypeError('The wordtype is not valid.')\n\n            _word.append(_digit)\n\n        self._word = _word", "response": "Property of the DigitWord returning the DigitWord as a list of integers or hexdigit strings. The property is called during instantiation and ensures that all digits are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(self, value):\n\n        if not isinstance(value, str):\n            raise TypeError('Expected JSON string')\n\n        _value = json.loads(value)\n        self._validate_word(value=_value)\n        self.word = _value", "response": "Load the value of the DigitWord from a JSON representation of a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef random(self, length=4):\n        if not isinstance(length, int):\n            raise TypeError('DigitWord can only be randomized by an integer length')\n\n        if self.wordtype == DigitWord.DIGIT:\n            self._word = [Digit(random.randint(0, 9)) for i in range(0, length)]\n        elif self.wordtype == DigitWord.HEXDIGIT:\n            self._word = [HexDigit(str(hex(random.randint(0, 15))).replace('0x',''))\n                          for i in range(0, length)]\n        else:\n            raise TypeError('wordtype is invalid.')", "response": "Method to randomize the DigitWord to a given length ; for example obj. random ( length = 4 ) would\n        produce a DigitWord containing of four random Digits or HexDigits."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompare the DigitWord with another DigitWord and returns a list of Comparison objects. The method returns a list of Comparison objects. The method returns a list of Comparison objects. The method returns a list of Comparison objects.", "response": "def compare(self, other):\n        \"\"\"Compare the DigitWord with another DigitWord (other) and provided iterated analysis of the\n        matches (none or loose) and the occurrence (one or more) of each DigitEntry in both\n        DigitWords. The method returns a list of Comparison objects.\"\"\"\n\n        self._validate_compare_parameters(other=other)\n\n        return_list = []\n        for idx, digit in enumerate(other):\n            dwa = DigitWordAnalysis(\n                index=idx,\n                digit=digit,\n                match=(digit == self._word[idx]),\n                in_word=(self._word.count(digit) > 0),\n                multiple=(self._word.count(digit) > 1)\n            )\n            return_list.append(dwa)\n\n        return return_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a package finder appropriate to this install command.", "response": "def _build_package_finder(self, options, index_urls):\n        \"\"\"\n        Create a package finder appropriate to this install command.\n        This method is meant to be overridden by subclasses, not\n        called directly.\n        \"\"\"\n        return PackageFinder(find_links=options.find_links,\n                             index_urls=index_urls,\n                             use_mirrors=options.use_mirrors,\n                             mirrors=options.mirrors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort(amend: bool = False, stage: bool = False):\n    _sort(amend, stage)", "response": "Runs iSort on the base item of the base item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, *args, **kwargs):\n        kwargs = self._inject_request_kwargs(kwargs)\n        url = reddit_url(*args)\n        r = requests.get(url, **kwargs)\n        # print r.url\n        if r.status_code == 200:\n            thing = self._thingify(json.loads(r.content), path=urlparse(r.url).path)\n            return thing\n        else:\n            raise BadResponse(r)", "response": "Send a GET request to a reddit path determined by args."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a POST request to a reddit path determined by args.", "response": "def post(self, *args, **kwargs):\n        \"\"\"Sends a POST request to a reddit path determined by ``args``.  Basically ``.post('foo', 'bar', 'baz')`` will POST http://www.reddit.com/foo/bar/baz/.json.  ``kwargs`` supplied will be passed to ``requests.post`` after having ``modhash`` and ``cookies`` injected, and after having modhash injected into ``kwargs['data']`` if logged in.  Injection only occurs if they don't already exist.\n        \n        Returns received response JSON content as a dict.\n        \n        Raises :class:`exceptions.BadResponse` if not a 200 response or no JSON content received or raises :class:`exceptions.PostError` if a reddit error was returned.\n        \n        :param \\*args: strings that will form the path to POST\n        :param \\*\\*kwargs: extra keyword arguments to be passed to ``requests.POST``\n        \"\"\"\n        kwargs = self._inject_request_kwargs(kwargs)\n        kwargs = self._inject_post_data(kwargs)\n        url = reddit_url(*args)\n        r = requests.post(url, **kwargs)\n        if r.status_code == 200:\n            try:\n                j = json.loads(r.content)\n            except ValueError:\n                raise BadResponse(r)\n            try:\n                errors = j['json']['errors']\n            except Exception:\n                errors = None\n            if errors:\n                raise PostError(errors)\n            else:\n                return j\n        else:\n            raise BadResponse(r)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef login(self, username, password):\n        data = dict(user=username, passwd=password, api_type='json')\n        r = requests.post(LOGIN_URL, data=data)\n        if r.status_code == 200:\n            try:\n                j = json.loads(r.content)\n                self._cookies = r.cookies\n                self._modhash = j['json']['data']['modhash']\n                self._username = username\n                return r\n            except Exception:\n                raise LoginFail()\n        else:\n            raise BadResponse(r)", "response": "Logs into reddit with supplied credentials using SSL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets info about url.", "response": "def info(self, url, limit=None):\n        \"\"\"GETs \"info\" about ``url``.  See https://github.com/reddit/reddit/wiki/API%3A-info.json.\n        \n        URL: ``http://www.reddit.com/api/info/?url=<url>``\n        \n        :param url: url\n        :param limit: max number of links to get\n        \"\"\"\n        return self._limit_get('api', 'info', params=dict(url=url), limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse reddit s search function.", "response": "def search(self, query, limit=None):\n        \"\"\"Use reddit's search function.  Returns :class:`things.Listing` object.\n        \n        URL: ``http://www.reddit.com/search/?q=<query>&limit=<limit>``\n        \n        :param query: query string\n        :param limit: max number of results to get\n        \"\"\"\n        return self._limit_get('search', params=dict(q=query), limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of moderators of a subreddit.", "response": "def moderators(self, sr, limit=None):\n        \"\"\"GETs moderators of subreddit ``sr``.  Returns :class:`things.ListBlob` object.\n        \n        **NOTE**: The :class:`things.Account` objects in the returned ListBlob *only* have ``id`` and ``name`` set.  This is because that's all reddit returns.  If you need full info on each moderator, you must individually GET them using :meth:`user` or :meth:`things.Account.about`.\n        \n        URL: ``http://www.reddit.com/r/<sr>/about/moderators/``\n        \n        :param sr: name of subreddit\n        \"\"\"\n        userlist = self._limit_get('r', sr, 'about', 'moderators', limit=limit)\n        return _process_userlist(userlist)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef vote(self, id_, dir_):\n        data = dict(id=id_, dir=dir_)\n        j = self.post('api', 'vote', data=data)\n        return assert_truthy(j)", "response": "Login required. POSTs a vote. Returns True or raises an unexpectedResponse if non - truthy value in response.\n        \n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comment(self, parent, text):\n        data = dict(parent=parent, text=text)\n        j = self.post('api', 'comment', data=data)\n        try:\n            return self._thingify(j['json']['data']['things'][0])\n        except Exception:\n            raise UnexpectedResponse(j)", "response": "Login required. POSTs a comment in response to parent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlogging-in required. Sends POST to change selftext or comment text to text. Returns a Comment or Link object depending on what s being edited.", "response": "def edit(self, id_, text):\n        \"\"\"Login required.  Sends POST to change selftext or comment text to ``text``.  Returns :class:`things.Comment` or :class:`things.Link` object depending on what's being edited.  Raises :class:`UnexpectedResponse` if neither is returned.\n        \n        URL: ``http://www.reddit.com/api/editusertext/``\n        \n        :param id\\_: full id of link or comment to edit\n        :param text: new self or comment text\n        \"\"\"\n        data = dict(thing_id=id_, text=text)\n        j = self.post('api', 'editusertext', data=data)\n        try:\n            return self._thingify(j['json']['data']['things'][0])\n        except Exception:\n            raise UnexpectedResponse(j)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef submit_link(self, sr, title, url, follow=True):\n        return self._submit(sr, title, 'link', url=url, follow=follow)", "response": "Login required. POSTs a link submission. Returns a string permalink of the new submission otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubmits a text submission.", "response": "def submit_text(self, sr, title, text, follow=True):\n        \"\"\"Login required.  POSTs a text submission.  Returns :class:`things.Link` object if ``follow=True`` (default), or the string permalink of the new submission otherwise.\n        \n        Argument ``follow`` exists because reddit only returns the permalink after POSTing a submission.  In order to get detailed info on the new submission, we need to make another request.  If you don't want to make that additional request, set ``follow=False``.\n        \n        See https://github.com/reddit/reddit/wiki/API%3A-submit.\n        \n        URL: ``http://www.reddit.com/api/submit/``\n        \n        :param sr: name of subreddit to submit to\n        :param title: title of submission\n        :param text: submission self text\n        :param follow: set to ``True`` to follow retrieved permalink to return detailed :class:`things.Link` object.  ``False`` to just return permalink.\n        :type follow: bool\n        \"\"\"\n        return self._submit(sr, title, 'self', text=text, follow=follow)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef message(self, to, subject, text):\n        return self.compose(to, subject, text)", "response": "A simple message with a to subject and text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compose(self, to, subject, text):\n        if isinstance(to, Account):\n            to = to.name\n        data = dict(to=to, subject=subject, text=text)\n        j = self.post('api', 'compose', data=data)\n        return assert_truthy(j)", "response": "Login required. Sends POST to compose a message to a user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlogin required. Send POST to mark a message as read. Returns True or raises Exception. UnexpectedResponse", "response": "def read_message(self, id_):\n        \"\"\"Login required.  Send POST to mark a message as read.  Returns True or raises :class:`exceptions.UnexpectedResponse` if non-\"truthy\" value in response.\n        \n        URL: ``http://www.reddit.com/api/read_message/``\n        \n        :param id\\_: full id of message to mark\n        \"\"\"\n        data = dict(id=id_)\n        j = self.post('api', 'read_message', data=data)\n        return assert_truthy(j)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging-in required. Send POST to subscribe to a subreddit.", "response": "def subscribe(self, sr):\n        \"\"\"Login required.  Send POST to subscribe to a subreddit.  If ``sr`` is the name of the subreddit, a GET request is sent to retrieve the full id of the subreddit, which is necessary for this API call.  Returns True or raises :class:`exceptions.UnexpectedResponse` if non-\"truthy\" value in response.\n        \n        URL: ``http://www.reddit.com/api/subscribe/``\n        \n        :param sr: full id of subreddit or name of subreddit (full id is preferred)\n        \"\"\"\n        if not sr.startswith('t5_'):\n            sr = self.subreddit(sr).name\n        data = dict(action='sub', sr=sr)\n        j = self.post('api', 'subscribe', data=data)\n        return assert_truthy(j)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distinguish(self, id_, how=True):\n        if how == True:\n            h = 'yes'\n        elif how == False:\n            h = 'no'\n        elif how == 'admin':\n            h = 'admin'\n        else:\n            raise ValueError(\"how must be either True, False, or 'admin'\") \n        data = dict(id=id_)\n        j = self.post('api', 'distinguish', h, data=data)\n        try:\n            return self._thingify(j['json']['data']['things'][0])\n        except Exception:\n            raise UnexpectedResponse(j)", "response": "Send a POST to distinguish a submission or comment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flairlist(self, r, limit=1000, after=None, before=None):\n        params = dict(limit=limit)\n        if after:\n            params['after'] = after\n        elif before:\n            params['before'] = before\n        b = self.get('r', r, 'api', 'flairlist', params=params)\n        return b.users", "response": "Get flairlist for subreddit r."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flair(self, r, name, text, css_class):\n        data = dict(r=r, name=name, text=text, css_class=css_class)\n        j = self.post('api', 'flair', data=data)\n        return assert_truthy(j)", "response": "Login required. Returns True or raises an unexpected response if non - truthy value in response. nkey."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flaircsv(self, r, flair_csv):\n        # TODO: handle the response better than just returning\n        data = dict(r=r, flair_csv=flair_csv)\n        return self.post('api', 'flaircsv', data=data)", "response": "Bulk sets flair for users."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contributors(self, sr, limit=None):\n        userlist = self._limit_get('r', sr, 'about', 'contributors', limit=limit)\n        return _process_userlist(userlist)", "response": "Login required. GETs list of contributors to subreddit sr."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a source object to an etree Element.", "response": "def to_etree(source, root_tag=None):\n    \"\"\" Convert various representations of an XML structure to a etree Element\n\n        Args:\n            source -- The source object to be converted - ET.Element\\ElementTree, dict or string.\n\n        Keyword args:\n            root_tag -- A optional parent tag in which to wrap the xml tree if no root in dict representation.\n                    See dict_to_etree()\n\n        Returns:\n            A etree Element matching the source object.\n\n    >>> to_etree(\"<content/>\")  #doctest: +ELLIPSIS\n    <Element content at 0x...>\n\n    >>> to_etree({'document': {'title': 'foo', 'list': [{'li':1}, {'li':2}]}})  #doctest: +ELLIPSIS\n    <Element document at 0x...>\n\n    >>> to_etree(ET.Element('root'))  #doctest: +ELLIPSIS\n    <Element root at 0x...>\n    \"\"\"\n    if hasattr(source, 'get_root'): #XXX:\n        return source.get_root()\n    elif isinstance(source, type(ET.Element('x'))):    #XXX: # cElementTree.Element isn't exposed directly\n        return source\n    elif isinstance(source, basestring):\n        try:\n            return ET.fromstring(source)\n        except:\n            raise XMLError(source)\n    elif hasattr(source, 'keys'):   # Dict.\n        return dict_to_etree(source, root_tag)\n    else:\n        raise XMLError(source)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a source object to a rew XML string.", "response": "def to_raw_xml(source):\n    \"\"\" Convert various representations of an XML structure to a normal XML string.\n\n        Args:\n            source -- The source object to be converted - ET.Element, dict or string.\n\n        Returns:\n            A rew xml string matching the source object.\n\n    >>> to_raw_xml(\"<content/>\")\n    '<content/>'\n\n    >>> to_raw_xml({'document': {'title': 'foo', 'list': [{'li':1}, {'li':2}]}})\n    '<document><list><li>1</li><li>2</li></list><title>foo</title></document>'\n\n    >>> to_raw_xml(ET.Element('root'))\n    '<root/>'\n    \"\"\"\n    if isinstance(source, basestring):\n        return source\n    elif hasattr(source, 'getiterator'):    # Element or ElementTree.\n        return ET.tostring(source, encoding=\"utf-8\")\n    elif hasattr(source, 'keys'):   # Dict.\n        xml_root = dict_to_etree(source)\n        return ET.tostring(xml_root, encoding=\"utf-8\")\n    else:\n        raise TypeError(\"Accepted representations of a document are string, dict and etree\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n\n    configure_obj = None\n    parser = argparse.ArgumentParser(description='\u81ea\u52a8\u5316\u5b89\u88c5')\n    parser.add_argument(\n        '-s', '--server',\n        help='\u670d\u52a1\u5668\u4ee3\u66ff\u540d',\n    )\n\n    parser.add_argument(\n        '-ba', '--bigdata-app',\n        help='\u5927\u6570\u636e\u670d\u52a1\u5e94\u7528\u66ff\u4ee3\u540d',\n    )\n\n    parser.add_argument(\n        '-add-slave', '--add-slave',\n        help='\u6dfb\u52a0\u4e00\u4e2a\u5b50\u8282\u70b9\u670d\u52a1\u5668',\n    )\n\n    parser.add_argument(\n        '-skip-master', '--skip-master',\n        dest='skip_master',\n        action='store_true',\n        help='\u8df3\u8fc7master\u670d\u52a1\u5668\u7684\u5b89\u88c5\u8fc7\u7a0b',\n    )\n\n    # force to install packages without ask question\n    parser.add_argument(\n        '-f', '--force',\n        dest='force',\n        action='store_true',\n        help='\u4e0d\u8be2\u95ee\u662f\u5426\u5b89\u88c5',\n    )\n    parser.add_argument(\n        '-nf', '--not-force',\n        dest='force',\n        action='store_false',\n        help='\u8be2\u95ee\u662f\u5426\u5b89\u88c5',\n    )\n    parser.set_defaults(force=False)\n\n    # login to remote mysql, default is false\n    parser.add_argument(\n        '-my', '--mysql',\n        dest='login_mysql',\n        action='store_true',\n        help='\u767b\u5f55\u5230Mysql\u6570\u636e\u5e93',\n    )\n    parser.set_defaults(login_mysql=False)\n\n    # login to server\n    parser.add_argument(\n        '-login', '--login',\n        dest='login_server',\n        action='store_true',\n        help='\u767b\u5f55\u5230\u8fdc\u7a0b\u670d\u52a1\u5668',\n    )\n    parser.set_defaults(login_server=False)\n\n    parser.add_argument(\n        '-p', '--project',\n        help='\u9879\u76ee\u540d\u79f0\uff0c\u9ed8\u8ba4\u662fdemo',\n        default='demo'\n    )\n\n    parser.add_argument(\n        '-gp', '--git-pull',\n        help='Github\u9879\u76ee\u7684\u4fdd\u5b58\u76ee\u5f55',\n    )\n\n    parser.add_argument(\n        '-C', '--config',\n        help='\u914d\u7f6e\u6587\u4ef6\u8def\u5f84',\n        nargs=2\n    )\n\n    parser.add_argument(\n        '-H', '--host',\n        help='\u5ba2\u6237\u673a\u5730\u5740',\n    )\n\n    parser.add_argument(\n        '-U', '--user',\n        help='\u5ba2\u6237\u673a\u7528\u6237\u540d',\n    )\n\n    parser.add_argument(\n        '-P', '--passwd',\n        help='\u5ba2\u6237\u673a\u767b\u5f55\u5bc6\u7801',\n    )\n\n    parser.add_argument(\n        '-K', '--keyfile',\n        help='\u5ba2\u6237\u673aSSH KEY\u7684\u8def\u5f84',\n    )\n\n    parser.add_argument(\n        '-ap', '--active-port',\n        help='\u5ba2\u6237\u673a\u5df2\u7ecf\u5f00\u542f\u7684\u7aef\u53e3',\n        action='store_true'\n    )\n\n    args = parser.parse_args()\n\n    # if config file and host both not provide, throw a error\n    if args.config is None and args.host is None:\n        raise ValueError('\u7f3a\u5c11\u914d\u7f6e\u6587\u4ef6-C(--config)\u6216\u5ba2\u6237\u673a\u5730\u5740-H(--host)')\n\n    # check user and passwd\n    if args.host is not None:\n        if (args.user and (args.passwd or args.keyfile)) is None:\n            raise ValueError('\u7f3a\u5c11\u767b\u5f55\u5fc5\u8981\u7684\u4fe1\u606f')\n\n    # if exist config file, read configuration from file\n    configure = None\n    if args.config is not None:\n        # init configuration parser\n        configure = configparser.ConfigParser()\n        configure.read(args.config[0])\n        config_sections = configure.sections()\n\n        # check key exist\n        if args.config[1] not in config_sections:\n            raise KeyError('\u672a\u627e\u5230\u4e0e{0}\u5bf9\u5e94\u7684\u767b\u5f55\u914d\u7f6e\u6587\u4ef6\uff0c\u5b58\u5728\u7684\u914d\u7f6e\u6587\u4ef6\u4e3a{1}'\n                           .format(args.config[1], config_sections))\n\n        configure_obj = configure[args.config[1]]\n    # init server\n    ServerBase(\n        args, configure_obj,\n        configure=configure\n    )", "response": "Main function for the check command"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the arguments of a single segment of a segment.", "response": "def parse_arguments(filters, arguments, modern=False):\n    \"\"\"\n    Return a dict of parameters.\n    Take a list of filters and for each try to get the corresponding\n    value in arguments or a default value. Then check that value's type.\n    The @modern parameter indicates how the arguments should be\n    interpreted. The old way is that you always specify a list and in\n    the list you write the names of types as strings. I.e. instad of\n    `str` you write `'str'`.\n    The modern way allows you to specify arguments by real Python types\n    and entering it as a list means you accept and expect it to be a list.\n    For example, using the modern way:\n        filters = [\n            (\"param1\", \"default\", [str]),\n            (\"param2\", None, int),\n            (\"param3\", [\"list\", \"of\", 4, \"values\"], [str])\n        ]\n        arguments = {\n            \"param1\": \"value1\",\n            \"unknown\": 12345\n        }\n        =>\n        {\n            \"param1\": [\"value1\"],\n            \"param2\": 0,\n            \"param3\": [\"list\", \"of\", \"4\", \"values\"]\n        }\n    And an example for the old way:\n        filters = [\n            (\"param1\", \"default\", [\"list\", \"str\"]),\n            (\"param2\", None, \"int\"),\n            (\"param3\", [\"list\", \"of\", 4, \"values\"], [\"list\", \"str\"])\n        ]\n        arguments = {\n            \"param1\": \"value1\",\n            \"unknown\": 12345\n        }\n        =>\n        {\n            \"param1\": [\"value1\"],\n            \"param2\": 0,\n            \"param3\": [\"list\", \"of\", \"4\", \"values\"]\n        }\n    The reason for having the modern and the non-modern way is\n    transition of legacy code. One day it will all be the modern way.\n    \"\"\"\n    params = DotDict()\n\n    for i in filters:\n        count = len(i)\n        param = None\n\n        if count <= 1:\n            param = arguments.get(i[0])\n        else:\n            param = arguments.get(i[0], i[1])\n\n        # proceed and do the type checking\n        if count >= 3:\n            types = i[2]\n\n            if modern:\n                if isinstance(types, list) and param is not None:\n                    assert len(types) == 1\n                    if not isinstance(param, list):\n                        param = [param]\n                    param = [check_type(x, types[0]) for x in param]\n                else:\n                    param = check_type(param, types)\n            else:\n                if not isinstance(types, list):\n                    types = [types]\n\n                for t in reversed(types):\n                    if t == \"list\" and not isinstance(param, list):\n                        if param is None or param == '':\n                            param = []\n                        else:\n                            param = [param]\n                    elif t == \"list\" and isinstance(param, list):\n                        continue\n                    elif isinstance(param, list) and \"list\" not in types:\n                        param = \" \".join(param)\n                        param = check_type(param, t)\n                    elif isinstance(param, list):\n                        param = [check_type(x, t) for x in param]\n                    else:\n                        param = check_type(param, t)\n\n        params[i[0]] = param\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that the parameter is of type datatype and return it.", "response": "def check_type(param, datatype):\n    \"\"\"\n    Make sure that param is of type datatype and return it.\n    If param is None, return it.\n    If param is an instance of datatype, return it.\n    If param is not an instance of datatype and is not None, cast it as\n    datatype and return it.\n    \"\"\"\n    if param is None:\n        return param\n\n    if getattr(datatype, 'clean', None) and callable(datatype.clean):\n        try:\n            return datatype.clean(param)\n        except ValueError:\n            raise BadArgumentError(param)\n\n    elif isinstance(datatype, str):\n        # You've given it something like `'bool'` as a string.\n        # This is the legacy way of doing it.\n        datatype = {\n            'str': str,\n            'bool': bool,\n            'float': float,\n            'date': datetime.date,\n            'datetime': datetime.datetime,\n            'timedelta': datetime.timedelta,\n            'json': 'json',  # exception\n            'int': int,\n        }[datatype]\n\n    if datatype is str and not isinstance(param, basestring):\n        try:\n            param = str(param)\n        except ValueError:\n            param = str()\n\n    elif datatype is int and not isinstance(param, int):\n        try:\n            param = int(param)\n        except ValueError:\n            param = int()\n\n    elif datatype is bool and not isinstance(param, bool):\n        param = str(param).lower() in (\"true\", \"t\", \"1\", \"y\", \"yes\")\n\n    elif (\n        datatype is datetime.datetime and\n        not isinstance(param, datetime.datetime)\n    ):\n        try:\n            param = dtutil.string_to_datetime(param)\n        except ValueError:\n            param = None\n\n    elif datatype is datetime.date and not isinstance(param, datetime.date):\n        try:\n            param = dtutil.string_to_datetime(param).date()\n        except ValueError:\n            param = None\n\n    elif (\n        datatype is datetime.timedelta and\n        not isinstance(param, datetime.timedelta)\n    ):\n        try:\n            param = dtutil.strHoursToTimeDelta(param)\n        except ValueError:\n            param = None\n\n    elif datatype == \"json\" and isinstance(param, basestring):\n        try:\n            param = json.loads(param)\n        except ValueError:\n            param = None\n\n    return param"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef authenticate(user=None):  # noqa: E501\n    if connexion.request.is_json:\n        user = UserAuth.from_dict(connexion.request.get_json())  # noqa: E501\n\n    credentials = mapUserAuthToCredentials(user)\n    auth = ApitaxAuthentication.login(credentials)\n    if(not auth):\n        return ErrorResponse(status=401, message=\"Invalid credentials\")\n\n    access_token = create_access_token(identity={'username': user.username, 'role': auth['role']})\n    refresh_token = create_refresh_token(identity={'username': user.username, 'role': auth['role']})\n\n    return AuthResponse(status=201, message='User ' + user.username + ' was authenticated as ' + auth['role'], access_token=access_token, refresh_token=refresh_token, auth=UserAuth(username=auth['credentials'].username, api_token=auth['credentials'].token))", "response": "Authenticate with the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresolves a local uri.", "response": "def resolve_local(self, uri, base_uri, ref):\n        \"\"\"\n        Resolve a local ``uri``.\n         Does not check the store first.\n\n         :argument str uri: the URI to resolve\n         :returns: the retrieved document\n\n        \"\"\"\n        # read it from the filesystem\n        file_path = None\n        # make the reference saleskingstyle\n        item_name = None\n        if (uri.startswith(u\"file\") or\n                uri.startswith(u\"File\")):\n            if ref.startswith(u\"./\"):\n                ref = ref.split(u\"./\")[-1]\n                org_ref = ref\n            if ref.find(u\"#properties\") != -1:\n                ref = ref.split(u\"#properties\")[0]\n            if ref.find(u\".json\") != -1:\n                item_name = ref.split(u\".json\")[0]\n\n        # on windwos systesm this needs to happen\n        if base_uri.startswith(u\"file://\") is True:\n            base_uri = base_uri.split(u\"file://\")[1]\n        elif base_uri.startswith(u\"File://\") is True:\n            base_uri = base_uri.split(u\"File://\")[1]\n\n        file_path = os.path.join(base_uri, ref)\n        result = None\n        try:\n            schema_file = open(file_path, \"r\").read()\n            result = json.loads(schema_file.decode(\"utf-8\"))\n        except IOError as e:\n            log.error(u\"file not found %s\" % e)\n            msg = \"Could not find schema file. %s\" % file_path\n            raise SalesKingException(\"SCHEMA_NOT_FOUND\", msg)\n\n        if self.cache_remote:\n            self.store[uri] = result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolving(self, ref):\n        # print u\"resol_scope: %s, ref: %s\" % (self.resolution_scope, ref)\n        full_uri = urljoin(self.resolution_scope, ref)\n        uri, fragment = urldefrag(full_uri)\n        if not uri:\n            uri = self.base_uri\n\n        if uri in self.store:\n            document = self.store[uri]\n        else:\n            if (uri.startswith(u\"file\") or uri.startswith(u\"File\")):\n                try:\n                    document = self.resolve_local(full_uri, self.resolution_scope, ref)\n                except Exception as exc:\n                    raise RefResolutionError(exc)\n            else:\n\n                try:\n                    document = self.resolve_remote(uri)\n                except Exception as exc:\n                    raise RefResolutionError(exc)\n\n        old_base_uri, self.base_uri = self.base_uri, uri\n        try:\n            with self.in_scope(uri):\n                yield self.resolve_fragment(document, fragment)\n        finally:\n            self.base_uri = old_base_uri", "response": "Context manager which resolves a JSON ref and enters the resolution scope of this ref."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the wait time based on the number of retries and cap on the wait time.", "response": "def retry_wait_time(attempt, cap):\n    \"\"\"\n    Determine a retry wait time based on the number of the\n    retry attempt and a cap on the wait time. The wait time\n    uses an exponential backoff with a random jitter.\n    The algorithm used is explained at\n    https://www.awsarchitectureblog.com/2015/03/backoff.html.\n\n    :param int attempt: The number of the attempt\n    :param int cap: A cap on the wait time in milliseconds\n    :returns: The number of milliseconds to wait\n    :rtype: int\n    \"\"\"\n    base = 100\n    max_wait = min(cap, base * (2 ** attempt))\n    return random.choice(range(0, max_wait))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retry_ex(callback, times=3, cap=120000):\n    for attempt in range(times + 1):\n        if attempt > 0:\n            time.sleep(retry_wait_time(attempt, cap) / 1000.0)\n        try:\n            return callback()\n        except:\n            if attempt == times:\n                raise", "response": "Retry a callback function if any exception is raised."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef retry_bool(callback, times=3, cap=120000):\n    for attempt in range(times + 1):\n        if attempt > 0:\n            time.sleep(retry_wait_time(attempt, cap) / 1000.0)\n        ret = callback()\n        if ret or attempt == times:\n            break\n    return ret", "response": "Retry a callback function if it returns False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retryable(retryer=retry_ex, times=3, cap=120000):\n    def _retryable(func):\n        @f.wraps(func)\n        def wrapper(*args, **kwargs):\n            return retryer(lambda: func(*args, **kwargs), times, cap)\n        return wrapper\n    return _retryable", "response": "A decorator to make a function retry on a node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_environment(variables):\n    missing = [v for v in variables if v not in os.environ]\n    if missing:\n        formatted = ', '.join(missing)\n        message = 'Environment variables not set: {}'.format(formatted)\n        raise IncompleteEnvironment(message, missing)\n    return os.environ", "response": "Checks os. environ to ensure that a given collection of environment variables has been set."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges the length of a column in the supplied table.", "response": "def change_column_length(table: Table, column: Column, length: int, engine: Engine) -> None:\n    \"\"\" Change the column length in the supplied table\n    \"\"\"\n    if column.type.length < length:\n        print(\"Changing length of {} from {} to {}\".format(column, column.type.length, length))\n        column.type.length = length\n        column_name = column.name\n        column_type = column.type.compile(engine.dialect)\n        engine.execute('ALTER TABLE {table} ALTER COLUMN {column_name} TYPE {column_type}'.format(**locals()))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _db_urls(opts: Namespace) -> Tuple[str, str]:\n        return opts.crcdb.replace(\"//\", \"//{crcuser}:{crcpassword}@\".format(**opts.__dict__)),\\\n            opts.ontodb.replace(\"//\", \"//{ontouser}:{ontopassword}@\".format(**opts.__dict__))", "response": "Return the crc and ontology db urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all known tables and its full URI", "response": "def _tables(self) -> List[Tuple[str, str]]:\n        \"\"\"\n        Return a list of all known tables and and its full URI\n        :return: table name and full URI\n        \"\"\"\n        return [(k.rsplit('.', 1)[1] if '.' in k else k, k) for k in self._ont_tables.keys()]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising an exception if the given directory does not exist.", "response": "def isdir(path, message):\n    \"\"\"\n    Raise an exception if the given directory does not exist.\n\n    :param path: The path to a directory to be tested\n    :param message: A custom message to report in the exception\n\n    :raises: FileNotFoundError\n    \"\"\"\n    if not os.path.isdir(path):\n        raise FileNotFoundError(\n            errno.ENOENT,\n            \"{}: {}\".format(message, os.strerror(errno.ENOENT)), path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flush(self):\n        # Flush buffer\n        line = self._buffer.getvalue()\n        self._buffer = StringIO()\n\n        # Send the message\n        content = {\"session_id\": self._session, \"text\": line}\n        self._herald.fire(self._peer, beans.Message(MSG_CLIENT_PRINT, content))", "response": "Flushes buffered data to the target\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a line from the Herald client and returns it.", "response": "def readline(self):\n        \"\"\"\n        Waits for a line from the Herald client\n        \"\"\"\n        content = {\"session_id\": self._session}\n        prompt_msg = self._herald.send(\n            self._peer, beans.Message(MSG_CLIENT_PROMPT, content))\n        if prompt_msg.subject == MSG_SERVER_CLOSE:\n            # Client closed its shell\n            raise EOFError\n\n        return prompt_msg.content"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_frog_fresco(text, width, padding=8):\n    stem = r'        /'\n    frog = r\"\"\"\n{text}\n{stem}\n  @..@\n (----)\n( >__< )\n^^ ~~ ^^\"\"\"\n    offset = len(stem) - 1\n\n    formatted_indent = ' ' * offset\n    formatted_text = textwrap.fill(text, width=width-padding,\n        initial_indent=formatted_indent, subsequent_indent=formatted_indent)\n\n    return frog.format(stem=stem, text=formatted_text)", "response": "\\ A simple wrapper around the FROG function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mgz_to_nifti(filename,prefix=None,gzip=True):\n    '''Convert ``filename`` to a NIFTI file using ``mri_convert``'''\n    setup_freesurfer()\n    if prefix==None:\n        prefix = nl.prefix(filename) + '.nii'\n    if gzip and not prefix.endswith('.gz'):\n        prefix += '.gz'\n    nl.run([os.path.join(freesurfer_home,'bin','mri_convert'),filename,prefix],products=prefix)", "response": "Convert a MRI file to a NIFTI file using mri_convert."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef guess_home():\n    '''If ``freesurfer_home`` is not set, try to make an intelligent guess at it'''\n    global freesurfer_home\n    if freesurfer_home != None:\n        return True\n    # if we already have it in the path, use that\n    fv = nl.which('freeview')\n    if fv:\n        freesurfer_home = parpar_dir(os.path.realpath(fv))\n        return True\n    for guess_dir in guess_locations:\n        if os.path.exists(guess_dir):\n            freesurfer_home = guess_dir\n            return True\n    return False", "response": "Try to make an intelligent guess at the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the recon_all script", "response": "def recon_all(subj_id,anatomies):\n    '''Run the ``recon_all`` script'''\n    if not environ_setup:\n        setup_freesurfer()\n    if isinstance(anatomies,basestring):\n        anatomies = [anatomies]\n    nl.run([os.path.join(freesurfer_home,'bin','recon-all'),'-all','-subjid',subj_id] + [['-i',anat] for anat in anatomies])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a PEP - 257 docstring.", "response": "def parse_docstring(docstring):\n    \"\"\"\n    Parse a PEP-257 docstring.\n\n    SHORT -> blank line -> LONG\n\n    \"\"\"\n    short_desc = long_desc = ''\n    if docstring:\n        docstring = trim(docstring.lstrip('\\n'))\n        lines = docstring.split('\\n\\n', 1)\n        short_desc = lines[0].strip().replace('\\n', ' ')\n\n        if len(lines) > 1:\n            long_desc = lines[1].strip()\n    return short_desc, long_desc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a command directly to the CLI object.", "response": "def add_command(self, factory, main, name=None, context_kwargs=None):\n        \"\"\"\n        Attach a command directly to the :class:`CLI` object.\n\n        \"\"\"\n        if name is None:\n            name = factory.__name__.replace('_', '-')\n\n        if context_kwargs is None:\n            context_kwargs = {}\n\n        short_desc, long_desc = parse_docstring(factory.__doc__)\n        if long_desc:\n            long_desc = short_desc + '\\n\\n' + long_desc\n\n        # determine the absolute import string if relative\n        if isinstance(main, str) and (\n            main.startswith('.') or main.startswith(':')\n        ):\n            module = __import__(factory.__module__, None, None, ['__doc__'])\n            package = package_for_module(module)\n            if main in ['.', ':']:\n                main = package.__name__\n            else:\n                main = package.__name__ + main\n\n        self.commands[name] = CommandMeta(\n            factory=factory,\n            main=main,\n            name=name,\n            help=short_desc,\n            description=long_desc,\n            context_kwargs=context_kwargs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattaching a command to the current :class:`CLI` object. The function should accept an instance of an :class:`argparse.ArgumentParser` and use it to define extra arguments and options. These options will only affect the specified command.", "response": "def command(self, *args, **kwargs):\n        \"\"\"\n        Attach a command to the current :class:`CLI` object.\n\n        The function should accept an instance of an\n        :class:`argparse.ArgumentParser` and use it to define extra\n        arguments and options. These options will only affect the specified\n        command.\n\n        \"\"\"\n\n        def wrapper(func):\n            self.add_command(func, *args, **kwargs)\n            return func\n\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_commands(self, obj):\n        if isinstance(obj, str):\n            if obj.startswith('.') or obj.startswith(':'):\n                package = caller_package()\n                if obj in ['.', ':']:\n                    obj = package.__name__\n                else:\n                    obj = package.__name__ + obj\n            obj = pkg_resources.EntryPoint.parse('x=%s' % obj).resolve()\n        command.discover_and_call(obj, self.command)", "response": "Load commands defined on an arbitrary object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading commands defined within a pkg_resources entry point.", "response": "def load_commands_from_entry_point(self, specifier):\n        \"\"\"\n        Load commands defined within a pkg_resources entry point.\n\n        Each entry will be a module that should be searched for functions\n        decorated with the :func:`subparse.command` decorator. This\n        operation is not recursive.\n\n        \"\"\"\n        for ep in pkg_resources.iter_entry_points(specifier):\n            module = ep.load()\n            command.discover_and_call(module, self.command)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the command - line application.", "response": "def run(self, argv=None):\n        \"\"\"\n        Run the command-line application.\n\n        This will dispatch to the specified function or raise a\n        ``SystemExit`` and output the appropriate usage information\n        if there is an error parsing the arguments.\n\n        The default ``argv`` is equivalent to ``sys.argv[1:]``.\n\n        \"\"\"\n        if argv is None:  # pragma: no cover\n            argv = sys.argv[1:]\n        argv = [str(v) for v in argv]\n        meta, args = parse_args(self, argv)\n        context_factory = contextmanager(make_generator(self.context_factory))\n        with context_factory(self, args, **meta.context_kwargs) as context:\n            main = load_main(meta)\n            return main(context, args) or 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(xmpp_server, xmpp_port, peer_name, node_name, app_id,\n         xmpp_jid=None, xmpp_password=None):\n    \"\"\"\n    Runs the framework\n\n    :param xmpp_server: Address of the XMPP server\n    :param xmpp_port: Port of the XMPP server\n    :param peer_name: Name of the peer\n    :param node_name: Name (also, UID) of the node hosting the peer\n    :param app_id: Application ID\n    :param xmpp_jid: XMPP JID, None for Anonymous login\n    :param xmpp_password: XMPP account password\n    \"\"\"\n    # Create the framework\n    framework = pelix.framework.create_framework(\n        ('pelix.ipopo.core',\n         'pelix.ipopo.waiting',\n         'pelix.shell.core',\n         'pelix.shell.ipopo',\n         'pelix.shell.console',\n\n         # Herald core\n         'herald.core',\n         'herald.directory',\n         'herald.shell',\n\n         # Herald XMPP\n         'herald.transports.xmpp.directory',\n         'herald.transports.xmpp.transport',\n\n         # RPC\n         'pelix.remote.dispatcher',\n         'pelix.remote.registry',\n         'herald.remote.discovery',\n         'herald.remote.herald_xmlrpc',),\n        {herald.FWPROP_NODE_UID: node_name,\n         herald.FWPROP_NODE_NAME: node_name,\n         herald.FWPROP_PEER_NAME: peer_name,\n         herald.FWPROP_APPLICATION_ID: app_id})\n    context = framework.get_bundle_context()\n\n    # Start everything\n    framework.start()\n\n    # Instantiate components\n    with use_waiting_list(context) as ipopo:\n        # ... XMPP Transport\n        ipopo.add(herald.transports.xmpp.FACTORY_TRANSPORT,\n                  \"herald-xmpp-transport\",\n                  {herald.transports.xmpp.PROP_XMPP_SERVER: xmpp_server,\n                   herald.transports.xmpp.PROP_XMPP_PORT: xmpp_port,\n                   herald.transports.xmpp.PROP_XMPP_JID: xmpp_jid,\n                   herald.transports.xmpp.PROP_XMPP_PASSWORD: xmpp_password})\n\n    # Start the framework and wait for it to stop\n    framework.wait_for_stop()", "response": "Main function for the Herald application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_small_objects(image, min_size=50, connectivity=1):\n    return skimage.morphology.remove_small_objects(image,\n                                                   min_size=min_size,\n                                                   connectivity=connectivity)", "response": "Remove small objects from an image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninverting an image of the same dtype.", "response": "def invert(image):\n    \"\"\"Return an inverted image of the same dtype.\n\n    Assumes the full range of the input dtype is in use and\n    that no negative values are present in the input image.\n\n    :param image: :class:`jicbioimage.core.image.Image`\n    :returns: inverted image of the same dtype as the input\n    \"\"\"\n    if image.dtype == bool:\n        return np.logical_not(image)\n    maximum = np.iinfo(image.dtype).max\n    maximum_array = np.ones(image.shape, dtype=image.dtype) * maximum\n    return maximum_array - image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(*popenargs, **kwargs):\n    stdin = kwargs.pop('input', None)\n    timeout = kwargs.pop('timeout', None)\n    check = kwargs.pop('check', False)\n    if stdin is not None:\n        if 'stdin' in kwargs:\n            raise ValueError('stdin and input arguments may not both be used.')\n        kwargs['stdin'] = PIPE\n\n    process = Popen(*popenargs, **kwargs)\n    try:\n        if __timeout__:\n            stdout, stderr = process.communicate(stdin, timeout=timeout)\n        else:\n            stdout, stderr = process.communicate(stdin)\n    except TimeoutExpired:\n        # this will never happen if __timeout__ is False\n        process.kill()\n        stdout, stderr = process.communicate()\n        # pylint: disable=no-member\n        raise _TimeoutExpired(process.args, timeout, output=stdout,\n                              stderr=stderr)\n    except:\n        process.kill()\n        process.wait()\n        raise\n    retcode = process.poll()\n    if check and retcode:\n        raise CalledProcessError(retcode, popenargs,\n                                 output=stdout, stderr=stderr)\n    return CompletedProcess(popenargs, retcode, stdout, stderr)", "response": "Run a command with arguments and return a CompletedProcess instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise CalledProcessError if the exit code is non - zero.", "response": "def check_returncode(self):\n        \"\"\"Raise CalledProcessError if the exit code is non-zero.\"\"\"\n        if self.returncode:\n            raise CalledProcessError(self.returncode, self.args, self.stdout,\n                                     self.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef double_lorgauss(x,p):\n    mu,sig1,sig2,gam1,gam2,G1,G2 = p\n    gam1 = float(gam1)\n    gam2 = float(gam2)\n\n    G1 = abs(G1)\n    G2 = abs(G2)\n    sig1 = abs(sig1)\n    sig2 = abs(sig2)\n    gam1 = abs(gam1)\n    gab2 = abs(gam2)\n    \n    L2 = (gam1/(gam1 + gam2)) * ((gam2*np.pi*G1)/(sig1*np.sqrt(2*np.pi)) - \n                                 (gam2*np.pi*G2)/(sig2*np.sqrt(2*np.pi)) +\n                                 (gam2/gam1)*(4-G1-G2))\n    L1 = 4 - G1 - G2 - L2\n\n    \n    #print G1,G2,L1,L2\n    \n    y1 = G1/(sig1*np.sqrt(2*np.pi)) * np.exp(-0.5*(x-mu)**2/sig1**2) +\\\n      L1/(np.pi*gam1) * gam1**2/((x-mu)**2 + gam1**2)\n    y2 = G2/(sig2*np.sqrt(2*np.pi)) * np.exp(-0.5*(x-mu)**2/sig2**2) +\\\n      L2/(np.pi*gam2) * gam2**2/((x-mu)**2 + gam2**2)\n    lo = (x < mu)\n    hi = (x >= mu)\n        \n    return  y1*lo + y2*hi", "response": "Evaluates a normalized distribution that is a mixture of a double - sided Gaussian and Double - sided Lorentzian distribution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_double_lorgauss(bins,h,Ntry=5):\n    try:\n        from lmfit import minimize, Parameters, Parameter, report_fit\n    except ImportError:\n        raise ImportError('you need lmfit to use this function.')\n        \n    #make sure histogram is normalized\n    h /= np.trapz(h,bins)\n\n    #zero-pad the ends of the distribution to keep fits positive\n    N = len(bins)\n    dbin = (bins[1:]-bins[:-1]).mean()\n    newbins = np.concatenate((np.linspace(bins.min() - N/10*dbin,bins.min(),N/10),\n                             bins,\n                             np.linspace(bins.max(),bins.max() + N/10*dbin,N/10)))\n    newh = np.concatenate((np.zeros(N/10),h,np.zeros(N/10)))\n\n    \n    mu0 = bins[np.argmax(newh)]\n    sig0 = abs(mu0 - newbins[np.argmin(np.absolute(newh - 0.5*newh.max()))])\n\n    def set_params(G1,G2):\n        params = Parameters()\n        params.add('mu',value=mu0)\n        params.add('sig1',value=sig0)\n        params.add('sig2',value=sig0)\n        params.add('gam1',value=sig0/10)\n        params.add('gam2',value=sig0/10)\n        params.add('G1',value=G1)\n        params.add('G2',value=G2)\n        return params\n\n    sum_devsq_best = np.inf\n    outkeep = None\n    for G1 in np.linspace(0.1,1.9,Ntry):\n        for G2 in np.linspace(0.1,1.9,Ntry):\n            params = set_params(G1,G2)\n        \n            def residual(ps):\n                pars = (params['mu'].value,\n                        params['sig1'].value,\n                        params['sig2'].value,\n                        params['gam1'].value,\n                        params['gam2'].value,\n                        params['G1'].value,\n                        params['G2'].value)\n                hmodel = double_lorgauss(newbins,pars)\n                return newh-hmodel\n\n            out = minimize(residual,params)\n            pars = (out.params['mu'].value,out.params['sig1'].value,\n                    out.params['sig2'].value,out.params['gam1'].value,\n                    out.params['gam2'].value,out.params['G1'].value,\n                    out.params['G2'].value)\n\n            sum_devsq = ((newh - double_lorgauss(newbins,pars))**2).sum()\n            #print 'devs = %.1f; initial guesses for G1, G2; %.1f, %.1f' % (sum_devsq,G1, G2)\n            if sum_devsq < sum_devsq_best:\n                sum_devsq_best = sum_devsq\n                outkeep = out\n            \n\n    return (outkeep.params['mu'].value,abs(outkeep.params['sig1'].value),\n            abs(outkeep.params['sig2'].value),abs(outkeep.params['gam1'].value),\n            abs(outkeep.params['gam2'].value),abs(outkeep.params['G1'].value),\n            abs(outkeep.params['G2'].value))", "response": "Uses lmfit to fit a Double LorGauss distribution to a provided histogram."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate normalized two - sided Gaussian distribution at input value x.", "response": "def doublegauss(x,p):\n    \"\"\"Evaluates normalized two-sided Gaussian distribution\n\n    Parameters\n    ----------\n    x : float or array-like\n        Value(s) at which to evaluate distribution\n\n    p : array-like\n        Parameters of distribution: (mu: mode of distribution,\n                                     sig1: LH width,\n                                     sig2: RH width)\n\n    Returns\n    -------\n    value : float or array-like\n        Distribution evaluated at input value(s).  If single value provided,\n        single value returned.\n    \"\"\"\n    mu,sig1,sig2 = p\n    x = np.atleast_1d(x)\n    A = 1./(np.sqrt(2*np.pi)*(sig1+sig2)/2.)\n    ylo = A*np.exp(-(x-mu)**2/(2*sig1**2))\n    yhi = A*np.exp(-(x-mu)**2/(2*sig2**2))\n    y = x*0\n    wlo = np.where(x < mu)\n    whi = np.where(x >= mu)\n    y[wlo] = ylo[wlo]\n    y[whi] = yhi[whi]\n    if np.size(x)==1:\n        return y[0]\n    else:\n        return y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doublegauss_cdf(x,p):\n    x = np.atleast_1d(x)\n    mu,sig1,sig2 = p\n    sig1 = np.absolute(sig1)\n    sig2 = np.absolute(sig2)\n    ylo = float(sig1)/(sig1 + sig2)*(1 + erf((x-mu)/np.sqrt(2*sig1**2)))\n    yhi = float(sig1)/(sig1 + sig2) + float(sig2)/(sig1+sig2)*(erf((x-mu)/np.sqrt(2*sig2**2)))\n    lo = x < mu\n    hi = x >= mu\n    return ylo*lo + yhi*hi", "response": "Cumulative distribution function for two - sided Gaussian\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfit a two - sided Gaussian to a set of samples.", "response": "def fit_doublegauss_samples(samples,**kwargs):\n    \"\"\"Fits a two-sided Gaussian to a set of samples.\n\n    Calculates 0.16, 0.5, and 0.84 quantiles and passes these to\n    `fit_doublegauss` for fitting.\n\n    Parameters\n    ----------\n    samples : array-like\n        Samples to which to fit the Gaussian.\n\n    kwargs\n        Keyword arguments passed to `fit_doublegauss`.\n    \"\"\"\n    sorted_samples = np.sort(samples)\n    N = len(samples)\n    med = sorted_samples[N/2]\n    siglo = med - sorted_samples[int(0.16*N)]\n    sighi = sorted_samples[int(0.84*N)] - med\n    return fit_doublegauss(med,siglo,sighi,median=True,**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_doublegauss(med,siglo,sighi,interval=0.683,p0=None,median=False,return_distribution=True):\n    if median:\n        q1 = 0.5 - (interval/2)\n        q2 = 0.5 + (interval/2)\n        targetvals = np.array([med-siglo,med,med+sighi])\n        qvals = np.array([q1,0.5,q2])\n        def objfn(pars):\n            logging.debug('{}'.format(pars))\n            logging.debug('{} {}'.format(doublegauss_cdf(targetvals,pars),qvals))\n            return doublegauss_cdf(targetvals,pars) - qvals\n\n        if p0 is None:\n            p0 = [med,siglo,sighi]\n        pfit,success = leastsq(objfn,p0)\n\n    else:\n        q1 = 0.5 - (interval/2)\n        q2 = 0.5 + (interval/2)\n        targetvals = np.array([med-siglo,med+sighi])\n        qvals = np.array([q1,q2])\n        def objfn(pars):\n            params = (med,pars[0],pars[1])\n            return doublegauss_cdf(targetvals,params) - qvals\n\n        if p0 is None:\n            p0 = [siglo,sighi]\n        pfit,success = leastsq(objfn,p0)\n        pfit = (med,pfit[0],pfit[1])\n\n    if return_distribution:\n        dist = DoubleGauss_Distribution(*pfit)\n        return dist\n    else:\n        return pfit", "response": "Fits a two - sided Gaussian distribution to match a given confidence interval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the desired percentile of the CDF at a given resolution.", "response": "def pctile(self,pct,res=1000):\n        \"\"\"Returns the desired percentile of the distribution.\n\n        Will only work if properly normalized.  Designed to mimic\n        the `ppf` method of the `scipy.stats` random variate objects.\n        Works by gridding the CDF at a given resolution and matching the nearest\n        point.  NB, this is of course not as precise as an analytic ppf.\n\n        Parameters\n        ----------\n\n        pct : float\n            Percentile between 0 and 1.\n\n        res : int, optional\n            The resolution at which to grid the CDF to find the percentile.\n\n        Returns\n        -------\n        percentile : float\n        \"\"\"\n        grid = np.linspace(self.minval,self.maxval,res)\n        return grid[np.argmin(np.absolute(pct-self.cdf(grid)))]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the distribution to an HDF5 file.", "response": "def save_hdf(self,filename,path='',res=1000,logspace=False):\n        \"\"\"Saves distribution to an HDF5 file.\n\n        Saves a pandas `dataframe` object containing tabulated pdf and cdf\n        values at a specfied resolution.  After saving to a particular path, a\n        distribution may be regenerated using the `Distribution_FromH5` subclass.  \n\n        Parameters\n        ----------\n        filename : string\n            File in which to save the distribution.  Should end in .h5.\n\n        path : string, optional\n            Path in which to save the distribution within the .h5 file.  By\n            default this is an empty string, which will lead to saving the\n            `fns` dataframe at the root level of the file.\n\n        res : int, optional\n            Resolution at which to grid the distribution for saving.\n\n        logspace : bool, optional\n            Sets whether the tabulated function should be gridded with log or\n            linear spacing.  Default will be logspace=False, corresponding\n            to linear gridding.\n\n        \"\"\"\n        if logspace:\n            vals = np.logspace(np.log10(self.minval),\n                               np.log10(self.maxval),\n                               res)\n        else:\n            vals = np.linspace(self.minval,self.maxval,res)\n        d = {'vals':vals,\n             'pdf':self(vals),\n             'cdf':self.cdf(vals)}\n        df = pd.DataFrame(d)\n        df.to_hdf(filename,path+'/fns')\n        if hasattr(self,'samples'):\n            s = pd.Series(self.samples)\n            s.to_hdf(filename,path+'/samples')\n        store = pd.HDFStore(filename)\n        attrs = store.get_storer('{}/fns'.format(path)).attrs\n        attrs.keywords = self.keywords\n        attrs.disttype = type(self)\n        store.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the distribution of the is .", "response": "def plot(self,minval=None,maxval=None,fig=None,log=False,\n             npts=500,**kwargs):\n        \"\"\"\n        Plots distribution.\n\n        Parameters\n        ----------\n        minval : float,optional\n            minimum value to plot.  Required if minval of Distribution is \n            `-np.inf`.\n\n        maxval : float, optional\n            maximum value to plot.  Required if maxval of Distribution is \n            `np.inf`.\n\n        fig : None or int, optional\n            Parameter to pass to `setfig`.  If `None`, then a new figure is \n            created; if a non-zero integer, the plot will go to that figure \n            (clearing everything first), if zero, then will overplot on \n            current axes.\n\n        log : bool, optional\n            If `True`, the x-spacing of the points to plot will be logarithmic.\n\n        npoints : int, optional\n            Number of points to plot.\n\n        kwargs\n            Keyword arguments are passed to plt.plot\n\n        Raises\n        ------\n        ValueError\n            If finite lower and upper bounds are not provided.\n        \"\"\"\n        if minval is None:\n            minval = self.minval\n        if maxval is None:\n            maxval = self.maxval\n        if maxval==np.inf or minval==-np.inf:\n            raise ValueError('must have finite upper and lower bounds to plot. (use minval, maxval kws)')\n\n        if log:\n            xs = np.logspace(np.log10(minval),np.log10(maxval),npts)\n        else:\n            xs = np.linspace(minval,maxval,npts)\n\n        setfig(fig)\n        plt.plot(xs,self(xs),**kwargs)\n        plt.xlabel(self.name)\n        plt.ylim(ymin=0,ymax=self(xs).max()*1.2)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning random samples generated according to the distribution of the CDF.", "response": "def resample(self,N,minval=None,maxval=None,log=False,res=1e4):\n        \"\"\"Returns random samples generated according to the distribution\n\n        Mirrors basic functionality of `rvs` method for `scipy.stats`\n        random variates.  Implemented by mapping uniform numbers onto the\n        inverse CDF using a closest-matching grid approach.\n\n        Parameters\n        ----------\n        N : int\n            Number of samples to return\n\n        minval,maxval : float, optional\n            Minimum/maximum values to resample.  Should both usually just be \n            `None`, which will default to `self.minval`/`self.maxval`.\n\n        log : bool, optional\n            Whether grid should be log- or linear-spaced.\n\n        res : int, optional\n            Resolution of CDF grid used.\n\n        Returns\n        -------\n        values : ndarray\n            N samples.\n\n        Raises\n        ------\n        ValueError\n            If maxval/minval are +/- infinity, this doesn't work because of\n            the grid-based approach.\n\n        \"\"\"\n        N = int(N)\n        if minval is None:\n            if hasattr(self,'minval_cdf'):\n                minval = self.minval_cdf\n            else:\n                minval = self.minval\n        if maxval is None:\n            if hasattr(self,'maxval_cdf'):\n                maxval = self.maxval_cdf\n            else:\n                maxval = self.maxval\n\n        if maxval==np.inf or minval==-np.inf:\n            raise ValueError('must have finite upper and lower bounds to resample. (set minval, maxval kws)')\n\n        u = rand.random(size=N)\n        if log:\n            vals = np.logspace(log10(minval),log10(maxval),res)\n        else:\n            vals = np.linspace(minval,maxval,res)\n            \n        #sometimes cdf is flat.  so ys will need to be uniqued\n        ys,yinds = np.unique(self.cdf(vals), return_index=True)\n        vals = vals[yinds]\n        \n\n        inds = np.digitize(u,ys)\n        return vals[inds]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a histogram of samples using provided bins.", "response": "def plothist(self,fig=None,**kwargs):\n        \"\"\"Plots a histogram of samples using provided bins.\n        \n        Parameters\n        ----------\n        fig : None or int\n            Parameter passed to `setfig`.\n\n        kwargs\n            Keyword arguments passed to `plt.hist`.\n        \"\"\"\n        setfig(fig)\n        plt.hist(self.samples,bins=self.bins,**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a bootstrap resampling of provided samples.", "response": "def resample(self,N):\n        \"\"\"Returns a bootstrap resampling of provided samples.\n\n        Parameters\n        ----------\n        N : int\n            Number of samples.\n        \"\"\"\n        inds = rand.randint(len(self.samples),size=N)\n        return self.samples[inds]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resample(self,N):\n        return rand.random(size=N)*(self.maxval - self.minval) + self.minval", "response": "Returns a random sampling."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tzname_in_python2(myfunc):\n    def inner_func(*args, **kwargs):\n        if PY3:\n            return myfunc(*args, **kwargs)\n        else:\n            return myfunc(*args, **kwargs).encode()\n    return inner_func", "response": "Decorator to change unicode output into bytestrings in Python 2 and Python 3"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ac3(space):\n    #determine arcs\n    arcs = {}\n    for name in space.variables:\n        arcs[name] = set([])\n    for const in space.constraints:\n        for vname1,vname2 in product(const.vnames,const.vnames):\n            if vname1 != vname2:\n                #this is pessimistic, we assume that each constraint\n                #pairwisely couples all variables it affects\n                arcs[vname1].add(vname2)\n\n    #enforce node consistency\n    for vname in space.variables:\n        for const in space.constraints:\n            _unary(space,const,vname)\n\n    #assemble work list\n    worklist = set([])\n    for v1 in space.variables:\n        for v2 in space.variables:\n            for const in space.constraints:\n                if _binary(space,const,v1,v2):\n                    for name in arcs[v1]:\n                        worklist.add((v1,name))\n\n    #work through work list\n    while worklist:\n        v1,v2 = worklist.pop()\n        for const in space.constraints:\n            if _binary(space,const,v1,v2):\n                for vname in arcs[v1]:\n                    worklist.add((v1,vname))", "response": "This function calculates the domains of the variables by propagating constraints to ensure that the arcs in the list are consistent with the variables in the list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unary(space,const,name):\n    if not name in const.vnames:\n        return False\n    if space.variables[name].discrete:\n        values = const.domains[name]\n    else:\n        values = const.domains[name]\n\n    space.domains[name] = space.domains[name].intersection(values)\n    return True", "response": "Reduce the domain of variable name to be node - consistent with this\n    constraint. Returns True if the domain of variable name was modified otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _binary(space,const,name1,name2):\n    if not (name1 in const.vnames and name2 in const.vnames):\n        return False\n    remove = set([])\n    for v1 in space.domains[name1].iter_members():\n        for v2 in space.domains[name2].iter_members():\n            if const.consistent({name1 : v1, name2 : v2}):\n                break\n        else:\n            remove.add(v1)\n\n    if len(remove) > 0:\n        if space.variables[name1].discrete:\n            remove = DiscreteSet(remove)\n        else:\n            remove = IntervalSet.from_values(remove)\n\n        space.domains[name1] = space.domains[name1].difference(remove)\n        return True\n    else:\n        return False", "response": "Returns True if the domain of variable name1 is two - consistent and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing an ArgumentParser for the given task.", "response": "def get_task_parser(task):\n    \"\"\"\n    Construct an ArgumentParser for the given task.\n\n    This function returns a tuple (parser, proxy_args).\n    If task accepts varargs only, proxy_args is True.\n    If task accepts only positional and explicit keyword args,\n    proxy args is False.\n    \"\"\"\n    args, varargs, keywords, defaults = inspect.getargspec(task)\n    defaults = defaults or []\n    parser = argparse.ArgumentParser(\n        prog='ape ' + task.__name__,\n        add_help=False,\n        description=task.__doc__,\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    posargslen = len(args) - len(defaults)\n    if varargs is None and keywords is None:\n        for idx, arg in enumerate(args):\n            if idx < posargslen:\n                parser.add_argument(arg)\n            else:\n                default = defaults[idx - posargslen]\n                parser.add_argument('--' + arg, default=default)\n        return parser, False\n    elif not args and varargs and not keywords and not defaults:\n        return parser, True\n    else:\n        raise InvalidTask(ERRMSG_UNSUPPORTED_SIG % task.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invoke_task(task, args):\n    parser, proxy_args = get_task_parser(task)\n    if proxy_args:\n        return task(*args)\n    else:\n        pargs = parser.parse_args(args)\n        return task(**vars(pargs))", "response": "Parse args and invoke task function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_task_module(feature):\n    try:\n        importlib.import_module(feature)\n    except ImportError:\n        raise FeatureNotFound(feature)\n\n    tasks_module = None\n\n    # ape tasks may be located in a module called apetasks\n    # or (if no apetasks module exists) in a module called tasks\n    try:\n        tasks_module = importlib.import_module(feature + '.apetasks')\n    except ImportError:\n        # No apetasks module in feature ... try tasks\n        pass\n\n    try:\n        tasks_module = importlib.import_module(feature + '.tasks')\n    except ImportError:\n        # No tasks module in feature ... skip it\n        pass\n\n    return tasks_module", "response": "Returns the module containing the ape tasks of the given feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(args, features=None):\n    features = features or []\n    for feature in features:\n        tasks_module = get_task_module(feature)\n        if tasks_module:\n            tasks.superimpose(tasks_module)\n\n    if len(args) < 2 or (len(args) == 2 and args[1] == 'help'):\n        tasks.help()\n    else:\n        taskname = args[1]\n        try:\n            task = tasks.get_task(taskname, include_helpers=False)\n        except TaskNotFound:\n            print('Task \"%s\" not found! Use \"ape help\" to get usage information.' % taskname)\n        else:\n            remaining_args = args[2:] if len(args) > 2 else []\n            invoke_task(task, remaining_args)", "response": "Runs an ape task."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collect(self):\n        if self.symlink:\n            if sys.platform == 'win32':\n                raise CommandError(\"Symlinking is not supported by this \"\n                                   \"platform (%s).\" % sys.platform)\n            if not self.local:\n                raise CommandError(\"Can't symlink to a remote destination.\")\n\n        if self.clear:\n            self.clear_dir('')\n\n        handler = self._get_handler()\n\n        do_post_process = self.post_process and hasattr(self.storage, 'post_process')\n\n        found_files = SortedDict()\n        for finder in finders.get_finders():\n            for path, storage in finder.list(self.ignore_patterns):\n                # Prefix the relative path if the source storage contains it\n                if getattr(storage, 'prefix', None):\n                    prefixed_path = os.path.join(storage.prefix, path)\n                else:\n                    prefixed_path = path\n\n                if prefixed_path not in found_files:\n                    found_files[prefixed_path] = (storage, path)\n                    handler(path, prefixed_path, storage)\n                    if self.progressive_post_process and do_post_process:\n                        try:\n                            self._post_process(\n                                    {prefixed_path: (storage, path)},\n                                    self.dry_run)\n                        except ValueError as e:\n                            message = ('%s current storage requires all files'\n                                ' to have been collected first. Try '\n                                ' ecstatic.storage.CachedStaticFilesStorage' \\\n                                % e)\n                            raise ValueError(message)\n\n        if not self.progressive_post_process and do_post_process:\n            self._post_process(found_files, self.dry_run)\n\n        return {\n            'modified': self.copied_files + self.symlinked_files,\n            'unmodified': self.unmodified_files,\n            'post_processed': self.post_processed_files,\n        }", "response": "Collect the static files for this command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the file should be copied.", "response": "def compare(self, path, prefixed_path, source_storage):\n        \"\"\"\n        Returns True if the file should be copied.\n        \"\"\"\n        # First try a method on the command named compare_<comparison_method>\n        # If that doesn't exist, create a comparitor that calls methods on the\n        # storage with the name <comparison_method>, passing them the name.\n        comparitor = getattr(self, 'compare_%s' % self.comparison_method, None)\n        if not comparitor:\n            comparitor = self._create_comparitor(self.comparison_method)\n        return comparitor(path, prefixed_path, source_storage)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitiate a session globally used in prof", "response": "def initiate_session(config):\n    \"\"\"\n    Initiate a session globally used in prof :\n      + Retrive the cookie\n      + Log to prof\n\n    Returns an initiated session\n    \"\"\"\n    global baseurl\n    baseurl = config['DEFAULT']['baseurl']\n    if 'session' in config['DEFAULT']:\n        cookies = {\n            'PHPSESSID': config['DEFAULT']['session']\n        }\n        prof_session.cookies = requests.utils.cookiejar_from_dict(cookies)\n    try:\n        valid = verify_session(prof_session, baseurl)\n        if not valid:\n            # Looks like this session is not valid anymore, try to get a new one\n            get_session(prof_session, baseurl, config)\n        return prof_session\n    except:\n        print(\"{baseurl} not reachable. Verify your connection\".format(baseurl=baseurl))\n        exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nverifying that this session is still valid on this baseurl", "response": "def verify_session(session, baseurl):\n    \"\"\"\n    Check that this session is still valid on this baseurl, ie, we get a list of projects\n    \"\"\"\n    request = session.post(baseurl+\"/select_projet.php\")\n    return VERIFY_SESSION_STRING in request.content.decode('iso-8859-1')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a valid session for this baseurl", "response": "def get_session(session, baseurl, config):\n    \"\"\"\n    Try to get a valid session for this baseurl, using login found in config.\n    This function invoques Firefox if necessary\n    \"\"\"\n    # Read proxy for firefox\n    if environ.get(\"HTTP_PROXY\"):\n        myProxy = environ.get(\"HTTP_PROXY\")\n        proxy = Proxy({\n            'proxyType': ProxyType.MANUAL,\n            'httpProxy': myProxy,\n            'ftpProxy': myProxy,\n            'sslProxy': myProxy,\n            'noProxy': ''  # set this value as desired\n        })\n    else:\n        proxy = None\n\n    if 'login' in config['DEFAULT']:\n        login, password = credentials(config['DEFAULT']['login'])\n    else:\n        login, password = credentials()\n\n    browser = webdriver.Firefox(proxy=proxy)\n    browser.get(baseurl)\n    browser.find_element_by_name('login').send_keys(login)\n    browser.find_element_by_name('passwd').send_keys(password)\n\n    cookie = {'PHPSESSID': browser.get_cookie('PHPSESSID')['value']}\n    prof_session.cookies = requests.utils.cookiejar_from_dict(cookie)\n    print(\"Please log using firefox\")\n    while True:\n        try:\n            browser.find_element_by_css_selector(\"select\")\n            break\n        except:\n            sleep(0.5)\n    browser.close()\n    set_sessid(cookie['PHPSESSID'])\n    if not verify_session(session, baseurl):\n        print(\"Cannot get a valid session, retry\")\n        get_session(session, baseurl, {'DEFAULT': {}})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef credentials(login=None):\n    if not login:\n        login = environ.get(\"PROF_LOGIN\")\n    password = environ.get(\"PROF_PASSWORD\")\n    if not login:\n        try:\n            login = input(\"login? \")\n            print(\"\\t\\tDon't get prompted everytime. Store your login in the ``~/.profrc`` config file\")\n        except KeyboardInterrupt:\n            exit(0)\n    if not password:\n        try:\n            password = getpass.getpass(\"pass for {0} ? \".format(login))\n        except KeyboardInterrupt:\n            exit(0)\n    return (login, password)", "response": "Find user credentials. We should have parsed the command line for a ``--login`` option.\n    We will try to find credentials in environment variables.\n    We will ask user if we cannot find any in arguments nor environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef display(self):\n        '''\n        Displays statistics about our LM\n        '''\n        voc_list = []\n        doc_ids = self.term_count_n.keys()\n        doc_ids.sort()\n        for doc_id in doc_ids:\n            ngrams = len(self.term_count_n[doc_id]['ngrams'])\n            print 'n-Grams (doc %s): %d' % (str(doc_id), ngrams)\n            ngrams1 = len(self.term_count_n_1[doc_id]['ngrams'])\n            print '(n-1)-Grams (doc %s): %d' % (str(doc_id), ngrams1)\n            voc_list.append(ngrams)\n        print 'Classed Vocabularies:', voc_list\n        print ''\n        corpus_ngrams = len(self.corpus_count_n['ngrams']) \n        print 'n-Grams (collection): %d' % (corpus_ngrams)\n        corpus_ngrams1 = len(self.corpus_count_n_1['ngrams']) \n        print '(n-1)-Grams (collection): %d' % (corpus_ngrams1)\n        self.unseen_counts.display()", "response": "Displays statistics about our LM\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of n - gram counts for a corpus", "response": "def get_ngram_counts(self):\n        ''' Returns a list of n-gram counts\n            Array of classes counts and last item is for corpus\n        '''\n        ngram_counts = {\n            'classes': [],\n            'corpus': 0\n        }\n        doc_ids = self.term_count_n.keys()\n        doc_ids.sort()\n        for doc_id in doc_ids:\n            print self.term_count_n[doc_id]\n            class_ngrams = len(self.term_count_n[doc_id]['ngrams'])\n            ngram_counts['classes'].append(class_ngrams)\n        corpus_ngrams = len(self.corpus_count_n['ngrams'])\n        ngram_counts['corpus'] = corpus_ngrams\n        return ngram_counts"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert terms to all possibe ngrams terms", "response": "def to_ngrams(self, terms):\n        ''' Converts terms to all possibe ngrams \n            terms: list of terms\n        '''\n        if len(terms) <= self.n:\n            return terms\n        if self.n == 1:\n            n_grams = [[term] for term in terms]\n        else:\n            n_grams = []\n            for i in range(0,len(terms)-self.n+1):\n                n_grams.append(terms[i:i+self.n])\n        return n_grams"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lr_padding(self, terms):\n        '''\n        Pad doc from the left and right before adding,\n        depending on what's in self.lpad and self.rpad\n        If any of them is '', then don't pad there. \n        '''\n        lpad = rpad = []\n        if self.lpad:\n            lpad = [self.lpad] * (self.n - 1) \n        if self.rpad:\n            rpad = [self.rpad] * (self.n - 1) \n        return lpad + terms + rpad", "response": "Pads the left and right of a set of terms."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new document to our language model.", "response": "def add_doc(self, doc_id ='', doc_terms=[], doc_length=-1):\n        '''\n        Add new document to our Language Model (training phase)\n        doc_id is used here, so we build seperate LF for each doc_id\n        I.e. if you call it more than once with same doc_id,\n        then all terms given via doc_terms will contribute to same LM\n        doc_terms: list of words in document to be added \n        doc_length: the length of the document, you can provide it yourself,\n                    otherwise, we use len(doc_terms) instead.\n        '''\n        if doc_length == -1:\n            self.update_lengths(doc_id=doc_id, doc_length=len(doc_terms))\n        else:\n            self.update_lengths(doc_id=doc_id, doc_length=int(doc_length)) \n        for term in doc_terms: \n            self.vocabulary.add(term)\n        terms = self.lr_padding(doc_terms)\n        ngrams = self.to_ngrams(terms)    \n        self.update_counts(doc_id, ngrams)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate(self, doc_terms=[], actual_id='', doc_length=-1):\n        '''\n        Given a set of terms, doc_terms\n        We find the doc in training data (calc_id),\n        whose LM is more likely to produce those terms\n        Then return the data structure calculated back\n        doc_length is passed to pr_ngram() and pr_doc()\n            it is up to them to use it or not.\n            normally, it should be ignored if doc_length == -1\n        calculated{\n            prob: calculated probability Pr(calc_id/doc_terms)\n            calc_id: Document ID in training data.\n            actual_id: Just returned back as passed to us.\n            seen_unseen_count: Counts for terms seen/unseen in training data\n        }  \n        ''' \n        calculated = {\n            'prob': -1,\n            'calc_id': '',\n            'actual_id': actual_id,\n            'seen_unseen_count': (0,0),\n            'all_probs': []\n        }\n        terms = self.lr_padding(doc_terms)\n        ngrams = self.to_ngrams(terms) \n        for doc_id in self.term_count_n:\n            #print '\\n', doc_id, ':'\n            doc_pr = 0\n            new_doc = True\n            seen_count = 0\n            unseen_count = 0\n            for ngram in ngrams:\n                (ngram_pr, ngram_seen) = self.pr_ngram(doc_id, ngram, \n                        new_doc=new_doc, log=True, logbase=2, doc_length=doc_length)\n                doc_pr += ngram_pr\n                new_doc = False\n                if ngram_seen:\n                    seen_count += 1\n                else:\n                    unseen_count += 1\n            doc_pr += self.pr_doc(doc_id, doc_length=doc_length) \n            if self.verbose:            \n                print doc_id, actual_id, doc_pr \n            calculated['all_probs'].append(doc_pr) \n            if calculated['prob'] == -1 or doc_pr < calculated['prob']:\n                calculated['prob'] = doc_pr\n                calculated['calc_id'] = doc_id\n                calculated['seen_unseen_count'] = (seen_count, unseen_count)\n        self.unseen_counts.per_doc(doc_id=calculated['actual_id'], \n            seen_unseen=calculated['seen_unseen_count'])\n        self.unseen_counts.per_cic(calculated_id=calculated['calc_id'], \n            actual_id=calculated['actual_id'],\n            seen_unseen=calculated['seen_unseen_count'])\n        return calculated", "response": "Calculate the probability of a set of terms in the training data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        response = None\n        root = tkinter.Tk()\n        root.withdraw()\n        while response is not True:\n            response = tkinter.messagebox.askokcancel(title=self.title, message=self.pre_message)\n        if self.post_message:\n            print(self.post_message)\n        self.exit_time = time.time()", "response": "This method is run when the user has closed the dialog box and return when the user has closed the dialog box and return when the user has closed the dialog box and return when the user has closed the dialog box and the user has closed the dialog box and return when the user has closed it\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download(url, file=None):\n    import urllib.request\n    import shutil\n    if isinstance(file, str):\n        file = open(file, 'wb')\n    try:\n        with urllib.request.urlopen(url) as response:\n            if file:\n                shutil.copyfileobj(response, file)\n            else:\n                return response.read()\n    finally:\n        if file:\n            file.close()", "response": "Download the file from url and return the request bytes instead of file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload and extract the tar at the url to the given folder", "response": "def download_extract_tar(tar_url, folder, tar_filename=''):\n    \"\"\"\n    Download and extract the tar at the url to the given folder\n\n    Args:\n        tar_url (str): URL of tar file to download\n        folder (str): Location of parent directory to extract to. Doesn't have to exist\n        tar_filename (str): Location to download tar. Default is to a temp file\n    \"\"\"\n    try:\n        makedirs(folder)\n    except OSError:\n        if not isdir(folder):\n            raise\n    data_file = tar_filename\n    if not data_file:\n        fd, data_file = mkstemp('.tar.gz')\n        download(tar_url, os.fdopen(fd, 'wb'))\n    else:\n        download(tar_url, data_file)\n\n    with tarfile.open(data_file) as tar:\n        tar.extractall(path=folder)"}
